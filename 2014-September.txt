From alaw005 at gmail.com  Mon Sep  1 02:07:06 2014
From: alaw005 at gmail.com (Adam Lawrence)
Date: Mon, 1 Sep 2014 12:07:06 +1200
Subject: [R] Bus stop sequence matching problem
In-Reply-To: <CAP01uR=6DCA9_mreFsRRgEs9ck6jqxfjQOm4KXzyb32BJqAUxw@mail.gmail.com>
References: <CAA_YnRwA=_7BQ5Xxi14ENAqaVE51WVXY5aLajdg=b+YXgkx3Yw@mail.gmail.com>
	<CAP01uR=6DCA9_mreFsRRgEs9ck6jqxfjQOm4KXzyb32BJqAUxw@mail.gmail.com>
Message-ID: <CAA_YnRzKTw_5H7Cnr=tNxgGSLW-44BBHr8EjJ_DT5pH6tc1jtw@mail.gmail.com>

Thank you for the help everyone, it has been a very helpful but steep
learning curve for me. I have ended up doing a loop as suggested by David
as I could understand this a bit better and seems can apply more generally.
I have set out my solution below in case that helps anyone.

I am interested though if the loop can be vectorized, as from my reading
this is the preferred (faster) R approach but I can't get my head around
how it works.

Regards
Adam

#
# I could either 1) loop through stops and check onoff, or 2) loop through
onoff and check stops.
#
# I chose option 2 because the first option might miss data if a stop
occurs more than once in the sequence and the
# first occurance of stop_onoff does not relate to the first occurance (e.g
for stop_sequence A,B,C,D,B,A if stop_onoff
# records are B, A then on first iteration option 1 will link the first
stop_sequence A to stop_onoff A and subsequent
# iterations will ignore stop_onoff B because occurs before A).
#
bus_load_profile <- function(stop_onoff, stop_sequence) {

  # Add additional columns to stop_sequence to hold matched on/off/load data
  stop_sequence <- cbind(stop_sequence, on=0, off=0, load=0)

  # Start stop_sequence index at 1 (i.e. over all records)
  idx_stop_sequence <- 1

  # Loop through stop_onoff records and assign to stop_sequence
  for (idx_stop_onoff in 1:nrow(stop_onoff)) {

    # Get stop_onoff ref
    ref_onoff <- as.character(stop_onoff$ref[idx_stop_onoff])

    # Get candidate refs from stop_sequence (i.e only those occuring after
any previous matches)
    ref_sequence_canidates <-
as.character(stop_sequence$ref[idx_stop_sequence:nrow(stop_sequence)])

    # Match the first occurance on ref_onoff in ref_sequence_canidates
    match_stop_sequence <- which(ref_onoff == ref_sequence_canidates)[1]

    # Update stop_sequence index to match current record
    idx_stop_sequence <- idx_stop_sequence + match_stop_sequence

    # Add stop_onoff data to the stop_sequence ()
    stop_sequence$on[idx_stop_sequence - 1] <- stop_onoff$on[idx_stop_onoff]
    stop_sequence$off[idx_stop_sequence - 1] <-
stop_onoff$off[idx_stop_onoff]
  }

  # Generate load profile
  stop_sequence$load <- cumsum(stop_sequence$on - stop_sequence$off)

  # return data.frame with load profile
  return(stop_sequence)

}


# Original test data:

# Test data, note use of data.frames because data is pulled from database,
noting real stop_equence data has
# additional columns. NB I have removed the seq column from stop_sequence
as the stops are by definition in sequence
stop_sequence <- data.frame(ref=c('A','B','C','D','B','A'))
stop_onoff <-
data.frame(ref=c('A','D','B','A'),on=c(5,0,10,0),off=c(0,2,2,6))
# Get bus load profile
bus_load_profile(stop_onoff, stop_sequence)

#Aditional test:
stop_sequence <- data.frame(ref=c('A','B','C','D','B','A'))
stop_onoff <- data.frame(ref=c('B','A'),on=c(10,0),off=c(4,6))
bus_load_profile(stop_onoff, stop_sequence)


On 31 August 2014 01:08, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:

> Try dtw.  First convert ref to numeric since dtw does not handle
> character input.  Then align using dtw and NA out repeated values in
> the alignment.  Finally zap ugly row names and calculate loading:
>
> library(dtw)
> s1 <- as.numeric(stop_sequence$ref)
> s2 <- as.numeric(factor(as.character(stop_onoff$ref),
> levels(stop_sequence$ref)))
> a <- dtw(s1, s2)
> DF <- cbind(stop_sequence,
>       stop_onoff[replace(a$index2, c(FALSE, diff(a$index2) == 0), NA),
> ])[-3]
> rownames(DF) <- NULL
> transform(DF, loading = cumsum(ifelse(is.na(on), 0, on)) -
>                         cumsum(ifelse(is.na(off), 0, off)))
>
> giving:
>
>   seq ref on off loading
> 1  10   A  5   0       5
> 2  20   B NA  NA       5
> 3  30   C NA  NA       5
> 4  40   D  0   2       3
> 5  50   B 10   2      11
> 6  60   A  0   6       5
>
> You will need to test this with more data and tweak it if necessary
> via the various dtw arguments.
>
>
> On Fri, Aug 29, 2014 at 8:46 PM, Adam Lawrence <alaw005 at gmail.com> wrote:
> > I am hoping someone can help me with a bus stop sequencing problem in R,
> > where I need to match counts of people getting on and off a bus to the
> > correct stop in the bus route stop sequence. I have tried looking
> > online/forums for sequence matching but seems to refer to numeric
> sequences
> > or DNA matching and over my head. I am after a simple example if anyone
> can
> > please help.
> >
> > I have two data series as per below (from database), that I want to
> > combine. In this example ?stop_sequence? includes the equence (seq) of
> bus
> > stops and ?stop_onoff? is a count of people getting on and off at certain
> > stops (there is no entry if noone gets on or off).
> >
> > stop_sequence <- data.frame(seq=c(10,20,30,40,50,60),
> > ref=c('A','B','C','D','B','A'))
> > ##   seq ref
> > ## 1  10   A
> > ## 2  20   B
> > ## 3  30   C
> > ## 4  40   D
> > ## 5  50   B
> > ## 6  60   A
> > stop_onoff <-
> > data.frame(ref=c('A','D','B','A'),on=c(5,0,10,0),off=c(0,2,2,6))
> > ##   ref on off
> > ## 1   A  5   0
> > ## 2   D  0   2
> > ## 3   B 10   2
> > ## 4   A  0   6
> >
> > I need to match the stop_onoff numbers in the right sto sequence, with
> the
> > correctly matched output as follows (load is a cumulative count of on and
> > off)
> >
> > desired_output <- data.frame(seq=c(10,20,30,40,50,60),
> > ref=c('A','B','C','D','B','A'),
> > on=c(5,'-','-',0,10,0),off=c(0,'-','-',2,2,6), load=c(5,0,0,3,11,5))
> > ##   seq ref on off load
> > ## 1  10   A  5   0    5
> > ## 2  20   B  -   -    0
> > ## 3  30   C  -   -    0
> > ## 4  40   D  0   2    3
> > ## 5  50   B 10   2   11
> > ## 6  60   A  0   6    5
> >
> > In this example the stop ?B? is matched to the second stop ?B? in the
> stop
> > sequence and not the first because the onoff data is after stop ?D?.
> >
> > Any guidance much appreciated.
> >
> > Regards
> > Adam
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>

	[[alternative HTML version deleted]]


From grothered at gmail.com  Mon Sep  1 05:12:27 2014
From: grothered at gmail.com (Gareth Davies)
Date: Mon, 01 Sep 2014 13:12:27 +1000
Subject: [R] rgl zooming to an arbitrary location
Message-ID: <5403E41B.90507@gmail.com>


I have been using rgl to view xyz point clouds containing topographic 
data ( with around 10^5 - 10^6 points).

It's working well aside from one thing: I would like to be able to zoom 
into an arbitrary part of the plot. However so far I could only figure 
out how to zoom into the centre.

See the example below -- in this case, I cannot 'zoom-in' to anything 
other than the central hill in the topography, whereas I would like to 
be able to zoom to an arbitrary location.

Is there a way to get around this?

##########################################
# EXAMPLE CODE
##########################################
library(rgl)
# Make up some topography
x=runif(1e+06, min=0,max=1000)
y=runif(1e+06, min=0,max=1000)
# Elevation with 'hill' in the centre
z=sin(x/50.)+cos(y/50.) + 30*exp(-((x-500)^2+(y-500)^2)*0.001)
plot3d(x,y,z,col=z+3,aspect=FALSE)
# Now try zooming [right mouse button]. I can only zoom into the central 
hill, not elsewhere.


Below are the details of my R Install

 > sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
  [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8
  [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
  [1] rgl_0.93.1098        unstructInterp_0.0-1 rgeos_0.3-6
  [4] rgdal_0.8-16         sp_1.0-15            geometry_0.3-4
  [7] magic_1.5-6          abind_1.4-0          SearchTrees_0.5.2
[10] roxygen2_4.0.1

loaded via a namespace (and not attached):
[1] digest_0.6.4    grid_3.1.1      lattice_0.20-29 Rcpp_0.11.2
[5] stringr_0.6.2   tools_3.1.1
 >


From tsonnekus at gmail.com  Mon Sep  1 12:52:17 2014
From: tsonnekus at gmail.com (Tinus Sonnekus)
Date: Mon, 1 Sep 2014 12:52:17 +0200
Subject: [R] Depth vs Temp graph for different transects
Message-ID: <CAPEc57GMyRhONYzsOfEU_jhoAyMvEh4PSnneEiWTWDB35iKd4A@mail.gmail.com>

Hi All,

Have the following code. The graph works well plotting the 15 transect for
me however the legend shows a total of 22 transects. The original data has
22 transects numbered from 1 to 22. New data set got only 15. How can I get
the legend to show only the transects plotted.


# Create Line Chart


TAll <- read.csv("TAll Data.csv")


# convert factor to numeric for convenience
TAll$Tran <- as.numeric(TAll$Trans)
nTrans <- max(TAll$Trans)

# get the range for the x and y axis
xrange <- range(TAll$Temp)
yrange <- range(TAll$Depth)

# set up the plot
plot(xrange, yrange, ylim = rev(yrange), type="n", xlab="Temp (deg C)",
  ylab="Depth (m)" )
colors <- rainbow(nTrans)
linetype <- c(1:nTrans)
plotchar <- seq(1,1+nTrans,1)

# add lines
for (i in 1:nTrans) {
  tree <- subset(TAll, Trans==i)
  lines(tree$Temp, tree$Depth, type="b", lwd=1.5,
    lty=linetype[i], col=colors[i], pch=plotchar[i])
}

# add a legend
legend(xrange[-2], yrange[-2], 1:nTrans, cex=0.8, col=colors,
  pch=plotchar, lty=linetype, title="Transect")



Thanks for the help,
Tinus

-- 
M.J. Sonnekus
PhD Candidate (The Phytoplankton of the southern Agulhas Current Large
Marine Ecosystem (ACLME))
Department of Botany
South Campus
Nelson Mandela Metropolitan University
PO Box 77000
Port Elizabeth
South Africa
6031

Cell: 082 080 9638
E-mail: tsonnekus at gmail.com

	[[alternative HTML version deleted]]


From peljasz at yahoo.co.uk  Mon Sep  1 13:25:01 2014
From: peljasz at yahoo.co.uk (lejeczek)
Date: Mon, 01 Sep 2014 12:25:01 +0100
Subject: [R] Building R for better performance
In-Reply-To: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
Message-ID: <5404578D.6050801@yahoo.co.uk>

could you tell us if the same/similar performance benefits 
we should expect when gnu complier suite + MKL are teamed up?
and how to configure such a compilation?
many thanks


On 04/03/14 21:44, Anspach, Jonathan P wrote:
> Greetings,
>
> I'm a software engineer with Intel.  Recently I've been investigating R performance on Intel Xeon and Xeon Phi processors and RH Linux.  I've also compared the performance of R built with the Intel compilers and Intel Math Kernel Library to a "default" build (no config options) that uses the GNU compilers.  To my dismay, I've found that the GNU build always runs on a single CPU core, even during matrix operations.  The Intel build runs matrix operations on multiple cores, so it is much faster on those operations.  Running the benchmark-2.5 on a 24 core Xeon system, the Intel build is 13x faster than the GNU build (21 seconds vs 275 seconds).  Unfortunately, this advantage is not documented anywhere that I can see.
>
> Building with the Intel tools is very easy.  Assuming the tools are installed in /opt/intel/composerxe, the process is simply (in bash shell):
>
> $ . /opt/intel/composerxe/bin/compilervars.sh intel64
> $ ./configure --with-blas="-L/opt/intel/composerxe/mkl/lib/intel64 -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread -lm" --with-lapack CC=icc CFLAGS=-O2 CXX=icpc CXXFLAGS=-O2 F77=ifort FFLAGS=-O2 FC=ifort FCFLAGS=-O2
> $ make
> $ make check
>
> My questions are:
> 1) Do most system admins and/or R installers know about this performance difference, and use the Intel tools to build R?
> 2) Can we add information on the advantage of building with the Intel tools, and how to do it, to the installation instructions and FAQ?
>
> I can post my data if anyone is interested.
>
> Thanks,
> Jonathan Anspach
> Sr. Software Engineer
> Intel Corp.
> jonathan.p.anspach at intel.com
> 713-751-9460
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sagnik.stats at gmail.com  Mon Sep  1 12:05:37 2014
From: sagnik.stats at gmail.com (sagnik chakravarty)
Date: Mon, 1 Sep 2014 15:35:37 +0530
Subject: [R] Issues with fa() function in "psych"
In-Reply-To: <CAMwbFxgCcVjn_MFmU6YW9i01MO30ku3GM5Ly9Qa4J9QpLeC8qQ@mail.gmail.com>
References: <CAMwbFxi2=mhjB66YH-=U7L2p0ZbeqCLDraOiUjDzUcCCtxDuKQ@mail.gmail.com>
	<CAAcyNCxvhFHFzGxTyEZ3z4YW8tOmo5ix7enAZ4TYXvPTjT=X-w@mail.gmail.com>
	<85300B76-7E05-4663-8D3A-E8C3FCE7DB15@revelle.net>
	<CAMwbFxjcsExo4XZUi3pCot5efYkK5U=NcMdxbkyqf20c9wabdg@mail.gmail.com>
	<1DEB6779-C83E-425B-8856-BE15F8A990DD@revelle.net>
	<CAMwbFxgCcVjn_MFmU6YW9i01MO30ku3GM5Ly9Qa4J9QpLeC8qQ@mail.gmail.com>
Message-ID: <CAMwbFxj_Er3k6gcqqpWXiFEEwCGcnGuE2cEM7NWoqtOhBX9okg@mail.gmail.com>

Hi William,

Recently I noticed that if the requested rotation is not available,
"principal" function also defaults to rotate=?none? without any WARNING.
You had earlier fixed the same issue with "fa" in version 1.4.4. Kindly
include the same for "principal" also.

Also, as I had pointed out earlier in my trailing mails, is there any
update on the following suggestion:

"The fa() function doesn't account for 'Heywood cases' (communality greater
than 1) and never ever throws out any error related to that which other
softwares do. This is a serious and common issue in iterative factor
analysis and hence should have been accounted for."

Awaiting your revert,

Thanks and Regards,

Sagnik


On Fri, May 16, 2014 at 10:54 AM, sagnik chakravarty <sagnik.stats at gmail.com
> wrote:

> Hi William,
>
> Thanks for the update. I see this package has so many capabilities ! I
> will suggest further for its development if anything else comes to my mind.
>
> Regards,
> Sagnik
>
>
> On Thu, May 15, 2014 at 6:34 AM, William Revelle <lists at revelle.net>
> wrote:
>
>> Sagnik,
>>
>> I did some more checking and in fact you can do equamax through GPA
>> rotation.  (Gunter Nickel pointed this out in a post to R-help).  I will
>> implement this in version 1.4.6 (1.4.5 is now working its way through the
>> various CRAN mirrors).
>>
>> You might like 1.4.5 in that I have added various ways of displaying
>> confidence intervals (cats eye plots) as well as upper and lower confidence
>> limits for correlations (cor.plot.upperLowerCi)
>>
>> Bill
>>
>> On Apr 10, 2014, at 1:22 AM, sagnik chakravarty <sagnik.stats at gmail.com>
>> wrote:
>>
>> > Thanks a lot Bill and Revelle for your helpful response.
>> > It would have been great if I could know when we can expect the release
>> of the edited version 1.4.4.
>> >
>> > Sagnik
>> >
>> >
>> > On Wed, Apr 9, 2014 at 8:05 PM, William Revelle <lists at revelle.net>
>> wrote:
>> > Sagnik raises the question as to why the psych package does not offer
>> the ?equamax? rotation.
>> > It is because all rotations are handled through the GPArotation package
>> which does not offer equamax.
>> >
>> > Sagnik also points out that if the requested rotation is not available,
>> fa defaults to rotate=?none? without any warning.  I have fixed that for
>> the  next release (1.4.4).
>> > (1.4.4 also will fix a bug in corr.test introduced into 1.4.3).
>> >
>> >
>> > The question about why printing just the loadings matrix leaves blank
>> cells?  That is because the loadings matrix of class ?loadings? which the
>> default print function prints with a cut = .3.
>> > Using the example from Sagnik, print(efa_pa$loadings,cut=0) will match
>> the output of efa_pa.
>> >
>> > The fm=?pa? option runs conventional principal axis factor analysis
>> (ala SPSS).  As documented, this iterates max.iter times
>> >
>> > "Not all factor programs that do principal axes do iterative solutions.
>> The example from the SAS manual (Chapter 26) is such a case. To achieve
>> that solution, it is necessary to specify that the max.iterations = 1.
>> Comparing that solution to an iterated one (the default) shows that
>> iterations improve the solution. In addition, fm="minres" or fm="mle"
>> produces even better solutions for this example.?
>> >
>> > The com column is factor complexity using the index developed by
>> Hofmann (1978).  It is a row wise measure of item complexity.
>> > I have added more documentation to this in 1.4.4
>> >
>> > Bill
>> >
>> >
>> > On Apr 8, 2014, at 2:28 AM, Pascal Oettli <kridox at ymail.com> wrote:
>> >
>> > > Hello,
>> > >
>> > > And what about submitting your suggestions directly to the package
>> > > author/maintainer?
>> > >
>> > > And please don't post in HTML.
>> > >
>> > > Regards,
>> > > Pascal
>> > >
>> > > On Tue, Apr 8, 2014 at 3:13 PM, sagnik chakravarty
>> > > <sagnik.stats at gmail.com> wrote:
>> > >> Hi Team,
>> > >>
>> > >> I was using your "psych" package for factor analysis and was also
>> comparing
>> > >> the results with SAS results. I have some suggestions and/or
>> confusions
>> > >> regarding the fa() function in the package:
>> > >>
>> > >>   - The fa() function *doesn't account for Heywood cases*
>> (communality
>> > >>   greater than 1) and never ever throws out any error related to
>> that which
>> > >>   other softwares do. This is a serious and common issue in
>> iterative factor
>> > >>   analysis and hence should have been accounted for.
>> > >>
>> > >>
>> > >>   - The fa() function doesn't provide "equamax" rotation in its
>> rotation
>> > >>   list and still if you specify "*rotation=equamax*", it will run
>> without
>> > >>   throwing out any error and even mentioning in the result that
>> "equamax" has
>> > >>   been applied. But I have thoroughly compared results from "
>> > >>   *rotation=none*" and "*rotation=equamax*" options and they are
>> exactly
>> > >>   same. *That means fa() is not doing the rotation at all and yet
>> telling
>> > >>   that it is doing that!!* I have even mentioned "*rotation=crap*"
>> option
>> > >>   just to check and surprisingly it ran(without any error) with the
>> result
>> > >>   showing:
>> > >>
>> > >>           *Factor Analysis using method =  gls*
>> > >> *           Call: fa(r = cor_mat, nfactors = 4, n.obs = 69576,
>> rotate =
>> > >> "crap", fm = "gls")*
>> > >>
>> > >>            I hope you understand the severity of this bug and hence
>> > >> request you to correct this.
>> > >>
>> > >>   - To my sense, there might be some problem with "fm=ml" and "fm=pa"
>> > >>   options since the convergence issue should be with MLE method and
>> not PA
>> > >>   method but while running factor analysis with PA, I am getting the
>> > >>   following warning:
>> > >>
>> > >>            *maximum iteration exceeded*
>> > >> *            The estimated weights for the factor scores are probably
>> > >> incorrect.  Try a different factor extraction method.*
>> > >>
>> > >>             If I compare the results of R and SAS,* I am getting
>> > >> convergence error for MLE in SAS whereas I am getting the same error
>> for PA
>> > >> in R *!! I am not being able to understand this mismatch.
>> > >>
>> > >>   - If I call the *loading matrix like efa_pa$loadings, the matrix
>> shown
>> > >>   has many blank cells whereas the final result showing the loadings
>> doesn't
>> > >>   have so* !!
>> > >>
>> > >> *Loadings:*
>> > >> *             PA1    PA2    PA3    PA4   *
>> > >> *Var1    0.401                       -0.243*
>> > >> *Var2    0.336 -0.104            0.710*
>> > >> *Var3    0.624  0.123 0.170      *
>> > >>
>> > >>
>> > >>   - Could you please explain* what the "com" column means* in the
>> output:?
>> > >>
>> > >>
>> > >> *           PA1   PA3   PA2   PA4     h2          u2      com*
>> > >> *Var1  0.44  0.14 -0.03  -0.10 0.22665  0.773  1.3*
>> > >> *Var2  0.08  0.11  0.02   0.78  0.62951  0.370  1.1*
>> > >> *Var3  0.62  0.12  0.15   0.14  0.43578  0.564  1.3*
>> > >>
>> > >>   - Request you to add option for *"equamax" rotation* also if
>> possible.
>> > >>
>> > >>
>> > >> I have come across the above issues until now. Please do correct me
>> if I am
>> > >> wrong.
>> > >>
>> > >> Awaiting your revert which would clear out my confusions,
>> > >>
>> > >> Thanks for your valuable time,
>> > >>
>> > >> Sagnik
>> > >>
>> > >> --
>> > >> Regards,
>> > >>
>> > >> *SAGNIK CHAKRAVARTY*
>> > >>
>> > >> *Mob:*  +919972865435
>> > >> *Email:* sagnik.stats at gmail.com
>> > >>           sagnik.739 at gmail.com
>> > >>
>> > >>        [[alternative HTML version deleted]]
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > >
>> > >
>> > > --
>> > > Pascal Oettli
>> > > Project Scientist
>> > > JAMSTEC
>> > > Yokohama, Japan
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> >
>> > William Revelle
>> http://personality-project.org/revelle.html
>> > Professor
>> http://personality-project.org
>> > Department of Psychology   http://www.wcas.northwestern.edu/psych/
>> > Northwestern University    http://www.northwestern.edu/
>> > Use R for psychology             http://personality-project.org/r
>> > It is 5 minutes to midnight        http://www.thebulletin.org
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > --
>> > Regards,
>> >
>> > SAGNIK CHAKRAVARTY
>> >
>> > Mob:  +919972865435
>> > Email: sagnik.stats at gmail.com
>> >            sagnik.739 at gmail.com
>>
>> William Revelle
>> http://personality-project.org/revelle.html
>> Professor                                  http://personality-project.org
>> Department of Psychology   http://www.wcas.northwestern.edu/psych/
>> Northwestern University    http://www.northwestern.edu/
>> Use R for psychology             http://personality-project.org/r
>> It is 5 minutes to midnight        http://www.thebulletin.org
>>
>>
>>
>>
>>
>
>
> --
> Regards,
>
> *SAGNIK CHAKRAVARTY*
>
> *Mob:*  +919972865435
> *Email:* sagnik.stats at gmail.com
>            sagnik.739 at gmail.com
>



-- 
Regards,

SAGNIK CHAKRAVARTY
Statistician, India
sagnik.stats at gmail.com

	[[alternative HTML version deleted]]


From d.kazakiewicz at gmail.com  Mon Sep  1 12:27:22 2014
From: d.kazakiewicz at gmail.com (Denis Kazakiewicz)
Date: Mon, 01 Sep 2014 12:27:22 +0200
Subject: [R] Linear regression of 0/1 response ElemStatLearn (Fig. 2.1 the
 elements of statistical learning)
Message-ID: <54044A0A.10501@gmail.com>

Hello
In chapter 2 ESL book authors write: Let's look at example of linear 
model in a classification context
They fit a simple linear model g = 0.3290614 -0.0226360x1 + 0.2495983x2 + e,
where g is given with values 0 or 1. Then they made a decision boundary 
where yhat, if yhat>0.5 then yellow.


Question: There is a separation line on the x1x2 plot. Where did 
intercept and slope for this line come from?

In the ElemStatLearn R package, they simply put as abline( 
(0.5-coef(x.mod)[1] 
<http://i.stack.imgur.com/ANaTc.png>)/coef(x.mod)[3], 
-coef(x.mod)[2]/coef(x.mod)[3]), where first term is the intercept, and 
second term is slope for this line

Regards
Denis


-------------- next part --------------
A non-text attachment was scrubbed...
Name: ElemStatLearn.png
Type: image/png
Size: 115859 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140901/bed7b4e1/attachment.png>

From smartpink111 at yahoo.com  Mon Sep  1 13:00:20 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 1 Sep 2014 04:00:20 -0700
Subject: [R] r convert current date format from y-m-d to m/d/y
In-Reply-To: <CAP0TLd_iMZwa4ZkyPPpJCiK8E4VDJ4DNVFba_YtOjJFbtaGmvA@mail.gmail.com>
References: <CAP0TLd_iMZwa4ZkyPPpJCiK8E4VDJ4DNVFba_YtOjJFbtaGmvA@mail.gmail.com>
Message-ID: <1409569220.46632.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

Use  ?format

 format(d, "%m/%d/%Y")
#[1] "09/01/2014"

A.K.


On Monday, September 1, 2014 5:26 AM, Velappan Periasamy <veepsirtt at gmail.com> wrote:





d=Sys.Date()
"2014-09-01"

How to convert this "2014-09-01" to "09/01/2014" format?

(ie y-m-d to m/d/y format)

thanks

veepsirtt


From angel.rodriguez at matiainstituto.net  Mon Sep  1 13:08:21 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Mon, 1 Sep 2014 13:08:21 +0200
Subject: [R] Unexpected behavior when giving a value to a new variable
	based on the value of another variable
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
	<CAAJSdjhPM_=A4Hs3E=Tr9C_iOdfj5pMCJCgjq0Z5FK8RmNBVcw@mail.gmail.com>
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B23C@MATIAEXCH.matiaf.local>

Thank you John, Jim, Jeff and both Davids for your answers.

After trying different combinations of values for the variable samplem, it looks like if age is greater than 65, R applies the correct code 1 whatever the value of samplem, but if age is less than 65, it just copies the values of samplem to sample. I do not understand why it does so.

In any case, Jim's syntax work very well, although I do not understand why either.

Answering to Jim, I just wanted a variable that could identify individuals with some characteristics (not only age, as in this example that has been oversimplified).

Best regards,

Angel Rodriguez-Laso


-----Mensaje original-----
De: John McKown [mailto:john.archie.mckown at gmail.com]
Enviado el: vie 29/08/2014 14:46
Para: Angel Rodriguez
CC: r-help
Asunto: Re: [R] Unexpected behavior when giving a value to a new variable based on the value of another variable
 
On Fri, Aug 29, 2014 at 3:53 AM, Angel Rodriguez
<angel.rodriguez at matiainstituto.net> wrote:
>
> Dear subscribers,
>
> I've found that if there is a variable in the dataframe with a name very similar to a new variable, R does not give the correct values to this latter variable based on the values of a third value:
>
>
<snip>
>
> Any clue for this behavior?
>
<snip>
>
> Thank you very much.
>
> Angel Rodriguez-Laso
> Research project manager
> Matia Instituto Gerontologico

That is unusual, but appears to be documented in a section from

?`[`

<quote>
Character indices

Character indices can in some circumstances be partially matched (see
pmatch) to the names or dimnames of the object being subsetted (but
never for subassignment). Unlike S (Becker et al p. 358)), R never
uses partial matching when extracting by [, and partial matching is
not by default used by [[ (see argument exact).

Thus the default behaviour is to use partial matching only when
extracting from recursive objects (except environments) by $. Even in
that case, warnings can be switched on by
options(warnPartialMatchDollar = TRUE).

Neither empty ("") nor NA indices match any names, not even empty nor
missing names. If any object has no names or appropriate dimnames,
they are taken as all "" and so match nothing.
</quote>

Note the commend about "partial matching" in the middle paragraph in
the quote above.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown







	[[alternative HTML version deleted]]


From patzelt at g.harvard.edu  Mon Sep  1 14:47:18 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Mon, 1 Sep 2014 08:47:18 -0400
Subject: [R] Correlation Matrix with a Covariate
Message-ID: <CAB9UfhROxa7jz2pc4yHL2cZxTewyJaWt1N7PqKG+Az724tiyyg@mail.gmail.com>

R Help -

I'm trying to run a correlation matrix with a covariate of "age" and will
at some point will also want to covary other variables concurrently.

I'm using the "psych" package and have tried other methods such as writing
a loop to extract semi-partial correlations, but it does not seem to be
working. How can I accomplish this?

library(psych)
> set.cor(y = (66:76), x = c(1:64), z = 65, data = dat5)
Error in solve.default(x.matrix, xy.matrix) :
  Lapack routine dgesv: system is exactly singular: U[54,54] = 0

structure(list(cope8_StriatumMask_7_betas_mean = c(11.47, -0.6002,
-11.59, -52.51, 36.63, -36.99, -26.89, 21.68, 3.776, 19.35, -56.44,
-11.41, -1.825, 5.327, -2.886, 11.91, 43.99, 42.17, 21.19, -1.14,
-9.156, -3.53, -12.79, 33.88, -35.92, 7.613, -61.59, -6.754,
2.672, -25.09, 19.87, -21.09, -37.97, -11.07, -7.276, 21.94,
-18.94, -16.83, 19.96, 7.533, -44.57, -23.17, 22.54),
cope7_StriatumMask_7_betas_mean = c(-11.47,
0.6002, 11.59, 52.51, -36.63, 36.99, 26.89, -21.68, -3.776, -19.35,
56.44, 11.41, 1.825, -5.327, 2.886, -11.91, -43.99, -42.17, -21.19,
1.14, 9.156, 3.53, 12.79, -33.88, 35.92, -7.613, 61.59, 6.754,
-2.672, 25.09, -19.87, 21.09, 37.97, 11.07, 7.276, -21.94, 18.94,
16.83, -19.96, -7.533, 44.57, 23.17, -22.54),
cope6_StriatumMask_7_betas_mean = c(-15.11,
-20.31, -24.63, -17.44, -33.64, -38.77, -37.67, -27.93, -13.28,
-7.351, -9.147, -2.561, -28.92, -26.39, 65.4, -30.5, -6.315,
6.017, -59.84, -12.24, 14.86, -36.17, -14.39, -11.74, -19.17,
41.23, 4.33, 19.48, 12.88, -29.51, 32.7, -35.65, -49.27, -4.2,
16.27, -9.706, -19.26, -22.49, -54.12, -48.03, 82.09, 1.946,
-68.66), cope5_StriatumMask_7_betas_mean = c(15.11, 20.31, 24.63,
17.44, 33.64, 38.77, 37.67, 27.93, 13.28, 7.351, 9.147, 2.561,
28.92, 26.39, -65.4, 30.5, 6.315, -6.017, 59.84, 12.24, -14.86,
36.17, 14.39, 11.74, 19.17, -41.23, -4.33, -19.48, -12.88, 29.51,
-32.7, 35.65, 49.27, 4.2, -16.27, 9.706, 19.26, 22.49, 54.12,
48.03, -82.09, -1.946, 68.66), cope4_StriatumMask_7_betas_mean = c(14.75,
15.24, 4.935, 4.835, 10.32, -19.23, -14.4, 39.01, 7.088, 16.77,
10.78, 4.741, 15.2, 6.144, -3.572, 9.995, 42.44, 36.24, 23.44,
-0.4025, 10.57, -8.036, 0.4127, -5.74, 7.335, -5.735, -32.63,
-3.122, 16.36, -6.741, 9.36, -2.567, -5.515, 22.81, 9.99, -2.034,
10.38, -16.34, 37.27, 12.11, -2.593, 5.341, 11.64),
cope3_StriatumMask_7_betas_mean = c(3.8,
8.024, 6.609, 56.04, -17.79, 27.05, 10.92, 19.12, 4.651, -1.325,
66.15, 16.36, 17.79, 2.177, -4.663, 4.534, 7.788, 3.822, 6.74,
-3.433, 20.96, 1.451, 16.81, -31.09, 26.59, -8.875, 27.25, -1.37,
8.634, 22.93, -10.99, 18.74, 34.3, 34.26, 6.989, -20.35, 38.61,
14.78, 14.24, 8.544, 42.79, 27.42, -12.53), cope2_StriatumMask_7_betas_mean
= c(-22.45,
-18.01, -28.1, -10.91, -33.2, -24.75, -9.261, 4.794, -11.8, -4.1,
-20.08, 17.07, -22.33, -12.02, 21.62, -10.31, 10, 3.088, -45.09,
-32.44, 5.73, -21.31, -12.11, -1.46, -21.26, 36.54, 7.501, 11.95,
11.9, -6.681, 22.08, -24.31, -22.79, -28.37, 23.36, -1.101, -3.984,
-6.315, -28.91, -35.64, 43.7, 8.317, -67.12),
cope1_StriatumMask_7_betas_mean = c(-3.331,
-0.6516, -3.038, 23.44, 2.235, 20.09, 16.99, 18.96, 1.348, 4.113,
-14.4, -2.449, 4.893, 12, -18.31, 15.32, 16.84, 1.516, 15.34,
-1.8, -11.98, 9.774, 2.055, 8.772, -50.38, -5.62, 2.985, 4.993,
7.956, 19.07, -10.01, 12.46, 13.24, -15.76, 9.281, 8.894, 12.9,
14.74, 23.37, 10.72, -16.88, 6.961, -8.737),
cope8_StriatumMask_6_betas_mean = c(24.61,
16.14, -9.034, -59.09, 23.45, -6.531, -15.25, 44.85, -0.97, 19.71,
-34.17, -13.74, 16.35, 22.46, -9.196, -1.073, 48.33, 52.74, 29.12,
24.44, -4.246, 3.402, -26.58, 35.38, -32.03, 10.15, -65.41, -12.14,
3.905, -2.271, 4.286, -1.484, -32.3, 0.3132, -25.83, 6.807, -14.56,
-6.214, 16.98, 27.18, -55.46, -38.73, 35.93),
cope7_StriatumMask_6_betas_mean = c(-24.61,
-16.14, 9.034, 59.09, -23.45, 6.531, 15.25, -44.85, 0.97, -19.71,
34.17, 13.74, -16.35, -22.46, 9.196, 1.073, -48.33, -52.74, -29.12,
-24.44, 4.246, -3.402, 26.58, -35.38, 32.03, -10.15, 65.41, 12.14,
-3.905, 2.271, -4.286, 1.484, 32.3, -0.3132, 25.83, -6.807, 14.56,
6.214, -16.98, -27.18, 55.46, 38.73, -35.93),
cope6_StriatumMask_6_betas_mean = c(-11.24,
-17.26, -17.59, -27.92, -42.3, -39.53, -49.99, -11.12, -23.51,
4.573, -2.713, 18.23, -13.94, -31.14, 72.81, -23.42, 18.89, 9.695,
-30.2, 2.776, 12.57, -15.8, -11.16, -19.92, -34.84, 5.129, -8.743,
1.578, 31.23, -23.09, 24.02, -50.99, -52.38, -15.81, 14.61, -26.57,
-23.76, -24.59, -41.38, -42.29, 48.82, -6.491, -57.52),
cope5_StriatumMask_6_betas_mean = c(11.24,
17.26, 17.59, 27.92, 42.3, 39.53, 49.99, 11.12, 23.51, -4.573,
2.713, -18.23, 13.94, 31.14, -72.81, 23.42, -18.89, -9.695, 30.2,
-2.776, -12.57, 15.8, 11.16, 19.92, 34.84, -5.129, 8.743, -1.578,
-31.23, 23.09, -24.02, 50.99, 52.38, 15.81, -14.61, 26.57, 23.76,
24.59, 41.38, 42.29, -48.82, 6.491, 57.52), cope4_StriatumMask_6_betas_mean
= c(16.28,
22.74, 1.5, -10.25, 0.712, 0.6925, -13.95, 43.29, -0.8349, 6.348,
13.2, 16.73, 13.11, 20.33, -18.84, 13.71, 47.84, 41.51, 32.87,
7.421, 18.35, -7.158, -9.818, -5.952, 13.16, -21.19, -30.92,
-5.915, 24.7, 12.84, -12.11, 12.37, -15.52, 22.66, -5.315, -12.37,
7.045, -13.68, 28.02, 19.65, -22.67, -1.333, 23.78),
cope3_StriatumMask_6_betas_mean = c(-8.463,
5.318, 2.124, 43.84, -14.8, 25.8, -2.843, 0.7301, -0.6077, -9.902,
47.76, 28.98, -2.971, 1.19, -12.33, 12.65, 7.477, -6.222, 4.726,
-22.8, 23.77, -5.952, 18.97, -33.54, 28.67, -19.31, 32.13, -5.62,
14.83, 15.99, -16.74, 14.86, 15.73, 22.8, 13.28, -18.03, 23.9,
4.578, 11.01, -2.828, 34.9, 34.42, -15.46), cope2_StriatumMask_6_betas_mean
= c(-20.5,
-19.39, -25.22, -15.81, -34.44, -27.47, -22.68, -4.421, -17.86,
-1.598, -17.63, 33.28, -8.592, -27.58, 14.24, -7.253, 28.22,
0.1134, -16.73, -18.45, 5.513, -14.15, -10.94, -6.778, -34.2,
4.84, 0.195, -4.455, 23.44, 4.901, 8.662, -39.93, -15.5, -54.58,
14.88, -18.37, -9.523, -19.71, -22.02, -39.69, 12.77, -2.043,
-49.19), cope1_StriatumMask_6_betas_mean = c(-3.715, -4.467,
-7.318, 26.67, 9.007, 15.94, 11.16, 5.649, 5.922, -3.561, -13.75,
-6.254, 6.448, 2.948, -34.84, 13.13, 11.08, -7.47, 15.83, -7.719,
-11.32, -1.264, -0.2779, 9.288, -43.47, -1.405, 4.105, 1.43,
6.055, 22.49, -17.85, 10.03, 11.48, -28.81, 2.534, 8.687, 11.05,
4.538, 17.95, 1.928, -14.82, 1.857, -4.488),
cope8_StriatumMask_5_betas_mean = c(-1.297,
11.7, 5.719, -57.14, 46.27, -60.21, -46.51, -15.42, 7.891, -6.234,
-49.77, 3.486, -3.769, -9.559, 18.63, -4.199, 26.85, 27.71, 57.15,
-16.85, 5.799, -34.23, -19.53, 34.89, -5.222, 12.96, -70.82,
-40.66, -10.55, -3.86, 31.22, -14.71, -28.96, -14.34, -18.29,
0.4763, -16.32, -44.12, 19.7, 5.786, -20.15, 13.51, 0.08071),
    cope7_StriatumMask_5_betas_mean = c(1.297, -11.7, -5.719,
    57.14, -46.27, 60.21, 46.51, 15.42, -7.891, 6.234, 49.77,
    -3.486, 3.769, 9.559, -18.63, 4.199, -26.85, -27.71, -57.15,
    16.85, -5.799, 34.23, 19.53, -34.89, 5.222, -12.96, 70.82,
    40.66, 10.55, 3.86, -31.22, 14.71, 28.96, 14.34, 18.29, -0.4763,
    16.32, 44.12, -19.7, -5.786, 20.15, -13.51, -0.08071),
cope6_StriatumMask_5_betas_mean = c(-24.38,
    -8.297, -23.09, -3.194, -15.96, -12.54, -18.76, -55.4, 13.63,
    -12.52, -8.805, 58.42, -37.33, -56.25, 52.02, -48.07, -0.5076,
    -8.608, -67.85, -40.23, 12.44, -33.79, -28.93, -4, -20.04,
    62.34, -10.09, 12.86, 1.249, -25.19, 69.77, -18.07, -16.69,
    18.09, 16.25, -27.2, -12.67, 6.946, -25.86, -21.46, 77.06,
    -3.023, -90.03), cope5_StriatumMask_5_betas_mean = c(24.38,
    8.297, 23.09, 3.194, 15.96, 12.54, 18.76, 55.4, -13.63, 12.52,
    8.805, -58.42, 37.33, 56.25, -52.02, 48.07, 0.5076, 8.608,
    67.85, 40.23, -12.44, 33.79, 28.93, 4, 20.04, -62.34, 10.09,
    -12.86, -1.249, 25.19, -69.77, 18.07, 16.69, -18.09, -16.25,
    27.2, 12.67, -6.946, 25.86, 21.46, -77.06, 3.023, 90.03),
    cope4_StriatumMask_5_betas_mean = c(-0.1806, 15.36, 16.78,
    -3.517, 28.02, -41.14, -22.81, 20.91, 15.26, 17.1, 6.271,
    20.32, 24.57, 6.072, 12.51, 5.534, 30.1, 49.02, 71.84, 2.404,
    8.636, -15.64, -6.885, -2.237, 33.27, 12.35, -45.2, -16.68,
    15.54, 4.278, 40.59, 0.7229, 13.89, 25.12, -20.32, 0.7402,
    14.96, -20.14, 54.07, 14.79, 16.95, 27.07, 14.58),
cope3_StriatumMask_5_betas_mean = c(1.978,
    -4.735, 4.603, 52.85, -11.23, 24.38, 21.69, 39.17, 11.54,
    17.79, 55.56, 20.45, 28.13, 13.82, -5.683, 2.911, 18.02,
    13.02, 25.72, 15.83, 6.11, 13.49, 16.81, -29.8, 21.49, 7.513,
    27.28, 14.86, 22.98, 9.325, 8.833, 14.27, 46.35, 39.8, -7.482,
    -0.1707, 44.42, 33.53, 26.02, 15, 39.72, 18.88, 14.45),
cope2_StriatumMask_5_betas_mean = c(-27.24,
    -3.252, -21.67, -14.59, -18.78, -10.4, -6.882, 15.76, 13.41,
    -1.525, -1.248, 69.55, -22.77, -30.24, 11.38, -21.1, 16.3,
    -5.086, -33.82, -48.84, 6.821, -12.66, -17.23, 8.287, -28.52,
    55.27, 8.905, 14.06, 10.88, -4.195, 59.09, -7.859, -0.6477,
    3.593, 19.66, -18.36, 4.738, 15.14, -5.58, -8.72, 50.4, 5.613,
    -89.5), cope1_StriatumMask_5_betas_mean = c(1.36, 2.678,
    3.126, 7.72, 0.1483, 13.5, 24.46, 41.42, 0.1413, 9.216, 1.829,
    -3.59, 14.06, 23.06, -20.59, 15.88, 17.19, 5.7, 31.9, -2.176,
    -8.67, 10.99, 11.2, 10.64, -58.77, -7.03, 14.4, 9.383, 13.62,
    16.88, -5.792, 10.24, 3.981, -6.872, 12.54, 11.69, 14.6,
    4.773, 20.04, 11.94, -12.34, 7.493, -13.52),
cope8_StriatumMask_4_betas_mean = c(30.02,
    10.13, -38.16, -31.45, -9.172, 12.4, -0.6511, 10.94, -4.569,
    2.312, -11.92, 8.502, 33.45, 20.34, -5.991, 4.608, 37.08,
    29.14, 15.19, 9.442, -28.13, -5.005, -7.524, 31.94, -32.13,
    -3.296, -60.59, 17.59, 16, 15.33, -3.383, 8.016, -20.84,
    20.43, -17.25, -5.585, 8.63, -5.552, 21.61, 50.3, -31.68,
    -16.84, 11.46), cope7_StriatumMask_4_betas_mean = c(-30.02,
    -10.13, 38.16, 31.45, 9.172, -12.4, 0.6511, -10.94, 4.569,
    -2.312, 11.92, -8.502, -33.45, -20.34, 5.991, -4.608, -37.08,
    -29.14, -15.19, -9.442, 28.13, 5.005, 7.524, -31.94, 32.13,
    3.296, 60.59, -17.59, -16, -15.33, 3.383, -8.016, 20.84,
    -20.43, 17.25, 5.585, -8.63, 5.552, -21.61, -50.3, 31.68,
    16.84, -11.46), cope6_StriatumMask_4_betas_mean = c(17.21,
    -24.2, -8.165, -5.871, -16.94, -30.75, -47.35, 57.53, -11.56,
    -0.2164, 45.58, 62.05, 18.5, -21.69, 40.14, -13.35, 23.01,
    33.62, -7.232, 2.781, 9.096, -2.845, 3.745, 6.809, -14.62,
    19.45, -16.77, 33.06, 30.85, -0.07361, 41.98, -27.19, -10.2,
    19.17, -9.795, -20.53, -4.74, -6.671, -12.01, 12.64, 25.96,
    -1.209, -24.23), cope5_StriatumMask_4_betas_mean = c(-17.21,
    24.2, 8.165, 5.871, 16.94, 30.75, 47.35, -57.53, 11.56, 0.2164,
    -45.58, -62.05, -18.5, 21.69, -40.14, 13.35, -23.01, -33.62,
    7.232, -2.781, -9.096, 2.845, -3.745, -6.809, 14.62, -19.45,
    16.77, -33.06, -30.85, 0.07361, -41.98, 27.19, 10.2, -19.17,
    9.795, 20.53, 4.74, 6.671, 12.01, -12.64, -25.96, 1.209,
    24.23), cope4_StriatumMask_4_betas_mean = c(26.36, 18.31,
    -5.294, 10.02, -14.03, 17.99, 2.606, 21.04, 17.48, 0.52,
    18.67, 41.7, 16.43, 22.12, -21.61, 17.06, 47.47, 49.68, 22.28,
    6.687, -4.8, -8.284, 5.924, 21.67, 7.679, -17.76, -25.72,
    15.04, 22.27, 37.97, -4.224, 19.68, -1.014, 33.49, -6.861,
    -9.917, 11.85, 13.93, 39.51, 46.16, -21.3, 3.857, 20.03),
    cope3_StriatumMask_4_betas_mean = c(-4.475, 8.136, 20.85,
    36.44, -4.315, 19.52, 0.5537, 12.27, 24.51, 0.8773, 31.16,
    30.13, -17.3, -4.434, -17.27, 9.764, 17.33, 18.36, 4.433,
    -9.225, 23.91, -5.546, 13.69, -2.575, 27.54, -4.718, 34.02,
    -0.7261, 5.103, 24.8, -2.262, 13.11, 18.56, 13.33, 8.641,
    -3.453, 5.022, 26.33, 17.79, 5.668, 12.13, 18.55, 3.057),
    cope2_StriatumMask_4_betas_mean = c(2.537, -19.08, -18.83,
    -2.023, -9.252, -21.48, -12.46, 35.15, -4.74, -2.526, 21.46,
    67.33, 11.77, -21.02, 10.89, -7.3, 24.4, 15.82, -2.558, -18.58,
    2.232, -2.148, -0.2798, 11.16, -21.73, 17.03, 3.65, 16.88,
    30.72, 14.44, 23.65, -22.22, 12.26, -17.75, -5.381, -21.71,
    6.899, -2.527, -4.107, 6.232, 2.13, 0.2781, -27.52),
cope1_StriatumMask_4_betas_mean = c(-9.172,
    0.5036, -9.281, 12.45, 7.121, 12.03, 21.94, -13.04, 5.152,
    -1.847, -17.35, -8.623, -5.062, -2.434, -8.646, 5.55, 0.654,
    -17.52, 6.386, -10.25, -10.51, -1.227, -4.453, 1.159, -50.89,
    -3.253, 16.37, -5.982, 9.533, 11.49, -13.87, 4.944, 6.463,
    -28.5, 5.955, 2.492, 8.083, 1.306, 7.27, -6.711, -13.84,
    -3.173, -6.582), cope8_StriatumMask_3_betas_mean = c(-9.827,
    -29.39, -5.072, -29.28, 18.69, 7.461, -25.71, 34.55, -56.11,
    -2.596, -33.97, 19.12, 28.57, 19.91, -16.04, 14.72, 68.99,
    50.07, 54.12, 38.88, 7.486, -10.9, -3.818, 13.97, 4.118,
    -7.899, -52.3, 0.5233, -3.36, -8.542, -26.68, 19.28, -14.09,
    -9.591, 6.136, -17.34, -13.37, -18.57, 7.236, -9.855, -21.91,
    4.76, 2.585), cope7_StriatumMask_3_betas_mean = c(9.827,
    29.39, 5.072, 29.28, -18.69, -7.461, 25.71, -34.55, 56.11,
    2.596, 33.97, -19.12, -28.57, -19.91, 16.04, -14.72, -68.99,
    -50.07, -54.12, -38.88, -7.486, 10.9, 3.818, -13.97, -4.118,
    7.899, 52.3, -0.5233, 3.36, 8.542, 26.68, -19.28, 14.09,
    9.591, -6.136, 17.34, 13.37, 18.57, -7.236, 9.855, 21.91,
    -4.76, -2.585), cope6_StriatumMask_3_betas_mean = c(22.87,
    -25.94, -11.68, -2.203, -10.23, -53.78, -83.96, 49.48, -11.44,
    -5.176, -52.12, 75.78, -4.78, 8.202, 36.8, -20.51, 41.93,
    21.93, -23.74, 13.54, 16.14, 0.104, -10.84, 1.206, -67.28,
    13.01, -39.97, 26.5, 29.88, -20.17, -17.02, -16.57, -31.55,
    -3.754, 13.22, -60.05, -18.23, -20.84, -32.5, -30.19, 17.32,
    -6.671, -68.85), cope5_StriatumMask_3_betas_mean = c(-22.87,
    25.94, 11.68, 2.203, 10.23, 53.78, 83.96, -49.48, 11.44,
    5.176, 52.12, -75.78, 4.78, -8.202, -36.8, 20.51, -41.93,
    -21.93, 23.74, -13.54, -16.14, -0.104, 10.84, -1.206, 67.28,
    -13.01, 39.97, -26.5, -29.88, 20.17, 17.02, 16.57, 31.55,
    3.754, -13.22, 60.05, 18.23, 20.84, 32.5, 30.19, -17.32,
    6.671, 68.85), cope4_StriatumMask_3_betas_mean = c(-16.05,
    2.658, -4.415, -12.2, 1.195, 13.03, -29.99, 33.07, -8.351,
    -14.77, -17.69, 30.84, 34.35, -6.265, -24.46, 31.91, 55.98,
    55.14, 10.99, 28.58, -0.6548, -22.82, -8.781, -4.039, 47.5,
    -10.17, -25.6, 9.067, -7.805, 4.68, -14.51, 30.94, -5.437,
    11.18, -4.785, -28.78, 7.116, -8.826, 28.71, -7.045, -15,
    6.487, 3.255), cope3_StriatumMask_3_betas_mean = c(-5.496,
    24.4, -6.178, 15.86, -14.12, 27.35, -9.234, 0.7806, 42.1,
    -14.02, 14.09, 10.54, 6.996, -11.21, -7.568, 20.19, -8.178,
    -0.5523, -30.68, -20.66, -7.418, -10.89, -7.568, -12.52,
    30.39, 20.52, 32.13, 7.49, -1.385, 21.98, 11.6, 16.08, 8.176,
    20.77, -9.026, -9.19, 25.62, 11.64, 25.4, 11.66, 8.522, 4.707,
    -0.9193), cope2_StriatumMask_3_betas_mean = c(1.248, -20.2,
    -12.85, -10.37, -6.481, -38.99, -40.29, 50.83, -9.962, -11.15,
    -42.64, 76.49, 17.13, 12.02, 1.068, -1.049, 50.45, 8.55,
    -13.25, -2.733, 13.62, -1.994, -9.352, 11.84, -53.07, 15.24,
    -10.38, 9.065, 21.26, 7.247, -9.854, -18.25, -5.975, -21.84,
    9.668, -50.28, 0.1118, -18.12, -13.33, -30.13, -2.708, 7.863,
    -45.51), cope1_StriatumMask_3_betas_mean = c(-16.21, 2.177,
    -0.6828, 2.681, 6.963, 16.77, 27.42, -2.669, 2.728, 0.2155,
    15.99, 0.9732, 22.23, -4.741, -22.42, 15.15, 4.144, -13.74,
    13.43, -8.654, -3.702, -5.625, 1.369, 11.16, -29.82, 1.106,
    25.75, 0.3423, 6.333, 24.31, 2.151, -2.602, 12, -11.66, 2.765,
    11.51, 14.19, 3.124, 20.18, -1.8, -1.045, 5.62, 13.11),
cope8_StriatumMask_2_betas_mean = c(25.81,
    0.1008, -17.35, -20.65, 11.98, 22.12, 6.479, -8.857, 12.72,
    -4.564, -21.54, 13.93, 50.64, -19.73, -19.55, 30.95, 33.47,
    10.15, -12.42, 17.9, -17.26, -27.29, 4.29, 19.53, -9.623,
    -25.66, -41.7, 11.19, 12.26, 18.57, 3.319, 13.15, -19.85,
    8.024, -30.64, -3.4, -15.03, 11.73, 38.76, 60.92, -35.55,
    -25.83, 38.08), cope7_StriatumMask_2_betas_mean = c(-25.81,
    -0.1008, 17.35, 20.65, -11.98, -22.12, -6.479, 8.857, -12.72,
    4.564, 21.54, -13.93, -50.64, 19.73, 19.55, -30.95, -33.47,
    -10.15, 12.42, -17.9, 17.26, 27.29, -4.29, -19.53, 9.623,
    25.66, 41.7, -11.19, -12.26, -18.57, -3.319, -13.15, 19.85,
    -8.024, 30.64, 3.4, 15.03, -11.73, -38.76, -60.92, 35.55,
    25.83, -38.08), cope6_StriatumMask_2_betas_mean = c(32.23,
    -30.2, -14.07, 8.605, 3.412, -26.22, -33.54, 44.45, 26.12,
    6.825, 3.423, 82.44, 21.13, 7.608, 25.97, -32.8, 39.59, 20.19,
    -11.03, 22.94, 1.544, 12.38, -8.389, 16.52, -20.52, 14.38,
    -10.88, 47.39, 14.78, 6.086, 44.31, -16.1, -7.038, 1.967,
    -0.5604, -16.6, -4.619, -27.21, -21.32, 7.096, 1.417, -0.6048,
    -13.26), cope5_StriatumMask_2_betas_mean = c(-32.23, 30.2,
    14.07, -8.605, -3.412, 26.22, 33.54, -44.45, -26.12, -6.825,
    -3.423, -82.44, -21.13, -7.608, -25.97, 32.8, -39.59, -20.19,
    11.03, -22.94, -1.544, -12.38, 8.389, -16.52, 20.52, -14.38,
    10.88, -47.39, -14.78, -6.086, -44.31, 16.1, 7.038, -1.967,
    0.5604, 16.6, 4.619, 27.21, 21.32, -7.096, -1.417, 0.6048,
    13.26), cope4_StriatumMask_2_betas_mean = c(15.01, 22.46,
    -4.224, 15.49, 6.115, 30.69, -9.205, 11, 33.86, -11.47, 8.718,
    40.24, 32.94, 10.32, -21.59, 40.88, 42.59, 38.26, -11.98,
    10.31, -11.61, -11.29, 8.09, 16.8, 26.23, -13.6, -9.128,
    13.4, 11.02, 42.82, -7.533, 31.68, 11.7, 18.03, -28.57, -16.58,
    8.403, 16.38, 50.65, 52.36, -33.33, -3.843, 40.4),
cope3_StriatumMask_2_betas_mean = c(-8.702,
    17.62, 7.219, 28.2, -1.924, 25.78, -19.31, 22.12, 22.83,
    -8.054, 28.44, 23.53, -16.75, 5.805, -4.127, 6.258, 14.48,
    13.64, -0.4828, -13.26, 4.439, 12.69, 0.6518, 7.227, 26.09,
    23.32, 36.05, 12.2, -0.9937, 33.69, -11.5, 21.97, 30.37,
    9.786, 5.107, -10.34, 22.97, 13.41, 16.56, 6.332, 5.224,
    21.78, -2.798), cope2_StriatumMask_2_betas_mean = c(12.04,
    -27.28, -12.81, 3.426, 6.537, -20.93, -3.958, 32.95, 31.27,
    3.16, 1.62, 84.87, 17.59, 16.39, 7.736, -19.22, 37.3, 10.39,
    -10.59, 4.182, -1.269, 13.05, -9.96, 22, -31.62, 19.31, 7.048,
    27.36, 16.38, 25.42, 27.44, -10.14, 11.67, -23.71, 1.572,
    -10.1, -0.7817, -14.73, -10.15, -1.167, -16.26, 4.545, -10.31
    ), cope1_StriatumMask_2_betas_mean = c(-11.59, -0.5801, 2.253,
    2.92, 3.628, 9.823, 16.41, -7.863, 5.275, -1.153, 2.206,
    -4.593, -1.623, 1.228, -2.079, 10.64, -3.458, -11.28, 4.056,
    -6.751, -5.711, -1.179, -2.362, 4.503, -45.23, 4.45, 15.2,
    0.3556, 7.904, 17.05, -14.17, 3.913, 8.457, -16.94, 3.676,
    6.673, 2.067, 8.915, 12.39, -10.32, -5.923, -0.4391, 0.09663
    ), cope8_StriatumMask_1_betas_mean = c(-7.671, 0.7324, 18.97,
    -28.64, 13.36, 26.06, 12.31, 45.68, -19.4, -15.43, -21.18,
    10.45, 40.84, 3.266, 28.25, 10.6, 50.66, 53.76, 26.57, 47.64,
    5.642, 5.603, -10.04, 37.04, 27.35, -41.75, -26.86, -11.13,
    13.09, 44.36, -1.843, 2.302, 0.6855, 14.22, -25.71, -9.987,
    -3.158, -39.82, 5.276, -12.38, -31.06, -4.346, 52.18),
cope7_StriatumMask_1_betas_mean = c(7.671,
    -0.7324, -18.97, 28.64, -13.36, -26.06, -12.31, -45.68, 19.4,
    15.43, 21.18, -10.45, -40.84, -3.266, -28.25, -10.6, -50.66,
    -53.76, -26.57, -47.64, -5.642, -5.603, 10.04, -37.04, -27.35,
    41.75, 26.86, 11.13, -13.09, -44.36, 1.843, -2.302, -0.6855,
    -14.22, 25.71, 9.987, 3.158, 39.82, -5.276, 12.38, 31.06,
    4.346, -52.18), cope6_StriatumMask_1_betas_mean = c(-10.78,
    -25.07, -17.08, 2.81, -6.211, -41.83, -9.084, 62.16, -32.2,
    -22.2, -28.83, 47.89, 17.46, 25.87, 52.77, -12.9, 11.86,
    9.416, -5.891, 16.54, 19.86, -7.199, -16.48, -13.35, -20.79,
    13.97, -8.254, -9.45, 10.29, -3.625, 15.06, -47.86, -35.86,
    8.605, -0.989, -20.42, -30.45, -54.43, -44.19, -32.61, 14.31,
    0.9104, -14.45), cope5_StriatumMask_1_betas_mean = c(10.78,
    25.07, 17.08, -2.81, 6.211, 41.83, 9.084, -62.16, 32.2, 22.2,
    28.83, -47.89, -17.46, -25.87, -52.77, 12.9, -11.86, -9.416,
    5.891, -16.54, -19.86, 7.199, 16.48, 13.35, 20.79, -13.97,
    8.254, 9.45, -10.29, 3.625, -15.06, 47.86, 35.86, -8.605,
    0.989, 20.42, 30.45, 54.43, 44.19, 32.61, -14.31, -0.9104,
    14.45), cope4_StriatumMask_1_betas_mean = c(4.84, 8.677,
    12.27, -7.647, 16.95, 11.6, -4.777, 36.14, -0.6954, -16.71,
    6.837, 24.48, 33.52, 16.08, 2.818, 33.76, 40.46, 49.53, 12.67,
    17.85, 4.385, -2.631, -6.774, 19.03, 24.32, -20.09, -10.17,
    -9.06, 8.567, 32.12, -2.03, -1.62, 0.146, 37.04, -22.95,
    -23.3, 8.028, -17.19, 20.37, 16.84, -22.3, -6.429, 51.04),
    cope3_StriatumMask_1_betas_mean = c(15.35, 5.55, -18.41,
    15.07, 3.556, 7.953, -14.82, -9.422, 16.4, -0.3186, 24.63,
    12.67, -6.266, 2.59, -20.88, 19.75, -6.401, -2.396, -5.993,
    -35.32, 2.134, -4.257, 2.744, -9.988, -11.43, 32.36, 18.16,
    1.64, -6.096, -2.82, -1.367, -2.237, -0.7249, 22.74, 2.451,
    -9.7, 20.11, 29.75, 16.12, 33.47, 11.92, -2.012, -1.725),
    cope2_StriatumMask_1_betas_mean = c(-22.73, -15.83, -19.77,
    -8.785, -1.132, -28.61, -8.759, 55.94, -23.65, -11.41, -25.9,
    55.99, 23.15, 20.83, 1.789, -8.291, 18.53, -3.007, 3.943,
    -6.776, 6.329, -9.923, -15.03, -6.602, -28.07, 15.85, 4.005,
    -9.185, 7.425, 15.21, 14.91, -29.58, -32.79, -8.068, 9.733,
    -14.88, -6.852, -45.85, -28.66, -33.56, -0.5571, 9.592, -19.33
    ), cope1_StriatumMask_1_betas_mean = c(-8.128, 5.758, -1.077,
    -2.914, 7.331, 17.59, 7.21, -1.398, 9.864, 9.548, 7.269,
    -1.59, 4.966, -2.957, -33.94, 4.149, 4.05, -12.29, 9.097,
    -12.87, -15.36, -2.254, 1.258, 6.453, -29.28, 0.6771, 7.286,
    12.21, 7.805, 16.56, -0.8941, 13.69, 1.07, -9.846, 10.8,
    9.538, 21.36, 6.965, 14.37, -2.649, 0.8941, 2.795, -7.913
    ), cope8_StriatumMask_betas_mean = c(19.19, 8.326, -14.14,
    -47.34, 21.49, -12.56, -16.33, 20.01, 1.212, 10.1, -35.27,
    -3.354, 17.25, 9.637, -4.914, 6.339, 41.29, 38.17, 23.69,
    10.55, -9.964, -7.758, -15.25, 32.33, -26.52, 2.892, -61.29,
    -5.893, 5.116, -1.717, 8.98, -3.727, -29.21, 0.6858, -19.31,
    5.567, -11.3, -11.28, 21.09, 27.76, -41.58, -22.77, 23.96
    ), cope7_StriatumMask_betas_mean = c(-19.19, -8.326, 14.14,
    47.34, -21.49, 12.56, 16.33, -20.01, -1.212, -10.1, 35.27,
    3.354, -17.25, -9.637, 4.914, -6.339, -41.29, -38.17, -23.69,
    -10.55, 9.964, 7.758, 15.25, -32.33, 26.52, -2.892, 61.29,
    5.893, -5.116, 1.717, -8.98, 3.727, 29.21, -0.6858, 19.31,
    -5.567, 11.3, 11.28, -21.09, -27.76, 41.58, 22.77, -23.96
    ), cope6_StriatumMask_betas_mean = c(-3.001, -19.78, -17.55,
    -13.93, -26.77, -33.2, -41.41, 0.257, -8.959, -1.035, 4.296,
    34.65, -9.697, -26.18, 56.74, -26.94, 14.28, 12.58, -34.56,
    -3.228, 11.26, -16.65, -10.86, -6.784, -24.45, 23.86, -8.12,
    18.23, 21.56, -17.01, 36.51, -34.84, -34.06, -0.2884, 8.737,
    -20.99, -15.66, -17.38, -34.47, -24.96, 49.42, -2.499, -52.5
    ), cope5_StriatumMask_betas_mean = c(3.001, 19.78, 17.55,
    13.93, 26.77, 33.2, 41.41, -0.257, 8.959, 1.035, -4.296,
    -34.65, 9.697, 26.18, -56.74, 26.94, -14.28, -12.58, 34.56,
    3.228, -11.26, 16.65, 10.86, 6.784, 24.45, -23.86, 8.12,
    -18.23, -21.56, 17.01, -36.51, 34.84, 34.06, 0.2884, -8.737,
    20.99, 15.66, 17.38, 34.47, 24.96, -49.42, 2.499, 52.5),
    cope4_StriatumMask_betas_mean = c(15.33, 19, 2.13, 0.6255,
    3.965, -1.875, -11.55, 31.71, 10.09, 6.487, 11.98, 22.06,
    18.12, 14.37, -12.51, 15.88, 43.94, 42.62, 28.01, 5.568,
    7.426, -9.192, -2.169, 2.482, 15.11, -12.14, -29.41, -0.2639,
    19.3, 15.57, 0.9526, 11.34, -3.821, 24.48, -6.627, -8.762,
    9.8, -6.399, 37.83, 25.74, -14.33, 4.295, 21.01),
cope3_StriatumMask_betas_mean = c(-3.592,
    6.864, 7.348, 44, -11.51, 24.63, 1.817, 13.9, 9.993, -2.448,
    46.96, 24.46, 1.184, 2.201, -9.854, 8.554, 11.19, 5.276,
    6.545, -10.3, 18.45, 0.09225, 14.79, -21.75, 26.66, -5.553,
    31.19, 0.8526, 10.5, 20.36, -8.67, 16.04, 25.48, 24.09, 7.305,
    -12.65, 25.91, 15.63, 15.62, 4.822, 29.16, 26.04, -6.085),
    cope2_StriatumMask_betas_mean = c(-13.48, -17.98, -22.68,
    -9.708, -22.45, -23.12, -13.93, 12.69, -4.801, -1.965, -6.992,
    46.79, -6.076, -17.57, 13.97, -10.84, 23.23, 4.383, -21.55,
    -22.44, 4.44, -10.1, -9.803, 3.025, -28.17, 22, 4.17, 9.131,
    19.87, 5.414, 22.37, -25.66, -7.043, -30.76, 11.91, -14.59,
    -2.368, -8.886, -16.82, -21.95, 18.63, 2.53, -49.32),
cope1_StriatumMask_betas_mean = c(-5.115,
    -1.257, -4.329, 17.92, 5.458, 15.17, 16.84, 7.652, 3.981,
    0.3726, -10.51, -5.246, 4.09, 6.008, -20.68, 12.2, 9.368,
    -6.345, 14.45, -6.155, -10.31, 2.61, 0.6008, 7.258, -48.2,
    -2.675, 8.916, 1.677, 8.255, 18.35, -13.18, 8.82, 9.647,
    -21.62, 6.05, 7.721, 10.41, 6.71, 16.76, 2.002, -13.56, 2.499,
    -6.206), age = c(34L, 32L, 34L, 22L, 27L, 33L, 33L, 41L,
    21L, 20L, 32L, 30L, 29L, 37L, 29L, 25L, 31L, 20L, 32L, 22L,
    24L, 26L, 20L, 22L, 34L, 34L, 44L, 40L, 43L, 36L, 41L, 22L,
    41L, 26L, 41L, 45L, 36L, 31L, 31L, 27L, 40L, 23L, 27L), hare2f1 = c(3L,
    10L, 7L, 5L, 4L, 3L, 5L, 6L, 13L, 13L, 7L, 9L, 12L, 7L, 4L,
    13L, 12L, 11L, 14L, 13L, 10L, 6L, 6L, 13L, 11L, 10L, 13L,
    16L, 6L, 8L, 8L, 11L, 9L, 13L, 10L, 9L, 5L, 9L, 5L, 12L,
    13L, 9L, 8L), hare2f2 = c(14, 18, 3, 10, 6, 6, 9, 7, 18.75,
    16, 15, 12, 14, 18, 14, 18, 18, 19, 18, 15.555556, 14.444444,
    12, 1.111111, 17, 12, 17, 14, 13, 16, 7.777778, 6.666667,
    13, 14, 13, 11, 16, 4, 12, 10, 13, 14, 17, 12), hare4 = c(10,
    8, 2, 3, 2, 3, 5, 2, 9, 8, 6, 4, 6, 10, 6, 8, 9, 9, 9, 7.5,
    7, 5, 0, 9, 4, 10, 10, 9, 8, 1.25, 0, 7, 7, 7, 5, 9, 0, 3,
    4, 7, 4, 9, 3), hare = c(20, 32, 10, 16, 11, 11, 15, 15,
    35.294118, 33, 26, 22, 27, 27, 22, 33, 33, 32, 34, 29.473684,
    27.368421, 20, 8.421053, 32, 27, 30, 30, 31, 24, 16.842105,
    15.789474, 25, 26, 30, 23, 29, 10, 22, 16, 29, 30, 27, 24
    ), ext_t = c(193L, 374L, 127L, 181L, 198L, 112L, 208L, 194L,
    185L, 224L, 275L, 204L, 235L, 257L, 149L, 279L, 320L, 322L,
    188L, 220L, 273L, 206L, 129L, 296L, 223L, 277L, 156L, 195L,
    219L, 155L, 167L, 176L, 220L, 227L, 224L, 195L, 150L, 277L,
    134L, 285L, 255L, 225L, 176L), total_barrat_11_imputed = c(52,
    49.65517241, 49, 50, 59, 33, 80, 59, 49, 88.96551724, 46,
    69, 55, 61, 55, 81, 63, 78, 63, 77, 74, 56, 66, 65, 64, 80,
    47, 41, 55, 61, 69, 65, 54, 60, 75, 48, 55, 92, 55, 80, 61,
    74, 75), mcq_k = c(0.026255008, 0.001003094, 0.005960345,
    0.015726049, 0.010265035, 0.001003162, 0.0000562, 0.001264102,
    0.101500481, 0.000371013, 0.041432153, 0.002816398, 0.000610156,
    0.002515929, 0.013917576, 0.041429705, 0.001003197, 0.015963745,
    0.004571462, 0.066152274, 0.001264173, 0.013917914, 0.0000145,
    0.000158281, 0.025279846, 0.007219305, 0.001003151, 0.000158275,
    0.040812627, 0.015218595, 0.0000234, 0.008376655, 0.003841158,
    0.007218929, 0.011170246, 0.001264155, 0.002183796, 0.041432825,
    0.018248241, 0.025279435, 0.00728945, 0.015218596, 0.000139047
    ), ppitots = c(127L, 144L, 123L, 139L, 132L, 104L, 124L,
    101L, 139L, 143L, 125L, 118L, 143L, 136L, 101L, 155L, 121L,
    163L, 144L, 137L, 161L, 132L, 129L, 172L, 130L, 149L, 130L,
    127L, 131L, 100L, 134L, 140L, 130L, 156L, 129L, 105L, 104L,
    144L, 131L, 155L, 141L, 148L, 122L), ppi_1_corrected = c(0.790903075,
    -0.699393955, -2.327819799, 1.081391412, 1.312482037, -1.237538376,
    -2.908572705, -1.431192482, 0.849643836, -0.164898186, -2.41690919,
    -2.180646599, 2.448811184, -0.690782751, -3.013794372, -0.299602118,
    -2.681787682, 1.644921908, -0.813003057, 1.123342946, 5.134178123,
    0.079542428, -0.261508648, 3.433661529, -0.273992274, 2.158546617,
    1.906361161, 1.422218718, -0.391906978, -3.50632425, -1.107140046,
    2.554466033, -0.185769247, 2.924775604, -1.911895686, -4.074384118,
    -3.514935455, -1.132749891, 3.135218938, 2.554032851, 1.165085067,
    1.001346409, -0.06377271), ppi_2_corrected = c(-2.126526342,
    2.11252134, 0.555050342, -1.00112002, 0.340187762, -5.601376296,
    1.123969936, -4.711504227, 0.689931234, 0.579906262, 1.063194228,
    -0.20079187, -0.692661735, 1.762800655, -3.876379279, 3.649272316,
    1.919311154, 6.385631495, 2.52094701, -0.266955763, 0.107879822,
    0.040699835, -0.035262664, 4.854103646, -0.699493009, 1.446789539,
    -2.783996549, -3.166278249, 0.253753447, -2.916502162, 0.483071268,
    -1.851965471, -0.491096031, 0.403290401, 0.807272843, -0.914685705,
    -2.568897775, 4.595852557, -3.588214202, 2.506562905, 0.802072504,
    1.563208978, -2.362131731), total_buss_perry = c(55L, 79L,
    64L, 79L, 86L, 37L, 85L, 69L, 76L, 109L, 80L, 62L, 46L, 85L,
    48L, 119L, 124L, 131L, 94L, 56L, 95L, 62L, 78L, 106L, 93L,
    76L, 46L, 54L, 61L, 61L, 76L, 94L, 98L, 85L, 94L, 70L, 65L,
    70L, 45L, 114L, 99L, 92L, 61L)), .Names =
c("cope8_StriatumMask_7_betas_mean",
"cope7_StriatumMask_7_betas_mean", "cope6_StriatumMask_7_betas_mean",
"cope5_StriatumMask_7_betas_mean", "cope4_StriatumMask_7_betas_mean",
"cope3_StriatumMask_7_betas_mean", "cope2_StriatumMask_7_betas_mean",
"cope1_StriatumMask_7_betas_mean", "cope8_StriatumMask_6_betas_mean",
"cope7_StriatumMask_6_betas_mean", "cope6_StriatumMask_6_betas_mean",
"cope5_StriatumMask_6_betas_mean", "cope4_StriatumMask_6_betas_mean",
"cope3_StriatumMask_6_betas_mean", "cope2_StriatumMask_6_betas_mean",
"cope1_StriatumMask_6_betas_mean", "cope8_StriatumMask_5_betas_mean",
"cope7_StriatumMask_5_betas_mean", "cope6_StriatumMask_5_betas_mean",
"cope5_StriatumMask_5_betas_mean", "cope4_StriatumMask_5_betas_mean",
"cope3_StriatumMask_5_betas_mean", "cope2_StriatumMask_5_betas_mean",
"cope1_StriatumMask_5_betas_mean", "cope8_StriatumMask_4_betas_mean",
"cope7_StriatumMask_4_betas_mean", "cope6_StriatumMask_4_betas_mean",
"cope5_StriatumMask_4_betas_mean", "cope4_StriatumMask_4_betas_mean",
"cope3_StriatumMask_4_betas_mean", "cope2_StriatumMask_4_betas_mean",
"cope1_StriatumMask_4_betas_mean", "cope8_StriatumMask_3_betas_mean",
"cope7_StriatumMask_3_betas_mean", "cope6_StriatumMask_3_betas_mean",
"cope5_StriatumMask_3_betas_mean", "cope4_StriatumMask_3_betas_mean",
"cope3_StriatumMask_3_betas_mean", "cope2_StriatumMask_3_betas_mean",
"cope1_StriatumMask_3_betas_mean", "cope8_StriatumMask_2_betas_mean",
"cope7_StriatumMask_2_betas_mean", "cope6_StriatumMask_2_betas_mean",
"cope5_StriatumMask_2_betas_mean", "cope4_StriatumMask_2_betas_mean",
"cope3_StriatumMask_2_betas_mean", "cope2_StriatumMask_2_betas_mean",
"cope1_StriatumMask_2_betas_mean", "cope8_StriatumMask_1_betas_mean",
"cope7_StriatumMask_1_betas_mean", "cope6_StriatumMask_1_betas_mean",
"cope5_StriatumMask_1_betas_mean", "cope4_StriatumMask_1_betas_mean",
"cope3_StriatumMask_1_betas_mean", "cope2_StriatumMask_1_betas_mean",
"cope1_StriatumMask_1_betas_mean", "cope8_StriatumMask_betas_mean",
"cope7_StriatumMask_betas_mean", "cope6_StriatumMask_betas_mean",
"cope5_StriatumMask_betas_mean", "cope4_StriatumMask_betas_mean",
"cope3_StriatumMask_betas_mean", "cope2_StriatumMask_betas_mean",
"cope1_StriatumMask_betas_mean", "age", "hare2f1", "hare2f2",
"hare4", "hare", "ext_t", "total_barrat_11_imputed", "mcq_k",
"ppitots", "ppi_1_corrected", "ppi_2_corrected", "total_buss_perry"
), row.names = c(NA, -43L), class = "data.frame")


-- 

*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University *

	[[alternative HTML version deleted]]


From edmirsilva at live.com  Mon Sep  1 16:25:17 2014
From: edmirsilva at live.com (Edmir Silva)
Date: Mon, 1 Sep 2014 14:25:17 +0000
Subject: [R] SpectrumBackground
Message-ID: <COL125-W296502A4B0FE8A599F3178B5C60@phx.gbl>

Hello there ...

Using package Peaks to run the function SNIP on a csv
file with 19 spectrum.

 

While trying to run:

### doing SNIP for every spectra

require(Peaks)

for (i in 1:NROW(Q))

                {

                Q.t[i,]<-Q[i,]-SpectrumBackground(as.numeric(as.vector(Q[i,])))

                print(i)

                }

Got the following error:

Error in .Call("R_SpectrumBackground",
as.vector(y), as.integer(iterations), 

: 

  "R_SpectrumBackground"
not available for .Call() for package "Peaks"

 

Any suggestions on how to correct this ?

 

Thanks for the help,

 

Edmir

Fiber&Polymer Science, NCSU 		 	   		  
	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Mon Sep  1 17:29:33 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Mon, 1 Sep 2014 18:29:33 +0300
Subject: [R] simulation data with mixed variables
Message-ID: <CABLo8nHP_1ayJvDifqgsDmN3srW5TYNzfFsreFH4vR9SHFWQtg@mail.gmail.com>

dear all members

i am trying to simulate  data with mixed ordered categorical and
dichotomous variables with 200 observation and 10 var. 5 ordered
categorical and 5 dichotomous and i want to put a high correlation between
variables so i must find correlation between dichotomous and the
correlation between ordered categorical and correlation between mixed
ordered categorical and dichotomous data. i know all types of corr. except
correlation between mixed. i hope anyone help me to solve this problem.


Many thanks in advance



Thanoon

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Sep  1 18:25:35 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 1 Sep 2014 16:25:35 +0000
Subject: [R] Correlation Matrix with a Covariate
In-Reply-To: <CAB9UfhROxa7jz2pc4yHL2cZxTewyJaWt1N7PqKG+Az724tiyyg@mail.gmail.com>
References: <CAB9UfhROxa7jz2pc4yHL2cZxTewyJaWt1N7PqKG+Az724tiyyg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F94334@mb02.ads.tamu.edu>

Thanks for including your data with dput(). I'm not familiar with set correlation, but altogether you are working with 76 variables (columns) and only 46 observations. Since the error message says "the system is exactly singlular," it is likely that you have too many variables for the number of observations or one of your columns is a linear combination of (can be predicted exactly from) the others.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Patzelt, Edward
Sent: Monday, September 1, 2014 7:47 AM
To: R-help at r-project.org
Subject: [R] Correlation Matrix with a Covariate

R Help -

I'm trying to run a correlation matrix with a covariate of "age" and will
at some point will also want to covary other variables concurrently.

I'm using the "psych" package and have tried other methods such as writing
a loop to extract semi-partial correlations, but it does not seem to be
working. How can I accomplish this?

library(psych)
> set.cor(y = (66:76), x = c(1:64), z = 65, data = dat5)
Error in solve.default(x.matrix, xy.matrix) :
  Lapack routine dgesv: system is exactly singular: U[54,54] = 0

structure(list(cope8_StriatumMask_7_betas_mean = c(11.47, -0.6002,
-11.59, -52.51, 36.63, -36.99, -26.89, 21.68, 3.776, 19.35, -56.44,
-11.41, -1.825, 5.327, -2.886, 11.91, 43.99, 42.17, 21.19, -1.14,
-9.156, -3.53, -12.79, 33.88, -35.92, 7.613, -61.59, -6.754,
2.672, -25.09, 19.87, -21.09, -37.97, -11.07, -7.276, 21.94,
-18.94, -16.83, 19.96, 7.533, -44.57, -23.17, 22.54),
cope7_StriatumMask_7_betas_mean = c(-11.47,
0.6002, 11.59, 52.51, -36.63, 36.99, 26.89, -21.68, -3.776, -19.35,
56.44, 11.41, 1.825, -5.327, 2.886, -11.91, -43.99, -42.17, -21.19,
1.14, 9.156, 3.53, 12.79, -33.88, 35.92, -7.613, 61.59, 6.754,
-2.672, 25.09, -19.87, 21.09, 37.97, 11.07, 7.276, -21.94, 18.94,
16.83, -19.96, -7.533, 44.57, 23.17, -22.54),
cope6_StriatumMask_7_betas_mean = c(-15.11,
-20.31, -24.63, -17.44, -33.64, -38.77, -37.67, -27.93, -13.28,
-7.351, -9.147, -2.561, -28.92, -26.39, 65.4, -30.5, -6.315,
6.017, -59.84, -12.24, 14.86, -36.17, -14.39, -11.74, -19.17,
41.23, 4.33, 19.48, 12.88, -29.51, 32.7, -35.65, -49.27, -4.2,
16.27, -9.706, -19.26, -22.49, -54.12, -48.03, 82.09, 1.946,
-68.66), cope5_StriatumMask_7_betas_mean = c(15.11, 20.31, 24.63,
17.44, 33.64, 38.77, 37.67, 27.93, 13.28, 7.351, 9.147, 2.561,
28.92, 26.39, -65.4, 30.5, 6.315, -6.017, 59.84, 12.24, -14.86,
36.17, 14.39, 11.74, 19.17, -41.23, -4.33, -19.48, -12.88, 29.51,
-32.7, 35.65, 49.27, 4.2, -16.27, 9.706, 19.26, 22.49, 54.12,
48.03, -82.09, -1.946, 68.66), cope4_StriatumMask_7_betas_mean = c(14.75,
15.24, 4.935, 4.835, 10.32, -19.23, -14.4, 39.01, 7.088, 16.77,
10.78, 4.741, 15.2, 6.144, -3.572, 9.995, 42.44, 36.24, 23.44,
-0.4025, 10.57, -8.036, 0.4127, -5.74, 7.335, -5.735, -32.63,
-3.122, 16.36, -6.741, 9.36, -2.567, -5.515, 22.81, 9.99, -2.034,
10.38, -16.34, 37.27, 12.11, -2.593, 5.341, 11.64),
cope3_StriatumMask_7_betas_mean = c(3.8,
8.024, 6.609, 56.04, -17.79, 27.05, 10.92, 19.12, 4.651, -1.325,
66.15, 16.36, 17.79, 2.177, -4.663, 4.534, 7.788, 3.822, 6.74,
-3.433, 20.96, 1.451, 16.81, -31.09, 26.59, -8.875, 27.25, -1.37,
8.634, 22.93, -10.99, 18.74, 34.3, 34.26, 6.989, -20.35, 38.61,
14.78, 14.24, 8.544, 42.79, 27.42, -12.53), cope2_StriatumMask_7_betas_mean
= c(-22.45,
-18.01, -28.1, -10.91, -33.2, -24.75, -9.261, 4.794, -11.8, -4.1,
-20.08, 17.07, -22.33, -12.02, 21.62, -10.31, 10, 3.088, -45.09,
-32.44, 5.73, -21.31, -12.11, -1.46, -21.26, 36.54, 7.501, 11.95,
11.9, -6.681, 22.08, -24.31, -22.79, -28.37, 23.36, -1.101, -3.984,
-6.315, -28.91, -35.64, 43.7, 8.317, -67.12),
cope1_StriatumMask_7_betas_mean = c(-3.331,
-0.6516, -3.038, 23.44, 2.235, 20.09, 16.99, 18.96, 1.348, 4.113,
-14.4, -2.449, 4.893, 12, -18.31, 15.32, 16.84, 1.516, 15.34,
-1.8, -11.98, 9.774, 2.055, 8.772, -50.38, -5.62, 2.985, 4.993,
7.956, 19.07, -10.01, 12.46, 13.24, -15.76, 9.281, 8.894, 12.9,
14.74, 23.37, 10.72, -16.88, 6.961, -8.737),
cope8_StriatumMask_6_betas_mean = c(24.61,
16.14, -9.034, -59.09, 23.45, -6.531, -15.25, 44.85, -0.97, 19.71,
-34.17, -13.74, 16.35, 22.46, -9.196, -1.073, 48.33, 52.74, 29.12,
24.44, -4.246, 3.402, -26.58, 35.38, -32.03, 10.15, -65.41, -12.14,
3.905, -2.271, 4.286, -1.484, -32.3, 0.3132, -25.83, 6.807, -14.56,
-6.214, 16.98, 27.18, -55.46, -38.73, 35.93),
cope7_StriatumMask_6_betas_mean = c(-24.61,
-16.14, 9.034, 59.09, -23.45, 6.531, 15.25, -44.85, 0.97, -19.71,
34.17, 13.74, -16.35, -22.46, 9.196, 1.073, -48.33, -52.74, -29.12,
-24.44, 4.246, -3.402, 26.58, -35.38, 32.03, -10.15, 65.41, 12.14,
-3.905, 2.271, -4.286, 1.484, 32.3, -0.3132, 25.83, -6.807, 14.56,
6.214, -16.98, -27.18, 55.46, 38.73, -35.93),
cope6_StriatumMask_6_betas_mean = c(-11.24,
-17.26, -17.59, -27.92, -42.3, -39.53, -49.99, -11.12, -23.51,
4.573, -2.713, 18.23, -13.94, -31.14, 72.81, -23.42, 18.89, 9.695,
-30.2, 2.776, 12.57, -15.8, -11.16, -19.92, -34.84, 5.129, -8.743,
1.578, 31.23, -23.09, 24.02, -50.99, -52.38, -15.81, 14.61, -26.57,
-23.76, -24.59, -41.38, -42.29, 48.82, -6.491, -57.52),
cope5_StriatumMask_6_betas_mean = c(11.24,
17.26, 17.59, 27.92, 42.3, 39.53, 49.99, 11.12, 23.51, -4.573,
2.713, -18.23, 13.94, 31.14, -72.81, 23.42, -18.89, -9.695, 30.2,
-2.776, -12.57, 15.8, 11.16, 19.92, 34.84, -5.129, 8.743, -1.578,
-31.23, 23.09, -24.02, 50.99, 52.38, 15.81, -14.61, 26.57, 23.76,
24.59, 41.38, 42.29, -48.82, 6.491, 57.52), cope4_StriatumMask_6_betas_mean
= c(16.28,
22.74, 1.5, -10.25, 0.712, 0.6925, -13.95, 43.29, -0.8349, 6.348,
13.2, 16.73, 13.11, 20.33, -18.84, 13.71, 47.84, 41.51, 32.87,
7.421, 18.35, -7.158, -9.818, -5.952, 13.16, -21.19, -30.92,
-5.915, 24.7, 12.84, -12.11, 12.37, -15.52, 22.66, -5.315, -12.37,
7.045, -13.68, 28.02, 19.65, -22.67, -1.333, 23.78),
cope3_StriatumMask_6_betas_mean = c(-8.463,
5.318, 2.124, 43.84, -14.8, 25.8, -2.843, 0.7301, -0.6077, -9.902,
47.76, 28.98, -2.971, 1.19, -12.33, 12.65, 7.477, -6.222, 4.726,
-22.8, 23.77, -5.952, 18.97, -33.54, 28.67, -19.31, 32.13, -5.62,
14.83, 15.99, -16.74, 14.86, 15.73, 22.8, 13.28, -18.03, 23.9,
4.578, 11.01, -2.828, 34.9, 34.42, -15.46), cope2_StriatumMask_6_betas_mean
= c(-20.5,
-19.39, -25.22, -15.81, -34.44, -27.47, -22.68, -4.421, -17.86,
-1.598, -17.63, 33.28, -8.592, -27.58, 14.24, -7.253, 28.22,
0.1134, -16.73, -18.45, 5.513, -14.15, -10.94, -6.778, -34.2,
4.84, 0.195, -4.455, 23.44, 4.901, 8.662, -39.93, -15.5, -54.58,
14.88, -18.37, -9.523, -19.71, -22.02, -39.69, 12.77, -2.043,
-49.19), cope1_StriatumMask_6_betas_mean = c(-3.715, -4.467,
-7.318, 26.67, 9.007, 15.94, 11.16, 5.649, 5.922, -3.561, -13.75,
-6.254, 6.448, 2.948, -34.84, 13.13, 11.08, -7.47, 15.83, -7.719,
-11.32, -1.264, -0.2779, 9.288, -43.47, -1.405, 4.105, 1.43,
6.055, 22.49, -17.85, 10.03, 11.48, -28.81, 2.534, 8.687, 11.05,
4.538, 17.95, 1.928, -14.82, 1.857, -4.488),
cope8_StriatumMask_5_betas_mean = c(-1.297,
11.7, 5.719, -57.14, 46.27, -60.21, -46.51, -15.42, 7.891, -6.234,
-49.77, 3.486, -3.769, -9.559, 18.63, -4.199, 26.85, 27.71, 57.15,
-16.85, 5.799, -34.23, -19.53, 34.89, -5.222, 12.96, -70.82,
-40.66, -10.55, -3.86, 31.22, -14.71, -28.96, -14.34, -18.29,
0.4763, -16.32, -44.12, 19.7, 5.786, -20.15, 13.51, 0.08071),
    cope7_StriatumMask_5_betas_mean = c(1.297, -11.7, -5.719,
    57.14, -46.27, 60.21, 46.51, 15.42, -7.891, 6.234, 49.77,
    -3.486, 3.769, 9.559, -18.63, 4.199, -26.85, -27.71, -57.15,
    16.85, -5.799, 34.23, 19.53, -34.89, 5.222, -12.96, 70.82,
    40.66, 10.55, 3.86, -31.22, 14.71, 28.96, 14.34, 18.29, -0.4763,
    16.32, 44.12, -19.7, -5.786, 20.15, -13.51, -0.08071),
cope6_StriatumMask_5_betas_mean = c(-24.38,
    -8.297, -23.09, -3.194, -15.96, -12.54, -18.76, -55.4, 13.63,
    -12.52, -8.805, 58.42, -37.33, -56.25, 52.02, -48.07, -0.5076,
    -8.608, -67.85, -40.23, 12.44, -33.79, -28.93, -4, -20.04,
    62.34, -10.09, 12.86, 1.249, -25.19, 69.77, -18.07, -16.69,
    18.09, 16.25, -27.2, -12.67, 6.946, -25.86, -21.46, 77.06,
    -3.023, -90.03), cope5_StriatumMask_5_betas_mean = c(24.38,
    8.297, 23.09, 3.194, 15.96, 12.54, 18.76, 55.4, -13.63, 12.52,
    8.805, -58.42, 37.33, 56.25, -52.02, 48.07, 0.5076, 8.608,
    67.85, 40.23, -12.44, 33.79, 28.93, 4, 20.04, -62.34, 10.09,
    -12.86, -1.249, 25.19, -69.77, 18.07, 16.69, -18.09, -16.25,
    27.2, 12.67, -6.946, 25.86, 21.46, -77.06, 3.023, 90.03),
    cope4_StriatumMask_5_betas_mean = c(-0.1806, 15.36, 16.78,
    -3.517, 28.02, -41.14, -22.81, 20.91, 15.26, 17.1, 6.271,
    20.32, 24.57, 6.072, 12.51, 5.534, 30.1, 49.02, 71.84, 2.404,
    8.636, -15.64, -6.885, -2.237, 33.27, 12.35, -45.2, -16.68,
    15.54, 4.278, 40.59, 0.7229, 13.89, 25.12, -20.32, 0.7402,
    14.96, -20.14, 54.07, 14.79, 16.95, 27.07, 14.58),
cope3_StriatumMask_5_betas_mean = c(1.978,
    -4.735, 4.603, 52.85, -11.23, 24.38, 21.69, 39.17, 11.54,
    17.79, 55.56, 20.45, 28.13, 13.82, -5.683, 2.911, 18.02,
    13.02, 25.72, 15.83, 6.11, 13.49, 16.81, -29.8, 21.49, 7.513,
    27.28, 14.86, 22.98, 9.325, 8.833, 14.27, 46.35, 39.8, -7.482,
    -0.1707, 44.42, 33.53, 26.02, 15, 39.72, 18.88, 14.45),
cope2_StriatumMask_5_betas_mean = c(-27.24,
    -3.252, -21.67, -14.59, -18.78, -10.4, -6.882, 15.76, 13.41,
    -1.525, -1.248, 69.55, -22.77, -30.24, 11.38, -21.1, 16.3,
    -5.086, -33.82, -48.84, 6.821, -12.66, -17.23, 8.287, -28.52,
    55.27, 8.905, 14.06, 10.88, -4.195, 59.09, -7.859, -0.6477,
    3.593, 19.66, -18.36, 4.738, 15.14, -5.58, -8.72, 50.4, 5.613,
    -89.5), cope1_StriatumMask_5_betas_mean = c(1.36, 2.678,
    3.126, 7.72, 0.1483, 13.5, 24.46, 41.42, 0.1413, 9.216, 1.829,
    -3.59, 14.06, 23.06, -20.59, 15.88, 17.19, 5.7, 31.9, -2.176,
    -8.67, 10.99, 11.2, 10.64, -58.77, -7.03, 14.4, 9.383, 13.62,
    16.88, -5.792, 10.24, 3.981, -6.872, 12.54, 11.69, 14.6,
    4.773, 20.04, 11.94, -12.34, 7.493, -13.52),
cope8_StriatumMask_4_betas_mean = c(30.02,
    10.13, -38.16, -31.45, -9.172, 12.4, -0.6511, 10.94, -4.569,
    2.312, -11.92, 8.502, 33.45, 20.34, -5.991, 4.608, 37.08,
    29.14, 15.19, 9.442, -28.13, -5.005, -7.524, 31.94, -32.13,
    -3.296, -60.59, 17.59, 16, 15.33, -3.383, 8.016, -20.84,
    20.43, -17.25, -5.585, 8.63, -5.552, 21.61, 50.3, -31.68,
    -16.84, 11.46), cope7_StriatumMask_4_betas_mean = c(-30.02,
    -10.13, 38.16, 31.45, 9.172, -12.4, 0.6511, -10.94, 4.569,
    -2.312, 11.92, -8.502, -33.45, -20.34, 5.991, -4.608, -37.08,
    -29.14, -15.19, -9.442, 28.13, 5.005, 7.524, -31.94, 32.13,
    3.296, 60.59, -17.59, -16, -15.33, 3.383, -8.016, 20.84,
    -20.43, 17.25, 5.585, -8.63, 5.552, -21.61, -50.3, 31.68,
    16.84, -11.46), cope6_StriatumMask_4_betas_mean = c(17.21,
    -24.2, -8.165, -5.871, -16.94, -30.75, -47.35, 57.53, -11.56,
    -0.2164, 45.58, 62.05, 18.5, -21.69, 40.14, -13.35, 23.01,
    33.62, -7.232, 2.781, 9.096, -2.845, 3.745, 6.809, -14.62,
    19.45, -16.77, 33.06, 30.85, -0.07361, 41.98, -27.19, -10.2,
    19.17, -9.795, -20.53, -4.74, -6.671, -12.01, 12.64, 25.96,
    -1.209, -24.23), cope5_StriatumMask_4_betas_mean = c(-17.21,
    24.2, 8.165, 5.871, 16.94, 30.75, 47.35, -57.53, 11.56, 0.2164,
    -45.58, -62.05, -18.5, 21.69, -40.14, 13.35, -23.01, -33.62,
    7.232, -2.781, -9.096, 2.845, -3.745, -6.809, 14.62, -19.45,
    16.77, -33.06, -30.85, 0.07361, -41.98, 27.19, 10.2, -19.17,
    9.795, 20.53, 4.74, 6.671, 12.01, -12.64, -25.96, 1.209,
    24.23), cope4_StriatumMask_4_betas_mean = c(26.36, 18.31,
    -5.294, 10.02, -14.03, 17.99, 2.606, 21.04, 17.48, 0.52,
    18.67, 41.7, 16.43, 22.12, -21.61, 17.06, 47.47, 49.68, 22.28,
    6.687, -4.8, -8.284, 5.924, 21.67, 7.679, -17.76, -25.72,
    15.04, 22.27, 37.97, -4.224, 19.68, -1.014, 33.49, -6.861,
    -9.917, 11.85, 13.93, 39.51, 46.16, -21.3, 3.857, 20.03),
    cope3_StriatumMask_4_betas_mean = c(-4.475, 8.136, 20.85,
    36.44, -4.315, 19.52, 0.5537, 12.27, 24.51, 0.8773, 31.16,
    30.13, -17.3, -4.434, -17.27, 9.764, 17.33, 18.36, 4.433,
    -9.225, 23.91, -5.546, 13.69, -2.575, 27.54, -4.718, 34.02,
    -0.7261, 5.103, 24.8, -2.262, 13.11, 18.56, 13.33, 8.641,
    -3.453, 5.022, 26.33, 17.79, 5.668, 12.13, 18.55, 3.057),
    cope2_StriatumMask_4_betas_mean = c(2.537, -19.08, -18.83,
    -2.023, -9.252, -21.48, -12.46, 35.15, -4.74, -2.526, 21.46,
    67.33, 11.77, -21.02, 10.89, -7.3, 24.4, 15.82, -2.558, -18.58,
    2.232, -2.148, -0.2798, 11.16, -21.73, 17.03, 3.65, 16.88,
    30.72, 14.44, 23.65, -22.22, 12.26, -17.75, -5.381, -21.71,
    6.899, -2.527, -4.107, 6.232, 2.13, 0.2781, -27.52),
cope1_StriatumMask_4_betas_mean = c(-9.172,
    0.5036, -9.281, 12.45, 7.121, 12.03, 21.94, -13.04, 5.152,
    -1.847, -17.35, -8.623, -5.062, -2.434, -8.646, 5.55, 0.654,
    -17.52, 6.386, -10.25, -10.51, -1.227, -4.453, 1.159, -50.89,
    -3.253, 16.37, -5.982, 9.533, 11.49, -13.87, 4.944, 6.463,
    -28.5, 5.955, 2.492, 8.083, 1.306, 7.27, -6.711, -13.84,
    -3.173, -6.582), cope8_StriatumMask_3_betas_mean = c(-9.827,
    -29.39, -5.072, -29.28, 18.69, 7.461, -25.71, 34.55, -56.11,
    -2.596, -33.97, 19.12, 28.57, 19.91, -16.04, 14.72, 68.99,
    50.07, 54.12, 38.88, 7.486, -10.9, -3.818, 13.97, 4.118,
    -7.899, -52.3, 0.5233, -3.36, -8.542, -26.68, 19.28, -14.09,
    -9.591, 6.136, -17.34, -13.37, -18.57, 7.236, -9.855, -21.91,
    4.76, 2.585), cope7_StriatumMask_3_betas_mean = c(9.827,
    29.39, 5.072, 29.28, -18.69, -7.461, 25.71, -34.55, 56.11,
    2.596, 33.97, -19.12, -28.57, -19.91, 16.04, -14.72, -68.99,
    -50.07, -54.12, -38.88, -7.486, 10.9, 3.818, -13.97, -4.118,
    7.899, 52.3, -0.5233, 3.36, 8.542, 26.68, -19.28, 14.09,
    9.591, -6.136, 17.34, 13.37, 18.57, -7.236, 9.855, 21.91,
    -4.76, -2.585), cope6_StriatumMask_3_betas_mean = c(22.87,
    -25.94, -11.68, -2.203, -10.23, -53.78, -83.96, 49.48, -11.44,
    -5.176, -52.12, 75.78, -4.78, 8.202, 36.8, -20.51, 41.93,
    21.93, -23.74, 13.54, 16.14, 0.104, -10.84, 1.206, -67.28,
    13.01, -39.97, 26.5, 29.88, -20.17, -17.02, -16.57, -31.55,
    -3.754, 13.22, -60.05, -18.23, -20.84, -32.5, -30.19, 17.32,
    -6.671, -68.85), cope5_StriatumMask_3_betas_mean = c(-22.87,
    25.94, 11.68, 2.203, 10.23, 53.78, 83.96, -49.48, 11.44,
    5.176, 52.12, -75.78, 4.78, -8.202, -36.8, 20.51, -41.93,
    -21.93, 23.74, -13.54, -16.14, -0.104, 10.84, -1.206, 67.28,
    -13.01, 39.97, -26.5, -29.88, 20.17, 17.02, 16.57, 31.55,
    3.754, -13.22, 60.05, 18.23, 20.84, 32.5, 30.19, -17.32,
    6.671, 68.85), cope4_StriatumMask_3_betas_mean = c(-16.05,
    2.658, -4.415, -12.2, 1.195, 13.03, -29.99, 33.07, -8.351,
    -14.77, -17.69, 30.84, 34.35, -6.265, -24.46, 31.91, 55.98,
    55.14, 10.99, 28.58, -0.6548, -22.82, -8.781, -4.039, 47.5,
    -10.17, -25.6, 9.067, -7.805, 4.68, -14.51, 30.94, -5.437,
    11.18, -4.785, -28.78, 7.116, -8.826, 28.71, -7.045, -15,
    6.487, 3.255), cope3_StriatumMask_3_betas_mean = c(-5.496,
    24.4, -6.178, 15.86, -14.12, 27.35, -9.234, 0.7806, 42.1,
    -14.02, 14.09, 10.54, 6.996, -11.21, -7.568, 20.19, -8.178,
    -0.5523, -30.68, -20.66, -7.418, -10.89, -7.568, -12.52,
    30.39, 20.52, 32.13, 7.49, -1.385, 21.98, 11.6, 16.08, 8.176,
    20.77, -9.026, -9.19, 25.62, 11.64, 25.4, 11.66, 8.522, 4.707,
    -0.9193), cope2_StriatumMask_3_betas_mean = c(1.248, -20.2,
    -12.85, -10.37, -6.481, -38.99, -40.29, 50.83, -9.962, -11.15,
    -42.64, 76.49, 17.13, 12.02, 1.068, -1.049, 50.45, 8.55,
    -13.25, -2.733, 13.62, -1.994, -9.352, 11.84, -53.07, 15.24,
    -10.38, 9.065, 21.26, 7.247, -9.854, -18.25, -5.975, -21.84,
    9.668, -50.28, 0.1118, -18.12, -13.33, -30.13, -2.708, 7.863,
    -45.51), cope1_StriatumMask_3_betas_mean = c(-16.21, 2.177,
    -0.6828, 2.681, 6.963, 16.77, 27.42, -2.669, 2.728, 0.2155,
    15.99, 0.9732, 22.23, -4.741, -22.42, 15.15, 4.144, -13.74,
    13.43, -8.654, -3.702, -5.625, 1.369, 11.16, -29.82, 1.106,
    25.75, 0.3423, 6.333, 24.31, 2.151, -2.602, 12, -11.66, 2.765,
    11.51, 14.19, 3.124, 20.18, -1.8, -1.045, 5.62, 13.11),
cope8_StriatumMask_2_betas_mean = c(25.81,
    0.1008, -17.35, -20.65, 11.98, 22.12, 6.479, -8.857, 12.72,
    -4.564, -21.54, 13.93, 50.64, -19.73, -19.55, 30.95, 33.47,
    10.15, -12.42, 17.9, -17.26, -27.29, 4.29, 19.53, -9.623,
    -25.66, -41.7, 11.19, 12.26, 18.57, 3.319, 13.15, -19.85,
    8.024, -30.64, -3.4, -15.03, 11.73, 38.76, 60.92, -35.55,
    -25.83, 38.08), cope7_StriatumMask_2_betas_mean = c(-25.81,
    -0.1008, 17.35, 20.65, -11.98, -22.12, -6.479, 8.857, -12.72,
    4.564, 21.54, -13.93, -50.64, 19.73, 19.55, -30.95, -33.47,
    -10.15, 12.42, -17.9, 17.26, 27.29, -4.29, -19.53, 9.623,
    25.66, 41.7, -11.19, -12.26, -18.57, -3.319, -13.15, 19.85,
    -8.024, 30.64, 3.4, 15.03, -11.73, -38.76, -60.92, 35.55,
    25.83, -38.08), cope6_StriatumMask_2_betas_mean = c(32.23,
    -30.2, -14.07, 8.605, 3.412, -26.22, -33.54, 44.45, 26.12,
    6.825, 3.423, 82.44, 21.13, 7.608, 25.97, -32.8, 39.59, 20.19,
    -11.03, 22.94, 1.544, 12.38, -8.389, 16.52, -20.52, 14.38,
    -10.88, 47.39, 14.78, 6.086, 44.31, -16.1, -7.038, 1.967,
    -0.5604, -16.6, -4.619, -27.21, -21.32, 7.096, 1.417, -0.6048,
    -13.26), cope5_StriatumMask_2_betas_mean = c(-32.23, 30.2,
    14.07, -8.605, -3.412, 26.22, 33.54, -44.45, -26.12, -6.825,
    -3.423, -82.44, -21.13, -7.608, -25.97, 32.8, -39.59, -20.19,
    11.03, -22.94, -1.544, -12.38, 8.389, -16.52, 20.52, -14.38,
    10.88, -47.39, -14.78, -6.086, -44.31, 16.1, 7.038, -1.967,
    0.5604, 16.6, 4.619, 27.21, 21.32, -7.096, -1.417, 0.6048,
    13.26), cope4_StriatumMask_2_betas_mean = c(15.01, 22.46,
    -4.224, 15.49, 6.115, 30.69, -9.205, 11, 33.86, -11.47, 8.718,
    40.24, 32.94, 10.32, -21.59, 40.88, 42.59, 38.26, -11.98,
    10.31, -11.61, -11.29, 8.09, 16.8, 26.23, -13.6, -9.128,
    13.4, 11.02, 42.82, -7.533, 31.68, 11.7, 18.03, -28.57, -16.58,
    8.403, 16.38, 50.65, 52.36, -33.33, -3.843, 40.4),
cope3_StriatumMask_2_betas_mean = c(-8.702,
    17.62, 7.219, 28.2, -1.924, 25.78, -19.31, 22.12, 22.83,
    -8.054, 28.44, 23.53, -16.75, 5.805, -4.127, 6.258, 14.48,
    13.64, -0.4828, -13.26, 4.439, 12.69, 0.6518, 7.227, 26.09,
    23.32, 36.05, 12.2, -0.9937, 33.69, -11.5, 21.97, 30.37,
    9.786, 5.107, -10.34, 22.97, 13.41, 16.56, 6.332, 5.224,
    21.78, -2.798), cope2_StriatumMask_2_betas_mean = c(12.04,
    -27.28, -12.81, 3.426, 6.537, -20.93, -3.958, 32.95, 31.27,
    3.16, 1.62, 84.87, 17.59, 16.39, 7.736, -19.22, 37.3, 10.39,
    -10.59, 4.182, -1.269, 13.05, -9.96, 22, -31.62, 19.31, 7.048,
    27.36, 16.38, 25.42, 27.44, -10.14, 11.67, -23.71, 1.572,
    -10.1, -0.7817, -14.73, -10.15, -1.167, -16.26, 4.545, -10.31
    ), cope1_StriatumMask_2_betas_mean = c(-11.59, -0.5801, 2.253,
    2.92, 3.628, 9.823, 16.41, -7.863, 5.275, -1.153, 2.206,
    -4.593, -1.623, 1.228, -2.079, 10.64, -3.458, -11.28, 4.056,
    -6.751, -5.711, -1.179, -2.362, 4.503, -45.23, 4.45, 15.2,
    0.3556, 7.904, 17.05, -14.17, 3.913, 8.457, -16.94, 3.676,
    6.673, 2.067, 8.915, 12.39, -10.32, -5.923, -0.4391, 0.09663
    ), cope8_StriatumMask_1_betas_mean = c(-7.671, 0.7324, 18.97,
    -28.64, 13.36, 26.06, 12.31, 45.68, -19.4, -15.43, -21.18,
    10.45, 40.84, 3.266, 28.25, 10.6, 50.66, 53.76, 26.57, 47.64,
    5.642, 5.603, -10.04, 37.04, 27.35, -41.75, -26.86, -11.13,
    13.09, 44.36, -1.843, 2.302, 0.6855, 14.22, -25.71, -9.987,
    -3.158, -39.82, 5.276, -12.38, -31.06, -4.346, 52.18),
cope7_StriatumMask_1_betas_mean = c(7.671,
    -0.7324, -18.97, 28.64, -13.36, -26.06, -12.31, -45.68, 19.4,
    15.43, 21.18, -10.45, -40.84, -3.266, -28.25, -10.6, -50.66,
    -53.76, -26.57, -47.64, -5.642, -5.603, 10.04, -37.04, -27.35,
    41.75, 26.86, 11.13, -13.09, -44.36, 1.843, -2.302, -0.6855,
    -14.22, 25.71, 9.987, 3.158, 39.82, -5.276, 12.38, 31.06,
    4.346, -52.18), cope6_StriatumMask_1_betas_mean = c(-10.78,
    -25.07, -17.08, 2.81, -6.211, -41.83, -9.084, 62.16, -32.2,
    -22.2, -28.83, 47.89, 17.46, 25.87, 52.77, -12.9, 11.86,
    9.416, -5.891, 16.54, 19.86, -7.199, -16.48, -13.35, -20.79,
    13.97, -8.254, -9.45, 10.29, -3.625, 15.06, -47.86, -35.86,
    8.605, -0.989, -20.42, -30.45, -54.43, -44.19, -32.61, 14.31,
    0.9104, -14.45), cope5_StriatumMask_1_betas_mean = c(10.78,
    25.07, 17.08, -2.81, 6.211, 41.83, 9.084, -62.16, 32.2, 22.2,
    28.83, -47.89, -17.46, -25.87, -52.77, 12.9, -11.86, -9.416,
    5.891, -16.54, -19.86, 7.199, 16.48, 13.35, 20.79, -13.97,
    8.254, 9.45, -10.29, 3.625, -15.06, 47.86, 35.86, -8.605,
    0.989, 20.42, 30.45, 54.43, 44.19, 32.61, -14.31, -0.9104,
    14.45), cope4_StriatumMask_1_betas_mean = c(4.84, 8.677,
    12.27, -7.647, 16.95, 11.6, -4.777, 36.14, -0.6954, -16.71,
    6.837, 24.48, 33.52, 16.08, 2.818, 33.76, 40.46, 49.53, 12.67,
    17.85, 4.385, -2.631, -6.774, 19.03, 24.32, -20.09, -10.17,
    -9.06, 8.567, 32.12, -2.03, -1.62, 0.146, 37.04, -22.95,
    -23.3, 8.028, -17.19, 20.37, 16.84, -22.3, -6.429, 51.04),
    cope3_StriatumMask_1_betas_mean = c(15.35, 5.55, -18.41,
    15.07, 3.556, 7.953, -14.82, -9.422, 16.4, -0.3186, 24.63,
    12.67, -6.266, 2.59, -20.88, 19.75, -6.401, -2.396, -5.993,
    -35.32, 2.134, -4.257, 2.744, -9.988, -11.43, 32.36, 18.16,
    1.64, -6.096, -2.82, -1.367, -2.237, -0.7249, 22.74, 2.451,
    -9.7, 20.11, 29.75, 16.12, 33.47, 11.92, -2.012, -1.725),
    cope2_StriatumMask_1_betas_mean = c(-22.73, -15.83, -19.77,
    -8.785, -1.132, -28.61, -8.759, 55.94, -23.65, -11.41, -25.9,
    55.99, 23.15, 20.83, 1.789, -8.291, 18.53, -3.007, 3.943,
    -6.776, 6.329, -9.923, -15.03, -6.602, -28.07, 15.85, 4.005,
    -9.185, 7.425, 15.21, 14.91, -29.58, -32.79, -8.068, 9.733,
    -14.88, -6.852, -45.85, -28.66, -33.56, -0.5571, 9.592, -19.33
    ), cope1_StriatumMask_1_betas_mean = c(-8.128, 5.758, -1.077,
    -2.914, 7.331, 17.59, 7.21, -1.398, 9.864, 9.548, 7.269,
    -1.59, 4.966, -2.957, -33.94, 4.149, 4.05, -12.29, 9.097,
    -12.87, -15.36, -2.254, 1.258, 6.453, -29.28, 0.6771, 7.286,
    12.21, 7.805, 16.56, -0.8941, 13.69, 1.07, -9.846, 10.8,
    9.538, 21.36, 6.965, 14.37, -2.649, 0.8941, 2.795, -7.913
    ), cope8_StriatumMask_betas_mean = c(19.19, 8.326, -14.14,
    -47.34, 21.49, -12.56, -16.33, 20.01, 1.212, 10.1, -35.27,
    -3.354, 17.25, 9.637, -4.914, 6.339, 41.29, 38.17, 23.69,
    10.55, -9.964, -7.758, -15.25, 32.33, -26.52, 2.892, -61.29,
    -5.893, 5.116, -1.717, 8.98, -3.727, -29.21, 0.6858, -19.31,
    5.567, -11.3, -11.28, 21.09, 27.76, -41.58, -22.77, 23.96
    ), cope7_StriatumMask_betas_mean = c(-19.19, -8.326, 14.14,
    47.34, -21.49, 12.56, 16.33, -20.01, -1.212, -10.1, 35.27,
    3.354, -17.25, -9.637, 4.914, -6.339, -41.29, -38.17, -23.69,
    -10.55, 9.964, 7.758, 15.25, -32.33, 26.52, -2.892, 61.29,
    5.893, -5.116, 1.717, -8.98, 3.727, 29.21, -0.6858, 19.31,
    -5.567, 11.3, 11.28, -21.09, -27.76, 41.58, 22.77, -23.96
    ), cope6_StriatumMask_betas_mean = c(-3.001, -19.78, -17.55,
    -13.93, -26.77, -33.2, -41.41, 0.257, -8.959, -1.035, 4.296,
    34.65, -9.697, -26.18, 56.74, -26.94, 14.28, 12.58, -34.56,
    -3.228, 11.26, -16.65, -10.86, -6.784, -24.45, 23.86, -8.12,
    18.23, 21.56, -17.01, 36.51, -34.84, -34.06, -0.2884, 8.737,
    -20.99, -15.66, -17.38, -34.47, -24.96, 49.42, -2.499, -52.5
    ), cope5_StriatumMask_betas_mean = c(3.001, 19.78, 17.55,
    13.93, 26.77, 33.2, 41.41, -0.257, 8.959, 1.035, -4.296,
    -34.65, 9.697, 26.18, -56.74, 26.94, -14.28, -12.58, 34.56,
    3.228, -11.26, 16.65, 10.86, 6.784, 24.45, -23.86, 8.12,
    -18.23, -21.56, 17.01, -36.51, 34.84, 34.06, 0.2884, -8.737,
    20.99, 15.66, 17.38, 34.47, 24.96, -49.42, 2.499, 52.5),
    cope4_StriatumMask_betas_mean = c(15.33, 19, 2.13, 0.6255,
    3.965, -1.875, -11.55, 31.71, 10.09, 6.487, 11.98, 22.06,
    18.12, 14.37, -12.51, 15.88, 43.94, 42.62, 28.01, 5.568,
    7.426, -9.192, -2.169, 2.482, 15.11, -12.14, -29.41, -0.2639,
    19.3, 15.57, 0.9526, 11.34, -3.821, 24.48, -6.627, -8.762,
    9.8, -6.399, 37.83, 25.74, -14.33, 4.295, 21.01),
cope3_StriatumMask_betas_mean = c(-3.592,
    6.864, 7.348, 44, -11.51, 24.63, 1.817, 13.9, 9.993, -2.448,
    46.96, 24.46, 1.184, 2.201, -9.854, 8.554, 11.19, 5.276,
    6.545, -10.3, 18.45, 0.09225, 14.79, -21.75, 26.66, -5.553,
    31.19, 0.8526, 10.5, 20.36, -8.67, 16.04, 25.48, 24.09, 7.305,
    -12.65, 25.91, 15.63, 15.62, 4.822, 29.16, 26.04, -6.085),
    cope2_StriatumMask_betas_mean = c(-13.48, -17.98, -22.68,
    -9.708, -22.45, -23.12, -13.93, 12.69, -4.801, -1.965, -6.992,
    46.79, -6.076, -17.57, 13.97, -10.84, 23.23, 4.383, -21.55,
    -22.44, 4.44, -10.1, -9.803, 3.025, -28.17, 22, 4.17, 9.131,
    19.87, 5.414, 22.37, -25.66, -7.043, -30.76, 11.91, -14.59,
    -2.368, -8.886, -16.82, -21.95, 18.63, 2.53, -49.32),
cope1_StriatumMask_betas_mean = c(-5.115,
    -1.257, -4.329, 17.92, 5.458, 15.17, 16.84, 7.652, 3.981,
    0.3726, -10.51, -5.246, 4.09, 6.008, -20.68, 12.2, 9.368,
    -6.345, 14.45, -6.155, -10.31, 2.61, 0.6008, 7.258, -48.2,
    -2.675, 8.916, 1.677, 8.255, 18.35, -13.18, 8.82, 9.647,
    -21.62, 6.05, 7.721, 10.41, 6.71, 16.76, 2.002, -13.56, 2.499,
    -6.206), age = c(34L, 32L, 34L, 22L, 27L, 33L, 33L, 41L,
    21L, 20L, 32L, 30L, 29L, 37L, 29L, 25L, 31L, 20L, 32L, 22L,
    24L, 26L, 20L, 22L, 34L, 34L, 44L, 40L, 43L, 36L, 41L, 22L,
    41L, 26L, 41L, 45L, 36L, 31L, 31L, 27L, 40L, 23L, 27L), hare2f1 = c(3L,
    10L, 7L, 5L, 4L, 3L, 5L, 6L, 13L, 13L, 7L, 9L, 12L, 7L, 4L,
    13L, 12L, 11L, 14L, 13L, 10L, 6L, 6L, 13L, 11L, 10L, 13L,
    16L, 6L, 8L, 8L, 11L, 9L, 13L, 10L, 9L, 5L, 9L, 5L, 12L,
    13L, 9L, 8L), hare2f2 = c(14, 18, 3, 10, 6, 6, 9, 7, 18.75,
    16, 15, 12, 14, 18, 14, 18, 18, 19, 18, 15.555556, 14.444444,
    12, 1.111111, 17, 12, 17, 14, 13, 16, 7.777778, 6.666667,
    13, 14, 13, 11, 16, 4, 12, 10, 13, 14, 17, 12), hare4 = c(10,
    8, 2, 3, 2, 3, 5, 2, 9, 8, 6, 4, 6, 10, 6, 8, 9, 9, 9, 7.5,
    7, 5, 0, 9, 4, 10, 10, 9, 8, 1.25, 0, 7, 7, 7, 5, 9, 0, 3,
    4, 7, 4, 9, 3), hare = c(20, 32, 10, 16, 11, 11, 15, 15,
    35.294118, 33, 26, 22, 27, 27, 22, 33, 33, 32, 34, 29.473684,
    27.368421, 20, 8.421053, 32, 27, 30, 30, 31, 24, 16.842105,
    15.789474, 25, 26, 30, 23, 29, 10, 22, 16, 29, 30, 27, 24
    ), ext_t = c(193L, 374L, 127L, 181L, 198L, 112L, 208L, 194L,
    185L, 224L, 275L, 204L, 235L, 257L, 149L, 279L, 320L, 322L,
    188L, 220L, 273L, 206L, 129L, 296L, 223L, 277L, 156L, 195L,
    219L, 155L, 167L, 176L, 220L, 227L, 224L, 195L, 150L, 277L,
    134L, 285L, 255L, 225L, 176L), total_barrat_11_imputed = c(52,
    49.65517241, 49, 50, 59, 33, 80, 59, 49, 88.96551724, 46,
    69, 55, 61, 55, 81, 63, 78, 63, 77, 74, 56, 66, 65, 64, 80,
    47, 41, 55, 61, 69, 65, 54, 60, 75, 48, 55, 92, 55, 80, 61,
    74, 75), mcq_k = c(0.026255008, 0.001003094, 0.005960345,
    0.015726049, 0.010265035, 0.001003162, 0.0000562, 0.001264102,
    0.101500481, 0.000371013, 0.041432153, 0.002816398, 0.000610156,
    0.002515929, 0.013917576, 0.041429705, 0.001003197, 0.015963745,
    0.004571462, 0.066152274, 0.001264173, 0.013917914, 0.0000145,
    0.000158281, 0.025279846, 0.007219305, 0.001003151, 0.000158275,
    0.040812627, 0.015218595, 0.0000234, 0.008376655, 0.003841158,
    0.007218929, 0.011170246, 0.001264155, 0.002183796, 0.041432825,
    0.018248241, 0.025279435, 0.00728945, 0.015218596, 0.000139047
    ), ppitots = c(127L, 144L, 123L, 139L, 132L, 104L, 124L,
    101L, 139L, 143L, 125L, 118L, 143L, 136L, 101L, 155L, 121L,
    163L, 144L, 137L, 161L, 132L, 129L, 172L, 130L, 149L, 130L,
    127L, 131L, 100L, 134L, 140L, 130L, 156L, 129L, 105L, 104L,
    144L, 131L, 155L, 141L, 148L, 122L), ppi_1_corrected = c(0.790903075,
    -0.699393955, -2.327819799, 1.081391412, 1.312482037, -1.237538376,
    -2.908572705, -1.431192482, 0.849643836, -0.164898186, -2.41690919,
    -2.180646599, 2.448811184, -0.690782751, -3.013794372, -0.299602118,
    -2.681787682, 1.644921908, -0.813003057, 1.123342946, 5.134178123,
    0.079542428, -0.261508648, 3.433661529, -0.273992274, 2.158546617,
    1.906361161, 1.422218718, -0.391906978, -3.50632425, -1.107140046,
    2.554466033, -0.185769247, 2.924775604, -1.911895686, -4.074384118,
    -3.514935455, -1.132749891, 3.135218938, 2.554032851, 1.165085067,
    1.001346409, -0.06377271), ppi_2_corrected = c(-2.126526342,
    2.11252134, 0.555050342, -1.00112002, 0.340187762, -5.601376296,
    1.123969936, -4.711504227, 0.689931234, 0.579906262, 1.063194228,
    -0.20079187, -0.692661735, 1.762800655, -3.876379279, 3.649272316,
    1.919311154, 6.385631495, 2.52094701, -0.266955763, 0.107879822,
    0.040699835, -0.035262664, 4.854103646, -0.699493009, 1.446789539,
    -2.783996549, -3.166278249, 0.253753447, -2.916502162, 0.483071268,
    -1.851965471, -0.491096031, 0.403290401, 0.807272843, -0.914685705,
    -2.568897775, 4.595852557, -3.588214202, 2.506562905, 0.802072504,
    1.563208978, -2.362131731), total_buss_perry = c(55L, 79L,
    64L, 79L, 86L, 37L, 85L, 69L, 76L, 109L, 80L, 62L, 46L, 85L,
    48L, 119L, 124L, 131L, 94L, 56L, 95L, 62L, 78L, 106L, 93L,
    76L, 46L, 54L, 61L, 61L, 76L, 94L, 98L, 85L, 94L, 70L, 65L,
    70L, 45L, 114L, 99L, 92L, 61L)), .Names =
c("cope8_StriatumMask_7_betas_mean",
"cope7_StriatumMask_7_betas_mean", "cope6_StriatumMask_7_betas_mean",
"cope5_StriatumMask_7_betas_mean", "cope4_StriatumMask_7_betas_mean",
"cope3_StriatumMask_7_betas_mean", "cope2_StriatumMask_7_betas_mean",
"cope1_StriatumMask_7_betas_mean", "cope8_StriatumMask_6_betas_mean",
"cope7_StriatumMask_6_betas_mean", "cope6_StriatumMask_6_betas_mean",
"cope5_StriatumMask_6_betas_mean", "cope4_StriatumMask_6_betas_mean",
"cope3_StriatumMask_6_betas_mean", "cope2_StriatumMask_6_betas_mean",
"cope1_StriatumMask_6_betas_mean", "cope8_StriatumMask_5_betas_mean",
"cope7_StriatumMask_5_betas_mean", "cope6_StriatumMask_5_betas_mean",
"cope5_StriatumMask_5_betas_mean", "cope4_StriatumMask_5_betas_mean",
"cope3_StriatumMask_5_betas_mean", "cope2_StriatumMask_5_betas_mean",
"cope1_StriatumMask_5_betas_mean", "cope8_StriatumMask_4_betas_mean",
"cope7_StriatumMask_4_betas_mean", "cope6_StriatumMask_4_betas_mean",
"cope5_StriatumMask_4_betas_mean", "cope4_StriatumMask_4_betas_mean",
"cope3_StriatumMask_4_betas_mean", "cope2_StriatumMask_4_betas_mean",
"cope1_StriatumMask_4_betas_mean", "cope8_StriatumMask_3_betas_mean",
"cope7_StriatumMask_3_betas_mean", "cope6_StriatumMask_3_betas_mean",
"cope5_StriatumMask_3_betas_mean", "cope4_StriatumMask_3_betas_mean",
"cope3_StriatumMask_3_betas_mean", "cope2_StriatumMask_3_betas_mean",
"cope1_StriatumMask_3_betas_mean", "cope8_StriatumMask_2_betas_mean",
"cope7_StriatumMask_2_betas_mean", "cope6_StriatumMask_2_betas_mean",
"cope5_StriatumMask_2_betas_mean", "cope4_StriatumMask_2_betas_mean",
"cope3_StriatumMask_2_betas_mean", "cope2_StriatumMask_2_betas_mean",
"cope1_StriatumMask_2_betas_mean", "cope8_StriatumMask_1_betas_mean",
"cope7_StriatumMask_1_betas_mean", "cope6_StriatumMask_1_betas_mean",
"cope5_StriatumMask_1_betas_mean", "cope4_StriatumMask_1_betas_mean",
"cope3_StriatumMask_1_betas_mean", "cope2_StriatumMask_1_betas_mean",
"cope1_StriatumMask_1_betas_mean", "cope8_StriatumMask_betas_mean",
"cope7_StriatumMask_betas_mean", "cope6_StriatumMask_betas_mean",
"cope5_StriatumMask_betas_mean", "cope4_StriatumMask_betas_mean",
"cope3_StriatumMask_betas_mean", "cope2_StriatumMask_betas_mean",
"cope1_StriatumMask_betas_mean", "age", "hare2f1", "hare2f2",
"hare4", "hare", "ext_t", "total_barrat_11_imputed", "mcq_k",
"ppitots", "ppi_1_corrected", "ppi_2_corrected", "total_buss_perry"
), row.names = c(NA, -43L), class = "data.frame")


-- 

*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University *

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Sep  1 18:32:29 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Sep 2014 09:32:29 -0700
Subject: [R] Depth vs Temp graph for different transects
In-Reply-To: <CAPEc57GMyRhONYzsOfEU_jhoAyMvEh4PSnneEiWTWDB35iKd4A@mail.gmail.com>
References: <CAPEc57GMyRhONYzsOfEU_jhoAyMvEh4PSnneEiWTWDB35iKd4A@mail.gmail.com>
Message-ID: <62D72974-3BDE-49A8-A425-052A2306D030@comcast.net>


On Sep 1, 2014, at 3:52 AM, Tinus Sonnekus wrote:

> Hi All,
>
> Have the following code. The graph works well plotting the 15  
> transect for
> me however the legend shows a total of 22 transects. The original  
> data has
> 22 transects numbered from 1 to 22. New data set got only 15. How  
> can I get
> the legend to show only the transects plotted.
>
>
> # Create Line Chart
>
>
> TAll <- read.csv("TAll Data.csv")

You have set up a situation where we can only guess.

>
>
> # convert factor to numeric for convenience
> TAll$Tran <- as.numeric(TAll$Trans)
> nTrans <- max(TAll$Trans)
>
> # get the range for the x and y axis
> xrange <- range(TAll$Temp)
> yrange <- range(TAll$Depth)
>
> # set up the plot
> plot(xrange, yrange, ylim = rev(yrange), type="n", xlab="Temp (deg  
> C)",
>  ylab="Depth (m)" )
> colors <- rainbow(nTrans)
> linetype <- c(1:nTrans)
> plotchar <- seq(1,1+nTrans,1)
>
> # add lines
> for (i in 1:nTrans) {
>  tree <- subset(TAll, Trans==i)
>  lines(tree$Temp, tree$Depth, type="b", lwd=1.5,
>    lty=linetype[i], col=colors[i], pch=plotchar[i])
> }
>
> # add a legend
> legend(xrange[-2], yrange[-2], 1:nTrans, cex=0.8, col=colors,
>  pch=plotchar, lty=linetype, title="Transect")
>
If nTrans is 22 then you are getting what you ask for. If you  
subsetted a dataset where TAll$Trans was a factor then it's perfecty  
possible that the legend would have more items than the subset.  
Perhaps you should use `length` or length(unique(.))` rather than `max`.

-- 
David.


>
>
> Thanks for the help,
> Tinus
>
> -- 
> M.J. Sonnekus
> PhD Candidate (The Phytoplankton of the southern Agulhas Current Large
> Marine Ecosystem (ACLME))
> Department of Botany
> South Campus
> Nelson Mandela Metropolitan University
> PO Box 77000
> Port Elizabeth
> South Africa
> 6031
>
> Cell: 082 080 9638
> E-mail: tsonnekus at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From wdunlap at tibco.com  Mon Sep  1 18:35:18 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 1 Sep 2014 09:35:18 -0700
Subject: [R] SpectrumBackground
In-Reply-To: <COL125-W296502A4B0FE8A599F3178B5C60@phx.gbl>
References: <COL125-W296502A4B0FE8A599F3178B5C60@phx.gbl>
Message-ID: <CAF8bMcZmQ_78eAfJx4WSa9GnZBSjenZk-sXV4Qu0mBjrF+ozKw@mail.gmail.com>

I think you can get yourself going by calling
   Peaks:::.First.lib(dirname(find.package("Peaks")), "Peaks")
to get Peaks' DLL loaded.  .First.lib is not getting called.

You should ask the package's maintainer, maintainer("Peaks"), to fix
up the statup procedures.  It the help files had examples or the
package had any tests I think this would have been caught by CRAN.  It
does have two demo's, which do not work for the same reason.



Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Sep 1, 2014 at 7:25 AM, Edmir Silva <edmirsilva at live.com> wrote:
> Hello there ...
>
> Using package Peaks to run the function SNIP on a csv
> file with 19 spectrum.
>
>
>
> While trying to run:
>
> ### doing SNIP for every spectra
>
> require(Peaks)
>
> for (i in 1:NROW(Q))
>
>                 {
>
>                 Q.t[i,]<-Q[i,]-SpectrumBackground(as.numeric(as.vector(Q[i,])))
>
>                 print(i)
>
>                 }
>
> Got the following error:
>
> Error in .Call("R_SpectrumBackground",
> as.vector(y), as.integer(iterations),
>
> :
>
>   "R_SpectrumBackground"
> not available for .Call() for package "Peaks"
>
>
>
> Any suggestions on how to correct this ?
>
>
>
> Thanks for the help,
>
>
>
> Edmir
>
> Fiber&Polymer Science, NCSU
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ross at biostat.ucsf.edu  Mon Sep  1 19:59:05 2014
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 1 Sep 2014 10:59:05 -0700
Subject: [R] Building R for better performance
In-Reply-To: <5404578D.6050801@yahoo.co.uk>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<5404578D.6050801@yahoo.co.uk>
Message-ID: <20140901175904.GJ22345@markov.biostat.ucsf.edu>

On Mon, Sep 01, 2014 at 12:25:01PM +0100, lejeczek wrote:
> could you tell us if the same/similar performance benefits we should 
> expect when gnu complier suite + MKL are teamed up?
> and how to configure such a compilation?
> many thanks
>

Jonathan, thanks for these very interesting results.  I'm curious how
the single core performance of the different compiler compare.

Sometimes it's desirable to keep code to a single core, e.g., if you
have assigned n jobs to n cores you don't want each job trying to grab
more cores.

Ross Boylan


From pdalgd at gmail.com  Mon Sep  1 20:10:11 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 1 Sep 2014 20:10:11 +0200
Subject: [R] Unexpected behavior when giving a value to a new variable
	based on the value of another variable
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B23C@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
	<CAAJSdjhPM_=A4Hs3E=Tr9C_iOdfj5pMCJCgjq0Z5FK8RmNBVcw@mail.gmail.com>
	<8564BCD7D26E0D40872F1A132C8BBB250258B23C@MATIAEXCH.matiaf.local>
Message-ID: <37D7D44D-F4AF-43FE-8CFF-21776A111A22@gmail.com>


On 01 Sep 2014, at 13:08 , Angel Rodriguez <angel.rodriguez at matiainstituto.net> wrote:

> Thank you John, Jim, Jeff and both Davids for your answers.
> 
> After trying different combinations of values for the variable samplem, it looks like if age is greater than 65, R applies the correct code 1 whatever the value of samplem, but if age is less than 65, it just copies the values of samplem to sample. I do not understand why it does so.
> 

It's because indexed assignment is really (white lie alert: it's actually worse)

N$sample <- `[<-`(`$`(N, `sample`), index, value)

and since N$sample isn't there from the outset, partial matching kicks in for the `$`bit and makes the right hand side equivalent to the same thing with `samplem`. The result still gets assigned to N$sample, but the value is the same that N$samplem would get from

N$samplem[N$age >= 65] <- 1

Notice the difference if you do

> N$sample <- NA
> N$sample[N$age >= 65] <- 1 
> N
  age samplem sample
1  67      NA      1
2  62       1     NA
3  74       1      1
4  61       1     NA
5  60       1     NA
6  55       1     NA
7  60       1     NA
8  59       1     NA
9  58      NA     NA

-pd

> In any case, Jim's syntax work very well, although I do not understand why either.
> 
> Answering to Jim, I just wanted a variable that could identify individuals with some characteristics (not only age, as in this example that has been oversimplified).
> 
> Best regards,
> 
> Angel Rodriguez-Laso
> 
> 
> -----Mensaje original-----
> De: John McKown [mailto:john.archie.mckown at gmail.com]
> Enviado el: vie 29/08/2014 14:46
> Para: Angel Rodriguez
> CC: r-help
> Asunto: Re: [R] Unexpected behavior when giving a value to a new variable based on the value of another variable
> 
> On Fri, Aug 29, 2014 at 3:53 AM, Angel Rodriguez
> <angel.rodriguez at matiainstituto.net> wrote:
>> 
>> Dear subscribers,
>> 
>> I've found that if there is a variable in the dataframe with a name very similar to a new variable, R does not give the correct values to this latter variable based on the values of a third value:
>> 
>> 
> <snip>
>> 
>> Any clue for this behavior?
>> 
> <snip>
>> 
>> Thank you very much.
>> 
>> Angel Rodriguez-Laso
>> Research project manager
>> Matia Instituto Gerontologico
> 
> That is unusual, but appears to be documented in a section from
> 
> ?`[`
> 
> <quote>
> Character indices
> 
> Character indices can in some circumstances be partially matched (see
> pmatch) to the names or dimnames of the object being subsetted (but
> never for subassignment). Unlike S (Becker et al p. 358)), R never
> uses partial matching when extracting by [, and partial matching is
> not by default used by [[ (see argument exact).
> 
> Thus the default behaviour is to use partial matching only when
> extracting from recursive objects (except environments) by $. Even in
> that case, warnings can be switched on by
> options(warnPartialMatchDollar = TRUE).
> 
> Neither empty ("") nor NA indices match any names, not even empty nor
> missing names. If any object has no names or appropriate dimnames,
> they are taken as all "" and so match nothing.
> </quote>
> 
> Note the commend about "partial matching" in the middle paragraph in
> the quote above.
> 
> -- 
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
> 
> Maranatha! <><
> John McKown
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Mon Sep  1 20:52:27 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 1 Sep 2014 20:52:27 +0200
Subject: [R] help.start() has a faulty link
In-Reply-To: <54034B1B.9010901@stats.ox.ac.uk>
References: <5403077F.20306@sapo.pt> <54034B1B.9010901@stats.ox.ac.uk>
Message-ID: <8BD34B4E-D88A-429C-989C-DA0F25AC9CDC@gmail.com>


On 31 Aug 2014, at 18:19 , Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On 31/08/2014 12:31, Rui Barradas wrote:
>> Hello,
>> 
>> With 'help.start()' an HTML browser interface to help pops up.
>> In the section 'Miscellaneous Material' if you click on 'User Manuals'
>> an error occurs:
>> 
>> Error in vignettes[i, "PDF"] : subscript out of bounds
>> 
>> Is this a bug? A missing link?
> 
> We have very little idea: you have not told us the 'at a minumum' information required in the posting guide.
> 
> But it works for me in R 3.1.1: most likely there is a bug in the way you installed R (whatever that was ...).  For example, maybe you did not install the vignette PDFs ....

I see it with a default (I think) install of 3.0.2 on OSX (haven't gotten around to upgrading the laptop). Oddly, the Vignettes entry on the Help menu works fine, but the User Manuals entry in the R Help window produces the error. Vignettes installed or not, it doesn't sound like the right message to get. 

Poking around: Following

debug(tools:::makeVignetteTable)

I see

debug: Outfile <- vignettes[i, "PDF"]
Browse[2]> i
[1] 1
Browse[2]> vignettes
      Package                     
File  "utils" "Sweave.Rnw"        
Title "utils" "Sweave User Manual"
PDF   "utils" "Sweave.pdf"        
R     "utils" "Sweave.R"          
Browse[2]> str(vignettes)
 chr [1:4, 1:2] "utils" "utils" "utils" "utils" "Sweave.Rnw" ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:4] "File" "Title" "PDF" "R"
  ..$ : chr [1:2] "Package" ""

which looks like something is up with the construction of the "vignettes" table. Presumably, it wants to be  N x 5 with column names  "Package" "File" "Title" "PDF" "R", right?

(Followups should likely go to r-devel rather than r-help.)

-pd

> 
>> 
>> Rui Barradas
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Mon Sep  1 21:36:24 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 1 Sep 2014 19:36:24 +0000
Subject: [R] Linear regression of 0/1 response ElemStatLearn (Fig. 2.1
 the elements of statistical learning)
In-Reply-To: <54044A0A.10501@gmail.com>
References: <54044A0A.10501@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F94407@mb02.ads.tamu.edu>

This is a list for R questions, not statistics or algebra, but if you set g=.5 and solve the linear model for x2 (ignore e), you will have your answer, eg:

.5 = B1 + B2*X1 + B3*X2

where B1, 2, 3 are the three coefficients of the linear model, coef()[1], [2], [3].

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Denis Kazakiewicz
Sent: Monday, September 1, 2014 5:27 AM
To: r-help at r-project.org
Subject: [R] Linear regression of 0/1 response ElemStatLearn (Fig. 2.1 the elements of statistical learning)

Hello
In chapter 2 ESL book authors write: Let's look at example of linear 
model in a classification context
They fit a simple linear model g = 0.3290614 -0.0226360x1 + 0.2495983x2 + e,
where g is given with values 0 or 1. Then they made a decision boundary 
where yhat, if yhat>0.5 then yellow.


Question: There is a separation line on the x1x2 plot. Where did 
intercept and slope for this line come from?

In the ElemStatLearn R package, they simply put as abline( 
(0.5-coef(x.mod)[1] 
<http://i.stack.imgur.com/ANaTc.png>)/coef(x.mod)[3], 
-coef(x.mod)[2]/coef(x.mod)[3]), where first term is the intercept, and 
second term is slope for this line

Regards
Denis


From jacksonmrodrigues at gmail.com  Mon Sep  1 21:52:01 2014
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Mon, 1 Sep 2014 21:52:01 +0200
Subject: [R] Adjusted R2 for Multivariate Regression Trees (MRT)
Message-ID: <CAPL76w8Z3jh8ZCyPcv5DzQS_8Ei9NdnnCNpVu7fjy2RqpiR_xg@mail.gmail.com>

Dear fellows,

I am using MVPARTwrap package to built a MRT of 25 pollen samples collected
from 5 different ecosystems, on my analysis I will include adjusted R2.

Based on MVPARTwrap package I want to get adjusted R2 for my MRT for this,
I am using the code below.

#step 1 - Building MRT.
Pre_euro.mvpart <- mvpart(data.matrix(mydata.2) ~ .,5Ecosystems,
margin=0.02, cp=0, xv="pick", xval=nrow(mydata.1), xvmult=100, which=4)

#step 2- Adjusted R2
R2aGDF(MRT.mite.tree, T=40, tau_const=0.6, 5Ecosystems)

However, if run adjusted R2 code (step 2) 100 times, I will get 100
different results. Which one is correct?

Does anyone can help me? Any help is very welcome.

Cheers.

Jackson Rodrigues

	[[alternative HTML version deleted]]


From jacksonmrodrigues at gmail.com  Mon Sep  1 22:08:27 2014
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Mon, 1 Sep 2014 22:08:27 +0200
Subject: [R] Adjusted R2 for Multivariate Regression Trees (MRT) (ignore the
 previous message)
Message-ID: <CAPL76w_EKMt-_EJKjkmm4uhumV8u1jaRpsEv9y_mWJdmbLdQzA@mail.gmail.com>

Dear fellows,

I am using MVPARTwrap package to built a MRT of 25 pollen samples collected
from 5 different ecosystems, on my analysis I will include adjusted R2.

Based on MVPARTwrap package I want to get adjusted R2 for my MRT for this,
I am using the code below.

#step 1 - Building MRT.
Pre_euro.mvpart <- mvpart(data.matrix(mydata.2) ~ .,5Ecosystems,
margin=0.02, cp=0, xv="pick", xval=nrow(mydata.1), xvmult=100, which=4)

MRT.mite.tree<-MRT(Pre_euro.mvpart, 10, LABELS=LABELS)
#step 2- Adjusted R2
R2aGDF(MRT.mite.tree, T=40, tau_const=0.6, 5Ecosystems)

However, if run adjusted R2 code (step 2) 100 times, I will get 100
different results. Which one is correct?

Does anyone can help me? Any help is very welcome.

Cheers.

Jackson Rodrigues

	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Mon Sep  1 21:29:54 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Mon, 1 Sep 2014 12:29:54 -0700
Subject: [R] Plot Lines instead of colour bands in R
Message-ID: <1409599794.25557.YahooMailNeo@web160603.mail.bf1.yahoo.com>

Hi,
I have a plotting issue which I am trying to resolve in R. Please load my attached sample data (I used dput(lapply(sim.summary,head,1)) but the data are too large) to R, install "Rglimclim" package and run this code which shows an example plot I would like to change. My main function, "myplot" is found in the attached R object:
#------------------------------------------------------------------------------------------------------------------------------
require(Rglimclim) #http://www.ucl.ac.uk/~ucakarc/work/rain_glm.html 
myplot(sim.summary,plot.titles="",which.stats="Mean",quantiles=c(0,0.025,0.5,0.975,1), 
imputation=obs.summary,which.sites=NULL,which.timescales="daily",colours.sim=c("magenta","darkorchid1","deeppink3","yellow"), 
cex.lab=1.4,cex.axis=1.5,ylabs="Precipitation (mm)") 
mtext(text=expression(paste(italic(Mean[C]))),font=3, side=3, line=1, cex=1.3, col="black")
#-------------------------------------------------------------------------------------------------------------------------------

I would like to remove the colours completely (EXCEPT THE BOLD BLACK COLOUR BAND) and replace them with line types in R. That is, I want to specify various inbuilt R line types/line colours/line width for quantiles=c(0,0.025,0.5,0.975,1). The colours can be removed by setting colours in colours.sim=c("magenta","darkorchid1","deeppink3","yellow") to "white".

Practically, I would like my final code after modifying "myplot" function to look like:

#---------------------------------------------------------------------------------------------------------
myplot(sim.summary,plot.titles="",which.stats="Mean",quantiles=c(0,0.025,0.5,0.975,1), 
     imputation=obs.summary,which.sites=NULL,which.timescales="daily",plot.type=c("l","l","l","l","l"),
line.type=c(2,3,4,5,6),linecol.type=c('green4','red','blue','darkorchid1','deeppink3'), 
     line.width=c(2,2,2,2,2), cex.lab=1.4,cex.axis=1.5,ylabs="Precipitation (mm)") 
mtext(text=expression(paste(italic(Mean[C]))),font=3, side=3, line=1, cex=1.3, col="black") 
#---------------------------------------------------------------------------------------------------------

I have 20 such graphs to develop.
Thanks for any inputs. 
AT.

From ben.bighair at gmail.com  Mon Sep  1 20:46:15 2014
From: ben.bighair at gmail.com (Ben Tupper)
Date: Mon, 1 Sep 2014 14:46:15 -0400
Subject: [R] Depth vs Temp graph for different transects
In-Reply-To: <62D72974-3BDE-49A8-A425-052A2306D030@comcast.net>
References: <CAPEc57GMyRhONYzsOfEU_jhoAyMvEh4PSnneEiWTWDB35iKd4A@mail.gmail.com>
	<62D72974-3BDE-49A8-A425-052A2306D030@comcast.net>
Message-ID: <634E1F94-D6E5-4290-A982-B803302DF870@gmail.com>


On Sep 1, 2014, at 12:32 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Sep 1, 2014, at 3:52 AM, Tinus Sonnekus wrote:
> 
>> Hi All,
>> 
>> Have the following code. The graph works well plotting the 15 transect for
>> me however the legend shows a total of 22 transects. The original data has
>> 22 transects numbered from 1 to 22. New data set got only 15. How can I get
>> the legend to show only the transects plotted.
>> 
>> 
>> # Create Line Chart
>> 
>> 
>> TAll <- read.csv("TAll Data.csv")
> 
> You have set up a situation where we can only guess.


If this data is generated by a CTD or similar instrument then I highly recommend you use Dan Kelley's oce package.  It will help you manage, analyze and display the cast data.

http://cran.r-project.org/web/packages/oce/index.html

Cheers,
Ben


> 
>> 
>> 
>> # convert factor to numeric for convenience
>> TAll$Tran <- as.numeric(TAll$Trans)
>> nTrans <- max(TAll$Trans)
>> 
>> # get the range for the x and y axis
>> xrange <- range(TAll$Temp)
>> yrange <- range(TAll$Depth)
>> 
>> # set up the plot
>> plot(xrange, yrange, ylim = rev(yrange), type="n", xlab="Temp (deg C)",
>> ylab="Depth (m)" )
>> colors <- rainbow(nTrans)
>> linetype <- c(1:nTrans)
>> plotchar <- seq(1,1+nTrans,1)
>> 
>> # add lines
>> for (i in 1:nTrans) {
>> tree <- subset(TAll, Trans==i)
>> lines(tree$Temp, tree$Depth, type="b", lwd=1.5,
>>   lty=linetype[i], col=colors[i], pch=plotchar[i])
>> }
>> 
>> # add a legend
>> legend(xrange[-2], yrange[-2], 1:nTrans, cex=0.8, col=colors,
>> pch=plotchar, lty=linetype, title="Transect")
>> 
> If nTrans is 22 then you are getting what you ask for. If you subsetted a dataset where TAll$Trans was a factor then it's perfecty possible that the legend would have more items than the subset. Perhaps you should use `length` or length(unique(.))` rather than `max`.
> 
> -- 
> David.
> 
> 
>> 
>> 
>> Thanks for the help,
>> Tinus
>> 
>> -- 
>> M.J. Sonnekus
>> PhD Candidate (The Phytoplankton of the southern Agulhas Current Large
>> Marine Ecosystem (ACLME))
>> Department of Botany
>> South Campus
>> Nelson Mandela Metropolitan University
>> PO Box 77000
>> Port Elizabeth
>> South Africa
>> 6031
>> 
>> Cell: 082 080 9638
>> E-mail: tsonnekus at gmail.com
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius, MD
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From okeyes at wikimedia.org  Mon Sep  1 18:02:33 2014
From: okeyes at wikimedia.org (Oliver Keyes)
Date: Mon, 1 Sep 2014 12:02:33 -0400
Subject: [R] URLdecode problems
Message-ID: <CAAUQgdA9OCY5oYBy7+A4FWaiCQb96Sjh7g1AD1Fit=j5W+q9Cg@mail.gmail.com>

Hey all,

So, I'm attempting to decode some (and I don't know why anyone did this)
URl-encoded user agents. Running URLdecode over them generates the error:

"Error in rawToChar(out) : embedded nul in string"

Okay, so there's an embedded nul - fair enough. Presumably decoding the URL
is exposing it in a format R doesn't like. Except when I try to dig down
and work out what an encoded nul looks like, in order to simply remove them
with something like gsub(), I end up with several different strings, all of
which apparently resolve to an embedded nul:

> URLdecode("0;%20@%gIL")
Error in rawToChar(out) : embedded nul in string: '0; @\0L'
In addition: Warning message:
In URLdecode("0;%20@%gIL") :
  out-of-range values treated as 0 in coercion to raw
> URLdecode("%20%use")
Error in rawToChar(out) : embedded nul in string: ' \0e'
In addition: Warning message:
In URLdecode("%20%use") :
  out-of-range values treated as 0 in coercion to raw

I'm a relative newb to encodings, so maybe the fault is simply in my
understanding of how this should work, but - why are both strings being
read as including nuls, despite having different values? And how would I go
about removing said nuls?

-- 
Oliver Keyes
Research Analyst
Wikimedia Foundation

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Sep  1 22:25:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 01 Sep 2014 16:25:12 -0400
Subject: [R] rgl zooming to an arbitrary location
In-Reply-To: <5403E41B.90507@gmail.com>
References: <5403E41B.90507@gmail.com>
Message-ID: <5404D628.70802@gmail.com>

On 31/08/2014, 11:12 PM, Gareth Davies wrote:
> 
> I have been using rgl to view xyz point clouds containing topographic 
> data ( with around 10^5 - 10^6 points).
> 
> It's working well aside from one thing: I would like to be able to zoom 
> into an arbitrary part of the plot. However so far I could only figure 
> out how to zoom into the centre.
> 
> See the example below -- in this case, I cannot 'zoom-in' to anything 
> other than the central hill in the topography, whereas I would like to 
> be able to zoom to an arbitrary location.
> 
> Is there a way to get around this?

Yes, you can manually set the userMatrix transformation.  See ?par3d for
a discussion about how rgl figures out what to display.  See the example
in ?rgl.setMouseCallbacks for some code that does something like what
you want.

There are plans to make this a little simpler in the next major release,
but no definite release date.

Duncan Murdoch

> 
> ##########################################
> # EXAMPLE CODE
> ##########################################
> library(rgl)
> # Make up some topography
> x=runif(1e+06, min=0,max=1000)
> y=runif(1e+06, min=0,max=1000)
> # Elevation with 'hill' in the centre
> z=sin(x/50.)+cos(y/50.) + 30*exp(-((x-500)^2+(y-500)^2)*0.001)
> plot3d(x,y,z,col=z+3,aspect=FALSE)
> # Now try zooming [right mouse button]. I can only zoom into the central 
> hill, not elsewhere.
> 
> 
> Below are the details of my R Install
> 
>  > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
>   [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
>   [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8
>   [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
> 
> other attached packages:
>   [1] rgl_0.93.1098        unstructInterp_0.0-1 rgeos_0.3-6
>   [4] rgdal_0.8-16         sp_1.0-15            geometry_0.3-4
>   [7] magic_1.5-6          abind_1.4-0          SearchTrees_0.5.2
> [10] roxygen2_4.0.1
> 
> loaded via a namespace (and not attached):
> [1] digest_0.6.4    grid_3.1.1      lattice_0.20-29 Rcpp_0.11.2
> [5] stringr_0.6.2   tools_3.1.1
>  >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Mon Sep  1 23:00:06 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 1 Sep 2014 23:00:06 +0200
Subject: [R] help.start() has a faulty link
In-Reply-To: <8BD34B4E-D88A-429C-989C-DA0F25AC9CDC@gmail.com>
References: <5403077F.20306@sapo.pt> <54034B1B.9010901@stats.ox.ac.uk>
	<8BD34B4E-D88A-429C-989C-DA0F25AC9CDC@gmail.com>
Message-ID: <10A0DCF7-8431-4B19-9036-537633FD1031@gmail.com>


On 01 Sep 2014, at 20:52 , peter dalgaard <pdalgd at gmail.com> wrote:

> I see it with a default (I think) install of 3.0.2 on OSX (haven't gotten around to upgrading the laptop). Oddly, the Vignettes entry on the Help menu works fine, but the User Manuals entry in the R Help window produces the error. Vignettes installed or not, it doesn't sound like the right message to get. 
> 
> Poking around: Following
> 
> debug(tools:::makeVignetteTable)
> 
> I see
....

A bit of further poking reveals that it comes from a missing drop=FALSE, which has already been fixed in r-patched, specifically by

$ svn log -c 66144 ./src/library/tools/R/dynamicHelp.R
------------------------------------------------------------------------
r66144 | ripley | 2014-07-14 12:09:56 +0200 (Mon, 14 Jul 2014) | 1 line

port tweaks from trunk
------------------------------------------------------------------------
$ svn diff -x -w -c 66144 ./src/library/tools/R/dynamicHelp.R
Index: src/library/tools/R/dynamicHelp.R
===================================================================
--- src/library/tools/R/dynamicHelp.R	(revision 66143)
+++ src/library/tools/R/dynamicHelp.R	(revision 66144)
@@ -1,7 +1,7 @@
 #  File src/library/tools/R/dynamicHelp.R
 #  Part of the R package, http://www.R-project.org
 #
-#  Copyright (C) 1995-2013 The R Core Team
+#  Copyright (C) 1995-2014 The R Core Team
 #
 #  This program is free software; you can redistribute it and/or modify
 #  it under the terms of the GNU General Public License as published by
@@ -54,7 +54,7 @@
             vinfo <- getVignetteInfo(pkg)
      	    if (nrow(vinfo)) 
          	out <- c(out, paste0('<h2>Manuals in package', sQuote(pkg),'</h2>'),
-         		 makeVignetteTable(cbind(Package=pkg, vinfo[,c("File", "Title", "PDF", "R")])))
+         		 makeVignetteTable(cbind(Package=pkg, vinfo[,c("File", "Title", "PDF", "R"), drop = FALSE])))
      	}
         out <- c(out, "<hr>\n</body></html>")
         list(payload = paste(out, collapse="\n"))

----------------------------------
Notice that 3.1.1 was on July 10, so this won't be in it.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Mon Sep  1 23:52:40 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 01 Sep 2014 14:52:40 -0700
Subject: [R] URLdecode problems
In-Reply-To: <CAAUQgdA9OCY5oYBy7+A4FWaiCQb96Sjh7g1AD1Fit=j5W+q9Cg@mail.gmail.com>
References: <CAAUQgdA9OCY5oYBy7+A4FWaiCQb96Sjh7g1AD1Fit=j5W+q9Cg@mail.gmail.com>
Message-ID: <9493576b-892f-4dee-bb8d-b221fa2735c9@email.android.com>

I would guess that the original URLs were encoded somehow (non-ASCII), and the person who received them didn't understand how to deal with them either and url-encoded them with the thought that they would not lose information that way. Unfortunately, they probably lost the meta information as to how they were originally encoded, and without that this turns into a detective job that will likely need C's ability (perhaps via RCpp) to ignore type information to put things back. If you are lucky all strings were originally encoded the same way... if really lucky they were all UTF8 or UTF16 (which would have nuls and other odd bytes). Proceeding with the broken strings you have now will almost certainly not work. The fragments shown are not even vaguely recognizable as URLs, so I don't see how we can do anything meaningful with them.

Please read the Posting Guide. One point made there to note is that if C becomes part of the question then R-devel becomes the more appropriate list. The other is that for all of these lists plain text email is expected (nor HTML). 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 1, 2014 9:02:33 AM PDT, Oliver Keyes <okeyes at wikimedia.org> wrote:
>Hey all,
>
>So, I'm attempting to decode some (and I don't know why anyone did
>this)
>URl-encoded user agents. Running URLdecode over them generates the
>error:
>
>"Error in rawToChar(out) : embedded nul in string"
>
>Okay, so there's an embedded nul - fair enough. Presumably decoding the
>URL
>is exposing it in a format R doesn't like. Except when I try to dig
>down
>and work out what an encoded nul looks like, in order to simply remove
>them
>with something like gsub(), I end up with several different strings,
>all of
>which apparently resolve to an embedded nul:
>
>> URLdecode("0;%20@%gIL")
>Error in rawToChar(out) : embedded nul in string: '0; @\0L'
>In addition: Warning message:
>In URLdecode("0;%20@%gIL") :
>  out-of-range values treated as 0 in coercion to raw
>> URLdecode("%20%use")
>Error in rawToChar(out) : embedded nul in string: ' \0e'
>In addition: Warning message:
>In URLdecode("%20%use") :
>  out-of-range values treated as 0 in coercion to raw
>
>I'm a relative newb to encodings, so maybe the fault is simply in my
>understanding of how this should work, but - why are both strings being
>read as including nuls, despite having different values? And how would
>I go
>about removing said nuls?


From sarah.goslee at gmail.com  Tue Sep  2 00:06:25 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 1 Sep 2014 18:06:25 -0400
Subject: [R] Plot Lines instead of colour bands in R
In-Reply-To: <1409599794.25557.YahooMailNeo@web160603.mail.bf1.yahoo.com>
References: <1409599794.25557.YahooMailNeo@web160603.mail.bf1.yahoo.com>
Message-ID: <CAM_vjukJ=CLHdOprm9jkR42aWLPrtpPu6Po_2Xyv2wjDArF1cw@mail.gmail.com>

We have no idea: This email list strips most attachments. I'm almost
certain that you don't need all of your "too large" data to provide a
small reproducible example, either. Please see

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

for some ideas on how to do that without requiring attachments.

If this is something specific to the package you mention, it might be
worthwhile to start by asking the package maintainer for help.

Sarah

On Mon, Sep 1, 2014 at 3:29 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> Hi,
> I have a plotting issue which I am trying to resolve in R. Please load my attached sample data (I used dput(lapply(sim.summary,head,1)) but the data are too large) to R, install "Rglimclim" package and run this code which shows an example plot I would like to change. My main function, "myplot" is found in the attached R object:
> #------------------------------------------------------------------------------------------------------------------------------
> require(Rglimclim) #http://www.ucl.ac.uk/~ucakarc/work/rain_glm.html
> myplot(sim.summary,plot.titles="",which.stats="Mean",quantiles=c(0,0.025,0.5,0.975,1),
> imputation=obs.summary,which.sites=NULL,which.timescales="daily",colours.sim=c("magenta","darkorchid1","deeppink3","yellow"),
> cex.lab=1.4,cex.axis=1.5,ylabs="Precipitation (mm)")
> mtext(text=expression(paste(italic(Mean[C]))),font=3, side=3, line=1, cex=1.3, col="black")
> #-------------------------------------------------------------------------------------------------------------------------------
>
> I would like to remove the colours completely (EXCEPT THE BOLD BLACK COLOUR BAND) and replace them with line types in R. That is, I want to specify various inbuilt R line types/line colours/line width for quantiles=c(0,0.025,0.5,0.975,1). The colours can be removed by setting colours in colours.sim=c("magenta","darkorchid1","deeppink3","yellow") to "white".
>
> Practically, I would like my final code after modifying "myplot" function to look like:
>
> #---------------------------------------------------------------------------------------------------------
> myplot(sim.summary,plot.titles="",which.stats="Mean",quantiles=c(0,0.025,0.5,0.975,1),
>      imputation=obs.summary,which.sites=NULL,which.timescales="daily",plot.type=c("l","l","l","l","l"),
> line.type=c(2,3,4,5,6),linecol.type=c('green4','red','blue','darkorchid1','deeppink3'),
>      line.width=c(2,2,2,2,2), cex.lab=1.4,cex.axis=1.5,ylabs="Precipitation (mm)")
> mtext(text=expression(paste(italic(Mean[C]))),font=3, side=3, line=1, cex=1.3, col="black")
> #---------------------------------------------------------------------------------------------------------
>
> I have 20 such graphs to develop.
> Thanks for any inputs.
> AT.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Sarah Goslee
http://www.functionaldiversity.org


From grothered at gmail.com  Tue Sep  2 01:19:12 2014
From: grothered at gmail.com (Gareth Davies)
Date: Tue, 02 Sep 2014 09:19:12 +1000
Subject: [R] rgl zooming to an arbitrary location
In-Reply-To: <5404D628.70802@gmail.com>
References: <5403E41B.90507@gmail.com> <5404D628.70802@gmail.com>
Message-ID: <5404FEF0.2070701@gmail.com>

Fantastic -- the pan3d function in the example for rgl.setMouseCallbacks 
solves the problem.

For illustration:

##################

library(rgl)

# Get the pan3d function by running this rgl example [ignore the error 
caused by not having an open rgl device]
example(rgl.setMouseCallbacks)

#Make up some topography
x=runif(1e+06, min=0,max=1000)
y=runif(1e+06, min=0,max=1000)

# Elevation with 'hill' in the centre
z=sin(x/50.)+cos(y/50.) + 30*exp(-((x-500)^2+(y-500)^2)*0.001)

plot3d(x,y,z,col=z+3,aspect=FALSE)
pan3d(3) # This makes my 'middle' mouse button function like pan



On 02/09/14 06:25, Duncan Murdoch wrote:
> On 31/08/2014, 11:12 PM, Gareth Davies wrote:
>> I have been using rgl to view xyz point clouds containing topographic
>> data ( with around 10^5 - 10^6 points).
>>
>> It's working well aside from one thing: I would like to be able to zoom
>> into an arbitrary part of the plot. However so far I could only figure
>> out how to zoom into the centre.
>>
>> See the example below -- in this case, I cannot 'zoom-in' to anything
>> other than the central hill in the topography, whereas I would like to
>> be able to zoom to an arbitrary location.
>>
>> Is there a way to get around this?
> Yes, you can manually set the userMatrix transformation.  See ?par3d for
> a discussion about how rgl figures out what to display.  See the example
> in ?rgl.setMouseCallbacks for some code that does something like what
> you want.
>
> There are plans to make this a little simpler in the next major release,
> but no definite release date.
>
> Duncan Murdoch
>
>> ##########################################
>> # EXAMPLE CODE
>> ##########################################
>> library(rgl)
>> # Make up some topography
>> x=runif(1e+06, min=0,max=1000)
>> y=runif(1e+06, min=0,max=1000)
>> # Elevation with 'hill' in the centre
>> z=sin(x/50.)+cos(y/50.) + 30*exp(-((x-500)^2+(y-500)^2)*0.001)
>> plot3d(x,y,z,col=z+3,aspect=FALSE)
>> # Now try zooming [right mouse button]. I can only zoom into the central
>> hill, not elsewhere.
>>
>>
>> Below are the details of my R Install
>>
>>   > sessionInfo()
>> R version 3.1.1 (2014-07-10)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>>    [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
>>    [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
>>    [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8
>>    [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C
>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>>    [1] rgl_0.93.1098        unstructInterp_0.0-1 rgeos_0.3-6
>>    [4] rgdal_0.8-16         sp_1.0-15            geometry_0.3-4
>>    [7] magic_1.5-6          abind_1.4-0          SearchTrees_0.5.2
>> [10] roxygen2_4.0.1
>>
>> loaded via a namespace (and not attached):
>> [1] digest_0.6.4    grid_3.1.1      lattice_0.20-29 Rcpp_0.11.2
>> [5] stringr_0.6.2   tools_3.1.1
>>   >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From jszhao at yeah.net  Tue Sep  2 01:40:49 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 01 Sep 2014 16:40:49 -0700
Subject: [R] depth of labels of axis
Message-ID: <54050401.4060203@yeah.net>

Hi there,

With the following code,

plot(1:5, xaxt = "n")
axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]), 
"E", expression(E[t])))

you may notice that the "E" within labels of axis(1) are not at the same 
depth. So the vision of axis(1) labels is something like wave.

Is there a possible way to typeset the labels so that they are have the 
same depth?

Any suggestions will be really appreciated. Thanks in advance.

Best regards,
Jinsong


From peljasz at yahoo.co.uk  Mon Sep  1 23:24:44 2014
From: peljasz at yahoo.co.uk (lejeczek)
Date: Mon, 01 Sep 2014 22:24:44 +0100
Subject: [R] Building R for better performance
In-Reply-To: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
Message-ID: <5404E41C.8030900@yahoo.co.uk>

could you tell us if the same/similar performance benefits 
we should expect when gnu complier suite + MKL are teamed up?
and how to configure such a compilation?
many thanks

On 04/03/14 21:44, Anspach, Jonathan P wrote:
> Greetings,
>
> I'm a software engineer with Intel.  Recently I've been investigating R performance on Intel Xeon and Xeon Phi processors and RH Linux.  I've also compared the performance of R built with the Intel compilers and Intel Math Kernel Library to a "default" build (no config options) that uses the GNU compilers.  To my dismay, I've found that the GNU build always runs on a single CPU core, even during matrix operations.  The Intel build runs matrix operations on multiple cores, so it is much faster on those operations.  Running the benchmark-2.5 on a 24 core Xeon system, the Intel build is 13x faster than the GNU build (21 seconds vs 275 seconds).  Unfortunately, this advantage is not documented anywhere that I can see.
>
> Building with the Intel tools is very easy.  Assuming the tools are installed in /opt/intel/composerxe, the process is simply (in bash shell):
>
> $ . /opt/intel/composerxe/bin/compilervars.sh intel64
> $ ./configure --with-blas="-L/opt/intel/composerxe/mkl/lib/intel64 -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread -lm" --with-lapack CC=icc CFLAGS=-O2 CXX=icpc CXXFLAGS=-O2 F77=ifort FFLAGS=-O2 FC=ifort FCFLAGS=-O2
> $ make
> $ make check
>
> My questions are:
> 1) Do most system admins and/or R installers know about this performance difference, and use the Intel tools to build R?
> 2) Can we add information on the advantage of building with the Intel tools, and how to do it, to the installation instructions and FAQ?
>
> I can post my data if anyone is interested.
>
> Thanks,
> Jonathan Anspach
> Sr. Software Engineer
> Intel Corp.
> jonathan.p.anspach at intel.com
> 713-751-9460
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From s.blomberg1 at uq.edu.au  Tue Sep  2 05:00:49 2014
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 02 Sep 2014 13:00:49 +1000
Subject: [R] Building R for better performance
In-Reply-To: <5404E41C.8030900@yahoo.co.uk>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<5404E41C.8030900@yahoo.co.uk>
Message-ID: <540532E1.4080400@uq.edu.au>

Is MKL open source software? If not, that could be the sticking point.

Simon.

On 02/09/14 07:24, lejeczek wrote:
> could you tell us if the same/similar performance benefits we should 
> expect when gnu complier suite + MKL are teamed up?
> and how to configure such a compilation?
> many thanks
>
> On 04/03/14 21:44, Anspach, Jonathan P wrote:
>> Greetings,
>>
>> I'm a software engineer with Intel.  Recently I've been investigating 
>> R performance on Intel Xeon and Xeon Phi processors and RH Linux.  
>> I've also compared the performance of R built with the Intel 
>> compilers and Intel Math Kernel Library to a "default" build (no 
>> config options) that uses the GNU compilers.  To my dismay, I've 
>> found that the GNU build always runs on a single CPU core, even 
>> during matrix operations.  The Intel build runs matrix operations on 
>> multiple cores, so it is much faster on those operations.  Running 
>> the benchmark-2.5 on a 24 core Xeon system, the Intel build is 13x 
>> faster than the GNU build (21 seconds vs 275 seconds).  
>> Unfortunately, this advantage is not documented anywhere that I can see.
>>
>> Building with the Intel tools is very easy.  Assuming the tools are 
>> installed in /opt/intel/composerxe, the process is simply (in bash 
>> shell):
>>
>> $ . /opt/intel/composerxe/bin/compilervars.sh intel64
>> $ ./configure --with-blas="-L/opt/intel/composerxe/mkl/lib/intel64 
>> -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread -lm" 
>> --with-lapack CC=icc CFLAGS=-O2 CXX=icpc CXXFLAGS=-O2 F77=ifort 
>> FFLAGS=-O2 FC=ifort FCFLAGS=-O2
>> $ make
>> $ make check
>>
>> My questions are:
>> 1) Do most system admins and/or R installers know about this 
>> performance difference, and use the Intel tools to build R?
>> 2) Can we add information on the advantage of building with the Intel 
>> tools, and how to do it, to the installation instructions and FAQ?
>>
>> I can post my data if anyone is interested.
>>
>> Thanks,
>> Jonathan Anspach
>> Sr. Software Engineer
>> Intel Corp.
>> jonathan.p.anspach at intel.com
>> 713-751-9460
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat, AStat.
Senior Lecturer and Consultant Statistician
School of Biological Sciences
The University of Queensland
St. Lucia Queensland 4072
Australia
T: +61 7 3365 2506
email: S.Blomberg1_at_uq.edu.au
http://www.evolutionarystatistics.org

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

Statistics is the grammar of science - Karl Pearson.


From h.wickham at gmail.com  Tue Sep  2 05:29:10 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 1 Sep 2014 22:29:10 -0500
Subject: [R] URLdecode problems
In-Reply-To: <CAAUQgdA9OCY5oYBy7+A4FWaiCQb96Sjh7g1AD1Fit=j5W+q9Cg@mail.gmail.com>
References: <CAAUQgdA9OCY5oYBy7+A4FWaiCQb96Sjh7g1AD1Fit=j5W+q9Cg@mail.gmail.com>
Message-ID: <CABdHhvHMbeP7Qqy-bDj2btrZmaCVZWnJ2=xbH5oy_SGTYpGYuA@mail.gmail.com>

Hi Oliver,

I think you're being misled by the default behaviour of warnings: they
all get displayed at once, before control returns to the console.  If
you making them immediate, you get a slightly more informative error:

> URLdecode("0;%20@%gIL")
Warning in URLdecode("0;%20@%gIL") :
  out-of-range values treated as 0 in coercion to raw
Error in rawToChar(out) : embedded nul in string: '0; @\0L'

So the out of range value (%g...) is getting converted to a raw(0),
aka a nul. Then rawToChar() chokes.

The code for URLdecode is simple enough that I'd recommend rewriting
yourself to better handle bad inputs.

Hadley

On Mon, Sep 1, 2014 at 11:02 AM, Oliver Keyes <okeyes at wikimedia.org> wrote:
> Hey all,
>
> So, I'm attempting to decode some (and I don't know why anyone did this)
> URl-encoded user agents. Running URLdecode over them generates the error:
>
> "Error in rawToChar(out) : embedded nul in string"
>
> Okay, so there's an embedded nul - fair enough. Presumably decoding the URL
> is exposing it in a format R doesn't like. Except when I try to dig down
> and work out what an encoded nul looks like, in order to simply remove them
> with something like gsub(), I end up with several different strings, all of
> which apparently resolve to an embedded nul:
>
>> URLdecode("0;%20@%gIL")
> Error in rawToChar(out) : embedded nul in string: '0; @\0L'
> In addition: Warning message:
> In URLdecode("0;%20@%gIL") :
>   out-of-range values treated as 0 in coercion to raw
>> URLdecode("%20%use")
> Error in rawToChar(out) : embedded nul in string: ' \0e'
> In addition: Warning message:
> In URLdecode("%20%use") :
>   out-of-range values treated as 0 in coercion to raw
>
> I'm a relative newb to encodings, so maybe the fault is simply in my
> understanding of how this should work, but - why are both strings being
> read as including nuls, despite having different values? And how would I go
> about removing said nuls?
>
> --
> Oliver Keyes
> Research Analyst
> Wikimedia Foundation
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From dwinsemius at comcast.net  Tue Sep  2 05:39:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Sep 2014 20:39:23 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <54050401.4060203@yeah.net>
References: <54050401.4060203@yeah.net>
Message-ID: <53ABA405-D506-4095-AB66-530808E15CAE@comcast.net>


On Sep 1, 2014, at 4:40 PM, Jinsong Zhao wrote:

> Hi there,
>
> With the following code,
>
> plot(1:5, xaxt = "n")
> axis(1, at = 1:5, labels = c(expression(E[g]), "E",  
> expression(E[j]), "E", expression(E[t])))
>
> you may notice that the "E" within labels of axis(1) are not at the  
> same depth. So the vision of axis(1) labels is something like wave.
>
> Is there a possible way to typeset the labels so that they are have  
> the same depth?

I'm not sure that we share an interpretation of the term "depth" in  
this context. I'm interpreting your request to me vertical alighnment.

> Any suggestions will be really appreciated.

Read the help page, especially the paragraph about padj. I will admit  
that I thought the description of the actions of padj=0 and padj=1  
were not what I experienced when I tried alternate versions. It did  
not seem to me that padj=0 produced "top alignment".


-- 

David Winsemius, MD
Alameda, CA, USA


From petr.pikal at precheza.cz  Tue Sep  2 08:03:57 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 2 Sep 2014 06:03:57 +0000
Subject: [R] what happened when copying a function definition into R
 prompt then press Enter?
In-Reply-To: <19e264b.2ccd.1482a733fcd.Coremail.rhelpmaillist@163.com>
References: <19e264b.2ccd.1482a733fcd.Coremail.rhelpmaillist@163.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE0600@SRVEXCHMBX.precheza.cz>

Hi

Can you be more specific or show some code? I am completely lost in your question.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of PO SU
> Sent: Sunday, August 31, 2014 7:04 AM
> To: R. Help
> Subject: [R] what happened when copying a function definition into R
> prompt then press Enter?
>
>
> Dear expeRts,
>     That's to say,what happened when loading source code  into memory?
> what's the difference between it and loading installed code into
> memory? Do they related with .Rdata?
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From johnson.cheryl625 at gmail.com  Tue Sep  2 07:11:24 2014
From: johnson.cheryl625 at gmail.com (Cheryl Johnson)
Date: Tue, 2 Sep 2014 01:11:24 -0400
Subject: [R] Is it possible to have different animations saved together with
 the saveSWF command?
Message-ID: <CAJJ9dtu2SGoC8DpqeBeAiupkuKtc_wODEqXtBYSetVcFO3iP7w@mail.gmail.com>

The way I have programed my code the same animation runs and then starts
over again with Adobe Flash. Each time the animation ends and starts is it
possible to have a different animation start each time? Thanks in advance
for any guidance.

	[[alternative HTML version deleted]]


From smileismystyl at gmail.com  Tue Sep  2 07:37:08 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Tue, 2 Sep 2014 11:07:08 +0530
Subject: [R] RGEOS ERROR
Message-ID: <CAG1d=2A5x_GpRsR05P_27pE2tWPBNpJSh-sDtrCaPEyUTqB2iQ@mail.gmail.com>

working configuration:
R-3.1.1
WIN-64
goal: want to perfrom ploygon clipping, giving bounding box values of my
study area and extract the area from world map.
 I followed:

> clip.extent <- as(extent(76.3700, 31.7439, 78.6541, 33.2653), "SpatialPolygons")

> proj4string(clip.extent) <- CRS(proj4string(WorldMap))> LSMap <- gIntersection(WorldMap, clip.extent, byid = TRUE)

Error :

In RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, drop_not_poly,
"rgeos_intersection") :
  spgeom1 and spgeom2 have different proj4 strings


Any help or assistance would be highly obliged

	[[alternative HTML version deleted]]


From kridox at ymail.com  Tue Sep  2 08:39:59 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 2 Sep 2014 15:39:59 +0900
Subject: [R] RGEOS ERROR
In-Reply-To: <CAG1d=2A5x_GpRsR05P_27pE2tWPBNpJSh-sDtrCaPEyUTqB2iQ@mail.gmail.com>
References: <CAG1d=2A5x_GpRsR05P_27pE2tWPBNpJSh-sDtrCaPEyUTqB2iQ@mail.gmail.com>
Message-ID: <CAAcyNCxZ5JKsp-PRTgBhkZZr5kZCCu-EAx0D_pOT=wfT4H2hNw@mail.gmail.com>

What is WorldMap? From where does it come?

Regards,
Pascal

On Tue, Sep 2, 2014 at 2:37 PM, Girija Kalyani <smileismystyl at gmail.com> wrote:
> working configuration:
> R-3.1.1
> WIN-64
> goal: want to perfrom ploygon clipping, giving bounding box values of my
> study area and extract the area from world map.
>  I followed:
>
>> clip.extent <- as(extent(76.3700, 31.7439, 78.6541, 33.2653), "SpatialPolygons")
>
>> proj4string(clip.extent) <- CRS(proj4string(WorldMap))> LSMap <- gIntersection(WorldMap, clip.extent, byid = TRUE)
>
> Error :
>
> In RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, drop_not_poly,
> "rgeos_intersection") :
>   spgeom1 and spgeom2 have different proj4 strings
>
>
> Any help or assistance would be highly obliged
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From jdnewmil at dcn.davis.CA.us  Tue Sep  2 08:40:51 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 01 Sep 2014 23:40:51 -0700
Subject: [R] Is it possible to have different animations saved together
	with the saveSWF command?
In-Reply-To: <CAJJ9dtu2SGoC8DpqeBeAiupkuKtc_wODEqXtBYSetVcFO3iP7w@mail.gmail.com>
References: <CAJJ9dtu2SGoC8DpqeBeAiupkuKtc_wODEqXtBYSetVcFO3iP7w@mail.gmail.com>
Message-ID: <8b14668b-ace9-4572-b782-7162d8b29cb9@email.android.com>

SaveSWF records a movie of your graphics as programmed in R. I don't think it is any help in actually programming in flash.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 1, 2014 10:11:24 PM PDT, Cheryl Johnson <johnson.cheryl625 at gmail.com> wrote:
>The way I have programed my code the same animation runs and then
>starts
>over again with Adobe Flash. Each time the animation ends and starts is
>it
>possible to have a different animation start each time? Thanks in
>advance
>for any guidance.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From angel.rodriguez at matiainstituto.net  Tue Sep  2 10:10:25 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Tue, 2 Sep 2014 10:10:25 +0200
Subject: [R] Unexpected behavior when giving a value to a new variable
	based on the value of another variable
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
	<CAAJSdjhPM_=A4Hs3E=Tr9C_iOdfj5pMCJCgjq0Z5FK8RmNBVcw@mail.gmail.com>
	<8564BCD7D26E0D40872F1A132C8BBB250258B23C@MATIAEXCH.matiaf.local>
	<37D7D44D-F4AF-43FE-8CFF-21776A111A22@gmail.com>
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B245@MATIAEXCH.matiaf.local>

Thank you for the explanation, Peter.

Angel


-----Mensaje original-----
De: peter dalgaard [mailto:pdalgd at gmail.com]
Enviado el: lun 01/09/2014 20:10
Para: Angel Rodriguez
CC: r-help
Asunto: Re: [R] Unexpected behavior when giving a value to a new variable based on the value of another variable
 

On 01 Sep 2014, at 13:08 , Angel Rodriguez <angel.rodriguez at matiainstituto.net> wrote:

> Thank you John, Jim, Jeff and both Davids for your answers.
> 
> After trying different combinations of values for the variable samplem, it looks like if age is greater than 65, R applies the correct code 1 whatever the value of samplem, but if age is less than 65, it just copies the values of samplem to sample. I do not understand why it does so.
> 

It's because indexed assignment is really (white lie alert: it's actually worse)

N$sample <- `[<-`(`$`(N, `sample`), index, value)

and since N$sample isn't there from the outset, partial matching kicks in for the `$`bit and makes the right hand side equivalent to the same thing with `samplem`. The result still gets assigned to N$sample, but the value is the same that N$samplem would get from

N$samplem[N$age >= 65] <- 1

Notice the difference if you do

> N$sample <- NA
> N$sample[N$age >= 65] <- 1 
> N
  age samplem sample
1  67      NA      1
2  62       1     NA
3  74       1      1
4  61       1     NA
5  60       1     NA
6  55       1     NA
7  60       1     NA
8  59       1     NA
9  58      NA     NA

-pd

> In any case, Jim's syntax work very well, although I do not understand why either.
> 
> Answering to Jim, I just wanted a variable that could identify individuals with some characteristics (not only age, as in this example that has been oversimplified).
> 
> Best regards,
> 
> Angel Rodriguez-Laso
> 
> 
> -----Mensaje original-----
> De: John McKown [mailto:john.archie.mckown at gmail.com]
> Enviado el: vie 29/08/2014 14:46
> Para: Angel Rodriguez
> CC: r-help
> Asunto: Re: [R] Unexpected behavior when giving a value to a new variable based on the value of another variable
> 
> On Fri, Aug 29, 2014 at 3:53 AM, Angel Rodriguez
> <angel.rodriguez at matiainstituto.net> wrote:
>> 
>> Dear subscribers,
>> 
>> I've found that if there is a variable in the dataframe with a name very similar to a new variable, R does not give the correct values to this latter variable based on the values of a third value:
>> 
>> 
> <snip>
>> 
>> Any clue for this behavior?
>> 
> <snip>
>> 
>> Thank you very much.
>> 
>> Angel Rodriguez-Laso
>> Research project manager
>> Matia Instituto Gerontologico
> 
> That is unusual, but appears to be documented in a section from
> 
> ?`[`
> 
> <quote>
> Character indices
> 
> Character indices can in some circumstances be partially matched (see
> pmatch) to the names or dimnames of the object being subsetted (but
> never for subassignment). Unlike S (Becker et al p. 358)), R never
> uses partial matching when extracting by [, and partial matching is
> not by default used by [[ (see argument exact).
> 
> Thus the default behaviour is to use partial matching only when
> extracting from recursive objects (except environments) by $. Even in
> that case, warnings can be switched on by
> options(warnPartialMatchDollar = TRUE).
> 
> Neither empty ("") nor NA indices match any names, not even empty nor
> missing names. If any object has no names or appropriate dimnames,
> they are taken as all "" and so match nothing.
> </quote>
> 
> Note the commend about "partial matching" in the middle paragraph in
> the quote above.
> 
> -- 
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
> 
> Maranatha! <><
> John McKown
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com












	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Tue Sep  2 11:00:10 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 2 Sep 2014 19:00:10 +1000
Subject: [R] RGEOS ERROR
In-Reply-To: <CAG1d=2A5x_GpRsR05P_27pE2tWPBNpJSh-sDtrCaPEyUTqB2iQ@mail.gmail.com>
References: <CAG1d=2A5x_GpRsR05P_27pE2tWPBNpJSh-sDtrCaPEyUTqB2iQ@mail.gmail.com>
Message-ID: <CAAcGz9-2XhxJq5nUjjFRRAT_nFZ1Dtkvy4pb37J-BbMKfs9poQ@mail.gmail.com>

I suspect you are seeing old code in rgeos. Please upgrade.  If you cannot
do that, try a few other things like

## since you obviously have raster loaded

projection(clip.extent) <- projection(WorldMap)

LSMap <- gIntersection(WorldMap, clip.extent, byid = TRUE)

Does that work? If not possibly

projection(clip.extent) <- as.character(NA)

projection(WorldMap) <- as.character(NA)

LSMap <- gIntersection(WorldMap, clip.extent, byid = TRUE)
I just cannot verify those because I am up to date.

Cheers, Mike

Here's what I can do with rgeos  0.3-6:

## please declare your environment btw

library(maptools)

library(raster)

library(rgeos)

data(wrld_simpl)

clip.extent <- as(extent(76.3700, 31.7439, 78.6541, 33.2653),
"SpatialPolygons")

## this works, albeit with a warning

amap <- gIntersection(wrld_simpl, clip.extent, byid = TRUE)

## this does also work

proj4string(clip.extent) <- CRS(proj4string(amap))

amap <- gIntersection(wrld_simpl, clip.extent, byid = TRUE)

sessionInfo()

R version 3.1.1 (2014-07-10)

Platform: x86_64-w64-mingw32/x64 (64-bit)


locale:

[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252

[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C

[5] LC_TIME=English_Australia.1252


attached base packages:

[1] stats     graphics  grDevices utils     datasets  compiler  methods

[8] base


other attached packages:

[1] rgeos_0.3-6     raster_2.2-31   maptools_0.8-30 sp_1.0-15


loaded via a namespace (and not attached):

[1] foreign_0.8-61  grid_3.1.1      lattice_0.20-29 tools_3.1.1


On 2 Sep 2014 16:09, "Girija Kalyani" <smileismystyl at gmail.com> wrote:

> working configuration:
> R-3.1.1
> WIN-64
> goal: want to perfrom ploygon clipping, giving bounding box values of my
> study area and extract the area from world map.
>  I followed:
>
> > clip.extent <- as(extent(76.3700, 31.7439, 78.6541, 33.2653),
> "SpatialPolygons")
>
> > proj4string(clip.extent) <- CRS(proj4string(WorldMap))> LSMap <-
> gIntersection(WorldMap, clip.extent, byid = TRUE)
>
> Error :
>
> In RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, drop_not_poly,
> "rgeos_intersection") :
>   spgeom1 and spgeom2 have different proj4 strings
>
>
> Any help or assistance would be highly obliged
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kridox at ymail.com  Tue Sep  2 12:49:28 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 2 Sep 2014 19:49:28 +0900
Subject: [R] RGEOS ERROR
In-Reply-To: <CAG1d=2Cp2i-3P7a+UJhsbwQUBmHj=zZs1myaNmc04Bpv19YQoQ@mail.gmail.com>
References: <CAG1d=2A5x_GpRsR05P_27pE2tWPBNpJSh-sDtrCaPEyUTqB2iQ@mail.gmail.com>
	<CAAcyNCxZ5JKsp-PRTgBhkZZr5kZCCu-EAx0D_pOT=wfT4H2hNw@mail.gmail.com>
	<CAG1d=2Cp2i-3P7a+UJhsbwQUBmHj=zZs1myaNmc04Bpv19YQoQ@mail.gmail.com>
Message-ID: <CAAcyNCzM3ZdyweGiHAbQpeB8ftry=TkDtSP=hh7Z8AMpwM5uXQ@mail.gmail.com>

Please keep your reply inside the thread. Anyway, it doesn't anwer the question.

Regards,
Pascal

On Tue, Sep 2, 2014 at 7:18 PM, Girija Kalyani <smileismystyl at gmail.com> wrote:
> Sir,
> The worldmap i here refer to is , the shape file of the complete world map
>
>
>
> On Tue, Sep 2, 2014 at 12:09 PM, Pascal Oettli <kridox at ymail.com> wrote:
>>
>> What is WorldMap? From where does it come?
>>
>> Regards,
>> Pascal
>>
>> On Tue, Sep 2, 2014 at 2:37 PM, Girija Kalyani <smileismystyl at gmail.com>
>> wrote:
>> > working configuration:
>> > R-3.1.1
>> > WIN-64
>> > goal: want to perfrom ploygon clipping, giving bounding box values of my
>> > study area and extract the area from world map.
>> >  I followed:
>> >
>> >> clip.extent <- as(extent(76.3700, 31.7439, 78.6541, 33.2653),
>> >> "SpatialPolygons")
>> >
>> >> proj4string(clip.extent) <- CRS(proj4string(WorldMap))> LSMap <-
>> >> gIntersection(WorldMap, clip.extent, byid = TRUE)
>> >
>> > Error :
>> >
>> > In RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, drop_not_poly,
>> > "rgeos_intersection") :
>> >   spgeom1 and spgeom2 have different proj4 strings
>> >
>> >
>> > Any help or assistance would be highly obliged
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Pascal Oettli
>> Project Scientist
>> JAMSTEC
>> Yokohama, Japan
>
>
>
>
> --
> :) Smile is my Style :)



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From john.archie.mckown at gmail.com  Tue Sep  2 14:03:26 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 2 Sep 2014 07:03:26 -0500
Subject: [R] Building R for better performance
In-Reply-To: <540532E1.4080400@uq.edu.au>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<5404E41C.8030900@yahoo.co.uk> <540532E1.4080400@uq.edu.au>
Message-ID: <CAAJSdjjKHL7msCuyry5dTbgLvNTYWfnaNXzOjJM_v2V7ni2AtA@mail.gmail.com>

On Mon, Sep 1, 2014 at 10:00 PM, Simon Blomberg <s.blomberg1 at uq.edu.au> wrote:
> Is MKL open source software? If not, that could be the sticking point.
>
> Simon.

IANAL, but from reading here:
https://software.intel.com/en-us/en-us/intel-mkl
It is neither Libre nor Gratis. But it is royalty free. IOW, you
cannot give the software to another. You must pay a license fee to
Intel to use it. But you do not need to pay Intel any money to
distribute your executable to others. For a commercial license, it is
not too bad.

The best that I can see for R would be if someone were to post a "how
to use MKL for compiling R" type document. And if someone really
needed to have the MKL performance boost, they could license MKL for
themselves, modify R to use it, and recompile. I am not suggesting
this be done. But that would most likely mean that the modifier CAN
NOT distribute the changed R executable to others because of the GPL.
I'm pretty sure that mixing in licensed code with GPL'd code __and
distributing the executable__ is not kosher. That would violate
section #3 of the GPL.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From johannesradinger at gmail.com  Tue Sep  2 14:12:19 2014
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Tue, 2 Sep 2014 14:12:19 +0200
Subject: [R] Match beginning and end of string (grepl)
Message-ID: <CABsGe_wjyQkhpSEZ-aGDap44t4re5O5N_dyjWyd38vBgSc_TFQ@mail.gmail.com>

Hi,

I'd like to match the beginning and the end of a string. E.g. I want to
extract all strings from a vector that beginn with "12" and end with
"Apples":

a <- "2 green Apples"
b <- "12 green Apples"
c <- "12 Apples and 2 green Bananas"
d <- "12 yellow Bananas"

fruitlist <- c(a,b,c,d)

# This is how to extract all that beginn with 12
grepl("^12",fruitlist)

But how can I get only those that also end with "Apples". So basically
just item b "12 green Apples" should remain.

Is there any clear description and examples of regular expressions
and how to use them? I find the manual ?grepl very difficult to read.

Thanks,
Johannes

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Sep  2 14:32:58 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 02 Sep 2014 08:32:58 -0400
Subject: [R] Detect expired RSQLiteConnection?
Message-ID: <5405B8FA.908@gmail.com>

Is there a test for an expired RSQLiteConnection?  For example, if I run

library(RSQLite)
f <- tempfile()
con <- dbConnect(SQLite(), f)
dbDisconnect(con)
con

then I get

> con
<Expired SQLiteConnection: DBI CON (11737, 2)>

and most operations using it give errors. (In my case I have a
persistent connection object, but if I save the workspace and then
reload it, I get the expired connection.) I'd like to detect this case.
 Do I need to use try(), or parse the result of printing it?

Duncan Murdoch


From john.archie.mckown at gmail.com  Tue Sep  2 14:34:02 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 2 Sep 2014 07:34:02 -0500
Subject: [R] Match beginning and end of string (grepl)
In-Reply-To: <CABsGe_wjyQkhpSEZ-aGDap44t4re5O5N_dyjWyd38vBgSc_TFQ@mail.gmail.com>
References: <CABsGe_wjyQkhpSEZ-aGDap44t4re5O5N_dyjWyd38vBgSc_TFQ@mail.gmail.com>
Message-ID: <CAAJSdjgrpvZD3LNBWfd4wE9=DSdi=N2GhWM3mOQ870f-GnasNA@mail.gmail.com>

On Tue, Sep 2, 2014 at 7:12 AM, Johannes Radinger
<johannesradinger at gmail.com> wrote:
> Hi,
>
> I'd like to match the beginning and the end of a string. E.g. I want to
> extract all strings from a vector that beginn with "12" and end with
> "Apples":
>
> a <- "2 green Apples"
> b <- "12 green Apples"
> c <- "12 Apples and 2 green Bananas"
> d <- "12 yellow Bananas"
>
> fruitlist <- c(a,b,c,d)
>
> # This is how to extract all that beginn with 12
> grepl("^12",fruitlist)
>
> But how can I get only those that also end with "Apples". So basically
> just item b "12 green Apples" should remain.
>
> Is there any clear description and examples of regular expressions
> and how to use them? I find the manual ?grepl very difficult to read.
>
> Thanks,
> Johannes
>

Please try to change your email to not use HTML, per forum requirements.

Now, on to some real help. Regular expressions are the most
complicated thing that I've ever run across except, maybe, for APL.
For me, the definitive book on them is "Mastering Regular Expressions"
by Jeffrey E. F. Friedl
http://www.amazon.com/Mastering-Regular-Expressions-Jeffrey-Friedl/dp/0596528124
$7.49 for the Kindle version. $32.19 for the "dead tree" (paperback)
version. If you go to that Amazon page, it has some other
possibilities as well.

However a very nice, free, web tutorial is available at:
http://www.regular-expressions.info/

To answer your immediate question, given your very good start,

grepl("^12.*Apples$",fruitlist);

The dollar sign says "match the logical end of the string" and is the
key you are looking for. In English, the regex says: Match the front
of the string (^). Now, immediately match the characters "12". The .
means match anything. Followed by the * which means "match the
previous expression (anything) 0 or more times". Then match the string
"Apples". Then match the end of the string ($). You don't want me to
explain how this is done. Talk about confusing to the novice. And
likely even to people who can use regular expressions farily well
(such as myself).

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From haenlein at escpeurope.eu  Tue Sep  2 15:54:31 2014
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Tue, 2 Sep 2014 15:54:31 +0200
Subject: [R] Bayesian multivariate linear regression
Message-ID: <CAOyz9G7-cv3St=7XtDFwM4L9vGAZ_PmvVuXbPFu6O7C02UX99Q@mail.gmail.com>

Dear all,

I'm looking for a package that allows me to run a Bayesian multivariate
linear regression and extract predicted values. In essence I'm looking for
the equivalent of lm and lm.predict in a Bayesian framework.

I have found several libraries that allow to run Bayesian multivariate
linear regression (e.g., bayesm), but those do not seem to have a
prediction function. And the ones with prediction (e.g., MCMCPack) do not
support multiple dependent variables.

If you have any pointers, please let me know.

Best wishes,

Michael


Michael Haenlein
ESCP Europe
Paris, France

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Sep  2 16:21:20 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 2 Sep 2014 14:21:20 +0000
Subject: [R] Adjusted R2 for Multivariate Regression Trees (MRT) (ignore
 the previous message)
In-Reply-To: <CAPL76w_EKMt-_EJKjkmm4uhumV8u1jaRpsEv9y_mWJdmbLdQzA@mail.gmail.com>
References: <CAPL76w_EKMt-_EJKjkmm4uhumV8u1jaRpsEv9y_mWJdmbLdQzA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F94813@mb02.ads.tamu.edu>

You should probably pose this question directly to the package author as the function you are using cites an unpublished manuscript as a reference. It appears that the function uses random draws to estimate R2 so each result is approximately correct and no result is exactly correct. You can probably take the mean of the 100 runs as a reasonable estimate. If the estimates are quite variable, you should probably use more than 40 runs by setting T=100 or an even larger number. Multiple runs should then be more similar to one another.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jackson Rodrigues
Sent: Monday, September 1, 2014 3:08 PM
To: r-help at r-project.org
Subject: [R] Adjusted R2 for Multivariate Regression Trees (MRT) (ignore the previous message)

Dear fellows,

I am using MVPARTwrap package to built a MRT of 25 pollen samples collected
from 5 different ecosystems, on my analysis I will include adjusted R2.

Based on MVPARTwrap package I want to get adjusted R2 for my MRT for this,
I am using the code below.

#step 1 - Building MRT.
Pre_euro.mvpart <- mvpart(data.matrix(mydata.2) ~ .,5Ecosystems,
margin=0.02, cp=0, xv="pick", xval=nrow(mydata.1), xvmult=100, which=4)

MRT.mite.tree<-MRT(Pre_euro.mvpart, 10, LABELS=LABELS)
#step 2- Adjusted R2
R2aGDF(MRT.mite.tree, T=40, tau_const=0.6, 5Ecosystems)

However, if run adjusted R2 code (step 2) 100 times, I will get 100
different results. Which one is correct?

Does anyone can help me? Any help is very welcome.

Cheers.

Jackson Rodrigues

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Sep  2 16:36:16 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 2 Sep 2014 14:36:16 +0000
Subject: [R] Correlation Matrix with a Covariate
In-Reply-To: <CAB9UfhQBOrzi+zFXik1orSQtdKS6N9cWvPHTuS38tj5jSZeXrQ@mail.gmail.com>
References: <CAB9UfhROxa7jz2pc4yHL2cZxTewyJaWt1N7PqKG+Az724tiyyg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F94334@mb02.ads.tamu.edu>
	<CAB9UfhQBOrzi+zFXik1orSQtdKS6N9cWvPHTuS38tj5jSZeXrQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F94831@mb02.ads.tamu.edu>

Look at your correlation matrices. Your variable names make it more difficult to so I?m abbreviating them:

> dat6 <- dat5
> colnames(dat6) <- abbreviate(colnames(dat5))
> round(cor(dat6[,1:6]), 4)
        c8_SM_7 c7_SM_7 c6_SM_7 c5_SM_7 c4_SM_7 c3_SM_7
c8_SM_7  1.0000 -1.0000 -0.1214  0.1214  0.6000 -0.7816
c7_SM_7 -1.0000  1.0000  0.1214 -0.1214 -0.6000  0.7816
c6_SM_7 -0.1214  0.1214  1.0000 -1.0000 -0.1313  0.0090
c5_SM_7  0.1214 -0.1214 -1.0000  1.0000  0.1313 -0.0090
c4_SM_7  0.6000 -0.6000 -0.1313  0.1313  1.0000 -0.0251
c3_SM_7 -0.7816  0.7816  0.0090 -0.0090 -0.0251  1.0000

col 1 is perfectly correlated with col 2
col 3 is perfectly correlated with col 4
col 5 is perfectly correlated with col 6

David C

From: Patzelt, Edward [mailto:patzelt at g.harvard.edu] 
Sent: Tuesday, September 2, 2014 9:21 AM
To: David L Carlson
Cc: R-help at r-project.org
Subject: Re: [R] Correlation Matrix with a Covariate

Even reducing the command to less variables than observations I still get:

set.cor(y = (66:76), x = c(1:6), z = 65, data = dat5)
Error in solve.default(x.matrix, xy.matrix) :?
? Lapack routine dgesv: system is exactly singular: U[2,2] = 0

On Mon, Sep 1, 2014 at 12:25 PM, David L Carlson <dcarlson at tamu.edu> wrote:
Thanks for including your data with dput(). I'm not familiar with set correlation, but altogether you are working with 76 variables (columns) and only 46 observations. Since the error message says "the system is exactly singlular," it is likely that you have too many variables for the number of observations or one of your columns is a linear combination of (can be predicted exactly from) the others.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Patzelt, Edward
Sent: Monday, September 1, 2014 7:47 AM
To: R-help at r-project.org
Subject: [R] Correlation Matrix with a Covariate

R Help -

I'm trying to run a correlation matrix with a covariate of "age" and will
at some point will also want to covary other variables concurrently.

I'm using the "psych" package and have tried other methods such as writing
a loop to extract semi-partial correlations, but it does not seem to be
working. How can I accomplish this?

library(psych)
> set.cor(y = (66:76), x = c(1:64), z = 65, data = dat5)
Error in solve.default(x.matrix, xy.matrix) :
? Lapack routine dgesv: system is exactly singular: U[54,54] = 0

structure(list(cope8_StriatumMask_7_betas_mean = c(11.47, -0.6002,
-11.59, -52.51, 36.63, -36.99, -26.89, 21.68, 3.776, 19.35, -56.44,
-11.41, -1.825, 5.327, -2.886, 11.91, 43.99, 42.17, 21.19, -1.14,
-9.156, -3.53, -12.79, 33.88, -35.92, 7.613, -61.59, -6.754,
2.672, -25.09, 19.87, -21.09, -37.97, -11.07, -7.276, 21.94,
-18.94, -16.83, 19.96, 7.533, -44.57, -23.17, 22.54),
cope7_StriatumMask_7_betas_mean = c(-11.47,
0.6002, 11.59, 52.51, -36.63, 36.99, 26.89, -21.68, -3.776, -19.35,
56.44, 11.41, 1.825, -5.327, 2.886, -11.91, -43.99, -42.17, -21.19,
1.14, 9.156, 3.53, 12.79, -33.88, 35.92, -7.613, 61.59, 6.754,
-2.672, 25.09, -19.87, 21.09, 37.97, 11.07, 7.276, -21.94, 18.94,
16.83, -19.96, -7.533, 44.57, 23.17, -22.54),
cope6_StriatumMask_7_betas_mean = c(-15.11,
-20.31, -24.63, -17.44, -33.64, -38.77, -37.67, -27.93, -13.28,
-7.351, -9.147, -2.561, -28.92, -26.39, 65.4, -30.5, -6.315,
6.017, -59.84, -12.24, 14.86, -36.17, -14.39, -11.74, -19.17,
41.23, 4.33, 19.48, 12.88, -29.51, 32.7, -35.65, -49.27, -4.2,
16.27, -9.706, -19.26, -22.49, -54.12, -48.03, 82.09, 1.946,
-68.66), cope5_StriatumMask_7_betas_mean = c(15.11, 20.31, 24.63,
17.44, 33.64, 38.77, 37.67, 27.93, 13.28, 7.351, 9.147, 2.561,
28.92, 26.39, -65.4, 30.5, 6.315, -6.017, 59.84, 12.24, -14.86,
36.17, 14.39, 11.74, 19.17, -41.23, -4.33, -19.48, -12.88, 29.51,
-32.7, 35.65, 49.27, 4.2, -16.27, 9.706, 19.26, 22.49, 54.12,
48.03, -82.09, -1.946, 68.66), cope4_StriatumMask_7_betas_mean = c(14.75,
15.24, 4.935, 4.835, 10.32, -19.23, -14.4, 39.01, 7.088, 16.77,
10.78, 4.741, 15.2, 6.144, -3.572, 9.995, 42.44, 36.24, 23.44,
-0.4025, 10.57, -8.036, 0.4127, -5.74, 7.335, -5.735, -32.63,
-3.122, 16.36, -6.741, 9.36, -2.567, -5.515, 22.81, 9.99, -2.034,
10.38, -16.34, 37.27, 12.11, -2.593, 5.341, 11.64),
cope3_StriatumMask_7_betas_mean = c(3.8,
8.024, 6.609, 56.04, -17.79, 27.05, 10.92, 19.12, 4.651, -1.325,
66.15, 16.36, 17.79, 2.177, -4.663, 4.534, 7.788, 3.822, 6.74,
-3.433, 20.96, 1.451, 16.81, -31.09, 26.59, -8.875, 27.25, -1.37,
8.634, 22.93, -10.99, 18.74, 34.3, 34.26, 6.989, -20.35, 38.61,
14.78, 14.24, 8.544, 42.79, 27.42, -12.53), cope2_StriatumMask_7_betas_mean
= c(-22.45,
-18.01, -28.1, -10.91, -33.2, -24.75, -9.261, 4.794, -11.8, -4.1,
-20.08, 17.07, -22.33, -12.02, 21.62, -10.31, 10, 3.088, -45.09,
-32.44, 5.73, -21.31, -12.11, -1.46, -21.26, 36.54, 7.501, 11.95,
11.9, -6.681, 22.08, -24.31, -22.79, -28.37, 23.36, -1.101, -3.984,
-6.315, -28.91, -35.64, 43.7, 8.317, -67.12),
cope1_StriatumMask_7_betas_mean = c(-3.331,
-0.6516, -3.038, 23.44, 2.235, 20.09, 16.99, 18.96, 1.348, 4.113,
-14.4, -2.449, 4.893, 12, -18.31, 15.32, 16.84, 1.516, 15.34,
-1.8, -11.98, 9.774, 2.055, 8.772, -50.38, -5.62, 2.985, 4.993,
7.956, 19.07, -10.01, 12.46, 13.24, -15.76, 9.281, 8.894, 12.9,
14.74, 23.37, 10.72, -16.88, 6.961, -8.737),
cope8_StriatumMask_6_betas_mean = c(24.61,
16.14, -9.034, -59.09, 23.45, -6.531, -15.25, 44.85, -0.97, 19.71,
-34.17, -13.74, 16.35, 22.46, -9.196, -1.073, 48.33, 52.74, 29.12,
24.44, -4.246, 3.402, -26.58, 35.38, -32.03, 10.15, -65.41, -12.14,
3.905, -2.271, 4.286, -1.484, -32.3, 0.3132, -25.83, 6.807, -14.56,
-6.214, 16.98, 27.18, -55.46, -38.73, 35.93),
cope7_StriatumMask_6_betas_mean = c(-24.61,
-16.14, 9.034, 59.09, -23.45, 6.531, 15.25, -44.85, 0.97, -19.71,
34.17, 13.74, -16.35, -22.46, 9.196, 1.073, -48.33, -52.74, -29.12,
-24.44, 4.246, -3.402, 26.58, -35.38, 32.03, -10.15, 65.41, 12.14,
-3.905, 2.271, -4.286, 1.484, 32.3, -0.3132, 25.83, -6.807, 14.56,
6.214, -16.98, -27.18, 55.46, 38.73, -35.93),
cope6_StriatumMask_6_betas_mean = c(-11.24,
-17.26, -17.59, -27.92, -42.3, -39.53, -49.99, -11.12, -23.51,
4.573, -2.713, 18.23, -13.94, -31.14, 72.81, -23.42, 18.89, 9.695,
-30.2, 2.776, 12.57, -15.8, -11.16, -19.92, -34.84, 5.129, -8.743,
1.578, 31.23, -23.09, 24.02, -50.99, -52.38, -15.81, 14.61, -26.57,
-23.76, -24.59, -41.38, -42.29, 48.82, -6.491, -57.52),
cope5_StriatumMask_6_betas_mean = c(11.24,
17.26, 17.59, 27.92, 42.3, 39.53, 49.99, 11.12, 23.51, -4.573,
2.713, -18.23, 13.94, 31.14, -72.81, 23.42, -18.89, -9.695, 30.2,
-2.776, -12.57, 15.8, 11.16, 19.92, 34.84, -5.129, 8.743, -1.578,
-31.23, 23.09, -24.02, 50.99, 52.38, 15.81, -14.61, 26.57, 23.76,
24.59, 41.38, 42.29, -48.82, 6.491, 57.52), cope4_StriatumMask_6_betas_mean
= c(16.28,
22.74, 1.5, -10.25, 0.712, 0.6925, -13.95, 43.29, -0.8349, 6.348,
13.2, 16.73, 13.11, 20.33, -18.84, 13.71, 47.84, 41.51, 32.87,
7.421, 18.35, -7.158, -9.818, -5.952, 13.16, -21.19, -30.92,
-5.915, 24.7, 12.84, -12.11, 12.37, -15.52, 22.66, -5.315, -12.37,
7.045, -13.68, 28.02, 19.65, -22.67, -1.333, 23.78),
cope3_StriatumMask_6_betas_mean = c(-8.463,
5.318, 2.124, 43.84, -14.8, 25.8, -2.843, 0.7301, -0.6077, -9.902,
47.76, 28.98, -2.971, 1.19, -12.33, 12.65, 7.477, -6.222, 4.726,
-22.8, 23.77, -5.952, 18.97, -33.54, 28.67, -19.31, 32.13, -5.62,
14.83, 15.99, -16.74, 14.86, 15.73, 22.8, 13.28, -18.03, 23.9,
4.578, 11.01, -2.828, 34.9, 34.42, -15.46), cope2_StriatumMask_6_betas_mean
= c(-20.5,
-19.39, -25.22, -15.81, -34.44, -27.47, -22.68, -4.421, -17.86,
-1.598, -17.63, 33.28, -8.592, -27.58, 14.24, -7.253, 28.22,
0.1134, -16.73, -18.45, 5.513, -14.15, -10.94, -6.778, -34.2,
4.84, 0.195, -4.455, 23.44, 4.901, 8.662, -39.93, -15.5, -54.58,
14.88, -18.37, -9.523, -19.71, -22.02, -39.69, 12.77, -2.043,
-49.19), cope1_StriatumMask_6_betas_mean = c(-3.715, -4.467,
-7.318, 26.67, 9.007, 15.94, 11.16, 5.649, 5.922, -3.561, -13.75,
-6.254, 6.448, 2.948, -34.84, 13.13, 11.08, -7.47, 15.83, -7.719,
-11.32, -1.264, -0.2779, 9.288, -43.47, -1.405, 4.105, 1.43,
6.055, 22.49, -17.85, 10.03, 11.48, -28.81, 2.534, 8.687, 11.05,
4.538, 17.95, 1.928, -14.82, 1.857, -4.488),
cope8_StriatumMask_5_betas_mean = c(-1.297,
11.7, 5.719, -57.14, 46.27, -60.21, -46.51, -15.42, 7.891, -6.234,
-49.77, 3.486, -3.769, -9.559, 18.63, -4.199, 26.85, 27.71, 57.15,
-16.85, 5.799, -34.23, -19.53, 34.89, -5.222, 12.96, -70.82,
-40.66, -10.55, -3.86, 31.22, -14.71, -28.96, -14.34, -18.29,
0.4763, -16.32, -44.12, 19.7, 5.786, -20.15, 13.51, 0.08071),
? ? cope7_StriatumMask_5_betas_mean = c(1.297, -11.7, -5.719,
? ? 57.14, -46.27, 60.21, 46.51, 15.42, -7.891, 6.234, 49.77,
? ? -3.486, 3.769, 9.559, -18.63, 4.199, -26.85, -27.71, -57.15,
? ? 16.85, -5.799, 34.23, 19.53, -34.89, 5.222, -12.96, 70.82,
? ? 40.66, 10.55, 3.86, -31.22, 14.71, 28.96, 14.34, 18.29, -0.4763,
? ? 16.32, 44.12, -19.7, -5.786, 20.15, -13.51, -0.08071),
cope6_StriatumMask_5_betas_mean = c(-24.38,
? ? -8.297, -23.09, -3.194, -15.96, -12.54, -18.76, -55.4, 13.63,
? ? -12.52, -8.805, 58.42, -37.33, -56.25, 52.02, -48.07, -0.5076,
? ? -8.608, -67.85, -40.23, 12.44, -33.79, -28.93, -4, -20.04,
? ? 62.34, -10.09, 12.86, 1.249, -25.19, 69.77, -18.07, -16.69,
? ? 18.09, 16.25, -27.2, -12.67, 6.946, -25.86, -21.46, 77.06,
? ? -3.023, -90.03), cope5_StriatumMask_5_betas_mean = c(24.38,
? ? 8.297, 23.09, 3.194, 15.96, 12.54, 18.76, 55.4, -13.63, 12.52,
? ? 8.805, -58.42, 37.33, 56.25, -52.02, 48.07, 0.5076, 8.608,
? ? 67.85, 40.23, -12.44, 33.79, 28.93, 4, 20.04, -62.34, 10.09,
? ? -12.86, -1.249, 25.19, -69.77, 18.07, 16.69, -18.09, -16.25,
? ? 27.2, 12.67, -6.946, 25.86, 21.46, -77.06, 3.023, 90.03),
? ? cope4_StriatumMask_5_betas_mean = c(-0.1806, 15.36, 16.78,
? ? -3.517, 28.02, -41.14, -22.81, 20.91, 15.26, 17.1, 6.271,
? ? 20.32, 24.57, 6.072, 12.51, 5.534, 30.1, 49.02, 71.84, 2.404,
? ? 8.636, -15.64, -6.885, -2.237, 33.27, 12.35, -45.2, -16.68,
? ? 15.54, 4.278, 40.59, 0.7229, 13.89, 25.12, -20.32, 0.7402,
? ? 14.96, -20.14, 54.07, 14.79, 16.95, 27.07, 14.58),
cope3_StriatumMask_5_betas_mean = c(1.978,
? ? -4.735, 4.603, 52.85, -11.23, 24.38, 21.69, 39.17, 11.54,
? ? 17.79, 55.56, 20.45, 28.13, 13.82, -5.683, 2.911, 18.02,
? ? 13.02, 25.72, 15.83, 6.11, 13.49, 16.81, -29.8, 21.49, 7.513,
? ? 27.28, 14.86, 22.98, 9.325, 8.833, 14.27, 46.35, 39.8, -7.482,
? ? -0.1707, 44.42, 33.53, 26.02, 15, 39.72, 18.88, 14.45),
cope2_StriatumMask_5_betas_mean = c(-27.24,
? ? -3.252, -21.67, -14.59, -18.78, -10.4, -6.882, 15.76, 13.41,
? ? -1.525, -1.248, 69.55, -22.77, -30.24, 11.38, -21.1, 16.3,
? ? -5.086, -33.82, -48.84, 6.821, -12.66, -17.23, 8.287, -28.52,
? ? 55.27, 8.905, 14.06, 10.88, -4.195, 59.09, -7.859, -0.6477,
? ? 3.593, 19.66, -18.36, 4.738, 15.14, -5.58, -8.72, 50.4, 5.613,
? ? -89.5), cope1_StriatumMask_5_betas_mean = c(1.36, 2.678,
? ? 3.126, 7.72, 0.1483, 13.5, 24.46, 41.42, 0.1413, 9.216, 1.829,
? ? -3.59, 14.06, 23.06, -20.59, 15.88, 17.19, 5.7, 31.9, -2.176,
? ? -8.67, 10.99, 11.2, 10.64, -58.77, -7.03, 14.4, 9.383, 13.62,
? ? 16.88, -5.792, 10.24, 3.981, -6.872, 12.54, 11.69, 14.6,
? ? 4.773, 20.04, 11.94, -12.34, 7.493, -13.52),
cope8_StriatumMask_4_betas_mean = c(30.02,
? ? 10.13, -38.16, -31.45, -9.172, 12.4, -0.6511, 10.94, -4.569,
? ? 2.312, -11.92, 8.502, 33.45, 20.34, -5.991, 4.608, 37.08,
? ? 29.14, 15.19, 9.442, -28.13, -5.005, -7.524, 31.94, -32.13,
? ? -3.296, -60.59, 17.59, 16, 15.33, -3.383, 8.016, -20.84,
? ? 20.43, -17.25, -5.585, 8.63, -5.552, 21.61, 50.3, -31.68,
? ? -16.84, 11.46), cope7_StriatumMask_4_betas_mean = c(-30.02,
? ? -10.13, 38.16, 31.45, 9.172, -12.4, 0.6511, -10.94, 4.569,
? ? -2.312, 11.92, -8.502, -33.45, -20.34, 5.991, -4.608, -37.08,
? ? -29.14, -15.19, -9.442, 28.13, 5.005, 7.524, -31.94, 32.13,
? ? 3.296, 60.59, -17.59, -16, -15.33, 3.383, -8.016, 20.84,
? ? -20.43, 17.25, 5.585, -8.63, 5.552, -21.61, -50.3, 31.68,
? ? 16.84, -11.46), cope6_StriatumMask_4_betas_mean = c(17.21,
? ? -24.2, -8.165, -5.871, -16.94, -30.75, -47.35, 57.53, -11.56,
? ? -0.2164, 45.58, 62.05, 18.5, -21.69, 40.14, -13.35, 23.01,
? ? 33.62, -7.232, 2.781, 9.096, -2.845, 3.745, 6.809, -14.62,
? ? 19.45, -16.77, 33.06, 30.85, -0.07361, 41.98, -27.19, -10.2,
? ? 19.17, -9.795, -20.53, -4.74, -6.671, -12.01, 12.64, 25.96,
? ? -1.209, -24.23), cope5_StriatumMask_4_betas_mean = c(-17.21,
? ? 24.2, 8.165, 5.871, 16.94, 30.75, 47.35, -57.53, 11.56, 0.2164,
? ? -45.58, -62.05, -18.5, 21.69, -40.14, 13.35, -23.01, -33.62,
? ? 7.232, -2.781, -9.096, 2.845, -3.745, -6.809, 14.62, -19.45,
? ? 16.77, -33.06, -30.85, 0.07361, -41.98, 27.19, 10.2, -19.17,
? ? 9.795, 20.53, 4.74, 6.671, 12.01, -12.64, -25.96, 1.209,
? ? 24.23), cope4_StriatumMask_4_betas_mean = c(26.36, 18.31,
? ? -5.294, 10.02, -14.03, 17.99, 2.606, 21.04, 17.48, 0.52,
? ? 18.67, 41.7, 16.43, 22.12, -21.61, 17.06, 47.47, 49.68, 22.28,
? ? 6.687, -4.8, -8.284, 5.924, 21.67, 7.679, -17.76, -25.72,
? ? 15.04, 22.27, 37.97, -4.224, 19.68, -1.014, 33.49, -6.861,
? ? -9.917, 11.85, 13.93, 39.51, 46.16, -21.3, 3.857, 20.03),
? ? cope3_StriatumMask_4_betas_mean = c(-4.475, 8.136, 20.85,
? ? 36.44, -4.315, 19.52, 0.5537, 12.27, 24.51, 0.8773, 31.16,
? ? 30.13, -17.3, -4.434, -17.27, 9.764, 17.33, 18.36, 4.433,
? ? -9.225, 23.91, -5.546, 13.69, -2.575, 27.54, -4.718, 34.02,
? ? -0.7261, 5.103, 24.8, -2.262, 13.11, 18.56, 13.33, 8.641,
? ? -3.453, 5.022, 26.33, 17.79, 5.668, 12.13, 18.55, 3.057),
? ? cope2_StriatumMask_4_betas_mean = c(2.537, -19.08, -18.83,
? ? -2.023, -9.252, -21.48, -12.46, 35.15, -4.74, -2.526, 21.46,
? ? 67.33, 11.77, -21.02, 10.89, -7.3, 24.4, 15.82, -2.558, -18.58,
? ? 2.232, -2.148, -0.2798, 11.16, -21.73, 17.03, 3.65, 16.88,
? ? 30.72, 14.44, 23.65, -22.22, 12.26, -17.75, -5.381, -21.71,
? ? 6.899, -2.527, -4.107, 6.232, 2.13, 0.2781, -27.52),
cope1_StriatumMask_4_betas_mean = c(-9.172,
? ? 0.5036, -9.281, 12.45, 7.121, 12.03, 21.94, -13.04, 5.152,
? ? -1.847, -17.35, -8.623, -5.062, -2.434, -8.646, 5.55, 0.654,
? ? -17.52, 6.386, -10.25, -10.51, -1.227, -4.453, 1.159, -50.89,
? ? -3.253, 16.37, -5.982, 9.533, 11.49, -13.87, 4.944, 6.463,
? ? -28.5, 5.955, 2.492, 8.083, 1.306, 7.27, -6.711, -13.84,
? ? -3.173, -6.582), cope8_StriatumMask_3_betas_mean = c(-9.827,
? ? -29.39, -5.072, -29.28, 18.69, 7.461, -25.71, 34.55, -56.11,
? ? -2.596, -33.97, 19.12, 28.57, 19.91, -16.04, 14.72, 68.99,
? ? 50.07, 54.12, 38.88, 7.486, -10.9, -3.818, 13.97, 4.118,
? ? -7.899, -52.3, 0.5233, -3.36, -8.542, -26.68, 19.28, -14.09,
? ? -9.591, 6.136, -17.34, -13.37, -18.57, 7.236, -9.855, -21.91,
? ? 4.76, 2.585), cope7_StriatumMask_3_betas_mean = c(9.827,
? ? 29.39, 5.072, 29.28, -18.69, -7.461, 25.71, -34.55, 56.11,
? ? 2.596, 33.97, -19.12, -28.57, -19.91, 16.04, -14.72, -68.99,
? ? -50.07, -54.12, -38.88, -7.486, 10.9, 3.818, -13.97, -4.118,
? ? 7.899, 52.3, -0.5233, 3.36, 8.542, 26.68, -19.28, 14.09,
? ? 9.591, -6.136, 17.34, 13.37, 18.57, -7.236, 9.855, 21.91,
? ? -4.76, -2.585), cope6_StriatumMask_3_betas_mean = c(22.87,
? ? -25.94, -11.68, -2.203, -10.23, -53.78, -83.96, 49.48, -11.44,
? ? -5.176, -52.12, 75.78, -4.78, 8.202, 36.8, -20.51, 41.93,
? ? 21.93, -23.74, 13.54, 16.14, 0.104, -10.84, 1.206, -67.28,
? ? 13.01, -39.97, 26.5, 29.88, -20.17, -17.02, -16.57, -31.55,
? ? -3.754, 13.22, -60.05, -18.23, -20.84, -32.5, -30.19, 17.32,
? ? -6.671, -68.85), cope5_StriatumMask_3_betas_mean = c(-22.87,
? ? 25.94, 11.68, 2.203, 10.23, 53.78, 83.96, -49.48, 11.44,
? ? 5.176, 52.12, -75.78, 4.78, -8.202, -36.8, 20.51, -41.93,
? ? -21.93, 23.74, -13.54, -16.14, -0.104, 10.84, -1.206, 67.28,
? ? -13.01, 39.97, -26.5, -29.88, 20.17, 17.02, 16.57, 31.55,
? ? 3.754, -13.22, 60.05, 18.23, 20.84, 32.5, 30.19, -17.32,
? ? 6.671, 68.85), cope4_StriatumMask_3_betas_mean = c(-16.05,
? ? 2.658, -4.415, -12.2, 1.195, 13.03, -29.99, 33.07, -8.351,
? ? -14.77, -17.69, 30.84, 34.35, -6.265, -24.46, 31.91, 55.98,
? ? 55.14, 10.99, 28.58, -0.6548, -22.82, -8.781, -4.039, 47.5,
? ? -10.17, -25.6, 9.067, -7.805, 4.68, -14.51, 30.94, -5.437,
? ? 11.18, -4.785, -28.78, 7.116, -8.826, 28.71, -7.045, -15,
? ? 6.487, 3.255), cope3_StriatumMask_3_betas_mean = c(-5.496,
? ? 24.4, -6.178, 15.86, -14.12, 27.35, -9.234, 0.7806, 42.1,
? ? -14.02, 14.09, 10.54, 6.996, -11.21, -7.568, 20.19, -8.178,
? ? -0.5523, -30.68, -20.66, -7.418, -10.89, -7.568, -12.52,
? ? 30.39, 20.52, 32.13, 7.49, -1.385, 21.98, 11.6, 16.08, 8.176,
? ? 20.77, -9.026, -9.19, 25.62, 11.64, 25.4, 11.66, 8.522, 4.707,
? ? -0.9193), cope2_StriatumMask_3_betas_mean = c(1.248, -20.2,
? ? -12.85, -10.37, -6.481, -38.99, -40.29, 50.83, -9.962, -11.15,
? ? -42.64, 76.49, 17.13, 12.02, 1.068, -1.049, 50.45, 8.55,
? ? -13.25, -2.733, 13.62, -1.994, -9.352, 11.84, -53.07, 15.24,
? ? -10.38, 9.065, 21.26, 7.247, -9.854, -18.25, -5.975, -21.84,
? ? 9.668, -50.28, 0.1118, -18.12, -13.33, -30.13, -2.708, 7.863,
? ? -45.51), cope1_StriatumMask_3_betas_mean = c(-16.21, 2.177,
? ? -0.6828, 2.681, 6.963, 16.77, 27.42, -2.669, 2.728, 0.2155,
? ? 15.99, 0.9732, 22.23, -4.741, -22.42, 15.15, 4.144, -13.74,
? ? 13.43, -8.654, -3.702, -5.625, 1.369, 11.16, -29.82, 1.106,
? ? 25.75, 0.3423, 6.333, 24.31, 2.151, -2.602, 12, -11.66, 2.765,
? ? 11.51, 14.19, 3.124, 20.18, -1.8, -1.045, 5.62, 13.11),
cope8_StriatumMask_2_betas_mean = c(25.81,
? ? 0.1008, -17.35, -20.65, 11.98, 22.12, 6.479, -8.857, 12.72,
? ? -4.564, -21.54, 13.93, 50.64, -19.73, -19.55, 30.95, 33.47,
? ? 10.15, -12.42, 17.9, -17.26, -27.29, 4.29, 19.53, -9.623,
? ? -25.66, -41.7, 11.19, 12.26, 18.57, 3.319, 13.15, -19.85,
? ? 8.024, -30.64, -3.4, -15.03, 11.73, 38.76, 60.92, -35.55,
? ? -25.83, 38.08), cope7_StriatumMask_2_betas_mean = c(-25.81,
? ? -0.1008, 17.35, 20.65, -11.98, -22.12, -6.479, 8.857, -12.72,
? ? 4.564, 21.54, -13.93, -50.64, 19.73, 19.55, -30.95, -33.47,
? ? -10.15, 12.42, -17.9, 17.26, 27.29, -4.29, -19.53, 9.623,
? ? 25.66, 41.7, -11.19, -12.26, -18.57, -3.319, -13.15, 19.85,
? ? -8.024, 30.64, 3.4, 15.03, -11.73, -38.76, -60.92, 35.55,
? ? 25.83, -38.08), cope6_StriatumMask_2_betas_mean = c(32.23,
? ? -30.2, -14.07, 8.605, 3.412, -26.22, -33.54, 44.45, 26.12,
? ? 6.825, 3.423, 82.44, 21.13, 7.608, 25.97, -32.8, 39.59, 20.19,
? ? -11.03, 22.94, 1.544, 12.38, -8.389, 16.52, -20.52, 14.38,
? ? -10.88, 47.39, 14.78, 6.086, 44.31, -16.1, -7.038, 1.967,
? ? -0.5604, -16.6, -4.619, -27.21, -21.32, 7.096, 1.417, -0.6048,
? ? -13.26), cope5_StriatumMask_2_betas_mean = c(-32.23, 30.2,
? ? 14.07, -8.605, -3.412, 26.22, 33.54, -44.45, -26.12, -6.825,
? ? -3.423, -82.44, -21.13, -7.608, -25.97, 32.8, -39.59, -20.19,
? ? 11.03, -22.94, -1.544, -12.38, 8.389, -16.52, 20.52, -14.38,
? ? 10.88, -47.39, -14.78, -6.086, -44.31, 16.1, 7.038, -1.967,
? ? 0.5604, 16.6, 4.619, 27.21, 21.32, -7.096, -1.417, 0.6048,
? ? 13.26), cope4_StriatumMask_2_betas_mean = c(15.01, 22.46,
? ? -4.224, 15.49, 6.115, 30.69, -9.205, 11, 33.86, -11.47, 8.718,
? ? 40.24, 32.94, 10.32, -21.59, 40.88, 42.59, 38.26, -11.98,
? ? 10.31, -11.61, -11.29, 8.09, 16.8, 26.23, -13.6, -9.128,
? ? 13.4, 11.02, 42.82, -7.533, 31.68, 11.7, 18.03, -28.57, -16.58,
? ? 8.403, 16.38, 50.65, 52.36, -33.33, -3.843, 40.4),
cope3_StriatumMask_2_betas_mean = c(-8.702,
? ? 17.62, 7.219, 28.2, -1.924, 25.78, -19.31, 22.12, 22.83,
? ? -8.054, 28.44, 23.53, -16.75, 5.805, -4.127, 6.258, 14.48,
? ? 13.64, -0.4828, -13.26, 4.439, 12.69, 0.6518, 7.227, 26.09,
? ? 23.32, 36.05, 12.2, -0.9937, 33.69, -11.5, 21.97, 30.37,
? ? 9.786, 5.107, -10.34, 22.97, 13.41, 16.56, 6.332, 5.224,
? ? 21.78, -2.798), cope2_StriatumMask_2_betas_mean = c(12.04,
? ? -27.28, -12.81, 3.426, 6.537, -20.93, -3.958, 32.95, 31.27,
? ? 3.16, 1.62, 84.87, 17.59, 16.39, 7.736, -19.22, 37.3, 10.39,
? ? -10.59, 4.182, -1.269, 13.05, -9.96, 22, -31.62, 19.31, 7.048,
? ? 27.36, 16.38, 25.42, 27.44, -10.14, 11.67, -23.71, 1.572,
? ? -10.1, -0.7817, -14.73, -10.15, -1.167, -16.26, 4.545, -10.31
? ? ), cope1_StriatumMask_2_betas_mean = c(-11.59, -0.5801, 2.253,
? ? 2.92, 3.628, 9.823, 16.41, -7.863, 5.275, -1.153, 2.206,
? ? -4.593, -1.623, 1.228, -2.079, 10.64, -3.458, -11.28, 4.056,
? ? -6.751, -5.711, -1.179, -2.362, 4.503, -45.23, 4.45, 15.2,
? ? 0.3556, 7.904, 17.05, -14.17, 3.913, 8.457, -16.94, 3.676,
? ? 6.673, 2.067, 8.915, 12.39, -10.32, -5.923, -0.4391, 0.09663
? ? ), cope8_StriatumMask_1_betas_mean = c(-7.671, 0.7324, 18.97,
? ? -28.64, 13.36, 26.06, 12.31, 45.68, -19.4, -15.43, -21.18,
? ? 10.45, 40.84, 3.266, 28.25, 10.6, 50.66, 53.76, 26.57, 47.64,
? ? 5.642, 5.603, -10.04, 37.04, 27.35, -41.75, -26.86, -11.13,
? ? 13.09, 44.36, -1.843, 2.302, 0.6855, 14.22, -25.71, -9.987,
? ? -3.158, -39.82, 5.276, -12.38, -31.06, -4.346, 52.18),
cope7_StriatumMask_1_betas_mean = c(7.671,
? ? -0.7324, -18.97, 28.64, -13.36, -26.06, -12.31, -45.68, 19.4,
? ? 15.43, 21.18, -10.45, -40.84, -3.266, -28.25, -10.6, -50.66,
? ? -53.76, -26.57, -47.64, -5.642, -5.603, 10.04, -37.04, -27.35,
? ? 41.75, 26.86, 11.13, -13.09, -44.36, 1.843, -2.302, -0.6855,
? ? -14.22, 25.71, 9.987, 3.158, 39.82, -5.276, 12.38, 31.06,
? ? 4.346, -52.18), cope6_StriatumMask_1_betas_mean = c(-10.78,
? ? -25.07, -17.08, 2.81, -6.211, -41.83, -9.084, 62.16, -32.2,
? ? -22.2, -28.83, 47.89, 17.46, 25.87, 52.77, -12.9, 11.86,
? ? 9.416, -5.891, 16.54, 19.86, -7.199, -16.48, -13.35, -20.79,
? ? 13.97, -8.254, -9.45, 10.29, -3.625, 15.06, -47.86, -35.86,
? ? 8.605, -0.989, -20.42, -30.45, -54.43, -44.19, -32.61, 14.31,
? ? 0.9104, -14.45), cope5_StriatumMask_1_betas_mean = c(10.78,
? ? 25.07, 17.08, -2.81, 6.211, 41.83, 9.084, -62.16, 32.2, 22.2,
? ? 28.83, -47.89, -17.46, -25.87, -52.77, 12.9, -11.86, -9.416,
? ? 5.891, -16.54, -19.86, 7.199, 16.48, 13.35, 20.79, -13.97,
? ? 8.254, 9.45, -10.29, 3.625, -15.06, 47.86, 35.86, -8.605,
? ? 0.989, 20.42, 30.45, 54.43, 44.19, 32.61, -14.31, -0.9104,
? ? 14.45), cope4_StriatumMask_1_betas_mean = c(4.84, 8.677,
? ? 12.27, -7.647, 16.95, 11.6, -4.777, 36.14, -0.6954, -16.71,
? ? 6.837, 24.48, 33.52, 16.08, 2.818, 33.76, 40.46, 49.53, 12.67,
? ? 17.85, 4.385, -2.631, -6.774, 19.03, 24.32, -20.09, -10.17,
? ? -9.06, 8.567, 32.12, -2.03, -1.62, 0.146, 37.04, -22.95,
? ? -23.3, 8.028, -17.19, 20.37, 16.84, -22.3, -6.429, 51.04),
? ? cope3_StriatumMask_1_betas_mean = c(15.35, 5.55, -18.41,
? ? 15.07, 3.556, 7.953, -14.82, -9.422, 16.4, -0.3186, 24.63,
? ? 12.67, -6.266, 2.59, -20.88, 19.75, -6.401, -2.396, -5.993,
? ? -35.32, 2.134, -4.257, 2.744, -9.988, -11.43, 32.36, 18.16,
? ? 1.64, -6.096, -2.82, -1.367, -2.237, -0.7249, 22.74, 2.451,
? ? -9.7, 20.11, 29.75, 16.12, 33.47, 11.92, -2.012, -1.725),
? ? cope2_StriatumMask_1_betas_mean = c(-22.73, -15.83, -19.77,
? ? -8.785, -1.132, -28.61, -8.759, 55.94, -23.65, -11.41, -25.9,
? ? 55.99, 23.15, 20.83, 1.789, -8.291, 18.53, -3.007, 3.943,
? ? -6.776, 6.329, -9.923, -15.03, -6.602, -28.07, 15.85, 4.005,
? ? -9.185, 7.425, 15.21, 14.91, -29.58, -32.79, -8.068, 9.733,
? ? -14.88, -6.852, -45.85, -28.66, -33.56, -0.5571, 9.592, -19.33
? ? ), cope1_StriatumMask_1_betas_mean = c(-8.128, 5.758, -1.077,
? ? -2.914, 7.331, 17.59, 7.21, -1.398, 9.864, 9.548, 7.269,
? ? -1.59, 4.966, -2.957, -33.94, 4.149, 4.05, -12.29, 9.097,
? ? -12.87, -15.36, -2.254, 1.258, 6.453, -29.28, 0.6771, 7.286,
? ? 12.21, 7.805, 16.56, -0.8941, 13.69, 1.07, -9.846, 10.8,
? ? 9.538, 21.36, 6.965, 14.37, -2.649, 0.8941, 2.795, -7.913
? ? ), cope8_StriatumMask_betas_mean = c(19.19, 8.326, -14.14,
? ? -47.34, 21.49, -12.56, -16.33, 20.01, 1.212, 10.1, -35.27,
? ? -3.354, 17.25, 9.637, -4.914, 6.339, 41.29, 38.17, 23.69,
? ? 10.55, -9.964, -7.758, -15.25, 32.33, -26.52, 2.892, -61.29,
? ? -5.893, 5.116, -1.717, 8.98, -3.727, -29.21, 0.6858, -19.31,
? ? 5.567, -11.3, -11.28, 21.09, 27.76, -41.58, -22.77, 23.96
? ? ), cope7_StriatumMask_betas_mean = c(-19.19, -8.326, 14.14,
? ? 47.34, -21.49, 12.56, 16.33, -20.01, -1.212, -10.1, 35.27,
? ? 3.354, -17.25, -9.637, 4.914, -6.339, -41.29, -38.17, -23.69,
? ? -10.55, 9.964, 7.758, 15.25, -32.33, 26.52, -2.892, 61.29,
? ? 5.893, -5.116, 1.717, -8.98, 3.727, 29.21, -0.6858, 19.31,
? ? -5.567, 11.3, 11.28, -21.09, -27.76, 41.58, 22.77, -23.96
? ? ), cope6_StriatumMask_betas_mean = c(-3.001, -19.78, -17.55,
? ? -13.93, -26.77, -33.2, -41.41, 0.257, -8.959, -1.035, 4.296,
? ? 34.65, -9.697, -26.18, 56.74, -26.94, 14.28, 12.58, -34.56,
? ? -3.228, 11.26, -16.65, -10.86, -6.784, -24.45, 23.86, -8.12,
? ? 18.23, 21.56, -17.01, 36.51, -34.84, -34.06, -0.2884, 8.737,
? ? -20.99, -15.66, -17.38, -34.47, -24.96, 49.42, -2.499, -52.5
? ? ), cope5_StriatumMask_betas_mean = c(3.001, 19.78, 17.55,
? ? 13.93, 26.77, 33.2, 41.41, -0.257, 8.959, 1.035, -4.296,
? ? -34.65, 9.697, 26.18, -56.74, 26.94, -14.28, -12.58, 34.56,
? ? 3.228, -11.26, 16.65, 10.86, 6.784, 24.45, -23.86, 8.12,
? ? -18.23, -21.56, 17.01, -36.51, 34.84, 34.06, 0.2884, -8.737,
? ? 20.99, 15.66, 17.38, 34.47, 24.96, -49.42, 2.499, 52.5),
? ? cope4_StriatumMask_betas_mean = c(15.33, 19, 2.13, 0.6255,
? ? 3.965, -1.875, -11.55, 31.71, 10.09, 6.487, 11.98, 22.06,
? ? 18.12, 14.37, -12.51, 15.88, 43.94, 42.62, 28.01, 5.568,
? ? 7.426, -9.192, -2.169, 2.482, 15.11, -12.14, -29.41, -0.2639,
? ? 19.3, 15.57, 0.9526, 11.34, -3.821, 24.48, -6.627, -8.762,
? ? 9.8, -6.399, 37.83, 25.74, -14.33, 4.295, 21.01),
cope3_StriatumMask_betas_mean = c(-3.592,
? ? 6.864, 7.348, 44, -11.51, 24.63, 1.817, 13.9, 9.993, -2.448,
? ? 46.96, 24.46, 1.184, 2.201, -9.854, 8.554, 11.19, 5.276,
? ? 6.545, -10.3, 18.45, 0.09225, 14.79, -21.75, 26.66, -5.553,
? ? 31.19, 0.8526, 10.5, 20.36, -8.67, 16.04, 25.48, 24.09, 7.305,
? ? -12.65, 25.91, 15.63, 15.62, 4.822, 29.16, 26.04, -6.085),
? ? cope2_StriatumMask_betas_mean = c(-13.48, -17.98, -22.68,
? ? -9.708, -22.45, -23.12, -13.93, 12.69, -4.801, -1.965, -6.992,
? ? 46.79, -6.076, -17.57, 13.97, -10.84, 23.23, 4.383, -21.55,
? ? -22.44, 4.44, -10.1, -9.803, 3.025, -28.17, 22, 4.17, 9.131,
? ? 19.87, 5.414, 22.37, -25.66, -7.043, -30.76, 11.91, -14.59,
? ? -2.368, -8.886, -16.82, -21.95, 18.63, 2.53, -49.32),
cope1_StriatumMask_betas_mean = c(-5.115,
? ? -1.257, -4.329, 17.92, 5.458, 15.17, 16.84, 7.652, 3.981,
? ? 0.3726, -10.51, -5.246, 4.09, 6.008, -20.68, 12.2, 9.368,
? ? -6.345, 14.45, -6.155, -10.31, 2.61, 0.6008, 7.258, -48.2,
? ? -2.675, 8.916, 1.677, 8.255, 18.35, -13.18, 8.82, 9.647,
? ? -21.62, 6.05, 7.721, 10.41, 6.71, 16.76, 2.002, -13.56, 2.499,
? ? -6.206), age = c(34L, 32L, 34L, 22L, 27L, 33L, 33L, 41L,
? ? 21L, 20L, 32L, 30L, 29L, 37L, 29L, 25L, 31L, 20L, 32L, 22L,
? ? 24L, 26L, 20L, 22L, 34L, 34L, 44L, 40L, 43L, 36L, 41L, 22L,
? ? 41L, 26L, 41L, 45L, 36L, 31L, 31L, 27L, 40L, 23L, 27L), hare2f1 = c(3L,
? ? 10L, 7L, 5L, 4L, 3L, 5L, 6L, 13L, 13L, 7L, 9L, 12L, 7L, 4L,
? ? 13L, 12L, 11L, 14L, 13L, 10L, 6L, 6L, 13L, 11L, 10L, 13L,
? ? 16L, 6L, 8L, 8L, 11L, 9L, 13L, 10L, 9L, 5L, 9L, 5L, 12L,
? ? 13L, 9L, 8L), hare2f2 = c(14, 18, 3, 10, 6, 6, 9, 7, 18.75,
? ? 16, 15, 12, 14, 18, 14, 18, 18, 19, 18, 15.555556, 14.444444,
? ? 12, 1.111111, 17, 12, 17, 14, 13, 16, 7.777778, 6.666667,
? ? 13, 14, 13, 11, 16, 4, 12, 10, 13, 14, 17, 12), hare4 = c(10,
? ? 8, 2, 3, 2, 3, 5, 2, 9, 8, 6, 4, 6, 10, 6, 8, 9, 9, 9, 7.5,
? ? 7, 5, 0, 9, 4, 10, 10, 9, 8, 1.25, 0, 7, 7, 7, 5, 9, 0, 3,
? ? 4, 7, 4, 9, 3), hare = c(20, 32, 10, 16, 11, 11, 15, 15,
? ? 35.294118, 33, 26, 22, 27, 27, 22, 33, 33, 32, 34, 29.473684,
? ? 27.368421, 20, 8.421053, 32, 27, 30, 30, 31, 24, 16.842105,
? ? 15.789474, 25, 26, 30, 23, 29, 10, 22, 16, 29, 30, 27, 24
? ? ), ext_t = c(193L, 374L, 127L, 181L, 198L, 112L, 208L, 194L,
? ? 185L, 224L, 275L, 204L, 235L, 257L, 149L, 279L, 320L, 322L,
? ? 188L, 220L, 273L, 206L, 129L, 296L, 223L, 277L, 156L, 195L,
? ? 219L, 155L, 167L, 176L, 220L, 227L, 224L, 195L, 150L, 277L,
? ? 134L, 285L, 255L, 225L, 176L), total_barrat_11_imputed = c(52,
? ? 49.65517241, 49, 50, 59, 33, 80, 59, 49, 88.96551724, 46,
? ? 69, 55, 61, 55, 81, 63, 78, 63, 77, 74, 56, 66, 65, 64, 80,
? ? 47, 41, 55, 61, 69, 65, 54, 60, 75, 48, 55, 92, 55, 80, 61,
? ? 74, 75), mcq_k = c(0.026255008, 0.001003094, 0.005960345,
? ? 0.015726049, 0.010265035, 0.001003162, 0.0000562, 0.001264102,
? ? 0.101500481, 0.000371013, 0.041432153, 0.002816398, 0.000610156,
? ? 0.002515929, 0.013917576, 0.041429705, 0.001003197, 0.015963745,
? ? 0.004571462, 0.066152274, 0.001264173, 0.013917914, 0.0000145,
? ? 0.000158281, 0.025279846, 0.007219305, 0.001003151, 0.000158275,
? ? 0.040812627, 0.015218595, 0.0000234, 0.008376655, 0.003841158,
? ? 0.007218929, 0.011170246, 0.001264155, 0.002183796, 0.041432825,
? ? 0.018248241, 0.025279435, 0.00728945, 0.015218596, 0.000139047
? ? ), ppitots = c(127L, 144L, 123L, 139L, 132L, 104L, 124L,
? ? 101L, 139L, 143L, 125L, 118L, 143L, 136L, 101L, 155L, 121L,
? ? 163L, 144L, 137L, 161L, 132L, 129L, 172L, 130L, 149L, 130L,
? ? 127L, 131L, 100L, 134L, 140L, 130L, 156L, 129L, 105L, 104L,
? ? 144L, 131L, 155L, 141L, 148L, 122L), ppi_1_corrected = c(0.790903075,
? ? -0.699393955, -2.327819799, 1.081391412, 1.312482037, -1.237538376,
? ? -2.908572705, -1.431192482, 0.849643836, -0.164898186, -2.41690919,
? ? -2.180646599, 2.448811184, -0.690782751, -3.013794372, -0.299602118,
? ? -2.681787682, 1.644921908, -0.813003057, 1.123342946, 5.134178123,
? ? 0.079542428, -0.261508648, 3.433661529, -0.273992274, 2.158546617,
? ? 1.906361161, 1.422218718, -0.391906978, -3.50632425, -1.107140046,
? ? 2.554466033, -0.185769247, 2.924775604, -1.911895686, -4.074384118,
? ? -3.514935455, -1.132749891, 3.135218938, 2.554032851, 1.165085067,
? ? 1.001346409, -0.06377271), ppi_2_corrected = c(-2.126526342,
? ? 2.11252134, 0.555050342, -1.00112002, 0.340187762, -5.601376296,
? ? 1.123969936, -4.711504227, 0.689931234, 0.579906262, 1.063194228,
? ? -0.20079187, -0.692661735, 1.762800655, -3.876379279, 3.649272316,
? ? 1.919311154, 6.385631495, 2.52094701, -0.266955763, 0.107879822,
? ? 0.040699835, -0.035262664, 4.854103646, -0.699493009, 1.446789539,
? ? -2.783996549, -3.166278249, 0.253753447, -2.916502162, 0.483071268,
? ? -1.851965471, -0.491096031, 0.403290401, 0.807272843, -0.914685705,
? ? -2.568897775, 4.595852557, -3.588214202, 2.506562905, 0.802072504,
? ? 1.563208978, -2.362131731), total_buss_perry = c(55L, 79L,
? ? 64L, 79L, 86L, 37L, 85L, 69L, 76L, 109L, 80L, 62L, 46L, 85L,
? ? 48L, 119L, 124L, 131L, 94L, 56L, 95L, 62L, 78L, 106L, 93L,
? ? 76L, 46L, 54L, 61L, 61L, 76L, 94L, 98L, 85L, 94L, 70L, 65L,
? ? 70L, 45L, 114L, 99L, 92L, 61L)), .Names =
c("cope8_StriatumMask_7_betas_mean",
"cope7_StriatumMask_7_betas_mean", "cope6_StriatumMask_7_betas_mean",
"cope5_StriatumMask_7_betas_mean", "cope4_StriatumMask_7_betas_mean",
"cope3_StriatumMask_7_betas_mean", "cope2_StriatumMask_7_betas_mean",
"cope1_StriatumMask_7_betas_mean", "cope8_StriatumMask_6_betas_mean",
"cope7_StriatumMask_6_betas_mean", "cope6_StriatumMask_6_betas_mean",
"cope5_StriatumMask_6_betas_mean", "cope4_StriatumMask_6_betas_mean",
"cope3_StriatumMask_6_betas_mean", "cope2_StriatumMask_6_betas_mean",
"cope1_StriatumMask_6_betas_mean", "cope8_StriatumMask_5_betas_mean",
"cope7_StriatumMask_5_betas_mean", "cope6_StriatumMask_5_betas_mean",
"cope5_StriatumMask_5_betas_mean", "cope4_StriatumMask_5_betas_mean",
"cope3_StriatumMask_5_betas_mean", "cope2_StriatumMask_5_betas_mean",
"cope1_StriatumMask_5_betas_mean", "cope8_StriatumMask_4_betas_mean",
"cope7_StriatumMask_4_betas_mean", "cope6_StriatumMask_4_betas_mean",
"cope5_StriatumMask_4_betas_mean", "cope4_StriatumMask_4_betas_mean",
"cope3_StriatumMask_4_betas_mean", "cope2_StriatumMask_4_betas_mean",
"cope1_StriatumMask_4_betas_mean", "cope8_StriatumMask_3_betas_mean",
"cope7_StriatumMask_3_betas_mean", "cope6_StriatumMask_3_betas_mean",
"cope5_StriatumMask_3_betas_mean", "cope4_StriatumMask_3_betas_mean",
"cope3_StriatumMask_3_betas_mean", "cope2_StriatumMask_3_betas_mean",
"cope1_StriatumMask_3_betas_mean", "cope8_StriatumMask_2_betas_mean",
"cope7_StriatumMask_2_betas_mean", "cope6_StriatumMask_2_betas_mean",
"cope5_StriatumMask_2_betas_mean", "cope4_StriatumMask_2_betas_mean",
"cope3_StriatumMask_2_betas_mean", "cope2_StriatumMask_2_betas_mean",
"cope1_StriatumMask_2_betas_mean", "cope8_StriatumMask_1_betas_mean",
"cope7_StriatumMask_1_betas_mean", "cope6_StriatumMask_1_betas_mean",
"cope5_StriatumMask_1_betas_mean", "cope4_StriatumMask_1_betas_mean",
"cope3_StriatumMask_1_betas_mean", "cope2_StriatumMask_1_betas_mean",
"cope1_StriatumMask_1_betas_mean", "cope8_StriatumMask_betas_mean",
"cope7_StriatumMask_betas_mean", "cope6_StriatumMask_betas_mean",
"cope5_StriatumMask_betas_mean", "cope4_StriatumMask_betas_mean",
"cope3_StriatumMask_betas_mean", "cope2_StriatumMask_betas_mean",
"cope1_StriatumMask_betas_mean", "age", "hare2f1", "hare2f2",
"hare4", "hare", "ext_t", "total_barrat_11_imputed", "mcq_k",
"ppitots", "ppi_1_corrected", "ppi_2_corrected", "total_buss_perry"
), row.names = c(NA, -43L), class = "data.frame")


--
*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University *

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




-- 
Edward H Patzelt?|?Clinical Science PhD Student
Psychology | Harvard University?

SNPLab?http://scholar.harvard.edu/buckholtz
?

From tal.galili at gmail.com  Tue Sep  2 17:01:54 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Tue, 2 Sep 2014 18:01:54 +0300
Subject: [R] Is there an ID3 implementation in R?
Message-ID: <CANdJ3dWzzCiuXvs942oRG04uj80+aehH8d-uY9+2uJKts5ecKw@mail.gmail.com>

Dear R help mailing list,

I am looking for an ID3 implementation in R. I know that there are many
other decision tree algorithms already implemented (via rpart, tree, caret,
C50, etc., etc.), but for research purposes I would like to reproduce the
result of running ID3.

I was not able to find such an implementation when searching in any of the
following:
http://rseek.org/
http://finzi.psych.upenn.edu/search.html
http://cran.r-project.org/web/views/MachineLearning.html

Any suggestions?

Thanks,
Tal


----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Tue Sep  2 17:13:05 2014
From: wht_crl at yahoo.com (carol white)
Date: Tue, 2 Sep 2014 08:13:05 -0700
Subject: [R] extract GO results in xml format
Message-ID: <1409670785.94311.YahooMailNeo@web121506.mail.ne1.yahoo.com>

from a list of GO term enrichment results in xml format, what is the best way to extract term and p-value columns? Which function is the best to use? I used  xmlToDataFrame but got 
Error in `[<-.data.frame`(`*tmp*`, i, names(nodes[[i]]), value = c("5",  : 
  duplicate subscripts for columns


Look forward to your reply,

Carol

	[[alternative HTML version deleted]]


From liuwensui at gmail.com  Tue Sep  2 17:13:28 2014
From: liuwensui at gmail.com (Wensui Liu)
Date: Tue, 2 Sep 2014 11:13:28 -0400
Subject: [R] Is there an ID3 implementation in R?
In-Reply-To: <CANdJ3dWzzCiuXvs942oRG04uj80+aehH8d-uY9+2uJKts5ecKw@mail.gmail.com>
References: <CANdJ3dWzzCiuXvs942oRG04uj80+aehH8d-uY9+2uJKts5ecKw@mail.gmail.com>
Message-ID: <CAKyN3iBXiHJhfq0cwFDcOj0Gk0gKnoA_5eEW6DN72zyzgj8QtQ@mail.gmail.com>

Rweka
On Sep 2, 2014 11:04 AM, "Tal Galili" <tal.galili at gmail.com> wrote:

> Dear R help mailing list,
>
> I am looking for an ID3 implementation in R. I know that there are many
> other decision tree algorithms already implemented (via rpart, tree, caret,
> C50, etc., etc.), but for research purposes I would like to reproduce the
> result of running ID3.
>
> I was not able to find such an implementation when searching in any of the
> following:
> http://rseek.org/
> http://finzi.psych.upenn.edu/search.html
> http://cran.r-project.org/web/views/MachineLearning.html
>
> Any suggestions?
>
> Thanks,
> Tal
>
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
>
> ----------------------------------------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tal.galili at gmail.com  Tue Sep  2 17:17:46 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Tue, 2 Sep 2014 18:17:46 +0300
Subject: [R] Is there an ID3 implementation in R?
In-Reply-To: <CAKyN3iBXiHJhfq0cwFDcOj0Gk0gKnoA_5eEW6DN72zyzgj8QtQ@mail.gmail.com>
References: <CANdJ3dWzzCiuXvs942oRG04uj80+aehH8d-uY9+2uJKts5ecKw@mail.gmail.com>
	<CAKyN3iBXiHJhfq0cwFDcOj0Gk0gKnoA_5eEW6DN72zyzgj8QtQ@mail.gmail.com>
Message-ID: <CANdJ3dVW1stEBpbOp97ouRKn=er3GHjREeTfsw-dswXPVwtS0w@mail.gmail.com>

Hi Wensui,

When I looked at their docs:
http://cran.r-project.org/web/packages/RWeka/RWeka.pdf
It appeared they only have a connection to:
J48
LMT
M5P
DecisionStump

Is it possible to connect it to:
http://www.cs.tufts.edu/~ablumer/weka/doc/weka.classifiers.Id3.html

If so, how?

Thanks.




----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------



On Tue, Sep 2, 2014 at 6:13 PM, Wensui Liu <liuwensui at gmail.com> wrote:

> Rweka
> On Sep 2, 2014 11:04 AM, "Tal Galili" <tal.galili at gmail.com> wrote:
>
>> Dear R help mailing list,
>>
>> I am looking for an ID3 implementation in R. I know that there are many
>> other decision tree algorithms already implemented (via rpart, tree,
>> caret,
>> C50, etc., etc.), but for research purposes I would like to reproduce the
>> result of running ID3.
>>
>> I was not able to find such an implementation when searching in any of the
>> following:
>> http://rseek.org/
>> http://finzi.psych.upenn.edu/search.html
>> http://cran.r-project.org/web/views/MachineLearning.html
>>
>> Any suggestions?
>>
>> Thanks,
>> Tal
>>
>>
>> ----------------Contact
>> Details:-------------------------------------------------------
>> Contact me: Tal.Galili at gmail.com |
>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>> www.r-statistics.com (English)
>>
>> ----------------------------------------------------------------------------------------------
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From chschulz at email.de  Tue Sep  2 17:42:58 2014
From: chschulz at email.de (Christian Schulz)
Date: Tue, 02 Sep 2014 17:42:58 +0200
Subject: [R] Is there an ID3 implementation in R?
In-Reply-To: <CANdJ3dVW1stEBpbOp97ouRKn=er3GHjREeTfsw-dswXPVwtS0w@mail.gmail.com>
References: <CANdJ3dWzzCiuXvs942oRG04uj80+aehH8d-uY9+2uJKts5ecKw@mail.gmail.com>	<CAKyN3iBXiHJhfq0cwFDcOj0Gk0gKnoA_5eEW6DN72zyzgj8QtQ@mail.gmail.com>
	<CANdJ3dVW1stEBpbOp97ouRKn=er3GHjREeTfsw-dswXPVwtS0w@mail.gmail.com>
Message-ID: <5405E582.7030003@email.de>

Yes with: make_Weka_classifier(name, class = NULL, handlers = list(), 
init = NULL)
HTH, Christian


> Hi Wensui,
>
> When I looked at their docs:
> http://cran.r-project.org/web/packages/RWeka/RWeka.pdf
> It appeared they only have a connection to:
> J48
> LMT
> M5P
> DecisionStump
>
> Is it possible to connect it to:
> http://www.cs.tufts.edu/~ablumer/weka/doc/weka.classifiers.Id3.html
>
> If so, how?
>
> Thanks.
>
>
>
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
>
>
>
> On Tue, Sep 2, 2014 at 6:13 PM, Wensui Liu <liuwensui at gmail.com> wrote:
>
>> Rweka
>> On Sep 2, 2014 11:04 AM, "Tal Galili" <tal.galili at gmail.com> wrote:
>>
>>> Dear R help mailing list,
>>>
>>> I am looking for an ID3 implementation in R. I know that there are many
>>> other decision tree algorithms already implemented (via rpart, tree,
>>> caret,
>>> C50, etc., etc.), but for research purposes I would like to reproduce the
>>> result of running ID3.
>>>
>>> I was not able to find such an implementation when searching in any of the
>>> following:
>>> http://rseek.org/
>>> http://finzi.psych.upenn.edu/search.html
>>> http://cran.r-project.org/web/views/MachineLearning.html
>>>
>>> Any suggestions?
>>>
>>> Thanks,
>>> Tal
>>>
>>>
>>> ----------------Contact
>>> Details:-------------------------------------------------------
>>> Contact me: Tal.Galili at gmail.com |
>>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>>> www.r-statistics.com (English)
>>>
>>> ----------------------------------------------------------------------------------------------
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ntfredo at gmail.com  Tue Sep  2 10:34:51 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 2 Sep 2014 11:34:51 +0300
Subject: [R] Making a table
Message-ID: <CAGh51gQRZcYO5Kd7NqQtiDRXnhnz9_eSsiQVstZQ1i7cSzJn5A@mail.gmail.com>

Dear All,

I want to make a table in the attached document.

The attached documents are dataset in csv format and the type of the table
I want to produce.

I made the following approach but it is not giving me what I want.

## read data
library(reshape2)
motorcycle=read.csv("/home/fredo/Desktop/Table2.csv")
#head(motorcycle)
#summary(motorcycle)

motorcycle2<-acast(motorcycle,
General.attribute~Basic.attribute,value.var=" Type.of.motorcycle")

It gives me this output:

                             braking stability  bumpy bends    clutch
operation feel at control fuel economy gearbox operation
                    Kawasaki G(0.5), E(0.5)     A(0.5), G(0.5) A(0.8)
         P(1.0)          A(1.0)       A(0.5), G(0.5)
overall performance <NA>     <NA>               <NA>           <NA>
         <NA>            <NA>         <NA>
                    headlights horn   Manoeuvrability mirrors
quality of finish quietness      responsiveness seat comfort
                    G(1.0)     A(1.0) A(1.0)          A(0.5), G(0.5)
P(0.5), I(0.5)    I(0.5), A(0.5) <NA>           G(1.0)
overall performance <NA>       <NA>   <NA>            <NA>
<NA>              <NA>           E(0.8)         <NA>
                    starting steering stopping power top speed
stability vibration
                    G(1.0)   E(0.9)   G(1.0)         E(1.0)
  G(1.0)
overall performance <NA>     <NA>     <NA>           <NA>
  <NA>


Any help is welcome.


Best regards,

Frederic.





-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: table.png
Type: image/png
Size: 302085 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140902/6ec27a5d/attachment.png>

From smileismystyl at gmail.com  Tue Sep  2 13:56:50 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Tue, 2 Sep 2014 17:26:50 +0530
Subject: [R] RGEOS ERROR
In-Reply-To: <CAAcyNCzM3ZdyweGiHAbQpeB8ftry=TkDtSP=hh7Z8AMpwM5uXQ@mail.gmail.com>
References: <CAG1d=2A5x_GpRsR05P_27pE2tWPBNpJSh-sDtrCaPEyUTqB2iQ@mail.gmail.com>
	<CAAcyNCxZ5JKsp-PRTgBhkZZr5kZCCu-EAx0D_pOT=wfT4H2hNw@mail.gmail.com>
	<CAG1d=2Cp2i-3P7a+UJhsbwQUBmHj=zZs1myaNmc04Bpv19YQoQ@mail.gmail.com>
	<CAAcyNCzM3ZdyweGiHAbQpeB8ftry=TkDtSP=hh7Z8AMpwM5uXQ@mail.gmail.com>
Message-ID: <CAG1d=2DAFUFK88wygS9+zD2Qtvj28_As-nTjgBJBQtRG9tCCQg@mail.gmail.com>

Thanx for the reply.
It is solved.
It is just a sample file whose dimensions are clipped.
Thanx


On Tue, Sep 2, 2014 at 4:19 PM, Pascal Oettli <kridox at ymail.com> wrote:

> Please keep your reply inside the thread. Anyway, it doesn't anwer the
> question.
>
> Regards,
> Pascal
>
> On Tue, Sep 2, 2014 at 7:18 PM, Girija Kalyani <smileismystyl at gmail.com>
> wrote:
> > Sir,
> > The worldmap i here refer to is , the shape file of the complete world
> map
> >
> >
> >
> > On Tue, Sep 2, 2014 at 12:09 PM, Pascal Oettli <kridox at ymail.com> wrote:
> >>
> >> What is WorldMap? From where does it come?
> >>
> >> Regards,
> >> Pascal
> >>
> >> On Tue, Sep 2, 2014 at 2:37 PM, Girija Kalyani <smileismystyl at gmail.com
> >
> >> wrote:
> >> > working configuration:
> >> > R-3.1.1
> >> > WIN-64
> >> > goal: want to perfrom ploygon clipping, giving bounding box values of
> my
> >> > study area and extract the area from world map.
> >> >  I followed:
> >> >
> >> >> clip.extent <- as(extent(76.3700, 31.7439, 78.6541, 33.2653),
> >> >> "SpatialPolygons")
> >> >
> >> >> proj4string(clip.extent) <- CRS(proj4string(WorldMap))> LSMap <-
> >> >> gIntersection(WorldMap, clip.extent, byid = TRUE)
> >> >
> >> > Error :
> >> >
> >> > In RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, drop_not_poly,
> >> > "rgeos_intersection") :
> >> >   spgeom1 and spgeom2 have different proj4 strings
> >> >
> >> >
> >> > Any help or assistance would be highly obliged
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Pascal Oettli
> >> Project Scientist
> >> JAMSTEC
> >> Yokohama, Japan
> >
> >
> >
> >
> > --
> > :) Smile is my Style :)
>
>
>
> --
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
>



-- 
:) Smile is my Style :)

	[[alternative HTML version deleted]]


From patzelt at g.harvard.edu  Tue Sep  2 16:21:08 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Tue, 2 Sep 2014 10:21:08 -0400
Subject: [R] Correlation Matrix with a Covariate
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F94334@mb02.ads.tamu.edu>
References: <CAB9UfhROxa7jz2pc4yHL2cZxTewyJaWt1N7PqKG+Az724tiyyg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F94334@mb02.ads.tamu.edu>
Message-ID: <CAB9UfhQBOrzi+zFXik1orSQtdKS6N9cWvPHTuS38tj5jSZeXrQ@mail.gmail.com>

Even reducing the command to less variables than observations I still get:

set.cor(y = (66:76), x = c(1:6), z = 65, data = dat5)
Error in solve.default(x.matrix, xy.matrix) :
  Lapack routine dgesv: system is exactly singular: U[2,2] = 0


On Mon, Sep 1, 2014 at 12:25 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> Thanks for including your data with dput(). I'm not familiar with set
> correlation, but altogether you are working with 76 variables (columns) and
> only 46 observations. Since the error message says "the system is exactly
> singlular," it is likely that you have too many variables for the number of
> observations or one of your columns is a linear combination of (can be
> predicted exactly from) the others.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Patzelt, Edward
> Sent: Monday, September 1, 2014 7:47 AM
> To: R-help at r-project.org
> Subject: [R] Correlation Matrix with a Covariate
>
> R Help -
>
> I'm trying to run a correlation matrix with a covariate of "age" and will
> at some point will also want to covary other variables concurrently.
>
> I'm using the "psych" package and have tried other methods such as writing
> a loop to extract semi-partial correlations, but it does not seem to be
> working. How can I accomplish this?
>
> library(psych)
> > set.cor(y = (66:76), x = c(1:64), z = 65, data = dat5)
> Error in solve.default(x.matrix, xy.matrix) :
>   Lapack routine dgesv: system is exactly singular: U[54,54] = 0
>
> structure(list(cope8_StriatumMask_7_betas_mean = c(11.47, -0.6002,
> -11.59, -52.51, 36.63, -36.99, -26.89, 21.68, 3.776, 19.35, -56.44,
> -11.41, -1.825, 5.327, -2.886, 11.91, 43.99, 42.17, 21.19, -1.14,
> -9.156, -3.53, -12.79, 33.88, -35.92, 7.613, -61.59, -6.754,
> 2.672, -25.09, 19.87, -21.09, -37.97, -11.07, -7.276, 21.94,
> -18.94, -16.83, 19.96, 7.533, -44.57, -23.17, 22.54),
> cope7_StriatumMask_7_betas_mean = c(-11.47,
> 0.6002, 11.59, 52.51, -36.63, 36.99, 26.89, -21.68, -3.776, -19.35,
> 56.44, 11.41, 1.825, -5.327, 2.886, -11.91, -43.99, -42.17, -21.19,
> 1.14, 9.156, 3.53, 12.79, -33.88, 35.92, -7.613, 61.59, 6.754,
> -2.672, 25.09, -19.87, 21.09, 37.97, 11.07, 7.276, -21.94, 18.94,
> 16.83, -19.96, -7.533, 44.57, 23.17, -22.54),
> cope6_StriatumMask_7_betas_mean = c(-15.11,
> -20.31, -24.63, -17.44, -33.64, -38.77, -37.67, -27.93, -13.28,
> -7.351, -9.147, -2.561, -28.92, -26.39, 65.4, -30.5, -6.315,
> 6.017, -59.84, -12.24, 14.86, -36.17, -14.39, -11.74, -19.17,
> 41.23, 4.33, 19.48, 12.88, -29.51, 32.7, -35.65, -49.27, -4.2,
> 16.27, -9.706, -19.26, -22.49, -54.12, -48.03, 82.09, 1.946,
> -68.66), cope5_StriatumMask_7_betas_mean = c(15.11, 20.31, 24.63,
> 17.44, 33.64, 38.77, 37.67, 27.93, 13.28, 7.351, 9.147, 2.561,
> 28.92, 26.39, -65.4, 30.5, 6.315, -6.017, 59.84, 12.24, -14.86,
> 36.17, 14.39, 11.74, 19.17, -41.23, -4.33, -19.48, -12.88, 29.51,
> -32.7, 35.65, 49.27, 4.2, -16.27, 9.706, 19.26, 22.49, 54.12,
> 48.03, -82.09, -1.946, 68.66), cope4_StriatumMask_7_betas_mean = c(14.75,
> 15.24, 4.935, 4.835, 10.32, -19.23, -14.4, 39.01, 7.088, 16.77,
> 10.78, 4.741, 15.2, 6.144, -3.572, 9.995, 42.44, 36.24, 23.44,
> -0.4025, 10.57, -8.036, 0.4127, -5.74, 7.335, -5.735, -32.63,
> -3.122, 16.36, -6.741, 9.36, -2.567, -5.515, 22.81, 9.99, -2.034,
> 10.38, -16.34, 37.27, 12.11, -2.593, 5.341, 11.64),
> cope3_StriatumMask_7_betas_mean = c(3.8,
> 8.024, 6.609, 56.04, -17.79, 27.05, 10.92, 19.12, 4.651, -1.325,
> 66.15, 16.36, 17.79, 2.177, -4.663, 4.534, 7.788, 3.822, 6.74,
> -3.433, 20.96, 1.451, 16.81, -31.09, 26.59, -8.875, 27.25, -1.37,
> 8.634, 22.93, -10.99, 18.74, 34.3, 34.26, 6.989, -20.35, 38.61,
> 14.78, 14.24, 8.544, 42.79, 27.42, -12.53), cope2_StriatumMask_7_betas_mean
> = c(-22.45,
> -18.01, -28.1, -10.91, -33.2, -24.75, -9.261, 4.794, -11.8, -4.1,
> -20.08, 17.07, -22.33, -12.02, 21.62, -10.31, 10, 3.088, -45.09,
> -32.44, 5.73, -21.31, -12.11, -1.46, -21.26, 36.54, 7.501, 11.95,
> 11.9, -6.681, 22.08, -24.31, -22.79, -28.37, 23.36, -1.101, -3.984,
> -6.315, -28.91, -35.64, 43.7, 8.317, -67.12),
> cope1_StriatumMask_7_betas_mean = c(-3.331,
> -0.6516, -3.038, 23.44, 2.235, 20.09, 16.99, 18.96, 1.348, 4.113,
> -14.4, -2.449, 4.893, 12, -18.31, 15.32, 16.84, 1.516, 15.34,
> -1.8, -11.98, 9.774, 2.055, 8.772, -50.38, -5.62, 2.985, 4.993,
> 7.956, 19.07, -10.01, 12.46, 13.24, -15.76, 9.281, 8.894, 12.9,
> 14.74, 23.37, 10.72, -16.88, 6.961, -8.737),
> cope8_StriatumMask_6_betas_mean = c(24.61,
> 16.14, -9.034, -59.09, 23.45, -6.531, -15.25, 44.85, -0.97, 19.71,
> -34.17, -13.74, 16.35, 22.46, -9.196, -1.073, 48.33, 52.74, 29.12,
> 24.44, -4.246, 3.402, -26.58, 35.38, -32.03, 10.15, -65.41, -12.14,
> 3.905, -2.271, 4.286, -1.484, -32.3, 0.3132, -25.83, 6.807, -14.56,
> -6.214, 16.98, 27.18, -55.46, -38.73, 35.93),
> cope7_StriatumMask_6_betas_mean = c(-24.61,
> -16.14, 9.034, 59.09, -23.45, 6.531, 15.25, -44.85, 0.97, -19.71,
> 34.17, 13.74, -16.35, -22.46, 9.196, 1.073, -48.33, -52.74, -29.12,
> -24.44, 4.246, -3.402, 26.58, -35.38, 32.03, -10.15, 65.41, 12.14,
> -3.905, 2.271, -4.286, 1.484, 32.3, -0.3132, 25.83, -6.807, 14.56,
> 6.214, -16.98, -27.18, 55.46, 38.73, -35.93),
> cope6_StriatumMask_6_betas_mean = c(-11.24,
> -17.26, -17.59, -27.92, -42.3, -39.53, -49.99, -11.12, -23.51,
> 4.573, -2.713, 18.23, -13.94, -31.14, 72.81, -23.42, 18.89, 9.695,
> -30.2, 2.776, 12.57, -15.8, -11.16, -19.92, -34.84, 5.129, -8.743,
> 1.578, 31.23, -23.09, 24.02, -50.99, -52.38, -15.81, 14.61, -26.57,
> -23.76, -24.59, -41.38, -42.29, 48.82, -6.491, -57.52),
> cope5_StriatumMask_6_betas_mean = c(11.24,
> 17.26, 17.59, 27.92, 42.3, 39.53, 49.99, 11.12, 23.51, -4.573,
> 2.713, -18.23, 13.94, 31.14, -72.81, 23.42, -18.89, -9.695, 30.2,
> -2.776, -12.57, 15.8, 11.16, 19.92, 34.84, -5.129, 8.743, -1.578,
> -31.23, 23.09, -24.02, 50.99, 52.38, 15.81, -14.61, 26.57, 23.76,
> 24.59, 41.38, 42.29, -48.82, 6.491, 57.52), cope4_StriatumMask_6_betas_mean
> = c(16.28,
> 22.74, 1.5, -10.25, 0.712, 0.6925, -13.95, 43.29, -0.8349, 6.348,
> 13.2, 16.73, 13.11, 20.33, -18.84, 13.71, 47.84, 41.51, 32.87,
> 7.421, 18.35, -7.158, -9.818, -5.952, 13.16, -21.19, -30.92,
> -5.915, 24.7, 12.84, -12.11, 12.37, -15.52, 22.66, -5.315, -12.37,
> 7.045, -13.68, 28.02, 19.65, -22.67, -1.333, 23.78),
> cope3_StriatumMask_6_betas_mean = c(-8.463,
> 5.318, 2.124, 43.84, -14.8, 25.8, -2.843, 0.7301, -0.6077, -9.902,
> 47.76, 28.98, -2.971, 1.19, -12.33, 12.65, 7.477, -6.222, 4.726,
> -22.8, 23.77, -5.952, 18.97, -33.54, 28.67, -19.31, 32.13, -5.62,
> 14.83, 15.99, -16.74, 14.86, 15.73, 22.8, 13.28, -18.03, 23.9,
> 4.578, 11.01, -2.828, 34.9, 34.42, -15.46), cope2_StriatumMask_6_betas_mean
> = c(-20.5,
> -19.39, -25.22, -15.81, -34.44, -27.47, -22.68, -4.421, -17.86,
> -1.598, -17.63, 33.28, -8.592, -27.58, 14.24, -7.253, 28.22,
> 0.1134, -16.73, -18.45, 5.513, -14.15, -10.94, -6.778, -34.2,
> 4.84, 0.195, -4.455, 23.44, 4.901, 8.662, -39.93, -15.5, -54.58,
> 14.88, -18.37, -9.523, -19.71, -22.02, -39.69, 12.77, -2.043,
> -49.19), cope1_StriatumMask_6_betas_mean = c(-3.715, -4.467,
> -7.318, 26.67, 9.007, 15.94, 11.16, 5.649, 5.922, -3.561, -13.75,
> -6.254, 6.448, 2.948, -34.84, 13.13, 11.08, -7.47, 15.83, -7.719,
> -11.32, -1.264, -0.2779, 9.288, -43.47, -1.405, 4.105, 1.43,
> 6.055, 22.49, -17.85, 10.03, 11.48, -28.81, 2.534, 8.687, 11.05,
> 4.538, 17.95, 1.928, -14.82, 1.857, -4.488),
> cope8_StriatumMask_5_betas_mean = c(-1.297,
> 11.7, 5.719, -57.14, 46.27, -60.21, -46.51, -15.42, 7.891, -6.234,
> -49.77, 3.486, -3.769, -9.559, 18.63, -4.199, 26.85, 27.71, 57.15,
> -16.85, 5.799, -34.23, -19.53, 34.89, -5.222, 12.96, -70.82,
> -40.66, -10.55, -3.86, 31.22, -14.71, -28.96, -14.34, -18.29,
> 0.4763, -16.32, -44.12, 19.7, 5.786, -20.15, 13.51, 0.08071),
>     cope7_StriatumMask_5_betas_mean = c(1.297, -11.7, -5.719,
>     57.14, -46.27, 60.21, 46.51, 15.42, -7.891, 6.234, 49.77,
>     -3.486, 3.769, 9.559, -18.63, 4.199, -26.85, -27.71, -57.15,
>     16.85, -5.799, 34.23, 19.53, -34.89, 5.222, -12.96, 70.82,
>     40.66, 10.55, 3.86, -31.22, 14.71, 28.96, 14.34, 18.29, -0.4763,
>     16.32, 44.12, -19.7, -5.786, 20.15, -13.51, -0.08071),
> cope6_StriatumMask_5_betas_mean = c(-24.38,
>     -8.297, -23.09, -3.194, -15.96, -12.54, -18.76, -55.4, 13.63,
>     -12.52, -8.805, 58.42, -37.33, -56.25, 52.02, -48.07, -0.5076,
>     -8.608, -67.85, -40.23, 12.44, -33.79, -28.93, -4, -20.04,
>     62.34, -10.09, 12.86, 1.249, -25.19, 69.77, -18.07, -16.69,
>     18.09, 16.25, -27.2, -12.67, 6.946, -25.86, -21.46, 77.06,
>     -3.023, -90.03), cope5_StriatumMask_5_betas_mean = c(24.38,
>     8.297, 23.09, 3.194, 15.96, 12.54, 18.76, 55.4, -13.63, 12.52,
>     8.805, -58.42, 37.33, 56.25, -52.02, 48.07, 0.5076, 8.608,
>     67.85, 40.23, -12.44, 33.79, 28.93, 4, 20.04, -62.34, 10.09,
>     -12.86, -1.249, 25.19, -69.77, 18.07, 16.69, -18.09, -16.25,
>     27.2, 12.67, -6.946, 25.86, 21.46, -77.06, 3.023, 90.03),
>     cope4_StriatumMask_5_betas_mean = c(-0.1806, 15.36, 16.78,
>     -3.517, 28.02, -41.14, -22.81, 20.91, 15.26, 17.1, 6.271,
>     20.32, 24.57, 6.072, 12.51, 5.534, 30.1, 49.02, 71.84, 2.404,
>     8.636, -15.64, -6.885, -2.237, 33.27, 12.35, -45.2, -16.68,
>     15.54, 4.278, 40.59, 0.7229, 13.89, 25.12, -20.32, 0.7402,
>     14.96, -20.14, 54.07, 14.79, 16.95, 27.07, 14.58),
> cope3_StriatumMask_5_betas_mean = c(1.978,
>     -4.735, 4.603, 52.85, -11.23, 24.38, 21.69, 39.17, 11.54,
>     17.79, 55.56, 20.45, 28.13, 13.82, -5.683, 2.911, 18.02,
>     13.02, 25.72, 15.83, 6.11, 13.49, 16.81, -29.8, 21.49, 7.513,
>     27.28, 14.86, 22.98, 9.325, 8.833, 14.27, 46.35, 39.8, -7.482,
>     -0.1707, 44.42, 33.53, 26.02, 15, 39.72, 18.88, 14.45),
> cope2_StriatumMask_5_betas_mean = c(-27.24,
>     -3.252, -21.67, -14.59, -18.78, -10.4, -6.882, 15.76, 13.41,
>     -1.525, -1.248, 69.55, -22.77, -30.24, 11.38, -21.1, 16.3,
>     -5.086, -33.82, -48.84, 6.821, -12.66, -17.23, 8.287, -28.52,
>     55.27, 8.905, 14.06, 10.88, -4.195, 59.09, -7.859, -0.6477,
>     3.593, 19.66, -18.36, 4.738, 15.14, -5.58, -8.72, 50.4, 5.613,
>     -89.5), cope1_StriatumMask_5_betas_mean = c(1.36, 2.678,
>     3.126, 7.72, 0.1483, 13.5, 24.46, 41.42, 0.1413, 9.216, 1.829,
>     -3.59, 14.06, 23.06, -20.59, 15.88, 17.19, 5.7, 31.9, -2.176,
>     -8.67, 10.99, 11.2, 10.64, -58.77, -7.03, 14.4, 9.383, 13.62,
>     16.88, -5.792, 10.24, 3.981, -6.872, 12.54, 11.69, 14.6,
>     4.773, 20.04, 11.94, -12.34, 7.493, -13.52),
> cope8_StriatumMask_4_betas_mean = c(30.02,
>     10.13, -38.16, -31.45, -9.172, 12.4, -0.6511, 10.94, -4.569,
>     2.312, -11.92, 8.502, 33.45, 20.34, -5.991, 4.608, 37.08,
>     29.14, 15.19, 9.442, -28.13, -5.005, -7.524, 31.94, -32.13,
>     -3.296, -60.59, 17.59, 16, 15.33, -3.383, 8.016, -20.84,
>     20.43, -17.25, -5.585, 8.63, -5.552, 21.61, 50.3, -31.68,
>     -16.84, 11.46), cope7_StriatumMask_4_betas_mean = c(-30.02,
>     -10.13, 38.16, 31.45, 9.172, -12.4, 0.6511, -10.94, 4.569,
>     -2.312, 11.92, -8.502, -33.45, -20.34, 5.991, -4.608, -37.08,
>     -29.14, -15.19, -9.442, 28.13, 5.005, 7.524, -31.94, 32.13,
>     3.296, 60.59, -17.59, -16, -15.33, 3.383, -8.016, 20.84,
>     -20.43, 17.25, 5.585, -8.63, 5.552, -21.61, -50.3, 31.68,
>     16.84, -11.46), cope6_StriatumMask_4_betas_mean = c(17.21,
>     -24.2, -8.165, -5.871, -16.94, -30.75, -47.35, 57.53, -11.56,
>     -0.2164, 45.58, 62.05, 18.5, -21.69, 40.14, -13.35, 23.01,
>     33.62, -7.232, 2.781, 9.096, -2.845, 3.745, 6.809, -14.62,
>     19.45, -16.77, 33.06, 30.85, -0.07361, 41.98, -27.19, -10.2,
>     19.17, -9.795, -20.53, -4.74, -6.671, -12.01, 12.64, 25.96,
>     -1.209, -24.23), cope5_StriatumMask_4_betas_mean = c(-17.21,
>     24.2, 8.165, 5.871, 16.94, 30.75, 47.35, -57.53, 11.56, 0.2164,
>     -45.58, -62.05, -18.5, 21.69, -40.14, 13.35, -23.01, -33.62,
>     7.232, -2.781, -9.096, 2.845, -3.745, -6.809, 14.62, -19.45,
>     16.77, -33.06, -30.85, 0.07361, -41.98, 27.19, 10.2, -19.17,
>     9.795, 20.53, 4.74, 6.671, 12.01, -12.64, -25.96, 1.209,
>     24.23), cope4_StriatumMask_4_betas_mean = c(26.36, 18.31,
>     -5.294, 10.02, -14.03, 17.99, 2.606, 21.04, 17.48, 0.52,
>     18.67, 41.7, 16.43, 22.12, -21.61, 17.06, 47.47, 49.68, 22.28,
>     6.687, -4.8, -8.284, 5.924, 21.67, 7.679, -17.76, -25.72,
>     15.04, 22.27, 37.97, -4.224, 19.68, -1.014, 33.49, -6.861,
>     -9.917, 11.85, 13.93, 39.51, 46.16, -21.3, 3.857, 20.03),
>     cope3_StriatumMask_4_betas_mean = c(-4.475, 8.136, 20.85,
>     36.44, -4.315, 19.52, 0.5537, 12.27, 24.51, 0.8773, 31.16,
>     30.13, -17.3, -4.434, -17.27, 9.764, 17.33, 18.36, 4.433,
>     -9.225, 23.91, -5.546, 13.69, -2.575, 27.54, -4.718, 34.02,
>     -0.7261, 5.103, 24.8, -2.262, 13.11, 18.56, 13.33, 8.641,
>     -3.453, 5.022, 26.33, 17.79, 5.668, 12.13, 18.55, 3.057),
>     cope2_StriatumMask_4_betas_mean = c(2.537, -19.08, -18.83,
>     -2.023, -9.252, -21.48, -12.46, 35.15, -4.74, -2.526, 21.46,
>     67.33, 11.77, -21.02, 10.89, -7.3, 24.4, 15.82, -2.558, -18.58,
>     2.232, -2.148, -0.2798, 11.16, -21.73, 17.03, 3.65, 16.88,
>     30.72, 14.44, 23.65, -22.22, 12.26, -17.75, -5.381, -21.71,
>     6.899, -2.527, -4.107, 6.232, 2.13, 0.2781, -27.52),
> cope1_StriatumMask_4_betas_mean = c(-9.172,
>     0.5036, -9.281, 12.45, 7.121, 12.03, 21.94, -13.04, 5.152,
>     -1.847, -17.35, -8.623, -5.062, -2.434, -8.646, 5.55, 0.654,
>     -17.52, 6.386, -10.25, -10.51, -1.227, -4.453, 1.159, -50.89,
>     -3.253, 16.37, -5.982, 9.533, 11.49, -13.87, 4.944, 6.463,
>     -28.5, 5.955, 2.492, 8.083, 1.306, 7.27, -6.711, -13.84,
>     -3.173, -6.582), cope8_StriatumMask_3_betas_mean = c(-9.827,
>     -29.39, -5.072, -29.28, 18.69, 7.461, -25.71, 34.55, -56.11,
>     -2.596, -33.97, 19.12, 28.57, 19.91, -16.04, 14.72, 68.99,
>     50.07, 54.12, 38.88, 7.486, -10.9, -3.818, 13.97, 4.118,
>     -7.899, -52.3, 0.5233, -3.36, -8.542, -26.68, 19.28, -14.09,
>     -9.591, 6.136, -17.34, -13.37, -18.57, 7.236, -9.855, -21.91,
>     4.76, 2.585), cope7_StriatumMask_3_betas_mean = c(9.827,
>     29.39, 5.072, 29.28, -18.69, -7.461, 25.71, -34.55, 56.11,
>     2.596, 33.97, -19.12, -28.57, -19.91, 16.04, -14.72, -68.99,
>     -50.07, -54.12, -38.88, -7.486, 10.9, 3.818, -13.97, -4.118,
>     7.899, 52.3, -0.5233, 3.36, 8.542, 26.68, -19.28, 14.09,
>     9.591, -6.136, 17.34, 13.37, 18.57, -7.236, 9.855, 21.91,
>     -4.76, -2.585), cope6_StriatumMask_3_betas_mean = c(22.87,
>     -25.94, -11.68, -2.203, -10.23, -53.78, -83.96, 49.48, -11.44,
>     -5.176, -52.12, 75.78, -4.78, 8.202, 36.8, -20.51, 41.93,
>     21.93, -23.74, 13.54, 16.14, 0.104, -10.84, 1.206, -67.28,
>     13.01, -39.97, 26.5, 29.88, -20.17, -17.02, -16.57, -31.55,
>     -3.754, 13.22, -60.05, -18.23, -20.84, -32.5, -30.19, 17.32,
>     -6.671, -68.85), cope5_StriatumMask_3_betas_mean = c(-22.87,
>     25.94, 11.68, 2.203, 10.23, 53.78, 83.96, -49.48, 11.44,
>     5.176, 52.12, -75.78, 4.78, -8.202, -36.8, 20.51, -41.93,
>     -21.93, 23.74, -13.54, -16.14, -0.104, 10.84, -1.206, 67.28,
>     -13.01, 39.97, -26.5, -29.88, 20.17, 17.02, 16.57, 31.55,
>     3.754, -13.22, 60.05, 18.23, 20.84, 32.5, 30.19, -17.32,
>     6.671, 68.85), cope4_StriatumMask_3_betas_mean = c(-16.05,
>     2.658, -4.415, -12.2, 1.195, 13.03, -29.99, 33.07, -8.351,
>     -14.77, -17.69, 30.84, 34.35, -6.265, -24.46, 31.91, 55.98,
>     55.14, 10.99, 28.58, -0.6548, -22.82, -8.781, -4.039, 47.5,
>     -10.17, -25.6, 9.067, -7.805, 4.68, -14.51, 30.94, -5.437,
>     11.18, -4.785, -28.78, 7.116, -8.826, 28.71, -7.045, -15,
>     6.487, 3.255), cope3_StriatumMask_3_betas_mean = c(-5.496,
>     24.4, -6.178, 15.86, -14.12, 27.35, -9.234, 0.7806, 42.1,
>     -14.02, 14.09, 10.54, 6.996, -11.21, -7.568, 20.19, -8.178,
>     -0.5523, -30.68, -20.66, -7.418, -10.89, -7.568, -12.52,
>     30.39, 20.52, 32.13, 7.49, -1.385, 21.98, 11.6, 16.08, 8.176,
>     20.77, -9.026, -9.19, 25.62, 11.64, 25.4, 11.66, 8.522, 4.707,
>     -0.9193), cope2_StriatumMask_3_betas_mean = c(1.248, -20.2,
>     -12.85, -10.37, -6.481, -38.99, -40.29, 50.83, -9.962, -11.15,
>     -42.64, 76.49, 17.13, 12.02, 1.068, -1.049, 50.45, 8.55,
>     -13.25, -2.733, 13.62, -1.994, -9.352, 11.84, -53.07, 15.24,
>     -10.38, 9.065, 21.26, 7.247, -9.854, -18.25, -5.975, -21.84,
>     9.668, -50.28, 0.1118, -18.12, -13.33, -30.13, -2.708, 7.863,
>     -45.51), cope1_StriatumMask_3_betas_mean = c(-16.21, 2.177,
>     -0.6828, 2.681, 6.963, 16.77, 27.42, -2.669, 2.728, 0.2155,
>     15.99, 0.9732, 22.23, -4.741, -22.42, 15.15, 4.144, -13.74,
>     13.43, -8.654, -3.702, -5.625, 1.369, 11.16, -29.82, 1.106,
>     25.75, 0.3423, 6.333, 24.31, 2.151, -2.602, 12, -11.66, 2.765,
>     11.51, 14.19, 3.124, 20.18, -1.8, -1.045, 5.62, 13.11),
> cope8_StriatumMask_2_betas_mean = c(25.81,
>     0.1008, -17.35, -20.65, 11.98, 22.12, 6.479, -8.857, 12.72,
>     -4.564, -21.54, 13.93, 50.64, -19.73, -19.55, 30.95, 33.47,
>     10.15, -12.42, 17.9, -17.26, -27.29, 4.29, 19.53, -9.623,
>     -25.66, -41.7, 11.19, 12.26, 18.57, 3.319, 13.15, -19.85,
>     8.024, -30.64, -3.4, -15.03, 11.73, 38.76, 60.92, -35.55,
>     -25.83, 38.08), cope7_StriatumMask_2_betas_mean = c(-25.81,
>     -0.1008, 17.35, 20.65, -11.98, -22.12, -6.479, 8.857, -12.72,
>     4.564, 21.54, -13.93, -50.64, 19.73, 19.55, -30.95, -33.47,
>     -10.15, 12.42, -17.9, 17.26, 27.29, -4.29, -19.53, 9.623,
>     25.66, 41.7, -11.19, -12.26, -18.57, -3.319, -13.15, 19.85,
>     -8.024, 30.64, 3.4, 15.03, -11.73, -38.76, -60.92, 35.55,
>     25.83, -38.08), cope6_StriatumMask_2_betas_mean = c(32.23,
>     -30.2, -14.07, 8.605, 3.412, -26.22, -33.54, 44.45, 26.12,
>     6.825, 3.423, 82.44, 21.13, 7.608, 25.97, -32.8, 39.59, 20.19,
>     -11.03, 22.94, 1.544, 12.38, -8.389, 16.52, -20.52, 14.38,
>     -10.88, 47.39, 14.78, 6.086, 44.31, -16.1, -7.038, 1.967,
>     -0.5604, -16.6, -4.619, -27.21, -21.32, 7.096, 1.417, -0.6048,
>     -13.26), cope5_StriatumMask_2_betas_mean = c(-32.23, 30.2,
>     14.07, -8.605, -3.412, 26.22, 33.54, -44.45, -26.12, -6.825,
>     -3.423, -82.44, -21.13, -7.608, -25.97, 32.8, -39.59, -20.19,
>     11.03, -22.94, -1.544, -12.38, 8.389, -16.52, 20.52, -14.38,
>     10.88, -47.39, -14.78, -6.086, -44.31, 16.1, 7.038, -1.967,
>     0.5604, 16.6, 4.619, 27.21, 21.32, -7.096, -1.417, 0.6048,
>     13.26), cope4_StriatumMask_2_betas_mean = c(15.01, 22.46,
>     -4.224, 15.49, 6.115, 30.69, -9.205, 11, 33.86, -11.47, 8.718,
>     40.24, 32.94, 10.32, -21.59, 40.88, 42.59, 38.26, -11.98,
>     10.31, -11.61, -11.29, 8.09, 16.8, 26.23, -13.6, -9.128,
>     13.4, 11.02, 42.82, -7.533, 31.68, 11.7, 18.03, -28.57, -16.58,
>     8.403, 16.38, 50.65, 52.36, -33.33, -3.843, 40.4),
> cope3_StriatumMask_2_betas_mean = c(-8.702,
>     17.62, 7.219, 28.2, -1.924, 25.78, -19.31, 22.12, 22.83,
>     -8.054, 28.44, 23.53, -16.75, 5.805, -4.127, 6.258, 14.48,
>     13.64, -0.4828, -13.26, 4.439, 12.69, 0.6518, 7.227, 26.09,
>     23.32, 36.05, 12.2, -0.9937, 33.69, -11.5, 21.97, 30.37,
>     9.786, 5.107, -10.34, 22.97, 13.41, 16.56, 6.332, 5.224,
>     21.78, -2.798), cope2_StriatumMask_2_betas_mean = c(12.04,
>     -27.28, -12.81, 3.426, 6.537, -20.93, -3.958, 32.95, 31.27,
>     3.16, 1.62, 84.87, 17.59, 16.39, 7.736, -19.22, 37.3, 10.39,
>     -10.59, 4.182, -1.269, 13.05, -9.96, 22, -31.62, 19.31, 7.048,
>     27.36, 16.38, 25.42, 27.44, -10.14, 11.67, -23.71, 1.572,
>     -10.1, -0.7817, -14.73, -10.15, -1.167, -16.26, 4.545, -10.31
>     ), cope1_StriatumMask_2_betas_mean = c(-11.59, -0.5801, 2.253,
>     2.92, 3.628, 9.823, 16.41, -7.863, 5.275, -1.153, 2.206,
>     -4.593, -1.623, 1.228, -2.079, 10.64, -3.458, -11.28, 4.056,
>     -6.751, -5.711, -1.179, -2.362, 4.503, -45.23, 4.45, 15.2,
>     0.3556, 7.904, 17.05, -14.17, 3.913, 8.457, -16.94, 3.676,
>     6.673, 2.067, 8.915, 12.39, -10.32, -5.923, -0.4391, 0.09663
>     ), cope8_StriatumMask_1_betas_mean = c(-7.671, 0.7324, 18.97,
>     -28.64, 13.36, 26.06, 12.31, 45.68, -19.4, -15.43, -21.18,
>     10.45, 40.84, 3.266, 28.25, 10.6, 50.66, 53.76, 26.57, 47.64,
>     5.642, 5.603, -10.04, 37.04, 27.35, -41.75, -26.86, -11.13,
>     13.09, 44.36, -1.843, 2.302, 0.6855, 14.22, -25.71, -9.987,
>     -3.158, -39.82, 5.276, -12.38, -31.06, -4.346, 52.18),
> cope7_StriatumMask_1_betas_mean = c(7.671,
>     -0.7324, -18.97, 28.64, -13.36, -26.06, -12.31, -45.68, 19.4,
>     15.43, 21.18, -10.45, -40.84, -3.266, -28.25, -10.6, -50.66,
>     -53.76, -26.57, -47.64, -5.642, -5.603, 10.04, -37.04, -27.35,
>     41.75, 26.86, 11.13, -13.09, -44.36, 1.843, -2.302, -0.6855,
>     -14.22, 25.71, 9.987, 3.158, 39.82, -5.276, 12.38, 31.06,
>     4.346, -52.18), cope6_StriatumMask_1_betas_mean = c(-10.78,
>     -25.07, -17.08, 2.81, -6.211, -41.83, -9.084, 62.16, -32.2,
>     -22.2, -28.83, 47.89, 17.46, 25.87, 52.77, -12.9, 11.86,
>     9.416, -5.891, 16.54, 19.86, -7.199, -16.48, -13.35, -20.79,
>     13.97, -8.254, -9.45, 10.29, -3.625, 15.06, -47.86, -35.86,
>     8.605, -0.989, -20.42, -30.45, -54.43, -44.19, -32.61, 14.31,
>     0.9104, -14.45), cope5_StriatumMask_1_betas_mean = c(10.78,
>     25.07, 17.08, -2.81, 6.211, 41.83, 9.084, -62.16, 32.2, 22.2,
>     28.83, -47.89, -17.46, -25.87, -52.77, 12.9, -11.86, -9.416,
>     5.891, -16.54, -19.86, 7.199, 16.48, 13.35, 20.79, -13.97,
>     8.254, 9.45, -10.29, 3.625, -15.06, 47.86, 35.86, -8.605,
>     0.989, 20.42, 30.45, 54.43, 44.19, 32.61, -14.31, -0.9104,
>     14.45), cope4_StriatumMask_1_betas_mean = c(4.84, 8.677,
>     12.27, -7.647, 16.95, 11.6, -4.777, 36.14, -0.6954, -16.71,
>     6.837, 24.48, 33.52, 16.08, 2.818, 33.76, 40.46, 49.53, 12.67,
>     17.85, 4.385, -2.631, -6.774, 19.03, 24.32, -20.09, -10.17,
>     -9.06, 8.567, 32.12, -2.03, -1.62, 0.146, 37.04, -22.95,
>     -23.3, 8.028, -17.19, 20.37, 16.84, -22.3, -6.429, 51.04),
>     cope3_StriatumMask_1_betas_mean = c(15.35, 5.55, -18.41,
>     15.07, 3.556, 7.953, -14.82, -9.422, 16.4, -0.3186, 24.63,
>     12.67, -6.266, 2.59, -20.88, 19.75, -6.401, -2.396, -5.993,
>     -35.32, 2.134, -4.257, 2.744, -9.988, -11.43, 32.36, 18.16,
>     1.64, -6.096, -2.82, -1.367, -2.237, -0.7249, 22.74, 2.451,
>     -9.7, 20.11, 29.75, 16.12, 33.47, 11.92, -2.012, -1.725),
>     cope2_StriatumMask_1_betas_mean = c(-22.73, -15.83, -19.77,
>     -8.785, -1.132, -28.61, -8.759, 55.94, -23.65, -11.41, -25.9,
>     55.99, 23.15, 20.83, 1.789, -8.291, 18.53, -3.007, 3.943,
>     -6.776, 6.329, -9.923, -15.03, -6.602, -28.07, 15.85, 4.005,
>     -9.185, 7.425, 15.21, 14.91, -29.58, -32.79, -8.068, 9.733,
>     -14.88, -6.852, -45.85, -28.66, -33.56, -0.5571, 9.592, -19.33
>     ), cope1_StriatumMask_1_betas_mean = c(-8.128, 5.758, -1.077,
>     -2.914, 7.331, 17.59, 7.21, -1.398, 9.864, 9.548, 7.269,
>     -1.59, 4.966, -2.957, -33.94, 4.149, 4.05, -12.29, 9.097,
>     -12.87, -15.36, -2.254, 1.258, 6.453, -29.28, 0.6771, 7.286,
>     12.21, 7.805, 16.56, -0.8941, 13.69, 1.07, -9.846, 10.8,
>     9.538, 21.36, 6.965, 14.37, -2.649, 0.8941, 2.795, -7.913
>     ), cope8_StriatumMask_betas_mean = c(19.19, 8.326, -14.14,
>     -47.34, 21.49, -12.56, -16.33, 20.01, 1.212, 10.1, -35.27,
>     -3.354, 17.25, 9.637, -4.914, 6.339, 41.29, 38.17, 23.69,
>     10.55, -9.964, -7.758, -15.25, 32.33, -26.52, 2.892, -61.29,
>     -5.893, 5.116, -1.717, 8.98, -3.727, -29.21, 0.6858, -19.31,
>     5.567, -11.3, -11.28, 21.09, 27.76, -41.58, -22.77, 23.96
>     ), cope7_StriatumMask_betas_mean = c(-19.19, -8.326, 14.14,
>     47.34, -21.49, 12.56, 16.33, -20.01, -1.212, -10.1, 35.27,
>     3.354, -17.25, -9.637, 4.914, -6.339, -41.29, -38.17, -23.69,
>     -10.55, 9.964, 7.758, 15.25, -32.33, 26.52, -2.892, 61.29,
>     5.893, -5.116, 1.717, -8.98, 3.727, 29.21, -0.6858, 19.31,
>     -5.567, 11.3, 11.28, -21.09, -27.76, 41.58, 22.77, -23.96
>     ), cope6_StriatumMask_betas_mean = c(-3.001, -19.78, -17.55,
>     -13.93, -26.77, -33.2, -41.41, 0.257, -8.959, -1.035, 4.296,
>     34.65, -9.697, -26.18, 56.74, -26.94, 14.28, 12.58, -34.56,
>     -3.228, 11.26, -16.65, -10.86, -6.784, -24.45, 23.86, -8.12,
>     18.23, 21.56, -17.01, 36.51, -34.84, -34.06, -0.2884, 8.737,
>     -20.99, -15.66, -17.38, -34.47, -24.96, 49.42, -2.499, -52.5
>     ), cope5_StriatumMask_betas_mean = c(3.001, 19.78, 17.55,
>     13.93, 26.77, 33.2, 41.41, -0.257, 8.959, 1.035, -4.296,
>     -34.65, 9.697, 26.18, -56.74, 26.94, -14.28, -12.58, 34.56,
>     3.228, -11.26, 16.65, 10.86, 6.784, 24.45, -23.86, 8.12,
>     -18.23, -21.56, 17.01, -36.51, 34.84, 34.06, 0.2884, -8.737,
>     20.99, 15.66, 17.38, 34.47, 24.96, -49.42, 2.499, 52.5),
>     cope4_StriatumMask_betas_mean = c(15.33, 19, 2.13, 0.6255,
>     3.965, -1.875, -11.55, 31.71, 10.09, 6.487, 11.98, 22.06,
>     18.12, 14.37, -12.51, 15.88, 43.94, 42.62, 28.01, 5.568,
>     7.426, -9.192, -2.169, 2.482, 15.11, -12.14, -29.41, -0.2639,
>     19.3, 15.57, 0.9526, 11.34, -3.821, 24.48, -6.627, -8.762,
>     9.8, -6.399, 37.83, 25.74, -14.33, 4.295, 21.01),
> cope3_StriatumMask_betas_mean = c(-3.592,
>     6.864, 7.348, 44, -11.51, 24.63, 1.817, 13.9, 9.993, -2.448,
>     46.96, 24.46, 1.184, 2.201, -9.854, 8.554, 11.19, 5.276,
>     6.545, -10.3, 18.45, 0.09225, 14.79, -21.75, 26.66, -5.553,
>     31.19, 0.8526, 10.5, 20.36, -8.67, 16.04, 25.48, 24.09, 7.305,
>     -12.65, 25.91, 15.63, 15.62, 4.822, 29.16, 26.04, -6.085),
>     cope2_StriatumMask_betas_mean = c(-13.48, -17.98, -22.68,
>     -9.708, -22.45, -23.12, -13.93, 12.69, -4.801, -1.965, -6.992,
>     46.79, -6.076, -17.57, 13.97, -10.84, 23.23, 4.383, -21.55,
>     -22.44, 4.44, -10.1, -9.803, 3.025, -28.17, 22, 4.17, 9.131,
>     19.87, 5.414, 22.37, -25.66, -7.043, -30.76, 11.91, -14.59,
>     -2.368, -8.886, -16.82, -21.95, 18.63, 2.53, -49.32),
> cope1_StriatumMask_betas_mean = c(-5.115,
>     -1.257, -4.329, 17.92, 5.458, 15.17, 16.84, 7.652, 3.981,
>     0.3726, -10.51, -5.246, 4.09, 6.008, -20.68, 12.2, 9.368,
>     -6.345, 14.45, -6.155, -10.31, 2.61, 0.6008, 7.258, -48.2,
>     -2.675, 8.916, 1.677, 8.255, 18.35, -13.18, 8.82, 9.647,
>     -21.62, 6.05, 7.721, 10.41, 6.71, 16.76, 2.002, -13.56, 2.499,
>     -6.206), age = c(34L, 32L, 34L, 22L, 27L, 33L, 33L, 41L,
>     21L, 20L, 32L, 30L, 29L, 37L, 29L, 25L, 31L, 20L, 32L, 22L,
>     24L, 26L, 20L, 22L, 34L, 34L, 44L, 40L, 43L, 36L, 41L, 22L,
>     41L, 26L, 41L, 45L, 36L, 31L, 31L, 27L, 40L, 23L, 27L), hare2f1 = c(3L,
>     10L, 7L, 5L, 4L, 3L, 5L, 6L, 13L, 13L, 7L, 9L, 12L, 7L, 4L,
>     13L, 12L, 11L, 14L, 13L, 10L, 6L, 6L, 13L, 11L, 10L, 13L,
>     16L, 6L, 8L, 8L, 11L, 9L, 13L, 10L, 9L, 5L, 9L, 5L, 12L,
>     13L, 9L, 8L), hare2f2 = c(14, 18, 3, 10, 6, 6, 9, 7, 18.75,
>     16, 15, 12, 14, 18, 14, 18, 18, 19, 18, 15.555556, 14.444444,
>     12, 1.111111, 17, 12, 17, 14, 13, 16, 7.777778, 6.666667,
>     13, 14, 13, 11, 16, 4, 12, 10, 13, 14, 17, 12), hare4 = c(10,
>     8, 2, 3, 2, 3, 5, 2, 9, 8, 6, 4, 6, 10, 6, 8, 9, 9, 9, 7.5,
>     7, 5, 0, 9, 4, 10, 10, 9, 8, 1.25, 0, 7, 7, 7, 5, 9, 0, 3,
>     4, 7, 4, 9, 3), hare = c(20, 32, 10, 16, 11, 11, 15, 15,
>     35.294118, 33, 26, 22, 27, 27, 22, 33, 33, 32, 34, 29.473684,
>     27.368421, 20, 8.421053, 32, 27, 30, 30, 31, 24, 16.842105,
>     15.789474, 25, 26, 30, 23, 29, 10, 22, 16, 29, 30, 27, 24
>     ), ext_t = c(193L, 374L, 127L, 181L, 198L, 112L, 208L, 194L,
>     185L, 224L, 275L, 204L, 235L, 257L, 149L, 279L, 320L, 322L,
>     188L, 220L, 273L, 206L, 129L, 296L, 223L, 277L, 156L, 195L,
>     219L, 155L, 167L, 176L, 220L, 227L, 224L, 195L, 150L, 277L,
>     134L, 285L, 255L, 225L, 176L), total_barrat_11_imputed = c(52,
>     49.65517241, 49, 50, 59, 33, 80, 59, 49, 88.96551724, 46,
>     69, 55, 61, 55, 81, 63, 78, 63, 77, 74, 56, 66, 65, 64, 80,
>     47, 41, 55, 61, 69, 65, 54, 60, 75, 48, 55, 92, 55, 80, 61,
>     74, 75), mcq_k = c(0.026255008, 0.001003094, 0.005960345,
>     0.015726049, 0.010265035, 0.001003162, 0.0000562, 0.001264102,
>     0.101500481, 0.000371013, 0.041432153, 0.002816398, 0.000610156,
>     0.002515929, 0.013917576, 0.041429705, 0.001003197, 0.015963745,
>     0.004571462, 0.066152274, 0.001264173, 0.013917914, 0.0000145,
>     0.000158281, 0.025279846, 0.007219305, 0.001003151, 0.000158275,
>     0.040812627, 0.015218595, 0.0000234, 0.008376655, 0.003841158,
>     0.007218929, 0.011170246, 0.001264155, 0.002183796, 0.041432825,
>     0.018248241, 0.025279435, 0.00728945, 0.015218596, 0.000139047
>     ), ppitots = c(127L, 144L, 123L, 139L, 132L, 104L, 124L,
>     101L, 139L, 143L, 125L, 118L, 143L, 136L, 101L, 155L, 121L,
>     163L, 144L, 137L, 161L, 132L, 129L, 172L, 130L, 149L, 130L,
>     127L, 131L, 100L, 134L, 140L, 130L, 156L, 129L, 105L, 104L,
>     144L, 131L, 155L, 141L, 148L, 122L), ppi_1_corrected = c(0.790903075,
>     -0.699393955, -2.327819799, 1.081391412, 1.312482037, -1.237538376,
>     -2.908572705, -1.431192482, 0.849643836, -0.164898186, -2.41690919,
>     -2.180646599, 2.448811184, -0.690782751, -3.013794372, -0.299602118,
>     -2.681787682, 1.644921908, -0.813003057, 1.123342946, 5.134178123,
>     0.079542428, -0.261508648, 3.433661529, -0.273992274, 2.158546617,
>     1.906361161, 1.422218718, -0.391906978, -3.50632425, -1.107140046,
>     2.554466033, -0.185769247, 2.924775604, -1.911895686, -4.074384118,
>     -3.514935455, -1.132749891, 3.135218938, 2.554032851, 1.165085067,
>     1.001346409, -0.06377271), ppi_2_corrected = c(-2.126526342,
>     2.11252134, 0.555050342, -1.00112002, 0.340187762, -5.601376296,
>     1.123969936, -4.711504227, 0.689931234, 0.579906262, 1.063194228,
>     -0.20079187, -0.692661735, 1.762800655, -3.876379279, 3.649272316,
>     1.919311154, 6.385631495, 2.52094701, -0.266955763, 0.107879822,
>     0.040699835, -0.035262664, 4.854103646, -0.699493009, 1.446789539,
>     -2.783996549, -3.166278249, 0.253753447, -2.916502162, 0.483071268,
>     -1.851965471, -0.491096031, 0.403290401, 0.807272843, -0.914685705,
>     -2.568897775, 4.595852557, -3.588214202, 2.506562905, 0.802072504,
>     1.563208978, -2.362131731), total_buss_perry = c(55L, 79L,
>     64L, 79L, 86L, 37L, 85L, 69L, 76L, 109L, 80L, 62L, 46L, 85L,
>     48L, 119L, 124L, 131L, 94L, 56L, 95L, 62L, 78L, 106L, 93L,
>     76L, 46L, 54L, 61L, 61L, 76L, 94L, 98L, 85L, 94L, 70L, 65L,
>     70L, 45L, 114L, 99L, 92L, 61L)), .Names =
> c("cope8_StriatumMask_7_betas_mean",
> "cope7_StriatumMask_7_betas_mean", "cope6_StriatumMask_7_betas_mean",
> "cope5_StriatumMask_7_betas_mean", "cope4_StriatumMask_7_betas_mean",
> "cope3_StriatumMask_7_betas_mean", "cope2_StriatumMask_7_betas_mean",
> "cope1_StriatumMask_7_betas_mean", "cope8_StriatumMask_6_betas_mean",
> "cope7_StriatumMask_6_betas_mean", "cope6_StriatumMask_6_betas_mean",
> "cope5_StriatumMask_6_betas_mean", "cope4_StriatumMask_6_betas_mean",
> "cope3_StriatumMask_6_betas_mean", "cope2_StriatumMask_6_betas_mean",
> "cope1_StriatumMask_6_betas_mean", "cope8_StriatumMask_5_betas_mean",
> "cope7_StriatumMask_5_betas_mean", "cope6_StriatumMask_5_betas_mean",
> "cope5_StriatumMask_5_betas_mean", "cope4_StriatumMask_5_betas_mean",
> "cope3_StriatumMask_5_betas_mean", "cope2_StriatumMask_5_betas_mean",
> "cope1_StriatumMask_5_betas_mean", "cope8_StriatumMask_4_betas_mean",
> "cope7_StriatumMask_4_betas_mean", "cope6_StriatumMask_4_betas_mean",
> "cope5_StriatumMask_4_betas_mean", "cope4_StriatumMask_4_betas_mean",
> "cope3_StriatumMask_4_betas_mean", "cope2_StriatumMask_4_betas_mean",
> "cope1_StriatumMask_4_betas_mean", "cope8_StriatumMask_3_betas_mean",
> "cope7_StriatumMask_3_betas_mean", "cope6_StriatumMask_3_betas_mean",
> "cope5_StriatumMask_3_betas_mean", "cope4_StriatumMask_3_betas_mean",
> "cope3_StriatumMask_3_betas_mean", "cope2_StriatumMask_3_betas_mean",
> "cope1_StriatumMask_3_betas_mean", "cope8_StriatumMask_2_betas_mean",
> "cope7_StriatumMask_2_betas_mean", "cope6_StriatumMask_2_betas_mean",
> "cope5_StriatumMask_2_betas_mean", "cope4_StriatumMask_2_betas_mean",
> "cope3_StriatumMask_2_betas_mean", "cope2_StriatumMask_2_betas_mean",
> "cope1_StriatumMask_2_betas_mean", "cope8_StriatumMask_1_betas_mean",
> "cope7_StriatumMask_1_betas_mean", "cope6_StriatumMask_1_betas_mean",
> "cope5_StriatumMask_1_betas_mean", "cope4_StriatumMask_1_betas_mean",
> "cope3_StriatumMask_1_betas_mean", "cope2_StriatumMask_1_betas_mean",
> "cope1_StriatumMask_1_betas_mean", "cope8_StriatumMask_betas_mean",
> "cope7_StriatumMask_betas_mean", "cope6_StriatumMask_betas_mean",
> "cope5_StriatumMask_betas_mean", "cope4_StriatumMask_betas_mean",
> "cope3_StriatumMask_betas_mean", "cope2_StriatumMask_betas_mean",
> "cope1_StriatumMask_betas_mean", "age", "hare2f1", "hare2f2",
> "hare4", "hare", "ext_t", "total_barrat_11_imputed", "mcq_k",
> "ppitots", "ppi_1_corrected", "ppi_2_corrected", "total_buss_perry"
> ), row.names = c(NA, -43L), class = "data.frame")
>
>
> --
>
> *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> University *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University SNPLab http://scholar.harvard.edu/buckholtz
<http://scholar.harvard.edu/buckholtz>*

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Sep  2 18:05:32 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 2 Sep 2014 12:05:32 -0400
Subject: [R] Is there an ID3 implementation in R?
In-Reply-To: <5405E582.7030003@email.de>
References: <CANdJ3dWzzCiuXvs942oRG04uj80+aehH8d-uY9+2uJKts5ecKw@mail.gmail.com>
	<CAKyN3iBXiHJhfq0cwFDcOj0Gk0gKnoA_5eEW6DN72zyzgj8QtQ@mail.gmail.com>
	<CANdJ3dVW1stEBpbOp97ouRKn=er3GHjREeTfsw-dswXPVwtS0w@mail.gmail.com>
	<5405E582.7030003@email.de>
Message-ID: <CA+vqiLEs5+bCHis84jHwNO0_w_wt90iEsfPH+ZG2RFnOoZtAeQ@mail.gmail.com>

This is explained in the RWeka vignette, but briefly:

## load RWeka
library(RWeka)
## look for a package providing id3
WPM("refresh-cache")
WPM("list-packages", "available") ## look for id3
## install package providing id3
WPM("install-package", "simpleEducationalLearningSchemes")
## load the package
WPM("load-package", "simpleEducationalLearningSchemes")
## make classifier
ID3 <- make_Weka_classifier("weka/classifiers/trees/Id3")
## test it out.
DF2 <- read.arff(system.file("arff", "contact-lenses.arff",
                             package = "RWeka"))
ID3(`contact-lenses` ~ ., data = DF2)


Best,
Ista

On Tue, Sep 2, 2014 at 11:42 AM, Christian Schulz <chschulz at email.de> wrote:
> Yes with: make_Weka_classifier(name, class = NULL, handlers = list(), init =
> NULL)
> HTH, Christian
>
>
>
>> Hi Wensui,
>>
>> When I looked at their docs:
>> http://cran.r-project.org/web/packages/RWeka/RWeka.pdf
>> It appeared they only have a connection to:
>> J48
>> LMT
>> M5P
>> DecisionStump
>>
>> Is it possible to connect it to:
>> http://www.cs.tufts.edu/~ablumer/weka/doc/weka.classifiers.Id3.html
>>
>> If so, how?
>>
>> Thanks.
>>
>>
>>
>>
>> ----------------Contact
>> Details:-------------------------------------------------------
>> Contact me: Tal.Galili at gmail.com |
>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>> www.r-statistics.com (English)
>>
>> ----------------------------------------------------------------------------------------------
>>
>>
>>
>> On Tue, Sep 2, 2014 at 6:13 PM, Wensui Liu <liuwensui at gmail.com> wrote:
>>
>>> Rweka
>>> On Sep 2, 2014 11:04 AM, "Tal Galili" <tal.galili at gmail.com> wrote:
>>>
>>>> Dear R help mailing list,
>>>>
>>>> I am looking for an ID3 implementation in R. I know that there are many
>>>> other decision tree algorithms already implemented (via rpart, tree,
>>>> caret,
>>>> C50, etc., etc.), but for research purposes I would like to reproduce
>>>> the
>>>> result of running ID3.
>>>>
>>>> I was not able to find such an implementation when searching in any of
>>>> the
>>>> following:
>>>> http://rseek.org/
>>>> http://finzi.psych.upenn.edu/search.html
>>>> http://cran.r-project.org/web/views/MachineLearning.html
>>>>
>>>> Any suggestions?
>>>>
>>>> Thanks,
>>>> Tal
>>>>
>>>>
>>>> ----------------Contact
>>>> Details:-------------------------------------------------------
>>>> Contact me: Tal.Galili at gmail.com |
>>>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>>>> www.r-statistics.com (English)
>>>>
>>>>
>>>> ----------------------------------------------------------------------------------------------
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tal.galili at gmail.com  Tue Sep  2 18:11:46 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Tue, 2 Sep 2014 19:11:46 +0300
Subject: [R] Is there an ID3 implementation in R?
In-Reply-To: <CA+vqiLEs5+bCHis84jHwNO0_w_wt90iEsfPH+ZG2RFnOoZtAeQ@mail.gmail.com>
References: <CANdJ3dWzzCiuXvs942oRG04uj80+aehH8d-uY9+2uJKts5ecKw@mail.gmail.com>
	<CAKyN3iBXiHJhfq0cwFDcOj0Gk0gKnoA_5eEW6DN72zyzgj8QtQ@mail.gmail.com>
	<CANdJ3dVW1stEBpbOp97ouRKn=er3GHjREeTfsw-dswXPVwtS0w@mail.gmail.com>
	<5405E582.7030003@email.de>
	<CA+vqiLEs5+bCHis84jHwNO0_w_wt90iEsfPH+ZG2RFnOoZtAeQ@mail.gmail.com>
Message-ID: <CANdJ3dWBXdOdR46-Z8pF6fi9O0_XtJOC3NeSkmbskCBGfgU2iQ@mail.gmail.com>

Dear Ista and Christian - this works wonderfully, thank you!




----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------



On Tue, Sep 2, 2014 at 7:05 PM, Ista Zahn <istazahn at gmail.com> wrote:

> This is explained in the RWeka vignette, but briefly:
>
> ## load RWeka
> library(RWeka)
> ## look for a package providing id3
> WPM("refresh-cache")
> WPM("list-packages", "available") ## look for id3
> ## install package providing id3
> WPM("install-package", "simpleEducationalLearningSchemes")
> ## load the package
> WPM("load-package", "simpleEducationalLearningSchemes")
> ## make classifier
> ID3 <- make_Weka_classifier("weka/classifiers/trees/Id3")
> ## test it out.
> DF2 <- read.arff(system.file("arff", "contact-lenses.arff",
>                              package = "RWeka"))
> ID3(`contact-lenses` ~ ., data = DF2)
>
>
> Best,
> Ista
>
> On Tue, Sep 2, 2014 at 11:42 AM, Christian Schulz <chschulz at email.de>
> wrote:
> > Yes with: make_Weka_classifier(name, class = NULL, handlers = list(),
> init =
> > NULL)
> > HTH, Christian
> >
> >
> >
> >> Hi Wensui,
> >>
> >> When I looked at their docs:
> >> http://cran.r-project.org/web/packages/RWeka/RWeka.pdf
> >> It appeared they only have a connection to:
> >> J48
> >> LMT
> >> M5P
> >> DecisionStump
> >>
> >> Is it possible to connect it to:
> >> http://www.cs.tufts.edu/~ablumer/weka/doc/weka.classifiers.Id3.html
> >>
> >> If so, how?
> >>
> >> Thanks.
> >>
> >>
> >>
> >>
> >> ----------------Contact
> >> Details:-------------------------------------------------------
> >> Contact me: Tal.Galili at gmail.com |
> >> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew)
> |
> >> www.r-statistics.com (English)
> >>
> >>
> ----------------------------------------------------------------------------------------------
> >>
> >>
> >>
> >> On Tue, Sep 2, 2014 at 6:13 PM, Wensui Liu <liuwensui at gmail.com> wrote:
> >>
> >>> Rweka
> >>> On Sep 2, 2014 11:04 AM, "Tal Galili" <tal.galili at gmail.com> wrote:
> >>>
> >>>> Dear R help mailing list,
> >>>>
> >>>> I am looking for an ID3 implementation in R. I know that there are
> many
> >>>> other decision tree algorithms already implemented (via rpart, tree,
> >>>> caret,
> >>>> C50, etc., etc.), but for research purposes I would like to reproduce
> >>>> the
> >>>> result of running ID3.
> >>>>
> >>>> I was not able to find such an implementation when searching in any of
> >>>> the
> >>>> following:
> >>>> http://rseek.org/
> >>>> http://finzi.psych.upenn.edu/search.html
> >>>> http://cran.r-project.org/web/views/MachineLearning.html
> >>>>
> >>>> Any suggestions?
> >>>>
> >>>> Thanks,
> >>>> Tal
> >>>>
> >>>>
> >>>> ----------------Contact
> >>>> Details:-------------------------------------------------------
> >>>> Contact me: Tal.Galili at gmail.com |
> >>>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il
> (Hebrew) |
> >>>> www.r-statistics.com (English)
> >>>>
> >>>>
> >>>>
> ----------------------------------------------------------------------------------------------
> >>>>
> >>>>          [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From deter088 at umn.edu  Tue Sep  2 18:59:24 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 2 Sep 2014 11:59:24 -0500
Subject: [R] shiny datatables column filtering plugin
Message-ID: <CAOLJphmztzATPeD66rtni5Xk+yeHscT+72OTsuedN_+GAEb0TA@mail.gmail.com>

Greetings,

I am currently exploring some capabilities of the 'Shiny' package.  I am
currently working with the most recent version of 'shiny' from the rstudio
github repository (version - 0.10.1.9006) in order to use the most up to
date datatables plugin.  Using the ggplot2 diamonds dataset, I can easily
set columns as unsearchable (commented out below) and I could also subset
out all the 'Ideal' diamonds for example, however I cannot filter out
multiple conditions such as 'Ideal' and 'Fair' diamonds together.  From my
searching, this multiple filtering can be done with checkboxes from the
column using the jquery column filtering plugin (
http://jquery-datatables-column-filter.googlecode.com/svn/trunk/checkbox.html).
Despite this, I cannot get this plugin to work with my shiny app.  Any
insight would be appreciated.

library(shiny)
library(ggplot2)
runApp(
  list(ui = basicPage(
    h1('Diamonds DataTable with TableTools'),

    # added column filter plugin
    singleton(tags$head(tags$script(src='https://code.google.com/p/jquery-datatables-column-filter/source/browse/trunk/media/js/jquery.dataTables.columnFilter.js',
type='text/javascript'))),
    dataTableOutput("mytable")
  )
  ,server = function(input, output) {
    output$mytable = renderDataTable({
      diamonds[,1:6]
    }, options = list(
      pageLength = 10,#       columnDefs = I('[{"targets": [0,1],
"searchable": false}]')
      columnFilter = I('[{
                        columnDefs: ["targets": [0,1], type: "checkbox"]
                        }]')

    )
    )
  }
  ))



Charles

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Tue Sep  2 19:29:07 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 02 Sep 2014 13:29:07 -0400
Subject: [R] frequencies of a discrete numeric variable, including zeros
Message-ID: <5405FE63.5030007@yorku.ca>

The data vector, art, given below using dput(),  gives a set of discrete 
numeric values for 915 observations,
in the range of 0:19.  I want to make some plots of the frequency 
distribution, but the standard
tools (hist, barplot, table) don't give me what I want to make a custom 
plot due to 0 frequencies
for some of the 0:19 counts.

table() excludes the values of art that occur with zero frequency, and 
these are excluded in
barplot()
 > table(art)
art
   0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
 > barplot(table(art))


A direct calculation, using colSums of outer() gives me the values I 
want, but this seems unnecessarily
complicated for this simple task.

 > (art.freq <- colSums(outer(art, 0:19, `==`)))
  [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0   
1   0   0   1
 >  barplot(art.freq, names.arg=0:19)


Moreover, I was surprised by the result of hist() on this data, because 
the 0 & 1 counts from
the above were combined in this call:

 > art.hist <- hist(art, breaks=0:19, plot=FALSE)
 > art.hist$breaks
  [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
 > art.hist$counts
  [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1   
0   0   1

Is there some option I missed here?

The data:

 > dput(art)
c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
11L, 12L, 12L, 16L, 19L)

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From marc_schwartz at me.com  Tue Sep  2 19:36:52 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 02 Sep 2014 12:36:52 -0500
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <5405FE63.5030007@yorku.ca>
References: <5405FE63.5030007@yorku.ca>
Message-ID: <C8FE134C-C860-42D5-AAD8-7E7B91557D0C@me.com>


On Sep 2, 2014, at 12:29 PM, Michael Friendly <friendly at yorku.ca> wrote:

> The data vector, art, given below using dput(),  gives a set of discrete numeric values for 915 observations,
> in the range of 0:19.  I want to make some plots of the frequency distribution, but the standard
> tools (hist, barplot, table) don't give me what I want to make a custom plot due to 0 frequencies
> for some of the 0:19 counts.
> 
> table() excludes the values of art that occur with zero frequency, and these are excluded in
> barplot()
> > table(art)
> art
>  0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
> > barplot(table(art))
> 
> 
> A direct calculation, using colSums of outer() gives me the values I want, but this seems unnecessarily
> complicated for this simple task.
> 
> > (art.freq <- colSums(outer(art, 0:19, `==`)))
> [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0   1   0   0   1
> >  barplot(art.freq, names.arg=0:19)
> 
> 
> Moreover, I was surprised by the result of hist() on this data, because the 0 & 1 counts from
> the above were combined in this call:
> 
> > art.hist <- hist(art, breaks=0:19, plot=FALSE)
> > art.hist$breaks
> [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
> > art.hist$counts
> [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1   0   0   1
> 
> Is there some option I missed here?
> 
> The data:
> 
> > dput(art)
> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
> 11L, 12L, 12L, 16L, 19L)


Micheal,

Corece the vector to be tabulated to a factor, that contains all of the levels 0:19, then use barplot():

art.fac <- factor(art, levels = 0:19)

> table(art.fac)
art.fac
  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17 
275 246 178  84  67  27  17  12   1   2   1   1   2   0   0   0   1   0 
 18  19 
  0   1 


barplot(table(art.fac), cex.names = 0.5)


Thanks for providing the data above.

Regards,

Marc Schwartz


From rmh at temple.edu  Tue Sep  2 19:45:18 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 2 Sep 2014 13:45:18 -0400
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <C8FE134C-C860-42D5-AAD8-7E7B91557D0C@me.com>
References: <5405FE63.5030007@yorku.ca>
	<C8FE134C-C860-42D5-AAD8-7E7B91557D0C@me.com>
Message-ID: <CAGx1TMCbOgRZ7Np4LEcSFk9zYd95qat8VvotatNLOyR-mLpeaw@mail.gmail.com>

I like Marc's answer, and I occasionaly have need for a different idiom.

old <-
structure(list(`0` = 275L, `1` = 246L, `2` = 178L, `3` = 84L,
    `4` = 67L, `5` = 27L, `6` = 17L, `7` = 12L, `8` = 1L, `9` = 2L,
    `10` = 1L, `11` = 1L, `12` = 2L, `16` = 1L, `19` = 1L), .Names = c("0",
"1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12",
"16", "19"), row.names = 2L, class = "data.frame")

new <- rep(0,20)
names(new) <- 0:19
new[names(old)] <- as.numeric(old)
new

Rich


On Tue, Sep 2, 2014 at 1:36 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
> On Sep 2, 2014, at 12:29 PM, Michael Friendly <friendly at yorku.ca> wrote:
>
>> The data vector, art, given below using dput(),  gives a set of discrete numeric values for 915 observations,
>> in the range of 0:19.  I want to make some plots of the frequency distribution, but the standard
>> tools (hist, barplot, table) don't give me what I want to make a custom plot due to 0 frequencies
>> for some of the 0:19 counts.
>>
>> table() excludes the values of art that occur with zero frequency, and these are excluded in
>> barplot()
>> > table(art)
>> art
>>  0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
>> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
>> > barplot(table(art))
>>
>>
>> A direct calculation, using colSums of outer() gives me the values I want, but this seems unnecessarily
>> complicated for this simple task.
>>
>> > (art.freq <- colSums(outer(art, 0:19, `==`)))
>> [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0   1   0   0   1
>> >  barplot(art.freq, names.arg=0:19)
>>
>>
>> Moreover, I was surprised by the result of hist() on this data, because the 0 & 1 counts from
>> the above were combined in this call:
>>
>> > art.hist <- hist(art, breaks=0:19, plot=FALSE)
>> > art.hist$breaks
>> [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
>> > art.hist$counts
>> [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1   0   0   1
>>
>> Is there some option I missed here?
>>
>> The data:
>>
>> > dput(art)
>> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
>> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
>> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
>> 11L, 12L, 12L, 16L, 19L)
>
>
> Micheal,
>
> Corece the vector to be tabulated to a factor, that contains all of the levels 0:19, then use barplot():
>
> art.fac <- factor(art, levels = 0:19)
>
>> table(art.fac)
> art.fac
>   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
> 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0   0   1   0
>  18  19
>   0   1
>
>
> barplot(table(art.fac), cex.names = 0.5)
>
>
> Thanks for providing the data above.
>
> Regards,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From arnaud.gaboury at gmail.com  Tue Sep  2 19:54:39 2014
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Tue, 2 Sep 2014 19:54:39 +0200
Subject: [R] Building R for better performance
In-Reply-To: <CAAJSdjjKHL7msCuyry5dTbgLvNTYWfnaNXzOjJM_v2V7ni2AtA@mail.gmail.com>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<5404E41C.8030900@yahoo.co.uk> <540532E1.4080400@uq.edu.au>
	<CAAJSdjjKHL7msCuyry5dTbgLvNTYWfnaNXzOjJM_v2V7ni2AtA@mail.gmail.com>
Message-ID: <CAK1hC9uDbQCmKvkV+=oiroLUiTmatTeXx=xHWfRKx59G9RQMNA@mail.gmail.com>

> The best that I can see for R would be if someone were to post a "how
> to use MKL for compiling R" type document.

I build R with MKL and ICC on my Archlinux box[1][2].

If I can help in anything, I will do it.

[1]https://wiki.archlinux.org/index.php/R
[2]https://aur.archlinux.org/packages/r-mkl/


From murdoch.duncan at gmail.com  Tue Sep  2 19:57:37 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 02 Sep 2014 13:57:37 -0400
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <5405FE63.5030007@yorku.ca>
References: <5405FE63.5030007@yorku.ca>
Message-ID: <54060511.9020504@gmail.com>

On 02/09/2014, 1:29 PM, Michael Friendly wrote:
> The data vector, art, given below using dput(),  gives a set of discrete 
> numeric values for 915 observations,
> in the range of 0:19.  I want to make some plots of the frequency 
> distribution, but the standard
> tools (hist, barplot, table) don't give me what I want to make a custom 
> plot due to 0 frequencies
> for some of the 0:19 counts.
> 
> table() excludes the values of art that occur with zero frequency, and 
> these are excluded in
> barplot()
>  > table(art)
> art
>    0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
>  > barplot(table(art))
> 
> 
> A direct calculation, using colSums of outer() gives me the values I 
> want, but this seems unnecessarily
> complicated for this simple task.
> 
>  > (art.freq <- colSums(outer(art, 0:19, `==`)))
>   [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0   
> 1   0   0   1
>  >  barplot(art.freq, names.arg=0:19)
> 
> 
> Moreover, I was surprised by the result of hist() on this data, because 
> the 0 & 1 counts from
> the above were combined in this call:

hist() is mainly aimed at continuous data, where values generally don't
show up on the boundaries.  Since you have integer data and integer
breaks, all values show up on the boundaries, and since you didn't
override the include.lowest argument, the bars are for intervals [0,1],
(1,2], (2,3], etc, i.e. the leftmost one includes its left end, but none
of the others do.

As Marc said, barplot is what you want, but you need to declare your
data to be a factor to include all the levels.

Duncan Murdoch

> 
>  > art.hist <- hist(art, breaks=0:19, plot=FALSE)
>  > art.hist$breaks
>   [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
>  > art.hist$counts
>   [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1   
> 0   0   1
> 
> Is there some option I missed here?
> 
> The data:
> 
>  > dput(art)
> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
> 11L, 12L, 12L, 16L, 19L)
>


From ruipbarradas at sapo.pt  Tue Sep  2 19:59:03 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 02 Sep 2014 18:59:03 +0100
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <5405FE63.5030007@yorku.ca>
References: <5405FE63.5030007@yorku.ca>
Message-ID: <54060567.60406@sapo.pt>

Hello,

As for table, the help page says that "It is best to supply factors 
rather than rely on coercion.", So if you want to include elements in 
the range 0:19 with a count of zero, try

table(factor(art, levels = 0:19))


As for hist, use option right = FALSE.

art.hist <- hist(art, breaks=0:19, plot=FALSE, right = FALSE)
art.hist$breaks
  [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
art.hist$counts
  [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0   0 
1   0   1


Hope this helps,

Rui Barradas

Em 02-09-2014 18:29, Michael Friendly escreveu:
> The data vector, art, given below using dput(),  gives a set of discrete
> numeric values for 915 observations,
> in the range of 0:19.  I want to make some plots of the frequency
> distribution, but the standard
> tools (hist, barplot, table) don't give me what I want to make a custom
> plot due to 0 frequencies
> for some of the 0:19 counts.
>
> table() excludes the values of art that occur with zero frequency, and
> these are excluded in
> barplot()
>  > table(art)
> art
>    0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
>  > barplot(table(art))
>
>
> A direct calculation, using colSums of outer() gives me the values I
> want, but this seems unnecessarily
> complicated for this simple task.
>
>  > (art.freq <- colSums(outer(art, 0:19, `==`)))
>   [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0 1
> 0   0   1
>  >  barplot(art.freq, names.arg=0:19)
>
>
> Moreover, I was surprised by the result of hist() on this data, because
> the 0 & 1 counts from
> the above were combined in this call:
>
>  > art.hist <- hist(art, breaks=0:19, plot=FALSE)
>  > art.hist$breaks
>   [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
>  > art.hist$counts
>   [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1 0
> 0   1
>
> Is there some option I missed here?
>
> The data:
>
>  > dput(art)
> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
> 11L, 12L, 12L, 16L, 19L)
>


From brian.s.diggs at gmail.com  Tue Sep  2 20:06:08 2014
From: brian.s.diggs at gmail.com (Brian Diggs)
Date: Tue, 2 Sep 2014 11:06:08 -0700
Subject: [R] ddply question
In-Reply-To: <1409433074.68081.YahooMailNeo@web126001.mail.ne1.yahoo.com>
References: <1409433074.68081.YahooMailNeo@web126001.mail.ne1.yahoo.com>
Message-ID: <54060710.1030209@gmail.com>

On 8/30/2014 2:11 PM, Felipe Carrillo wrote:
>   library(plyr)
> b <- structure(list(SampleDate = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L), .Label = "5/8/1996", class = "factor"), TotalCount = c(1L,
> 2L, 1L, 1L, 4L, 3L, 1L, 10L, 3L), ForkLength = c(61L, 22L, NA,
> NA, 72L, 34L, 100L, 23L, 25L), TotalSalvage = c(12L, 24L, 12L,
> 12L, 17L, 23L, 31L, 12L, 15L), Age = c(1L, 0L, NA, NA, 1L, 0L,
> 1L, 0L, 0L)), .Names = c("SampleDate", "TotalCount", "ForkLength",
> "TotalSalvage", "Age"), class = "data.frame", row.names = c(NA,
> -9L))
> b
> ddply(b,.(SampleDate,Age),summarise,salvage=sum(TotalSalvage),pct=TotalCount/sum(TotalCount))
> Error: expecting result of length one, got : 4

I get a slightly different error:

Error: length(rows) == 1 is not TRUE

but the problem is the same. sum returns a single value, while the 
computation for pct returns a vector the same length as TotalCount (the 
number of rows in the specific piece of b). summarise is designed to 
take a data frame and reduce the number of rows in it by 
aggregating/summarizing (some of) the columns. Since your two 
computations give different numbers of resulting rows, it errors out. It 
seems you don't want to reduce the number of rows, so replace summarise 
with mutate. That function can handle the different length return 
vectors and recycles appropriately.

(The other difference between summarise and mutate is that mutate keeps 
the original columns while summarise drops all original columns and 
returns only the computed ones; this makes sense given that summarise 
expects to return fewer rows than in the original data.)

> #Computing TotalCount inside ddply works but the pct seems wrong...
> ddply(b,.(SampleDate,Age),summarise,salvage=sum(TotalSalvage),Count=sum(TotalCount),pct=Count/sum(Count))
> 	[[alternative HTML version deleted]]


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From dcarlson at tamu.edu  Tue Sep  2 20:19:23 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 2 Sep 2014 18:19:23 +0000
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <54060567.60406@sapo.pt>
References: <5405FE63.5030007@yorku.ca> <54060567.60406@sapo.pt>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F94975@mb02.ads.tamu.edu>

Another approach using barplot:

barplot(table(cut(art, breaks= -1:19, labels=0:19)))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Tuesday, September 2, 2014 12:59 PM
To: Michael Friendly; R-help
Subject: Re: [R] frequencies of a discrete numeric variable, including zeros

Hello,

As for table, the help page says that "It is best to supply factors 
rather than rely on coercion.", So if you want to include elements in 
the range 0:19 with a count of zero, try

table(factor(art, levels = 0:19))


As for hist, use option right = FALSE.

art.hist <- hist(art, breaks=0:19, plot=FALSE, right = FALSE)
art.hist$breaks
  [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
art.hist$counts
  [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0   0 
1   0   1


Hope this helps,

Rui Barradas

Em 02-09-2014 18:29, Michael Friendly escreveu:
> The data vector, art, given below using dput(),  gives a set of discrete
> numeric values for 915 observations,
> in the range of 0:19.  I want to make some plots of the frequency
> distribution, but the standard
> tools (hist, barplot, table) don't give me what I want to make a custom
> plot due to 0 frequencies
> for some of the 0:19 counts.
>
> table() excludes the values of art that occur with zero frequency, and
> these are excluded in
> barplot()
>  > table(art)
> art
>    0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
>  > barplot(table(art))
>
>
> A direct calculation, using colSums of outer() gives me the values I
> want, but this seems unnecessarily
> complicated for this simple task.
>
>  > (art.freq <- colSums(outer(art, 0:19, `==`)))
>   [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0 1
> 0   0   1
>  >  barplot(art.freq, names.arg=0:19)
>
>
> Moreover, I was surprised by the result of hist() on this data, because
> the 0 & 1 counts from
> the above were combined in this call:
>
>  > art.hist <- hist(art, breaks=0:19, plot=FALSE)
>  > art.hist$breaks
>   [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
>  > art.hist$counts
>   [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1 0
> 0   1
>
> Is there some option I missed here?
>
> The data:
>
>  > dput(art)
> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
> 11L, 12L, 12L, 16L, 19L)
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Sep  2 20:50:40 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 2 Sep 2014 18:50:40 +0000
Subject: [R] depth of labels of axis
In-Reply-To: <54050401.4060203@yeah.net>
References: <54050401.4060203@yeah.net>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>

The bottom of the expression is set by the lowest character (which can even change for subscripted letters with descenders. The solution is to get axis() to align the tops of the axis labels and move the line up to reduce the space, e.g.

plot(1:5, xaxt = "n")
axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]), 
"E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
# Check alignment
abline(h=.7, xpd=TRUE, lty=3)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jinsong Zhao
Sent: Monday, September 1, 2014 6:41 PM
To: r-help at r-project.org
Subject: [R] depth of labels of axis

Hi there,

With the following code,

plot(1:5, xaxt = "n")
axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]), 
"E", expression(E[t])))

you may notice that the "E" within labels of axis(1) are not at the same 
depth. So the vision of axis(1) labels is something like wave.

Is there a possible way to typeset the labels so that they are have the 
same depth?

Any suggestions will be really appreciated. Thanks in advance.

Best regards,
Jinsong

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From c.danyluck at gmail.com  Tue Sep  2 21:29:04 2014
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Tue, 2 Sep 2014 15:29:04 -0400
Subject: [R] Problems bootstrapping multigroup SEM
In-Reply-To: <004401cfc24a$91247dd0$b36d7970$@mcmaster.ca>
References: <CA+_f+RFmRj8QGD2sy7KmqUVCeLxfKAUY=qXnj9Opz2+J53MSWw@mail.gmail.com>
	<004401cfc24a$91247dd0$b36d7970$@mcmaster.ca>
Message-ID: <CA+_f+RFRcKgZvezX-9tVNmC6x-tEZ7W-Ry2FLRoQmt33D7wk7Q@mail.gmail.com>

Dear John,

Thank you for your insights. I think you do understand what I've been
trying to do. Because I am doing a multigroup comparison ? specifically,
examining the moderating role of test type on outcome ? I needed two
covariance matrices to pass through the model. I wasn't sure how to do this
other than by listing these covariance matrices together. This list was
called to the SEM and worked when the summary stats were called. As you
point out, however, the covariance matrix did not get passed into bootSem()
because, rather than use the cov function, I simply added the list. On
further reflection, the crux of my problem, or confusion, seems to stem
from not understanding how to deal with the need to pass two covariance
matrices into bootSem(). I could pass
"cov(na.omit(stereotype.MAP.data[,-1],
na.omit(evaluative.MAP.data[,-1])))", but I thought that the two matrices
needed to be kept separate because I am comparing the models produced by
each matrix to one another.

Another problem comes to light as I think through the help documentation:

"In the case of an msem (i.e., multi-group) model, *a list of data sets
(again in the appropriate form), one for each group*; in this case,
bootstrapping is done within each group, treating the groups as strata.
Note that the original observations are required, not just the covariance
matrix of the observed variables in the model. *The default is the data set
stored in the sem object*, which will be present only if the model was fit
to a data set rather than to a covariance or moment matrix, and may not be
in a form suitable for Cov."

In my case, the data passed through the sem object was
"c(nrow(stereotype.MAP.data), nrow(evaluative.MAP.data))". Perhaps this is
not suitable for Cov?

At this point I am spinning my wheels. Any further suggestions would be
appreciated.

Kind regards,

Chad


On Wed, Aug 27, 2014 at 6:59 PM, John Fox <jfox at mcmaster.ca> wrote:

> Dear Chad,
>
> It's possible that I don't understand properly what you've done, but it
> appears as if you're passing to bootSem() the covariance matrices for the
> observed data rather than the case-by-variable data sets themselves. That's
> also what you say you're doing, and it's what the error message says.
>
> Moreover, if you look at the documentation in ?bootSem, you'll is that the
> Cov argument isn't a covariance matrix, but "a function to compute the
> input covariance or moment matrix; the default is cov. Use cor if the model
> is fit to the correlation matrix. The function hetcor in the polycor
> package will compute product-moment, polychoric, and polyserial
> correlations among mixed continuous and ordinal variables (see the first
> example below for an illustration)."
>
> So what is there to bootstrap if bootSem() doesn't have access to the
> original data sets? I suppose that one could do a parametric bootstrap of
> some sort, but that's not what bootSem() does -- in implements a
> nonoparametric bootstrap, which requires the original data.
>
> I hope this helps,
>  John
>
> -----------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox/
>
>
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Chad Danyluck
> > Sent: Wednesday, August 27, 2014 12:22 PM
> > To: r-help at r-project.org
> > Subject: [R] Problems bootstrapping multigroup SEM
> >
> > Hello,
> >
> > I am having difficulty resolving an error I receive trying to bootstrap
> > a
> > multigroup SEM. The error (below) indicates that the model called to
> > bootSem doesn't contain matrices. This is true, sort of, because I
> > created
> > a list of two covariance matrices for the model to call. All of this
> > syntax
> > works fine (a summary of "MAP.mg.sem" will produce parameter estimates,
> > goodness of fit indices, etc.), however, the bootSem function does not
> > run.
> > Any ideas on a workaround?
> >
> > MLM.MAP.Data$IAT.factor <- as.factor(IAT)
> > IAT.factor <- MLM.MAP.Data$IAT.factor
> > evaluative.MAP.data <- subset(data.frame(IAT.factor, exp.race,
> > meditation.experience, years.meditate, repeated.iat, repeated.ERN, age,
> > acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
> > FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
> > FCz.eval.150.cor), IAT==2)
> > stereotype.MAP.data <- subset(data.frame(IAT.factor, exp.race,
> > meditation.experience, years.meditate, repeated.iat, repeated.ERN, age,
> > acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
> > FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
> > FCz.eval.150.cor), IAT==1)
> >
> > MAP.stereotype.cov <- cov(na.omit(stereotype.MAP.data[,-1]))
> > MAP.evaluative.cov <- cov(na.omit(evaluative.MAP.data[,-1]))
> > MAP.cov.list <- list(stereotype=MAP.stereotype.cov,
> > evaluative=MAP.evaluative.cov)
> >
> > #### Specify your MSEM path model: Years Meditating, ERN, IAT####
> > MAP.msem.model <- specifyModel()
> > years.meditate -> repeated.ERN, path1
> > years.meditate -> repeated.iat, path2
> > repeated.ERN -> repeated.iat, path3
> > age -> repeated.iat, path4
> > years.meditate <-> years.meditate, var1
> > repeated.ERN <-> repeated.ERN, var2
> > age <-> age, var3
> > age <-> years.meditate, cov1
> > repeated.iat <-> repeated.iat, d1
> >
> > MAP.mg.mod <- multigroupModel(MAP.msem.model, groups=c("stereotype",
> > "evaluative"))
> >
> > MAP.mg.sem <- sem(MAP.mg.mod, MAP.cov.list,
> > c(nrow(stereotype.MAP.data),
> > nrow(evaluative.MAP.data)), group="IAT.factor")
> >
> > system.time(bootSem(MAP.mg.sem, R=100, MAP.cov.list))
> >
> > Error in bootSem.msem(MAP.mg.sem, MAP.cov.list, R = 100) :
> >   the model object doesn't contain data matrices
> >
> > --
> > Chad M. Danyluck
> > PhD Candidate, Psychology
> > University of Toronto
> > Lab: http://embodiedsocialcognition.com
> >
> >
> > ?There is nothing either good or bad but thinking makes it so.? -
> > William
> > Shakespeare
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Chad M. Danyluck
PhD Candidate, Psychology
University of Toronto
Lab: http://embodiedsocialcognition.com


?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Sep  2 21:49:57 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 2 Sep 2014 15:49:57 -0400
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <5405FE63.5030007@yorku.ca>
References: <5405FE63.5030007@yorku.ca>
Message-ID: <002a01cfc6e7$134de210$39e9a630$@mcmaster.ca>

Hi Michael,

I think that histograms are intrinsically misleading for discrete data, and
that while bar graphs are an improvement, they also invite
misinterpretation. I generally do something like this:

f <- table(factor(art, levels=0:19))
plot(as.numeric(names(f)), as.numeric(f), type="h",
    xlab="art", ylab="frequency", axes=FALSE)
axis(1, pos=0, at=0:19)
axis(2)
points(as.numeric(names(f)), f, pch=16)
abline(h=0)


Actually, I prefer omitting the points corresponding to 0 counts, which is
even simpler:

f <- table(art)
plot(as.numeric(names(f)), as.numeric(f), type="h",
    xlab="art", ylab="frequency", axes=FALSE)
axis(1, pos=0, at=min(art):max(art))
axis(2)
points(as.numeric(names(f)), f, pch=16)
abline(h=0)


Best,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Michael Friendly
> Sent: Tuesday, September 02, 2014 1:29 PM
> To: R-help
> Subject: [R] frequencies of a discrete numeric variable, including
> zeros
> 
> The data vector, art, given below using dput(),  gives a set of
> discrete
> numeric values for 915 observations,
> in the range of 0:19.  I want to make some plots of the frequency
> distribution, but the standard
> tools (hist, barplot, table) don't give me what I want to make a custom
> plot due to 0 frequencies
> for some of the 0:19 counts.
> 
> table() excludes the values of art that occur with zero frequency, and
> these are excluded in
> barplot()
>  > table(art)
> art
>    0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
>  > barplot(table(art))
> 
> 
> A direct calculation, using colSums of outer() gives me the values I
> want, but this seems unnecessarily
> complicated for this simple task.
> 
>  > (art.freq <- colSums(outer(art, 0:19, `==`)))
>   [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0
> 1   0   0   1
>  >  barplot(art.freq, names.arg=0:19)
> 
> 
> Moreover, I was surprised by the result of hist() on this data, because
> the 0 & 1 counts from
> the above were combined in this call:
> 
>  > art.hist <- hist(art, breaks=0:19, plot=FALSE)
>  > art.hist$breaks
>   [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
>  > art.hist$counts
>   [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1
> 0   0   1
> 
> Is there some option I missed here?
> 
> The data:
> 
>  > dput(art)
> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
> 11L, 12L, 12L, 16L, 19L)
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Tue Sep  2 20:45:49 2014
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 02 Sep 2014 14:45:49 -0400
Subject: [R] Overwriting a procedure
Message-ID: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>

Is there a way to over-write a procedure (subroutine)?

I include a default procedure fixx in a list of procedures which are 
compiled into a package. By default, the procedure deliver the data matrix x.

fixx <- function(x){
result <- list(x=x)
return(result)
}

In some applications, I have transformations (such as squared terms) 
in some column(s) in x. So I include the following procedure in the 
mail (calling) program, hoping to over-write the default procedure 
under the same name in the package (which is the way other languages 
works, e.g., Gauss):

fixx <- function(x){
x[,6]<-x[,5]^2/10
result <- list(x=x)
return(result)
}

This does not seem to work. The procedure in the main (calling) 
program seems to get ignored. Any idea? Thanks.


From jfox at mcmaster.ca  Tue Sep  2 22:03:59 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 2 Sep 2014 16:03:59 -0400
Subject: [R] Problems bootstrapping multigroup SEM
In-Reply-To: <CA+_f+RFRcKgZvezX-9tVNmC6x-tEZ7W-Ry2FLRoQmt33D7wk7Q@mail.gmail.com>
References: <CA+_f+RFmRj8QGD2sy7KmqUVCeLxfKAUY=qXnj9Opz2+J53MSWw@mail.gmail.com>	<004401cfc24a$91247dd0$b36d7970$@mcmaster.ca>
	<CA+_f+RFRcKgZvezX-9tVNmC6x-tEZ7W-Ry2FLRoQmt33D7wk7Q@mail.gmail.com>
Message-ID: <002b01cfc6e9$090d9b40$1b28d1c0$@mcmaster.ca>

Dear Chad,

> -----Original Message-----
> From: Chad Danyluck [mailto:c.danyluck at gmail.com]
> Sent: Tuesday, September 02, 2014 3:29 PM
> To: John Fox
> Cc: r-help at r-project.org
> Subject: Re: [R] Problems bootstrapping multigroup SEM
> 
> Dear John,
> 
> Thank you for your insights. I think you do understand what I've been
> trying to do. Because I am doing a multigroup comparison ?
> specifically, examining the moderating role of test type on outcome ? I
> needed two covariance matrices to pass through the model. I wasn't sure
> how to do this other than by listing these covariance matrices
> together. This list was called to the SEM and worked when the summary
> stats were called. As you point out, however, the covariance matrix did
> not get passed into bootSem() because, rather than use the cov
> function, I simply added the list. On further reflection, the crux of
> my problem, or confusion, seems to stem from not understanding how to
> deal with the need to pass two covariance matrices into bootSem(). I
> could pass "cov(na.omit(stereotype.MAP.data[,-1],
> na.omit(evaluative.MAP.data[,-1])))", but I thought that the two
> matrices needed to be kept separate because I am comparing the models
> produced by each matrix to one another.
> 
> Another problem comes to light as I think through the help
> documentation:
> 
> "In the case of an msem (i.e., multi-group) model, a list of data sets
> (again in the appropriate form), one for each group; in this case,
> bootstrapping is done within each group, treating the groups as strata.
> Note that the original observations are required, not just the
> covariance matrix of the observed variables in the model. The default
> is the data set stored in the sem object, which will be present only if
> the model was fit to a data set rather than to a covariance or moment
> matrix, and may not be in a form suitable for Cov."
> 
> In my case, the data passed through the sem object was
> "c(nrow(stereotype.MAP.data), nrow(evaluative.MAP.data))". Perhaps this
> is not suitable for Cov?

I'm sorry but I don't follow this: c(nrow(stereotype.MAP.data), nrow(evaluative.MAP.data)) are simply the numbers of observations in the data sets, not the data sets themselves. From what you've said, the data sets are stereotype.MAP.data and evaluative.MAP.data. You can use the data and formula arguments to sem(). You need the explicit formula argument because you're apparently omitting one of the variables in each data set; alternatively, you can directly remove the unused variable from each data set, as you've done above. And you need not filter out the missing data (though it doesn't hurt to do so), since the default na.action is na.omit (as is shown in ?sem).

>From ?sem:

"data: As a generally preferable alternative to specifying S and N, the user may supply a data frame containing the data to which the model is to be fit. In a multigroup model, the data argument may be a list of data frames or a single data frame; in the later event, the factor given as the group argument is used to split the data into groups."

and

"formula: a one-sided formula, to be applied to data to generate the variables for which covariances or raw moments are computed. The default formula is ~., i.e., all of the variables in the data, including an implied intercept; if a covariance matrix is to be computed, the constant is suppressed. In a multigroup model, alternatively a list one one-sided formulas as be given, to be applied individually to the groups."

The multigroup example given in ?sem for the HS.data uses a single data frame, which is then classified by the factor Gender. In your case, you'd specify a list of two data frames; if the same variables are to be used in each, then you need give only one formula rather than a list of two, though the latter would also work.

Best,
 John

> 
> At this point I am spinning my wheels. Any further suggestions would be
> appreciated.
> 
> Kind regards,
> 
> 
> Chad
> 
> 
> 
> 
> On Wed, Aug 27, 2014 at 6:59 PM, John Fox <jfox at mcmaster.ca> wrote:
> 
> 
> 	Dear Chad,
> 
> 	It's possible that I don't understand properly what you've done,
> but it appears as if you're passing to bootSem() the covariance
> matrices for the observed data rather than the case-by-variable data
> sets themselves. That's also what you say you're doing, and it's what
> the error message says.
> 
> 	Moreover, if you look at the documentation in ?bootSem, you'll is
> that the Cov argument isn't a covariance matrix, but "a function to
> compute the input covariance or moment matrix; the default is cov. Use
> cor if the model is fit to the correlation matrix. The function hetcor
> in the polycor package will compute product-moment, polychoric, and
> polyserial correlations among mixed continuous and ordinal variables
> (see the first example below for an illustration)."
> 
> 	So what is there to bootstrap if bootSem() doesn't have access to
> the original data sets? I suppose that one could do a parametric
> bootstrap of some sort, but that's not what bootSem() does -- in
> implements a nonoparametric bootstrap, which requires the original
> data.
> 
> 	I hope this helps,
> 	 John
> 
> 	-----------------------------------------------
> 	John Fox, Professor
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 	http://socserv.socsci.mcmaster.ca/jfox/
> 
> 
> 
> 
> 	> -----Original Message-----
> 	> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> 	> project.org] On Behalf Of Chad Danyluck
> 	> Sent: Wednesday, August 27, 2014 12:22 PM
> 	> To: r-help at r-project.org
> 	> Subject: [R] Problems bootstrapping multigroup SEM
> 	>
> 	> Hello,
> 	>
> 	> I am having difficulty resolving an error I receive trying to
> bootstrap
> 	> a
> 	> multigroup SEM. The error (below) indicates that the model
> called to
> 	> bootSem doesn't contain matrices. This is true, sort of, because
> I
> 	> created
> 	> a list of two covariance matrices for the model to call. All of
> this
> 	> syntax
> 	> works fine (a summary of "MAP.mg.sem" will produce parameter
> estimates,
> 	> goodness of fit indices, etc.), however, the bootSem function
> does not
> 	> run.
> 	> Any ideas on a workaround?
> 	>
> 	> MLM.MAP.Data$IAT.factor <- as.factor(IAT)
> 	> IAT.factor <- MLM.MAP.Data$IAT.factor
> 	> evaluative.MAP.data <- subset(data.frame(IAT.factor, exp.race,
> 	> meditation.experience, years.meditate, repeated.iat,
> repeated.ERN, age,
> 	> acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
> 	> FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
> 	> FCz.eval.150.cor), IAT==2)
> 	> stereotype.MAP.data <- subset(data.frame(IAT.factor, exp.race,
> 	> meditation.experience, years.meditate, repeated.iat,
> repeated.ERN, age,
> 	> acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
> 	> FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
> 	> FCz.eval.150.cor), IAT==1)
> 	>
> 	> MAP.stereotype.cov <- cov(na.omit(stereotype.MAP.data[,-1]))
> 	> MAP.evaluative.cov <- cov(na.omit(evaluative.MAP.data[,-1]))
> 	> MAP.cov.list <- list(stereotype=MAP.stereotype.cov,
> 	> evaluative=MAP.evaluative.cov)
> 	>
> 	> #### Specify your MSEM path model: Years Meditating, ERN,
> IAT####
> 	> MAP.msem.model <- specifyModel()
> 	> years.meditate -> repeated.ERN, path1
> 	> years.meditate -> repeated.iat, path2
> 	> repeated.ERN -> repeated.iat, path3
> 	> age -> repeated.iat, path4
> 	> years.meditate <-> years.meditate, var1
> 	> repeated.ERN <-> repeated.ERN, var2
> 	> age <-> age, var3
> 	> age <-> years.meditate, cov1
> 	> repeated.iat <-> repeated.iat, d1
> 	>
> 	> MAP.mg.mod <- multigroupModel(MAP.msem.model,
> groups=c("stereotype",
> 	> "evaluative"))
> 	>
> 	> MAP.mg.sem <- sem(MAP.mg.mod, MAP.cov.list,
> 	> c(nrow(stereotype.MAP.data),
> 	> nrow(evaluative.MAP.data)), group="IAT.factor")
> 	>
> 	> system.time(bootSem(MAP.mg.sem, R=100, MAP.cov.list))
> 	>
> 	> Error in bootSem.msem(MAP.mg.sem, MAP.cov.list, R = 100) :
> 	>   the model object doesn't contain data matrices
> 	>
> 	> --
> 	> Chad M. Danyluck
> 	> PhD Candidate, Psychology
> 	> University of Toronto
> 	> Lab: http://embodiedsocialcognition.com
> 	>
> 	>
> 	> ?There is nothing either good or bad but thinking makes it so.?
> -
> 	> William
> 	> Shakespeare
> 	>
> 
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> ______________________________________________
> 	> R-help at r-project.org mailing list
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-
> project.org/posting-
> 	> guide.html
> 	> and provide commented, minimal, self-contained, reproducible
> code.
> 
> 
> 
> 
> 
> 
> --
> 
> Chad M. Danyluck
> PhD Candidate, Psychology
> University of Toronto
> Lab: http://embodiedsocialcognition.com
> <http://embodiedsocialcognition.com/>
> 
> 
> 
> 
> ?There is nothing either good or bad but thinking makes it so.? -
> William Shakespeare


From wdunlap at tibco.com  Tue Sep  2 22:13:51 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 2 Sep 2014 13:13:51 -0700
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <002a01cfc6e7$134de210$39e9a630$@mcmaster.ca>
References: <5405FE63.5030007@yorku.ca>
	<002a01cfc6e7$134de210$39e9a630$@mcmaster.ca>
Message-ID: <CAF8bMcbuGThkpQ72BA++jF1jWRXT2br-X5_PEsb8XROEXXTtdg@mail.gmail.com>

The built-in table method for plot() makes a decent looking plot as
well.  Look at
  plot(table(art), ylab="Count")
  plot(table(factor(art, levels=0:19)), ylab="Count")
  plot(table(LETTERS[art+1]), ylab="Count")
  plot(table(factor(LETTERS[art+1], levels=LETTERS[1:20])), ylab="Count")
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Sep 2, 2014 at 12:49 PM, John Fox <jfox at mcmaster.ca> wrote:
> Hi Michael,
>
> I think that histograms are intrinsically misleading for discrete data, and
> that while bar graphs are an improvement, they also invite
> misinterpretation. I generally do something like this:
>
> f <- table(factor(art, levels=0:19))
> plot(as.numeric(names(f)), as.numeric(f), type="h",
>     xlab="art", ylab="frequency", axes=FALSE)
> axis(1, pos=0, at=0:19)
> axis(2)
> points(as.numeric(names(f)), f, pch=16)
> abline(h=0)
>
>
> Actually, I prefer omitting the points corresponding to 0 counts, which is
> even simpler:
>
> f <- table(art)
> plot(as.numeric(names(f)), as.numeric(f), type="h",
>     xlab="art", ylab="frequency", axes=FALSE)
> axis(1, pos=0, at=min(art):max(art))
> axis(2)
> points(as.numeric(names(f)), f, pch=16)
> abline(h=0)
>
>
> Best,
>  John
>
> -----------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox/
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Michael Friendly
>> Sent: Tuesday, September 02, 2014 1:29 PM
>> To: R-help
>> Subject: [R] frequencies of a discrete numeric variable, including
>> zeros
>>
>> The data vector, art, given below using dput(),  gives a set of
>> discrete
>> numeric values for 915 observations,
>> in the range of 0:19.  I want to make some plots of the frequency
>> distribution, but the standard
>> tools (hist, barplot, table) don't give me what I want to make a custom
>> plot due to 0 frequencies
>> for some of the 0:19 counts.
>>
>> table() excludes the values of art that occur with zero frequency, and
>> these are excluded in
>> barplot()
>>  > table(art)
>> art
>>    0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
>> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
>>  > barplot(table(art))
>>
>>
>> A direct calculation, using colSums of outer() gives me the values I
>> want, but this seems unnecessarily
>> complicated for this simple task.
>>
>>  > (art.freq <- colSums(outer(art, 0:19, `==`)))
>>   [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0
>> 1   0   0   1
>>  >  barplot(art.freq, names.arg=0:19)
>>
>>
>> Moreover, I was surprised by the result of hist() on this data, because
>> the 0 & 1 counts from
>> the above were combined in this call:
>>
>>  > art.hist <- hist(art, breaks=0:19, plot=FALSE)
>>  > art.hist$breaks
>>   [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
>>  > art.hist$counts
>>   [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1
>> 0   0   1
>>
>> Is there some option I missed here?
>>
>> The data:
>>
>>  > dput(art)
>> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
>> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
>> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
>> 11L, 12L, 12L, 16L, 19L)
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Tue Sep  2 22:17:33 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 2 Sep 2014 16:17:33 -0400
Subject: [R] Overwriting a procedure
In-Reply-To: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>
References: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>
Message-ID: <CA+vqiLFV7xc4e3n=YkX1LW3eCKSeXLL50GJJDMZeGwYh1ewFHg@mail.gmail.com>

Hi,

Trying to change the way functions inside packages work is almost
certainly not what you want to do. It's possible but usually there is
an easier way.

Your example is so simplified that I suspect it doesn't capture your
actual needs very well, but in the case of your example you can simply
do

pre <- function(x){
x[,6]<-x[,5]^2/10
return(x)
}

fixx(pre(x))


Best,
Ista

On Tue, Sep 2, 2014 at 2:45 PM, Steven Yen <syen04 at gmail.com> wrote:
> Is there a way to over-write a procedure (subroutine)?
>
> I include a default procedure fixx in a list of procedures which are
> compiled into a package. By default, the procedure deliver the data matrix
> x.
>
> fixx <- function(x){
> result <- list(x=x)
> return(result)
> }
>
> In some applications, I have transformations (such as squared terms) in some
> column(s) in x. So I include the following procedure in the mail (calling)
> program, hoping to over-write the default procedure under the same name in
> the package (which is the way other languages works, e.g., Gauss):
>
> fixx <- function(x){
> x[,6]<-x[,5]^2/10
> result <- list(x=x)
> return(result)
> }
>
> This does not seem to work. The procedure in the main (calling) program
> seems to get ignored. Any idea? Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Tue Sep  2 22:32:19 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 2 Sep 2014 16:32:19 -0400
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <CAF8bMcbuGThkpQ72BA++jF1jWRXT2br-X5_PEsb8XROEXXTtdg@mail.gmail.com>
References: <5405FE63.5030007@yorku.ca>
	<002a01cfc6e7$134de210$39e9a630$@mcmaster.ca>
	<CAF8bMcbuGThkpQ72BA++jF1jWRXT2br-X5_PEsb8XROEXXTtdg@mail.gmail.com>
Message-ID: <003301cfc6ec$fe8d5350$fba7f9f0$@mcmaster.ca>

Dear Bill,

Yes, that's better -- essentially similar to what I suggested but much less work. I wasn't aware of it. You could even add the points at the tops of the spikes via a follow-up points() command.

Thanks,
 John

> -----Original Message-----
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: Tuesday, September 02, 2014 4:14 PM
> To: John Fox
> Cc: Michael Friendly; R-help
> Subject: Re: [R] frequencies of a discrete numeric variable, including
> zeros
> 
> The built-in table method for plot() makes a decent looking plot as
> well.  Look at
>   plot(table(art), ylab="Count")
>   plot(table(factor(art, levels=0:19)), ylab="Count")
>   plot(table(LETTERS[art+1]), ylab="Count")
>   plot(table(factor(LETTERS[art+1], levels=LETTERS[1:20])),
> ylab="Count")
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
> On Tue, Sep 2, 2014 at 12:49 PM, John Fox <jfox at mcmaster.ca> wrote:
> > Hi Michael,
> >
> > I think that histograms are intrinsically misleading for discrete
> data, and
> > that while bar graphs are an improvement, they also invite
> > misinterpretation. I generally do something like this:
> >
> > f <- table(factor(art, levels=0:19))
> > plot(as.numeric(names(f)), as.numeric(f), type="h",
> >     xlab="art", ylab="frequency", axes=FALSE)
> > axis(1, pos=0, at=0:19)
> > axis(2)
> > points(as.numeric(names(f)), f, pch=16)
> > abline(h=0)
> >
> >
> > Actually, I prefer omitting the points corresponding to 0 counts,
> which is
> > even simpler:
> >
> > f <- table(art)
> > plot(as.numeric(names(f)), as.numeric(f), type="h",
> >     xlab="art", ylab="frequency", axes=FALSE)
> > axis(1, pos=0, at=min(art):max(art))
> > axis(2)
> > points(as.numeric(names(f)), f, pch=16)
> > abline(h=0)
> >
> >
> > Best,
> >  John
> >
> > -----------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.socsci.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Michael Friendly
> >> Sent: Tuesday, September 02, 2014 1:29 PM
> >> To: R-help
> >> Subject: [R] frequencies of a discrete numeric variable, including
> >> zeros
> >>
> >> The data vector, art, given below using dput(),  gives a set of
> >> discrete
> >> numeric values for 915 observations,
> >> in the range of 0:19.  I want to make some plots of the frequency
> >> distribution, but the standard
> >> tools (hist, barplot, table) don't give me what I want to make a
> custom
> >> plot due to 0 frequencies
> >> for some of the 0:19 counts.
> >>
> >> table() excludes the values of art that occur with zero frequency,
> and
> >> these are excluded in
> >> barplot()
> >>  > table(art)
> >> art
> >>    0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
> >> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
> >>  > barplot(table(art))
> >>
> >>
> >> A direct calculation, using colSums of outer() gives me the values I
> >> want, but this seems unnecessarily
> >> complicated for this simple task.
> >>
> >>  > (art.freq <- colSums(outer(art, 0:19, `==`)))
> >>   [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0
> >> 1   0   0   1
> >>  >  barplot(art.freq, names.arg=0:19)
> >>
> >>
> >> Moreover, I was surprised by the result of hist() on this data,
> because
> >> the 0 & 1 counts from
> >> the above were combined in this call:
> >>
> >>  > art.hist <- hist(art, breaks=0:19, plot=FALSE)
> >>  > art.hist$breaks
> >>   [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
> >>  > art.hist$counts
> >>   [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1
> >> 0   0   1
> >>
> >> Is there some option I missed here?
> >>
> >> The data:
> >>
> >>  > dput(art)
> >> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> >> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> >> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> >> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> >> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> >> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
> >> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
> >> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
> >> 11L, 12L, 12L, 16L, 19L)
> >>
> >> --
> >> Michael Friendly     Email: friendly AT yorku DOT ca
> >> Professor, Psychology Dept. & Chair, Quantitative Methods
> >> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> >> 4700 Keele Street    Web:http://www.datavis.ca
> >> Toronto, ONT  M3J 1P3 CANADA
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Sep  2 22:41:01 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 2 Sep 2014 14:41:01 -0600
Subject: [R] Overwriting a procedure
In-Reply-To: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>
References: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>
Message-ID: <CAFEqCdw2UpyecMkiCQvvT+aGB299UKeF3n_45d0jpXWmhAF4ZQ@mail.gmail.com>

A perhaps better approach would be to have the functions that
currently call fixx accept an argument of a function to use.  It could
default to fixx, but if the caller passed in a new function it would
use that function instead.

If you really want to overwrite a function inside of a package
namespace then look at the assignInNamespace function in the utils
package (but note the warning in the description on the help page).

On Tue, Sep 2, 2014 at 12:45 PM, Steven Yen <syen04 at gmail.com> wrote:
> Is there a way to over-write a procedure (subroutine)?
>
> I include a default procedure fixx in a list of procedures which are
> compiled into a package. By default, the procedure deliver the data matrix
> x.
>
> fixx <- function(x){
> result <- list(x=x)
> return(result)
> }
>
> In some applications, I have transformations (such as squared terms) in some
> column(s) in x. So I include the following procedure in the mail (calling)
> program, hoping to over-write the default procedure under the same name in
> the package (which is the way other languages works, e.g., Gauss):
>
> fixx <- function(x){
> x[,6]<-x[,5]^2/10
> result <- list(x=x)
> return(result)
> }
>
> This does not seem to work. The procedure in the main (calling) program
> seems to get ignored. Any idea? Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From dwinsemius at comcast.net  Tue Sep  2 23:28:31 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Sep 2014 14:28:31 -0700
Subject: [R] Detect expired RSQLiteConnection?
In-Reply-To: <5405B8FA.908@gmail.com>
References: <5405B8FA.908@gmail.com>
Message-ID: <0015811F-A900-4551-99E6-F48B18C86434@comcast.net>


On Sep 2, 2014, at 5:32 AM, Duncan Murdoch wrote:

> Is there a test for an expired RSQLiteConnection?  For example, if I run
> 
> library(RSQLite)
> f <- tempfile()
> con <- dbConnect(SQLite(), f)
> dbDisconnect(con)
> con
> 
> then I get
> 
>> con
> <Expired SQLiteConnection: DBI CON (11737, 2)>
> 
> and most operations using it give errors. (In my case I have a
> persistent connection object, but if I save the workspace and then
> reload it, I get the expired connection.) I'd like to detect this case.
> Do I need to use try(), or parse the result of printing it?
> 

Noodling through the S4 and then the S3 code I found:

?isIdCurrent as the test in `sqliteCloseConnection`
> 

-- 

David Winsemius
Alameda, CA, USA


From h.wickham at gmail.com  Tue Sep  2 23:42:42 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 2 Sep 2014 16:42:42 -0500
Subject: [R] Detect expired RSQLiteConnection?
In-Reply-To: <5405B8FA.908@gmail.com>
References: <5405B8FA.908@gmail.com>
Message-ID: <CABdHhvFXRrPc21FFXcYdEfMcBBSceLzu1-sYZ25V1NCVgqtrvA@mail.gmail.com>

DBI 0.3 (just released to CRAN) includes a new generic, dbIsValid(),
for exactly this purpose. Unfortunately no packages implement a method
for it yet, but eventually it will be the right way to detect this
problem.

(I'm now the maintainer for RSQLite, so I added this to my to do list:
https://github.com/rstats-db/RSQLite/issues/36. Pull requests are very
welcome!)

Hadley

On Tue, Sep 2, 2014 at 7:32 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> Is there a test for an expired RSQLiteConnection?  For example, if I run
>
> library(RSQLite)
> f <- tempfile()
> con <- dbConnect(SQLite(), f)
> dbDisconnect(con)
> con
>
> then I get
>
>> con
> <Expired SQLiteConnection: DBI CON (11737, 2)>
>
> and most operations using it give errors. (In my case I have a
> persistent connection object, but if I save the workspace and then
> reload it, I get the expired connection.) I'd like to detect this case.
>  Do I need to use try(), or parse the result of printing it?
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From murdoch.duncan at gmail.com  Wed Sep  3 00:01:15 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 02 Sep 2014 18:01:15 -0400
Subject: [R] Detect expired RSQLiteConnection?
In-Reply-To: <0015811F-A900-4551-99E6-F48B18C86434@comcast.net>
References: <5405B8FA.908@gmail.com>
	<0015811F-A900-4551-99E6-F48B18C86434@comcast.net>
Message-ID: <54063E2B.6000109@gmail.com>

On 02/09/2014, 5:28 PM, David Winsemius wrote:
> 
> On Sep 2, 2014, at 5:32 AM, Duncan Murdoch wrote:
> 
>> Is there a test for an expired RSQLiteConnection?  For example, if I run
>>
>> library(RSQLite)
>> f <- tempfile()
>> con <- dbConnect(SQLite(), f)
>> dbDisconnect(con)
>> con
>>
>> then I get
>>
>>> con
>> <Expired SQLiteConnection: DBI CON (11737, 2)>
>>
>> and most operations using it give errors. (In my case I have a
>> persistent connection object, but if I save the workspace and then
>> reload it, I get the expired connection.) I'd like to detect this case.
>> Do I need to use try(), or parse the result of printing it?
>>
> 
> Noodling through the S4 and then the S3 code I found:
> 
> ?isIdCurrent as the test in `sqliteCloseConnection`
>>
> 

Thanks!  (And this makes it look like an implementation of dbIsValid
might be easy.)

Duncan Murdoch


From lucy.leigh at newcastle.edu.au  Wed Sep  3 03:52:09 2014
From: lucy.leigh at newcastle.edu.au (Lucy Leigh)
Date: Wed, 3 Sep 2014 01:52:09 +0000
Subject: [R] Simulating from a Weibull distribution
Message-ID: <8cf0886fc803468e8125a0e47266ec18@HKXPR04MB056.apcprd04.prod.outlook.com>

Hi,
I wish to simulate some data from a Weibull distribution. The rweibull function in R uses the parameterisation

'with shape parameter a and scale parameter b has density given by f(x) = (a/b) (x/b)^(a-1) exp(- (x/b)^a)'.

However, it would be much more useful for me to simulate data using a different parameterisation of the

Weibull, with shape a1 and scale b1,  namely f(x) = a1*b1*x^(a1-1)exp(-b1*x^a1).

However I'm not sure how to do this, as I have only ever used the random generators that come pre-programmed in R.

Is there a package or example someone can point me to that demonstrates how to simulate data from any given distribution?

Cheers,

Lucy




	[[alternative HTML version deleted]]


From jwiley.psych at gmail.com  Wed Sep  3 04:04:17 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 3 Sep 2014 12:04:17 +1000
Subject: [R] Simulating from a Weibull distribution
In-Reply-To: <8cf0886fc803468e8125a0e47266ec18@HKXPR04MB056.apcprd04.prod.outlook.com>
References: <8cf0886fc803468e8125a0e47266ec18@HKXPR04MB056.apcprd04.prod.outlook.com>
Message-ID: <CANz9Z_K9iHN_2ajki-A3LK8-0r1TAuubLLAekd8wkSwa99doeA@mail.gmail.com>

Hi Lucy,

Try the gamlss.dist package, specifically the rWEI2() function.

Cheers,

Josh


On Wed, Sep 3, 2014 at 11:52 AM, Lucy Leigh <lucy.leigh at newcastle.edu.au>
wrote:

> Hi,
> I wish to simulate some data from a Weibull distribution. The rweibull
> function in R uses the parameterisation
>
> 'with shape parameter a and scale parameter b has density given by f(x) =
> (a/b) (x/b)^(a-1) exp(- (x/b)^a)'.
>
> However, it would be much more useful for me to simulate data using a
> different parameterisation of the
>
> Weibull, with shape a1 and scale b1,  namely f(x) =
> a1*b1*x^(a1-1)exp(-b1*x^a1).
>
> However I'm not sure how to do this, as I have only ever used the random
> generators that come pre-programmed in R.
>
> Is there a package or example someone can point me to that demonstrates
> how to simulate data from any given distribution?
>
> Cheers,
>
> Lucy
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Sep  3 04:10:13 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 02 Sep 2014 22:10:13 -0400
Subject: [R] Simulating from a Weibull distribution
In-Reply-To: <8cf0886fc803468e8125a0e47266ec18@HKXPR04MB056.apcprd04.prod.outlook.com>
References: <8cf0886fc803468e8125a0e47266ec18@HKXPR04MB056.apcprd04.prod.outlook.com>
Message-ID: <54067885.3090608@gmail.com>

On 02/09/2014, 9:52 PM, Lucy Leigh wrote:
> Hi,
> I wish to simulate some data from a Weibull distribution. The rweibull function in R uses the parameterisation
> 
> 'with shape parameter a and scale parameter b has density given by f(x) = (a/b) (x/b)^(a-1) exp(- (x/b)^a)'.
> 
> However, it would be much more useful for me to simulate data using a different parameterisation of the
> 
> Weibull, with shape a1 and scale b1,  namely f(x) = a1*b1*x^(a1-1)exp(-b1*x^a1).
> 
> However I'm not sure how to do this, as I have only ever used the random generators that come pre-programmed in R.
> 
> Is there a package or example someone can point me to that demonstrates how to simulate data from any given distribution?

That's the same distribution, just with the parameters specified
differently.  The correspondence is

a1 = a
b1 = b^(-a)

or

a = a1
b = b1^(-1/a1)

Duncan Murdoch


From lucy.leigh at newcastle.edu.au  Wed Sep  3 04:56:51 2014
From: lucy.leigh at newcastle.edu.au (Lucy Leigh)
Date: Wed, 3 Sep 2014 02:56:51 +0000
Subject: [R] Simulating from a Weibull distribution
In-Reply-To: <CANz9Z_K9iHN_2ajki-A3LK8-0r1TAuubLLAekd8wkSwa99doeA@mail.gmail.com>
References: <8cf0886fc803468e8125a0e47266ec18@HKXPR04MB056.apcprd04.prod.outlook.com>
	<CANz9Z_K9iHN_2ajki-A3LK8-0r1TAuubLLAekd8wkSwa99doeA@mail.gmail.com>
Message-ID: <80fe1e0b6f734694a86b159e5d2e0d9c@HKXPR04MB056.apcprd04.prod.outlook.com>

Awesome, thankyou!

From: Joshua Wiley [mailto:jwiley.psych at gmail.com]
Sent: Wednesday, 3 September 2014 12:04 PM
To: Lucy Leigh
Cc: r-help at R-project.org
Subject: Re: [R] Simulating from a Weibull distribution

Hi Lucy,

Try the gamlss.dist package, specifically the rWEI2() function.

Cheers,

Josh

On Wed, Sep 3, 2014 at 11:52 AM, Lucy Leigh <lucy.leigh at newcastle.edu.au<mailto:lucy.leigh at newcastle.edu.au>> wrote:
Hi,
I wish to simulate some data from a Weibull distribution. The rweibull function in R uses the parameterisation

'with shape parameter a and scale parameter b has density given by f(x) = (a/b) (x/b)^(a-1) exp(- (x/b)^a)'.

However, it would be much more useful for me to simulate data using a different parameterisation of the

Weibull, with shape a1 and scale b1,  namely f(x) = a1*b1*x^(a1-1)exp(-b1*x^a1).

However I'm not sure how to do this, as I have only ever used the random generators that come pre-programmed in R.

Is there a package or example someone can point me to that demonstrates how to simulate data from any given distribution?

Cheers,

Lucy




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

	[[alternative HTML version deleted]]


From xie at yihui.name  Wed Sep  3 06:07:57 2014
From: xie at yihui.name (Yihui Xie)
Date: Tue, 2 Sep 2014 23:07:57 -0500
Subject: [R] shiny datatables column filtering plugin
In-Reply-To: <CAOLJphmztzATPeD66rtni5Xk+yeHscT+72OTsuedN_+GAEb0TA@mail.gmail.com>
References: <CAOLJphmztzATPeD66rtni5Xk+yeHscT+72OTsuedN_+GAEb0TA@mail.gmail.com>
Message-ID: <CANROs4eHtNagFq91+iC70uT9cc4ug9k6EW9O0FDHSLp3LY=r6w@mail.gmail.com>

I just tested it and this plugin does not seem to work with the new
.DataTable() API in DataTables 1.10.x, so I guess it is unlikely to
make it work in (the current development version of) shiny. It is not
in the official list of plugins, either:
http://www.datatables.net/extensions/index

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Tue, Sep 2, 2014 at 11:59 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Greetings,
>
> I am currently exploring some capabilities of the 'Shiny' package.  I am
> currently working with the most recent version of 'shiny' from the rstudio
> github repository (version - 0.10.1.9006) in order to use the most up to
> date datatables plugin.  Using the ggplot2 diamonds dataset, I can easily
> set columns as unsearchable (commented out below) and I could also subset
> out all the 'Ideal' diamonds for example, however I cannot filter out
> multiple conditions such as 'Ideal' and 'Fair' diamonds together.  From my
> searching, this multiple filtering can be done with checkboxes from the
> column using the jquery column filtering plugin (
> http://jquery-datatables-column-filter.googlecode.com/svn/trunk/checkbox.html).
> Despite this, I cannot get this plugin to work with my shiny app.  Any
> insight would be appreciated.
>
> library(shiny)
> library(ggplot2)
> runApp(
>   list(ui = basicPage(
>     h1('Diamonds DataTable with TableTools'),
>
>     # added column filter plugin
>     singleton(tags$head(tags$script(src='https://code.google.com/p/jquery-datatables-column-filter/source/browse/trunk/media/js/jquery.dataTables.columnFilter.js',
> type='text/javascript'))),
>     dataTableOutput("mytable")
>   )
>   ,server = function(input, output) {
>     output$mytable = renderDataTable({
>       diamonds[,1:6]
>     }, options = list(
>       pageLength = 10,#       columnDefs = I('[{"targets": [0,1],
> "searchable": false}]')
>       columnFilter = I('[{
>                         columnDefs: ["targets": [0,1], type: "checkbox"]
>                         }]')
>
>     )
>     )
>   }
>   ))
>
>
>
> Charles


From heather.h.kettrey at vanderbilt.edu  Wed Sep  3 06:29:33 2014
From: heather.h.kettrey at vanderbilt.edu (Heather Kettrey)
Date: Tue, 2 Sep 2014 23:29:33 -0500
Subject: [R] Covariance between two dichotomous variables
Message-ID: <CAGcnpaQy9M1kW+9OqDRm5Ayj78hOz8rdy=8Oq5VxAB+uAVr2AQ@mail.gmail.com>

Hi,

I am trying to test a mediation hypothesis using coefficients from logistic
regression analyses (x, m, and y are all dichotomous). I am running a test
of significance using MacKinnon and Dwyer's adaptation of Sobel's test
(i.e., correcting for different scales of coefficients in cases of a
dichotomous outcome).

In order to make this correction I need to compute the covariance between x
and m. I have searched various R packages and the R-help page archive and
cannot find a way to do this in R.

Does anyone know how to compute the covariance between two dichotomous
variables in R? It seems like there should be a very simple answer to this
question, but I cannot find it.

Thanks in advance!

Heather


-- 
Heather Hensman Kettrey
PhD Candidate
Department of Sociology
Vanderbilt University

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Sep  3 06:49:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Sep 2014 21:49:49 -0700
Subject: [R] Simulating from a Weibull distribution
In-Reply-To: <8cf0886fc803468e8125a0e47266ec18@HKXPR04MB056.apcprd04.prod.outlook.com>
References: <8cf0886fc803468e8125a0e47266ec18@HKXPR04MB056.apcprd04.prod.outlook.com>
Message-ID: <689984AA-0265-4D7A-8845-30E6B34EFB6F@comcast.net>


On Sep 2, 2014, at 6:52 PM, Lucy Leigh wrote:

> Hi,
> I wish to simulate some data from a Weibull distribution. The rweibull function in R uses the parameterisation
> 
> 'with shape parameter a and scale parameter b has density given by f(x) = (a/b) (x/b)^(a-1) exp(- (x/b)^a)'.
> 
> However, it would be much more useful for me to simulate data using a different parameterisation of the
> 
> Weibull, with shape a1 and scale b1,  namely f(x) = a1*b1*x^(a1-1)exp(-b1*x^a1).
> 
> However I'm not sure how to do this, as I have only ever used the random generators that come pre-programmed in R.
> 
> Is there a package or example someone can point me to that demonstrates how to simulate data from any given distribution?

You could look at an alternative parametrization in pkg:survival. An exmaple in the survreg docs says:

# Weibull parametrisation
y<-rweibull(1000, shape=2, scale=5)

survreg(Surv(y)~1, dist="weibull")
# survreg scale parameter maps to 1/shape, linear predictor to log(scale)





David Winsemius
Alameda, CA, USA


From bradknox at mit.edu  Wed Sep  3 02:54:12 2014
From: bradknox at mit.edu (W Bradley Knox)
Date: Tue, 2 Sep 2014 19:54:12 -0500
Subject: [R] wilcox.test - difference between p-values of R and online
	calculators
Message-ID: <CAFE=h4B0QpXnU2avD=EiqcJpOrTszC6zJhwC1q5E+jfw8dpwDQ@mail.gmail.com>

Hi.

I'm taking the long-overdue step of moving from using online calculators to
compute results for Mann-Whitney U tests to a more streamlined system
involving R.

However, I'm finding that R computes a different result than the 3 online
calculators that I've used before (all of which approximately agree). These
calculators are here:

http://elegans.som.vcu.edu/~leon/stats/utest.cgi
http://vassarstats.net/utest.html
http://www.socscistatistics.com/tests/mannwhitney/

An example calculation is

*wilcox.test(c(359,359,359,359,359,359,335,359,359,359,359,359,359,359,359,359,359,359,359,359,359,303,359,359,359),c(332,85,359,359,359,220,231,300,359,237,359,183,286,355,250,105,359,359,298,359,359,359,28.6,359,359,128))*

which prints









*Wilcoxon rank sum test with continuity correction  data: c(359, 359, 359,
359, 359, 359, 335, 359, 359, 359, 359, 359, and c(332, 85, 359, 359, 359,
220, 231, 300, 359, 237, 359, 183, 359, 359, 359, 359, 359, 359, 359, 359,
359, 303, 359, 359, and 286, 355, 250, 105, 359, 359, 298, 359, 359, 359,
28.6, 359, 359) and 359, 128)  W = 485, p-value = 0.0002594 alternative
hypothesis: true location shift is not equal to 0 Warning message: In
wilcox.test.default(c(359, 359, 359, 359, 359, 359, 335, 359, : cannot
compute exact p-value with ties*


However, all of the online calculators find p-values close to 0.0025, 10x
the value output by R. All results are for a two-tailed case. Importantly,
the W value computed by R *does agree* with the U values output by the
first two online calculators listed above, yet it has a different p-value.

Can anyone shed some light on how and why R's calculation differs from that
of these online calculators? Thanks for your time.

____________________
W. Bradley Knox, PhD
http://bradknox.net
bradknox at mit.edu

	[[alternative HTML version deleted]]


From tal.galili at gmail.com  Wed Sep  3 12:23:53 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Wed, 3 Sep 2014 13:23:53 +0300
Subject: [R] wilcox.test - difference between p-values of R and online
	calculators
In-Reply-To: <CAFE=h4B0QpXnU2avD=EiqcJpOrTszC6zJhwC1q5E+jfw8dpwDQ@mail.gmail.com>
References: <CAFE=h4B0QpXnU2avD=EiqcJpOrTszC6zJhwC1q5E+jfw8dpwDQ@mail.gmail.com>
Message-ID: <CANdJ3dVsr4fz6hs-dm3f61DfQf+JijgE=XW-+XyziSQZK6NjXQ@mail.gmail.com>

It seems your numbers has ties. What happens if you run wilcox.test with
correct=FALSE, will the results be the same as the online calculators?



----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------



On Wed, Sep 3, 2014 at 3:54 AM, W Bradley Knox <bradknox at mit.edu> wrote:

> Hi.
>
> I'm taking the long-overdue step of moving from using online calculators to
> compute results for Mann-Whitney U tests to a more streamlined system
> involving R.
>
> However, I'm finding that R computes a different result than the 3 online
> calculators that I've used before (all of which approximately agree). These
> calculators are here:
>
> http://elegans.som.vcu.edu/~leon/stats/utest.cgi
> http://vassarstats.net/utest.html
> http://www.socscistatistics.com/tests/mannwhitney/
>
> An example calculation is
>
>
> *wilcox.test(c(359,359,359,359,359,359,335,359,359,359,359,359,359,359,359,359,359,359,359,359,359,303,359,359,359),c(332,85,359,359,359,220,231,300,359,237,359,183,286,355,250,105,359,359,298,359,359,359,28.6,359,359,128))*
>
> which prints
>
>
>
>
>
>
>
>
>
> *Wilcoxon rank sum test with continuity correction  data: c(359, 359, 359,
> 359, 359, 359, 335, 359, 359, 359, 359, 359, and c(332, 85, 359, 359, 359,
> 220, 231, 300, 359, 237, 359, 183, 359, 359, 359, 359, 359, 359, 359, 359,
> 359, 303, 359, 359, and 286, 355, 250, 105, 359, 359, 298, 359, 359, 359,
> 28.6, 359, 359) and 359, 128)  W = 485, p-value = 0.0002594 alternative
> hypothesis: true location shift is not equal to 0 Warning message: In
> wilcox.test.default(c(359, 359, 359, 359, 359, 359, 335, 359, : cannot
> compute exact p-value with ties*
>
>
> However, all of the online calculators find p-values close to 0.0025, 10x
> the value output by R. All results are for a two-tailed case. Importantly,
> the W value computed by R *does agree* with the U values output by the
> first two online calculators listed above, yet it has a different p-value.
>
> Can anyone shed some light on how and why R's calculation differs from that
> of these online calculators? Thanks for your time.
>
> ____________________
> W. Bradley Knox, PhD
> http://bradknox.net
> bradknox at mit.edu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From deter088 at umn.edu  Wed Sep  3 14:12:21 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 3 Sep 2014 07:12:21 -0500
Subject: [R] shiny datatables column filtering plugin
In-Reply-To: <CANROs4eHtNagFq91+iC70uT9cc4ug9k6EW9O0FDHSLp3LY=r6w@mail.gmail.com>
References: <CAOLJphmztzATPeD66rtni5Xk+yeHscT+72OTsuedN_+GAEb0TA@mail.gmail.com>
	<CANROs4eHtNagFq91+iC70uT9cc4ug9k6EW9O0FDHSLp3LY=r6w@mail.gmail.com>
Message-ID: <CAOLJphmzx70OSZXGcNWnU+S3fOoAbeWtUySt6oMXQMusnx8xeA@mail.gmail.com>

Thank you for checking Yihui, on the off chance are you familiar with any
other methods to filter on multiple conditions?


On Tue, Sep 2, 2014 at 11:07 PM, Yihui Xie <xie at yihui.name> wrote:

> I just tested it and this plugin does not seem to work with the new
> .DataTable() API in DataTables 1.10.x, so I guess it is unlikely to
> make it work in (the current development version of) shiny. It is not
> in the official list of plugins, either:
> http://www.datatables.net/extensions/index
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
>
>
> On Tue, Sep 2, 2014 at 11:59 AM, Charles Determan Jr <deter088 at umn.edu>
> wrote:
> > Greetings,
> >
> > I am currently exploring some capabilities of the 'Shiny' package.  I am
> > currently working with the most recent version of 'shiny' from the
> rstudio
> > github repository (version - 0.10.1.9006) in order to use the most up to
> > date datatables plugin.  Using the ggplot2 diamonds dataset, I can easily
> > set columns as unsearchable (commented out below) and I could also subset
> > out all the 'Ideal' diamonds for example, however I cannot filter out
> > multiple conditions such as 'Ideal' and 'Fair' diamonds together.  From
> my
> > searching, this multiple filtering can be done with checkboxes from the
> > column using the jquery column filtering plugin (
> >
> http://jquery-datatables-column-filter.googlecode.com/svn/trunk/checkbox.html
> ).
> > Despite this, I cannot get this plugin to work with my shiny app.  Any
> > insight would be appreciated.
> >
> > library(shiny)
> > library(ggplot2)
> > runApp(
> >   list(ui = basicPage(
> >     h1('Diamonds DataTable with TableTools'),
> >
> >     # added column filter plugin
> >     singleton(tags$head(tags$script(src='
> https://code.google.com/p/jquery-datatables-column-filter/source/browse/trunk/media/js/jquery.dataTables.columnFilter.js
> ',
> > type='text/javascript'))),
> >     dataTableOutput("mytable")
> >   )
> >   ,server = function(input, output) {
> >     output$mytable = renderDataTable({
> >       diamonds[,1:6]
> >     }, options = list(
> >       pageLength = 10,#       columnDefs = I('[{"targets": [0,1],
> > "searchable": false}]')
> >       columnFilter = I('[{
> >                         columnDefs: ["targets": [0,1], type: "checkbox"]
> >                         }]')
> >
> >     )
> >     )
> >   }
> >   ))
> >
> >
> >
> > Charles
>


Charles

	[[alternative HTML version deleted]]


From ingfimo at gmail.com  Wed Sep  3 14:28:13 2014
From: ingfimo at gmail.com (Filippo Monari)
Date: Wed, 03 Sep 2014 13:28:13 +0100
Subject: [R] .C and .Fortran
Message-ID: <5407095D.9020503@gmail.com>

Hi,
I'd like to know what is the difference between the functions .C() and 
.Fortran.
I noticed that by enclosing my F90 subroutines in modules .Fortran() 
can't find them any more in the load table, while .C() still can. I also 
checked that the subroutine was loaded with the is.loaded() function...
So can anyone explain to me the difference and which is better to use?
Thanks in advance,
Filippo


From friendly at yorku.ca  Wed Sep  3 14:52:43 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 03 Sep 2014 08:52:43 -0400
Subject: [R] frequencies of a discrete numeric variable, including zeros
In-Reply-To: <002a01cfc6e7$134de210$39e9a630$@mcmaster.ca>
References: <5405FE63.5030007@yorku.ca>
	<002a01cfc6e7$134de210$39e9a630$@mcmaster.ca>
Message-ID: <54070F1B.50805@yorku.ca>

Thanks to all who replied to this thread.

To summarize, John Fox and William Dunlap's suggestion amounts to this 
plot, where it
becomes *crucial* to eliminate the zeros (otherwise they would not be 
distinguishable
from the counts of 1, with points()):

# Fox/Dunlap plot, using plot.table method
art.tab0 <- table(art)
plot(art.tab0, ylab="Frequency", xlab="Number of articles")
points(as.numeric(names(art.tab0)), art.tab0, pch=16)

Here, I actually prefer the barplot, using factor() to retain the zeros:

# coerce to a factor, then use table()
art.fac <- factor(art, levels = 0:19)
art.tab <- table(art.fac)
barplot(art.tab, ylab="Frequency", xlab="Number of articles")

However, the frequencies for small values of art dominate the display, 
and I'm contemplating a
Poisson regression anyway, so why not plot on a log scale:

# plot on log scale, but start at 1 to avoid log(0)
barplot(art.tab+1, ylab="log(Frequency+1)", xlab="Number of articles", 
log="y")

# plot on log scale, directly
barplot(log(art.tab+1), ylab="log(Frequency+1)", xlab="Number of articles")

The first method, using log="y" gives axis labels on the scale of frequency.

best,
-Michael


On 9/2/2014 3:49 PM, John Fox wrote:
> Hi Michael,
>
> I think that histograms are intrinsically misleading for discrete data, and
> that while bar graphs are an improvement, they also invite
> misinterpretation. I generally do something like this:
>
> f <- table(factor(art, levels=0:19))
> plot(as.numeric(names(f)), as.numeric(f), type="h",
>      xlab="art", ylab="frequency", axes=FALSE)
> axis(1, pos=0, at=0:19)
> axis(2)
> points(as.numeric(names(f)), f, pch=16)
> abline(h=0)
>
>
> Actually, I prefer omitting the points corresponding to 0 counts, which is
> even simpler:
>
> f <- table(art)
> plot(as.numeric(names(f)), as.numeric(f), type="h",
>      xlab="art", ylab="frequency", axes=FALSE)
> axis(1, pos=0, at=min(art):max(art))
> axis(2)
> points(as.numeric(names(f)), f, pch=16)
> abline(h=0)
>
>
> Best,
>   John
>
> -----------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox/
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Michael Friendly
>> Sent: Tuesday, September 02, 2014 1:29 PM
>> To: R-help
>> Subject: [R] frequencies of a discrete numeric variable, including
>> zeros
>>
>> The data vector, art, given below using dput(),  gives a set of
>> discrete
>> numeric values for 915 observations,
>> in the range of 0:19.  I want to make some plots of the frequency
>> distribution, but the standard
>> tools (hist, barplot, table) don't give me what I want to make a custom
>> plot due to 0 frequencies
>> for some of the 0:19 counts.
>>
>> table() excludes the values of art that occur with zero frequency, and
>> these are excluded in
>> barplot()
>>   > table(art)
>> art
>>     0   1   2   3   4   5   6   7   8   9  10  11  12  16  19
>> 275 246 178  84  67  27  17  12   1   2   1   1   2   1   1
>>   > barplot(table(art))
>>
>>
>> A direct calculation, using colSums of outer() gives me the values I
>> want, but this seems unnecessarily
>> complicated for this simple task.
>>
>>   > (art.freq <- colSums(outer(art, 0:19, `==`)))
>>    [1] 275 246 178  84  67  27  17  12   1   2   1   1   2   0   0 0
>> 1   0   0   1
>>   >  barplot(art.freq, names.arg=0:19)
>>
>>
>> Moreover, I was surprised by the result of hist() on this data, because
>> the 0 & 1 counts from
>> the above were combined in this call:
>>
>>   > art.hist <- hist(art, breaks=0:19, plot=FALSE)
>>   > art.hist$breaks
>>    [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
>>   > art.hist$counts
>>    [1] 521 178  84  67  27  17  12   1   2   1   1   2   0   0   0 1
>> 0   0   1
>>
>> Is there some option I missed here?
>>
>> The data:
>>
>>   > dput(art)
>> c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
>> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
>> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 9L, 9L, 10L,
>> 11L, 12L, 12L, 16L, 19L)
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From nmprista at ipma.pt  Wed Sep  3 13:07:45 2014
From: nmprista at ipma.pt (Nuno Prista)
Date: Wed, 03 Sep 2014 12:07:45 +0100
Subject: [R] strange date format after extracting calendar data with RSQLite
Message-ID: <5406F681.2000907@ipma.pt>

Hi,

I have recently downloaded RSQLite with intention of using it to access 
googlecalendar data stored in Thunderbird "cache.sqlite" and 
"local.sqlite". Thunderbird exports the data just fine as a .ics file 
but when I access it directly from R using RSQLite function "dbGetQuery" 
I get strange dates. As an examples:

a date stored as
20140818
appears to me in R as
1129528320

a date stored as
20140823
appears to me in R as
-1663476736

I have not been able to make sense of this and I have found no way to 
convert it back. I am wondering if anyone has experienced these issues 
or have any suggestions what is causing this and how to correct it.

Thank you,

Nuno


	[[alternative HTML version deleted]]


From pgauthi1 at lakeheadu.ca  Wed Sep  3 15:15:35 2014
From: pgauthi1 at lakeheadu.ca (Patrick Gauthier)
Date: Wed, 3 Sep 2014 09:15:35 -0400
Subject: [R] predictNLS {propagate} bug for multiple predictors?
Message-ID: <CAKzvatwAZK5V5z2ORvVUy+Uvf5LazGB3Ha0eg8Y7P02NPw4OJQ@mail.gmail.com>

Many R users have requested means to generate prediction/confidence
intervals
for their non-linear models in R. The propagate packages offers this
service. However, I'm having issues when applying predictNLS to my model.
Has anyone else had issues with predictNLS?

Here is my simple problem.

t <- c(194.84, 95.62, 40.87, 31.64, 0.00)
m <- c(0.00, 2.29, 4.72, 10.95, 28.36)
t0 <- t[1]
m0 <- m[5]

dat <- data.frame(t = t, m = m)

nlls <- nls(m ~ (m0 ^ (1 / lambda) - (t * m0 / t0) ^ (1 / lambda)) ^ lambda,
                 start=list(lambda = 1), data = dat)

xv <- seq(0,t0, length.out = 100)
library(propagate)

predictNLS forces me to redefine m0 and t0, which are constants in the
model.

predictNLS(nlls, newdata = data.frame(t = xv))

/Error in predictNLS(nlls, newdata = data.frame(t = xv, t0 = t0, m0 = m0)) :
  newdata should have name(s) m0tt0!/

OK, predict.nls doesn't have this issue. But, let's just give it what it
wants. Notice the predictors needs to be defined in the right order as
well. .

predictNLS(nlls, newdata = data.frame(m0 = m0, t = xv, t0 = t0))

/Propagating predictor value #1 ...
Error in propagate(expr = EXPR, data = DF, use.cov = COV, alpha = alpha,  :
  Names of input dataframe and var-cov matrix do not match!/

I'm not sure what else I can do here to fix the problem, as the issue seems
to be related to names, which predictNLS has accepted until it's internal
use of propagate(). My model is quite simple (i.e., plot the data and see).
The predictNLS works fine on the example provided in the packages
documentation which has only one predictor. Could this be where
the error is being generated (i.e., multiple predictors)? What am I doing
wrong here?

Thanks for any help/advice,

-- 
Patrick Gauthier
PhD Candidate
Faculty of Natural Resources Management
Lakehead University
Office: BB-1007-D (tel. 807 766-7127)
Lab: BB-1071-A (tel. 807 343-8739)
http://abel.lakeheadu.ca/index.shtml
http://forward.lakeheadu.ca/gradstudents.htm

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Sep  3 16:10:50 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 3 Sep 2014 14:10:50 +0000
Subject: [R] wilcox.test - difference between p-values of R and
	online	calculators
In-Reply-To: <CANdJ3dVsr4fz6hs-dm3f61DfQf+JijgE=XW-+XyziSQZK6NjXQ@mail.gmail.com>
References: <CAFE=h4B0QpXnU2avD=EiqcJpOrTszC6zJhwC1q5E+jfw8dpwDQ@mail.gmail.com>
	<CANdJ3dVsr4fz6hs-dm3f61DfQf+JijgE=XW-+XyziSQZK6NjXQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F94CB5@mb02.ads.tamu.edu>

That does not change the results. The problem is likely to be the way ties are handled. The first sample has 25 values of which 23 are identical (359). The second sample has 26 values of which 12 are identical (359). The difference between the implementations may be a result of the way the ties are ranked. For example the R function rank() offers 5 different ways of handling the rank on tied observations. With so many ties, that could make a substantial difference.

Package coin has wilxon_test() which uses Monte Carlo simulation to estimate the confidence limits.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Tal Galili
Sent: Wednesday, September 3, 2014 5:24 AM
To: W Bradley Knox
Cc: r-help at r-project.org
Subject: Re: [R] wilcox.test - difference between p-values of R and online calculators

It seems your numbers has ties. What happens if you run wilcox.test with
correct=FALSE, will the results be the same as the online calculators?



----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------



On Wed, Sep 3, 2014 at 3:54 AM, W Bradley Knox <bradknox at mit.edu> wrote:

> Hi.
>
> I'm taking the long-overdue step of moving from using online calculators to
> compute results for Mann-Whitney U tests to a more streamlined system
> involving R.
>
> However, I'm finding that R computes a different result than the 3 online
> calculators that I've used before (all of which approximately agree). These
> calculators are here:
>
> http://elegans.som.vcu.edu/~leon/stats/utest.cgi
> http://vassarstats.net/utest.html
> http://www.socscistatistics.com/tests/mannwhitney/
>
> An example calculation is
>
>
> *wilcox.test(c(359,359,359,359,359,359,335,359,359,359,359,359,359,359,359,359,359,359,359,359,359,303,359,359,359),c(332,85,359,359,359,220,231,300,359,237,359,183,286,355,250,105,359,359,298,359,359,359,28.6,359,359,128))*
>
> which prints
>
>
>
>
>
>
>
>
>
> *Wilcoxon rank sum test with continuity correction  data: c(359, 359, 359,
> 359, 359, 359, 335, 359, 359, 359, 359, 359, and c(332, 85, 359, 359, 359,
> 220, 231, 300, 359, 237, 359, 183, 359, 359, 359, 359, 359, 359, 359, 359,
> 359, 303, 359, 359, and 286, 355, 250, 105, 359, 359, 298, 359, 359, 359,
> 28.6, 359, 359) and 359, 128)  W = 485, p-value = 0.0002594 alternative
> hypothesis: true location shift is not equal to 0 Warning message: In
> wilcox.test.default(c(359, 359, 359, 359, 359, 359, 335, 359, : cannot
> compute exact p-value with ties*
>
>
> However, all of the online calculators find p-values close to 0.0025, 10x
> the value output by R. All results are for a two-tailed case. Importantly,
> the W value computed by R *does agree* with the U values output by the
> first two online calculators listed above, yet it has a different p-value.
>
> Can anyone shed some light on how and why R's calculation differs from that
> of these online calculators? Thanks for your time.
>
> ____________________
> W. Bradley Knox, PhD
> http://bradknox.net
> bradknox at mit.edu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From xie at yihui.name  Wed Sep  3 18:27:55 2014
From: xie at yihui.name (Yihui Xie)
Date: Wed, 3 Sep 2014 11:27:55 -0500
Subject: [R] shiny datatables column filtering plugin
In-Reply-To: <CAOLJphmzx70OSZXGcNWnU+S3fOoAbeWtUySt6oMXQMusnx8xeA@mail.gmail.com>
References: <CAOLJphmztzATPeD66rtni5Xk+yeHscT+72OTsuedN_+GAEb0TA@mail.gmail.com>
	<CANROs4eHtNagFq91+iC70uT9cc4ug9k6EW9O0FDHSLp3LY=r6w@mail.gmail.com>
	<CAOLJphmzx70OSZXGcNWnU+S3fOoAbeWtUySt6oMXQMusnx8xeA@mail.gmail.com>
Message-ID: <CANROs4dxBMmRu1wj+L8cqMhG-OF0-XDMm5sq66KWVw4OEbkd7w@mail.gmail.com>

The built-in version of DataTables in shiny has already supported
numeric ranges. For a numeric column x in data, if you type a,b in the
search box, the data will be filtered using a <= x <= b. The check
boxes are not supported, but you can use regular expressions (more
flexible) to achieve the same thing, e.g. (this example requires the
development version of shiny:
https://groups.google.com/forum/#!topic/shiny-discuss/-0u-wTnq_lA)

library(shiny)
runApp(list(
  ui = fluidPage(
    dataTableOutput("mytable")
  ),
  server = function(input, output) {
    output$mytable = renderDataTable(
      iris[sample(nrow(iris)), ],
      options = list(search = list(regex = TRUE))
    )
  }
))


Then you can search for ^setosa|versicolor$, which means both setosa
and versicolor in the iris data. Or 4,5 in the search box of
Sepal.Length to filter this column. Depending on what you want, this
may or may not be enough.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Wed, Sep 3, 2014 at 7:12 AM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Thank you for checking Yihui, on the off chance are you familiar with any
> other methods to filter on multiple conditions?
>
>
> On Tue, Sep 2, 2014 at 11:07 PM, Yihui Xie <xie at yihui.name> wrote:
>>
>> I just tested it and this plugin does not seem to work with the new
>> .DataTable() API in DataTables 1.10.x, so I guess it is unlikely to
>> make it work in (the current development version of) shiny. It is not
>> in the official list of plugins, either:
>> http://www.datatables.net/extensions/index
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Web: http://yihui.name
>>
>>
>> On Tue, Sep 2, 2014 at 11:59 AM, Charles Determan Jr <deter088 at umn.edu>
>> wrote:
>> > Greetings,
>> >
>> > I am currently exploring some capabilities of the 'Shiny' package.  I am
>> > currently working with the most recent version of 'shiny' from the
>> > rstudio
>> > github repository (version - 0.10.1.9006) in order to use the most up to
>> > date datatables plugin.  Using the ggplot2 diamonds dataset, I can
>> > easily
>> > set columns as unsearchable (commented out below) and I could also
>> > subset
>> > out all the 'Ideal' diamonds for example, however I cannot filter out
>> > multiple conditions such as 'Ideal' and 'Fair' diamonds together.  From
>> > my
>> > searching, this multiple filtering can be done with checkboxes from the
>> > column using the jquery column filtering plugin (
>> >
>> > http://jquery-datatables-column-filter.googlecode.com/svn/trunk/checkbox.html).
>> > Despite this, I cannot get this plugin to work with my shiny app.  Any
>> > insight would be appreciated.
>> >
>> > library(shiny)
>> > library(ggplot2)
>> > runApp(
>> >   list(ui = basicPage(
>> >     h1('Diamonds DataTable with TableTools'),
>> >
>> >     # added column filter plugin
>> >
>> > singleton(tags$head(tags$script(src='https://code.google.com/p/jquery-datatables-column-filter/source/browse/trunk/media/js/jquery.dataTables.columnFilter.js',
>> > type='text/javascript'))),
>> >     dataTableOutput("mytable")
>> >   )
>> >   ,server = function(input, output) {
>> >     output$mytable = renderDataTable({
>> >       diamonds[,1:6]
>> >     }, options = list(
>> >       pageLength = 10,#       columnDefs = I('[{"targets": [0,1],
>> > "searchable": false}]')
>> >       columnFilter = I('[{
>> >                         columnDefs: ["targets": [0,1], type: "checkbox"]
>> >                         }]')
>> >
>> >     )
>> >     )
>> >   }
>> >   ))
>> >
>> >
>> >
>> > Charles
>
>
>
> Charles


From ripley at stats.ox.ac.uk  Wed Sep  3 19:04:12 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 03 Sep 2014 18:04:12 +0100
Subject: [R] .C and .Fortran
In-Reply-To: <5407095D.9020503@gmail.com>
References: <5407095D.9020503@gmail.com>
Message-ID: <54074A0C.60002@stats.ox.ac.uk>

On 03/09/2014 13:28, Filippo Monari wrote:
> Hi,
> I'd like to know what is the difference between the functions .C() and
> .Fortran.
> I noticed that by enclosing my F90 subroutines in modules .Fortran()
> can't find them any more in the load table, while .C() still can. I also
> checked that the subroutine was loaded with the is.loaded() function...
> So can anyone explain to me the difference and which is better to use?

This is not the right list: see the posting guide.  But .Fortran is 
intended for *Fortran 77* code (as the help page says), and maps the 
supplied NAME argument in the same way as the Fortran 77 compiler does, 
which is often different from the way the C compiler does.

I would strongly recommend that new code uses .Call and a C wrapper to 
F90 code: it is a safer and more portable route.

If you want any more help, you need to follow the posting guide and

- post to R-devel,
- supply the 'at a minimum information' asked for there,
- supply the minimal example asked for, and what the messages you see are.

> Thanks in advance,
> Filippo
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From dcarlson at tamu.edu  Wed Sep  3 19:13:01 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 3 Sep 2014 17:13:01 +0000
Subject: [R] wilcox.test - difference between p-values of R and online
 calculators
In-Reply-To: <CAFE=h4DzzeR21R7cV-qUi2NXR=i=uH_7ebvt-9JAm8Zhqy-rmA@mail.gmail.com>
References: <CAFE=h4B0QpXnU2avD=EiqcJpOrTszC6zJhwC1q5E+jfw8dpwDQ@mail.gmail.com>
	<CANdJ3dVsr4fz6hs-dm3f61DfQf+JijgE=XW-+XyziSQZK6NjXQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F94CB5@mb02.ads.tamu.edu>
	<CAFE=h4DzzeR21R7cV-qUi2NXR=i=uH_7ebvt-9JAm8Zhqy-rmA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F94D78@mb02.ads.tamu.edu>

Since they all have the same W/U value, it seems likely that the difference is how the different versions adjust the standard error for ties. Here are a couple of posts addressing the issues of ties:

http://tolstoy.newcastle.edu.au/R/e8/help/09/12/9200.html
http://stats.stackexchange.com/questions/6127/which-permutation-test-implementation-in-r-to-use-instead-of-t-tests-paired-and

David C

From: wbradleyknox at gmail.com [mailto:wbradleyknox at gmail.com] On Behalf Of W Bradley Knox
Sent: Wednesday, September 3, 2014 9:20 AM
To: David L Carlson
Cc: Tal Galili; r-help at r-project.org
Subject: Re: [R] wilcox.test - difference between p-values of R and online calculators

Tal and David, thanks for your messages.

I should have added that I tried all variations of true/false values for the exact and correct parameters. Running with correct=FALSE makes only a tiny change, resulting in W = 485, p-value = 0.0002481.

At one point, I also thought that the discrepancy between R and these online calculators might come from how ties are handled, but the fact that R and two of the online calcultors reach the same U/W values seems to indicate that ties aren't the issue, since (I believe) the U or W values contain all of the information needed to calculate the p-value, assuming the number of samples is also known for each condition. (However, it's been a while since I looked into how MWU tests work, so maybe now's the time to refresh.) If that's correct, the discrepancy seems to be based in what R does with the W value that is identical to the U values of two of the online calculators. (I'm also assuming that U and W have the same meaning, which seems likely.)

- Brad

____________________
W. Bradley Knox, PhD
http://bradknox.net<http://bradknox.net/>
bradknox at mit.edu<mailto:bradknox at mit.edu>

On Wed, Sep 3, 2014 at 9:10 AM, David L Carlson <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>> wrote:
That does not change the results. The problem is likely to be the way ties are handled. The first sample has 25 values of which 23 are identical (359). The second sample has 26 values of which 12 are identical (359). The difference between the implementations may be a result of the way the ties are ranked. For example the R function rank() offers 5 different ways of handling the rank on tied observations. With so many ties, that could make a substantial difference.

Package coin has wilxon_test() which uses Monte Carlo simulation to estimate the confidence limits.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Tal Galili
Sent: Wednesday, September 3, 2014 5:24 AM
To: W Bradley Knox
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] wilcox.test - difference between p-values of R and online calculators

It seems your numbers has ties. What happens if you run wilcox.test with
correct=FALSE, will the results be the same as the online calculators?



----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com<mailto:Tal.Galili at gmail.com> |
Read me: www.talgalili.com<http://www.talgalili.com> (Hebrew) | www.biostatistics.co.il<http://www.biostatistics.co.il> (Hebrew) |
www.r-statistics.com<http://www.r-statistics.com> (English)
----------------------------------------------------------------------------------------------



On Wed, Sep 3, 2014 at 3:54 AM, W Bradley Knox <bradknox at mit.edu<mailto:bradknox at mit.edu>> wrote:

> Hi.
>
> I'm taking the long-overdue step of moving from using online calculators to
> compute results for Mann-Whitney U tests to a more streamlined system
> involving R.
>
> However, I'm finding that R computes a different result than the 3 online
> calculators that I've used before (all of which approximately agree). These
> calculators are here:
>
> http://elegans.som.vcu.edu/~leon/stats/utest.cgi
> http://vassarstats.net/utest.html
> http://www.socscistatistics.com/tests/mannwhitney/
>
> An example calculation is
>
>
> *wilcox.test(c(359,359,359,359,359,359,335,359,359,359,359,359,359,359,359,359,359,359,359,359,359,303,359,359,359),c(332,85,359,359,359,220,231,300,359,237,359,183,286,355,250,105,359,359,298,359,359,359,28.6,359,359,128))*
>
> which prints
>
>
>
>
>
>
>
>
>
> *Wilcoxon rank sum test with continuity correction  data: c(359, 359, 359,
> 359, 359, 359, 335, 359, 359, 359, 359, 359, and c(332, 85, 359, 359, 359,
> 220, 231, 300, 359, 237, 359, 183, 359, 359, 359, 359, 359, 359, 359, 359,
> 359, 303, 359, 359, and 286, 355, 250, 105, 359, 359, 298, 359, 359, 359,
> 28.6, 359, 359) and 359, 128)  W = 485, p-value = 0.0002594 alternative
> hypothesis: true location shift is not equal to 0 Warning message: In
> wilcox.test.default(c(359, 359, 359, 359, 359, 359, 335, 359, : cannot
> compute exact p-value with ties*
>
>
> However, all of the online calculators find p-values close to 0.0025, 10x
> the value output by R. All results are for a two-tailed case. Importantly,
> the W value computed by R *does agree* with the U values output by the
> first two online calculators listed above, yet it has a different p-value.
>
> Can anyone shed some light on how and why R's calculation differs from that
> of these online calculators? Thanks for your time.
>
> ____________________
> W. Bradley Knox, PhD
> http://bradknox.net
> bradknox at mit.edu<mailto:bradknox at mit.edu>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From deter088 at umn.edu  Wed Sep  3 21:09:28 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 3 Sep 2014 14:09:28 -0500
Subject: [R] shiny datatables column filtering plugin
In-Reply-To: <CANROs4dxBMmRu1wj+L8cqMhG-OF0-XDMm5sq66KWVw4OEbkd7w@mail.gmail.com>
References: <CAOLJphmztzATPeD66rtni5Xk+yeHscT+72OTsuedN_+GAEb0TA@mail.gmail.com>
	<CANROs4eHtNagFq91+iC70uT9cc4ug9k6EW9O0FDHSLp3LY=r6w@mail.gmail.com>
	<CAOLJphmzx70OSZXGcNWnU+S3fOoAbeWtUySt6oMXQMusnx8xeA@mail.gmail.com>
	<CANROs4dxBMmRu1wj+L8cqMhG-OF0-XDMm5sq66KWVw4OEbkd7w@mail.gmail.com>
Message-ID: <CAOLJphkiE=4QD4z7aKg=W5EzF68F_AHmv0o7H-0ZsnGXKK5-yg@mail.gmail.com>

Thank you Yihui, this would certainly work for me however I have having
trouble getting the regex to work appropriately.  I am using the
developmental version of shiny and have copied your code.  I launch the app
and the filtering of numbers works fine (i.e. 4,5) but the search for
setosa and versicolor gives me a blank datatable.  Is there some dependency
that I am missing that would prevent this regex to work with shiny?


On Wed, Sep 3, 2014 at 11:27 AM, Yihui Xie <xie at yihui.name> wrote:

> The built-in version of DataTables in shiny has already supported
> numeric ranges. For a numeric column x in data, if you type a,b in the
> search box, the data will be filtered using a <= x <= b. The check
> boxes are not supported, but you can use regular expressions (more
> flexible) to achieve the same thing, e.g. (this example requires the
> development version of shiny:
> https://groups.google.com/forum/#!topic/shiny-discuss/-0u-wTnq_lA)
>
> library(shiny)
> runApp(list(
>   ui = fluidPage(
>     dataTableOutput("mytable")
>   ),
>   server = function(input, output) {
>     output$mytable = renderDataTable(
>       iris[sample(nrow(iris)), ],
>       options = list(search = list(regex = TRUE))
>     )
>   }
> ))
>
>
> Then you can search for ^setosa|versicolor$, which means both setosa
> and versicolor in the iris data. Or 4,5 in the search box of
> Sepal.Length to filter this column. Depending on what you want, this
> may or may not be enough.
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
>
>
> On Wed, Sep 3, 2014 at 7:12 AM, Charles Determan Jr <deter088 at umn.edu>
> wrote:
> > Thank you for checking Yihui, on the off chance are you familiar with any
> > other methods to filter on multiple conditions?
> >
> >
> > On Tue, Sep 2, 2014 at 11:07 PM, Yihui Xie <xie at yihui.name> wrote:
> >>
> >> I just tested it and this plugin does not seem to work with the new
> >> .DataTable() API in DataTables 1.10.x, so I guess it is unlikely to
> >> make it work in (the current development version of) shiny. It is not
> >> in the official list of plugins, either:
> >> http://www.datatables.net/extensions/index
> >>
> >> Regards,
> >> Yihui
> >> --
> >> Yihui Xie <xieyihui at gmail.com>
> >> Web: http://yihui.name
> >>
> >>
> >> On Tue, Sep 2, 2014 at 11:59 AM, Charles Determan Jr <deter088 at umn.edu>
> >> wrote:
> >> > Greetings,
> >> >
> >> > I am currently exploring some capabilities of the 'Shiny' package.  I
> am
> >> > currently working with the most recent version of 'shiny' from the
> >> > rstudio
> >> > github repository (version - 0.10.1.9006) in order to use the most up
> to
> >> > date datatables plugin.  Using the ggplot2 diamonds dataset, I can
> >> > easily
> >> > set columns as unsearchable (commented out below) and I could also
> >> > subset
> >> > out all the 'Ideal' diamonds for example, however I cannot filter out
> >> > multiple conditions such as 'Ideal' and 'Fair' diamonds together.
> From
> >> > my
> >> > searching, this multiple filtering can be done with checkboxes from
> the
> >> > column using the jquery column filtering plugin (
> >> >
> >> >
> http://jquery-datatables-column-filter.googlecode.com/svn/trunk/checkbox.html
> ).
> >> > Despite this, I cannot get this plugin to work with my shiny app.  Any
> >> > insight would be appreciated.
> >> >
> >> > library(shiny)
> >> > library(ggplot2)
> >> > runApp(
> >> >   list(ui = basicPage(
> >> >     h1('Diamonds DataTable with TableTools'),
> >> >
> >> >     # added column filter plugin
> >> >
> >> > singleton(tags$head(tags$script(src='
> https://code.google.com/p/jquery-datatables-column-filter/source/browse/trunk/media/js/jquery.dataTables.columnFilter.js
> ',
> >> > type='text/javascript'))),
> >> >     dataTableOutput("mytable")
> >> >   )
> >> >   ,server = function(input, output) {
> >> >     output$mytable = renderDataTable({
> >> >       diamonds[,1:6]
> >> >     }, options = list(
> >> >       pageLength = 10,#       columnDefs = I('[{"targets": [0,1],
> >> > "searchable": false}]')
> >> >       columnFilter = I('[{
> >> >                         columnDefs: ["targets": [0,1], type:
> "checkbox"]
> >> >                         }]')
> >> >
> >> >     )
> >> >     )
> >> >   }
> >> >   ))
> >> >
> >> >
> >> >
> >> > Charles
> >
> >
> >
> > Charles
>



-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From xie at yihui.name  Wed Sep  3 22:08:51 2014
From: xie at yihui.name (Yihui Xie)
Date: Wed, 3 Sep 2014 15:08:51 -0500
Subject: [R] shiny datatables column filtering plugin
In-Reply-To: <CAOLJphkiE=4QD4z7aKg=W5EzF68F_AHmv0o7H-0ZsnGXKK5-yg@mail.gmail.com>
References: <CAOLJphmztzATPeD66rtni5Xk+yeHscT+72OTsuedN_+GAEb0TA@mail.gmail.com>
	<CANROs4eHtNagFq91+iC70uT9cc4ug9k6EW9O0FDHSLp3LY=r6w@mail.gmail.com>
	<CAOLJphmzx70OSZXGcNWnU+S3fOoAbeWtUySt6oMXQMusnx8xeA@mail.gmail.com>
	<CANROs4dxBMmRu1wj+L8cqMhG-OF0-XDMm5sq66KWVw4OEbkd7w@mail.gmail.com>
	<CAOLJphkiE=4QD4z7aKg=W5EzF68F_AHmv0o7H-0ZsnGXKK5-yg@mail.gmail.com>
Message-ID: <CANROs4cSM9hzeq3=pf6FLRr2ELVxEZhr7=cx7gNAYKY+-yHHxA@mail.gmail.com>

It looks like a problem of DataTables -- I cannot find a way to
specify the search.regex option for individual columns. You may ask
this question on the DataTables forum. Basically I was expecting this
to work:

.DataTable({
  "search": { "regex": true },
  "columnDefs": [{ "search": { "regex": true }, "targets": [0, 1, 2, 3, 4] }]
})

The global search box works, though.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Wed, Sep 3, 2014 at 2:09 PM, Charles Determan Jr <deter088 at umn.edu> wrote:
> Thank you Yihui, this would certainly work for me however I have having
> trouble getting the regex to work appropriately.  I am using the
> developmental version of shiny and have copied your code.  I launch the app
> and the filtering of numbers works fine (i.e. 4,5) but the search for setosa
> and versicolor gives me a blank datatable.  Is there some dependency that I
> am missing that would prevent this regex to work with shiny?
>
>
> On Wed, Sep 3, 2014 at 11:27 AM, Yihui Xie <xie at yihui.name> wrote:
>>
>> The built-in version of DataTables in shiny has already supported
>> numeric ranges. For a numeric column x in data, if you type a,b in the
>> search box, the data will be filtered using a <= x <= b. The check
>> boxes are not supported, but you can use regular expressions (more
>> flexible) to achieve the same thing, e.g. (this example requires the
>> development version of shiny:
>> https://groups.google.com/forum/#!topic/shiny-discuss/-0u-wTnq_lA)
>>
>> library(shiny)
>> runApp(list(
>>   ui = fluidPage(
>>     dataTableOutput("mytable")
>>   ),
>>   server = function(input, output) {
>>     output$mytable = renderDataTable(
>>       iris[sample(nrow(iris)), ],
>>       options = list(search = list(regex = TRUE))
>>     )
>>   }
>> ))
>>
>>
>> Then you can search for ^setosa|versicolor$, which means both setosa
>> and versicolor in the iris data. Or 4,5 in the search box of
>> Sepal.Length to filter this column. Depending on what you want, this
>> may or may not be enough.
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Web: http://yihui.name
>>
>>
>> On Wed, Sep 3, 2014 at 7:12 AM, Charles Determan Jr <deter088 at umn.edu>
>> wrote:
>> > Thank you for checking Yihui, on the off chance are you familiar with
>> > any
>> > other methods to filter on multiple conditions?
>> >
>> >
>> > On Tue, Sep 2, 2014 at 11:07 PM, Yihui Xie <xie at yihui.name> wrote:
>> >>
>> >> I just tested it and this plugin does not seem to work with the new
>> >> .DataTable() API in DataTables 1.10.x, so I guess it is unlikely to
>> >> make it work in (the current development version of) shiny. It is not
>> >> in the official list of plugins, either:
>> >> http://www.datatables.net/extensions/index
>> >>
>> >> Regards,
>> >> Yihui
>> >> --
>> >> Yihui Xie <xieyihui at gmail.com>
>> >> Web: http://yihui.name
>> >>
>> >>
>> >> On Tue, Sep 2, 2014 at 11:59 AM, Charles Determan Jr <deter088 at umn.edu>
>> >> wrote:
>> >> > Greetings,
>> >> >
>> >> > I am currently exploring some capabilities of the 'Shiny' package.  I
>> >> > am
>> >> > currently working with the most recent version of 'shiny' from the
>> >> > rstudio
>> >> > github repository (version - 0.10.1.9006) in order to use the most up
>> >> > to
>> >> > date datatables plugin.  Using the ggplot2 diamonds dataset, I can
>> >> > easily
>> >> > set columns as unsearchable (commented out below) and I could also
>> >> > subset
>> >> > out all the 'Ideal' diamonds for example, however I cannot filter out
>> >> > multiple conditions such as 'Ideal' and 'Fair' diamonds together.
>> >> > From
>> >> > my
>> >> > searching, this multiple filtering can be done with checkboxes from
>> >> > the
>> >> > column using the jquery column filtering plugin (
>> >> >
>> >> >
>> >> > http://jquery-datatables-column-filter.googlecode.com/svn/trunk/checkbox.html).
>> >> > Despite this, I cannot get this plugin to work with my shiny app.
>> >> > Any
>> >> > insight would be appreciated.
>> >> >
>> >> > library(shiny)
>> >> > library(ggplot2)
>> >> > runApp(
>> >> >   list(ui = basicPage(
>> >> >     h1('Diamonds DataTable with TableTools'),
>> >> >
>> >> >     # added column filter plugin
>> >> >
>> >> >
>> >> > singleton(tags$head(tags$script(src='https://code.google.com/p/jquery-datatables-column-filter/source/browse/trunk/media/js/jquery.dataTables.columnFilter.js',
>> >> > type='text/javascript'))),
>> >> >     dataTableOutput("mytable")
>> >> >   )
>> >> >   ,server = function(input, output) {
>> >> >     output$mytable = renderDataTable({
>> >> >       diamonds[,1:6]
>> >> >     }, options = list(
>> >> >       pageLength = 10,#       columnDefs = I('[{"targets": [0,1],
>> >> > "searchable": false}]')
>> >> >       columnFilter = I('[{
>> >> >                         columnDefs: ["targets": [0,1], type:
>> >> > "checkbox"]
>> >> >                         }]')
>> >> >
>> >> >     )
>> >> >     )
>> >> >   }
>> >> >   ))
>> >> >
>> >> >
>> >> >
>> >> > Charles
>> >
>> >
>> >
>> > Charles
>
>
>
>
> --
> Dr. Charles Determan, PhD
> Integrated Biosciences


From highstat at highstat.com  Wed Sep  3 22:33:18 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 03 Sep 2014 21:33:18 +0100
Subject: [R] Four available places on GLMM course in Banff
Message-ID: <54077B0E.9080100@highstat.com>

There are four remaining places on the following course:


Course: Introduction to MCMC, Linear mixed effects models and GLMM with R
When: 22-26 September, 2014
Where: Parks Canada, Banff, Canada
Flyer: http://www.highstat.com/Courses/Flyer2014_09Banff.pdf

Course website: http://www.highstat.com/statscourse.htm


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From pdalgd at gmail.com  Wed Sep  3 23:20:04 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 3 Sep 2014 23:20:04 +0200
Subject: [R] wilcox.test - difference between p-values of R and online
	calculators
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F94D78@mb02.ads.tamu.edu>
References: <CAFE=h4B0QpXnU2avD=EiqcJpOrTszC6zJhwC1q5E+jfw8dpwDQ@mail.gmail.com>
	<CANdJ3dVsr4fz6hs-dm3f61DfQf+JijgE=XW-+XyziSQZK6NjXQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F94CB5@mb02.ads.tamu.edu>
	<CAFE=h4DzzeR21R7cV-qUi2NXR=i=uH_7ebvt-9JAm8Zhqy-rmA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F94D78@mb02.ads.tamu.edu>
Message-ID: <FFDE9637-160E-4555-9C2A-E944947000D7@gmail.com>

Notice that correct=TRUE for wilcox.test refers to the continuity correction, not the correction for ties. 

You can fairly easily simulate from the exact distribution of W:

x <- c(359,359,359,359,359,359,335,359,359,359,359,
      359,359,359,359,359,359,359,359,359,359,303,359,359,359)
y <- c(332,85,359,359,359,220,231,300,359,237,359,183,286,
      355,250,105,359,359,298,359,359,359,28.6,359,359,128)
R <- rank(c(x,y))
sim <- replicate(1e6,sum(sample(R,25))) - 325

# With no ties, the ranks would be a permutation of 1:51, and we could do
sim2 <- replicate(1e6,sum(sample(1:51,25))) - 325

In either case, the p-value is the probability that W >= 485 or W <= 165, and

> mean(sim >= 485 | sim <= 165) 
[1] 0.000151
> mean(sim2 >= 485 | sim2 <= 165) 
[1] 0.002182

Also, try

plot(density(sim))
lines(density(sim2))

and notice that the distribution of sim is narrower than that of sim2 (hence the smaller p-value with tie correction), but also that the normal approximationtion is not nearly as good as for the untied case. The "clumpiness" is due to the fact that 35 of the ranks have the maximum value of 34 (corresponding to the original 359's).

-pd 

On 03 Sep 2014, at 19:13 , David L Carlson <dcarlson at tamu.edu> wrote:

> Since they all have the same W/U value, it seems likely that the difference is how the different versions adjust the standard error for ties. Here are a couple of posts addressing the issues of ties:
> 
> http://tolstoy.newcastle.edu.au/R/e8/help/09/12/9200.html
> http://stats.stackexchange.com/questions/6127/which-permutation-test-implementation-in-r-to-use-instead-of-t-tests-paired-and
> 
> David C
> 
> From: wbradleyknox at gmail.com [mailto:wbradleyknox at gmail.com] On Behalf Of W Bradley Knox
> Sent: Wednesday, September 3, 2014 9:20 AM
> To: David L Carlson
> Cc: Tal Galili; r-help at r-project.org
> Subject: Re: [R] wilcox.test - difference between p-values of R and online calculators
> 
> Tal and David, thanks for your messages.
> 
> I should have added that I tried all variations of true/false values for the exact and correct parameters. Running with correct=FALSE makes only a tiny change, resulting in W = 485, p-value = 0.0002481.
> 
> At one point, I also thought that the discrepancy between R and these online calculators might come from how ties are handled, but the fact that R and two of the online calcultors reach the same U/W values seems to indicate that ties aren't the issue, since (I believe) the U or W values contain all of the information needed to calculate the p-value, assuming the number of samples is also known for each condition. (However, it's been a while since I looked into how MWU tests work, so maybe now's the time to refresh.) If that's correct, the discrepancy seems to be based in what R does with the W value that is identical to the U values of two of the online calculators. (I'm also assuming that U and W have the same meaning, which seems likely.)
> 
> - Brad
> 
> ____________________
> W. Bradley Knox, PhD
> http://bradknox.net<http://bradknox.net/>
> bradknox at mit.edu<mailto:bradknox at mit.edu>
> 
> On Wed, Sep 3, 2014 at 9:10 AM, David L Carlson <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>> wrote:
> That does not change the results. The problem is likely to be the way ties are handled. The first sample has 25 values of which 23 are identical (359). The second sample has 26 values of which 12 are identical (359). The difference between the implementations may be a result of the way the ties are ranked. For example the R function rank() offers 5 different ways of handling the rank on tied observations. With so many ties, that could make a substantial difference.
> 
> Package coin has wilxon_test() which uses Monte Carlo simulation to estimate the confidence limits.
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Tal Galili
> Sent: Wednesday, September 3, 2014 5:24 AM
> To: W Bradley Knox
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] wilcox.test - difference between p-values of R and online calculators
> 
> It seems your numbers has ties. What happens if you run wilcox.test with
> correct=FALSE, will the results be the same as the online calculators?
> 
> 
> 
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com<mailto:Tal.Galili at gmail.com> |
> Read me: www.talgalili.com<http://www.talgalili.com> (Hebrew) | www.biostatistics.co.il<http://www.biostatistics.co.il> (Hebrew) |
> www.r-statistics.com<http://www.r-statistics.com> (English)
> ----------------------------------------------------------------------------------------------
> 
> 
> 
> On Wed, Sep 3, 2014 at 3:54 AM, W Bradley Knox <bradknox at mit.edu<mailto:bradknox at mit.edu>> wrote:
> 
>> Hi.
>> 
>> I'm taking the long-overdue step of moving from using online calculators to
>> compute results for Mann-Whitney U tests to a more streamlined system
>> involving R.
>> 
>> However, I'm finding that R computes a different result than the 3 online
>> calculators that I've used before (all of which approximately agree). These
>> calculators are here:
>> 
>> http://elegans.som.vcu.edu/~leon/stats/utest.cgi
>> http://vassarstats.net/utest.html
>> http://www.socscistatistics.com/tests/mannwhitney/
>> 
>> An example calculation is
>> 
>> 
>> *wilcox.test(c(359,359,359,359,359,359,335,359,359,359,359,359,359,359,359,359,359,359,359,359,359,303,359,359,359),c(332,85,359,359,359,220,231,300,359,237,359,183,286,355,250,105,359,359,298,359,359,359,28.6,359,359,128))*
>> 
>> which prints
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> *Wilcoxon rank sum test with continuity correction  data: c(359, 359, 359,
>> 359, 359, 359, 335, 359, 359, 359, 359, 359, and c(332, 85, 359, 359, 359,
>> 220, 231, 300, 359, 237, 359, 183, 359, 359, 359, 359, 359, 359, 359, 359,
>> 359, 303, 359, 359, and 286, 355, 250, 105, 359, 359, 298, 359, 359, 359,
>> 28.6, 359, 359) and 359, 128)  W = 485, p-value = 0.0002594 alternative
>> hypothesis: true location shift is not equal to 0 Warning message: In
>> wilcox.test.default(c(359, 359, 359, 359, 359, 359, 335, 359, : cannot
>> compute exact p-value with ties*
>> 
>> 
>> However, all of the online calculators find p-values close to 0.0025, 10x
>> the value output by R. All results are for a two-tailed case. Importantly,
>> the W value computed by R *does agree* with the U values output by the
>> first two online calculators listed above, yet it has a different p-value.
>> 
>> Can anyone shed some light on how and why R's calculation differs from that
>> of these online calculators? Thanks for your time.
>> 
>> ____________________
>> W. Bradley Knox, PhD
>> http://bradknox.net
>> bradknox at mit.edu<mailto:bradknox at mit.edu>
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bradknox at mit.edu  Wed Sep  3 16:20:21 2014
From: bradknox at mit.edu (W Bradley Knox)
Date: Wed, 3 Sep 2014 09:20:21 -0500
Subject: [R] wilcox.test - difference between p-values of R and online
	calculators
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F94CB5@mb02.ads.tamu.edu>
References: <CAFE=h4B0QpXnU2avD=EiqcJpOrTszC6zJhwC1q5E+jfw8dpwDQ@mail.gmail.com>
	<CANdJ3dVsr4fz6hs-dm3f61DfQf+JijgE=XW-+XyziSQZK6NjXQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F94CB5@mb02.ads.tamu.edu>
Message-ID: <CAFE=h4DzzeR21R7cV-qUi2NXR=i=uH_7ebvt-9JAm8Zhqy-rmA@mail.gmail.com>

Tal and David, thanks for your messages.

I should have added that I tried all variations of true/false values for
the exact and correct parameters. Running with correct=FALSE makes only a
tiny change, resulting in W = 485, p-value = 0.0002481.

At one point, I also thought that the discrepancy between R and these
online calculators might come from how ties are handled, but the fact that
R and two of the online calcultors reach the same U/W values seems to
indicate that ties aren't the issue, since (I believe) the U or W values
contain all of the information needed to calculate the p-value, assuming
the number of samples is also known for each condition. (However, it's been
a while since I looked into how MWU tests work, so maybe now's the time to
refresh.) If that's correct, the discrepancy seems to be based in what R
does with the W value that is identical to the U values of two of the
online calculators. (I'm also assuming that U and W have the same meaning,
which seems likely.)

- Brad

____________________
W. Bradley Knox, PhD
http://bradknox.net
bradknox at mit.edu


On Wed, Sep 3, 2014 at 9:10 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> That does not change the results. The problem is likely to be the way ties
> are handled. The first sample has 25 values of which 23 are identical
> (359). The second sample has 26 values of which 12 are identical (359). The
> difference between the implementations may be a result of the way the ties
> are ranked. For example the R function rank() offers 5 different ways of
> handling the rank on tied observations. With so many ties, that could make
> a substantial difference.
>
> Package coin has wilxon_test() which uses Monte Carlo simulation to
> estimate the confidence limits.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Tal Galili
> Sent: Wednesday, September 3, 2014 5:24 AM
> To: W Bradley Knox
> Cc: r-help at r-project.org
> Subject: Re: [R] wilcox.test - difference between p-values of R and online
> calculators
>
> It seems your numbers has ties. What happens if you run wilcox.test with
> correct=FALSE, will the results be the same as the online calculators?
>
>
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
>
> ----------------------------------------------------------------------------------------------
>
>
>
> On Wed, Sep 3, 2014 at 3:54 AM, W Bradley Knox <bradknox at mit.edu> wrote:
>
> > Hi.
> >
> > I'm taking the long-overdue step of moving from using online calculators
> to
> > compute results for Mann-Whitney U tests to a more streamlined system
> > involving R.
> >
> > However, I'm finding that R computes a different result than the 3 online
> > calculators that I've used before (all of which approximately agree).
> These
> > calculators are here:
> >
> > http://elegans.som.vcu.edu/~leon/stats/utest.cgi
> > http://vassarstats.net/utest.html
> > http://www.socscistatistics.com/tests/mannwhitney/
> >
> > An example calculation is
> >
> >
> >
> *wilcox.test(c(359,359,359,359,359,359,335,359,359,359,359,359,359,359,359,359,359,359,359,359,359,303,359,359,359),c(332,85,359,359,359,220,231,300,359,237,359,183,286,355,250,105,359,359,298,359,359,359,28.6,359,359,128))*
> >
> > which prints
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > *Wilcoxon rank sum test with continuity correction  data: c(359, 359,
> 359,
> > 359, 359, 359, 335, 359, 359, 359, 359, 359, and c(332, 85, 359, 359,
> 359,
> > 220, 231, 300, 359, 237, 359, 183, 359, 359, 359, 359, 359, 359, 359,
> 359,
> > 359, 303, 359, 359, and 286, 355, 250, 105, 359, 359, 298, 359, 359, 359,
> > 28.6, 359, 359) and 359, 128)  W = 485, p-value = 0.0002594 alternative
> > hypothesis: true location shift is not equal to 0 Warning message: In
> > wilcox.test.default(c(359, 359, 359, 359, 359, 359, 335, 359, : cannot
> > compute exact p-value with ties*
> >
> >
> > However, all of the online calculators find p-values close to 0.0025, 10x
> > the value output by R. All results are for a two-tailed case.
> Importantly,
> > the W value computed by R *does agree* with the U values output by the
> > first two online calculators listed above, yet it has a different
> p-value.
> >
> > Can anyone shed some light on how and why R's calculation differs from
> that
> > of these online calculators? Thanks for your time.
> >
> > ____________________
> > W. Bradley Knox, PhD
> > http://bradknox.net
> > bradknox at mit.edu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kathy at haapi.mn.org  Wed Sep  3 17:17:53 2014
From: kathy at haapi.mn.org (Kathy Haapala)
Date: Wed, 3 Sep 2014 11:17:53 -0400
Subject: [R] GLM Help
Message-ID: <CAEcORNN0LyBo8bBrjPoxS_iyZ6CA=VmM3-X2Npn9Zn=kJY0n8A@mail.gmail.com>

Hi all,

I have a large set of data that looks something like this, although
this data frame is much smaller and includes made up numbers to make
my question easier.

> x.df <- data.frame(Region = c("A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B", "C", "C", "C", "C"), Group_ID = c(1:15), No_Offspring = c(3, 0, 4, 2, 1, 0, 3, 4, 3, 2, 2, 5, 4, 1, 3), M_Offspring = c(2, 0, 2, 1, 0, 0, 1, 1, 2, 0, 1, 3, 2, 1, 1), F_Offspring = c(1, 0, 2, 1, 1, 0, 2, 3, 1, 2, 1, 2, 2, 0, 2), No_Helpers = c(5, 0, 2, 1, 0, 1, 3, 4, 2, 3, 2, 3, 4, 0, 0))

> x.df
   Region Group_ID No_Offspring M_Offspring F_Offspring No_Helpers
1       A        1            3           2           1          5
2       A        2            0           0           0          0
3       A        3            4           2           2          2
4       A        4            2           1           1          1
5       A        5            1           0           1          0
6       B        6            0           0           0          1
7       B        7            3           1           2          3
8       B        8            4           1           3          4
9       B        9            3           2           1          2
10      B       10            2           0           2          3
11      B       11            2           1           1          2
12      C       12            5           3           2          3
13      C       13            4           2           2          4
14      C       14            1           1           0          0
15      C       15            3           1           2          0

I have been using GLMs to determine if the number of helpers
(No_Helpers) has an effect on the sex ratio of the offspring. Here's
the GLM I have been using:

> prop.male <- x.df$M_Offspring/x.df$No_Offspring
> glm = glm(prop.male~No_Helpers,binomial,data=x.df)

However, now I'd like to fit a model with region-specific regressions
and see if this has more support than the model without
region-specificity. So, I'd like one model that generates a regression
for each region (A, B, & C).

I've tried treating No_Helpers and Region as covariates:
> glm2 = glm(prop.male~No_Helpers+Region-1,binomial,data=x.df)
which includes region-specificity in the intercepts, but not the
entire regression,
and as interaction terms:
> glm3 = glm(prop.male~No_Helpers*Region-1,binomial,data=x.df)
which also does not give me an intercept and slope for each region.

I'm not sure how else to adjust the formula, or if the adjustment
should be somewhere else in the GLM call.

Thanks in advance for your help.


From leek2 at llnl.gov  Thu Sep  4 00:25:23 2014
From: leek2 at llnl.gov (Jim Leek)
Date: Wed, 03 Sep 2014 15:25:23 -0700
Subject: [R] snow/Rmpi without MPI.spawn?
Message-ID: <54079553.6090807@llnl.gov>

I'm a programmer at a high-performance computing center.  I'm not very
familiar with R, but I have used MPI from C, C++, and Python.  I have to run
an R code provided by a guy who knows R, but not MPI.  So, this fellow used
the R snow library to parallelize his R code (theoretically, I'm not
actually sure what he did.)  I need to get this code running on our
machines.

However, Rmpi and snow seem to require mpi spawn, which our computing center
doesn't support.  I even tried building Rmpi with MPICH1 instead of 2,
because Rmpi has that option, but it still tries to use spawn.

I can launch plenty of processes, but I have to launch them all at once at
the beginning. Is there any way to convince Rmpi to just use those processes
rather than trying to spawn its own?  I haven't found any documentation on
this issue, although I would've thought it would be quite common.

Thanks,
Jim


From mtmorgan at fhcrc.org  Thu Sep  4 02:07:36 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 03 Sep 2014 17:07:36 -0700
Subject: [R] snow/Rmpi without MPI.spawn?
In-Reply-To: <54079553.6090807@llnl.gov>
References: <54079553.6090807@llnl.gov>
Message-ID: <5407AD48.3050906@fhcrc.org>

On 09/03/2014 03:25 PM, Jim Leek wrote:
> I'm a programmer at a high-performance computing center.  I'm not very
> familiar with R, but I have used MPI from C, C++, and Python.  I have to run
> an R code provided by a guy who knows R, but not MPI.  So, this fellow used
> the R snow library to parallelize his R code (theoretically, I'm not
> actually sure what he did.)  I need to get this code running on our
> machines.
>
> However, Rmpi and snow seem to require mpi spawn, which our computing center
> doesn't support.  I even tried building Rmpi with MPICH1 instead of 2,
> because Rmpi has that option, but it still tries to use spawn.
>
> I can launch plenty of processes, but I have to launch them all at once at
> the beginning. Is there any way to convince Rmpi to just use those processes
> rather than trying to spawn its own?  I haven't found any documentation on
> this issue, although I would've thought it would be quite common.

This script

spawn.R
=======
# salloc -n 12 orterun -n 1 R -f spawn.R
library(Rmpi)
## Recent Rmpi bug -- should be mpi.universe.size()
nWorkers <- mpi.universe.size()
mpi.spawn.Rslaves(nslaves=nWorkers)
mpiRank <- function(i)
   c(i=i, rank=mpi.comm.rank())
mpi.parSapply(seq_len(2*nWorkers), mpiRank)
mpi.close.Rslaves()
mpi.quit()

can be run like the comment suggests

    salloc -n 12 orterun -n 1 R -f spawn.R

uses slurm (or whatever job manager) to allocate resources for 12 tasks and 
spawn within that allocation. Maybe that's 'good enough' -- spawning within the 
assigned allocation? Likely this requires minimal modification of the current code.

More extensive is to revise the manager/worker-style code to something more like 
single instruction, multiple data


simd.R
======
## salloc -n 4 orterun R --slave -f simd.R
sink("/dev/null") # don't capture output -- more care needed here
library(Rmpi)

TAGS = list(FROM_WORKER=1L)
.comm = 0L

## shared `work', here just determine rank and host
work = c(rank=mpi.comm.rank(.comm),
          host=system("hostname", intern=TRUE))

if (mpi.comm.rank(.comm) == 0) {
     ## manager
     mpi.barrier(.comm)
     nWorkers = mpi.comm.size(.comm)
     res = list(nWorkers)
     for (i in seq_len(nWorkers - 1L)) {
         res[[i]] <- mpi.recv.Robj(mpi.any.source(), TAGS$FROM_WORKER,
                                   comm=.comm)
     }
     res[[nWorkers]] = work
     sink() # start capturing output
     print(do.call(rbind, res))
} else {
     ## worker
     mpi.barrier(.comm)
     mpi.send.Robj(work, 0L, TAGS$FROM_WORKER, comm=.comm)
}
mpi.quit()

but this likely requires some serious code revision; if going this route then 
http://r-pbd.org/ might be helpful (and from a similar HPC environment).

It's always worth asking whether the code is written to be efficient in R -- a 
typical 'mistake' is to write R-level explicit 'for' loops that 
"copy-and-append" results, along the lines of

    len <- 100000
    result <- NULL
    for (i in seq_len(len))
        ## some complicated calculation, then...
        result <- c(result, sqrt(i))

whereas it's much better to "pre-allocate and fill"

     result <- integer(len)
     for (i in seq_len(len))
         result[[i]] = sqrt(i)

or

     lapply(seq_len(len), sqrt)

and very much better still to 'vectorize'

     result <- sqrt(seq_len(len))

(timing for me are about 1 minute for "copy-and-append", .2 s for "pre-allocate 
and fill", and .002s for "vectorize").

Pushing back on the guy providing the code (grep for "for" loops, and look for 
that copy-and-append pattern) might save you from having to use parallel 
evaluation at all.

Martin

>
> Thanks,
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From macqueen1 at llnl.gov  Thu Sep  4 02:58:39 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 4 Sep 2014 00:58:39 +0000
Subject: [R] Overwriting a procedure
In-Reply-To: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>
References: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>
Message-ID: <D02D0460.109E50%macqueen1@llnl.gov>

If you have more than one version of fixx(), then the one that is used is
the one that comes first in the search path. The search path is revealed
by the search() function. So if you can learn to control the search path,
then you can control which version of fixx() is used. That would be my
initial approach.

As an aside, you can define your first version of fixx() more simply as

  fixx <- function(x) list(x=x)

and the second more simply as

fixx <- function(x) {
 x[,6]<-x[,5]^2/10
 list(x=x)
}

Using return() is completely unnecessary (but of course ok if preferred as
a matter of programming style).


Of course, this all assumes you truly need two different functions with
the same name. I would think that is unlikely, but since there?s no
indication of what determines which one should be used, I can?t say.
However, there must be some criterion that determines that the second
version should be used, so perhaps


fixx <- function(x, criterion) {
  ## criterion must be a logical value of length 1
  if (criterion) x[,6]<-x[,5]^2/10
  list(x=x)
}

would work.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/2/14, 11:45 AM, "Steven Yen" <syen04 at gmail.com> wrote:

>Is there a way to over-write a procedure (subroutine)?
>
>I include a default procedure fixx in a list of procedures which are
>compiled into a package. By default, the procedure deliver the data
>matrix x.
>
>fixx <- function(x){
>result <- list(x=x)
>return(result)
>}
>
>In some applications, I have transformations (such as squared terms)
>in some column(s) in x. So I include the following procedure in the
>mail (calling) program, hoping to over-write the default procedure
>under the same name in the package (which is the way other languages
>works, e.g., Gauss):
>
>fixx <- function(x){
>x[,6]<-x[,5]^2/10
>result <- list(x=x)
>return(result)
>}
>
>This does not seem to work. The procedure in the main (calling)
>program seems to get ignored. Any idea? Thanks.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Sep  4 03:20:08 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 03 Sep 2014 21:20:08 -0400
Subject: [R] Overwriting a procedure
In-Reply-To: <D02D0460.109E50%macqueen1@llnl.gov>
References: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>
	<D02D0460.109E50%macqueen1@llnl.gov>
Message-ID: <5407BE48.50402@gmail.com>

On 03/09/2014, 8:58 PM, MacQueen, Don wrote:
> If you have more than one version of fixx(), then the one that is used is
> the one that comes first in the search path. The search path is revealed
> by the search() function. So if you can learn to control the search path,
> then you can control which version of fixx() is used. That would be my
> initial approach.

This is only partially correct information.  It only applies to uses of
fixx() from the console.  The original poster wanted to replace a
function in a package:  uses within the package will search the package
namespace first, regardless of the search path.

Duncan Murdoch

> 
> As an aside, you can define your first version of fixx() more simply as
> 
>   fixx <- function(x) list(x=x)
> 
> and the second more simply as
> 
> fixx <- function(x) {
>  x[,6]<-x[,5]^2/10
>  list(x=x)
> }
> 
> Using return() is completely unnecessary (but of course ok if preferred as
> a matter of programming style).
> 
> 
> Of course, this all assumes you truly need two different functions with
> the same name. I would think that is unlikely, but since there?s no
> indication of what determines which one should be used, I can?t say.
> However, there must be some criterion that determines that the second
> version should be used, so perhaps
> 
> 
> fixx <- function(x, criterion) {
>   ## criterion must be a logical value of length 1
>   if (criterion) x[,6]<-x[,5]^2/10
>   list(x=x)
> }
> 
> would work.
> 
>


From jszhao at yeah.net  Thu Sep  4 05:57:21 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Wed, 03 Sep 2014 20:57:21 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <53ABA405-D506-4095-AB66-530808E15CAE@comcast.net>
References: <54050401.4060203@yeah.net>
	<53ABA405-D506-4095-AB66-530808E15CAE@comcast.net>
Message-ID: <5407E321.4090209@yeah.net>

On 2014/9/1 20:39, David Winsemius wrote:
>
> On Sep 1, 2014, at 4:40 PM, Jinsong Zhao wrote:
>
>> Hi there,
>>
>> With the following code,
>>
>> plot(1:5, xaxt = "n")
>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>> "E", expression(E[t])))
>>
>> you may notice that the "E" within labels of axis(1) are not at the
>> same depth. So the vision of axis(1) labels is something like wave.
>>
>> Is there a possible way to typeset the labels so that they are have
>> the same depth?
>
> I'm not sure that we share an interpretation of the term "depth" in this
> context. I'm interpreting your request to me vertical alighnment.

"depth" is not the accurate word for this situation. Maybe, "baseline" 
is a better one.

>
>> Any suggestions will be really appreciated.
>
> Read the help page, especially the paragraph about padj. I will admit
> that I thought the description of the actions of padj=0 and padj=1 were
> not what I experienced when I tried alternate versions. It did not seem
> to me that padj=0 produced "top alignment".

Thank you very much for pointing me to this. I did not notice this argument.

Best regards,
Jinsong


From jszhao at yeah.net  Thu Sep  4 06:33:46 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Wed, 03 Sep 2014 21:33:46 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>
References: <54050401.4060203@yeah.net>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>
Message-ID: <5407EBAA.6070807@yeah.net>

On 2014/9/2 11:50, David L Carlson wrote:
> The bottom of the expression is set by the lowest character (which can even change for subscripted letters with descenders. The solution is to get axis() to align the tops of the axis labels and move the line up to reduce the space, e.g.
>
> plot(1:5, xaxt = "n")
> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
> "E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
> # Check alignment
> abline(h=.7, xpd=TRUE, lty=3)

yes. In this situation, padj = 1 is the fast solution. However, If there 
are also superscript, then it's hard to alignment all the labels.

If R provide a mechanism that aligns the label in axis() or text() with 
the baseline of the character without the super- and/or sub-script, that 
will be terrific.

Regards,
Jinsong

>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jinsong Zhao
> Sent: Monday, September 1, 2014 6:41 PM
> To: r-help at r-project.org
> Subject: [R] depth of labels of axis
>
> Hi there,
>
> With the following code,
>
> plot(1:5, xaxt = "n")
> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
> "E", expression(E[t])))
>
> you may notice that the "E" within labels of axis(1) are not at the same
> depth. So the vision of axis(1) labels is something like wave.
>
> Is there a possible way to typeset the labels so that they are have the
> same depth?
>
> Any suggestions will be really appreciated. Thanks in advance.
>
> Best regards,
> Jinsong
>


From jszhao at yeah.net  Thu Sep  4 07:05:25 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Wed, 03 Sep 2014 22:05:25 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <5407EBAA.6070807@yeah.net>
References: <54050401.4060203@yeah.net>	<53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>
	<5407EBAA.6070807@yeah.net>
Message-ID: <5407F315.9060606@yeah.net>

On 2014/9/3 21:33, Jinsong Zhao wrote:
> On 2014/9/2 11:50, David L Carlson wrote:
>> The bottom of the expression is set by the lowest character (which can
>> even change for subscripted letters with descenders. The solution is
>> to get axis() to align the tops of the axis labels and move the line
>> up to reduce the space, e.g.
>>
>> plot(1:5, xaxt = "n")
>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>> "E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
>> # Check alignment
>> abline(h=.7, xpd=TRUE, lty=3)
>
> yes. In this situation, padj = 1 is the fast solution. However, If there
> are also superscript, then it's hard to alignment all the labels.
>
> If R provide a mechanism that aligns the label in axis() or text() with
> the baseline of the character without the super- and/or sub-script, that
> will be terrific.

it seems that the above wish is on the Graphics TODO lists:
https://www.stat.auckland.ac.nz/~paul/R/graphicstodos.html

Allow text adjustment for mathematical annotations which is relative to 
a text baseline (in addition to the current situation where adjustment 
is relative to the bounding box).

>
> Regards,
> Jinsong
>
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Jinsong Zhao
>> Sent: Monday, September 1, 2014 6:41 PM
>> To: r-help at r-project.org
>> Subject: [R] depth of labels of axis
>>
>> Hi there,
>>
>> With the following code,
>>
>> plot(1:5, xaxt = "n")
>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>> "E", expression(E[t])))
>>
>> you may notice that the "E" within labels of axis(1) are not at the same
>> depth. So the vision of axis(1) labels is something like wave.
>>
>> Is there a possible way to typeset the labels so that they are have the
>> same depth?
>>
>> Any suggestions will be really appreciated. Thanks in advance.
>>
>> Best regards,
>> Jinsong


From leek2 at llnl.gov  Thu Sep  4 07:24:30 2014
From: leek2 at llnl.gov (Leek, Jim)
Date: Thu, 4 Sep 2014 05:24:30 +0000
Subject: [R] snow/Rmpi without MPI.spawn?
In-Reply-To: <5407AD48.3050906@fhcrc.org>
References: <54079553.6090807@llnl.gov> <5407AD48.3050906@fhcrc.org>
Message-ID: <6B554E87D42BA74AB76EC1D40C57A0DA75C4130C@PRDEXMBX-04.the-lab.llnl.gov>

Thanks for the tips.  I'll take a look around for for loops in the morning.

I think the example you provided worked for OpenMPI.  (The default on our machine is MPICH2, but it gave the same error about calling spawn.)  Anyway, with OpenMPI I got this:

> # salloc -n 12 orterun -n 1 R -f spawn.R
> library(Rmpi)
> ## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- mpi.universe.size()
> nslaves = 4
> mpi.spawn.Rslaves(nslaves)
Reported: 2 (out of 2) daemons - 4 (out of 4) procs

Then it hung there.  So things spawned anyway, which is progress.  I'm just not sure is that expected behavior for parSupply or not.

Jim

-----Original Message-----
From: Martin Morgan [mailto:mtmorgan at fhcrc.org] 
Sent: Wednesday, September 03, 2014 5:08 PM
To: Leek, Jim; r-help at r-project.org
Subject: Re: [R] snow/Rmpi without MPI.spawn?

On 09/03/2014 03:25 PM, Jim Leek wrote:
> I'm a programmer at a high-performance computing center.  I'm not very 
> familiar with R, but I have used MPI from C, C++, and Python.  I have 
> to run an R code provided by a guy who knows R, but not MPI.  So, this 
> fellow used the R snow library to parallelize his R code 
> (theoretically, I'm not actually sure what he did.)  I need to get 
> this code running on our machines.
>
> However, Rmpi and snow seem to require mpi spawn, which our computing 
> center doesn't support.  I even tried building Rmpi with MPICH1 
> instead of 2, because Rmpi has that option, but it still tries to use spawn.
>
> I can launch plenty of processes, but I have to launch them all at 
> once at the beginning. Is there any way to convince Rmpi to just use 
> those processes rather than trying to spawn its own?  I haven't found 
> any documentation on this issue, although I would've thought it would be quite common.

This script

spawn.R
=======
# salloc -n 12 orterun -n 1 R -f spawn.R
library(Rmpi)
## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- mpi.universe.size()
mpi.spawn.Rslaves(nslaves=nWorkers)
mpiRank <- function(i)
   c(i=i, rank=mpi.comm.rank())
mpi.parSapply(seq_len(2*nWorkers), mpiRank)
mpi.close.Rslaves()
mpi.quit()

can be run like the comment suggests

    salloc -n 12 orterun -n 1 R -f spawn.R

uses slurm (or whatever job manager) to allocate resources for 12 tasks and spawn within that allocation. Maybe that's 'good enough' -- spawning within the assigned allocation? Likely this requires minimal modification of the current code.

More extensive is to revise the manager/worker-style code to something more like single instruction, multiple data


simd.R
======
## salloc -n 4 orterun R --slave -f simd.R
sink("/dev/null") # don't capture output -- more care needed here
library(Rmpi)

TAGS = list(FROM_WORKER=1L)
.comm = 0L

## shared `work', here just determine rank and host
work = c(rank=mpi.comm.rank(.comm),
          host=system("hostname", intern=TRUE))

if (mpi.comm.rank(.comm) == 0) {
     ## manager
     mpi.barrier(.comm)
     nWorkers = mpi.comm.size(.comm)
     res = list(nWorkers)
     for (i in seq_len(nWorkers - 1L)) {
         res[[i]] <- mpi.recv.Robj(mpi.any.source(), TAGS$FROM_WORKER,
                                   comm=.comm)
     }
     res[[nWorkers]] = work
     sink() # start capturing output
     print(do.call(rbind, res))
} else {
     ## worker
     mpi.barrier(.comm)
     mpi.send.Robj(work, 0L, TAGS$FROM_WORKER, comm=.comm)
}
mpi.quit()

but this likely requires some serious code revision; if going this route then 
http://r-pbd.org/ might be helpful (and from a similar HPC environment).

It's always worth asking whether the code is written to be efficient in R -- a 
typical 'mistake' is to write R-level explicit 'for' loops that 
"copy-and-append" results, along the lines of

    len <- 100000
    result <- NULL
    for (i in seq_len(len))
        ## some complicated calculation, then...
        result <- c(result, sqrt(i))

whereas it's much better to "pre-allocate and fill"

     result <- integer(len)
     for (i in seq_len(len))
         result[[i]] = sqrt(i)

or

     lapply(seq_len(len), sqrt)

and very much better still to 'vectorize'

     result <- sqrt(seq_len(len))

(timing for me are about 1 minute for "copy-and-append", .2 s for "pre-allocate 
and fill", and .002s for "vectorize").

Pushing back on the guy providing the code (grep for "for" loops, and look for 
that copy-and-append pattern) might save you from having to use parallel 
evaluation at all.

Martin

>
> Thanks,
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From leek2 at llnl.gov  Thu Sep  4 07:35:20 2014
From: leek2 at llnl.gov (Leek, Jim)
Date: Thu, 4 Sep 2014 05:35:20 +0000
Subject: [R] snow/Rmpi without MPI.spawn?
In-Reply-To: <6B554E87D42BA74AB76EC1D40C57A0DA75C4130C@PRDEXMBX-04.the-lab.llnl.gov>
References: <54079553.6090807@llnl.gov> <5407AD48.3050906@fhcrc.org>
	<6B554E87D42BA74AB76EC1D40C57A0DA75C4130C@PRDEXMBX-04.the-lab.llnl.gov>
Message-ID: <6B554E87D42BA74AB76EC1D40C57A0DA75C4134C@PRDEXMBX-04.the-lab.llnl.gov>

I spoke a bit too soon.  You may have noticed that it isn't hanging in parSapply, it's hanging in mpi.spawn.Rslaves().  It claims to have launched the slaves, but I can't see them by logging into the target node and running 'top'.  I only see the top level R process (which is burning up 100% of a CPU).  So I don't know what's going on.  It never gets back from the spawn call anyway.

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Leek, Jim
Sent: Wednesday, September 03, 2014 10:25 PM
To: Martin Morgan; r-help at r-project.org
Subject: Re: [R] snow/Rmpi without MPI.spawn?

Thanks for the tips.  I'll take a look around for for loops in the morning.

I think the example you provided worked for OpenMPI.  (The default on our machine is MPICH2, but it gave the same error about calling spawn.)  Anyway, with OpenMPI I got this:

> # salloc -n 12 orterun -n 1 R -f spawn.R
> library(Rmpi)
> ## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- 
> mpi.universe.size() nslaves = 4
> mpi.spawn.Rslaves(nslaves)
Reported: 2 (out of 2) daemons - 4 (out of 4) procs

Then it hung there.  So things spawned anyway, which is progress.  I'm just not sure is that expected behavior for parSupply or not.

Jim

-----Original Message-----
From: Martin Morgan [mailto:mtmorgan at fhcrc.org]
Sent: Wednesday, September 03, 2014 5:08 PM
To: Leek, Jim; r-help at r-project.org
Subject: Re: [R] snow/Rmpi without MPI.spawn?

On 09/03/2014 03:25 PM, Jim Leek wrote:
> I'm a programmer at a high-performance computing center.  I'm not very 
> familiar with R, but I have used MPI from C, C++, and Python.  I have 
> to run an R code provided by a guy who knows R, but not MPI.  So, this 
> fellow used the R snow library to parallelize his R code 
> (theoretically, I'm not actually sure what he did.)  I need to get 
> this code running on our machines.
>
> However, Rmpi and snow seem to require mpi spawn, which our computing 
> center doesn't support.  I even tried building Rmpi with MPICH1 
> instead of 2, because Rmpi has that option, but it still tries to use spawn.
>
> I can launch plenty of processes, but I have to launch them all at 
> once at the beginning. Is there any way to convince Rmpi to just use 
> those processes rather than trying to spawn its own?  I haven't found 
> any documentation on this issue, although I would've thought it would be quite common.

This script

spawn.R
=======
# salloc -n 12 orterun -n 1 R -f spawn.R
library(Rmpi)
## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- mpi.universe.size()
mpi.spawn.Rslaves(nslaves=nWorkers)
mpiRank <- function(i)
   c(i=i, rank=mpi.comm.rank())
mpi.parSapply(seq_len(2*nWorkers), mpiRank)
mpi.close.Rslaves()
mpi.quit()

can be run like the comment suggests

    salloc -n 12 orterun -n 1 R -f spawn.R

uses slurm (or whatever job manager) to allocate resources for 12 tasks and spawn within that allocation. Maybe that's 'good enough' -- spawning within the assigned allocation? Likely this requires minimal modification of the current code.

More extensive is to revise the manager/worker-style code to something more like single instruction, multiple data


simd.R
======
## salloc -n 4 orterun R --slave -f simd.R
sink("/dev/null") # don't capture output -- more care needed here
library(Rmpi)

TAGS = list(FROM_WORKER=1L)
.comm = 0L

## shared `work', here just determine rank and host work = c(rank=mpi.comm.rank(.comm),
          host=system("hostname", intern=TRUE))

if (mpi.comm.rank(.comm) == 0) {
     ## manager
     mpi.barrier(.comm)
     nWorkers = mpi.comm.size(.comm)
     res = list(nWorkers)
     for (i in seq_len(nWorkers - 1L)) {
         res[[i]] <- mpi.recv.Robj(mpi.any.source(), TAGS$FROM_WORKER,
                                   comm=.comm)
     }
     res[[nWorkers]] = work
     sink() # start capturing output
     print(do.call(rbind, res))
} else {
     ## worker
     mpi.barrier(.comm)
     mpi.send.Robj(work, 0L, TAGS$FROM_WORKER, comm=.comm) }
mpi.quit()

but this likely requires some serious code revision; if going this route then http://r-pbd.org/ might be helpful (and from a similar HPC environment).

It's always worth asking whether the code is written to be efficient in R -- a typical 'mistake' is to write R-level explicit 'for' loops that "copy-and-append" results, along the lines of

    len <- 100000
    result <- NULL
    for (i in seq_len(len))
        ## some complicated calculation, then...
        result <- c(result, sqrt(i))

whereas it's much better to "pre-allocate and fill"

     result <- integer(len)
     for (i in seq_len(len))
         result[[i]] = sqrt(i)

or

     lapply(seq_len(len), sqrt)

and very much better still to 'vectorize'

     result <- sqrt(seq_len(len))

(timing for me are about 1 minute for "copy-and-append", .2 s for "pre-allocate and fill", and .002s for "vectorize").

Pushing back on the guy providing the code (grep for "for" loops, and look for that copy-and-append pattern) might save you from having to use parallel evaluation at all.

Martin

>
> Thanks,
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


--
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Tim.Williams at ucb.com  Thu Sep  4 03:27:23 2014
From: Tim.Williams at ucb.com (Tim.Williams at ucb.com)
Date: Thu, 4 Sep 2014 01:27:23 +0000
Subject: [R] Convert time zone to difference from Coordinated Universal Time
Message-ID: <C74091AA8BDDA94D8DA9980B20A9A7F43F40E0B7@BRAEXCAP011.dir.ucb-group.com>

Hello everyone,

I want to convert times provided by Sys.time()  to use  the difference from Coordinated Universal Time instead of the character abbreviation.

For example, instead of:
2014-09-03 21:12:35 EDT

I want the value as:
2004-09-03 13:20:00-04:00

Is there a way to do this with strftime() ?

Thanks in advance,

Tim

________________________________
UCB BIOSCIENCES, Inc.
Mail P.O. Box 110167 - Research Triangle Park - NC 27709 - USA
Via Courier 8010 Arco Corporate Drive - Suite 100 - Raleigh - NC 27617 - USA
Phone +1 919 767 2555 - Fax +1 919 767 2570

(Ref: #*UBI0111) [Ref-UBI0111]
________________________________
Legal Notice: This electronic mail and its attachments a...{{dropped:16}}


From rhelpmaillist at 163.com  Thu Sep  4 04:27:15 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 4 Sep 2014 10:27:15 +0800 (CST)
Subject: [R] The newest version of Rstudio Desktop v0.98.1049 couldn't be
 installed
Message-ID: <53addd1f.1a9ad.1483e7cbe58.Coremail.rhelpmaillist@163.com>


Dear expeRts,
?? I find the newest Rstudio Desktop v0.98.1049 ?for windows is not newest, after i installed, it was a old version.





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From pdalgd at gmail.com  Thu Sep  4 08:51:34 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Sep 2014 08:51:34 +0200
Subject: [R] GLM Help
In-Reply-To: <CAEcORNN0LyBo8bBrjPoxS_iyZ6CA=VmM3-X2Npn9Zn=kJY0n8A@mail.gmail.com>
References: <CAEcORNN0LyBo8bBrjPoxS_iyZ6CA=VmM3-X2Npn9Zn=kJY0n8A@mail.gmail.com>
Message-ID: <B0A9AD72-8CEB-4679-9572-AD685127933A@gmail.com>

I think you are looking for

~ Region + Region:Helpers - 1

a.k.a. 

~ Region/Helpers - 1

Notice that these are actually the same model as your glm3 (and also as ~Region*Helpers), only the parametrization differs. The latter includes an overall Helpers term so that the interaction coefficients should be read as differences in slope. (With default treatment contrasts, the Helpers term would be the slope for the first region and the interactions are differences in slope compared to the first region).

-pd

On 03 Sep 2014, at 17:17 , Kathy Haapala <kathy at haapi.mn.org> wrote:

> Hi all,
> 
> I have a large set of data that looks something like this, although
> this data frame is much smaller and includes made up numbers to make
> my question easier.
> 
>> x.df <- data.frame(Region = c("A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B", "C", "C", "C", "C"), Group_ID = c(1:15), No_Offspring = c(3, 0, 4, 2, 1, 0, 3, 4, 3, 2, 2, 5, 4, 1, 3), M_Offspring = c(2, 0, 2, 1, 0, 0, 1, 1, 2, 0, 1, 3, 2, 1, 1), F_Offspring = c(1, 0, 2, 1, 1, 0, 2, 3, 1, 2, 1, 2, 2, 0, 2), No_Helpers = c(5, 0, 2, 1, 0, 1, 3, 4, 2, 3, 2, 3, 4, 0, 0))
> 
>> x.df
>   Region Group_ID No_Offspring M_Offspring F_Offspring No_Helpers
> 1       A        1            3           2           1          5
> 2       A        2            0           0           0          0
> 3       A        3            4           2           2          2
> 4       A        4            2           1           1          1
> 5       A        5            1           0           1          0
> 6       B        6            0           0           0          1
> 7       B        7            3           1           2          3
> 8       B        8            4           1           3          4
> 9       B        9            3           2           1          2
> 10      B       10            2           0           2          3
> 11      B       11            2           1           1          2
> 12      C       12            5           3           2          3
> 13      C       13            4           2           2          4
> 14      C       14            1           1           0          0
> 15      C       15            3           1           2          0
> 
> I have been using GLMs to determine if the number of helpers
> (No_Helpers) has an effect on the sex ratio of the offspring. Here's
> the GLM I have been using:
> 
>> prop.male <- x.df$M_Offspring/x.df$No_Offspring
>> glm = glm(prop.male~No_Helpers,binomial,data=x.df)
> 
> However, now I'd like to fit a model with region-specific regressions
> and see if this has more support than the model without
> region-specificity. So, I'd like one model that generates a regression
> for each region (A, B, & C).
> 
> I've tried treating No_Helpers and Region as covariates:
>> glm2 = glm(prop.male~No_Helpers+Region-1,binomial,data=x.df)
> which includes region-specificity in the intercepts, but not the
> entire regression,
> and as interaction terms:
>> glm3 = glm(prop.male~No_Helpers*Region-1,binomial,data=x.df)
> which also does not give me an intercept and slope for each region.
> 
> I'm not sure how else to adjust the formula, or if the adjustment
> should be somewhere else in the GLM call.
> 
> Thanks in advance for your help.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Thu Sep  4 08:54:07 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 04 Sep 2014 07:54:07 +0100
Subject: [R] Convert time zone to difference from Coordinated Universal
 Time
In-Reply-To: <C74091AA8BDDA94D8DA9980B20A9A7F43F40E0B7@BRAEXCAP011.dir.ucb-group.com>
References: <C74091AA8BDDA94D8DA9980B20A9A7F43F40E0B7@BRAEXCAP011.dir.ucb-group.com>
Message-ID: <54080C8F.4030603@stats.ox.ac.uk>

On 04/09/2014 02:27, Tim.Williams at ucb.com wrote:
> Hello everyone,
>
> I want to convert times provided by Sys.time()  to use  the difference from Coordinated Universal Time instead of the character abbreviation.
>
> For example, instead of:
> 2014-09-03 21:12:35 EDT
>
> I want the value as:
> 2004-09-03 13:20:00-04:00
>
> Is there a way to do this with strftime() ?

On some systems.  Although the posting guide required it, you did not 
provide information on yours.

Please do read the help page for yourself -- %z is relevant.


>
> Thanks in advance,
>
> Tim
>
> ________________________________
> UCB BIOSCIENCES, Inc.
> Mail P.O. Box 110167 - Research Triangle Park - NC 27709 - USA
> Via Courier 8010 Arco Corporate Drive - Suite 100 - Raleigh - NC 27617 - USA
> Phone +1 919 767 2555 - Fax +1 919 767 2570
>
> (Ref: #*UBI0111) [Ref-UBI0111]
> ________________________________
> Legal Notice: This electronic mail and its attachments a...{{dropped:16}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From bhh at xs4all.nl  Thu Sep  4 11:08:25 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 4 Sep 2014 11:08:25 +0200
Subject: [R] The newest version of Rstudio Desktop v0.98.1049 couldn't
	be installed
In-Reply-To: <53addd1f.1a9ad.1483e7cbe58.Coremail.rhelpmaillist@163.com>
References: <53addd1f.1a9ad.1483e7cbe58.Coremail.rhelpmaillist@163.com>
Message-ID: <99108B75-541B-45F1-BA5F-E60CED44AB39@xs4all.nl>


On 04-09-2014, at 04:27, PO SU <rhelpmaillist at 163.com> wrote:

> 
> Dear expeRts,
>    I find the newest Rstudio Desktop v0.98.1049  for windows is not newest, after i installed, it was a old version.
> 


Questions and information relating to RStudio do not belong on this list.
Send mail to RStudio support.

Berend


From kridox at ymail.com  Thu Sep  4 11:07:52 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 4 Sep 2014 18:07:52 +0900
Subject: [R] The newest version of Rstudio Desktop v0.98.1049 couldn't
	be installed
In-Reply-To: <53addd1f.1a9ad.1483e7cbe58.Coremail.rhelpmaillist@163.com>
References: <53addd1f.1a9ad.1483e7cbe58.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAcyNCxs60cgfYpL4x89GJN8cPU2jOQpcpbnxHzOTYMV2eCaww@mail.gmail.com>

Please ask your question to the dedicated forum: https://support.rstudio.com

Regards,
Pascal

On Thu, Sep 4, 2014 at 11:27 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Dear expeRts,
>    I find the newest Rstudio Desktop v0.98.1049  for windows is not newest, after i installed, it was a old version.
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From mamushbukana at gmail.com  Thu Sep  4 11:42:08 2014
From: mamushbukana at gmail.com (mamuash bukana)
Date: Thu, 4 Sep 2014 11:42:08 +0200
Subject: [R] Error in ur.df function
Message-ID: <CAFxDEqLHGBPncDe-eMTfZRZ002E=fBcRtnvd4WFPD-uG8EbiwQ@mail.gmail.com>

Dear R users,

For a time series, say y:
y<-cumsum(rnorm(100)) # I used ur.df function (urca package) to test
for unit root with/without a drift as follows:

test<-ur.df(y,lags=3,type="drift") # this works for the artificial
data here, but when I apply the same function to my very big data, it
comes with the following error:

Error in coef(summary(result))[2, 3] : subscript out of bounds


Any suggestion please?




Mamuash


From mtmorgan at fhcrc.org  Thu Sep  4 14:03:52 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 04 Sep 2014 05:03:52 -0700
Subject: [R] snow/Rmpi without MPI.spawn?
In-Reply-To: <6B554E87D42BA74AB76EC1D40C57A0DA75C4130C@PRDEXMBX-04.the-lab.llnl.gov>
References: <54079553.6090807@llnl.gov> <5407AD48.3050906@fhcrc.org>
	<6B554E87D42BA74AB76EC1D40C57A0DA75C4130C@PRDEXMBX-04.the-lab.llnl.gov>
Message-ID: <54085528.4050907@fhcrc.org>

On 09/03/2014 10:24 PM, Leek, Jim wrote:
> Thanks for the tips.  I'll take a look around for for loops in the morning.
>
> I think the example you provided worked for OpenMPI.  (The default on our machine is MPICH2, but it gave the same error about calling spawn.)  Anyway, with OpenMPI I got this:
>
>> # salloc -n 12 orterun -n 1 R -f spawn.R
>> library(Rmpi)
>> ## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- mpi.universe.size()

(the '## Recent Rmpi bug' comment should have been removed, it's a holdover from 
when the script was written several years ago)

>> nslaves = 4
>> mpi.spawn.Rslaves(nslaves)

The argument needs to be named

   mpi.spawn.Rslaves(nslaves=4)

otherwise R matches unnamed arguments by position, and '4' is associated with 
the 'Rscript' argument.

Martin

> Reported: 2 (out of 2) daemons - 4 (out of 4) procs
>
> Then it hung there.  So things spawned anyway, which is progress.  I'm just not sure is that expected behavior for parSupply or not.
>
> Jim
>
> -----Original Message-----
> From: Martin Morgan [mailto:mtmorgan at fhcrc.org]
> Sent: Wednesday, September 03, 2014 5:08 PM
> To: Leek, Jim; r-help at r-project.org
> Subject: Re: [R] snow/Rmpi without MPI.spawn?
>
> On 09/03/2014 03:25 PM, Jim Leek wrote:
>> I'm a programmer at a high-performance computing center.  I'm not very
>> familiar with R, but I have used MPI from C, C++, and Python.  I have
>> to run an R code provided by a guy who knows R, but not MPI.  So, this
>> fellow used the R snow library to parallelize his R code
>> (theoretically, I'm not actually sure what he did.)  I need to get
>> this code running on our machines.
>>
>> However, Rmpi and snow seem to require mpi spawn, which our computing
>> center doesn't support.  I even tried building Rmpi with MPICH1
>> instead of 2, because Rmpi has that option, but it still tries to use spawn.
>>
>> I can launch plenty of processes, but I have to launch them all at
>> once at the beginning. Is there any way to convince Rmpi to just use
>> those processes rather than trying to spawn its own?  I haven't found
>> any documentation on this issue, although I would've thought it would be quite common.
>
> This script
>
> spawn.R
> =======
> # salloc -n 12 orterun -n 1 R -f spawn.R
> library(Rmpi)
> ## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- mpi.universe.size()
> mpi.spawn.Rslaves(nslaves=nWorkers)
> mpiRank <- function(i)
>     c(i=i, rank=mpi.comm.rank())
> mpi.parSapply(seq_len(2*nWorkers), mpiRank)
> mpi.close.Rslaves()
> mpi.quit()
>
> can be run like the comment suggests
>
>      salloc -n 12 orterun -n 1 R -f spawn.R
>
> uses slurm (or whatever job manager) to allocate resources for 12 tasks and spawn within that allocation. Maybe that's 'good enough' -- spawning within the assigned allocation? Likely this requires minimal modification of the current code.
>
> More extensive is to revise the manager/worker-style code to something more like single instruction, multiple data
>
>
> simd.R
> ======
> ## salloc -n 4 orterun R --slave -f simd.R
> sink("/dev/null") # don't capture output -- more care needed here
> library(Rmpi)
>
> TAGS = list(FROM_WORKER=1L)
> .comm = 0L
>
> ## shared `work', here just determine rank and host
> work = c(rank=mpi.comm.rank(.comm),
>            host=system("hostname", intern=TRUE))
>
> if (mpi.comm.rank(.comm) == 0) {
>       ## manager
>       mpi.barrier(.comm)
>       nWorkers = mpi.comm.size(.comm)
>       res = list(nWorkers)
>       for (i in seq_len(nWorkers - 1L)) {
>           res[[i]] <- mpi.recv.Robj(mpi.any.source(), TAGS$FROM_WORKER,
>                                     comm=.comm)
>       }
>       res[[nWorkers]] = work
>       sink() # start capturing output
>       print(do.call(rbind, res))
> } else {
>       ## worker
>       mpi.barrier(.comm)
>       mpi.send.Robj(work, 0L, TAGS$FROM_WORKER, comm=.comm)
> }
> mpi.quit()
>
> but this likely requires some serious code revision; if going this route then
> http://r-pbd.org/ might be helpful (and from a similar HPC environment).
>
> It's always worth asking whether the code is written to be efficient in R -- a
> typical 'mistake' is to write R-level explicit 'for' loops that
> "copy-and-append" results, along the lines of
>
>      len <- 100000
>      result <- NULL
>      for (i in seq_len(len))
>          ## some complicated calculation, then...
>          result <- c(result, sqrt(i))
>
> whereas it's much better to "pre-allocate and fill"
>
>       result <- integer(len)
>       for (i in seq_len(len))
>           result[[i]] = sqrt(i)
>
> or
>
>       lapply(seq_len(len), sqrt)
>
> and very much better still to 'vectorize'
>
>       result <- sqrt(seq_len(len))
>
> (timing for me are about 1 minute for "copy-and-append", .2 s for "pre-allocate
> and fill", and .002s for "vectorize").
>
> Pushing back on the guy providing the code (grep for "for" loops, and look for
> that copy-and-append pattern) might save you from having to use parallel
> evaluation at all.
>
> Martin
>
>>
>> Thanks,
>> Jim
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From lorenz at usgs.gov  Thu Sep  4 15:17:17 2014
From: lorenz at usgs.gov (Lorenz, David)
Date: Thu, 4 Sep 2014 08:17:17 -0500
Subject: [R] wilcox.test - difference between p-values of R and online
	calculators
Message-ID: <CALxY2LdfRzeid73cz2MyPC4i5m56KuUvwFXq=kz4KGsJWhY9Hg@mail.gmail.com>

  I think that the issue, at least with the online calculator that I looked
at, is that it does not  adjust the standard deviation of the test
statistic for ties, so the standard deviation is larger and hence larger
p-value. I was able to reproduce the reported z-score using the equation
for the standard deviation with out ties.
Dave

Message: 14
> Date: Wed, 3 Sep 2014 23:20:04 +0200
> From: peter dalgaard <pdalgd at gmail.com
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=pdalgd at gmail.com>>
> To: David L Carlson <dcarlson at tamu.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=dcarlson at tamu.edu>>
> Cc: "r-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>"
> <r-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>>,
>     W Bradley Knox
>         <bradknox at mit.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>>
> Subject: Re: [R] wilcox.test - difference between p-values of R and
>         online  calculators
> Message-ID: <FFDE9637-160E-4555-9C2A-E944947000D7 at gmail.com
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=FFDE9637-160E-4555-9C2A-E944947000D7 at gmail.com>
> >
> Content-Type: text/plain; charset=us-ascii
>
> Notice that correct=TRUE for wilcox.test refers to the continuity
> correction, not the correction for ties.
>
> You can fairly easily simulate from the exact distribution of W:
>
> x <- c(359,359,359,359,359,359,335,359,359,359,359,
>       359,359,359,359,359,359,359,359,359,359,303,359,359,359)
> y <- c(332,85,359,359,359,220,231,300,359,237,359,183,286,
>       355,250,105,359,359,298,359,359,359,28.6,359,359,128)
> R <- rank(c(x,y))
> sim <- replicate(1e6,sum(sample(R,25))) - 325
>
> # With no ties, the ranks would be a permutation of 1:51, and we could do
> sim2 <- replicate(1e6,sum(sample(1:51,25))) - 325
>
> In either case, the p-value is the probability that W >= 485 or W <= 165,
> and
>
> > mean(sim >= 485 | sim <= 165)
> [1] 0.000151
> > mean(sim2 >= 485 | sim2 <= 165)
> [1] 0.002182
>
> Also, try
>
> plot(density(sim))
> lines(density(sim2))
>
> and notice that the distribution of sim is narrower than that of sim2
> (hence the smaller p-value with tie correction), but also that the normal
> approximationtion is not nearly as good as for the untied case. The
> "clumpiness" is due to the fact that 35 of the ranks have the maximum value
> of 34 (corresponding to the original 359's).
>
> -pd
>
> On 03 Sep 2014, at 19:13 , David L Carlson <dcarlson at tamu.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=dcarlson at tamu.edu>>
> wrote:
>
> > Since they all have the same W/U value, it seems likely that the
> difference is how the different versions adjust the standard error for
> ties. Here are a couple of posts addressing the issues of ties:
> >
> > http://tolstoy.newcastle.edu.au/R/e8/help/09/12/9200.html
> >
> http://stats.stackexchange.com/questions/6127/which-permutation-test-implementation-in-r-to-use-instead-of-t-tests-paired-and
> >
> > David C
> >
> > From: wbradleyknox at gmail.com
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=wbradleyknox at gmail.com>
> [mailto:wbradleyknox at gmail.com
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=wbradleyknox at gmail.com>]
> On Behalf Of W Bradley Knox
> > Sent: Wednesday, September 3, 2014 9:20 AM
> > To: David L Carlson
> > Cc: Tal Galili; r-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>
> > Subject: Re: [R] wilcox.test - difference between p-values of R and
> online calculators
> >
> > Tal and David, thanks for your messages.
> >
> > I should have added that I tried all variations of true/false values for
> the exact and correct parameters. Running with correct=FALSE makes only a
> tiny change, resulting in W = 485, p-value = 0.0002481.
> >
> > At one point, I also thought that the discrepancy between R and these
> online calculators might come from how ties are handled, but the fact that
> R and two of the online calcultors reach the same U/W values seems to
> indicate that ties aren't the issue, since (I believe) the U or W values
> contain all of the information needed to calculate the p-value, assuming
> the number of samples is also known for each condition. (However, it's been
> a while since I looked into how MWU tests work, so maybe now's the time to
> refresh.) If that's correct, the discrepancy seems to be based in what R
> does with the W value that is identical to the U values of two of the
> online calculators. (I'm also assuming that U and W have the same meaning,
> which seems likely.)
> >
> > - Brad
> >
> > ____________________
> > W. Bradley Knox, PhD
> > http://bradknox.net<http://bradknox.net/>
> > bradknox at mit.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>
> <mailto:bradknox at mit.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>>
> >
> > On Wed, Sep 3, 2014 at 9:10 AM, David L Carlson <dcarlson at tamu.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=dcarlson at tamu.edu>
> <mailto:dcarlson at tamu.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=dcarlson at tamu.edu>>>
> wrote:
> > That does not change the results. The problem is likely to be the way
> ties are handled. The first sample has 25 values of which 23 are identical
> (359). The second sample has 26 values of which 12 are identical (359). The
> difference between the implementations may be a result of the way the ties
> are ranked. For example the R function rank() offers 5 different ways of
> handling the rank on tied observations. With so many ties, that could make
> a substantial difference.
> >
> > Package coin has wilxon_test() which uses Monte Carlo simulation to
> estimate the confidence limits.
> >
> > -------------------------------------
> > David L Carlson
> > Department of Anthropology
> > Texas A&M University
> > College Station, TX 77840-4352
> >
> >
> > -----Original Message-----
> > From: r-help-bounces at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help-bounces at r-project.org>
> <mailto:r-help-bounces at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help-bounces at r-project.org>>
> [mailto:r-help-bounces at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help-bounces at r-project.org>
> <mailto:r-help-bounces at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help-bounces at r-project.org>>]
> On Behalf Of Tal Galili
> > Sent: Wednesday, September 3, 2014 5:24 AM
> > To: W Bradley Knox
> > Cc: r-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>
> <mailto:r-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>>
> > Subject: Re: [R] wilcox.test - difference between p-values of R and
> online calculators
> >
> > It seems your numbers has ties. What happens if you run wilcox.test with
> > correct=FALSE, will the results be the same as the online calculators?
> >
> >
> >
> > ----------------Contact
> > Details:-------------------------------------------------------
> > Contact me: Tal.Galili at gmail.com
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=Tal.Galili at gmail.com>
> <mailto:Tal.Galili at gmail.com
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=Tal.Galili at gmail.com>>
> |
> > Read me: www.talgalili.com<http://www.talgalili.com> (Hebrew) |
> www.biostatistics.co.il<http://www.biostatistics.co.il> (Hebrew) |
> > www.r-statistics.com<http://www.r-statistics.com> (English)
> >
> ----------------------------------------------------------------------------------------------
> >
> >
> >
> > On Wed, Sep 3, 2014 at 3:54 AM, W Bradley Knox <bradknox at mit.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>
> <mailto:bradknox at mit.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>>>
> wrote:
> >
> >> Hi.
> >>
> >> I'm taking the long-overdue step of moving from using online
> calculators to
> >> compute results for Mann-Whitney U tests to a more streamlined system
> >> involving R.
> >>
> >> However, I'm finding that R computes a different result than the 3
> online
> >> calculators that I've used before (all of which approximately agree).
> These
> >> calculators are here:
> >>
> >> http://elegans.som.vcu.edu/~leon/stats/utest.cgi
> >> http://vassarstats.net/utest.html
> >> http://www.socscistatistics.com/tests/mannwhitney/
> >>
> >> An example calculation is
> >>
> >>
> >>
> *wilcox.test(c(359,359,359,359,359,359,335,359,359,359,359,359,359,359,359,359,359,359,359,359,359,303,359,359,359),c(332,85,359,359,359,220,231,300,359,237,359,183,286,355,250,105,359,359,298,359,359,359,28.6,359,359,128))*
> >>
> >> which prints
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> *Wilcoxon rank sum test with continuity correction  data: c(359, 359,
> 359,
> >> 359, 359, 359, 335, 359, 359, 359, 359, 359, and c(332, 85, 359, 359,
> 359,
> >> 220, 231, 300, 359, 237, 359, 183, 359, 359, 359, 359, 359, 359, 359,
> 359,
> >> 359, 303, 359, 359, and 286, 355, 250, 105, 359, 359, 298, 359, 359,
> 359,
> >> 28.6, 359, 359) and 359, 128)  W = 485, p-value = 0.0002594 alternative
> >> hypothesis: true location shift is not equal to 0 Warning message: In
> >> wilcox.test.default(c(359, 359, 359, 359, 359, 359, 335, 359, : cannot
> >> compute exact p-value with ties*
> >>
> >>
> >> However, all of the online calculators find p-values close to 0.0025,
> 10x
> >> the value output by R. All results are for a two-tailed case.
> Importantly,
> >> the W value computed by R *does agree* with the U values output by the
> >> first two online calculators listed above, yet it has a different
> p-value.
> >>
> >> Can anyone shed some light on how and why R's calculation differs from
> that
> >> of these online calculators? Thanks for your time.
> >>
> >> ____________________
> >> W. Bradley Knox, PhD
> >> http://bradknox.net
> >> bradknox at mit.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>
> <mailto:bradknox at mit.edu
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>
> <mailto:R-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>>
> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>
> <mailto:R-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>>
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=pd.mes at cbs.dk>  Priv:
> PDalgd at gmail.com
> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=PDalgd at gmail.com>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Sep  4 16:30:52 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Sep 2014 16:30:52 +0200
Subject: [R] wilcox.test - difference between p-values of R and online
	calculators
In-Reply-To: <CALxY2LdfRzeid73cz2MyPC4i5m56KuUvwFXq=kz4KGsJWhY9Hg@mail.gmail.com>
References: <CALxY2LdfRzeid73cz2MyPC4i5m56KuUvwFXq=kz4KGsJWhY9Hg@mail.gmail.com>
Message-ID: <756D6E17-F42A-4BDF-BAC2-997E1BB902E3@gmail.com>

Yes, that is the point that David made and that I illustrated with the simulations: The null distribution of W is more narrow in the presence of ties, hence W=485 is a more extreme observation in the tied case. I.e. it will look less extreme if you ignore that there are ties.

-pd

On 04 Sep 2014, at 15:17 , Lorenz, David <lorenz at usgs.gov> wrote:

>  I think that the issue, at least with the online calculator that I looked
> at, is that it does not  adjust the standard deviation of the test
> statistic for ties, so the standard deviation is larger and hence larger
> p-value. I was able to reproduce the reported z-score using the equation
> for the standard deviation with out ties.
> Dave
> 
> Message: 14
>> Date: Wed, 3 Sep 2014 23:20:04 +0200
>> From: peter dalgaard <pdalgd at gmail.com
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=pdalgd at gmail.com>>
>> To: David L Carlson <dcarlson at tamu.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=dcarlson at tamu.edu>>
>> Cc: "r-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>"
>> <r-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>>,
>>    W Bradley Knox
>>        <bradknox at mit.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>>
>> Subject: Re: [R] wilcox.test - difference between p-values of R and
>>        online  calculators
>> Message-ID: <FFDE9637-160E-4555-9C2A-E944947000D7 at gmail.com
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=FFDE9637-160E-4555-9C2A-E944947000D7 at gmail.com>
>>> 
>> Content-Type: text/plain; charset=us-ascii
>> 
>> Notice that correct=TRUE for wilcox.test refers to the continuity
>> correction, not the correction for ties.
>> 
>> You can fairly easily simulate from the exact distribution of W:
>> 
>> x <- c(359,359,359,359,359,359,335,359,359,359,359,
>>      359,359,359,359,359,359,359,359,359,359,303,359,359,359)
>> y <- c(332,85,359,359,359,220,231,300,359,237,359,183,286,
>>      355,250,105,359,359,298,359,359,359,28.6,359,359,128)
>> R <- rank(c(x,y))
>> sim <- replicate(1e6,sum(sample(R,25))) - 325
>> 
>> # With no ties, the ranks would be a permutation of 1:51, and we could do
>> sim2 <- replicate(1e6,sum(sample(1:51,25))) - 325
>> 
>> In either case, the p-value is the probability that W >= 485 or W <= 165,
>> and
>> 
>>> mean(sim >= 485 | sim <= 165)
>> [1] 0.000151
>>> mean(sim2 >= 485 | sim2 <= 165)
>> [1] 0.002182
>> 
>> Also, try
>> 
>> plot(density(sim))
>> lines(density(sim2))
>> 
>> and notice that the distribution of sim is narrower than that of sim2
>> (hence the smaller p-value with tie correction), but also that the normal
>> approximationtion is not nearly as good as for the untied case. The
>> "clumpiness" is due to the fact that 35 of the ranks have the maximum value
>> of 34 (corresponding to the original 359's).
>> 
>> -pd
>> 
>> On 03 Sep 2014, at 19:13 , David L Carlson <dcarlson at tamu.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=dcarlson at tamu.edu>>
>> wrote:
>> 
>>> Since they all have the same W/U value, it seems likely that the
>> difference is how the different versions adjust the standard error for
>> ties. Here are a couple of posts addressing the issues of ties:
>>> 
>>> http://tolstoy.newcastle.edu.au/R/e8/help/09/12/9200.html
>>> 
>> http://stats.stackexchange.com/questions/6127/which-permutation-test-implementation-in-r-to-use-instead-of-t-tests-paired-and
>>> 
>>> David C
>>> 
>>> From: wbradleyknox at gmail.com
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=wbradleyknox at gmail.com>
>> [mailto:wbradleyknox at gmail.com
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=wbradleyknox at gmail.com>]
>> On Behalf Of W Bradley Knox
>>> Sent: Wednesday, September 3, 2014 9:20 AM
>>> To: David L Carlson
>>> Cc: Tal Galili; r-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>
>>> Subject: Re: [R] wilcox.test - difference between p-values of R and
>> online calculators
>>> 
>>> Tal and David, thanks for your messages.
>>> 
>>> I should have added that I tried all variations of true/false values for
>> the exact and correct parameters. Running with correct=FALSE makes only a
>> tiny change, resulting in W = 485, p-value = 0.0002481.
>>> 
>>> At one point, I also thought that the discrepancy between R and these
>> online calculators might come from how ties are handled, but the fact that
>> R and two of the online calcultors reach the same U/W values seems to
>> indicate that ties aren't the issue, since (I believe) the U or W values
>> contain all of the information needed to calculate the p-value, assuming
>> the number of samples is also known for each condition. (However, it's been
>> a while since I looked into how MWU tests work, so maybe now's the time to
>> refresh.) If that's correct, the discrepancy seems to be based in what R
>> does with the W value that is identical to the U values of two of the
>> online calculators. (I'm also assuming that U and W have the same meaning,
>> which seems likely.)
>>> 
>>> - Brad
>>> 
>>> ____________________
>>> W. Bradley Knox, PhD
>>> http://bradknox.net<http://bradknox.net/>
>>> bradknox at mit.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>
>> <mailto:bradknox at mit.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>>
>>> 
>>> On Wed, Sep 3, 2014 at 9:10 AM, David L Carlson <dcarlson at tamu.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=dcarlson at tamu.edu>
>> <mailto:dcarlson at tamu.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=dcarlson at tamu.edu>>>
>> wrote:
>>> That does not change the results. The problem is likely to be the way
>> ties are handled. The first sample has 25 values of which 23 are identical
>> (359). The second sample has 26 values of which 12 are identical (359). The
>> difference between the implementations may be a result of the way the ties
>> are ranked. For example the R function rank() offers 5 different ways of
>> handling the rank on tied observations. With so many ties, that could make
>> a substantial difference.
>>> 
>>> Package coin has wilxon_test() which uses Monte Carlo simulation to
>> estimate the confidence limits.
>>> 
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>> 
>>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help-bounces at r-project.org>
>> <mailto:r-help-bounces at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help-bounces at r-project.org>>
>> [mailto:r-help-bounces at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help-bounces at r-project.org>
>> <mailto:r-help-bounces at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help-bounces at r-project.org>>]
>> On Behalf Of Tal Galili
>>> Sent: Wednesday, September 3, 2014 5:24 AM
>>> To: W Bradley Knox
>>> Cc: r-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>
>> <mailto:r-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=r-help at r-project.org>>
>>> Subject: Re: [R] wilcox.test - difference between p-values of R and
>> online calculators
>>> 
>>> It seems your numbers has ties. What happens if you run wilcox.test with
>>> correct=FALSE, will the results be the same as the online calculators?
>>> 
>>> 
>>> 
>>> ----------------Contact
>>> Details:-------------------------------------------------------
>>> Contact me: Tal.Galili at gmail.com
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=Tal.Galili at gmail.com>
>> <mailto:Tal.Galili at gmail.com
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=Tal.Galili at gmail.com>>
>> |
>>> Read me: www.talgalili.com<http://www.talgalili.com> (Hebrew) |
>> www.biostatistics.co.il<http://www.biostatistics.co.il> (Hebrew) |
>>> www.r-statistics.com<http://www.r-statistics.com> (English)
>>> 
>> ----------------------------------------------------------------------------------------------
>>> 
>>> 
>>> 
>>> On Wed, Sep 3, 2014 at 3:54 AM, W Bradley Knox <bradknox at mit.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>
>> <mailto:bradknox at mit.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>>>
>> wrote:
>>> 
>>>> Hi.
>>>> 
>>>> I'm taking the long-overdue step of moving from using online
>> calculators to
>>>> compute results for Mann-Whitney U tests to a more streamlined system
>>>> involving R.
>>>> 
>>>> However, I'm finding that R computes a different result than the 3
>> online
>>>> calculators that I've used before (all of which approximately agree).
>> These
>>>> calculators are here:
>>>> 
>>>> http://elegans.som.vcu.edu/~leon/stats/utest.cgi
>>>> http://vassarstats.net/utest.html
>>>> http://www.socscistatistics.com/tests/mannwhitney/
>>>> 
>>>> An example calculation is
>>>> 
>>>> 
>>>> 
>> *wilcox.test(c(359,359,359,359,359,359,335,359,359,359,359,359,359,359,359,359,359,359,359,359,359,303,359,359,359),c(332,85,359,359,359,220,231,300,359,237,359,183,286,355,250,105,359,359,298,359,359,359,28.6,359,359,128))*
>>>> 
>>>> which prints
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> *Wilcoxon rank sum test with continuity correction  data: c(359, 359,
>> 359,
>>>> 359, 359, 359, 335, 359, 359, 359, 359, 359, and c(332, 85, 359, 359,
>> 359,
>>>> 220, 231, 300, 359, 237, 359, 183, 359, 359, 359, 359, 359, 359, 359,
>> 359,
>>>> 359, 303, 359, 359, and 286, 355, 250, 105, 359, 359, 298, 359, 359,
>> 359,
>>>> 28.6, 359, 359) and 359, 128)  W = 485, p-value = 0.0002594 alternative
>>>> hypothesis: true location shift is not equal to 0 Warning message: In
>>>> wilcox.test.default(c(359, 359, 359, 359, 359, 359, 335, 359, : cannot
>>>> compute exact p-value with ties*
>>>> 
>>>> 
>>>> However, all of the online calculators find p-values close to 0.0025,
>> 10x
>>>> the value output by R. All results are for a two-tailed case.
>> Importantly,
>>>> the W value computed by R *does agree* with the U values output by the
>>>> first two online calculators listed above, yet it has a different
>> p-value.
>>>> 
>>>> Can anyone shed some light on how and why R's calculation differs from
>> that
>>>> of these online calculators? Thanks for your time.
>>>> 
>>>> ____________________
>>>> W. Bradley Knox, PhD
>>>> http://bradknox.net
>>>> bradknox at mit.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>
>> <mailto:bradknox at mit.edu
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=bradknox at mit.edu>>
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>
>> <mailto:R-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>>
>> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>
>> <mailto:R-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>>
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=R-help at r-project.org>
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=pd.mes at cbs.dk>  Priv:
>> PDalgd at gmail.com
>> <https://mail.google.com/mail/?view=cm&fs=1&tf=1&to=PDalgd at gmail.com>
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From torbjorn.lindahl at gmail.com  Thu Sep  4 16:41:20 2014
From: torbjorn.lindahl at gmail.com (=?UTF-8?Q?Torbj=C3=B8rn_Lindahl?=)
Date: Thu, 4 Sep 2014 16:41:20 +0200
Subject: [R] Operator proposal: %between%
Message-ID: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>

Not sure if this is the proper list to propose changes like this, if it
passes constructive criticism, it would like to have a %between% operator
in the R language.

I currently have this in my local R startup script:

`%between%` <- function(x,...) {
  y <- range( unlist(c(...)) )
  return( x >= y[1] & x =< y[2] )
}

It allows me to do things like: 5 %between c(1,10)

and also as act as an "in_range" operator:
foo %between% a.long.list.with.many.values

This may seem unnecessary, since 5 >= foo[1] && foo<= foo[2] is also quite
short to type, but there is a mental cost to this, eg if you are deeply
focused on a complicated program flow, the %between% construct is a lot
easier to type out, and relate to, than the logically more complex
construct with && and <=/>=, at least in my experience.

-- 
mvh
Torbj?rn Lindahl

	[[alternative HTML version deleted]]


From Tim.Williams at ucb.com  Thu Sep  4 16:57:30 2014
From: Tim.Williams at ucb.com (Tim.Williams at ucb.com)
Date: Thu, 4 Sep 2014 14:57:30 +0000
Subject: [R] Convert time zone to difference from Coordinated
Message-ID: <C74091AA8BDDA94D8DA9980B20A9A7F43F40E4E3@BRAEXCAP011.dir.ucb-group.com>

Thank you for your reply.  %z fits the bill perfectly.



Apologies for my breach of etiquette on my first post to the list.



-          Tim

R 3.1.1 on Windows 7 OS



From: Prof Brian Ripley <ripley at stats.ox.ac.uk>

To: r-help at r-project.org

Subject: Re: [R] Convert time zone to difference from Coordinated

                Universal Time

Message-ID: <54080C8F.4030603 at stats.ox.ac.uk>

Content-Type: text/plain; charset=windows-1252; format=flowed



On 04/09/2014 02:27, Tim.Williams at ucb.com wrote:

> Hello everyone,

>

> I want to convert times provided by Sys.time()  to use  the difference from Coordinated Universal Time instead of the character abbreviation.

>

> For example, instead of:

> 2014-09-03 21:12:35 EDT

>

> I want the value as:

> 2004-09-03 13:20:00-04:00

>

> Is there a way to do this with strftime() ?



On some systems.  Although the posting guide required it, you did not

provide information on yours.



Please do read the help page for yourself -- %z is relevant.

________________________________
UCB BIOSCIENCES, Inc.
Mail P.O. Box 110167 - Research Triangle Park - NC 27709 - USA
Via Courier 8010 Arco Corporate Drive - Suite 100 - Raleigh - NC 27617 - USA
Phone +1 919 767 2555 - Fax +1 919 767 2570

(Ref: #*UBI0111) [Ref-UBI0111]
________________________________
Legal Notice: This electronic mail and its attachments a...{{dropped:16}}


From murdoch.duncan at gmail.com  Thu Sep  4 17:01:48 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 04 Sep 2014 11:01:48 -0400
Subject: [R] Operator proposal: %between%
In-Reply-To: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
Message-ID: <54087EDC.9060908@gmail.com>

On 04/09/2014 10:41 AM, Torbj?rn Lindahl wrote:
> Not sure if this is the proper list to propose changes like this, if it
> passes constructive criticism, it would like to have a %between% operator
> in the R language.

But it appears that you do:
>
> I currently have this in my local R startup script:
>
> `%between%` <- function(x,...) {
>    y <- range( unlist(c(...)) )
>    return( x >= y[1] & x =< y[2] )
> }
>
> It allows me to do things like: 5 %between c(1,10)
>
> and also as act as an "in_range" operator:
> foo %between% a.long.list.with.many.values

So what you are asking is that someone should make this available to 
others, as well.  That seems like a reasonable thing to do, but why 
shouldn't that someone be you?
>
> This may seem unnecessary, since 5 >= foo[1] && foo<= foo[2] is also quite
> short to type, but there is a mental cost to this, eg if you are deeply
> focused on a complicated program flow, the %between% construct is a lot
> easier to type out, and relate to, than the logically more complex
> construct with && and <=/>=, at least in my experience.
>
One problem with your definition is that it's not clear it does the 
right thing when x is a vector.  I might have a vector of lower bounds, 
and a vector of upper bounds, and want to check each element of x 
against the corresponding bound, i.e. compute

  lower <= x & x <= upper

Your %between% operator could be rewritten so that x %between% 
cbind(lower, upper) would give this result, but it doesn't do so now.   
(I'm not saying you *should* rewrite it like that, but it's something 
you should consider.)

Duncan Murdoch


From leek2 at llnl.gov  Thu Sep  4 17:36:21 2014
From: leek2 at llnl.gov (Jim Leek)
Date: Thu, 04 Sep 2014 08:36:21 -0700
Subject: [R] snow/Rmpi without MPI.spawn?
In-Reply-To: <54085528.4050907@fhcrc.org>
References: <54079553.6090807@llnl.gov> <5407AD48.3050906@fhcrc.org>
	<6B554E87D42BA74AB76EC1D40C57A0DA75C4130C@PRDEXMBX-04.the-lab.llnl.gov>
	<54085528.4050907@fhcrc.org>
Message-ID: <540886F5.70005@llnl.gov>

Ah, now it's working.  Thanks.  Now I just need to figure out how to get 
snow doing this...

Jim

On 09/04/2014 05:03 AM, Martin Morgan wrote:
> On 09/03/2014 10:24 PM, Leek, Jim wrote:
>> Thanks for the tips.  I'll take a look around for for loops in the 
>> morning.
>>
>> I think the example you provided worked for OpenMPI.  (The default on 
>> our machine is MPICH2, but it gave the same error about calling 
>> spawn.)  Anyway, with OpenMPI I got this:
>>
>>> # salloc -n 12 orterun -n 1 R -f spawn.R
>>> library(Rmpi)
>>> ## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- 
>>> mpi.universe.size()
>
> (the '## Recent Rmpi bug' comment should have been removed, it's a 
> holdover from when the script was written several years ago)
>
>>> nslaves = 4
>>> mpi.spawn.Rslaves(nslaves)
>
> The argument needs to be named
>
>   mpi.spawn.Rslaves(nslaves=4)
>
> otherwise R matches unnamed arguments by position, and '4' is 
> associated with the 'Rscript' argument.
>
> Martin
>
>> Reported: 2 (out of 2) daemons - 4 (out of 4) procs
>>
>> Then it hung there.  So things spawned anyway, which is progress.  
>> I'm just not sure is that expected behavior for parSupply or not.
>>
>> Jim
>>
>> -----Original Message-----
>> From: Martin Morgan [mailto:mtmorgan at fhcrc.org]
>> Sent: Wednesday, September 03, 2014 5:08 PM
>> To: Leek, Jim; r-help at r-project.org
>> Subject: Re: [R] snow/Rmpi without MPI.spawn?
>>
>> On 09/03/2014 03:25 PM, Jim Leek wrote:
>>> I'm a programmer at a high-performance computing center.  I'm not very
>>> familiar with R, but I have used MPI from C, C++, and Python. I have
>>> to run an R code provided by a guy who knows R, but not MPI. So, this
>>> fellow used the R snow library to parallelize his R code
>>> (theoretically, I'm not actually sure what he did.)  I need to get
>>> this code running on our machines.
>>>
>>> However, Rmpi and snow seem to require mpi spawn, which our computing
>>> center doesn't support.  I even tried building Rmpi with MPICH1
>>> instead of 2, because Rmpi has that option, but it still tries to 
>>> use spawn.
>>>
>>> I can launch plenty of processes, but I have to launch them all at
>>> once at the beginning. Is there any way to convince Rmpi to just use
>>> those processes rather than trying to spawn its own?  I haven't found
>>> any documentation on this issue, although I would've thought it 
>>> would be quite common.
>>
>> This script
>>
>> spawn.R
>> =======
>> # salloc -n 12 orterun -n 1 R -f spawn.R
>> library(Rmpi)
>> ## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- 
>> mpi.universe.size()
>> mpi.spawn.Rslaves(nslaves=nWorkers)
>> mpiRank <- function(i)
>>     c(i=i, rank=mpi.comm.rank())
>> mpi.parSapply(seq_len(2*nWorkers), mpiRank)
>> mpi.close.Rslaves()
>> mpi.quit()
>>
>> can be run like the comment suggests
>>
>>      salloc -n 12 orterun -n 1 R -f spawn.R
>>
>> uses slurm (or whatever job manager) to allocate resources for 12 
>> tasks and spawn within that allocation. Maybe that's 'good enough' -- 
>> spawning within the assigned allocation? Likely this requires minimal 
>> modification of the current code.
>>
>> More extensive is to revise the manager/worker-style code to 
>> something more like single instruction, multiple data
>>
>>
>> simd.R
>> ======
>> ## salloc -n 4 orterun R --slave -f simd.R
>> sink("/dev/null") # don't capture output -- more care needed here
>> library(Rmpi)
>>
>> TAGS = list(FROM_WORKER=1L)
>> .comm = 0L
>>
>> ## shared `work', here just determine rank and host
>> work = c(rank=mpi.comm.rank(.comm),
>>            host=system("hostname", intern=TRUE))
>>
>> if (mpi.comm.rank(.comm) == 0) {
>>       ## manager
>>       mpi.barrier(.comm)
>>       nWorkers = mpi.comm.size(.comm)
>>       res = list(nWorkers)
>>       for (i in seq_len(nWorkers - 1L)) {
>>           res[[i]] <- mpi.recv.Robj(mpi.any.source(), TAGS$FROM_WORKER,
>>                                     comm=.comm)
>>       }
>>       res[[nWorkers]] = work
>>       sink() # start capturing output
>>       print(do.call(rbind, res))
>> } else {
>>       ## worker
>>       mpi.barrier(.comm)
>>       mpi.send.Robj(work, 0L, TAGS$FROM_WORKER, comm=.comm)
>> }
>> mpi.quit()
>>
>> but this likely requires some serious code revision; if going this 
>> route then
>> http://r-pbd.org/ might be helpful (and from a similar HPC environment).
>>
>> It's always worth asking whether the code is written to be efficient 
>> in R -- a
>> typical 'mistake' is to write R-level explicit 'for' loops that
>> "copy-and-append" results, along the lines of
>>
>>      len <- 100000
>>      result <- NULL
>>      for (i in seq_len(len))
>>          ## some complicated calculation, then...
>>          result <- c(result, sqrt(i))
>>
>> whereas it's much better to "pre-allocate and fill"
>>
>>       result <- integer(len)
>>       for (i in seq_len(len))
>>           result[[i]] = sqrt(i)
>>
>> or
>>
>>       lapply(seq_len(len), sqrt)
>>
>> and very much better still to 'vectorize'
>>
>>       result <- sqrt(seq_len(len))
>>
>> (timing for me are about 1 minute for "copy-and-append", .2 s for 
>> "pre-allocate
>> and fill", and .002s for "vectorize").
>>
>> Pushing back on the guy providing the code (grep for "for" loops, and 
>> look for
>> that copy-and-append pattern) might save you from having to use parallel
>> evaluation at all.
>>
>> Martin
>>
>>>
>>> Thanks,
>>> Jim
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>


From 538280 at gmail.com  Thu Sep  4 17:40:12 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 4 Sep 2014 09:40:12 -0600
Subject: [R] Covariance between two dichotomous variables
In-Reply-To: <CAGcnpaQy9M1kW+9OqDRm5Ayj78hOz8rdy=8Oq5VxAB+uAVr2AQ@mail.gmail.com>
References: <CAGcnpaQy9M1kW+9OqDRm5Ayj78hOz8rdy=8Oq5VxAB+uAVr2AQ@mail.gmail.com>
Message-ID: <CAFEqCdwQgU6mXGeRgCZvc3nhRSQTnJ4GMMe2XkNoLske1khDnQ@mail.gmail.com>

If you have 2 dichotomous variables coded 0/1 (and stored as numerics)
then the var and cov functions can be used to compute the covariance
as if they were continuous variables.  Some algebra shows that the
continous covariance and the binomial covariance only differ by the
denominator (n for binomial, n-1 for continuous), for large sample
sizes the difference is trivial, for small sample sizes (or even large
if you want) you can just multiply by (n-1)/n to correct.

On Tue, Sep 2, 2014 at 10:29 PM, Heather Kettrey
<heather.h.kettrey at vanderbilt.edu> wrote:
> Hi,
>
> I am trying to test a mediation hypothesis using coefficients from logistic
> regression analyses (x, m, and y are all dichotomous). I am running a test
> of significance using MacKinnon and Dwyer's adaptation of Sobel's test
> (i.e., correcting for different scales of coefficients in cases of a
> dichotomous outcome).
>
> In order to make this correction I need to compute the covariance between x
> and m. I have searched various R packages and the R-help page archive and
> cannot find a way to do this in R.
>
> Does anyone know how to compute the covariance between two dichotomous
> variables in R? It seems like there should be a very simple answer to this
> question, but I cannot find it.
>
> Thanks in advance!
>
> Heather
>
>
> --
> Heather Hensman Kettrey
> PhD Candidate
> Department of Sociology
> Vanderbilt University
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jsorkin at grecc.umaryland.edu  Thu Sep  4 18:04:50 2014
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 04 Sep 2014 12:04:50 -0400
Subject: [R] Defining vectors with per-determined correlations
In-Reply-To: <CAFEqCdwQgU6mXGeRgCZvc3nhRSQTnJ4GMMe2XkNoLske1khDnQ@mail.gmail.com>
References: <CAGcnpaQy9M1kW+9OqDRm5Ayj78hOz8rdy=8Oq5VxAB+uAVr2AQ@mail.gmail.com>
	<CAFEqCdwQgU6mXGeRgCZvc3nhRSQTnJ4GMMe2XkNoLske1khDnQ@mail.gmail.com>
Message-ID: <54085562020000CB00113A29@smtp.medicine.umaryland.edu>

I need to define three vectors x, y, z (each of length 100) such that the pair-wise correlations of the vectors have per-defined values r1 and r2. More specifically I need to define x, y, and z so that:
 
corr(x,y) = r1
corr(y,z) = r2
 
Is there any easy way to accomplish this with R?
 
Thank you,
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From luke-tierney at uiowa.edu  Thu Sep  4 18:37:47 2014
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 4 Sep 2014 11:37:47 -0500
Subject: [R] snow/Rmpi without MPI.spawn?
In-Reply-To: <540886F5.70005@llnl.gov>
References: <54079553.6090807@llnl.gov> <5407AD48.3050906@fhcrc.org>
	<6B554E87D42BA74AB76EC1D40C57A0DA75C4130C@PRDEXMBX-04.the-lab.llnl.gov>
	<54085528.4050907@fhcrc.org> <540886F5.70005@llnl.gov>
Message-ID: <alpine.DEB.2.02.1409041136270.2272@luke-Latitude>

You could look into the RMPISNOW shell script that is included in snow
for use with mpirun, eg as

mpirun -np 3 RMPISNOW

The script might need adjusting for your setting.

Best,

luke

On Thu, 4 Sep 2014, Jim Leek wrote:

> Ah, now it's working.  Thanks.  Now I just need to figure out how to get snow 
> doing this...
>
> Jim
>
> On 09/04/2014 05:03 AM, Martin Morgan wrote:
>> On 09/03/2014 10:24 PM, Leek, Jim wrote:
>>> Thanks for the tips.  I'll take a look around for for loops in the 
>>> morning.
>>> 
>>> I think the example you provided worked for OpenMPI.  (The default on our 
>>> machine is MPICH2, but it gave the same error about calling spawn.) 
>>> Anyway, with OpenMPI I got this:
>>> 
>>>> # salloc -n 12 orterun -n 1 R -f spawn.R
>>>> library(Rmpi)
>>>> ## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- 
>>>> mpi.universe.size()
>> 
>> (the '## Recent Rmpi bug' comment should have been removed, it's a holdover 
>> from when the script was written several years ago)
>> 
>>>> nslaves = 4
>>>> mpi.spawn.Rslaves(nslaves)
>> 
>> The argument needs to be named
>>
>>   mpi.spawn.Rslaves(nslaves=4)
>> 
>> otherwise R matches unnamed arguments by position, and '4' is associated 
>> with the 'Rscript' argument.
>> 
>> Martin
>> 
>>> Reported: 2 (out of 2) daemons - 4 (out of 4) procs
>>> 
>>> Then it hung there.  So things spawned anyway, which is progress.  I'm 
>>> just not sure is that expected behavior for parSupply or not.
>>> 
>>> Jim
>>> 
>>> -----Original Message-----
>>> From: Martin Morgan [mailto:mtmorgan at fhcrc.org]
>>> Sent: Wednesday, September 03, 2014 5:08 PM
>>> To: Leek, Jim; r-help at r-project.org
>>> Subject: Re: [R] snow/Rmpi without MPI.spawn?
>>> 
>>> On 09/03/2014 03:25 PM, Jim Leek wrote:
>>>> I'm a programmer at a high-performance computing center.  I'm not very
>>>> familiar with R, but I have used MPI from C, C++, and Python. I have
>>>> to run an R code provided by a guy who knows R, but not MPI. So, this
>>>> fellow used the R snow library to parallelize his R code
>>>> (theoretically, I'm not actually sure what he did.)  I need to get
>>>> this code running on our machines.
>>>> 
>>>> However, Rmpi and snow seem to require mpi spawn, which our computing
>>>> center doesn't support.  I even tried building Rmpi with MPICH1
>>>> instead of 2, because Rmpi has that option, but it still tries to use 
>>>> spawn.
>>>> 
>>>> I can launch plenty of processes, but I have to launch them all at
>>>> once at the beginning. Is there any way to convince Rmpi to just use
>>>> those processes rather than trying to spawn its own?  I haven't found
>>>> any documentation on this issue, although I would've thought it would be 
>>>> quite common.
>>> 
>>> This script
>>> 
>>> spawn.R
>>> =======
>>> # salloc -n 12 orterun -n 1 R -f spawn.R
>>> library(Rmpi)
>>> ## Recent Rmpi bug -- should be mpi.universe.size() nWorkers <- 
>>> mpi.universe.size()
>>> mpi.spawn.Rslaves(nslaves=nWorkers)
>>> mpiRank <- function(i)
>>>     c(i=i, rank=mpi.comm.rank())
>>> mpi.parSapply(seq_len(2*nWorkers), mpiRank)
>>> mpi.close.Rslaves()
>>> mpi.quit()
>>> 
>>> can be run like the comment suggests
>>>
>>>      salloc -n 12 orterun -n 1 R -f spawn.R
>>> 
>>> uses slurm (or whatever job manager) to allocate resources for 12 tasks 
>>> and spawn within that allocation. Maybe that's 'good enough' -- spawning 
>>> within the assigned allocation? Likely this requires minimal modification 
>>> of the current code.
>>> 
>>> More extensive is to revise the manager/worker-style code to something 
>>> more like single instruction, multiple data
>>> 
>>> 
>>> simd.R
>>> ======
>>> ## salloc -n 4 orterun R --slave -f simd.R
>>> sink("/dev/null") # don't capture output -- more care needed here
>>> library(Rmpi)
>>> 
>>> TAGS = list(FROM_WORKER=1L)
>>> .comm = 0L
>>> 
>>> ## shared `work', here just determine rank and host
>>> work = c(rank=mpi.comm.rank(.comm),
>>>            host=system("hostname", intern=TRUE))
>>> 
>>> if (mpi.comm.rank(.comm) == 0) {
>>>       ## manager
>>>       mpi.barrier(.comm)
>>>       nWorkers = mpi.comm.size(.comm)
>>>       res = list(nWorkers)
>>>       for (i in seq_len(nWorkers - 1L)) {
>>>           res[[i]] <- mpi.recv.Robj(mpi.any.source(), TAGS$FROM_WORKER,
>>>                                     comm=.comm)
>>>       }
>>>       res[[nWorkers]] = work
>>>       sink() # start capturing output
>>>       print(do.call(rbind, res))
>>> } else {
>>>       ## worker
>>>       mpi.barrier(.comm)
>>>       mpi.send.Robj(work, 0L, TAGS$FROM_WORKER, comm=.comm)
>>> }
>>> mpi.quit()
>>> 
>>> but this likely requires some serious code revision; if going this route 
>>> then
>>> http://r-pbd.org/ might be helpful (and from a similar HPC environment).
>>> 
>>> It's always worth asking whether the code is written to be efficient in R 
>>> -- a
>>> typical 'mistake' is to write R-level explicit 'for' loops that
>>> "copy-and-append" results, along the lines of
>>>
>>>      len <- 100000
>>>      result <- NULL
>>>      for (i in seq_len(len))
>>>          ## some complicated calculation, then...
>>>          result <- c(result, sqrt(i))
>>> 
>>> whereas it's much better to "pre-allocate and fill"
>>>
>>>       result <- integer(len)
>>>       for (i in seq_len(len))
>>>           result[[i]] = sqrt(i)
>>> 
>>> or
>>>
>>>       lapply(seq_len(len), sqrt)
>>> 
>>> and very much better still to 'vectorize'
>>>
>>>       result <- sqrt(seq_len(len))
>>> 
>>> (timing for me are about 1 minute for "copy-and-append", .2 s for 
>>> "pre-allocate
>>> and fill", and .002s for "vectorize").
>>> 
>>> Pushing back on the guy providing the code (grep for "for" loops, and look 
>>> for
>>> that copy-and-append pattern) might save you from having to use parallel
>>> evaluation at all.
>>> 
>>> Martin
>>> 
>>>> 
>>>> Thanks,
>>>> Jim
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From david at revolutionanalytics.com  Thu Sep  4 19:10:26 2014
From: david at revolutionanalytics.com (David Smith)
Date: Thu, 4 Sep 2014 12:10:26 -0500
Subject: [R] Revolutions blog roundup: August 2014
Message-ID: <CABgvEC8SOP603Ta76a5x=naZR9oRqrqj-QVNQkwZT0TF_U04hg@mail.gmail.com>

Revolution Analytics staff and guests write about R every weekday at
the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of August:

R is the most popular software in the KDNuggets poll for the 4th year
running: http://bit.ly/1AaTLsu

The frequency of R user group meetings continues to rise, and there
are now 147 R user groups worldwide: http://bit.ly/1AaTINi

A video interview with me (David Smith) at the useR! 2014 conference:
http://bit.ly/1AaTINj

In a provocative op-ed, Norm Matloff worries that Statistics is losing
ground to Computer Science: http://bit.ly/1AaTLss

A new certification program for Revolution R Enterprise: http://bit.ly/1AaTJ3D

An interactive map of R user groups around the world, created with R
and Shiny: http://bit.ly/1AaTLst

Using R to generate calendar entries (and create photo opportunities):
http://bit.ly/1AaTINk

Integrating R with production systems with Domino: http://bit.ly/1AaTLsw

The New York Times compares data science to janitorial work:
http://bit.ly/1AaTLsv

Rdocumentation.org provides search for CRAN, GitHub and BioConductor
packages and publishes a top-10 list of packages by downloads:
http://bit.ly/1AaTLsz

An update to the "airlines" data set (the "iris" of Big Data) with
flights through the end of 2012: http://bit.ly/1AaTLsx

A consultant compares the statistical capabilities of R, Matlab, SAS,
Stata and SPSS: http://bit.ly/1AaTINo

Using heatmaps to explore correlations in financial portfolios:
http://bit.ly/1AaTJ3C

Video of John Chambers' keynote at the useR! 2014 conference on the
interfaces, efficiency, big data and the history of R:
http://bit.ly/1AaTLsy

CIO magazine says the open source R language is becoming pervasive:
http://bit.ly/1AaTJ3E

Reviews of some presentations at the JSM 2014 conference that used R:
http://bit.ly/1AaTJ3F

GRAN is a new R package to manage package repositories to support
reproducibility: http://bit.ly/1AaTLIM

The ASA launches a PR campaign to promote the role of statisticians in
society: http://bit.ly/1AaTLIN

Video replay of the webinar Applications in R, featuring examples from
several companies using R: http://bit.ly/1AaTJ3G

General interest stories (not related to R) in the past month
included: dance moves from Japan (http://bit.ly/1AaTLIP), an
earthquake's signal in personal sensors (http://bit.ly/1AaTLIQ), a
3-minute movie in less than 4k (http://bit.ly/1AaTLIR), smooth
time-lapse videos (http://bit.ly/1AaTLIS), representing mazes as trees
(http://bit.ly/1AaTJ3K), and the view from inside a fireworks display
(http://bit.ly/1AaTLIV).

Meeting times for local R user groups
(http://blog.revolutionanalytics.com/local-r-groups.html) can be found
on the updated R Community Calendar at:
http://blog.revolutionanalytics.com/calendar.html

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid

-- 
Try Enterprise R Now!  
<https://aws.amazon.com/marketplace/seller-profile/ref=_ptnr_emailfooter?ie=UTF8&id=3c6536d3-8115-4bc0-a713-be58e257a7be>
Get a 14 Day Free Trial of Revolution R Enterprise on AWS Marketplace


From pabloemilio.verde at hhu.de  Thu Sep  4 10:52:42 2014
From: pabloemilio.verde at hhu.de (Dr. Pablo E. Verde)
Date: Thu, 04 Sep 2014 10:52:42 +0200
Subject: [R] citation of a task view
Message-ID: <5408285A.8090903@hhu.de>

Hi all,

Which is a formal bibliography citation of an R's task view? For example 
if I want to make a citation of "MetaAnalysis" task view.

Thanks in advance!

Pablo


From tonia.marks at yahoo.co.uk  Thu Sep  4 12:53:28 2014
From: tonia.marks at yahoo.co.uk (tonia marks)
Date: Thu, 4 Sep 2014 11:53:28 +0100
Subject: [R] log likelihood and optimize
Message-ID: <1409828008.93181.YahooMailNeo@web171503.mail.ir2.yahoo.com>

Hello

I want to estimate the covariance matrix of the likelihood f(x1,x2,x3)=f(x2|x1)f(x3|x2)f(x1), where f(x2|x1) follows a Binomial distribution with parameters (2, 0.2), f(x3|x2) follows a Binomial distribution with parameters (2, 0.8) and f(x1) follows a Binomial distribution with parameters (2, 0.1). Could you please suggest a way of doing it using log likelihood and optimize?


Many thanks
Tonia Marks

	[[alternative HTML version deleted]]


From angel_nauti at yahoo.com  Thu Sep  4 15:03:56 2014
From: angel_nauti at yahoo.com (Angel Marley)
Date: Thu, 4 Sep 2014 06:03:56 -0700
Subject: [R] mvpart error in R 3.1.1 "s_to_rp" not available for .C()
Message-ID: <1409835836.36896.YahooMailNeo@web125201.mail.ne1.yahoo.com>

Dear R list, 

I'm working with recursive tress using packages mvpart and rpart in R in linux xubuntu (64).

The package performed with no problem under my previous R version (2.14)

I had recently updated my R version to 3.1.1 and when I try to run a mvpart model I get the following error mesage

data(spider)
mvpart(data.matrix(spider[,1:12])~herbs+reft+moss+sand+twigs+water, data=spider)  


Error en .C("s_to_rp", n = as.integer(nobs), nvarx = as.integer(nvar),  : 
  "s_to_rp" not available for .C() for package "mvpart"

I tried to find this problem on the web, but I was not able to find any response.

If you can please help me to solve this problem, I would be grateful.
Best regards and thank you in advance
Angel Segura

PD below you will find R and session info

Working on Ubuntu 12.04.2 LTS \n \l

R.Version()
$platform
[1] "x86_64-pc-linux-gnu"

$arch
[1] "x86_64"

$os
[1] "linux-gnu"

$system
[1] "x86_64, linux-gnu"

$status
[1] ""

$major
[1] "3"

$minor
[1] "1.1"

$year
[1] "2014"

$month
[1] "07"

$day
[1] "10"

$`svn rev`
[1] "66115"

$language
[1] "R"

$version.string
[1] "R version 3.1.1 (2014-07-10)"

$nickname
[1] "Sock it to Me"

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=es_ES.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=es_ES.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] mvpart_1.6-2 rpart_4.1-8 

	[[alternative HTML version deleted]]


From trichter at uni-bremen.de  Thu Sep  4 15:23:54 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Thu, 04 Sep 2014 15:23:54 +0200
Subject: [R] gplot heatmaps: clustering according to rowsidecolors +
	key.xtickfun
Message-ID: <540867EA.8030503@uni-bremen.de>

Hi there,

I have two questions about heatmap.2 in gplot.
My input is a simple square matrix with numeric values between 75 and 
100 (it is a similarity matrix based on bacterial DNA sequences).

1. I can sort my input matrix into categories with rowsidecolors (in 
this case, very conveniently by bacterial taxa). I do a clustering and 
reordering of my matrix by Rowv=TRUE (and Colv="Rowv").
The question is now, can i combine the two features that the 
clustering/reordering is done only for submatrices defined by the 
vectors given in rowsidecolors (so, in this case, that the original 
ordering by bacterial taxa is preserved)?


That would be very amazing.

2. I have set my own coloring rules with:

mypal <- c("grey","blue", "green","yellow","orange","red")
col_breaks = c(seq(0,74.9), seq(75.0,78.4), seq(78.5,81.9), 
seq(82.0,86.4), seq(86.5, 94.5),  seq(94.5,100.0))

Is it possible to pass this sequential ordering to key.xtickfun? May i 
ask for an example code?

Thank you very much!

-- 
Tim Richter-Heitmann (M.Sc.)
PhD Candidate



International Max-Planck Research School for Marine Microbiology
University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


From basiliussap at gmail.com  Thu Sep  4 17:40:21 2014
From: basiliussap at gmail.com (Basilius Sapientia)
Date: Thu, 4 Sep 2014 17:40:21 +0200
Subject: [R] Help with regression
Message-ID: <CACduCw9dp6HTcZYZ2_j0-_YkWCxjpFCgNhSbeMeKsT-rCzH7DA@mail.gmail.com>

I have this code:
Vm <- c(6.2208, 4.9736, 4.1423, 3.1031, 2.4795, 1.6483, 1.2328, 0.98357,
0.81746, 0.60998); #Molvolume
p <- c(0.4, 0.5, 0.6, 0.8, 1, 1.5, 2, 2.5, 3, 4)*1000; #Pressure
Rydb <- 8.3144621; #Constant
Tempi <- 300; #Temperature in Kelvin

Vmi <- Vm^(-1); #To get Vm^(-1)
Zi <- (p*Vm)/(Rydb*Tempi) #To get Z

#Plot
dframe <- data.frame(Vmi, Zi)
plot(dframe, pch=19, col='red', main='Thermodynamic properties of Argon',
xlab='1/Vm', ylab='Z')

#Fit for B
fitb <-lm(Zi ~ Vmi);
fitb$coefficients[1];
fitb$coefficients[2];
summary(fitb)




I want to make a regression on the data with this generel formula:
y=1+Bx+Cx^2. I need to figure out what B and C in this formula is. Please
help me! I want to become better to R.

	[[alternative HTML version deleted]]


From basiliussap at gmail.com  Thu Sep  4 17:41:28 2014
From: basiliussap at gmail.com (Basilius Sapientia)
Date: Thu, 4 Sep 2014 17:41:28 +0200
Subject: [R] R for chemistry
Message-ID: <CACduCw_p82DktvWND+whqT-PMkR8YUR3ygEg21RwjdZ2i9_rkQ@mail.gmail.com>

 Dear community.

I am studying chemistry and physics. We don'te get an intro to mathematic
programms or programming. We shall just find something and use it. So I
have choosen R. But was that  a good choice?

Do you think I could get threw my study with R as my only programming
language (combined with C++) and as my only mathematic "calculator". Is it
an alternative to MatLab? Or is R just for statistics?

Hopefully anyone can answer this question? Kind regards!

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Sep  4 19:16:56 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 04 Sep 2014 13:16:56 -0400
Subject: [R] citation of a task view
In-Reply-To: <5408285A.8090903@hhu.de>
References: <5408285A.8090903@hhu.de>
Message-ID: <54089E88.6080400@gmail.com>

On 04/09/2014 4:52 AM, Dr. Pablo E. Verde wrote:
> Hi all,
>
> Which is a formal bibliography citation of an R's task view? For example
> if I want to make a citation of "MetaAnalysis" task view.
>
> Thanks in advance!

I don't think there is a recognized standard one.  I would use whatever 
format your journal requires for citing any web page, e.g. something like

Lewin-Koh, Nicholas (2013).  CRAN Task View: Graphic Displays & Dynamic 
Graphics & Graphic Devices & Visualization.
Web page with URL <http://cran.r-project.org/web/views/Bayesian.html>, 
retrieved Sept. 4, 2014.

Duncan Murdoch


From istazahn at gmail.com  Thu Sep  4 19:32:36 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 4 Sep 2014 13:32:36 -0400
Subject: [R] Defining vectors with per-determined correlations
In-Reply-To: <54085562020000CB00113A29@smtp.medicine.umaryland.edu>
References: <CAGcnpaQy9M1kW+9OqDRm5Ayj78hOz8rdy=8Oq5VxAB+uAVr2AQ@mail.gmail.com>
	<CAFEqCdwQgU6mXGeRgCZvc3nhRSQTnJ4GMMe2XkNoLske1khDnQ@mail.gmail.com>
	<54085562020000CB00113A29@smtp.medicine.umaryland.edu>
Message-ID: <CA+vqiLHqvQjqWyNdmMCsKTTXnCgET4_9LhF6iAsOnPA=4B1t4Q@mail.gmail.com>

See ?mvrnorm in the MASS package.

Best,
Ista


On Thu, Sep 4, 2014 at 12:04 PM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> I need to define three vectors x, y, z (each of length 100) such that the
> pair-wise correlations of the vectors have per-defined values r1 and r2.
> More specifically I need to define x, y, and z so that:
>
> corr(x,y) = r1
> corr(y,z) = r2
>
> Is there any easy way to accomplish this with R?
>
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:18}}


From rshepard at appl-ecosys.com  Thu Sep  4 19:42:17 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 4 Sep 2014 10:42:17 -0700 (PDT)
Subject: [R] R for chemistry
In-Reply-To: <CACduCw_p82DktvWND+whqT-PMkR8YUR3ygEg21RwjdZ2i9_rkQ@mail.gmail.com>
References: <CACduCw_p82DktvWND+whqT-PMkR8YUR3ygEg21RwjdZ2i9_rkQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.11.1409041030030.25008@localhost>

On Thu, 4 Sep 2014, Basilius Sapientia wrote:

> So I have choosen R. But was that a good choice?

Basilius,

   Yes. For data analyses. While you could use R as a general programming
language, but others are better suited.

> Do you think I could get threw my study with R as my only programming
> language (combined with C++) and as my only mathematic "calculator". Is it
> an alternative to MatLab? Or is R just for statistics?

   Take a close look at Python. It has extensive scientific support (NumPy,
SciPy, Pandas, etc.) and can do what MatLab does (so does the open-source
Octave, by the way). It's also used for general progamming; for example, the
Mailman mailing list manager is written in python. I moved from C to Python
a number of years ago and have no regrets.

Rich


From kmezhoud at gmail.com  Thu Sep  4 20:02:24 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 4 Sep 2014 19:02:24 +0100
Subject: [R] Built R package with example
Message-ID: <CALJKBv9OtsqJpipUQ-UA++P2pjxZAXtYOjXAzasaEf=fXNZWbQ@mail.gmail.com>

Dear All,
How can I add folder content  examples of needed files to run example?
The simple add of folder did not built and reload with the package.

Thanks!
Karim

	[[alternative HTML version deleted]]


From sjkiss at gmail.com  Thu Sep  4 20:28:05 2014
From: sjkiss at gmail.com (Simon Kiss)
Date: Thu, 4 Sep 2014 14:28:05 -0400
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing	A
	Data	Frame
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9132B@mb02.ads.tamu.edu>
References: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>
	<696C4B48-C745-4E5A-A3A1-05D2E93991A2@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F910CA@mb02.ads.tamu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9132B@mb02.ads.tamu.edu>
Message-ID: <15332AED-0A26-418B-B81B-B0DAD57BF6B5@gmail.com>

Hi David and list:
This is working, except at this command
mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)

dcast is using "length" as the default aggregating function. This results in not accurate results. It tells me, for example how many choices were missing values and it tells me if a person selected any given option (value is reported as 1).
When I try to run your reproducible research, it works great, but something with the aggregating function is not working properly with mine. 
Any other thoughts?
Simon
On Aug 18, 2014, at 10:44 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Another approach using reshape2:
> 
>> library(reshape2)
>> # Construct data/ add column of row numbers
>> set.seed(42)
>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
> +   "green", "yellow", NA), 4))))
>> mydf <- data.frame(rows=1:100, mydf)
>> colnames(mydf) <- c("row", "rank1", "rank2", "rank3", "rank4")
>> head(mydf)
>  row  rank1  rank2  rank3 rank4
> 1   1   <NA> yellow    red  blue
> 2   2 yellow  green   <NA>   red
> 3   3 yellow  green   blue  <NA>
> 4   4   <NA>   blue yellow green
> 5   5   <NA>    red   blue green
> 6   6   <NA>    red  green  blue
>> # Reshape
>> mymelt <- melt(mydf, id.vars=1, measure.vars=2:5, 
> +     variable.name="rank", value.name="color")
>> # Convert rank to numeric
>> mymelt$rank <- as.numeric(mymelt$rank)
>> mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)
>> head(mycast)
>  row blue green red yellow NA
> 1   1    4     0   3      2  1
> 2   2    0     2   4      1  3
> 3   3    3     2   0      1  4
> 4   4    2     4   0      3  1
> 5   5    3     4   2      0  1
> 6   6    4     3   2      0  1
> 
> David C
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
> Sent: Sunday, August 17, 2014 6:32 PM
> To: Simon Kiss; r-help at r-project.org
> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> There is probably an easier way to do this, but
> 
>> set.seed(42)
>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
> +  "green", "yellow", NA), 4))))
>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>> head(mydf)
>   rank1  rank2  rank3 rank4
> 1   <NA> yellow    red  blue
> 2 yellow  green   <NA>   red
> 3 yellow  green   blue  <NA>
> 4   <NA>   blue yellow green
> 5   <NA>    red   blue green
> 6   <NA>    red  green  blue
>> lvls <- levels(mydf$rank1)
>> # convert color factors to numeric
>> for (i in seq_along(mydf)) mydf[,i] <- as.numeric(mydf[,i]) 
>> # stack the columns
>> mydf2 <- stack(mydf)
>> # convert rank factor to numeric
>> mydf2$ind <- as.numeric(mydf2$ind)
>> # add row numbers
>> mydf2 <- data.frame(rows=1:100, mydf2)
>> # Create table
>> mytbl <- xtabs(ind~rows+values, mydf2)
>> # convert to data frame
>> mydf3 <- data.frame(unclass(mytbl))
>> colnames(mydf3) <- lvls
>> head(mydf3)
>  blue green red yellow
> 1    4     0   3      2
> 2    0     2   4      1
> 3    3     2   0      1
> 4    2     4   0      3
> 5    3     4   2      0
> 6    4     3   2      0
> 
> David C
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
> Sent: Friday, August 15, 2014 3:58 PM
> To: r-help at r-project.org
> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> 
> Both the suggestions I got work very well, but what I didn't realize is that NA values would cause serious problems.  Where there is a missing value, using the argument na.last=NA to order just returns the the order of the factor levels, but excludes the missing values, but I have no idea where those occur in the or rather which of those variables were actually missing.  
> Have I explained this problem sufficiently? 
> I didn't think it would cause such a problem so I didn't include it in the original problem definition.
> Yours, Simon
> On Jul 25, 2014, at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
>> I think this gets what you want. But your data are not reproducible since they are randomly drawn without setting a seed and the two data sets have no relationship to one another.
>> 
>>> set.seed(42)
>>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
>> + "green", "yellow")))))
>>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>>> mydf2 <- data.frame(t(apply(mydf, 1, order)))
>>> colnames(mydf2) <- levels(mydf$rank1)
>>> head(mydf)
>>  rank1  rank2  rank3 rank4
>> 1 yellow  green    red  blue
>> 2  green   blue yellow   red
>> 3  green yellow    red  blue
>> 4 yellow    red  green  blue
>> 5 yellow    red  green  blue
>> 6 yellow    red   blue green
>>> head(mydf2)
>> blue green red yellow
>> 1    4     2   3      1
>> 2    2     1   4      3
>> 3    4     1   3      2
>> 4    4     3   2      1
>> 5    4     3   2      1
>> 6    3     4   2      1
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
>> Sent: Friday, July 25, 2014 2:34 PM
>> To: r-help at r-project.org
>> Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
>> 
>> Hello:
>> I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 
>> 
>> Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
>> I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
>> Thank you
>> Simon
>> #Reproducible code
>> mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))
>> 
>> mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
>> *********************************
>> Simon J. Kiss, PhD
>> Assistant Professor, Wilfrid Laurier University
>> 73 George Street
>> Brantford, Ontario, Canada
>> N3T 2C9
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From Achim.Zeileis at uibk.ac.at  Thu Sep  4 20:28:52 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 4 Sep 2014 20:28:52 +0200 (CEST)
Subject: [R] citation of a task view
In-Reply-To: <54089E88.6080400@gmail.com>
References: <5408285A.8090903@hhu.de> <54089E88.6080400@gmail.com>
Message-ID: <alpine.DEB.2.11.1409042020150.8132@paninaro.uibk.ac.at>

On Thu, 4 Sep 2014, Duncan Murdoch wrote:

> On 04/09/2014 4:52 AM, Dr. Pablo E. Verde wrote:
>> Hi all,
>> 
>> Which is a formal bibliography citation of an R's task view? For example
>> if I want to make a citation of "MetaAnalysis" task view.
>> 
>> Thanks in advance!
>
> I don't think there is a recognized standard one.

Not yet. But since this summer the web pages contain <meta> tags (both in 
Highwire Press and Dublin Core format) that state how the pages can be 
cited.

> I would use whatever format your journal requires for citing any web 
> page, e.g. something like
>
> Lewin-Koh, Nicholas (2013).  CRAN Task View: Graphic Displays & Dynamic 
> Graphics & Graphic Devices & Visualization.
> Web page with URL <http://cran.r-project.org/web/views/Bayesian.html>, 
> retrieved Sept. 4, 2014.

I would recommend two changes: (1) Use the official stable URL 
http://CRAN.R-project.org/view=... (2) Instead of the "retrieved" 
information, use the version date stated on the task view. For example for 
the current version of the MetaAnalysis view:

Michael Dewey (2014). CRAN Task View: Meta-Analysis. Version 2014-07-25.
URL http://CRAN.R-project.org/view=MetaAnalysis.

or in BibTeX:

@Misc{,
   author = {Michael Dewey},
   note = {Version~2014-07-25},
   title = {{CRAN} Task View: Meta-Analysis},
   year = {2014},
   url = {http://CRAN.R-project.org/view=MetaAnalysis}
}

hth,
Z

> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Thu Sep  4 20:29:06 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 04 Sep 2014 11:29:06 -0700
Subject: [R] R for chemistry
In-Reply-To: <CACduCw_p82DktvWND+whqT-PMkR8YUR3ygEg21RwjdZ2i9_rkQ@mail.gmail.com>
References: <CACduCw_p82DktvWND+whqT-PMkR8YUR3ygEg21RwjdZ2i9_rkQ@mail.gmail.com>
Message-ID: <64838831-5396-4975-bb7a-9dbba388a4a3@email.android.com>

R is useful for quite a range of applications, but not everything. I recommend planning on learning multiple programming languages eventually, because each type of problem has its own set of "useful phrases". An example of this in R is comparing the base, lattice, and ggplot models of graph generation... each has its own perspective that is valuable in different contexts. Another example might be in iterative algorithms... these are often implemented in C or C++ or Fortran and called from R. It is common to build packages in R to create convenient groups of functions that are useful for specific problem types, but other languages sometimes have features that make these packages look clumsy. Knowing about how other languages do things can make it easier to see better solutions in R, or even avoid struggling with poorly-suited functions.

In the vein of communicating appropriately, be sure follow the instructions in the footer of this or any other post, which among other things asks you to not post in HTML on this list.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 4, 2014 8:41:28 AM PDT, Basilius Sapientia <basiliussap at gmail.com> wrote:
> Dear community.
>
>I am studying chemistry and physics. We don'te get an intro to
>mathematic
>programms or programming. We shall just find something and use it. So I
>have choosen R. But was that  a good choice?
>
>Do you think I could get threw my study with R as my only programming
>language (combined with C++) and as my only mathematic "calculator". Is
>it
>an alternative to MatLab? Or is R just for statistics?
>
>Hopefully anyone can answer this question? Kind regards!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Sep  4 20:32:42 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 04 Sep 2014 14:32:42 -0400
Subject: [R] citation of a task view
In-Reply-To: <alpine.DEB.2.11.1409042020150.8132@paninaro.uibk.ac.at>
References: <5408285A.8090903@hhu.de> <54089E88.6080400@gmail.com>
	<alpine.DEB.2.11.1409042020150.8132@paninaro.uibk.ac.at>
Message-ID: <5408B04A.7020100@gmail.com>

On 04/09/2014 2:28 PM, Achim Zeileis wrote:
> On Thu, 4 Sep 2014, Duncan Murdoch wrote:
>
> > On 04/09/2014 4:52 AM, Dr. Pablo E. Verde wrote:
> >> Hi all,
> >>
> >> Which is a formal bibliography citation of an R's task view? For example
> >> if I want to make a citation of "MetaAnalysis" task view.
> >>
> >> Thanks in advance!
> >
> > I don't think there is a recognized standard one.
>
> Not yet. But since this summer the web pages contain <meta> tags (both in
> Highwire Press and Dublin Core format) that state how the pages can be
> cited.
>
> > I would use whatever format your journal requires for citing any web
> > page, e.g. something like
> >
> > Lewin-Koh, Nicholas (2013).  CRAN Task View: Graphic Displays & Dynamic
> > Graphics & Graphic Devices & Visualization.
> > Web page with URL <http://cran.r-project.org/web/views/Bayesian.html>,
> > retrieved Sept. 4, 2014.
>
> I would recommend two changes: (1) Use the official stable URL
> http://CRAN.R-project.org/view=... (2) Instead of the "retrieved"
> information, use the version date stated on the task view. For example for
> the current version of the MetaAnalysis view:

Thanks.  One more correction:  I described the Graphics view, but put in 
the link to the Bayesian one :-).  So the real link should have been

http://CRAN.R-project.org/view=Graphics

Duncan Murdoch

>
> Michael Dewey (2014). CRAN Task View: Meta-Analysis. Version 2014-07-25.
> URL http://CRAN.R-project.org/view=MetaAnalysis.
>
> or in BibTeX:
>
> @Misc{,
>     author = {Michael Dewey},
>     note = {Version~2014-07-25},
>     title = {{CRAN} Task View: Meta-Analysis},
>     year = {2014},
>     url = {http://CRAN.R-project.org/view=MetaAnalysis}
> }
>
> hth,
> Z
>
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From dcarlson at tamu.edu  Thu Sep  4 20:35:43 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 4 Sep 2014 18:35:43 +0000
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing	A
 Data	Frame
In-Reply-To: <15332AED-0A26-418B-B81B-B0DAD57BF6B5@gmail.com>
References: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>
	<696C4B48-C745-4E5A-A3A1-05D2E93991A2@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F910CA@mb02.ads.tamu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9132B@mb02.ads.tamu.edu>
	<15332AED-0A26-418B-B81B-B0DAD57BF6B5@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9524E@mb02.ads.tamu.edu>

I think we would need enough of the data you are using to figure out how to modify the process. Can you use dput() to send a small data set that fails to work?

David C

-----Original Message-----
From: Simon Kiss [mailto:sjkiss at gmail.com] 
Sent: Thursday, September 4, 2014 1:28 PM
To: David L Carlson
Cc: r-help at r-project.org
Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame

Hi David and list:
This is working, except at this command
mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)

dcast is using "length" as the default aggregating function. This results in not accurate results. It tells me, for example how many choices were missing values and it tells me if a person selected any given option (value is reported as 1).
When I try to run your reproducible research, it works great, but something with the aggregating function is not working properly with mine. 
Any other thoughts?
Simon
On Aug 18, 2014, at 10:44 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Another approach using reshape2:
> 
>> library(reshape2)
>> # Construct data/ add column of row numbers
>> set.seed(42)
>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
> +   "green", "yellow", NA), 4))))
>> mydf <- data.frame(rows=1:100, mydf)
>> colnames(mydf) <- c("row", "rank1", "rank2", "rank3", "rank4")
>> head(mydf)
>  row  rank1  rank2  rank3 rank4
> 1   1   <NA> yellow    red  blue
> 2   2 yellow  green   <NA>   red
> 3   3 yellow  green   blue  <NA>
> 4   4   <NA>   blue yellow green
> 5   5   <NA>    red   blue green
> 6   6   <NA>    red  green  blue
>> # Reshape
>> mymelt <- melt(mydf, id.vars=1, measure.vars=2:5, 
> +     variable.name="rank", value.name="color")
>> # Convert rank to numeric
>> mymelt$rank <- as.numeric(mymelt$rank)
>> mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)
>> head(mycast)
>  row blue green red yellow NA
> 1   1    4     0   3      2  1
> 2   2    0     2   4      1  3
> 3   3    3     2   0      1  4
> 4   4    2     4   0      3  1
> 5   5    3     4   2      0  1
> 6   6    4     3   2      0  1
> 
> David C
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
> Sent: Sunday, August 17, 2014 6:32 PM
> To: Simon Kiss; r-help at r-project.org
> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> There is probably an easier way to do this, but
> 
>> set.seed(42)
>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
> +  "green", "yellow", NA), 4))))
>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>> head(mydf)
>   rank1  rank2  rank3 rank4
> 1   <NA> yellow    red  blue
> 2 yellow  green   <NA>   red
> 3 yellow  green   blue  <NA>
> 4   <NA>   blue yellow green
> 5   <NA>    red   blue green
> 6   <NA>    red  green  blue
>> lvls <- levels(mydf$rank1)
>> # convert color factors to numeric
>> for (i in seq_along(mydf)) mydf[,i] <- as.numeric(mydf[,i]) 
>> # stack the columns
>> mydf2 <- stack(mydf)
>> # convert rank factor to numeric
>> mydf2$ind <- as.numeric(mydf2$ind)
>> # add row numbers
>> mydf2 <- data.frame(rows=1:100, mydf2)
>> # Create table
>> mytbl <- xtabs(ind~rows+values, mydf2)
>> # convert to data frame
>> mydf3 <- data.frame(unclass(mytbl))
>> colnames(mydf3) <- lvls
>> head(mydf3)
>  blue green red yellow
> 1    4     0   3      2
> 2    0     2   4      1
> 3    3     2   0      1
> 4    2     4   0      3
> 5    3     4   2      0
> 6    4     3   2      0
> 
> David C
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
> Sent: Friday, August 15, 2014 3:58 PM
> To: r-help at r-project.org
> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> 
> Both the suggestions I got work very well, but what I didn't realize is that NA values would cause serious problems.  Where there is a missing value, using the argument na.last=NA to order just returns the the order of the factor levels, but excludes the missing values, but I have no idea where those occur in the or rather which of those variables were actually missing.  
> Have I explained this problem sufficiently? 
> I didn't think it would cause such a problem so I didn't include it in the original problem definition.
> Yours, Simon
> On Jul 25, 2014, at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
>> I think this gets what you want. But your data are not reproducible since they are randomly drawn without setting a seed and the two data sets have no relationship to one another.
>> 
>>> set.seed(42)
>>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
>> + "green", "yellow")))))
>>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>>> mydf2 <- data.frame(t(apply(mydf, 1, order)))
>>> colnames(mydf2) <- levels(mydf$rank1)
>>> head(mydf)
>>  rank1  rank2  rank3 rank4
>> 1 yellow  green    red  blue
>> 2  green   blue yellow   red
>> 3  green yellow    red  blue
>> 4 yellow    red  green  blue
>> 5 yellow    red  green  blue
>> 6 yellow    red   blue green
>>> head(mydf2)
>> blue green red yellow
>> 1    4     2   3      1
>> 2    2     1   4      3
>> 3    4     1   3      2
>> 4    4     3   2      1
>> 5    4     3   2      1
>> 6    3     4   2      1
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
>> Sent: Friday, July 25, 2014 2:34 PM
>> To: r-help at r-project.org
>> Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
>> 
>> Hello:
>> I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 
>> 
>> Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
>> I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
>> Thank you
>> Simon
>> #Reproducible code
>> mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))
>> 
>> mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
>> *********************************
>> Simon J. Kiss, PhD
>> Assistant Professor, Wilfrid Laurier University
>> 73 George Street
>> Brantford, Ontario, Canada
>> N3T 2C9
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From dwinsemius at comcast.net  Thu Sep  4 21:24:50 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Sep 2014 12:24:50 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <5407F315.9060606@yeah.net>
References: <54050401.4060203@yeah.net>	<53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>
	<5407EBAA.6070807@yeah.net> <5407F315.9060606@yeah.net>
Message-ID: <AFB35C66-1DBA-483E-AE60-056D77E11167@comcast.net>


On Sep 3, 2014, at 10:05 PM, Jinsong Zhao wrote:

> On 2014/9/3 21:33, Jinsong Zhao wrote:
>> On 2014/9/2 11:50, David L Carlson wrote:
>>> The bottom of the expression is set by the lowest character (which can
>>> even change for subscripted letters with descenders. The solution is
>>> to get axis() to align the tops of the axis labels and move the line
>>> up to reduce the space, e.g.
>>> 
>>> plot(1:5, xaxt = "n")
>>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>>> "E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
>>> # Check alignment
>>> abline(h=.7, xpd=TRUE, lty=3)
>> 
>> yes. In this situation, padj = 1 is the fast solution. However, If there
>> are also superscript, then it's hard to alignment all the labels.
>> 
>> If R provide a mechanism that aligns the label in axis() or text() with
>> the baseline of the character without the super- and/or sub-script, that
>> will be terrific.
> 
> it seems that the above wish is on the Graphics TODO lists:
> https://www.stat.auckland.ac.nz/~paul/R/graphicstodos.html
> 
> Allow text adjustment for mathematical annotations which is relative to a text baseline (in addition to the current situation where adjustment is relative to the bounding box).
> 

In many case adding a phantom argument will correct aliognment problems:

plot(1:5, xaxt = "n")
axis(1, at = 1:5, labels = c(expression(E[g]), E~phantom(E[g]), expression(E[j]),
E~phantom(E[g]), expression(E[t])))

abline(h=.7, xpd=TRUE, lty=3)

Notice that c(expression(.), ...) will coerce all items separated by commas to expressions, sot you cna just put in "native" expression that are not surrounded by the `expression`-function

c(expression(E[g]), E~phantom(E[g]), expression(E[j])  ) #returns
# expression(E[g], E ~ phantom(E[g]), E[j])

The tilde is actually a function that converts parse-able strings into R language objects:

c(expression(E[g]), E~phantom(E[g]), ~E[j])

-- 
David.

>>> 
>>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org
>>> [mailto:r-help-bounces at r-project.org] On Behalf Of Jinsong Zhao
>>> Sent: Monday, September 1, 2014 6:41 PM
>>> To: r-help at r-project.org
>>> Subject: [R] depth of labels of axis
>>> 
>>> Hi there,
>>> 
>>> With the following code,
>>> 
>>> plot(1:5, xaxt = "n")
>>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>>> "E", expression(E[t])))
>>> 
>>> you may notice that the "E" within labels of axis(1) are not at the same
>>> depth. So the vision of axis(1) labels is something like wave.
>>> 
>>> Is there a possible way to typeset the labels so that they are have the
>>> same depth?
>>> 
>>> Any suggestions will be really appreciated. Thanks in advance.
>>> 
>>> Best regards,
>>> Jinsong

David Winsemius
Alameda, CA, USA


From misilvafbq at gmail.com  Thu Sep  4 20:58:17 2014
From: misilvafbq at gmail.com (Michele Silva)
Date: Thu, 04 Sep 2014 15:58:17 -0300
Subject: [R] structural equation modeling in sem, error,
 The model has negative degrees of freedom = -3,
 and The model is almost surely misspecified...
In-Reply-To: <004501cb7453$4915bca0$db4135e0$@ca>
References: <004501cb7453$4915bca0$db4135e0$@ca>
Message-ID: <5408B649.8020002@gmail.com>

Dear Prof. John,

I'm trying to solve the following model in R, but I getting error about 
the degree of freedom. As I don't have much experience, could you please 
explain to me what is the problem? I'm studying the influence of several 
soil parameters (pH, NH4, OM, Moisture) on the abundance of some 
microbial groups (Nitrosotalea, Nitrosos_Cl1, Nitrosos_Cl3, Nitrosos_Cl4 
e Nitrosos_Cl7), and on enzyme activity (PNA).

Thanks in advance,

Best regards

Michele



mod.pnr1 <- specifyModel()
PD_AOA -> PNA, B1, NA
Nitrosotalea -> PNA, B2, NA
Nitrosos_Cl1 -> PNA, B3, NA
Nitrosos_Cl3 -> PNA, B4, NA
Nitrosos_Cl4 -> PNA, B5, NA
Nitrosos_Cl7 -> PNA, B6, NA
pH -> PNA, B9, NA
NH4 -> PNA, B10, NA
OM -> PNA, B11, NA
Moisture -> PNA, B12, NA
pH -> PD_AOA, B18, NA
NH4 -> PD_AOA, B19, NA
OM -> PD_AOA, B20, NA
Moisture -> PD_AOA, B21, NA
pH -> Nitrosotalea, B22, NA
NH4 -> Nitrosotalea, B23, NA
OM -> Nitrosotalea, B24, NA
Moisture -> Nitrosotalea, B25, NA
pH -> Nitrosos_Cl1, B26, NA
NH4 -> Nitrosos_Cl1, B27, NA
OM -> Nitrosos_Cl1, B28, NA
Moisture -> Nitrosos_Cl1, B29, NA
pH -> Nitrosos_Cl3, B30, NA
NH4 -> Nitrosos_Cl3, B31, NA
OM -> Nitrosos_Cl3, B32, NA
Moisture -> Nitrosos_Cl3, B33, NA
pH -> Nitrosos_Cl4, B34, NA
NH4 -> Nitrosos_Cl4, B35, NA
OM -> Nitrosos_Cl4, B36, NA
Moisture -> Nitrosos_Cl4, B37, NA
pH -> Nitrosos_Cl7, B38, NA
NH4 -> Nitrosos_Cl7, B39, NA
OM -> Nitrosos_Cl7, B40, NA
Moisture -> Nitrosos_Cl7, B41, NA
Nitrosotalea -> Nitrosos_Cl1, B53, NA
Nitrosotalea -> Nitrosos_Cl3, B54, NA
Nitrosotalea -> Nitrosos_Cl4, B55, NA
Nitrosotalea -> Nitrosos_Cl7, B56, NA
Nitrosos_Cl1 -> Nitrosotalea, B57, NA
Nitrosos_Cl1 -> Nitrosos_Cl3, B58, NA
Nitrosos_Cl1 -> Nitrosos_Cl4, B59, NA
Nitrosos_Cl1 -> Nitrosos_Cl7, B60, NA
Nitrosos_Cl3 -> Nitrosotalea, B61, NA
Nitrosos_Cl3 -> Nitrosos_Cl1, B62, NA
Nitrosos_Cl3 -> Nitrosos_Cl4, B63, NA
Nitrosos_Cl3 -> Nitrosos_Cl7, B64, NA
Nitrosos_Cl4 -> Nitrosotalea, B65, NA
Nitrosos_Cl4 -> Nitrosos_Cl1, B66, NA
Nitrosos_Cl4 -> Nitrosos_Cl3, B67, NA
Nitrosos_Cl4 -> Nitrosos_Cl7, B68, NA
Nitrosos_Cl7 -> Nitrosotalea, B69, NA
Nitrosos_Cl7 -> Nitrosos_Cl1, B70, NA
Nitrosos_Cl7 -> Nitrosos_Cl4, B71, NA
Nitrosos_Cl7 -> Nitrosos_Cl3, B72, NA
pH -> NH4, B42, NA
pH -> OM, B43, NA
NH4 -> OM, B45, NA
NH4 -> pH, B46, NA
OM -> NH4, B47, NA
OM -> Moisture, B48, NA
OM -> pH, B52, NA
Moisture -> OM, B70, NA
PNA <-> PNA, e12, NA
PD_AOA <-> PD_AOA, NA, 1
Nitrosotalea <-> Nitrosotalea, e5, NA
Nitrosos_Cl1 <-> Nitrosos_Cl1, e6, NA
Nitrosos_Cl3 <-> Nitrosos_Cl3, e7, NA
Nitrosos_Cl4 <-> Nitrosos_Cl4, e8, NA
Nitrosos_Cl7 <-> Nitrosos_Cl7, e9, NA
NH4 <-> NH4, e6, NA
OM <-> OM, e5, NA
Moisture <-> Moisture, e7, NA
pH <-> pH, NA, 1




-- 
Dra. Michele de C?ssia Pereira e Silva
Escola Superior de Agricultura Luiz de Queiroz (ESALQ)/ USP
Departamento de Ci?ncia do Solo e Nutri??o de Plantas
Laborat?rio de Microbiologia do Solo
Av P?dua Dias, 11 CP 09 CEP-13400-970
Piracicaba - S?o Paulo


	[[alternative HTML version deleted]]


From 538280 at gmail.com  Thu Sep  4 21:54:16 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 4 Sep 2014 13:54:16 -0600
Subject: [R] Operator proposal: %between%
In-Reply-To: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
Message-ID: <CAFEqCdzyYrKhWJnJQCOOCqj1pVprsp0mMSZYEp63voK4yoHHkg@mail.gmail.com>

The TeachingDemos package has %<% and %<=% operators for a between
style comparison.  So for your example you could write:

1 %<% 5 %<% 10

or

1 %<=% 5 %<=% 10

And these operators already work with vectors:

lb %<=% x %<% ub

and can even be further chained:

0 %<% x %<% y %<% z %<% 1  # only points where x < y and y < z and all
between 0 and 1.

It is a little bit different syntax from yours, but would that do what you want?

If not, we could add a %between% function (expand it a bit following
Duncan's suggestion) to the TeachingDemos package if you don't want to
create your own package.

On Thu, Sep 4, 2014 at 8:41 AM, Torbj?rn Lindahl
<torbjorn.lindahl at gmail.com> wrote:
> Not sure if this is the proper list to propose changes like this, if it
> passes constructive criticism, it would like to have a %between% operator
> in the R language.
>
> I currently have this in my local R startup script:
>
> `%between%` <- function(x,...) {
>   y <- range( unlist(c(...)) )
>   return( x >= y[1] & x =< y[2] )
> }
>
> It allows me to do things like: 5 %between c(1,10)
>
> and also as act as an "in_range" operator:
> foo %between% a.long.list.with.many.values
>
> This may seem unnecessary, since 5 >= foo[1] && foo<= foo[2] is also quite
> short to type, but there is a mental cost to this, eg if you are deeply
> focused on a complicated program flow, the %between% construct is a lot
> easier to type out, and relate to, than the logically more complex
> construct with && and <=/>=, at least in my experience.
>
> --
> mvh
> Torbj?rn Lindahl
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jfox at mcmaster.ca  Thu Sep  4 22:00:28 2014
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 4 Sep 2014 16:00:28 -0400
Subject: [R] structural equation modeling in sem, error,
	The model has negative degrees of freedom = -3,
	and The model is almost surely misspecified...
In-Reply-To: <5408B649.8020002@gmail.com>
References: <004501cb7453$4915bca0$db4135e0$@ca> <5408B649.8020002@gmail.com>
Message-ID: <004c01cfc87a$dff93410$9feb9c30$@mcmaster.ca>

Dear Michele,

It's impossible to know without the data, since that's the only way to determine which variables in the model are observed and which are latent variables, but if there are negative df, then you're trying to estimate a model with more free parameters than there are moments (typically, covariances) among the observed variables. Clearly, such a model is necessarily underidentified.

Additionally, I suggest that you use specifyEquations() in preference to specifyModel() to describe the model. That should prove simpler (but of course won't allow you to estimate an underidentified model).

I hope this helps,
 John

-----------------------------------------------
John Fox, Professor
Chair, Sociology Graduate Programme
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Michele Silva
> Sent: Thursday, September 04, 2014 2:58 PM
> To: r-help at r-project.org
> Subject: Re: [R] structural equation modeling in sem, error, The model
> has negative degrees of freedom = -3, and The model is almost surely
> misspecified...
> 
> Dear Prof. John,
> 
> I'm trying to solve the following model in R, but I getting error about
> the degree of freedom. As I don't have much experience, could you
> please
> explain to me what is the problem? I'm studying the influence of
> several
> soil parameters (pH, NH4, OM, Moisture) on the abundance of some
> microbial groups (Nitrosotalea, Nitrosos_Cl1, Nitrosos_Cl3,
> Nitrosos_Cl4
> e Nitrosos_Cl7), and on enzyme activity (PNA).
> 
> Thanks in advance,
> 
> Best regards
> 
> Michele
> 
> 
> 
> mod.pnr1 <- specifyModel()
> PD_AOA -> PNA, B1, NA
> Nitrosotalea -> PNA, B2, NA
> Nitrosos_Cl1 -> PNA, B3, NA
> Nitrosos_Cl3 -> PNA, B4, NA
> Nitrosos_Cl4 -> PNA, B5, NA
> Nitrosos_Cl7 -> PNA, B6, NA
> pH -> PNA, B9, NA
> NH4 -> PNA, B10, NA
> OM -> PNA, B11, NA
> Moisture -> PNA, B12, NA
> pH -> PD_AOA, B18, NA
> NH4 -> PD_AOA, B19, NA
> OM -> PD_AOA, B20, NA
> Moisture -> PD_AOA, B21, NA
> pH -> Nitrosotalea, B22, NA
> NH4 -> Nitrosotalea, B23, NA
> OM -> Nitrosotalea, B24, NA
> Moisture -> Nitrosotalea, B25, NA
> pH -> Nitrosos_Cl1, B26, NA
> NH4 -> Nitrosos_Cl1, B27, NA
> OM -> Nitrosos_Cl1, B28, NA
> Moisture -> Nitrosos_Cl1, B29, NA
> pH -> Nitrosos_Cl3, B30, NA
> NH4 -> Nitrosos_Cl3, B31, NA
> OM -> Nitrosos_Cl3, B32, NA
> Moisture -> Nitrosos_Cl3, B33, NA
> pH -> Nitrosos_Cl4, B34, NA
> NH4 -> Nitrosos_Cl4, B35, NA
> OM -> Nitrosos_Cl4, B36, NA
> Moisture -> Nitrosos_Cl4, B37, NA
> pH -> Nitrosos_Cl7, B38, NA
> NH4 -> Nitrosos_Cl7, B39, NA
> OM -> Nitrosos_Cl7, B40, NA
> Moisture -> Nitrosos_Cl7, B41, NA
> Nitrosotalea -> Nitrosos_Cl1, B53, NA
> Nitrosotalea -> Nitrosos_Cl3, B54, NA
> Nitrosotalea -> Nitrosos_Cl4, B55, NA
> Nitrosotalea -> Nitrosos_Cl7, B56, NA
> Nitrosos_Cl1 -> Nitrosotalea, B57, NA
> Nitrosos_Cl1 -> Nitrosos_Cl3, B58, NA
> Nitrosos_Cl1 -> Nitrosos_Cl4, B59, NA
> Nitrosos_Cl1 -> Nitrosos_Cl7, B60, NA
> Nitrosos_Cl3 -> Nitrosotalea, B61, NA
> Nitrosos_Cl3 -> Nitrosos_Cl1, B62, NA
> Nitrosos_Cl3 -> Nitrosos_Cl4, B63, NA
> Nitrosos_Cl3 -> Nitrosos_Cl7, B64, NA
> Nitrosos_Cl4 -> Nitrosotalea, B65, NA
> Nitrosos_Cl4 -> Nitrosos_Cl1, B66, NA
> Nitrosos_Cl4 -> Nitrosos_Cl3, B67, NA
> Nitrosos_Cl4 -> Nitrosos_Cl7, B68, NA
> Nitrosos_Cl7 -> Nitrosotalea, B69, NA
> Nitrosos_Cl7 -> Nitrosos_Cl1, B70, NA
> Nitrosos_Cl7 -> Nitrosos_Cl4, B71, NA
> Nitrosos_Cl7 -> Nitrosos_Cl3, B72, NA
> pH -> NH4, B42, NA
> pH -> OM, B43, NA
> NH4 -> OM, B45, NA
> NH4 -> pH, B46, NA
> OM -> NH4, B47, NA
> OM -> Moisture, B48, NA
> OM -> pH, B52, NA
> Moisture -> OM, B70, NA
> PNA <-> PNA, e12, NA
> PD_AOA <-> PD_AOA, NA, 1
> Nitrosotalea <-> Nitrosotalea, e5, NA
> Nitrosos_Cl1 <-> Nitrosos_Cl1, e6, NA
> Nitrosos_Cl3 <-> Nitrosos_Cl3, e7, NA
> Nitrosos_Cl4 <-> Nitrosos_Cl4, e8, NA
> Nitrosos_Cl7 <-> Nitrosos_Cl7, e9, NA
> NH4 <-> NH4, e6, NA
> OM <-> OM, e5, NA
> Moisture <-> Moisture, e7, NA
> pH <-> pH, NA, 1
> 
> 
> 
> 
> --
> Dra. Michele de C?ssia Pereira e Silva
> Escola Superior de Agricultura Luiz de Queiroz (ESALQ)/ USP
> Departamento de Ci?ncia do Solo e Nutri??o de Plantas
> Laborat?rio de Microbiologia do Solo
> Av P?dua Dias, 11 CP 09 CEP-13400-970
> Piracicaba - S?o Paulo
> 
> 
> 	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Sep  4 22:18:49 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 4 Sep 2014 15:18:49 -0500
Subject: [R] Help with regression
In-Reply-To: <CACduCw9dp6HTcZYZ2_j0-_YkWCxjpFCgNhSbeMeKsT-rCzH7DA@mail.gmail.com>
References: <CACduCw9dp6HTcZYZ2_j0-_YkWCxjpFCgNhSbeMeKsT-rCzH7DA@mail.gmail.com>
Message-ID: <CAN5YmCEER+3hcut528wkv0D6aVRzBmJXyfiv8DG+iMnBpfsLbg@mail.gmail.com>

You will find lots of examples if you do an internet search for
     R quadratic regression
Here's just one ... http://www.theanalysisfactor.com/r-tutorial-4/

Jean


On Thu, Sep 4, 2014 at 10:40 AM, Basilius Sapientia <basiliussap at gmail.com>
wrote:

> I have this code:
> Vm <- c(6.2208, 4.9736, 4.1423, 3.1031, 2.4795, 1.6483, 1.2328, 0.98357,
> 0.81746, 0.60998); #Molvolume
> p <- c(0.4, 0.5, 0.6, 0.8, 1, 1.5, 2, 2.5, 3, 4)*1000; #Pressure
> Rydb <- 8.3144621; #Constant
> Tempi <- 300; #Temperature in Kelvin
>
> Vmi <- Vm^(-1); #To get Vm^(-1)
> Zi <- (p*Vm)/(Rydb*Tempi) #To get Z
>
> #Plot
> dframe <- data.frame(Vmi, Zi)
> plot(dframe, pch=19, col='red', main='Thermodynamic properties of Argon',
> xlab='1/Vm', ylab='Z')
>
> #Fit for B
> fitb <-lm(Zi ~ Vmi);
> fitb$coefficients[1];
> fitb$coefficients[2];
> summary(fitb)
>
>
>
>
> I want to make a regression on the data with this generel formula:
> y=1+Bx+Cx^2. I need to figure out what B and C in this formula is. Please
> help me! I want to become better to R.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From PabloEmilio.Verde at uni-duesseldorf.de  Thu Sep  4 23:09:22 2014
From: PabloEmilio.Verde at uni-duesseldorf.de (PabloEmilio.Verde at uni-duesseldorf.de)
Date: Thu, 04 Sep 2014 23:09:22 +0200
Subject: [R] citation of a task view
In-Reply-To: <alpine.DEB.2.11.1409042020150.8132@paninaro.uibk.ac.at>
References: <5408285A.8090903@hhu.de> <54089E88.6080400@gmail.com>
	<alpine.DEB.2.11.1409042020150.8132@paninaro.uibk.ac.at>
Message-ID: <20140904230922.151556glgyial69u@wwwmail.uni-duesseldorf.de>

Hi Achim and Murdoch,

Thanks a lot!

Cheers,

Pablo


Achim Zeileis <Achim.Zeileis at uibk.ac.at> escribi?:

> On Thu, 4 Sep 2014, Duncan Murdoch wrote:
>
>> On 04/09/2014 4:52 AM, Dr. Pablo E. Verde wrote:
>>> Hi all,
>>>
>>> Which is a formal bibliography citation of an R's task view? For example
>>> if I want to make a citation of "MetaAnalysis" task view.
>>>
>>> Thanks in advance!
>>
>> I don't think there is a recognized standard one.
>
> Not yet. But since this summer the web pages contain <meta> tags  
> (both in Highwire Press and Dublin Core format) that state how the  
> pages can be cited.
>
>> I would use whatever format your journal requires for citing any  
>> web page, e.g. something like
>>
>> Lewin-Koh, Nicholas (2013).  CRAN Task View: Graphic Displays &  
>> Dynamic Graphics & Graphic Devices & Visualization.
>> Web page with URL  
>> <http://cran.r-project.org/web/views/Bayesian.html>, retrieved  
>> Sept. 4, 2014.
>
> I would recommend two changes: (1) Use the official stable URL  
> http://CRAN.R-project.org/view=... (2) Instead of the "retrieved"  
> information, use the version date stated on the task view. For  
> example for the current version of the MetaAnalysis view:
>
> Michael Dewey (2014). CRAN Task View: Meta-Analysis. Version 2014-07-25.
> URL http://CRAN.R-project.org/view=MetaAnalysis.
>
> or in BibTeX:
>
> @Misc{,
>   author = {Michael Dewey},
>   note = {Version~2014-07-25},
>   title = {{CRAN} Task View: Meta-Analysis},
>   year = {2014},
>   url = {http://CRAN.R-project.org/view=MetaAnalysis}
> }
>
> hth,
> Z
>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From dwinsemius at comcast.net  Thu Sep  4 23:49:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Sep 2014 14:49:23 -0700
Subject: [R] Help with regression
In-Reply-To: <CACduCw9dp6HTcZYZ2_j0-_YkWCxjpFCgNhSbeMeKsT-rCzH7DA@mail.gmail.com>
References: <CACduCw9dp6HTcZYZ2_j0-_YkWCxjpFCgNhSbeMeKsT-rCzH7DA@mail.gmail.com>
Message-ID: <CC16D5C5-2242-4364-9CD3-9F7AFECA86E8@comcast.net>


On Sep 4, 2014, at 8:40 AM, Basilius Sapientia wrote:

> I have this code:
> Vm <- c(6.2208, 4.9736, 4.1423, 3.1031, 2.4795, 1.6483, 1.2328, 0.98357,
> 0.81746, 0.60998); #Molvolume
> p <- c(0.4, 0.5, 0.6, 0.8, 1, 1.5, 2, 2.5, 3, 4)*1000; #Pressure
> Rydb <- 8.3144621; #Constant
> Tempi <- 300; #Temperature in Kelvin
> 
> Vmi <- Vm^(-1); #To get Vm^(-1)
> Zi <- (p*Vm)/(Rydb*Tempi) #To get Z
> 
> #Plot
> dframe <- data.frame(Vmi, Zi)
> plot(dframe, pch=19, col='red', main='Thermodynamic properties of Argon',
> xlab='1/Vm', ylab='Z')
> 
> #Fit for B
> fitb <-lm(Zi ~ Vmi);
> fitb$coefficients[1];
> fitb$coefficients[2];
> summary(fitb)

The appropriate approach to regression on polynomials is to use poly(.)

> fitb <-lm(Zi ~ poly( Vmi, 2) );
> fitb

Call:
lm(formula = Zi ~ poly(Vmi, 2))

Coefficients:
  (Intercept)  poly(Vmi, 2)1  poly(Vmi, 2)2  
    0.9907137     -0.0198321      0.0006682  

> summary(fitb)

Call:
lm(formula = Zi ~ poly(Vmi, 2))

Residuals:
       Min         1Q     Median         3Q        Max 
-2.622e-05 -7.785e-06  3.268e-06  1.047e-05  1.557e-05 

Coefficients:
                Estimate Std. Error   t value Pr(>|t|)    
(Intercept)    9.907e-01  4.884e-06 202853.74  < 2e-16 ***
poly(Vmi, 2)1 -1.983e-02  1.544e-05  -1284.12  < 2e-16 ***
poly(Vmi, 2)2  6.682e-04  1.544e-05     43.27  9.2e-10 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.544e-05 on 7 degrees of freedom
Multiple R-squared:      1,	Adjusted R-squared:      1 
F-statistic: 8.254e+05 on 2 and 7 DF,  p-value: < 2.2e-16

The second order term has been constructed to not be highly correlated with the linear term.

> plot( Zi, predict(fitb) )

And now that you "know" that both terms are significant, construct that polynomial with:

> fitb <-lm(Zi ~  Vmi+I(Vmi^2) );
> fitb

Call:
lm(formula = Zi ~ Vmi + I(Vmi^2))

Coefficients:
(Intercept)          Vmi     I(Vmi^2)  
   0.999964    -0.015025     0.001063  

> 
> I want to make a regression on the data with this generel formula:
> y=1+Bx+Cx^2. I need to figure out what B and C in this formula is. Please
> help me! I want to become better to R.

Please read the Posting Guide. It's really very easy to post in plain-text from gmail.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Thu Sep  4 23:58:16 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 4 Sep 2014 21:58:16 +0000
Subject: [R] depth of labels of axis
In-Reply-To: <AFB35C66-1DBA-483E-AE60-056D77E11167@comcast.net>
References: <54050401.4060203@yeah.net>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>
	<5407EBAA.6070807@yeah.net> <5407F315.9060606@yeah.net>
	<AFB35C66-1DBA-483E-AE60-056D77E11167@comcast.net>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F95361@mb02.ads.tamu.edu>

The problem with this approach is that the horizontal positioning of the labels is based on the width of the label including the phantom part so that the E's are pushed to the left of the tick mark (at least on my Windows machine). But it does provide a way of dealing with superscripts as long as the phantom is added to each label and hadj= is used to position the label horizontally, eg (changing the last label to a superscript for illustration):

lbl <- expression(E[g]~phantom(E[g]), E~phantom(E[g]), E[j]~phantom(E[g]),
       E~phantom(E[g]), E^t~phantom(E[g]))
plot(1:5, xaxt = "n")
axis(1, at = 1:5, labels = lbl, hadj=.1)
abline(h=.7, xpd=TRUE, lty=3)

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
Sent: Thursday, September 4, 2014 2:25 PM
To: Jinsong Zhao
Cc: r-help at r-project.org
Subject: Re: [R] depth of labels of axis


On Sep 3, 2014, at 10:05 PM, Jinsong Zhao wrote:

> On 2014/9/3 21:33, Jinsong Zhao wrote:
>> On 2014/9/2 11:50, David L Carlson wrote:
>>> The bottom of the expression is set by the lowest character (which can
>>> even change for subscripted letters with descenders. The solution is
>>> to get axis() to align the tops of the axis labels and move the line
>>> up to reduce the space, e.g.
>>> 
>>> plot(1:5, xaxt = "n")
>>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>>> "E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
>>> # Check alignment
>>> abline(h=.7, xpd=TRUE, lty=3)
>> 
>> yes. In this situation, padj = 1 is the fast solution. However, If there
>> are also superscript, then it's hard to alignment all the labels.
>> 
>> If R provide a mechanism that aligns the label in axis() or text() with
>> the baseline of the character without the super- and/or sub-script, that
>> will be terrific.
> 
> it seems that the above wish is on the Graphics TODO lists:
> https://www.stat.auckland.ac.nz/~paul/R/graphicstodos.html
> 
> Allow text adjustment for mathematical annotations which is relative to a text baseline (in addition to the current situation where adjustment is relative to the bounding box).
> 

In many case adding a phantom argument will correct aliognment problems:

plot(1:5, xaxt = "n")
axis(1, at = 1:5, labels = c(expression(E[g]), E~phantom(E[g]), expression(E[j]),
E~phantom(E[g]), expression(E[t])))

abline(h=.7, xpd=TRUE, lty=3)

Notice that c(expression(.), ...) will coerce all items separated by commas to expressions, sot you cna just put in "native" expression that are not surrounded by the `expression`-function

c(expression(E[g]), E~phantom(E[g]), expression(E[j])  ) #returns
# expression(E[g], E ~ phantom(E[g]), E[j])

The tilde is actually a function that converts parse-able strings into R language objects:

c(expression(E[g]), E~phantom(E[g]), ~E[j])

-- 
David.

>>> 
>>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org
>>> [mailto:r-help-bounces at r-project.org] On Behalf Of Jinsong Zhao
>>> Sent: Monday, September 1, 2014 6:41 PM
>>> To: r-help at r-project.org
>>> Subject: [R] depth of labels of axis
>>> 
>>> Hi there,
>>> 
>>> With the following code,
>>> 
>>> plot(1:5, xaxt = "n")
>>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>>> "E", expression(E[t])))
>>> 
>>> you may notice that the "E" within labels of axis(1) are not at the same
>>> depth. So the vision of axis(1) labels is something like wave.
>>> 
>>> Is there a possible way to typeset the labels so that they are have the
>>> same depth?
>>> 
>>> Any suggestions will be really appreciated. Thanks in advance.
>>> 
>>> Best regards,
>>> Jinsong

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pollaroid at gmail.com  Thu Sep  4 23:58:54 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Thu, 4 Sep 2014 23:58:54 +0200
Subject: [R] Subset a column with specific characters
Message-ID: <CAAC1QdA8fn5y8ip2ZMAEx-Y7ztRv7CfJyDdho7bGgkn_khSfQQ@mail.gmail.com>

This post has NOT been accepted by the mailing list yet.
I would like to subset a column based on the contents of a column with
specific character. In the sample data I wish to do the following:

First keep the data based on column "prog" if prog contains "ca", and
secondly to drop if race contains "ic"

Thanks

library(foreign)
hsb2 <- read.dta('http://www.ats.ucla.edu/stat/stata/notes/hsb2.dta')


From mccormack at molbio.mgh.harvard.edu  Fri Sep  5 00:40:52 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Thu, 04 Sep 2014 18:40:52 -0400
Subject: [R] find the data frames in list of objects and make a list of
 them
In-Reply-To: <CAF8bMcZ=HF4TeU4qeq4R0hQpb2gLoR71hoRsWC7ToAwnGEYEcg@mail.gmail.com>
References: <53EBB4DF.7030709@molbio.mgh.harvard.edu>
	<CAGx1TMCE8gk=Z2tU9=P=A=coGifbZfmZ+chgbsXWVvxos=rSTw@mail.gmail.com>
	<53EBEB8F.4080805@molbio.mgh.harvard.edu>
	<CAF8bMcZ=HF4TeU4qeq4R0hQpb2gLoR71hoRsWC7ToAwnGEYEcg@mail.gmail.com>
Message-ID: <5408EA74.8030406@molbio.mgh.harvard.edu>

Thank you very much, Bill !

     It has taken my a while to figure out, but yes, what I need is a 
list (the R object, list) of data frames and not a character vector 
containing the names of the data frames.

   Thank you very much. This works well and is getting me in the 
direction I want to go.

Matthew

On 8/13/2014 7:40 PM, William Dunlap wrote:
> Previously you asked
>>      A second question: is this the best way to make a list
>>     of data frames without having to manually type c(dataframe1, dataframe2, ...)  ?
> If you use 'c' there you will not get a list of data.frames - you will
> get a list of all the columns in the data.frame you supplied.  Use
> 'list' instead of 'c' if you are taking that route.
>
> The *apply functions are helpful  here.  To make list of all
> data.frames in an environment you can use the following function,
> which takes the environment to search as an argument.
>
> f <- function(envir = globalenv()) {
>      tmp <- eapply(envir,
>                             all.names=TRUE,
>                             FUN=function(obj) if (is.data.frame(obj))
> obj else NULL)
>      # remove NULL's now
>      tmp[!vapply(tmp, is.null, TRUE)]
> }
>
> Use is as
>    allDataFrames <- f(globalenv()) # or just f()
>
>
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Aug 13, 2014 at 3:49 PM, Matthew
> <mccormack at molbio.mgh.harvard.edu>  wrote:
>> Hi Richard,
>>
>>      Thank you very much for your reply and your code.
>> Your code is doing just what I asked for, but does not seem to be what I
>> need.
>>
>> I will need to review some basic R before I can continue.
>>
>> I am trying to list data frames in order to bind them into 1 single data
>> frame with something like: dplyr::rbind_all(list of data frames), but when I
>> try dplyr::rbind_all(lsDataFrame(ls())), I get the error: object at index 1
>> not a data.frame. So, I am going to have to learn some more about lists in R
>> before proceding.
>>
>> Thank you for your help and code.
>>
>> Matthew
>>
>>
>>
>>
>>
>> Matthew
>>
>> On 8/13/2014 3:12 PM, Richard M. Heiberger wrote:
>>> I would do something like this
>>>
>>> lsDataFrame <- function(xx=ls()) xx[sapply(xx, function(x)
>>> is.data.frame(get(x)))]
>>> ls("package:datasets")
>>> lsDataFrame(ls("package:datasets"))
>>>
>>> On Wed, Aug 13, 2014 at 2:56 PM, Matthew
>>> <mccormack at molbio.mgh.harvard.edu>  wrote:
>>>> Hi everyone,
>>>>
>>>>      I would like the find which objects are data frames in all the
>>>> objects I
>>>> have created ( in other words in what you get when you type: ls()  ),
>>>> then I
>>>> would like to make a list of these data frames.
>>>>
>>>> Explained in other words; after typing ls(), you get the names of
>>>> objects.
>>>> Which objects are data frames ?  How to then make a list of these data
>>>> frames.
>>>>
>>>>      A second question: is this the best way to make a list of data frames
>>>> without having to manually type c(dataframe1, dataframe2, ...)  ?
>>>>
>>>> Matthew
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org  mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ycding at coh.org  Thu Sep  4 22:10:34 2014
From: ycding at coh.org (Ding, Yuan Chun)
Date: Thu, 4 Sep 2014 13:10:34 -0700
Subject: [R] calculate Euclidean distances between populations in R with
	this data structure
Message-ID: <B13036EC0F1BA7438324228EA489637C0320B27A6F@EXCHMBX1.coh.org>




I want to calculate Euclidean distance between 12 populations, in each population there are 20 samples and each sample is measured for 100 genes (these are microarray data; the numbers here are just examples).
The equation I found is:
distance = sqrt{[sum(Average of xi -average of yi)^2] /n }, i=1 to n;
where xi and yi are the expression of gene i over two populations with p and q samples (x1, x2,...,xp), (y1, y2,...,yq), n is the number of genes.
part of data are pasted below
row.names pop1.1    pop1.2  pop1.3  pop1.4  pop2.1  pop2.2  pop2.3  pop2.4
7A5     5.38194 4.06191 4.88044 5.60383 6.23101 6.53738 4.80336 5.86136
A1BG    5.15155 4.29441 4.59131 4.90026 4.62908 4.48712 4.73039 4.46208
A1CF    4.22396 4.14451 4.41465 3.93179 4.89638 4.66109 4.20918 4.48107
A26C3   12.1969 12.4179 10.9786 11.7659 11.405  11.7594 11.1757 11.8128
How might one calculate these distances in R with this data structure?


Thanks,

Ding



---------------------------------------------------------------------
*SECURITY/CONFIDENTIALITY WARNING:
This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (fpc5p)
---------------------------------------------------------------------


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Sep  5 01:28:59 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Sep 2014 16:28:59 -0700
Subject: [R] Operator proposal: %between%
In-Reply-To: <CAFEqCdzyYrKhWJnJQCOOCqj1pVprsp0mMSZYEp63voK4yoHHkg@mail.gmail.com>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
	<CAFEqCdzyYrKhWJnJQCOOCqj1pVprsp0mMSZYEp63voK4yoHHkg@mail.gmail.com>
Message-ID: <451A10B7-CB7B-4F55-B553-9C858435F689@comcast.net>


On Sep 4, 2014, at 12:54 PM, Greg Snow wrote:

> The TeachingDemos package has %<% and %<=% operators for a between
> style comparison.  So for your example you could write:
> 
> 1 %<% 5 %<% 10
> 
> or
> 
> 1 %<=% 5 %<=% 10
> 
> And these operators already work with vectors:
> 
> lb %<=% x %<% ub
> 
> and can even be further chained:
> 
> 0 %<% x %<% y %<% z %<% 1  # only points where x < y and y < z and all
> between 0 and 1.
> 
> It is a little bit different syntax from yours, but would that do what you want?
> 
> If not, we could add a %between% function (expand it a bit following
> Duncan's suggestion) to the TeachingDemos package if you don't want to
> create your own package.

If you are accepting feature requests I would like to see a `%btwn%` function that would accept as its second argument either a two element numeric or alpha vector or a two column matrix of with the same number of rows as the first argument. Something along these lines:


> `%btwn%` <- function(x,y) if(!is.null(dim(y))&&dim(y)[1] == length(x) ){x >= y[,1] & x < y[,2]}else{x >= y[1] & x <y[2]}
> 4 %btwn% c(2,6)
[1] TRUE

-- 
David
> 
> On Thu, Sep 4, 2014 at 8:41 AM, Torbj?rn Lindahl
> <torbjorn.lindahl at gmail.com> wrote:
>> Not sure if this is the proper list to propose changes like this, if it
>> passes constructive criticism, it would like to have a %between% operator
>> in the R language.
>> 
>> I currently have this in my local R startup script:
>> 
>> `%between%` <- function(x,...) {
>>  y <- range( unlist(c(...)) )
>>  return( x >= y[1] & x =< y[2] )
>> }
>> 
>> It allows me to do things like: 5 %between c(1,10)
>> 
>> and also as act as an "in_range" operator:
>> foo %between% a.long.list.with.many.values
>> 
>> This may seem unnecessary, since 5 >= foo[1] && foo<= foo[2] is also quite
>> short to type, but there is a mental cost to this, eg if you are deeply
>> focused on a complicated program flow, the %between% construct is a lot
>> easier to type out, and relate to, than the logically more complex
>> construct with && and <=/>=, at least in my experience.
>> 
>> --
>> mvh
>> Torbj?rn Lindahl
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Sep  5 01:38:09 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Sep 2014 16:38:09 -0700
Subject: [R] Subset a column with specific characters
In-Reply-To: <CAAC1QdA8fn5y8ip2ZMAEx-Y7ztRv7CfJyDdho7bGgkn_khSfQQ@mail.gmail.com>
References: <CAAC1QdA8fn5y8ip2ZMAEx-Y7ztRv7CfJyDdho7bGgkn_khSfQQ@mail.gmail.com>
Message-ID: <A4105CC0-CF57-458E-8723-20ED0D8B0762@comcast.net>


On Sep 4, 2014, at 2:58 PM, Kuma Raj wrote:

> This post has NOT been accepted by the mailing list yet.

Well, it has now. Were you earlier posting from Nabble? (Not an efficient strategy.)

> I would like to subset a column based on the contents of a column with
> specific character. In the sample data I wish to do the following:
> 
> First keep the data based on column "prog" if prog contains "ca", and
> secondly to drop if race contains "ic"
> 
> Thanks
> 
> library(foreign)
> hsb2 <- read.dta('http://www.ats.ucla.edu/stat/stata/notes/hsb2.dta')

> NROW( hsb2[ grepl("ca", hsb2$prog) & !grepl("ic", hsb2$race) , ] )
[1] 120

-- 

David Winsemius
Alameda, CA, USA


From sarah.goslee at gmail.com  Fri Sep  5 01:48:31 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 4 Sep 2014 19:48:31 -0400
Subject: [R] calculate Euclidean distances between populations in R with
 this data structure
In-Reply-To: <B13036EC0F1BA7438324228EA489637C0320B27A6F@EXCHMBX1.coh.org>
References: <B13036EC0F1BA7438324228EA489637C0320B27A6F@EXCHMBX1.coh.org>
Message-ID: <CAM_vjun--rve7DCGWnQeyahHPmKX1DST9O9YUi9i7+pcMfY46A@mail.gmail.com>

I'd probably start with ?dist

Sarah

On Thu, Sep 4, 2014 at 4:10 PM, Ding, Yuan Chun <ycding at coh.org> wrote:
>
>
>
> I want to calculate Euclidean distance between 12 populations, in each population there are 20 samples and each sample is measured for 100 genes (these are microarray data; the numbers here are just examples).
> The equation I found is:
> distance = sqrt{[sum(Average of xi -average of yi)^2] /n }, i=1 to n;
> where xi and yi are the expression of gene i over two populations with p and q samples (x1, x2,...,xp), (y1, y2,...,yq), n is the number of genes.
> part of data are pasted below
> row.names pop1.1    pop1.2  pop1.3  pop1.4  pop2.1  pop2.2  pop2.3  pop2.4
> 7A5     5.38194 4.06191 4.88044 5.60383 6.23101 6.53738 4.80336 5.86136
> A1BG    5.15155 4.29441 4.59131 4.90026 4.62908 4.48712 4.73039 4.46208
> A1CF    4.22396 4.14451 4.41465 3.93179 4.89638 4.66109 4.20918 4.48107
> A26C3   12.1969 12.4179 10.9786 11.7659 11.405  11.7594 11.1757 11.8128
> How might one calculate these distances in R with this data structure?
>
>
> Thanks,
>
> Ding
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Fri Sep  5 02:16:47 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 4 Sep 2014 20:16:47 -0400
Subject: [R] calculate Euclidean distances between populations in R with
 this data structure
In-Reply-To: <B13036EC0F1BA7438324228EA489637C0320B27CA4@EXCHMBX1.coh.org>
References: <B13036EC0F1BA7438324228EA489637C0320B27A6F@EXCHMBX1.coh.org>
	<CAM_vjun--rve7DCGWnQeyahHPmKX1DST9O9YUi9i7+pcMfY46A@mail.gmail.com>
	<B13036EC0F1BA7438324228EA489637C0320B27CA4@EXCHMBX1.coh.org>
Message-ID: <CAM_vjunRF-9EHwqUPeAsgx9EwEYWRo7M-5izYerFGH6PaLLQ_w@mail.gmail.com>

Hi,

Please keep your replies on the R-help list so others may participate
in the conversation.

On Thu, Sep 4, 2014 at 8:12 PM, Ding, Yuan Chun <ycding at coh.org> wrote:
> Hi Sarah,
>
> Thank you very  much for your quick response.
>
> I checked the dist() function. It calculate distance between two samples with a number of variables.
>
>    Variable1 variable 2 variable 3 variable4 ....
> X      3       5           6            7
> Y      4       8           9            10
>
> So it is easy to calculate distance between x and y.
>
> But in my study, X is a group with 20 samples and y is another group with 30 samples, so I need to calculate distance between x group between y group.


That doesn't make any sense to me. If the variables are different, how
can you calculate a distance between them? You also potentially run
into scaling issues. Also, your original question (below) stated that
your populations have 20 samples.

> I think I need to get mean for each group, then use dist() function.  I tried to find a R package to do it.

I think you'd be better off reconsidering what you're trying to accomplish.

Sarah

> Thanks,
>
> Ding
>
> -----Original Message-----
> From: Sarah Goslee [mailto:sarah.goslee at gmail.com]
> Sent: Thursday, September 04, 2014 4:49 PM
> To: Ding, Yuan Chun
> Cc: r-help at R-project.org
> Subject: Re: [R] calculate Euclidean distances between populations in R with this data structure
>
> I'd probably start with ?dist
>
> Sarah
>
> On Thu, Sep 4, 2014 at 4:10 PM, Ding, Yuan Chun <ycding at coh.org> wrote:
>>
>>
>>
>> I want to calculate Euclidean distance between 12 populations, in each population there are 20 samples and each sample is measured for 100 genes (these are microarray data; the numbers here are just examples).
>> The equation I found is:
>> distance = sqrt{[sum(Average of xi -average of yi)^2] /n }, i=1 to n;
>> where xi and yi are the expression of gene i over two populations with p and q samples (x1, x2,...,xp), (y1, y2,...,yq), n is the number of genes.
>> part of data are pasted below
>> row.names pop1.1    pop1.2  pop1.3  pop1.4  pop2.1  pop2.2  pop2.3  pop2.4
>> 7A5     5.38194 4.06191 4.88044 5.60383 6.23101 6.53738 4.80336 5.86136
>> A1BG    5.15155 4.29441 4.59131 4.90026 4.62908 4.48712 4.73039 4.46208
>> A1CF    4.22396 4.14451 4.41465 3.93179 4.89638 4.66109 4.20918 4.48107
>> A26C3   12.1969 12.4179 10.9786 11.7659 11.405  11.7594 11.1757 11.8128
>> How might one calculate these distances in R with this data structure?
>>
>>
>> Thanks,
>>
>> Ding
>>
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From ycding at coh.org  Fri Sep  5 02:19:47 2014
From: ycding at coh.org (Ding, Yuan Chun)
Date: Thu, 4 Sep 2014 17:19:47 -0700
Subject: [R] calculate Euclidean distances between populations in R with
	this data structure
In-Reply-To: <CAM_vjun--rve7DCGWnQeyahHPmKX1DST9O9YUi9i7+pcMfY46A@mail.gmail.com>
References: <B13036EC0F1BA7438324228EA489637C0320B27A6F@EXCHMBX1.coh.org>
	<CAM_vjun--rve7DCGWnQeyahHPmKX1DST9O9YUi9i7+pcMfY46A@mail.gmail.com>
Message-ID: <B13036EC0F1BA7438324228EA489637C0320B27CB0@EXCHMBX1.coh.org>

Hi Sarah,

Thank you very  much for your quick response.

I checked the dist() function. It calculate distance between two samples with a number of variables.

   Variable1 variable 2 variable 3 variable4 ....
X      3       5           6            7 
Y      4       8           9            10

So it is easy to calculate distance between x and y.

But in my study, X is a group with 20 samples and y is another group with 30 samples, so I need to calculate distance between x group and y group.

I think I need to calculate a mean for each group, then use dist() function.  I tried to find a R package to do it.

Thanks,

Ding

-----Original Message-----
From: Sarah Goslee [mailto:sarah.goslee at gmail.com] 
Sent: Thursday, September 04, 2014 4:49 PM
To: Ding, Yuan Chun
Cc: r-help at R-project.org
Subject: Re: [R] calculate Euclidean distances between populations in R with this data structure

I'd probably start with ?dist

Sarah

On Thu, Sep 4, 2014 at 4:10 PM, Ding, Yuan Chun <ycding at coh.org> wrote:
>
>
>
> I want to calculate Euclidean distance between 12 populations, in each population there are 20 samples and each sample is measured for 100 genes (these are microarray data; the numbers here are just examples).
> The equation I found is:
> distance = sqrt{[sum(Average of xi -average of yi)^2] /n }, i=1 to n; 
> where xi and yi are the expression of gene i over two populations with p and q samples (x1, x2,...,xp), (y1, y2,...,yq), n is the number of genes.
> part of data are pasted below
> row.names pop1.1    pop1.2  pop1.3  pop1.4  pop2.1  pop2.2  pop2.3  pop2.4
> 7A5     5.38194 4.06191 4.88044 5.60383 6.23101 6.53738 4.80336 5.86136
> A1BG    5.15155 4.29441 4.59131 4.90026 4.62908 4.48712 4.73039 4.46208
> A1CF    4.22396 4.14451 4.41465 3.93179 4.89638 4.66109 4.20918 4.48107
> A26C3   12.1969 12.4179 10.9786 11.7659 11.405  11.7594 11.1757 11.8128
> How might one calculate these distances in R with this data structure?
>
>
> Thanks,
>
> Ding
>

--
Sarah Goslee
http://www.functionaldiversity.org


---------------------------------------------------------------------
*SECURITY/CONFIDENTIALITY WARNING:
This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (fpc5p)
---------------------------------------------------------------------


From madhvi.gupta at orkash.com  Fri Sep  5 09:01:22 2014
From: madhvi.gupta at orkash.com (madhvi.gupta)
Date: Fri, 05 Sep 2014 12:31:22 +0530
Subject: [R] How to get source code of a package
Message-ID: <54095FC2.80805@orkash.com>

Hi,
Can anyone tell me how to get  source code of a package of R?
I want to integrate elastic search with R if there is any way please let 
me know or give me a direction to do that.

Thanks.

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Fri Sep  5 09:12:17 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 05 Sep 2014 09:12:17 +0200
Subject: [R] How to get source code of a package
In-Reply-To: <54095FC2.80805@orkash.com>
References: <54095FC2.80805@orkash.com>
Message-ID: <54096251.9090708@statistik.tu-dortmund.de>



On 05.09.2014 09:01, madhvi.gupta wrote:
> Hi,
> Can anyone tell me how to get  source code of a package of R?

An R package is distributed in form of source code:
Say you want to see the sources of "abc", then go to
http://cran.r-project.org/web/packages/abc/index.html
and download the osurces or use

download.package("abc", "path/to/destination", type="source")

Best,
Uwe Ligges


> I want to integrate elastic search with R if there is any way please let
> me know or give me a direction to do that.
>
> Thanks.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Fri Sep  5 09:13:50 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 05 Sep 2014 09:13:50 +0200
Subject: [R] Built R package with example
In-Reply-To: <CALJKBv9OtsqJpipUQ-UA++P2pjxZAXtYOjXAzasaEf=fXNZWbQ@mail.gmail.com>
References: <CALJKBv9OtsqJpipUQ-UA++P2pjxZAXtYOjXAzasaEf=fXNZWbQ@mail.gmail.com>
Message-ID: <540962AE.5070002@statistik.tu-dortmund.de>



On 04.09.2014 20:02, Karim Mezhoud wrote:
> Dear All,
> How can I add folder content  examples of needed files to run example?
> The simple add of folder did not built and reload with the package.

If you need additional data, put the data in the package as described in 
Writing R Extensions.
If you aim at something different, please try to describe it better, 
since actually I can only guess the sense of your question.

Best,
Uwe Ligges


>
> Thanks!
> Karim
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Fri Sep  5 09:15:24 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 05 Sep 2014 09:15:24 +0200
Subject: [R] mvpart error in R 3.1.1 "s_to_rp" not available for .C()
In-Reply-To: <1409835836.36896.YahooMailNeo@web125201.mail.ne1.yahoo.com>
References: <1409835836.36896.YahooMailNeo@web125201.mail.ne1.yahoo.com>
Message-ID: <5409630C.1050709@statistik.tu-dortmund.de>



On 04.09.2014 15:03, Angel Marley wrote:
> Dear R list,
>
> I'm working with recursive tress using packages mvpart and rpart in R in linux xubuntu (64).
>
> The package performed with no problem under my previous R version (2.14)
>
> I had recently updated my R version to 3.1.1 and when I try to run a mvpart model I get the following error mesage
>
> data(spider)
> mvpart(data.matrix(spider[,1:12])~herbs+reft+moss+sand+twigs+water, data=spider)


This works for me.

Please run

update.packages(checkBuilt=TRUE)

and update your packages.

Best,
Uwe Ligges



>
> Error en .C("s_to_rp", n = as.integer(nobs), nvarx = as.integer(nvar),  :
>    "s_to_rp" not available for .C() for package "mvpart"
>
> I tried to find this problem on the web, but I was not able to find any response.
>
> If you can please help me to solve this problem, I would be grateful.
> Best regards and thank you in advance
> Angel Segura
>
> PD below you will find R and session info
>
> Working on Ubuntu 12.04.2 LTS \n \l
>
> R.Version()
> $platform
> [1] "x86_64-pc-linux-gnu"
>
> $arch
> [1] "x86_64"
>
> $os
> [1] "linux-gnu"
>
> $system
> [1] "x86_64, linux-gnu"
>
> $status
> [1] ""
>
> $major
> [1] "3"
>
> $minor
> [1] "1.1"
>
> $year
> [1] "2014"
>
> $month
> [1] "07"
>
> $day
> [1] "10"
>
> $`svn rev`
> [1] "66115"
>
> $language
> [1] "R"
>
> $version.string
> [1] "R version 3.1.1 (2014-07-10)"
>
> $nickname
> [1] "Sock it to Me"
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=es_ES.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=es_ES.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] mvpart_1.6-2 rpart_4.1-8
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From b.rowlingson at lancaster.ac.uk  Fri Sep  5 09:24:46 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 5 Sep 2014 08:24:46 +0100
Subject: [R] Operator proposal: %between%
In-Reply-To: <24e0e43a1f43484a88f498c9cc40a9f1@EX-1-HT0.lancs.local>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
	<CAFEqCdzyYrKhWJnJQCOOCqj1pVprsp0mMSZYEp63voK4yoHHkg@mail.gmail.com>
	<24e0e43a1f43484a88f498c9cc40a9f1@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMyVo58UK24akx3HGOtOU1aB0H6ZnQsypMO_ercebcBiw@mail.gmail.com>

On Fri, Sep 5, 2014 at 12:28 AM, David Winsemius <dwinsemius at comcast.net> wrote:

> If you are accepting feature requests

The R issue tracker has a "wishlist" section:

https://bugs.r-project.org/bugzilla3/buglist.cgi?component=Wishlist&order=changeddate%20DESC%2Cbug_status%2Cpriority%2Cassigned_to%2Cbug_id&product=R&query_based_on=&query_format=advanced&resolution=---

 - dream on....

> I would like to see a `%btwn%` function that would accept as its second argument either a two element numeric or alpha vector or a two column matrix of with the same number of rows as the first argument. Something along these lines:
>
>
>> `%btwn%` <- function(x,y) if(!is.null(dim(y))&&dim(y)[1] == length(x) ){x >= y[,1] & x < y[,2]}else{x >= y[1] & x <y[2]}
>> 4 %btwn% c(2,6)
> [1] TRUE

The problem with wishes is that someone has to make them come true, in
this case R-core. And unlike a genie who grants your wish and then
jumps back in his bottle, R-core are nice enough to hang around in
case your wish doesn't quite go to plan. They have to keep your wish
up to date, make sure it doesn't conflict with anyone elses wishes and
so on (probably taken this analogy too far now...).

 So Duncan's unspoken subtext is "why not put this in a package and
submit it to CRAN?". And then you maintain it. Because after all, you
wrote it.

 My additional question is "Why are things like %<% hidden away inside
the TeachingDemos package?". Is it worth collating useful %operators%
into a new package?

 I can't see the point really since in about a year or two everyone
will just think A %foo% B is some kind of foo-pipe that pipes A into
B...

Barry


From b.rowlingson at lancaster.ac.uk  Fri Sep  5 09:38:14 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 5 Sep 2014 08:38:14 +0100
Subject: [R] How to get source code of a package
In-Reply-To: <ef5ab280b4de49ccb9d9bc6ccf852759@EX-0-HT0.lancs.local>
References: <ef5ab280b4de49ccb9d9bc6ccf852759@EX-0-HT0.lancs.local>
Message-ID: <CANVKczML7a+F6k9wvKUS03g09JKy1yg7DY6yqQOHk9KR25xGDw@mail.gmail.com>

On Fri, Sep 5, 2014 at 8:01 AM, madhvi.gupta <madhvi.gupta at orkash.com> wrote:
> Hi,
> Can anyone tell me how to get  source code of a package of R?
> I want to integrate elastic search with R if there is any way please let
> me know or give me a direction to do that.

Which R packages do you want source code for? I should think that
source code of other ElasticSearch API clients would be useful,
particularly those languages that are most like R in style, such as
Python or Ruby.

 However if you google for "Elastic Search API Client R" you'll find this:

https://github.com/ropensci/elastic

 which is a start. That's assuming you are talking about a client-side
elastic search package for R, and not somehow integrating it into the
server....

Barry


> Thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Sep  5 09:45:20 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 05 Sep 2014 00:45:20 -0700
Subject: [R] How to get source code of a package
In-Reply-To: <54095FC2.80805@orkash.com>
References: <54095FC2.80805@orkash.com>
Message-ID: <451591e3-cb7a-4c8e-9932-908157224ed4@email.android.com>

Read the Writing R Extensions document that comes with R? Use that knowledge to write a package? Read the Advanced R website (http://adv-r.had.co.nz)? Use a web search engine to look for others working on a similar package? Read the Posting Guide mentioned at the bottom of this or any other post on this list and follow the instructions there, including using plain text to post on this list?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 5, 2014 12:01:22 AM PDT, "madhvi.gupta" <madhvi.gupta at orkash.com> wrote:
>Hi,
>Can anyone tell me how to get  source code of a package of R?
>I want to integrate elastic search with R if there is any way please
>let 
>me know or give me a direction to do that.
>
>Thanks.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From torbjorn.lindahl at gmail.com  Fri Sep  5 09:59:58 2014
From: torbjorn.lindahl at gmail.com (=?UTF-8?Q?Torbj=C3=B8rn_Lindahl?=)
Date: Fri, 5 Sep 2014 09:59:58 +0200
Subject: [R] Operator proposal: %between%
In-Reply-To: <451A10B7-CB7B-4F55-B553-9C858435F689@comcast.net>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
	<CAFEqCdzyYrKhWJnJQCOOCqj1pVprsp0mMSZYEp63voK4yoHHkg@mail.gmail.com>
	<451A10B7-CB7B-4F55-B553-9C858435F689@comcast.net>
Message-ID: <CA+Dw+SOYst1F_JnzGFp8Cb2YXz+tDdmPOE=XQpJyN-kWCZRSQA@mail.gmail.com>

Please add it if you think it fits, and expand it as discussed, I am not
creating a package for one single utility function.

T.


On Fri, Sep 5, 2014 at 1:28 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Sep 4, 2014, at 12:54 PM, Greg Snow wrote:
>
> > The TeachingDemos package has %<% and %<=% operators for a between
> > style comparison.  So for your example you could write:
> >
> > 1 %<% 5 %<% 10
> >
> > or
> >
> > 1 %<=% 5 %<=% 10
> >
> > And these operators already work with vectors:
> >
> > lb %<=% x %<% ub
> >
> > and can even be further chained:
> >
> > 0 %<% x %<% y %<% z %<% 1  # only points where x < y and y < z and all
> > between 0 and 1.
> >
> > It is a little bit different syntax from yours, but would that do what
> you want?
> >
> > If not, we could add a %between% function (expand it a bit following
> > Duncan's suggestion) to the TeachingDemos package if you don't want to
> > create your own package.
>
> If you are accepting feature requests I would like to see a `%btwn%`
> function that would accept as its second argument either a two element
> numeric or alpha vector or a two column matrix of with the same number of
> rows as the first argument. Something along these lines:
>
>
> > `%btwn%` <- function(x,y) if(!is.null(dim(y))&&dim(y)[1] == length(x)
> ){x >= y[,1] & x < y[,2]}else{x >= y[1] & x <y[2]}
> > 4 %btwn% c(2,6)
> [1] TRUE
>
> --
> David
> >
> > On Thu, Sep 4, 2014 at 8:41 AM, Torbj?rn Lindahl
> > <torbjorn.lindahl at gmail.com> wrote:
> >> Not sure if this is the proper list to propose changes like this, if it
> >> passes constructive criticism, it would like to have a %between%
> operator
> >> in the R language.
> >>
> >> I currently have this in my local R startup script:
> >>
> >> `%between%` <- function(x,...) {
> >>  y <- range( unlist(c(...)) )
> >>  return( x >= y[1] & x =< y[2] )
> >> }
> >>
> >> It allows me to do things like: 5 %between c(1,10)
> >>
> >> and also as act as an "in_range" operator:
> >> foo %between% a.long.list.with.many.values
> >>
> >> This may seem unnecessary, since 5 >= foo[1] && foo<= foo[2] is also
> quite
> >> short to type, but there is a mental cost to this, eg if you are deeply
> >> focused on a complicated program flow, the %between% construct is a lot
> >> easier to type out, and relate to, than the logically more complex
> >> construct with && and <=/>=, at least in my experience.
> >>
> >> --
> >> mvh
> >> Torbj?rn Lindahl
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Gregory (Greg) L. Snow Ph.D.
> > 538280 at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
mvh
Torbj?rn Lindahl

	[[alternative HTML version deleted]]


From pollaroid at gmail.com  Fri Sep  5 10:07:59 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Fri, 5 Sep 2014 10:07:59 +0200
Subject: [R] Obtain coefficients of several nlme objects
Message-ID: <CAAC1QdC2nfJubKpcQZDyZ1Yr=3WOK4cSE2rYefS1mBNenDV-1w@mail.gmail.com>

I have several lme objects like the ones shown below and I wish to
combine the coefficients and confidence intervals of fixed effects of
several models.  Is there a function that could do that job?

m1 <- lme(mark1 ~   pm10  + temp +   + age  + gender + bmi   + statin
+ smoke + dow +  season

          , data =  df , random = ~ 1 | id,na.action=na.exclude, method="ML")

m2 <- lme(mark2 ~   pm10  + temp +   + age  + gender + bmi   + statin
+ smoke + dow +  season

          , data =  df , random = ~ 1 | id,na.action=na.exclude, method="ML")


From ggrothendieck at gmail.com  Fri Sep  5 10:36:57 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 5 Sep 2014 04:36:57 -0400
Subject: [R] Operator proposal: %between%
In-Reply-To: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
Message-ID: <CAP01uR=G94+-Xg6uA=+yMVDcyO2JbvpT8O9iQfDTo113NNrheg@mail.gmail.com>

On Thu, Sep 4, 2014 at 10:41 AM, Torbj?rn Lindahl
<torbjorn.lindahl at gmail.com> wrote:
> Not sure if this is the proper list to propose changes like this, if it
> passes constructive criticism, it would like to have a %between% operator
> in the R language.
>

There is a between function in the data.table package.

> library(data.table)
> between
function (x, lower, upper, incbounds = TRUE)
{
    if (incbounds)
        x >= lower & x <= upper
    else x > lower & x < upper
}

and also in the tis package which works differently:

> library(tis)
> between
function (y, x1, x2)
{
    y <- unclass(y)
    x1 <- unclass(x1)
    x2 <- unclass(x2)
    small <- pmin(x1, x2)
    large <- pmax(x1, x2)
    (y >= small) & (y <= large)
}

In addition, SQL has a between operator

> library(sqldf)
> sqldf("select * from BOD where Time between 3 and 5")
  Time demand
1    3   19.0
2    4   16.0
3    5   15.6


From torbjorn.lindahl at gmail.com  Fri Sep  5 12:47:35 2014
From: torbjorn.lindahl at gmail.com (=?UTF-8?Q?Torbj=C3=B8rn_Lindahl?=)
Date: Fri, 5 Sep 2014 12:47:35 +0200
Subject: [R] Operator proposal: %between%
In-Reply-To: <CAP01uR=G94+-Xg6uA=+yMVDcyO2JbvpT8O9iQfDTo113NNrheg@mail.gmail.com>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
	<CAP01uR=G94+-Xg6uA=+yMVDcyO2JbvpT8O9iQfDTo113NNrheg@mail.gmail.com>
Message-ID: <CA+Dw+SPs95rP8GTXS5B+eG65UCwb1XM6wsMg49neDVHVFcHg_Q@mail.gmail.com>

I don't mind maintaining this, however I'm not creating a new util package
just for one function, there are already several nice util libraries out
there, adding one more adds to fragmentation more than this single function
provides usefulness.

If anyone wants to adopt this low-maintenance-cost love child, that would
be the best option. If this is something, worthy of R-Core I'd be happy to
submit it, but from the sound of it that door seems closed. I think %>%
etc. also should go there, they look great and would make everyday life
simpler, almost enjoyable.

Also some of the point of this function is keeping it as an operator, that
provides better readability and mental flow.

Looks like all variations of between shown could easily be merged into one
cover-it-all operator

T.


On Fri, Sep 5, 2014 at 10:36 AM, Gabor Grothendieck <ggrothendieck at gmail.com
> wrote:

> On Thu, Sep 4, 2014 at 10:41 AM, Torbj?rn Lindahl
> <torbjorn.lindahl at gmail.com> wrote:
> > Not sure if this is the proper list to propose changes like this, if it
> > passes constructive criticism, it would like to have a %between% operator
> > in the R language.
> >
>
> There is a between function in the data.table package.
>
> > library(data.table)
> > between
> function (x, lower, upper, incbounds = TRUE)
> {
>     if (incbounds)
>         x >= lower & x <= upper
>     else x > lower & x < upper
> }
>
> and also in the tis package which works differently:
>
> > library(tis)
> > between
> function (y, x1, x2)
> {
>     y <- unclass(y)
>     x1 <- unclass(x1)
>     x2 <- unclass(x2)
>     small <- pmin(x1, x2)
>     large <- pmax(x1, x2)
>     (y >= small) & (y <= large)
> }
>
> In addition, SQL has a between operator
>
> > library(sqldf)
> > sqldf("select * from BOD where Time between 3 and 5")
>   Time demand
> 1    3   19.0
> 2    4   16.0
> 3    5   15.6
>



-- 
mvh
Torbj?rn Lindahl

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Sep  5 13:43:00 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 05 Sep 2014 07:43:00 -0400
Subject: [R] Operator proposal: %between%
In-Reply-To: <CA+Dw+SPs95rP8GTXS5B+eG65UCwb1XM6wsMg49neDVHVFcHg_Q@mail.gmail.com>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>	<CAP01uR=G94+-Xg6uA=+yMVDcyO2JbvpT8O9iQfDTo113NNrheg@mail.gmail.com>
	<CA+Dw+SPs95rP8GTXS5B+eG65UCwb1XM6wsMg49neDVHVFcHg_Q@mail.gmail.com>
Message-ID: <5409A1C4.2070004@gmail.com>

On 05/09/2014, 6:47 AM, Torbj?rn Lindahl wrote:
> I don't mind maintaining this, however I'm not creating a new util package
> just for one function, there are already several nice util libraries out
> there, adding one more adds to fragmentation more than this single function
> provides usefulness.
> 
> If anyone wants to adopt this low-maintenance-cost love child, that would
> be the best option. If this is something, worthy of R-Core I'd be happy to
> submit it, but from the sound of it that door seems closed. I think %>%
> etc. also should go there, they look great and would make everyday life
> simpler, almost enjoyable.
> 
> Also some of the point of this function is keeping it as an operator, that
> provides better readability and mental flow.
> 

Another issue with operators is that they have quite high operator
precedence, as mentioned in the TeachingDemos help page for %<%.  So for
example,

2 < 4
2 %<% 4
1 + 1 < 2 + 2

all return TRUE (in %<% with some attributes), but

1 + 1 %<% 2 + 2

returns 4, with attributes.  (It is evaluated as 1 + (1 %<% 2) + 2,
whereas the regular < has lower precedence, so it is evaluated as (1 +
1) < (2 + 2).

See the ?Syntax help page for the precedence rules.  Some languages
allow user-defined operators to be assigned a particular precedence, but
in R the precedence is fixed.  This means that user-defined operators
are less readable than you might think.

Duncan Murdoch

> Looks like all variations of between shown could easily be merged into one
> cover-it-all operator
> 
> T.
> 
> 
> On Fri, Sep 5, 2014 at 10:36 AM, Gabor Grothendieck <ggrothendieck at gmail.com
>> wrote:
> 
>> On Thu, Sep 4, 2014 at 10:41 AM, Torbj?rn Lindahl 
>> <torbjorn.lindahl at gmail.com> wrote:
>>> Not sure if this is the proper list to propose changes like this, if it
>>> passes constructive criticism, it would like to have a %between% operator
>>> in the R language.
>>>
>>
>> There is a between function in the data.table package.
>>
>>> library(data.table)
>>> between
>> function (x, lower, upper, incbounds = TRUE)
>> {
>>     if (incbounds)
>>         x >= lower & x <= upper
>>     else x > lower & x < upper
>> }
>>
>> and also in the tis package which works differently:
>>
>>> library(tis)
>>> between
>> function (y, x1, x2)
>> {
>>     y <- unclass(y)
>>     x1 <- unclass(x1)
>>     x2 <- unclass(x2)
>>     small <- pmin(x1, x2)
>>     large <- pmax(x1, x2)
>>     (y >= small) & (y <= large)
>> }
>>
>> In addition, SQL has a between operator
>>
>>> library(sqldf)
>>> sqldf("select * from BOD where Time between 3 and 5")
>>   Time demand
>> 1    3   19.0
>> 2    4   16.0
>> 3    5   15.6
>>
> 
> 
>


From h.wickham at gmail.com  Fri Sep  5 14:53:53 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 5 Sep 2014 07:53:53 -0500
Subject: [R] Operator proposal: %between%
In-Reply-To: <CA+Dw+SOYst1F_JnzGFp8Cb2YXz+tDdmPOE=XQpJyN-kWCZRSQA@mail.gmail.com>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
	<CAFEqCdzyYrKhWJnJQCOOCqj1pVprsp0mMSZYEp63voK4yoHHkg@mail.gmail.com>
	<451A10B7-CB7B-4F55-B553-9C858435F689@comcast.net>
	<CA+Dw+SOYst1F_JnzGFp8Cb2YXz+tDdmPOE=XQpJyN-kWCZRSQA@mail.gmail.com>
Message-ID: <CABdHhvG=2NBqXm7n1Dk3VS8zF_QsxZx98PDnXjwVSPTKyhvhmw@mail.gmail.com>

> Please add it if you think it fits, and expand it as discussed, I am not
> creating a package for one single utility function.

Why not?  There's nothing wrong with a package that only provides one function.

Hadley

-- 
http://had.co.nz/


From rl at openmailbox.org  Fri Sep  5 11:40:19 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Fri, 05 Sep 2014 09:40:19 +0000
Subject: [R] sequential input script dataframe process functionality
Message-ID: <695146e848491ad828a6cb1374b16a15@openmailbox.org>

Subscribers,

Could someone please indicate correct terminology and relevant manual 
sections to achieve the following conceptual workflow, to create a 
script to select sequentially parts of a dataframe:

> "Welcome to this R script program"
> Select level number below of variable 'X'
[1]
[2]
[3]
> 3
> Select level number below of variable 'Y'
[1]
[2]
> 1
> Summary
X, [2] 'descriptive text A for level 3 selected'
[1] 'descriptive text B for level 1 selected'
> Display graph? Y/N
> y
> [specific selected script activated, graph displayed]

Thanks in advance.

--
N.B. digest mode subscriber; please cc message.


From angel_nauti at yahoo.com  Fri Sep  5 12:39:02 2014
From: angel_nauti at yahoo.com (Angel Marley)
Date: Fri, 5 Sep 2014 03:39:02 -0700
Subject: [R] mvpart error in R 3.1.1 "s_to_rp" not available for .C()
In-Reply-To: <5409630C.1050709@statistik.tu-dortmund.de>
References: <1409835836.36896.YahooMailNeo@web125201.mail.ne1.yahoo.com>
	<5409630C.1050709@statistik.tu-dortmund.de>
Message-ID: <1409913542.56641.YahooMailNeo@web125202.mail.ne1.yahoo.com>

Dear Uwe, 

thanks for your prompt reply.

I have run the update.packages, but the error persisted, then I  did it again and it works....


Best regards and thank for your time

Angel



On Friday, September 5, 2014 4:15 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
 




On 04.09.2014 15:03, Angel Marley wrote:
> Dear R list,
>
> I'm working with recursive tress using packages mvpart and rpart in R in linux xubuntu (64).
>
> The package performed with no problem under my previous R version (2.14)
>
> I had recently updated my R version to 3.1.1 and when I try to run a mvpart model I get the following error mesage
>
> data(spider)
> mvpart(data.matrix(spider[,1:12])~herbs+reft+moss+sand+twigs+water, data=spider)


This works for me.

Please run

update.packages(checkBuilt=TRUE)

and update your packages.

Best,
Uwe Ligges




>
> Error en .C("s_to_rp", n = as.integer(nobs), nvarx = as.integer(nvar),  :
>    "s_to_rp" not available for .C() for package "mvpart"
>
> I tried to find this problem on the web, but I was not able to find any response.
>
> If you can please help me to solve this problem, I would be grateful.
> Best regards and thank you in advance
> Angel Segura
>
> PD below you will find R and session info
>
> Working on Ubuntu 12.04.2 LTS \n \l
>
> R.Version()
> $platform
> [1] "x86_64-pc-linux-gnu"
>
> $arch
> [1] "x86_64"
>
> $os
> [1] "linux-gnu"
>
> $system
> [1] "x86_64, linux-gnu"
>
> $status
> [1] ""
>
> $major
> [1] "3"
>
> $minor
> [1] "1.1"
>
> $year
> [1] "2014"
>
> $month
> [1] "07"
>
> $day
> [1] "10"
>
> $`svn rev`
> [1] "66115"
>
> $language
> [1] "R"
>
> $version.string
> [1] "R version 3.1.1 (2014-07-10)"
>
> $nickname
> [1] "Sock it to Me"
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=es_ES.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=es_ES.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] mvpart_1.6-2 rpart_4.1-8
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

>
	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Sep  5 16:14:08 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Sep 2014 07:14:08 -0700
Subject: [R] Operator proposal: %between%
In-Reply-To: <CAFEqCdzyYrKhWJnJQCOOCqj1pVprsp0mMSZYEp63voK4yoHHkg@mail.gmail.com>
References: <CA+Dw+SMoEGPy7a0fEd+MCLGBgegkHa7taWZe6Kh+Dz6T=ez9ag@mail.gmail.com>
	<CAFEqCdzyYrKhWJnJQCOOCqj1pVprsp0mMSZYEp63voK4yoHHkg@mail.gmail.com>
Message-ID: <CAF8bMcZsK7uxcjYY+JQxF1OEuTNBVYmSiZv9ZnM4qZx-8wHhZw@mail.gmail.com>

You can easily run into precedence problems with the %fun% syntax.  E.g., if
   1 %<% 5 %<% 10
returns TRUE then
    1 %<% 5 %<% 10*2
will return 2 because %<% has higher precedence than *.
     > as.list(quote(1 %<% 5 %<% 10*2))
     [[1]]
     `*`

    [[2]]
    1 %<% 5 %<% 10

    [[3]]
    [1] 2

Standard functional syntax makes this unambiguous and allows you to
use named arguments to make their meanings unambiguous.
   isBetween(5, lower=1, upper=10)
or
   isBetween(5, range=c(1,10))


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Sep 4, 2014 at 12:54 PM, Greg Snow <538280 at gmail.com> wrote:
> The TeachingDemos package has %<% and %<=% operators for a between
> style comparison.  So for your example you could write:
>
> 1 %<% 5 %<% 10
>
> or
>
> 1 %<=% 5 %<=% 10
>
> And these operators already work with vectors:
>
> lb %<=% x %<% ub
>
> and can even be further chained:
>
> 0 %<% x %<% y %<% z %<% 1  # only points where x < y and y < z and all
> between 0 and 1.
>
> It is a little bit different syntax from yours, but would that do what you want?
>
> If not, we could add a %between% function (expand it a bit following
> Duncan's suggestion) to the TeachingDemos package if you don't want to
> create your own package.
>
> On Thu, Sep 4, 2014 at 8:41 AM, Torbj?rn Lindahl
> <torbjorn.lindahl at gmail.com> wrote:
>> Not sure if this is the proper list to propose changes like this, if it
>> passes constructive criticism, it would like to have a %between% operator
>> in the R language.
>>
>> I currently have this in my local R startup script:
>>
>> `%between%` <- function(x,...) {
>>   y <- range( unlist(c(...)) )
>>   return( x >= y[1] & x =< y[2] )
>> }
>>
>> It allows me to do things like: 5 %between c(1,10)
>>
>> and also as act as an "in_range" operator:
>> foo %between% a.long.list.with.many.values
>>
>> This may seem unnecessary, since 5 >= foo[1] && foo<= foo[2] is also quite
>> short to type, but there is a mental cost to this, eg if you are deeply
>> focused on a complicated program flow, the %between% construct is a lot
>> easier to type out, and relate to, than the logically more complex
>> construct with && and <=/>=, at least in my experience.
>>
>> --
>> mvh
>> Torbj?rn Lindahl
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Sep  5 16:42:03 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 5 Sep 2014 14:42:03 +0000
Subject: [R] calculate Euclidean distances between populations in R
	with	this data structure
In-Reply-To: <B13036EC0F1BA7438324228EA489637C0320B27A6F@EXCHMBX1.coh.org>
References: <B13036EC0F1BA7438324228EA489637C0320B27A6F@EXCHMBX1.coh.org>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F95564@mb02.ads.tamu.edu>

There may be a specialized package for this in bioconductor, but it seems that you could just use aggregate() to calculate the means for each population and then use the results of that in dist().

?aggregate

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ding, Yuan Chun
Sent: Thursday, September 4, 2014 3:11 PM
To: r-help at R-project.org
Subject: [R] calculate Euclidean distances between populations in R with this data structure




I want to calculate Euclidean distance between 12 populations, in each population there are 20 samples and each sample is measured for 100 genes (these are microarray data; the numbers here are just examples).
The equation I found is:
distance = sqrt{[sum(Average of xi -average of yi)^2] /n }, i=1 to n;
where xi and yi are the expression of gene i over two populations with p and q samples (x1, x2,...,xp), (y1, y2,...,yq), n is the number of genes.
part of data are pasted below
row.names pop1.1    pop1.2  pop1.3  pop1.4  pop2.1  pop2.2  pop2.3  pop2.4
7A5     5.38194 4.06191 4.88044 5.60383 6.23101 6.53738 4.80336 5.86136
A1BG    5.15155 4.29441 4.59131 4.90026 4.62908 4.48712 4.73039 4.46208
A1CF    4.22396 4.14451 4.41465 3.93179 4.89638 4.66109 4.20918 4.48107
A26C3   12.1969 12.4179 10.9786 11.7659 11.405  11.7594 11.1757 11.8128
How might one calculate these distances in R with this data structure?


Thanks,

Ding



---------------------------------------------------------------------
*SECURITY/CONFIDENTIALITY WARNING:
This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wi!
 sh to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (fpc5p)
---------------------------------------------------------------------


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sjkiss at gmail.com  Fri Sep  5 17:22:22 2014
From: sjkiss at gmail.com (Simon Kiss)
Date: Fri, 5 Sep 2014 11:22:22 -0400
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing	A
	Data	Frame
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9524E@mb02.ads.tamu.edu>
References: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>
	<696C4B48-C745-4E5A-A3A1-05D2E93991A2@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F910CA@mb02.ads.tamu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9132B@mb02.ads.tamu.edu>
	<15332AED-0A26-418B-B81B-B0DAD57BF6B5@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9524E@mb02.ads.tamu.edu>
Message-ID: <D9DC510B-13FD-4E73-9147-A10115475F6C@gmail.com>

HI, of course.

The a mini-version of my data-set is below, stored in d2. Then the code I'm working follows.
library(reshape2)
#Create d2
structure(list(row = 1:50, rank1 = structure(c(3L, 3L, 3L, 4L, 
3L, 3L, NA, NA, 3L, NA, 3L, 3L, 1L, NA, 2L, NA, 3L, NA, 2L, 1L, 
1L, 3L, NA, 6L, NA, 1L, NA, 3L, 1L, NA, 1L, NA, NA, 6L, 3L, NA, 
1L, 3L, 3L, 4L, 1L, NA, 3L, 3L, 3L, NA, 3L, 3L, NA, 1L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank2 = structure(c(6L, 1L, 1L, 
2L, 4L, 6L, NA, NA, 6L, NA, 6L, 4L, 2L, NA, 4L, NA, 6L, NA, 1L, 
6L, 3L, 2L, NA, 3L, NA, 6L, NA, 6L, 6L, NA, 3L, NA, NA, 3L, 6L, 
NA, 6L, 6L, 6L, 7L, 3L, NA, 1L, 6L, 6L, NA, 2L, 6L, NA, 2L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank3 = structure(c(1L, 6L, 4L, 
3L, 2L, 4L, NA, NA, 4L, NA, 1L, 1L, 6L, NA, 1L, NA, 1L, NA, 7L, 
3L, 6L, 1L, NA, 2L, NA, 4L, NA, 1L, 3L, NA, 6L, NA, NA, 4L, 2L, 
NA, 7L, 1L, 1L, 6L, 7L, NA, 6L, 1L, 1L, NA, 4L, 1L, NA, 3L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank4 = structure(c(7L, 4L, 2L, 
1L, 1L, 7L, NA, NA, 1L, NA, 7L, 2L, 7L, NA, 3L, NA, 2L, NA, 3L, 
4L, 5L, 6L, NA, 4L, NA, 3L, NA, 4L, 4L, NA, 4L, NA, NA, 2L, 7L, 
NA, 2L, 2L, 2L, 3L, 6L, NA, 2L, 5L, 4L, NA, 1L, 2L, NA, 4L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank5 = structure(c(2L, 7L, 6L, 
7L, 7L, 2L, NA, NA, 2L, NA, 2L, 7L, 3L, NA, 6L, NA, 7L, NA, 6L, 
7L, 4L, 7L, NA, 7L, NA, 7L, NA, 2L, 2L, NA, 2L, NA, NA, 7L, 1L, 
NA, 3L, 7L, 4L, 2L, 2L, NA, 4L, 2L, 2L, NA, 6L, 4L, NA, 5L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank6 = structure(c(4L, 2L, 7L, 
6L, 6L, 1L, NA, NA, 7L, NA, 4L, 5L, 4L, NA, 7L, NA, 4L, NA, 4L, 
2L, 2L, 4L, NA, 1L, NA, 2L, NA, 7L, 7L, NA, 7L, NA, NA, 1L, 4L, 
NA, 4L, 4L, 7L, 1L, 4L, NA, 7L, 7L, 7L, NA, 7L, 7L, NA, 7L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank7 = structure(c(5L, 5L, 5L, 
5L, 5L, 5L, NA, NA, 5L, NA, 5L, 6L, 5L, NA, 5L, NA, 5L, NA, 5L, 
5L, 7L, 5L, NA, 5L, NA, 5L, NA, 5L, 5L, NA, 5L, NA, NA, 5L, 5L, 
NA, 5L, NA, 5L, 5L, 5L, NA, 5L, 4L, 5L, NA, 5L, 5L, NA, 6L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor")), .Names = c("row", "rank1", "rank2", 
"rank3", "rank4", "rank5", "rank6", "rank7"), row.names = c(NA, 
50L), class = "data.frame")


#This code is a replication of David Carlson's code (below) which works splendidly, but does not work on my data-set
#Melt d2: Note, I've used value.name='color' to maximize comparability with David's suggestion
d3 <- melt(d2, id.vars=1, measure.vars=2:8, variable.name="rank",value.name="color")
#Make Rank Variable Numeric
d3$rank<-as.numeric(d3$rank)
#Recast d3 into d4
d4<- dcast(d3, row~color,value.var="rank", fill=0)
#Note that d4 appears to provide a binary variable for one if a respondent checked the option, but does not provide information as to which rank they assigned each option, but also seems to summarize the number of missing values

#David Carlson's Code
mydf <- data.frame(t(replicate(100, sample(c("red", "blue",  "green", "yellow", NA), 4))))
mydf <- data.frame(rows=1:100, mydf)
colnames(mydf) <- c("row", "rank1", "rank2", "rank3", "rank4")
mymelt <- melt(mydf, id.vars=1, measure.vars=2:5, variable.name="rank", value.name="color")
mymelt$rank <- as.numeric(mymelt$rank)
mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)

#Compare
str(mydf)
str(d2)
head(mycast)
head(d4)

Again, I'm grateful for assistance. I can't understand what how my data-set differs from David's sample data-set.
Simon Kiss
On Sep 4, 2014, at 2:35 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> I think we would need enough of the data you are using to figure out how to modify the process. Can you use dput() to send a small data set that fails to work?
> 
> David C
> 
> -----Original Message-----
> From: Simon Kiss [mailto:sjkiss at gmail.com] 
> Sent: Thursday, September 4, 2014 1:28 PM
> To: David L Carlson
> Cc: r-help at r-project.org
> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> Hi David and list:
> This is working, except at this command
> mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)
> 
> dcast is using "length" as the default aggregating function. This results in not accurate results. It tells me, for example how many choices were missing values and it tells me if a person selected any given option (value is reported as 1).
> When I try to run your reproducible research, it works great, but something with the aggregating function is not working properly with mine. 
> Any other thoughts?
> Simon
> On Aug 18, 2014, at 10:44 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
>> Another approach using reshape2:
>> 
>>> library(reshape2)
>>> # Construct data/ add column of row numbers
>>> set.seed(42)
>>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
>> +   "green", "yellow", NA), 4))))
>>> mydf <- data.frame(rows=1:100, mydf)
>>> colnames(mydf) <- c("row", "rank1", "rank2", "rank3", "rank4")
>>> head(mydf)
>> row  rank1  rank2  rank3 rank4
>> 1   1   <NA> yellow    red  blue
>> 2   2 yellow  green   <NA>   red
>> 3   3 yellow  green   blue  <NA>
>> 4   4   <NA>   blue yellow green
>> 5   5   <NA>    red   blue green
>> 6   6   <NA>    red  green  blue
>>> # Reshape
>>> mymelt <- melt(mydf, id.vars=1, measure.vars=2:5, 
>> +     variable.name="rank", value.name="color")
>>> # Convert rank to numeric
>>> mymelt$rank <- as.numeric(mymelt$rank)
>>> mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)
>>> head(mycast)
>> row blue green red yellow NA
>> 1   1    4     0   3      2  1
>> 2   2    0     2   4      1  3
>> 3   3    3     2   0      1  4
>> 4   4    2     4   0      3  1
>> 5   5    3     4   2      0  1
>> 6   6    4     3   2      0  1
>> 
>> David C
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
>> Sent: Sunday, August 17, 2014 6:32 PM
>> To: Simon Kiss; r-help at r-project.org
>> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
>> 
>> There is probably an easier way to do this, but
>> 
>>> set.seed(42)
>>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
>> +  "green", "yellow", NA), 4))))
>>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>>> head(mydf)
>>  rank1  rank2  rank3 rank4
>> 1   <NA> yellow    red  blue
>> 2 yellow  green   <NA>   red
>> 3 yellow  green   blue  <NA>
>> 4   <NA>   blue yellow green
>> 5   <NA>    red   blue green
>> 6   <NA>    red  green  blue
>>> lvls <- levels(mydf$rank1)
>>> # convert color factors to numeric
>>> for (i in seq_along(mydf)) mydf[,i] <- as.numeric(mydf[,i]) 
>>> # stack the columns
>>> mydf2 <- stack(mydf)
>>> # convert rank factor to numeric
>>> mydf2$ind <- as.numeric(mydf2$ind)
>>> # add row numbers
>>> mydf2 <- data.frame(rows=1:100, mydf2)
>>> # Create table
>>> mytbl <- xtabs(ind~rows+values, mydf2)
>>> # convert to data frame
>>> mydf3 <- data.frame(unclass(mytbl))
>>> colnames(mydf3) <- lvls
>>> head(mydf3)
>> blue green red yellow
>> 1    4     0   3      2
>> 2    0     2   4      1
>> 3    3     2   0      1
>> 4    2     4   0      3
>> 5    3     4   2      0
>> 6    4     3   2      0
>> 
>> David C
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
>> Sent: Friday, August 15, 2014 3:58 PM
>> To: r-help at r-project.org
>> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
>> 
>> 
>> Both the suggestions I got work very well, but what I didn't realize is that NA values would cause serious problems.  Where there is a missing value, using the argument na.last=NA to order just returns the the order of the factor levels, but excludes the missing values, but I have no idea where those occur in the or rather which of those variables were actually missing.  
>> Have I explained this problem sufficiently? 
>> I didn't think it would cause such a problem so I didn't include it in the original problem definition.
>> Yours, Simon
>> On Jul 25, 2014, at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> 
>>> I think this gets what you want. But your data are not reproducible since they are randomly drawn without setting a seed and the two data sets have no relationship to one another.
>>> 
>>>> set.seed(42)
>>>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
>>> + "green", "yellow")))))
>>>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>>>> mydf2 <- data.frame(t(apply(mydf, 1, order)))
>>>> colnames(mydf2) <- levels(mydf$rank1)
>>>> head(mydf)
>>> rank1  rank2  rank3 rank4
>>> 1 yellow  green    red  blue
>>> 2  green   blue yellow   red
>>> 3  green yellow    red  blue
>>> 4 yellow    red  green  blue
>>> 5 yellow    red  green  blue
>>> 6 yellow    red   blue green
>>>> head(mydf2)
>>> blue green red yellow
>>> 1    4     2   3      1
>>> 2    2     1   4      3
>>> 3    4     1   3      2
>>> 4    4     3   2      1
>>> 5    4     3   2      1
>>> 6    3     4   2      1
>>> 
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
>>> Sent: Friday, July 25, 2014 2:34 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
>>> 
>>> Hello:
>>> I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 
>>> 
>>> Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
>>> I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
>>> Thank you
>>> Simon
>>> #Reproducible code
>>> mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))
>>> 
>>> mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
>>> *********************************
>>> Simon J. Kiss, PhD
>>> Assistant Professor, Wilfrid Laurier University
>>> 73 George Street
>>> Brantford, Ontario, Canada
>>> N3T 2C9
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> *********************************
>> Simon J. Kiss, PhD
>> Assistant Professor, Wilfrid Laurier University
>> 73 George Street
>> Brantford, Ontario, Canada
>> N3T 2C9
>> Cell: +1 905 746 7606
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
> 
> 
> 

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From dcarlson at tamu.edu  Fri Sep  5 19:16:42 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 5 Sep 2014 17:16:42 +0000
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing	A
 Data	Frame
In-Reply-To: <D9DC510B-13FD-4E73-9147-A10115475F6C@gmail.com>
References: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>
	<696C4B48-C745-4E5A-A3A1-05D2E93991A2@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F910CA@mb02.ads.tamu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9132B@mb02.ads.tamu.edu>
	<15332AED-0A26-418B-B81B-B0DAD57BF6B5@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9524E@mb02.ads.tamu.edu>
	<D9DC510B-13FD-4E73-9147-A10115475F6C@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F956FE@mb02.ads.tamu.edu>

The big difference between the data sets is that many of your rows (16) have all missing values. None of mine do. If you run my data and yours, you will see that decast throws a warning "Aggregation function missing: defaulting to length" with your data but not with mine. As a result, instead of using the value of rank, dcast uses length(rank) which is always 1 except when there are multiple missing values when it is the number of missing values. This problem will occur whenever there is more than one missing value on a row. The simplest way to handle this is to create a function that returns the first value of a vector and use that with the fun.aggregate= argument:

> first <- function(x) {x[1]}
> d4<- dcast(d3, row~color, fun.aggregate=first, value.var="rank", fill=0)

The only drawback is that this will not warn you if a category was ranked twice except that the NA column will be zero and one of the other columns will be zero. The number of missing values is the number of zeroes in your category columns (not including row or NA) and the value in NA is the lowest rank that was missing.

David C

-----Original Message-----
From: Simon Kiss [mailto:sjkiss at gmail.com] 
Sent: Friday, September 5, 2014 10:22 AM
To: David L Carlson
Cc: r-help at r-project.org
Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame

HI, of course.

The a mini-version of my data-set is below, stored in d2. Then the code I'm working follows.
library(reshape2)
#Create d2
structure(list(row = 1:50, rank1 = structure(c(3L, 3L, 3L, 4L, 
3L, 3L, NA, NA, 3L, NA, 3L, 3L, 1L, NA, 2L, NA, 3L, NA, 2L, 1L, 
1L, 3L, NA, 6L, NA, 1L, NA, 3L, 1L, NA, 1L, NA, NA, 6L, 3L, NA, 
1L, 3L, 3L, 4L, 1L, NA, 3L, 3L, 3L, NA, 3L, 3L, NA, 1L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank2 = structure(c(6L, 1L, 1L, 
2L, 4L, 6L, NA, NA, 6L, NA, 6L, 4L, 2L, NA, 4L, NA, 6L, NA, 1L, 
6L, 3L, 2L, NA, 3L, NA, 6L, NA, 6L, 6L, NA, 3L, NA, NA, 3L, 6L, 
NA, 6L, 6L, 6L, 7L, 3L, NA, 1L, 6L, 6L, NA, 2L, 6L, NA, 2L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank3 = structure(c(1L, 6L, 4L, 
3L, 2L, 4L, NA, NA, 4L, NA, 1L, 1L, 6L, NA, 1L, NA, 1L, NA, 7L, 
3L, 6L, 1L, NA, 2L, NA, 4L, NA, 1L, 3L, NA, 6L, NA, NA, 4L, 2L, 
NA, 7L, 1L, 1L, 6L, 7L, NA, 6L, 1L, 1L, NA, 4L, 1L, NA, 3L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank4 = structure(c(7L, 4L, 2L, 
1L, 1L, 7L, NA, NA, 1L, NA, 7L, 2L, 7L, NA, 3L, NA, 2L, NA, 3L, 
4L, 5L, 6L, NA, 4L, NA, 3L, NA, 4L, 4L, NA, 4L, NA, NA, 2L, 7L, 
NA, 2L, 2L, 2L, 3L, 6L, NA, 2L, 5L, 4L, NA, 1L, 2L, NA, 4L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank5 = structure(c(2L, 7L, 6L, 
7L, 7L, 2L, NA, NA, 2L, NA, 2L, 7L, 3L, NA, 6L, NA, 7L, NA, 6L, 
7L, 4L, 7L, NA, 7L, NA, 7L, NA, 2L, 2L, NA, 2L, NA, NA, 7L, 1L, 
NA, 3L, 7L, 4L, 2L, 2L, NA, 4L, 2L, 2L, NA, 6L, 4L, NA, 5L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank6 = structure(c(4L, 2L, 7L, 
6L, 6L, 1L, NA, NA, 7L, NA, 4L, 5L, 4L, NA, 7L, NA, 4L, NA, 4L, 
2L, 2L, 4L, NA, 1L, NA, 2L, NA, 7L, 7L, NA, 7L, NA, NA, 1L, 4L, 
NA, 4L, 4L, 7L, 1L, 4L, NA, 7L, 7L, 7L, NA, 7L, 7L, NA, 7L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor"), rank7 = structure(c(5L, 5L, 5L, 
5L, 5L, 5L, NA, NA, 5L, NA, 5L, 6L, 5L, NA, 5L, NA, 5L, NA, 5L, 
5L, 7L, 5L, NA, 5L, NA, 5L, NA, 5L, 5L, NA, 5L, NA, NA, 5L, 5L, 
NA, 5L, NA, 5L, 5L, 5L, NA, 5L, 4L, 5L, NA, 5L, 5L, NA, 6L), .Label = c("accessible", 
"alternatives", "information", "responsive", "social", "technical", 
"trade"), class = "factor")), .Names = c("row", "rank1", "rank2", 
"rank3", "rank4", "rank5", "rank6", "rank7"), row.names = c(NA, 
50L), class = "data.frame")


#This code is a replication of David Carlson's code (below) which works splendidly, but does not work on my data-set
#Melt d2: Note, I've used value.name='color' to maximize comparability with David's suggestion
d3 <- melt(d2, id.vars=1, measure.vars=2:8, variable.name="rank",value.name="color")
#Make Rank Variable Numeric
d3$rank<-as.numeric(d3$rank)
#Recast d3 into d4
d4<- dcast(d3, row~color,value.var="rank", fill=0)
#Note that d4 appears to provide a binary variable for one if a respondent checked the option, but does not provide information as to which rank they assigned each option, but also seems to summarize the number of missing values

#David Carlson's Code
mydf <- data.frame(t(replicate(100, sample(c("red", "blue",  "green", "yellow", NA), 4))))
mydf <- data.frame(rows=1:100, mydf)
colnames(mydf) <- c("row", "rank1", "rank2", "rank3", "rank4")
mymelt <- melt(mydf, id.vars=1, measure.vars=2:5, variable.name="rank", value.name="color")
mymelt$rank <- as.numeric(mymelt$rank)
mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)

#Compare
str(mydf)
str(d2)
head(mycast)
head(d4)

Again, I'm grateful for assistance. I can't understand what how my data-set differs from David's sample data-set.
Simon Kiss
On Sep 4, 2014, at 2:35 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> I think we would need enough of the data you are using to figure out how to modify the process. Can you use dput() to send a small data set that fails to work?
> 
> David C
> 
> -----Original Message-----
> From: Simon Kiss [mailto:sjkiss at gmail.com] 
> Sent: Thursday, September 4, 2014 1:28 PM
> To: David L Carlson
> Cc: r-help at r-project.org
> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> Hi David and list:
> This is working, except at this command
> mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)
> 
> dcast is using "length" as the default aggregating function. This results in not accurate results. It tells me, for example how many choices were missing values and it tells me if a person selected any given option (value is reported as 1).
> When I try to run your reproducible research, it works great, but something with the aggregating function is not working properly with mine. 
> Any other thoughts?
> Simon
> On Aug 18, 2014, at 10:44 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
>> Another approach using reshape2:
>> 
>>> library(reshape2)
>>> # Construct data/ add column of row numbers
>>> set.seed(42)
>>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
>> +   "green", "yellow", NA), 4))))
>>> mydf <- data.frame(rows=1:100, mydf)
>>> colnames(mydf) <- c("row", "rank1", "rank2", "rank3", "rank4")
>>> head(mydf)
>> row  rank1  rank2  rank3 rank4
>> 1   1   <NA> yellow    red  blue
>> 2   2 yellow  green   <NA>   red
>> 3   3 yellow  green   blue  <NA>
>> 4   4   <NA>   blue yellow green
>> 5   5   <NA>    red   blue green
>> 6   6   <NA>    red  green  blue
>>> # Reshape
>>> mymelt <- melt(mydf, id.vars=1, measure.vars=2:5, 
>> +     variable.name="rank", value.name="color")
>>> # Convert rank to numeric
>>> mymelt$rank <- as.numeric(mymelt$rank)
>>> mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)
>>> head(mycast)
>> row blue green red yellow NA
>> 1   1    4     0   3      2  1
>> 2   2    0     2   4      1  3
>> 3   3    3     2   0      1  4
>> 4   4    2     4   0      3  1
>> 5   5    3     4   2      0  1
>> 6   6    4     3   2      0  1
>> 
>> David C
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
>> Sent: Sunday, August 17, 2014 6:32 PM
>> To: Simon Kiss; r-help at r-project.org
>> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
>> 
>> There is probably an easier way to do this, but
>> 
>>> set.seed(42)
>>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
>> +  "green", "yellow", NA), 4))))
>>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>>> head(mydf)
>>  rank1  rank2  rank3 rank4
>> 1   <NA> yellow    red  blue
>> 2 yellow  green   <NA>   red
>> 3 yellow  green   blue  <NA>
>> 4   <NA>   blue yellow green
>> 5   <NA>    red   blue green
>> 6   <NA>    red  green  blue
>>> lvls <- levels(mydf$rank1)
>>> # convert color factors to numeric
>>> for (i in seq_along(mydf)) mydf[,i] <- as.numeric(mydf[,i]) 
>>> # stack the columns
>>> mydf2 <- stack(mydf)
>>> # convert rank factor to numeric
>>> mydf2$ind <- as.numeric(mydf2$ind)
>>> # add row numbers
>>> mydf2 <- data.frame(rows=1:100, mydf2)
>>> # Create table
>>> mytbl <- xtabs(ind~rows+values, mydf2)
>>> # convert to data frame
>>> mydf3 <- data.frame(unclass(mytbl))
>>> colnames(mydf3) <- lvls
>>> head(mydf3)
>> blue green red yellow
>> 1    4     0   3      2
>> 2    0     2   4      1
>> 3    3     2   0      1
>> 4    2     4   0      3
>> 5    3     4   2      0
>> 6    4     3   2      0
>> 
>> David C
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
>> Sent: Friday, August 15, 2014 3:58 PM
>> To: r-help at r-project.org
>> Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
>> 
>> 
>> Both the suggestions I got work very well, but what I didn't realize is that NA values would cause serious problems.  Where there is a missing value, using the argument na.last=NA to order just returns the the order of the factor levels, but excludes the missing values, but I have no idea where those occur in the or rather which of those variables were actually missing.  
>> Have I explained this problem sufficiently? 
>> I didn't think it would cause such a problem so I didn't include it in the original problem definition.
>> Yours, Simon
>> On Jul 25, 2014, at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> 
>>> I think this gets what you want. But your data are not reproducible since they are randomly drawn without setting a seed and the two data sets have no relationship to one another.
>>> 
>>>> set.seed(42)
>>>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
>>> + "green", "yellow")))))
>>>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>>>> mydf2 <- data.frame(t(apply(mydf, 1, order)))
>>>> colnames(mydf2) <- levels(mydf$rank1)
>>>> head(mydf)
>>> rank1  rank2  rank3 rank4
>>> 1 yellow  green    red  blue
>>> 2  green   blue yellow   red
>>> 3  green yellow    red  blue
>>> 4 yellow    red  green  blue
>>> 5 yellow    red  green  blue
>>> 6 yellow    red   blue green
>>>> head(mydf2)
>>> blue green red yellow
>>> 1    4     2   3      1
>>> 2    2     1   4      3
>>> 3    4     1   3      2
>>> 4    4     3   2      1
>>> 5    4     3   2      1
>>> 6    3     4   2      1
>>> 
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
>>> Sent: Friday, July 25, 2014 2:34 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
>>> 
>>> Hello:
>>> I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 
>>> 
>>> Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
>>> I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
>>> Thank you
>>> Simon
>>> #Reproducible code
>>> mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))
>>> 
>>> mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
>>> *********************************
>>> Simon J. Kiss, PhD
>>> Assistant Professor, Wilfrid Laurier University
>>> 73 George Street
>>> Brantford, Ontario, Canada
>>> N3T 2C9
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> *********************************
>> Simon J. Kiss, PhD
>> Assistant Professor, Wilfrid Laurier University
>> 73 George Street
>> Brantford, Ontario, Canada
>> N3T 2C9
>> Cell: +1 905 746 7606
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> Cell: +1 905 746 7606
> 
> 
> 

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From c.danyluck at gmail.com  Fri Sep  5 21:41:37 2014
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Fri, 5 Sep 2014 15:41:37 -0400
Subject: [R] Problems bootstrapping multigroup SEM
In-Reply-To: <002b01cfc6e9$090d9b40$1b28d1c0$@mcmaster.ca>
References: <CA+_f+RFmRj8QGD2sy7KmqUVCeLxfKAUY=qXnj9Opz2+J53MSWw@mail.gmail.com>
	<004401cfc24a$91247dd0$b36d7970$@mcmaster.ca>
	<CA+_f+RFRcKgZvezX-9tVNmC6x-tEZ7W-Ry2FLRoQmt33D7wk7Q@mail.gmail.com>
	<002b01cfc6e9$090d9b40$1b28d1c0$@mcmaster.ca>
Message-ID: <CA+_f+RF6mF+A3UnsB35U27h45_h_P3QbQ5zzKcxVEHujH82pDA@mail.gmail.com>

Thanks again John. I think the problem is now resolved.

I changed the information that I passed through the sem() as follows:

MAP.mg.sem <- sem(MAP.mg.mod, data=list(stereotype=stereotype.MAP.data,
evaluative=evaluative.MAP.data), group="IAT.factor")

Then, from ?bootSem

"The default is the data set stored in the sem object, which will be
present only if the model was fit to a data set rather than to a covariance
or moment matrix, and may not be in a form suitable for Cov."

>From this I realized that I don't need to pass anything about the data or
the Cov into bootSem() and so

booted.sem <- bootSem(MAP.mg.sem, R=100)

And I get the anticipated return.

Interestingly, when I tried to pass the Cov and data into the bootSem()
like this:

booted.sem <- bootSem(MAP.mg.sem, R=100, Cov=cov,
data=list(stereotype=stereotype.MAP.data, evaluative=evaluative.MAP.data))

I had a failure to converge.

Kind regards!

Chad


On Tue, Sep 2, 2014 at 4:03 PM, John Fox <jfox at mcmaster.ca> wrote:

> Dear Chad,
>
> > -----Original Message-----
> > From: Chad Danyluck [mailto:c.danyluck at gmail.com]
> > Sent: Tuesday, September 02, 2014 3:29 PM
> > To: John Fox
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Problems bootstrapping multigroup SEM
> >
> > Dear John,
> >
> > Thank you for your insights. I think you do understand what I've been
> > trying to do. Because I am doing a multigroup comparison ?
> > specifically, examining the moderating role of test type on outcome ? I
> > needed two covariance matrices to pass through the model. I wasn't sure
> > how to do this other than by listing these covariance matrices
> > together. This list was called to the SEM and worked when the summary
> > stats were called. As you point out, however, the covariance matrix did
> > not get passed into bootSem() because, rather than use the cov
> > function, I simply added the list. On further reflection, the crux of
> > my problem, or confusion, seems to stem from not understanding how to
> > deal with the need to pass two covariance matrices into bootSem(). I
> > could pass "cov(na.omit(stereotype.MAP.data[,-1],
> > na.omit(evaluative.MAP.data[,-1])))", but I thought that the two
> > matrices needed to be kept separate because I am comparing the models
> > produced by each matrix to one another.
> >
> > Another problem comes to light as I think through the help
> > documentation:
> >
> > "In the case of an msem (i.e., multi-group) model, a list of data sets
> > (again in the appropriate form), one for each group; in this case,
> > bootstrapping is done within each group, treating the groups as strata.
> > Note that the original observations are required, not just the
> > covariance matrix of the observed variables in the model. The default
> > is the data set stored in the sem object, which will be present only if
> > the model was fit to a data set rather than to a covariance or moment
> > matrix, and may not be in a form suitable for Cov."
> >
> > In my case, the data passed through the sem object was
> > "c(nrow(stereotype.MAP.data), nrow(evaluative.MAP.data))". Perhaps this
> > is not suitable for Cov?
>
> I'm sorry but I don't follow this: c(nrow(stereotype.MAP.data),
> nrow(evaluative.MAP.data)) are simply the numbers of observations in the
> data sets, not the data sets themselves. From what you've said, the data
> sets are stereotype.MAP.data and evaluative.MAP.data. You can use the data
> and formula arguments to sem(). You need the explicit formula argument
> because you're apparently omitting one of the variables in each data set;
> alternatively, you can directly remove the unused variable from each data
> set, as you've done above. And you need not filter out the missing data
> (though it doesn't hurt to do so), since the default na.action is na.omit
> (as is shown in ?sem).
>
> From ?sem:
>
> "data: As a generally preferable alternative to specifying S and N, the
> user may supply a data frame containing the data to which the model is to
> be fit. In a multigroup model, the data argument may be a list of data
> frames or a single data frame; in the later event, the factor given as the
> group argument is used to split the data into groups."
>
> and
>
> "formula: a one-sided formula, to be applied to data to generate the
> variables for which covariances or raw moments are computed. The default
> formula is ~., i.e., all of the variables in the data, including an implied
> intercept; if a covariance matrix is to be computed, the constant is
> suppressed. In a multigroup model, alternatively a list one one-sided
> formulas as be given, to be applied individually to the groups."
>
> The multigroup example given in ?sem for the HS.data uses a single data
> frame, which is then classified by the factor Gender. In your case, you'd
> specify a list of two data frames; if the same variables are to be used in
> each, then you need give only one formula rather than a list of two, though
> the latter would also work.
>
> Best,
>  John
>
> >
> > At this point I am spinning my wheels. Any further suggestions would be
> > appreciated.
> >
> > Kind regards,
> >
> >
> > Chad
> >
> >
> >
> >
> > On Wed, Aug 27, 2014 at 6:59 PM, John Fox <jfox at mcmaster.ca> wrote:
> >
> >
> >       Dear Chad,
> >
> >       It's possible that I don't understand properly what you've done,
> > but it appears as if you're passing to bootSem() the covariance
> > matrices for the observed data rather than the case-by-variable data
> > sets themselves. That's also what you say you're doing, and it's what
> > the error message says.
> >
> >       Moreover, if you look at the documentation in ?bootSem, you'll is
> > that the Cov argument isn't a covariance matrix, but "a function to
> > compute the input covariance or moment matrix; the default is cov. Use
> > cor if the model is fit to the correlation matrix. The function hetcor
> > in the polycor package will compute product-moment, polychoric, and
> > polyserial correlations among mixed continuous and ordinal variables
> > (see the first example below for an illustration)."
> >
> >       So what is there to bootstrap if bootSem() doesn't have access to
> > the original data sets? I suppose that one could do a parametric
> > bootstrap of some sort, but that's not what bootSem() does -- in
> > implements a nonoparametric bootstrap, which requires the original
> > data.
> >
> >       I hope this helps,
> >        John
> >
> >       -----------------------------------------------
> >       John Fox, Professor
> >       McMaster University
> >       Hamilton, Ontario, Canada
> >       http://socserv.socsci.mcmaster.ca/jfox/
> >
> >
> >
> >
> >       > -----Original Message-----
> >       > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >       > project.org] On Behalf Of Chad Danyluck
> >       > Sent: Wednesday, August 27, 2014 12:22 PM
> >       > To: r-help at r-project.org
> >       > Subject: [R] Problems bootstrapping multigroup SEM
> >       >
> >       > Hello,
> >       >
> >       > I am having difficulty resolving an error I receive trying to
> > bootstrap
> >       > a
> >       > multigroup SEM. The error (below) indicates that the model
> > called to
> >       > bootSem doesn't contain matrices. This is true, sort of, because
> > I
> >       > created
> >       > a list of two covariance matrices for the model to call. All of
> > this
> >       > syntax
> >       > works fine (a summary of "MAP.mg.sem" will produce parameter
> > estimates,
> >       > goodness of fit indices, etc.), however, the bootSem function
> > does not
> >       > run.
> >       > Any ideas on a workaround?
> >       >
> >       > MLM.MAP.Data$IAT.factor <- as.factor(IAT)
> >       > IAT.factor <- MLM.MAP.Data$IAT.factor
> >       > evaluative.MAP.data <- subset(data.frame(IAT.factor, exp.race,
> >       > meditation.experience, years.meditate, repeated.iat,
> > repeated.ERN, age,
> >       > acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
> >       > FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
> >       > FCz.eval.150.cor), IAT==2)
> >       > stereotype.MAP.data <- subset(data.frame(IAT.factor, exp.race,
> >       > meditation.experience, years.meditate, repeated.iat,
> > repeated.ERN, age,
> >       > acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
> >       > FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
> >       > FCz.eval.150.cor), IAT==1)
> >       >
> >       > MAP.stereotype.cov <- cov(na.omit(stereotype.MAP.data[,-1]))
> >       > MAP.evaluative.cov <- cov(na.omit(evaluative.MAP.data[,-1]))
> >       > MAP.cov.list <- list(stereotype=MAP.stereotype.cov,
> >       > evaluative=MAP.evaluative.cov)
> >       >
> >       > #### Specify your MSEM path model: Years Meditating, ERN,
> > IAT####
> >       > MAP.msem.model <- specifyModel()
> >       > years.meditate -> repeated.ERN, path1
> >       > years.meditate -> repeated.iat, path2
> >       > repeated.ERN -> repeated.iat, path3
> >       > age -> repeated.iat, path4
> >       > years.meditate <-> years.meditate, var1
> >       > repeated.ERN <-> repeated.ERN, var2
> >       > age <-> age, var3
> >       > age <-> years.meditate, cov1
> >       > repeated.iat <-> repeated.iat, d1
> >       >
> >       > MAP.mg.mod <- multigroupModel(MAP.msem.model,
> > groups=c("stereotype",
> >       > "evaluative"))
> >       >
> >       > MAP.mg.sem <- sem(MAP.mg.mod, MAP.cov.list,
> >       > c(nrow(stereotype.MAP.data),
> >       > nrow(evaluative.MAP.data)), group="IAT.factor")
> >       >
> >       > system.time(bootSem(MAP.mg.sem, R=100, MAP.cov.list))
> >       >
> >       > Error in bootSem.msem(MAP.mg.sem, MAP.cov.list, R = 100) :
> >       >   the model object doesn't contain data matrices
> >       >
> >       > --
> >       > Chad M. Danyluck
> >       > PhD Candidate, Psychology
> >       > University of Toronto
> >       > Lab: http://embodiedsocialcognition.com
> >       >
> >       >
> >       > ?There is nothing either good or bad but thinking makes it so.?
> > -
> >       > William
> >       > Shakespeare
> >       >
> >
> >       >       [[alternative HTML version deleted]]
> >       >
> >       > ______________________________________________
> >       > R-help at r-project.org mailing list
> >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > PLEASE do read the posting guide http://www.R-
> > project.org/posting-
> >       > guide.html
> >       > and provide commented, minimal, self-contained, reproducible
> > code.
> >
> >
> >
> >
> >
> >
> > --
> >
> > Chad M. Danyluck
> > PhD Candidate, Psychology
> > University of Toronto
> > Lab: http://embodiedsocialcognition.com
> > <http://embodiedsocialcognition.com/>
> >
> >
> >
> >
> > ?There is nothing either good or bad but thinking makes it so.? -
> > William Shakespeare
>
>
>


-- 
Chad M. Danyluck
PhD Candidate, Psychology
University of Toronto
Lab: http://embodiedsocialcognition.com


?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From vz33 at qq.com  Fri Sep  5 22:51:55 2014
From: vz33 at qq.com (=?utf-8?B?5a2R5r2c?=)
Date: Sat, 6 Sep 2014 04:51:55 +0800
Subject: [R] 'mv: preserving permissions for `all.R': Operation not
	supported' when installing R 3.1.0 via compiling source code
	in CentOS
Message-ID: <tencent_4E2F22FC7CA5C5AC6AF982E8@qq.com>

I compile R3.1.0 to install it in centOS without root. The disk partition format is NFS (network file system). After configure it ($/home/XX/download/R3.1.0/configure --prefix=/home/zj/local/R --enable-R-shlib --with-x?) successfully,  I make it ($make). But there always is an error when make the base package. As bellow:

mkdir -p -- ../../../library/translations
make[4]: Entering directory `/home/zj/tmp/rbuild/src/library/translations'
make[4]: Leaving directory `/home/zj?/tmp/rbuild/src/library/translations'
make[3]: Leaving directory `/home/zj?/tmp/rbuild/src/library/translations'
make[3]: Entering directory `/home/zj?/tmp/rbuild/src/library/base'
building package 'base'
make[4]: Entering directory `/home/zj?/tmp/rbuild/src/library/base'
mv: preserving permissions for `all.R': Operation not supported
make[4]: *** [mkRbase] Error 1
make[4]: Leaving directory `/home/zj?/tmp/rbuild/src/library/base'
make[3]: *** [all] Error 2
make[3]: Leaving directory `/home/zj?/tmp/rbuild/src/library/base'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/zj?/tmp/rbuild/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/zj?/tmp/rbuild/src'
make: *** [R] Error 1
? 
Someone suggest it's related with NFS partition format. but how to deal with this issue. Thank you.
	[[alternative HTML version deleted]]


From garman.dale at gmail.com  Fri Sep  5 19:57:59 2014
From: garman.dale at gmail.com (Dale Garman)
Date: Fri, 5 Sep 2014 10:57:59 -0700
Subject: [R] parameterization question
Message-ID: <CA+GvB=3q=-4fZ8n9tHYJJQV5gMKd6s9f8tGk8Q6iKur8x0U48A@mail.gmail.com>

How can I parameterize the function call to aggregate() below with colx (a
character string) in the following code?   That is, replace both if
statements with aaa <- aggregate(colx_something, data=tidy[grpyrs,],sum).
I've tried a couple of ideas for "colx_something" but get an R-error each
time.  Been using R for 5-6 months and want to expand my knowledge.

explain_causes <- function(spread, colx, peakyears) {
    for(i in peakyears) {
        grpyrs <- tidy$year >= (i-spread) & tidy$year <= (i+spread)
        if(colx == "harm")
            aaa <- aggregate(harm ~ EVTYPE, data=tidy[grpyrs,],sum)
        if(colx == "damage")
            aaa <- aggregate(damage ~ EVTYPE, data=tidy[grpyrs,],sum)
        .
        .
        .
    }
}

# "harm" is a column var in tidy dataframe
explain_causes(0,"harm",c(1953,1965,1974,1979,1984,1995,1998,2011))

# "damage" is a column var in tidy dataframe
explain_causes(0,"damage",c(2005,2006))

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Sat Sep  6 01:04:41 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 05 Sep 2014 16:04:41 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <AFB35C66-1DBA-483E-AE60-056D77E11167@comcast.net>
References: <54050401.4060203@yeah.net>	<53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>
	<5407EBAA.6070807@yeah.net> <5407F315.9060606@yeah.net>
	<AFB35C66-1DBA-483E-AE60-056D77E11167@comcast.net>
Message-ID: <540A4189.6060408@yeah.net>

On 2014/9/4 12:24, David Winsemius wrote:
>
> On Sep 3, 2014, at 10:05 PM, Jinsong Zhao wrote:
>
>> On 2014/9/3 21:33, Jinsong Zhao wrote:
>>> On 2014/9/2 11:50, David L Carlson wrote:
>>>> The bottom of the expression is set by the lowest character (which can
>>>> even change for subscripted letters with descenders. The solution is
>>>> to get axis() to align the tops of the axis labels and move the line
>>>> up to reduce the space, e.g.
>>>>
>>>> plot(1:5, xaxt = "n")
>>>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>>>> "E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
>>>> # Check alignment
>>>> abline(h=.7, xpd=TRUE, lty=3)
>>>
>>> yes. In this situation, padj = 1 is the fast solution. However, If there
>>> are also superscript, then it's hard to alignment all the labels.
>>>
>>> If R provide a mechanism that aligns the label in axis() or text() with
>>> the baseline of the character without the super- and/or sub-script, that
>>> will be terrific.
>>
>> it seems that the above wish is on the Graphics TODO lists:
>> https://www.stat.auckland.ac.nz/~paul/R/graphicstodos.html
>>
>> Allow text adjustment for mathematical annotations which is relative to a text baseline (in addition to the current situation where adjustment is relative to the bounding box).
>>
>
> In many case adding a phantom argument will correct aliognment problems:
>
> plot(1:5, xaxt = "n")
> axis(1, at = 1:5, labels = c(expression(E[g]), E~phantom(E[g]), expression(E[j]),
> E~phantom(E[g]), expression(E[t])))
>
> abline(h=.7, xpd=TRUE, lty=3)
>
> Notice that c(expression(.), ...) will coerce all items separated by commas to expressions, sot you cna just put in "native" expression that are not surrounded by the `expression`-function
>
> c(expression(E[g]), E~phantom(E[g]), expression(E[j])  ) #returns
> # expression(E[g], E ~ phantom(E[g]), E[j])
>
> The tilde is actually a function that converts parse-able strings into R language objects:
>
> c(expression(E[g]), E~phantom(E[g]), ~E[j])
>

I never knew the trick of c(expression(.), ...). It simplifies my code a 
lot.

Thanks a lot.

Best regards,
Jinsong


From jszhao at yeah.net  Sat Sep  6 01:15:54 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 05 Sep 2014 16:15:54 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F95361@mb02.ads.tamu.edu>
References: <54050401.4060203@yeah.net>	<53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>	<5407EBAA.6070807@yeah.net>
	<5407F315.9060606@yeah.net>
	<AFB35C66-1DBA-483E-AE60-056D77E11167@comcast.net>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F95361@mb02.ads.tamu.edu>
Message-ID: <540A442A.9050602@yeah.net>

On 2014/9/4 14:58, David L Carlson wrote:
> The problem with this approach is that the horizontal positioning of the labels is based on the width of the label including the phantom part so that the E's are pushed to the left of the tick mark (at least on my Windows machine). But it does provide a way of dealing with superscripts as long as the phantom is added to each label and hadj= is used to position the label horizontally, eg (changing the last label to a superscript for illustration):
>
> lbl <- expression(E[g]~phantom(E[g]), E~phantom(E[g]), E[j]~phantom(E[g]),
>         E~phantom(E[g]), E^t~phantom(E[g]))
> plot(1:5, xaxt = "n")
> axis(1, at = 1:5, labels = lbl, hadj=.1)
> abline(h=.7, xpd=TRUE, lty=3)
>
> David C

Yes, it works well. However, we have to adjust the hadj with our eyes.

I hope the TODO wish can be implemented in the nearly future.

Thanks a lot.

Best regards,
Jinsong


>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
> Sent: Thursday, September 4, 2014 2:25 PM
> To: Jinsong Zhao
> Cc: r-help at r-project.org
> Subject: Re: [R] depth of labels of axis
>
>
> On Sep 3, 2014, at 10:05 PM, Jinsong Zhao wrote:
>
>> On 2014/9/3 21:33, Jinsong Zhao wrote:
>>> On 2014/9/2 11:50, David L Carlson wrote:
>>>> The bottom of the expression is set by the lowest character (which can
>>>> even change for subscripted letters with descenders. The solution is
>>>> to get axis() to align the tops of the axis labels and move the line
>>>> up to reduce the space, e.g.
>>>>
>>>> plot(1:5, xaxt = "n")
>>>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>>>> "E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
>>>> # Check alignment
>>>> abline(h=.7, xpd=TRUE, lty=3)
>>>
>>> yes. In this situation, padj = 1 is the fast solution. However, If there
>>> are also superscript, then it's hard to alignment all the labels.
>>>
>>> If R provide a mechanism that aligns the label in axis() or text() with
>>> the baseline of the character without the super- and/or sub-script, that
>>> will be terrific.
>>
>> it seems that the above wish is on the Graphics TODO lists:
>> https://www.stat.auckland.ac.nz/~paul/R/graphicstodos.html
>>
>> Allow text adjustment for mathematical annotations which is relative to a text baseline (in addition to the current situation where adjustment is relative to the bounding box).
>>
>
> In many case adding a phantom argument will correct aliognment problems:
>
> plot(1:5, xaxt = "n")
> axis(1, at = 1:5, labels = c(expression(E[g]), E~phantom(E[g]), expression(E[j]),
> E~phantom(E[g]), expression(E[t])))
>
> abline(h=.7, xpd=TRUE, lty=3)
>
> Notice that c(expression(.), ...) will coerce all items separated by commas to expressions, sot you cna just put in "native" expression that are not surrounded by the `expression`-function
>
> c(expression(E[g]), E~phantom(E[g]), expression(E[j])  ) #returns
> # expression(E[g], E ~ phantom(E[g]), E[j])
>
> The tilde is actually a function that converts parse-able strings into R language objects:
>
> c(expression(E[g]), E~phantom(E[g]), ~E[j])
>


From wdunlap at tibco.com  Sat Sep  6 01:28:16 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Sep 2014 16:28:16 -0700
Subject: [R] parameterization question
In-Reply-To: <CA+GvB=3q=-4fZ8n9tHYJJQV5gMKd6s9f8tGk8Q6iKur8x0U48A@mail.gmail.com>
References: <CA+GvB=3q=-4fZ8n9tHYJJQV5gMKd6s9f8tGk8Q6iKur8x0U48A@mail.gmail.com>
Message-ID: <CAF8bMcZGsjFg5N4Ab4ZbRc_pXAhNKz91g9pvPsWkZPYAVSU14g@mail.gmail.com>

You could try using the non-formula interface to aggregate.

Note that the following two calls to aggregate are equivalent but
the second (using the non-formula interface) makes the response column
a variable:

  > df <- data.frame(Y1=1:10, Y2=101:110, Group=rep(letters[1:3], c(3,3,4)))
  > aggregate(Y1 ~ Group, data=df, FUN=sum)
    Group Y1
  1     a  6
  2     b 15
  3     c 34
  > responseColumn <- "Y1"
  > aggregate(df[responseColumn], by=df["Group"], FUN=sum)
    Group Y1
  1     a  6
  2     b 15
  3     c 34

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Sep 5, 2014 at 10:57 AM, Dale Garman <garman.dale at gmail.com> wrote:
> How can I parameterize the function call to aggregate() below with colx (a
> character string) in the following code?   That is, replace both if
> statements with aaa <- aggregate(colx_something, data=tidy[grpyrs,],sum).
> I've tried a couple of ideas for "colx_something" but get an R-error each
> time.  Been using R for 5-6 months and want to expand my knowledge.
>
> explain_causes <- function(spread, colx, peakyears) {
>     for(i in peakyears) {
>         grpyrs <- tidy$year >= (i-spread) & tidy$year <= (i+spread)
>         if(colx == "harm")
>             aaa <- aggregate(harm ~ EVTYPE, data=tidy[grpyrs,],sum)
>         if(colx == "damage")
>             aaa <- aggregate(damage ~ EVTYPE, data=tidy[grpyrs,],sum)
>         .
>         .
>         .
>     }
> }
>
> # "harm" is a column var in tidy dataframe
> explain_causes(0,"harm",c(1953,1965,1974,1979,1984,1995,1998,2011))
>
> # "damage" is a column var in tidy dataframe
> explain_causes(0,"damage",c(2005,2006))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Sep  6 01:53:42 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Sep 2014 16:53:42 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <540A442A.9050602@yeah.net>
References: <54050401.4060203@yeah.net>	<53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>	<5407EBAA.6070807@yeah.net>
	<5407F315.9060606@yeah.net>
	<AFB35C66-1DBA-483E-AE60-056D77E11167@comcast.net>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F95361@mb02.ads.tamu.edu>
	<540A442A.9050602@yeah.net>
Message-ID: <820AD3DC-1B03-49C2-B42D-497CD6801502@comcast.net>


On Sep 5, 2014, at 4:15 PM, Jinsong Zhao wrote:

> On 2014/9/4 14:58, David L Carlson wrote:
>> The problem with this approach is that the horizontal positioning of the labels is based on the width of the label including the phantom part so that the E's are pushed to the left of the tick mark (at least on my Windows machine). But it does provide a way of dealing with superscripts as long as the phantom is added to each label and hadj= is used to position the label horizontally, eg (changing the last label to a superscript for illustration):
>> 
>> lbl <- expression(E[g]~phantom(E[g]), E~phantom(E[g]), E[j]~phantom(E[g]),
>>        E~phantom(E[g]), E^t~phantom(E[g]))
>> plot(1:5, xaxt = "n")
>> axis(1, at = 1:5, labels = lbl, hadj=.1)
>> abline(h=.7, xpd=TRUE, lty=3)
>> 
>> David C
> 
> Yes, it works well. However, we have to adjust the hadj with our eyes.
> 
> I hope the TODO wish can be implemented in the nearly future.

Man, this is a really hard crowd to please. Consider this use of the c(expression(),...) "trick" and the appending of super and subscripts to every item fore and aft (sailing terminology):

updown <- function(x){ e <- expression(); return(c(e,sapply( x, function(x) bquote( phantom(E)^phantom(t)*.(x)*phantom(E)[phantom(g)] , list(x=x)) ))) }

lbl <- expression(E[g], E, E[j], E, E^t)

plot(1:5, xaxt = "n")
axis(1, at = 1:5, labels = updown(lbl) )
abline(h=.7, xpd=TRUE, lty=3)



> 
> Thanks a lot.
> 
> Best regards,
> Jinsong
> 
> 
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
>> Sent: Thursday, September 4, 2014 2:25 PM
>> To: Jinsong Zhao
>> Cc: r-help at r-project.org
>> Subject: Re: [R] depth of labels of axis
>> 
>> 
>> On Sep 3, 2014, at 10:05 PM, Jinsong Zhao wrote:
>> 
>>> On 2014/9/3 21:33, Jinsong Zhao wrote:
>>>> On 2014/9/2 11:50, David L Carlson wrote:
>>>>> The bottom of the expression is set by the lowest character (which can
>>>>> even change for subscripted letters with descenders. The solution is
>>>>> to get axis() to align the tops of the axis labels and move the line
>>>>> up to reduce the space, e.g.
>>>>> 
>>>>> plot(1:5, xaxt = "n")
>>>>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>>>>> "E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
>>>>> # Check alignment
>>>>> abline(h=.7, xpd=TRUE, lty=3)
>>>> 
>>>> yes. In this situation, padj = 1 is the fast solution. However, If there
>>>> are also superscript, then it's hard to alignment all the labels.
>>>> 
>>>> If R provide a mechanism that aligns the label in axis() or text() with
>>>> the baseline of the character without the super- and/or sub-script, that
>>>> will be terrific.
>>> 
>>> it seems that the above wish is on the Graphics TODO lists:
>>> https://www.stat.auckland.ac.nz/~paul/R/graphicstodos.html
>>> 
>>> Allow text adjustment for mathematical annotations which is relative to a text baseline (in addition to the current situation where adjustment is relative to the bounding box).
>>> 
>> 
>> In many case adding a phantom argument will correct aliognment problems:
>> 
>> plot(1:5, xaxt = "n")
>> axis(1, at = 1:5, labels = c(expression(E[g]), E~phantom(E[g]), expression(E[j]),
>> E~phantom(E[g]), expression(E[t])))
>> 
>> abline(h=.7, xpd=TRUE, lty=3)
>> 
>> Notice that c(expression(.), ...) will coerce all items separated by commas to expressions, sot you cna just put in "native" expression that are not surrounded by the `expression`-function
>> 
>> c(expression(E[g]), E~phantom(E[g]), expression(E[j])  ) #returns
>> # expression(E[g], E ~ phantom(E[g]), E[j])
>> 
>> The tilde is actually a function that converts parse-able strings into R language objects:
>> 
>> c(expression(E[g]), E~phantom(E[g]), ~E[j])
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Sep  6 02:04:18 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Sep 2014 17:04:18 -0700
Subject: [R] depth of labels of axis
In-Reply-To: <820AD3DC-1B03-49C2-B42D-497CD6801502@comcast.net>
References: <54050401.4060203@yeah.net>	<53BF8FB63FAF2E4A9455EF1EE94DA726F949B6@mb02.ads.tamu.edu>	<5407EBAA.6070807@yeah.net>
	<5407F315.9060606@yeah.net>
	<AFB35C66-1DBA-483E-AE60-056D77E11167@comcast.net>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F95361@mb02.ads.tamu.edu>
	<540A442A.9050602@yeah.net>
	<820AD3DC-1B03-49C2-B42D-497CD6801502@comcast.net>
Message-ID: <6A384A58-511C-4CCD-AE91-0F5D2E393614@comcast.net>


On Sep 5, 2014, at 4:53 PM, David Winsemius wrote:

> 
> On Sep 5, 2014, at 4:15 PM, Jinsong Zhao wrote:
> 
>> On 2014/9/4 14:58, David L Carlson wrote:
>>> The problem with this approach is that the horizontal positioning of the labels is based on the width of the label including the phantom part so that the E's are pushed to the left of the tick mark (at least on my Windows machine). But it does provide a way of dealing with superscripts as long as the phantom is added to each label and hadj= is used to position the label horizontally, eg (changing the last label to a superscript for illustration):
>>> 
>>> lbl <- expression(E[g]~phantom(E[g]), E~phantom(E[g]), E[j]~phantom(E[g]),
>>>       E~phantom(E[g]), E^t~phantom(E[g]))
>>> plot(1:5, xaxt = "n")
>>> axis(1, at = 1:5, labels = lbl, hadj=.1)
>>> abline(h=.7, xpd=TRUE, lty=3)
>>> 
>>> David C
>> 
>> Yes, it works well. However, we have to adjust the hadj with our eyes.
>> 
>> I hope the TODO wish can be implemented in the nearly future.
> 
> Man, this is a really hard crowd to please. Consider this use of the c(expression(),...) "trick" and the appending of super and subscripts to every item fore and aft (sailing terminology):
> 
> updown <- function(x){ e <- expression(); return(c(e,sapply( x, function(x) bquote( phantom(E)^phantom(t)*.(x)*phantom(E)[phantom(g)] , list(x=x)) ))) }

There is an extraneous list(x=x) left over from when I was trying to use substitute() that should be removed, although it didn't seem to affect the output..
> 
> lbl <- expression(E[g], E, E[j], E, E^t)
> 
> plot(1:5, xaxt = "n")
> axis(1, at = 1:5, labels = updown(lbl) )
> abline(h=.7, xpd=TRUE, lty=3)
> 
> 
> 
>> 
>> Thanks a lot.
>> 
>> Best regards,
>> Jinsong
>> 
>> 
>>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
>>> Sent: Thursday, September 4, 2014 2:25 PM
>>> To: Jinsong Zhao
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] depth of labels of axis
>>> 
>>> 
>>> On Sep 3, 2014, at 10:05 PM, Jinsong Zhao wrote:
>>> 
>>>> On 2014/9/3 21:33, Jinsong Zhao wrote:
>>>>> On 2014/9/2 11:50, David L Carlson wrote:
>>>>>> The bottom of the expression is set by the lowest character (which can
>>>>>> even change for subscripted letters with descenders. The solution is
>>>>>> to get axis() to align the tops of the axis labels and move the line
>>>>>> up to reduce the space, e.g.
>>>>>> 
>>>>>> plot(1:5, xaxt = "n")
>>>>>> axis(1, at = 1:5, labels = c(expression(E[g]), "E", expression(E[j]),
>>>>>> "E", expression(E[t])), padj=1, mgp=c(3, .1, 0))
>>>>>> # Check alignment
>>>>>> abline(h=.7, xpd=TRUE, lty=3)
>>>>> 
>>>>> yes. In this situation, padj = 1 is the fast solution. However, If there
>>>>> are also superscript, then it's hard to alignment all the labels.
>>>>> 
>>>>> If R provide a mechanism that aligns the label in axis() or text() with
>>>>> the baseline of the character without the super- and/or sub-script, that
>>>>> will be terrific.
>>>> 
>>>> it seems that the above wish is on the Graphics TODO lists:
>>>> https://www.stat.auckland.ac.nz/~paul/R/graphicstodos.html
>>>> 
>>>> Allow text adjustment for mathematical annotations which is relative to a text baseline (in addition to the current situation where adjustment is relative to the bounding box).
>>>> 
>>> 
>>> In many case adding a phantom argument will correct aliognment problems:
>>> 
>>> plot(1:5, xaxt = "n")
>>> axis(1, at = 1:5, labels = c(expression(E[g]), E~phantom(E[g]), expression(E[j]),
>>> E~phantom(E[g]), expression(E[t])))
>>> 
>>> abline(h=.7, xpd=TRUE, lty=3)
>>> 
>>> Notice that c(expression(.), ...) will coerce all items separated by commas to expressions, sot you cna just put in "native" expression that are not surrounded by the `expression`-function
>>> 
>>> c(expression(E[g]), E~phantom(E[g]), expression(E[j])  ) #returns
>>> # expression(E[g], E ~ phantom(E[g]), E[j])
>>> 
>>> The tilde is actually a function that converts parse-able strings into R language objects:
>>> 
>>> c(expression(E[g]), E~phantom(E[g]), ~E[j])
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bonsxanco at yahoo.com  Sat Sep  6 04:17:06 2014
From: bonsxanco at yahoo.com (Chris)
Date: Sat, 6 Sep 2014 02:17:06 +0000
Subject: [R] Testing general hypotheses on regression coefficients
Message-ID: <loom.20140906T040650-156@post.gmane.org>

Hi.

Say I have a model like

y = a + B1*x1 + B2*x2 + B3*x3 + B4*x4 + e

and I want to test

H0: B2/B1 = 0

or

H0: B2/B1=B4/B3

(whatever H1). How can I proceed?

I now about car::linearHypothesis, but I can't figure out a way to do the 
tests above.

Any hint?

Thanks.

C


From sorenh at math.aau.dk  Sat Sep  6 06:48:24 2014
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sat, 6 Sep 2014 04:48:24 +0000
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <loom.20140906T040650-156@post.gmane.org>
References: <loom.20140906T040650-156@post.gmane.org>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3A161F209@AD-EXCHMBX2-1.aau.dk>

AFAICS you are not testing a linear hypothesis (which is of the form Lb=b0 where L is a matrix and b=(a,B1,B2,B3,B3) is the parameter vector).

If, for simplicity, your model is E(y) = a + bx then -a/b is the x-value for which y is zero.

When you turn to estimates then u = -a/b is the ratio of two (typically correlated) normal variables and such a ratio is *not* normal. (Just think of the Cauchy distribution.)

One approach is to calculate the approximate variance of u and then construct a Wald test or similar while hoping for the best. Alternatively one could perhaps try with a parametric bootstrap test. 

Just ideas. Good luck.
S?ren




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Chris
Sent: 6. september 2014 04:17
To: r-help at stat.math.ethz.ch
Subject: [R] Testing general hypotheses on regression coefficients

Hi.

Say I have a model like

y = a + B1*x1 + B2*x2 + B3*x3 + B4*x4 + e

and I want to test

H0: B2/B1 = 0

or

H0: B2/B1=B4/B3

(whatever H1). How can I proceed?

I now about car::linearHypothesis, but I can't figure out a way to do the tests above.

Any hint?

Thanks.

C

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Sep  6 06:56:10 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 5 Sep 2014 21:56:10 -0700
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <loom.20140906T040650-156@post.gmane.org>
References: <loom.20140906T040650-156@post.gmane.org>
Message-ID: <CACk-te3q2VwkbnSh5+J4BzXr7f4LWv6TuKtUBjK30JePdeT7Gg@mail.gmail.com>

Well:

1) 8th grade algebra tells me B2/B1 == 0 <==> B2 =0;

2) I suspect you would need to provide more context for the other, as
you may be going about this entirely incorrectly (have you consulted a
local statistician?):  your nonlinear hypothesis probably can be made
linear under the right parametrization, but context might suggest
something entirely different than the approach that motivated your
query.

3) But forget all that! -- this is a list about the R language, not
statistics -- which seems to be the essence of your query --  although
I grant that the intersection is nonempty. But for statistics help,
you should try a statistics list like stats.stackexchange.com instead.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Sep 5, 2014 at 7:17 PM, Chris <bonsxanco at yahoo.com> wrote:
> Hi.
>
> Say I have a model like
>
> y = a + B1*x1 + B2*x2 + B3*x3 + B4*x4 + e
>
> and I want to test
>
> H0: B2/B1 = 0
>
> or
>
> H0: B2/B1=B4/B3
>
> (whatever H1). How can I proceed?
>
> I now about car::linearHypothesis, but I can't figure out a way to do the
> tests above.
>
> Any hint?
>
> Thanks.
>
> C
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From skostysh at princeton.edu  Sat Sep  6 10:15:10 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sat, 6 Sep 2014 04:15:10 -0400
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <CACk-te3q2VwkbnSh5+J4BzXr7f4LWv6TuKtUBjK30JePdeT7Gg@mail.gmail.com>
References: <loom.20140906T040650-156@post.gmane.org>
	<CACk-te3q2VwkbnSh5+J4BzXr7f4LWv6TuKtUBjK30JePdeT7Gg@mail.gmail.com>
Message-ID: <CAE3=dmd_W5n=kCi2fdPUqst1xaF726ZqLC75KNW-PCq-xQKu9w@mail.gmail.com>

Hi Chris,

> On Fri, Sep 5, 2014 at 7:17 PM, Chris <bonsxanco at yahoo.com> wrote:
> Hi.
>
> Say I have a model like
>
> y = a + B1*x1 + B2*x2 + B3*x3 + B4*x4 + e
>
> and I want to test
>
> H0: B2/B1 = 0

As noted by Bert, think about this.

> or
>
> H0: B2/B1=B4/B3
>
> (whatever H1). How can I proceed?
>
> I now about car::linearHypothesis, but I can't figure out a way to do the
> tests above.
>
> Any hint?

Take a look at car::deltaMethod. I suggest you study the theory of the
delta method. If you happen to have taken a graduate
statistics/econometrics class it should not be difficult and can
provide some insights. If not, at least consider that the delta method
can lead to misleading estimates (biased standard errors) in many
cases for finite samples. You might want to run some simulations to
get a feel for it.

Best,

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From rl at openmailbox.org  Sat Sep  6 15:14:44 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Sat, 06 Sep 2014 13:14:44 +0000
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
Message-ID: <487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>

On 2014-09-05 09:40, rl at openmailbox.org wrote:
> Subscribers,
> 
> Could someone please indicate correct terminology and relevant manual
> sections to achieve the following conceptual workflow, to create a
> script to select sequentially parts of a dataframe:
> 
>> "Welcome to this R script program"
>> Select level number below of variable 'X'
> [1]
> [2]
> [3]
>> 3
>> Select level number below of variable 'Y'
> [1]
> [2]
>> 1
>> Summary
> X, [2] 'descriptive text A for level 3 selected'
> [1] 'descriptive text B for level 1 selected'
>> Display graph? Y/N
>> y
>> [specific selected script activated, graph displayed]
> 
> Thanks in advance.
> 
> --
> N.B. digest mode subscriber; please cc message.

For a test csv file:

variablea,variableb,variablec
"text test1","other textx",100
"text test2","other texty",200
"text test3","other textz",400

Tried the following:

testdata<-read.csv('test.csv')
testdataextract1<-switch(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select 
something'))

Select something

1: text test1
2: text test2
3: text test3

Selection: 1
> testdataextract1
NULL

The requested output is:

"text test1","other textx",100

Why is the result 'NULL'?


From wdunlap at tibco.com  Sat Sep  6 17:21:19 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 6 Sep 2014 08:21:19 -0700
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
	<487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
Message-ID: <CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>

> testdataextract1<-switch(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select something'))

The switch function does not work the way you are expecting it to.
Read help("switch") and read the introduction to R that comes with R.

You probably want to use the output of menu() to extract a row of
testdata with testdata[outputOfMenu,].  (How could testdataextract1
contain anything in the 2nd or 3rd columns of testdata if the
expression producing testdataextract1 does not contain any reference
to that column?)


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Sep 6, 2014 at 6:14 AM,  <rl at openmailbox.org> wrote:
> On 2014-09-05 09:40, rl at openmailbox.org wrote:
>>
>> Subscribers,
>>
>> Could someone please indicate correct terminology and relevant manual
>> sections to achieve the following conceptual workflow, to create a
>> script to select sequentially parts of a dataframe:
>>
>>> "Welcome to this R script program"
>>> Select level number below of variable 'X'
>>
>> [1]
>> [2]
>> [3]
>>>
>>> 3
>>> Select level number below of variable 'Y'
>>
>> [1]
>> [2]
>>>
>>> 1
>>> Summary
>>
>> X, [2] 'descriptive text A for level 3 selected'
>> [1] 'descriptive text B for level 1 selected'
>>>
>>> Display graph? Y/N
>>> y
>>> [specific selected script activated, graph displayed]
>>
>>
>> Thanks in advance.
>>
>> --
>> N.B. digest mode subscriber; please cc message.
>
>
> For a test csv file:
>
> variablea,variableb,variablec
> "text test1","other textx",100
> "text test2","other texty",200
> "text test3","other textz",400
>
> Tried the following:
>
> testdata<-read.csv('test.csv')
> testdataextract1<-switch(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select
> something'))
>
> Select something
>
> 1: text test1
> 2: text test2
> 3: text test3
>
> Selection: 1
>>
>> testdataextract1
>
> NULL
>
> The requested output is:
>
> "text test1","other textx",100
>
> Why is the result 'NULL'?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Sep  7 00:31:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 6 Sep 2014 15:31:49 -0700
Subject: [R] Why does debugging  print()  change output of function?
Message-ID: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>

The goal: 
   to create a function modeled after `subset` (notorious for its non-standard evaluation) that will take a series of logical tests as unqiuoted expressions to be evaluated in the framework of a dataframe environment and return a dataframe of logicals:


 mtest.data.frame <- 
 function (x, ..., drop=FALSE) 
 { tests <- list(...); print(tests)
     r <- if (length(tests)==0) 
         stop("no 'tests'")
     else { cbind.data.frame(
             lapply( tests, function(t){
                          e <- substitute(t)
                          r <- eval(e, x, parent.frame() )
                  if ( !is.logical(r) ) {
                      stop("'tests' must be logical") }
                     r & !is.na(r) } ) )
     }
 }
#--------------

testdata <- structure(list(group1 = structure(1:7, .Label = c("Group A", 
"Group B", "Group C", "Group D", "Group E", "Group F", "Group G"
), class = "factor"), group2 = structure(c(3L, 3L, 2L, 1L, 1L, 
2L, 3L), .Label = c("LS", "SS", "UNC"), class = "factor"), valid1 = structure(c(2L, 
1L, NA, 1L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"), 
    valid2 = structure(c(1L, 1L, 2L, 1L, 1L, 2L, 1L), .Label = c("N", 
    "Y"), class = "factor"), valid3 = structure(c(4L, 3L, NA, 
    2L, 1L, NA, 5L), .Label = c("0.3", "0.7", "1.2", "1.4", "1.7"
    ), class = "factor"), valid4 = structure(c(2L, 1L, 3L, 4L, 
    1L, 1L, 5L), .Label = c("0.3", "0.4", "0.53", "0.66", "0.71"
    ), class = "factor"), valid5 = structure(c(4L, 1L, NA, NA, 
    3L, NA, 2L), .Label = c("11.2", "11.7", "8.3", "8.5"), class = "factor")), .Names = c("group1", 
"group2", "valid1", "valid2", "valid3", "valid4", "valid5"), row.names = c(NA, 
-7L), class = "data.frame")

#######


> mtest.data.frame(testdata, valid2=="N", valid3 > 1)
[[1]]
[1] "tests are"

[[2]]
[1]  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE

[[3]]
[1]  TRUE  TRUE    NA FALSE FALSE    NA  TRUE

This actually seemed to be somewhat successful, but when ... 

Now if I take out the `print()` call for 'tests', I get an different answer:

> mtest.data.frame <- 
+  function (x, ..., drop=FALSE) 
+  { tests <- list(...)
+      r <- if (length(tests)==0) 
+          stop("no 'tests'")
+      else { cbind.data.frame(
+              lapply( tests, function(t){
+                           e <- substitute(t)
+                           r <- eval(e, x, parent.frame() )
+                   if ( !is.logical(r) ) {
+                       stop("'tests' must be logical") }
+                      r & !is.na(r) } ) )
+      }
+  }
> mtest.data.frame(testdata, valid2=="N", valid3 > 1)
>   # i.e. no answer

-- 

David Winsemius
Alameda, CA, USA


From jwd at surewest.net  Sun Sep  7 01:17:12 2014
From: jwd at surewest.net (jwd)
Date: Sat, 6 Sep 2014 16:17:12 -0700
Subject: [R] Why does debugging  print()  change output of function?
In-Reply-To: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
References: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
Message-ID: <20140906161712.7833983d@draco>

On Sat, 6 Sep 2014 15:31:49 -0700
David Winsemius <dwinsemius at comcast.net> wrote:

The only other difference I see is a missing semicolon in the second
example, which, in the first precedes your print() instruction.

JWDougherty


From wdunlap at tibco.com  Sun Sep  7 01:24:47 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 6 Sep 2014 16:24:47 -0700
Subject: [R] Why does debugging print() change output of function?
In-Reply-To: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
References: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
Message-ID: <CAF8bMcbn-GJnvHWi3qN1o3rk48X2uBb+SDdHERDxswAnrVVy-g@mail.gmail.com>

In your first example I get an error:
  > mtest.data.frame(testdata, valid2=="N", valid3 > 1)
  Error in mtest.data.frame(testdata, valid2 == "N", valid3 > 1) :
    object 'valid2' not found
I expect the error because list(...) ought to evaluate the ... arguments.

Use substitute() to get the unevaluated ... arguments up front and
don't use substitute() in the loop over the elements of test.

There are several ways to get the unevaluated ... arguments.  E.g.,
  f0 <- function(x, ..., drop=FALSE) match.call(expand.dots=FALSE)$...
  f1 <- function(x, ..., drop=FALSE) substitute(...())
  f2 <- function(x, ..., drop=FALSE) as.list(substitute(list(...)))[-1]

Your function could be the following, where I also fixed a problem
with parent.frame() being
called in the wrong scope and improved, IMO, the names on the output data.frame.

m2 <- function (x, ..., drop = FALSE, verbose = FALSE)
{
    tests <- substitute(...())
    nms <- names(tests) # fix up names, since data.frame makes ugly ones
    if (is.null(nms)) {
        names(tests) <- paste0("T", seq_along(tests))
    }
    else if (any(nms == "")) {
        names(tests)[nms == ""] <- paste0("T", which(nms == ""))
    }
    if (verbose) {
        print(tests)
    }
    r <- if (length(tests) == 0) {
        stop("no 'tests'")
    }
    else {
        enclos <- parent.frame() # evaluate parent.frame() outside of FUN()
        data.frame(lapply(tests, FUN=function(e) {
            r <- eval(e, x, enclos)
            if (!is.logical(r)) {
                stop("'tests' must be logical")
            }
            r & !is.na(r)
        }))
    }
    r
}

used as:
> m2(testdata, group2=="UNC", Eleven.Two=valid5=="11.2")
     T1 Eleven.Two
1  TRUE      FALSE
2  TRUE       TRUE
3 FALSE      FALSE
4 FALSE      FALSE
5 FALSE      FALSE
6 FALSE      FALSE
7  TRUE      FALSE
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Sep 6, 2014 at 3:31 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> The goal:
>    to create a function modeled after `subset` (notorious for its non-standard evaluation) that will take a series of logical tests as unqiuoted expressions to be evaluated in the framework of a dataframe environment and return a dataframe of logicals:
>
>
>  mtest.data.frame <-
>  function (x, ..., drop=FALSE)
>  { tests <- list(...); print(tests)
>      r <- if (length(tests)==0)
>          stop("no 'tests'")
>      else { cbind.data.frame(
>              lapply( tests, function(t){
>                           e <- substitute(t)
>                           r <- eval(e, x, parent.frame() )
>                   if ( !is.logical(r) ) {
>                       stop("'tests' must be logical") }
>                      r & !is.na(r) } ) )
>      }
>  }
> #--------------
>
> testdata <- structure(list(group1 = structure(1:7, .Label = c("Group A",
> "Group B", "Group C", "Group D", "Group E", "Group F", "Group G"
> ), class = "factor"), group2 = structure(c(3L, 3L, 2L, 1L, 1L,
> 2L, 3L), .Label = c("LS", "SS", "UNC"), class = "factor"), valid1 = structure(c(2L,
> 1L, NA, 1L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"),
>     valid2 = structure(c(1L, 1L, 2L, 1L, 1L, 2L, 1L), .Label = c("N",
>     "Y"), class = "factor"), valid3 = structure(c(4L, 3L, NA,
>     2L, 1L, NA, 5L), .Label = c("0.3", "0.7", "1.2", "1.4", "1.7"
>     ), class = "factor"), valid4 = structure(c(2L, 1L, 3L, 4L,
>     1L, 1L, 5L), .Label = c("0.3", "0.4", "0.53", "0.66", "0.71"
>     ), class = "factor"), valid5 = structure(c(4L, 1L, NA, NA,
>     3L, NA, 2L), .Label = c("11.2", "11.7", "8.3", "8.5"), class = "factor")), .Names = c("group1",
> "group2", "valid1", "valid2", "valid3", "valid4", "valid5"), row.names = c(NA,
> -7L), class = "data.frame")
>
> #######
>
>
>> mtest.data.frame(testdata, valid2=="N", valid3 > 1)
> [[1]]
> [1] "tests are"
>
> [[2]]
> [1]  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE
>
> [[3]]
> [1]  TRUE  TRUE    NA FALSE FALSE    NA  TRUE
>
> This actually seemed to be somewhat successful, but when ...
>
> Now if I take out the `print()` call for 'tests', I get an different answer:
>
>> mtest.data.frame <-
> +  function (x, ..., drop=FALSE)
> +  { tests <- list(...)
> +      r <- if (length(tests)==0)
> +          stop("no 'tests'")
> +      else { cbind.data.frame(
> +              lapply( tests, function(t){
> +                           e <- substitute(t)
> +                           r <- eval(e, x, parent.frame() )
> +                   if ( !is.logical(r) ) {
> +                       stop("'tests' must be logical") }
> +                      r & !is.na(r) } ) )
> +      }
> +  }
>> mtest.data.frame(testdata, valid2=="N", valid3 > 1)
>>   # i.e. no answer
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bonsxanco at yahoo.com  Sat Sep  6 12:24:03 2014
From: bonsxanco at yahoo.com (bonsxanco)
Date: Sat, 6 Sep 2014 03:24:03 -0700
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <CAE3=dmd_W5n=kCi2fdPUqst1xaF726ZqLC75KNW-PCq-xQKu9w@mail.gmail.com>
References: <loom.20140906T040650-156@post.gmane.org>	<CACk-te3q2VwkbnSh5+J4BzXr7f4LWv6TuKtUBjK30JePdeT7Gg@mail.gmail.com>
	<CAE3=dmd_W5n=kCi2fdPUqst1xaF726ZqLC75KNW-PCq-xQKu9w@mail.gmail.com>
Message-ID: <1409999043.70851.YahooMailNeo@web120102.mail.ne1.yahoo.com>

Hi.

First of all, thanks to all who have replied.

> 1) 8th grade algebra tells me B2/B1 == 0 <==> B2 =0;

EViews (econometrics program) doesn't have the same opinion:

Wald test on my real model (edited):

* H0: B3/B2 = 0 -> F-stat = 37.82497 
* H0: B3 = 0    -> F-stat = 16.31689 

> 2) I suspect you would need to provide more context for the other


The context is this: I'm estimating a model which is:

d(y) = a + B1*y(-1) + B2*X_p(-1) + B3*X_n(-1) + other + error

where X_p and X_n are partial sum decompositions of positive and negative shocks:

X_p(t) = X_p(t-1) + (d(X_p(t))>0)*d(X_p(t)) ; X_p(0)=0
X_n(t) = X_n(t-1) + (d(X_n(t))>0)*d(X_n(t)) ; X_p(0)=0

I think this is enough, but I can provide the full references.

Now, back to the problem: testing B2/B1=0 tells me about that the long term effect, while testing for B2/B1=B3/B1 tells me that about the equality of long term effects to negative and positive shocks.

> car::deltaMethod

I just gave a quick look and searched about delta method, but I can't see how it would help in testing the restrictions above. I'll read more about it, though, as it seems interesting, thanks for the pointer.

(Sorry if this e-mail goes out of context, but the first time I sent it through gmane, as I wasn't subscribed.)

Chris


From bonsxanco at yahoo.com  Sat Sep  6 13:07:23 2014
From: bonsxanco at yahoo.com (bonsxanco)
Date: Sat, 6 Sep 2014 04:07:23 -0700
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <1409999043.70851.YahooMailNeo@web120102.mail.ne1.yahoo.com>
References: <loom.20140906T040650-156@post.gmane.org>	<CACk-te3q2VwkbnSh5+J4BzXr7f4LWv6TuKtUBjK30JePdeT7Gg@mail.gmail.com>
	<CAE3=dmd_W5n=kCi2fdPUqst1xaF726ZqLC75KNW-PCq-xQKu9w@mail.gmail.com>
	<1409999043.70851.YahooMailNeo@web120102.mail.ne1.yahoo.com>
Message-ID: <1410001643.61828.YahooMailNeo@web120102.mail.ne1.yahoo.com>

Scott said:


> car::deltaMethod

I said:

> I just gave a quick look and searched about delta method, but I can't
> see how it would help in testing the restrictions above. 

Actually it seems that it should be the way to go: I just noticed under the EViews Wald test window the message "Delta method computed using analytic derivatives.
"

Anyway, I wonder if there's some easier way to do it.

Best,

Chris


From dwinsemius at comcast.net  Sun Sep  7 07:37:53 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 6 Sep 2014 22:37:53 -0700
Subject: [R] Why does debugging print() change output of function?
In-Reply-To: <CAF8bMcbn-GJnvHWi3qN1o3rk48X2uBb+SDdHERDxswAnrVVy-g@mail.gmail.com>
References: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
	<CAF8bMcbn-GJnvHWi3qN1o3rk48X2uBb+SDdHERDxswAnrVVy-g@mail.gmail.com>
Message-ID: <0BEC3325-5AFB-474C-8D32-964DD930C1CB@comcast.net>


On Sep 6, 2014, at 4:24 PM, William Dunlap wrote:

> In your first example I get an error:
>> mtest.data.frame(testdata, valid2=="N", valid3 > 1)
>  Error in mtest.data.frame(testdata, valid2 == "N", valid3 > 1) :
>    object 'valid2' not found
> I expect the error because list(...) ought to evaluate the ... arguments.

Thank you (and JWDougherty) for looking at this. I see that the difference lies in the fact that I have vectors in my workspace that were used  as preliminaries in constructing my test case that are being accessed by my logical expressions.

 group1 <- paste("Group", rep(LETTERS[1:7], sep=''))
  group2 <- c("UNC", "UNC", "SS", "LS", "LS", "SS", "UNC")
  valid1 <- c("Y", "N", NA, "N", "Y", "Y", "N")
 valid2 <- c("N", "N", "Y", "N", "N", "Y", "N")
  valid3 <- c(1.4, 1.2, NA, 0.7, 0.3, NA, 1.7)
  valid4 <- c(0.4, 0.3, 0.53, 0.66, 0.3, 0.3, 0.71)
 valid5 <- c(8.5, 11.2,NA, NA, 8.3, NA, 11.7)

I should have executed rm(list=ls()) and repeated my testing before posting, but you 
> Use substitute() to get the unevaluated ... arguments up front and
> don't use substitute() in the loop over the elements of test.
> 
> There are several ways to get the unevaluated ... arguments.  E.g.,
>  f0 <- function(x, ..., drop=FALSE) match.call(expand.dots=FALSE)$...

>  f1 <- function(x, ..., drop=FALSE) substitute(...())
>  f2 <- function(x, ..., drop=FALSE) as.list(substitute(list(...)))[-1]

These three version are somewhat confusing,  the second one in particular makes it appear that the ellipsis is a function, while the other ones make it appear that they are an expression pointing to a list.

> 
> Your function could be the following, where I also fixed a problem
> with parent.frame() being
> called in the wrong scope and improved,

Yes, I was worried about that.

> IMO, the names on the output data.frame.
> 
> m2 <- function (x, ..., drop = FALSE, verbose = FALSE)
> {
>    tests <- substitute(...())
>    nms <- names(tests) # fix up names, since data.frame makes ugly ones
>    if (is.null(nms)) {
>        names(tests) <- paste0("T", seq_along(tests))
>    }
>    else if (any(nms == "")) {
>        names(tests)[nms == ""] <- paste0("T", which(nms == ""))
>    }
>    if (verbose) {
>        print(tests)
>    }
>    r <- if (length(tests) == 0) {
>        stop("no 'tests'")
>    }
>    else {
>        enclos <- parent.frame() # evaluate parent.frame() outside of FUN()
>        data.frame(lapply(tests, FUN=function(e) {
>            r <- eval(e, x, enclos)
>            if (!is.logical(r)) {
>                stop("'tests' must be logical")
>            }
>            r & !is.na(r)
>        }))
>    }
>    r
> }
> 
> used as:
>> m2(testdata, group2=="UNC", Eleven.Two=valid5=="11.2")
>     T1 Eleven.Two
> 1  TRUE      FALSE
> 2  TRUE       TRUE
> 3 FALSE      FALSE
> 4 FALSE      FALSE
> 5 FALSE      FALSE
> 6 FALSE      FALSE
> 7  TRUE      FALSE
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com

Thank you again, Bill. 

-- 
David.

> 
> 
> On Sat, Sep 6, 2014 at 3:31 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> The goal:
>>   to create a function modeled after `subset` (notorious for its non-standard evaluation) that will take a series of logical tests as unqiuoted expressions to be evaluated in the framework of a dataframe environment and return a dataframe of logicals:
>> 
>> 
>> mtest.data.frame <-
>> function (x, ..., drop=FALSE)
>> { tests <- list(...); print(tests)
>>     r <- if (length(tests)==0)
>>         stop("no 'tests'")
>>     else { cbind.data.frame(
>>             lapply( tests, function(t){
>>                          e <- substitute(t)
>>                          r <- eval(e, x, parent.frame() )
>>                  if ( !is.logical(r) ) {
>>                      stop("'tests' must be logical") }
>>                     r & !is.na(r) } ) )
>>     }
>> }
>> #--------------
>> 
>> testdata <- structure(list(group1 = structure(1:7, .Label = c("Group A",
>> "Group B", "Group C", "Group D", "Group E", "Group F", "Group G"
>> ), class = "factor"), group2 = structure(c(3L, 3L, 2L, 1L, 1L,
>> 2L, 3L), .Label = c("LS", "SS", "UNC"), class = "factor"), valid1 = structure(c(2L,
>> 1L, NA, 1L, 2L, 2L, 1L), .Label = c("N", "Y"), class = "factor"),
>>    valid2 = structure(c(1L, 1L, 2L, 1L, 1L, 2L, 1L), .Label = c("N",
>>    "Y"), class = "factor"), valid3 = structure(c(4L, 3L, NA,
>>    2L, 1L, NA, 5L), .Label = c("0.3", "0.7", "1.2", "1.4", "1.7"
>>    ), class = "factor"), valid4 = structure(c(2L, 1L, 3L, 4L,
>>    1L, 1L, 5L), .Label = c("0.3", "0.4", "0.53", "0.66", "0.71"
>>    ), class = "factor"), valid5 = structure(c(4L, 1L, NA, NA,
>>    3L, NA, 2L), .Label = c("11.2", "11.7", "8.3", "8.5"), class = "factor")), .Names = c("group1",
>> "group2", "valid1", "valid2", "valid3", "valid4", "valid5"), row.names = c(NA,
>> -7L), class = "data.frame")
>> 
>> #######
>> 
>> 
>>> mtest.data.frame(testdata, valid2=="N", valid3 > 1)
>> [[1]]
>> [1] "tests are"
>> 
>> [[2]]
>> [1]  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE
>> 
>> [[3]]
>> [1]  TRUE  TRUE    NA FALSE FALSE    NA  TRUE
>> 
>> This actually seemed to be somewhat successful, but when ...
>> 
>> Now if I take out the `print()` call for 'tests', I get an different answer:
>> 
>>> mtest.data.frame <-
>> +  function (x, ..., drop=FALSE)
>> +  { tests <- list(...)
>> +      r <- if (length(tests)==0)
>> +          stop("no 'tests'")
>> +      else { cbind.data.frame(
>> +              lapply( tests, function(t){
>> +                           e <- substitute(t)
>> +                           r <- eval(e, x, parent.frame() )
>> +                   if ( !is.logical(r) ) {
>> +                       stop("'tests' must be logical") }
>> +                      r & !is.na(r) } ) )
>> +      }
>> +  }
>>> mtest.data.frame(testdata, valid2=="N", valid3 > 1)
>>>  # i.e. no answer
>> 
>> --

David Winsemius
Alameda, CA, USA


From rhelpmaillist at 163.com  Sun Sep  7 11:06:44 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
Subject: [R]   using  edit to extract codes from vignette failed
Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist@163.com>


Dear expeRts,
? ? When i using the following code, i get a error as follows:



?edit(file=vignette("grobs",package = "grid"))
Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
? argument "name" is missing, with no default


I investigated edit function, but still can't ?get codes from a vignette, May you help me?


--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From pdalgd at gmail.com  Sun Sep  7 14:33:16 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 7 Sep 2014 14:33:16 +0200
Subject: [R] Defining vectors with per-determined correlations
In-Reply-To: <CA+vqiLHqvQjqWyNdmMCsKTTXnCgET4_9LhF6iAsOnPA=4B1t4Q@mail.gmail.com>
References: <CAGcnpaQy9M1kW+9OqDRm5Ayj78hOz8rdy=8Oq5VxAB+uAVr2AQ@mail.gmail.com>
	<CAFEqCdwQgU6mXGeRgCZvc3nhRSQTnJ4GMMe2XkNoLske1khDnQ@mail.gmail.com>
	<54085562020000CB00113A29@smtp.medicine.umaryland.edu>
	<CA+vqiLHqvQjqWyNdmMCsKTTXnCgET4_9LhF6iAsOnPA=4B1t4Q@mail.gmail.com>
Message-ID: <41CA0E2F-C247-4676-A348-CF738FA9B641@gmail.com>


On 04 Sep 2014, at 19:32 , Ista Zahn <istazahn at gmail.com> wrote:

> See ?mvrnorm in the MASS package.

... and in particular, notice its empirical=TRUE argument. 

Also, notice that the 3rd correlation (corr(x, z)=r3, say) can't be set arbitrarily: if r1=r2=0.99, r3 cannot be zero. 

> 
> Best,
> Ista
> 
> 
> On Thu, Sep 4, 2014 at 12:04 PM, John Sorkin <jsorkin at grecc.umaryland.edu>
> wrote:
> 
>> I need to define three vectors x, y, z (each of length 100) such that the
>> pair-wise correlations of the vectors have per-defined values r1 and r2.
>> More specifically I need to define x, y, and z so that:
>> 
>> corr(x,y) = r1
>> corr(y,z) = r2
>> 
>> Is there any easy way to accomplish this with R?
>> 
>> Thank you,
>> John
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> 
>> Confidentiality Statement:
>> This email message, including any attachments, is for ...{{dropped:18}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ligges at statistik.tu-dortmund.de  Sun Sep  7 15:30:12 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 07 Sep 2014 15:30:12 +0200
Subject: [R] using  edit to extract codes from vignette failed
In-Reply-To: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist@163.com>
References: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist@163.com>
Message-ID: <540C5DE4.9060109@statistik.tu-dortmund.de>



On 07.09.2014 11:06, PO SU wrote:
>
> Dear expeRts,
>      When i using the following code, i get a error as follows:
>
>
>
>   edit(file=vignette("grobs",package = "grid"))

I guess you want to

edit(file = vignette("grobs", package = "grid")[["file"]])

?

Best,
Uwe Ligges




> Error in edit.vignette(file = vignette("grobs", package = "grid")) :
>    argument "name" is missing, with no default
>
>
> I investigated edit function, but still can't  get codes from a vignette, May you help me?
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From axel.urbiz at gmail.com  Sun Sep  7 16:20:00 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sun, 7 Sep 2014 10:20:00 -0400
Subject: [R] Question about searchTwitter{twitteR}
Message-ID: <CAAyVsXLJvCwP91ewrJoBZrjMMCX8mj8GH0W=Aoyhmy10Q+BPNw@mail.gmail.com>

Hello,

The function searchTwitter() with the arguments supplied as below would
give me a different number of results on different days I run this code.
Maybe it is my lack of understanding about what the date arguments are
supposed to do in this function, but I would think I should be getting the
same tweets?


tweets <- searchTwitter('my text search',
                                    n = 1000,
                                    since = '2013-09-01',
                                    until = '2014-08-31')


Thanks,
Axel.

	[[alternative HTML version deleted]]


From radhakrishnan.mohan at gmail.com  Sun Sep  7 10:54:52 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Sun, 7 Sep 2014 14:24:52 +0530
Subject: [R] Solving equations
Message-ID: <CAOoXFP_sGjacz8Y38D5cfPx4RssBx7bt+VpLnPRKE2SGAY+RzA@mail.gmail.com>

Hi,
         I code R to parse data but not for solving equations. So this is
my first such problem. It is a programming puzzle.

I have these two equations.

1)    4x - 3w = 0
2)    8x - 7w =0

I know the value of x and w for

equation 1).  x = 3 and w = 4
equation 2).  x = 7 and w = 8

I also know how to write more equations based on data available in the
puzzle.

How do I solve a set of such equations ? I need to find out the values of x
and w for each such equation.

I know that here the equations are simple because the puzzle can be
simplfied.


Thanks,
Mohan

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun Sep  7 17:46:59 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 7 Sep 2014 17:46:59 +0200
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <1409999043.70851.YahooMailNeo@web120102.mail.ne1.yahoo.com>
References: <loom.20140906T040650-156@post.gmane.org>	<CACk-te3q2VwkbnSh5+J4BzXr7f4LWv6TuKtUBjK30JePdeT7Gg@mail.gmail.com>
	<CAE3=dmd_W5n=kCi2fdPUqst1xaF726ZqLC75KNW-PCq-xQKu9w@mail.gmail.com>
	<1409999043.70851.YahooMailNeo@web120102.mail.ne1.yahoo.com>
Message-ID: <94EA0576-7548-494F-982D-961BA52F97D3@gmail.com>


On 06 Sep 2014, at 12:24 , bonsxanco <bonsxanco at yahoo.com> wrote:

>> 
>> 1) 8th grade algebra tells me B2/B1 == 0 <==> B2 =0;
> 
> EViews (econometrics program) doesn't have the same opinion:
> 
> Wald test on my real model (edited):
> 
> * H0: B3/B2 = 0 -> F-stat = 37.82497 
> * H0: B3 = 0    -> F-stat = 16.31689 

And when the econometrics program contradicts what you learned in 8th grade, surely the latter is wrong and the former is right, because it is done by a computer and computers cannot be wrong? ;-)

Probably what this shows most of all is a weakness of the Wald test approach: The s.e. of (b3hat/b2hat) will likely differ from s.e.(b3hat)/b2hat and hence the test statistics will differ even though they really test the same hypothesis. Actually, there are two generic weaknesses: (a) the somewhat arbitrary choice of test statistic and (b) the fact that the s.e. is not calculated at the null value of the parameter, but at the estimate.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Sun Sep  7 19:01:18 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 7 Sep 2014 10:01:18 -0700
Subject: [R] Solving equations
In-Reply-To: <CAOoXFP_sGjacz8Y38D5cfPx4RssBx7bt+VpLnPRKE2SGAY+RzA@mail.gmail.com>
References: <CAOoXFP_sGjacz8Y38D5cfPx4RssBx7bt+VpLnPRKE2SGAY+RzA@mail.gmail.com>
Message-ID: <03C1816B-9C3E-4874-97C4-FF9A10ED6232@comcast.net>

In my education this was 9th or 10th grade (US) math. The r-help mailing list is not set up for providing mini-tutorials on R programming. Please read the Posting Guide, do the expected self-eduction in R programming, do the requested searching on your remaining questions in the Archives or StackOverflow and then in a few weeks considered reposting. Before doing so ... learn to post in plain text as as the Guide request.

-- 
David.

On Sep 7, 2014, at 1:54 AM, Mohan Radhakrishnan wrote:

> Hi,
>         I code R to parse data but not for solving equations. So this is
> my first such problem. It is a programming puzzle.
> 
> I have these two equations.
> 
> 1)    4x - 3w = 0
> 2)    8x - 7w =0
> 
> I know the value of x and w for
> 
> equation 1).  x = 3 and w = 4
> equation 2).  x = 7 and w = 8
> 
> I also know how to write more equations based on data available in the
> puzzle.
> 
> How do I solve a set of such equations ? I need to find out the values of x
> and w for each such equation.
> 
> I know that here the equations are simple because the puzzle can be
> simplfied.
> 
> 
> Thanks,
> Mohan
> 
> 	[[alternative HTML version deleted]]
-- 

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sun Sep  7 21:01:57 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 07 Sep 2014 20:01:57 +0100
Subject: [R] Solving equations
In-Reply-To: <CAOoXFP_sGjacz8Y38D5cfPx4RssBx7bt+VpLnPRKE2SGAY+RzA@mail.gmail.com>
References: <CAOoXFP_sGjacz8Y38D5cfPx4RssBx7bt+VpLnPRKE2SGAY+RzA@mail.gmail.com>
Message-ID: <540CABA5.60908@sapo.pt>

Hello,

Inline.

Em 07-09-2014 09:54, Mohan Radhakrishnan escreveu:
> Hi,
>           I code R to parse data but not for solving equations. So this is
> my first such problem. It is a programming puzzle.
>
> I have these two equations.
>
> 1)    4x - 3w = 0
> 2)    8x - 7w =0
>
> I know the value of x and w for
>
> equation 1).  x = 3 and w = 4
> equation 2).  x = 7 and w = 8

Why? Any of those equations defines a straight line, not a point. Those 
two points are just one of the infinitely many solutions.

Your equations are equivalent to
eq1) w = 4/3x
eq2) w = 8/7x

the equations of straight lines passing through the origin (no 
independent term).

>
> I also know how to write more equations based on data available in the
> puzzle.
>
> How do I solve a set of such equations ? I need to find out the values of x
> and w for each such equation.

There are packages to solve simultaneous equations but I've never used them.

Hope this helps,

Rui Barradas
>
> I know that here the equations are simple because the puzzle can be
> simplfied.
>
>
> Thanks,
> Mohan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From amos.elberg at gmail.com  Sun Sep  7 23:19:10 2014
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Sun, 7 Sep 2014 17:19:10 -0400
Subject: [R] Question about searchTwitter{twitteR}
In-Reply-To: <CAAyVsXLJvCwP91ewrJoBZrjMMCX8mj8GH0W=Aoyhmy10Q+BPNw@mail.gmail.com>
References: <CAAyVsXLJvCwP91ewrJoBZrjMMCX8mj8GH0W=Aoyhmy10Q+BPNw@mail.gmail.com>
Message-ID: <F6F2E67A-8375-4B3D-B2C9-C8B9D20AD2C1@gmail.com>

Twitter tweets aren't a stable database. I wouldn't expect the search results to stay stable, as tweets are retweeted, deleted, accounts are closed, privacy settings adjusted, etc.  And if there are more than 1000 results, I don't know that twitter is internally ordered so you'd get the same set of results each time you run the same search. 

> On Sep 7, 2014, at 10:20 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> 
> Hello,
> 
> The function searchTwitter() with the arguments supplied as below would
> give me a different number of results on different days I run this code.
> Maybe it is my lack of understanding about what the date arguments are
> supposed to do in this function, but I would think I should be getting the
> same tweets?
> 
> 
> tweets <- searchTwitter('my text search',
>                                    n = 1000,
>                                    since = '2013-09-01',
>                                    until = '2014-08-31')
> 
> 
> Thanks,
> Axel.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cranatic at gmail.com  Mon Sep  8 00:40:05 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 7 Sep 2014 18:40:05 -0400
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <540cdec592fda_5d9fbaf893416a@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* classyfire (0.1-0)
  Maintainer: Eleni Chatzimichali
  Author(s): Eleni Chatzimichali <ea.chatzimichali at gmail.com> and Conrad Bessant
             <c.bessant at qmul.ac.uk>
  License: GPL (>= 2)
  http://crantastic.org/packages/classyfire

  A collection of functions for the creation and application of highly
  optimised, robustly evaluated ensembles of support vector machines
  (SVMs). The package takes care of training individual SVM
  classifiers using a fast parallel heuristic algorithm, and combines
  individual classifiers into ensembles. Robust metrics of
  classification performance are offered by bootstrap resampling and
  permutation testing.

* cooptrees (1.0)
  Maintainer: Manuel Fontenla
  Author(s): Manuel Fontenla
  License: GPL-3
  http://crantastic.org/packages/cooptrees

  Computes several cooperative games and allocation rules associated
  with minimum cost spanning tree problems and minimum cost
  arborescence problems.

* coreTDT (1.0)
  Maintainer: Yu Jiang
  Author(s): Yu Jiang, Andrew S Allen
  License: GPL-3
  http://crantastic.org/packages/coreTDT

  Use to analysis case-parent trio sequencing studies. Test the compound
  heterozygous and recessive disease models

* descomponer (1.0)
  Maintainer: Francisco Parra
  Author(s): Francisco Parra  <parra_fj at cantabria.es>
  License: GPL (>= 2)
  http://crantastic.org/packages/descomponer

  Decompose a time series into seasonal, trend and irregular components
  using transformations to amplitude-frequency domain.

* Frames2 (0.0.3)
  Maintainer: David Molina
  Author(s): Antonio Arcos <arcos at ugr.es>, Maria del Mar Rueda <mrueda at ugr.es>,
             Maria Giovanna Ranalli <giovanna.ranalli at stat.unipg.it>
             and David Molina <dmolinam at ugr.es>
  License: GPL (>= 2)
  http://crantastic.org/packages/Frames2

  Point and interval estimation in dual frame surveys. In contrast to
  classic sampling theory, where only one sampling frame is
  considered, dual frame methodology assumes that there are two frames
  available for sampling and that, overall, they cover the entire
  target population. Then, two probability samples (one from each
  frame) are drawn and information collected is suitably combined to
  get estimators of the parameter of interest.

* GUILDS (1.2)
  Maintainer: Thijs Janzen
  Author(s): Thijs Janzen
  License: GPL-2
  http://crantastic.org/packages/GUILDS

  The GUILDS package combines a range of sampling formulas for the
  unified neutral model of biogeography and biodiversity. Alongside
  the sampling formulas, it includes methods to perform maximum
  likelihood optimization of the sampling formulas, methods to
  generate data given the neutral model, and methods to estimate the
  expected species abundance distribution. Sampling formulas included
  in the GUILDS package are the Etienne Sampling Formula (Etienne
  2005), the guild sampling formula, where guilds are assumed to
  differ in dispersal ability (Janzen 2014), and  the guilds sampling
  formula conditioned on guild size (Janzen 2014).

* iBATCGH (1.0)
  Maintainer: Alberto Cassese
  Author(s): Alberto Cassese
  License: GPL-2
  http://crantastic.org/packages/iBATCGH

  Bayesian integrative models of gene expression and comparative genomic
  hybridization data. The package provides inference on copy number
  variations and their association with gene expression

* ica (1.0-0)
  Maintainer: Nathaniel E. Helwig
  Author(s): Nathaniel E. Helwig <helwig at umn.edu>
  License: GPL (>= 2)
  http://crantastic.org/packages/ica

  Independent Component Analysis (ICA) using various algorithms:
  FastICA, Information-Maximization (Infomax), and Joint Approximate
  Diagonalization of Eigenmatrices (JADE).

* insuranceData (1.0)
  Maintainer: Alicja Wolny--Dominiak
  Author(s): Alicja Wolny--Dominiak and Michal Trzesiok
  License: GPL-2
  http://crantastic.org/packages/insuranceData

  Insurance datasets, which are often used in claims severity and claims
  frequency modelling. It helps testing new regression models in those
  problems, such as GLM, GLMM, HGLM, non-linear mixed models etc. Most
  of the data sets are applied in the project &quot;Mixed models in
  ratemaking&quot; supported by grant NN 111461540 from Polish National
  Science Center.

* JAGUAR (1.1)
  Maintainer: Chaitanya Acharya
  Author(s): Chaitanya R. Acharya and Andrew S. Allen
  License: GPL-2
  http://crantastic.org/packages/JAGUAR

  Implements a 2 degree-of-freedom score test that measures 1) the
  overall shift in the gene expression due to genotype, and 2)
  group-specific changes in gene expression due to genotype
  (interaction term) in a mixed-effects model framework.

* mpcv (1.0)
  Maintainer: Krzysztof Ciupke
  Author(s): Krzysztof Ciupke <krzysztof.ciupke at polsl.pl>
  License: GPL (>= 2.0)
  http://crantastic.org/packages/mpcv

  Multivariate process capability analysis using the multivariate
  process capability vector. Allows to analyze a multivariate process
  with both normally and non-normally distributed and also with
  dependent and independent quality characteristics.

* MSIseq (0.99.1)
  Maintainer: Mini Huang
  Author(s): Mini Huang
  License: GPL (>= 2)
  http://crantastic.org/packages/MSIseq

  A decision tree classifier for detecting microsatellite instability
  (MSI) in somatic mutation data from whole exome sequencing. MSI is
  detected based on different mutation rates in all sites as well as
  in simple sequence repeats. This mechanism can also be applied to
  sequence data of targeted gene panels with shorter sequence length.

* nabor (0.4.3)
  Maintainer: Gregory Jefferis
  Author(s): Stephane Mangenat (for libnabo), Gregory Jefferis
  License: BSD_3_clause + file LICENSE
  http://crantastic.org/packages/nabor

  An R wrapper for libnabo, an exact or approximate k nearest neighbour
  library which is optimised for low dimensional spaces (e.g. 3D).
  libnabo has speed and space advantages over the ANN library wrapped
  by package RANN. nabor includes a knn function that is designed as a
  drop-in replacement for RANN::nn2. In addition, objects which
  include the k-d tree search structure can be returned to speed up
  repeated queries of the same set of target points.

* optrees (1.0)
  Maintainer: Manuel Fontenla
  Author(s): Manuel Fontenla [aut, cre]
  License: GPL-3
  http://crantastic.org/packages/optrees

  Finds optimal trees in weighted graphs. In particular, this package
  provides solving tools for minimum cost spanning tree problems,
  minimum cost arborescence problems, shortest path tree problems and
  minimum cut tree problem.

* packrat (0.4.1-1)
  Maintainer: Kevin Ushey
  Author(s): Kevin Ushey, Jonathan McPherson, Joe Cheng, JJ Allaire
  License: GPL-2
  http://crantastic.org/packages/packrat

  Packrat is a tool for managing the R packages your project depends on
  in an isolated, portable, and reproducible way.

* pdR (1.1)
  Maintainer: Ho Tsung-wu
  Author(s): Ho Tsung-wu
  License: GPL (>= 2)
  http://crantastic.org/packages/pdR

  threshold regression in panel data

* pxweb (0.4)
  Maintainer: Mans Magnusson
  Author(s): Mans Magnusson, Leo Lahti, Love Hansson
  License: BSD_2_clause + file LICENSE
  http://crantastic.org/packages/pxweb

  Generic interface for the PX-Web/PC-Axis API. The PX-Web/PC-Axis API
  is used by organizations such as Statistics Sweden and Statistics
  Finland to disseminate data. The R package can interact with all
  PX-Web/PC-Axis APIs to fetch information about the data hierarchy,
  extract metadata and extract and parse statistics to R data.frame
  format. PX-Web is a solution to disseminate PC-Axis data files in
  dynamic tables on the web. Since 2013 PX-Web contains an API to
  disseminate PC-Axis files. PX-Web/PC-Axis API information can be
  found at: http://www.scb.se/Grupp/OmSCB/API/API-description.pdf

* rappdirs (0.3)
  Maintainer: Hadley Wickham
  Author(s): Hadley Wickham [trl, cre, cph], RStudio [cph], Sridhar Ratnakumar
             [aut], Trent Mick [aut], ActiveState [cph] (R/appdir.r,
             R/cache.r, R/data.r, R/log.r translated from appdirs),
             Eddy Petrisor [ctb], Trevor Davis [trl, aut], Gabor
             Csardi [ctb], Gregory Jefferis [ctb]
  License: MIT + file LICENSE
  http://crantastic.org/packages/rappdirs

  An easy way to determine which directories on the users computer you
  should use to save data, caches and logs. A port of Python&#39;s Appdirs
  (\url{https://github.com/ActiveState/appdirs}) to R.

* rcbalance (1.0)
  Maintainer: Samuel D. Pimentel
  Author(s): Samuel D. Pimentel
  License: MIT + file LICENSE
  http://crantastic.org/packages/rcbalance

  Tools for large, sparse optimal matching of treated units 	and control
  units in observational studies.  Provisions are 	made for refined
  covariate balance constraints, which include 	fine and near-fine
  balance as special cases.  Matches are  	optimal in the sense that
  they are computed as solutions to 	network optimization problems
  rather than greedy algorithms.

* recosystem (0.2.1)
  Maintainer: Yixuan Qiu
  Author(s): Chih-Jen Lin, Yu-Chin Juan, Yong Zhuang, and Wei-Sheng Chin for the
             original C++ code, Yixuan Qiu for the R wrapper
  License: BSD_3_clause + file LICENSE
  http://crantastic.org/packages/recosystem

  This package is an R wrapper of the libmf library
  (http://www.csie.ntu.edu.tw/~cjlin/libmf/) for recommender system
  using matrix factorization. It&#39;s typically used to approximate an
  incomplete matrix using the product of two matrices in a latent
  space. Other common names for this task include &quot;collaborative
  filtering&quot;, &quot;matrix completion&quot;, &quot;matrix recovery&quot;, etc. This
  package mainly supports UNIX-like operating systems, with
  experimental support for Windows. See README for the links of
  precompiled packages.

* subrank (0.8.5)
  Maintainer: Jerome Collet
  Author(s): Jerome Collet
  License: GPL (>= 3)
  http://crantastic.org/packages/subrank

  essentially a discussion tool about estimation of copula using ranks
  and subsampling.

* sweidnumbr (0.1.1)
  Maintainer: Mans Magnusson
  Author(s): Mans Magnusson
  License: BSD_2_clause + file LICENSE
  http://crantastic.org/packages/sweidnumbr

  Structural handling of identity numbers used in the Swedish
  administration such as personal identity numbers (&#39;personnummer&#39;)
  and organizational identity numbers (&#39;organisationsnummer&#39;).

* Tampo (1.0)
  Maintainer: Matthias Vignon
  Author(s): Matthias Vignon
  License: GPL (>= 2)
  http://crantastic.org/packages/Tampo

  Facilitates analyzing microchemical profiles (both mono- and
  multielemental composition) from fish otoliths (stones from the
  inner ear) using a recursive partitioning approach that can
  accommodate some form of user-specified constraints. It also allows
  extracting environmental histories from otolith based on typical
  elemental sequences generated using methods such as LA-ICPMS.
  Microchemical analysis is widely used in fisheries management and
  fisheries biology to identify stocks and characterize fish movements
  but the provided functions may be considered from the more general
  perspective of the chronological clustering of multivariate time
  series using piecewise constant regressions.

* trotter (0.5)
  Maintainer: Richard Ambler
  Author(s): Richard Ambler
  License: GPL-3
  http://crantastic.org/packages/trotter

  Class definitions and constructors for pseudo-vectors containing all
  permutations and combinations of objects taken from a vector.

* xgboost (0.3-2)
  Maintainer: Tong He
  Author(s): Tianqi Chen <tianqi.tchen at gmail.com>, Tong He <hetong007 at gmail.com>
  License: Apache License (== 2.0) | file LICENSE
  http://crantastic.org/packages/xgboost

  This package is a R wrapper of xgboost, which is short for eXtreme
  Gradient Boosting. It is an efficient and scalable implementation of
  gradient boosting framework. The package includes efficient linear
  model solver and tree learning algorithms. The package can
  automatically do parallel computation with OpenMP, and it can be
  more than 10 times faster than existing gradient boosting packages
  such as gbm. It supports various objective functions, including
  regression, classification and ranking. The package is made to be
  extensible, so that users are also allowed to define their own
  objectives easily.


Updated packages
----------------

agricolae (1.2-1), asbio (1.1-1), BCA (0.9-3), chebpol (1.3-1367),
circlize (0.1.1), cluster (1.15.3), copula (0.999-11),
CopulaRegression (0.1-5), Cprob (1.2.3), DBI (0.3.0), DNAtools
(0.1-21), ds (3.0), e1071 (1.6-4), Ecdat (0.2-7), fMultivar (3011.78),
GGIR (1.0-6), GPfit (0.2-1), GUILDS (1.1), haplo.stats (1.6.11), heavy
(0.2-35), helloJavaWorld (0.0-9), httr (0.5), idr (1.2), jaatha (2.6),
kmi (0.5.1), lmSupport (2.09), logcondens (2.1.2), mht (3.0.11), mixAK
(3.8), mixOmics (5.0-3), MPV (1.35), MRCV (0.3-3), nabor (0.4.3),
NbClust (2.0.2), NCmisc (1.1.3), NCmisc (1.1.2), nor1mix (1.2-0),
OpasnetUtils (1.1.0), OrdFacReg (1.0.5), packrat (0.4.1-1), parcor
(0.2-6), pec (2.3.7), plsdof (0.2-7), powerGWASinteraction (1.1.0), PP
(0.5.3), ppls (1.6-1), prodlim (1.4.5), pyramid (1.4), R.devices
(2.11.0), R2HTML (2.3.0), RankAggreg (0.5), raster (2.3-0), Rcmdr
(2.1-1), RcmdrPlugin.BCA (0.9-8), RcmdrPlugin.temis (0.7.2),
RcmdrPlugin.temis (0.7.1), readbitmap (0.1-4), REBayes (0.50), rebmix
(2.6.2), REPPlab (0.9), Rmpfr (0.5-6), rNOMADS (2.0.2), roxygen2
(4.0.2), rpf (0.38), sanon (1.4), SCRT (1.1), SCVA (1.1), SDaA
(0.1-3), selectMeta (1.0.7), sgr (1.2), StAMPP (1.3), structSSI (1.1),
stylo (0.5.8), synbreed (0.10-1), tolerance (1.0.0), traitr (0.14),
upclass (2.0), UsingR (2.0-2), wgaim (1.4-3), wordnet (0.1-10)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From hb at biostat.ucsf.edu  Mon Sep  8 04:40:04 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 7 Sep 2014 19:40:04 -0700
Subject: [R] Mixed sorting/ordering of strings acknowledging roman
	numerals?
In-Reply-To: <E3C40F2D-0666-406C-BB68-0B05951892FA@comcast.net>
References: <CAFDcVCT1kukpFiDCwtyMebQdvTCYEggy3dzAL6_DqzM7L=5RMw@mail.gmail.com>
	<E3C40F2D-0666-406C-BB68-0B05951892FA@comcast.net>
Message-ID: <CAFDcVCQLSoidnwJ4pgxQz5WPic4v=JiqfiA=1FXAEf5DkvxB1g@mail.gmail.com>

Thank you David - it took me awhile to get back to this and dig into
it.  It's clever to imitate gtools::mixedorder() as far as possible.
A few comments:

1. It took me a while to understand why you picked 3899 in your
Roman-to-integer table; it's because roman(x) is NA for x > 3899.
(BTW, in 'utils', there's utils:::.roman2numeric() which could be
utilized, but it's currently internal.)

2. I think you forgot D=500 and M=1000.

3. There was a typo in your code; I think you meant rank.roman instead
of rank.numeric in one place.

4. The idea behind nonnumeric() is to identify non-numeric substrings
by is.na(as.numeric()).  Unfortunately, for romans that does not work.
Instead, we need to use is.na(numeric(x)) here, i.e.

  nonnumeric <- function(x) {
      suppressWarnings(ifelse(is.na(numeric(x)), toupper(x), NA))
  }

Actually, gtools::mixedorder() could use the same.

5. I undid your ".numeric" to ".roman" to minimize any differences to
gtools::mixedorder().


With the above fixes, we now have:

mixedorderRoman <- function (x)
{
    if (length(x) < 1)
        return(NULL)
    else if (length(x) == 1)
        return(1)
    if (is.numeric(x))
        return(order(x))
    delim = "\\$\\@\\$"
    # NOTE: Note that as.roman(x) is NA for x > 3899
    romanC <- as.character( as.roman(1:3899) )
    numeric <- function(x) {
        suppressWarnings(match(x, romanC))
    }
    nonnumeric <- function(x) {
        suppressWarnings(ifelse(is.na(numeric(x)), toupper(x),
            NA))
    }
    x <- as.character(x)
    which.nas <- which(is.na(x))
    which.blanks <- which(x == "")
    if (length(which.blanks) > 0)
        x[which.blanks] <- -Inf
    if (length(which.nas) > 0)
        x[which.nas] <- Inf
    delimited <- gsub("([IVXCLM]+)",
        paste(delim, "\\1", delim, sep = ""), x)
    step1 <- strsplit(delimited, delim)
    step1 <- lapply(step1, function(x) x[x > ""])
    step1.numeric <- lapply(step1, numeric)
    step1.character <- lapply(step1, nonnumeric)
    maxelem <- max(sapply(step1, length))
    step1.numeric.t <- lapply(1:maxelem, function(i) sapply(step1.numeric,
        function(x) x[i]))
    step1.character.t <- lapply(1:maxelem, function(i) sapply(step1.character,
        function(x) x[i]))
    rank.numeric <- sapply(step1.numeric.t, rank)
    rank.character <- sapply(step1.character.t, function(x)
as.numeric(factor(x)))
    rank.numeric[!is.na(rank.character)] <- 0
    rank.character <- t(t(rank.character) + apply(matrix(rank.numeric),
        2, max, na.rm = TRUE))
    rank.overall <- ifelse(is.na(rank.character), rank.numeric,
        rank.character)
    order.frame <- as.data.frame(rank.overall)
    if (length(which.nas) > 0)
        order.frame[which.nas, ] <- Inf
    retval <- do.call("order", order.frame)
    return(retval)
}


The difference to gtools::mixedorder() is minimal:

<     romanC <- as.character( as.roman(1:3899) )
21c11
<         suppressWarnings(match(x, romanC))
---
>         suppressWarnings(as.numeric(x))
24c14
<         suppressWarnings(ifelse(is.na(numeric(x)), toupper(x),
---
>         suppressWarnings(ifelse(is.na(as.numeric(x)), toupper(x),
34c24
<     delimited <- gsub("([IVXCLDM]+)",
---
>     delimited <- gsub("([+-]{0,1}[0-9]+\\.{0,1}[0-9]*([eE][\\+\\-]{0,1}[0-9]+\\.{0,1}[0-9]*){0,1})",
59,62d48

This difference is so small that the above could now be an option to
mixedorder() with minimal overhead added, e.g. mixedorder(y,
type=c("decimal", "roman")).  One could even imagine adding support
for "binary", "octal" and "hexadecimal" (not done).

Greg (maintainer of gtools; cc:ed), is this something you would
consider adding to gtools?  I've modified the gtools source code
available on CRAN (that's the only source I found), added package
tests, updated the Rd and verified it passes R CMD check.  If
interested, please find the updates at:

  https://github.com/HenrikBengtsson/gtools/compare/cran:master...master

Thanks

Henrik

On Tue, Aug 26, 2014 at 6:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 26, 2014, at 5:24 PM, Henrik Bengtsson wrote:
>
>> Hi,
>>
>> does anyone know of an implementation/function that sorts strings that
>> *contain* roman numerals (I, II, III, IV, V, ...) which are treated as
>> numbers.  In 'gtools' there is mixedsort() which does this for strings
>> that contains (decimal) numbers.  I'm looking for a "mixedsortroman()"
>> function that does the same but with roman numbers, e.g.
>
> It's pretty easy to sort something you know to be congruent with the existing roman class:
>
> romanC <- as.character( as.roman(1:3899) )
> match(c("I", "II", "III","X","V"), romanC)
> #[1]  1  2  3 10  5
>
> But I guess you already know that, so you want a regex approach to parsing. Looking at the path taken by Warnes, it would involve doing something like his regex based insertion of a delimiter for "Roman numeral" but simpler because he needed to deal with decimal points and signs and exponent notation, none of which you appear to need. If you only need to consider character and Roman, then this hack of Warnes tools succeeds:
>
>  mixedorderRoman <- function (x)
> {
>     if (length(x) < 1)
>         return(NULL)
>     else if (length(x) == 1)
>         return(1)
>     if (is.numeric(x))
>         return(order(x))
>     delim = "\\$\\@\\$"
>     roman <- function(x) {
>         suppressWarnings(match(x, romanC))
>     }
>     nonnumeric <- function(x) {
>         suppressWarnings(ifelse(is.na(as.numeric(x)), toupper(x),
>             NA))
>     }
>     x <- as.character(x)
>     which.nas <- which(is.na(x))
>     which.blanks <- which(x == "")
>     if (length(which.blanks) > 0)
>         x[which.blanks] <- -Inf
>     if (length(which.nas) > 0)
>         x[which.nas] <- Inf
>     delimited <- gsub("([IVXCL]+)",
>         paste(delim, "\\1", delim, sep = ""), x)
>     step1 <- strsplit(delimited, delim)
>     step1 <- lapply(step1, function(x) x[x > ""])
>     step1.roman <- lapply(step1, roman)
>     step1.character <- lapply(step1, nonnumeric)
>     maxelem <- max(sapply(step1, length))
>     step1.roman.t <- lapply(1:maxelem, function(i) sapply(step1.roman,
>         function(x) x[i]))
>     step1.character.t <- lapply(1:maxelem, function(i) sapply(step1.character,
>         function(x) x[i]))
>     rank.roman <- sapply(step1.roman.t, rank)
>     rank.character <- sapply(step1.character.t, function(x) as.numeric(factor(x)))
>     rank.roman[!is.na(rank.character)] <- 0
>     rank.character <- t(t(rank.character) + apply(matrix(rank.roman),
>         2, max, na.rm = TRUE))
>     rank.overall <- ifelse(is.na(rank.character), rank.numeric,
>         rank.character)
>     order.frame <- as.data.frame(rank.overall)
>     if (length(which.nas) > 0)
>         order.frame[which.nas, ] <- Inf
>     retval <- do.call("order", order.frame)
>     return(retval)
> }
>
> y[mixedorderRoman(y)]
>  [1] "chr I"    "chr II"   "chr III"  "chr IV"   "chr IX"
>  [6] "chr V"    "chr VI"   "chr VII"  "chr VIII" "chr X"
> [11] "chr XI"   "chr XII"
>
>
> --
> David.
>>
>> ## DECIMAL NUMBERS
>>> x <- sprintf("chr %d", 12:1)
>>> x
>> [1] "chr 12" "chr 11" "chr 10" "chr 9"  "chr 8"
>> [6] "chr 7"  "chr 6"  "chr 5"  "chr 4"  "chr 3"
>> [11] "chr 2"  "chr 1"
>>
>>> sort(x)
>> [1] "chr 1"  "chr 10" "chr 11" "chr 12" "chr 2"
>> [6] "chr 3"  "chr 4"  "chr 5"  "chr 6"  "chr 7"
>> [11] "chr 8"  "chr 9"
>>
>>> gtools::mixedsort(x)
>> [1] "chr 1"  "chr 2"  "chr 3"  "chr 4"  "chr 5"
>> [6] "chr 6"  "chr 7"  "chr 8"  "chr 9"  "chr 10"
>> [11] "chr 11" "chr 12"
>>
>>
>> ## ROMAN NUMBERS
>>> y <- sprintf("chr %s", as.roman(12:1))
>>> y
>> [1] "chr XII"  "chr XI"   "chr X"    "chr IX"
>> [5] "chr VIII" "chr VII"  "chr VI"   "chr V"
>> [9] "chr IV"   "chr III"  "chr II"   "chr I"
>>
>>> sort(y)
>> [1] "chr I"    "chr II"   "chr III"  "chr IV"
>> [5] "chr IX"   "chr V"    "chr VI"   "chr VII"
>> [9] "chr VIII" "chr X"    "chr XI"   "chr XII"
>>
>>> mixedsortroman(y)
>> [1] "chr I"    "chr II"   "chr III"  "chr IV"
>> [5] "chr V"    "chr VI"   "chr VII"  "chr VIII"
>> [9] "chr IX"   "chr X"    "chr XI"   "chr XII"
>>
>> The latter is what I'm looking for.
>>
>> Before hacking together something myself (e.g. identify roman numerals
>> substrings, translate them to decimal numbers, use gtools::mixedsort()
>> to sort them and then translate them back to roman numbers), I'd like
>> to hear if someone already has this implemented/know of a package that
>> does this.
>>
>> Thanks,
>>
>> Henrik
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Mon Sep  8 05:46:55 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 7 Sep 2014 20:46:55 -0700
Subject: [R] Mixed sorting/ordering of strings acknowledging roman
	numerals?
In-Reply-To: <CAFDcVCQLSoidnwJ4pgxQz5WPic4v=JiqfiA=1FXAEf5DkvxB1g@mail.gmail.com>
References: <CAFDcVCT1kukpFiDCwtyMebQdvTCYEggy3dzAL6_DqzM7L=5RMw@mail.gmail.com>
	<E3C40F2D-0666-406C-BB68-0B05951892FA@comcast.net>
	<CAFDcVCQLSoidnwJ4pgxQz5WPic4v=JiqfiA=1FXAEf5DkvxB1g@mail.gmail.com>
Message-ID: <B20B63E1-0100-4277-83B0-2C6338D64739@comcast.net>


On Sep 7, 2014, at 7:40 PM, Henrik Bengtsson wrote:

> Thank you David - it took me awhile to get back to this and dig into
> it.  It's clever to imitate gtools::mixedorder() as far as possible.
> A few comments:
> 
> 1. It took me a while to understand why you picked 3899 in your
> Roman-to-integer table; it's because roman(x) is NA for x > 3899.
> (BTW, in 'utils', there's utils:::.roman2numeric() which could be
> utilized, but it's currently internal.)

Yes, that was the reason. I didn't think I needed a Roman-to-numeric function because I discovered the roman numbers were actually simple numeric vectors to which a class had been assigned and that it was the class-facilities that did all the work. The standard Ops functions were just acting on numeric vectors.

If one doesn't take care, their "romanity" can be lost:

> R <- as.roman(10^(0:4))
> R
[1] I    X    C    M    <NA>

> unclass(R)
[1]    1   10  100 1000   NA

> sum(R, na.rm=TRUE)
[1] 1111
> as.roman(sum(R, na.rm=TRUE))
[1] MCXI

> 
> 2. I think you forgot D=500 and M=1000.

Quite possible. I suspect Greg will have corrected the omission, but if not, this will be helpful to him.

> 
> 3. There was a typo in your code; I think you meant rank.roman instead
> of rank.numeric in one place.
> 

I understood Greg's intention to wrap this into the mixedorder and mixed sort duo.

Best;
David.

> 4. The idea behind nonnumeric() is to identify non-numeric substrings
> by is.na(as.numeric()).  Unfortunately, for romans that does not work.
> Instead, we need to use is.na(numeric(x)) here, i.e.
> 
>  nonnumeric <- function(x) {
>      suppressWarnings(ifelse(is.na(numeric(x)), toupper(x), NA))
>  }
> 
> Actually, gtools::mixedorder() could use the same.
> 
> 5. I undid your ".numeric" to ".roman" to minimize any differences to
> gtools::mixedorder().
> 
> 
> With the above fixes, we now have:
> 
> mixedorderRoman <- function (x)
> {
>    if (length(x) < 1)
>        return(NULL)
>    else if (length(x) == 1)
>        return(1)
>    if (is.numeric(x))
>        return(order(x))
>    delim = "\\$\\@\\$"
>    # NOTE: Note that as.roman(x) is NA for x > 3899
>    romanC <- as.character( as.roman(1:3899) )
>    numeric <- function(x) {
>        suppressWarnings(match(x, romanC))
>    }
>    nonnumeric <- function(x) {
>        suppressWarnings(ifelse(is.na(numeric(x)), toupper(x),
>            NA))
>    }
>    x <- as.character(x)
>    which.nas <- which(is.na(x))
>    which.blanks <- which(x == "")
>    if (length(which.blanks) > 0)
>        x[which.blanks] <- -Inf
>    if (length(which.nas) > 0)
>        x[which.nas] <- Inf
>    delimited <- gsub("([IVXCLM]+)",
>        paste(delim, "\\1", delim, sep = ""), x)
>    step1 <- strsplit(delimited, delim)
>    step1 <- lapply(step1, function(x) x[x > ""])
>    step1.numeric <- lapply(step1, numeric)
>    step1.character <- lapply(step1, nonnumeric)
>    maxelem <- max(sapply(step1, length))
>    step1.numeric.t <- lapply(1:maxelem, function(i) sapply(step1.numeric,
>        function(x) x[i]))
>    step1.character.t <- lapply(1:maxelem, function(i) sapply(step1.character,
>        function(x) x[i]))
>    rank.numeric <- sapply(step1.numeric.t, rank)
>    rank.character <- sapply(step1.character.t, function(x)
> as.numeric(factor(x)))
>    rank.numeric[!is.na(rank.character)] <- 0
>    rank.character <- t(t(rank.character) + apply(matrix(rank.numeric),
>        2, max, na.rm = TRUE))
>    rank.overall <- ifelse(is.na(rank.character), rank.numeric,
>        rank.character)
>    order.frame <- as.data.frame(rank.overall)
>    if (length(which.nas) > 0)
>        order.frame[which.nas, ] <- Inf
>    retval <- do.call("order", order.frame)
>    return(retval)
> }
> 
> 
> The difference to gtools::mixedorder() is minimal:
> 
> <     romanC <- as.character( as.roman(1:3899) )
> 21c11
> <         suppressWarnings(match(x, romanC))
> ---
>>        suppressWarnings(as.numeric(x))
> 24c14
> <         suppressWarnings(ifelse(is.na(numeric(x)), toupper(x),
> ---
>>        suppressWarnings(ifelse(is.na(as.numeric(x)), toupper(x),
> 34c24
> <     delimited <- gsub("([IVXCLDM]+)",
> ---
>>    delimited <- gsub("([+-]{0,1}[0-9]+\\.{0,1}[0-9]*([eE][\\+\\-]{0,1}[0-9]+\\.{0,1}[0-9]*){0,1})",
> 59,62d48
> 
> This difference is so small that the above could now be an option to
> mixedorder() with minimal overhead added, e.g. mixedorder(y,
> type=c("decimal", "roman")).  One could even imagine adding support
> for "binary", "octal" and "hexadecimal" (not done).
> 
> Greg (maintainer of gtools; cc:ed), is this something you would
> consider adding to gtools?  I've modified the gtools source code
> available on CRAN (that's the only source I found), added package
> tests, updated the Rd and verified it passes R CMD check.  If
> interested, please find the updates at:
> 
>  https://github.com/HenrikBengtsson/gtools/compare/cran:master...master
> 
> Thanks
> 
> Henrik
> 
> On Tue, Aug 26, 2014 at 6:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Aug 26, 2014, at 5:24 PM, Henrik Bengtsson wrote:
>> 
>>> Hi,
>>> 
>>> does anyone know of an implementation/function that sorts strings that
>>> *contain* roman numerals (I, II, III, IV, V, ...) which are treated as
>>> numbers.  In 'gtools' there is mixedsort() which does this for strings
>>> that contains (decimal) numbers.  I'm looking for a "mixedsortroman()"
>>> function that does the same but with roman numbers, e.g.
>> 
>> It's pretty easy to sort something you know to be congruent with the existing roman class:
>> 
>> romanC <- as.character( as.roman(1:3899) )
>> match(c("I", "II", "III","X","V"), romanC)
>> #[1]  1  2  3 10  5
>> 
>> But I guess you already know that, so you want a regex approach to parsing. Looking at the path taken by Warnes, it would involve doing something like his regex based insertion of a delimiter for "Roman numeral" but simpler because he needed to deal with decimal points and signs and exponent notation, none of which you appear to need. If you only need to consider character and Roman, then this hack of Warnes tools succeeds:
>> 
>> mixedorderRoman <- function (x)
>> {
>>    if (length(x) < 1)
>>        return(NULL)
>>    else if (length(x) == 1)
>>        return(1)
>>    if (is.numeric(x))
>>        return(order(x))
>>    delim = "\\$\\@\\$"
>>    roman <- function(x) {
>>        suppressWarnings(match(x, romanC))
>>    }
>>    nonnumeric <- function(x) {
>>        suppressWarnings(ifelse(is.na(as.numeric(x)), toupper(x),
>>            NA))
>>    }
>>    x <- as.character(x)
>>    which.nas <- which(is.na(x))
>>    which.blanks <- which(x == "")
>>    if (length(which.blanks) > 0)
>>        x[which.blanks] <- -Inf
>>    if (length(which.nas) > 0)
>>        x[which.nas] <- Inf
>>    delimited <- gsub("([IVXCL]+)",
>>        paste(delim, "\\1", delim, sep = ""), x)
>>    step1 <- strsplit(delimited, delim)
>>    step1 <- lapply(step1, function(x) x[x > ""])
>>    step1.roman <- lapply(step1, roman)
>>    step1.character <- lapply(step1, nonnumeric)
>>    maxelem <- max(sapply(step1, length))
>>    step1.roman.t <- lapply(1:maxelem, function(i) sapply(step1.roman,
>>        function(x) x[i]))
>>    step1.character.t <- lapply(1:maxelem, function(i) sapply(step1.character,
>>        function(x) x[i]))
>>    rank.roman <- sapply(step1.roman.t, rank)
>>    rank.character <- sapply(step1.character.t, function(x) as.numeric(factor(x)))
>>    rank.roman[!is.na(rank.character)] <- 0
>>    rank.character <- t(t(rank.character) + apply(matrix(rank.roman),
>>        2, max, na.rm = TRUE))
>>    rank.overall <- ifelse(is.na(rank.character), rank.numeric,
>>        rank.character)
>>    order.frame <- as.data.frame(rank.overall)
>>    if (length(which.nas) > 0)
>>        order.frame[which.nas, ] <- Inf
>>    retval <- do.call("order", order.frame)
>>    return(retval)
>> }
>> 
>> y[mixedorderRoman(y)]
>> [1] "chr I"    "chr II"   "chr III"  "chr IV"   "chr IX"
>> [6] "chr V"    "chr VI"   "chr VII"  "chr VIII" "chr X"
>> [11] "chr XI"   "chr XII"
>> 
>> 
>> --
>> David.
>>> 
>>> ## DECIMAL NUMBERS
>>>> x <- sprintf("chr %d", 12:1)
>>>> x
>>> [1] "chr 12" "chr 11" "chr 10" "chr 9"  "chr 8"
>>> [6] "chr 7"  "chr 6"  "chr 5"  "chr 4"  "chr 3"
>>> [11] "chr 2"  "chr 1"
>>> 
>>>> sort(x)
>>> [1] "chr 1"  "chr 10" "chr 11" "chr 12" "chr 2"
>>> [6] "chr 3"  "chr 4"  "chr 5"  "chr 6"  "chr 7"
>>> [11] "chr 8"  "chr 9"
>>> 
>>>> gtools::mixedsort(x)
>>> [1] "chr 1"  "chr 2"  "chr 3"  "chr 4"  "chr 5"
>>> [6] "chr 6"  "chr 7"  "chr 8"  "chr 9"  "chr 10"
>>> [11] "chr 11" "chr 12"
>>> 
>>> 
>>> ## ROMAN NUMBERS
>>>> y <- sprintf("chr %s", as.roman(12:1))
>>>> y
>>> [1] "chr XII"  "chr XI"   "chr X"    "chr IX"
>>> [5] "chr VIII" "chr VII"  "chr VI"   "chr V"
>>> [9] "chr IV"   "chr III"  "chr II"   "chr I"
>>> 
>>>> sort(y)
>>> [1] "chr I"    "chr II"   "chr III"  "chr IV"
>>> [5] "chr IX"   "chr V"    "chr VI"   "chr VII"
>>> [9] "chr VIII" "chr X"    "chr XI"   "chr XII"
>>> 
>>>> mixedsortroman(y)
>>> [1] "chr I"    "chr II"   "chr III"  "chr IV"
>>> [5] "chr V"    "chr VI"   "chr VII"  "chr VIII"
>>> [9] "chr IX"   "chr X"    "chr XI"   "chr XII"
>>> 
>>> The latter is what I'm looking for.
>>> 
>>> Before hacking together something myself (e.g. identify roman numerals
>>> substrings, translate them to decimal numbers, use gtools::mixedsort()
>>> to sort them and then translate them back to roman numbers), I'd like
>>> to hear if someone already has this implemented/know of a package that
>>> does this.
>>> 
>>> Thanks,
>>> 
>>> Henrik
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From radhakrishnan.mohan at gmail.com  Mon Sep  8 06:55:30 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Mon, 8 Sep 2014 10:25:30 +0530
Subject: [R] Solving equations
In-Reply-To: <540CABA5.60908@sapo.pt>
References: <CAOoXFP_sGjacz8Y38D5cfPx4RssBx7bt+VpLnPRKE2SGAY+RzA@mail.gmail.com>
	<540CABA5.60908@sapo.pt>
Message-ID: <CAOoXFP9Bsrxp+SgD0MM7PE5+dFv+FJkx50KC5PUUKOevMUUY2w@mail.gmail.com>

No. I was not looking for an answer to that question. I wasn't clear :-) I
already code using Octave and R to solve ML algorithms.

I am trying to understand  how R packages can help us to solve such
equations using LU decomposition etc. The question was about using R with
these math algorithms.

Mohan

On Mon, Sep 8, 2014 at 12:31 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Inline.
>
> Em 07-09-2014 09:54, Mohan Radhakrishnan escreveu:
>
>> Hi,
>>           I code R to parse data but not for solving equations. So this is
>> my first such problem. It is a programming puzzle.
>>
>> I have these two equations.
>>
>> 1)    4x - 3w = 0
>> 2)    8x - 7w =0
>>
>> I know the value of x and w for
>>
>> equation 1).  x = 3 and w = 4
>> equation 2).  x = 7 and w = 8
>>
>
> Why? Any of those equations defines a straight line, not a point. Those
> two points are just one of the infinitely many solutions.
>
> Your equations are equivalent to
> eq1) w = 4/3x
> eq2) w = 8/7x
>
> the equations of straight lines passing through the origin (no independent
> term).
>
>
>> I also know how to write more equations based on data available in the
>> puzzle.
>>
>> How do I solve a set of such equations ? I need to find out the values of
>> x
>> and w for each such equation.
>>
>
> There are packages to solve simultaneous equations but I've never used
> them.
>
> Hope this helps,
>
> Rui Barradas
>
>>
>> I know that here the equations are simple because the puzzle can be
>> simplfied.
>>
>>
>> Thanks,
>> Mohan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From sarbani.dasgupta at accenture.com  Mon Sep  8 07:05:06 2014
From: sarbani.dasgupta at accenture.com (sarbani.dasgupta at accenture.com)
Date: Mon, 8 Sep 2014 05:05:06 +0000
Subject: [R] Psych package
Message-ID: <af07f3afc573408386836fb92cb04250@CO2PR42MB012.048d.mgd.msft.net>

Hi Team,

I tried using fa.ply function for a dataset with ordinal and nominal variables.Its giving the following Warning.Is it a bug?Or we need to use some other procedure for factor analysis of ordinal/nominal data?

Code:-
faPCdirect <- fa.poly(mydata, nfactors=12, rotate="varimax")

Warning:-
The items do not have an equal number of response alternatives, global set to FALSE

The items do not have an equal number of response alternatives, global set to FALSE
The estimated weights for the factor scores are probably incorrect.  Try a different factor extraction method.
There were 35 warnings (use warnings() to see them)

Regards
Sarbani

________________________________

This message is for the designated recipient only and ma...{{dropped:16}}


From bhh at xs4all.nl  Mon Sep  8 08:51:38 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 8 Sep 2014 08:51:38 +0200
Subject: [R] Solving equations
In-Reply-To: <CAOoXFP9Bsrxp+SgD0MM7PE5+dFv+FJkx50KC5PUUKOevMUUY2w@mail.gmail.com>
References: <CAOoXFP_sGjacz8Y38D5cfPx4RssBx7bt+VpLnPRKE2SGAY+RzA@mail.gmail.com>
	<540CABA5.60908@sapo.pt>
	<CAOoXFP9Bsrxp+SgD0MM7PE5+dFv+FJkx50KC5PUUKOevMUUY2w@mail.gmail.com>
Message-ID: <67B34534-0FC8-42A3-A9F3-49E44BF29CFB@xs4all.nl>


On 08-09-2014, at 06:55, Mohan Radhakrishnan <radhakrishnan.mohan at gmail.com> wrote:

> No. I was not looking for an answer to that question. I wasn't clear :-) I
> already code using Octave and R to solve ML algorithms.
> 
> I am trying to understand  how R packages can help us to solve such
> equations using LU decomposition etc. The question was about using R with
> these math algorithms.
> 

It?s still unclear what you want.
Look at

?solve

The solution to your simultaneous system of linear equations is x=0 and w=0.

Berend

> Mohan
> 
> On Mon, Sep 8, 2014 at 12:31 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
>> Hello,
>> 
>> Inline.
>> 
>> Em 07-09-2014 09:54, Mohan Radhakrishnan escreveu:
>> 
>>> Hi,
>>>          I code R to parse data but not for solving equations. So this is
>>> my first such problem. It is a programming puzzle.
>>> 
>>> I have these two equations.
>>> 
>>> 1)    4x - 3w = 0
>>> 2)    8x - 7w =0
>>> 
>>> I know the value of x and w for
>>> 
>>> equation 1).  x = 3 and w = 4
>>> equation 2).  x = 7 and w = 8
>>> 
>> 
>> Why? Any of those equations defines a straight line, not a point. Those
>> two points are just one of the infinitely many solutions.
>> 
>> Your equations are equivalent to
>> eq1) w = 4/3x
>> eq2) w = 8/7x
>> 
>> the equations of straight lines passing through the origin (no independent
>> term).
>> 
>> 
>>> I also know how to write more equations based on data available in the
>>> puzzle.
>>> 
>>> How do I solve a set of such equations ? I need to find out the values of
>>> x
>>> and w for each such equation.
>>> 
>> 
>> There are packages to solve simultaneous equations but I've never used
>> them.
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>>> 
>>> I know that here the equations are simple because the puzzle can be
>>> simplfied.
>>> 
>>> 
>>> Thanks,
>>> Mohan
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rl at openmailbox.org  Mon Sep  8 11:12:49 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Mon, 08 Sep 2014 09:12:49 +0000
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
	<487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
	<CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>
Message-ID: <6f4f6fd6eaf0164f42b958a4f4d56848@openmailbox.org>

On Sat, 6 Sep 2014 08:21:19 -0700
William Dunlap <wdunlap at tibco.com> wrote:

> > testdataextract1<-switch(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select
> > something'))
> 
> The switch function does not work the way you are expecting it to.
> Read help("switch") and read the introduction to R that comes with R.
> 
> You probably want to use the output of menu() to extract a row of
> testdata with testdata[outputOfMenu,].  (How could testdataextract1
> contain anything in the 2nd or 3rd columns of testdata if the
> expression producing testdataextract1 does not contain any reference
> to that column?)
> 

I tried:

> testdataextract1<-function (testdata) {
+
selectionresult<-switch(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select
something'))
+ return (testdata[selectionresult,])
+ }
> testdataextract1(testdata)
Select something

1: text test1
2: text test2
3: text test3

Selection: 2
[1] variablea variableb variablec
<0 rows> (or 0-length row.names)

Why does this error occur?

Although the menu must show only unique values to be chosen, the
resultant output must show all values that match the chosen value in
this example:

text test2 other texty       200
text test2 other texty       700
text test2 other texty       300
text test2 other texty       250


From K.Ropkins at its.leeds.ac.uk  Mon Sep  8 11:46:39 2014
From: K.Ropkins at its.leeds.ac.uk (Karl Ropkins)
Date: Mon, 8 Sep 2014 10:46:39 +0100
Subject: [R] using  edit to extract codes from vignette failed
In-Reply-To: <mailman.15.1410084009.23748.r-help@r-project.org>
References: <mailman.15.1410084009.23748.r-help@r-project.org>
Message-ID: <928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>

Try:

edit(vignette("grobs",package = "grid"))

(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)

Karl     


Message: 9
Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
From: "PO SU" <rhelpmaillist at 163.com>
To: "R. Help" <r-help at r-project.org>
Subject: [R]   using  edit to extract codes from vignette failed
Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
Content-Type: text/plain; charset=UTF-8

Dear expeRts,
? ? When i using the following code, i get a error as follows:

?edit(file=vignette("grobs",package = "grid"))
Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
? argument "name" is missing, with no default

I investigated edit function, but still can't ?get codes from a vignette, May you help me?

--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU


From wdunlap at tibco.com  Mon Sep  8 16:55:23 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Sep 2014 07:55:23 -0700
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <6f4f6fd6eaf0164f42b958a4f4d56848@openmailbox.org>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
	<487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
	<CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>
	<6f4f6fd6eaf0164f42b958a4f4d56848@openmailbox.org>
Message-ID: <CAF8bMcaXtZiLRQE55ZvuhH4XYPyBVzQneJn0KJSGBHr_V5vSDA@mail.gmail.com>

Again, feed the output of menu() directly into "[".  Do not use switch().
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Sep 8, 2014 at 2:12 AM,  <rl at openmailbox.org> wrote:
> On Sat, 6 Sep 2014 08:21:19 -0700
> William Dunlap <wdunlap at tibco.com> wrote:
>
>> >
>> > testdataextract1<-switch(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select
>> > something'))
>>
>> The switch function does not work the way you are expecting it to.
>> Read help("switch") and read the introduction to R that comes with R.
>>
>> You probably want to use the output of menu() to extract a row of
>> testdata with testdata[outputOfMenu,].  (How could testdataextract1
>> contain anything in the 2nd or 3rd columns of testdata if the
>> expression producing testdataextract1 does not contain any reference
>> to that column?)
>>
>
> I tried:
>
>> testdataextract1<-function (testdata) {
>
> +
> selectionresult<-switch(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select
> something'))
> + return (testdata[selectionresult,])
> + }
>>
>> testdataextract1(testdata)
>
> Select something
>
> 1: text test1
> 2: text test2
> 3: text test3
>
> Selection: 2
> [1] variablea variableb variablec
> <0 rows> (or 0-length row.names)
>
> Why does this error occur?
>
> Although the menu must show only unique values to be chosen, the
> resultant output must show all values that match the chosen value in
> this example:
>
> text test2 other texty       200
> text test2 other texty       700
> text test2 other texty       300
> text test2 other texty       250


From rl at openmailbox.org  Mon Sep  8 17:13:23 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Mon, 08 Sep 2014 15:13:23 +0000
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <CAF8bMcaXtZiLRQE55ZvuhH4XYPyBVzQneJn0KJSGBHr_V5vSDA@mail.gmail.com>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
	<487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
	<CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>
	<6f4f6fd6eaf0164f42b958a4f4d56848@openmailbox.org>
	<CAF8bMcaXtZiLRQE55ZvuhH4XYPyBVzQneJn0KJSGBHr_V5vSDA@mail.gmail.com>
Message-ID: <d4743dcf80f5d20a9e3ac5d0530ab6e3@openmailbox.org>

On Mon, 8 Sep 2014 07:55:23 -0700
William Dunlap <wdunlap at tibco.com> wrote:

> Again, feed the output of menu() directly into "[".  Do not use
> switch(). Bill Dunlap

The function was changed to:

testdataextract1<-function (testdata) {
selectionresult<-menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select
something') return (testdata[selectionresult,])
}
testdataextract1(testdata)

> testdataextract1(testdata)
Select something

1: text test1
2: text test2
3: text test3

Selection: 2
    variablea   variableb variablec
2 text test2 other texty       200

However, how to adjust the function 'return' so that _all_ values that
match the selected value from the menu are returned (as below)?

>> 
>> Although the menu must show only unique values to be chosen, the
>> resultant output must show all values that match the chosen value in
>> this example:
>> 
>> text test2 other texty       200
>> text test2 other texty       700
>> text test2 other texty       300
>> text test2 other texty       250


From wdunlap at tibco.com  Mon Sep  8 17:47:36 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Sep 2014 08:47:36 -0700
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <d4743dcf80f5d20a9e3ac5d0530ab6e3@openmailbox.org>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
	<487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
	<CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>
	<6f4f6fd6eaf0164f42b958a4f4d56848@openmailbox.org>
	<CAF8bMcaXtZiLRQE55ZvuhH4XYPyBVzQneJn0KJSGBHr_V5vSDA@mail.gmail.com>
	<d4743dcf80f5d20a9e3ac5d0530ab6e3@openmailbox.org>
Message-ID: <CAF8bMcbjCiLkHWHpqqk78jHY5PPP7Ge+zHnYsmmu8zXQUd2YLQ@mail.gmail.com>

d <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
i <- 1 # possible output of menu(unique(d$Choices))
d[ d$Choices[i] == d$Choices, ]
#  Choices X
#1     One 1
#3     One 3

I believe this sort of thing is covered in the Introduction to R pdf
that comes with R.  It is worth reading.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Sep 8, 2014 at 8:13 AM,  <rl at openmailbox.org> wrote:
> On Mon, 8 Sep 2014 07:55:23 -0700
> William Dunlap <wdunlap at tibco.com> wrote:
>
>> Again, feed the output of menu() directly into "[".  Do not use
>> switch(). Bill Dunlap
>
>
> The function was changed to:
>
> testdataextract1<-function (testdata) {
> selectionresult<-menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select
> something') return (testdata[selectionresult,])
> }
> testdataextract1(testdata)
>
>> testdataextract1(testdata)
>
> Select something
>
> 1: text test1
> 2: text test2
> 3: text test3
>
> Selection: 2
>    variablea   variableb variablec
> 2 text test2 other texty       200
>
> However, how to adjust the function 'return' so that _all_ values that
> match the selected value from the menu are returned (as below)?
>
>>>
>>> Although the menu must show only unique values to be chosen, the
>>> resultant output must show all values that match the chosen value in
>>> this example:
>>>
>>> text test2 other texty       200
>>> text test2 other texty       700
>>> text test2 other texty       300
>>> text test2 other texty       250


From rhelpmaillist at 163.com  Mon Sep  8 18:21:16 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 9 Sep 2014 00:21:16 +0800 (CST)
Subject: [R] using  edit to extract codes from vignette failed
In-Reply-To: <928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
References: <mailman.15.1410084009.23748.r-help@r-project.org>
	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
Message-ID: <5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>


Tks for correcting me not using the file argument, but the codes you supply ?seem still not work.

edit(vignette("grobs",package = "grid")) can't work.
I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
Error in editor(file = file, title = title) : 
  argument "name" is missing, with no default











--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-09-08 05:46:39, "Karl Ropkins" <K.Ropkins at its.leeds.ac.uk> wrote:
>Try:
>
>edit(vignette("grobs",package = "grid"))
>
>(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)
>
>Karl     
>
>
>Message: 9
>Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
>From: "PO SU" <rhelpmaillist at 163.com>
>To: "R. Help" <r-help at r-project.org>
>Subject: [R]   using  edit to extract codes from vignette failed
>Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
>Content-Type: text/plain; charset=UTF-8
>
>Dear expeRts,
>? ? When i using the following code, i get a error as follows:
>
>?edit(file=vignette("grobs",package = "grid"))
>Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
>? argument "name" is missing, with no default
>
>I investigated edit function, but still can't ?get codes from a vignette, May you help me?
>
>--
>
>PO SU
>mail: desolator88 at 163.com
>Majored in Statistics from SJTU
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From john.archie.mckown at gmail.com  Mon Sep  8 18:36:00 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 8 Sep 2014 11:36:00 -0500
Subject: [R] using edit to extract codes from vignette failed
In-Reply-To: <5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
References: <mailman.15.1410084009.23748.r-help@r-project.org>
	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
	<5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAJSdjgH5L757zdCWE_dzdFd0ox6pQKfLztpkMNpFbfsM_m5gw@mail.gmail.com>

On Mon, Sep 8, 2014 at 11:21 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Tks for correcting me not using the file argument, but the codes you supply  seem still not work.
>
> edit(vignette("grobs",package = "grid")) can't work.
> I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
> Error in editor(file = file, title = title) :
>   argument "name" is missing, with no default
>

The following worked for me:

edit(vignette("grobs",package="grid"),editor="notepad")

Sys.info() returns:

> Sys.info()
                     sysname                      release
                   "Windows"                      "7 x64"
                     version                     nodename
"build 7601, Service Pack 1"                 "IT-JMCKOWN"
                     machine                        login
                    "x86-64"                "john.mckown"
                        user               effective_user
               "john.mckown"                "john.mckown"

Apparently there is some option, called editor?, which neither of us
has set. And I guess Rstudio doesn't have a default.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From murdoch.duncan at gmail.com  Mon Sep  8 18:35:44 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Sep 2014 12:35:44 -0400
Subject: [R] using  edit to extract codes from vignette failed
In-Reply-To: <5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
References: <mailman.15.1410084009.23748.r-help@r-project.org>	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
	<5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
Message-ID: <540DDAE0.9020501@gmail.com>

On 08/09/2014 12:21 PM, PO SU wrote:
> Tks for correcting me not using the file argument, but the codes you supply  seem still not work.
>
> edit(vignette("grobs",package = "grid")) can't work.
> I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
> Error in editor(file = file, title = title) :
>    argument "name" is missing, with no default
>
>

That appears to be an RStudio bug.

edit(vignette("grobs",package = "grid"))

works fine in R.  You should report it to them.


Duncan Murdoch

>
>
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-09-08 05:46:39, "Karl Ropkins" <K.Ropkins at its.leeds.ac.uk> wrote:
> >Try:
> >
> >edit(vignette("grobs",package = "grid"))
> >
> >(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)
> >
> >Karl
> >
> >
> >Message: 9
> >Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
> >From: "PO SU" <rhelpmaillist at 163.com>
> >To: "R. Help" <r-help at r-project.org>
> >Subject: [R]   using  edit to extract codes from vignette failed
> >Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
> >Content-Type: text/plain; charset=UTF-8
> >
> >Dear expeRts,
> >? ? When i using the following code, i get a error as follows:
> >
> >?edit(file=vignette("grobs",package = "grid"))
> >Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
> >? argument "name" is missing, with no default
> >
> >I investigated edit function, but still can't ?get codes from a vignette, May you help me?
> >
> >--
> >
> >PO SU
> >mail: desolator88 at 163.com
> >Majored in Statistics from SJTU
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Sep  8 18:41:33 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Sep 2014 09:41:33 -0700
Subject: [R] using edit to extract codes from vignette failed
In-Reply-To: <5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
References: <mailman.15.1410084009.23748.r-help@r-project.org>
	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
	<5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
Message-ID: <CAF8bMcZMDpMw_LNqnFAD_qsSTNYZ9n8BSxn2Zpzmw5FoRd6d5g@mail.gmail.com>

Complain to the RStudio people - RStudio defines its own
options("editor") which is not completely compatible with R's
option(editor="internal").  If you set options(editor="internal") in
RStudio then you can look at the code in the vignette. (I tried with
last year's RStudio 0.98.501 and this may have been fixed by now.)
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Sep 8, 2014 at 9:21 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Tks for correcting me not using the file argument, but the codes you supply  seem still not work.
>
> edit(vignette("grobs",package = "grid")) can't work.
> I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
> Error in editor(file = file, title = title) :
>   argument "name" is missing, with no default
>
>
>
>
>
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-09-08 05:46:39, "Karl Ropkins" <K.Ropkins at its.leeds.ac.uk> wrote:
>>Try:
>>
>>edit(vignette("grobs",package = "grid"))
>>
>>(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)
>>
>>Karl
>>
>>
>>Message: 9
>>Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
>>From: "PO SU" <rhelpmaillist at 163.com>
>>To: "R. Help" <r-help at r-project.org>
>>Subject: [R]   using  edit to extract codes from vignette failed
>>Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
>>Content-Type: text/plain; charset=UTF-8
>>
>>Dear expeRts,
>>? ? When i using the following code, i get a error as follows:
>>
>>?edit(file=vignette("grobs",package = "grid"))
>>Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
>>? argument "name" is missing, with no default
>>
>>I investigated edit function, but still can't ?get codes from a vignette, May you help me?
>>
>>--
>>
>>PO SU
>>mail: desolator88 at 163.com
>>Majored in Statistics from SJTU
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Mon Sep  8 18:46:34 2014
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 8 Sep 2014 10:46:34 -0600
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <loom.20140906T040650-156@post.gmane.org>
References: <loom.20140906T040650-156@post.gmane.org>
Message-ID: <CAFEqCdza_8p+ksPHx=K+QULBDqty_b4U23G_aeVVUspCUwgryw@mail.gmail.com>

Others have discussed some of the theoretical approaches (delta
method), but as has also been pointed out, this is a mailing list
about R, not theory, so here are some approaches to your question from
the approach of those of us who like programming R more than
remembering theory.

I assume that one reason you may be interested in B2/B1 is that you
want the confidence interval on the quantity, not just the test of
whether it is 0 (that test being equivalent to B2=0 unless B1 is
exactly equal to 0).  So I will focus more on confidence intervals
(which you can use as tests by seeing if the null value is in the
interval/region or not).

Approach 1, simulation:

If all the assumptions hold for the linear regression, then the
parameter estimates are considered to by multivariate normal.  You can
get the covariance matrix for this normal using the vcov function on
the summary of your fitted object.  Now you can use the mvrnorm
function with the estimated means and covariance to generate a bunch
of observations from this multivariate normal and compute B2/B1 or
some combination of B2/B1 and B4/B3 for each observation.  These
values represent the distribution of interest and you can calculate a
confidence interval by finding the quantiles of the values (0.025 and
0.975 for 95%) or finding the HPD interval (minimum width interval),
the emp.hpd function in the TeachingDemos package is one way to do
this.  For your second hypothesis you could look at B2/B1 - B4/B3 = 0
or (B2/B1) / (B4/B3) = 1, or create a joint confidence region on the 2
ratios and see if the x=y line intersects that region.

Approach 2, bootstrap:

Bootstrap the whole process, fit the regression model then find the
ratio of the estimates.  Find the bootstrap confidence interval of the
ratio(s), follow above advice.

Approach 3, Bayes:

Fit a Bayesian regression model and look at the posterior distribution
of the ratio(s) of interest, calculate the credible interval/region
(the steps will be similar to the previous approaches).

Approach 4, simulate from the null:

Fit your regression model under then null hypothesis of interest being
true (for a more complicated null, your second, you may need to use
optimization or quadratic programming to allow some values to vary,
but have others dependent on those, then find the least squares
solution).  Now simulate data based on that model, fit the full
regression to the simulated data sets and compare the parameter
estimates (or ratios thereof) to the parameter estimates from the
original data.


You could try any of these approaches for hypotheses where traditional
linear hypotheses work and compare the results from the traditional
approach to the above approaches to see how they compare (and how many
iterations/samples you will need).

On Fri, Sep 5, 2014 at 8:17 PM, Chris <bonsxanco at yahoo.com> wrote:
> Hi.
>
> Say I have a model like
>
> y = a + B1*x1 + B2*x2 + B3*x3 + B4*x4 + e
>
> and I want to test
>
> H0: B2/B1 = 0
>
> or
>
> H0: B2/B1=B4/B3
>
> (whatever H1). How can I proceed?
>
> I now about car::linearHypothesis, but I can't figure out a way to do the
> tests above.
>
> Any hint?
>
> Thanks.
>
> C
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From murdoch.duncan at gmail.com  Mon Sep  8 18:48:47 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Sep 2014 12:48:47 -0400
Subject: [R] using  edit to extract codes from vignette failed
In-Reply-To: <540DDAE0.9020501@gmail.com>
References: <mailman.15.1410084009.23748.r-help@r-project.org>	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
	<5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
	<540DDAE0.9020501@gmail.com>
Message-ID: <540DDDEF.70301@gmail.com>

On 08/09/2014 12:35 PM, Duncan Murdoch wrote:
> On 08/09/2014 12:21 PM, PO SU wrote:
> > Tks for correcting me not using the file argument, but the codes you supply  seem still not work.
> >
> > edit(vignette("grobs",package = "grid")) can't work.
> > I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
> > Error in editor(file = file, title = title) :
> >    argument "name" is missing, with no default
> >
> >
>
> That appears to be an RStudio bug.
>
> edit(vignette("grobs",package = "grid"))
>
> works fine in R.  You should report it to them.

Yes, confirmed:  RStudio sets the "editor" option to a function that 
requires a "name" argument, but file.edit doesn't provide one.

The documentation for that "editor" option is pretty weak, but I'd still 
say this is an RStudio bug.

Duncan Murdoch
>
>
> Duncan Murdoch
>
> >
> >
> >
> >
> >
> >
> >
> >
> > --
> >
> > PO SU
> > mail: desolator88 at 163.com
> > Majored in Statistics from SJTU
> >
> >
> >
> > At 2014-09-08 05:46:39, "Karl Ropkins" <K.Ropkins at its.leeds.ac.uk> wrote:
> > >Try:
> > >
> > >edit(vignette("grobs",package = "grid"))
> > >
> > >(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)
> > >
> > >Karl
> > >
> > >
> > >Message: 9
> > >Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
> > >From: "PO SU" <rhelpmaillist at 163.com>
> > >To: "R. Help" <r-help at r-project.org>
> > >Subject: [R]   using  edit to extract codes from vignette failed
> > >Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
> > >Content-Type: text/plain; charset=UTF-8
> > >
> > >Dear expeRts,
> > >? ? When i using the following code, i get a error as follows:
> > >
> > >?edit(file=vignette("grobs",package = "grid"))
> > >Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
> > >? argument "name" is missing, with no default
> > >
> > >I investigated edit function, but still can't ?get codes from a vignette, May you help me?
> > >
> > >--
> > >
> > >PO SU
> > >mail: desolator88 at 163.com
> > >Majored in Statistics from SJTU
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From tom at maladmin.com  Mon Sep  8 19:10:47 2014
From: tom at maladmin.com (Tom Wright)
Date: Mon, 08 Sep 2014 13:10:47 -0400
Subject: [R] ggplot - boxplot and points split by two factors
Message-ID: <1410196247.9029.20.camel@tom-laptop>

Hi,
I'm trying to create a boxplot overlayed with points where the data is
split by two factor groups.
So far:

x1<-factor(rep(LETTERS[1:4],5))
x2<-factor(rep(letters[1:2],10))
z<-runif(20,0,10)

data<-data.frame(x1=x1,x2=x2,z=z)

ggplot(data,aes(x=x1,y=z,fill=x2)) +
	geom_boxplot() +
	geom_point()


Obviously I'd also like to separate the points to overlay the relevant boxplots.

Any hints gratefully received.
Thanks,
Tom


From tom at maladmin.com  Mon Sep  8 19:37:32 2014
From: tom at maladmin.com (Tom Wright)
Date: Mon, 08 Sep 2014 13:37:32 -0400
Subject: [R] ggplot - boxplot and points split by two factors
In-Reply-To: <1410196247.9029.20.camel@tom-laptop>
References: <1410196247.9029.20.camel@tom-laptop>
Message-ID: <1410197852.9029.22.camel@tom-laptop>

ggplot(data,aes(x = z1, y = x, fill=x2)) +
  geom_boxplot() +
  geom_point(alpha=0.5,
	position=position_jitterdodge(jitter.width=0.1),
	aes(group=x2))

On Mon, 2014-09-08 at 13:10 -0400, Tom Wright wrote:
> Hi,
> I'm trying to create a boxplot overlayed with points where the data is
> split by two factor groups.
> So far:
> 
> x1<-factor(rep(LETTERS[1:4],5))
> x2<-factor(rep(letters[1:2],10))
> z<-runif(20,0,10)
> 
> data<-data.frame(x1=x1,x2=x2,z=z)
> 
> ggplot(data,aes(x=x1,y=z,fill=x2)) +
> 	geom_boxplot() +
> 	geom_point()
> 
> 
> Obviously I'd also like to separate the points to overlay the relevant boxplots.
> 
> Any hints gratefully received.
> Thanks,
> Tom
>


From murdoch.duncan at gmail.com  Mon Sep  8 20:30:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Sep 2014 14:30:12 -0400
Subject: [R] using  edit to extract codes from vignette failed
In-Reply-To: <540DDDEF.70301@gmail.com>
References: <mailman.15.1410084009.23748.r-help@r-project.org>	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
	<5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
	<540DDAE0.9020501@gmail.com> <540DDDEF.70301@gmail.com>
Message-ID: <540DF5B4.2060106@gmail.com>

On 08/09/2014 12:48 PM, Duncan Murdoch wrote:
> On 08/09/2014 12:35 PM, Duncan Murdoch wrote:
> > On 08/09/2014 12:21 PM, PO SU wrote:
> > > Tks for correcting me not using the file argument, but the codes you supply  seem still not work.
> > >
> > > edit(vignette("grobs",package = "grid")) can't work.
> > > I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
> > > Error in editor(file = file, title = title) :
> > >    argument "name" is missing, with no default
> > >
> > >
> >
> > That appears to be an RStudio bug.
> >
> > edit(vignette("grobs",package = "grid"))
> >
> > works fine in R.  You should report it to them.

No need to do that, I've just done so.

Duncan Murdoch
>
> Yes, confirmed:  RStudio sets the "editor" option to a function that
> requires a "name" argument, but file.edit doesn't provide one.
>
> The documentation for that "editor" option is pretty weak, but I'd still
> say this is an RStudio bug.
>
> Duncan Murdoch
> >
> >
> > Duncan Murdoch
> >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > --
> > >
> > > PO SU
> > > mail: desolator88 at 163.com
> > > Majored in Statistics from SJTU
> > >
> > >
> > >
> > > At 2014-09-08 05:46:39, "Karl Ropkins" <K.Ropkins at its.leeds.ac.uk> wrote:
> > > >Try:
> > > >
> > > >edit(vignette("grobs",package = "grid"))
> > > >
> > > >(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)
> > > >
> > > >Karl
> > > >
> > > >
> > > >Message: 9
> > > >Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
> > > >From: "PO SU" <rhelpmaillist at 163.com>
> > > >To: "R. Help" <r-help at r-project.org>
> > > >Subject: [R]   using  edit to extract codes from vignette failed
> > > >Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
> > > >Content-Type: text/plain; charset=UTF-8
> > > >
> > > >Dear expeRts,
> > > >? ? When i using the following code, i get a error as follows:
> > > >
> > > >?edit(file=vignette("grobs",package = "grid"))
> > > >Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
> > > >? argument "name" is missing, with no default
> > > >
> > > >I investigated edit function, but still can't ?get codes from a vignette, May you help me?
> > > >
> > > >--
> > > >
> > > >PO SU
> > > >mail: desolator88 at 163.com
> > > >Majored in Statistics from SJTU
> > > >
> > > >______________________________________________
> > > >R-help at r-project.org mailing list
> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >and provide commented, minimal, self-contained, reproducible code.
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>


From felasa at gmail.com  Mon Sep  8 20:57:03 2014
From: felasa at gmail.com (Federico Lasa)
Date: Mon, 8 Sep 2014 13:57:03 -0500
Subject: [R] ggplot - boxplot and points split by two factors
In-Reply-To: <1410197852.9029.22.camel@tom-laptop>
References: <1410196247.9029.20.camel@tom-laptop>
	<1410197852.9029.22.camel@tom-laptop>
Message-ID: <CAE8W1T3nnPeKk31Z1Y=nk+=iPfJ1boJ4GBDR+5jtF9BxLuqH9Q@mail.gmail.com>

Use geom_jitter() instead of geom_point

On Mon, Sep 8, 2014 at 12:37 PM, Tom Wright <tom at maladmin.com> wrote:
> ggplot(data,aes(x = z1, y = x, fill=x2)) +
>   geom_boxplot() +
>   geom_point(alpha=0.5,
>         position=position_jitterdodge(jitter.width=0.1),
>         aes(group=x2))
>
> On Mon, 2014-09-08 at 13:10 -0400, Tom Wright wrote:
>> Hi,
>> I'm trying to create a boxplot overlayed with points where the data is
>> split by two factor groups.
>> So far:
>>
>> x1<-factor(rep(LETTERS[1:4],5))
>> x2<-factor(rep(letters[1:2],10))
>> z<-runif(20,0,10)
>>
>> data<-data.frame(x1=x1,x2=x2,z=z)
>>
>> ggplot(data,aes(x=x1,y=z,fill=x2)) +
>>       geom_boxplot() +
>>       geom_point()
>>
>>
>> Obviously I'd also like to separate the points to overlay the relevant boxplots.
>>
>> Any hints gratefully received.
>> Thanks,
>> Tom
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stefan at inizio.se  Mon Sep  8 22:22:03 2014
From: stefan at inizio.se (Stefan Petersson)
Date: Mon, 8 Sep 2014 22:22:03 +0200
Subject: [R] Parliament Seats Graph
Message-ID: <CAFy6Y8VGLanmQtn_0p3YuT2FkH45fv4NsdZ=psQE2pD3Kor0Jg@mail.gmail.com>

Hi,

Is there any package (or homegrown function) that can produce
"Parliament Seats Graph"? I'm referring to the nice looking concentric
half circles of colored "seats" as seen on Wikipedia (for example).

I can pretty easily plot the points and color them. But I can't group
the colored points in sectors, as seen on the example.

Example:
http://en.wikipedia.org/wiki/Verkhovna_Rada#mediaviewer/File:Fractions_of_the_Parliament_of_Ukraine.svg

Found here (on the right, a bit down):
http://en.wikipedia.org/wiki/Verkhovna_Rada

TIA


From eliza_botto at hotmail.com  Mon Sep  8 21:08:43 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Mon, 8 Sep 2014 19:08:43 +0000
Subject: [R] splitting data
Message-ID: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>

Dear R members,

I have this data frame of 100 years in the following format

year            month       day         A           B           C         D

where  A,B,C and D are item number sold each day. I am trying 

1-split the data w.r.t the monthly values for each year

2-then, sum them up

I am pasting here just a part of data to make it more clearer

structure(list(year = c(1961, 1961, 1961, 1961, 1961, 1961, 1961, 
1961, 1961, 1961, 1961, 1961), month = c(1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1), day = 1:12, A = 1:12, B = 3:14, C = 6:17, D = 16:27), .Names = c("year", 
"month", "day", "A", "B", "C", "D"), row.names = c(NA, 12L), class = "data.frame")

I initially tried to use "dcast" command but for no use.

Your kind help is needed.

Thanks in advance

Eliza


 		 	   		  
	[[alternative HTML version deleted]]


From chichi.shu at hotmail.com  Mon Sep  8 19:39:18 2014
From: chichi.shu at hotmail.com (Chichi Shu)
Date: Mon, 8 Sep 2014 13:39:18 -0400
Subject: [R] Using R to get updated access token on FB Graph API?
Message-ID: <SNT149-DS244829C1FC166CFAC067F88FC10@phx.gbl>

Hi, R users,

Is it possible to use R to obtain access token to Facebook API automatically? The access token generated in Facebook Graph API expires very soon so I'd like to use R to generate new access token and grab it and save it to a variable automatically every 60 days.

Is it possible? If so, which packages should I use? Could someone shed light?

Thanks!
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Sep  8 22:42:15 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 8 Sep 2014 13:42:15 -0700
Subject: [R] splitting data
In-Reply-To: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>
References: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>
Message-ID: <CACk-te2C+=qC-K23f_YZ4SY+QfjEGgszJ9QWpJaWzcDGxrPYgQ@mail.gmail.com>

?tapply

e.g.

with(yourdata, tapply(A,list(year,month),sum,simplify=FALSE))

This assumes "sum them up" means summing each column separately. You
were unclear as to exactly what you meant by this.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Sep 8, 2014 at 12:08 PM, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear R members,
>
> I have this data frame of 100 years in the following format
>
> year            month       day         A           B           C         D
>
> where  A,B,C and D are item number sold each day. I am trying
>
> 1-split the data w.r.t the monthly values for each year
>
> 2-then, sum them up
>
> I am pasting here just a part of data to make it more clearer
>
> structure(list(year = c(1961, 1961, 1961, 1961, 1961, 1961, 1961,
> 1961, 1961, 1961, 1961, 1961), month = c(1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1), day = 1:12, A = 1:12, B = 3:14, C = 6:17, D = 16:27), .Names = c("year",
> "month", "day", "A", "B", "C", "D"), row.names = c(NA, 12L), class = "data.frame")
>
> I initially tried to use "dcast" command but for no use.
>
> Your kind help is needed.
>
> Thanks in advance
>
> Eliza
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Mon Sep  8 22:44:07 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 8 Sep 2014 15:44:07 -0500
Subject: [R] splitting data
In-Reply-To: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>
References: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>
Message-ID: <CAAJSdjifNJrUyDtrJGzBJeSqZUyVQ-fDcsWWKtRGe0Ot8ZZ6UQ@mail.gmail.com>

On Mon, Sep 8, 2014 at 2:08 PM, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear R members,
>
> I have this data frame of 100 years in the following format
>
> year            month       day         A           B           C         D
>
> where  A,B,C and D are item number sold each day. I am trying
>
> 1-split the data w.r.t the monthly values for each year
>
> 2-then, sum them up
>
> I am pasting here just a part of data to make it more clearer
>
> structure(list(year = c(1961, 1961, 1961, 1961, 1961, 1961, 1961,
> 1961, 1961, 1961, 1961, 1961), month = c(1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1), day = 1:12, A = 1:12, B = 3:14, C = 6:17, D = 16:27), .Names = c("year",
> "month", "day", "A", "B", "C", "D"), row.names = c(NA, 12L), class = "data.frame")
>
> I initially tried to use "dcast" command but for no use.
>
> Your kind help is needed.
>
> Thanks in advance
>
> Eliza

I'm not sure if I really understand what you want, but perhaps this?

library(dplyr);
summarize(group_by(data,year,month),sum(A),sum(B),sum(C),sum(D));

If you are SQL oriented this is equivalent to the SQL query:

select year, month, sum(A), sum(B), sum(C), sum(D)
from data
group by year, month
;

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From dwinsemius at comcast.net  Mon Sep  8 23:01:06 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 8 Sep 2014 14:01:06 -0700
Subject: [R] splitting data
In-Reply-To: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>
References: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>
Message-ID: <8956CF9F-2497-41F8-BEFE-0B854269D720@comcast.net>


On Sep 8, 2014, at 12:08 PM, eliza botto wrote:

> Dear R members,
> 
> I have this data frame of 100 years in the following format
> 
> year            month       day         A           B           C         D
> 
> where  A,B,C and D are item number sold each day. I am trying 
> 
> 1-split the data w.r.t the monthly values for each year
> 
> 2-then, sum them up
> 
> I am pasting here just a part of data to make it more clearer
> 
> structure(list(year = c(1961, 1961, 1961, 1961, 1961, 1961, 1961, 
> 1961, 1961, 1961, 1961, 1961), month = c(1, 1, 1, 1, 1, 1, 1, 
> 1, 1, 1, 1, 1), day = 1:12, A = 1:12, B = 3:14, C = 6:17, D = 16:27), .Names = c("year", 
> "month", "day", "A", "B", "C", "D"), row.names = c(NA, 12L), class = "data.frame")
> 
> I initially tried to use "dcast" command but for no use.
> 

This is typical use for base function aggregate:

> with( dfrm, aggregate(dfrm[4:7], dfrm[1:2], FUN=sum))
  year month  A   B   C   D
1 1961     1 78 102 138 258

> 		 	   		  
> 	[[alternative HTML version deleted]]

Please stop posting in plain text. (You have already been asked multiple times.)

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Sep  9 01:05:08 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 8 Sep 2014 16:05:08 -0700
Subject: [R] splitting data
In-Reply-To: <8956CF9F-2497-41F8-BEFE-0B854269D720@comcast.net>
References: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>
	<8956CF9F-2497-41F8-BEFE-0B854269D720@comcast.net>
Message-ID: <6943CA2B-223D-4EC3-AE49-BE10BFE1A1C7@comcast.net>


On Sep 8, 2014, at 2:01 PM, David Winsemius wrote:

> 
> On Sep 8, 2014, at 12:08 PM, eliza botto wrote:
> 
>> 
>> 
> 
> This is typical use for base function aggregate:
> 
>> with( dfrm, aggregate(dfrm[4:7], dfrm[1:2], FUN=sum))
>  year month  A   B   C   D
> 1 1961     1 78 102 138 258
> 
>> 		 	   		  
>> 	[[alternative HTML version deleted]]
> 
> Please stop posting in plain text. (You have already been asked multiple times.)

I have now been asked by three readers if I really meant this. No, I did not I mean that... Eliza, stop posting in HTML and start posting in plain text.

-- 

David Winsemius
Alameda, CA, USA


From iuri at ufrgs.br  Tue Sep  9 01:33:01 2014
From: iuri at ufrgs.br (Iuri Gavronski)
Date: Mon, 8 Sep 2014 20:33:01 -0300
Subject: [R] Problems with bstats::white.test()
Message-ID: <CA+YqJQCN-qtoHYfWvLsEtkk2Hyn669umTPhqQk7qieZucNVijg@mail.gmail.com>

Hi,

I am trying to test for heteroskedascity in an OLS model, but I am not
able to run the white.test() if the model has dummy variables built
from factors. Any suggestions?

Please find a reproducible code below:

myswiss <- swiss
myswiss$fert <- ifelse(
 myswiss$Fertility>70,
 "High","Low")
myswiss$fert <- factor(myswiss$fert)
str(myswiss)
mod1 <- lm(Infant.Mortality ~ fert,
 data=myswiss)
library(bstats)
bptest(mod1)
white.test(mod1)

myswiss$fertlow <- ifelse(
 myswiss$Fertility>70,
 0,1)
mod2 <- lm(Infant.Mortality ~ fertlow,
 data=myswiss)
library(bstats)
bptest(mod2)
white.test(mod2)

Results:


> bptest(mod2)

        studentized Breusch-Pagan test for homoscedasticity

data:  mod2
BP = 2e-04, df = 1, p-value = 0.989

> white.test(mod2)

        White test for constant variance

data:
White = 2e-04, df = 1, p-value = 0.989

> bptest(mod1)

        studentized Breusch-Pagan test for homoscedasticity

data:  mod1
BP = 2e-04, df = 1, p-value = 0.989

> white.test(mod1)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels
In addition: Warning message:
In Ops.factor(fert, fert) : * not meaningful for factors
>


From saptarshi.guha at gmail.com  Tue Sep  9 01:57:12 2014
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Mon, 8 Sep 2014 16:57:12 -0700
Subject: [R] KDE routines for data that is aggregated
Message-ID: <CAJDot1r6QaiWY_nJ3CwJa6yd4U9h_686yDTN5a1zs5ccgxsovA@mail.gmail.com>

Hello,
Couldn't think of a better subject line. Rather than a matrix like

x,y
..,..
.,..

I have a matrix like
x,y,n,
..,..,..,
..,..,..

and so on. Also, sum(n) is roughly few hundred million. The number of rows
is <1MM

Are they routines to fit a 2d kde estimate to data provided in this form?
I can sample from the data according to weights given by 'n' but i am
curious if there is something that can use all the data when given a
structure of this form.

Regards
Saptarshi

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Tue Sep  9 04:07:59 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 9 Sep 2014 10:07:59 +0800 (CST)
Subject: [R] using edit to extract codes from vignette failed
In-Reply-To: <CAF8bMcZMDpMw_LNqnFAD_qsSTNYZ9n8BSxn2Zpzmw5FoRd6d5g@mail.gmail.com>
References: <mailman.15.1410084009.23748.r-help@r-project.org>
	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
	<5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
	<CAF8bMcZMDpMw_LNqnFAD_qsSTNYZ9n8BSxn2Zpzmw5FoRd6d5g@mail.gmail.com>
Message-ID: <7f23b21a.4149.148582ae71a.Coremail.rhelpmaillist@163.com>



OK, i get it, i should set the editor argument , i don't know how to report a bug to Rstudio, may you do that? ?

?

--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-09 00:41:33, "William Dunlap" <wdunlap at tibco.com> wrote:
>Complain to the RStudio people - RStudio defines its own
>options("editor") which is not completely compatible with R's
>option(editor="internal").  If you set options(editor="internal") in
>RStudio then you can look at the code in the vignette. (I tried with
>last year's RStudio 0.98.501 and this may have been fixed by now.)
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>
>On Mon, Sep 8, 2014 at 9:21 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>
>> Tks for correcting me not using the file argument, but the codes you supply  seem still not work.
>>
>> edit(vignette("grobs",package = "grid")) can't work.
>> I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
>> Error in editor(file = file, title = title) :
>>   argument "name" is missing, with no default
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>>
>>
>>
>> At 2014-09-08 05:46:39, "Karl Ropkins" <K.Ropkins at its.leeds.ac.uk> wrote:
>>>Try:
>>>
>>>edit(vignette("grobs",package = "grid"))
>>>
>>>(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)
>>>
>>>Karl
>>>
>>>
>>>Message: 9
>>>Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
>>>From: "PO SU" <rhelpmaillist at 163.com>
>>>To: "R. Help" <r-help at r-project.org>
>>>Subject: [R]   using  edit to extract codes from vignette failed
>>>Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
>>>Content-Type: text/plain; charset=UTF-8
>>>
>>>Dear expeRts,
>>>? ? When i using the following code, i get a error as follows:
>>>
>>>?edit(file=vignette("grobs",package = "grid"))
>>>Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
>>>? argument "name" is missing, with no default
>>>
>>>I investigated edit function, but still can't ?get codes from a vignette, May you help me?
>>>
>>>--
>>>
>>>PO SU
>>>mail: desolator88 at 163.com
>>>Majored in Statistics from SJTU
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From rhelpmaillist at 163.com  Tue Sep  9 04:49:32 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 9 Sep 2014 10:49:32 +0800 (CST)
Subject: [R]  How to use multi paragraph comment like /*  and */ in cpp?
Message-ID: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>


Dear expeRts,
?? I find it's terrible? when? i want to comment multi paragraph (e.g.? a 30 lines function) , i have to comment each line with #,? is there any good way to do that ?
?? I investgate it, but found no easy way, may you help me ?





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From jdnewmil at dcn.davis.CA.us  Tue Sep  9 05:14:22 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 08 Sep 2014 20:14:22 -0700
Subject: [R] How to use multi paragraph comment like /*  and */ in cpp?
In-Reply-To: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
Message-ID: <6dcd4dfc-0355-43c9-9bdb-d0ccf6824dce@email.android.com>

There are no multi line comment markers in R. However, since you are always referring to RStudio you might want to look into roxygen, since their editor supports that tool.

I would also suggest making more functions that are smaller.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 8, 2014 7:49:32 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>
>Dear expeRts,
>?? I find it's terrible? when? i want to comment multi paragraph (e.g.?
>a 30 lines function) , i have to comment each line with #,? is there
>any good way to do that ?
>?? I investgate it, but found no easy way, may you help me ?
>
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Tue Sep  9 05:51:21 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 9 Sep 2014 12:51:21 +0900
Subject: [R] How to use multi paragraph comment like /* and */ in cpp?
In-Reply-To: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAcyNCy8OGiMdM9YeWVDDJNnZawXc51zZ3q-wSOj3jYXoeRjVw@mail.gmail.com>

A workaround is to escape the evaluation of the lines. For example:

tt <- 0
while(tt > 0){
  cat('rr\n')
}

Regards,
Pascal

On Tue, Sep 9, 2014 at 11:49 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Dear expeRts,
>    I find it's terrible  when  i want to comment multi paragraph (e.g.  a 30 lines function) , i have to comment each line with #,  is there any good way to do that ?
>    I investgate it, but found no easy way, may you help me ?
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From K.Ropkins at its.leeds.ac.uk  Tue Sep  9 08:12:19 2014
From: K.Ropkins at its.leeds.ac.uk (Karl Ropkins)
Date: Tue, 9 Sep 2014 07:12:19 +0100
Subject: [R] using edit to extract codes from vignette failed
In-Reply-To: <7f23b21a.4149.148582ae71a.Coremail.rhelpmaillist@163.com>
References: <mailman.15.1410084009.23748.r-help@r-project.org>
	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
	<5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
	<CAF8bMcZMDpMw_LNqnFAD_qsSTNYZ9n8BSxn2Zpzmw5FoRd6d5g@mail.gmail.com>,
	<7f23b21a.4149.148582ae71a.Coremail.rhelpmaillist@163.com>
Message-ID: <928C4F7877280844B906D12D63A3F15B01D551871E1D@HERMES8.ds.leeds.ac.uk>

FYI:
I get the same for Windows 7 and 8, no RStudio:
edit(vignette("grobs",package = "grid")) works for me
edit(file=vignette("grobs",package = "grid")) does not

> edit(file=vignette("grobs",package = "grid"))
Error in tempfile(name$topic, fileext = ".R") :
  argument "name" is missing, with no default
> edit(vignette("grobs",package = "grid"))
>

Re RStudio: https://support.rstudio.com/hc/en-us?community_id=public?



________________________________________
From: PO SU [rhelpmaillist at 163.com]
Sent: 09 September 2014 03:07
To: William Dunlap
Cc: Karl Ropkins; R. Help
Subject: Re:Re: [R] using edit to extract codes from vignette failed

OK, i get it, i should set the editor argument , i don't know how to report a bug to Rstudio, may you do that  ?



--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU




At 2014-09-09 00:41:33, "William Dunlap" <wdunlap at tibco.com> wrote:
>Complain to the RStudio people - RStudio defines its own
>options("editor") which is not completely compatible with R's
>option(editor="internal").  If you set options(editor="internal") in
>RStudio then you can look at the code in the vignette. (I tried with
>last year's RStudio 0.98.501 and this may have been fixed by now.)
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>
>On Mon, Sep 8, 2014 at 9:21 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>
>> Tks for correcting me not using the file argument, but the codes you supply  seem still not work.
>>
>> edit(vignette("grobs",package = "grid")) can't work.
>> I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
>> Error in editor(file = file, title = title) :
>>   argument "name" is missing, with no default
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>>
>>
>>
>> At 2014-09-08 05:46:39, "Karl Ropkins" <K.Ropkins at its.leeds.ac.uk> wrote:
>>>Try:
>>>
>>>edit(vignette("grobs",package = "grid"))
>>>
>>>(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)
>>>
>>>Karl
>>>
>>>
>>>Message: 9
>>>Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
>>>From: "PO SU" <rhelpmaillist at 163.com>
>>>To: "R. Help" <r-help at r-project.org>
>>>Subject: [R]   using  edit to extract codes from vignette failed
>>>Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
>>>Content-Type: text/plain; charset=UTF-8
>>>
>>>Dear expeRts,
>>>? ? When i using the following code, i get a error as follows:
>>>
>>>?edit(file=vignette("grobs",package = "grid"))
>>>Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
>>>? argument "name" is missing, with no default
>>>
>>>I investigated edit function, but still can't ?get codes from a vignette, May you help me?
>>>
>>>--
>>>
>>>PO SU
>>>mail: desolator88 at 163.com
>>>Majored in Statistics from SJTU
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rhelpmaillist at 163.com  Tue Sep  9 08:25:26 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 9 Sep 2014 14:25:26 +0800 (CST)
Subject: [R] How to use multi paragraph comment like /* and */ in cpp?
In-Reply-To: <CAAcyNCy8OGiMdM9YeWVDDJNnZawXc51zZ3q-wSOj3jYXoeRjVw@mail.gmail.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
	<CAAcyNCy8OGiMdM9YeWVDDJNnZawXc51zZ3q-wSOj3jYXoeRjVw@mail.gmail.com>
Message-ID: <7b9fbccc.9e59.148591699ac.Coremail.rhelpmaillist@163.com>



I don't understand what's your meaning, do you mean that i should do some file processing,(like writing a script) ,so that i could add # in any line??i wanted. 
I think it is not convenient.
And, it does seems that there is no way to multi line comment in R. But when i turn to using Rstudio, after lots trying, i find that ctrl+shift+C can do the thing.
Also i investgate roxygen, but it seems needing to learn the whole package ,? if some one happen to know how to do in roxygen, may you give me a quick reference?






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-09 11:51:21, "Pascal Oettli" <kridox at ymail.com> wrote:
>A workaround is to escape the evaluation of the lines. For example:
>
>tt <- 0
>while(tt > 0){
>  cat('rr\n')
>}
>
>Regards,
>Pascal
>
>On Tue, Sep 9, 2014 at 11:49 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>
>> Dear expeRts,
>>    I find it's terrible  when  i want to comment multi paragraph (e.g.  a 30 lines function) , i have to comment each line with #,  is there any good way to do that ?
>>    I investgate it, but found no easy way, may you help me ?
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>-- 
>Pascal Oettli
>Project Scientist
>JAMSTEC
>Yokohama, Japan

From bhh at xs4all.nl  Tue Sep  9 09:10:55 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 9 Sep 2014 09:10:55 +0200
Subject: [R] How to use multi paragraph comment like /* and */ in cpp?
In-Reply-To: <7b9fbccc.9e59.148591699ac.Coremail.rhelpmaillist@163.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
	<CAAcyNCy8OGiMdM9YeWVDDJNnZawXc51zZ3q-wSOj3jYXoeRjVw@mail.gmail.com>
	<7b9fbccc.9e59.148591699ac.Coremail.rhelpmaillist@163.com>
Message-ID: <3EDC5F64-C2E1-432D-B632-9E7CF3D1BA34@xs4all.nl>


On 09-09-2014, at 08:25, PO SU <rhelpmaillist at 163.com> wrote:

> 
> 
> I don't understand what's your meaning, do you mean that i should do some file processing,(like writing a script) ,so that i could add # in any line  i wanted. 
> I think it is not convenient.
> And, it does seems that there is no way to multi line comment in R. But when i turn to using Rstudio, after lots trying, i find that ctrl+shift+C can do the thing.


R only knows about single line comments. There is no multi line comment.
If you wish to comment several lines you will have to prefix each line with #.

Your editor may provide means of prefixing several lines with # by selecting lines and executing some command.
Rstudio provides Ctrl+Shift+C (Windows. Linux) and Cmd+Shift+C (OS X) on selected lines.
And other editors have other shortcuts.
You?ll just have to get used to this.

Berend

> Also i investgate roxygen, but it seems needing to learn the whole package ,  if some one happen to know how to do in roxygen, may you give me a quick reference?
> 
> 
> 
> 
> 
> 
> --
> 
> PO SU
> mail: desolator88 at 163.com 
> Majored in Statistics from SJTU
> 
> 
> 
> 
> At 2014-09-09 11:51:21, "Pascal Oettli" <kridox at ymail.com> wrote:
>> A workaround is to escape the evaluation of the lines. For example:
>> 
>> tt <- 0
>> while(tt > 0){
>> cat('rr\n')
>> }
>> 
>> Regards,
>> Pascal
>> 
>> On Tue, Sep 9, 2014 at 11:49 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>> 
>>> Dear expeRts,
>>>   I find it's terrible  when  i want to comment multi paragraph (e.g.  a 30 lines function) , i have to comment each line with #,  is there any good way to do that ?
>>>   I investgate it, but found no easy way, may you help me ?
>>> 
>>> 
>>> 
>>> 
>>> 
>>> --
>>> 
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> -- 
>> Pascal Oettli
>> Project Scientist
>> JAMSTEC
>> Yokohama, Japan
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Tue Sep  9 09:23:13 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 9 Sep 2014 16:23:13 +0900
Subject: [R] How to use multi paragraph comment like /* and */ in cpp?
In-Reply-To: <7b9fbccc.9e59.148591699ac.Coremail.rhelpmaillist@163.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
	<CAAcyNCy8OGiMdM9YeWVDDJNnZawXc51zZ3q-wSOj3jYXoeRjVw@mail.gmail.com>
	<7b9fbccc.9e59.148591699ac.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAcyNCw2Ao9+xSodXaF-qkcLwor=S9XBPWVGyv0vs1zKtm=HgA@mail.gmail.com>

No I don't mean this. Did you at least try the small example I provided?

On Tue, Sep 9, 2014 at 3:25 PM, PO SU <rhelpmaillist at 163.com> wrote:
>
>
> I don't understand what's your meaning, do you mean that i should do some file processing,(like writing a script) ,so that i could add # in any line  i wanted.
> I think it is not convenient.
> And, it does seems that there is no way to multi line comment in R. But when i turn to using Rstudio, after lots trying, i find that ctrl+shift+C can do the thing.
> Also i investgate roxygen, but it seems needing to learn the whole package ,  if some one happen to know how to do in roxygen, may you give me a quick reference?
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
>
> At 2014-09-09 11:51:21, "Pascal Oettli" <kridox at ymail.com> wrote:
>>A workaround is to escape the evaluation of the lines. For example:
>>
>>tt <- 0
>>while(tt > 0){
>>  cat('rr\n')
>>}
>>
>>Regards,
>>Pascal
>>
>>On Tue, Sep 9, 2014 at 11:49 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>>
>>> Dear expeRts,
>>>    I find it's terrible  when  i want to comment multi paragraph (e.g.  a 30 lines function) , i have to comment each line with #,  is there any good way to do that ?
>>>    I investgate it, but found no easy way, may you help me ?
>>>
>>>
>>>
>>>
>>>
>>> --
>>>
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>--
>>Pascal Oettli
>>Project Scientist
>>JAMSTEC
>>Yokohama, Japan



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From Achim.Zeileis at uibk.ac.at  Tue Sep  9 09:42:02 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 9 Sep 2014 09:42:02 +0200 (CEST)
Subject: [R] Problems with bstats::white.test()
In-Reply-To: <CA+YqJQCN-qtoHYfWvLsEtkk2Hyn669umTPhqQk7qieZucNVijg@mail.gmail.com>
References: <CA+YqJQCN-qtoHYfWvLsEtkk2Hyn669umTPhqQk7qieZucNVijg@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1409090933530.26333@paninaro.uibk.ac.at>

On Mon, 8 Sep 2014, Iuri Gavronski wrote:

> Hi,
>
> I am trying to test for heteroskedascity in an OLS model, but I am not
> able to run the white.test() if the model has dummy variables built
> from factors. Any suggestions?

The White test is equivalent to the Breusch-Pagan test with an auxiliary 
model containing all regressors, their squares and their cross-products. 
For dummy variables the regressors and their squares are identical, so 
this strategy has to be modified. Other collinearities might occur as 
well.

For this reason the "lmtest" package has only a function bptest() but no 
additional whitetest() function. Examples show how to compute the White 
test, though. See e.g. example("CigarettesB", package = "AER").

The "bstats" package has copied code for bptest (and dwtest) from "lmtest" 
without crediting the original authors. The maintainer is cc'ed here and 
encouraged to read and follow the CRAN policies.

The white.test() function in "bstats" does not leverage the bptest() 
function (and hence does not offer the recommended studentization option). 
It sets up the auxiliary model by pasting "I(...^2)" and ":" into the 
model formula which is very error prone and does not work for factor 
variables. (This is the reason why "lmtest" doesn't do it.)

> Please find a reproducible code below:
>
> myswiss <- swiss
> myswiss$fert <- ifelse(
> myswiss$Fertility>70,
> "High","Low")
> myswiss$fert <- factor(myswiss$fert)
> str(myswiss)
> mod1 <- lm(Infant.Mortality ~ fert,
> data=myswiss)
> library(bstats)
> bptest(mod1)
> white.test(mod1)
>
> myswiss$fertlow <- ifelse(
> myswiss$Fertility>70,
> 0,1)
> mod2 <- lm(Infant.Mortality ~ fertlow,
> data=myswiss)
> library(bstats)
> bptest(mod2)
> white.test(mod2)
>
> Results:
>
>
>> bptest(mod2)
>
>        studentized Breusch-Pagan test for homoscedasticity
>
> data:  mod2
> BP = 2e-04, df = 1, p-value = 0.989
>
>> white.test(mod2)
>
>        White test for constant variance
>
> data:
> White = 2e-04, df = 1, p-value = 0.989
>
>> bptest(mod1)
>
>        studentized Breusch-Pagan test for homoscedasticity
>
> data:  mod1
> BP = 2e-04, df = 1, p-value = 0.989
>
>> white.test(mod1)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>  contrasts can be applied only to factors with 2 or more levels
> In addition: Warning message:
> In Ops.factor(fert, fert) : * not meaningful for factors
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pollaroid at gmail.com  Tue Sep  9 11:21:40 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Tue, 9 Sep 2014 11:21:40 +0200
Subject: [R] How to identify outliers with values five times 99th percentile
Message-ID: <CAAC1QdDQ3RVQAw3S-KuJFnN7RDZ9eFvXJD0AwRoUp+i_w-t6oQ@mail.gmail.com>

I have a data frame with some extreme values which I wish to identify
and repeat an analysis without these extreme values. How could I
identify several columns with values which are 5 times higher than the
99th percentile?

Sample data is pasted below.

> dput(df)

structure(list(ad1 = c(98, 6.9, 8.1, 56, 3.9, 6.9, 6.9, 5.8,

7.2, 20.5, 9.4, 7.6, 5.3, 7.9, 62.2, 9.2, 11.9, 8.8, 23.1, 5.4,

9.4, 56, 8.6, 20.7, 21, 10.5, 5.5, 4.3, 15.8, 6.8, 10.4, 5.1),

    ad2 = c(14.9, 19.7, 1, 17.7, 14.9, 13.6, 18.8, 20.9, 46,

    16.5, 11.7, 1, 9.2, 23.6, 19.7, 1, 11.4, 11, 23.1, 1, 1,

    8.9, 11.3, 6.4, 15.2, 1, 17.3, 10.1, 13.3, 21.3, 12.3, 15.4

    ), ad3 = c(0.91, 0.95, 10.7, 4.4, 0.43, 0.8, 3.1, 1.9, 2.3,

    5.6, 3.9, 7.3, 0.37, 4.1, 15.1, 21.8, 3, 0.79, 1, 4.6, 0.61,

    0.46, 0.87, 23.5, 3.8, 3.1, 0.33, 1.9, 3.2, 1.7, 0.53, 62.5

    ), ad4 = c(225.5, 269.7, 326, 485.4, 193.2, 274.1, 553.2,

    166.8, 435.9, 433.2, 187.1, 660.4, 235.4, 356.5, 378.8, 500.5,

    323.5, 327.1, 289.5, 301.2, 291.7, 333.5, 351.7, 384.1, 347,

    1354, 440.4, 189.2, 381, 252.7, 391.1, 255.1), ad5 = c(337.9,

    355.6, 419.5, 798.5, 225, 355.9, 394.4, 340.6, 463.9, 291.9,

    312.3, 491, 290.5, 231.9, 358, 386.4, 306.7, 440.6, 297.9,

    339.3, 341.1, 366.2, 325.4, 357, 412.2, 370.2, 421.3, 346.3,

    289.1, 257.4, 368, 322.6), ad6 = c(64.5, 130.6, 76, 167.8,

    47.3, 117, 60.7, 91.9, 221.9, 91.1, 105.1, 110.8, 64.5, 184.5,

    191.6, 259.4, 879.5, 142.1, 55.3, 123.1, 62.2, 75.2, 154.6,

    100.7, 93.1, 136.7, 74.3, 41.8, 110.1, 109.1, 172.5, 87.7

    ), ad7 = c(128L, 987L, 158L, 124L, 137L, 215L, 141L, 98L,

    291L, 261L, 106L, 137L, 141L, 159L, 221L, 108L, 123L, 107L,

    137L, 175L, 257L, 97L, 168L, 145L, 147L, 188L, 145L, 128L,

    153L, 187L, 123L, 354L), ad8 = c(3.26, 3.98, 2.88, 2.85,

    4.17, 3.16, 3.09, 4.35, 3.46, 3.81, 3.78, 3.81, 4.17, 4.27,

    4.27, 2.97, 3.43, 3.48, 3.78, 3.86, 3.11, 3.12, 3.16, 4.24,

    3.81, 3.11, 5.31, 3.75, 3.78, 3.55, 4.08, 3.5), ad9 = c(433L,

    211L, 66L, 173L, 224L, 466L, 224L, 273L, 94L, 321L, 160L,

    107L, 121L, 186L, 455L, 80L, 897L, 186L, 285L, 134L, 107L,

    355L, 261L, 249L, 332L, 107L, 273L, 107L, 160L, 535L, 160L,

    121L)), .Names = c("ad1", "ad2", "ad3", "ad4", "ad5", "ad6",

"ad7", "ad8", "ad9"), class = "data.frame", row.names = c(NA,

-32L))


From ruipbarradas at sapo.pt  Tue Sep  9 11:35:17 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 09 Sep 2014 10:35:17 +0100
Subject: [R] How to identify outliers with values five times 99th
	percentile
In-Reply-To: <CAAC1QdDQ3RVQAw3S-KuJFnN7RDZ9eFvXJD0AwRoUp+i_w-t6oQ@mail.gmail.com>
References: <CAAC1QdDQ3RVQAw3S-KuJFnN7RDZ9eFvXJD0AwRoUp+i_w-t6oQ@mail.gmail.com>
Message-ID: <540EC9D5.70406@sapo.pt>

Hello,

Try the following.

out <- lapply(df, function(x){
	qq <- quantile(x, probs = 0.99)
	which(x > 5*qq)
})

out

The list 'out' contains indices to the outliers. You can now have those 
outliers as follows

df[out[[1]], 1]  # first column

Etc.

Hope this helps,

Rui Barradas


Em 09-09-2014 10:21, Kuma Raj escreveu:
> I have a data frame with some extreme values which I wish to identify
> and repeat an analysis without these extreme values. How could I
> identify several columns with values which are 5 times higher than the
> 99th percentile?
>
> Sample data is pasted below.
>
>> dput(df)
>
> structure(list(ad1 = c(98, 6.9, 8.1, 56, 3.9, 6.9, 6.9, 5.8,
>
> 7.2, 20.5, 9.4, 7.6, 5.3, 7.9, 62.2, 9.2, 11.9, 8.8, 23.1, 5.4,
>
> 9.4, 56, 8.6, 20.7, 21, 10.5, 5.5, 4.3, 15.8, 6.8, 10.4, 5.1),
>
>      ad2 = c(14.9, 19.7, 1, 17.7, 14.9, 13.6, 18.8, 20.9, 46,
>
>      16.5, 11.7, 1, 9.2, 23.6, 19.7, 1, 11.4, 11, 23.1, 1, 1,
>
>      8.9, 11.3, 6.4, 15.2, 1, 17.3, 10.1, 13.3, 21.3, 12.3, 15.4
>
>      ), ad3 = c(0.91, 0.95, 10.7, 4.4, 0.43, 0.8, 3.1, 1.9, 2.3,
>
>      5.6, 3.9, 7.3, 0.37, 4.1, 15.1, 21.8, 3, 0.79, 1, 4.6, 0.61,
>
>      0.46, 0.87, 23.5, 3.8, 3.1, 0.33, 1.9, 3.2, 1.7, 0.53, 62.5
>
>      ), ad4 = c(225.5, 269.7, 326, 485.4, 193.2, 274.1, 553.2,
>
>      166.8, 435.9, 433.2, 187.1, 660.4, 235.4, 356.5, 378.8, 500.5,
>
>      323.5, 327.1, 289.5, 301.2, 291.7, 333.5, 351.7, 384.1, 347,
>
>      1354, 440.4, 189.2, 381, 252.7, 391.1, 255.1), ad5 = c(337.9,
>
>      355.6, 419.5, 798.5, 225, 355.9, 394.4, 340.6, 463.9, 291.9,
>
>      312.3, 491, 290.5, 231.9, 358, 386.4, 306.7, 440.6, 297.9,
>
>      339.3, 341.1, 366.2, 325.4, 357, 412.2, 370.2, 421.3, 346.3,
>
>      289.1, 257.4, 368, 322.6), ad6 = c(64.5, 130.6, 76, 167.8,
>
>      47.3, 117, 60.7, 91.9, 221.9, 91.1, 105.1, 110.8, 64.5, 184.5,
>
>      191.6, 259.4, 879.5, 142.1, 55.3, 123.1, 62.2, 75.2, 154.6,
>
>      100.7, 93.1, 136.7, 74.3, 41.8, 110.1, 109.1, 172.5, 87.7
>
>      ), ad7 = c(128L, 987L, 158L, 124L, 137L, 215L, 141L, 98L,
>
>      291L, 261L, 106L, 137L, 141L, 159L, 221L, 108L, 123L, 107L,
>
>      137L, 175L, 257L, 97L, 168L, 145L, 147L, 188L, 145L, 128L,
>
>      153L, 187L, 123L, 354L), ad8 = c(3.26, 3.98, 2.88, 2.85,
>
>      4.17, 3.16, 3.09, 4.35, 3.46, 3.81, 3.78, 3.81, 4.17, 4.27,
>
>      4.27, 2.97, 3.43, 3.48, 3.78, 3.86, 3.11, 3.12, 3.16, 4.24,
>
>      3.81, 3.11, 5.31, 3.75, 3.78, 3.55, 4.08, 3.5), ad9 = c(433L,
>
>      211L, 66L, 173L, 224L, 466L, 224L, 273L, 94L, 321L, 160L,
>
>      107L, 121L, 186L, 455L, 80L, 897L, 186L, 285L, 134L, 107L,
>
>      355L, 261L, 249L, 332L, 107L, 273L, 107L, 160L, 535L, 160L,
>
>      121L)), .Names = c("ad1", "ad2", "ad3", "ad4", "ad5", "ad6",
>
> "ad7", "ad8", "ad9"), class = "data.frame", row.names = c(NA,
>
> -32L))
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rl at openmailbox.org  Tue Sep  9 12:53:15 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Tue, 09 Sep 2014 10:53:15 +0000
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <CAF8bMcbjCiLkHWHpqqk78jHY5PPP7Ge+zHnYsmmu8zXQUd2YLQ@mail.gmail.com>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
	<487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
	<CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>
	<6f4f6fd6eaf0164f42b958a4f4d56848@openmailbox.org>
	<CAF8bMcaXtZiLRQE55ZvuhH4XYPyBVzQneJn0KJSGBHr_V5vSDA@mail.gmail.com>
	<d4743dcf80f5d20a9e3ac5d0530ab6e3@openmailbox.org>
	<CAF8bMcbjCiLkHWHpqqk78jHY5PPP7Ge+zHnYsmmu8zXQUd2YLQ@mail.gmail.com>
Message-ID: <daa78bae9b65fb128b98396bb882c816@openmailbox.org>

On 2014-09-08 15:47, William Dunlap wrote:
> d <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
> i <- 1 # possible output of menu(unique(d$Choices))
> d[ d$Choices[i] == d$Choices, ]
> #  Choices X
> #1     One 1
> #3     One 3
> 

> testd <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
> testi <- 1 # possible output of menu(unique(d$Choices))
> testd[ testd$Choices[testi] == testd$Choices, ]
   Choices X
1     One 1
3     One 3

This instruction did not give any opportunity to enter a choice? Then 
tried:

?Choices
No documentation for 'Choices' in specified packages and libraries:
you could try '??Choices'

??Choices
Help files with alias or concept or title matching ?Choices? using
fuzzy matching:


mgcv::choose.k          Basis dimension choice for smooths
mvtnorm::GenzBretz      Choice of Algorithm and Hyper Parameters


Type '?PKG::FOO' to inspect entry 'PKG::FOO TITLE'.

Then I tried to use with my test data:

testdataextract1<-data.frame(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select 
something'))
selectionresult<-2
testdata[testdata$menu[selectionresult]==testdata$menu,]
> testdataextract1<-data.frame(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='Select 
> something'))
Select something

1: text test1
2: text test2
3: text test3

Selection: selectionresult<-2
Enter an item from the menu, or 0 to exit
Selection: testdata[testdata$menu[selectionresult]==testdata$menu,]
Enter an item from the menu, or 0 to exit
Selection: 0

Now confused by "Choices"! :) What is my error please?


From murdoch.duncan at gmail.com  Tue Sep  9 13:43:17 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 09 Sep 2014 07:43:17 -0400
Subject: [R] How to use multi paragraph comment like /*  and */ in cpp?
In-Reply-To: <6dcd4dfc-0355-43c9-9bdb-d0ccf6824dce@email.android.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
	<6dcd4dfc-0355-43c9-9bdb-d0ccf6824dce@email.android.com>
Message-ID: <540EE7D5.6070806@gmail.com>

On 08/09/2014, 11:14 PM, Jeff Newmiller wrote:
> There are no multi line comment markers in R. However, since you are always referring to RStudio you might want to look into roxygen, since their editor supports that tool.

RStudio has a command to comment a block:  it's in the Code menu.  (On
my Mac the shortcut is <unprintable><unspeakable>C :-).

Duncan Murdoch


> 
> I would also suggest making more functions that are smaller.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On September 8, 2014 7:49:32 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>>
>> Dear expeRts,
>>    I find it's terrible  when  i want to comment multi paragraph (e.g. 
>> a 30 lines function) , i have to comment each line with #,  is there
>> any good way to do that ?
>>    I investgate it, but found no easy way, may you help me ?
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com 
>> Majored in Statistics from SJTU
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Tue Sep  9 15:36:59 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 9 Sep 2014 15:36:59 +0200
Subject: [R] How to use multi paragraph comment like /*  and */ in cpp?
In-Reply-To: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
Message-ID: <21519.635.865385.564927@stat.math.ethz.ch>

>>>>> "PS" == PO SU <rhelpmaillist at 163.com>
>>>>>     on Tue, 9 Sep 2014 10:49:32 +0800 writes:

    PS> Dear expeRts, ?? I find it's terrible? when? i want to
    PS> comment multi paragraph (e.g.? a 30 lines function) , i
    PS> have to comment each line with #,? is there any good way
    PS> to do that ?  ?? I investgate it, but found no easy way,
    PS> may you help me ?

Even though I can easily mark such a block and use the general
emacs  comment key    M-;
to comment each of those lines,
I often prefer

 if(FALSE) {

   ...
   ...
   ...

 }

which in the case of a single function definition which is only
one R expression can even do without the braces  {, }
and hence very easily activated/deactivated.


From wdunlap at tibco.com  Tue Sep  9 17:48:12 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 9 Sep 2014 08:48:12 -0700
Subject: [R] using edit to extract codes from vignette failed
In-Reply-To: <7f23b21a.4149.148582ae71a.Coremail.rhelpmaillist@163.com>
References: <mailman.15.1410084009.23748.r-help@r-project.org>
	<928C4F7877280844B906D12D63A3F15B01D551871E1A@HERMES8.ds.leeds.ac.uk>
	<5b76dcfd.cdc5.1485611bd15.Coremail.rhelpmaillist@163.com>
	<CAF8bMcZMDpMw_LNqnFAD_qsSTNYZ9n8BSxn2Zpzmw5FoRd6d5g@mail.gmail.com>
	<7f23b21a.4149.148582ae71a.Coremail.rhelpmaillist@163.com>
Message-ID: <CAF8bMcaEm5XWKG86eGJckD9eVcWPq03GvHP8=4wgx46d2m1Vqw@mail.gmail.com>

>  i don't know how to report a bug to Rstudio

Have you tried clicking on 'Help', then on 'RStudio Support' in the
menu that pops up?

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Sep 8, 2014 at 7:07 PM, PO SU <rhelpmaillist at 163.com> wrote:
>
>
> OK, i get it, i should set the editor argument , i don't know how to report a bug to Rstudio, may you do that  ?
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
>
> At 2014-09-09 00:41:33, "William Dunlap" <wdunlap at tibco.com> wrote:
>>Complain to the RStudio people - RStudio defines its own
>>options("editor") which is not completely compatible with R's
>>option(editor="internal").  If you set options(editor="internal") in
>>RStudio then you can look at the code in the vignette. (I tried with
>>last year's RStudio 0.98.501 and this may have been fixed by now.)
>>Bill Dunlap
>>TIBCO Software
>>wdunlap tibco.com
>>
>>
>>On Mon, Sep 8, 2014 at 9:21 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>>
>>> Tks for correcting me not using the file argument, but the codes you supply  seem still not work.
>>>
>>> edit(vignette("grobs",package = "grid")) can't work.
>>> I am using win7, the latest version of Rstudio which using R.3.1.1.The error is:
>>> Error in editor(file = file, title = title) :
>>>   argument "name" is missing, with no default
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>>
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>>
>>>
>>>
>>> At 2014-09-08 05:46:39, "Karl Ropkins" <K.Ropkins at its.leeds.ac.uk> wrote:
>>>>Try:
>>>>
>>>>edit(vignette("grobs",package = "grid"))
>>>>
>>>>(edit is a method. It looks at the class of the first entry, name, to identify which method to use. See ?edit.  You want it to use edit.vignette, so you need to drop 'file=' so you pass the vignette to edit as the first argument or name=. Then edit will pass it to edit.vignette and it'll work. Or go direct: edit.vignette(vignette("grobs",package = "grid")). See ?vignette. Maybe the use of name as the first argument of a method is a little misleading? But you can work out what is going if you work through the help documentation.)
>>>>
>>>>Karl
>>>>
>>>>
>>>>Message: 9
>>>>Date: Sun, 7 Sep 2014 17:06:44 +0800 (CST)
>>>>From: "PO SU" <rhelpmaillist at 163.com>
>>>>To: "R. Help" <r-help at r-project.org>
>>>>Subject: [R]   using  edit to extract codes from vignette failed
>>>>Message-ID: <4d3c1c8a.1c96.1484f5d8d31.Coremail.rhelpmaillist at 163.com>
>>>>Content-Type: text/plain; charset=UTF-8
>>>>
>>>>Dear expeRts,
>>>>? ? When i using the following code, i get a error as follows:
>>>>
>>>>?edit(file=vignette("grobs",package = "grid"))
>>>>Error in edit.vignette(file = vignette("grobs", package = "grid")) :?
>>>>? argument "name" is missing, with no default
>>>>
>>>>I investigated edit function, but still can't ?get codes from a vignette, May you help me?
>>>>
>>>>--
>>>>
>>>>PO SU
>>>>mail: desolator88 at 163.com
>>>>Majored in Statistics from SJTU
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From roger.bos at rothschild.com  Tue Sep  9 18:37:45 2014
From: roger.bos at rothschild.com (Bos, Roger)
Date: Tue, 9 Sep 2014 16:37:45 +0000
Subject: [R] How to use multi paragraph comment like /*  and */ in cpp?
In-Reply-To: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
Message-ID: <0765308CD028654885F30322557308D81ECAE4B2@NYCSM0208.rth.ad.rothschild.com>

What I do in cases like that is wrap the code in a FALSE statement so it won't get executed:  its easy to add and remove as needed.

If (FALSE) {

...Code to exclude....

}



***************************************************************
This message and any attachments are for the named person's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies. You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of PO SU
Sent: Monday, September 08, 2014 10:50 PM
To: R. Help
Subject: [R] How to use multi paragraph comment like /* and */ in cpp?


Dear expeRts,
   I find it's terrible  when  i want to comment multi paragraph (e.g.  a 30 lines function) , i have to comment each line with #,  is there any good way to do that ?
   I investgate it, but found no easy way, may you help me ?





--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From eliza_botto at hotmail.com  Tue Sep  9 19:08:50 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 9 Sep 2014 17:08:50 +0000
Subject: [R] splitting data
In-Reply-To: <CADv2QyFwJLxLmQXpR=QWXjg6_n53bF5t5=80MsdtCCJ8ccvWqw@mail.gmail.com>
References: <BLU170-W92BD6A86422EC80D064ED489C10@phx.gbl>,
	<CADv2QyFwJLxLmQXpR=QWXjg6_n53bF5t5=80MsdtCCJ8ccvWqw@mail.gmail.com>
Message-ID: <BLU170-W10157E6054C86D41B36EE2989CE0@phx.gbl>

Dear Davis, Dennis and John,
I am thankyou that you replied. I'll take care of it in future. 

Eliza

> Date: Mon, 8 Sep 2014 17:36:30 -0700
> Subject: Re: [R] splitting data
> From: djmuser at gmail.com
> To: eliza_botto at hotmail.com
> 
> Hi Eliza:
> 
> Here are a few potential solutions. Given that you have 100 years of
> monthly data, it's likely that a package such as dplyr or data.table
> would be significantly faster than some of the alternatives offered to
> date. I'm assuming the game is to generate the monthly sums for each
> of A, B, C below.
> 
> # Fake data set intended to replicate four years of data
> # To keep it simple, I only use 30 days a month.
> d <- data.frame(expand.grid(year = 1961:1964, month = seq(12), day = seq(30)),
>                 A = rpois(1440, 10), B = rpois(1440, 15), C = rpois(1440, 25))
> 
> 
> # plyr package solution - colwise() applies the same function to each
> # of the variables named within .()
> 
> library(plyr)
> ymsums <- ddply(d, .(year, month), colwise(sum, .(A, B, C)))
> 
> 
> 
> # dplyr package solution using the new piping operator %>% from the
> # magrittr package. (Think of  a %>% b as: take the data in a and
> # then call function b on it. This idea can be strung in sequence:
> # the term on the left of %>% supplies the input data for the
> # function call on the right.)
> 
> library(dplyr)
> # library(magrittr)
> 
> ymsums2 <- d %>% group_by(year, month) %>%
>                  summarise(Atot = sum(A), Btot = sum(B), Ctot = sum(C))
> 
> 
> 
> # data.table package solution
> 
> library(data.table)
> 
> dt <- data.table(d, key = c("year", "month"))
> ymsums3 <- dt[, list(Atot = sum(A), Btot = sum(B), Ctot = sum(C)),
>                 by = key(dt)]
> 
> head(ymsums)
> head(ymsums2)
> head(ymsums3)
> 
> dplyr was about 2.5 times faster than data.table and almost 30 times
> faster than plyr for this example. To be honest, though, I don't think
> I used the most efficient code for either of dplyr or data.table, so
> the relative timings may be somewhat misleading. OTOH, for this 1440
> line fake data set, dplyr processed it in 0.1 sec. with the code I
> used and data.table took 0.24 sec. If your data frame is 100 years in
> length, it should be approximately 25 times the length of mine, so
> we'd be talking about 2.5 sec with dplyr and somewhere between 3.5 - 5
> sec. with data.table, since the advantage of the way it sets keys
> improves processing speed in a relative sense as the size of the data
> set grows. That's not bad no matter which one you choose.
> 
> BTW, it's possible to do it with reshape2 as follows:
> 
> library(reshape2)
> 
> # stack variables A-C, producing the long form
> dm <- melt(d, id = c("year", "month", "day"))
> 
> # reshape
> drt <- dcast(dm, year + month ~ variable, fun.aggregate = sum,
>                  value.var = "value")
> head(drt)
> 
> This is approximately 4 times faster than the plyr solution and about
> 3 times slower than data.table. This is about as fast as you can get
> it in reshape2.
> 
> HTH,
> Dennis
> 
> PS: I agree with David about the HTML postings. You've been on this
> list long enough to know what is expected. All it takes is a change or
> two in the settings of your mailing client. I use gmail, and one
> change of setting is all it took for me...five years ago, the one and
> only time I was admonished to do so.
> 
> On Mon, Sep 8, 2014 at 12:08 PM, eliza botto <eliza_botto at hotmail.com> wrote:
> > Dear R members,
> >
> > I have this data frame of 100 years in the following format
> >
> > year            month       day         A           B           C         D
> >
> > where  A,B,C and D are item number sold each day. I am trying
> >
> > 1-split the data w.r.t the monthly values for each year
> >
> > 2-then, sum them up
> >
> > I am pasting here just a part of data to make it more clearer
> >
> > structure(list(year = c(1961, 1961, 1961, 1961, 1961, 1961, 1961,
> > 1961, 1961, 1961, 1961, 1961), month = c(1, 1, 1, 1, 1, 1, 1,
> > 1, 1, 1, 1, 1), day = 1:12, A = 1:12, B = 3:14, C = 6:17, D = 16:27), .Names = c("year",
> > "month", "day", "A", "B", "C", "D"), row.names = c(NA, 12L), class = "data.frame")
> >
> > I initially tried to use "dcast" command but for no use.
> >
> > Your kind help is needed.
> >
> > Thanks in advance
> >
> > Eliza
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Sep  9 19:37:12 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 9 Sep 2014 17:37:12 +0000
Subject: [R] KDE routines for data that is aggregated
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F965BC@mb02.ads.tamu.edu>

If the x and y values are regularly spaced, you could use contour() or persp() to plot the densities. If they are not, you can use density(), loess(), gam(), kriging another function to estimate a smooth surface for the values and then estimate the values over a regular grid and then plot with contour, etc.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Saptarshi Guha
Sent: Monday, September 8, 2014 6:57 PM
To: R-help at r-project.org
Subject: [R] KDE routines for data that is aggregated

Hello,
Couldn't think of a better subject line. Rather than a matrix like

x,y
..,..
.,..

I have a matrix like
x,y,n,
..,..,..,
..,..,..

and so on. Also, sum(n) is roughly few hundred million. The number of rows
is <1MM

Are they routines to fit a 2d kde estimate to data provided in this form?
I can sample from the data according to weights given by 'n' but i am
curious if there is something that can use all the data when given a
structure of this form.

Regards
Saptarshi

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gjalt-jorn at behaviorchange.eu  Tue Sep  9 07:41:48 2014
From: gjalt-jorn at behaviorchange.eu (Gjalt-Jorn Peters)
Date: Tue, 09 Sep 2014 07:41:48 +0200
Subject: [R] How to use multi paragraph comment like /* and */ in cpp?
In-Reply-To: <CAAcyNCy8OGiMdM9YeWVDDJNnZawXc51zZ3q-wSOj3jYXoeRjVw@mail.gmail.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
	<CAAcyNCy8OGiMdM9YeWVDDJNnZawXc51zZ3q-wSOj3jYXoeRjVw@mail.gmail.com>
Message-ID: <540E931C.8000307@behaviorchange.eu>

In R-studio, you can also select whatever you want to comment out, and 
press CTRL-SHIFT-C to comment the selection in one go.
To uncomment it all in one go again, you can select it again and press 
CTRL-SHIFT-C again.

Gjalt-Jorn

On 2014-09-09 5:51, Pascal Oettli wrote:
> A workaround is to escape the evaluation of the lines. For example:
>
> tt <- 0
> while(tt > 0){
>    cat('rr\n')
> }
>
> Regards,
> Pascal
>
> On Tue, Sep 9, 2014 at 11:49 AM, PO SU <rhelpmaillist at 163.com> wrote:
>> Dear expeRts,
>>     I find it's terrible  when  i want to comment multi paragraph (e.g.  a 30 lines function) , i have to comment each line with #,  is there any good way to do that ?
>>     I investgate it, but found no easy way, may you help me ?
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From norbert at doerrer.at  Tue Sep  9 16:42:11 2014
From: norbert at doerrer.at (=?UTF-8?Q?Norbert_D=C3=B6rrer?=)
Date: Tue, 9 Sep 2014 16:42:11 +0200
Subject: [R] marketing-questionnaire with split-design
Message-ID: <CAEzmP8i7x8eE9akGxpL+7Z4YySM5Jhx9Tbz1Q=ThqN2kHsaP1A@mail.gmail.com>

Dear Experts

I'm quite new to the world of R; so maybe my question is kind of
beginners...

I am right now trying to analyse questionnaire data (CAWI) for producing a
image/positioning map of the competitors of my company; when programming
the CAWI, a split design was needed; every respondent had to answer a
couple of multiple-choice questions (on reputation of company, image,
sympathy etc.; 1 "perfect" to 5 "absolutely not perfect") for two companies
only - out of a list of several companies; companies were chosen randomly.

So what I have now is two variables that tell me which two companies the
respondent was actually evaluating...
Company 1:      A, B, C, D, E, F or G
Company 2:      A, B, C, D, E, F or G

... and of course several image-related variables:
reputation of company 1:  3,4,2,3,5,1,2,3,4,2,3,1,5 and so on
reputation of company 2:  5,2,3,4,2,5,1,2,3,2,4,21 and so on
image of company 1:        2,4,3,5,2,3,4,1,2,5,3,4,2 and so on
image of company 2:        3,4,5,2,5,4,5,3,4,2,5,1,2 and so on
sympathy of company 1:  1,5,3,4,2,5,3,4,1,2,3,4,5 and so on
sympathy of company 2:   5,5,4,5,3,3,4,3,3,3,4,2,5 and so on
etc.


But what I need in order to do proper calculations is one
Reputation/Image/Sympathy-Variable for every single company, like this:
reputation of Company A: e.g. 3,4,3,5,NA,3,NA,5,2,1,NA,NA
reputation of Company B: e.g. NA,4,3,5,NA,3,NA,5,2,1,NA
reputation of Company C and so on
image of Company A:...
image of Company B :...
image of Company C and so on
sympathy of Company A:...
sympathy of Company B :...
sympathy of Company C and so on

So I need some syntax to compute a new variable  e.g. "reputation_CompanyA"
that contains the values of "reputation of company 1" whenever "Company
1"=A and that contains the values of "reputation of company 2" whenever
"Company 2"=A... else is of course missing values!

The solution has to has something to do with loops and flow control, but I
really can't solve this puzzle.

Thanks for your help and best regards
Norbert

	[[alternative HTML version deleted]]


From raspbian at tanucoo.com  Tue Sep  9 18:33:43 2014
From: raspbian at tanucoo.com (Subba Rao)
Date: Tue, 09 Sep 2014 18:33:43 +0200
Subject: [R] R, Big Data and books
Message-ID: <540F2BE7.60301@tanucoo.com>

Hi,

I am interested in R programming in the Big Data space.  Are there any
books that would be a good starting point for this career path? 
Predictive analysis is also an area I am interested in.

Thank you in advance for any information and help.

Subba Rao


From sudhanshu.d at sonata-software.com  Tue Sep  9 07:57:47 2014
From: sudhanshu.d at sonata-software.com (anshuji)
Date: Mon, 8 Sep 2014 22:57:47 -0700 (PDT)
Subject: [R] Affinity Analysis at Product Category Level
Message-ID: <25DA9F810428CF40A1A6FBC5ECD7BF8BD6DEE5@BGLBG4Ex10MBX01>


Hi - Need help to do product affinity analysis for a Retailer. Products are categorized into categories such as say Baby Care, Male Hair Care, Female Hair Care etc. I can do affinity analysis at the product level using Apriori algorithm. I get the support, confidence and lift and using this I get the product affinity.

My objective is to tell that buying a product from say Category A means that there is chance that products from Category B also will be bought. However, I might not be able to apply same principle that I applied for individual products to Product Categories also. The reason is that in a customer's basket, there can be say 5 products of say Category A and just 1 product of category B, and in another transaction there might be 10 Category products and 4 Category B products and in another there might be 2 products of Categories A and B. There can be a similar imbalance across categories across transactions. In such a scenario, how do we perform affinity analysis.

Thanks in advance


Disclaimer: "The materials contained in this email and any attachments may contain confidential or legally privileged information. The information contained in this communication is intended solely for the use of the individual or entity to whom it is addressed and others authorized to receive it. If you are not the intended recipient you are hereby notified that any disclosure, copying, distribution or taking any action in reliance on the contents of this information is strictly prohibited and may be unlawful. If you have received this communication in error, please notify us immediately by responding to this email and then delete it from your system. Sonata is neither liable for the proper and complete transmission of the information contained in this communication nor for any delay in its receipt"




--
View this message in context: http://r.789695.n4.nabble.com/Affinity-Analysis-at-Product-Category-Level-tp4696681.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From sudhanshu.d at sonata-software.com  Tue Sep  9 10:42:03 2014
From: sudhanshu.d at sonata-software.com (anshuji)
Date: Tue, 9 Sep 2014 01:42:03 -0700 (PDT)
Subject: [R] Sentence Splitting using R's openNLP library is not efficient
Message-ID: <25DA9F810428CF40A1A6FBC5ECD7BF8BD6DF49@BGLBG4Ex10MBX01>

Please suggest any efficient way/code of splitting text into sentences in R.
Currently, I'm using openNLP library for the same, it is taking several hours to process 8,000+ records of twitter post/comments.

Below is my R code for same:

options(java.parameters = "-Xmx4g")

library("NLP"); library("openNLPdata"); library("openNLP")
sentence_token_annotator <- Maxent_Sent_Token_Annotator()
convert_text_to_sentences <- function(text) {
text <- as.String(text)
sentence.boundaries <- annotate(text, sentence_token_annotator)
sentences <- text[sentence.boundaries]
return(sentences)
}

system.time(textofcomment_list <- lapply(data_all$TEXT, convert_text_to_sentences))

Thanks in advance

Disclaimer: "The materials contained in this email and any attachments may contain confidential or legally privileged information. The information contained in this communication is intended solely for the use of the individual or entity to whom it is addressed and others authorized to receive it. If you are not the intended recipient you are hereby notified that any disclosure, copying, distribution or taking any action in reliance on the contents of this information is strictly prohibited and may be unlawful. If you have received this communication in error, please notify us immediately by responding to this email and then delete it from your system. Sonata is neither liable for the proper and complete transmission of the information contained in this communication nor for any delay in its receipt"




--
View this message in context: http://r.789695.n4.nabble.com/Sentence-Splitting-using-R-s-openNLP-library-is-not-efficient-tp4696694.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Tue Sep  9 14:49:20 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Tue, 9 Sep 2014 14:49:20 +0200
Subject: [R] How to use multi paragraph comment like /* and */ in cpp?
In-Reply-To: <540EE7D5.6070806@gmail.com>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
	<6dcd4dfc-0355-43c9-9bdb-d0ccf6824dce@email.android.com>
	<540EE7D5.6070806@gmail.com>
Message-ID: <CAHuTOvo0M7LhGvHUAzQLFkD6rUj1HV6FeZVPTqXQBP-HM+hEfg@mail.gmail.com>

One way I know to do this is (in bash) to use a dummy variable and make the
comment a multiline character string:

dummy <- c("
This is my multiline
comment or code block.
")

or if printing does not disturb you, just use:

"
...
"

Use ' if you have " in the block.
Other workarounds are here, which you find when using a search engine:
http://stackoverflow.com/questions/1231195/multiline-comment-workarounds

Hope this helps.

@Duncan: sorry sending the mail to you twice.

Sven

On 9 September 2014 13:43, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 08/09/2014, 11:14 PM, Jeff Newmiller wrote:
>> There are no multi line comment markers in R. However, since you are always referring to RStudio you might want to look into roxygen, since their editor supports that tool.
>
> RStudio has a command to comment a block:  it's in the Code menu.  (On
> my Mac the shortcut is <unprintable><unspeakable>C :-).
>
> Duncan Murdoch
>
>
>>
>> I would also suggest making more functions that are smaller.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 8, 2014 7:49:32 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>>>
>>> Dear expeRts,
>>>    I find it's terrible  when  i want to comment multi paragraph (e.g.
>>> a 30 lines function) , i have to comment each line with #,  is there
>>> any good way to do that ?
>>>    I investgate it, but found no easy way, may you help me ?
>>>
>>>
>>>
>>>
>>>
>>> --
>>>
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fredj.jawadi at france-bs.com  Tue Sep  9 22:48:26 2014
From: fredj.jawadi at france-bs.com (JAWADI Fredj)
Date: Tue, 9 Sep 2014 20:48:26 +0000
Subject: [R] Import data from Excel to R
Message-ID: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>

Hi
I am a New user of R.
Please, how to import data from Excel to R?
Thanks,
Best regards,
Fredj,


	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Sep 10 00:51:45 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 9 Sep 2014 18:51:45 -0400
Subject: [R] Import data from Excel to R
In-Reply-To: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
References: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
Message-ID: <CA+vqiLFnDx94PJB71Fx37m12hRDxuCDzqqXtXV_hyRsrnbfy8w@mail.gmail.com>

Read the manual.

http://cran.r-project.org/doc/manuals/r-release/R-data.html#Reading-Excel-spreadsheets

Best,
Ista
On Sep 9, 2014 6:39 PM, "JAWADI Fredj" <fredj.jawadi at france-bs.com> wrote:

> Hi
> I am a New user of R.
> Please, how to import data from Excel to R?
> Thanks,
> Best regards,
> Fredj,
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Peter.Alspach at plantandfood.co.nz  Wed Sep 10 00:56:54 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Wed, 10 Sep 2014 10:56:54 +1200
Subject: [R] Import data from Excel to R
In-Reply-To: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
References: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC2283B407B6@AKLEXM01.PFR.CO.NZ>

Tena koe Fredj

There are lots of ways, depending on your precise task and preference.  Have you Googled 'Import data from Excel to R'?  That will bring up lots of relevant hits, including the data import/export manual that ships with R.

FWIW, I use RODBC and have written a simple wrapper to do the most standard tasks (which I can share if you like) ....

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of JAWADI Fredj
Sent: Wednesday, 10 September 2014 8:48 a.m.
To: r-help at R-project.org
Subject: [R] Import data from Excel to R

Hi
I am a New user of R.
Please, how to import data from Excel to R?
Thanks,
Best regards,
Fredj,


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From ggrothendieck at gmail.com  Wed Sep 10 01:03:38 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 9 Sep 2014 19:03:38 -0400
Subject: [R] Import data from Excel to R
In-Reply-To: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
References: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
Message-ID: <CAP01uRnCZ_HxVEkNGjw7E7kbzmMOY-=jwg9vj=RgnHW7JMRzkQ@mail.gmail.com>

On Tue, Sep 9, 2014 at 4:48 PM, JAWADI Fredj <fredj.jawadi at france-bs.com> wrote:
> Hi
> I am a New user of R.
> Please, how to import data from Excel to R?
> Thanks,
> Best regards,
> Fredj,
>

There are some ways listed here:
https://web.archive.org/web/20131109195709/http://rwiki.sciviews.org/doku.php?id=tips:data-io:ms_windows&s=excel


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pdalgd at gmail.com  Wed Sep 10 01:07:23 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 10 Sep 2014 01:07:23 +0200
Subject: [R] Why does debugging  print()  change output of function?
In-Reply-To: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
References: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
Message-ID: <58B41C11-4B60-4810-A6D5-A6C58F0BC838@gmail.com>


On 07 Sep 2014, at 00:31 , David Winsemius <dwinsemius at comcast.net> wrote:

> The goal: 
>   to create a function modeled after `subset` (notorious for its non-standard evaluation) that will take a series of logical tests as unqiuoted expressions to be evaluated in the framework of a dataframe environment and return a dataframe of logicals:
...

A belated peep from the author of subset(): Don't!

I think we learned the hard way by now that it is much easier to pass unevaluated expressions in the shape of formula objects or maybe expression objects. Lots of pain can be avoided by slipping in a simple "~".

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Wed Sep 10 07:13:52 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 Sep 2014 22:13:52 -0700
Subject: [R] Why does debugging  print()  change output of function?
In-Reply-To: <58B41C11-4B60-4810-A6D5-A6C58F0BC838@gmail.com>
References: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
	<58B41C11-4B60-4810-A6D5-A6C58F0BC838@gmail.com>
Message-ID: <D4EF764B-8255-4EBF-AC42-F3D08668C298@comcast.net>


On Sep 9, 2014, at 4:07 PM, peter dalgaard wrote:

>
> On 07 Sep 2014, at 00:31 , David Winsemius <dwinsemius at comcast.net>  
> wrote:
>
>> The goal:
>> to create a function modeled after `subset` (notorious for its non- 
>> standard evaluation) that will take a series of logical tests as  
>> unquoted expressions to be evaluated in the framework of a  
>> dataframe environment and return a dataframe of logicals:
> ...
>
> A belated peep from the author of subset(): Don't!
>
> I think we learned the hard way by now that it is much easier to  
> pass unevaluated expressions in the shape of formula objects or  
> maybe expression objects. Lots of pain can be avoided by slipping in  
> a simple "~".

It's taken me several years to understand why you are probably correct  
in this regard. I needed to learn that `~` is actually a function that  
creates a language object.

 > is.function(`~`)
[1] TRUE
 > is.language( ~ x > 5 & x < 10)
[1] TRUE

... and that it's rather easy to extract the object somewhat like but  
not really an expression embedded in such an object:

 > is.expression( ~ x > 5 & x < 10)
[1] FALSE

 > is.call( (~ x > 5 & x < 10)[2] )
[1] TRUE

The task of learning the various types of language objects is not an  
easy one.

-- 

David Winsemius, MD
Alameda, CA, USA


From yuan.hypnos.luo at gmail.com  Wed Sep 10 07:56:04 2014
From: yuan.hypnos.luo at gmail.com (Yuan Luo)
Date: Wed, 10 Sep 2014 01:56:04 -0400
Subject: [R] multi-threading
Message-ID: <CAMY509=xaGBT=h+Wwsa57vfZw9HosZfC4OOiOTAr7-kEQHTZpQ@mail.gmail.com>

Hi,
I am merging large data frames and it would be great if I can run merge in
multi-threading/parallel mode. Can someone point me to the right way to do
it?

Best,
Yuan

	[[alternative HTML version deleted]]


From kridox at ymail.com  Wed Sep 10 08:20:37 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 10 Sep 2014 15:20:37 +0900
Subject: [R] multi-threading
In-Reply-To: <CAMY509=xaGBT=h+Wwsa57vfZw9HosZfC4OOiOTAr7-kEQHTZpQ@mail.gmail.com>
References: <CAMY509=xaGBT=h+Wwsa57vfZw9HosZfC4OOiOTAr7-kEQHTZpQ@mail.gmail.com>
Message-ID: <CAAcyNCxHvvoeJ3DGz5g35qAbnKqN63QejVBC-04xNi=X8_6mRQ@mail.gmail.com>

Hi Yuan,

You can start reading the following site:
http://cran.r-project.org/web/views/HighPerformanceComputing.html

Regards,
Pascal

On Wed, Sep 10, 2014 at 2:56 PM, Yuan Luo <yuan.hypnos.luo at gmail.com> wrote:
> Hi,
> I am merging large data frames and it would be great if I can run merge in
> multi-threading/parallel mode. Can someone point me to the right way to do
> it?
>
> Best,
> Yuan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From rhelpmaillist at 163.com  Wed Sep 10 08:30:58 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Wed, 10 Sep 2014 14:30:58 +0800 (CST)
Subject: [R] How to use multi paragraph comment like /* and */ in cpp?
In-Reply-To: <540E931C.8000307@behaviorchange.eu>
References: <3b022782.3f5c.1485850f0bc.Coremail.rhelpmaillist@163.com>
	<CAAcyNCy8OGiMdM9YeWVDDJNnZawXc51zZ3q-wSOj3jYXoeRjVw@mail.gmail.com>
	<540E931C.8000307@behaviorchange.eu>
Message-ID: <54852ce3.1e999.1485e4204ff.Coremail.rhelpmaillist@163.com>


Tks for all your help,? finally i choose the way in Rstudio ctrl+shift+C, and do twice to cancel those comments. It's enough for me now. BTW, I also like the way:
if(FALSE) {}?? :) 



--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-10 02:15:49, "Gjalt-Jorn Peters" <gjalt-jorn at behaviorchange.eu> wrote:
>In R-studio, you can also select whatever you want to comment out, and 
>press CTRL-SHIFT-C to comment the selection in one go.
>To uncomment it all in one go again, you can select it again and press 
>CTRL-SHIFT-C again.
>
>Gjalt-Jorn
>
>On 2014-09-09 5:51, Pascal Oettli wrote:
>> A workaround is to escape the evaluation of the lines. For example:
>>
>> tt <- 0
>> while(tt > 0){
>>    cat('rr\n')
>> }
>>
>> Regards,
>> Pascal
>>
>> On Tue, Sep 9, 2014 at 11:49 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>> Dear expeRts,
>>>     I find it's terrible  when  i want to comment multi paragraph (e.g.  a 30 lines function) , i have to comment each line with #,  is there any good way to do that ?
>>>     I investgate it, but found no easy way, may you help me ?
>>>
>>>
>>>
>>>
>>>
>>> --
>>>
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From rhelpmaillist at 163.com  Wed Sep 10 09:21:12 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Wed, 10 Sep 2014 15:21:12 +0800 (CST)
Subject: [R]   some question about  vector[-NULL]
Message-ID: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>


Dear expeRts,
????? I have?some programming questions about NULL in R.There are listed as follows:
1. I find i can't let a list have a element NULL:
a<-list()
a$ress<-1
a$res<-NULL
a
str(a)

How can i know i have?a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
2.The most important thing:
a<-1:10
b<-NULL or 1
a<-c(a,b) will work so i don't need to know whether b is null or not,but:
a[-NULL] can't work!!? i just need a[-NULL]==a , how can i reach this purpose?




???? 
??? 





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From petr.pikal at precheza.cz  Wed Sep 10 12:13:55 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 10 Sep 2014 10:13:55 +0000
Subject: [R] some question about  vector[-NULL]
In-Reply-To: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1696@SRVEXCHMBX.precheza.cz>

Hi

I am puzzled about what do you want?

You was discouraged using $ operator due to partial matching, however you still use it.

In your example you do not have named element being NULL. Just check it yourself.

> a<-list()
> a$ress<-1
> a$res<-NULL
> a
$ress
[1] 1

> str(a)
List of 1
 $ ress: num 1

For working with lists lapply/sapply is the preferred way.

> a<-vector("list",3)
> a[[2]]<-1:10
> a
[[1]]
NULL

[[2]]
 [1]  1  2  3  4  5  6  7  8  9 10

[[3]]
NULL

> is.null(a)
[1] FALSE
> lapply(a, is.null)
[[1]]
[1] TRUE

[[2]]
[1] FALSE

[[3]]
[1] TRUE


What do you expect from your second example? a is numeric vector b is NULL, c(a,b) is vector.

> a[-NULL]
Error in -NULL : invalid argument to unary operator

gives an error.

OK, let me polish my crystal ball.
You want to get rid of all list elements which are null?

a[unlist(lapply(a, function(x) !is.null(x)))]

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of PO SU
> Sent: Wednesday, September 10, 2014 9:21 AM
> To: R. Help
> Subject: [R] some question about vector[-NULL]
>
>
> Dear expeRts,
>       I have some programming questions about NULL in R.There are
> listed as follows:
> 1. I find i can't let a list have a element NULL:
> a<-list()
> a$ress<-1
> a$res<-NULL
> a
> str(a)
>
> How can i know i have a named element but it is NULL, not just get
> a$xxxx,a$iiii,a$oooo there all get NULL
> 2.The most important thing:
> a<-1:10
> b<-NULL or 1
> a<-c(a,b) will work so i don't need to know whether b is null or
> not,but:
> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this
> purpose?
>
>
>
>
>
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Sep 10 12:45:26 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 10 Sep 2014 10:45:26 +0000
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <daa78bae9b65fb128b98396bb882c816@openmailbox.org>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
	<487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
	<CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>
	<6f4f6fd6eaf0164f42b958a4f4d56848@openmailbox.org>
	<CAF8bMcaXtZiLRQE55ZvuhH4XYPyBVzQneJn0KJSGBHr_V5vSDA@mail.gmail.com>
	<d4743dcf80f5d20a9e3ac5d0530ab6e3@openmailbox.org>
	<CAF8bMcbjCiLkHWHpqqk78jHY5PPP7Ge+zHnYsmmu8zXQUd2YLQ@mail.gmail.com>
	<daa78bae9b65fb128b98396bb882c816@openmailbox.org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE16F7@SRVEXCHMBX.precheza.cz>

Hi

> Now confused by "Choices"! :) What is my error please?

Your main error is that you do not read help which was offered by Wiliam. Choices is not a function it is name of a variable. You can call it e.g. ctsanddogs if you wish.

see in line

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of rl at openmailbox.org
> Sent: Tuesday, September 09, 2014 12:53 PM
> To: William Dunlap
> Cc: r-help at r-project.org
> Subject: Re: [R] sequential input script dataframe process
> functionality
>
> On 2014-09-08 15:47, William Dunlap wrote:
> > d <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
> > i <- 1 # possible output of menu(unique(d$Choices))
> > d[ d$Choices[i] == d$Choices, ]
> > #  Choices X
> > #1     One 1
> > #3     One 3
> >
>
> > testd <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
> > testi <- 1 # possible output of menu(unique(d$Choices))
> > testd[ testd$Choices[testi] == testd$Choices, ]
>    Choices X
> 1     One 1
> 3     One 3
>
> This instruction did not give any opportunity to enter a choice? Then
> tried:

Why do you think so? Did you try it? Follow Wiliam's advice

d <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
i <- menu(unique(d$Choices))

now i is set to some value according your choice

d[ d$Choices[i] == d$Choices, ]

selects items which correspond to chosen value.

BTW, did you read R-intro? If not, why not?

Regards
Petr

>
> ?Choices
> No documentation for 'Choices' in specified packages and libraries:
> you could try '??Choices'
>
> ??Choices
> Help files with alias or concept or title matching ?Choices? using
> fuzzy matching:
>
>
> mgcv::choose.k          Basis dimension choice for smooths
> mvtnorm::GenzBretz      Choice of Algorithm and Hyper Parameters
>
>
> Type '?PKG::FOO' to inspect entry 'PKG::FOO TITLE'.
>
> Then I tried to use with my test data:
>
> testdataextract1<-
> data.frame(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='S
> elect
> something'))
> selectionresult<-2
> testdata[testdata$menu[selectionresult]==testdata$menu,]
> > testdataextract1<-
> data.frame(menu(c(unique(levels(testdata[,1]))),graphics=FALSE,title='S
> elect
> > something'))
> Select something
>
> 1: text test1
> 2: text test2
> 3: text test3
>
> Selection: selectionresult<-2
> Enter an item from the menu, or 0 to exit
> Selection: testdata[testdata$menu[selectionresult]==testdata$menu,]
> Enter an item from the menu, or 0 to exit
> Selection: 0
>
> Now confused by "Choices"! :) What is my error please?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Wed Sep 10 12:45:59 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 10 Sep 2014 06:45:59 -0400
Subject: [R] some question about  vector[-NULL]
In-Reply-To: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
Message-ID: <54102BE7.6080002@gmail.com>

On 10/09/2014, 3:21 AM, PO SU wrote:
> 
> Dear expeRts,
>       I have some programming questions about NULL in R.There are listed as follows:
> 1. I find i can't let a list have a element NULL:
> a<-list()
> a$ress<-1
> a$res<-NULL
> a
> str(a)

You can do it using

a <- list(ress = 1, res = NULL)

> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL

That's a little harder.  There are a few ways:

"res" %in% names(a) & is.null(a[["res"]])

or

identical(a["res"], list(res = NULL))

or

is.null(a[[2]])

should all work.

Generally because of the special handling needed, it's a bad idea to try
to store NULL in a list.

> 2.The most important thing:
> a<-1:10
> b<-NULL or 1
> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?

Using !, and a logical test, e.g.

a[!nullentry(a)]

where nullentry() is a function based on one of the tests above, but
applied to all entries.

Duncan Murdoch


From angel.rodriguez at matiainstituto.net  Wed Sep 10 12:37:27 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Wed, 10 Sep 2014 12:37:27 +0200
Subject: [R] R, Big Data and books
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B272@MATIAEXCH.matiaf.local>

>From an email list:

"R is well known in the world of Big Data and is increasing in popularity. A number of very useful resources are available for anyone undertaking data mining in R.
For example, Luis Torgo has just published a book called Data Mining with R ? learning with case studies (Torgo, Luis. Data Mining with R. ), and presents a set of four case studies with accompanying data sets and code which the interested student can work through. Torgo?s book provides the usual analytic and graphical techniques used every day by data miners, including specialized visualization techniques, dealing with missing values, developing prediction models, and methods for evaluating the performance of your models.
Also of interest to the data miner is the Rattle (R Analytical Tool to Learn Easily) GUI. Rattle is a data mining facility for analyzing very large data sets. It provides many useful statistical and graphical data summaries, presents mechanisms for developing a variety of models, and summarizes the performance of your models.
Another web-site worth reading is the following:
http://www.revolutionanalytics.com/"

Also check this book (free and recommended by John Hopskins' Department of Statistics".

Best regards,

Angel Rodriguez-Laso




	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Wed Sep 10 10:51:14 2014
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Wed, 10 Sep 2014 03:51:14 -0500
Subject: [R] Import data from Excel to R
In-Reply-To: <CAP01uRnCZ_HxVEkNGjw7E7kbzmMOY-=jwg9vj=RgnHW7JMRzkQ@mail.gmail.com>
References: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
	<CAP01uRnCZ_HxVEkNGjw7E7kbzmMOY-=jwg9vj=RgnHW7JMRzkQ@mail.gmail.com>
Message-ID: <CAM-xyZj0JL5sFjWFidrsFWp9OmScPaspaRySV4e4vKq96J5Ccg@mail.gmail.com>

The best way is to save the file as CSV... after you can simply import it
with this comand in R:

read.csv(...) ... to know more about the read.csv comand use in R this:
?read.csv.

There are other packages to import EXCEL FILES, but the simplest way, its
importing this as CSV.

2014-09-09 18:03 GMT-05:00 Gabor Grothendieck <ggrothendieck at gmail.com>:

> On Tue, Sep 9, 2014 at 4:48 PM, JAWADI Fredj <fredj.jawadi at france-bs.com>
> wrote:
> > Hi
> > I am a New user of R.
> > Please, how to import data from Excel to R?
> > Thanks,
> > Best regards,
> > Fredj,
> >
>
> There are some ways listed here:
>
> https://web.archive.org/web/20131109195709/http://rwiki.sciviews.org/doku.php?id=tips:data-io:ms_windows&s=excel
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Wed Sep 10 14:45:49 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 10 Sep 2014 07:45:49 -0500
Subject: [R] Import data from Excel to R
In-Reply-To: <CAM-xyZj0JL5sFjWFidrsFWp9OmScPaspaRySV4e4vKq96J5Ccg@mail.gmail.com>
References: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
	<CAP01uRnCZ_HxVEkNGjw7E7kbzmMOY-=jwg9vj=RgnHW7JMRzkQ@mail.gmail.com>
	<CAM-xyZj0JL5sFjWFidrsFWp9OmScPaspaRySV4e4vKq96J5Ccg@mail.gmail.com>
Message-ID: <CAAJSdjjB=uS+EiJAN6h6o5TzjahC58SvStEGPs4ge_x5DX56Ag@mail.gmail.com>

On Wed, Sep 10, 2014 at 3:51 AM, Omar Andr? Gonz?les D?az
<oma.gonzales at gmail.com> wrote:
> The best way is to save the file as CSV... after you can simply import it
> with this comand in R:
>
> read.csv(...) ... to know more about the read.csv comand use in R this:
> ?read.csv.
>
> There are other packages to import EXCEL FILES, but the simplest way, its
> importing this as CSV.
>

I agree, if the person is using R on a Windows system. And they have
Excel installed on it. If, like me, they are on a non-Windows system,
then it _might_ be faster and easier to use a package from CRAN such
as openxlsx (my favorite because it is native C code), or XLConnect
(Java based, using the Apache foundarion's POI code). These could be
used on Windows also. If the OP just wanted to run an R script without
first needing to start up Excel, open the spreadsheet, save the data
in CSV format, then run the R script. What can I say? I'm lazy! (And
_proud_ of it).

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From jdnewmil at dcn.davis.CA.us  Wed Sep 10 16:00:50 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 10 Sep 2014 07:00:50 -0700
Subject: [R] Import data from Excel to R
In-Reply-To: <CAAJSdjjB=uS+EiJAN6h6o5TzjahC58SvStEGPs4ge_x5DX56Ag@mail.gmail.com>
References: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
	<CAP01uRnCZ_HxVEkNGjw7E7kbzmMOY-=jwg9vj=RgnHW7JMRzkQ@mail.gmail.com>
	<CAM-xyZj0JL5sFjWFidrsFWp9OmScPaspaRySV4e4vKq96J5Ccg@mail.gmail.com>
	<CAAJSdjjB=uS+EiJAN6h6o5TzjahC58SvStEGPs4ge_x5DX56Ag@mail.gmail.com>
Message-ID: <a3d1c37f-bc75-4f82-82b1-78baba65c5a8@email.android.com>

Although it may seem troublesome to export to csv, I have found that every direct access library for reading Excel files seems to come with some fiddly bits that confuse new users (and can show down an experienced user). For example, XLConnect can be a headache if your files are large because it seems to use memory inefficiently and requires preallocation for loading the library for large files. It also requires a working Java installation with the right OS architecture which can be an off-topic diversion on this list. And of course there are the xlsx vs xls compatibility problems and the people who sprinkle data around the spreadsheet randomly that add steps to the data extraction that we can't predict.
Telling new users to start out by exporting to CSV is a compact way to get them to solve the their data transfer problem interactively. Most people working with xls/xlsx files have a spreadsheet program with which they can accomplish this initial task, and leave the fiddly bits until they decide to streamline their data processing.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 10, 2014 5:45:49 AM PDT, John McKown <john.archie.mckown at gmail.com> wrote:
>On Wed, Sep 10, 2014 at 3:51 AM, Omar Andr? Gonz?les D?az
><oma.gonzales at gmail.com> wrote:
>> The best way is to save the file as CSV... after you can simply
>import it
>> with this comand in R:
>>
>> read.csv(...) ... to know more about the read.csv comand use in R
>this:
>> ?read.csv.
>>
>> There are other packages to import EXCEL FILES, but the simplest way,
>its
>> importing this as CSV.
>>
>
>I agree, if the person is using R on a Windows system. And they have
>Excel installed on it. If, like me, they are on a non-Windows system,
>then it _might_ be faster and easier to use a package from CRAN such
>as openxlsx (my favorite because it is native C code), or XLConnect
>(Java based, using the Apache foundarion's POI code). These could be
>used on Windows also. If the OP just wanted to run an R script without
>first needing to start up Excel, open the spreadsheet, save the data
>in CSV format, then run the R script. What can I say? I'm lazy! (And
>_proud_ of it).
>
>-- 
>There is nothing more pleasant than traveling and meeting new people!
>Genghis Khan
>
>Maranatha! <><
>John McKown
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kw.stat at gmail.com  Wed Sep 10 17:10:43 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 10 Sep 2014 10:10:43 -0500
Subject: [R] Import data from Excel to R
In-Reply-To: <CAM-xyZj0JL5sFjWFidrsFWp9OmScPaspaRySV4e4vKq96J5Ccg@mail.gmail.com>
References: <47eecc28b8ce4b708b8adb6e4d5a2dd6@DBXPR05MB224.eurprd05.prod.outlook.com>
	<CAP01uRnCZ_HxVEkNGjw7E7kbzmMOY-=jwg9vj=RgnHW7JMRzkQ@mail.gmail.com>
	<CAM-xyZj0JL5sFjWFidrsFWp9OmScPaspaRySV4e4vKq96J5Ccg@mail.gmail.com>
Message-ID: <CAKFxdiRUzorQniWa1C2B8gTtQ6AF2o7UwQXRSRB7UMtg5wSy8w@mail.gmail.com>

Most of the time I would agree with csv being the best format.  _If_ you
are dealing with plain ASCII text.

Having spent most of yesterday with an Excel spreadsheet containing Russian
letters, I can say it is quite difficult to export the data to Unicode
UTF-16 tab-delimited text and then successfully import it to R.  At least
on Windows.  Maybe dependent upon the locale as well. (Google around on
this topic and you find some people seem to be able to succeed at this
task, but at least some other people have had problems.)

What did seem to work reliably for Unicode-containing spreadsheets was to
use the XLConnect package and read the xlsx file directly.

Kevin Wright


On Wed, Sep 10, 2014 at 3:51 AM, Omar Andr? Gonz?les D?az <
oma.gonzales at gmail.com> wrote:

> The best way is to save the file as CSV... after you can simply import it
> with this comand in R:
>
> read.csv(...) ... to know more about the read.csv comand use in R this:
> ?read.csv.
>
> There are other packages to import EXCEL FILES, but the simplest way, its
> importing this as CSV.
>
> 2014-09-09 18:03 GMT-05:00 Gabor Grothendieck <ggrothendieck at gmail.com>:
>
> > On Tue, Sep 9, 2014 at 4:48 PM, JAWADI Fredj <fredj.jawadi at france-bs.com
> >
> > wrote:
> > > Hi
> > > I am a New user of R.
> > > Please, how to import data from Excel to R?
> > > Thanks,
> > > Best regards,
> > > Fredj,
> > >
> >
> > There are some ways listed here:
> >
> >
> https://web.archive.org/web/20131109195709/http://rwiki.sciviews.org/doku.php?id=tips:data-io:ms_windows&s=excel
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Wed Sep 10 17:53:01 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Wed, 10 Sep 2014 23:53:01 +0800 (CST)
Subject: [R] some question about  vector[-NULL]
In-Reply-To: <54102BE7.6080002@gmail.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
Message-ID: <55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>


Tks for your?

a <- list(ress = 1, res = NULL)
And in my second question, let me explain it :
Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
F<-function( B ) {
B<-B[-A]
some processing...
res<-NULL or some new index not included in A
return(res)
}
so in a loop,
A<-NULL
for( i in 1:100000) {
D<-F(B)
A<-c(A,D) 
}
I never know whether D is a NULL or a different index  compared with indexes already recorded in A. 
Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
so i hope that, e.g.  
a<-1:3
a[-NULL] wouldn't trigger an error but return a.
Because, if i wrote function like the following:

F<-function( B ) {
if( is.null(A))?         
B<-B
else 
B<-B[-A]
some processing...
res<-NULL or some new index not included in A
return(res)
}
May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
 




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>On 10/09/2014, 3:21 AM, PO SU wrote:
>> 
>> Dear expeRts,
>>       I have some programming questions about NULL in R.There are listed as follows:
>> 1. I find i can't let a list have a element NULL:
>> a<-list()
>> a$ress<-1
>> a$res<-NULL
>> a
>> str(a)
>
>You can do it using
>
>a <- list(ress = 1, res = NULL)
>
>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
>
>That's a little harder.  There are a few ways:
>
>"res" %in% names(a) & is.null(a[["res"]])
>
>or
>
>identical(a["res"], list(res = NULL))
>
>or
>
>is.null(a[[2]])
>
>should all work.
>
>Generally because of the special handling needed, it's a bad idea to try
>to store NULL in a list.
>
>> 2.The most important thing:
>> a<-1:10
>> b<-NULL or 1
>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
>
>Using !, and a logical test, e.g.
>
>a[!nullentry(a)]
>
>where nullentry() is a function based on one of the tests above, but
>applied to all entries.
>
>Duncan Murdoch
>

From wdunlap at tibco.com  Wed Sep 10 18:06:17 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 10 Sep 2014 09:06:17 -0700
Subject: [R] Why does debugging print() change output of function?
In-Reply-To: <D4EF764B-8255-4EBF-AC42-F3D08668C298@comcast.net>
References: <D6514205-145D-4D11-9485-B19954B2DE11@comcast.net>
	<58B41C11-4B60-4810-A6D5-A6C58F0BC838@gmail.com>
	<D4EF764B-8255-4EBF-AC42-F3D08668C298@comcast.net>
Message-ID: <CAF8bMcYCiHt_Gu-F2YmkMOZ=_t51NdbpPN7PtyPrjdW0nKjBOg@mail.gmail.com>

Another nice thing about using ~formula is that it stores the
environment in which the formula was made along with the formula.
Thus you know which envrionment should be used with evaluating it (and
don't have to guess that parent.frame() may be the right environmnet).
  E.g.,
  evalRHS <- function(formula) {
     RHS <- formula[[length(formula)]]
     eval(RHS, envir=environment(formula))
  }
  p1 <- 1:3
  p2 <- 11:13
  f1 <- function(formula) {
      p1 <- 1000
      evalRHS(formula)
  }
  f1(~p1+p2) # does not use the p1 defined in f1
  # [1] 12 14 16
If you do want to override some of the variables in the formula you
can do that by replacing the environment of the formula with a child
of that environment.  Do this in a function so it only replaces the
environment in a copy of the formula, not the original one.
  f2 <- function(formula) {
      environment(formula) <- list2env(list(p1=1000),
new.env(parent=environment(formula)))
      evalRHS(formula)
  }
  f2(~p1+p2)
  # [1] 1011 1012 1013
  f1(~p1+p2)
  # [1] 12 14 16

(These examples are not the best since the global environment is
searched in any case.  Put the entire example inside a function to see
the strength of the formula approach.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Sep 9, 2014 at 10:13 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Sep 9, 2014, at 4:07 PM, peter dalgaard wrote:
>
>>
>> On 07 Sep 2014, at 00:31 , David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> The goal:
>>> to create a function modeled after `subset` (notorious for its
>>> non-standard evaluation) that will take a series of logical tests as
>>> unquoted expressions to be evaluated in the framework of a dataframe
>>> environment and return a dataframe of logicals:
>>
>> ...
>>
>> A belated peep from the author of subset(): Don't!
>>
>> I think we learned the hard way by now that it is much easier to pass
>> unevaluated expressions in the shape of formula objects or maybe expression
>> objects. Lots of pain can be avoided by slipping in a simple "~".
>
>
> It's taken me several years to understand why you are probably correct in
> this regard. I needed to learn that `~` is actually a function that creates
> a language object.
>
>> is.function(`~`)
> [1] TRUE
>> is.language( ~ x > 5 & x < 10)
> [1] TRUE
>
> ... and that it's rather easy to extract the object somewhat like but not
> really an expression embedded in such an object:
>
>> is.expression( ~ x > 5 & x < 10)
> [1] FALSE
>
>> is.call( (~ x > 5 & x < 10)[2] )
> [1] TRUE
>
> The task of learning the various types of language objects is not an easy
> one.
>
> --
>
> David Winsemius, MD
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rhelpmaillist at 163.com  Wed Sep 10 18:08:17 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 11 Sep 2014 00:08:17 +0800 (CST)
Subject: [R] some question about  vector[-NULL]
In-Reply-To: <55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
Message-ID: <7b250ba.15139.148605291af.Coremail.rhelpmaillist@163.com>


May be i could add a extra elment to B,that's:

F<-function( C ) {
C<-C[-A]
some processing...
res<-NULL or some new index not included in A
return(res)
}
so in a loop,


C<-c(B,1)
tmpindex<-length(C)
A<-tmpindex
for( i in 1:100000) {
D<-F(C)
A<-c(A,D) 
}




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-09-10 11:53:01, "PO SU" <rhelpmaillist at 163.com> wrote:
>
>Tks for your?
>
>a <- list(ress = 1, res = NULL)
>And in my second question, let me explain it :
>Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
>Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
>But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
>F<-function( B ) {
>B<-B[-A]
>some processing...
>res<-NULL or some new index not included in A
>return(res)
>}
>so in a loop,
>A<-NULL
>for( i in 1:100000) {
>D<-F(B)
>A<-c(A,D) 
>}
>I never know whether D is a NULL or a different index  compared with indexes already recorded in A. 
>Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
>so i hope that, e.g.  
>a<-1:3
>a[-NULL] wouldn't trigger an error but return a.
>Because, if i wrote function like the following:
>
>F<-function( B ) {
>if( is.null(A))?         
>B<-B
>else 
>B<-B[-A]
>some processing...
>res<-NULL or some new index not included in A
>return(res)
>}
>May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
> 
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>
>
>
>At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>On 10/09/2014, 3:21 AM, PO SU wrote:
>>> 
>>> Dear expeRts,
>>>       I have some programming questions about NULL in R.There are listed as follows:
>>> 1. I find i can't let a list have a element NULL:
>>> a<-list()
>>> a$ress<-1
>>> a$res<-NULL
>>> a
>>> str(a)
>>
>>You can do it using
>>
>>a <- list(ress = 1, res = NULL)
>>
>>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
>>
>>That's a little harder.  There are a few ways:
>>
>>"res" %in% names(a) & is.null(a[["res"]])
>>
>>or
>>
>>identical(a["res"], list(res = NULL))
>>
>>or
>>
>>is.null(a[[2]])
>>
>>should all work.
>>
>>Generally because of the special handling needed, it's a bad idea to try
>>to store NULL in a list.
>>
>>> 2.The most important thing:
>>> a<-1:10
>>> b<-NULL or 1
>>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
>>
>>Using !, and a logical test, e.g.
>>
>>a[!nullentry(a)]
>>
>>where nullentry() is a function based on one of the tests above, but
>>applied to all entries.
>>
>>Duncan Murdoch
>>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From wdunlap at tibco.com  Wed Sep 10 18:20:24 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 10 Sep 2014 09:20:24 -0700
Subject: [R] some question about vector[-NULL]
In-Reply-To: <55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
Message-ID: <CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>

Can you make your example a bit more concrete?  E.g., is your 'index
vector' A an integer vector?  If so, integer(0), an integer vector
with no elements, would be a more reasonable return value than NULL,
an object of class NULL with length 0, for the 'not found' case and
you could check for that case by asking if length(A)==0.

Show us typical inputs and expected outputs for your function (i.e.,
the problem you want to solve).

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Tks for your
>
> a <- list(ress = 1, res = NULL)
> And in my second question, let me explain it :
> Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
> Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
> But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
> F<-function( B ) {
> B<-B[-A]
> some processing...
> res<-NULL or some new index not included in A
> return(res)
> }
> so in a loop,
> A<-NULL
> for( i in 1:100000) {
> D<-F(B)
> A<-c(A,D)
> }
> I never know whether D is a NULL or a different index  compared with indexes already recorded in A.
> Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
> so i hope that, e.g.
> a<-1:3
> a[-NULL] wouldn't trigger an error but return a.
> Because, if i wrote function like the following:
>
> F<-function( B ) {
> if( is.null(A))
> B<-B
> else
> B<-B[-A]
> some processing...
> res<-NULL or some new index not included in A
> return(res)
> }
> May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>On 10/09/2014, 3:21 AM, PO SU wrote:
>>>
>>> Dear expeRts,
>>>       I have some programming questions about NULL in R.There are listed as follows:
>>> 1. I find i can't let a list have a element NULL:
>>> a<-list()
>>> a$ress<-1
>>> a$res<-NULL
>>> a
>>> str(a)
>>
>>You can do it using
>>
>>a <- list(ress = 1, res = NULL)
>>
>>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
>>
>>That's a little harder.  There are a few ways:
>>
>>"res" %in% names(a) & is.null(a[["res"]])
>>
>>or
>>
>>identical(a["res"], list(res = NULL))
>>
>>or
>>
>>is.null(a[[2]])
>>
>>should all work.
>>
>>Generally because of the special handling needed, it's a bad idea to try
>>to store NULL in a list.
>>
>>> 2.The most important thing:
>>> a<-1:10
>>> b<-NULL or 1
>>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
>>
>>Using !, and a logical test, e.g.
>>
>>a[!nullentry(a)]
>>
>>where nullentry() is a function based on one of the tests above, but
>>applied to all entries.
>>
>>Duncan Murdoch
>>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Sep 10 19:58:46 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 10 Sep 2014 13:58:46 -0400
Subject: [R] some question about vector[-NULL]
In-Reply-To: <CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
Message-ID: <54109156.1090407@gmail.com>

On 10/09/2014 12:20 PM, William Dunlap wrote:
> Can you make your example a bit more concrete?  E.g., is your 'index
> vector' A an integer vector?  If so, integer(0), an integer vector
> with no elements, would be a more reasonable return value than NULL,
> an object of class NULL with length 0, for the 'not found' case and
> you could check for that case by asking if length(A)==0.
>
> Show us typical inputs and expected outputs for your function (i.e.,
> the problem you want to solve).

I think the problem with integer(0) and NULL is the same:  a[-i] doesn't 
act as expected (leaving out all the elements of i, i.e. nothing) if i 
is either of those.  The solution is to use logical indexing, not 
negative numerical indexing.

Duncan Murdoch
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com> wrote:
> >
> > Tks for your
> >
> > a <- list(ress = 1, res = NULL)
> > And in my second question, let me explain it :
> > Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
> > Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
> > But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
> > F<-function( B ) {
> > B<-B[-A]
> > some processing...
> > res<-NULL or some new index not included in A
> > return(res)
> > }
> > so in a loop,
> > A<-NULL
> > for( i in 1:100000) {
> > D<-F(B)
> > A<-c(A,D)
> > }
> > I never know whether D is a NULL or a different index  compared with indexes already recorded in A.
> > Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
> > so i hope that, e.g.
> > a<-1:3
> > a[-NULL] wouldn't trigger an error but return a.
> > Because, if i wrote function like the following:
> >
> > F<-function( B ) {
> > if( is.null(A))
> > B<-B
> > else
> > B<-B[-A]
> > some processing...
> > res<-NULL or some new index not included in A
> > return(res)
> > }
> > May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
> >
> >
> >
> >
> >
> > --
> >
> > PO SU
> > mail: desolator88 at 163.com
> > Majored in Statistics from SJTU
> >
> >
> >
> > At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
> >>On 10/09/2014, 3:21 AM, PO SU wrote:
> >>>
> >>> Dear expeRts,
> >>>       I have some programming questions about NULL in R.There are listed as follows:
> >>> 1. I find i can't let a list have a element NULL:
> >>> a<-list()
> >>> a$ress<-1
> >>> a$res<-NULL
> >>> a
> >>> str(a)
> >>
> >>You can do it using
> >>
> >>a <- list(ress = 1, res = NULL)
> >>
> >>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
> >>
> >>That's a little harder.  There are a few ways:
> >>
> >>"res" %in% names(a) & is.null(a[["res"]])
> >>
> >>or
> >>
> >>identical(a["res"], list(res = NULL))
> >>
> >>or
> >>
> >>is.null(a[[2]])
> >>
> >>should all work.
> >>
> >>Generally because of the special handling needed, it's a bad idea to try
> >>to store NULL in a list.
> >>
> >>> 2.The most important thing:
> >>> a<-1:10
> >>> b<-NULL or 1
> >>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
> >>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
> >>
> >>Using !, and a logical test, e.g.
> >>
> >>a[!nullentry(a)]
> >>
> >>where nullentry() is a function based on one of the tests above, but
> >>applied to all entries.
> >>
> >>Duncan Murdoch
> >>
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From peljasz at yahoo.co.uk  Wed Sep 10 22:39:53 2014
From: peljasz at yahoo.co.uk (lejeczek)
Date: Wed, 10 Sep 2014 21:39:53 +0100
Subject: [R] Building R for better performance
In-Reply-To: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5A6F@ORSMSX104.amr.corp.intel.com>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>	<87430F4E-90CE-4A20-87D0-EFBBE293FB9C@uni-bonn.de>
	<9EB21FFA75EC13438CA12AD2A022D8CC2E9C5A6F@ORSMSX104.amr.corp.intel.com>
Message-ID: <5410B719.7030706@yahoo.co.uk>

hi,
I can confirm that MKL even with gcc (and on AMD Opterons) 
is damn fast!
I tried R-benchmark-25 and MASS-ex
but Intel's own link advisor is rubbish, I mean look at this:

  -Wl,--start-group 
$(MKLROOT)/lib/intel64/libmkl_intel_lp64.a 
$(MKLROOT)/lib/intel64/libmkl_core.a 
$(MKLROOT)/lib/intel64/libmkl_gnu_thread.a -Wl,--end-group 
-ldl -lpthread -lm

above is what you get for mkl static + gnu + libgomp,
try it and it does not work

On 05/03/14 22:41, Anspach, Jonathan P wrote:
> Simon,
>
> Thanks for the information and links.  First of all, did you ever resolve your problem?  If not, did you file an issue in Intel Premier Support?  That's the best way to bring it to our attention.  If you don't want to do that I can try to get a compiler or MKL support engineer to look at your Intel Developer Zone discussion.  I have no experience with OS X, so I wouldn't be much help.
>
> I got the benchmark script, which I've attached, from Texas Advanced Computing Center.  Here are my results (elapsed times, in secs):
>
>                                                                                                                               gcc build (default)                 icc/MKL build
> Creation, transp., deformation of a 5000x5000 matrix                                3.25                                          2.95
> 5000x5000 normal distributed random matrix ^1000                                   5.13                                          1.52
> Sorting of 14,000,000 random values                                                                  1.61                                          1.64
> 5600x5600 cross-product matrix (b = a' * a)                                                   97.44                                          0.56
> Linear regr. over a 4000x4000 matrix (c = a \ b')                                           46.06                                           0.49
> FFT over 4,800,000 random values                                                                       0.65                                           0.61
> Eigenvalues of a 1200x1200 random matrix                                                      5.55                                           1.37
> Determinant of a 5000x5000 random matrix                                                  34.18                                           0.55
> Cholesky decomposition of a 6000x6000 matrix                                            37.07                                           0.47
> Inverse of a 3200x3200 random matrix                                                             29.49                                           0.57
> 3,500,000 Fibonacci numbers calculation (vector calc)                                  1.31                                            0.38
> Creation of a 6000x6000 Hilbert matrix (matrix calc)                                     0.77                                             0.99
> Grand common divisors of 400,000 pairs (recursion)                                    0.63                                             0.56
> Creation of a 1000x1000 Toeplitz matrix (loops)                                             2.24                                             2.34
> Escoufier's method on a 90x90 matrix (mixed)                                               9.55                                             6.02
> Total                                                                                                                             274.93                                           21.01
>
> Regards,
> Jonathan Anspach
> Sr. Software Engineer
> Intel Corp.
> jonathan.p.anspach at intel.com
> 713-751-9460
>
>
> -----Original Message-----
> From: Simon Zehnder [mailto:szehnder at uni-bonn.de]
> Sent: Wednesday, March 05, 2014 3:55 AM
> To: Anspach, Jonathan P
> Cc: r-help at r-project.org
> Subject: Re: [R] Building R for better performance
>
> Jonathan,
>
> I myself tried something like this - comparing gcc, clang and intel on a Mac. From my experiences in HPC on the university cluster (where we also use the Xeon Phi, Landeshochleistungscluster University RWTH Aachen), the Intel compiler has better code optimization in regard to vectorisation, etc. (clang is up to now suffering from a not yet implemented OpenMP library).
>
> Here is a revolutionanalytics article about this topic: http://blog.revolutionanalytics.com/2010/06/performance-benefits-of-multithreaded-r.html
>
> As I usually use the Rcpp package for C++ extensions this could give me further performance. Though, I already failed when trying to compile R with the Intel compiler and linking against the MKL (see my topic in the Intel developer zone: http://software.intel.com/en-us/comment/1767418 and my threads on the R-User list: https://stat.ethz.ch/pipermail/r-sig-mac/2013-November/010472.html).
>
> So, to your questions:
>
> 1) I think that most admins do not even use the Intel compiler to compile R - this seems to me rare. There are some people I know they do and I think they could be aware of it - but these are only a few. As R is growing in usage and I do know from regional user meetings that very large companies start using it in their BI units - this should be of interest.
>
> 2) I would really welcome this step because compilation with intel (especially on a Mac) and linking to the MKL seems to be delicate.
>
> I am interested in the data - so if it is possible send it via the list or directly to my account. Further, could you show some code that you used for the computations?
>
>
> Best
>
> Simon
>
>
> On 04 Mar 2014, at 22:44, Anspach, Jonathan P <jonathan.p.anspach at intel.com> wrote:
>
>> Greetings,
>>
>> I'm a software engineer with Intel.  Recently I've been investigating R performance on Intel Xeon and Xeon Phi processors and RH Linux.  I've also compared the performance of R built with the Intel compilers and Intel Math Kernel Library to a "default" build (no config options) that uses the GNU compilers.  To my dismay, I've found that the GNU build always runs on a single CPU core, even during matrix operations.  The Intel build runs matrix operations on multiple cores, so it is much faster on those operations.  Running the benchmark-2.5 on a 24 core Xeon system, the Intel build is 13x faster than the GNU build (21 seconds vs 275 seconds).  Unfortunately, this advantage is not documented anywhere that I can see.
>>
>> Building with the Intel tools is very easy.  Assuming the tools are installed in /opt/intel/composerxe, the process is simply (in bash shell):
>>
>> $ . /opt/intel/composerxe/bin/compilervars.sh intel64 $ ./configure
>> --with-blas="-L/opt/intel/composerxe/mkl/lib/intel64 -lmkl_intel_lp64
>> -lmkl_intel_thread -lmkl_core -liomp5 -lpthread -lm" --with-lapack
>> CC=icc CFLAGS=-O2 CXX=icpc CXXFLAGS=-O2 F77=ifort FFLAGS=-O2 FC=ifort
>> FCFLAGS=-O2 $ make $ make check
>>
>> My questions are:
>> 1) Do most system admins and/or R installers know about this performance difference, and use the Intel tools to build R?
>> 2) Can we add information on the advantage of building with the Intel tools, and how to do it, to the installation instructions and FAQ?
>>
>> I can post my data if anyone is interested.
>>
>> Thanks,
>> Jonathan Anspach
>> Sr. Software Engineer
>> Intel Corp.
>> jonathan.p.anspach at intel.com
>> 713-751-9460
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thi_veloso at yahoo.com.br  Wed Sep 10 22:20:01 2014
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Wed, 10 Sep 2014 13:20:01 -0700
Subject: [R] How to plot soil moisture data as a contour plot
Message-ID: <1410380401.82513.YahooMailNeo@web121902.mail.ne1.yahoo.com>

Dear all,

This is my first message in this list, so please excuse any mistake.

I am trying to plot moisture data for 11 soil layers over the course of the year, but I am yet to find the correct function to do that. I am trying to reproduce the lower figure in this panel: https://imageshack.com/i/exmVz5QSp

Please read the comments while reproducing my data with the code below: 

----------------------------------------
library(repmis) # reads text data directly from dropbox - no need to download any file

# read data
url <- 'https://dl.dropboxusercontent.com/u/27700634/precip.txt'
tmp <- repmis::source_data(url, sep = '', header = TRUE)

# convert julian day to date
date <- as.Date(tmp$julian, origin='2011-12-31')
data <- cbind(date, tmp)
head(data)

# now, convert soil layers to matrix and transpose it
mat <- t(as.matrix(data[, 4:14]))
head(mat) 

# this is the very matrix I want to plot. Please notice that it is already organized as a "profile",
# with rows representing soil layers and columns representing day of year.
----------------------------------------


My first attempt was to use function filled.contour from "graphics" package. I define a vector with labels for soil layers and then I try to plot, but I receive an error saying the matrix has incorrect dimensions:


----------------------------------------

# define vector with depth of soil layers

depths <- c(0.05,0.10,0.20,0.30,
            0.40,0.60,0.80,1.00,
            1.50,2.00,2.50)

# Plot soil moisture profile
plot <- filled.contour(data$julian, depths, mat)


#Error in .filled.contour(x, y, z, levels, col) : dimension mismatch
----------------------------------------


I can obviously tranpose the matrix to force the plot, but the resulting figure is not what I need - the soil profile is shown upside down:

----------------------------------------
plot <- filled.contour(data$julian, depths, t(mat))

----------------------------------------


Because this functions requires axis labels to be ascendent, I am not able to reverse them in order to show the first layer at the top of the graphic.

I would really appreciate any feedback or directions on how to show my data as a contour plot as mentioned above. Thanks in advance! 


Greetings,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323
 9898
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Sep 10 23:56:22 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Sep 2014 14:56:22 -0700
Subject: [R] How to plot soil moisture data as a contour plot
In-Reply-To: <1410380401.82513.YahooMailNeo@web121902.mail.ne1.yahoo.com>
References: <1410380401.82513.YahooMailNeo@web121902.mail.ne1.yahoo.com>
Message-ID: <9E1C3AD7-339A-453E-8E2C-0E9B5EFD70A8@comcast.net>


On Sep 10, 2014, at 1:20 PM, Thiago V. dos Santos wrote:

> Dear all,
> 
> This is my first message in this list, so please excuse any mistake.
> 
> I am trying to plot moisture data for 11 soil layers over the course of the year, but I am yet to find the correct function to do that. I am trying to reproduce the lower figure in this panel: https://imageshack.com/i/exmVz5QSp
> 
> Please read the comments while reproducing my data with the code below: 
> 
> ----------------------------------------
> library(repmis) # reads text data directly from dropbox - no need to download any file
> 
> # read data
> url <- 'https://dl.dropboxusercontent.com/u/27700634/precip.txt'
> tmp <- repmis::source_data(url, sep = '', header = TRUE)
> 
> # convert julian day to date
> date <- as.Date(tmp$julian, origin='2011-12-31')
> data <- cbind(date, tmp)
> head(data)
> 
> # now, convert soil layers to matrix and transpose it
> mat <- t(as.matrix(data[, 4:14]))
> head(mat) 
> 
> # this is the very matrix I want to plot. Please notice that it is already organized as a "profile",
> # with rows representing soil layers and columns representing day of year.
> ----------------------------------------
> 
> 
> My first attempt was to use function filled.contour from "graphics" package. I define a vector with labels for soil layers and then I try to plot, but I receive an error saying the matrix has incorrect dimensions:
> 
> 
> ----------------------------------------
> 
> # define vector with depth of soil layers
> 
> depths <- c(0.05,0.10,0.20,0.30,
>            0.40,0.60,0.80,1.00,
>            1.50,2.00,2.50)
> 
> # Plot soil moisture profile
> plot <- filled.contour(data$julian, depths, mat)
> 
> 
> #Error in .filled.contour(x, y, z, levels, col) : dimension mismatch

You need to decide what orientation you want. At the moment the mat-matrix is 11 x 366 and the x-component is the 11. (And for some reason you are the one who made the first transposition.) There's no auto-transformation in filled.contour when the dimensions are reversed. 

This proceeds without error:

mat2 <- as.matrix(data[, 4:14])
plot <- filled.contour(x=data$julian, y=depths, z=mat2)

> ----------------------------------------
> 
> 
> I can obviously tranpose the matrix to force the plot, but the resulting figure is not what I need - the soil profile is shown upside down:
> 

If you want the reverse the depth order, do not transpose, .... just:

plot <- filled.contour(x=data$julian, y=depths, z=mat2[, 11:1])



> ----------------------------------------
> plot <- filled.contour(data$julian, depths, t(mat))
> 
> ----------------------------------------
> 
> 
> Because this functions requires axis labels to be ascendent, I am not able to reverse them in order to show the first layer at the top of the graphic.
> 
> I would really appreciate any feedback or directions on how to show my data as a contour plot as mentioned above. Thanks in advance! 
> 
> 
> Greetings,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323
> 9898
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rhelpmaillist at 163.com  Thu Sep 11 03:53:45 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 11 Sep 2014 09:53:45 +0800 (CST)
Subject: [R] some question about vector[-NULL]
In-Reply-To: <54109156.1090407@gmail.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
Message-ID: <117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>


Tks, i think using logical index is a way, but to do that, i have to keep a vector as long as the original vector. that's, to exclude position 1 and 3 from 
a<-1:5
I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which c(1,3) is much?shorter than?b if?a is a long vector. that's, b would be?c(F,T,F,T,T,T,T,......,T)
I thought a way?,
?let?d<-c(a,1) 
that d<-c(1,2,3,4,5,1)
and initialize the index vector?? iv to length(d). that is iv<-6.
then, d[-iv] is always equal? a[- i?] ,? whether i is NULL or not. 
Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so on.......
?






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>On 10/09/2014 12:20 PM, William Dunlap wrote:
>> Can you make your example a bit more concrete?  E.g., is your 'index
>> vector' A an integer vector?  If so, integer(0), an integer vector
>> with no elements, would be a more reasonable return value than NULL,
>> an object of class NULL with length 0, for the 'not found' case and
>> you could check for that case by asking if length(A)==0.
>>
>> Show us typical inputs and expected outputs for your function (i.e.,
>> the problem you want to solve).
>
>I think the problem with integer(0) and NULL is the same:  a[-i] doesn't 
>act as expected (leaving out all the elements of i, i.e. nothing) if i 
>is either of those.  The solution is to use logical indexing, not 
>negative numerical indexing.
>
>Duncan Murdoch
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com> wrote:
>> >
>> > Tks for your
>> >
>> > a <- list(ress = 1, res = NULL)
>> > And in my second question, let me explain it :
>> > Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
>> > Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
>> > But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
>> > F<-function( B ) {
>> > B<-B[-A]
>> > some processing...
>> > res<-NULL or some new index not included in A
>> > return(res)
>> > }
>> > so in a loop,
>> > A<-NULL
>> > for( i in 1:100000) {
>> > D<-F(B)
>> > A<-c(A,D)
>> > }
>> > I never know whether D is a NULL or a different index  compared with indexes already recorded in A.
>> > Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
>> > so i hope that, e.g.
>> > a<-1:3
>> > a[-NULL] wouldn't trigger an error but return a.
>> > Because, if i wrote function like the following:
>> >
>> > F<-function( B ) {
>> > if( is.null(A))
>> > B<-B
>> > else
>> > B<-B[-A]
>> > some processing...
>> > res<-NULL or some new index not included in A
>> > return(res)
>> > }
>> > May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
>> >
>> >
>> >
>> >
>> >
>> > --
>> >
>> > PO SU
>> > mail: desolator88 at 163.com
>> > Majored in Statistics from SJTU
>> >
>> >
>> >
>> > At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>> >>On 10/09/2014, 3:21 AM, PO SU wrote:
>> >>>
>> >>> Dear expeRts,
>> >>>       I have some programming questions about NULL in R.There are listed as follows:
>> >>> 1. I find i can't let a list have a element NULL:
>> >>> a<-list()
>> >>> a$ress<-1
>> >>> a$res<-NULL
>> >>> a
>> >>> str(a)
>> >>
>> >>You can do it using
>> >>
>> >>a <- list(ress = 1, res = NULL)
>> >>
>> >>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
>> >>
>> >>That's a little harder.  There are a few ways:
>> >>
>> >>"res" %in% names(a) & is.null(a[["res"]])
>> >>
>> >>or
>> >>
>> >>identical(a["res"], list(res = NULL))
>> >>
>> >>or
>> >>
>> >>is.null(a[[2]])
>> >>
>> >>should all work.
>> >>
>> >>Generally because of the special handling needed, it's a bad idea to try
>> >>to store NULL in a list.
>> >>
>> >>> 2.The most important thing:
>> >>> a<-1:10
>> >>> b<-NULL or 1
>> >>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
>> >>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
>> >>
>> >>Using !, and a logical test, e.g.
>> >>
>> >>a[!nullentry(a)]
>> >>
>> >>where nullentry() is a function based on one of the tests above, but
>> >>applied to all entries.
>> >>
>> >>Duncan Murdoch
>> >>
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>

From rhelpmaillist at 163.com  Thu Sep 11 08:19:32 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 11 Sep 2014 14:19:32 +0800 (CST)
Subject: [R] unable to move temporary installation when install some packages
Message-ID: <1842926f.55f9.148635dec94.Coremail.rhelpmaillist@163.com>


Dear expeRts,
These days? i and some of my friends often encount?? the same problem when installing packages, e.g. when i try to install.packages("stringi"), i will get :


package ?stringi? successfully unpacked and MD5 sums checked
Warning in install.packages :
  unable to move temporary installation ?C:\Program Files\R\library\file28744050180\stringi? to ?C:\Program Files\R\library\stringi?

The downloaded binary packages are in
	C:\Users\po.su\AppData\Local\Temp\RtmpeobZut\downloaded_packages


But when i try to install some other packages, it is ok,like ggplot2,but my friends encount the same problem with ggplot2 like stringi for me.
we all use windows 7, and the latest version of?Rstudio with R 3.1.1.
We investgate it, open the path dir 's modify permissions, it works for some packages,but for packages like Rcpp, the problem still come!
Is there some one happen to  know the solution?

--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From petr.pikal at precheza.cz  Thu Sep 11 08:24:25 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 11 Sep 2014 06:24:25 +0000
Subject: [R] some question about vector[-NULL]
In-Reply-To: <117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1917@SRVEXCHMBX.precheza.cz>

Hi

You still do not disclose important info about details of your functions. However, when you want to perform indexing like you show, you maybe can get rid of NULL and use zero instead.

> a<-1:5
> a[-c(1,3)]
[1] 2 4 5
> a[-c(0,1,3)]
[1] 2 4 5
> a[-c(1,0,3)]
[1] 2 4 5
> a[-c(0,1,0,3,0)]
[1] 2 4 5

However I am almost sure that you are fishing in murky waters and what you do by cycle and fiddling with NULL elements can be achieved by more efficiently.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of PO SU
> Sent: Thursday, September 11, 2014 3:54 AM
> To: Duncan Murdoch
> Cc: R. Help
> Subject: Re: [R] some question about vector[-NULL]
>
>
> Tks, i think using logical index is a way, but to do that, i have to
> keep a vector as long as the original vector. that's, to exclude
> position 1 and 3 from
> a<-1:5
> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which
> c(1,3) is much shorter than b if a is a long vector. that's, b would
> be c(F,T,F,T,T,T,T,......,T) I thought a way ,
>  let d<-c(a,1)
> that d<-c(1,2,3,4,5,1)
> and initialize the index vector   iv to length(d). that is iv<-6.
> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not.
> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so
> on.......
>
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
>
> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com>
> wrote:
> >On 10/09/2014 12:20 PM, William Dunlap wrote:
> >> Can you make your example a bit more concrete?  E.g., is your 'index
> >> vector' A an integer vector?  If so, integer(0), an integer vector
> >> with no elements, would be a more reasonable return value than NULL,
> >> an object of class NULL with length 0, for the 'not found' case and
> >> you could check for that case by asking if length(A)==0.
> >>
> >> Show us typical inputs and expected outputs for your function (i.e.,
> >> the problem you want to solve).
> >
> >I think the problem with integer(0) and NULL is the same:  a[-i]
> doesn't
> >act as expected (leaving out all the elements of i, i.e. nothing) if i
> >is either of those.  The solution is to use logical indexing, not
> >negative numerical indexing.
> >
> >Duncan Murdoch
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com
> >>
> >>
> >> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com>
> wrote:
> >> >
> >> > Tks for your
> >> >
> >> > a <- list(ress = 1, res = NULL)
> >> > And in my second question, let me explain it :
> >> > Actually i have two vectors in global enviroment, called A and B
> .A is initialized to NULL which used to record some index in B.
> >> > Then i would run a function F,  and each time, i would get a index
> value or NULL. that's,  D<-F(B). D would be NULL or  some index
> position in B.
> >> > But in the function F, though input is B,  i would exclude the
> index value from  B recorded in A. That's :
> >> > F<-function( B ) {
> >> > B<-B[-A]
> >> > some processing...
> >> > res<-NULL or some new index not included in A
> >> > return(res)
> >> > }
> >> > so in a loop,
> >> > A<-NULL
> >> > for( i in 1:100000) {
> >> > D<-F(B)
> >> > A<-c(A,D)
> >> > }
> >> > I never know whether D is a NULL or a different index  compared
> with indexes already recorded in A.
> >> > Actually, A<-c(A,D) work well, i never worry about whether D is
> NULL or a real index, but in the function F,  B<-B[-A] won't work.
> >> > so i hope that, e.g.
> >> > a<-1:3
> >> > a[-NULL] wouldn't trigger an error but return a.
> >> > Because, if i wrote function like the following:
> >> >
> >> > F<-function( B ) {
> >> > if( is.null(A))
> >> > B<-B
> >> > else
> >> > B<-B[-A]
> >> > some processing...
> >> > res<-NULL or some new index not included in A
> >> > return(res)
> >> > }
> >> > May be after 5 or 10 loops, A would already not NULL, so the added
> if ..else statement would be repeated in left  9999 loops which i would
> not like to see.
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> >
> >> > PO SU
> >> > mail: desolator88 at 163.com
> >> > Majored in Statistics from SJTU
> >> >
> >> >
> >> >
> >> > At 2014-09-10 06:45:59, "Duncan Murdoch"
> <murdoch.duncan at gmail.com> wrote:
> >> >>On 10/09/2014, 3:21 AM, PO SU wrote:
> >> >>>
> >> >>> Dear expeRts,
> >> >>>       I have some programming questions about NULL in R.There
> are listed as follows:
> >> >>> 1. I find i can't let a list have a element NULL:
> >> >>> a<-list()
> >> >>> a$ress<-1
> >> >>> a$res<-NULL
> >> >>> a
> >> >>> str(a)
> >> >>
> >> >>You can do it using
> >> >>
> >> >>a <- list(ress = 1, res = NULL)
> >> >>
> >> >>> How can i know i have a named element but it is NULL, not just
> get a$xxxx,a$iiii,a$oooo there all get NULL
> >> >>
> >> >>That's a little harder.  There are a few ways:
> >> >>
> >> >>"res" %in% names(a) & is.null(a[["res"]])
> >> >>
> >> >>or
> >> >>
> >> >>identical(a["res"], list(res = NULL))
> >> >>
> >> >>or
> >> >>
> >> >>is.null(a[[2]])
> >> >>
> >> >>should all work.
> >> >>
> >> >>Generally because of the special handling needed, it's a bad idea
> to try
> >> >>to store NULL in a list.
> >> >>
> >> >>> 2.The most important thing:
> >> >>> a<-1:10
> >> >>> b<-NULL or 1
> >> >>> a<-c(a,b) will work so i don't need to know whether b is null or
> not,but:
> >> >>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach
> this purpose?
> >> >>
> >> >>Using !, and a logical test, e.g.
> >> >>
> >> >>a[!nullentry(a)]
> >> >>
> >> >>where nullentry() is a function based on one of the tests above,
> but
> >> >>applied to all entries.
> >> >>
> >> >>Duncan Murdoch
> >> >>
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ripley at stats.ox.ac.uk  Thu Sep 11 08:37:32 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Sep 2014 07:37:32 +0100
Subject: [R] unable to move temporary installation when install some
	packages
In-Reply-To: <1842926f.55f9.148635dec94.Coremail.rhelpmaillist@163.com>
References: <1842926f.55f9.148635dec94.Coremail.rhelpmaillist@163.com>
Message-ID: <5411432C.1040300@stats.ox.ac.uk>

On 11/09/2014 07:19, PO SU wrote:
>
> Dear expeRts,
> These days  i and some of my friends often encount   the same problem when installing packages, e.g. when i try to install.packages("stringi"), i will get :
>
>
> package ?stringi? successfully unpacked and MD5 sums checked
> Warning in install.packages :
>    unable to move temporary installation ?C:\Program Files\R\library\file28744050180\stringi? to ?C:\Program Files\R\library\stringi?
>
> The downloaded binary packages are in
> 	C:\Users\po.su\AppData\Local\Temp\RtmpeobZut\downloaded_packages
>
>
> But when i try to install some other packages, it is ok,like ggplot2,but my friends encount the same problem with ggplot2 like stringi for me.
> we all use windows 7, and the latest version of Rstudio with R 3.1.1.
> We investgate it, open the path dir 's modify permissions, it works for some packages,but for packages like Rcpp, the problem still come!
> Is there some one happen to  know the solution?

1) Use a less unreliable OS.

2) Tame other software running on the system.  This is most often seen 
from anti-virus or indexing software which is interfering with standard 
OS operations.

> PO SU



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From rhelpmaillist at 163.com  Thu Sep 11 09:27:03 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 11 Sep 2014 15:27:03 +0800 (CST)
Subject: [R] some question about vector[-NULL]
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1917@SRVEXCHMBX.precheza.cz>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1917@SRVEXCHMBX.precheza.cz>
Message-ID: <4f29780b.c7cd.148639bbc7d.Coremail.rhelpmaillist@163.com>



It really suprise me that a[-c(0,1,2)] works as a[-c(1,2)].
But, unfortunately, a[-0] still can't work . That 's mean:
i want:
a<-1:3
a[-0]
> 1 2 3
or
a[-NULL]
> 1 2 3



--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-11 02:24:25, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:
>Hi
>
>You still do not disclose important info about details of your functions. However, when you want to perform indexing like you show, you maybe can get rid of NULL and use zero instead.
>
>> a<-1:5
>> a[-c(1,3)]
>[1] 2 4 5
>> a[-c(0,1,3)]
>[1] 2 4 5
>> a[-c(1,0,3)]
>[1] 2 4 5
>> a[-c(0,1,0,3,0)]
>[1] 2 4 5
>
>However I am almost sure that you are fishing in murky waters and what you do by cycle and fiddling with NULL elements can be achieved by more efficiently.
>
>Regards
>Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of PO SU
>> Sent: Thursday, September 11, 2014 3:54 AM
>> To: Duncan Murdoch
>> Cc: R. Help
>> Subject: Re: [R] some question about vector[-NULL]
>>
>>
>> Tks, i think using logical index is a way, but to do that, i have to
>> keep a vector as long as the original vector. that's, to exclude
>> position 1 and 3 from
>> a<-1:5
>> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which
>> c(1,3) is much shorter than b if a is a long vector. that's, b would
>> be c(F,T,F,T,T,T,T,......,T) I thought a way ,
>>  let d<-c(a,1)
>> that d<-c(1,2,3,4,5,1)
>> and initialize the index vector   iv to length(d). that is iv<-6.
>> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not.
>> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so
>> on.......
>>
>>
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>>
>>
>>
>>
>> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com>
>> wrote:
>> >On 10/09/2014 12:20 PM, William Dunlap wrote:
>> >> Can you make your example a bit more concrete?  E.g., is your 'index
>> >> vector' A an integer vector?  If so, integer(0), an integer vector
>> >> with no elements, would be a more reasonable return value than NULL,
>> >> an object of class NULL with length 0, for the 'not found' case and
>> >> you could check for that case by asking if length(A)==0.
>> >>
>> >> Show us typical inputs and expected outputs for your function (i.e.,
>> >> the problem you want to solve).
>> >
>> >I think the problem with integer(0) and NULL is the same:  a[-i]
>> doesn't
>> >act as expected (leaving out all the elements of i, i.e. nothing) if i
>> >is either of those.  The solution is to use logical indexing, not
>> >negative numerical indexing.
>> >
>> >Duncan Murdoch
>> >>
>> >> Bill Dunlap
>> >> TIBCO Software
>> >> wdunlap tibco.com
>> >>
>> >>
>> >> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com>
>> wrote:
>> >> >
>> >> > Tks for your
>> >> >
>> >> > a <- list(ress = 1, res = NULL)
>> >> > And in my second question, let me explain it :
>> >> > Actually i have two vectors in global enviroment, called A and B
>> .A is initialized to NULL which used to record some index in B.
>> >> > Then i would run a function F,  and each time, i would get a index
>> value or NULL. that's,  D<-F(B). D would be NULL or  some index
>> position in B.
>> >> > But in the function F, though input is B,  i would exclude the
>> index value from  B recorded in A. That's :
>> >> > F<-function( B ) {
>> >> > B<-B[-A]
>> >> > some processing...
>> >> > res<-NULL or some new index not included in A
>> >> > return(res)
>> >> > }
>> >> > so in a loop,
>> >> > A<-NULL
>> >> > for( i in 1:100000) {
>> >> > D<-F(B)
>> >> > A<-c(A,D)
>> >> > }
>> >> > I never know whether D is a NULL or a different index  compared
>> with indexes already recorded in A.
>> >> > Actually, A<-c(A,D) work well, i never worry about whether D is
>> NULL or a real index, but in the function F,  B<-B[-A] won't work.
>> >> > so i hope that, e.g.
>> >> > a<-1:3
>> >> > a[-NULL] wouldn't trigger an error but return a.
>> >> > Because, if i wrote function like the following:
>> >> >
>> >> > F<-function( B ) {
>> >> > if( is.null(A))
>> >> > B<-B
>> >> > else
>> >> > B<-B[-A]
>> >> > some processing...
>> >> > res<-NULL or some new index not included in A
>> >> > return(res)
>> >> > }
>> >> > May be after 5 or 10 loops, A would already not NULL, so the added
>> if ..else statement would be repeated in left  9999 loops which i would
>> not like to see.
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > --
>> >> >
>> >> > PO SU
>> >> > mail: desolator88 at 163.com
>> >> > Majored in Statistics from SJTU
>> >> >
>> >> >
>> >> >
>> >> > At 2014-09-10 06:45:59, "Duncan Murdoch"
>> <murdoch.duncan at gmail.com> wrote:
>> >> >>On 10/09/2014, 3:21 AM, PO SU wrote:
>> >> >>>
>> >> >>> Dear expeRts,
>> >> >>>       I have some programming questions about NULL in R.There
>> are listed as follows:
>> >> >>> 1. I find i can't let a list have a element NULL:
>> >> >>> a<-list()
>> >> >>> a$ress<-1
>> >> >>> a$res<-NULL
>> >> >>> a
>> >> >>> str(a)
>> >> >>
>> >> >>You can do it using
>> >> >>
>> >> >>a <- list(ress = 1, res = NULL)
>> >> >>
>> >> >>> How can i know i have a named element but it is NULL, not just
>> get a$xxxx,a$iiii,a$oooo there all get NULL
>> >> >>
>> >> >>That's a little harder.  There are a few ways:
>> >> >>
>> >> >>"res" %in% names(a) & is.null(a[["res"]])
>> >> >>
>> >> >>or
>> >> >>
>> >> >>identical(a["res"], list(res = NULL))
>> >> >>
>> >> >>or
>> >> >>
>> >> >>is.null(a[[2]])
>> >> >>
>> >> >>should all work.
>> >> >>
>> >> >>Generally because of the special handling needed, it's a bad idea
>> to try
>> >> >>to store NULL in a list.
>> >> >>
>> >> >>> 2.The most important thing:
>> >> >>> a<-1:10
>> >> >>> b<-NULL or 1
>> >> >>> a<-c(a,b) will work so i don't need to know whether b is null or
>> not,but:
>> >> >>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach
>> this purpose?
>> >> >>
>> >> >>Using !, and a logical test, e.g.
>> >> >>
>> >> >>a[!nullentry(a)]
>> >> >>
>> >> >>where nullentry() is a function based on one of the tests above,
>> but
>> >> >>applied to all entries.
>> >> >>
>> >> >>Duncan Murdoch
>> >> >>
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
>This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Sep 11 10:22:38 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 11 Sep 2014 08:22:38 +0000
Subject: [R] some question about vector[-NULL]
In-Reply-To: <4f29780b.c7cd.148639bbc7d.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1917@SRVEXCHMBX.precheza.cz>
	<4f29780b.c7cd.148639bbc7d.Coremail.rhelpmaillist@163.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1997@SRVEXCHMBX.precheza.cz>

Hi

If you insist on this behaviour you need to redefine [ function to suit your needs. You can see there is already plenty of methods for this operator.

> methods("[")
 [1] [.acf*             [.arrow*           [.AsIs             [.bibentry*
 [5] [.data.frame       [.Date             [.difftime         [.Dlist
 [9] [.factor           [.formula*         [.fractions*       [.getAnywhere*
[13] [.gList*           [.gpar*            [.gtable*          [.hexmode
[17] [.idf*             [.indexed*         [.listof           [.noquote
[21] [.numeric_version  [.octmode          [.pdf_doc*         [.person*
[25] [.POSIXct          [.POSIXlt          [.quoted*          [.raster*
[29] [.roman*           [.SavedPlots*      [.shingle*         [.simple.list
[33] [.split*           [.terms*           [.trellis*         [.ts*
[37] [.tskernel*        [.uneval*          [.unit*            [.unit.arithmetic*
[41] [.unit.list*       [.vpPath*          [.warnings

You can see how it is constructed eg. by

base:::"[.data.frame"

It can be done but if you do not persuade R core to do it for you, you need to do it yourself. As this operator is omnipresent and changing of its behaviour would change almost any R code I am afraid that you need to reprogram it yourself.

Regards
Petr


> -----Original Message-----
> From: PO SU [mailto:rhelpmaillist at 163.com]
> Sent: Thursday, September 11, 2014 9:27 AM
> To: PIKAL Petr
> Cc: R. Help
> Subject: Re:RE: [R] some question about vector[-NULL]
>
>
>
> It really suprise me that a[-c(0,1,2)] works as a[-c(1,2)].
> But, unfortunately, a[-0] still can't work . That 's mean:
> i want:
> a<-1:3
> a[-0]
> > 1 2 3
> or
> a[-NULL]
> > 1 2 3
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
>
> At 2014-09-11 02:24:25, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:
> >Hi
> >
> >You still do not disclose important info about details of your
> functions. However, when you want to perform indexing like you show,
> you maybe can get rid of NULL and use zero instead.
> >
> >> a<-1:5
> >> a[-c(1,3)]
> >[1] 2 4 5
> >> a[-c(0,1,3)]
> >[1] 2 4 5
> >> a[-c(1,0,3)]
> >[1] 2 4 5
> >> a[-c(0,1,0,3,0)]
> >[1] 2 4 5
> >
> >However I am almost sure that you are fishing in murky waters and what
> you do by cycle and fiddling with NULL elements can be achieved by more
> efficiently.
> >
> >Regards
> >Petr
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of PO SU
> >> Sent: Thursday, September 11, 2014 3:54 AM
> >> To: Duncan Murdoch
> >> Cc: R. Help
> >> Subject: Re: [R] some question about vector[-NULL]
> >>
> >>
> >> Tks, i think using logical index is a way, but to do that, i have to
> >> keep a vector as long as the original vector. that's, to exclude
> >> position 1 and 3 from
> >> a<-1:5
> >> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which
> >> c(1,3) is much shorter than b if a is a long vector. that's, b would
> >> be c(F,T,F,T,T,T,T,......,T) I thought a way ,
> >>  let d<-c(a,1)
> >> that d<-c(1,2,3,4,5,1)
> >> and initialize the index vector   iv to length(d). that is iv<-6.
> >> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not.
> >> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and
> so
> >> on.......
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >> PO SU
> >> mail: desolator88 at 163.com
> >> Majored in Statistics from SJTU
> >>
> >>
> >>
> >>
> >> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com>
> >> wrote:
> >> >On 10/09/2014 12:20 PM, William Dunlap wrote:
> >> >> Can you make your example a bit more concrete?  E.g., is your
> 'index
> >> >> vector' A an integer vector?  If so, integer(0), an integer
> vector
> >> >> with no elements, would be a more reasonable return value than
> NULL,
> >> >> an object of class NULL with length 0, for the 'not found' case
> and
> >> >> you could check for that case by asking if length(A)==0.
> >> >>
> >> >> Show us typical inputs and expected outputs for your function
> (i.e.,
> >> >> the problem you want to solve).
> >> >
> >> >I think the problem with integer(0) and NULL is the same:  a[-i]
> >> doesn't
> >> >act as expected (leaving out all the elements of i, i.e. nothing)
> if i
> >> >is either of those.  The solution is to use logical indexing, not
> >> >negative numerical indexing.
> >> >
> >> >Duncan Murdoch
> >> >>
> >> >> Bill Dunlap
> >> >> TIBCO Software
> >> >> wdunlap tibco.com
> >> >>
> >> >>
> >> >> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com>
> >> wrote:
> >> >> >
> >> >> > Tks for your
> >> >> >
> >> >> > a <- list(ress = 1, res = NULL)
> >> >> > And in my second question, let me explain it :
> >> >> > Actually i have two vectors in global enviroment, called A and
> B
> >> .A is initialized to NULL which used to record some index in B.
> >> >> > Then i would run a function F,  and each time, i would get a
> index
> >> value or NULL. that's,  D<-F(B). D would be NULL or  some index
> >> position in B.
> >> >> > But in the function F, though input is B,  i would exclude the
> >> index value from  B recorded in A. That's :
> >> >> > F<-function( B ) {
> >> >> > B<-B[-A]
> >> >> > some processing...
> >> >> > res<-NULL or some new index not included in A
> >> >> > return(res)
> >> >> > }
> >> >> > so in a loop,
> >> >> > A<-NULL
> >> >> > for( i in 1:100000) {
> >> >> > D<-F(B)
> >> >> > A<-c(A,D)
> >> >> > }
> >> >> > I never know whether D is a NULL or a different index  compared
> >> with indexes already recorded in A.
> >> >> > Actually, A<-c(A,D) work well, i never worry about whether D is
> >> NULL or a real index, but in the function F,  B<-B[-A] won't work.
> >> >> > so i hope that, e.g.
> >> >> > a<-1:3
> >> >> > a[-NULL] wouldn't trigger an error but return a.
> >> >> > Because, if i wrote function like the following:
> >> >> >
> >> >> > F<-function( B ) {
> >> >> > if( is.null(A))
> >> >> > B<-B
> >> >> > else
> >> >> > B<-B[-A]
> >> >> > some processing...
> >> >> > res<-NULL or some new index not included in A
> >> >> > return(res)
> >> >> > }
> >> >> > May be after 5 or 10 loops, A would already not NULL, so the
> added
> >> if ..else statement would be repeated in left  9999 loops which i
> would
> >> not like to see.
> >> >> >
> >> >> >
> >> >> >
> >> >> >
> >> >> >
> >> >> > --
> >> >> >
> >> >> > PO SU
> >> >> > mail: desolator88 at 163.com
> >> >> > Majored in Statistics from SJTU
> >> >> >
> >> >> >
> >> >> >
> >> >> > At 2014-09-10 06:45:59, "Duncan Murdoch"
> >> <murdoch.duncan at gmail.com> wrote:
> >> >> >>On 10/09/2014, 3:21 AM, PO SU wrote:
> >> >> >>>
> >> >> >>> Dear expeRts,
> >> >> >>>       I have some programming questions about NULL in R.There
> >> are listed as follows:
> >> >> >>> 1. I find i can't let a list have a element NULL:
> >> >> >>> a<-list()
> >> >> >>> a$ress<-1
> >> >> >>> a$res<-NULL
> >> >> >>> a
> >> >> >>> str(a)
> >> >> >>
> >> >> >>You can do it using
> >> >> >>
> >> >> >>a <- list(ress = 1, res = NULL)
> >> >> >>
> >> >> >>> How can i know i have a named element but it is NULL, not
> just
> >> get a$xxxx,a$iiii,a$oooo there all get NULL
> >> >> >>
> >> >> >>That's a little harder.  There are a few ways:
> >> >> >>
> >> >> >>"res" %in% names(a) & is.null(a[["res"]])
> >> >> >>
> >> >> >>or
> >> >> >>
> >> >> >>identical(a["res"], list(res = NULL))
> >> >> >>
> >> >> >>or
> >> >> >>
> >> >> >>is.null(a[[2]])
> >> >> >>
> >> >> >>should all work.
> >> >> >>
> >> >> >>Generally because of the special handling needed, it's a bad
> idea
> >> to try
> >> >> >>to store NULL in a list.
> >> >> >>
> >> >> >>> 2.The most important thing:
> >> >> >>> a<-1:10
> >> >> >>> b<-NULL or 1
> >> >> >>> a<-c(a,b) will work so i don't need to know whether b is null
> or
> >> not,but:
> >> >> >>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i
> reach
> >> this purpose?
> >> >> >>
> >> >> >>Using !, and a logical test, e.g.
> >> >> >>
> >> >> >>a[!nullentry(a)]
> >> >> >>
> >> >> >>where nullentry() is a function based on one of the tests
> above,
> >> but
> >> >> >>applied to all entries.
> >> >> >>
> >> >> >>Duncan Murdoch
> >> >> >>
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide http://www.R-
> project.org/posting-
> >> guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible
> code.
> >> >
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >________________________________
> >Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou ur?eny pouze jeho adres?t?m.
> >Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> >Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> >V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> >- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> >This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> >If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> >If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> >The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> >In case that this e-mail forms part of business dealings:
> >- the sender reserves the right to end negotiations about entering
> into a contract in any time, for any reason, and without stating any
> reasoning.
> >- if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> >- the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> >- the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From stefan at inizio.se  Thu Sep 11 10:47:10 2014
From: stefan at inizio.se (Stefan Petersson)
Date: Thu, 11 Sep 2014 10:47:10 +0200
Subject: [R] Margins to fill matrix
Message-ID: <CAFy6Y8UxCbsbm05P2rtPjUGOj3_TBZB9iM0gm6PvU1ZR3ugXZg@mail.gmail.com>

Hi,

I have two vector of margins. Now I want to create "fill" matrix that
reflects the margins.

 seats <- c(17,24,28,30,34,36,40,44,46,50)
 mandates <- c(107,23,24,19,112,19,25,20)

Both vectors adds up to 349. So I want a 10x8 matrix with row sums
corresponding to "seats" and column sums corresponding to "mandates".


From arnaud.gaboury at gmail.com  Thu Sep 11 10:49:12 2014
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 11 Sep 2014 10:49:12 +0200
Subject: [R] Building R for better performance
In-Reply-To: <5410B719.7030706@yahoo.co.uk>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<87430F4E-90CE-4A20-87D0-EFBBE293FB9C@uni-bonn.de>
	<9EB21FFA75EC13438CA12AD2A022D8CC2E9C5A6F@ORSMSX104.amr.corp.intel.com>
	<5410B719.7030706@yahoo.co.uk>
Message-ID: <CAK1hC9utTPpzQYhmdoPQwvmomJJ01cBrOd+6dyoY3p-oBaS8zw@mail.gmail.com>

>> I got the benchmark script, which I've attached, from Texas Advanced
>> Computing Center.  Here are my results (elapsed times, in secs):


Where can we get the benchmark script?


From madhvi.gupta at orkash.com  Thu Sep 11 11:08:26 2014
From: madhvi.gupta at orkash.com (madhvi.gupta)
Date: Thu, 11 Sep 2014 14:38:26 +0530
Subject: [R] How to get JRI package
Message-ID: <5411668A.8070006@orkash.com>

Hi,
My R Studio version is 3.1.0 but JRI package is not getting installed on 
it.It is giving the following error.
package ?JRI? is not available (for R version 3.1.0)
Is there any another way to do this?

Thanks


From angel.rodriguez at matiainstituto.net  Thu Sep 11 11:10:05 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Thu, 11 Sep 2014 11:10:05 +0200
Subject: [R] R, Big Data and books
References: <8564BCD7D26E0D40872F1A132C8BBB250258B272@MATIAEXCH.matiaf.local>
	<CAHy4naENKP5VYGS1VyKNLafb6Ywq7Ob+51UVYpAiYN8s6e9FMA@mail.gmail.com>
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB25030F6EEA@MATIAEXCH.matiaf.local>

Sorry for that, Glenn.

http://statweb.stanford.edu/~tibs/ElemStatLearn/

Have also a look at this that I've run into:

http://codecondo.com/9-free-books-for-learning-data-mining-data-analysis/

Best regards,

Angel

De: Glenn Doherty [mailto:glennrdoherty at gmail.com] 
Enviado el: mi?rcoles, 10 de septiembre de 2014 18:10
Para: Angel Rodriguez
Asunto: Re: [R] R, Big Data and books

Angel,
Thanks for the references. I am not seeing the name or link to the book that is "free and recommended by John Hopskins' Department of Statistics". Can you please let me know the name of that book. Thanks again for all your help.
Glenn

On Wed, Sep 10, 2014 at 3:37 AM, Angel Rodriguez <angel.rodriguez at matiainstituto.net> wrote:
>From an email list:

"R is well known in the world of Big Data and is increasing in popularity. A number of very useful resources are available for anyone undertaking data mining in R.
For example, Luis Torgo has just published a book called Data Mining with R - learning with case studies (Torgo, Luis. Data Mining with R. ), and presents a set of four case studies with accompanying data sets and code which the interested student can work through. Torgo's book provides the usual analytic and graphical techniques used every day by data miners, including specialized visualization techniques, dealing with missing values, developing prediction models, and methods for evaluating the performance of your models.
Also of interest to the data miner is the Rattle (R Analytical Tool to Learn Easily) GUI. Rattle is a data mining facility for analyzing very large data sets. It provides many useful statistical and graphical data summaries, presents mechanisms for developing a variety of models, and summarizes the performance of your models.
Another web-site worth reading is the following:
http://www.revolutionanalytics.com/"

Also check this book (free and recommended by John Hopskins' Department of Statistics".

Best regards,

Angel Rodriguez-Laso




? ? ? ? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Thu Sep 11 11:14:43 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 11 Sep 2014 18:14:43 +0900
Subject: [R] How to get JRI package
In-Reply-To: <5411668A.8070006@orkash.com>
References: <5411668A.8070006@orkash.com>
Message-ID: <CAAcyNCx0y-06bjwCgx+=ZK7zA95brZF6UAr24CNFAsxJOVS+BQ@mail.gmail.com>

Hi,

As far as I know, there is any package "JRI". You need to install "rJava".

Regards,
Pascal

On Thu, Sep 11, 2014 at 6:08 PM, madhvi.gupta <madhvi.gupta at orkash.com> wrote:
> Hi,
> My R Studio version is 3.1.0 but JRI package is not getting installed on
> it.It is giving the following error.
> package ?JRI? is not available (for R version 3.1.0)
> Is there any another way to do this?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From murdoch.duncan at gmail.com  Thu Sep 11 11:38:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 11 Sep 2014 05:38:12 -0400
Subject: [R] some question about vector[-NULL]
In-Reply-To: <117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
Message-ID: <54116D84.2030501@gmail.com>

On 10/09/2014, 9:53 PM, PO SU wrote:
> 
> Tks, i think using logical index is a way, but to do that, i have to keep a vector as long as the original vector. that's, to exclude position 1 and 3 from 
> a<-1:5
> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which c(1,3) is much shorter than b if a is a long vector. that's, b would be c(F,T,F,T,T,T,T,......,T)

If you know that you want to omit elements 1 and 3, then negative
integer indexing is safe.  You'll never need to explicitly type out the
whole logical vector.

The only problem with it is when you construct the indices by tests, and
sometimes nothing matches the tests, so you end up with an empty vector
or NULL.  In that case you can just as easily construct the logical
vector.

If your vectors are so long that you are worried about the cost of
constructing a logical vector that long, then it's probably worthwhile
checking the length of the integer index explicitly, i.e. instead of

a <- a[ -i ]

use

if (any(i > 0)) a <- a[ -i ]

Duncan Murdoch


> I thought a way ,
>  let d<-c(a,1) 
> that d<-c(1,2,3,4,5,1)
> and initialize the index vector   iv to length(d). that is iv<-6.
> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not. 
> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so on.......
>  
> 
> 
> 
> 
> 
> 
> --
> 
> PO SU
> mail: desolator88 at 163.com 
> Majored in Statistics from SJTU
> 
> 
> 
> 
> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>> On 10/09/2014 12:20 PM, William Dunlap wrote:
>>> Can you make your example a bit more concrete?  E.g., is your 'index
>>> vector' A an integer vector?  If so, integer(0), an integer vector
>>> with no elements, would be a more reasonable return value than NULL,
>>> an object of class NULL with length 0, for the 'not found' case and
>>> you could check for that case by asking if length(A)==0.
>>>
>>> Show us typical inputs and expected outputs for your function (i.e.,
>>> the problem you want to solve).
>>
>> I think the problem with integer(0) and NULL is the same:  a[-i] doesn't 
>> act as expected (leaving out all the elements of i, i.e. nothing) if i 
>> is either of those.  The solution is to use logical indexing, not 
>> negative numerical indexing.
>>
>> Duncan Murdoch
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>>>
>>>> Tks for your
>>>>
>>>> a <- list(ress = 1, res = NULL)
>>>> And in my second question, let me explain it :
>>>> Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
>>>> Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
>>>> But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
>>>> F<-function( B ) {
>>>> B<-B[-A]
>>>> some processing...
>>>> res<-NULL or some new index not included in A
>>>> return(res)
>>>> }
>>>> so in a loop,
>>>> A<-NULL
>>>> for( i in 1:100000) {
>>>> D<-F(B)
>>>> A<-c(A,D)
>>>> }
>>>> I never know whether D is a NULL or a different index  compared with indexes already recorded in A.
>>>> Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
>>>> so i hope that, e.g.
>>>> a<-1:3
>>>> a[-NULL] wouldn't trigger an error but return a.
>>>> Because, if i wrote function like the following:
>>>>
>>>> F<-function( B ) {
>>>> if( is.null(A))
>>>> B<-B
>>>> else
>>>> B<-B[-A]
>>>> some processing...
>>>> res<-NULL or some new index not included in A
>>>> return(res)
>>>> }
>>>> May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>>
>>>> PO SU
>>>> mail: desolator88 at 163.com
>>>> Majored in Statistics from SJTU
>>>>
>>>>
>>>>
>>>> At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>> On 10/09/2014, 3:21 AM, PO SU wrote:
>>>>>>
>>>>>> Dear expeRts,
>>>>>>       I have some programming questions about NULL in R.There are listed as follows:
>>>>>> 1. I find i can't let a list have a element NULL:
>>>>>> a<-list()
>>>>>> a$ress<-1
>>>>>> a$res<-NULL
>>>>>> a
>>>>>> str(a)
>>>>>
>>>>> You can do it using
>>>>>
>>>>> a <- list(ress = 1, res = NULL)
>>>>>
>>>>>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
>>>>>
>>>>> That's a little harder.  There are a few ways:
>>>>>
>>>>> "res" %in% names(a) & is.null(a[["res"]])
>>>>>
>>>>> or
>>>>>
>>>>> identical(a["res"], list(res = NULL))
>>>>>
>>>>> or
>>>>>
>>>>> is.null(a[[2]])
>>>>>
>>>>> should all work.
>>>>>
>>>>> Generally because of the special handling needed, it's a bad idea to try
>>>>> to store NULL in a list.
>>>>>
>>>>>> 2.The most important thing:
>>>>>> a<-1:10
>>>>>> b<-NULL or 1
>>>>>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
>>>>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
>>>>>
>>>>> Using !, and a logical test, e.g.
>>>>>
>>>>> a[!nullentry(a)]
>>>>>
>>>>> where nullentry() is a function based on one of the tests above, but
>>>>> applied to all entries.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>


From kridox at ymail.com  Thu Sep 11 11:57:04 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 11 Sep 2014 18:57:04 +0900
Subject: [R] How to get JRI package
In-Reply-To: <54116EE8.5090206@orkash.com>
References: <5411668A.8070006@orkash.com>
	<CAAcyNCx0y-06bjwCgx+=ZK7zA95brZF6UAr24CNFAsxJOVS+BQ@mail.gmail.com>
	<54116EE8.5090206@orkash.com>
Message-ID: <CAAcyNCw80qxPOX4aNe5bh11JNPOPdYshGfKqxOseRDVFS1bBGw@mail.gmail.com>

Please check this link, particularly the red line: http://rforge.net/JRI/

Regards,
Pascal

On Thu, Sep 11, 2014 at 6:44 PM, madhvi.gupta <madhvi.gupta at orkash.com> wrote:
> I already have rjava.JRI package is for r java interface
>
> On 09/11/2014 02:44 PM, Pascal Oettli wrote:
>>
>> Hi,
>>
>> As far as I know, there is any package "JRI". You need to install "rJava".
>>
>> Regards,
>> Pascal
>>
>> On Thu, Sep 11, 2014 at 6:08 PM, madhvi.gupta <madhvi.gupta at orkash.com>
>> wrote:
>>>
>>> Hi,
>>> My R Studio version is 3.1.0 but JRI package is not getting installed on
>>> it.It is giving the following error.
>>> package ?JRI? is not available (for R version 3.1.0)
>>> Is there any another way to do this?
>>>
>>> Thanks
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From rhelpmaillist at 163.com  Thu Sep 11 11:59:42 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 11 Sep 2014 17:59:42 +0800 (CST)
Subject: [R] some question about vector[-NULL]
In-Reply-To: <54116D84.2030501@gmail.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
	<54116D84.2030501@gmail.com>
Message-ID: <5948a4bf.11b5b.14864277e30.Coremail.rhelpmaillist@163.com>


Orignally i?don't want to do the if ( length) check because i know that in a 10000 loops, after may be 10 or 20 or 100 loops , "i" will not be empty. 
so i mean , in the left loops, i would always check something not?needed to check?which i?would not like to do.

?

--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-11 05:38:12, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>On 10/09/2014, 9:53 PM, PO SU wrote:
>> 
>> Tks, i think using logical index is a way, but to do that, i have to keep a vector as long as the original vector. that's, to exclude position 1 and 3 from 
>> a<-1:5
>> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which c(1,3) is much shorter than b if a is a long vector. that's, b would be c(F,T,F,T,T,T,T,......,T)
>
>If you know that you want to omit elements 1 and 3, then negative
>integer indexing is safe.  You'll never need to explicitly type out the
>whole logical vector.
>
>The only problem with it is when you construct the indices by tests, and
>sometimes nothing matches the tests, so you end up with an empty vector
>or NULL.  In that case you can just as easily construct the logical
>vector.
>
>If your vectors are so long that you are worried about the cost of
>constructing a logical vector that long, then it's probably worthwhile
>checking the length of the integer index explicitly, i.e. instead of
>
>a <- a[ -i ]
>
>use
>
>if (any(i > 0)) a <- a[ -i ]
>
>Duncan Murdoch
>
>
>> I thought a way ,
>>  let d<-c(a,1) 
>> that d<-c(1,2,3,4,5,1)
>> and initialize the index vector   iv to length(d). that is iv<-6.
>> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not. 
>> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so on.......
>>  
>> 
>> 
>> 
>> 
>> 
>> 
>> --
>> 
>> PO SU
>> mail: desolator88 at 163.com 
>> Majored in Statistics from SJTU
>> 
>> 
>> 
>> 
>> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>> On 10/09/2014 12:20 PM, William Dunlap wrote:
>>>> Can you make your example a bit more concrete?  E.g., is your 'index
>>>> vector' A an integer vector?  If so, integer(0), an integer vector
>>>> with no elements, would be a more reasonable return value than NULL,
>>>> an object of class NULL with length 0, for the 'not found' case and
>>>> you could check for that case by asking if length(A)==0.
>>>>
>>>> Show us typical inputs and expected outputs for your function (i.e.,
>>>> the problem you want to solve).
>>>
>>> I think the problem with integer(0) and NULL is the same:  a[-i] doesn't 
>>> act as expected (leaving out all the elements of i, i.e. nothing) if i 
>>> is either of those.  The solution is to use logical indexing, not 
>>> negative numerical indexing.
>>>
>>> Duncan Murdoch
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>>>>
>>>>> Tks for your
>>>>>
>>>>> a <- list(ress = 1, res = NULL)
>>>>> And in my second question, let me explain it :
>>>>> Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
>>>>> Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
>>>>> But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
>>>>> F<-function( B ) {
>>>>> B<-B[-A]
>>>>> some processing...
>>>>> res<-NULL or some new index not included in A
>>>>> return(res)
>>>>> }
>>>>> so in a loop,
>>>>> A<-NULL
>>>>> for( i in 1:100000) {
>>>>> D<-F(B)
>>>>> A<-c(A,D)
>>>>> }
>>>>> I never know whether D is a NULL or a different index  compared with indexes already recorded in A.
>>>>> Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
>>>>> so i hope that, e.g.
>>>>> a<-1:3
>>>>> a[-NULL] wouldn't trigger an error but return a.
>>>>> Because, if i wrote function like the following:
>>>>>
>>>>> F<-function( B ) {
>>>>> if( is.null(A))
>>>>> B<-B
>>>>> else
>>>>> B<-B[-A]
>>>>> some processing...
>>>>> res<-NULL or some new index not included in A
>>>>> return(res)
>>>>> }
>>>>> May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>>
>>>>> PO SU
>>>>> mail: desolator88 at 163.com
>>>>> Majored in Statistics from SJTU
>>>>>
>>>>>
>>>>>
>>>>> At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>>> On 10/09/2014, 3:21 AM, PO SU wrote:
>>>>>>>
>>>>>>> Dear expeRts,
>>>>>>>       I have some programming questions about NULL in R.There are listed as follows:
>>>>>>> 1. I find i can't let a list have a element NULL:
>>>>>>> a<-list()
>>>>>>> a$ress<-1
>>>>>>> a$res<-NULL
>>>>>>> a
>>>>>>> str(a)
>>>>>>
>>>>>> You can do it using
>>>>>>
>>>>>> a <- list(ress = 1, res = NULL)
>>>>>>
>>>>>>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
>>>>>>
>>>>>> That's a little harder.  There are a few ways:
>>>>>>
>>>>>> "res" %in% names(a) & is.null(a[["res"]])
>>>>>>
>>>>>> or
>>>>>>
>>>>>> identical(a["res"], list(res = NULL))
>>>>>>
>>>>>> or
>>>>>>
>>>>>> is.null(a[[2]])
>>>>>>
>>>>>> should all work.
>>>>>>
>>>>>> Generally because of the special handling needed, it's a bad idea to try
>>>>>> to store NULL in a list.
>>>>>>
>>>>>>> 2.The most important thing:
>>>>>>> a<-1:10
>>>>>>> b<-NULL or 1
>>>>>>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
>>>>>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
>>>>>>
>>>>>> Using !, and a logical test, e.g.
>>>>>>
>>>>>> a[!nullentry(a)]
>>>>>>
>>>>>> where nullentry() is a function based on one of the tests above, but
>>>>>> applied to all entries.
>>>>>>
>>>>>> Duncan Murdoch
>>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>

From rhelpmaillist at 163.com  Thu Sep 11 12:04:58 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 11 Sep 2014 18:04:58 +0800 (CST)
Subject: [R] some question about vector[-NULL]
In-Reply-To: <5948a4bf.11b5b.14864277e30.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
	<54116D84.2030501@gmail.com>
	<5948a4bf.11b5b.14864277e30.Coremail.rhelpmaillist@163.com>
Message-ID: <2262fa98.11cee.148642c4e4c.Coremail.rhelpmaillist@163.com>



Actually, i??thought ?the way:
a<-1:3
b<-NULL or 2
a[-b] will not work if b is NULL

A<-c(a,1)
B<-c(b,length(A))
A[-B] will get the same result as if b is NULL get a, if b is 2 get a[-2]

I think it works well? in considering memory use or efficiency or code tidy.




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-11 05:59:42, "PO SU" <rhelpmaillist at 163.com> wrote:
>
>Orignally i?don't want to do the if ( length) check because i know that in a 10000 loops, after may be 10 or 20 or 100 loops , "i" will not be empty. 
>so i mean , in the left loops, i would always check something not?needed to check?which i?would not like to do.
>
>?
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>
>
>
>
>At 2014-09-11 05:38:12, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>On 10/09/2014, 9:53 PM, PO SU wrote:
>>> 
>>> Tks, i think using logical index is a way, but to do that, i have to keep a vector as long as the original vector. that's, to exclude position 1 and 3 from 
>>> a<-1:5
>>> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which c(1,3) is much shorter than b if a is a long vector. that's, b would be c(F,T,F,T,T,T,T,......,T)
>>
>>If you know that you want to omit elements 1 and 3, then negative
>>integer indexing is safe.  You'll never need to explicitly type out the
>>whole logical vector.
>>
>>The only problem with it is when you construct the indices by tests, and
>>sometimes nothing matches the tests, so you end up with an empty vector
>>or NULL.  In that case you can just as easily construct the logical
>>vector.
>>
>>If your vectors are so long that you are worried about the cost of
>>constructing a logical vector that long, then it's probably worthwhile
>>checking the length of the integer index explicitly, i.e. instead of
>>
>>a <- a[ -i ]
>>
>>use
>>
>>if (any(i > 0)) a <- a[ -i ]
>>
>>Duncan Murdoch
>>
>>
>>> I thought a way ,
>>>  let d<-c(a,1) 
>>> that d<-c(1,2,3,4,5,1)
>>> and initialize the index vector   iv to length(d). that is iv<-6.
>>> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not. 
>>> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so on.......
>>>  
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> --
>>> 
>>> PO SU
>>> mail: desolator88 at 163.com 
>>> Majored in Statistics from SJTU
>>> 
>>> 
>>> 
>>> 
>>> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>> On 10/09/2014 12:20 PM, William Dunlap wrote:
>>>>> Can you make your example a bit more concrete?  E.g., is your 'index
>>>>> vector' A an integer vector?  If so, integer(0), an integer vector
>>>>> with no elements, would be a more reasonable return value than NULL,
>>>>> an object of class NULL with length 0, for the 'not found' case and
>>>>> you could check for that case by asking if length(A)==0.
>>>>>
>>>>> Show us typical inputs and expected outputs for your function (i.e.,
>>>>> the problem you want to solve).
>>>>
>>>> I think the problem with integer(0) and NULL is the same:  a[-i] doesn't 
>>>> act as expected (leaving out all the elements of i, i.e. nothing) if i 
>>>> is either of those.  The solution is to use logical indexing, not 
>>>> negative numerical indexing.
>>>>
>>>> Duncan Murdoch
>>>>>
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>>
>>>>> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>>>>>
>>>>>> Tks for your
>>>>>>
>>>>>> a <- list(ress = 1, res = NULL)
>>>>>> And in my second question, let me explain it :
>>>>>> Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
>>>>>> Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
>>>>>> But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
>>>>>> F<-function( B ) {
>>>>>> B<-B[-A]
>>>>>> some processing...
>>>>>> res<-NULL or some new index not included in A
>>>>>> return(res)
>>>>>> }
>>>>>> so in a loop,
>>>>>> A<-NULL
>>>>>> for( i in 1:100000) {
>>>>>> D<-F(B)
>>>>>> A<-c(A,D)
>>>>>> }
>>>>>> I never know whether D is a NULL or a different index  compared with indexes already recorded in A.
>>>>>> Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
>>>>>> so i hope that, e.g.
>>>>>> a<-1:3
>>>>>> a[-NULL] wouldn't trigger an error but return a.
>>>>>> Because, if i wrote function like the following:
>>>>>>
>>>>>> F<-function( B ) {
>>>>>> if( is.null(A))
>>>>>> B<-B
>>>>>> else
>>>>>> B<-B[-A]
>>>>>> some processing...
>>>>>> res<-NULL or some new index not included in A
>>>>>> return(res)
>>>>>> }
>>>>>> May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>>
>>>>>> PO SU
>>>>>> mail: desolator88 at 163.com
>>>>>> Majored in Statistics from SJTU
>>>>>>
>>>>>>
>>>>>>
>>>>>> At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>>>> On 10/09/2014, 3:21 AM, PO SU wrote:
>>>>>>>>
>>>>>>>> Dear expeRts,
>>>>>>>>       I have some programming questions about NULL in R.There are listed as follows:
>>>>>>>> 1. I find i can't let a list have a element NULL:
>>>>>>>> a<-list()
>>>>>>>> a$ress<-1
>>>>>>>> a$res<-NULL
>>>>>>>> a
>>>>>>>> str(a)
>>>>>>>
>>>>>>> You can do it using
>>>>>>>
>>>>>>> a <- list(ress = 1, res = NULL)
>>>>>>>
>>>>>>>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
>>>>>>>
>>>>>>> That's a little harder.  There are a few ways:
>>>>>>>
>>>>>>> "res" %in% names(a) & is.null(a[["res"]])
>>>>>>>
>>>>>>> or
>>>>>>>
>>>>>>> identical(a["res"], list(res = NULL))
>>>>>>>
>>>>>>> or
>>>>>>>
>>>>>>> is.null(a[[2]])
>>>>>>>
>>>>>>> should all work.
>>>>>>>
>>>>>>> Generally because of the special handling needed, it's a bad idea to try
>>>>>>> to store NULL in a list.
>>>>>>>
>>>>>>>> 2.The most important thing:
>>>>>>>> a<-1:10
>>>>>>>> b<-NULL or 1
>>>>>>>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
>>>>>>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
>>>>>>>
>>>>>>> Using !, and a logical test, e.g.
>>>>>>>
>>>>>>> a[!nullentry(a)]
>>>>>>>
>>>>>>> where nullentry() is a function based on one of the tests above, but
>>>>>>> applied to all entries.
>>>>>>>
>>>>>>> Duncan Murdoch
>>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>

From rl at openmailbox.org  Thu Sep 11 12:46:53 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Thu, 11 Sep 2014 10:46:53 +0000
Subject: [R] sequential input script dataframe process functionality
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE16F7@SRVEXCHMBX.precheza.cz>
References: <695146e848491ad828a6cb1374b16a15@openmailbox.org>
	<487b01efa9bd42b8b3bd8708e3e2b285@openmailbox.org>
	<CAF8bMcYREtp7uZ6p653_NVHGSrJvm1FYhiWWQfKMTYCmdTbrig@mail.gmail.com>
	<6f4f6fd6eaf0164f42b958a4f4d56848@openmailbox.org>
	<CAF8bMcaXtZiLRQE55ZvuhH4XYPyBVzQneJn0KJSGBHr_V5vSDA@mail.gmail.com>
	<d4743dcf80f5d20a9e3ac5d0530ab6e3@openmailbox.org>
	<CAF8bMcbjCiLkHWHpqqk78jHY5PPP7Ge+zHnYsmmu8zXQUd2YLQ@mail.gmail.com>
	<daa78bae9b65fb128b98396bb882c816@openmailbox.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE16F7@SRVEXCHMBX.precheza.cz>
Message-ID: <a2f9998dc324f94fac0bb0975f62f0b0@openmailbox.org>

On 2014-09-10 10:45, PIKAL Petr wrote:
>> 
>> On 2014-09-08 15:47, William Dunlap wrote:
>> > d <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
>> > i <- 1 # possible output of menu(unique(d$Choices))
>> > d[ d$Choices[i] == d$Choices, ]
>> > #  Choices X
>> > #1     One 1
>> > #3     One 3
>> >
>> 
>> > testd <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
>> > testi <- 1 # possible output of menu(unique(d$Choices))
>> > testd[ testd$Choices[testi] == testd$Choices, ]
>>    Choices X
>> 1     One 1
>> 3     One 3
>> 
>> This instruction did not give any opportunity to enter a choice? Then
>> tried:
> 
> Why do you think so? Did you try it? Follow Wiliam's advice
> 
> d <- data.frame(Choices=c("One","Two","One","Three"), X=1:4)
> i <- menu(unique(d$Choices))
> 

It looks that you understood that 'menu...' was to be assigned to the 
variable 'i'; I did not understand, it was interpreted as a part of a 
comment, not a command to apply! :)

Of course, the menu function as you wrote it was successfully 
replicated. Thanks.

> 
> BTW, did you read R-intro? If not, why not?
> 

Yes, but for the benefit of other novices, information about 'menu' is 
accessible via '?menu' within R, or via R command 'help.start()' and web 
browser hyperlinks: 'packages','utils','menu'.


From murdoch.duncan at gmail.com  Thu Sep 11 12:48:44 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 11 Sep 2014 06:48:44 -0400
Subject: [R] some question about vector[-NULL]
In-Reply-To: <2262fa98.11cee.148642c4e4c.Coremail.rhelpmaillist@163.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
	<54116D84.2030501@gmail.com>
	<5948a4bf.11b5b.14864277e30.Coremail.rhelpmaillist@163.com>
	<2262fa98.11cee.148642c4e4c.Coremail.rhelpmaillist@163.com>
Message-ID: <54117E0C.6000905@gmail.com>

On 11/09/2014, 6:04 AM, PO SU wrote:
> 
> 
> Actually, i  thought  the way:
> a<-1:3
> b<-NULL or 2
> a[-b] will not work if b is NULL
> 
> A<-c(a,1)

If a is a long vector, that is a very expensive operation, at least as
expensive as constructing a logical vector of the same length as a.

> B<-c(b,length(A))
> A[-B] will get the same result as if b is NULL get a, if b is 2 get a[-2]
> 
> I think it works well  in considering memory use or efficiency or code tidy.

Understanding R memory use is hard:  be sure to profile it before you
decide on the efficiency of one operation over another.

Duncan Murdoch

> 
> 
> 
> 
> --
> 
> PO SU
> mail: desolator88 at 163.com 
> Majored in Statistics from SJTU
> 
> 
> 
> 
> At 2014-09-11 05:59:42, "PO SU" <rhelpmaillist at 163.com> wrote:
>>
>> Orignally i don't want to do the if ( length) check because i know that in a 10000 loops, after may be 10 or 20 or 100 loops , "i" will not be empty. 
>> so i mean , in the left loops, i would always check something not needed to check which i would not like to do.
>>
>>  
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com 
>> Majored in Statistics from SJTU
>>
>>
>>
>>
>> At 2014-09-11 05:38:12, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>> On 10/09/2014, 9:53 PM, PO SU wrote:
>>>>
>>>> Tks, i think using logical index is a way, but to do that, i have to keep a vector as long as the original vector. that's, to exclude position 1 and 3 from 
>>>> a<-1:5
>>>> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which c(1,3) is much shorter than b if a is a long vector. that's, b would be c(F,T,F,T,T,T,T,......,T)
>>>
>>> If you know that you want to omit elements 1 and 3, then negative
>>> integer indexing is safe.  You'll never need to explicitly type out the
>>> whole logical vector.
>>>
>>> The only problem with it is when you construct the indices by tests, and
>>> sometimes nothing matches the tests, so you end up with an empty vector
>>> or NULL.  In that case you can just as easily construct the logical
>>> vector.
>>>
>>> If your vectors are so long that you are worried about the cost of
>>> constructing a logical vector that long, then it's probably worthwhile
>>> checking the length of the integer index explicitly, i.e. instead of
>>>
>>> a <- a[ -i ]
>>>
>>> use
>>>
>>> if (any(i > 0)) a <- a[ -i ]
>>>
>>> Duncan Murdoch
>>>
>>>
>>>> I thought a way ,
>>>>  let d<-c(a,1) 
>>>> that d<-c(1,2,3,4,5,1)
>>>> and initialize the index vector   iv to length(d). that is iv<-6.
>>>> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not. 
>>>> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so on.......
>>>>  
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>>
>>>> PO SU
>>>> mail: desolator88 at 163.com 
>>>> Majored in Statistics from SJTU
>>>>
>>>>
>>>>
>>>>
>>>> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>> On 10/09/2014 12:20 PM, William Dunlap wrote:
>>>>>> Can you make your example a bit more concrete?  E.g., is your 'index
>>>>>> vector' A an integer vector?  If so, integer(0), an integer vector
>>>>>> with no elements, would be a more reasonable return value than NULL,
>>>>>> an object of class NULL with length 0, for the 'not found' case and
>>>>>> you could check for that case by asking if length(A)==0.
>>>>>>
>>>>>> Show us typical inputs and expected outputs for your function (i.e.,
>>>>>> the problem you want to solve).
>>>>>
>>>>> I think the problem with integer(0) and NULL is the same:  a[-i] doesn't 
>>>>> act as expected (leaving out all the elements of i, i.e. nothing) if i 
>>>>> is either of those.  The solution is to use logical indexing, not 
>>>>> negative numerical indexing.
>>>>>
>>>>> Duncan Murdoch
>>>>>>
>>>>>> Bill Dunlap
>>>>>> TIBCO Software
>>>>>> wdunlap tibco.com
>>>>>>
>>>>>>
>>>>>> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>>>>>>
>>>>>>> Tks for your
>>>>>>>
>>>>>>> a <- list(ress = 1, res = NULL)
>>>>>>> And in my second question, let me explain it :
>>>>>>> Actually i have two vectors in global enviroment, called A and B .A is initialized to NULL which used to record some index in B.
>>>>>>> Then i would run a function F,  and each time, i would get a index value or NULL. that's,  D<-F(B). D would be NULL or  some index position in B.
>>>>>>> But in the function F, though input is B,  i would exclude the index value from  B recorded in A. That's :
>>>>>>> F<-function( B ) {
>>>>>>> B<-B[-A]
>>>>>>> some processing...
>>>>>>> res<-NULL or some new index not included in A
>>>>>>> return(res)
>>>>>>> }
>>>>>>> so in a loop,
>>>>>>> A<-NULL
>>>>>>> for( i in 1:100000) {
>>>>>>> D<-F(B)
>>>>>>> A<-c(A,D)
>>>>>>> }
>>>>>>> I never know whether D is a NULL or a different index  compared with indexes already recorded in A.
>>>>>>> Actually, A<-c(A,D) work well, i never worry about whether D is NULL or a real index, but in the function F,  B<-B[-A] won't work.
>>>>>>> so i hope that, e.g.
>>>>>>> a<-1:3
>>>>>>> a[-NULL] wouldn't trigger an error but return a.
>>>>>>> Because, if i wrote function like the following:
>>>>>>>
>>>>>>> F<-function( B ) {
>>>>>>> if( is.null(A))
>>>>>>> B<-B
>>>>>>> else
>>>>>>> B<-B[-A]
>>>>>>> some processing...
>>>>>>> res<-NULL or some new index not included in A
>>>>>>> return(res)
>>>>>>> }
>>>>>>> May be after 5 or 10 loops, A would already not NULL, so the added if ..else statement would be repeated in left  9999 loops which i would not like to see.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>>
>>>>>>> PO SU
>>>>>>> mail: desolator88 at 163.com
>>>>>>> Majored in Statistics from SJTU
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> At 2014-09-10 06:45:59, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>>>>> On 10/09/2014, 3:21 AM, PO SU wrote:
>>>>>>>>>
>>>>>>>>> Dear expeRts,
>>>>>>>>>       I have some programming questions about NULL in R.There are listed as follows:
>>>>>>>>> 1. I find i can't let a list have a element NULL:
>>>>>>>>> a<-list()
>>>>>>>>> a$ress<-1
>>>>>>>>> a$res<-NULL
>>>>>>>>> a
>>>>>>>>> str(a)
>>>>>>>>
>>>>>>>> You can do it using
>>>>>>>>
>>>>>>>> a <- list(ress = 1, res = NULL)
>>>>>>>>
>>>>>>>>> How can i know i have a named element but it is NULL, not just get a$xxxx,a$iiii,a$oooo there all get NULL
>>>>>>>>
>>>>>>>> That's a little harder.  There are a few ways:
>>>>>>>>
>>>>>>>> "res" %in% names(a) & is.null(a[["res"]])
>>>>>>>>
>>>>>>>> or
>>>>>>>>
>>>>>>>> identical(a["res"], list(res = NULL))
>>>>>>>>
>>>>>>>> or
>>>>>>>>
>>>>>>>> is.null(a[[2]])
>>>>>>>>
>>>>>>>> should all work.
>>>>>>>>
>>>>>>>> Generally because of the special handling needed, it's a bad idea to try
>>>>>>>> to store NULL in a list.
>>>>>>>>
>>>>>>>>> 2.The most important thing:
>>>>>>>>> a<-1:10
>>>>>>>>> b<-NULL or 1
>>>>>>>>> a<-c(a,b) will work so i don't need to know whether b is null or not,but:
>>>>>>>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach this purpose?
>>>>>>>>
>>>>>>>> Using !, and a logical test, e.g.
>>>>>>>>
>>>>>>>> a[!nullentry(a)]
>>>>>>>>
>>>>>>>> where nullentry() is a function based on one of the tests above, but
>>>>>>>> applied to all entries.
>>>>>>>>
>>>>>>>> Duncan Murdoch
>>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>


From jim at bitwrit.com.au  Thu Sep 11 12:58:54 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 11 Sep 2014 20:58:54 +1000
Subject: [R] marketing-questionnaire with split-design
In-Reply-To: <CAEzmP8i7x8eE9akGxpL+7Z4YySM5Jhx9Tbz1Q=ThqN2kHsaP1A@mail.gmail.com>
References: <CAEzmP8i7x8eE9akGxpL+7Z4YySM5Jhx9Tbz1Q=ThqN2kHsaP1A@mail.gmail.com>
Message-ID: <1604080.m69SCYtKi7@localhost.localdomain>

On Tue, 9 Sep 2014 04:42:11 PM Norbert D?rrer wrote:
> Dear Experts
> 
> I'm quite new to the world of R; so maybe my question is kind of
> beginners...
> 
> I am right now trying to analyse questionnaire data (CAWI) for 
producing a
> image/positioning map of the competitors of my company; when 
programming
> the CAWI, a split design was needed; every respondent had to 
answer a
> couple of multiple-choice questions (on reputation of company, 
image,
> sympathy etc.; 1 "perfect" to 5 "absolutely not perfect") for two 
companies
> only - out of a list of several companies; companies were chosen 
randomly.
> 
> So what I have now is two variables that tell me which two 
companies the
> respondent was actually evaluating...
> Company 1:      A, B, C, D, E, F or G
> Company 2:      A, B, C, D, E, F or G
> 
> ... and of course several image-related variables:
> reputation of company 1:  3,4,2,3,5,1,2,3,4,2,3,1,5 and so on
> reputation of company 2:  5,2,3,4,2,5,1,2,3,2,4,21 and so on
> image of company 1:        2,4,3,5,2,3,4,1,2,5,3,4,2 and so on
> image of company 2:        3,4,5,2,5,4,5,3,4,2,5,1,2 and so on
> sympathy of company 1:  1,5,3,4,2,5,3,4,1,2,3,4,5 and so on
> sympathy of company 2:   5,5,4,5,3,3,4,3,3,3,4,2,5 and so on
> etc.
> 
> 
> But what I need in order to do proper calculations is one
> Reputation/Image/Sympathy-Variable for every single company, like 
this:
> reputation of Company A: e.g. 3,4,3,5,NA,3,NA,5,2,1,NA,NA
> reputation of Company B: e.g. NA,4,3,5,NA,3,NA,5,2,1,NA
> reputation of Company C and so on
> image of Company A:...
> image of Company B :...
> image of Company C and so on
> sympathy of Company A:...
> sympathy of Company B :...
> sympathy of Company C and so on
> 
> So I need some syntax to compute a new variable  e.g. 
"reputation_CompanyA"
> that contains the values of "reputation of company 1" whenever 
"Company
> 1"=A and that contains the values of "reputation of company 2" 
whenever
> "Company 2"=A... else is of course missing values!
> 
> The solution has to has something to do with loops and flow control, 
but I
> really can't solve this puzzle.
> 
Hi Norbert,
I'll assume that you have your data (call it nddf) in a form something 
like this:

	rep1  rep2  img1  img2  sym1  sym2  ...
S1         3       4        2        3         1         5
S2         4       2        4        4         5         5
S3         ...

and your allocation of companies to subjects (call it subcomp) is in 
another file like this:

S1         A       C
S2         B       D
S3         ...

If so, you can do something like this. Say you surveyed 10 subjects 
and your overall variable is the sum of the five (?) scores:

# create a list of company by attribute scores
comp_by_attr<-vector("list",7)
names(comp_by_attr)<-LETTERS[1:7]
# step through your rating data
for(subject in 1:10) {
  company1<-
   which(subcomp[subject,1]==names(company_by_attr))
  company2<-
   which(subcomp[subject,2]==names(company_by_attr))
  # add the sum of the subject's company 1 ratings
  comp_by_attr[[company1]]<-c(comp_by_attr[[company1]],
   sum(nddf[subject,seq(1,9,by=2)]))
  # add the sum of the subject's company 2 ratings
  comp_by_attr[[company2]]<-c(comp_by_attr[[company2]],
   sum(nddf[subject,seq(1,9,by=2)]))
}

You should now have a list of seven elements, each labeled with the 
code of the company and containing the overall scores for that 
company. Since I don't have the data, I haven't checked this, but it 
may get you out of trouble.

Jim


From jim at bitwrit.com.au  Thu Sep 11 13:07:44 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 11 Sep 2014 21:07:44 +1000
Subject: [R] marketing-questionnaire with split-design
In-Reply-To: <1604080.m69SCYtKi7@localhost.localdomain>
References: <CAEzmP8i7x8eE9akGxpL+7Z4YySM5Jhx9Tbz1Q=ThqN2kHsaP1A@mail.gmail.com>
	<1604080.m69SCYtKi7@localhost.localdomain>
Message-ID: <4113367.IbtqgzaWQh@localhost.localdomain>

On Thu, 11 Sep 2014 08:58:54 PM Jim Lemon wrote:

Sorry, copying fumble. The last line in the loop should read:

sum(nddf[subject,seq(2,10,by=2)]))

Jim


From Philippe.GROSJEAN at umons.ac.be  Thu Sep 11 09:29:57 2014
From: Philippe.GROSJEAN at umons.ac.be (Philippe GROSJEAN)
Date: Thu, 11 Sep 2014 07:29:57 +0000
Subject: [R] some question about vector[-NULL]
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1917@SRVEXCHMBX.precheza.cz>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1917@SRVEXCHMBX.precheza.cz>
Message-ID: <FFA82080-2322-4503-A57E-EBDD9CA7E094@umons.ac.be>

On 11 Sep 2014, at 08:24, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
> 
> You still do not disclose important info about details of your functions. However, when you want to perform indexing like you show, you maybe can get rid of NULL and use zero instead.
> 
>> a<-1:5
>> a[-c(1,3)]
> [1] 2 4 5
>> a[-c(0,1,3)]
> [1] 2 4 5
>> a[-c(1,0,3)]
> [1] 2 4 5
>> a[-c(0,1,0,3,0)]
> [1] 2 4 5
> 
> However I am almost sure that you are fishing in murky waters and what you do by cycle and fiddling with NULL elements can be achieved by more efficiently.
> 
? and also look at this weird case:

> a <- 1:5
> a[-0]
integer(0)
> a[-c(0, 0)]
integer(0)

Best,

Philippe


> Regards
> Petr
> 
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of PO SU
>> Sent: Thursday, September 11, 2014 3:54 AM
>> To: Duncan Murdoch
>> Cc: R. Help
>> Subject: Re: [R] some question about vector[-NULL]
>> 
>> 
>> Tks, i think using logical index is a way, but to do that, i have to
>> keep a vector as long as the original vector. that's, to exclude
>> position 1 and 3 from
>> a<-1:5
>> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which
>> c(1,3) is much shorter than b if a is a long vector. that's, b would
>> be c(F,T,F,T,T,T,T,......,T) I thought a way ,
>> let d<-c(a,1)
>> that d<-c(1,2,3,4,5,1)
>> and initialize the index vector   iv to length(d). that is iv<-6.
>> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not.
>> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so
>> on.......
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> --
>> 
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> 
>> 
>> 
>> 
>> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com>
>> wrote:
>>> On 10/09/2014 12:20 PM, William Dunlap wrote:
>>>> Can you make your example a bit more concrete?  E.g., is your 'index
>>>> vector' A an integer vector?  If so, integer(0), an integer vector
>>>> with no elements, would be a more reasonable return value than NULL,
>>>> an object of class NULL with length 0, for the 'not found' case and
>>>> you could check for that case by asking if length(A)==0.
>>>> 
>>>> Show us typical inputs and expected outputs for your function (i.e.,
>>>> the problem you want to solve).
>>> 
>>> I think the problem with integer(0) and NULL is the same:  a[-i]
>> doesn't
>>> act as expected (leaving out all the elements of i, i.e. nothing) if i
>>> is either of those.  The solution is to use logical indexing, not
>>> negative numerical indexing.
>>> 
>>> Duncan Murdoch
>>>> 
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>> 
>>>> 
>>>> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com>
>> wrote:
>>>>> 
>>>>> Tks for your
>>>>> 
>>>>> a <- list(ress = 1, res = NULL)
>>>>> And in my second question, let me explain it :
>>>>> Actually i have two vectors in global enviroment, called A and B
>> .A is initialized to NULL which used to record some index in B.
>>>>> Then i would run a function F,  and each time, i would get a index
>> value or NULL. that's,  D<-F(B). D would be NULL or  some index
>> position in B.
>>>>> But in the function F, though input is B,  i would exclude the
>> index value from  B recorded in A. That's :
>>>>> F<-function( B ) {
>>>>> B<-B[-A]
>>>>> some processing...
>>>>> res<-NULL or some new index not included in A
>>>>> return(res)
>>>>> }
>>>>> so in a loop,
>>>>> A<-NULL
>>>>> for( i in 1:100000) {
>>>>> D<-F(B)
>>>>> A<-c(A,D)
>>>>> }
>>>>> I never know whether D is a NULL or a different index  compared
>> with indexes already recorded in A.
>>>>> Actually, A<-c(A,D) work well, i never worry about whether D is
>> NULL or a real index, but in the function F,  B<-B[-A] won't work.
>>>>> so i hope that, e.g.
>>>>> a<-1:3
>>>>> a[-NULL] wouldn't trigger an error but return a.
>>>>> Because, if i wrote function like the following:
>>>>> 
>>>>> F<-function( B ) {
>>>>> if( is.null(A))
>>>>> B<-B
>>>>> else
>>>>> B<-B[-A]
>>>>> some processing...
>>>>> res<-NULL or some new index not included in A
>>>>> return(res)
>>>>> }
>>>>> May be after 5 or 10 loops, A would already not NULL, so the added
>> if ..else statement would be repeated in left  9999 loops which i would
>> not like to see.
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> 
>>>>> PO SU
>>>>> mail: desolator88 at 163.com
>>>>> Majored in Statistics from SJTU
>>>>> 
>>>>> 
>>>>> 
>>>>> At 2014-09-10 06:45:59, "Duncan Murdoch"
>> <murdoch.duncan at gmail.com> wrote:
>>>>>> On 10/09/2014, 3:21 AM, PO SU wrote:
>>>>>>> 
>>>>>>> Dear expeRts,
>>>>>>>      I have some programming questions about NULL in R.There
>> are listed as follows:
>>>>>>> 1. I find i can't let a list have a element NULL:
>>>>>>> a<-list()
>>>>>>> a$ress<-1
>>>>>>> a$res<-NULL
>>>>>>> a
>>>>>>> str(a)
>>>>>> 
>>>>>> You can do it using
>>>>>> 
>>>>>> a <- list(ress = 1, res = NULL)
>>>>>> 
>>>>>>> How can i know i have a named element but it is NULL, not just
>> get a$xxxx,a$iiii,a$oooo there all get NULL
>>>>>> 
>>>>>> That's a little harder.  There are a few ways:
>>>>>> 
>>>>>> "res" %in% names(a) & is.null(a[["res"]])
>>>>>> 
>>>>>> or
>>>>>> 
>>>>>> identical(a["res"], list(res = NULL))
>>>>>> 
>>>>>> or
>>>>>> 
>>>>>> is.null(a[[2]])
>>>>>> 
>>>>>> should all work.
>>>>>> 
>>>>>> Generally because of the special handling needed, it's a bad idea
>> to try
>>>>>> to store NULL in a list.
>>>>>> 
>>>>>>> 2.The most important thing:
>>>>>>> a<-1:10
>>>>>>> b<-NULL or 1
>>>>>>> a<-c(a,b) will work so i don't need to know whether b is null or
>> not,but:
>>>>>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach
>> this purpose?
>>>>>> 
>>>>>> Using !, and a logical test, e.g.
>>>>>> 
>>>>>> a[!nullentry(a)]
>>>>>> 
>>>>>> where nullentry() is a function based on one of the tests above,
>> but
>>>>>> applied to all entries.
>>>>>> 
>>>>>> Duncan Murdoch
>>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sabine.siegert at uni-koeln.de  Thu Sep 11 10:18:16 2014
From: sabine.siegert at uni-koeln.de (Sabine Siegert)
Date: Thu, 11 Sep 2014 10:18:16 +0200
Subject: [R] Linkage disequilibrium plot
Message-ID: <54115AC8.4060409@uni-koeln.de>

Hi,

I want to generate a LD plot that looks like the triangle in the lower part
of the output of snp.plotter()

As I would not use the values of the original LD measure (instead I use a
more general measure) I have calulated pairwise "correlation" on my own. I
could arrange the results in a data frame like

chr1 pos1 snp1 chr2 pos2 snp2 ld

Is there a way/ function to generate a LD plot without prior calculation of
LD done by R?
Which function can I use based on my own calculations?

Thanks!


From deter088 at umn.edu  Thu Sep 11 14:09:28 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 11 Sep 2014 07:09:28 -0500
Subject: [R] Margins to fill matrix
In-Reply-To: <CAFy6Y8UxCbsbm05P2rtPjUGOj3_TBZB9iM0gm6PvU1ZR3ugXZg@mail.gmail.com>
References: <CAFy6Y8UxCbsbm05P2rtPjUGOj3_TBZB9iM0gm6PvU1ZR3ugXZg@mail.gmail.com>
Message-ID: <CAOLJphkt54CbPrwxq6PnF=BXH9Fq8DnaQcQJ6xy5EBBSQwWO5w@mail.gmail.com>

Do you have an example of what you would like your output to look like?  It
is a little difficult to fully understand what you are looking for.  You
only have 18 values but are looking to fill at 10x8 matrix (i.e. 80
values).  If you can clarify better we may be better able to help you.

Charles


On Thu, Sep 11, 2014 at 3:47 AM, Stefan Petersson <stefan at inizio.se> wrote:

> Hi,
>
> I have two vector of margins. Now I want to create "fill" matrix that
> reflects the margins.
>
>  seats <- c(17,24,28,30,34,36,40,44,46,50)
>  mandates <- c(107,23,24,19,112,19,25,20)
>
> Both vectors adds up to 349. So I want a 10x8 matrix with row sums
> corresponding to "seats" and column sums corresponding to "mandates".
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From stefan at inizio.se  Thu Sep 11 14:13:08 2014
From: stefan at inizio.se (Stefan Petersson)
Date: Thu, 11 Sep 2014 14:13:08 +0200
Subject: [R] Margins to fill matrix
In-Reply-To: <CAOLJphkt54CbPrwxq6PnF=BXH9Fq8DnaQcQJ6xy5EBBSQwWO5w@mail.gmail.com>
References: <CAFy6Y8UxCbsbm05P2rtPjUGOj3_TBZB9iM0gm6PvU1ZR3ugXZg@mail.gmail.com>
	<CAOLJphkt54CbPrwxq6PnF=BXH9Fq8DnaQcQJ6xy5EBBSQwWO5w@mail.gmail.com>
Message-ID: <CAFy6Y8W_vcpz0WD8Vwe6HEGfGJuozdjRBJZC3zJ712GD04+8MQ@mail.gmail.com>

I have :

rs <- c(3, 2, 3, 4)
cs <- c(4, 5, 3)

And want:

> matrix
    [,1] [,2] [,3]
[1,] 1    2    0
[2,] 1    0    1
[3,] 1    1    1
[4,] 1    2    1

The rowSums in the above matrix is equal to sum(rs) and colSums is
equal to sum(cs). It's sort of a matrix expansion where the margins
are known beforehand...

I hope I make sense.


2014-09-11 14:09 GMT+02:00 Charles Determan Jr <deter088 at umn.edu>:
> Do you have an example of what you would like your output to look like?  It
> is a little difficult to fully understand what you are looking for.  You
> only have 18 values but are looking to fill at 10x8 matrix (i.e. 80 values).
> If you can clarify better we may be better able to help you.
>
> Charles
>
>
> On Thu, Sep 11, 2014 at 3:47 AM, Stefan Petersson <stefan at inizio.se> wrote:
>>
>> Hi,
>>
>> I have two vector of margins. Now I want to create "fill" matrix that
>> reflects the margins.
>>
>>  seats <- c(17,24,28,30,34,36,40,44,46,50)
>>  mandates <- c(107,23,24,19,112,19,25,20)
>>
>> Both vectors adds up to 349. So I want a 10x8 matrix with row sums
>> corresponding to "seats" and column sums corresponding to "mandates".
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Dr. Charles Determan, PhD
> Integrated Biosciences


From jonathan.p.anspach at intel.com  Thu Sep 11 15:18:43 2014
From: jonathan.p.anspach at intel.com (Anspach, Jonathan P)
Date: Thu, 11 Sep 2014 13:18:43 +0000
Subject: [R] Building R for better performance
In-Reply-To: <CAK1hC9utTPpzQYhmdoPQwvmomJJ01cBrOd+6dyoY3p-oBaS8zw@mail.gmail.com>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<87430F4E-90CE-4A20-87D0-EFBBE293FB9C@uni-bonn.de>
	<9EB21FFA75EC13438CA12AD2A022D8CC2E9C5A6F@ORSMSX104.amr.corp.intel.com>
	<5410B719.7030706@yahoo.co.uk>,
	<CAK1hC9utTPpzQYhmdoPQwvmomJJ01cBrOd+6dyoY3p-oBaS8zw@mail.gmail.com>
Message-ID: <47EDA395-0BA9-4D0A-8B7D-EC48D25FADA1@intel.com>

I'm out of the office today, but will resend it tomorrow.

Jonathan Anspach
Intel Corp.

Sent from my mobile phone.

On Sep 11, 2014, at 3:49 AM, "arnaud gaboury" <arnaud.gaboury at gmail.com> wrote:

>>> I got the benchmark script, which I've attached, from Texas Advanced
>>> Computing Center.  Here are my results (elapsed times, in secs):
> 
> 
> Where can we get the benchmark script?


From hb at biostat.ucsf.edu  Thu Sep 11 16:17:52 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 11 Sep 2014 07:17:52 -0700
Subject: [R] Building R for better performance
In-Reply-To: <47EDA395-0BA9-4D0A-8B7D-EC48D25FADA1@intel.com>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<87430F4E-90CE-4A20-87D0-EFBBE293FB9C@uni-bonn.de>
	<9EB21FFA75EC13438CA12AD2A022D8CC2E9C5A6F@ORSMSX104.amr.corp.intel.com>
	<5410B719.7030706@yahoo.co.uk>
	<CAK1hC9utTPpzQYhmdoPQwvmomJJ01cBrOd+6dyoY3p-oBaS8zw@mail.gmail.com>
	<47EDA395-0BA9-4D0A-8B7D-EC48D25FADA1@intel.com>
Message-ID: <CAFDcVCQ_=bhKYPMYgRrZ7pEEHQ4-Vey2-YvsA_K0NL2NCZXTtg@mail.gmail.com>

You'll find R-benchmark-25.R, which I assume is the same and the proper
pointer to use, at http:// <http://r.research.att.com/benchmarks/>
r.research.att.com <http://r.research.att.com/benchmarks/>/benchmarks/
<http://r.research.att.com/benchmarks/>

Henrik
I'm out of the office today, but will resend it tomorrow.

Jonathan Anspach
Intel Corp.

Sent from my mobile phone.

On Sep 11, 2014, at 3:49 AM, "arnaud gaboury" <arnaud.gaboury at gmail.com>
wrote:

>>> I got the benchmark script, which I've attached, from Texas Advanced
>>> Computing Center.  Here are my results (elapsed times, in secs):
>
>
> Where can we get the benchmark script?

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Sep 11 17:18:19 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 11 Sep 2014 11:18:19 -0400
Subject: [R] some question about vector[-NULL]
In-Reply-To: <FFA82080-2322-4503-A57E-EBDD9CA7E094@umons.ac.be>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>	<54102BE7.6080002@gmail.com>	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>	<54109156.1090407@gmail.com>	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1917@SRVEXCHMBX.precheza.cz>
	<FFA82080-2322-4503-A57E-EBDD9CA7E094@umons.ac.be>
Message-ID: <5411BD3B.9040905@gmail.com>

On 11/09/2014 3:29 AM, Philippe GROSJEAN wrote:
> On 11 Sep 2014, at 08:24, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi
> >
> > You still do not disclose important info about details of your functions. However, when you want to perform indexing like you show, you maybe can get rid of NULL and use zero instead.
> >
> >> a<-1:5
> >> a[-c(1,3)]
> > [1] 2 4 5
> >> a[-c(0,1,3)]
> > [1] 2 4 5
> >> a[-c(1,0,3)]
> > [1] 2 4 5
> >> a[-c(0,1,0,3,0)]
> > [1] 2 4 5
> >
> > However I am almost sure that you are fishing in murky waters and what you do by cycle and fiddling with NULL elements can be achieved by more efficiently.
> >
> ? and also look at this weird case:
>
> > a <- 1:5
> > a[-0]
> integer(0)
> > a[-c(0, 0)]
> integer(0)

What do you find to be weird about this?  As far as I can see it is 
acting exactly as the documentation suggests it should:  -0 is treated 
the same as 0.  Zero as an index selects nothing.  Two zeroes also 
select nothing.  What's the surprise?

Duncan Murdoch

>
> Best,
>
> Philippe
>
>
> > Regards
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of PO SU
> >> Sent: Thursday, September 11, 2014 3:54 AM
> >> To: Duncan Murdoch
> >> Cc: R. Help
> >> Subject: Re: [R] some question about vector[-NULL]
> >>
> >>
> >> Tks, i think using logical index is a way, but to do that, i have to
> >> keep a vector as long as the original vector. that's, to exclude
> >> position 1 and 3 from
> >> a<-1:5
> >> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which
> >> c(1,3) is much shorter than b if a is a long vector. that's, b would
> >> be c(F,T,F,T,T,T,T,......,T) I thought a way ,
> >> let d<-c(a,1)
> >> that d<-c(1,2,3,4,5,1)
> >> and initialize the index vector   iv to length(d). that is iv<-6.
> >> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not.
> >> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so
> >> on.......
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >> PO SU
> >> mail: desolator88 at 163.com
> >> Majored in Statistics from SJTU
> >>
> >>
> >>
> >>
> >> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com>
> >> wrote:
> >>> On 10/09/2014 12:20 PM, William Dunlap wrote:
> >>>> Can you make your example a bit more concrete?  E.g., is your 'index
> >>>> vector' A an integer vector?  If so, integer(0), an integer vector
> >>>> with no elements, would be a more reasonable return value than NULL,
> >>>> an object of class NULL with length 0, for the 'not found' case and
> >>>> you could check for that case by asking if length(A)==0.
> >>>>
> >>>> Show us typical inputs and expected outputs for your function (i.e.,
> >>>> the problem you want to solve).
> >>>
> >>> I think the problem with integer(0) and NULL is the same:  a[-i]
> >> doesn't
> >>> act as expected (leaving out all the elements of i, i.e. nothing) if i
> >>> is either of those.  The solution is to use logical indexing, not
> >>> negative numerical indexing.
> >>>
> >>> Duncan Murdoch
> >>>>
> >>>> Bill Dunlap
> >>>> TIBCO Software
> >>>> wdunlap tibco.com
> >>>>
> >>>>
> >>>> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com>
> >> wrote:
> >>>>>
> >>>>> Tks for your
> >>>>>
> >>>>> a <- list(ress = 1, res = NULL)
> >>>>> And in my second question, let me explain it :
> >>>>> Actually i have two vectors in global enviroment, called A and B
> >> .A is initialized to NULL which used to record some index in B.
> >>>>> Then i would run a function F,  and each time, i would get a index
> >> value or NULL. that's,  D<-F(B). D would be NULL or  some index
> >> position in B.
> >>>>> But in the function F, though input is B,  i would exclude the
> >> index value from  B recorded in A. That's :
> >>>>> F<-function( B ) {
> >>>>> B<-B[-A]
> >>>>> some processing...
> >>>>> res<-NULL or some new index not included in A
> >>>>> return(res)
> >>>>> }
> >>>>> so in a loop,
> >>>>> A<-NULL
> >>>>> for( i in 1:100000) {
> >>>>> D<-F(B)
> >>>>> A<-c(A,D)
> >>>>> }
> >>>>> I never know whether D is a NULL or a different index  compared
> >> with indexes already recorded in A.
> >>>>> Actually, A<-c(A,D) work well, i never worry about whether D is
> >> NULL or a real index, but in the function F,  B<-B[-A] won't work.
> >>>>> so i hope that, e.g.
> >>>>> a<-1:3
> >>>>> a[-NULL] wouldn't trigger an error but return a.
> >>>>> Because, if i wrote function like the following:
> >>>>>
> >>>>> F<-function( B ) {
> >>>>> if( is.null(A))
> >>>>> B<-B
> >>>>> else
> >>>>> B<-B[-A]
> >>>>> some processing...
> >>>>> res<-NULL or some new index not included in A
> >>>>> return(res)
> >>>>> }
> >>>>> May be after 5 or 10 loops, A would already not NULL, so the added
> >> if ..else statement would be repeated in left  9999 loops which i would
> >> not like to see.
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> --
> >>>>>
> >>>>> PO SU
> >>>>> mail: desolator88 at 163.com
> >>>>> Majored in Statistics from SJTU
> >>>>>
> >>>>>
> >>>>>
> >>>>> At 2014-09-10 06:45:59, "Duncan Murdoch"
> >> <murdoch.duncan at gmail.com> wrote:
> >>>>>> On 10/09/2014, 3:21 AM, PO SU wrote:
> >>>>>>>
> >>>>>>> Dear expeRts,
> >>>>>>>      I have some programming questions about NULL in R.There
> >> are listed as follows:
> >>>>>>> 1. I find i can't let a list have a element NULL:
> >>>>>>> a<-list()
> >>>>>>> a$ress<-1
> >>>>>>> a$res<-NULL
> >>>>>>> a
> >>>>>>> str(a)
> >>>>>>
> >>>>>> You can do it using
> >>>>>>
> >>>>>> a <- list(ress = 1, res = NULL)
> >>>>>>
> >>>>>>> How can i know i have a named element but it is NULL, not just
> >> get a$xxxx,a$iiii,a$oooo there all get NULL
> >>>>>>
> >>>>>> That's a little harder.  There are a few ways:
> >>>>>>
> >>>>>> "res" %in% names(a) & is.null(a[["res"]])
> >>>>>>
> >>>>>> or
> >>>>>>
> >>>>>> identical(a["res"], list(res = NULL))
> >>>>>>
> >>>>>> or
> >>>>>>
> >>>>>> is.null(a[[2]])
> >>>>>>
> >>>>>> should all work.
> >>>>>>
> >>>>>> Generally because of the special handling needed, it's a bad idea
> >> to try
> >>>>>> to store NULL in a list.
> >>>>>>
> >>>>>>> 2.The most important thing:
> >>>>>>> a<-1:10
> >>>>>>> b<-NULL or 1
> >>>>>>> a<-c(a,b) will work so i don't need to know whether b is null or
> >> not,but:
> >>>>>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach
> >> this purpose?
> >>>>>>
> >>>>>> Using !, and a logical test, e.g.
> >>>>>>
> >>>>>> a[!nullentry(a)]
> >>>>>>
> >>>>>> where nullentry() is a function based on one of the tests above,
> >> but
> >>>>>> applied to all entries.
> >>>>>>
> >>>>>> Duncan Murdoch
> >>>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> > If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> > - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Philippe.GROSJEAN at umons.ac.be  Thu Sep 11 17:27:29 2014
From: Philippe.GROSJEAN at umons.ac.be (Philippe GROSJEAN)
Date: Thu, 11 Sep 2014 15:27:29 +0000
Subject: [R] some question about vector[-NULL]
In-Reply-To: <5411BD3B.9040905@gmail.com>
References: <447cb4de.2029f.1485e700243.Coremail.rhelpmaillist@163.com>
	<54102BE7.6080002@gmail.com>
	<55e4ecd0.1508b.14860449b14.Coremail.rhelpmaillist@163.com>
	<CAF8bMcbVsDa5M7VvmBrehh1Vq8VaHaf=kF6mD+=iCfx4J4ARcw@mail.gmail.com>
	<54109156.1090407@gmail.com>
	<117c93cb.2d20.148626a949b.Coremail.rhelpmaillist@163.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1917@SRVEXCHMBX.precheza.cz>
	<FFA82080-2322-4503-A57E-EBDD9CA7E094@umons.ac.be>
	<5411BD3B.9040905@gmail.com>
Message-ID: <40320713-F541-4645-9C74-2C9AB7B78ED6@umons.ac.be>


..............................................<?}))><........
 ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
 ) ) ) ) )   Mons University, Belgium
( ( ( ( (
..............................................................

On 11 Sep 2014, at 17:18, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 11/09/2014 3:29 AM, Philippe GROSJEAN wrote:
>> On 11 Sep 2014, at 08:24, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> 
>> > Hi
>> >
>> > You still do not disclose important info about details of your functions. However, when you want to perform indexing like you show, you maybe can get rid of NULL and use zero instead.
>> >
>> >> a<-1:5
>> >> a[-c(1,3)]
>> > [1] 2 4 5
>> >> a[-c(0,1,3)]
>> > [1] 2 4 5
>> >> a[-c(1,0,3)]
>> > [1] 2 4 5
>> >> a[-c(0,1,0,3,0)]
>> > [1] 2 4 5
>> >
>> > However I am almost sure that you are fishing in murky waters and what you do by cycle and fiddling with NULL elements can be achieved by more efficiently.
>> >
>> ? and also look at this weird case:
>> 
>> > a <- 1:5
>> > a[-0]
>> integer(0)
>> > a[-c(0, 0)]
>> integer(0)
> 
> What do you find to be weird about this?  As far as I can see it is acting exactly as the documentation suggests it should:  -0 is treated the same as 0.  Zero as an index selects nothing.  Two zeroes also select nothing.  What's the surprise?
> 
> Duncan Murdoch
> 
No, it is not a surprise, nor a problem with the behaviour of R, really. It is just in connection with Petr's suggestion to replace NULL by 0. I just wanted to indicate that it could produce unwanted results in several cases.

Philippe



>> 
>> Best,
>> 
>> Philippe
>> 
>> 
>> > Regards
>> > Petr
>> >
>> >
>> >> -----Original Message-----
>> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> >> project.org] On Behalf Of PO SU
>> >> Sent: Thursday, September 11, 2014 3:54 AM
>> >> To: Duncan Murdoch
>> >> Cc: R. Help
>> >> Subject: Re: [R] some question about vector[-NULL]
>> >>
>> >>
>> >> Tks, i think using logical index is a way, but to do that, i have to
>> >> keep a vector as long as the original vector. that's, to exclude
>> >> position 1 and 3 from
>> >> a<-1:5
>> >> I have to let b<-c(F,T,F,T,T) and exec a[b], not a[-c(1,3)]. which
>> >> c(1,3) is much shorter than b if a is a long vector. that's, b would
>> >> be c(F,T,F,T,T,T,T,......,T) I thought a way ,
>> >> let d<-c(a,1)
>> >> that d<-c(1,2,3,4,5,1)
>> >> and initialize the index vector   iv to length(d). that is iv<-6.
>> >> then, d[-iv] is always equal  a[- i ] ,  whether i is NULL or not.
>> >> Because if i is NULL ,then iv is 6, if i is 2.then iv is c(2,6) and so
>> >> on.......
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> --
>> >>
>> >> PO SU
>> >> mail: desolator88 at 163.com
>> >> Majored in Statistics from SJTU
>> >>
>> >>
>> >>
>> >>
>> >> At 2014-09-11 01:58:46, "Duncan Murdoch" <murdoch.duncan at gmail.com>
>> >> wrote:
>> >>> On 10/09/2014 12:20 PM, William Dunlap wrote:
>> >>>> Can you make your example a bit more concrete?  E.g., is your 'index
>> >>>> vector' A an integer vector?  If so, integer(0), an integer vector
>> >>>> with no elements, would be a more reasonable return value than NULL,
>> >>>> an object of class NULL with length 0, for the 'not found' case and
>> >>>> you could check for that case by asking if length(A)==0.
>> >>>>
>> >>>> Show us typical inputs and expected outputs for your function (i.e.,
>> >>>> the problem you want to solve).
>> >>>
>> >>> I think the problem with integer(0) and NULL is the same:  a[-i]
>> >> doesn't
>> >>> act as expected (leaving out all the elements of i, i.e. nothing) if i
>> >>> is either of those.  The solution is to use logical indexing, not
>> >>> negative numerical indexing.
>> >>>
>> >>> Duncan Murdoch
>> >>>>
>> >>>> Bill Dunlap
>> >>>> TIBCO Software
>> >>>> wdunlap tibco.com
>> >>>>
>> >>>>
>> >>>> On Wed, Sep 10, 2014 at 8:53 AM, PO SU <rhelpmaillist at 163.com>
>> >> wrote:
>> >>>>>
>> >>>>> Tks for your
>> >>>>>
>> >>>>> a <- list(ress = 1, res = NULL)
>> >>>>> And in my second question, let me explain it :
>> >>>>> Actually i have two vectors in global enviroment, called A and B
>> >> .A is initialized to NULL which used to record some index in B.
>> >>>>> Then i would run a function F,  and each time, i would get a index
>> >> value or NULL. that's,  D<-F(B). D would be NULL or  some index
>> >> position in B.
>> >>>>> But in the function F, though input is B,  i would exclude the
>> >> index value from  B recorded in A. That's :
>> >>>>> F<-function( B ) {
>> >>>>> B<-B[-A]
>> >>>>> some processing...
>> >>>>> res<-NULL or some new index not included in A
>> >>>>> return(res)
>> >>>>> }
>> >>>>> so in a loop,
>> >>>>> A<-NULL
>> >>>>> for( i in 1:100000) {
>> >>>>> D<-F(B)
>> >>>>> A<-c(A,D)
>> >>>>> }
>> >>>>> I never know whether D is a NULL or a different index  compared
>> >> with indexes already recorded in A.
>> >>>>> Actually, A<-c(A,D) work well, i never worry about whether D is
>> >> NULL or a real index, but in the function F,  B<-B[-A] won't work.
>> >>>>> so i hope that, e.g.
>> >>>>> a<-1:3
>> >>>>> a[-NULL] wouldn't trigger an error but return a.
>> >>>>> Because, if i wrote function like the following:
>> >>>>>
>> >>>>> F<-function( B ) {
>> >>>>> if( is.null(A))
>> >>>>> B<-B
>> >>>>> else
>> >>>>> B<-B[-A]
>> >>>>> some processing...
>> >>>>> res<-NULL or some new index not included in A
>> >>>>> return(res)
>> >>>>> }
>> >>>>> May be after 5 or 10 loops, A would already not NULL, so the added
>> >> if ..else statement would be repeated in left  9999 loops which i would
>> >> not like to see.
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> --
>> >>>>>
>> >>>>> PO SU
>> >>>>> mail: desolator88 at 163.com
>> >>>>> Majored in Statistics from SJTU
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> At 2014-09-10 06:45:59, "Duncan Murdoch"
>> >> <murdoch.duncan at gmail.com> wrote:
>> >>>>>> On 10/09/2014, 3:21 AM, PO SU wrote:
>> >>>>>>>
>> >>>>>>> Dear expeRts,
>> >>>>>>>      I have some programming questions about NULL in R.There
>> >> are listed as follows:
>> >>>>>>> 1. I find i can't let a list have a element NULL:
>> >>>>>>> a<-list()
>> >>>>>>> a$ress<-1
>> >>>>>>> a$res<-NULL
>> >>>>>>> a
>> >>>>>>> str(a)
>> >>>>>>
>> >>>>>> You can do it using
>> >>>>>>
>> >>>>>> a <- list(ress = 1, res = NULL)
>> >>>>>>
>> >>>>>>> How can i know i have a named element but it is NULL, not just
>> >> get a$xxxx,a$iiii,a$oooo there all get NULL
>> >>>>>>
>> >>>>>> That's a little harder.  There are a few ways:
>> >>>>>>
>> >>>>>> "res" %in% names(a) & is.null(a[["res"]])
>> >>>>>>
>> >>>>>> or
>> >>>>>>
>> >>>>>> identical(a["res"], list(res = NULL))
>> >>>>>>
>> >>>>>> or
>> >>>>>>
>> >>>>>> is.null(a[[2]])
>> >>>>>>
>> >>>>>> should all work.
>> >>>>>>
>> >>>>>> Generally because of the special handling needed, it's a bad idea
>> >> to try
>> >>>>>> to store NULL in a list.
>> >>>>>>
>> >>>>>>> 2.The most important thing:
>> >>>>>>> a<-1:10
>> >>>>>>> b<-NULL or 1
>> >>>>>>> a<-c(a,b) will work so i don't need to know whether b is null or
>> >> not,but:
>> >>>>>>> a[-NULL] can't work!!  i just need a[-NULL]==a , how can i reach
>> >> this purpose?
>> >>>>>>
>> >>>>>> Using !, and a logical test, e.g.
>> >>>>>>
>> >>>>>> a[!nullentry(a)]
>> >>>>>>
>> >>>>>> where nullentry() is a function based on one of the tests above,
>> >> but
>> >>>>>> applied to all entries.
>> >>>>>>
>> >>>>>> Duncan Murdoch
>> >>>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> >> guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-
>> >> guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ________________________________
>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> >
>> > This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>> > If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>> > If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> > The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>> >
>> > In case that this e-mail forms part of business dealings:
>> > - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>> > - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>> > - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>> > - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From barvazduck at gmail.com  Thu Sep 11 17:49:02 2014
From: barvazduck at gmail.com (raz)
Date: Thu, 11 Sep 2014 18:49:02 +0300
Subject: [R] create new column by replacing multiple unique values in
	existing column
Message-ID: <CAGHW+oJjFTf4DkmuZS8Va-1_TDtbUTNRmfkOCCyuJO=nnHwfPg@mail.gmail.com>

Hi,

?I got the following data frame:
 dat1 <- read.table(text="a,b
1,A1
2,A1
3,A1
4,A1
5,A1
6,A2
7,A2
8,A2
9,A2
10,A2
11,B1
12,B1
13,B1
14,B1
15,B1",sep=",",header=T)
?

?I would like to add a new column dat1$new based on column "b" (dat$b) in
which values will be substituted according to their unique values e.g "A1"
will be "1", "A2" will be "2" and so on (this is only a part of a large
table). It would be better if I could change all unique values in dat1 to
numbers 1:unique(n). if not then how do I change all values
("A1","A2","B1") to (1,2,3) in a new column?.

Thanks a lot,

Raz?


-- 
\m/

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Sep 11 18:06:04 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 11 Sep 2014 16:06:04 +0000
Subject: [R] create new column by replacing multiple unique values
	in	existing column
In-Reply-To: <CAGHW+oJjFTf4DkmuZS8Va-1_TDtbUTNRmfkOCCyuJO=nnHwfPg@mail.gmail.com>
References: <CAGHW+oJjFTf4DkmuZS8Va-1_TDtbUTNRmfkOCCyuJO=nnHwfPg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F96D92@mb02.ads.tamu.edu>

Note that in the data you sent, b is a factor:
> str(dat1)
'data.frame':   15 obs. of  2 variables:
 $ a: int  1 2 3 4 5 6 7 8 9 10 ...
 $ b: Factor w/ 3 levels "A1","A2","B1": 1 1 1 1 1 2 2 2 2 2 ...

So all you need is
> dat1$new <- as.numeric(dat1$b)
> table(dat1$new)
> table(dat1$new)

1 2 3 
5 5 5 
> table(dat1$b)

A1 A2 B1 
 5  5  5 

If b is not a factor in your table, make it one ?factor
-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of raz
Sent: Thursday, September 11, 2014 10:49 AM
To: r-help at r-project.org
Subject: [R] create new column by replacing multiple unique values in existing column

Hi,

?I got the following data frame:
 dat1 <- read.table(text="a,b
1,A1
2,A1
3,A1
4,A1
5,A1
6,A2
7,A2
8,A2
9,A2
10,A2
11,B1
12,B1
13,B1
14,B1
15,B1",sep=",",header=T)
?

?I would like to add a new column dat1$new based on column "b" (dat$b) in
which values will be substituted according to their unique values e.g "A1"
will be "1", "A2" will be "2" and so on (this is only a part of a large
table). It would be better if I could change all unique values in dat1 to
numbers 1:unique(n). if not then how do I change all values
("A1","A2","B1") to (1,2,3) in a new column?.

Thanks a lot,

Raz?


-- 
\m/

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From john.archie.mckown at gmail.com  Thu Sep 11 18:16:43 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 11 Sep 2014 11:16:43 -0500
Subject: [R] create new column by replacing multiple unique values in
 existing column
In-Reply-To: <CAGHW+oJjFTf4DkmuZS8Va-1_TDtbUTNRmfkOCCyuJO=nnHwfPg@mail.gmail.com>
References: <CAGHW+oJjFTf4DkmuZS8Va-1_TDtbUTNRmfkOCCyuJO=nnHwfPg@mail.gmail.com>
Message-ID: <CAAJSdjjMdshY84uDXyHJP0UTDWBjbBfn5NPrccnp0COOq9JbgA@mail.gmail.com>

On Thu, Sep 11, 2014 at 10:49 AM, raz <barvazduck at gmail.com> wrote:
> Hi,
>
> I got the following data frame:
>  dat1 <- read.table(text="a,b
> 1,A1
> 2,A1
> 3,A1
> 4,A1
> 5,A1
> 6,A2
> 7,A2
> 8,A2
> 9,A2
> 10,A2
> 11,B1
> 12,B1
> 13,B1
> 14,B1
> 15,B1",sep=",",header=T)
>
>
> I would like to add a new column dat1$new based on column "b" (dat$b) in
> which values will be substituted according to their unique values e.g "A1"
> will be "1", "A2" will be "2" and so on (this is only a part of a large
> table). It would be better if I could change all unique values in dat1 to
> numbers 1:unique(n). if not then how do I change all values
> ("A1","A2","B1") to (1,2,3) in a new column?.
>
> Thanks a lot,
>
> Raz
>
> --
> \m/
>
>         [[alternative HTML version deleted]]
>

Please change your email client to post only in plain text, no HTML. Thanks.

And, lucky you. You __already__ have what you want in the table. Try
the following:

print(dat1$b);

Hum, you just get what you're expecting. Things like A1 and B1 and so
on. Now try:

print(as.integer(dat1$b));

Whoa! You have unique integers based on the values in column b! That's
because the data in column b is a __factor__. And the as.integer()
prints the factor number instead of the factor value. If column b is
not a factor, then you can make it one with a simple: dat1$b <-
as.factor(dat1$b); it you really want it in a separate column for some
reason: dat1$new <- as.integer(dat1$b); But then you are responsible
for keeping columns b and new "in sync". Keeping/making column b a
factor lets you use as.integer() and you are GOLDEN!


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From radhakrishnan.mohan at gmail.com  Thu Sep 11 19:40:53 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Thu, 11 Sep 2014 23:10:53 +0530
Subject: [R] R, Big Data and books
In-Reply-To: <540F2BE7.60301@tanucoo.com>
References: <540F2BE7.60301@tanucoo.com>
Message-ID: <CAOoXFP-NtZV_913Q3yg_pEX_RrKrXgqDLOPgJqtcOtdzQVH1TQ@mail.gmail.com>

This too.

Applied Predictive Modeling

Max Kuhn ? Kjell Johnson

Thanks,

Mohan

On Tue, Sep 9, 2014 at 10:03 PM, Subba Rao <raspbian at tanucoo.com> wrote:

> Hi,
>
> I am interested in R programming in the Big Data space.  Are there any
> books that would be a good starting point for this career path?
> Predictive analysis is also an area I am interested in.
>
> Thank you in advance for any information and help.
>
> Subba Rao
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From corynissen at gmail.com  Thu Sep 11 16:17:12 2014
From: corynissen at gmail.com (Cory N)
Date: Thu, 11 Sep 2014 07:17:12 -0700 (PDT)
Subject: [R] Question about searchTwitter{twitteR}
In-Reply-To: <CAAyVsXLJvCwP91ewrJoBZrjMMCX8mj8GH0W=Aoyhmy10Q+BPNw@mail.gmail.com>
References: <CAAyVsXLJvCwP91ewrJoBZrjMMCX8mj8GH0W=Aoyhmy10Q+BPNw@mail.gmail.com>
Message-ID: <af3c6b91-d946-4608-9c52-1335213e5c1f@googlegroups.com>

You are only able to search twitter history for a short period of time. 
gnip.com and similar companies offer historical tweets for sale.

cn


On Sunday, September 7, 2014 9:21:34 AM UTC-5, Axel Urbiz wrote:
>
> Hello, 
>
> The function searchTwitter() with the arguments supplied as below would 
> give me a different number of results on different days I run this code. 
> Maybe it is my lack of understanding about what the date arguments are 
> supposed to do in this function, but I would think I should be getting the 
> same tweets? 
>
>
> tweets <- searchTwitter('my text search', 
>                                     n = 1000, 
>                                     since = '2013-09-01', 
>                                     until = '2014-08-31') 
>
>
> Thanks, 
> Axel. 
>
>         [[alternative HTML version deleted]] 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From jonathan.p.anspach at intel.com  Thu Sep 11 17:38:03 2014
From: jonathan.p.anspach at intel.com (Anspach, Jonathan P)
Date: Thu, 11 Sep 2014 15:38:03 +0000
Subject: [R] Building R for better performance
In-Reply-To: <CAFDcVCQ_=bhKYPMYgRrZ7pEEHQ4-Vey2-YvsA_K0NL2NCZXTtg@mail.gmail.com>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<87430F4E-90CE-4A20-87D0-EFBBE293FB9C@uni-bonn.de>
	<9EB21FFA75EC13438CA12AD2A022D8CC2E9C5A6F@ORSMSX104.amr.corp.intel.com>
	<5410B719.7030706@yahoo.co.uk>
	<CAK1hC9utTPpzQYhmdoPQwvmomJJ01cBrOd+6dyoY3p-oBaS8zw@mail.gmail.com>
	<47EDA395-0BA9-4D0A-8B7D-EC48D25FADA1@intel.com>,
	<CAFDcVCQ_=bhKYPMYgRrZ7pEEHQ4-Vey2-YvsA_K0NL2NCZXTtg@mail.gmail.com>
Message-ID: <01137834-05EC-40D4-B51A-6881812248B4@intel.com>

Yes, that's the original. Then TACC increased the matrix sizes for their tests.

Jonathan Anspach
Intel Corp.

Sent from my mobile phone.

On Sep 11, 2014, at 9:18 AM, "Henrik Bengtsson" <hb at biostat.ucsf.edu<mailto:hb at biostat.ucsf.edu>> wrote:


You'll find R-benchmark-25.R, which I assume is the same and the proper pointer to use, at http://<http://r.research.att.com/benchmarks/>r.research.att.com<http://r.research.att.com/benchmarks/>/benchmarks/<http://r.research.att.com/benchmarks/>

Henrik

I'm out of the office today, but will resend it tomorrow.

Jonathan Anspach
Intel Corp.

Sent from my mobile phone.

On Sep 11, 2014, at 3:49 AM, "arnaud gaboury" <arnaud.gaboury at gmail.com<mailto:arnaud.gaboury at gmail.com>> wrote:

>>> I got the benchmark script, which I've attached, from Texas Advanced
>>> Computing Center.  Here are my results (elapsed times, in secs):
>
>
> Where can we get the benchmark script?

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marie-eve.st-onge at outlook.com  Thu Sep 11 17:52:39 2014
From: marie-eve.st-onge at outlook.com (Marie-Eve St-Onge)
Date: Thu, 11 Sep 2014 13:52:39 -0200
Subject: [R] incorrect number of dimensions
Message-ID: <COL129-W63C78E38BC0DCD7133835DF2CC0@phx.gbl>

Dear all, I'm trying the following experiment simulation, but I'm receiving this error:
> probs()Error in x[j, 4] : incorrect number of dimensions
however, the simulation works fine outside the function statement{}. What am I doing wrong?
# Create some fake data and call the function: df <- data.frame(y1 = rpois(5, 9),y2 = rpois(5, 7), y3 = rpois(5, 8), n = rpois(5, 100)) 
probs = function(x='df', j=5, export=1){  p=gtools::rdirichlet(100000, x[j,4] * c(x[j,1],x[j,2],x[j,3], 1-x[j,1]-x[j,2]-x[j,3])/100+1 )if(export==1){  mean(p[,1] > p[,3])} else {  return(p)} }

Eve

 		 	   		  
	[[alternative HTML version deleted]]


From thi_veloso at yahoo.com.br  Thu Sep 11 18:03:09 2014
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Thu, 11 Sep 2014 09:03:09 -0700
Subject: [R] How to plot soil moisture data as a contour plot
In-Reply-To: <9E1C3AD7-339A-453E-8E2C-0E9B5EFD70A8@comcast.net>
References: <1410380401.82513.YahooMailNeo@web121902.mail.ne1.yahoo.com>
	<9E1C3AD7-339A-453E-8E2C-0E9B5EFD70A8@comcast.net>
Message-ID: <1410451389.49973.YahooMailNeo@web121901.mail.ne1.yahoo.com>

David,

Thanks a lot for your sugestion, it solved my problem!
 
Greetings,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898


On Wednesday, September 10, 2014 4:56 PM, David Winsemius <dwinsemius at comcast.net> wrote:
 



On Sep 10, 2014, at 1:20 PM, Thiago V. dos Santos wrote:

> Dear all,
> 
> This is my first message in this list, so please excuse any mistake.
> 
> I am trying to plot moisture data for 11 soil layers over the course of the year, but I am yet to find the correct function to do that. I am trying to reproduce the lower figure in this panel: https://imageshack.com/i/exmVz5QSp
> 
> Please read the comments while reproducing my data with the code below: 
> 
> ----------------------------------------
> library(repmis) # reads text data directly from dropbox - no need to download any file
> 
> # read data
> url <- 'https://dl.dropboxusercontent.com/u/27700634/precip.txt'
> tmp <- repmis::source_data(url, sep = '', header = TRUE)
> 
> # convert julian day to date
> date <- as.Date(tmp$julian, origin='2011-12-31')
> data <- cbind(date, tmp)
> head(data)
> 
> # now, convert soil layers to matrix and transpose it
> mat <- t(as.matrix(data[, 4:14]))
> head(mat) 
> 
> # this is the very matrix I want to plot. Please notice that it is already organized as a "profile",
> # with rows representing soil layers and columns representing day of year.
> ----------------------------------------
> 
> 
> My first attempt was to use function filled.contour from "graphics" package. I define a vector with labels for soil layers and then I try to plot, but I receive an error saying the matrix has incorrect dimensions:
> 
> 
> ----------------------------------------
> 
> # define vector with depth of soil layers
> 
> depths <- c(0.05,0.10,0.20,0.30,
>            0.40,0.60,0.80,1.00,
>            1.50,2.00,2.50)
> 
> # Plot soil moisture profile
> plot <- filled.contour(data$julian, depths, mat)
> 
> 
> #Error in .filled.contour(x, y, z, levels, col) : dimension mismatch

You need to decide what orientation you want. At the moment the mat-matrix is 11 x 366 and the x-component is the 11. (And for some reason you are the one who made the first transposition.) There's no auto-transformation in filled.contour when the dimensions are reversed. 

This proceeds without error:

mat2 <- as.matrix(data[, 4:14])
plot <- filled.contour(x=data$julian, y=depths, z=mat2)

> ----------------------------------------
> 
> 
> I can obviously tranpose the matrix to force the plot, but the resulting figure is not what I need - the soil profile is shown upside down:
> 

If you want the reverse the depth order, do not transpose, .... just:

plot <- filled.contour(x=data$julian, y=depths, z=mat2[, 11:1])




> ----------------------------------------
> plot <- filled.contour(data$julian, depths, t(mat))
> 
> ----------------------------------------
> 
> 
> Because this functions requires axis labels to be ascendent, I am not able to reverse them in order to show the first layer at the top of the graphic.
> 
> I would really appreciate any feedback or directions on how to show my data as a contour plot as mentioned above. Thanks in advance! 
> 
> 
> Greetings,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323
> 9898
>     [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA
	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Sep 11 21:09:48 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 11 Sep 2014 19:09:48 +0000
Subject: [R] incorrect number of dimensions
In-Reply-To: <COL129-W63C78E38BC0DCD7133835DF2CC0@phx.gbl>
References: <COL129-W63C78E38BC0DCD7133835DF2CC0@phx.gbl>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F96EA6@mb02.ads.tamu.edu>

Look below to see what happens to your formatting when you use html. Don't use html.

Why do you use x='df' in defining the function

df is a data frame with 5 observations and 4 variables.
'df' is a character vector of length 1. Your function is looking for a data frame (or matrix) with at least 4 columns.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Marie-Eve St-Onge
Sent: Thursday, September 11, 2014 10:53 AM
To: r-help at r-project.org
Subject: [R] incorrect number of dimensions

Dear all, I'm trying the following experiment simulation, but I'm receiving this error:
> probs()Error in x[j, 4] : incorrect number of dimensions
however, the simulation works fine outside the function statement{}. What am I doing wrong?
# Create some fake data and call the function: df <- data.frame(y1 = rpois(5, 9),y2 = rpois(5, 7), y3 = rpois(5, 8), n = rpois(5, 100)) 
probs = function(x='df', j=5, export=1){  p=gtools::rdirichlet(100000, x[j,4] * c(x[j,1],x[j,2],x[j,3], 1-x[j,1]-x[j,2]-x[j,3])/100+1 )if(export==1){  mean(p[,1] > p[,3])} else {  return(p)} }

Eve

 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Sep 11 21:20:26 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 11 Sep 2014 19:20:26 +0000
Subject: [R] Margins to fill matrix
In-Reply-To: <CAFy6Y8W_vcpz0WD8Vwe6HEGfGJuozdjRBJZC3zJ712GD04+8MQ@mail.gmail.com>
References: <CAFy6Y8UxCbsbm05P2rtPjUGOj3_TBZB9iM0gm6PvU1ZR3ugXZg@mail.gmail.com>
	<CAOLJphkt54CbPrwxq6PnF=BXH9Fq8DnaQcQJ6xy5EBBSQwWO5w@mail.gmail.com>
	<CAFy6Y8W_vcpz0WD8Vwe6HEGfGJuozdjRBJZC3zJ712GD04+8MQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F96EBB@mb02.ads.tamu.edu>

You want r2dtable():

> ?r2dtable
> set.seed(42)
> a <- r2dtable(1, seats, mandates)
addmargins(a[[1]])
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
 [1,]    2    3    1    0    6    2    1    2   17
 [2,]    8    0    1    1   11    0    2    1   24
 [3,]    8    0    5    2    7    1    1    4   28
 [4,]   10    5    3    1    6    3    0    2   30
 [5,]   13    4    1    4    9    0    2    1   34
 [6,]    8    2    2    0   17    3    4    0   36
 [7,]   13    0    2    6    9    2    3    5   40
 [8,]   12    4    4    3   12    3    3    3   44
 [9,]   14    3    3    2   18    0    4    2   46
[10,]   19    2    2    0   17    5    5    0   50
[11,]  107   23   24   19  112   19   25   20  349


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Stefan Petersson
Sent: Thursday, September 11, 2014 7:13 AM
To: Charles Determan Jr
Cc: r-help at r-project.org
Subject: Re: [R] Margins to fill matrix

I have :

rs <- c(3, 2, 3, 4)
cs <- c(4, 5, 3)

And want:

> matrix
    [,1] [,2] [,3]
[1,] 1    2    0
[2,] 1    0    1
[3,] 1    1    1
[4,] 1    2    1

The rowSums in the above matrix is equal to sum(rs) and colSums is
equal to sum(cs). It's sort of a matrix expansion where the margins
are known beforehand...

I hope I make sense.


2014-09-11 14:09 GMT+02:00 Charles Determan Jr <deter088 at umn.edu>:
> Do you have an example of what you would like your output to look like?  It
> is a little difficult to fully understand what you are looking for.  You
> only have 18 values but are looking to fill at 10x8 matrix (i.e. 80 values).
> If you can clarify better we may be better able to help you.
>
> Charles
>
>
> On Thu, Sep 11, 2014 at 3:47 AM, Stefan Petersson <stefan at inizio.se> wrote:
>>
>> Hi,
>>
>> I have two vector of margins. Now I want to create "fill" matrix that
>> reflects the margins.
>>
>>  seats <- c(17,24,28,30,34,36,40,44,46,50)
>>  mandates <- c(107,23,24,19,112,19,25,20)
>>
>> Both vectors adds up to 349. So I want a 10x8 matrix with row sums
>> corresponding to "seats" and column sums corresponding to "mandates".
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Dr. Charles Determan, PhD
> Integrated Biosciences

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kw.stat at gmail.com  Thu Sep 11 22:06:17 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 11 Sep 2014 15:06:17 -0500
Subject: [R] How to test for open pdf file on Windows before calling
	cairo_pdf ?
Message-ID: <CAKFxdiS6EmYjkgTKDG_LJEykpu+AoAHHpw6T5qbTe2MpZ-FWYQ@mail.gmail.com>

On Windows:

The pdf("file1.pdf") command will throw an error if the file1.pdf is open
in a viewer.  For example:

pdf("file1.pdf")
plot(1:10)
dev.off()
shell.exec("file1.pdf")
pdf("file1.pdf") # Causes an error

As suggested by the help page for file.access(), I normally use
try(pdf("file1.pdf")) to test if file1.pdf is open.

Oddly, I cannot do the same using cairo_pdf.  For example:

cairo_pdf("file2.pdf")
plot(1:10)
dev.off()
shell.exec("file2.pdf")
cairo_pdf("file2.pdf") # No error

It is not until a plotting command is called that an error is generated.

Is there a way to test if a pdf file can be written to by cairo_pdf ?

I'd rather not wrap all plotting commands with try()....I have many such
commands in my script and the choice of which one is first depends on user
input.

Kevin Wright

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Sep 11 22:33:30 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Sep 2014 13:33:30 -0700
Subject: [R] Margins to fill matrix
In-Reply-To: <CAFy6Y8W_vcpz0WD8Vwe6HEGfGJuozdjRBJZC3zJ712GD04+8MQ@mail.gmail.com>
References: <CAFy6Y8UxCbsbm05P2rtPjUGOj3_TBZB9iM0gm6PvU1ZR3ugXZg@mail.gmail.com>
	<CAOLJphkt54CbPrwxq6PnF=BXH9Fq8DnaQcQJ6xy5EBBSQwWO5w@mail.gmail.com>
	<CAFy6Y8W_vcpz0WD8Vwe6HEGfGJuozdjRBJZC3zJ712GD04+8MQ@mail.gmail.com>
Message-ID: <08039793-B48D-4AE1-A948-D8644080547A@comcast.net>


On Sep 11, 2014, at 5:13 AM, Stefan Petersson wrote:

> I have :
> 
> rs <- c(3, 2, 3, 4)
> cs <- c(4, 5, 3)
> 
> And want:
> 
>> matrix
>    [,1] [,2] [,3]
> [1,] 1    2    0
> [2,] 1    0    1
> [3,] 1    1    1
> [4,] 1    2    1
> 
> The rowSums in the above matrix is equal to sum(rs) and colSums is
> equal to sum(cs). It's sort of a matrix expansion where the margins
> are known beforehand...
> 

Looks like an integer programming question. 7 integer equations with 12 unknowns, so probably not specifying a unique solution. Have you looked at the appropriate Task Views?

Best;
David.


> I hope I make sense.
> 
> 
> 2014-09-11 14:09 GMT+02:00 Charles Determan Jr <deter088 at umn.edu>:
>> Do you have an example of what you would like your output to look like?  It
>> is a little difficult to fully understand what you are looking for.  You
>> only have 18 values but are looking to fill at 10x8 matrix (i.e. 80 values).
>> If you can clarify better we may be better able to help you.
>> 
>> Charles
>> 
>> 
>> On Thu, Sep 11, 2014 at 3:47 AM, Stefan Petersson <stefan at inizio.se> wrote:
>>> 
>>> Hi,
>>> 
>>> I have two vector of margins. Now I want to create "fill" matrix that
>>> reflects the margins.
>>> 
>>> seats <- c(17,24,28,30,34,36,40,44,46,50)
>>> mandates <- c(107,23,24,19,112,19,25,20)
>>> 
>>> Both vectors adds up to 349. So I want a 10x8 matrix with row sums
>>> corresponding to "seats" and column sums corresponding to "mandates".
>>> 
>>> ______________________________________________

> 

David Winsemius
Alameda, CA, USA


From yuan.hypnos.luo at gmail.com  Thu Sep 11 22:42:46 2014
From: yuan.hypnos.luo at gmail.com (Yuan Luo)
Date: Thu, 11 Sep 2014 16:42:46 -0400
Subject: [R] weird install package error
Message-ID: <CAMY509kBrnvLb-nij4uhx30KiNUuOg_XwFvGfHbmfYXU=PM0RA@mail.gmail.com>

Hi,

I am getting an error installing the MASS package. Googling suggests
restarting R, but it didn't help. Anyone has a clue?

Many thanks,
Yuan


> install.packages("MASS")
Installing package into ?/PHShome/yl960/R/3.0?
(as ?lib? is unspecified)
trying URL 'http://lib.stat.cmu.edu/R/CRAN/src/contrib/MASS_7.3-34.tar.gz'
Content type 'application/x-gzip' length 486552 bytes (475 Kb)
opened URL
==================================================
downloaded 475 Kb

* installing *source* package ?MASS? ...
** package ?MASS? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/source/R-3.0.2-mkl/lib64/R/include -DNDEBUG
 -I/usr/local/include    -fpic  -g -O2  -c MASS.c -o MASS.o
gcc -std=gnu99 -I/source/R-3.0.2-mkl/lib64/R/include -DNDEBUG
 -I/usr/local/include    -fpic  -g -O2  -c lqs.c -o lqs.o
gcc -std=gnu99 -shared -L/usr/local/lib64 -o MASS.so MASS.o lqs.o
-L/source/R-3.0.2-mkl/lib64/R/lib -lR
installing to /PHShome/yl960/R/3.0/MASS/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Warning in get(hookname, envir = env, inherits = FALSE) :
  internal error -3 in R_decompress1
Error in get(hookname, envir = env, inherits = FALSE) :
  lazy-load database 'P' is corrupt
* removing ?/PHShome/yl960/R/3.0/MASS?

The downloaded source packages are in
?/tmp/RtmpJpFCbC/downloaded_packages?
Warning message:
In install.packages("MASS") :
  installation of package ?MASS? had non-zero exit status

	[[alternative HTML version deleted]]


From stefan at inizio.se  Thu Sep 11 22:52:40 2014
From: stefan at inizio.se (Stefan Petersson)
Date: Thu, 11 Sep 2014 22:52:40 +0200
Subject: [R] Margins to fill matrix
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F96EBB@mb02.ads.tamu.edu>
References: <CAFy6Y8UxCbsbm05P2rtPjUGOj3_TBZB9iM0gm6PvU1ZR3ugXZg@mail.gmail.com>
	<CAOLJphkt54CbPrwxq6PnF=BXH9Fq8DnaQcQJ6xy5EBBSQwWO5w@mail.gmail.com>
	<CAFy6Y8W_vcpz0WD8Vwe6HEGfGJuozdjRBJZC3zJ712GD04+8MQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F96EBB@mb02.ads.tamu.edu>
Message-ID: <CAFy6Y8XXw_KUDtqXt4OFBXSXm_p6giS7x8YSgjsXQj_zUfOKoA@mail.gmail.com>

Yes! That's excactly what I need. Thank You so much!
 Den 11 sep 2014 21:20 skrev "David L Carlson" <dcarlson at tamu.edu>:

> You want r2dtable():
>
> > ?r2dtable
> > set.seed(42)
> > a <- r2dtable(1, seats, mandates)
> addmargins(a[[1]])
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
>  [1,]    2    3    1    0    6    2    1    2   17
>  [2,]    8    0    1    1   11    0    2    1   24
>  [3,]    8    0    5    2    7    1    1    4   28
>  [4,]   10    5    3    1    6    3    0    2   30
>  [5,]   13    4    1    4    9    0    2    1   34
>  [6,]    8    2    2    0   17    3    4    0   36
>  [7,]   13    0    2    6    9    2    3    5   40
>  [8,]   12    4    4    3   12    3    3    3   44
>  [9,]   14    3    3    2   18    0    4    2   46
> [10,]   19    2    2    0   17    5    5    0   50
> [11,]  107   23   24   19  112   19   25   20  349
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Stefan Petersson
> Sent: Thursday, September 11, 2014 7:13 AM
> To: Charles Determan Jr
> Cc: r-help at r-project.org
> Subject: Re: [R] Margins to fill matrix
>
> I have :
>
> rs <- c(3, 2, 3, 4)
> cs <- c(4, 5, 3)
>
> And want:
>
> > matrix
>     [,1] [,2] [,3]
> [1,] 1    2    0
> [2,] 1    0    1
> [3,] 1    1    1
> [4,] 1    2    1
>
> The rowSums in the above matrix is equal to sum(rs) and colSums is
> equal to sum(cs). It's sort of a matrix expansion where the margins
> are known beforehand...
>
> I hope I make sense.
>
>
> 2014-09-11 14:09 GMT+02:00 Charles Determan Jr <deter088 at umn.edu>:
> > Do you have an example of what you would like your output to look like?
> It
> > is a little difficult to fully understand what you are looking for.  You
> > only have 18 values but are looking to fill at 10x8 matrix (i.e. 80
> values).
> > If you can clarify better we may be better able to help you.
> >
> > Charles
> >
> >
> > On Thu, Sep 11, 2014 at 3:47 AM, Stefan Petersson <stefan at inizio.se>
> wrote:
> >>
> >> Hi,
> >>
> >> I have two vector of margins. Now I want to create "fill" matrix that
> >> reflects the margins.
> >>
> >>  seats <- c(17,24,28,30,34,36,40,44,46,50)
> >>  mandates <- c(107,23,24,19,112,19,25,20)
> >>
> >> Both vectors adds up to 349. So I want a 10x8 matrix with row sums
> >> corresponding to "seats" and column sums corresponding to "mandates".
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Dr. Charles Determan, PhD
> > Integrated Biosciences
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Thu Sep 11 22:56:52 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 11 Sep 2014 13:56:52 -0700
Subject: [R] How to test for open pdf file on Windows before calling
 cairo_pdf ?
In-Reply-To: <CAKFxdiS6EmYjkgTKDG_LJEykpu+AoAHHpw6T5qbTe2MpZ-FWYQ@mail.gmail.com>
References: <CAKFxdiS6EmYjkgTKDG_LJEykpu+AoAHHpw6T5qbTe2MpZ-FWYQ@mail.gmail.com>
Message-ID: <CAFDcVCS1r3bRn4p-dK+QaTxSdiOQ6YZwUuiZmQirh3LajP5aGg@mail.gmail.com>

A poor mans solution would be to try to temporarily delete or move the
file, depending exactly what you wish to do. You can also try:

library("R.utils")
pathname <- Arguments$getWritablePathname("file2.pdf", mustNotExist=FALSE)

which does lots of assertions of write permissions of new and existing
file, in the target directory etc. and tries to give an informative
error if it fails.  However, it does not have a particular
test/message for "locked" PDF files.  This is the error message I get
when I view a PDF in Adobe Reader on Windows:

> pathname <- Arguments$getWritablePathname("file2.pdf", mustNotExist=FALSE)
[2014-09-11 13:42:14] Exception: No permission to modify existing file: file2.pd
f

  at #03. getWritablePathname.Arguments(static, ...)
          - getWritablePathname.Arguments() is in environment 'R.utils'

  at #02. getWritablePathname(static, ...)
          - getWritablePathname() is in environment 'R.utils'
          - originating from '<text>'

  at #01. Arguments$getWritablePathname("file2.pdf", mustNotExist = FALSE)
          - Arguments$getWritablePathname() is local of the calling function

Error: No permission to modify existing file: file2.pdf
In addition: Warning message:
In fileAccess.default(pathname, mode = 2) :
  file.access(..., mode=2) and file(..., open="ab") gives different
results (0 != -1). Will use the file() results: file2.pdf


Note that it is not all PDF viewers that lock/prevent files from being
overwritten.  For instance, when I view the same file using Foxit
Reader, I don't get an error, e.g.

library("R.utils")
pathname <- Arguments$getWritablePathname("file2.pdf", mustNotExist=FALSE)
pdf(pathname)
plot(1:10)
dev.off()


Better yet, just use the R.devices package
[http://cran.r-project.org/web/packages/R.devices/index.html] and
it'll all be take care of for you:

library("R.devices")
devEval("png", name="file1", {
  plot(1:10)
})

library("R.devices")
devEval("cairo_pdf", name="file2", {
  plot(1:10)
}, ext="pdf")

You'll get the above error message if, say, Adobe Reader is preventing
the file from being overwritten.  This approach will make sure to
close any opened graphics devices, not to leave incomplete image files
behind if there is an errors and so on.  There are plenty of option
for it, e.g. the default output directory is "./figures/", which can
be changed.  (The need for argument ext="pdf" is due to a minor bug
that will be fixed in the next release.)


Hope this helps,

Henrik
(author of R.utils and R.devices)

On Thu, Sep 11, 2014 at 1:06 PM, Kevin Wright <kw.stat at gmail.com> wrote:
> On Windows:
>
> The pdf("file1.pdf") command will throw an error if the file1.pdf is open
> in a viewer.  For example:
>
> pdf("file1.pdf")
> plot(1:10)
> dev.off()
> shell.exec("file1.pdf")
> pdf("file1.pdf") # Causes an error
>
> As suggested by the help page for file.access(), I normally use
> try(pdf("file1.pdf")) to test if file1.pdf is open.
>
> Oddly, I cannot do the same using cairo_pdf.  For example:
>
> cairo_pdf("file2.pdf")
> plot(1:10)
> dev.off()
> shell.exec("file2.pdf")
> cairo_pdf("file2.pdf") # No error
>
> It is not until a plotting command is called that an error is generated.
>
> Is there a way to test if a pdf file can be written to by cairo_pdf ?
>
> I'd rather not wrap all plotting commands with try()....I have many such
> commands in my script and the choice of which one is first depends on user
> input.
>
> Kevin Wright
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jeremy.miles at gmail.com  Fri Sep 12 02:49:05 2014
From: jeremy.miles at gmail.com (Jeremy Miles)
Date: Thu, 11 Sep 2014 17:49:05 -0700
Subject: [R] mice - undefined columns selected
Message-ID: <CAMtGSx=PPtwcYGhRK_rijx8te1S53dQ5Bk9-Kk9sn-W+N2w4Lw@mail.gmail.com>

I've got a problem with the mice package that I don't understand.

Here's the code:
library(mice)
d <- read.csv("https://dl.dropboxusercontent.com/u/24381951/employment.csv",
 as.is=TRUE, row.names=1)d.imp <- mice(data=d, m=1)

Result is:
Error in `[.data.frame`(data, , jj) : undefined columns selected

I hope I'm doing something foolish,

thanks,

Jeremy

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Sep 12 06:10:13 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 12 Sep 2014 12:10:13 +0800 (CST)
Subject: [R]    using pdf(file="") encount a Chinese garbled
Message-ID: <502ba5da.1dddf.148680de2f9.Coremail.rhelpmaillist@163.com>


Dear expeRts,
??? When i use the following codes:
??? pdf(file="1.pdf",width=15)
? ? plot(1:3,main="??")
??? dev.off()
#There were 12 warnings (use warnings() to see them)
? I find that "??" can't show correctly in pdf file, but? i just ?plot(1:3,main="??") to R plot viewer, it's ok .
? Is there anyone happen to know the solution? BTW, i explore the encoding argument in ?pdf ,but still can't solve the problem.




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From jszhao at yeah.net  Fri Sep 12 06:33:19 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Thu, 11 Sep 2014 21:33:19 -0700
Subject: [R] using pdf(file="") encount a Chinese garbled
In-Reply-To: <502ba5da.1dddf.148680de2f9.Coremail.rhelpmaillist@163.com>
References: <502ba5da.1dddf.148680de2f9.Coremail.rhelpmaillist@163.com>
Message-ID: <5412778F.7090002@yeah.net>

On 2014/9/11 21:10, PO SU wrote:
>
> Dear expeRts,
>      When i use the following codes:
>      pdf(file="1.pdf",width=15)
>      plot(1:3,main="??")
>      dev.off()
> #There were 12 warnings (use warnings() to see them)
>    I find that "??" can't show correctly in pdf file, but  i just  plot(1:3,main="??") to R plot viewer, it's ok .
>    Is there anyone happen to know the solution? BTW, i explore the encoding argument in ?pdf ,but still can't solve the problem.
>

please refer to:
Paul Murrell and Brian Ripley (2006) Non-standard fonts in PostScript 
and PDF graphics. R News, 6(2):41?47. 
http://cran.r-project.org/doc/Rnews/Rnews_2006-2.pdf

if you can read Chinese, you also can refer to:
http://www.newsmth.net/bbscon.php?bid=1039&id=3924

HTH,
Jinsong

>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From foto521ster at gmail.com  Fri Sep 12 05:39:15 2014
From: foto521ster at gmail.com (Man Photo)
Date: Thu, 11 Sep 2014 23:39:15 -0400
Subject: [R] how to run Fleming-Harrington weighted log-rank test in R
Message-ID: <CAJTrLiyVLdDEu=4QhCF-+X_SsHWnPsF9hpjTf33XYr+Tv57YYg@mail.gmail.com>

Hi,
I am looking for an R package that allows one to run the Fleming-Harrington
weighted log-rank test with varying Rho and Gamma. Any help is appreciated.
Thanks.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Sep 12 09:27:24 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Sep 2014 00:27:24 -0700
Subject: [R] how to run Fleming-Harrington weighted log-rank test in R
In-Reply-To: <CAJTrLiyVLdDEu=4QhCF-+X_SsHWnPsF9hpjTf33XYr+Tv57YYg@mail.gmail.com>
References: <CAJTrLiyVLdDEu=4QhCF-+X_SsHWnPsF9hpjTf33XYr+Tv57YYg@mail.gmail.com>
Message-ID: <0EFBC556-1E3D-4289-97B9-434415B81869@comcast.net>


On Sep 11, 2014, at 8:39 PM, Man Photo wrote:

> Hi,
> I am looking for an R package that allows one to run the Fleming- 
> Harrington
> weighted log-rank test with varying Rho and Gamma. Any help is  
> appreciated.
> Thanks.

install.packages("sos")
library(sos)
findFn("Fleming-Harrington")
>
>
> 	[[alternative HTML version deleted]]

Learn to search and learn to post in plain text.

>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

-- 

David Winsemius, MD
Alameda, CA, USA


From angel.rodriguez at matiainstituto.net  Fri Sep 12 10:32:09 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Fri, 12 Sep 2014 10:32:09 +0200
Subject: [R] Lines instead of points in a scatterplot
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>



Dear subscribers,

I have the following dataframe:

> aggr
   child65$decedad       logit
1          [65,67)  0.00000000
10              67  0.00000000
2          [68,70) -0.06669137
3          [70,72) -0.71294981
4          [72,74) -0.59783700
5          [74,77) -1.08334482
6          [77,79) -1.88273125
7          [79,81) -1.21924028
8          [81,84) -1.94591015
9          [84,98] -1.65822808

When I write:

> plot(aggr)

I get the correct scatterplot, but points are substituted by horizontal lines. I prefer points.

If I write:

> plot(aggr, pch=1)

nothing changes

> plot(aggr[,1],aggr[,2])

nothing changes

> plot(aggr, type="p")

nothing changes


Any idea?

Best regards,

Angel Rodr?guez-Laso

	[[alternative HTML version deleted]]


From vd4mmind at gmail.com  Fri Sep 12 10:50:14 2014
From: vd4mmind at gmail.com (Vivek Das)
Date: Fri, 12 Sep 2014 10:50:14 +0200
Subject: [R] Lines instead of points in a scatterplot
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>
Message-ID: <CAFkF=gGbLoUdhOs9QerKjPkjCcOQkQSwyxjv36Fa1LNLRuw-tA@mail.gmail.com>

HI,

Try to change with

plot(aggr, type="l")

see what happens?

This should work

----------------------------------------------------------

Vivek Das


On Fri, Sep 12, 2014 at 10:32 AM, Angel Rodriguez <
angel.rodriguez at matiainstituto.net> wrote:

>
>
> Dear subscribers,
>
> I have the following dataframe:
>
> > aggr
>    child65$decedad       logit
> 1          [65,67)  0.00000000
> 10              67  0.00000000
> 2          [68,70) -0.06669137
> 3          [70,72) -0.71294981
> 4          [72,74) -0.59783700
> 5          [74,77) -1.08334482
> 6          [77,79) -1.88273125
> 7          [79,81) -1.21924028
> 8          [81,84) -1.94591015
> 9          [84,98] -1.65822808
>
> When I write:
>
> > plot(aggr)
>
> I get the correct scatterplot, but points are substituted by horizontal
> lines. I prefer points.
>
> If I write:
>
> > plot(aggr, pch=1)
>
> nothing changes
>
> > plot(aggr[,1],aggr[,2])
>
> nothing changes
>
> > plot(aggr, type="p")
>
> nothing changes
>
>
> Any idea?
>
> Best regards,
>
> Angel Rodr?guez-Laso
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From angel.rodriguez at matiainstituto.net  Fri Sep 12 10:54:30 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Fri, 12 Sep 2014 10:54:30 +0200
Subject: [R] Lines instead of points in a scatterplot
References: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>
	<CAFkF=gGbLoUdhOs9QerKjPkjCcOQkQSwyxjv36Fa1LNLRuw-tA@mail.gmail.com>
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B27E@MATIAEXCH.matiaf.local>

Thank you, Vivek, but it hasn?t worked. I've tryed type="o" and type="h" to no avail.

Angel




-----Mensaje original-----
De: Vivek Das [mailto:vd4mmind at gmail.com]
Enviado el: vie 12/09/2014 10:50
Para: Angel Rodriguez
CC: R help
Asunto: Re: [R] Lines instead of points in a scatterplot
 
HI,

Try to change with

plot(aggr, type="l")

see what happens?

This should work

----------------------------------------------------------

Vivek Das


On Fri, Sep 12, 2014 at 10:32 AM, Angel Rodriguez <
angel.rodriguez at matiainstituto.net> wrote:

>
>
> Dear subscribers,
>
> I have the following dataframe:
>
> > aggr
>    child65$decedad       logit
> 1          [65,67)  0.00000000
> 10              67  0.00000000
> 2          [68,70) -0.06669137
> 3          [70,72) -0.71294981
> 4          [72,74) -0.59783700
> 5          [74,77) -1.08334482
> 6          [77,79) -1.88273125
> 7          [79,81) -1.21924028
> 8          [81,84) -1.94591015
> 9          [84,98] -1.65822808
>
> When I write:
>
> > plot(aggr)
>
> I get the correct scatterplot, but points are substituted by horizontal
> lines. I prefer points.
>
> If I write:
>
> > plot(aggr, pch=1)
>
> nothing changes
>
> > plot(aggr[,1],aggr[,2])
>
> nothing changes
>
> > plot(aggr, type="p")
>
> nothing changes
>
>
> Any idea?
>
> Best regards,
>
> Angel Rodr?guez-Laso
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Sep 12 11:01:43 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 12 Sep 2014 17:01:43 +0800 (CST)
Subject: [R] using pdf(file="") encount a Chinese garbled
In-Reply-To: <5412778F.7090002@yeah.net>
References: <502ba5da.1dddf.148680de2f9.Coremail.rhelpmaillist@163.com>
	<5412778F.7090002@yeah.net>
Message-ID: <15535f4.13143.1486918c2ca.Coremail.rhelpmaillist@163.com>



Tks, it works now , just needing some extra?ajustment.



--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-12 12:33:19, "Jinsong Zhao" <jszhao at yeah.net> wrote:
>On 2014/9/11 21:10, PO SU wrote:
>>
>> Dear expeRts,
>>      When i use the following codes:
>>      pdf(file="1.pdf",width=15)
>>      plot(1:3,main="??")
>>      dev.off()
>> #There were 12 warnings (use warnings() to see them)
>>    I find that "??" can't show correctly in pdf file, but  i just  plot(1:3,main="??") to R plot viewer, it's ok .
>>    Is there anyone happen to know the solution? BTW, i explore the encoding argument in ?pdf ,but still can't solve the problem.
>>
>
>please refer to:
>Paul Murrell and Brian Ripley (2006) Non-standard fonts in PostScript 
>and PDF graphics. R News, 6(2):41?47. 
>http://cran.r-project.org/doc/Rnews/Rnews_2006-2.pdf
>
>if you can read Chinese, you also can refer to:
>http://www.newsmth.net/bbscon.php?bid=1039&id=3924
>
>HTH,
>Jinsong
>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From pdalgd at gmail.com  Fri Sep 12 11:07:31 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 Sep 2014 11:07:31 +0200
Subject: [R] Lines instead of points in a scatterplot
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>
Message-ID: <50DD5E28-072B-4A9C-8367-BA80035B94A8@gmail.com>

The root cause is that column 1 is a factor. So what you get is really a set of parallel boxplots each based on one observation. 

plot.default() is one way out, but you may need to generate the x-axis labels yourself.

I.e.,

x <- factor(LETTERS[1:10])
y <- rnorm(10)
plot(x,y)
plot.default(x,y)

For full control, recode the factor to a numeric variable. 


On 12 Sep 2014, at 10:32 , Angel Rodriguez <angel.rodriguez at matiainstituto.net> wrote:

> 
> 
> Dear subscribers,
> 
> I have the following dataframe:
> 
>> aggr
>   child65$decedad       logit
> 1          [65,67)  0.00000000
> 10              67  0.00000000
> 2          [68,70) -0.06669137
> 3          [70,72) -0.71294981
> 4          [72,74) -0.59783700
> 5          [74,77) -1.08334482
> 6          [77,79) -1.88273125
> 7          [79,81) -1.21924028
> 8          [81,84) -1.94591015
> 9          [84,98] -1.65822808
> 
> When I write:
> 
>> plot(aggr)
> 
> I get the correct scatterplot, but points are substituted by horizontal lines. I prefer points.
> 
> If I write:
> 
>> plot(aggr, pch=1)
> 
> nothing changes
> 
>> plot(aggr[,1],aggr[,2])
> 
> nothing changes
> 
>> plot(aggr, type="p")
> 
> nothing changes
> 
> 
> Any idea?
> 
> Best regards,
> 
> Angel Rodr?guez-Laso
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From angel.rodriguez at matiainstituto.net  Fri Sep 12 11:23:55 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Fri, 12 Sep 2014 11:23:55 +0200
Subject: [R] Lines instead of points in a scatterplot
References: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>
	<50DD5E28-072B-4A9C-8367-BA80035B94A8@gmail.com>
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B280@MATIAEXCH.matiaf.local>

Thank you Peter. plot.default works perfectly.

I'm puzzled now with the first column of the dataframe aggr. 

aggr comes from:

aggr<-summarize(child65$benvii, by=child65$decedad, FUN=mean, na.rm=TRUE)

If I write:

> aggr[,1]
 [1] [65,67) 67      [68,70) [70,72) [72,74) [74,77) [77,79) [79,81) [81,84) [84,98]
attr(,"label")
[1] child65$decedad
Levels: [65,67) 67 [68,70) [70,72) [72,74) [74,77) [77,79) [79,81) [81,84) [84,98]
> aggr[,2]
    [65,67)          67     [68,70)     [70,72)     [72,74)     [74,77)     [77,79)     [79,81)     [81,84) 
 0.00000000  0.00000000 -0.06669137 -0.71294981 -0.59783700 -1.08334482 -1.88273125 -1.21924028 -1.94591015 
    [84,98] 
-1.65822808 
attr(,"label")
[1] "child65$benvii"
attr(,"class")
[1] "labelled" "array"   


So, it's like if the first column does not exist. It does not even have a name.

Angel




-----Mensaje original-----
De: peter dalgaard [mailto:pdalgd at gmail.com]
Enviado el: vie 12/09/2014 11:07
Para: Angel Rodriguez
CC: R-help at r-project.org
Asunto: Re: [R] Lines instead of points in a scatterplot
 
The root cause is that column 1 is a factor. So what you get is really a set of parallel boxplots each based on one observation. 

plot.default() is one way out, but you may need to generate the x-axis labels yourself.

I.e.,

x <- factor(LETTERS[1:10])
y <- rnorm(10)
plot(x,y)
plot.default(x,y)

For full control, recode the factor to a numeric variable. 


On 12 Sep 2014, at 10:32 , Angel Rodriguez <angel.rodriguez at matiainstituto.net> wrote:

> 
> 
> Dear subscribers,
> 
> I have the following dataframe:
> 
>> aggr
>   child65$decedad       logit
> 1          [65,67)  0.00000000
> 10              67  0.00000000
> 2          [68,70) -0.06669137
> 3          [70,72) -0.71294981
> 4          [72,74) -0.59783700
> 5          [74,77) -1.08334482
> 6          [77,79) -1.88273125
> 7          [79,81) -1.21924028
> 8          [81,84) -1.94591015
> 9          [84,98] -1.65822808
> 
> When I write:
> 
>> plot(aggr)
> 
> I get the correct scatterplot, but points are substituted by horizontal lines. I prefer points.
> 
> If I write:
> 
>> plot(aggr, pch=1)
> 
> nothing changes
> 
>> plot(aggr[,1],aggr[,2])
> 
> nothing changes
> 
>> plot(aggr, type="p")
> 
> nothing changes
> 
> 
> Any idea?
> 
> Best regards,
> 
> Angel Rodr?guez-Laso
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com










	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Sep 12 11:40:12 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 12 Sep 2014 09:40:12 +0000
Subject: [R] Lines instead of points in a scatterplot
In-Reply-To: <CAFkF=gGbLoUdhOs9QerKjPkjCcOQkQSwyxjv36Fa1LNLRuw-tA@mail.gmail.com>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>
	<CAFkF=gGbLoUdhOs9QerKjPkjCcOQkQSwyxjv36Fa1LNLRuw-tA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1C61@SRVEXCHMBX.precheza.cz>

Hi

look at str(aggr)

I bet you will find that your first column is factor and lines you see are from making a boxplot with your plot command.

You can change it by various ways but I would prefer to change factor to numeric, which requires some regular expression.
Here is one but I believe that other experts can come with easier one.

dat <- gsub("^.*([[:digit:]]{2}),([[:digit:]]*).*$", "\\1", aggr$child65$decedad)

Then plot
plot(dat, aggr[,2])

shall produce points.

Another option can be

plot(as.numeric(aggr[,1], aggr[,2], axes=FALSE)

and then you need to ad axes labels, see ?axis

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Vivek Das
> Sent: Friday, September 12, 2014 10:50 AM
> To: Angel Rodriguez
> Cc: R help
> Subject: Re: [R] Lines instead of points in a scatterplot
>
> HI,
>
> Try to change with
>
> plot(aggr, type="l")
>
> see what happens?
>
> This should work
>
> ----------------------------------------------------------
>
> Vivek Das
>
>
> On Fri, Sep 12, 2014 at 10:32 AM, Angel Rodriguez <
> angel.rodriguez at matiainstituto.net> wrote:
>
> >
> >
> > Dear subscribers,
> >
> > I have the following dataframe:
> >
> > > aggr
> >    child65$decedad       logit
> > 1          [65,67)  0.00000000
> > 10              67  0.00000000
> > 2          [68,70) -0.06669137
> > 3          [70,72) -0.71294981
> > 4          [72,74) -0.59783700
> > 5          [74,77) -1.08334482
> > 6          [77,79) -1.88273125
> > 7          [79,81) -1.21924028
> > 8          [81,84) -1.94591015
> > 9          [84,98] -1.65822808
> >
> > When I write:
> >
> > > plot(aggr)
> >
> > I get the correct scatterplot, but points are substituted by
> > horizontal lines. I prefer points.
> >
> > If I write:
> >
> > > plot(aggr, pch=1)
> >
> > nothing changes
> >
> > > plot(aggr[,1],aggr[,2])
> >
> > nothing changes
> >
> > > plot(aggr, type="p")
> >
> > nothing changes
> >
> >
> > Any idea?
> >
> > Best regards,
> >
> > Angel Rodr?guez-Laso
> >
> >         [[alternative HTML version deleted]]
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From angel.rodriguez at matiainstituto.net  Fri Sep 12 11:42:28 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Fri, 12 Sep 2014 11:42:28 +0200
Subject: [R] Lines instead of points in a scatterplot
References: <8564BCD7D26E0D40872F1A132C8BBB250258B27B@MATIAEXCH.matiaf.local>
	<CAFkF=gGbLoUdhOs9QerKjPkjCcOQkQSwyxjv36Fa1LNLRuw-tA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE1C61@SRVEXCHMBX.precheza.cz>
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B281@MATIAEXCH.matiaf.local>

Thank you, Petr.

I understand now. I thought the first column Peter was referring to in his email was 

1         
10         
2         
3         
4          
5          
6          
7          
8          
9          

that appears when I write > aggr. In facti, it is:

[65,67) 
67  
[68,70) 
[70,72)
...

There is no need to change this column if one uses plot.default

Angel



-----Mensaje original-----
De: PIKAL Petr [mailto:petr.pikal at precheza.cz]
Enviado el: vie 12/09/2014 11:40
Para: Vivek Das; Angel Rodriguez
CC: R help
Asunto: RE: [R] Lines instead of points in a scatterplot
 
Hi

look at str(aggr)

I bet you will find that your first column is factor and lines you see are from making a boxplot with your plot command.

You can change it by various ways but I would prefer to change factor to numeric, which requires some regular expression.
Here is one but I believe that other experts can come with easier one.

dat <- gsub("^.*([[:digit:]]{2}),([[:digit:]]*).*$", "\\1", aggr$child65$decedad)

Then plot
plot(dat, aggr[,2])

shall produce points.

Another option can be

plot(as.numeric(aggr[,1], aggr[,2], axes=FALSE)

and then you need to ad axes labels, see ?axis

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Vivek Das
> Sent: Friday, September 12, 2014 10:50 AM
> To: Angel Rodriguez
> Cc: R help
> Subject: Re: [R] Lines instead of points in a scatterplot
>
> HI,
>
> Try to change with
>
> plot(aggr, type="l")
>
> see what happens?
>
> This should work
>
> ----------------------------------------------------------
>
> Vivek Das
>
>
> On Fri, Sep 12, 2014 at 10:32 AM, Angel Rodriguez <
> angel.rodriguez at matiainstituto.net> wrote:
>
> >
> >
> > Dear subscribers,
> >
> > I have the following dataframe:
> >
> > > aggr
> >    child65$decedad       logit
> > 1          [65,67)  0.00000000
> > 10              67  0.00000000
> > 2          [68,70) -0.06669137
> > 3          [70,72) -0.71294981
> > 4          [72,74) -0.59783700
> > 5          [74,77) -1.08334482
> > 6          [77,79) -1.88273125
> > 7          [79,81) -1.21924028
> > 8          [81,84) -1.94591015
> > 9          [84,98] -1.65822808
> >
> > When I write:
> >
> > > plot(aggr)
> >
> > I get the correct scatterplot, but points are substituted by
> > horizontal lines. I prefer points.
> >
> > If I write:
> >
> > > plot(aggr, pch=1)
> >
> > nothing changes
> >
> > > plot(aggr[,1],aggr[,2])
> >
> > nothing changes
> >
> > > plot(aggr, type="p")
> >
> > nothing changes
> >
> >
> > Any idea?
> >
> > Best regards,
> >
> > Angel Rodr?guez-Laso
> >
> >         [[alternative HTML version deleted]]
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k nemu pripojen? dokumenty jsou duvern? a jsou urceny pouze jeho adres?tum.
Jestlize jste obdrzel(a) tento e-mail omylem, informujte laskave neprodlene jeho odes?latele. Obsah tohoto emailu i s pr?lohami a jeho kopie vymazte ze sv?ho syst?mu.
Nejste-li zam?slen?m adres?tem tohoto emailu, nejste opr?vneni tento email jakkoliv uz?vat, rozsirovat, kop?rovat ci zverejnovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? skodu zpusobenou modifikacemi ci zpozden?m prenosu e-mailu.

V pr?pade, ze je tento e-mail souc?st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukoncit kdykoliv jedn?n? o uzavren? smlouvy, a to z jak?hokoliv duvodu i bez uveden? duvodu.
- a obsahuje-li nab?dku, je adres?t opr?vnen nab?dku bezodkladne prijmout; Odes?latel tohoto e-mailu (nab?dky) vylucuje prijet? nab?dky ze strany pr?jemce s dodatkem ci odchylkou.
- trv? odes?latel na tom, ze pr?slusn? smlouva je uzavrena teprve v?slovn?m dosazen?m shody na vsech jej?ch n?lezitostech.
- odes?latel tohoto emailu informuje, ze nen? opr?vnen uzav?rat za spolecnost z?dn? smlouvy s v?jimkou pr?padu, kdy k tomu byl p?semne zmocnen nebo p?semne poveren a takov? poveren? nebo pln? moc byly adres?tovi tohoto emailu pr?padne osobe, kterou adres?t zastupuje, predlozeny nebo jejich existence je adres?tovi ci osobe j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


	[[alternative HTML version deleted]]


From julian.bothe at elitepartner.de  Fri Sep 12 12:03:31 2014
From: julian.bothe at elitepartner.de (julian.bothe at elitepartner.de)
Date: Fri, 12 Sep 2014 12:03:31 +0200 (CEST)
Subject: [R] Error with RJDBC when trying dbUnloadDriver()
Message-ID: <cde7075e.00000d24.0000000e@FIW7PC12.ELITEMEDIANET>

Hello everyone, Hello Simon, 

 

I am starting to use RJDBC. When trying to unload the driver, I get an
Error message - even when not connecting to any database. 

This issue has been reported before in 2011
(https://stat.ethz.ch/pipermail/r-sig-db/2011q4/001103.html ), and it was
said that it's possibly a bug. But it seems that it's still there. 

 

Any hints?

 

-----------

library("RJDBC")

Postgres_drv <- JDBC(driverClass = 'org.postgresql.Driver',

                     classPath=
'PATH/TO/JAR/postgresql-9.3-1102.jdbc4.jar')

dbUnloadDriver(Postgres_drv)

 

#Error in .valueClassTest(standardGeneric("dbUnloadDriver"), "logical",  :


#  invalid value from generic function 'dbUnloadDriver', class "NULL",
expected "logical"

--------------

All the best 

Julian


	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Fri Sep 12 12:25:26 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 12 Sep 2014 20:25:26 +1000
Subject: [R] Parliament Seats Graph
In-Reply-To: <CAFy6Y8VGLanmQtn_0p3YuT2FkH45fv4NsdZ=psQE2pD3Kor0Jg@mail.gmail.com>
References: <CAFy6Y8VGLanmQtn_0p3YuT2FkH45fv4NsdZ=psQE2pD3Kor0Jg@mail.gmail.com>
Message-ID: <2667724.z13KEhXo2E@localhost.localdomain>

On Mon, 8 Sep 2014 10:22:03 PM Stefan Petersson wrote:
> Hi,
> 
> Is there any package (or homegrown function) that can produce
> "Parliament Seats Graph"? I'm referring to the nice looking concentric
> half circles of colored "seats" as seen on Wikipedia (for example).
> 
> I can pretty easily plot the points and color them. But I can't group
> the colored points in sectors, as seen on the example.
> 
> Example:
> 
http://en.wikipedia.org/wiki/Verkhovna_Rada#mediaviewer/File:Fractions_of_th
> e_Parliament_of_Ukraine.svg
> 
> Found here (on the right, a bit down):
> http://en.wikipedia.org/wiki/Verkhovna_Rada
> 
Hi Stefan,
I can see how you would plot the points going from right to left (the easy 
way), by plotting the next point on the arc with the least increase in 
angle from the last point plotted. If this is the way you have worked out, I 
think all that you have to do is to turn the party affiliation into a factor (if 
it is not already) and plot the points by the sorted numeric value of the 
factor. You will probably want to adjust the levels to some political 
dimensions before doing the sort.

Jim


From b.rowlingson at lancaster.ac.uk  Fri Sep 12 13:18:14 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Sep 2014 12:18:14 +0100
Subject: [R] Parliament Seats Graph
In-Reply-To: <c2fba23d1d5140f3a5aab3d6ad94e6af@EX-1-HT0.lancs.local>
References: <CAFy6Y8VGLanmQtn_0p3YuT2FkH45fv4NsdZ=psQE2pD3Kor0Jg@mail.gmail.com>
	<c2fba23d1d5140f3a5aab3d6ad94e6af@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMg=5Dq0QREBb6h+vHVyyR1e7Q-CFS8LknMW1j-dC-OyA@mail.gmail.com>

On Fri, Sep 12, 2014 at 11:25 AM, Jim Lemon <jim at bitwrit.com.au> wrote:

> I can see how you would plot the points going from right to left (the easy
> way), by plotting the next point on the arc with the least increase in
> angle from the last point plotted. If this is the way you have worked out, I
> think all that you have to do is to turn the party affiliation into a factor (if
> it is not already) and plot the points by the sorted numeric value of the
> factor. You will probably want to adjust the levels to some political
> dimensions before doing the sort.

 I'm interested in how you get exactly N seats in M rows that look as
neat as that. My eyes are going funny trying to count the dots in each
arc but there must be some nice algorithm for generating a sequence
that sums to N, has M elements, and has a small variable difference
between the row sizes to constrain the sum...

 Or am I overthinking this?

Barry


From stefan at inizio.se  Fri Sep 12 13:28:15 2014
From: stefan at inizio.se (Stefan Petersson)
Date: Fri, 12 Sep 2014 13:28:15 +0200
Subject: [R] Parliament Seats Graph
In-Reply-To: <CANVKczMg=5Dq0QREBb6h+vHVyyR1e7Q-CFS8LknMW1j-dC-OyA@mail.gmail.com>
References: <CAFy6Y8VGLanmQtn_0p3YuT2FkH45fv4NsdZ=psQE2pD3Kor0Jg@mail.gmail.com>
	<c2fba23d1d5140f3a5aab3d6ad94e6af@EX-1-HT0.lancs.local>
	<CANVKczMg=5Dq0QREBb6h+vHVyyR1e7Q-CFS8LknMW1j-dC-OyA@mail.gmail.com>
Message-ID: <CAFy6Y8UodA3dCsWB1zr3ZkR-+XtbqckUWQM8pyyeMnxc1CzEyQ@mail.gmail.com>

Yes. That's correct. The main problem is to solve a matrix where the
colSums and rowSums are known. Credits to dwinsemius at comcast.net for
pointing out the function "r2dtable" to me. Just feed it with the
known margins and the number of matrices You want. And Bob is Your
uncle!

Look at the thread "Margins to fill matrix" that I started on the subject.




2014-09-12 13:18 GMT+02:00 Barry Rowlingson <b.rowlingson at lancaster.ac.uk>:
> On Fri, Sep 12, 2014 at 11:25 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
>
>> I can see how you would plot the points going from right to left (the easy
>> way), by plotting the next point on the arc with the least increase in
>> angle from the last point plotted. If this is the way you have worked out, I
>> think all that you have to do is to turn the party affiliation into a factor (if
>> it is not already) and plot the points by the sorted numeric value of the
>> factor. You will probably want to adjust the levels to some political
>> dimensions before doing the sort.
>
>  I'm interested in how you get exactly N seats in M rows that look as
> neat as that. My eyes are going funny trying to count the dots in each
> arc but there must be some nice algorithm for generating a sequence
> that sums to N, has M elements, and has a small variable difference
> between the row sizes to constrain the sum...
>
>  Or am I overthinking this?
>
> Barry


From murdoch.duncan at gmail.com  Fri Sep 12 13:41:43 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 Sep 2014 07:41:43 -0400
Subject: [R] Parliament Seats Graph
In-Reply-To: <CANVKczMg=5Dq0QREBb6h+vHVyyR1e7Q-CFS8LknMW1j-dC-OyA@mail.gmail.com>
References: <CAFy6Y8VGLanmQtn_0p3YuT2FkH45fv4NsdZ=psQE2pD3Kor0Jg@mail.gmail.com>	<c2fba23d1d5140f3a5aab3d6ad94e6af@EX-1-HT0.lancs.local>
	<CANVKczMg=5Dq0QREBb6h+vHVyyR1e7Q-CFS8LknMW1j-dC-OyA@mail.gmail.com>
Message-ID: <5412DBF7.9000001@gmail.com>

On 12/09/2014, 7:18 AM, Barry Rowlingson wrote:> On Fri, Sep 12, 2014 at
11:25 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
>
>> I can see how you would plot the points going from right to left (the
easy
>> way), by plotting the next point on the arc with the least increase in
>> angle from the last point plotted. If this is the way you have worked
out, I
>> think all that you have to do is to turn the party affiliation into a
factor (if
>> it is not already) and plot the points by the sorted numeric value of the
>> factor. You will probably want to adjust the levels to some political
>> dimensions before doing the sort.
>
>  I'm interested in how you get exactly N seats in M rows that look as
> neat as that. My eyes are going funny trying to count the dots in each
> arc but there must be some nice algorithm for generating a sequence
> that sums to N, has M elements, and has a small variable difference
> between the row sizes to constrain the sum...
>
>  Or am I overthinking this?

I would guess it's something like this:

1.  Set the radii of each arc.  Since the spacing of the dots looks
even, the number of dots in each arc should be proportional to the radius.

2.  Using the proportions above find the number of dots in the largest
arc by rounding the proportion times total to an integer.

3.  Repeat for each arc moving inwards, subtracting the number of dots
already shown from the grand total.

The same scheme can be used to set the number of dots of each colour in
each arc.

For example:

radii <- seq(2.5, 1, len=11)
N <- 449
counts <- numeric(11)
plot(c(-2.5, 2.5), c(0, 2.5), type="n", axes=FALSE, asp=1)
for (i in 1:11) {
  counts[i] <- round(N*radii[i]/sum(radii[i:11]))
  theta <- seq(0, pi, len = counts[i])
  points(radii[i]*cos(theta), radii[i]*sin(theta))
  N <- N - counts[i]
}

Duncan Murdoch


From b.rowlingson at lancaster.ac.uk  Fri Sep 12 14:01:57 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Sep 2014 13:01:57 +0100
Subject: [R] Parliament Seats Graph
In-Reply-To: <d0394fbecb75475da10f6634e664cb76@EX-0-HT0.lancs.local>
References: <CAFy6Y8VGLanmQtn_0p3YuT2FkH45fv4NsdZ=psQE2pD3Kor0Jg@mail.gmail.com>
	<c2fba23d1d5140f3a5aab3d6ad94e6af@EX-1-HT0.lancs.local>
	<CANVKczMg=5Dq0QREBb6h+vHVyyR1e7Q-CFS8LknMW1j-dC-OyA@mail.gmail.com>
	<d0394fbecb75475da10f6634e664cb76@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPpefb87sn3peH9OWgfp-_1G5ZFtpv+ML4c7vuzZgo0KA@mail.gmail.com>

I've generalised Duncan's code:

seats <- function(N,M, r0=2.5){
    radii <- seq(r0, 1, len=M)

    counts <- numeric(M)
    pts = do.call(rbind,
            lapply(1:M, function(i){
        counts[i] <<- round(N*radii[i]/sum(radii[i:M]))
        theta <- seq(0, pi, len = counts[i])
        N <<- N - counts[i]
        data.frame(x=radii[i]*cos(theta), y=radii[i]*sin(theta), r=i,
theta=theta)
    }  )
            )
    pts = pts[order(-pts$theta,-pts$r),]
    pts
}


and written this:

election <- function(seats, counts){
    stopifnot(sum(counts)==nrow(seats))
    seats$party = rep(1:length(counts),counts)
    seats
}


sample usage:

> layout = seats(449,16)
> result = election(layout, c(200,200,49)) # no overall majority!!!
> plot(result$x, result$y, col=result$party,pch=19, asp=1)

Looks like a start...


On Fri, Sep 12, 2014 at 12:41 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12/09/2014, 7:18 AM, Barry Rowlingson wrote:> On Fri, Sep 12, 2014 at
> 11:25 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
>>
>>> I can see how you would plot the points going from right to left (the
> easy
>>> way), by plotting the next point on the arc with the least increase in
>>> angle from the last point plotted. If this is the way you have worked
> out, I
>>> think all that you have to do is to turn the party affiliation into a
> factor (if
>>> it is not already) and plot the points by the sorted numeric value of the
>>> factor. You will probably want to adjust the levels to some political
>>> dimensions before doing the sort.
>>
>>  I'm interested in how you get exactly N seats in M rows that look as
>> neat as that. My eyes are going funny trying to count the dots in each
>> arc but there must be some nice algorithm for generating a sequence
>> that sums to N, has M elements, and has a small variable difference
>> between the row sizes to constrain the sum...
>>
>>  Or am I overthinking this?
>
> I would guess it's something like this:
>
> 1.  Set the radii of each arc.  Since the spacing of the dots looks
> even, the number of dots in each arc should be proportional to the radius.
>
> 2.  Using the proportions above find the number of dots in the largest
> arc by rounding the proportion times total to an integer.
>
> 3.  Repeat for each arc moving inwards, subtracting the number of dots
> already shown from the grand total.
>
> The same scheme can be used to set the number of dots of each colour in
> each arc.
>
> For example:
>
> radii <- seq(2.5, 1, len=11)
> N <- 449
> counts <- numeric(11)
> plot(c(-2.5, 2.5), c(0, 2.5), type="n", axes=FALSE, asp=1)
> for (i in 1:11) {
>   counts[i] <- round(N*radii[i]/sum(radii[i:11]))
>   theta <- seq(0, pi, len = counts[i])
>   points(radii[i]*cos(theta), radii[i]*sin(theta))
>   N <- N - counts[i]
> }
>
> Duncan Murdoch
>


From simon.urbanek at r-project.org  Fri Sep 12 15:25:21 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 12 Sep 2014 09:25:21 -0400
Subject: [R] Error with RJDBC when trying dbUnloadDriver()
In-Reply-To: <cde7075e.00000d24.0000000e@FIW7PC12.ELITEMEDIANET>
References: <cde7075e.00000d24.0000000e@FIW7PC12.ELITEMEDIANET>
Message-ID: <BBD87865-D648-442A-B0DD-FCB051C74FDC@r-project.org>

Julian,

On Sep 12, 2014, at 6:03 AM, julian.bothe at elitepartner.de wrote:

> Hello everyone, Hello Simon,
>  
> I am starting to use RJDBC. When trying to unload the driver, I get an Error message ? even when not connecting to any database.
> This issue has been reported before in 2011 (https://stat.ethz.ch/pipermail/r-sig-db/2011q4/001103.html ), and it was said that it?s possibly a bug. But it seems that it?s still there.
>  
> Any hints?

This issue has been never raised with me or the RJDBC issue tracker (it's beyond me why people don't ask the package maintainers).

In principle, it's bug that it returns NULL instead of FALSE (now fixed), but note that dbUnloadDriver() is will always fail with JDBC, because Java has no provision to unload classes. This is legal, since dbUnloadDriver() is declared as optional.

Cheers,
Simon



>  
> -----------
> library("RJDBC")
> Postgres_drv <- JDBC(driverClass = 'org.postgresql.Driver',
>                      classPath= ?PATH/TO/JAR/postgresql-9.3-1102.jdbc4.jar')
> dbUnloadDriver(Postgres_drv)
>  
> #Error in .valueClassTest(standardGeneric("dbUnloadDriver"), "logical",  : 
> #  invalid value from generic function ?dbUnloadDriver?, class ?NULL?, expected ?logical?
> --------------
> All the best
> Julian


From b.rowlingson at lancaster.ac.uk  Fri Sep 12 15:35:46 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Sep 2014 14:35:46 +0100
Subject: [R] Parliament Seats Graph
In-Reply-To: <ef061db7bea54e079b507e12cb859ec7@EX-0-HT0.lancs.local>
References: <CAFy6Y8VGLanmQtn_0p3YuT2FkH45fv4NsdZ=psQE2pD3Kor0Jg@mail.gmail.com>
	<c2fba23d1d5140f3a5aab3d6ad94e6af@EX-1-HT0.lancs.local>
	<CANVKczMg=5Dq0QREBb6h+vHVyyR1e7Q-CFS8LknMW1j-dC-OyA@mail.gmail.com>
	<d0394fbecb75475da10f6634e664cb76@EX-0-HT0.lancs.local>
	<ef061db7bea54e079b507e12cb859ec7@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMssYw_nnX39XRtwTXwruqGgjfSLmLaonvKLqH=4_EZ4w@mail.gmail.com>

Note if you are trying to compare parliament diagrams created with
this code with images from wikipedia, the wikipedia images I tried are
wrong.

The Ukrainian one: http://en.wikipedia.org/wiki/Verkhovna_Rada  shows
two groups in red but the legend only has one red party, and the
French Senate: http://en.wikipedia.org/wiki/French_Parliament has 21
red "Communist" dots but the text says 20. It also has 10 green
("Green") dots but the text says 12.

Maybe wikipedia would like to use this code to generate these diagrams
from the data!





On Fri, Sep 12, 2014 at 1:01 PM, Rowlingson, Barry
<b.rowlingson at lancaster.ac.uk> wrote:
> I've generalised Duncan's code:
>
> seats <- function(N,M, r0=2.5){
>     radii <- seq(r0, 1, len=M)
>
>     counts <- numeric(M)
>     pts = do.call(rbind,
>             lapply(1:M, function(i){
>         counts[i] <<- round(N*radii[i]/sum(radii[i:M]))
>         theta <- seq(0, pi, len = counts[i])
>         N <<- N - counts[i]
>         data.frame(x=radii[i]*cos(theta), y=radii[i]*sin(theta), r=i,
> theta=theta)
>     }  )
>             )
>     pts = pts[order(-pts$theta,-pts$r),]
>     pts
> }
>
>
> and written this:
>
> election <- function(seats, counts){
>     stopifnot(sum(counts)==nrow(seats))
>     seats$party = rep(1:length(counts),counts)
>     seats
> }
>
>
> sample usage:
>
>> layout = seats(449,16)
>> result = election(layout, c(200,200,49)) # no overall majority!!!
>> plot(result$x, result$y, col=result$party,pch=19, asp=1)
>
> Looks like a start...
>
>
> On Fri, Sep 12, 2014 at 12:41 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 12/09/2014, 7:18 AM, Barry Rowlingson wrote:> On Fri, Sep 12, 2014 at
>> 11:25 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
>>>
>>>> I can see how you would plot the points going from right to left (the
>> easy
>>>> way), by plotting the next point on the arc with the least increase in
>>>> angle from the last point plotted. If this is the way you have worked
>> out, I
>>>> think all that you have to do is to turn the party affiliation into a
>> factor (if
>>>> it is not already) and plot the points by the sorted numeric value of the
>>>> factor. You will probably want to adjust the levels to some political
>>>> dimensions before doing the sort.
>>>
>>>  I'm interested in how you get exactly N seats in M rows that look as
>>> neat as that. My eyes are going funny trying to count the dots in each
>>> arc but there must be some nice algorithm for generating a sequence
>>> that sums to N, has M elements, and has a small variable difference
>>> between the row sizes to constrain the sum...
>>>
>>>  Or am I overthinking this?
>>
>> I would guess it's something like this:
>>
>> 1.  Set the radii of each arc.  Since the spacing of the dots looks
>> even, the number of dots in each arc should be proportional to the radius.
>>
>> 2.  Using the proportions above find the number of dots in the largest
>> arc by rounding the proportion times total to an integer.
>>
>> 3.  Repeat for each arc moving inwards, subtracting the number of dots
>> already shown from the grand total.
>>
>> The same scheme can be used to set the number of dots of each colour in
>> each arc.
>>
>> For example:
>>
>> radii <- seq(2.5, 1, len=11)
>> N <- 449
>> counts <- numeric(11)
>> plot(c(-2.5, 2.5), c(0, 2.5), type="n", axes=FALSE, asp=1)
>> for (i in 1:11) {
>>   counts[i] <- round(N*radii[i]/sum(radii[i:11]))
>>   theta <- seq(0, pi, len = counts[i])
>>   points(radii[i]*cos(theta), radii[i]*sin(theta))
>>   N <- N - counts[i]
>> }
>>
>> Duncan Murdoch
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Sep 12 16:17:59 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 12 Sep 2014 14:17:59 +0000
Subject: [R] mice - undefined columns selected
In-Reply-To: <CAMtGSx=PPtwcYGhRK_rijx8te1S53dQ5Bk9-Kk9sn-W+N2w4Lw@mail.gmail.com>
References: <CAMtGSx=PPtwcYGhRK_rijx8te1S53dQ5Bk9-Kk9sn-W+N2w4Lw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F97261@mb02.ads.tamu.edu>

I'm copying the package maintainer who can probably give a more definite answer. I'm getting the same error on your data. I can get a subset of your data to run, eg:

d.imp <- mice(d[,c(1:2, 5:6)]) works, but
d.imp <- mice(d[,c(3:4, 7:8)]) fails. 

That suggests to me that the problem is with your data. There are some very high correlations between variables. Looking at pairwise complete observations, C1 has correlations of .998, .999, and .998 with C2, C3, and C4 while M1 has correlations of .999, .999, and .999 with M2, M3, and M4. The correlations between the C variables and the M variables are also high (consistently greater than .80). You really have only two variables C and M. This is probably the reason function mice() is failing, but the error message could be more informative. Since you are only imputing single values, you might be better off with simpler imputation methods. Package VIM has a number of options of which nearest neighbor and hot deck might work well with your data.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jeremy Miles
Sent: Thursday, September 11, 2014 7:49 PM
To: r-help
Subject: [R] mice - undefined columns selected

I've got a problem with the mice package that I don't understand.

Here's the code:
library(mice)
d <- read.csv("https://dl.dropboxusercontent.com/u/24381951/employment.csv",
 as.is=TRUE, row.names=1)d.imp <- mice(data=d, m=1)

Result is:
Error in `[.data.frame`(data, , jj) : undefined columns selected

I hope I'm doing something foolish,

thanks,

Jeremy

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Leif at Ruckman.se  Fri Sep 12 11:26:46 2014
From: Leif at Ruckman.se (Leif Ruckman)
Date: Fri, 12 Sep 2014 11:26:46 +0200
Subject: [R] 8 fast or 4 very fast cores?
Message-ID: <5412BC56.6060203@Ruckman.se>

I am going to buy a new computer ( Dell workstation T5810 - Windows 8) 
to work with simulatons in R.

Now I am asked what kind of processor I like and I was given two choices.

1. Intel Xeon E5-1620 v3 - 4 cores 3.7 GHz Turbo
2. Intel Xeon E5-2640 v3 - 8 cores 2.6 GHz Turbo

I don't know what is better in simulations studies in R, a few very fast 
cores or many cores at normal speed.

Can you please give me help about this?

Warm regards

Leif Ruckman


From stef.vanbuuren at tno.nl  Fri Sep 12 16:24:23 2014
From: stef.vanbuuren at tno.nl (Buuren, S. (Stef) van)
Date: Fri, 12 Sep 2014 14:24:23 +0000
Subject: [R] mice - undefined columns selected
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F97261@mb02.ads.tamu.edu>
References: <CAMtGSx=PPtwcYGhRK_rijx8te1S53dQ5Bk9-Kk9sn-W+N2w4Lw@mail.gmail.com>,
	<53BF8FB63FAF2E4A9455EF1EE94DA726F97261@mb02.ads.tamu.edu>
Message-ID: <D40AD595-1C34-4DCD-9897-FAFAEC2CE12E@tno.nl>

Dear David, mice eliminates variables that are linearly dependent. Type 
> imp$log
To see which are removed, and why.

 You have three options:
1 forget about those remove variables since they don't carry additional information
2 don't use them as predictors, and they will be imputed (although not preserving linear relations)
3 use passive imputation to impute them

I cannot see which one is best for you, but you have a choice.

Hope this helps. Stef.

Verstuurd vanaf mijn iPad

> Op 12 sep. 2014 om 16:18 heeft "David L Carlson" <dcarlson at tamu.edu> het volgende geschreven:
> 
> I'm copying the package maintainer who can probably give a more definite answer. I'm getting the same error on your data. I can get a subset of your data to run, eg:
> 
> d.imp <- mice(d[,c(1:2, 5:6)]) works, but
> d.imp <- mice(d[,c(3:4, 7:8)]) fails. 
> 
> That suggests to me that the problem is with your data. There are some very high correlations between variables. Looking at pairwise complete observations, C1 has correlations of .998, .999, and .998 with C2, C3, and C4 while M1 has correlations of .999, .999, and .999 with M2, M3, and M4. The correlations between the C variables and the M variables are also high (consistently greater than .80). You really have only two variables C and M. This is probably the reason function mice() is failing, but the error message could be more informative. Since you are only imputing single values, you might be better off with simpler imputation methods. Package VIM has a number of options of which nearest neighbor and hot deck might work well with your data.
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jeremy Miles
> Sent: Thursday, September 11, 2014 7:49 PM
> To: r-help
> Subject: [R] mice - undefined columns selected
> 
> I've got a problem with the mice package that I don't understand.
> 
> Here's the code:
> library(mice)
> d <- read.csv("https://dl.dropboxusercontent.com/u/24381951/employment.csv",
> as.is=TRUE, row.names=1)d.imp <- mice(data=d, m=1)
> 
> Result is:
> Error in `[.data.frame`(data, , jj) : undefined columns selected
> 
> I hope I'm doing something foolish,
> 
> thanks,
> 
> Jeremy
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Dit bericht kan informatie bevatten die niet voor u is bestemd. Indien u niet de geadresseerde bent of dit bericht abusievelijk aan u is toegezonden, wordt u verzocht dat aan de afzender te melden en het bericht te verwijderen. TNO aanvaardt geen aansprakelijkheid voor de inhoud van deze e-mail, de wijze waarop u deze gebruikt en voor schade, van welke aard ook, die verband houdt met risico's verbonden aan het elektronisch verzenden van berichten.

 

This message may contain information that is not intended for you. If you are not the addressee or if this message was sent to you by mistake, you are requested to inform the sender and delete the message. TNO accepts no liability for the content of this e-mail, for the manner in which you use it and for damage of any kind resulting from the risks inherent to the electronic transmission of messages.


From kw.stat at gmail.com  Fri Sep 12 20:06:24 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 12 Sep 2014 13:06:24 -0500
Subject: [R] How to test for open pdf file on Windows before calling
 cairo_pdf ?
In-Reply-To: <CAFDcVCS1r3bRn4p-dK+QaTxSdiOQ6YZwUuiZmQirh3LajP5aGg@mail.gmail.com>
References: <CAKFxdiS6EmYjkgTKDG_LJEykpu+AoAHHpw6T5qbTe2MpZ-FWYQ@mail.gmail.com>
	<CAFDcVCS1r3bRn4p-dK+QaTxSdiOQ6YZwUuiZmQirh3LajP5aGg@mail.gmail.com>
Message-ID: <CAKFxdiQqGkyQYDWWH1WdwEgpOCGt25x6OBiO0diwVWL9kZDsMQ@mail.gmail.com>

What I finally ended up doing was using the file() command to see if I
could open a writeable connection to a pdf, then closing the connection
before opening the file with cairo_pdf.

However, my whole effort may be pointless.  The cairo_pdf() device is
crashing R on Windows so often as to be mostly useless.

Kevin


On Thu, Sep 11, 2014 at 3:56 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
wrote:

> A poor mans solution would be to try to temporarily delete or move the
> file, depending exactly what you wish to do. You can also try:
>
> library("R.utils")
> pathname <- Arguments$getWritablePathname("file2.pdf", mustNotExist=FALSE)
>
> which does lots of assertions of write permissions of new and existing
> file, in the target directory etc. and tries to give an informative
> error if it fails.  However, it does not have a particular
> test/message for "locked" PDF files.  This is the error message I get
> when I view a PDF in Adobe Reader on Windows:
>
> > pathname <- Arguments$getWritablePathname("file2.pdf",
> mustNotExist=FALSE)
> [2014-09-11 13:42:14] Exception: No permission to modify existing file:
> file2.pd
> f
>
>   at #03. getWritablePathname.Arguments(static, ...)
>           - getWritablePathname.Arguments() is in environment 'R.utils'
>
>   at #02. getWritablePathname(static, ...)
>           - getWritablePathname() is in environment 'R.utils'
>           - originating from '<text>'
>
>   at #01. Arguments$getWritablePathname("file2.pdf", mustNotExist = FALSE)
>           - Arguments$getWritablePathname() is local of the calling
> function
>
> Error: No permission to modify existing file: file2.pdf
> In addition: Warning message:
> In fileAccess.default(pathname, mode = 2) :
>   file.access(..., mode=2) and file(..., open="ab") gives different
> results (0 != -1). Will use the file() results: file2.pdf
>
>
> Note that it is not all PDF viewers that lock/prevent files from being
> overwritten.  For instance, when I view the same file using Foxit
> Reader, I don't get an error, e.g.
>
> library("R.utils")
> pathname <- Arguments$getWritablePathname("file2.pdf", mustNotExist=FALSE)
> pdf(pathname)
> plot(1:10)
> dev.off()
>
>
> Better yet, just use the R.devices package
> [http://cran.r-project.org/web/packages/R.devices/index.html] and
> it'll all be take care of for you:
>
> library("R.devices")
> devEval("png", name="file1", {
>   plot(1:10)
> })
>
> library("R.devices")
> devEval("cairo_pdf", name="file2", {
>   plot(1:10)
> }, ext="pdf")
>
> You'll get the above error message if, say, Adobe Reader is preventing
> the file from being overwritten.  This approach will make sure to
> close any opened graphics devices, not to leave incomplete image files
> behind if there is an errors and so on.  There are plenty of option
> for it, e.g. the default output directory is "./figures/", which can
> be changed.  (The need for argument ext="pdf" is due to a minor bug
> that will be fixed in the next release.)
>
>
> Hope this helps,
>
> Henrik
> (author of R.utils and R.devices)
>
> On Thu, Sep 11, 2014 at 1:06 PM, Kevin Wright <kw.stat at gmail.com> wrote:
> > On Windows:
> >
> > The pdf("file1.pdf") command will throw an error if the file1.pdf is open
> > in a viewer.  For example:
> >
> > pdf("file1.pdf")
> > plot(1:10)
> > dev.off()
> > shell.exec("file1.pdf")
> > pdf("file1.pdf") # Causes an error
> >
> > As suggested by the help page for file.access(), I normally use
> > try(pdf("file1.pdf")) to test if file1.pdf is open.
> >
> > Oddly, I cannot do the same using cairo_pdf.  For example:
> >
> > cairo_pdf("file2.pdf")
> > plot(1:10)
> > dev.off()
> > shell.exec("file2.pdf")
> > cairo_pdf("file2.pdf") # No error
> >
> > It is not until a plotting command is called that an error is generated.
> >
> > Is there a way to test if a pdf file can be written to by cairo_pdf ?
> >
> > I'd rather not wrap all plotting commands with try()....I have many such
> > commands in my script and the choice of which one is first depends on
> user
> > input.
> >
> > Kevin Wright
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Fri Sep 12 20:12:12 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 12 Sep 2014 13:12:12 -0500
Subject: [R] cairo_pdf crashing R on Windows
Message-ID: <CAKFxdiSABCobUxar=Fx7C5yix=LfXv6gVcKwbApyd1Cxo239kA@mail.gmail.com>

I'm having trouble with cairo_pdf crashing R on Windows.

How can I debug this?  This is a "exited abnormally" type crash, so I can't
drop into the browser and look at the call stack.

Kevin


-- 
Kevin Wright

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Fri Sep 12 20:28:09 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 12 Sep 2014 11:28:09 -0700
Subject: [R] cairo_pdf crashing R on Windows
In-Reply-To: <CAKFxdiSABCobUxar=Fx7C5yix=LfXv6gVcKwbApyd1Cxo239kA@mail.gmail.com>
References: <CAKFxdiSABCobUxar=Fx7C5yix=LfXv6gVcKwbApyd1Cxo239kA@mail.gmail.com>
Message-ID: <CAFDcVCS+F9fMi6QJpBet2Pzr7QdvwdiTb=HcDptoksEW_DtBNw@mail.gmail.com>

First try a newer version of R, e.g. most recent patched and/or devel
version.  If that doesn't help, record sessionInfo() before calling
cairo_pdf() and before the crash. Try to find a minimal example and a
minimal figure for which you can reproduce this on your setup.  If it
only occurs occasional still try to identify an example where it
happens if you call it, say 100 times.  When you've done that share
you experience here for others to try to reproduce it.

/Henrik
(not using cairo_pdf() on a regular basis so haven't had any problems)

On Fri, Sep 12, 2014 at 11:12 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> I'm having trouble with cairo_pdf crashing R on Windows.
>
> How can I debug this?  This is a "exited abnormally" type crash, so I can't
> drop into the browser and look at the call stack.
>
> Kevin
>
>
> --
> Kevin Wright
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Sep 12 20:43:52 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 Sep 2014 14:43:52 -0400
Subject: [R] cairo_pdf crashing R on Windows
In-Reply-To: <CAKFxdiSABCobUxar=Fx7C5yix=LfXv6gVcKwbApyd1Cxo239kA@mail.gmail.com>
References: <CAKFxdiSABCobUxar=Fx7C5yix=LfXv6gVcKwbApyd1Cxo239kA@mail.gmail.com>
Message-ID: <54133EE8.4070800@gmail.com>

On 12/09/2014 2:12 PM, Kevin Wright wrote:
> I'm having trouble with cairo_pdf crashing R on Windows.
>
> How can I debug this?  This is a "exited abnormally" type crash, so I can't
> drop into the browser and look at the call stack.

This is getting into R-devel territory, but if Henrik's suggestions 
aren't enough, here are some more:

1.  Make the crash reproducible, and the trigger code as simple as 
possible.  If you can succeed in this and submit a bug report on 
bugs.r-project.org and someone in R Core can use your code to trigger a 
crash, that alone will be very helpful.

2.  Run under a debugger.  gdb is available for Windows, although it's 
not the easiest debugger in the world to use.  It's a lot easier if you 
can do a build of R with debugging information (not the default in 
Windows).  You do this by setting the environment variable DEBUG to T, 
and rebuilding R.  If you're lucky, gdb will identify which source line 
triggered the crash, and that might be enough (if you examine the source 
code carefully) to find the cause.

You might want to trigger the bug on a different platform; generally the 
debugging tools that work with R work better on Unix-alikes than on Windows.

3.  At this point you're rebuilding R, so if gdb wasn't enough to tell 
you what's going on, start sticking Rprintf() calls into the R source to 
see if you can find where things start to go wrong.  It's slow work, 
because you'll do a lot of rebuilds until you track down the bug.

I hope that helps.  Remember, even completing step 1 will be very 
helpful for others.  Actually tracking down and fixing the bug would be 
wonderful.

Duncan Murdoch


From aeswx at uga.edu  Sat Sep 13 15:59:11 2014
From: aeswx at uga.edu (Alan E. Stewart)
Date: Sat, 13 Sep 2014 09:59:11 -0400
Subject: [R] kripp.alpha - Getting Data into It
Message-ID: <54144DAF.1080006@uga.edu>

I have used read.csv put three columns (of raters) who rated 188 things 
(rows) into the object PublicKnow

After loading irr and calling kripp.alpha(PublicKnow), I get what I see 
on searching is the common error:

Error in sort.list(y) : 'x' must be atomic for 'sort.list'
Have you called 'sort' on a list?

The example in kripp.alpha shows the use of this application by entering 
data from the console in matrix format.

I tried turning PublicKnow into a matrix:

pknowmat=matrix(PublicKnow).

Still, no success, but the same error.  kripp.alpha is wanting something 
"sliced/diced" in a way that I do not know how to create/make.

What kinds of manipulations must I do on my data, as it was read in, so 
that kripp.alpha will work?

Thanks...Al


	[[alternative HTML version deleted]]


From fabian.krueger83 at gmail.com  Fri Sep 12 10:15:34 2014
From: fabian.krueger83 at gmail.com (Krueger, Fabian)
Date: Fri, 12 Sep 2014 10:15:34 +0200
Subject: [R] [R-pkgs] New R package ``bvarsv''
Message-ID: <5412ABA6.5080808@gmail.com>

Dear R users,

please let me draw your attention to my new R package bvarsv (on CRAN 
since August 28) which implements the Primiceri (Review of Economic 
Studies, 2005) vector autoregressive model. The model is popular in 
macroeconomic analysis as it allows to model instabilities (e.g. in the 
mean and volatility dynamics) that are often observed in macroeconomic 
time series like inflation.

The package provides functionality for Bayesian analysis of the 
Primiceri model. To the best of my knowledge, it is the only publicly 
available R code to do so. The underlying Markov Chain Monte Carlo 
algorithm is computationally challenging, since each iteration requires 
multiple calls of a recursive Kalman filter type algorithm. Therefore, 
bvarsv relies on C++ code ported to R via Rcpp and RcppArmadillo. The 
clear focus of the package is on forecasting, as opposed to structural 
analysis of economic relationships. The package allows to compute 
posterior predictive distributions, which can then be plotted and 
analyzed using forecast evaluation techniques. More detailed 
documentation and examples is available here:

https://sites.google.com/site/fk83research/code

Your feedback on any aspects of the package, as well as possible 
improvements or extensions, would be highly appreciated.

Thank you and best wishes,
Fabian Kr?ger

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bonsxanco at yahoo.com  Sat Sep 13 17:03:45 2014
From: bonsxanco at yahoo.com (bonsxanco)
Date: Sat, 13 Sep 2014 08:03:45 -0700
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <94EA0576-7548-494F-982D-961BA52F97D3@gmail.com>
References: <loom.20140906T040650-156@post.gmane.org>	<CACk-te3q2VwkbnSh5+J4BzXr7f4LWv6TuKtUBjK30JePdeT7Gg@mail.gmail.com>
	<CAE3=dmd_W5n=kCi2fdPUqst1xaF726ZqLC75KNW-PCq-xQKu9w@mail.gmail.com>
	<1409999043.70851.YahooMailNeo@web120102.mail.ne1.yahoo.com>
	<94EA0576-7548-494F-982D-961BA52F97D3@gmail.com>
Message-ID: <1410620625.92477.YahooMailNeo@web120105.mail.ne1.yahoo.com>

On Sunday, September 7, 2014 5:47 PM, peter dalgaard <pdalgd at gmail.com> wrote: 
> On 06 Sep 2014, at 12:24 , bonsxanco <bonsxanco at yahoo.com> wrote: 
> 
> >> 
> >> 1) 8th grade algebra tells me B2/B1 == 0 <==> B2 =0; 
> > 
> > EViews (econometrics program) doesn't have the same opinion: 
> > 
> > Wald test on my real model (edited): 
> > 
> > * H0: B3/B2 = 0 -> F-stat = 37.82497 
> > * H0: B3 = 0    -> F-stat = 16.31689 
> 
> 
> And when the econometrics program contradicts what you learned in 8th grade, 
> surely the latter is wrong and the former is right, because it is done by a 
> computer and computers cannot be wrong? ;-) 
I simply thought that there was a "standard" way to do this: EViews and Stata 
both give the exact same F statistic for my original problem. Given that these 
programs were not developed by the same author (AFAIK), there is some specific 
way to reformulate the restriction which make EViews and Stata give the same 
answer.


From bonsxanco at yahoo.com  Sat Sep 13 17:11:05 2014
From: bonsxanco at yahoo.com (bonsxanco)
Date: Sat, 13 Sep 2014 08:11:05 -0700
Subject: [R] Testing general hypotheses on regression coefficients
In-Reply-To: <CAFEqCdza_8p+ksPHx=K+QULBDqty_b4U23G_aeVVUspCUwgryw@mail.gmail.com>
References: <loom.20140906T040650-156@post.gmane.org>
	<CAFEqCdza_8p+ksPHx=K+QULBDqty_b4U23G_aeVVUspCUwgryw@mail.gmail.com>
Message-ID: <1410621065.61451.YahooMailNeo@web120104.mail.ne1.yahoo.com>

On Monday, September 8, 2014 6:46 PM, Greg Snow <538280 at gmail.com> wrote:

> [very good suggestions]



Thank you Greg for dedicating some time to my problem and giving
advice on how I can tackle the issue. It is very appreciated.
Unfortunately I think I will use another program for my original
problem. Anyway, I'll go through all your suggestions, time
permitting.

Best,

Chris


From ligges at statistik.tu-dortmund.de  Sat Sep 13 19:39:18 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 13 Sep 2014 19:39:18 +0200
Subject: [R] weird install package error
In-Reply-To: <CAMY509kBrnvLb-nij4uhx30KiNUuOg_XwFvGfHbmfYXU=PM0RA@mail.gmail.com>
References: <CAMY509kBrnvLb-nij4uhx30KiNUuOg_XwFvGfHbmfYXU=PM0RA@mail.gmail.com>
Message-ID: <54148146.3030400@statistik.tu-dortmund.de>



On 11.09.2014 22:42, Yuan Luo wrote:
> Hi,
>
> I am getting an error installing the MASS package. Googling suggests
> restarting R, but it didn't help. Anyone has a clue?

Recompile R. Looks like you mkl enabled (?) build of R is broken.

Best,
Uwe Ligges



>
> Many thanks,
> Yuan
>
>
>> install.packages("MASS")
> Installing package into ?/PHShome/yl960/R/3.0?
> (as ?lib? is unspecified)
> trying URL 'http://lib.stat.cmu.edu/R/CRAN/src/contrib/MASS_7.3-34.tar.gz'
> Content type 'application/x-gzip' length 486552 bytes (475 Kb)
> opened URL
> ==================================================
> downloaded 475 Kb
>
> * installing *source* package ?MASS? ...
> ** package ?MASS? successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/source/R-3.0.2-mkl/lib64/R/include -DNDEBUG
>   -I/usr/local/include    -fpic  -g -O2  -c MASS.c -o MASS.o
> gcc -std=gnu99 -I/source/R-3.0.2-mkl/lib64/R/include -DNDEBUG
>   -I/usr/local/include    -fpic  -g -O2  -c lqs.c -o lqs.o
> gcc -std=gnu99 -shared -L/usr/local/lib64 -o MASS.so MASS.o lqs.o
> -L/source/R-3.0.2-mkl/lib64/R/lib -lR
> installing to /PHShome/yl960/R/3.0/MASS/libs
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** inst
> ** byte-compile and prepare package for lazy loading
> Warning in get(hookname, envir = env, inherits = FALSE) :
>    internal error -3 in R_decompress1
> Error in get(hookname, envir = env, inherits = FALSE) :
>    lazy-load database 'P' is corrupt
> * removing ?/PHShome/yl960/R/3.0/MASS?
>
> The downloaded source packages are in
> ?/tmp/RtmpJpFCbC/downloaded_packages?
> Warning message:
> In install.packages("MASS") :
>    installation of package ?MASS? had non-zero exit status
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From radhakrishnan.mohan at gmail.com  Sat Sep 13 21:53:20 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Sun, 14 Sep 2014 01:23:20 +0530
Subject: [R] ggplot y-axis labels are not continuous
Message-ID: <CAOoXFP-WNxNaQGLTu1niJgccODgcR6pNaLD80oWsG=Y+_5geDA@mail.gmail.com>

Hi,

This is the code to create a ggplot. The plot is rendered but the y-axis
labels are not continuous. So the lines are split.

Moreover multiple y-axis labels overwrite each other due to this. How can I
fix this?

If I try to set ylim I get "

*Discrete value supplied to continuous scale"*

library(RJSONIO)
library(ggplot2)
this.dir <- dirname(parent.frame(2)$ofile)
setwd(this.dir)

airlines   = fromJSON("json")
df <- sapply(airlines$data,unlist)
df <- data.frame(t(df))
colnames(df) <- c( (airlines[[1]][[1]])[[2]],
gsub("[^A-Z]","",(airlines[[1]][[2]])[[2]]),
gsub("[^A-Z]","",(airlines[[1]][[3]])[[2]] ),
gsub("[^A-Z]","",(airlines[[1]][[4]])[[2]]), (airlines[[1]][[5]])[[2]],
(airlines[[1]][[6]])[[2]], (airlines[[1]][[7]])[[2]],
(airlines[[1]][[8]])[[2]],
(airlines[[1]][[9]])[[2]],(airlines[[1]][[10]])[[2]] )

df.melted <- melt(df, id = "YEAR")
print(ggplot(data = df.melted, aes(x = YEAR, y = value, color = variable))
+geom_point() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
ylab(""))
dev.off()


> head(df)

     YEAR INTERNATIONALACMINNOS DOMESTICACMINNOS TOTALACMINNOS

1 1995-96                 92515           314727        407242

2 1996-97                 94884           324462        419346

3 1997-98                 98226           317531        415757

4 1998-99                 99563           325392        424955

5 1999-00                 99701           368015        467716

6 2000-01                103211           386575        489786

  INTERNATIONAL PAX (IN NOS) DOMESTIC PAX (IN NOS) TOTAL PAX (IN NOS)

1                   11449756              25563998           37013754

2                   12223660              24276108           36499768

3                   12782769              23848833           36631602

4                   12916788              24072631           36989419

5                   13293027              25741521           39034548

6                   14009052              28017568           42026620

  INTERNATIONAL FREIGHT (IN MT) DOMESTIC FREIGHT (IN MT) TOTAL FREIGHT (IN
MT)

1                        452853                   196516
649369

2                        479088                   202122
681210

3                        488175                   217405
705580

4                        474660                   224490
699150

5                        531844                   265570
797414

6                        557772                   288373
846145


Thanks,

Mohan

	[[alternative HTML version deleted]]


From juliosergio at gmail.com  Sun Sep 14 02:55:00 2014
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Sun, 14 Sep 2014 00:55:00 +0000
Subject: [R] legend with math (greek letters) symbols
Message-ID: <loom.20140914T023349-525@post.gmane.org>

I need to add a legend with three entries that should
contain a greek letter (lambda). I learnt that it is
possible using the function expression. So I need to
build the expressions from the lambdas vector, and I
simply cannot do it. This is the uggly result I got:


   x <- 0:20
   cc <- c("yellow", "springgreen", "navyblue")
   lambdas <- c(6, 10, 13)
   ds <- as.data.frame(lapply(lambdas, function(ll) dpois(x, ll)))
   names(ds) <- lambdas
   funcs <- list(plot, lines)

   for (i in 1:3) {
       ff <- funcs[[1+(i!=1)]]
       ff(x,ds[[i]], type="o", pch=21,bg=cc[i])
   }
   
   # I can't build the expressions:
   q <- list(expression(lambda==6), expression(lambda==10),   
             expression(lambda==13))
  
   legend("topright", 
          legend=q,
          lty=1, pch=21, pt.bg=cc)

legend() doesn't interpret the expressions and then it doesn't show
the lambda symbol.

Do you have any comments on this?

Thanks,

  -Sergio.


From dwinsemius at comcast.net  Sun Sep 14 06:04:17 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 13 Sep 2014 21:04:17 -0700
Subject: [R] legend with math (greek letters) symbols
In-Reply-To: <loom.20140914T023349-525@post.gmane.org>
References: <loom.20140914T023349-525@post.gmane.org>
Message-ID: <A5DD189D-E4D1-4A61-8F02-E21D6BBBFCC3@comcast.net>


On Sep 13, 2014, at 5:55 PM, Julio Sergio Santana wrote:

> I need to add a legend with three entries that should
> contain a greek letter (lambda). I learnt that it is
> possible using the function expression. So I need to
> build the expressions from the lambdas vector, and I
> simply cannot do it. This is the uggly result I got:
>
>
>  x <- 0:20
>  cc <- c("yellow", "springgreen", "navyblue")
>  lambdas <- c(6, 10, 13)
>  ds <- as.data.frame(lapply(lambdas, function(ll) dpois(x, ll)))
>  names(ds) <- lambdas
>  funcs <- list(plot, lines)
>
>  for (i in 1:3) {
>      ff <- funcs[[1+(i!=1)]]
>      ff(x,ds[[i]], type="o", pch=21,bg=cc[i])
>  }
>
>  # I can't build the expressions:
>  q <- list(expression(lambda==6), expression(lambda==10),
>            expression(lambda==13))
>
>  legend("topright",
>         legend=q,
>         lty=1, pch=21, pt.bg=cc)

q <- expression(lambda==6, lambda==10 ,lambda==13)
  legend("topright",
          legend=q,
          lty=1, pch=21, pt.bg=cc)

-- 
David.

>
> legend() doesn't interpret the expressions and then it doesn't show
> the lambda symbol.
>
> Do you have any comments on this?
>
> Thanks,
>
> -Sergio.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From radhakrishnan.mohan at gmail.com  Sun Sep 14 10:15:30 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Sun, 14 Sep 2014 13:45:30 +0530
Subject: [R] ggplot y-axis labels are not continuous
In-Reply-To: <CADv2QyHKKKm9qGBGnsZWEt3A=eB_aZWySQyXHGvUdtQBa6feqA@mail.gmail.com>
References: <CAOoXFP-WNxNaQGLTu1niJgccODgcR6pNaLD80oWsG=Y+_5geDA@mail.gmail.com>
	<CADv2QyHKKKm9qGBGnsZWEt3A=eB_aZWySQyXHGvUdtQBa6feqA@mail.gmail.com>
Message-ID: <CAOoXFP-3RyqOQQoQ78k-N-ii7iR6oAikKNA13mqX_t2gD2dA8Q@mail.gmail.com>

Thanks Dennis.

df.melted$value<-as.numeric(df.melted$value)
df.melted$value <- format(df.melted$value, scientific = FALSE)


Mohan

On Sun, Sep 14, 2014 at 9:22 AM, Dennis Murphy <djmuser at gmail.com> wrote:

> Hi:
>
> Try
>
> str(df.melted)
>
> I'm guessing value is a factor. It needs to be numeric or integer.
>
> Dennis
>
>
> On Sat, Sep 13, 2014 at 12:53 PM, Mohan Radhakrishnan
> <radhakrishnan.mohan at gmail.com> wrote:
> > Hi,
> >
> > This is the code to create a ggplot. The plot is rendered but the y-axis
> > labels are not continuous. So the lines are split.
> >
> > Moreover multiple y-axis labels overwrite each other due to this. How
> can I
> > fix this?
> >
> > If I try to set ylim I get "
> >
> > *Discrete value supplied to continuous scale"*
> >
> > library(RJSONIO)
> > library(ggplot2)
> > this.dir <- dirname(parent.frame(2)$ofile)
> > setwd(this.dir)
> >
> > airlines   = fromJSON("json")
> > df <- sapply(airlines$data,unlist)
> > df <- data.frame(t(df))
> > colnames(df) <- c( (airlines[[1]][[1]])[[2]],
> > gsub("[^A-Z]","",(airlines[[1]][[2]])[[2]]),
> > gsub("[^A-Z]","",(airlines[[1]][[3]])[[2]] ),
> > gsub("[^A-Z]","",(airlines[[1]][[4]])[[2]]), (airlines[[1]][[5]])[[2]],
> > (airlines[[1]][[6]])[[2]], (airlines[[1]][[7]])[[2]],
> > (airlines[[1]][[8]])[[2]],
> > (airlines[[1]][[9]])[[2]],(airlines[[1]][[10]])[[2]] )
> >
> > df.melted <- melt(df, id = "YEAR")
> > print(ggplot(data = df.melted, aes(x = YEAR, y = value, color =
> variable))
> > +geom_point() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
> +
> > ylab(""))
> > dev.off()
> >
> >
> >> head(df)
> >
> >      YEAR INTERNATIONALACMINNOS DOMESTICACMINNOS TOTALACMINNOS
> >
> > 1 1995-96                 92515           314727        407242
> >
> > 2 1996-97                 94884           324462        419346
> >
> > 3 1997-98                 98226           317531        415757
> >
> > 4 1998-99                 99563           325392        424955
> >
> > 5 1999-00                 99701           368015        467716
> >
> > 6 2000-01                103211           386575        489786
> >
> >   INTERNATIONAL PAX (IN NOS) DOMESTIC PAX (IN NOS) TOTAL PAX (IN NOS)
> >
> > 1                   11449756              25563998           37013754
> >
> > 2                   12223660              24276108           36499768
> >
> > 3                   12782769              23848833           36631602
> >
> > 4                   12916788              24072631           36989419
> >
> > 5                   13293027              25741521           39034548
> >
> > 6                   14009052              28017568           42026620
> >
> >   INTERNATIONAL FREIGHT (IN MT) DOMESTIC FREIGHT (IN MT) TOTAL FREIGHT
> (IN
> > MT)
> >
> > 1                        452853                   196516
> > 649369
> >
> > 2                        479088                   202122
> > 681210
> >
> > 3                        488175                   217405
> > 705580
> >
> > 4                        474660                   224490
> > 699150
> >
> > 5                        531844                   265570
> > 797414
> >
> > 6                        557772                   288373
> > 846145
> >
> >
> > Thanks,
> >
> > Mohan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Sun Sep 14 15:56:34 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Sun, 14 Sep 2014 16:56:34 +0300
Subject: [R] simulation data in SEM
Message-ID: <CABLo8nEvKCsY=TW0r-33+rd1aPJf-0H-bPL6DcnwMRiBZ5UyrA@mail.gmail.com>

Dear R members
I want to simulate data depending on SEM and when i applied the code below
i found some errors and i still cannot run it.
many thanks in advance


Thanoon

#Do simulation for 100 replications
N<-1000; P<-10

phi<-matrix(data=c(1.0,0.3,0.3,1.0),ncol=2) #The covariance matrix of xi
Ro<-matrix(data=c(7.0,2.1,2.1,7.0), ncol=2)
yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)

for (t in 1:100) {
    #Generate the data for the simulation study
    for (i in 1:N) {
        #Generate xi
        xi<-mvrnorm(1,mu=c(0,0),phi)
        #Generate the fixed covariates
        co<-rnorm(1,0,1)
        #Generate error term is structural equation
        delta<-rnorm(1,0,sqrt(0.3))
        #Generate eta1 according to the structural equation
        eta<-0.8*co[i]+0.6*xi[1]+0.6*xi[2]+0.8*xi[1]*xi[2]+delta
        #Generate error terms in measurement equations
        eps<-rnorm(3,0,1)

        #Generate theta according to measurement equations
        v1[1]<-1.0+eta+eps[1]; v1[2]<-1.0+0.7*eta+eps[2]
        v1[3]<-1.0+0.7*eta+eps[3]
        v1[4]<-1.0+xi[1]; v1[5]<-1.0+0.8*xi[1]; v1[6]<-1.0+0.8*xi[1]
        v1[7]<-1.0+xi[2]; v1[8]<-1.0+0.7*xi[2]; v1[9]<-1.0+0.7*xi[2];
        v1[10]<-1.0+0.7*xi1[2]


        #transform theta to orinal variables
        for (j in 1:10) { if (v[j]>0) yo[i,j]<-1 else yo[i,j]<-0 }


    #Input data set for WinBUGS
    data<-list(N=200,P=10,R=Ro,z=yo)

}   #end

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Sep 14 16:49:21 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 14 Sep 2014 07:49:21 -0700
Subject: [R] legend with math (greek letters) symbols
In-Reply-To: <loom.20140914T023349-525@post.gmane.org>
References: <loom.20140914T023349-525@post.gmane.org>
Message-ID: <CAF8bMcZ6vVZPH6q0Oq6REJT8L+aue5APFjh2UKnzQyLnEMt7VQ@mail.gmail.com>

'q' should be an expression object, not a list of expression objects.
Try defining 'q' as
    q <- as.expression(lapply(lambdas, function(l)bquote(lambda==.(l))))

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Sep 13, 2014 at 5:55 PM, Julio Sergio Santana
<juliosergio at gmail.com> wrote:
> I need to add a legend with three entries that should
> contain a greek letter (lambda). I learnt that it is
> possible using the function expression. So I need to
> build the expressions from the lambdas vector, and I
> simply cannot do it. This is the uggly result I got:
>
>
>    x <- 0:20
>    cc <- c("yellow", "springgreen", "navyblue")
>    lambdas <- c(6, 10, 13)
>    ds <- as.data.frame(lapply(lambdas, function(ll) dpois(x, ll)))
>    names(ds) <- lambdas
>    funcs <- list(plot, lines)
>
>    for (i in 1:3) {
>        ff <- funcs[[1+(i!=1)]]
>        ff(x,ds[[i]], type="o", pch=21,bg=cc[i])
>    }
>
>    # I can't build the expressions:
>    q <- list(expression(lambda==6), expression(lambda==10),
>              expression(lambda==13))
>
>    legend("topright",
>           legend=q,
>           lty=1, pch=21, pt.bg=cc)
>
> legend() doesn't interpret the expressions and then it doesn't show
> the lambda symbol.
>
> Do you have any comments on this?
>
> Thanks,
>
>   -Sergio.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dmck at u.washington.edu  Sun Sep 14 17:41:07 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Sun, 14 Sep 2014 08:41:07 -0700
Subject: [R] simulation data in SEM
In-Reply-To: <CABLo8nEvKCsY=TW0r-33+rd1aPJf-0H-bPL6DcnwMRiBZ5UyrA@mail.gmail.com>
References: <CABLo8nEvKCsY=TW0r-33+rd1aPJf-0H-bPL6DcnwMRiBZ5UyrA@mail.gmail.com>
Message-ID: <CB2161CB-7423-4FFD-879C-FA468D220F91@u.washington.edu>

What errors?  What is your output?  What output did you expect?

On Sep 14, 2014, at 6:56 AM, thanoon younis <thanoon.younis80 at gmail.com> wrote:

> Dear R members
> I want to simulate data depending on SEM and when i applied the code below
> i found some errors and i still cannot run it.
> many thanks in advance
> 
> 
> Thanoon
> 
> #Do simulation for 100 replications
> N<-1000; P<-10
> 
> phi<-matrix(data=c(1.0,0.3,0.3,1.0),ncol=2) #The covariance matrix of xi
> Ro<-matrix(data=c(7.0,2.1,2.1,7.0), ncol=2)
> yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)
> 
> for (t in 1:100) {
>    #Generate the data for the simulation study
>    for (i in 1:N) {
>        #Generate xi
>        xi<-mvrnorm(1,mu=c(0,0),phi)
>        #Generate the fixed covariates
>        co<-rnorm(1,0,1)
>        #Generate error term is structural equation
>        delta<-rnorm(1,0,sqrt(0.3))
>        #Generate eta1 according to the structural equation
>        eta<-0.8*co[i]+0.6*xi[1]+0.6*xi[2]+0.8*xi[1]*xi[2]+delta
>        #Generate error terms in measurement equations
>        eps<-rnorm(3,0,1)
> 
>        #Generate theta according to measurement equations
>        v1[1]<-1.0+eta+eps[1]; v1[2]<-1.0+0.7*eta+eps[2]
>        v1[3]<-1.0+0.7*eta+eps[3]
>        v1[4]<-1.0+xi[1]; v1[5]<-1.0+0.8*xi[1]; v1[6]<-1.0+0.8*xi[1]
>        v1[7]<-1.0+xi[2]; v1[8]<-1.0+0.7*xi[2]; v1[9]<-1.0+0.7*xi[2];
>        v1[10]<-1.0+0.7*xi1[2]
> 
> 
>        #transform theta to orinal variables
>        for (j in 1:10) { if (v[j]>0) yo[i,j]<-1 else yo[i,j]<-0 }
> 
> 
>    #Input data set for WinBUGS
>    data<-list(N=200,P=10,R=Ro,z=yo)
> 
> }   #end
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From dmck at u.washington.edu  Sun Sep 14 17:48:25 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Sun, 14 Sep 2014 08:48:25 -0700
Subject: [R] simulation data in SEM
In-Reply-To: <CABLo8nGQH1bMxReMDzCGnCOTpcXjNf37P_iwnmGq0AHD1joR7w@mail.gmail.com>
References: <CABLo8nEvKCsY=TW0r-33+rd1aPJf-0H-bPL6DcnwMRiBZ5UyrA@mail.gmail.com>
	<CB2161CB-7423-4FFD-879C-FA468D220F91@u.washington.edu>
	<CABLo8nGQH1bMxReMDzCGnCOTpcXjNf37P_iwnmGq0AHD1joR7w@mail.gmail.com>
Message-ID: <F71431EF-26A6-4207-9D68-91D126AD910C@u.washington.edu>

cc?ing to list, as requested in the posting guide, so that others may be able to help you.

On Sep 14, 2014, at 8:45 AM, thanoon younis <thanoon.younis80 at gmail.com> wrote:

> Thank you very much for your reply
> 
> the output is
> 
> > #Do simulation for 100 replications
> > N<-1000; P<-10
> > 
> > phi<-matrix(data=c(1.0,0.3,0.3,1.0),ncol=2) #The covariance matrix of xi
> > Ro<-matrix(data=c(7.0,2.1,2.1,7.0), ncol=2)
> > yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)
> Error: unexpected symbol in "yo<-matrix(data=NA,nrow=N,ncol=P) p"
> > 
> > for (t in 1:100) {
> +     #Generate the data for the simulation study
> +     for (i in 1:N) {
> +         #Generate xi
> +         xi<-mvrnorm(1,mu=c(0,0),phi)
> +         #Generate the fixed covariates
> +         co<-rnorm(1,0,1)
> +         #Generate error term is structural equation
> +         delta<-rnorm(1,0,sqrt(0.3))
> +         #Generate eta1 according to the structural equation
> +         eta<-0.8*co[i]+0.6*xi[1]+0.6*xi[2]+0.8*xi[1]*xi[2]+delta
> +         #Generate error terms in measurement equations
> +         eps<-rnorm(3,0,1)
> + 
> +         #Generate theta according to measurement equations
> +         v1[1]<-1.0+eta+eps[1]; v1[2]<-1.0+0.7*eta+eps[2]
> +         v1[3]<-1.0+0.7*eta+eps[3]
> +         v1[4]<-1.0+xi[1]; v1[5]<-1.0+0.8*xi[1]; v1[6]<-1.0+0.8*xi[1]
> +         v1[7]<-1.0+xi[2]; v1[8]<-1.0+0.7*xi[2]; v1[9]<-1.0+0.7*xi[2];
> +         v1[10]<-1.0+0.7*xi1[2]
> +         
> +                
> +         #transform theta to orinal variables
> +         for (j in 1:10) { if (v[j]>0) yo[i,j]<-1 else yo[i,j]<-0 }
> + 
> + 
> +     #Input data set for WinBUGS
> +     data<-list(N=200,P=10,R=Ro,z=yo)
> +   
> + }   #end
> + 
> 
> also i cannot continue to get on a data.
> 
> 
> many thanks again
> 
> 
> Thanoon
> 
> 
> 
> On 14 September 2014 18:41, Don McKenzie <dmck at u.washington.edu> wrote:
> What errors?  What is your output?  What output did you expect?
> 
> On Sep 14, 2014, at 6:56 AM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> 
> > Dear R members
> > I want to simulate data depending on SEM and when i applied the code below
> > i found some errors and i still cannot run it.
> > many thanks in advance
> >
> >
> > Thanoon
> >
> > #Do simulation for 100 replications
> > N<-1000; P<-10
> >
> > phi<-matrix(data=c(1.0,0.3,0.3,1.0),ncol=2) #The covariance matrix of xi
> > Ro<-matrix(data=c(7.0,2.1,2.1,7.0), ncol=2)
> > yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)
> >
> > for (t in 1:100) {
> >    #Generate the data for the simulation study
> >    for (i in 1:N) {
> >        #Generate xi
> >        xi<-mvrnorm(1,mu=c(0,0),phi)
> >        #Generate the fixed covariates
> >        co<-rnorm(1,0,1)
> >        #Generate error term is structural equation
> >        delta<-rnorm(1,0,sqrt(0.3))
> >        #Generate eta1 according to the structural equation
> >        eta<-0.8*co[i]+0.6*xi[1]+0.6*xi[2]+0.8*xi[1]*xi[2]+delta
> >        #Generate error terms in measurement equations
> >        eps<-rnorm(3,0,1)
> >
> >        #Generate theta according to measurement equations
> >        v1[1]<-1.0+eta+eps[1]; v1[2]<-1.0+0.7*eta+eps[2]
> >        v1[3]<-1.0+0.7*eta+eps[3]
> >        v1[4]<-1.0+xi[1]; v1[5]<-1.0+0.8*xi[1]; v1[6]<-1.0+0.8*xi[1]
> >        v1[7]<-1.0+xi[2]; v1[8]<-1.0+0.7*xi[2]; v1[9]<-1.0+0.7*xi[2];
> >        v1[10]<-1.0+0.7*xi1[2]
> >
> >
> >        #transform theta to orinal variables
> >        for (j in 1:10) { if (v[j]>0) yo[i,j]<-1 else yo[i,j]<-0 }
> >
> >
> >    #Input data set for WinBUGS
> >    data<-list(N=200,P=10,R=Ro,z=yo)
> >
> > }   #end
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
> 
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
> 
> 
> 
> 
> 

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu





	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Sep 14 18:27:54 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Sep 2014 09:27:54 -0700
Subject: [R] ggplot y-axis labels are not continuous
In-Reply-To: <CAOoXFP-3RyqOQQoQ78k-N-ii7iR6oAikKNA13mqX_t2gD2dA8Q@mail.gmail.com>
References: <CAOoXFP-WNxNaQGLTu1niJgccODgcR6pNaLD80oWsG=Y+_5geDA@mail.gmail.com>
	<CADv2QyHKKKm9qGBGnsZWEt3A=eB_aZWySQyXHGvUdtQBa6feqA@mail.gmail.com>
	<CAOoXFP-3RyqOQQoQ78k-N-ii7iR6oAikKNA13mqX_t2gD2dA8Q@mail.gmail.com>
Message-ID: <A1D90EDF-66DC-4D1C-AE67-FA4D4981AA8A@comcast.net>


On Sep 14, 2014, at 1:15 AM, Mohan Radhakrishnan wrote:

> Thanks Dennis.
>
> df.melted$value<-as.numeric(df.melted$value)

See the FAQ about converting factors to numeric.

The more typical way of making that conversion is:

  df.melted$value<-as.numeric(as.character(df.melted$value))

... although the FAQ points out that this is more efficient:

  df.melted$value<-levels(df.melted$value)[ df.melted$value]


> df.melted$value <- format(df.melted$value, scientific = FALSE)

So you started out with a factor and then you converted back to a  
character with `format`? Was that what was really desired? You  
probably want to leave it as numeric and then you plotting routines  
will "know" what type of axis to create for the data features. If you  
are in the ggplot world view then there will be functions like  
scale_x_continuous that appears to offer a 'labels' parameter. Reading  
the help page for scale_continuous it seems that you might want to try  
formating the result of the `waiver()` function, but the somewhat  
older version of the package I have on this aging laptop does not have  
any worked examples.


>
>
> Mohan
>
> On Sun, Sep 14, 2014 at 9:22 AM, Dennis Murphy <djmuser at gmail.com>  
> wrote:
>
>> Hi:
>>
>> Try
>>
>> str(df.melted)
>>
>> I'm guessing value is a factor. It needs to be numeric or integer.
>>
>> Dennis
>>
>>
>> On Sat, Sep 13, 2014 at 12:53 PM, Mohan Radhakrishnan
>> <radhakrishnan.mohan at gmail.com> wrote:
>>> Hi,
>>>
>>> This is the code to create a ggplot. The plot is rendered but the  
>>> y-axis
>>> labels are not continuous. So the lines are split.
>>>
>>> Moreover multiple y-axis labels overwrite each other due to this.  
>>> How
>> can I
>>> fix this?
>>>
>>> If I try to set ylim I get "
>>>
>>> *Discrete value supplied to continuous scale"*
>>>
>>> library(RJSONIO)
>>> library(ggplot2)
>>> this.dir <- dirname(parent.frame(2)$ofile)
>>> setwd(this.dir)
>>>
>>> airlines   = fromJSON("json")
>>> df <- sapply(airlines$data,unlist)
>>> df <- data.frame(t(df))
>>> colnames(df) <- c( (airlines[[1]][[1]])[[2]],
>>> gsub("[^A-Z]","",(airlines[[1]][[2]])[[2]]),
>>> gsub("[^A-Z]","",(airlines[[1]][[3]])[[2]] ),
>>> gsub("[^A-Z]","",(airlines[[1]][[4]])[[2]]), (airlines[[1]][[5]]) 
>>> [[2]],
>>> (airlines[[1]][[6]])[[2]], (airlines[[1]][[7]])[[2]],
>>> (airlines[[1]][[8]])[[2]],
>>> (airlines[[1]][[9]])[[2]],(airlines[[1]][[10]])[[2]] )
>>>
>>> df.melted <- melt(df, id = "YEAR")
>>> print(ggplot(data = df.melted, aes(x = YEAR, y = value, color =
>> variable))
>>> +geom_point() + theme(axis.text.x = element_text(angle = 90, hjust  
>>> = 1))
>> +
>>> ylab(""))
>>> dev.off()
>>>
>>>
>>>> head(df)
>>>
>>>     YEAR INTERNATIONALACMINNOS DOMESTICACMINNOS TOTALACMINNOS
>>>
>>> 1 1995-96                 92515           314727        407242
>>>
>>> 2 1996-97                 94884           324462        419346
>>>
>>> 3 1997-98                 98226           317531        415757
>>>
>>> 4 1998-99                 99563           325392        424955
>>>
>>> 5 1999-00                 99701           368015        467716
>>>
>>> 6 2000-01                103211           386575        489786
>>>
>>>  INTERNATIONAL PAX (IN NOS) DOMESTIC PAX (IN NOS) TOTAL PAX (IN NOS)
>>>
>>> 1                   11449756              25563998            
>>> 37013754
>>>
>>> 2                   12223660              24276108            
>>> 36499768
>>>
>>> 3                   12782769              23848833            
>>> 36631602
>>>
>>> 4                   12916788              24072631            
>>> 36989419
>>>
>>> 5                   13293027              25741521            
>>> 39034548
>>>
>>> 6                   14009052              28017568            
>>> 42026620
>>>
>>>  INTERNATIONAL FREIGHT (IN MT) DOMESTIC FREIGHT (IN MT) TOTAL  
>>> FREIGHT
>> (IN
>>> MT)
>>>
>>> 1                        452853                   196516
>>> 649369
>>>
>>> 2                        479088                   202122
>>> 681210
>>>
>>> 3                        488175                   217405
>>> 705580
>>>
>>> 4                        474660                   224490
>>> 699150
>>>
>>> 5                        531844                   265570
>>> 797414
>>>
>>> 6                        557772                   288373
>>> 846145
>>>
>>>
>>> Thanks,
>>>
>>> Mohan
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Sep 14 18:37:44 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Sep 2014 09:37:44 -0700
Subject: [R] simulation data in SEM
In-Reply-To: <F71431EF-26A6-4207-9D68-91D126AD910C@u.washington.edu>
References: <CABLo8nEvKCsY=TW0r-33+rd1aPJf-0H-bPL6DcnwMRiBZ5UyrA@mail.gmail.com>
	<CB2161CB-7423-4FFD-879C-FA468D220F91@u.washington.edu>
	<CABLo8nGQH1bMxReMDzCGnCOTpcXjNf37P_iwnmGq0AHD1joR7w@mail.gmail.com>
	<F71431EF-26A6-4207-9D68-91D126AD910C@u.washington.edu>
Message-ID: <67835576-C150-4660-86B5-523C7398F6D0@comcast.net>


On Sep 14, 2014, at 8:48 AM, Don McKenzie wrote:

> cc?ing to list, as requested in the posting guide, so that others  
> may be able to help you.
>
> On Sep 14, 2014, at 8:45 AM, thanoon younis <thanoon.younis80 at gmail.com 
> > wrote:
>
>> Thank you very much for your reply
>>
>> the output is
>>
>>> #Do simulation for 100 replications
>>> N<-1000; P<-10
>>>
>>> phi<-matrix(data=c(1.0,0.3,0.3,1.0),ncol=2) #The covariance matrix  
>>> of xi
>>> Ro<-matrix(data=c(7.0,2.1,2.1,7.0), ncol=2)
>>> yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)
>> Error: unexpected symbol in "yo<-matrix(data=NA,nrow=N,ncol=P) p"

Almost any time you see an error message that says " : unexpected  
_something_" it means you submitted a malformed expression to the  
interpreter that was missing a paren or a bracket or a comma or  
_something_.  You always need to go back to the left of where the  
error was discovered. In this case you are missing a semicolon about  
here:

yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)
                                  ^

-- 
David.

>>>
>>> for (t in 1:100) {
>> +     #Generate the data for the simulation study
>> +     for (i in 1:N) {
>> +         #Generate xi
>> +         xi<-mvrnorm(1,mu=c(0,0),phi)
>> +         #Generate the fixed covariates
>> +         co<-rnorm(1,0,1)

snipped

-- 
David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Sep 14 23:05:03 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Sep 2014 14:05:03 -0700
Subject: [R] simulation data in SEM
In-Reply-To: <CABLo8nECa9=LKU6Kb88fTKghQEi5kvn42E7boKH5cJwx7dVLig@mail.gmail.com>
References: <CABLo8nEvKCsY=TW0r-33+rd1aPJf-0H-bPL6DcnwMRiBZ5UyrA@mail.gmail.com>
	<CB2161CB-7423-4FFD-879C-FA468D220F91@u.washington.edu>
	<CABLo8nGQH1bMxReMDzCGnCOTpcXjNf37P_iwnmGq0AHD1joR7w@mail.gmail.com>
	<F71431EF-26A6-4207-9D68-91D126AD910C@u.washington.edu>
	<67835576-C150-4660-86B5-523C7398F6D0@comcast.net>
	<CABLo8nECa9=LKU6Kb88fTKghQEi5kvn42E7boKH5cJwx7dVLig@mail.gmail.com>
Message-ID: <6B30BB88-08B1-4C72-8142-A0049092513D@comcast.net>

Adding back the list address:

On Sep 14, 2014, at 9:53 AM, thanoon younis wrote:

> thank you for your help but i still have error after putting  semicolon "Error: unexpected symbol in:
> "Ro<-matrix(data=c(7.0,2.1,2.1,7.0), ncol=2)
> yo<-matrix(data=NA,nrow=N,ncol=P) p""

The error message shows no semicolon in the location I pointed at that was missing one. Furthermore the error message is now attaching the prior line which should not have thrown an error. Since you didn't include the actual code block that was your revision we can only guess (and I do not have a good guess why that is now occurring unless perhaps your font has two different encodings for semi-colon glyphs.)

You typed (or at least that is what I see in my mail client):
yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)

I suggested:
yo<-matrix(data=NA,nrow=N,ncol=P); p<-numeric(P); v<-numeric(P)

PLEASE read the Posting Guide.  I will not respond to offlist messages from you in the future.

-- 
David.


> 
> 
> many thanks again
> 
> On 14 September 2014 19:37, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Sep 14, 2014, at 8:48 AM, Don McKenzie wrote:
> 
> cc?ing to list, as requested in the posting guide, so that others may be able to help you.
> 
> On Sep 14, 2014, at 8:45 AM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> 
> Thank you very much for your reply
> 
> the output is
> 
> #Do simulation for 100 replications
> N<-1000; P<-10
> 
> phi<-matrix(data=c(1.0,0.3,0.3,1.0),ncol=2) #The covariance matrix of xi
> Ro<-matrix(data=c(7.0,2.1,2.1,7.0), ncol=2)
> yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)
> Error: unexpected symbol in "yo<-matrix(data=NA,nrow=N,ncol=P) p"
> 
> Almost any time you see an error message that says " : unexpected _something_" it means you submitted a malformed expression to the interpreter that was missing a paren or a bracket or a comma or _something_.  You always need to go back to the left of where the error was discovered. In this case you are missing a semicolon about here:
> 
> yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)
>                                  ^
> 
> -- 
> David.
> 
> 
> for (t in 1:100) {
> +     #Generate the data for the simulation study
> +     for (i in 1:N) {
> +         #Generate xi
> +         xi<-mvrnorm(1,mu=c(0,0),phi)
> +         #Generate the fixed covariates
> +         co<-rnorm(1,0,1)
> 
> snipped
> 
> -- 
> David Winsemius, MD
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From cranatic at gmail.com  Mon Sep 15 00:40:06 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 14 Sep 2014 18:40:06 -0400
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <54161946a8d4_7797e589130199@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* cmvnorm (1.0)
  Maintainer: Robin Hankin
  Author(s): Robin K. S. Hankin
  License: GPL-2
  http://crantastic.org/packages/cmvnorm

  various utilities for the complex multivariate Gaussian distribution

* couchDB (1.3.0)
  Maintainer: Aleksander Dietrichson
  Author(s): Aleksander Dietrichson
  License: AGPL-3
  http://crantastic.org/packages/couchDB

  Interface to couchDB

* eegkit (1.0-0)
  Maintainer: Nathaniel E. Helwig
  Author(s): Nathaniel E. Helwig <helwig at umn.edu>
  License: GPL (>= 2)
  http://crantastic.org/packages/eegkit

  Analysis and visualization tools for electroencephalography (EEG)
  data. Includes functions for plotting (a) EEG caps, (b) single- and
  multi-channel EEG time courses, and (c) EEG spatial maps. Also
  includes smoothing and Independent Component Analysis functions for
  EEG data analysis.

* eegkitdata (1.0)
  Maintainer: Nathaniel E. Helwig
  Author(s): Nathaniel E. Helwig <helwig at umn.edu>
  License: GPL (>= 2)
  http://crantastic.org/packages/eegkitdata

  Contains the example EEG data used in the package eegkit. Also
  contains code for easily creating larger EEG datasets from the EEG
  Database on the UCI Machine Learning Repository.

* ForwardSearch (1.0)
  Maintainer: Bent Nielsen
  Author(s): Bent Nielsen
  License: GPL-3
  http://crantastic.org/packages/ForwardSearch

  Forward Search analysis of time series regressions. Implements the
  asymptotic theory developed in Johansen and Nielsen (2013, 2014).

* FRESA.CAD (1.0)
  Maintainer: Jose Gerardo Tamez-Pena
  Author(s): Jose Gerardo Tamez-Pena
  License: LGPL (>= 2)
  http://crantastic.org/packages/FRESA-CAD

  FRESA.CAD provides a set of functions and feature selection algorithms
  for building Computer Aided Diagnosis Models

* funFEM (1.0)
  Maintainer: Charles Bouveyron
  Author(s): Charles Bouveyron
  License: GPL-2
  http://crantastic.org/packages/funFEM

  The funFEM algorithm (Bouveyron et al., 2014) allows to cluster
  functional data by modeling the curves within a common and
  discriminative functional subspace.

* funHDDC (1.0)
  Maintainer: Charles Bouveyron
  Author(s): C. Bouveyron & J. Jacques
  License: GPL-2
  http://crantastic.org/packages/funHDDC

  The package provides the funHDDC algorithm (Bouveyron &amp; Jacques, 2011)
  which allows to cluster functional data by modeling each group
  within a specific functional subspace.

* gapmap (0.0.1)
  Maintainer: Ryo Sakai
  Author(s): Ryo Sakai
  License: GPL-2 | GPL-3
  http://crantastic.org/packages/gapmap

  The gap encodes the distance between clusters and improves
  interpretation of cluster heatmaps. The gaps can be of the same
  distance based on a height threshold to cut the dendrogram. Another
  option is to vary the size of gaps based on the distance between
  clusters.

* GENLIB (1.0)
  Maintainer: Marie-Helene Roy-Gagnon
  Author(s): Louis Houde, Jean-Francois Lefebvre, Valery Roy-Lagace, Sebastien
             Lemieux
  License: GPL (>= 2)
  http://crantastic.org/packages/GENLIB

  Takes genealogical data frames and calculates different demographic
  variables such as genetic contribution, kinship, etc...

* lefse (0.1)
  Maintainer: Nathan G. Swenson
  Author(s): Nathan G. Swenson
  License: GPL-2 | GPL-3
  http://crantastic.org/packages/lefse

  Utilizing phylogenetic and functional information for the analyses of
  ecological datasets. The analyses include methods for quantifying
  the phylogenetic and functional diversity of assemblages.

* lunar (0.1-04)
  Maintainer: Emmanuel Lazaridis
  Author(s): Emmanuel Lazaridis [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/lunar

  Provides functions to calculate lunar and other environmental
  covariates.

* micropan (1.0)
  Maintainer: Lars Snipen
  Author(s): Lars Snipen and Kristian Hovde Liland
  License: GPL-2
  http://crantastic.org/packages/micropan

  A collection of functions for computations and visualizations of
  microbial pan-genomes.

* nettools (1.0.1)
  Maintainer: Michele Filosi
  Author(s): Michele Filosi [aut, cre], Roberto Visintainer [aut], Samantha
             Riccadonna [aut], Giuseppe Jurman [ctb], Cesare
             Furlanello [ctb]
  License: CC BY-NC-SA 4.0
  http://crantastic.org/packages/nettools

  A collection of network inference methods for co-expression networks,
  quantitative network distances and a novel framework for network
  stability analysis.

* RDML (0.4-2)
  Maintainer: Konstantin A. Blagodatskikh
  Author(s): Konstantin A. Blagodatskikh [cre, aut], Stefan Roediger [aut], Michal
             Burdukiewicz [aut]
  License: GPL (>= 2)
  http://crantastic.org/packages/RDML

  Imports real-time thermo cycler (qPCR) data from RDML format files and
  transforms to the appropriate formats of the &#39;qpcR&#39; and &#39;chipPCR&#39;
  packages.

* saery (1.0)
  Maintainer: Agustin Perez Martin
  Author(s): Maria Dolores Esteban Lefler, Domingo Morales Gonzalez, Agustin Perez
             Martin
  License: GPL-2
  http://crantastic.org/packages/saery

  A complete set of functions to calculate several EBLUP (Empirical Best
  Linear Unbiased Predictor) estimators and their mean squared errors.
  All estimators are based on an area-level linear mixed model
  introduced by Rao and Yu in 1994 (see documentation). The REML
  method is used for fitting this model.

* slackr (1.2)
  Maintainer: Bob Rudis
  Author(s): Bob Rudis (@hrbrmstr) & Jay Jacobs (@jayjacobs)
  License: MIT + file LICENSE
  http://crantastic.org/packages/slackr

  Slackr contains functions that make it possible to interact with
  Slack.com messaging platform. When you need to share
  information/data from R, rather than resort to copy/paste in e-mails
  or other services like Skype, you can use this package to send
  well-formatted output from multiple R objects and expressions to all
  teammates at the same time with little effort. You can also send
  images from the current graphics device, R objects (as RData), and
  upload files.

* tlm (0.1.2)
  Maintainer: Jose Barrera-Gomez
  Author(s): Jose Barrera-Gomez and Xavier Basagana
  License: GPL (>= 2)
  http://crantastic.org/packages/tlm

  Computation of effects under linear, logistic and Poisson regression
  models with transformed variables. Logarithm and power
  transformations are allowed. Effects can be displayed both
  numerically and graphically in both the original and the transformed
  space of the variables.

* treatSens (1.0)
  Maintainer: &quot;Nicole Bohme Carnegie&quot;
  Author(s): Nicole Bohme Carnegie, Masataka Harada, Jennifer Hill
  License: GPL-2
  http://crantastic.org/packages/treatSens

  Utilities to investigate sensitivity to unmeasured confounding in
  parametric models with either binary or continuous treatment.

* vcrpart (0.2-1)
  Maintainer: Reto Buergin
  Author(s): Reto Buergin [aut, cre, cph], Gilbert Ritschard [ctb, ths]
  License: GPL (>= 2)
  http://crantastic.org/packages/vcrpart

  Recursive partitioning algorithm for varying coefficient generalized
  linear models and ordinal 2-stage linear mixed models. Special
  features are coefficient-wise partitioning, non-varying coefficients
  and partitioning of time-varying variables in longitudinal ordinal
  regression.


Updated packages
----------------

anacor (1.0-5), astro (1.2), BMA (3.18), bpkde (1.0-7), caTools
(1.17.1), catR (3.2), DatABEL (0.9-5), dismo (1.0-5), doBy (4.5-11),
easyanova (4.0), emulator (1.2-15), FastPCS (0.1.0), FastRCS (0.0.4),
fcros (1.2), fpc (2.1-8), gdsfmt (1.1.0), geepack (1.2-0), geosphere
(1.3-11), GGMselect (0.1-9), glmmLasso (1.3.3), glmmLasso (1.3.2), HH
(3.1-5), Hmisc (3.14-5), hwriter (1.3.2), iBATCGH (1.1), ibd (1.2),
intsvy (1.4), investr (1.1.1), isotone (1.0-2), Lahman (3.0-1), lcmm
(1.6.6), MarkedPointProcess (0.2.22), meta (3.8-0), mmcm (1.2-5),
Mobilize (2.16-4), MODISTools (0.94.4), MTurkR (0.5.1), ngspatial
(1.0-4), Ohmage (2.11-4), OjaNP (0.9-8), operators (0.1-7), partykit
(0.8-2), partykit (0.8-1), pbkrtest (0.4-1), PReMiuM (3.0.29), PReMiuM
(3.0.30), rChoiceDialogs (1.0.6), RcmdrPlugin.EBM (1.0-8),
RcmdrPlugin.IPSUR (0.2-1), recosystem (0.2.3), recosystem (0.2.4), rgl
(0.94.1131), RGraphics (2.0-12), seewave (1.7.6), segmented (0.5-0.0),
Sim.DiffProc (2.9), SimComp (2.2), snpEnrichment (1.4-1), spam
(1.0-1), synbreed (0.10-2), TAM (1.0-3.18-1), taxize (0.4.0), TripleR
(1.4), VennDiagram (1.6.8), xtable (1.7-4)

New reviews
-----------

* XLConnect, by tim_lindgren
  http://crantastic.org/reviews/234



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From radhakrishnan.mohan at gmail.com  Mon Sep 15 06:44:07 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Mon, 15 Sep 2014 10:14:07 +0530
Subject: [R] ggplot y-axis labels are not continuous
In-Reply-To: <A1D90EDF-66DC-4D1C-AE67-FA4D4981AA8A@comcast.net>
References: <CAOoXFP-WNxNaQGLTu1niJgccODgcR6pNaLD80oWsG=Y+_5geDA@mail.gmail.com>
	<CADv2QyHKKKm9qGBGnsZWEt3A=eB_aZWySQyXHGvUdtQBa6feqA@mail.gmail.com>
	<CAOoXFP-3RyqOQQoQ78k-N-ii7iR6oAikKNA13mqX_t2gD2dA8Q@mail.gmail.com>
	<A1D90EDF-66DC-4D1C-AE67-FA4D4981AA8A@comcast.net>
Message-ID: <CAOoXFP_vi6uebT+KwvW+pkdYbZD765wHE=9kVFzMpLk164UcLg@mail.gmail.com>

options("scipen"=100, "digits"=4)
df.melted$value<-as.integer(df.melted$value)

I was not looking at the return type of 'format'. But these alternative
work well.

Thanks,
Mohan

On Sun, Sep 14, 2014 at 9:57 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Sep 14, 2014, at 1:15 AM, Mohan Radhakrishnan wrote:
>
>  Thanks Dennis.
>>
>> df.melted$value<-as.numeric(df.melted$value)
>>
>
> See the FAQ about converting factors to numeric.
>
> The more typical way of making that conversion is:
>
>  df.melted$value<-as.numeric(as.character(df.melted$value))
>
> ... although the FAQ points out that this is more efficient:
>
>  df.melted$value<-levels(df.melted$value)[ df.melted$value]
>
>
>  df.melted$value <- format(df.melted$value, scientific = FALSE)
>>
>
> So you started out with a factor and then you converted back to a
> character with `format`? Was that what was really desired? You probably
> want to leave it as numeric and then you plotting routines will "know" what
> type of axis to create for the data features. If you are in the ggplot
> world view then there will be functions like scale_x_continuous that
> appears to offer a 'labels' parameter. Reading the help page for
> scale_continuous it seems that you might want to try formating the result
> of the `waiver()` function, but the somewhat older version of the package I
> have on this aging laptop does not have any worked examples.
>
>
>
>
>>
>> Mohan
>>
>> On Sun, Sep 14, 2014 at 9:22 AM, Dennis Murphy <djmuser at gmail.com> wrote:
>>
>>  Hi:
>>>
>>> Try
>>>
>>> str(df.melted)
>>>
>>> I'm guessing value is a factor. It needs to be numeric or integer.
>>>
>>> Dennis
>>>
>>>
>>> On Sat, Sep 13, 2014 at 12:53 PM, Mohan Radhakrishnan
>>> <radhakrishnan.mohan at gmail.com> wrote:
>>>
>>>> Hi,
>>>>
>>>> This is the code to create a ggplot. The plot is rendered but the y-axis
>>>> labels are not continuous. So the lines are split.
>>>>
>>>> Moreover multiple y-axis labels overwrite each other due to this. How
>>>>
>>> can I
>>>
>>>> fix this?
>>>>
>>>> If I try to set ylim I get "
>>>>
>>>> *Discrete value supplied to continuous scale"*
>>>>
>>>> library(RJSONIO)
>>>> library(ggplot2)
>>>> this.dir <- dirname(parent.frame(2)$ofile)
>>>> setwd(this.dir)
>>>>
>>>> airlines   = fromJSON("json")
>>>> df <- sapply(airlines$data,unlist)
>>>> df <- data.frame(t(df))
>>>> colnames(df) <- c( (airlines[[1]][[1]])[[2]],
>>>> gsub("[^A-Z]","",(airlines[[1]][[2]])[[2]]),
>>>> gsub("[^A-Z]","",(airlines[[1]][[3]])[[2]] ),
>>>> gsub("[^A-Z]","",(airlines[[1]][[4]])[[2]]), (airlines[[1]][[5]])[[2]],
>>>> (airlines[[1]][[6]])[[2]], (airlines[[1]][[7]])[[2]],
>>>> (airlines[[1]][[8]])[[2]],
>>>> (airlines[[1]][[9]])[[2]],(airlines[[1]][[10]])[[2]] )
>>>>
>>>> df.melted <- melt(df, id = "YEAR")
>>>> print(ggplot(data = df.melted, aes(x = YEAR, y = value, color =
>>>>
>>> variable))
>>>
>>>> +geom_point() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
>>>>
>>> +
>>>
>>>> ylab(""))
>>>> dev.off()
>>>>
>>>>
>>>>  head(df)
>>>>>
>>>>
>>>>     YEAR INTERNATIONALACMINNOS DOMESTICACMINNOS TOTALACMINNOS
>>>>
>>>> 1 1995-96                 92515           314727        407242
>>>>
>>>> 2 1996-97                 94884           324462        419346
>>>>
>>>> 3 1997-98                 98226           317531        415757
>>>>
>>>> 4 1998-99                 99563           325392        424955
>>>>
>>>> 5 1999-00                 99701           368015        467716
>>>>
>>>> 6 2000-01                103211           386575        489786
>>>>
>>>>  INTERNATIONAL PAX (IN NOS) DOMESTIC PAX (IN NOS) TOTAL PAX (IN NOS)
>>>>
>>>> 1                   11449756              25563998           37013754
>>>>
>>>> 2                   12223660              24276108           36499768
>>>>
>>>> 3                   12782769              23848833           36631602
>>>>
>>>> 4                   12916788              24072631           36989419
>>>>
>>>> 5                   13293027              25741521           39034548
>>>>
>>>> 6                   14009052              28017568           42026620
>>>>
>>>>  INTERNATIONAL FREIGHT (IN MT) DOMESTIC FREIGHT (IN MT) TOTAL FREIGHT
>>>>
>>> (IN
>>>
>>>> MT)
>>>>
>>>> 1                        452853                   196516
>>>> 649369
>>>>
>>>> 2                        479088                   202122
>>>> 681210
>>>>
>>>> 3                        488175                   217405
>>>> 705580
>>>>
>>>> 4                        474660                   224490
>>>> 699150
>>>>
>>>> 5                        531844                   265570
>>>> 797414
>>>>
>>>> 6                        557772                   288373
>>>> 846145
>>>>
>>>>
>>>> Thanks,
>>>>
>>>> Mohan
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>>
>>> http://www.R-project.org/posting-guide.html
>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> David Winsemius, MD
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From radhakrishnan.mohan at gmail.com  Mon Sep 15 07:07:06 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Mon, 15 Sep 2014 10:37:06 +0530
Subject: [R] ggplot y-axis labels are not continuous
In-Reply-To: <CAOoXFP_vi6uebT+KwvW+pkdYbZD765wHE=9kVFzMpLk164UcLg@mail.gmail.com>
References: <CAOoXFP-WNxNaQGLTu1niJgccODgcR6pNaLD80oWsG=Y+_5geDA@mail.gmail.com>
	<CADv2QyHKKKm9qGBGnsZWEt3A=eB_aZWySQyXHGvUdtQBa6feqA@mail.gmail.com>
	<CAOoXFP-3RyqOQQoQ78k-N-ii7iR6oAikKNA13mqX_t2gD2dA8Q@mail.gmail.com>
	<A1D90EDF-66DC-4D1C-AE67-FA4D4981AA8A@comcast.net>
	<CAOoXFP_vi6uebT+KwvW+pkdYbZD765wHE=9kVFzMpLk164UcLg@mail.gmail.com>
Message-ID: <CAOoXFP-y7i7pc_uh9eG_2U=XZAG7MSCM46oG8N2uHhMBG1sYdA@mail.gmail.com>

I have more control over labels using David's suggestion.

scale_y_continuous(breaks=seq(min(df.melted$value)-20000,max(df.melted$value),by=1700000)

Thanks,
Mohan

On Mon, Sep 15, 2014 at 10:14 AM, Mohan Radhakrishnan <
radhakrishnan.mohan at gmail.com> wrote:

> options("scipen"=100, "digits"=4)
> df.melted$value<-as.integer(df.melted$value)
>
> I was not looking at the return type of 'format'. But these alternative
> work well.
>
> Thanks,
> Mohan
>
> On Sun, Sep 14, 2014 at 9:57 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> On Sep 14, 2014, at 1:15 AM, Mohan Radhakrishnan wrote:
>>
>>  Thanks Dennis.
>>>
>>> df.melted$value<-as.numeric(df.melted$value)
>>>
>>
>> See the FAQ about converting factors to numeric.
>>
>> The more typical way of making that conversion is:
>>
>>  df.melted$value<-as.numeric(as.character(df.melted$value))
>>
>> ... although the FAQ points out that this is more efficient:
>>
>>  df.melted$value<-levels(df.melted$value)[ df.melted$value]
>>
>>
>>  df.melted$value <- format(df.melted$value, scientific = FALSE)
>>>
>>
>> So you started out with a factor and then you converted back to a
>> character with `format`? Was that what was really desired? You probably
>> want to leave it as numeric and then you plotting routines will "know" what
>> type of axis to create for the data features. If you are in the ggplot
>> world view then there will be functions like scale_x_continuous that
>> appears to offer a 'labels' parameter. Reading the help page for
>> scale_continuous it seems that you might want to try formating the result
>> of the `waiver()` function, but the somewhat older version of the package I
>> have on this aging laptop does not have any worked examples.
>>
>>
>>
>>
>>>
>>> Mohan
>>>
>>> On Sun, Sep 14, 2014 at 9:22 AM, Dennis Murphy <djmuser at gmail.com>
>>> wrote:
>>>
>>>  Hi:
>>>>
>>>> Try
>>>>
>>>> str(df.melted)
>>>>
>>>> I'm guessing value is a factor. It needs to be numeric or integer.
>>>>
>>>> Dennis
>>>>
>>>>
>>>> On Sat, Sep 13, 2014 at 12:53 PM, Mohan Radhakrishnan
>>>> <radhakrishnan.mohan at gmail.com> wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> This is the code to create a ggplot. The plot is rendered but the
>>>>> y-axis
>>>>> labels are not continuous. So the lines are split.
>>>>>
>>>>> Moreover multiple y-axis labels overwrite each other due to this. How
>>>>>
>>>> can I
>>>>
>>>>> fix this?
>>>>>
>>>>> If I try to set ylim I get "
>>>>>
>>>>> *Discrete value supplied to continuous scale"*
>>>>>
>>>>> library(RJSONIO)
>>>>> library(ggplot2)
>>>>> this.dir <- dirname(parent.frame(2)$ofile)
>>>>> setwd(this.dir)
>>>>>
>>>>> airlines   = fromJSON("json")
>>>>> df <- sapply(airlines$data,unlist)
>>>>> df <- data.frame(t(df))
>>>>> colnames(df) <- c( (airlines[[1]][[1]])[[2]],
>>>>> gsub("[^A-Z]","",(airlines[[1]][[2]])[[2]]),
>>>>> gsub("[^A-Z]","",(airlines[[1]][[3]])[[2]] ),
>>>>> gsub("[^A-Z]","",(airlines[[1]][[4]])[[2]]),
>>>>> (airlines[[1]][[5]])[[2]],
>>>>> (airlines[[1]][[6]])[[2]], (airlines[[1]][[7]])[[2]],
>>>>> (airlines[[1]][[8]])[[2]],
>>>>> (airlines[[1]][[9]])[[2]],(airlines[[1]][[10]])[[2]] )
>>>>>
>>>>> df.melted <- melt(df, id = "YEAR")
>>>>> print(ggplot(data = df.melted, aes(x = YEAR, y = value, color =
>>>>>
>>>> variable))
>>>>
>>>>> +geom_point() + theme(axis.text.x = element_text(angle = 90, hjust =
>>>>> 1))
>>>>>
>>>> +
>>>>
>>>>> ylab(""))
>>>>> dev.off()
>>>>>
>>>>>
>>>>>  head(df)
>>>>>>
>>>>>
>>>>>     YEAR INTERNATIONALACMINNOS DOMESTICACMINNOS TOTALACMINNOS
>>>>>
>>>>> 1 1995-96                 92515           314727        407242
>>>>>
>>>>> 2 1996-97                 94884           324462        419346
>>>>>
>>>>> 3 1997-98                 98226           317531        415757
>>>>>
>>>>> 4 1998-99                 99563           325392        424955
>>>>>
>>>>> 5 1999-00                 99701           368015        467716
>>>>>
>>>>> 6 2000-01                103211           386575        489786
>>>>>
>>>>>  INTERNATIONAL PAX (IN NOS) DOMESTIC PAX (IN NOS) TOTAL PAX (IN NOS)
>>>>>
>>>>> 1                   11449756              25563998           37013754
>>>>>
>>>>> 2                   12223660              24276108           36499768
>>>>>
>>>>> 3                   12782769              23848833           36631602
>>>>>
>>>>> 4                   12916788              24072631           36989419
>>>>>
>>>>> 5                   13293027              25741521           39034548
>>>>>
>>>>> 6                   14009052              28017568           42026620
>>>>>
>>>>>  INTERNATIONAL FREIGHT (IN MT) DOMESTIC FREIGHT (IN MT) TOTAL FREIGHT
>>>>>
>>>> (IN
>>>>
>>>>> MT)
>>>>>
>>>>> 1                        452853                   196516
>>>>> 649369
>>>>>
>>>>> 2                        479088                   202122
>>>>> 681210
>>>>>
>>>>> 3                        488175                   217405
>>>>> 705580
>>>>>
>>>>> 4                        474660                   224490
>>>>> 699150
>>>>>
>>>>> 5                        531844                   265570
>>>>> 797414
>>>>>
>>>>> 6                        557772                   288373
>>>>> 846145
>>>>>
>>>>>
>>>>> Thanks,
>>>>>
>>>>> Mohan
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>>
>>>> http://www.R-project.org/posting-guide.html
>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>>
>

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Mon Sep 15 08:48:38 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 15 Sep 2014 14:48:38 +0800 (CST)
Subject: [R] simulation data in SEM
In-Reply-To: <CABLo8nEvKCsY=TW0r-33+rd1aPJf-0H-bPL6DcnwMRiBZ5UyrA@mail.gmail.com>
References: <CABLo8nEvKCsY=TW0r-33+rd1aPJf-0H-bPL6DcnwMRiBZ5UyrA@mail.gmail.com>
Message-ID: <72f13b3f.8f50.1487811ffcc.Coremail.rhelpmaillist@163.com>



PLZ mke sure the package installed which contains "mvrnorm" function.




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-09-14 09:56:34, "thanoon younis" <thanoon.younis80 at gmail.com> wrote:
>Dear R members
>I want to simulate data depending on SEM and when i applied the code below
>i found some errors and i still cannot run it.
>many thanks in advance
>
>
>Thanoon
>
>#Do simulation for 100 replications
>N<-1000; P<-10
>
>phi<-matrix(data=c(1.0,0.3,0.3,1.0),ncol=2) #The covariance matrix of xi
>Ro<-matrix(data=c(7.0,2.1,2.1,7.0), ncol=2)
>yo<-matrix(data=NA,nrow=N,ncol=P) p<-numeric(P); v<-numeric(P)
>
>for (t in 1:100) {
>    #Generate the data for the simulation study
>    for (i in 1:N) {
>        #Generate xi
>        xi<-mvrnorm(1,mu=c(0,0),phi)
>        #Generate the fixed covariates
>        co<-rnorm(1,0,1)
>        #Generate error term is structural equation
>        delta<-rnorm(1,0,sqrt(0.3))
>        #Generate eta1 according to the structural equation
>        eta<-0.8*co[i]+0.6*xi[1]+0.6*xi[2]+0.8*xi[1]*xi[2]+delta
>        #Generate error terms in measurement equations
>        eps<-rnorm(3,0,1)
>
>        #Generate theta according to measurement equations
>        v1[1]<-1.0+eta+eps[1]; v1[2]<-1.0+0.7*eta+eps[2]
>        v1[3]<-1.0+0.7*eta+eps[3]
>        v1[4]<-1.0+xi[1]; v1[5]<-1.0+0.8*xi[1]; v1[6]<-1.0+0.8*xi[1]
>        v1[7]<-1.0+xi[2]; v1[8]<-1.0+0.7*xi[2]; v1[9]<-1.0+0.7*xi[2];
>        v1[10]<-1.0+0.7*xi1[2]
>
>
>        #transform theta to orinal variables
>        for (j in 1:10) { if (v[j]>0) yo[i,j]<-1 else yo[i,j]<-0 }
>
>
>    #Input data set for WinBUGS
>    data<-list(N=200,P=10,R=Ro,z=yo)
>
>}   #end
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From rl at openmailbox.org  Mon Sep 15 10:52:50 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Mon, 15 Sep 2014 08:52:50 +0000
Subject: [R] apply block of if statements with menu function
Message-ID: <eb4cde6f90a194657e53038765e926df@openmailbox.org>

Subscribers,

apply block of if statements with menu function
Subscribers,

For a menu:

menu(c('a','b','c','d'))

How to create a function that will apply to specific menu choice 
objects? For example:

object1<-function (menuifchoices) {
menu1<-menu(c('a','b','c','d'))
	if (menu1==1)
	...
	menu1a<-menu...
		if (menu1a==1)
		...
	menu2a<-menu...
		if (menu2a==1)
		...
menu2
	<-menu(c('a','b','c','d'))
	if (menu1==2)
	...
}

The request action is that a user can select a menu option that will 
activate a series of "multiple choice" questions, results in "menu1" 
being activated without menu2 being activated. If someone could direct 
to the relevant terminology, thank you.

Separate question; for a menu:

menu(c('a','b','c','d'))

1: a
2: b
3: c
4: d

Selection: 1
[1] 1

is it possible to change behaviour so that result of the selection is 
not the integer, but the original menu choice:

Selection: 1
[1] a


From friendly at yorku.ca  Sun Sep 14 16:41:04 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 14 Sep 2014 10:41:04 -0400
Subject: [R] [R-pkgs] Announce: Lahman baseball database archive package,
	v 3.0
Message-ID: <5415A900.8000406@yorku.ca>

Dear list

Version 3.0-1 of the Lahman package was recently submitted to CRAN. It 
contains the
the tables from Sean Lahman's  Baseball Database,
http://www.seanlahman.com/baseball-archive/statistics/
as a set of R data.frames with examples of use.

V 3.0 provides the updated data on pitching, hitting and fielding 
performance and other tables from 1871
through 2013, as recorded in the 2014 version of the database.  The 
Lahman project has a home page
at http://lahman.r-forge.r-project.org/ with some additional examples.  
Additional links to other
applications or analyses of this database are invited.

If you have used the earlier v. 2.0-x package in scripts or examples, 
please note that the database schema
has been somewhat revised to regularize the use of player ID variables 
across the various tables, and
remove some redundant variables, so some scripts may need to be 
revised.  In particular:

   o HallOfFame$hofID is now HallOfFame$playerID
   o managerID is now playerID in all tables
   o Removed from Master: managerID, hofID, holtzID, lahmanID, 
lahman40ID, lahman45ID, nameNote, nameNick, and college

-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bbolker at gmail.com  Mon Sep 15 12:21:46 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 15 Sep 2014 10:21:46 +0000
Subject: [R] 8 fast or 4 very fast cores?
References: <5412BC56.6060203@Ruckman.se>
Message-ID: <loom.20140915T121928-343@post.gmane.org>

Leif Ruckman <Leif <at> Ruckman.se> writes:

> 
> I am going to buy a new computer ( Dell workstation T5810 - Windows 8) 
> to work with simulatons in R.
> 
> Now I am asked what kind of processor I like and I was given two choices.
> 
> 1. Intel Xeon E5-1620 v3 - 4 cores 3.7 GHz Turbo
> 2. Intel Xeon E5-2640 v3 - 8 cores 2.6 GHz Turbo
> 
> I don't know what is better in simulations studies in R, a few very fast 
> cores or many cores at normal speed.


  It's **very** hard to answer such general questions reliably, but I'll
take a guess and say that if you're doing simulation studies you're likely
to be doing tasks that are easily distributable (e.g. many random
realizations of the same simulation and/or realizations for many
different sets of parameter values) and so the more-cores option
will be a good idea.

  But it's possible that what you mean by "simulation studies" is
different.

  If you can do some benchmarking of your problems on an existing
machine that would probably be a good idea.

  Ben Bolker


From ripley at stats.ox.ac.uk  Mon Sep 15 14:07:02 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Sep 2014 13:07:02 +0100
Subject: [R] 8 fast or 4 very fast cores?
In-Reply-To: <loom.20140915T121928-343@post.gmane.org>
References: <5412BC56.6060203@Ruckman.se>
	<loom.20140915T121928-343@post.gmane.org>
Message-ID: <5416D666.3090701@stats.ox.ac.uk>

On 15/09/2014 11:21, Ben Bolker wrote:
> Leif Ruckman <Leif <at> Ruckman.se> writes:
>
>>
>> I am going to buy a new computer ( Dell workstation T5810 - Windows 8)
>> to work with simulatons in R.
>>
>> Now I am asked what kind of processor I like and I was given two choices.
>>
>> 1. Intel Xeon E5-1620 v3 - 4 cores 3.7 GHz Turbo
>> 2. Intel Xeon E5-2640 v3 - 8 cores 2.6 GHz Turbo
>>
>> I don't know what is better in simulations studies in R, a few very fast
>> cores or many cores at normal speed.
>
>
>    It's **very** hard to answer such general questions reliably, but I'll
> take a guess and say that if you're doing simulation studies you're likely
> to be doing tasks that are easily distributable (e.g. many random
> realizations of the same simulation and/or realizations for many
> different sets of parameter values) and so the more-cores option
> will be a good idea.
>
>    But it's possible that what you mean by "simulation studies" is
> different.
>
>    If you can do some benchmarking of your problems on an existing
> machine that would probably be a good idea.

Unfortunately unless it is of very similar architecture that may not 
help much.

Three issues hard to scale from are the 'Turbo', the hyperthreading of 
modern Xeons and the cache sizes.  Now, I happen to have machines with 
multiple E5-24x0 and E5-26x0 Xeons: both do hyperthreading well, so you 
would have 8 or 16 virtual CPUs and they will give you say 50% increase 
in throughput if all the virtual cores are used.  But you cannot scale 
up from using just one process on one core.

I find it hard to think of tasks where option 1) would have more 
throughput, but if most of the time you are not running things in 
parallel then the higher speed on a single task is a consideration.

>
>    Ben Bolker
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From schuttesebastian at gmail.com  Mon Sep 15 10:47:25 2014
From: schuttesebastian at gmail.com (Sebastian Schutte)
Date: Mon, 15 Sep 2014 10:47:25 +0200
Subject: [R] spatstat rmh problem
Message-ID: <5416A79D.4040101@gmail.com>

Dear R and spatstat developers,

Thanks so much for the time and effort that you invest into this awesome 
software. I have a problem simulating from a Point Process Model in 
spatstat. In summary, the option "new.coef" should allow me to use a 
fitted model and change its beta coefficients before simulating a point 
pattern from the model via Monte Carlo simulation. Intuitively, one 
would assume that the predicted point pattern changes as one fiddles 
with the beta coefficients. However, this does not seem to work.

Please let me know what I am missing here and which screw to drive to 
actually change the simulation output.

#owin is a polygon of country boundaries, "im.pop" is a raster with 
georeferenced population counts.
#I am using a random point pattern for demonstration purposes

#Fix random seed
set.seed(12345)
#Generate artificial points
dat <- rpoint(500,win=cshape)
#Fit a (inhomogenous spatial poisson) model to the data
mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
#Simulate some points:
plot(density(rmh(mod)))
#plot(density(simulate(mod)))
#Show that this is reproducible
set.seed(12345)
#Generate artificial points
dat <- rpoint(500,win=cshape)
#Fit a (inhomogenous spatial poisson) model to the data
mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
#Simulate some points:
plot(density(rmh(mod)))
#As expected, the density is the same

#Now change the coefs and do it again:
set.seed(12345)
#Generate artificial points
dat <- rpoint(500,win=cshape)
#Fit a (inhomogenous spatial poisson) model to the data
mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
#Simulate some points:
plot(density(rmh(mod),new.coef=c(1,200)))
#Looks the same, so what am I missing?

Thanks for your help,
Sebastian

P.S:
R 3.1.1
Spatstat 1.38-1
Ubuntu 14.04
Linux 3.13.0-34-generic


From mewing at eastman.com  Mon Sep 15 15:30:49 2014
From: mewing at eastman.com (pofigster)
Date: Mon, 15 Sep 2014 06:30:49 -0700 (PDT)
Subject: [R] [I] Re: Installing nloptr in UNIX environ
In-Reply-To: <1410526255832-4696884.post@n4.nabble.com>
References: <1410270203834-4696711.post@n4.nabble.com>
	<1410526255832-4696884.post@n4.nabble.com>
Message-ID: <20A3C789D3C2454BAB6FCF0E2C7008F626D37ED0@MAILX04.emn.com>

Thanks - I ended up getting our linux admin to let the server connect to the internet and got it working.

Mark Ewing

From: ray48 [via R] [mailto:ml-node+s789695n4696884h73 at n4.nabble.com]
Sent: Friday, September 12, 2014 8:51 AM
To: Ewing, Mark
Subject: [I] Re: Installing nloptr in UNIX environ

I had this issue too as a result of having to hand install nlopt-2.4.2 (as a result of not having a connection to CRAN at the time)

I first removed my nlopt installation (using 'make uninstall') and then installed nloptr using online CRAN.
This will cause CRAN to download nlopt-2.4.2 prior to it installing nloptr.

________________________________
If you reply to this email, your message will be added to the discussion below:
http://r.789695.n4.nabble.com/Installing-nloptr-in-UNIX-environ-tp4696711p4696884.html
To unsubscribe from Installing nloptr in UNIX environ, click here<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4696711&code=bWV3aW5nQGVhc3RtYW4uY29tfDQ2OTY3MTF8LTQ0NzY1NDY3OQ==>.
NAML<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>




--
View this message in context: http://r.789695.n4.nabble.com/Installing-nloptr-in-UNIX-environ-tp4696711p4696951.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From m.heidari.b at gmail.com  Mon Sep 15 15:47:20 2014
From: m.heidari.b at gmail.com (Maryam Heidari)
Date: Mon, 15 Sep 2014 08:47:20 -0500
Subject: [R] the properties of a DATA to run DBSCAN in R
Message-ID: <CAJ4Akz9pxUOBG7KLW-jKg6Y-Oj9RsO5N5MoYryBLLnLw=CbG4Q@mail.gmail.com>

hello everybody,

I have been trying to run "dbscan" algorithm on my data, my data round
40000 records which each of them has 3 attributes + plus the ID for each
record.
the interesting thing is that when I run the "dbscan just on 3 attributes"
R gives me an ERROR regarding "stackoverflow" but when I run it including
the 4 attributes it runs with out any problem.
so is the problem with my data?!

this is statistics about my data
   att1                           att2                                att3
 Min.   :0.00000      Min.   :0.000000       Min.   :0.000000
 1st Qu.:0.01429    1st Qu.:0.000000     1st Qu.:0.000000
 Median :0.02857    Median :0.000000   Median :0.000000
 Mean   :0.02764    Mean   :0.001135    Mean   :0.000477
 3rd Qu.:0.02857    3rd Qu.:0.000000    3rd Qu.:0.000000
 Max.   :1.00000      Max.   :1.000000     Max.   :1.000000

	[[alternative HTML version deleted]]


From marie.dogherty79 at gmail.com  Mon Sep 15 12:27:26 2014
From: marie.dogherty79 at gmail.com (Marie Dogherty)
Date: Mon, 15 Sep 2014 11:27:26 +0100
Subject: [R] Fwd: CoxME: Family relatedness
In-Reply-To: <CANRNCSpdr-LHhciaSGan_sHNyiNGEpwmQvN79hnPerYYzgn-sg@mail.gmail.com>
References: <CANRNCSpdr-LHhciaSGan_sHNyiNGEpwmQvN79hnPerYYzgn-sg@mail.gmail.com>
Message-ID: <CANRNCSorcLnhemaHrVVTv0fSiqhfgaGtwBwd0=-8VVN6dVR3Ww@mail.gmail.com>

Hello all,



I have a table like this, with ~300 individuals:



Famid     Id   Faid Moid Cohort    Sex  Survival Event SNP1 SNP2 SNP3

1    1    0    0    0    0    10   1    0    1    0

2    2    0    0    1    1    20   1    0    0    0

2    3    0    0    0    0    25   1    0    1    0

4    5    1    2    0    0    35   1    0    1    1

4    6    1    2    0    0    35   0    1    0    1







famid=family id, id=id of person,faid=father id,moid=mother id.



My question of interest: What impact does SNP1/SNP2/SNP3 have on survival
of individuals (Id), after accounting for possible effects due to family
relatedness (Famid).



So I want to account for family-specific frailty effects, and individual
frailty effects according to degree of relationship between individuals.



The commands I've used are:



Library(survival)

Library(coxme)

Library(kinship2)

Library(bdsmatrix)



Death.dat <-read.table(?Table?,header=T)



deathdat.kmat
<-makekinship(famid=death.dat$famid,id=death.dat$id,father=death.dat$faid,mother=death.dat$moid)



death.dat1<-subset(death.dat,!is.na(Survival))



all <-dimnames(deathdat.kmat)[[1]]



temp <-which(!is.na(death.dat$Survival[match(all,death.dat$id)]))



deathdat1.kmat <-deathdat.kmat[temp,temp]



model4
<-coxme(Surv(Survival,Event)~Sex+strata(Cohort)+SNP1+SNP2+SNP3,data=death.dat1,id|famid,varlist=list(deathdat1.kmat,famblockf.mat),pdcheck=FALSE)







I almost completely edited these commands from :
http://www.ncbi.nlm.nih.gov/pubmed/21786277 as I am new to R.



The error I obtain is:



Error in coxme(Surv(Survival, Event) ~ Sex + strata(Cohort) + SNP1 + SNP2
+  :

No observations remain in the data set

In addition: Warning message:

In Ops.factor(id, famid) : | not meaningful for factors





I have two questions:

1. What is the difference between (id|famid) and (1+id|famid)/How to I tell
which is appropriate for my data set/Have I formatted that section of the
command properly?

2. Does anyone understand the error/how to fix it?



Many thanks

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Sep 15 16:22:19 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 15 Sep 2014 14:22:19 +0000
Subject: [R] apply block of if statements with menu function
In-Reply-To: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
References: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>

I think switch() should work for you here, but it is not clear how much flexibility you are trying to have (different tests based on the first response; different tests based on first, then second response; different tests based on each successive response). 

?switch

For the second question just index the return value:

> let <- letters[1:4]
> let[menu(let)]

1: a
2: b
3: c
4: d

Selection: 3
[1] "c"

Or a bit more polished:

> cat("Choice: ", let[menu(let)], "\n")

1: a
2: b
3: c
4: d

Selection: 4
Choice:  d

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of rl at openmailbox.org
Sent: Monday, September 15, 2014 3:53 AM
To: r-help at r-project.org
Subject: [R] apply block of if statements with menu function

Subscribers,

apply block of if statements with menu function
Subscribers,

For a menu:

menu(c('a','b','c','d'))

How to create a function that will apply to specific menu choice 
objects? For example:

object1<-function (menuifchoices) {
menu1<-menu(c('a','b','c','d'))
	if (menu1==1)
	...
	menu1a<-menu...
		if (menu1a==1)
		...
	menu2a<-menu...
		if (menu2a==1)
		...
menu2
	<-menu(c('a','b','c','d'))
	if (menu1==2)
	...
}

The request action is that a user can select a menu option that will 
activate a series of "multiple choice" questions, results in "menu1" 
being activated without menu2 being activated. If someone could direct 
to the relevant terminology, thank you.

Separate question; for a menu:

menu(c('a','b','c','d'))

1: a
2: b
3: c
4: d

Selection: 1
[1] 1

is it possible to change behaviour so that result of the selection is 
not the integer, but the original menu choice:

Selection: 1
[1] a

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rl at openmailbox.org  Mon Sep 15 16:51:12 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Mon, 15 Sep 2014 14:51:12 +0000
Subject: [R] apply block of if statements with menu function
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
References: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
Message-ID: <2e7d4d99a0a6c989abcfb4871ec78863@openmailbox.org>

On 2014-09-15 14:22, David L Carlson wrote:
> I think switch() should work for you here, but it is not clear how
> much flexibility you are trying to have (different tests based on the
> first response; different tests based on first, then second response;
> different tests based on each successive response).
> 

Yes, different tests are to be written dependent upon the first 
response.


From eliza_botto at hotmail.com  Mon Sep 15 16:57:17 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Mon, 15 Sep 2014 14:57:17 +0000
Subject: [R] chi-square test
Message-ID: <BLU170-W133B5AF83C06FE34FFFDB4889C80@phx.gbl>

Dear useRs of R,
I have two datasets (TT and SS) and i wanted to to see if my data is uniformly distributed or not?I tested it through chi-square test and results are given at the end of it.Now apparently P-value has a significant importance but I cant interpret the results and why it says that "In chisq.test(TT) : Chi-squared approximation may be incorrect"
###############################################################
> dput(TT)
structure(list(clc5 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.26, 0.14, 0, 0.44, 0.26, 0, 0, 0, 0, 0, 0, 0.11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.16, 0.56, 0, 1.49, 0, 0.64, 0.79, 0.66, 0, 0, 0.17, 0, 0, 0, 0, 0.56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.43, 0.41, 0, 0.5, 0.44, 0, 0, 0, 0, 0.09, 0.46, 0, 0.27, 0.45, 0.15, 0.31, 0.16, 0.44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07, 0, 0, 0, 0, 0, 0.06, 0, 0.09, 0.07, 0, 0, 7.89, 0, 0.22, 0.29, 0.33, 0.27, 0, 0.36, 0.41, 0, 0, 0, 0, 0.55, 0.81, 0, 0.09, 0.13, 0.28, 0, 0, 0), quota_massima = c(1167L, 1167L, 4572L, 3179L, 3141L, 585L, 585L, 876L, 876L, 1678L, 2667L, 1369L, 1369L, 1369L, 1381L, 1381L, 1381L, 1381L, 2284L, 410L, 2109L, 2507L, 2579L, 2507L, 1436L, 3234L, 3234L, 3234L, 3234L, 2792L, 2569L, 2569L, 2569L, 1669L, 4743L, 4743L, 4743L, 3403L, 3197L, 3267L, 3583L, 3583L, 3583L, 2584L, 2584L, 2579L, 1241L, 1241L, 4174L, 3006L, 3197L, 2366L, 2618L, 2670L, 4487L, 3196L, 3196L, 2107L, 2107L, 2427L, 1814L, 2622L, 1268L, 1268L, 1268L, 3885L, 3885L, 3092L, 3234L, 2625L, 2625L, 3760L, 4743L, 3707L, 3760L, 4743L, 3760L, 3885L, 3760L, 4743L, 2951L, 782L, 2957L, 3343L, 2697L, 2697L, 3915L, 2277L, 1678L, 1678L, 3197L, 2957L, 2957L, 2957L, 4530L, 4530L, 4530L, 2131L, 3618L, 3618L, 3335L, 2512L, 2390L, 1616L, 3526L, 3197L, 3197L, 2625L, 2622L, 3197L, 3197L, 2622L, 2622L, 2622L, 368L, 4572L, 3953L, 863L, 3716L, 3716L, 3716L, 2697L, 2697L, 1358L)), .Names = c("clc5", "quota_massima"), class = "data.frame", row.names = c(NA, -124L))

>  chisq.test(TT)
        Pearson's Chi-squared test
data:  TT
X-squared = 411.5517, df = 123, p-value < 2.2e-16
Warning message:
In chisq.test(TT) : Chi-squared approximation may be incorrect 
#######################################################################
> dput(SS)
structure(list(NDVIanno = c(0.57, 0.536, 0.082, 0.262, 0.209, 0.539, 0.536, 0.543, 0.588, 0.599, 0.397, 0.63, 0.616, 0.644, 0.579, 0.597, 0.617, 0.622, 0.548, 0.528, 0.541, 0.436, 0.509, 0.467, 0.534, 0.412, 0.324, 0.299, 0.41, 0.462, 0.427, 0.456, 0.508, 0.581, 0.242, 0.291, 0.324, 0.28, 0.291, 0.305, 0.365, 0.338, 0.399, 0.516, 0.357, 0.558, 0.605, 0.638, 0.191, 0.377, 0.325, 0.574, 0.458, 0.426, 0.188, 0.412, 0.464, 0.568, 0.582, 0.494, 0.598, 0.451, 0.577, 0.572, 0.602, 0.321, 0.38, 0.413, 0.427, 0.55, 0.437, 0.481, 0.425, 0.234, 0.466, 0.464, 0.491, 0.463, 0.489, 0.435, 0.267, 0.564, 0.256, 0.156, 0.476, 0.498, 0.122, 0.508, 0.582, 0.615, 0.409, 0.356, 0.284, 0.285, 0.444, 0.303, 0.478, 0.557, 0.345, 0.408, 0.347, 0.498, 0.534, 0.576, 0.361, 0.495, 0.502, 0.553, 0.519, 0.504, 0.53, 0.547, 0.559, 0.505, 0.557, 0.377, 0.36, 0.613, 0.452, 0.397, 0.277, 0.42, 0.443, 0.62), delta_z = c(211L, 171L, 925L, 534L, 498L, 50L, 53L, 331L, 135L, 456L, 850L, 288L, 286L, 233L, 342L, 274L, 184L, 198L, 312L, 67L, 476L, 676L, 349L, 873L, 65L, 963L, 553L, 474L, 948L, 1082L, 616L, 704L, 814L, 450L, 865L, 987L, 1265L, 720L, 565L, 652L, 941L, 822L, 1239L, 929L, 477L, 361L, 199L, 203L, 642L, 788L, 818L, 450L, 703L, 760L, 711L, 1015L, 1351L, 195L, 511L, 617L, 296L, 604L, 381L, 389L, 287L, 1043L, 1465L, 963L, 1125L, 582L, 662L, 1424L, 1762L, 575L, 1477L, 1364L, 1236L, 1483L, 1201L, 1644L, 498L, 142L, 510L, 482L, 811L, 788L, 466L, 626L, 461L, 350L, 1177L, 826L, 575L, 568L, 916L, 767L, 1017L, 532L, 1047L, 1370L, 902L, 686L, 703L, 440L, 1016L, 1148L, 1089L, 753L, 650L, 1065L, 568L, 712L, 762L, 636L, 79L, 1092L, 955L, 158L, 1524L, 1145L, 673L, 513L, 596L, 239L)), .Names = c("NDVIanno", "delta_z"), class = "data.frame", row.names = c(NA, -124L))
>  chisq.test(SS)
        Pearson's Chi-squared test
data:  SS
X-squared = 72.8115, df = 123, p-value = 0.9999
Warning message:
In chisq.test(SS) : Chi-squared approximation may be incorrect
#####################################################################################
Kindly guide me through like you always did :)
thanks in advance,


Eliza 		 	   		  
	[[alternative HTML version deleted]]


From rab45 at pitt.edu  Mon Sep 15 17:17:49 2014
From: rab45 at pitt.edu (Rick Bilonick)
Date: Mon, 15 Sep 2014 11:17:49 -0400
Subject: [R] chi-square test
In-Reply-To: <BLU170-W133B5AF83C06FE34FFFDB4889C80@phx.gbl>
References: <BLU170-W133B5AF83C06FE34FFFDB4889C80@phx.gbl>
Message-ID: <5417031D.9020801@pitt.edu>

On 09/15/2014 10:57 AM, eliza botto wrote:
> Dear useRs of R,
> I have two datasets (TT and SS) and i wanted to to see if my data is uniformly distributed or not?I tested it through chi-square test and results are given at the end of it.Now apparently P-value has a significant importance but I cant interpret the results and why it says that "In chisq.test(TT) : Chi-squared approximation may be incorrect"
> ###############################################################
>> dput(TT)
> structure(list(clc5 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.26, 0.14, 0, 0.44, 0.26, 0, 0, 0, 0, 0, 0, 0.11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.16, 0.56, 0, 1.49, 0, 0.64, 0.79, 0.66, 0, 0, 0.17, 0, 0, 0, 0, 0.56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.43, 0.41, 0, 0.5, 0.44, 0, 0, 0, 0, 0.09, 0.46, 0, 0.27, 0.45, 0.15, 0.31, 0.16, 0.44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07, 0, 0, 0, 0, 0, 0.06, 0, 0.09, 0.07, 0, 0, 7.89, 0, 0.22, 0.29, 0.33, 0.27, 0, 0.36, 0.41, 0, 0, 0, 0, 0.55, 0.81, 0, 0.09, 0.13, 0.28, 0, 0, 0), quota_massima = c(1167L, 1167L, 4572L, 3179L, 3141L, 585L, 585L, 876L, 876L, 1678L, 2667L, 1369L, 1369L, 1369L, 1381L, 1381L, 1381L, 1381L, 2284L, 410L, 2109L, 2507L, 2579L, 2507L, 1436L, 3234L, 3234L, 3234L, 3234L, 2792L, 2569L, 2569L, 2569L, 1669L, 4743L, 4743L, 4743L, 3403L, 3197L, 3267L, 3583L, 3583L, 3583L, 2584L, 2584L, 2579L, 1241L, 1241L, 4174L, 3006L, 3197L, 2366L, 2618L, 2670L, 4487L, 3196L, 3196L, 2107L, 2107L, 2427L, 1814L, 2622L, 1268L, 1268L, 1268L,!
>    3885L, 3885L, 3092L, 3234L, 2625L, 2625L, 3760L, 4743L, 3707L, 3760L, 4743L, 3760L, 3885L, 3760L, 4743L, 2951L, 782L, 2957L, 3343L, 2697L, 2697L, 3915L, 2277L, 1678L, 1678L, 3197L, 2957L, 2957L, 2957L, 4530L, 4530L, 4530L, 2131L, 3618L, 3618L, 3335L, 2512L, 2390L, 1616L, 3526L, 3197L, 3197L, 2625L, 2622L, 3197L, 3197L, 2622L, 2622L, 2622L, 368L, 4572L, 3953L, 863L, 3716L, 3716L, 3716L, 2697L, 2697L, 1358L)), .Names = c("clc5", "quota_massima"), class = "data.frame", row.names = c(NA, -124L))
>
>>   chisq.test(TT)
>          Pearson's Chi-squared test
> data:  TT
> X-squared = 411.5517, df = 123, p-value < 2.2e-16
> Warning message:
> In chisq.test(TT) : Chi-squared approximation may be incorrect
> #######################################################################
>> dput(SS)
> structure(list(NDVIanno = c(0.57, 0.536, 0.082, 0.262, 0.209, 0.539, 0.536, 0.543, 0.588, 0.599, 0.397, 0.63, 0.616, 0.644, 0.579, 0.597, 0.617, 0.622, 0.548, 0.528, 0.541, 0.436, 0.509, 0.467, 0.534, 0.412, 0.324, 0.299, 0.41, 0.462, 0.427, 0.456, 0.508, 0.581, 0.242, 0.291, 0.324, 0.28, 0.291, 0.305, 0.365, 0.338, 0.399, 0.516, 0.357, 0.558, 0.605, 0.638, 0.191, 0.377, 0.325, 0.574, 0.458, 0.426, 0.188, 0.412, 0.464, 0.568, 0.582, 0.494, 0.598, 0.451, 0.577, 0.572, 0.602, 0.321, 0.38, 0.413, 0.427, 0.55, 0.437, 0.481, 0.425, 0.234, 0.466, 0.464, 0.491, 0.463, 0.489, 0.435, 0.267, 0.564, 0.256, 0.156, 0.476, 0.498, 0.122, 0.508, 0.582, 0.615, 0.409, 0.356, 0.284, 0.285, 0.444, 0.303, 0.478, 0.557, 0.345, 0.408, 0.347, 0.498, 0.534, 0.576, 0.361, 0.495, 0.502, 0.553, 0.519, 0.504, 0.53, 0.547, 0.559, 0.505, 0.557, 0.377, 0.36, 0.613, 0.452, 0.397, 0.277, 0.42, 0.443, 0.62), delta_z = c(211L, 171L, 925L, 534L, 498L, 50L, 53L, 331L, 135L, 456L, 850L, 288L, 286L, 233L, 342L, 27!
>   4L, 184L, 198L, 312L, 67L, 476L, 676L, 349L, 873L, 65L, 963L, 553L, 474L, 948L, 1082L, 616L, 704L, 814L, 450L, 865L, 987L, 1265L, 720L, 565L, 652L, 941L, 822L, 1239L, 929L, 477L, 361L, 199L, 203L, 642L, 788L, 818L, 450L, 703L, 760L, 711L, 1015L, 1351L, 195L, 511L, 617L, 296L, 604L, 381L, 389L, 287L, 1043L, 1465L, 963L, 1125L, 582L, 662L, 1424L, 1762L, 575L, 1477L, 1364L, 1236L, 1483L, 1201L, 1644L, 498L, 142L, 510L, 482L, 811L, 788L, 466L, 626L, 461L, 350L, 1177L, 826L, 575L, 568L, 916L, 767L, 1017L, 532L, 1047L, 1370L, 902L, 686L, 703L, 440L, 1016L, 1148L, 1089L, 753L, 650L, 1065L, 568L, 712L, 762L, 636L, 79L, 1092L, 955L, 158L, 1524L, 1145L, 673L, 513L, 596L, 239L)), .Names = c("NDVIanno", "delta_z"), class = "data.frame", row.names = c(NA, -124L))
>>   chisq.test(SS)
>          Pearson's Chi-squared test
> data:  SS
> X-squared = 72.8115, df = 123, p-value = 0.9999
> Warning message:
> In chisq.test(SS) : Chi-squared approximation may be incorrect
> #####################################################################################
> Kindly guide me through like you always did :)
> thanks in advance,
>
>
> Eliza 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
You are using a Chi-squared test on a 124x2 matrix of values (not all 
integers) and many are zeros. The expected frequencies for many cells 
are very small (near zero, less than 1) hence the warning message. More 
importantly, does this application of the Chi-squared test make sense? 
What am I missing?

Rick

-- 
Richard A. Bilonick, PhD
Assistant Professor
Dept. of Ophthalmology, School of Medicine
Dept. of Biostatistics, Graduate School of Public Health
Dept. of Orthodontics, School of Dental Medicine
University of Pittsburgh
Principal Investigator for the Pittsburgh Aerosol Research
  and Inhalation Epidemiology Study (PARIES)
412 647 5756


From HDoran at air.org  Mon Sep 15 18:09:07 2014
From: HDoran at air.org (Doran, Harold)
Date: Mon, 15 Sep 2014 16:09:07 +0000
Subject: [R] Using sqldf() to read in .fwf files
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686B638C9C5@DC1VEX10MB001.air.org>

I am learning to use sqldf() to read in very large fixed width files that otherwise do not work efficiently with read.fwf. I found the following example online and have worked with this in various ways to read in the data

cat("1 8.3
210.3
319.0
416.0
515.6
719.8
", file = "fixed")

fixed <- file("fixed")
sqldf("select substr(V1, 1, 1) f1, substr(V1, 2, 4) f2 from fixed")

I then applied this to my real world data problem though it yields the following error message and I am not sure how to interpret this.

dor <- file("dor")
> sqldf("select substr(V1, 1, 1) f1, substr(V1, 2, 4) f2 from dor")
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
  line 1 did not have 6 elements

Looking at my .fwf. data in a text editor shows the data are structured as I would expect. In fact, I can read in the first few lines of the file using read.fwf and the data are as I would expect after being read into R.

Thanks,
Harold


	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Mon Sep 15 18:21:29 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Mon, 15 Sep 2014 09:21:29 -0700 (PDT)
Subject: [R] 8 fast or 4 very fast cores?
In-Reply-To: <5416D666.3090701@stats.ox.ac.uk>
References: <5412BC56.6060203@Ruckman.se>
	<loom.20140915T121928-343@post.gmane.org>
	<5416D666.3090701@stats.ox.ac.uk>
Message-ID: <alpine.LRH.2.11.1409150918430.7424@aeolus.ecy.wa.gov>

I'm in a similar situation and am looking seriously at a pair of E5-2643v3 
(6 cores each-hyperthreaded).

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Mon, 15 Sep 2014, Prof Brian Ripley wrote:

> On 15/09/2014 11:21, Ben Bolker wrote:
>>  Leif Ruckman <Leif <at> Ruckman.se> writes:
>> 
>> > 
>> >  I am going to buy a new computer ( Dell workstation T5810 - Windows 8)
>> >  to work with simulatons in R.
>> > 
>> >  Now I am asked what kind of processor I like and I was given two 
>> >  choices.
>> > 
>> >  1. Intel Xeon E5-1620 v3 - 4 cores 3.7 GHz Turbo
>> >  2. Intel Xeon E5-2640 v3 - 8 cores 2.6 GHz Turbo
>> > 
>> >  I don't know what is better in simulations studies in R, a few very fast
>> >  cores or many cores at normal speed.
>> 
>>
>>     It's **very** hard to answer such general questions reliably, but I'll
>>  take a guess and say that if you're doing simulation studies you're likely
>>  to be doing tasks that are easily distributable (e.g. many random
>>  realizations of the same simulation and/or realizations for many
>>  different sets of parameter values) and so the more-cores option
>>  will be a good idea.
>>
>>     But it's possible that what you mean by "simulation studies" is
>>  different.
>>
>>     If you can do some benchmarking of your problems on an existing
>>  machine that would probably be a good idea.
>
> Unfortunately unless it is of very similar architecture that may not help 
> much.
>
> Three issues hard to scale from are the 'Turbo', the hyperthreading of modern 
> Xeons and the cache sizes.  Now, I happen to have machines with multiple 
> E5-24x0 and E5-26x0 Xeons: both do hyperthreading well, so you would have 8 
> or 16 virtual CPUs and they will give you say 50% increase in throughput if 
> all the virtual cores are used.  But you cannot scale up from using just one 
> process on one core.
>
> I find it hard to think of tasks where option 1) would have more throughput, 
> but if most of the time you are not running things in parallel then the 
> higher speed on a single task is a consideration.
>
>>
>>     Ben Bolker
>>
>>  ______________________________________________
>>  R-help at r-project.org mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>  PLEASE do read the posting guide
>>  http://www.R-project.org/posting-guide.html
>>  and provide commented, minimal, self-contained, reproducible code.
>> 
>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From samuel.k at gmx.de  Mon Sep 15 17:30:26 2014
From: samuel.k at gmx.de (Samuel Knapp)
Date: Mon, 15 Sep 2014 17:30:26 +0200
Subject: [R] Bug in rep() function
Message-ID: <54170612.1080905@gmx.de>

Dear all,

I have discovered a bug in the standard rep() function: At certain 
values, rep() does not replicate the element by the proper number of times:

 > a <- (1-0.9)*100
 > a
[1] 10
 > length(rep(1,times=a))
[1] 9
 > length(rep(1,each=a))
[1] 9

As shown, this happens as well for the times= as for the each= 
parameter. It does not depend on the kind of element that is to be repeated:

 > length(rep("abc",each=a))
[1] 9

I tried to narrow down the bug, but haven't really managed to find a 
pattern behind the bug. Here is a list with values for a (see above) 
that returns a false object ( after the value for a, i've collected the 
expected length and the length that is produced by r):

# mistake at
(1-0.9)*100       10           9
(1-0.8)*100       20          19
(1-0.8)*1000      200       199
(1-0.9)*1000      100       99
(1-0.9)*10            1         0
(1-0.8)*10            2         1
(1-0.9)*1000000000      100000000       99999999
(2-1-0.9)*100         10      9
(10/10-0.9)*100     10      9

# the following sets for a work fine
(1+0.1)*100
(1-0.1)*100
(1-0.7)*100
(1-0.99)*1000
(1-0.7)*10
(1-0.90)*10
(1-0.95)*100
(1-0.95)*1000
(2-0.9)*1000
(2-1.9)*100
(1.1-1)*100
(10-9)*100

Did I make any mistake? Or where else should I address this problem?

Thanks and best regards,
Samuel


From schuttesebastian at gmail.com  Mon Sep 15 16:30:07 2014
From: schuttesebastian at gmail.com (Sebastian Schutte)
Date: Mon, 15 Sep 2014 16:30:07 +0200
Subject: [R] spatstat rmh problem
Message-ID: <5416F7EF.6070502@gmail.com>

Dear R and spatstat developers,

Thanks so much for the time and effort that you invest into this awesome 
software. I have a problem simulating from a Point Process Model in 
spatstat. In summary, the option "new.coef" should allow me to use a 
fitted model and change its beta coefficients before simulating a point 
pattern from the model via Monte Carlo simulation. Intuitively, one 
would assume that the predicted point pattern changes as one fiddles 
with the beta coefficients. However, this does not seem to work.

Please let me know what I am missing here and which screw to drive to 
actually change the simulation output.

#owin is a polygon of country boundaries, "im.pop" is a raster with 
georeferenced population counts.
#I am using a random point pattern for demonstration purposes

#Fix random seed
set.seed(12345)
#Generate artificial points
dat <- rpoint(500,win=cshape)
#Fit a (inhomogenous spatial poisson) model to the data
mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
#Simulate some points:
plot(density(rmh(mod)))
#plot(density(simulate(mod)))
#Show that this is reproducible
set.seed(12345)
#Generate artificial points
dat <- rpoint(500,win=cshape)
#Fit a (inhomogenous spatial poisson) model to the data
mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
#Simulate some points:
plot(density(rmh(mod)))
#As expected, the density is the same

#Now change the coefs and do it again:
set.seed(12345)
#Generate artificial points
dat <- rpoint(500,win=cshape)
#Fit a (inhomogenous spatial poisson) model to the data
mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
#Simulate some points:
plot(density(rmh(mod),new.coef=c(1,200)))
#Looks the same, so what am I missing?

Thanks for your help,
Sebastian


From jonathan.p.anspach at intel.com  Mon Sep 15 16:45:24 2014
From: jonathan.p.anspach at intel.com (Anspach, Jonathan P)
Date: Mon, 15 Sep 2014 14:45:24 +0000
Subject: [R] Building R for better performance
In-Reply-To: <CAFDcVCQ_=bhKYPMYgRrZ7pEEHQ4-Vey2-YvsA_K0NL2NCZXTtg@mail.gmail.com>
References: <9EB21FFA75EC13438CA12AD2A022D8CC2E9C5565@ORSMSX104.amr.corp.intel.com>
	<87430F4E-90CE-4A20-87D0-EFBBE293FB9C@uni-bonn.de>
	<9EB21FFA75EC13438CA12AD2A022D8CC2E9C5A6F@ORSMSX104.amr.corp.intel.com>
	<5410B719.7030706@yahoo.co.uk>
	<CAK1hC9utTPpzQYhmdoPQwvmomJJ01cBrOd+6dyoY3p-oBaS8zw@mail.gmail.com>
	<47EDA395-0BA9-4D0A-8B7D-EC48D25FADA1@intel.com>
	<CAFDcVCQ_=bhKYPMYgRrZ7pEEHQ4-Vey2-YvsA_K0NL2NCZXTtg@mail.gmail.com>
Message-ID: <9EB21FFA75EC13438CA12AD2A022D8CC2EA8A4D3@ORSMSX104.amr.corp.intel.com>

All,

I?ve attached the actual benchmark TACC and I used.  I?ve also attached a paper I wrote covering this in a little more detail.  The paper specifies the hardware configuration I used.  Let me know if you have any other questions.

Regards,
Jonathan Anspach
Sr. Software Engineer
Intel Corp.
jonathan.p.anspach at intel.com<mailto:jonathan.p.anspach at intel.com>
713-751-9460

From: henrik.bengtsson at gmail.com [mailto:henrik.bengtsson at gmail.com] On Behalf Of Henrik Bengtsson
Sent: Thursday, September 11, 2014 9:18 AM
To: Anspach, Jonathan P
Cc: arnaud gaboury; r-help at r-project.org
Subject: Re: [R] Building R for better performance


You'll find R-benchmark-25.R, which I assume is the same and the proper pointer to use, at http://<http://r.research.att.com/benchmarks/>r.research.att.com<http://r.research.att.com/benchmarks/>/benchmarks/<http://r.research.att.com/benchmarks/>

Henrik
I'm out of the office today, but will resend it tomorrow.

Jonathan Anspach
Intel Corp.

Sent from my mobile phone.

On Sep 11, 2014, at 3:49 AM, "arnaud gaboury" <arnaud.gaboury at gmail.com<mailto:arnaud.gaboury at gmail.com>> wrote:

>>> I got the benchmark script, which I've attached, from Texas Advanced
>>> Computing Center.  Here are my results (elapsed times, in secs):
>
>
> Where can we get the benchmark script?

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From sarah.goslee at gmail.com  Mon Sep 15 18:32:49 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 15 Sep 2014 12:32:49 -0400
Subject: [R] Bug in rep() function
In-Reply-To: <54170612.1080905@gmx.de>
References: <54170612.1080905@gmx.de>
Message-ID: <CAM_vjukCmxXhCSWJwd+tUtcTGyXoSRQ5V2QJtFfZV8+T+=sQuA@mail.gmail.com>

No, actually you've discovered FAQ 7.31.

> a <- (1-0.9)*100
> a
[1] 10
> print(a, digits=20)
[1] 9.9999999999999982236

In combination with the description in ?rep:
     Non-integer values of ?times? will be truncated towards zero.  If
     ?times? is a computed quantity it is prudent to add a small fuzz.

you get 9 times.

The best thing to do is ensure that your values are integer *before*
passing them to rep(), unless you know that truncating toward zero is
the right thing to do.

Sarah

On Mon, Sep 15, 2014 at 11:30 AM, Samuel Knapp <samuel.k at gmx.de> wrote:
> Dear all,
>
> I have discovered a bug in the standard rep() function: At certain values,
> rep() does not replicate the element by the proper number of times:
>
>> a <- (1-0.9)*100
>> a
> [1] 10
>> length(rep(1,times=a))
> [1] 9
>> length(rep(1,each=a))
> [1] 9
>
> As shown, this happens as well for the times= as for the each= parameter. It
> does not depend on the kind of element that is to be repeated:
>
>> length(rep("abc",each=a))
> [1] 9
>
> I tried to narrow down the bug, but haven't really managed to find a pattern
> behind the bug. Here is a list with values for a (see above) that returns a
> false object ( after the value for a, i've collected the expected length and
> the length that is produced by r):
>
> # mistake at
> (1-0.9)*100       10           9
> (1-0.8)*100       20          19
> (1-0.8)*1000      200       199
> (1-0.9)*1000      100       99
> (1-0.9)*10            1         0
> (1-0.8)*10            2         1
> (1-0.9)*1000000000      100000000       99999999
> (2-1-0.9)*100         10      9
> (10/10-0.9)*100     10      9
>
> # the following sets for a work fine
> (1+0.1)*100
> (1-0.1)*100
> (1-0.7)*100
> (1-0.99)*1000
> (1-0.7)*10
> (1-0.90)*10
> (1-0.95)*100
> (1-0.95)*1000
> (2-0.9)*1000
> (2-1.9)*100
> (1.1-1)*100
> (10-9)*100
>
> Did I make any mistake? Or where else should I address this problem?
>
> Thanks and best regards,
> Samuel
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ripley at stats.ox.ac.uk  Mon Sep 15 18:36:42 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Sep 2014 17:36:42 +0100
Subject: [R] Bug in rep() function
In-Reply-To: <54170612.1080905@gmx.de>
References: <54170612.1080905@gmx.de>
Message-ID: <5417159A.8050606@stats.ox.ac.uk>

On 15/09/2014 16:30, Samuel Knapp wrote:
> Dear all,
>
> I have discovered a bug in the standard rep() function: At certain

Not so:

 > a <- (1-0.9)*100
 > trunc(a)
[1] 9

As the help says

      Non-integer values of ?times? will be truncated towards zero.  If
      ?times? is a computed quantity it is prudent to add a small fuzz.

And as the posting guide said

Do your homework before posting:
...
     Read the online help for relevant functions (type ?functionname, 
e.g., ?prod, at the R prompt)


> values, rep() does not replicate the element by the proper number of times:
>
>  > a <- (1-0.9)*100
>  > a
> [1] 10
>  > length(rep(1,times=a))
> [1] 9
>  > length(rep(1,each=a))
> [1] 9
>
> As shown, this happens as well for the times= as for the each=
> parameter. It does not depend on the kind of element that is to be
> repeated:
>
>  > length(rep("abc",each=a))
> [1] 9
>
> I tried to narrow down the bug, but haven't really managed to find a
> pattern behind the bug. Here is a list with values for a (see above)
> that returns a false object ( after the value for a, i've collected the
> expected length and the length that is produced by r):
>
> # mistake at
> (1-0.9)*100       10           9
> (1-0.8)*100       20          19
> (1-0.8)*1000      200       199
> (1-0.9)*1000      100       99
> (1-0.9)*10            1         0
> (1-0.8)*10            2         1
> (1-0.9)*1000000000      100000000       99999999
> (2-1-0.9)*100         10      9
> (10/10-0.9)*100     10      9
>
> # the following sets for a work fine
> (1+0.1)*100
> (1-0.1)*100
> (1-0.7)*100
> (1-0.99)*1000
> (1-0.7)*10
> (1-0.90)*10
> (1-0.95)*100
> (1-0.95)*1000
> (2-0.9)*1000
> (2-1.9)*100
> (1.1-1)*100
> (10-9)*100
>
> Did I make any mistake? Or where else should I address this problem?
>
> Thanks and best regards,
> Samuel
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From ggrothendieck at gmail.com  Mon Sep 15 18:42:27 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 15 Sep 2014 12:42:27 -0400
Subject: [R] Using sqldf() to read in .fwf files
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686B638C9C5@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686B638C9C5@DC1VEX10MB001.air.org>
Message-ID: <CAP01uRk-EM9gqSmDyL-B9udkVx72criKea_W_kMVUWDjXaoTjw@mail.gmail.com>

On Mon, Sep 15, 2014 at 12:09 PM, Doran, Harold <HDoran at air.org> wrote:
> I am learning to use sqldf() to read in very large fixed width files that otherwise do not work efficiently with read.fwf. I found the following example online and have worked with this in various ways to read in the data
>
> cat("1 8.3
> 210.3
> 319.0
> 416.0
> 515.6
> 719.8
> ", file = "fixed")
>
> fixed <- file("fixed")
> sqldf("select substr(V1, 1, 1) f1, substr(V1, 2, 4) f2 from fixed")
>
> I then applied this to my real world data problem though it yields the following error message and I am not sure how to interpret this.
>
> dor <- file("dor")
>> sqldf("select substr(V1, 1, 1) f1, substr(V1, 2, 4) f2 from dor")
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   line 1 did not have 6 elements
>
> Looking at my .fwf. data in a text editor shows the data are structured as I would expect. In fact, I can read in the first few lines of the file using read.fwf and the data are as I would expect after being read into R.
>

We want it to regard the entire line as one field so specify sep= as
some character not in the file.

    attr(fixed, "file.format") <- list(sep = ";")


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From HDoran at air.org  Mon Sep 15 21:23:40 2014
From: HDoran at air.org (Doran, Harold)
Date: Mon, 15 Sep 2014 19:23:40 +0000
Subject: [R] Using sqldf() to read in .fwf files
In-Reply-To: <CAP01uRk-EM9gqSmDyL-B9udkVx72criKea_W_kMVUWDjXaoTjw@mail.gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686B638C9C5@DC1VEX10MB001.air.org>
	<CAP01uRk-EM9gqSmDyL-B9udkVx72criKea_W_kMVUWDjXaoTjw@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686B638CCCB@DC1VEX10MB001.air.org>

Thank you, Gabor. This has seemingly resolved the issue. Perhaps a quick follow up. Suppose I know that the 1st variable I am reading in is to be numeric and the second is character. Can that be specified in the substr() argument?

sqldf("select substr(V1, 1, 1) f1, substr(V1, 2, 4) f2 from fixed")

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Monday, September 15, 2014 12:42 PM
To: Doran, Harold
Cc: r-help at r-project.org
Subject: Re: [R] Using sqldf() to read in .fwf files

On Mon, Sep 15, 2014 at 12:09 PM, Doran, Harold <HDoran at air.org> wrote:
> I am learning to use sqldf() to read in very large fixed width files 
> that otherwise do not work efficiently with read.fwf. I found the 
> following example online and have worked with this in various ways to 
> read in the data
>
> cat("1 8.3
> 210.3
> 319.0
> 416.0
> 515.6
> 719.8
> ", file = "fixed")
>
> fixed <- file("fixed")
> sqldf("select substr(V1, 1, 1) f1, substr(V1, 2, 4) f2 from fixed")
>
> I then applied this to my real world data problem though it yields the following error message and I am not sure how to interpret this.
>
> dor <- file("dor")
>> sqldf("select substr(V1, 1, 1) f1, substr(V1, 2, 4) f2 from dor")
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   line 1 did not have 6 elements
>
> Looking at my .fwf. data in a text editor shows the data are structured as I would expect. In fact, I can read in the first few lines of the file using read.fwf and the data are as I would expect after being read into R.
>

We want it to regard the entire line as one field so specify sep= as some character not in the file.

    attr(fixed, "file.format") <- list(sep = ";")


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

From ggrothendieck at gmail.com  Mon Sep 15 21:35:13 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 15 Sep 2014 15:35:13 -0400
Subject: [R] Using sqldf() to read in .fwf files
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686B638CCCB@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686B638C9C5@DC1VEX10MB001.air.org>
	<CAP01uRk-EM9gqSmDyL-B9udkVx72criKea_W_kMVUWDjXaoTjw@mail.gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686B638CCCB@DC1VEX10MB001.air.org>
Message-ID: <CAP01uRmG5CW6wHf5-u3G46Cx6bxxJ-=no40APSM4ULgSyfGTjw@mail.gmail.com>

On Mon, Sep 15, 2014 at 3:23 PM, Doran, Harold <HDoran at air.org> wrote:
> Thank you, Gabor. This has seemingly resolved the issue. Perhaps a quick follow up. Suppose I know that the 1st variable I am reading in is to be numeric and the second is character. Can that be specified in the substr() argument?
>
> sqldf("select substr(V1, 1, 1) f1, substr(V1, 2, 4) f2 from fixed")
>

Cast the numeric field to real:
   select  cast(substr(V1, 1, 1) as real)  ...


From dcarlson at tamu.edu  Mon Sep 15 21:57:32 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 15 Sep 2014 19:57:32 +0000
Subject: [R] chi-square test
In-Reply-To: <5417031D.9020801@pitt.edu>
References: <BLU170-W133B5AF83C06FE34FFFDB4889C80@phx.gbl>
	<5417031D.9020801@pitt.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F97CF1@mb02.ads.tamu.edu>

Rick's question is a good one. It is unlikely that the results will be informative, but from a technical standpoint, you can estimate the p value using the simulate.p.value=TRUE argument to chisq.test().

> chisq.test(TT, simulate.p.value=TRUE)

        Pearson's Chi-squared test with simulated p-value (based on 2000
        replicates)

data:  TT
X-squared = 7919.632, df = NA, p-value = 0.0004998

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rick Bilonick
Sent: Monday, September 15, 2014 10:18 AM
To: r-help at r-project.org
Subject: Re: [R] chi-square test

On 09/15/2014 10:57 AM, eliza botto wrote:
> Dear useRs of R,
> I have two datasets (TT and SS) and i wanted to to see if my data is uniformly distributed or not?I tested it through chi-square test and results are given at the end of it.Now apparently P-value has a significant importance but I cant interpret the results and why it says that "In chisq.test(TT) : Chi-squared approximation may be incorrect"
> ###############################################################
>> dput(TT)
> structure(list(clc5 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.26, 0.14, 0, 0.44, 0.26, 0, 0, 0, 0, 0, 0, 0.11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.17, 0.16, 0.56, 0, 1.49, 0, 0.64, 0.79, 0.66, 0, 0, 0.17, 0, 0, 0, 0, 0.56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.43, 0.41, 0, 0.5, 0.44, 0, 0, 0, 0, 0.09, 0.46, 0, 0.27, 0.45, 0.15, 0.31, 0.16, 0.44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.07, 0, 0, 0, 0, 0, 0.06, 0, 0.09, 0.07, 0, 0, 7.89, 0, 0.22, 0.29, 0.33, 0.27, 0, 0.36, 0.41, 0, 0, 0, 0, 0.55, 0.81, 0, 0.09, 0.13, 0.28, 0, 0, 0), quota_massima = c(1167L, 1167L, 4572L, 3179L, 3141L, 585L, 585L, 876L, 876L, 1678L, 2667L, 1369L, 1369L, 1369L, 1381L, 1381L, 1381L, 1381L, 2284L, 410L, 2109L, 2507L, 2579L, 2507L, 1436L, 3234L, 3234L, 3234L, 3234L, 2792L, 2569L, 2569L, 2569L, 1669L, 4743L, 4743L, 4743L, 3403L, 3197L, 3267L, 3583L, 3583L, 3583L, 2584L, 2584L, 2579L, 1241L, 1241L, 4174L, 3006L, 3197L, 2366L, 2618L, 2670L, 4487L, 3196L, 3196L, 2107L, 2107L, 2427L, 1814L, 2622L, 1268L, 1268L, 1268!
 L,!
>    3885L, 3885L, 3092L, 3234L, 2625L, 2625L, 3760L, 4743L, 3707L, 3760L, 4743L, 3760L, 3885L, 3760L, 4743L, 2951L, 782L, 2957L, 3343L, 2697L, 2697L, 3915L, 2277L, 1678L, 1678L, 3197L, 2957L, 2957L, 2957L, 4530L, 4530L, 4530L, 2131L, 3618L, 3618L, 3335L, 2512L, 2390L, 1616L, 3526L, 3197L, 3197L, 2625L, 2622L, 3197L, 3197L, 2622L, 2622L, 2622L, 368L, 4572L, 3953L, 863L, 3716L, 3716L, 3716L, 2697L, 2697L, 1358L)), .Names = c("clc5", "quota_massima"), class = "data.frame", row.names = c(NA, -124L))
>
>>   chisq.test(TT)
>          Pearson's Chi-squared test
> data:  TT
> X-squared = 411.5517, df = 123, p-value < 2.2e-16
> Warning message:
> In chisq.test(TT) : Chi-squared approximation may be incorrect
> #######################################################################
>> dput(SS)
> structure(list(NDVIanno = c(0.57, 0.536, 0.082, 0.262, 0.209, 0.539, 0.536, 0.543, 0.588, 0.599, 0.397, 0.63, 0.616, 0.644, 0.579, 0.597, 0.617, 0.622, 0.548, 0.528, 0.541, 0.436, 0.509, 0.467, 0.534, 0.412, 0.324, 0.299, 0.41, 0.462, 0.427, 0.456, 0.508, 0.581, 0.242, 0.291, 0.324, 0.28, 0.291, 0.305, 0.365, 0.338, 0.399, 0.516, 0.357, 0.558, 0.605, 0.638, 0.191, 0.377, 0.325, 0.574, 0.458, 0.426, 0.188, 0.412, 0.464, 0.568, 0.582, 0.494, 0.598, 0.451, 0.577, 0.572, 0.602, 0.321, 0.38, 0.413, 0.427, 0.55, 0.437, 0.481, 0.425, 0.234, 0.466, 0.464, 0.491, 0.463, 0.489, 0.435, 0.267, 0.564, 0.256, 0.156, 0.476, 0.498, 0.122, 0.508, 0.582, 0.615, 0.409, 0.356, 0.284, 0.285, 0.444, 0.303, 0.478, 0.557, 0.345, 0.408, 0.347, 0.498, 0.534, 0.576, 0.361, 0.495, 0.502, 0.553, 0.519, 0.504, 0.53, 0.547, 0.559, 0.505, 0.557, 0.377, 0.36, 0.613, 0.452, 0.397, 0.277, 0.42, 0.443, 0.62), delta_z = c(211L, 171L, 925L, 534L, 498L, 50L, 53L, 331L, 135L, 456L, 850L, 288L, 286L, 233L, 342L, !
 27!
>   4L, 184L, 198L, 312L, 67L, 476L, 676L, 349L, 873L, 65L, 963L, 553L, 474L, 948L, 1082L, 616L, 704L, 814L, 450L, 865L, 987L, 1265L, 720L, 565L, 652L, 941L, 822L, 1239L, 929L, 477L, 361L, 199L, 203L, 642L, 788L, 818L, 450L, 703L, 760L, 711L, 1015L, 1351L, 195L, 511L, 617L, 296L, 604L, 381L, 389L, 287L, 1043L, 1465L, 963L, 1125L, 582L, 662L, 1424L, 1762L, 575L, 1477L, 1364L, 1236L, 1483L, 1201L, 1644L, 498L, 142L, 510L, 482L, 811L, 788L, 466L, 626L, 461L, 350L, 1177L, 826L, 575L, 568L, 916L, 767L, 1017L, 532L, 1047L, 1370L, 902L, 686L, 703L, 440L, 1016L, 1148L, 1089L, 753L, 650L, 1065L, 568L, 712L, 762L, 636L, 79L, 1092L, 955L, 158L, 1524L, 1145L, 673L, 513L, 596L, 239L)), .Names = c("NDVIanno", "delta_z"), class = "data.frame", row.names = c(NA, -124L))
>>   chisq.test(SS)
>          Pearson's Chi-squared test
> data:  SS
> X-squared = 72.8115, df = 123, p-value = 0.9999
> Warning message:
> In chisq.test(SS) : Chi-squared approximation may be incorrect
> #####################################################################################
> Kindly guide me through like you always did :)
> thanks in advance,
>
>
> Eliza 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
You are using a Chi-squared test on a 124x2 matrix of values (not all 
integers) and many are zeros. The expected frequencies for many cells 
are very small (near zero, less than 1) hence the warning message. More 
importantly, does this application of the Chi-squared test make sense? 
What am I missing?

Rick

-- 
Richard A. Bilonick, PhD
Assistant Professor
Dept. of Ophthalmology, School of Medicine
Dept. of Biostatistics, Graduate School of Public Health
Dept. of Orthodontics, School of Dental Medicine
University of Pittsburgh
Principal Investigator for the Pittsburgh Aerosol Research
  and Inhalation Epidemiology Study (PARIES)
412 647 5756

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Mon Sep 15 23:20:18 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 15 Sep 2014 16:20:18 -0500
Subject: [R] CoxME: Family relatedness
In-Reply-To: <CANRNCSqpJ11hzyjCnNk2s=Z0gF5rFuxw8dh_F138VJj4K=cCXQ@mail.gmail.com>
References: <CANRNCSqpJ11hzyjCnNk2s=Z0gF5rFuxw8dh_F138VJj4K=cCXQ@mail.gmail.com>
Message-ID: <58e5f6$im6kba@ironport9.mayo.edu>

I would have caught this tomorrow (I read the digest).
Some thoughts:

1. Skip the entire step of subsetting the death.kmat object.  The coxme function knows how 
to do this on its own, and is more likely to get it correct.  My version of your code would be
   deathdat.kmat <- 2* with(deathdat, makekinship(famid, id, faid, moid))
   model3 <- coxme(Surv(Survival, Event) ~ Sex + strata(cohort) + SNP1 + SNP2 + SNP3 + (1|id),
                 data=death.dat, varlist=deathdat.kmat)


This all assumes that the "id" variable is unique.  If family 3 and family 4 both have an 
id of "1", then the coxme call can't match up rows in the data to rows/cols in the kinship 
matrix uniquely.  But that is simple to fix.
The kinship matrix K has .5 on the diagonal, by definition, but when used as a correlation 
most folks prefer to use 2K.  (This causes mixups since some software adds the "2" for 
you, but coxme does not.)

2. The model above is the correct covariance structure for a set of families.  There is a 
single intercept per subject, with a complex correlation matrix.  The simpler "per family" 
frailty model would be

     model4 <- coxme(Surv(Survival, Event) ~ Sex + strata(cohort) + SNP1 + SNP2 + SNP3 + 
(1|famid), death.dat)

This model lets each family have a separate risk, with everyone in the same family sharing 
the exact same risk.  It is less general than model3 above which lets a family have higher 
risk plus has variation between family members.

A model with both per-subject and per family terms is identical to one with a covariance 
matrix of s1 K + s2 B, where K is the kinship matrix, B is a block diagonal matrix which 
has a solid block of "1" for each family, and s1 s2 are the fitted variance coefficients.

   I don't find this intuitive, but have seen the argument that "B" is a shared 
environmental effect.  (Perhaps because I have large family trees where they do not all 
live together).  If you want such a model:
    model5 <- coxme(...... + (1|id) + (1|famid), death.dat, varlist=deathdat.kmat)

(When the varlist is too short the program uses the default for remaining terms).

3. To go further you will need to tell us what you are trying to model, as math formulas 
not as R code.

4. The error messages you got would more properly read "I'm confused" on the part of the 
program.  They cases of something I would never do, so never got that message.  Therefore 
useful for me to see.  Continuous variables go to the left of the | and categoricals to 
the right of the |.  Having a family id to the left makes no sense at all.

Terry Therneau


On 09/15/2014 03:20 PM, Marie Dogherty wrote:
> Dr. Therneau,
>
> I was wondering if you had a spare minute, if you could view a post in the R forum:
>
> http://r.789695.n4.nabble.com/CoxME-family-relatedness-td4696976.html
>
> I would appreciate it, I'm stuck and out of ideas!
>
> Many thanks
>
> Marie.

-----------Original post ----------

Hello all,

I have a table like this, with ~300 individuals:

Famid Id  Faid Moid Cohort  Sex  Survival Event SNP1 SNP2 SNP3

1    1    0    0    0    0    10   1    0    1    0

2    2    0    0    1    1    20   1    0    0    0

2    3    0    0    0    0    25   1    0    1    0

4    5    1    2    0    0    35   1    0    1    1

4    6    1    2    0    0    35   0    1    0    1



famid=family id, id=id of person,faid=father id,moid=mother id.

My question of interest: What impact does SNP1/SNP2/SNP3 have on survival of individuals 
(Id), after accounting for possible effects due to family relatedness (Famid).

So I want to account for family-specific frailty effects, and individual frailty effects 
according to degree of relationship between individuals.

The commands I've used are from this paper: http://www.ncbi.nlm.nih.gov/pubmed/21786277

Library(survival)
Library(coxme)
Library(kinship2)
Library(bdsmatrix)

Death.dat <-read.table(?Table?,header=T)

#Make a kinship matrix for the whole study
deathdat.kmat 
<-makekinship(famid=death.dat$famid,id=death.dat$id,father=death.dat$faid,mother=death.dat$moid)

##omit linker individuals with no phenotypic data, used only to ##properly specify the 
pedigree when calculating kinship ##coefficints:
death.dat1<-subset(death.dat,!is.na(Survival))

##temp is an array with the indices of the individuals with Survival years:
all <-dimnames(deathdat.kmat)[[1]]
temp <-which(!is.na(death.dat$Survival[match(all,death.dat$id)]))

##kinship matrix for the subset with phenotype Survival:
deathdat1.kmat <-deathdat.kmat[temp,temp]


If I type:

model3 
<-coxme(Surv(Survival,Event)~Sex+strata(Cohort)+SNP1+SNP2+SNP3+(1+id|famid),data=death.dat,varlist=deathdat1.kmat)

I get:

?Error in coxme(Surv(Survival, Event) ~ Sex + strata(Cohort) + SNP1 +  :
   In random term 1: Mlist cannot have both covariates and grouping?


Whereas if I type:

model3 
<-coxme(Surv(Survival,Event)~Sex+strata(Cohort)+SNP1+SNP2+SNP3,(id|famid),data=death.dat1,varlist=deathdat1.kmat)


I get:

Error in coxme(Surv(Survival, Event) ~ Sex + strata(Cohort) + SNP1 +  :
   No observations remain in the data set
In addition: Warning message:
In Ops.factor(id, famid) : | not meaningful for factors


Eventually, I would like to, once I has this piece of code working, use:

famblockf.mat<-bdsBlock(death.dat1$id,death.dat1$famid1)

model4 
<-coxme(Surv(Survival,Event)~Sex+strata(Cohort)+SNP1+SNP2+SNP3,data=death.dat1,id|famid,varlist=list(deathdat1.kmat,famblockf.mat),pdcheck=FALSE)


to account for both family specific frailty effects and individual relatedness between 
families.

If someone could explain the error(s) to me/tell me what I'm doing wrong/suggest the right 
way, I would appreciate it as I'm fairly new to R.

Also, if someone could explain the difference between (id|famid) and (1+id|famid), I'd 
appreciate it. I did both of them with a test, and couldn't see much difference between them.


Thanks.


From r.turner at auckland.ac.nz  Tue Sep 16 00:18:52 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 16 Sep 2014 10:18:52 +1200
Subject: [R] spatstat rmh problem
In-Reply-To: <5416F7EF.6070502@gmail.com>
References: <5416F7EF.6070502@gmail.com>
Message-ID: <541765CC.2070507@auckland.ac.nz>


Your example is not reproducible.  We don't have "cshape" or "im.pop" 
(and are possibly lacking other bits and pieces; I didn't check the 
details since the example fails to run from the get-go).  Please provide 
a *reproducible* example.

Also I am puzzled by the line

> mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))

Did you mean

> mod <- ppm (dat, ~  pop ,  covariates = list (pop = im.pop))

???

Also please note that with versions of spatstat later than or equal to 
1.37-0 you can write

     ppm(dat ~ im.pop)

when the object "im.pop" is present in the global environment.

cheers,

Rolf Turner

On 16/09/14 02:30, Sebastian Schutte wrote:
> Dear R and spatstat developers,
>
> Thanks so much for the time and effort that you invest into this awesome
> software. I have a problem simulating from a Point Process Model in
> spatstat. In summary, the option "new.coef" should allow me to use a
> fitted model and change its beta coefficients before simulating a point
> pattern from the model via Monte Carlo simulation. Intuitively, one
> would assume that the predicted point pattern changes as one fiddles
> with the beta coefficients. However, this does not seem to work.
>
> Please let me know what I am missing here and which screw to drive to
> actually change the simulation output.
>
> #owin is a polygon of country boundaries, "im.pop" is a raster with
> georeferenced population counts.
> #I am using a random point pattern for demonstration purposes
>
> #Fix random seed
> set.seed(12345)
> #Generate artificial points
> dat <- rpoint(500,win=cshape)
> #Fit a (inhomogenous spatial poisson) model to the data
> mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
> #Simulate some points:
> plot(density(rmh(mod)))
> #plot(density(simulate(mod)))
> #Show that this is reproducible
> set.seed(12345)
> #Generate artificial points
> dat <- rpoint(500,win=cshape)
> #Fit a (inhomogenous spatial poisson) model to the data
> mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
> #Simulate some points:
> plot(density(rmh(mod)))
> #As expected, the density is the same
>
> #Now change the coefs and do it again:
> set.seed(12345)
> #Generate artificial points
> dat <- rpoint(500,win=cshape)
> #Fit a (inhomogenous spatial poisson) model to the data
> mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
> #Simulate some points:
> plot(density(rmh(mod),new.coef=c(1,200)))
> #Looks the same, so what am I missing?

-- 
Rolf Turner
Technical Editor ANZJS


From samuel.k at gmx.de  Mon Sep 15 19:12:20 2014
From: samuel.k at gmx.de (Samuel Knapp)
Date: Mon, 15 Sep 2014 19:12:20 +0200
Subject: [R] Bug in rep() function
In-Reply-To: <5417159A.8050606@stats.ox.ac.uk>
References: <54170612.1080905@gmx.de> <5417159A.8050606@stats.ox.ac.uk>
Message-ID: <54171DF4.40304@gmx.de>

Thank you.
I got the point with non-integer values in rep(). I also red FAQ 7.3:
"The only numbers that can be represented exactly in R?s numeric type 
are integers and fractions whose denominator is a power of 2."

But then I still don't understand:

 > for (b in seq(0.2,0.8,0.2))
+ {
+   a <- (1-b)*10
+
+   print(1-b,digits=20)
+   print(a,digits=22)
+   print(trunc(a))
+   print("///////")
+ }
[1] 0.80000000000000004441
[1] 8
[1] 8
[1] "///////"
[1] 0.5999999999999999778
[1] 6
[1] 6
[1] "///////"
[1] 0.39999999999999991118
[1] 3.999999999999999111822
[1] 3
[1] "///////"
[1] 0.19999999999999995559
[1] 1.999999999999999555911
[1] 1
[1] "///////"

Why are the first two yielding an integer after multiplying, and the 
last two don't? Apparently, c(0.8,0.6,0.4,0.2) can't be represented exactly.

What would be your approach? Always round numbers first, before giving 
them to rep() ?

Thanks,
Samuel

On 15.09.2014 18:36, Prof Brian Ripley wrote:
> On 15/09/2014 16:30, Samuel Knapp wrote:
>> Dear all,
>>
>> I have discovered a bug in the standard rep() function: At certain
>
> Not so:
>
> > a <- (1-0.9)*100
> > trunc(a)
> [1] 9
>
> As the help says
>
>      Non-integer values of ?times? will be truncated towards zero.  If
>      ?times? is a computed quantity it is prudent to add a small fuzz.
>
> And as the posting guide said
>
> Do your homework before posting:
> ...
>     Read the online help for relevant functions (type ?functionname, 
> e.g., ?prod, at the R prompt)
>
>
>> values, rep() does not replicate the element by the proper number of 
>> times:
>>
>>  > a <- (1-0.9)*100
>>  > a
>> [1] 10
>>  > length(rep(1,times=a))
>> [1] 9
>>  > length(rep(1,each=a))
>> [1] 9
>>
>> As shown, this happens as well for the times= as for the each=
>> parameter. It does not depend on the kind of element that is to be
>> repeated:
>>
>>  > length(rep("abc",each=a))
>> [1] 9
>>
>> I tried to narrow down the bug, but haven't really managed to find a
>> pattern behind the bug. Here is a list with values for a (see above)
>> that returns a false object ( after the value for a, i've collected the
>> expected length and the length that is produced by r):
>>
>> # mistake at
>> (1-0.9)*100       10           9
>> (1-0.8)*100       20          19
>> (1-0.8)*1000      200       199
>> (1-0.9)*1000      100       99
>> (1-0.9)*10            1         0
>> (1-0.8)*10            2         1
>> (1-0.9)*1000000000      100000000       99999999
>> (2-1-0.9)*100         10      9
>> (10/10-0.9)*100     10      9
>>
>> # the following sets for a work fine
>> (1+0.1)*100
>> (1-0.1)*100
>> (1-0.7)*100
>> (1-0.99)*1000
>> (1-0.7)*10
>> (1-0.90)*10
>> (1-0.95)*100
>> (1-0.95)*1000
>> (2-0.9)*1000
>> (2-1.9)*100
>> (1.1-1)*100
>> (10-9)*100
>>
>> Did I make any mistake? Or where else should I address this problem?
>>
>> Thanks and best regards,
>> Samuel
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From felixdietrich87 at googlemail.com  Mon Sep 15 20:17:56 2014
From: felixdietrich87 at googlemail.com (Felix Dietrich)
Date: Mon, 15 Sep 2014 20:17:56 +0200
Subject: [R] Quantile
Message-ID: <6EF22425-9CBC-460B-903B-4ED10C6D2203@gmail.com>

Hi, I want to use the quantile function, the example shown under "help"

x <- rnorm(1001)
quantile(x <- rnorm(1001)) # Extremes & Quartiles by default
quantile(x,  probs = c(0.1, 0.5, 1, 2, 5, 10, 50, NA)/100)

I get the following error:
Error in quantile(x, probs = c(0.1, 0.5, 1, 2, 5, 10, 50, NA)/100) : 
  unused argument (probs = c(0.1, 0.5, 1, 2, 5, 10, 50, NA)/100)

The argument probs does not seems to work. I tried many other variations. Does anybody have an idea?

Thanks, Felix

From rgentlem at gmail.com  Mon Sep 15 18:36:17 2014
From: rgentlem at gmail.com (Robert Gentleman)
Date: Mon, 15 Sep 2014 09:36:17 -0700
Subject: [R] Updates to R Core and R Foundation Membership
Message-ID: <CAGYbZUDSY-uh7svf4QO4=F8xgvsCHLshCEUuD7adfgdbNnRYDg@mail.gmail.com>

Hi all,
  It is my pleasure to announce new members to R Core and to the R
Foundation
 whose efforts will be most appreciated as R continues to evolve and
advance.

    There are 2 new R core members:  Martin Morgan and Michael Lawrence.
    In addition Stefano Iacus has decided to step down from R Core.

   There are 7 new R foundation members:
  Dirk Eddelbuettel, Torsten Hothorn, Marc Schwartz,
  Hadley Wickham, and Achim Zeileis, Martin Morgan and Michael Lawrence.
  The R Foundation now has 29 ordinary members.

  Please join me in welcoming them to their new roles and especially in
thanking
 Stefano for his many years of contributions.


  best wishes
    Robert

 for the R Foundation

-- 
Robert Gentleman
rgentlem at gmail.com

	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From aparna.eco04 at gmail.com  Mon Sep 15 21:40:37 2014
From: aparna.eco04 at gmail.com (Aparna)
Date: Mon, 15 Sep 2014 14:40:37 -0500
Subject: [R] Efficient frontier
Message-ID: <5A52AC39-612B-40C9-AEBE-753BA8309136@gmail.com>

Hi I need help for plotting efficient frontier, I have expected return and covariance matrix. I am using tseries and downloaded portfolio package too. The suggestion says to use efficient.frontier, but it looks you replaces it by something in R 3.1.1 as it says this is not available. At current R version, what is the way to draw efficient frontier? 

Sent from my iPad

From hmorenor at uwyo.edu  Tue Sep 16 01:20:01 2014
From: hmorenor at uwyo.edu (Hernan A. Moreno Ramirez)
Date: Mon, 15 Sep 2014 23:20:01 +0000
Subject: [R] ncdf size error
Message-ID: <338322FF-7ADA-48DC-BC76-47AF0BEE042A@uwyo.edu>


Hi I am using both ncdf and ncdf4 libraries and with both I keep getting the
same error: Error in R_nc_enddef: NetCDF: One or more variable sizes violate
format constraints. Error in R_nc_sync: NetCDF: Operation not allowed in
define mode. This happens when I try to create.ncdf() a file with more than
13 variables. I think is a problem of memory size. What would you recommend?
Any help will be appreciated,.
Sent from my iPhone


From m.heidari.b at gmail.com  Tue Sep 16 02:11:29 2014
From: m.heidari.b at gmail.com (Maryam Heidari)
Date: Mon, 15 Sep 2014 19:11:29 -0500
Subject: [R] Fwd: the properties of a DATA to run DBSCAN in R
In-Reply-To: <CAJ4Akz9pxUOBG7KLW-jKg6Y-Oj9RsO5N5MoYryBLLnLw=CbG4Q@mail.gmail.com>
References: <CAJ4Akz9pxUOBG7KLW-jKg6Y-Oj9RsO5N5MoYryBLLnLw=CbG4Q@mail.gmail.com>
Message-ID: <CAJ4Akz8hutE5aWj1VWMh_5ZsUa9+-DAof_Ky55MZxUE+1ZWtcA@mail.gmail.com>

hello everybody,

I have been trying to run "dbscan" algorithm on my data, my data round
40000 records which each of them has 3 attributes + plus the ID for each
record.
the interesting thing is that when I run the "dbscan just on 3 attributes"
R gives me an ERROR regarding "stackoverflow" but when I run it including
the 4 attributes it runs with out any problem.
so is the problem with my data?!

this is statistics about my data
   att1                           att2                                att3
 Min.   :0.00000      Min.   :0.000000       Min.   :0.000000
 1st Qu.:0.01429    1st Qu.:0.000000     1st Qu.:0.000000
 Median :0.02857    Median :0.000000   Median :0.000000
 Mean   :0.02764    Mean   :0.001135    Mean   :0.000477
 3rd Qu.:0.02857    3rd Qu.:0.000000    3rd Qu.:0.000000
 Max.   :1.00000      Max.   :1.000000     Max.   :1.000000

	[[alternative HTML version deleted]]


From dpierce at ucsd.edu  Tue Sep 16 03:00:45 2014
From: dpierce at ucsd.edu (David W. Pierce)
Date: Mon, 15 Sep 2014 18:00:45 -0700
Subject: [R] ncdf size error
In-Reply-To: <338322FF-7ADA-48DC-BC76-47AF0BEE042A@uwyo.edu>
References: <338322FF-7ADA-48DC-BC76-47AF0BEE042A@uwyo.edu>
Message-ID: <CAL+Zad8AnjLMq0VKwj+nbNTEN_DD01RV0T9VneinBW295frNkQ@mail.gmail.com>

On Mon, Sep 15, 2014 at 4:20 PM, Hernan A. Moreno Ramirez
<hmorenor at uwyo.edu> wrote:
>
> Hi I am using both ncdf and ncdf4 libraries and with both I keep getting the
> same error: Error in R_nc_enddef: NetCDF: One or more variable sizes violate
> format constraints. Error in R_nc_sync: NetCDF: Operation not allowed in
> define mode. This happens when I try to create.ncdf() a file with more than
> 13 variables. I think is a problem of memory size. What would you recommend?
> Any help will be appreciated

Hi Hernan,

can you supply an example that shows the problem?

Regards,

--Dave

-------------------
David W. Pierce
Division of Climate, Atmospheric Science, and Physical Oceanography
Scripps Institution of Oceanography, La Jolla, California, USA
(858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu


From dwinsemius at comcast.net  Tue Sep 16 03:16:46 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 15 Sep 2014 18:16:46 -0700
Subject: [R] Quantile
In-Reply-To: <6EF22425-9CBC-460B-903B-4ED10C6D2203@gmail.com>
References: <6EF22425-9CBC-460B-903B-4ED10C6D2203@gmail.com>
Message-ID: <5D03A4C7-358A-4011-AE91-827E96DA1D71@comcast.net>


On Sep 15, 2014, at 11:17 AM, Felix Dietrich wrote:

> Hi, I want to use the quantile function, the example shown under "help"
> 
> x <- rnorm(1001)
> quantile(x <- rnorm(1001)) # Extremes & Quartiles by default
> quantile(x,  probs = c(0.1, 0.5, 1, 2, 5, 10, 50, NA)/100)
> 
> I get the following error:
> Error in quantile(x, probs = c(0.1, 0.5, 1, 2, 5, 10, 50, NA)/100) : 
>  unused argument (probs = c(0.1, 0.5, 1, 2, 5, 10, 50, NA)/100)
> 
> The argument probs does not seems to work. I tried many other variations. Does anybody have an idea?

You have probably already read the responses to the duplicate question you posed on StackOverfow earlier today that said this problem could not be duplicated by anyone who responded, and one leading theory is that you or one of the packages has overwritten the `quantile` function. 

This is what the code shows:

>  quantile
function (x, ...) 
UseMethod("quantile")
<bytecode: 0x10247ddf0>
<environment: namespace:stats>

That may be informative in your case.

Please read the Posting Guide. It asks that you not crosspost. If you post a followup to rhelp, then the reading of the Posting guide will tell you that much more in the way of detail about your setup was requested.

-- 

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Tue Sep 16 03:52:44 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 15 Sep 2014 18:52:44 -0700
Subject: [R] Bug in rep() function
In-Reply-To: <54171DF4.40304@gmx.de>
References: <54170612.1080905@gmx.de> <5417159A.8050606@stats.ox.ac.uk>
	<54171DF4.40304@gmx.de>
Message-ID: <CAF8bMcbrH8pjQNNCKk77ox5GPjs57+CnK11ZRad5o4_Bto8u8A@mail.gmail.com>

> Why are the first two yielding an integer after multiplying, and the last two don't?
> Apparently, c(0.8,0.6,0.4,0.2) can't be represented exactly.

Most fractions cannot be represented exactly.  Also, you cannot depend
on the third element of seq(.2,.8,by=.2) being equal to .6 (it is
slightly greater).  Use subtraction
instead of equality tests to get a better feel for what is happening.
  > seq(.2, .8, .2)[3] - .6
  [1] 1.110223e-16

> What would be your approach? Always round numbers first, before giving them
> to rep() ?

You can do that or generate integer sequences.  It is not just rep() -
any function that interprets an argument as an integer has the same
problem.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Sep 15, 2014 at 10:12 AM, Samuel Knapp <samuel.k at gmx.de> wrote:
> Thank you.
> I got the point with non-integer values in rep(). I also red FAQ 7.3:
> "The only numbers that can be represented exactly in R?s numeric type are
> integers and fractions whose denominator is a power of 2."
>
> But then I still don't understand:
>
>> for (b in seq(0.2,0.8,0.2))
> + {
> +   a <- (1-b)*10
> +
> +   print(1-b,digits=20)
> +   print(a,digits=22)
> +   print(trunc(a))
> +   print("///////")
> + }
> [1] 0.80000000000000004441
> [1] 8
> [1] 8
> [1] "///////"
> [1] 0.5999999999999999778
> [1] 6
> [1] 6
> [1] "///////"
> [1] 0.39999999999999991118
> [1] 3.999999999999999111822
> [1] 3
> [1] "///////"
> [1] 0.19999999999999995559
> [1] 1.999999999999999555911
> [1] 1
> [1] "///////"
>
> Why are the first two yielding an integer after multiplying, and the last
> two don't? Apparently, c(0.8,0.6,0.4,0.2) can't be represented exactly.
>
> What would be your approach? Always round numbers first, before giving them
> to rep() ?
>
> Thanks,
> Samuel
>
> On 15.09.2014 18:36, Prof Brian Ripley wrote:
>>
>> On 15/09/2014 16:30, Samuel Knapp wrote:
>>>
>>> Dear all,
>>>
>>> I have discovered a bug in the standard rep() function: At certain
>>
>>
>> Not so:
>>
>> > a <- (1-0.9)*100
>> > trunc(a)
>> [1] 9
>>
>> As the help says
>>
>>      Non-integer values of ?times? will be truncated towards zero.  If
>>      ?times? is a computed quantity it is prudent to add a small fuzz.
>>
>> And as the posting guide said
>>
>> Do your homework before posting:
>> ...
>>     Read the online help for relevant functions (type ?functionname, e.g.,
>> ?prod, at the R prompt)
>>
>>
>>> values, rep() does not replicate the element by the proper number of
>>> times:
>>>
>>>  > a <- (1-0.9)*100
>>>  > a
>>> [1] 10
>>>  > length(rep(1,times=a))
>>> [1] 9
>>>  > length(rep(1,each=a))
>>> [1] 9
>>>
>>> As shown, this happens as well for the times= as for the each=
>>> parameter. It does not depend on the kind of element that is to be
>>> repeated:
>>>
>>>  > length(rep("abc",each=a))
>>> [1] 9
>>>
>>> I tried to narrow down the bug, but haven't really managed to find a
>>> pattern behind the bug. Here is a list with values for a (see above)
>>> that returns a false object ( after the value for a, i've collected the
>>> expected length and the length that is produced by r):
>>>
>>> # mistake at
>>> (1-0.9)*100       10           9
>>> (1-0.8)*100       20          19
>>> (1-0.8)*1000      200       199
>>> (1-0.9)*1000      100       99
>>> (1-0.9)*10            1         0
>>> (1-0.8)*10            2         1
>>> (1-0.9)*1000000000      100000000       99999999
>>> (2-1-0.9)*100         10      9
>>> (10/10-0.9)*100     10      9
>>>
>>> # the following sets for a work fine
>>> (1+0.1)*100
>>> (1-0.1)*100
>>> (1-0.7)*100
>>> (1-0.99)*1000
>>> (1-0.7)*10
>>> (1-0.90)*10
>>> (1-0.95)*100
>>> (1-0.95)*1000
>>> (2-0.9)*1000
>>> (2-1.9)*100
>>> (1.1-1)*100
>>> (10-9)*100
>>>
>>> Did I make any mistake? Or where else should I address this problem?
>>>
>>> Thanks and best regards,
>>> Samuel
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Sep 16 06:01:10 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 15 Sep 2014 21:01:10 -0700
Subject: [R] Fwd: the properties of a DATA to run DBSCAN in R
In-Reply-To: <CAJ4Akz8hutE5aWj1VWMh_5ZsUa9+-DAof_Ky55MZxUE+1ZWtcA@mail.gmail.com>
References: <CAJ4Akz9pxUOBG7KLW-jKg6Y-Oj9RsO5N5MoYryBLLnLw=CbG4Q@mail.gmail.com>
	<CAJ4Akz8hutE5aWj1VWMh_5ZsUa9+-DAof_Ky55MZxUE+1ZWtcA@mail.gmail.com>
Message-ID: <0aa52b84-d5aa-44a2-b0f4-7f119e06c632@email.android.com>

Instead of repeating yourself, please do some research. There is a Posting Guide mentioned at the bottom of this message. One of the things it mentions is making a reproducible example. (You might find [1] helpful in that regard.) Another thing it mentions is posting in plain text, which does not get mangled in transit. Another useful but of advice is to cc the package maintainer in case they are not monitoring R-help (see ?maintainer).

Keep in mind that there are over 6000 contributed packages out there, so making it easy for someone familiar with R but not familiar with your special package is an important strategy in getting help. In addition, if this turns out to be a bug that the maintainer needs to fix then they will need a reproducible example in order to do that.

[1]  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 15, 2014 5:11:29 PM PDT, Maryam Heidari <m.heidari.b at gmail.com> wrote:
>hello everybody,
>
>I have been trying to run "dbscan" algorithm on my data, my data round
>40000 records which each of them has 3 attributes + plus the ID for
>each
>record.
>the interesting thing is that when I run the "dbscan just on 3
>attributes"
>R gives me an ERROR regarding "stackoverflow" but when I run it
>including
>the 4 attributes it runs with out any problem.
>so is the problem with my data?!
>
>this is statistics about my data
>att1                           att2                                att3
> Min.   :0.00000      Min.   :0.000000       Min.   :0.000000
> 1st Qu.:0.01429    1st Qu.:0.000000     1st Qu.:0.000000
> Median :0.02857    Median :0.000000   Median :0.000000
> Mean   :0.02764    Mean   :0.001135    Mean   :0.000477
> 3rd Qu.:0.02857    3rd Qu.:0.000000    3rd Qu.:0.000000
> Max.   :1.00000      Max.   :1.000000     Max.   :1.000000
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Sep 16 06:24:48 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 15 Sep 2014 21:24:48 -0700
Subject: [R] Efficient frontier
In-Reply-To: <5A52AC39-612B-40C9-AEBE-753BA8309136@gmail.com>
References: <5A52AC39-612B-40C9-AEBE-753BA8309136@gmail.com>
Message-ID: <CACk-te3P9ZnW_Te7tNJuJKxzynzDHK-WyDXt1Np1n755rHRbUw@mail.gmail.com>

Please read the posting guide (link at bottom of message) to learn how
to post coherently to get a useful response. I, at least, found your
post to be unintelligible gibberish.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Sep 15, 2014 at 12:40 PM, Aparna <aparna.eco04 at gmail.com> wrote:
> Hi I need help for plotting efficient frontier, I have expected return and covariance matrix. I am using tseries and downloaded portfolio package too. The suggestion says to use efficient.frontier, but it looks you replaces it by something in R 3.1.1 as it says this is not available. At current R version, what is the way to draw efficient frontier?
>
> Sent from my iPad
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From schuttesebastian at gmail.com  Tue Sep 16 06:30:21 2014
From: schuttesebastian at gmail.com (Sebastian Schutte)
Date: Tue, 16 Sep 2014 06:30:21 +0200
Subject: [R] spatstat rmh problem
In-Reply-To: <541765CC.2070507@auckland.ac.nz>
References: <5416F7EF.6070502@gmail.com> <541765CC.2070507@auckland.ac.nz>
Message-ID: <5417BCDD.5080301@gmail.com>

Thanks so much for your comments. Sorry for not having sent a running 
example from the start. Here it is:

library (spatstat)

#Load example data
data(demopat)
#Generate a random point pattern within the polygon
set.seed(12345)
pdat <- rpoint(200,win=demopat$window)
#Generate a distmap, which will serve as covariate information
im.cdat <- as.im(distmap(pdat))
#Now the random seed is fixed and a new set of random points is 
generated for the example
set.seed(11111)
pdat <- rpoint(200,win=demopat$window)
#Fitting a model to the data
mod <- ppm (pdat ~  im.cdat)
#Now a point pattern is simulated via rmh from the fitted model an 
visualized as a density surface
set.seed(22222)
plot(density(rmh(mod)))
#And here is the problem: When I repeat the exercise with different 
coefs, the very same patter come out. "new.coef" has no effect.
set.seed(22222)
plot(density(rmh(mod),new.coef=c(1,200)))

What am I missing?

Thanks again,
Sebastian


On 16.09.2014 00:18, Rolf Turner wrote:
>
> Your example is not reproducible.  We don't have "cshape" or "im.pop" 
> (and are possibly lacking other bits and pieces; I didn't check the 
> details since the example fails to run from the get-go).  Please 
> provide a *reproducible* example.
>
> Also I am puzzled by the line
>
>> mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
>
> Did you mean
>
>> mod <- ppm (dat, ~  pop ,  covariates = list (pop = im.pop))
>
> ???
>
> Also please note that with versions of spatstat later than or equal to 
> 1.37-0 you can write
>
>     ppm(dat ~ im.pop)
>
> when the object "im.pop" is present in the global environment.
>
> cheers,
>
> Rolf Turner
>
> On 16/09/14 02:30, Sebastian Schutte wrote:
>> Dear R and spatstat developers,
>>
>> Thanks so much for the time and effort that you invest into this awesome
>> software. I have a problem simulating from a Point Process Model in
>> spatstat. In summary, the option "new.coef" should allow me to use a
>> fitted model and change its beta coefficients before simulating a point
>> pattern from the model via Monte Carlo simulation. Intuitively, one
>> would assume that the predicted point pattern changes as one fiddles
>> with the beta coefficients. However, this does not seem to work.
>>
>> Please let me know what I am missing here and which screw to drive to
>> actually change the simulation output.
>>
>> #owin is a polygon of country boundaries, "im.pop" is a raster with
>> georeferenced population counts.
>> #I am using a random point pattern for demonstration purposes
>>
>> #Fix random seed
>> set.seed(12345)
>> #Generate artificial points
>> dat <- rpoint(500,win=cshape)
>> #Fit a (inhomogenous spatial poisson) model to the data
>> mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
>> #Simulate some points:
>> plot(density(rmh(mod)))
>> #plot(density(simulate(mod)))
>> #Show that this is reproducible
>> set.seed(12345)
>> #Generate artificial points
>> dat <- rpoint(500,win=cshape)
>> #Fit a (inhomogenous spatial poisson) model to the data
>> mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
>> #Simulate some points:
>> plot(density(rmh(mod)))
>> #As expected, the density is the same
>>
>> #Now change the coefs and do it again:
>> set.seed(12345)
>> #Generate artificial points
>> dat <- rpoint(500,win=cshape)
>> #Fit a (inhomogenous spatial poisson) model to the data
>> mod <- ppm (ppp, ~  pop ,  covariates = list (pop = im.pop))
>> #Simulate some points:
>> plot(density(rmh(mod),new.coef=c(1,200)))
>> #Looks the same, so what am I missing?
>


From r.turner at auckland.ac.nz  Tue Sep 16 08:11:48 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 16 Sep 2014 18:11:48 +1200
Subject: [R] spatstat rmh problem
In-Reply-To: <5417BCDD.5080301@gmail.com>
References: <5416F7EF.6070502@gmail.com> <541765CC.2070507@auckland.ac.nz>
	<5417BCDD.5080301@gmail.com>
Message-ID: <5417D4A4.4080607@auckland.ac.nz>


OK.  Two things are going wrong.

(1) There is an error in your code.  You are passing the new.coef 
argument to density() and not to rmh(). The function density() has no 
such argument, but has a "..." argument, so "new.coef" simply gets ignored.

You should use:

plot(density(rmh(mod,new.coef=c(1,200))))

(2) However, even when the correct call is given you still wind up with 
identical densities!!!

Hmmmmm.  I think this may be a bug; I'll will check with the other 
authors of spatstat and report back.

cheers,

Rolf Turner

On 16/09/14 16:30, Sebastian Schutte wrote:
> Thanks so much for your comments. Sorry for not having sent a running
> example from the start. Here it is:
>
> library (spatstat)
>
> #Load example data
> data(demopat)
> #Generate a random point pattern within the polygon
> set.seed(12345)
> pdat <- rpoint(200,win=demopat$window)
> #Generate a distmap, which will serve as covariate information
> im.cdat <- as.im(distmap(pdat))
> #Now the random seed is fixed and a new set of random points is
> generated for the example
> set.seed(11111)
> pdat <- rpoint(200,win=demopat$window)
> #Fitting a model to the data
> mod <- ppm (pdat ~  im.cdat)
> #Now a point pattern is simulated via rmh from the fitted model an
> visualized as a density surface
> set.seed(22222)
> plot(density(rmh(mod)))
> #And here is the problem: When I repeat the exercise with different
> coefs, the very same patter come out. "new.coef" has no effect.
> set.seed(22222)
> plot(density(rmh(mod),new.coef=c(1,200)))
>
> What am I missing?

-- 
Rolf Turner
Technical Editor ANZJS


From rl at openmailbox.org  Tue Sep 16 11:09:54 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Tue, 16 Sep 2014 09:09:54 +0000
Subject: [R] apply block of if statements with menu function
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
References: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
Message-ID: <55db8485faf3fbd2cdbd75c8b0570b71@openmailbox.org>

On 2014-09-15 14:22, David L Carlson wrote:
> I think switch() should work for you here, but it is not clear how
> much flexibility you are trying to have (different tests based on the
> first response; different tests based on first, then second response;
> different tests based on each successive response).
> 

The help page for 'menu' shows:

switch(menu(c("List letters", "List LETTERS")) + 1,
	cat("Nothing done\n"), letters, LETTERS)

why is the result changed if ' + 1,' removed?

The help page for switch states that "arguments" are required, but this 
conflicts with the syntax for the function 'menu':

> testswitch<-function (testfunctionname) {
+ menu1<-switch(menu(c(1,2,3,4),graphics=FALSE,title='select 
something'))
+ if (menu1==1)
+ menu1a<-menu(c('1a','2a','3a','4a'),graphics=FALSE,title='select 
something else')
+ if (menu1a==1)
+ object1<-seq(1:10)
+ object2<-seq(20:30)
+ menu2a<-menu(c('5a','6a','7a','8a'),graphics=FALSE,title='select 
something else again')
+ if (menu2a==2)
+ object3<-'3y'
+ finalobject<<-object3
+ if (menu1==2)
+ menu2x<-menu(c('5a','15a','20a'),graphics=FALSE,title='select 
something else')
+ if (menu2x==1)
+ object22<-seq(10:100)
+ object22<-seq(2:30)
+ object33<-rnorm(10)
+ menu2y<-menu(c('5a','6a','7a','8a'),graphics=FALSE,title='select 
something else again')
+ if (menu2y==2)
+ object3<-'3y'
+ finalobject<<-object3
+ }
> testswitch(testfunctionname)
select something

1: 1
2: 2
3: 3
4: 4

Selection: 1
Error in if (menu1 == 1) menu1a <- menu(c("1a", "2a", "3a", "4a"), 
graphics = FALSE,  :
	argument is of length zero

How to correct this error please, for this zero length argument?


From r.turner at auckland.ac.nz  Tue Sep 16 12:22:27 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 16 Sep 2014 22:22:27 +1200
Subject: [R] spatstat rmh problem
In-Reply-To: <5417BCDD.5080301@gmail.com>
References: <5416F7EF.6070502@gmail.com> <541765CC.2070507@auckland.ac.nz>
	<5417BCDD.5080301@gmail.com>
Message-ID: <54180F63.4070204@auckland.ac.nz>


There was indeed a bug in rmh() w.r.t. the "new.coeff" argument.
The bug has been fixed and will not be present in the next release of 
spatstat.

cheers,

Rolf Turner

On 16/09/14 16:30, Sebastian Schutte wrote:
> Thanks so much for your comments. Sorry for not having sent a running
> example from the start. Here it is:
>
> library (spatstat)
>
> #Load example data
> data(demopat)
> #Generate a random point pattern within the polygon
> set.seed(12345)
> pdat <- rpoint(200,win=demopat$window)
> #Generate a distmap, which will serve as covariate information
> im.cdat <- as.im(distmap(pdat))
> #Now the random seed is fixed and a new set of random points is
> generated for the example
> set.seed(11111)
> pdat <- rpoint(200,win=demopat$window)
> #Fitting a model to the data
> mod <- ppm (pdat ~  im.cdat)
> #Now a point pattern is simulated via rmh from the fitted model an
> visualized as a density surface
> set.seed(22222)
> plot(density(rmh(mod)))
> #And here is the problem: When I repeat the exercise with different
> coefs, the very same patter come out. "new.coef" has no effect.
> set.seed(22222)
> plot(density(rmh(mod),new.coef=c(1,200)))
>
> What am I missing?


-- 
Rolf Turner
Technical Editor ANZJS


From petr.pikal at precheza.cz  Tue Sep 16 12:50:30 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 16 Sep 2014 10:50:30 +0000
Subject: [R] apply block of if statements with menu function
In-Reply-To: <55db8485faf3fbd2cdbd75c8b0570b71@openmailbox.org>
References: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
	<55db8485faf3fbd2cdbd75c8b0570b71@openmailbox.org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE333E@SRVEXCHMBX.precheza.cz>

Hi

> Selection: 1
> Error in if (menu1 == 1) menu1a <- menu(c("1a", "2a", "3a", "4a"),
> graphics = FALSE,  :
>       argument is of length zero
>
> How to correct this error please, for this zero length argument?

Instead of writing functions which you are unable to debug and resolve look what elements of your function returns.

Here is what your first line does

> menu1<-switch(menu(c(1,2,3,4),graphics=FALSE,title="select something"))
select something

1: 1
2: 2
3: 3
4: 4

Selection: 3
> menu1
NULL

Regardless of selection menu1 stays NULL, what is probably not what you want.

> switch(menu(c("List letters", "List LETTERS")) + 1,
>       cat("Nothing done\n"), letters, LETTERS)
>
> why is the result changed if ' + 1,' removed?

Because +1 belongs to switch not to menu. You can translate above to:

open menu with 2 items
select one of those 2 items  or press 0
return 0, 1 or 2 based on your choice
add 1 to returned value to enable **switch** to perform first, second or third item
perform desired item e.g print Nothing done, letters or LETTERS.

Nothing more, nothing less.

so in your case it shall be

menu1 <- menu(c(1,2,3,4),graphics=FALSE,title='select something')
if (menu1 == 1) ...

or
menu1 <- menu1+1

switch (menu1, "Nothing selected",
{do something1},
{do something2},
{do something3},
{do something4})

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of rl at openmailbox.org
> Sent: Tuesday, September 16, 2014 11:10 AM
> To: David L Carlson
> Cc: r-help at r-project.org
> Subject: Re: [R] apply block of if statements with menu function
>
> On 2014-09-15 14:22, David L Carlson wrote:
> > I think switch() should work for you here, but it is not clear how
> > much flexibility you are trying to have (different tests based on the
> > first response; different tests based on first, then second response;
> > different tests based on each successive response).
> >
>
> The help page for 'menu' shows:
>
> switch(menu(c("List letters", "List LETTERS")) + 1,
>       cat("Nothing done\n"), letters, LETTERS)
>
> why is the result changed if ' + 1,' removed?
>
> The help page for switch states that "arguments" are required, but this
> conflicts with the syntax for the function 'menu':
>
> > testswitch<-function (testfunctionname) {
> + menu1<-switch(menu(c(1,2,3,4),graphics=FALSE,title='select
> something'))
> + if (menu1==1)
> + menu1a<-menu(c('1a','2a','3a','4a'),graphics=FALSE,title='select
> something else')
> + if (menu1a==1)
> + object1<-seq(1:10)
> + object2<-seq(20:30)
> + menu2a<-menu(c('5a','6a','7a','8a'),graphics=FALSE,title='select
> something else again')
> + if (menu2a==2)
> + object3<-'3y'
> + finalobject<<-object3
> + if (menu1==2)
> + menu2x<-menu(c('5a','15a','20a'),graphics=FALSE,title='select
> something else')
> + if (menu2x==1)
> + object22<-seq(10:100)
> + object22<-seq(2:30)
> + object33<-rnorm(10)
> + menu2y<-menu(c('5a','6a','7a','8a'),graphics=FALSE,title='select
> something else again')
> + if (menu2y==2)
> + object3<-'3y'
> + finalobject<<-object3
> + }
> > testswitch(testfunctionname)
> select something
>
> 1: 1
> 2: 2
> 3: 3
> 4: 4
>
> Selection: 1
> Error in if (menu1 == 1) menu1a <- menu(c("1a", "2a", "3a", "4a"),
> graphics = FALSE,  :
>       argument is of length zero
>
> How to correct this error please, for this zero length argument?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From barry.king at qlx.com  Tue Sep 16 13:40:29 2014
From: barry.king at qlx.com (Barry King)
Date: Tue, 16 Sep 2014 07:40:29 -0400
Subject: [R] R's memory limitation and Hadoop
Message-ID: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>

Is there a way to get around R?s memory-bound limitation by interfacing
with a Hadoop database or should I look at products like SAS or JMP to work
with data that has hundreds of thousands of records?  Any help is
appreciated.

-- 
__________________________
*Barry E. King, Ph.D.*
Analytics Modeler
Qualex Consulting Services, Inc.
Barry.King at qlx.com
O: (317)940-5464
M: (317)507-0661
__________________________

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Tue Sep 16 14:01:38 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 16 Sep 2014 07:01:38 -0500
Subject: [R] R's memory limitation and Hadoop
In-Reply-To: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>
References: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>
Message-ID: <CAAJSdjjh--AgSmivkFnHjSp9eVrWdwbTqgkdxkREbpAPV6XxTw@mail.gmail.com>

On Tue, Sep 16, 2014 at 6:40 AM, Barry King <barry.king at qlx.com> wrote:
> Is there a way to get around R?s memory-bound limitation by interfacing
> with a Hadoop database or should I look at products like SAS or JMP to work
> with data that has hundreds of thousands of records?  Any help is
> appreciated.
> __________________________
> *Barry E. King, Ph.D.*
> Analytics Modeler

Please change your email to plain text only, per forum standards.

You might want to look at bigmemory.
http://cran.revolutionanalytics.com/web/packages/bigmemory/index.html


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From rl at openmailbox.org  Tue Sep 16 14:16:30 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Tue, 16 Sep 2014 12:16:30 +0000
Subject: [R] apply block of if statements with menu function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE333E@SRVEXCHMBX.precheza.cz>
References: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
	<55db8485faf3fbd2cdbd75c8b0570b71@openmailbox.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE333E@SRVEXCHMBX.precheza.cz>
Message-ID: <de9e90496abf9d4d16ea37b61f5e5c8d@openmailbox.org>

On 2014-09-16 10:50, PIKAL Petr wrote:
> 
>> switch(menu(c("List letters", "List LETTERS")) + 1,
>>       cat("Nothing done\n"), letters, LETTERS)
>> 
>> why is the result changed if ' + 1,' removed?
> 
> Because +1 belongs to switch not to menu. You can translate above to:
> 

The help pages ?switch, ?menu do not describe (in my eyes! :) ) the 
significance of '+ 1'; where is this described in more detail please?


From jdnewmil at dcn.davis.CA.us  Tue Sep 16 14:27:28 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 16 Sep 2014 05:27:28 -0700
Subject: [R] R's memory limitation and Hadoop
In-Reply-To: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>
References: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>
Message-ID: <574eca5d-d32a-4f27-8995-e3c2c76ea470@email.android.com>

If you need to start your question with a false dichotomy, by all means choose the option you seem to have already chosen and stop trolling us.
If you actually want an answer here, try Googling on the topic first (is "R hadoop" so un-obvious?) and then phrase a specific question so someone has a chance to help you.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 16, 2014 4:40:29 AM PDT, Barry King <barry.king at qlx.com> wrote:
>Is there a way to get around R?s memory-bound limitation by interfacing
>with a Hadoop database or should I look at products like SAS or JMP to
>work
>with data that has hundreds of thousands of records?  Any help is
>appreciated.
>
>-- 
>__________________________
>*Barry E. King, Ph.D.*
>Analytics Modeler
>Qualex Consulting Services, Inc.
>Barry.King at qlx.com
>O: (317)940-5464
>M: (317)507-0661
>__________________________
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Sep 16 14:35:26 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 16 Sep 2014 12:35:26 +0000
Subject: [R] apply block of if statements with menu function
In-Reply-To: <de9e90496abf9d4d16ea37b61f5e5c8d@openmailbox.org>
References: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
	<55db8485faf3fbd2cdbd75c8b0570b71@openmailbox.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE333E@SRVEXCHMBX.precheza.cz>
	<de9e90496abf9d4d16ea37b61f5e5c8d@openmailbox.org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE33DB@SRVEXCHMBX.precheza.cz>

Hi

One comment: I never used menu or switch, this is just how I understand its function. So you probably are on a wrong track and do not understand what are objects and functions in R languange.

menu

Description
menu presents the user with a menu of choices labelled from 1 to the number of choices. To exit without choosing an item one can select 0.

Value
The number corresponding to the selected item, or 0 if no choice was made.

It is obvious (for me :) that results of menu command is 0,1,2, ... depending on how many items are in menu

switch

Description
switch evaluates EXPR and accordingly chooses one of the further arguments (in ...).

Details
switch works in two distinct ways depending whether the first argument evaluates to a character string or a number.

If the value of EXPR is not a character string it is coerced to integer. If the integer is between 1 and nargs()-1 then the corresponding element of ... is evaluated and the result returned: thus if the first argument is 3 then the fourth argument is evaluated and returned.

> switch(1,"a","b","c","d")
[1] "a"
> switch(2,"a","b","c","d")
[1] "b"
> switch(3,"a","b","c","d")
[1] "c"
> switch(4,"a","b","c","d")
[1] "d"
> switch(0,"a","b","c","d")
>

So if result of menu is 0 (you did not choose anything) you can either stay with 0, then switch does not return anything or add 1 and let evaluate something meaningful specified in second and following positions of switch command.

Regards
Petr


> -----Original Message-----
> From: rl at openmailbox.org [mailto:rl at openmailbox.org]
> Sent: Tuesday, September 16, 2014 2:17 PM
> To: PIKAL Petr
> Cc: r-help at r-project.org
> Subject: RE: [R] apply block of if statements with menu function
>
> On 2014-09-16 10:50, PIKAL Petr wrote:
> >
> >> switch(menu(c("List letters", "List LETTERS")) + 1,
> >>       cat("Nothing done\n"), letters, LETTERS)
> >>
> >> why is the result changed if ' + 1,' removed?
> >
> > Because +1 belongs to switch not to menu. You can translate above to:
> >
>
> The help pages ?switch, ?menu do not describe (in my eyes! :) ) the
> significance of '+ 1'; where is this described in more detail please?


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Tue Sep 16 14:56:07 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 16 Sep 2014 14:56:07 +0200
Subject: [R] R's memory limitation and Hadoop
In-Reply-To: <574eca5d-d32a-4f27-8995-e3c2c76ea470@email.android.com>
References: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>
	<574eca5d-d32a-4f27-8995-e3c2c76ea470@email.android.com>
Message-ID: <1A55A8E3-6C30-405D-A188-2A150A1F951D@gmail.com>

Not sure trolling was intended here.

Anyways:

Yes, there are ways of working with very large datasets in R, using databases or otherwise. Check the CRAN task views. 

SAS will for _some_ purposes be able to avoid overflowing RAM by using sequential file access. The biglm package is an example of using similar techniques in R. SAS is not (to my knowledge) able to do this invariably, some procedures may need to load the entire data set into RAM.

JMP's data tables are limited by available RAM, just like R's are.

R does have somewhat inefficient memory strategies (e.g., model matrices may include multiple columns of binary variables, each using 8 bytes per entry), so may run out of memory sooner than other programs, but it is not like the competition is not RAM-restricted at all.

- Peter D.

On 16 Sep 2014, at 14:27 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> If you need to start your question with a false dichotomy, by all means choose the option you seem to have already chosen and stop trolling us.
> If you actually want an answer here, try Googling on the topic first (is "R hadoop" so un-obvious?) and then phrase a specific question so someone has a chance to help you.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On September 16, 2014 4:40:29 AM PDT, Barry King <barry.king at qlx.com> wrote:
>> Is there a way to get around R?s memory-bound limitation by interfacing
>> with a Hadoop database or should I look at products like SAS or JMP to
>> work
>> with data that has hundreds of thousands of records?  Any help is
>> appreciated.
>> 
>> -- 
>> __________________________
>> *Barry E. King, Ph.D.*
>> Analytics Modeler
>> Qualex Consulting Services, Inc.
>> Barry.King at qlx.com
>> O: (317)940-5464
>> M: (317)507-0661
>> __________________________
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From h.wickham at gmail.com  Tue Sep 16 15:53:15 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 16 Sep 2014 14:53:15 +0100
Subject: [R] R's memory limitation and Hadoop
In-Reply-To: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>
References: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>
Message-ID: <CABdHhvEe8-So5SeR6ij5Prj2Wc1DEaSJybj04_un5xNM0zc_xA@mail.gmail.com>

Hundreds of thousands of records usually fit into memory fine.

Hadley

On Tue, Sep 16, 2014 at 12:40 PM, Barry King <barry.king at qlx.com> wrote:
> Is there a way to get around R?s memory-bound limitation by interfacing
> with a Hadoop database or should I look at products like SAS or JMP to work
> with data that has hundreds of thousands of records?  Any help is
> appreciated.
>
> --
> __________________________
> *Barry E. King, Ph.D.*
> Analytics Modeler
> Qualex Consulting Services, Inc.
> Barry.King at qlx.com
> O: (317)940-5464
> M: (317)507-0661
> __________________________
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From schuttesebastian at gmail.com  Tue Sep 16 08:17:28 2014
From: schuttesebastian at gmail.com (Sebastian Schutte)
Date: Tue, 16 Sep 2014 08:17:28 +0200
Subject: [R] spatstat rmh problem
In-Reply-To: <5417D4A4.4080607@auckland.ac.nz>
References: <5416F7EF.6070502@gmail.com> <541765CC.2070507@auckland.ac.nz>
	<5417BCDD.5080301@gmail.com> <5417D4A4.4080607@auckland.ac.nz>
Message-ID: <5417D5F8.6090604@gmail.com>


> You should use:
> plot(density(rmh(mod,new.coef=c(1,200))))
>
Sorry, my bad, typo in the example code.
> (2) However, even when the correct call is given you still wind up 
> with identical densities!!!
>
> Hmmmmm.  I think this may be a bug; I'll will check with the other 
> authors of spatstat and report back.
>
Thanks!

>
> On 16/09/14 16:30, Sebastian Schutte wrote:
>> Thanks so much for your comments. Sorry for not having sent a running
>> example from the start. Here it is:
>>
>> library (spatstat)
>>
>> #Load example data
>> data(demopat)
>> #Generate a random point pattern within the polygon
>> set.seed(12345)
>> pdat <- rpoint(200,win=demopat$window)
>> #Generate a distmap, which will serve as covariate information
>> im.cdat <- as.im(distmap(pdat))
>> #Now the random seed is fixed and a new set of random points is
>> generated for the example
>> set.seed(11111)
>> pdat <- rpoint(200,win=demopat$window)
>> #Fitting a model to the data
>> mod <- ppm (pdat ~  im.cdat)
>> #Now a point pattern is simulated via rmh from the fitted model an
>> visualized as a density surface
>> set.seed(22222)
>> plot(density(rmh(mod)))
>> #And here is the problem: When I repeat the exercise with different
>> coefs, the very same patter come out. "new.coef" has no effect.
>> set.seed(22222)
>> plot(density(rmh(mod),new.coef=c(1,200)))
>>
>> What am I missing?
>


From ValleeM at iarc.fr  Tue Sep 16 15:24:50 2014
From: ValleeM at iarc.fr (Maxime Vallee)
Date: Tue, 16 Sep 2014 13:24:50 +0000
Subject: [R] R "write" strange behavior in huge file
Message-ID: <D03E06C1.65E77%ValleeM@iarc.fr>

Hello, 

In my script I have one list of 1,132,533 vectors (each vector contains
381 elements). 

When I use "write" to save this list in a flat text file (I unlist my
list, separate by tabs, and set ncol to 381), I end up with a file of
1,132,535 lines (2 additional lines). I checked back, my R list do not
have those two additional items before writing.

With awk, I determined if lines where not made of 381 fields: there were
two, separated by around 400k lines.

I made sub-files, using those "incomplete" lines as boundaries. My files
are very close in size : 1.9 GB (respectively 1971841853 B and 1972614897
B). It feels like a 32 bit / 64 bit issue.

My R version is this:
./Rscript -e 'sessionInfo()$platform'
[1] "x86_64-unknown-linux-gnu (64-bit)"

There is somewhere, reaching 1.9 GB, something that is changing my tabs to
unwanted carriage returns...
Any idea that might cause this, and if it looks solvable in R?

Cheers, 

--Maxime 





-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From manojkumarsivaraj334 at gmail.com  Tue Sep 16 16:11:13 2014
From: manojkumarsivaraj334 at gmail.com (Manoj Kumar)
Date: Tue, 16 Sep 2014 16:11:13 +0200
Subject: [R] ReadMM does not support array format
Message-ID: <CAFQAd-=vfoXAZudtT4=bWS+V-UAhK0Vqa4juU=kuE0NyV52LVA@mail.gmail.com>

Hello,

I have a file "x.mtx" stored as a array format MatrixMarket file.

The header says "%%MatrixMarket matrix array real general"

However when I do readMM("x.mtx"), it raises an error saying Error in
scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
  scan() expected 'an integer', got '-8.1977721447407614e-01'

which means that it expects the coordinate matrix format. Is this a bug? or
am I doing something wrong? since I expect the MatrixMarket format to
handle both formats of data.

Thanks

-- 
Godspeed,
Manoj Kumar,
Intern, Telecom ParisTech
Mech Undergrad
http://manojbits.wordpress.com

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Tue Sep 16 20:47:27 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Sep 2014 19:47:27 +0100
Subject: [R] R's memory limitation and Hadoop
In-Reply-To: <1A55A8E3-6C30-405D-A188-2A150A1F951D@gmail.com>
References: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>	<574eca5d-d32a-4f27-8995-e3c2c76ea470@email.android.com>
	<1A55A8E3-6C30-405D-A188-2A150A1F951D@gmail.com>
Message-ID: <541885BF.4060301@stats.ox.ac.uk>

On 16/09/2014 13:56, peter dalgaard wrote:
> Not sure trolling was intended here.
>
> Anyways:
>
> Yes, there are ways of working with very large datasets in R, using databases or otherwise. Check the CRAN task views.
>
> SAS will for _some_ purposes be able to avoid overflowing RAM by using sequential file access. The biglm package is an example of using similar techniques in R. SAS is not (to my knowledge) able to do this invariably, some procedures may need to load the entire data set into RAM.
>
> JMP's data tables are limited by available RAM, just like R's are.
>
> R does have somewhat inefficient memory strategies (e.g., model matrices may include multiple columns of binary variables, each using 8 bytes per entry), so may run out of memory sooner than other programs, but it is not like the competition is not RAM-restricted at all.

Also 'hundreds of thousands of records' is not really very much: I have 
seen analyses of millions many times[*]: I have analysed a few billion 
with 0.3TB of RAM.

[*] I recall a student fitting a GLM with about 30 predictors to 1.5m 
records: at the time (ca R 2.14) it did not fit in 4GB but did in 8GB.

> - Peter D.
>>
>> On September 16, 2014 4:40:29 AM PDT, Barry King <barry.king at qlx.com> wrote:
>>> Is there a way to get around R?s memory-bound limitation by interfacing
>>> with a Hadoop database or should I look at products like SAS or JMP to
>>> work
>>> with data that has hundreds of thousands of records?  Any help is
>>> appreciated.
>>>
>>> --
>>> __________________________
>>> *Barry E. King, Ph.D.*
>>> Analytics Modeler
>>> Qualex Consulting Services, Inc.
>>> Barry.King at qlx.com
>>> O: (317)940-5464
>>> M: (317)507-0661
>>> __________________________


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From chichi.shu at hotmail.com  Tue Sep 16 17:01:39 2014
From: chichi.shu at hotmail.com (Chichi Shu)
Date: Tue, 16 Sep 2014 11:01:39 -0400
Subject: [R] Using R to get updated access token on FB Graph API?
In-Reply-To: <CA+vqiLFr9iyk4p7zV7WFHh8=Q5+=ki=H0KbcwoBNcyvTEATEmA@mail.gmail.com>
References: <SNT149-DS244829C1FC166CFAC067F88FC10@phx.gbl>
	<CA+vqiLFr9iyk4p7zV7WFHh8=Q5+=ki=H0KbcwoBNcyvTEATEmA@mail.gmail.com>
Message-ID: <SNT149-DS1296197E1F10ED971F67248FC90@phx.gbl>

Thanks, Ista. I think RFacebook package is using HTTR to get access token too. So I don?t have to use it separately to get access token.

Once someone creates an app ID and secret, do they ever expire? I can?t find any information online about the expiration of App ID and App secret so I?m assuming they don?t ever become invalid?

From: Ista Zahn 
Sent: Monday, September 08, 2014 5:24 PM
To: Chichi Shu 
Subject: Re: [R] Using R to get updated access token on FB Graph API?

Take a look at the httr package, there is a Facebook example in the package demos.

Best,
Ista

On Sep 8, 2014 4:35 PM, "Chichi Shu" <chichi.shu at hotmail.com> wrote:

  Hi, R users,

  Is it possible to use R to obtain access token to Facebook API automatically? The access token generated in Facebook Graph API expires very soon so I'd like to use R to generate new access token and grab it and save it to a variable automatically every 60 days.

  Is it possible? If so, which packages should I use? Could someone shed light?

  Thanks!
          [[alternative HTML version deleted]]

  ______________________________________________
  R-help at r-project.org mailing list
  https://stat.ethz.ch/mailman/listinfo/r-help
  PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
  and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From hmorenor at uwyo.edu  Tue Sep 16 20:36:21 2014
From: hmorenor at uwyo.edu (Hernan A. Moreno Ramirez)
Date: Tue, 16 Sep 2014 18:36:21 +0000
Subject: [R] ncdf size error
In-Reply-To: <CAL+Zad8AnjLMq0VKwj+nbNTEN_DD01RV0T9VneinBW295frNkQ@mail.gmail.com>
References: <338322FF-7ADA-48DC-BC76-47AF0BEE042A@uwyo.edu>,
	<CAL+Zad8AnjLMq0VKwj+nbNTEN_DD01RV0T9VneinBW295frNkQ@mail.gmail.com>
Message-ID: <1410892579836.91251@uwyo.edu>

Sure, here it is. Thanks for any help with this Dr. Pierce:


##### Exporting to NETCDF files #################################################################
# define the netcdf coordinate variables 
library(ncdf)
dim1 = dim.def.ncdf( "Nodes","", seq(1,19000))
dim2= dim.def.ncdf( "Time","Hours since 2005-01-01 00:00:00",seq(1:2190)) #final[1,2,]))

varT2 = var.def.ncdf("T2","celsius", list(dim1,dim2), -99999, longname="T2")
varQ2 = var.def.ncdf("Q2","kg kg-1", list(dim1,dim2), -99999, longname="Q2")
varQVAPOR = var.def.ncdf("QVAPOR","kg kg-1", list(dim1,dim2), -99999, longname="QVAPOR")
varQCLOUD = var.def.ncdf("QCLOUD","kg kg-1", list(dim1,dim2), -99999, longname="QCLOUD")
varPSFC = var.def.ncdf("PSFC","Pa", list(dim1,dim2), -99999, longname="PSFC")
varW10 = var.def.ncdf("W10","ms-1", list(dim1,dim2), -99999, longname="W10")
varW = var.def.ncdf("W","ms-1", list(dim1,dim2), -99999, longname="W")
varVEGFRA = var.def.ncdf("VEGFRA","", list(dim1,dim2), -99999, longname="VEGFRA")
varMAXVEGFRA = var.def.ncdf("MAXVEGFRA","", list(dim1,dim2), -99999, longname="MAXVEGFRA")
varTPREC = var.def.ncdf("TPREC","mm", list(dim1,dim2), -99999, longname="TPREC")
varFRAC_FROZ_PREC = var.def.ncdf("FRAC_FROZ_PREC","mm", list(dim1,dim2), -99999, longname="FRAC_FROZ_PREC")
varSWDOWN = var.def.ncdf("SWDOWN","W m-2", list(dim1,dim2), -99999, longname="SWDOWN")
varGLW = var.def.ncdf("GLW","W m-2", list(dim1,dim2), -99999, longname="GLW")
varPBLH = var.def.ncdf("PBLH","m", list(dim1,dim2), -99999, longname="PBLH")
varTSLB = var.def.ncdf("TSLB","Celsius", list(dim1,dim2), -99999, longname="TSLB")

# associate the netcdf variable with a netcdf file   
# put the variable into the file, and
# close

nc.ex = create.ncdf("/media/D/output.nc",list(varT2, varQ2, varQVAPOR, varQCLOUD, varPSFC, varW10, varW, varVEGFRA, varMAXVEGFRA, varTPREC, varFRAC_FROZ_PREC, varSWDOWN, varGLW, varPBLH, varTSLB))

Error in R_nc_enddef: NetCDF: One or more variable sizes violate format constraints
Error in R_nc_sync: NetCDF: Operation not allowed in define mode

---------------------------------------------------------------------------------------
Hernan A. Moreno, Ph.D.
Postdoctoral Research Associate
Department of Civil & Architectural Engineering
Room 3038, Engineering Building
University of Wyoming
Phone: 480-3990571
http://www.public.asu.edu/~hamoreno/

________________________________________
From: davidwilliampierce at gmail.com <davidwilliampierce at gmail.com> on behalf of David W. Pierce <dpierce at ucsd.edu>
Sent: Monday, September 15, 2014 7:00 PM
To: Hernan A. Moreno Ramirez
Cc: r-help at r-project.org
Subject: Re: [R] ncdf size error

On Mon, Sep 15, 2014 at 4:20 PM, Hernan A. Moreno Ramirez
<hmorenor at uwyo.edu> wrote:
>
> Hi I am using both ncdf and ncdf4 libraries and with both I keep getting the
> same error: Error in R_nc_enddef: NetCDF: One or more variable sizes violate
> format constraints. Error in R_nc_sync: NetCDF: Operation not allowed in
> define mode. This happens when I try to create.ncdf() a file with more than
> 13 variables. I think is a problem of memory size. What would you recommend?
> Any help will be appreciated

Hi Hernan,

can you supply an example that shows the problem?

Regards,

--Dave

-------------------
David W. Pierce
Division of Climate, Atmospheric Science, and Physical Oceanography
Scripps Institution of Oceanography, La Jolla, California, USA
(858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu


From wdunlap at tibco.com  Tue Sep 16 21:14:05 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 16 Sep 2014 12:14:05 -0700
Subject: [R] R's memory limitation and Hadoop
In-Reply-To: <541885BF.4060301@stats.ox.ac.uk>
References: <CAP8Wkry0tkkyjay8qRuzSBtK7H=WWF3v2hpv18qUZxK0JBJHeQ@mail.gmail.com>
	<574eca5d-d32a-4f27-8995-e3c2c76ea470@email.android.com>
	<1A55A8E3-6C30-405D-A188-2A150A1F951D@gmail.com>
	<541885BF.4060301@stats.ox.ac.uk>
Message-ID: <CAF8bMcaQXz4+_5fR9TQ8KWHu4b5wiaiStM5rasZF0YM7DG1E6Q@mail.gmail.com>

> [*] I recall a student fitting a GLM with about 30 predictors to 1.5m
> records: at the time (ca R 2.14) it did not fit in 4GB but did in 8GB.

You can easily run out of memory when a few of the variables are
factors, each with many levels, and the user looks for interactions
between them.  This can happen by accident if your data was imported
with read.table() and a variable meant to be numeric was read as
factor (or character).  str(yourData) would tell you about this
problem.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Sep 16, 2014 at 11:47 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 16/09/2014 13:56, peter dalgaard wrote:
>>
>> Not sure trolling was intended here.
>>
>> Anyways:
>>
>> Yes, there are ways of working with very large datasets in R, using
>> databases or otherwise. Check the CRAN task views.
>>
>> SAS will for _some_ purposes be able to avoid overflowing RAM by using
>> sequential file access. The biglm package is an example of using similar
>> techniques in R. SAS is not (to my knowledge) able to do this invariably,
>> some procedures may need to load the entire data set into RAM.
>>
>> JMP's data tables are limited by available RAM, just like R's are.
>>
>> R does have somewhat inefficient memory strategies (e.g., model matrices
>> may include multiple columns of binary variables, each using 8 bytes per
>> entry), so may run out of memory sooner than other programs, but it is not
>> like the competition is not RAM-restricted at all.
>
>
> Also 'hundreds of thousands of records' is not really very much: I have seen
> analyses of millions many times[*]: I have analysed a few billion with 0.3TB
> of RAM.
>
> [*] I recall a student fitting a GLM with about 30 predictors to 1.5m
> records: at the time (ca R 2.14) it did not fit in 4GB but did in 8GB.
>
>> - Peter D.
>>>
>>>
>>> On September 16, 2014 4:40:29 AM PDT, Barry King <barry.king at qlx.com>
>>> wrote:
>>>>
>>>> Is there a way to get around R?s memory-bound limitation by interfacing
>>>> with a Hadoop database or should I look at products like SAS or JMP to
>>>> work
>>>> with data that has hundreds of thousands of records?  Any help is
>>>> appreciated.
>>>>
>>>> --
>>>> __________________________
>>>> *Barry E. King, Ph.D.*
>>>> Analytics Modeler
>>>> Qualex Consulting Services, Inc.
>>>> Barry.King at qlx.com
>>>> O: (317)940-5464
>>>> M: (317)507-0661
>>>> __________________________
>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davide.chicco at gmail.com  Tue Sep 16 21:19:43 2014
From: davide.chicco at gmail.com (davide.chicco at gmail.com)
Date: Tue, 16 Sep 2014 15:19:43 -0400
Subject: [R] =?utf-8?b?Ui9VYnVudHUsIOKAnHBhY2thZ2Ug4oCYc3RhdHPigJkgaW4g?=
	=?utf-8?b?b3B0aW9ucyjigJ1kZWZhdWx0UGFja2FnZXPigJwpIHdhcyBub3QgZm91?=
	=?utf-8?b?bmTigJ0=?=
Message-ID: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>

Hi guys
I'm having some troubles in installing the "topicmodels" package in my
R system on a Linux Ubuntu machine.
I also described the problem here: http://bit.ly/1m8Ah6Z

I have just installed R 3.1.1 on my Linux Ubuntu 12.04.5 LTS. Then I
wanted to install the topicmodels package, and so I type
install.packages("topicmodels"), but the installation did not work.

It seems that I do not have the "stats" package installed in my
default packages. Here's the log:

++++++LOG+START++++++++++++++++++++

> install.packages("topicmodels");
Installing package into ?/usr/local/lib/R/site-library?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
also installing the dependencies ?modeltools?, ?slam?, ?tm?

provo con l'URL
'http://cran.utstat.utoronto.ca/src/contrib/modeltools_0.2-21.tar.gz'
Content type 'application/x-gzip' length 14794 bytes (14 Kb)
URL aperto
==================================================
downloaded 14 Kb

provo con l'URL 'http://cran.utstat.utoronto.ca/src/contrib/slam_0.1-32.tar.gz'
Content type 'application/x-gzip' length 46672 bytes (45 Kb)
URL aperto
==================================================
downloaded 45 Kb

provo con l'URL 'http://cran.utstat.utoronto.ca/src/contrib/tm_0.6.tar.gz'
Content type 'application/x-gzip' length 505212 bytes (493 Kb)
URL aperto
==================================================
downloaded 493 Kb

provo con l'URL
'http://cran.utstat.utoronto.ca/src/contrib/topicmodels_0.2-1.tar.gz'
Content type 'application/x-gzip' length 847889 bytes (828 Kb)
URL aperto
==================================================
downloaded 828 Kb

Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
  /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
Durante l'avvio - Warning message:
package ?stats? in options("defaultPackages") was not found
* installing *source* package ?modeltools? ...
** package ?modeltools? successfully unpacked and MD5 sums checked
** R
** inst
** preparing package for lazy loading
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
  /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
Error : package ?stats? could not be loaded
ERROR: lazy loading failed for package ?modeltools?
* removing ?/usr/local/lib/R/site-library/modeltools?
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
  /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
Durante l'avvio - Warning message:
package ?stats? in options("defaultPackages") was not found
* installing *source* package ?slam? ...
** package ?slam? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c apply.c -o apply.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c grouped.c -o
grouped.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c sparse.c -o
sparse.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c util.c -o util.o
gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o
slam.so apply.o grouped.o sparse.o util.o -lblas -lgfortran -lm
-lquadmath -L/usr/lib/R/lib -lR
installing to /usr/local/lib/R/site-library/slam/libs
** R
** preparing package for lazy loading
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
  /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
ERROR: lazy loading failed for package ?slam?
* removing ?/usr/local/lib/R/site-library/slam?
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
  /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
Durante l'avvio - Warning message:
package ?stats? in options("defaultPackages") was not found
ERROR: dependency ?slam? is not available for package ?tm?
* removing ?/usr/local/lib/R/site-library/tm?
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
  /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
Durante l'avvio - Warning message:
package ?stats? in options("defaultPackages") was not found
ERROR: dependencies ?modeltools?, ?slam?, ?tm? are not available for
package ?topicmodels?
* removing ?/usr/local/lib/R/site-library/topicmodels?

The downloaded source packages are in
    ?/tmp/RtmpIppG4O/downloaded_packages?
Warning messages:
1: In install.packages("topicmodels") :
  installation of package ?modeltools? had non-zero exit status
2: In install.packages("topicmodels") :
  installation of package ?slam? had non-zero exit status
3: In install.packages("topicmodels") :
  installation of package ?tm? had non-zero exit status
4: In install.packages("topicmodels") :
  installation of package ?topicmodels? had non-zero exit status

++++++LOG+END++++++++++++++++++++

Here's the output of the dpkg -l | grep "blas\|atlas" command:

ii  libatlas3gf-base   3.8.4-3build1  Automatically Tuned Linear
Algebra Software, generic shared
ii  libblas-dev        1.2.20110419-2ubuntu1  Basic Linear Algebra
Subroutines 3, static library
ii  libblas3gf         1.2.20110419-2ubuntu1  Basic Linear Algebra
Reference implementations, shared library
ii  libopenblas-base   0.1alpha2.2-3  Optimized BLAS (linear algebra)
library based on GotoBLAS2
ii  libopenblas-dev    0.1alpha2.2-3  Optimized BLAS (linear algebra)
library based on GotoBLAS2

Do you have any idea on how to solve this problem?

Thanks a lot!

-- Davide


::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
  Davide Chicco
Postdoctoral Fellow
Princess Margaret Cancer Centre, University of Toronto
Toronto Medical Discovery Tower 11-401
101 College St, Toronto, Ontario M5G 1L7, Canada
mail: davide.chicco at gmail.com
web: http://www.davidechicco.it
::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::


From dpierce at ucsd.edu  Tue Sep 16 22:21:57 2014
From: dpierce at ucsd.edu (David W. Pierce)
Date: Tue, 16 Sep 2014 13:21:57 -0700
Subject: [R] ncdf size error
In-Reply-To: <1410892579836.91251@uwyo.edu>
References: <338322FF-7ADA-48DC-BC76-47AF0BEE042A@uwyo.edu>
	<CAL+Zad8AnjLMq0VKwj+nbNTEN_DD01RV0T9VneinBW295frNkQ@mail.gmail.com>
	<1410892579836.91251@uwyo.edu>
Message-ID: <CAL+Zad9ixUzq=cHrYf+WcqQV2EcmEbL=kiB-7u9WkBZcVxTiHg@mail.gmail.com>

On Tue, Sep 16, 2014 at 11:36 AM, Hernan A. Moreno Ramirez
<hmorenor at uwyo.edu> wrote:
> Sure, here it is. Thanks for any help with this Dr. Pierce:
>
>
> ##### Exporting to NETCDF files #################################################################
> # define the netcdf coordinate variables
> library(ncdf)

... rest of example omitted ...

Hi Hernan,

The file you are trying to make is violating size constraints imposed
by the netcdf library/R interface, which is 2 GB in the R ncdf
package. To get around this switch to the R ncdf4 package, which is
the replacement for the ncdf package (I stopped supporting the ncdf
package in 2010) and set force_v4=TRUE in the nc_create() call. This
requires a modern version of the netcdf library to be installed on
your machine, which it probably is, since the netcdf version 4 library
has been out for many years now.

Regards,

--Dave

> http://www.public.asu.edu/~hamoreno/
>
> ________________________________________
> From: davidwilliampierce at gmail.com <davidwilliampierce at gmail.com> on behalf of David W. Pierce <dpierce at ucsd.edu>
> Sent: Monday, September 15, 2014 7:00 PM
> To: Hernan A. Moreno Ramirez
> Cc: r-help at r-project.org
> Subject: Re: [R] ncdf size error
>
> On Mon, Sep 15, 2014 at 4:20 PM, Hernan A. Moreno Ramirez
> <hmorenor at uwyo.edu> wrote:
>>
>> Hi I am using both ncdf and ncdf4 libraries and with both I keep getting the
>> same error: Error in R_nc_enddef: NetCDF: One or more variable sizes violate
>> format constraints. Error in R_nc_sync: NetCDF: Operation not allowed in
>> define mode. This happens when I try to create.ncdf() a file with more than
>> 13 variables. I think is a problem of memory size. What would you recommend?
>> Any help will be appreciated
>
> Hi Hernan,
>
> can you supply an example that shows the problem?
>
> Regards,
>
> --Dave
>
> -------------------
> David W. Pierce
> Division of Climate, Atmospheric Science, and Physical Oceanography
> Scripps Institution of Oceanography, La Jolla, California, USA
> (858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu



-- 
David W. Pierce
Division of Climate, Atmospheric Science, and Physical Oceanography
Scripps Institution of Oceanography, La Jolla, California, USA
(858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu


From dpierce at ucsd.edu  Tue Sep 16 23:08:15 2014
From: dpierce at ucsd.edu (David W. Pierce)
Date: Tue, 16 Sep 2014 14:08:15 -0700
Subject: [R] ncdf size error
In-Reply-To: <1410901316667.73449@uwyo.edu>
References: <338322FF-7ADA-48DC-BC76-47AF0BEE042A@uwyo.edu>
	<CAL+Zad8AnjLMq0VKwj+nbNTEN_DD01RV0T9VneinBW295frNkQ@mail.gmail.com>
	<1410892579836.91251@uwyo.edu>
	<CAL+Zad9ixUzq=cHrYf+WcqQV2EcmEbL=kiB-7u9WkBZcVxTiHg@mail.gmail.com>
	<1410901316667.73449@uwyo.edu>
Message-ID: <CAL+Zad8q-Y7A4ZAofu3U0ti34fatBBuhg9ZeLFtC6dfihrL3LQ@mail.gmail.com>

Remember, you have to *also* set force_v4=TRUE in the nc_create() call.

Regards,

--Dave

On Tue, Sep 16, 2014 at 2:01 PM, Hernan A. Moreno Ramirez
<hmorenor at uwyo.edu> wrote:
> Hi Professor,
>
> Thanks for you valuable help. I did change my code to use ncdf4 package and still I get the same error:
>
> ##### Exporting to NETCDF files #################################################################
> # define the netcdf coordinate variables -- note these have values!
> library(ncdf4)
> cat("--Exporting final NETCDF file to Outputfolder",fill=TRUE)
> dim1 = ncdim_def( "Nodes","", seq(1,19000))
> dim2= ncdim_def( "Time","Hours since 2005-01-01 00:00:00",seq(1:2190)) #final[1,2,]))
> #dim2= dim.def.ncdf( "Time","",as.data.frame(final[1,2,]))
>
>
> # define the EMPTY (elevation) netcdf variable
> varT2 = ncvar_def("T2","celsius", list(dim1,dim2), -99999, longname="T2")
> varQ2 = ncvar_def("Q2","kg kg-1", list(dim1,dim2), -99999, longname="Q2")
> varQVAPOR = ncvar_def("QVAPOR","kg kg-1", list(dim1,dim2), -99999, longname="QVAPOR")
> varQCLOUD = ncvar_def("QCLOUD","kg kg-1", list(dim1,dim2), -99999, longname="QCLOUD")
> varPSFC = ncvar_def("PSFC","Pa", list(dim1,dim2), -99999, longname="PSFC")
> varW10 = ncvar_def("W10","ms-1", list(dim1,dim2), -99999, longname="W10")
> varW = ncvar_def("W","ms-1", list(dim1,dim2), -99999, longname="W")
> varVEGFRA = ncvar_def("VEGFRA","", list(dim1,dim2), -99999, longname="VEGFRA")
> varMAXVEGFRA = ncvar_def("MAXVEGFRA","", list(dim1,dim2), -99999, longname="MAXVEGFRA")
> varTPREC = ncvar_def("TPREC","mm", list(dim1,dim2), -99999, longname="TPREC")
> varFRAC_FROZ_PREC = ncvar_def("FRAC_FROZ_PREC","mm", list(dim1,dim2), -99999, longname="FRAC_FROZ_PREC")
> varSWDOWN = ncvar_def("SWDOWN","W m-2", list(dim1,dim2), -99999, longname="SWDOWN")
> varGLW = ncvar_def("GLW","W m-2", list(dim1,dim2), -99999, longname="GLW")
> varPBLH = ncvar_def("PBLH","m", list(dim1,dim2), -99999, longname="PBLH")
> varTSLB = ncvar_def("TSLB","Celsius", list(dim1,dim2), -99999, longname="TSLB")
>
> nc.ex = nc_create("/media/D/output.nc",list(varT2, varQ2, varQVAPOR, varQCLOUD, varPSFC, varW10, varW, varVEGFRA, varMAXVEGFRA, varTPREC, varFRAC_FROZ_PREC, varSWDOWN, varGLW, varPBLH, varTSLB))
>
> Error in R_nc4_enddef: NetCDF: One or more variable sizes violate format constraints
> Error in R_nc4_sync: NetCDF: Operation not allowed in define mode
>
> Thanks a lot for more help
>
> ---------------------------------------------------------------------------------------
> Hernan A. Moreno, Ph.D.
> Postdoctoral Research Associate
> Department of Civil & Architectural Engineering
> Room 3038, Engineering Building
> University of Wyoming
> Phone: 480-3990571
> http://www.public.asu.edu/~hamoreno/
>
> ________________________________________
> From: davidwilliampierce at gmail.com <davidwilliampierce at gmail.com> on behalf of David W. Pierce <dpierce at ucsd.edu>
> Sent: Tuesday, September 16, 2014 2:21 PM
> To: Hernan A. Moreno Ramirez
> Cc: r-help at r-project.org
> Subject: Re: [R] ncdf size error
>
> On Tue, Sep 16, 2014 at 11:36 AM, Hernan A. Moreno Ramirez
> <hmorenor at uwyo.edu> wrote:
>> Sure, here it is. Thanks for any help with this Dr. Pierce:
>>
>>
>> ##### Exporting to NETCDF files #################################################################
>> # define the netcdf coordinate variables
>> library(ncdf)
>
> ... rest of example omitted ...
>
> Hi Hernan,
>
> The file you are trying to make is violating size constraints imposed
> by the netcdf library/R interface, which is 2 GB in the R ncdf
> package. To get around this switch to the R ncdf4 package, which is
> the replacement for the ncdf package (I stopped supporting the ncdf
> package in 2010) and set force_v4=TRUE in the nc_create() call. This
> requires a modern version of the netcdf library to be installed on
> your machine, which it probably is, since the netcdf version 4 library
> has been out for many years now.
>
> Regards,
>
> --Dave
>
>> http://www.public.asu.edu/~hamoreno/
>>
>> ________________________________________
>> From: davidwilliampierce at gmail.com <davidwilliampierce at gmail.com> on behalf of David W. Pierce <dpierce at ucsd.edu>
>> Sent: Monday, September 15, 2014 7:00 PM
>> To: Hernan A. Moreno Ramirez
>> Cc: r-help at r-project.org
>> Subject: Re: [R] ncdf size error
>>
>> On Mon, Sep 15, 2014 at 4:20 PM, Hernan A. Moreno Ramirez
>> <hmorenor at uwyo.edu> wrote:
>>>
>>> Hi I am using both ncdf and ncdf4 libraries and with both I keep getting the
>>> same error: Error in R_nc_enddef: NetCDF: One or more variable sizes violate
>>> format constraints. Error in R_nc_sync: NetCDF: Operation not allowed in
>>> define mode. This happens when I try to create.ncdf() a file with more than
>>> 13 variables. I think is a problem of memory size. What would you recommend?
>>> Any help will be appreciated
>>
>> Hi Hernan,
>>
>> can you supply an example that shows the problem?
>>
>> Regards,
>>
>> --Dave
>>
>> -------------------
>> David W. Pierce
>> Division of Climate, Atmospheric Science, and Physical Oceanography
>> Scripps Institution of Oceanography, La Jolla, California, USA
>> (858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu
>
>
>
> --
> David W. Pierce
> Division of Climate, Atmospheric Science, and Physical Oceanography
> Scripps Institution of Oceanography, La Jolla, California, USA
> (858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu



-- 
David W. Pierce
Division of Climate, Atmospheric Science, and Physical Oceanography
Scripps Institution of Oceanography, La Jolla, California, USA
(858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu


From dwinsemius at comcast.net  Tue Sep 16 23:15:44 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 16 Sep 2014 14:15:44 -0700
Subject: [R]
 =?windows-1252?q?R/Ubuntu=2C_=93package_=91stats=92_in_option?=
 =?windows-1252?q?s=28=94defaultPackages=93=29_was_not_found=94?=
In-Reply-To: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
References: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
Message-ID: <02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>


On Sep 16, 2014, at 12:19 PM, davide.chicco at gmail.com wrote:

> Hi guys
> I'm having some troubles in installing the "topicmodels" package in my
> R system on a Linux Ubuntu machine.
> I also described the problem here: http://bit.ly/1m8Ah6Z

(You were asked in the Posting Guide to not crosspost. And when you post to Stack Overflow you should respond to requests for clarification which you have not done either. You will never get useful answers if you don't respond to requests for clarification.)

> 
> I have just installed R 3.1.1 on my Linux Ubuntu 12.04.5 LTS.

More details are needed. How did you do this?


> Then Iwanted to install the topicmodels package, and so I type
> install.packages("topicmodels"), but the installation did not work.

> It seems that I do not have the "stats" package installed in my
> default packages.

That would be somewhat unusual, but possible. You were asked in the Rhelp Posting Guide to provide the output of sessionInfo().



-- 
David.


]
> Here's the log:
> 
> ++++++LOG+START++++++++++++++++++++
> 
>> install.packages("topicmodels");
> Installing package into ?/usr/local/lib/R/site-library?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> also installing the dependencies ?modeltools?, ?slam?, ?tm?
> 
> provo con l'URL
> 'http://cran.utstat.utoronto.ca/src/contrib/modeltools_0.2-21.tar.gz'
> Content type 'application/x-gzip' length 14794 bytes (14 Kb)
> URL aperto
> ==================================================
> downloaded 14 Kb
> 
> provo con l'URL 'http://cran.utstat.utoronto.ca/src/contrib/slam_0.1-32.tar.gz'
> Content type 'application/x-gzip' length 46672 bytes (45 Kb)
> URL aperto
> ==================================================
> downloaded 45 Kb
> 
> provo con l'URL 'http://cran.utstat.utoronto.ca/src/contrib/tm_0.6.tar.gz'
> Content type 'application/x-gzip' length 505212 bytes (493 Kb)
> URL aperto
> ==================================================
> downloaded 493 Kb
> 
> provo con l'URL
> 'http://cran.utstat.utoronto.ca/src/contrib/topicmodels_0.2-1.tar.gz'
> Content type 'application/x-gzip' length 847889 bytes (828 Kb)
> URL aperto
> ==================================================
> downloaded 828 Kb
> 
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
> Durante l'avvio - Warning message:
> package ?stats? in options("defaultPackages") was not found
> * installing *source* package ?modeltools? ...
> ** package ?modeltools? successfully unpacked and MD5 sums checked
> ** R
> ** inst
> ** preparing package for lazy loading
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
> Error : package ?stats? could not be loaded
> ERROR: lazy loading failed for package ?modeltools?
> * removing ?/usr/local/lib/R/site-library/modeltools?
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
> Durante l'avvio - Warning message:
> package ?stats? in options("defaultPackages") was not found
> * installing *source* package ?slam? ...
> ** package ?slam? successfully unpacked and MD5 sums checked
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c apply.c -o apply.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c grouped.c -o
> grouped.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c sparse.c -o
> sparse.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c util.c -o util.o
> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o
> slam.so apply.o grouped.o sparse.o util.o -lblas -lgfortran -lm
> -lquadmath -L/usr/lib/R/lib -lR
> installing to /usr/local/lib/R/site-library/slam/libs
> ** R
> ** preparing package for lazy loading
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
> ERROR: lazy loading failed for package ?slam?
> * removing ?/usr/local/lib/R/site-library/slam?
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
> Durante l'avvio - Warning message:
> package ?stats? in options("defaultPackages") was not found
> ERROR: dependency ?slam? is not available for package ?tm?
> * removing ?/usr/local/lib/R/site-library/tm?
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
> Durante l'avvio - Warning message:
> package ?stats? in options("defaultPackages") was not found
> ERROR: dependencies ?modeltools?, ?slam?, ?tm? are not available for
> package ?topicmodels?
> * removing ?/usr/local/lib/R/site-library/topicmodels?
> 
> The downloaded source packages are in
>   ?/tmp/RtmpIppG4O/downloaded_packages?
> Warning messages:
> 1: In install.packages("topicmodels") :
> installation of package ?modeltools? had non-zero exit status
> 2: In install.packages("topicmodels") :
> installation of package ?slam? had non-zero exit status
> 3: In install.packages("topicmodels") :
> installation of package ?tm? had non-zero exit status
> 4: In install.packages("topicmodels") :
> installation of package ?topicmodels? had non-zero exit status
> 
> ++++++LOG+END++++++++++++++++++++
> 
> Here's the output of the dpkg -l | grep "blas\|atlas" command:
> 
> ii  libatlas3gf-base   3.8.4-3build1  Automatically Tuned Linear
> Algebra Software, generic shared
> ii  libblas-dev        1.2.20110419-2ubuntu1  Basic Linear Algebra
> Subroutines 3, static library
> ii  libblas3gf         1.2.20110419-2ubuntu1  Basic Linear Algebra
> Reference implementations, shared library
> ii  libopenblas-base   0.1alpha2.2-3  Optimized BLAS (linear algebra)
> library based on GotoBLAS2
> ii  libopenblas-dev    0.1alpha2.2-3  Optimized BLAS (linear algebra)
> library based on GotoBLAS2
> 
> Do you have any idea on how to solve this problem?
> 
> Thanks a lot!
> 
> -- Davide
> 
> 
> ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
> Davide Chicco
> Postdoctoral Fellow
> Princess Margaret Cancer Centre, University of Toronto
> Toronto Medical Discovery Tower 11-401
> 101 College St, Toronto, Ontario M5G 1L7, Canada
> mail: davide.chicco at gmail.com
> web: http://www.davidechicco.it
> ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From hmorenor at uwyo.edu  Tue Sep 16 23:01:58 2014
From: hmorenor at uwyo.edu (Hernan A. Moreno Ramirez)
Date: Tue, 16 Sep 2014 21:01:58 +0000
Subject: [R] ncdf size error
In-Reply-To: <CAL+Zad9ixUzq=cHrYf+WcqQV2EcmEbL=kiB-7u9WkBZcVxTiHg@mail.gmail.com>
References: <338322FF-7ADA-48DC-BC76-47AF0BEE042A@uwyo.edu>
	<CAL+Zad8AnjLMq0VKwj+nbNTEN_DD01RV0T9VneinBW295frNkQ@mail.gmail.com>
	<1410892579836.91251@uwyo.edu>,
	<CAL+Zad9ixUzq=cHrYf+WcqQV2EcmEbL=kiB-7u9WkBZcVxTiHg@mail.gmail.com>
Message-ID: <1410901316667.73449@uwyo.edu>

Hi Professor,

Thanks for you valuable help. I did change my code to use ncdf4 package and still I get the same error:

##### Exporting to NETCDF files #################################################################
# define the netcdf coordinate variables -- note these have values!
library(ncdf4)
cat("--Exporting final NETCDF file to Outputfolder",fill=TRUE)
dim1 = ncdim_def( "Nodes","", seq(1,19000))
dim2= ncdim_def( "Time","Hours since 2005-01-01 00:00:00",seq(1:2190)) #final[1,2,]))
#dim2= dim.def.ncdf( "Time","",as.data.frame(final[1,2,])) 


# define the EMPTY (elevation) netcdf variable
varT2 = ncvar_def("T2","celsius", list(dim1,dim2), -99999, longname="T2")
varQ2 = ncvar_def("Q2","kg kg-1", list(dim1,dim2), -99999, longname="Q2")
varQVAPOR = ncvar_def("QVAPOR","kg kg-1", list(dim1,dim2), -99999, longname="QVAPOR")
varQCLOUD = ncvar_def("QCLOUD","kg kg-1", list(dim1,dim2), -99999, longname="QCLOUD")
varPSFC = ncvar_def("PSFC","Pa", list(dim1,dim2), -99999, longname="PSFC")
varW10 = ncvar_def("W10","ms-1", list(dim1,dim2), -99999, longname="W10")
varW = ncvar_def("W","ms-1", list(dim1,dim2), -99999, longname="W")
varVEGFRA = ncvar_def("VEGFRA","", list(dim1,dim2), -99999, longname="VEGFRA")
varMAXVEGFRA = ncvar_def("MAXVEGFRA","", list(dim1,dim2), -99999, longname="MAXVEGFRA")
varTPREC = ncvar_def("TPREC","mm", list(dim1,dim2), -99999, longname="TPREC")
varFRAC_FROZ_PREC = ncvar_def("FRAC_FROZ_PREC","mm", list(dim1,dim2), -99999, longname="FRAC_FROZ_PREC")
varSWDOWN = ncvar_def("SWDOWN","W m-2", list(dim1,dim2), -99999, longname="SWDOWN")
varGLW = ncvar_def("GLW","W m-2", list(dim1,dim2), -99999, longname="GLW")
varPBLH = ncvar_def("PBLH","m", list(dim1,dim2), -99999, longname="PBLH")
varTSLB = ncvar_def("TSLB","Celsius", list(dim1,dim2), -99999, longname="TSLB")

nc.ex = nc_create("/media/D/output.nc",list(varT2, varQ2, varQVAPOR, varQCLOUD, varPSFC, varW10, varW, varVEGFRA, varMAXVEGFRA, varTPREC, varFRAC_FROZ_PREC, varSWDOWN, varGLW, varPBLH, varTSLB))

Error in R_nc4_enddef: NetCDF: One or more variable sizes violate format constraints
Error in R_nc4_sync: NetCDF: Operation not allowed in define mode

Thanks a lot for more help

---------------------------------------------------------------------------------------
Hernan A. Moreno, Ph.D.
Postdoctoral Research Associate
Department of Civil & Architectural Engineering
Room 3038, Engineering Building
University of Wyoming
Phone: 480-3990571
http://www.public.asu.edu/~hamoreno/

________________________________________
From: davidwilliampierce at gmail.com <davidwilliampierce at gmail.com> on behalf of David W. Pierce <dpierce at ucsd.edu>
Sent: Tuesday, September 16, 2014 2:21 PM
To: Hernan A. Moreno Ramirez
Cc: r-help at r-project.org
Subject: Re: [R] ncdf size error

On Tue, Sep 16, 2014 at 11:36 AM, Hernan A. Moreno Ramirez
<hmorenor at uwyo.edu> wrote:
> Sure, here it is. Thanks for any help with this Dr. Pierce:
>
>
> ##### Exporting to NETCDF files #################################################################
> # define the netcdf coordinate variables
> library(ncdf)

... rest of example omitted ...

Hi Hernan,

The file you are trying to make is violating size constraints imposed
by the netcdf library/R interface, which is 2 GB in the R ncdf
package. To get around this switch to the R ncdf4 package, which is
the replacement for the ncdf package (I stopped supporting the ncdf
package in 2010) and set force_v4=TRUE in the nc_create() call. This
requires a modern version of the netcdf library to be installed on
your machine, which it probably is, since the netcdf version 4 library
has been out for many years now.

Regards,

--Dave

> http://www.public.asu.edu/~hamoreno/
>
> ________________________________________
> From: davidwilliampierce at gmail.com <davidwilliampierce at gmail.com> on behalf of David W. Pierce <dpierce at ucsd.edu>
> Sent: Monday, September 15, 2014 7:00 PM
> To: Hernan A. Moreno Ramirez
> Cc: r-help at r-project.org
> Subject: Re: [R] ncdf size error
>
> On Mon, Sep 15, 2014 at 4:20 PM, Hernan A. Moreno Ramirez
> <hmorenor at uwyo.edu> wrote:
>>
>> Hi I am using both ncdf and ncdf4 libraries and with both I keep getting the
>> same error: Error in R_nc_enddef: NetCDF: One or more variable sizes violate
>> format constraints. Error in R_nc_sync: NetCDF: Operation not allowed in
>> define mode. This happens when I try to create.ncdf() a file with more than
>> 13 variables. I think is a problem of memory size. What would you recommend?
>> Any help will be appreciated
>
> Hi Hernan,
>
> can you supply an example that shows the problem?
>
> Regards,
>
> --Dave
>
> -------------------
> David W. Pierce
> Division of Climate, Atmospheric Science, and Physical Oceanography
> Scripps Institution of Oceanography, La Jolla, California, USA
> (858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu



--
David W. Pierce
Division of Climate, Atmospheric Science, and Physical Oceanography
Scripps Institution of Oceanography, La Jolla, California, USA
(858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu


From danielmiquelluti at yahoo.com.br  Tue Sep 16 22:06:47 2014
From: danielmiquelluti at yahoo.com.br (Daniel Miquelluti)
Date: Tue, 16 Sep 2014 13:06:47 -0700
Subject: [R] Problem when estimating through "dlm" package
Message-ID: <1410898007.99865.YahooMailNeo@web162902.mail.bf1.yahoo.com>

I'm trying to set up an AR(2) model in the dlm context. I've generated a time series utilizing the code: 

    am = 800; #sample size 
    des = 200; #initial values to be discarded 
    V = 0.5 
    v = rnorm((am+des+1),0,sqrt(V)) 
    W = 0.9 
    w = rnorm((am+des+1),0,sqrt(W)) 
    U = 0.9 
    u = rnorm((am+des+1),0,sqrt(U)) 
    phi1 = 0.6; 
    phi2 = -0.4; 
    mu=matrix(0,nrow=(am+des+1)) 
    mu[2,1] = 10; 
    x=matrix(0,nrow=(am+des+1)) 
    x[1,1] = 0; 
    x[2,1] = 0; 
    #---------------------------------------------------------- 
   yg=NULL 
   for (i in 3:(am+des+1)) { 
       mu[i] = mu[i-1] + w[i] 
       x[i] = phi1*x[i-1] + phi2*x[i-2] + u[i] 
       yg[i] = mu[i] + x[i] + v[i] 
      } 

     y=NULL 
     for (i in 1:(am + 1)) { 
     y[i] = yg[(i+des)] 
     } 
And obtained the estimates through: 

     buildfun = function(theta) { 
     dlm(FF=t(c(1,1,0)),GG=matrix(c(1,0,0,0,theta[1],theta[2],0,1,0),nrow=3,byrow=T), 
     V=exp(theta[3]),W=diag(c(exp(theta[4]),exp(theta[5]),0)), 
     m0=c(0,0,0),C0=diag(c(0.3,0.8,0.7))) 
     } 

     estMLE = dlmMLE (y, parm = c(0,0,0,0,0), build=buildfun) 
     phis=estMLE$par[1:2] 
     variances=exp(estMLE$par[3:5]) 
     c(phis,variances) 

The estimates are not very close to the values defined in the series generated. I think there is some sort of problem in the model specified in "buildfun", however, I cannot identify it. Any help is appreciated.

	[[alternative HTML version deleted]]


From Kristopher.Jones at water.ca.gov  Tue Sep 16 22:17:00 2014
From: Kristopher.Jones at water.ca.gov (Jones, Kristopher@DWR)
Date: Tue, 16 Sep 2014 20:17:00 +0000
Subject: [R] Changepoint analysis--is it possible to attribute changpoints
 to explanatory variables?
Message-ID: <35E09CCCBBCF4944A3DA18A09AB5A66C0873EE12@057-SN2MPN2-112.057d.mgd.msft.net>

Hello, 

I would like to evaluate the relationship between flows and phytoplankton abundance (or Chlorophyll a concentrations) using a changepoint analysis.? Specifically, I have two study questions:

Study Question 1: Are there certain flow thresholds that result in spikes in phytoplankton abundance?
Study Question 2: Are the duration of certain flows important for phytoplankton abundance (e.g., would a certain flow value need to be reached for 1 day, 1 week etc. to create a spike in phytoplankton abundance)? 

Many of the examples I've seen online have only looked for change points in a time series.? However, I have not seen any examples, which look at whether changes in the mean or variance can be attributed to a particular factor (e.g., changes in abundance relative to an environmental factor).? 

Question #1: Is it possible to attribute changes in the mean or variance of a time series (e.g., of phytoplankton abundance) to a particular environmental variable (e.g., flows)?  If so, can you provide guidance for how to do that in R (or refer me to a good example)?

Question #2: is it possible to take Question #1 a step further, adding a time component (as described in study question 2, above)? If so, can you provide guidance for how to do that in R (or refer me to a good example)?

One resource on changepoint analyses (using changepoint package) that I have been trying to model my work after (at least the R code) is by Killick and Eckley (Lancaster University).? 
http://www.lancs.ac.uk/~killick/Pub/KillickEckley2011.pdf

Their descriptions and the accompanying code were really helpful (although, their questions were not similar to mine, as described above).? In reviewing this document, and other descriptions online, I've noticed that data for changepoint analyses need to be in a time series.? My data is set up with columns of sampling date, Chlorophyll a concentration, and stage (a surrogate for flow).  In reviewing the help online regarding changepoint, I realized that the data I am using would likely not be considered a 'time series', as the sampling did not occur at uniform time intervals. 

Question #3: Do data for changepoint analyses in R need to be at uniform time intervals?? If so, is there an appropriate way to transform my data (which was not collected at uniform time intervals) to make it work in changepoint?

Question #4: Do data in the time series need to be transformed (e.g., Chlorophyll a and Stage)?

Hopefully, I've laid out my question in a way that makes sense.? Any help you can provide would be much appreciated.? I've been trying to read up on this for a while, and have tried to narrow my questions down to those with which I am still struggling.

Thanks in advance for your help.

Kris





? 


From isabella at ghement.ca  Wed Sep 17 00:06:21 2014
From: isabella at ghement.ca (isabella at ghement.ca)
Date: Tue, 16 Sep 2014 17:06:21 -0500
Subject: [R] Error in predict.lm() for models with no intercept?
Message-ID: <64807.1410905181@ghement.ca>

 

	Hi everyone,  

	Could there be an error in the predict() function in R for models
without intercepts which include one or more predictors?  When using
the predict() function to obtain the standard errors of the fitted
values produced by a linear model (lm), the behaviour of the standard
errors seems to mirror that of models which include an intercept
(which should not happen).   

	Here is an attempt to produce standard errors (and hence confidence
bands) for the fitted values in a linear model with a single predictor
and no intercept using R code: 

	## simulate a response y and two predictors x and z  

	x 
	[[alternative HTML version deleted]]


From isabella at ghement.ca  Wed Sep 17 00:09:21 2014
From: isabella at ghement.ca (isabella at ghement.ca)
Date: Tue, 16 Sep 2014 17:09:21 -0500
Subject: [R] Error in predict.lm() for models with no intercept?
Message-ID: <64857.1410905361@ghement.ca>

 

	Hi Antonio,  

	I've just sent an e-mail to the r-help list with some R code which
shows that the standard errors of the fitted values are indeed
computed incorrectly by R (please see below).  Let's hope that there
will be at least one helpful answer to the question.   

	Best,  

	Isabella 
 On Tue 16/09/14 3:06 PM , isabella at ghement.ca sent:
	Hi everyone,  

	Could there be an error in the predict() function in R for models
without intercepts which include one or more predictors?  When using
the predict() function to obtain the standard errors of the fitted
values produced by a linear model (lm), the behaviour of the standard
errors seems to mirror that of models which include an intercept
(which should not happen).   

	Here is an attempt to produce standard errors (and hence confidence
bands) for the fitted values in a linear model with a single predictor
and no intercept using R code: 

	## simulate a response y and two predictors x and z  

	x 
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Wed Sep 17 00:14:15 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 16 Sep 2014 15:14:15 -0700
Subject: [R] Changepoint analysis--is it possible to attribute
 changpoints to explanatory variables?
In-Reply-To: <35E09CCCBBCF4944A3DA18A09AB5A66C0873EE12@057-SN2MPN2-112.057d.mgd.msft.net>
References: <35E09CCCBBCF4944A3DA18A09AB5A66C0873EE12@057-SN2MPN2-112.057d.mgd.msft.net>
Message-ID: <CACk-te1YjEarYGCu3HA3yTna_yD_kUr4N3mH6_a8OU-k3SVwTA@mail.gmail.com>

This is primarily a statistical issue and is offtopic here.

I would strongly suggest that you consult with a local statistical
expert. The answer is almost certainly yes: this is regression
(perhaps quantile regression) in which the error structure is not iid
(the response is an autocorrelated time series) and there probably is
inertia in the system, too.  So it may be complicated. That's why you
need to spend time with someone who knows how to handle this.
Econometricians tend to do this sort of thing I believe.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Sep 16, 2014 at 1:17 PM, Jones, Kristopher at DWR
<Kristopher.Jones at water.ca.gov> wrote:
> Hello,
>
> I would like to evaluate the relationship between flows and phytoplankton abundance (or Chlorophyll a concentrations) using a changepoint analysis.  Specifically, I have two study questions:
>
> Study Question 1: Are there certain flow thresholds that result in spikes in phytoplankton abundance?
> Study Question 2: Are the duration of certain flows important for phytoplankton abundance (e.g., would a certain flow value need to be reached for 1 day, 1 week etc. to create a spike in phytoplankton abundance)?
>
> Many of the examples I've seen online have only looked for change points in a time series.  However, I have not seen any examples, which look at whether changes in the mean or variance can be attributed to a particular factor (e.g., changes in abundance relative to an environmental factor).
>
> Question #1: Is it possible to attribute changes in the mean or variance of a time series (e.g., of phytoplankton abundance) to a particular environmental variable (e.g., flows)?  If so, can you provide guidance for how to do that in R (or refer me to a good example)?
>
> Question #2: is it possible to take Question #1 a step further, adding a time component (as described in study question 2, above)? If so, can you provide guidance for how to do that in R (or refer me to a good example)?
>
> One resource on changepoint analyses (using changepoint package) that I have been trying to model my work after (at least the R code) is by Killick and Eckley (Lancaster University).
> http://www.lancs.ac.uk/~killick/Pub/KillickEckley2011.pdf
>
> Their descriptions and the accompanying code were really helpful (although, their questions were not similar to mine, as described above).  In reviewing this document, and other descriptions online, I've noticed that data for changepoint analyses need to be in a time series.  My data is set up with columns of sampling date, Chlorophyll a concentration, and stage (a surrogate for flow).  In reviewing the help online regarding changepoint, I realized that the data I am using would likely not be considered a 'time series', as the sampling did not occur at uniform time intervals.
>
> Question #3: Do data for changepoint analyses in R need to be at uniform time intervals?  If so, is there an appropriate way to transform my data (which was not collected at uniform time intervals) to make it work in changepoint?
>
> Question #4: Do data in the time series need to be transformed (e.g., Chlorophyll a and Stage)?
>
> Hopefully, I've laid out my question in a way that makes sense.  Any help you can provide would be much appreciated.  I've been trying to read up on this for a while, and have tried to narrow my questions down to those with which I am still struggling.
>
> Thanks in advance for your help.
>
> Kris
>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Wed Sep 17 00:42:39 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 16 Sep 2014 18:42:39 -0400
Subject: [R] Error in predict.lm() for models with no intercept?
In-Reply-To: <64807.1410905181@ghement.ca>
References: <64807.1410905181@ghement.ca>
Message-ID: <CA+vqiLFtD3AcopfoPMYcdEqL572TEcVQ84U4Lz63d_+w5CAaPA@mail.gmail.com>

Hi,

Your example didn't come through, probably because you sent your message in
HTML. Please re send it in plain text (messages sent to this list should
always be plain text, as explained in the posting guide).

Best,
Ista


        Hi everyone,

        Could there be an error in the predict() function in R for models
without intercepts which include one or more predictors?  When using
the predict() function to obtain the standard errors of the fitted
values produced by a linear model (lm), the behaviour of the standard
errors seems to mirror that of models which include an intercept
(which should not happen).

        Here is an attempt to produce standard errors (and hence confidence
bands) for the fitted values in a linear model with a single predictor
and no intercept using R code:

        ## simulate a response y and two predictors x and z

        x
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From isabella at ghement.ca  Wed Sep 17 00:51:39 2014
From: isabella at ghement.ca (isabella at ghement.ca)
Date: Tue, 16 Sep 2014 17:51:39 -0500
Subject: [R] Error in predict.lm() for models without intercept?
Message-ID: <49847.1410907899@ghement.ca>

Hi everyone, 

It appears my R code didn't come through the first time (thanks for letting me know, Ista). Here is my message again: 

Could there be an error in the predict() function in R for models without intercepts which include one or more predictors?  
When using the predict() function to obtain the standard errors of the fitted values produced by a linear model (lm), the 
behaviour of the standard errors seems to mirror that of models which include an intercept (which should not happen).  

Here is an attempt to produce standard errors (and hence confidence bands) for the fitted values in a linear model with a 
single predictor and no intercept using R code:

## simulate a response y and two predictors x and z 

x <- rnorm(100,mean=0, sd=1)

z <- runif(100,min=-1,max=1)

y <- 1*x + 2*z + rnorm(100,mean=0, sd=1)


## fit a linear model with no intercept but with one predictor 

mod <- lm(y ~ 0 + x)

## compute confidence bands (i.e., fitted values +/- 1.96 standard errors of fitted values)

conf.band.x <- predict(mod,newdata=data.frame(x = seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01)), 
                           interval="confidence")

## display confidence bands

conf.band.x <- data.frame(lwr=conf.band.x[,"lwr"],
                              fit=conf.band.x[,"fit"],
                              upr=conf.band.x[,"upr"])

matplot(x=seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01), y=conf.band.x, type="l", xlab="x", ylab="y")
abline(v=mean(x),lty=3,col="magenta")
title("Effect of x on y")

According to statistical theory, in a model with no intercept and one predictor, the standard errors should be directly 
proportional to the value of x at which they are evaluated.  If x=0, the standard errors should also be zero. If x increases, 
the standard errors should also increase. The resulting plot produced by matplot shows this is not the case - the standard 
errors appear to increase as one moves away from the average value of x.  We would expect this behaviour if the model included 
an intercept, which is not the case here.  

Here is some R code for looking at standard errors of fitted values when the model includes no intercept and two predictors x 
and z.  In this code, the value of the predictor z is set to its average level. 
## linear model with no intercept but with two predictors 

mod <- lm(y ~ 0 + x + z)

conf.band.x <- predict(mod,newdata=data.frame(x = seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01),
                                                  z = mean(z)), 
                           interval="confidence")

conf.band.x <- data.frame(lwr=conf.band.x[,"lwr"],
                              fit=conf.band.x[,"fit"],
                              upr=conf.band.x[,"upr"])

matplot(x=seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01), y=conf.band.x, type="l", xlab="x", ylab="y")
abline(v=mean(x),lty=3,col="magenta")
title("Partial Effect of x on y (obtained by setting z to its average level)")

Again, the standard errors seem to behave as though they would come from a model with an intercept (given that they are 
flaring up as one moves away from the average value of the predictor x).

I would very much appreciate any clarifications or suggestions for how to fix this problem. 

If the problem is confirmed, it appears to also carry over to the effects package in R, which constructs plots similar to the 
ones produced by matplot above by relying on the predict() function.  

Many thanks, 

Isabella 


Isabella R. Ghement, Ph.D. 
Ghement Statistical Consulting Company Ltd. 
301-7031 Blundell Road, Richmond, B.C., Canada, V6Y 1J5 
Tel: 604-767-1250 
Fax: 604-270-3922 
E-mail: isabella at ghement.ca 
Web: www.ghement.ca 


From r.turner at auckland.ac.nz  Wed Sep 17 03:00:58 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 17 Sep 2014 13:00:58 +1200
Subject: [R] Error in predict.lm() for models without intercept?
In-Reply-To: <49847.1410907899@ghement.ca>
References: <49847.1410907899@ghement.ca>
Message-ID: <5418DD4A.7080306@auckland.ac.nz>


When I run your code (in the single predictor case) I get exactly what I 
would expect.  In particular the standard errors are indeed proportional 
to the (absolute) value of x, and the standard error is indeed 0 at x = 0.

The proportionality constant is exactly what it should be, explicitly
s/sqrt(sum(x^2)) where "s" is the estimate of sigma (obtained via
summary(mod)$sigma).

So all is in harmony in the universe.

It is ***VERY*** unlikely that there is any error in predict.lm(), which 
has been around and in heavy use for a long, long time.

I don't know what you are seeing to make you think that there is an 
error, but I am not seeing anything untoward.

cheers,

Rolf Turner


On 17/09/14 10:51, isabella at ghement.ca wrote:
> Hi everyone,
>
> It appears my R code didn't come through the first time (thanks for letting me know, Ista). Here is my message again:
>
> Could there be an error in the predict() function in R for models without intercepts which include one or more predictors?
> When using the predict() function to obtain the standard errors of the fitted values produced by a linear model (lm), the
> behaviour of the standard errors seems to mirror that of models which include an intercept (which should not happen).
>
> Here is an attempt to produce standard errors (and hence confidence bands) for the fitted values in a linear model with a
> single predictor and no intercept using R code:
>
> ## simulate a response y and two predictors x and z
>
> x <- rnorm(100,mean=0, sd=1)
>
> z <- runif(100,min=-1,max=1)
>
> y <- 1*x + 2*z + rnorm(100,mean=0, sd=1)
>
>
> ## fit a linear model with no intercept but with one predictor
>
> mod <- lm(y ~ 0 + x)
>
> ## compute confidence bands (i.e., fitted values +/- 1.96 standard errors of fitted values)
>
> conf.band.x <- predict(mod,newdata=data.frame(x = seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01)),
>                             interval="confidence")
>
> ## display confidence bands
>
> conf.band.x <- data.frame(lwr=conf.band.x[,"lwr"],
>                                fit=conf.band.x[,"fit"],
>                                upr=conf.band.x[,"upr"])
>
> matplot(x=seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01), y=conf.band.x, type="l", xlab="x", ylab="y")
> abline(v=mean(x),lty=3,col="magenta")
> title("Effect of x on y")
>
> According to statistical theory, in a model with no intercept and one predictor, the standard errors should be directly
> proportional to the value of x at which they are evaluated.  If x=0, the standard errors should also be zero. If x increases,
> the standard errors should also increase. The resulting plot produced by matplot shows this is not the case - the standard
> errors appear to increase as one moves away from the average value of x.  We would expect this behaviour if the model included
> an intercept, which is not the case here.
>
> Here is some R code for looking at standard errors of fitted values when the model includes no intercept and two predictors x
> and z.  In this code, the value of the predictor z is set to its average level.
> ## linear model with no intercept but with two predictors
>
> mod <- lm(y ~ 0 + x + z)
>
> conf.band.x <- predict(mod,newdata=data.frame(x = seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01),
>                                                    z = mean(z)),
>                             interval="confidence")
>
> conf.band.x <- data.frame(lwr=conf.band.x[,"lwr"],
>                                fit=conf.band.x[,"fit"],
>                                upr=conf.band.x[,"upr"])
>
> matplot(x=seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01), y=conf.band.x, type="l", xlab="x", ylab="y")
> abline(v=mean(x),lty=3,col="magenta")
> title("Partial Effect of x on y (obtained by setting z to its average level)")
>
> Again, the standard errors seem to behave as though they would come from a model with an intercept (given that they are
> flaring up as one moves away from the average value of the predictor x).
>
> I would very much appreciate any clarifications or suggestions for how to fix this problem.
>
> If the problem is confirmed, it appears to also carry over to the effects package in R, which constructs plots similar to the
> ones produced by matplot above by relying on the predict() function.


-- 
Rolf Turner
Technical Editor ANZJS


From walmeszeviani at gmail.com  Wed Sep 17 05:36:24 2014
From: walmeszeviani at gmail.com (walmes .)
Date: Wed, 17 Sep 2014 00:36:24 -0300
Subject: [R] Unexpected behaviour of plyr::ddply
Message-ID: <CAFU=EkaeTDxjWGfGMOs4rFNtG_Tx6q39jPumNk1+4AVg1U8rtg@mail.gmail.com>

Hello R users,

I'm writing a brief tutorial of getting statistical measures by splitting
according strata and over columns. When I used plyr::ddply I got and
unexpected result, with NA/NaN for non existing cells. Below is a minimal
reproducible code with the result that I got. For comparison, the result of
aggregate is showed. Why this behaviour? What I can do to avoid it?

> require(plyr)
>
> hab <-
+     read.table("http://www.leg.ufpr.br/~walmes/data/ipea_habitacao.csv",
+                header=TRUE, sep=",", stringsAsFactors=FALSE, quote="",
+                encoding="utf-8")
>
> hab <- hab[,-ncol(hab)]
> names(hab) <- c("sig", "cod", "mun", "agua", "ener", "tel", "carro",
+                 "comp", "tot")
> hab <- transform(hab, sig=factor(sig))
> hab$siz <- cut(hab$tot, breaks=c(-Inf, 5000, Inf),
+                labels=c("P","G"))
> str(hab, ve.len=1)
'data.frame':    5596 obs. of  10 variables:
 $ sig  : Factor w/ 27 levels "AC","AL","AM",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ cod  : int  1200013 1200054 1200104 1200138 1200179 1200203 1200252
1200302 1200328 1200336 ...
 $ mun  : chr  "Acrel?ndia" "Assis Brasil" "Brasil?ia" "Bujari" ...
 $ agua : num  21.5 27.4 26.9 17.3 13.1 ...
 $ ener : num  56.2 65.3 55.9 43.9 35.9 ...
 $ tel  : num  8.85 26.71 22.73 12.28 9.19 ...
 $ carro: num  9.3 6.03 7.47 6.49 5.73 ...
 $ comp : num  0.947 1.637 1.857 0.127 0.088 ...
 $ tot  : int  1878 807 4114 1365 1267 14368 2807 5268 740 2308 ...
 $ siz  : Factor w/ 2 levels "P","G": 1 1 1 1 1 2 1 2 1 1 ...
>
> xtabs(~siz+sig, hab)
   sig
siz  AC  AL  AM  AP  BA  CE  DF  ES  GO  MA  MG  MS  MT  PA  PB  PE  PI
PR  RJ
  P  17  72  47  13 266 103   0  43 187 152 671  52 100  80 195  97 199
310  27
  G   5  29  15   3 149  81   1  34  55  65 182  25  26  63  28  88  22
89  64
   sig
siz  RN  RO  RR  RS  SC  SE  SP  TO
  P 147  34  14 355 236  56 396 129
  G  19  18   1 112  57  19 249  10
>
> x <- ddply(hab, ~sig+siz,
+            colwise(.fun=mean,
+                    .cols=~agua+ener+tel+carro+comp, na.rm=TRUE))
> head(x)
  sig  siz     agua     ener       tel    carro      comp
1  AC    P 19.30229 51.30535 12.857118 5.395824 0.7028235
2  AC    G 28.39300 65.95740 26.322800 8.942000 2.3806000
3  AL    P 42.14337 81.20935  4.801500 7.069958 0.5332639
4  AL    G 54.03966 87.47834  9.771724 9.428586 1.3583793
5  *AL <NA>      NaN      NaN       NaN      NaN       NaN*
6  AM    P 25.66202 61.12709  5.749596 1.980362 0.7629362
>
> x <- ddply(hab, ~sig+siz,
+            colwise(.fun=sum,
+                    .cols=~agua+ener+tel+carro+comp, na.rm=TRUE))
> head(x)
  sig  siz     agua     ener     tel   carro   comp
1  AC    P  328.139  872.191 218.571  91.729 11.948
2  AC    G  141.965  329.787 131.614  44.710 11.903
3  AL    P 3034.323 5847.073 345.708 509.037 38.395
4  AL    G 1567.150 2536.872 283.380 273.429 39.393
5  *AL <NA>    0.000    0.000   0.000   0.000  0.000*
6  AM    P 1206.115 2872.973 270.231  93.077 35.858
>
> y <- aggregate(as.matrix(hab[,4:8])~sig+siz, data=hab, FUN=mean,
+                na.rm=TRUE)
> head(y)
  sig siz     agua     ener       tel     carro      comp
1  AC   P 19.30229 51.30535 12.857118  5.395824 0.7028235
2  AL   P 42.14337 81.20935  4.801500  7.069958 0.5332639
3  AM   P 25.66202 61.12709  5.749596  1.980362 0.7629362
4  AP   P 37.20362 82.04515 14.929154  5.775923 0.7922308
5  BA   P 41.23200 66.45516  4.524045 10.387203 0.8404624
6  CE   P 36.78599 78.20176  6.339990  7.768981 0.6446990
>
> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=pt_BR.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=pt_BR.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=pt_BR.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_BR.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] plyr_1.8.1

loaded via a namespace (and not attached):
[1] compiler_3.1.1 Rcpp_0.11.2    tools_3.1.1
>

Thanks in advance.
Walmes.

==========================================================================
Walmes Marques Zeviani
LEG (Laborat?rio de Estat?stica e Geoinforma??o, 25.450418 S, 49.231759 W)
Departamento de Estat?stica - Universidade Federal do Paran?
fone: (+55) 41 3361 3573
skype: walmeszeviani
homepage: http://www.leg.ufpr.br/~walmes
linux user number: 531218
==========================================================================

	[[alternative HTML version deleted]]


From isabella at ghement.ca  Wed Sep 17 05:58:50 2014
From: isabella at ghement.ca (isabella at ghement.ca)
Date: Tue, 16 Sep 2014 22:58:50 -0500
Subject: [R] Error in predict.lm() for models without intercept?
Message-ID: <56278.1410926330@ghement.ca>

 

	Hi Rolf,  

	  BODY { font-family:Arial, Helvetica, sans-serif;font-size:12px; }
Thanks very much for your response.   You are right - my simulated
example works as intended, so it can't be used to get to the bottom of
this problem (if it is a problem at all).   

	Here is another example, which is the one I actually worked with when
I thought maybe something is not quite right in the universe.   

	The example is based on a real data set (please keep it
confidential), which is attached to this e-mail as mod.data.csv.  
This data set includes terminal run numbers for salmon, recorded at
Age_5, Age_4, Age_3 and Age_2.  A model of the form lm(Age_5 ~ 0 +
Age_4 + Age_3 + Age_2) is fitted to these data and the goal is to
visualize the effects of Age_4, Age_3 and Age_2 on Age_5.  For
biological reasons, this model is supposed to not have an intercept.  


	The attachment Effect_1.pdf shows what these effects look like.  If
the model has no intercept, should the confidence bands still flare up
as one moves away from the value of the predictor whose effect we care
about?   

	The attachment Effect_2.pdf replicates the effects plots but this
time using the effects package.   

	If predict() is correct, should we expect from statistical theory to
see that the confidence bands have this particular behaviour? 
Intuitively, I would have expected them to look like a fan plot that
starts out at zero and then flares up as we move away from zero. 

	Here is the R code I used to create the two attached plots (with R
x64 3.1.0).  In this code, Age_5 becomes y, Age_4 becomes x, Age_3
becomes z and Age_2 becomes v.   

	## read mod.data into R 

	mod.data  single predictor and no intercept using R code:
 >
 > ## simulate a response y and two predictors x and z
 >
 > x 
 > z 
 > y 
 >
 > ## fit a linear model with no intercept but with one predictor
 >
 > mod 
 > ## compute confidence bands (i.e., fitted values +/- 1.96 standard
errors of fitted values)
 >
 > conf.band.x  interval="confidence")
 >
 > ## display confidence bands
 >
 > conf.band.x  fit=conf.band.x[,"fit"],
 > upr=conf.band.x[,"upr"])
 >
 > matplot(x=seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01),
y=conf.band.x, type="l", xlab="x", ylab="y")
 > abline(v=mean(x),lty=3,col="magenta")
 > title("Effect of x on y")
 >
 > According to statistical theory, in a model with no intercept and
one predictor, the standard errors should be directly
 > proportional to the value of x at which they are evaluated. If x=0,
the standard errors should also be zero. If x increases,
 > the standard errors should also increase. The resulting plot
produced by matplot shows this is not the case - the standard
 > errors appear to increase as one moves away from the average value
of x. We would expect this behaviour if the model included
 > an intercept, which is not the case here.
 >
 > Here is some R code for looking at standard errors of fitted values
when the model includes no intercept and two predictors x
 > and z. In this code, the value of the predictor z is set to its
average level.
 > ## linear model with no intercept but with two predictors
 >
 > mod 
 > conf.band.x  z = mean(z)),
 > interval="confidence")
 >
 > conf.band.x  fit=conf.band.x[,"fit"],
 > upr=conf.band.x[,"upr"])
 >
 > matplot(x=seq(from=ceiling(min(x)),to=floor(max(x)),by=0.01),
y=conf.band.x, type="l", xlab="x", ylab="y")
 > abline(v=mean(x),lty=3,col="magenta")
 > title("Partial Effect of x on y (obtained by setting z to its
average level)")
 >
 > Again, the standard errors seem to behave as though they would come
from a model with an intercept (given that they are
 > flaring up as one moves away from the average value of the
predictor x).
 >
 > I would very much appreciate any clarifications or suggestions for
how to fix this problem.
 >
 > If the problem is confirmed, it appears to also carry over to the
effects package in R, which constructs plots similar to the
 > ones produced by matplot above by relying on the predict()
function.
 -- 
 Rolf Turner
 Technical Editor ANZJS
 

From sma.ali at fsjegj.rnu.tn  Tue Sep 16 23:39:28 2014
From: sma.ali at fsjegj.rnu.tn (Donia Smaali Bouhlila)
Date: Tue, 16 Sep 2014 22:39:28 +0100
Subject: [R] quantile regression with complex survey data
Message-ID: <12db756c10f7165e15da8221ff739b4a@pop.rnu.tn>

Dear r Users,
I am new in r. I am trying to estimate regression quantiles in complex 
surveys.I used these commands.

  mydesign 
<-svydesign(ids=~IDSCHOOL,strata=~IDSTRATE,data=TUNISIA,nest=TRUE,weights=~TOTWGT)
bootdesign <-  as.svrepdesign(mydesign,type="auto",replicates=150)
fit<withReplicates(bootdesign,quote(coef(rq(Math1~Female+Age+calculator+computer+desk
+dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2,tau=0.5,weights=.weights, 
method="fn"))))



  However, I don't get the results of the estimated coefficients.In 
addition, I don't know how to calculate pseudo R squared.

When I type summary (fit) , I get the following results:

summary (fit)
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
-33.340  -6.358  12.200  38.800  17.510 645.700

For the pseudo R squared , I read the post [R] Pseudo R for Quant Reg 
showing how to compute it:

rho <- function(u,tau=.5)u*(tau - (u < 0))
	V <- sum(rho(f$resid, f$tau))


when I type

  > rho <- function(u,tau=.5)u*(tau - (u < 0))
V <- sum(rho(fit$resid, fit$tau))

I get the following message
Error in fit$resid : $ operator is invalid for atomic vectors



Any help please


-- 
Dr. Donia Smaali Bouhlila
Associate-Professor
Department of Economics
Facult? des Sciences Economiques et de Gestion de Tunis


From davide.chicco at gmail.com  Wed Sep 17 03:40:31 2014
From: davide.chicco at gmail.com (davide.chicco at gmail.com)
Date: Tue, 16 Sep 2014 21:40:31 -0400
Subject: [R] =?utf-8?b?Ui9VYnVudHUsIOKAnHBhY2thZ2Ug4oCYc3RhdHPigJkgaW4g?=
	=?utf-8?b?b3B0aW9ucyjigJ1kZWZhdWx0UGFja2FnZXPigJwpIHdhcyBub3QgZm91?=
	=?utf-8?b?bmTigJ0=?=
In-Reply-To: <02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>
References: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
	<02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>
Message-ID: <CAK7YrFWnu2fW314azzjLA3QdL_UdZ+_WbW80g2wJzKtDz3DegQ@mail.gmail.com>

Sorry guys for the errors in my behavior. I apologize.

I installed R by using commands:
apt-get install r-base
apt-get install r-base-dev

Here's the output of sessioninfo();

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=it_IT.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=it_IT.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tcltk_3.1.1 tools_3.1.1


Any idea? Thanks!

-- Davide

2014-09-16 17:15 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:
>
> On Sep 16, 2014, at 12:19 PM, davide.chicco at gmail.com wrote:
>
>> Hi guys
>> I'm having some troubles in installing the "topicmodels" package in my
>> R system on a Linux Ubuntu machine.
>> I also described the problem here: http://bit.ly/1m8Ah6Z
>
> (You were asked in the Posting Guide to not crosspost. And when you post to Stack Overflow you should respond to requests for clarification which you have not done either. You will never get useful answers if you don't respond to requests for clarification.)
>
>>
>> I have just installed R 3.1.1 on my Linux Ubuntu 12.04.5 LTS.
>
> More details are needed. How did you do this?
>
>
>> Then Iwanted to install the topicmodels package, and so I type
>> install.packages("topicmodels"), but the installation did not work.
>
>> It seems that I do not have the "stats" package installed in my
>> default packages.
>
> That would be somewhat unusual, but possible. You were asked in the Rhelp Posting Guide to provide the output of sessionInfo().
>
>
>
> --
> David.
>
>
> ]
>> Here's the log:
>>
>> ++++++LOG+START++++++++++++++++++++
>>
>>> install.packages("topicmodels");
>> Installing package into ?/usr/local/lib/R/site-library?
>> (as ?lib? is unspecified)
>> --- Please select a CRAN mirror for use in this session ---
>> also installing the dependencies ?modeltools?, ?slam?, ?tm?
>>
>> provo con l'URL
>> 'http://cran.utstat.utoronto.ca/src/contrib/modeltools_0.2-21.tar.gz'
>> Content type 'application/x-gzip' length 14794 bytes (14 Kb)
>> URL aperto
>> ==================================================
>> downloaded 14 Kb
>>
>> provo con l'URL 'http://cran.utstat.utoronto.ca/src/contrib/slam_0.1-32.tar.gz'
>> Content type 'application/x-gzip' length 46672 bytes (45 Kb)
>> URL aperto
>> ==================================================
>> downloaded 45 Kb
>>
>> provo con l'URL 'http://cran.utstat.utoronto.ca/src/contrib/tm_0.6.tar.gz'
>> Content type 'application/x-gzip' length 505212 bytes (493 Kb)
>> URL aperto
>> ==================================================
>> downloaded 493 Kb
>>
>> provo con l'URL
>> 'http://cran.utstat.utoronto.ca/src/contrib/topicmodels_0.2-1.tar.gz'
>> Content type 'application/x-gzip' length 847889 bytes (828 Kb)
>> URL aperto
>> ==================================================
>> downloaded 828 Kb
>>
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>> Durante l'avvio - Warning message:
>> package ?stats? in options("defaultPackages") was not found
>> * installing *source* package ?modeltools? ...
>> ** package ?modeltools? successfully unpacked and MD5 sums checked
>> ** R
>> ** inst
>> ** preparing package for lazy loading
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>> Error : package ?stats? could not be loaded
>> ERROR: lazy loading failed for package ?modeltools?
>> * removing ?/usr/local/lib/R/site-library/modeltools?
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>> Durante l'avvio - Warning message:
>> package ?stats? in options("defaultPackages") was not found
>> * installing *source* package ?slam? ...
>> ** package ?slam? successfully unpacked and MD5 sums checked
>> ** libs
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c apply.c -o apply.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c grouped.c -o
>> grouped.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c sparse.c -o
>> sparse.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Wformat-security
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c util.c -o util.o
>> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o
>> slam.so apply.o grouped.o sparse.o util.o -lblas -lgfortran -lm
>> -lquadmath -L/usr/lib/R/lib -lR
>> installing to /usr/local/lib/R/site-library/slam/libs
>> ** R
>> ** preparing package for lazy loading
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>> ERROR: lazy loading failed for package ?slam?
>> * removing ?/usr/local/lib/R/site-library/slam?
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>> Durante l'avvio - Warning message:
>> package ?stats? in options("defaultPackages") was not found
>> ERROR: dependency ?slam? is not available for package ?tm?
>> * removing ?/usr/local/lib/R/site-library/tm?
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> unable to load shared object '/usr/lib/R/library/stats/libs/stats.so':
>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>> Durante l'avvio - Warning message:
>> package ?stats? in options("defaultPackages") was not found
>> ERROR: dependencies ?modeltools?, ?slam?, ?tm? are not available for
>> package ?topicmodels?
>> * removing ?/usr/local/lib/R/site-library/topicmodels?
>>
>> The downloaded source packages are in
>>   ?/tmp/RtmpIppG4O/downloaded_packages?
>> Warning messages:
>> 1: In install.packages("topicmodels") :
>> installation of package ?modeltools? had non-zero exit status
>> 2: In install.packages("topicmodels") :
>> installation of package ?slam? had non-zero exit status
>> 3: In install.packages("topicmodels") :
>> installation of package ?tm? had non-zero exit status
>> 4: In install.packages("topicmodels") :
>> installation of package ?topicmodels? had non-zero exit status
>>
>> ++++++LOG+END++++++++++++++++++++
>>
>> Here's the output of the dpkg -l | grep "blas\|atlas" command:
>>
>> ii  libatlas3gf-base   3.8.4-3build1  Automatically Tuned Linear
>> Algebra Software, generic shared
>> ii  libblas-dev        1.2.20110419-2ubuntu1  Basic Linear Algebra
>> Subroutines 3, static library
>> ii  libblas3gf         1.2.20110419-2ubuntu1  Basic Linear Algebra
>> Reference implementations, shared library
>> ii  libopenblas-base   0.1alpha2.2-3  Optimized BLAS (linear algebra)
>> library based on GotoBLAS2
>> ii  libopenblas-dev    0.1alpha2.2-3  Optimized BLAS (linear algebra)
>> library based on GotoBLAS2
>>
>> Do you have any idea on how to solve this problem?
>>
>> Thanks a lot!
>>
>> -- Davide
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From wszsdmjj at 163.com  Wed Sep 17 06:34:39 2014
From: wszsdmjj at 163.com (wszsdmjj)
Date: Tue, 16 Sep 2014 21:34:39 -0700 (PDT)
Subject: [R] How can I create colors correspond to the number of a variable?
Message-ID: <1410928479711-4697052.post@n4.nabble.com>

I need to create a color vector with 4000 colors, and I have another
variable, it contains 4000 element. If my variable is number of bed, and I
want the color corresponds to the number of bed in this variable. How should
I do? 



--
View this message in context: http://r.789695.n4.nabble.com/How-can-I-create-colors-correspond-to-the-number-of-a-variable-tp4697052.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From radhakrishnan.mohan at gmail.com  Wed Sep 17 08:15:17 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 17 Sep 2014 11:45:17 +0530
Subject: [R] Training a model using glm
Message-ID: <CAOoXFP-JrLfvfwWSKUnu1Jd1haYCLRF468Wf1W1VcoiSm+ds5A@mail.gmail.com>

I answered this question which was part of the online course correctly by
executing some commands and guessing.

But I didn't get the gist of this approach though my R code works.

I have a training and test dataset.

> nrow(training)

[1] 251

> nrow(testing)

[1] 82

> head(training1)

   diagnosis    IL_11    IL_13    IL_16   IL_17E IL_1alpha      IL_3
IL_4

6   Impaired 6.103215 1.282549 2.671032 3.637051 -8.180721 -3.863233
1.208960

10  Impaired 4.593226 1.269463 3.476091 3.637051 -7.369791 -4.017384
1.808289

11  Impaired 6.919778 1.274133 2.154845 4.749337 -7.849364 -4.509860
1.568616

12  Impaired 3.218759 1.286356 3.593860 3.867347 -8.047190 -3.575551
1.916923

13  Impaired 4.102821 1.274133 2.876338 5.731246 -7.849364 -4.509860
1.808289

16  Impaired 4.360856 1.278484 2.776394 5.170380 -7.662778 -4.017384
1.547563

         IL_5       IL_6 IL_6_Receptor     IL_7     IL_8

6  -0.4004776  0.1856864   -0.51727788 2.776394 1.708270

10  0.1823216 -1.5342758    0.09668586 2.154845 1.701858

11  0.1823216 -1.0965412    0.35404039 2.924466 1.719944

12  0.3364722 -0.3987186    0.09668586 2.924466 1.675557

13  0.0000000  0.4223589   -0.53219115 1.564217 1.691393

16  0.2623643  0.4223589    0.18739989 1.269636 1.705116

The testing dataset is similar with 13 columns. Number of rows vary.


training1 <- training[,grepl("^IL|^diagnosis",names(training))]

test1 <- testing[,grepl("^IL|^diagnosis",names(testing))]

modelFit <- train(training1$diagnosis ~ training1$IL_11 + training1$IL_13 +
training1$IL_16 + training1$IL_17E + training1$IL_1alpha + training1$IL_3 +
training1$IL_4 + training1$IL_5 + training1$IL_6 + training1$IL_6_Receptor
+ training1$IL_7 + training1$IL_8,method="glm",data=training1)

confusionMatrix(test1$diagnosis,predict(modelFit, test1))

I get this error when I run the above command to get the confusion matrix.

*'newdata' had 82 rows but variables found have 251 rows '*

I thought this was simple. I train a model using the training dataset and
predict using the test dataset and get the accuracy.

Am I missing the obvious here ?

Thanks,

Mohan

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Sep 17 08:42:28 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 16 Sep 2014 23:42:28 -0700
Subject: [R] =?utf-8?b?Ui9VYnVudHUsIOKAnHBhY2thZ2Ug4oCYc3RhdHPigJkgaW4g?=
	=?utf-8?b?b3B0aW9ucyjigJ1kZWZhdWx0UGFja2FnZXPigJwpIHdhcyBub3QgZm91?=
	=?utf-8?b?bmTigJ0=?=
In-Reply-To: <CAK7YrFWnu2fW314azzjLA3QdL_UdZ+_WbW80g2wJzKtDz3DegQ@mail.gmail.com>
References: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
	<02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>
	<CAK7YrFWnu2fW314azzjLA3QdL_UdZ+_WbW80g2wJzKtDz3DegQ@mail.gmail.com>
Message-ID: <9c4c518e-7678-4d91-bd7d-49b3dd811a46@email.android.com>

Are you using the apt sources described on CRAN for Ubuntu? I don't expect stock 12.04 would give you R3.1.1, yet I have not seen this problem on machines using the CRAN apt repositories. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 16, 2014 6:40:31 PM PDT, "davide.chicco at gmail.com" <davide.chicco at gmail.com> wrote:
>Sorry guys for the errors in my behavior. I apologize.
>
>I installed R by using commands:
>apt-get install r-base
>apt-get install r-base-dev
>
>Here's the output of sessioninfo();
>
>> sessionInfo()
>R version 3.1.1 (2014-07-10)
>Platform: i686-pc-linux-gnu (32-bit)
>
>locale:
> [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=it_IT.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=it_IT.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>attached base packages:
>[1] graphics  grDevices utils     datasets  methods   base
>
>loaded via a namespace (and not attached):
>[1] tcltk_3.1.1 tools_3.1.1
>
>
>Any idea? Thanks!
>
>-- Davide
>
>2014-09-16 17:15 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:
>>
>> On Sep 16, 2014, at 12:19 PM, davide.chicco at gmail.com wrote:
>>
>>> Hi guys
>>> I'm having some troubles in installing the "topicmodels" package in
>my
>>> R system on a Linux Ubuntu machine.
>>> I also described the problem here: http://bit.ly/1m8Ah6Z
>>
>> (You were asked in the Posting Guide to not crosspost. And when you
>post to Stack Overflow you should respond to requests for clarification
>which you have not done either. You will never get useful answers if
>you don't respond to requests for clarification.)
>>
>>>
>>> I have just installed R 3.1.1 on my Linux Ubuntu 12.04.5 LTS.
>>
>> More details are needed. How did you do this?
>>
>>
>>> Then Iwanted to install the topicmodels package, and so I type
>>> install.packages("topicmodels"), but the installation did not work.
>>
>>> It seems that I do not have the "stats" package installed in my
>>> default packages.
>>
>> That would be somewhat unusual, but possible. You were asked in the
>Rhelp Posting Guide to provide the output of sessionInfo().
>>
>>
>>
>> --
>> David.
>>
>>
>> ]
>>> Here's the log:
>>>
>>> ++++++LOG+START++++++++++++++++++++
>>>
>>>> install.packages("topicmodels");
>>> Installing package into ?/usr/local/lib/R/site-library?
>>> (as ?lib? is unspecified)
>>> --- Please select a CRAN mirror for use in this session ---
>>> also installing the dependencies ?modeltools?, ?slam?, ?tm?
>>>
>>> provo con l'URL
>>>
>'http://cran.utstat.utoronto.ca/src/contrib/modeltools_0.2-21.tar.gz'
>>> Content type 'application/x-gzip' length 14794 bytes (14 Kb)
>>> URL aperto
>>> ==================================================
>>> downloaded 14 Kb
>>>
>>> provo con l'URL
>'http://cran.utstat.utoronto.ca/src/contrib/slam_0.1-32.tar.gz'
>>> Content type 'application/x-gzip' length 46672 bytes (45 Kb)
>>> URL aperto
>>> ==================================================
>>> downloaded 45 Kb
>>>
>>> provo con l'URL
>'http://cran.utstat.utoronto.ca/src/contrib/tm_0.6.tar.gz'
>>> Content type 'application/x-gzip' length 505212 bytes (493 Kb)
>>> URL aperto
>>> ==================================================
>>> downloaded 493 Kb
>>>
>>> provo con l'URL
>>>
>'http://cran.utstat.utoronto.ca/src/contrib/topicmodels_0.2-1.tar.gz'
>>> Content type 'application/x-gzip' length 847889 bytes (828 Kb)
>>> URL aperto
>>> ==================================================
>>> downloaded 828 Kb
>>>
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>> unable to load shared object
>'/usr/lib/R/library/stats/libs/stats.so':
>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>> Durante l'avvio - Warning message:
>>> package ?stats? in options("defaultPackages") was not found
>>> * installing *source* package ?modeltools? ...
>>> ** package ?modeltools? successfully unpacked and MD5 sums checked
>>> ** R
>>> ** inst
>>> ** preparing package for lazy loading
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>> unable to load shared object
>'/usr/lib/R/library/stats/libs/stats.so':
>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>> Error : package ?stats? could not be loaded
>>> ERROR: lazy loading failed for package ?modeltools?
>>> * removing ?/usr/local/lib/R/site-library/modeltools?
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>> unable to load shared object
>'/usr/lib/R/library/stats/libs/stats.so':
>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>> Durante l'avvio - Warning message:
>>> package ?stats? in options("defaultPackages") was not found
>>> * installing *source* package ?slam? ...
>>> ** package ?slam? successfully unpacked and MD5 sums checked
>>> ** libs
>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>-Wformat-security
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c apply.c -o
>apply.o
>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>-Wformat-security
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c grouped.c -o
>>> grouped.o
>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>-Wformat-security
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c sparse.c -o
>>> sparse.o
>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>-Wformat-security
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c util.c -o util.o
>>> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o
>>> slam.so apply.o grouped.o sparse.o util.o -lblas -lgfortran -lm
>>> -lquadmath -L/usr/lib/R/lib -lR
>>> installing to /usr/local/lib/R/site-library/slam/libs
>>> ** R
>>> ** preparing package for lazy loading
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>> unable to load shared object
>'/usr/lib/R/library/stats/libs/stats.so':
>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>> ERROR: lazy loading failed for package ?slam?
>>> * removing ?/usr/local/lib/R/site-library/slam?
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>> unable to load shared object
>'/usr/lib/R/library/stats/libs/stats.so':
>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>> Durante l'avvio - Warning message:
>>> package ?stats? in options("defaultPackages") was not found
>>> ERROR: dependency ?slam? is not available for package ?tm?
>>> * removing ?/usr/local/lib/R/site-library/tm?
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>> unable to load shared object
>'/usr/lib/R/library/stats/libs/stats.so':
>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>> Durante l'avvio - Warning message:
>>> package ?stats? in options("defaultPackages") was not found
>>> ERROR: dependencies ?modeltools?, ?slam?, ?tm? are not available for
>>> package ?topicmodels?
>>> * removing ?/usr/local/lib/R/site-library/topicmodels?
>>>
>>> The downloaded source packages are in
>>>   ?/tmp/RtmpIppG4O/downloaded_packages?
>>> Warning messages:
>>> 1: In install.packages("topicmodels") :
>>> installation of package ?modeltools? had non-zero exit status
>>> 2: In install.packages("topicmodels") :
>>> installation of package ?slam? had non-zero exit status
>>> 3: In install.packages("topicmodels") :
>>> installation of package ?tm? had non-zero exit status
>>> 4: In install.packages("topicmodels") :
>>> installation of package ?topicmodels? had non-zero exit status
>>>
>>> ++++++LOG+END++++++++++++++++++++
>>>
>>> Here's the output of the dpkg -l | grep "blas\|atlas" command:
>>>
>>> ii  libatlas3gf-base   3.8.4-3build1  Automatically Tuned Linear
>>> Algebra Software, generic shared
>>> ii  libblas-dev        1.2.20110419-2ubuntu1  Basic Linear Algebra
>>> Subroutines 3, static library
>>> ii  libblas3gf         1.2.20110419-2ubuntu1  Basic Linear Algebra
>>> Reference implementations, shared library
>>> ii  libopenblas-base   0.1alpha2.2-3  Optimized BLAS (linear
>algebra)
>>> library based on GotoBLAS2
>>> ii  libopenblas-dev    0.1alpha2.2-3  Optimized BLAS (linear
>algebra)
>>> library based on GotoBLAS2
>>>
>>> Do you have any idea on how to solve this problem?
>>>
>>> Thanks a lot!
>>>
>>> -- Davide
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Sep 17 09:06:49 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 17 Sep 2014 19:06:49 +1200
Subject: [R] Error in predict.lm() for models without intercept?
In-Reply-To: <56278.1410926330@ghement.ca>
References: <56278.1410926330@ghement.ca>
Message-ID: <54193309.8050108@auckland.ac.nz>


What's going on is very simple.  I apologize for not getting my thoughts 
organized from the start.

Confidence bands for mu_y (the expected value of y) will have straight 
line edges if and only if there is a *single predictor* in the model.

If there are two or more predictors the edges will be curved.  It 
doesn't really matter if one of the predictors is constant or not.

The standard error of the estimate of mu_y is

     s * sqrt(t(x)%*%H%*%x)

where x is the value of the covariates at which y is being predicted and
H = (t(X)%*%X)^{-1} --- where in turn X is the design matrix.

It there is a single predictor "x" then X is n x 1 and H is 1 x 1, i.e. 
a scalar, say h.  Thus the standard error is

    s*sqrt(h)*|x|

and you get the proportionality to the absolute value of x.

If there are two predictors, x_1 and x_2 then the standard error has the
form

     s*sqrt(a*x_1^2 + 2*b*x_1*x_2 + c*x_2^2)

i.e. s times the square root of a quadratic form.  This will *not* be a 
straight line function of x_1 when x_2 is held constant, and vice versa.

Thus your expectation of seeing straight line edges to confidence bands 
was misguided.  This happens only when there is just *one* predictor.

Again I'm sorry I didn't get my head together about this earlier and 
save you sending me your data set. The issue has nothing whatever to do 
with your particular data set --- it's just basic mathematics.

There is nothing at all wrong with predict.lm().

cheers,

Rolf


P.S.  This is not an R matter at all, so if you have any further 
questions you should email me off-list.

R.

On 17/09/14 15:58, isabella at ghement.ca wrote:

> Hi Rolf,
>
> Thanks very much for your response.   You are right - my simulated
> example works as intended, so it can't be used to get to the bottom of
> this problem (if it is a problem at all).
>
> Here is another example, which is the one I actually worked with when I
> thought maybe something is not quite right in the universe.
>
> The example is based on a real data set (please keep it confidential),
> which is attached to this e-mail as *mod.data.csv*.   This data set
> includes terminal run numbers for salmon, recorded at Age_5, Age_4,
> Age_3 and Age_2.  A model of the form lm(Age_5 ~ 0 + Age_4 + Age_3 +
> Age_2) is fitted to these data and the goal is to visualize the effects
> of Age_4, Age_3 and Age_2 on Age_5.  For biological reasons, this model
> is supposed to not have an intercept.
>
> The attachment Effect_1.pdf shows what these effects look like.  If the
> model has no intercept, should the confidence bands still flare up
> as one moves away from the value of the predictor whose effect we care
> about?
>
> The attachment Effect_2.pdf replicates the effects plots but this time
> using the effects package.
>
> If predict() is correct, should we expect from statistical theory to see
> that the confidence bands have this particular behaviour?  Intuitively,
> I would have expected them to look like a fan plot that starts out at
> zero and then flares up as we move away from zero.
>
> Here is the R code I used to create the two attached plots (with R x64
> 3.1.0).  In this code, Age_5 becomes y, Age_4 becomes x, Age_3 becomes z
> and Age_2 becomes v.
>
> ## read mod.data into R
>
> mod.data <- read.csv("mod.data.csv")
>
> ## compute confidence bands (i.e., fitted values +/- 1.96 standard
> errors of fitted values)
>
> y <- mod.data$Age_5
> x <- mod.data$Age_4
> z <- mod.data$Age_3
> v <- mod.data$Age_2
>
> mod <- lm(y ~ 0 + x)
>
> conf.band.x <- predict(mod,newdata=data.frame(x =
> seq(from=0,to=max(x),by=100)),
>                 interval="confidence")
>
> ## display confidence bands
>
> conf.band.x <- data.frame(lwr=conf.band.x[,"lwr"],
>                            fit=conf.band.x[,"fit"],
>                            upr=conf.band.x[,"upr"])
>
> matplot(x=seq(from=0,to=floor(max(x)),by=100), y=conf.band.x, type="l",
> xlab="x", ylab="y")
> ## abline(v=0,lty=3,col="magenta")
> title("Effect of x on y")
>
> ## linear model with no intercept but with three predictors
>
> par(mfrow=c(2,2))
>
> mod <- lm(y ~ 0 + x + z + v)
>
> ## effect of x on y
>
> conf.band.x <- predict(mod,newdata=data.frame(x =
> seq(from=0,to=max(x),by=100),
>               z = mean(z),
>               v=mean(v)),
>              interval="confidence")
>
> conf.band.x <- data.frame(lwr=conf.band.x[,"lwr"],
>   fit=conf.band.x[,"fit"],
> upr=conf.band.x[,"upr"])
>
> matplot(x=seq(from=0,to=max(x),by=100), y=conf.band.x, type="l",
> xlab="x", ylab="y")
> abline(v=mean(x),lty=3,col="magenta")
> title("Effect of x on y (obtained by setting z and v to their average
> levels)")
>
>
> ## effect of z on y
> conf.band.z <- predict(mod,newdata=data.frame(z = seq(0,to=max(z),by=100),
>               x = mean(x),v=mean(v)),
>              interval="confidence")
>
> conf.band.z <- data.frame(lwr=conf.band.z[,"lwr"],
>   fit=conf.band.z[,"fit"],
> upr=conf.band.z[,"upr"])
>
> matplot(seq(from=0,to=max(z),by=100), y=conf.band.z, type="l", xlab="z",
> ylab="y")
> abline(v=mean(z),lty=3,col="magenta")
> title("Effect of z on y (obtained by setting x and v to their average
> levels)")
>
>
> ## effect of v on y
> conf.band.v <- predict(mod,newdata=data.frame(v = seq(0,to=max(v),by=100),
>               x = mean(x),z=mean(z)),
>              interval="confidence")
>
> conf.band.v <- data.frame(lwr=conf.band.v[,"lwr"],
>   fit=conf.band.v[,"fit"],
>   upr=conf.band.v[,"upr"])
>
> matplot(seq(from=0,to=max(v),by=100), y=conf.band.v, type="l", xlab="v",
> ylab="y")
> abline(v=mean(v),lty=3,col="magenta")
> title("Effect of v on y (obtained by setting x and z to their average
> levels)")
>
> ###
> ### Replicate effect plots using effects package
> ###
>
> require(effects)
> plot(allEffects(mod))
>
> Maybe my intuition is playing tricks on me - if you have any idea as to
> what may be going on here, please let me know.



-- 
Rolf Turner
Technical Editor ANZJS


From francois.rebaudo at legs.cnrs-gif.fr  Wed Sep 17 09:26:49 2014
From: francois.rebaudo at legs.cnrs-gif.fr (=?ISO-8859-1?Q?Fran=E7ois_Rebaudo?=)
Date: Wed, 17 Sep 2014 09:26:49 +0200
Subject: [R] RGtk2 drawing area as cairo device - no points
Message-ID: <541937B9.7050804@legs.cnrs-gif.fr>

Hi,
The following code adapted from Michael post (https://stat.ethz.ch/pipermail/r-help/2012-March/306069.html) works just fine on Linux Debian, but not on Windows 7 (no points on plots 2 and 3). More surprisingly, if the
first plot is a boxplot, it works on both OS... and if I do a pdf (using pdf()), I get my points... Thanks in advance for your
help.

library(RGtk2)
library(cairoDevice)
win = gtkWindow(show = FALSE)
win$setDefaultSize(500, 500)
da = gtkDrawingArea()
asCairoDevice(da)
win$add(da)
win$showAll()
layout(matrix(c(1,1,2,3),2,2,byrow=TRUE))
par(mar=c(0,0,0,0))
plot(1:10) #boxplot(1:10)
plot(1:10)
plot(1:10)

> sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
[3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
[5] LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.0


From john.archie.mckown at gmail.com  Wed Sep 17 10:26:58 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 17 Sep 2014 03:26:58 -0500
Subject: [R] How can I create colors correspond to the number of a
	variable?
In-Reply-To: <1410928479711-4697052.post@n4.nabble.com>
References: <1410928479711-4697052.post@n4.nabble.com>
Message-ID: <CAAJSdji6pYwFaLziLD1f7RyhHV7wmkfu0U_UnO8RJFwcY9_FaQ@mail.gmail.com>

First off, please post in plain text not HTML. It is a forum
requirement. HTML posts are often ignored, especially if they look
"messy" in plain text, which is all that the mailing list software
distributes. It strips off the HTML portion entirely.

Your question is vague in that you didn't indicate what you wanted in
the way of colors and what you were going to do with them. For
plotting? For visually distinguishing one out of 4,000 possible beds
by color on a screen display? If you want plotting, then use ggplot2
and the scale_color_brewer() function:
http://docs.ggplot2.org/current/scale_brewer.html . My personal
opinion is that it is unlikely that an average person will be able to
memorize 4,000 different colors, be able to see one of them, and say
definitively "that is bed number ---". Especially if the person is
even mildly color blind. Depending on use, the U.S. ADA (American with
Disabilities Act) may become a factor. Companies need to remember
this. Individuals, not so much.

But rather than give any real opinion about this question, I will just
point out some archive messages which might be of some help.

https://groups.google.com/forum/#!searchin/r-help-archive/$2Br-help$20$2Bcolor/r-help-archive/yOXrLIU-S8M/jc0yRQ6tNZgJ
https://groups.google.com/forum/#!searchin/r-help-archive/$2Br-help$20$2Bcolor/r-help-archive/duLEBjtqzTU/J45x_EB2BAIJ

This doesn't address R, but does address the use of color, and gives a
reference to the R color brewer (http://colorbrewer2.org/)
http://ux.stackexchange.com/questions/17964/how-many-visually-distinct-colors-can-accurately-be-associated-with-a-separate

Pantone, an industry standard in color, has 2,058 colors in their Goe inventory:
http://pantone.custhelp.com/app/answers/detail/a_id/1671/related/1

This site might help you select the colors:
http://www.colorsontheweb.com/

And I do know that I did not directly answer your question with a
piece of code.

On Tue, Sep 16, 2014 at 11:34 PM, wszsdmjj <wszsdmjj at 163.com> wrote:
> I need to create a color vector with 4000 colors, and I have another
> variable, it contains 4000 element. If my variable is number of bed, and I
> want the color corresponds to the number of bed in this variable. How should
> I do?
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-can-I-create-colors-correspond-to-the-number-of-a-variable-tp4697052.html
> Sent from the R help mailing list archive at Nabble.com.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From jim at bitwrit.com.au  Wed Sep 17 11:16:46 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 17 Sep 2014 19:16:46 +1000
Subject: [R] How can I create colors correspond to the number of a
	variable?
In-Reply-To: <1410928479711-4697052.post@n4.nabble.com>
References: <1410928479711-4697052.post@n4.nabble.com>
Message-ID: <14853385.LUZ8ANSMnz@localhost.localdomain>

On Tue, 16 Sep 2014 09:34:39 PM wszsdmjj wrote:
> I need to create a color vector with 4000 colors, and I have another
> variable, it contains 4000 element. If my variable is number of bed, 
and I
> want the color corresponds to the number of bed in this variable. How 
should
> I do?
> 
Hi wszsdmjj,
I assume that you have 4000 numbers of which all may be different and 
you want to assign colors that will represent these values along some 
dimension. I think that the answer that John gave is probably correct, but 
if not, have a look at the color.scale function in the plotrix package.

Jim


From thi_veloso at yahoo.com.br  Wed Sep 17 10:53:05 2014
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Wed, 17 Sep 2014 01:53:05 -0700
Subject: [R] Control color palette and legend in filled.contour
Message-ID: <1410943985.1852.YahooMailNeo@web121903.mail.ne1.yahoo.com>

Dear all,

I am having some difficulties trying to control color palette and legend of a filled.countour plot. 

Basically, I am plotting volumetric soil moisture which ranges from 0 to 1 (although the data excerpt I'm providing here ranges from 0 to 0.4, my complete dataset ranges from 0 to 1). Low values mean dry soil and higher values denote wet soil.

Instead of the default color palette, I would like to set a 'red to blue' palette with legend ranging from 0 (red) to 1 (blue). My final goal is to achive a color palette and legend similar to this figure: https://imageshack.com/i/exmVz5QSp. 

A sample of my data (as well as an attemptive plot) can be reproduced with this code:

-------------------------------------------------------------------------------------------------

library(repmis) # reads text data directly from dropbox - no need to download any file

# read data
url <- 'https://dl.dropboxusercontent.com/u/27700634/precip.txt'
tmp <- repmis::source_data(url, sep = '', header = TRUE)

# convert julian day to date
date <- as.Date(tmp$julian, origin='2011-12-31')
data <- cbind(date, tmp)
head(data)

# define vector with depth of soil layers
depths <- c(0.05,0.10,0.20,0.30,
                 0.40,0.60,0.80,1.00,
                 1.50,2.00,2.50)

# Plot soil moisture profile
cols <- ncol(data):4

x11(width=15, height=6, pointsize=12)
op <- par(mar = c(3,5,12,3))
plot <- filled.contour(x= date,
                       y= sort(-depths),
                       z= as.matrix(data[, cols]),
                       ylab= expression(theta(m^3~~m^-3)))

# also plot rainfall
par(new=T,mar=c(19,5,1,9))
with(data,
      plot(date, precip, type = "h", xaxt = "n", xpd = T, xaxs="i", ylab = "Precip (mm)", xlab = ""))
par(op)

-------------------------------------------------------------------------------------------------

I have some experience with R but I used to work with ggplot2, and therefore I am not very familiar with fine-tuning plots created with the base graphical package. 

I thank in advance for any suggestion or advice.

Greetings,

--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898
	[[alternative HTML version deleted]]


From btyner at gmail.com  Wed Sep 17 13:04:25 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Wed, 17 Sep 2014 07:04:25 -0400
Subject: [R] <NA> from cut.Date
Message-ID: <54196AB9.6000803@gmail.com>

Hello,

I'm wondering if this is expected?

    > cut(structure(11111, class="Date"), structure(c(11100,11111),
class="Date"))
    [1] <NA>
    Levels: 2000-05-23

The help page says that "for ?"Date"? objects, only ?"day"?, ?"week"?,
?"month"?, ?"quarter"? and ?"year"? are allowed" [for the 'breaks'
argument]. Though I am not sure whether this statement is only
applicable in the context of the previous sentence about interval
specification (i.e., a roundabout way of saying that ?"sec"?, ?"min"?,
?"hour"?, and ?"DSTday"? are not allowed for 'Date' objects), or whether
it also means that a vector of cut points (as in my example) is likewise
not allowed? If the latter, then perhaps the function out to error out
rather than return <NA> in this case?

Regards
Ben


From ripley at stats.ox.ac.uk  Wed Sep 17 13:31:34 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 Sep 2014 12:31:34 +0100
Subject: [R] <NA> from cut.Date
In-Reply-To: <54196AB9.6000803@gmail.com>
References: <54196AB9.6000803@gmail.com>
Message-ID: <54197116.7040805@stats.ox.ac.uk>

On 17/09/2014 12:04, Benjamin Tyner wrote:
> Hello,
>
> I'm wondering if this is expected?

It is as documented!
>
>      > cut(structure(11111, class="Date"), structure(c(11100,11111),
> class="Date"))
>      [1] <NA>
>      Levels: 2000-05-23
>
> The help page says that "for ?"Date"? objects, only ?"day"?, ?"week"?,
> ?"month"?, ?"quarter"? and ?"year"? are allowed" [for the 'breaks'
> argument]. Though I am not sure whether this statement is only
> applicable in the context of the previous sentence about interval
> specification (i.e., a roundabout way of saying that ?"sec"?, ?"min"?,
> ?"hour"?, and ?"DSTday"? are not allowed for 'Date' objects), or whether
> it also means that a vector of cut points (as in my example) is likewise
> not allowed? If the latter, then perhaps the function out to error out
> rather than return <NA> in this case?

The NA is correct: the value you pass is not covered by the 'breaks' you 
specified.  As the help says

      Using both ?right = TRUE? and ?include.lowest = TRUE? will include
      both ends of the range of dates.

With the default values, only the lower end is included.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From eliza_botto at hotmail.com  Wed Sep 17 14:28:26 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 17 Sep 2014 12:28:26 +0000
Subject: [R] column names to row names
Message-ID: <BLU170-W109CF38C484D9F7B9F3BEFB89B60@phx.gbl>

Dear useRs,
I have a data frame "y"  starting from 1961 to 2010 in the following manner (where A,B,C ......, I are station names and the values uder these are "discharge" values.)
> dput(y)
structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36), .Dim = c(4L, 12L), .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C", "D", "E", "F", "G", "H", "I")))

I want it to be in the following manner "E" where the stations names are in a seperate column and all discharge values are in one column.
> dput(E)

structure(list(year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1961", class = "factor"),     month = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,     2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,     4), day = c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L,     1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L,     4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L), discharge = structure(c(1L,     12L, 23L, 31L, 32L, 33L, 34L, 35L, 36L, 2L, 3L, 4L, 5L, 6L,     7L, 8L, 9L, 10L, 11L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,     20L, 21L, 22L, 24L, 25L, 26L, 27L, 28L, 29L, 30L), .Label = c("1",     "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",     "2", "20", "21", "22", "23", "24", "25", "26", "27", "28",     "29", "3", "30", "31", "32", "33", "34", "35", "36", "4",     "5", "6", "7", "8", "9"), class = "factor"), station = c("A",     "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "C", "D",     "D", "D", "D", "E", "E", "E", "E", "F", "F", "F", "F", "G",     "G", "G", "G", "H", "H", "H", "H", "I", "I", "I", "I")), .Names = c("year", "month", "day", "discharge", "station"), row.names = c(NA, 36L), class = "data.frame")

I hope I followed all the instructions given to be by some fellows.
Thankyou very much in advance.
Eliza
 		 	   		  
	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Sep 17 15:26:07 2014
From: jholtman at gmail.com (jim holtman)
Date: Wed, 17 Sep 2014 09:26:07 -0400
Subject: [R] column names to row names
In-Reply-To: <BLU170-W109CF38C484D9F7B9F3BEFB89B60@phx.gbl>
References: <BLU170-W109CF38C484D9F7B9F3BEFB89B60@phx.gbl>
Message-ID: <CAAxdm-4k97171Dn50xsyRtxoDnViVg947M-ZPLCeYhjt3DeEtA@mail.gmail.com>

Use the 'tidyr' package:  your 'month' does not match your desired output -

> x <- structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3
+         , 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14
+         , 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27
+         , 28, 29, 30, 31, 32, 33, 34, 35, 36)
+     , .Dim = c(4L, 12L)
+     , .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C"
+         , "D", "E", "F", "G", "H", "I"))
+     )
> xdf <- as.data.frame(x)
> xdf
  year month day A B  C  D  E  F  G  H  I
1 1961     1   1 1 5  9 13 17 21 25 29 33
2 1961     1   2 2 6 10 14 18 22 26 30 34
3 1961     1   3 3 7 11 15 19 23 27 31 35
4 1961     1   4 4 8 12 16 20 24 28 32 36
> require(tidyr)
> require(dplyr)
> xdf %>% gather(station, discharge, -year, -month, -day)
   year month day station discharge
1  1961     1   1       A         1
2  1961     1   2       A         2
3  1961     1   3       A         3
4  1961     1   4       A         4
5  1961     1   1       B         5
6  1961     1   2       B         6
7  1961     1   3       B         7
8  1961     1   4       B         8
9  1961     1   1       C         9
10 1961     1   2       C        10
11 1961     1   3       C        11
12 1961     1   4       C        12
13 1961     1   1       D        13
14 1961     1   2       D        14
15 1961     1   3       D        15
16 1961     1   4       D        16
17 1961     1   1       E        17
18 1961     1   2       E        18
19 1961     1   3       E        19
20 1961     1   4       E        20
21 1961     1   1       F        21
22 1961     1   2       F        22
23 1961     1   3       F        23
24 1961     1   4       F        24
25 1961     1   1       G        25
26 1961     1   2       G        26
27 1961     1   3       G        27
28 1961     1   4       G        28
29 1961     1   1       H        29
30 1961     1   2       H        30
31 1961     1   3       H        31
32 1961     1   4       H        32
33 1961     1   1       I        33
34 1961     1   2       I        34
35 1961     1   3       I        35
36 1961     1   4       I        36
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Sep 17, 2014 at 8:28 AM, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear useRs,
> I have a data frame "y"  starting from 1961 to 2010 in the following manner (where A,B,C ......, I are station names and the values uder these are "discharge" values.)
>> dput(y)
> structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36), .Dim = c(4L, 12L), .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C", "D", "E", "F", "G", "H", "I")))
>
> I want it to be in the following manner "E" where the stations names are in a seperate column and all discharge values are in one column.
>> dput(E)
>
> structure(list(year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1961", class = "factor"),     month = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,     2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,     4), day = c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L,     1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L,     4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L), discharge = structure(c(1L,     12L, 23L, 31L, 32L, 33L, 34L, 35L, 36L, 2L, 3L, 4L, 5L, 6L,     7L, 8L, 9L, 10L, 11L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,     20L, 21L, 22L, 24L, 25L, 26L, 27L, 28L, 29L, 30L), .Label = c("1",     "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",     "2", "20", "21", "22", "23", "24", "25", "26", "27", "28",     "29", "3", "30", "31", "32", "33", "34", "35", "36", "4",     "5", "6", "7", "8", "9"), class = "factor"), station = c("A",    !
>   "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "C", "D",     "D", "D", "D", "E", "E", "E", "E", "F", "F", "F", "F", "G",     "G", "G", "G", "H", "H", "H", "H", "I", "I", "I", "I")), .Names = c("year", "month", "day", "discharge", "station"), row.names = c(NA, 36L), class = "data.frame")
>
> I hope I followed all the instructions given to be by some fellows.
> Thankyou very much in advance.
> Eliza
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davide.chicco at gmail.com  Wed Sep 17 14:51:08 2014
From: davide.chicco at gmail.com (davide.chicco at gmail.com)
Date: Wed, 17 Sep 2014 08:51:08 -0400
Subject: [R] =?utf-8?b?Ui9VYnVudHUsIOKAnHBhY2thZ2Ug4oCYc3RhdHPigJkgaW4g?=
	=?utf-8?b?b3B0aW9ucyjigJ1kZWZhdWx0UGFja2FnZXPigJwpIHdhcyBub3QgZm91?=
	=?utf-8?b?bmTigJ0=?=
In-Reply-To: <9c4c518e-7678-4d91-bd7d-49b3dd811a46@email.android.com>
References: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
	<02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>
	<CAK7YrFWnu2fW314azzjLA3QdL_UdZ+_WbW80g2wJzKtDz3DegQ@mail.gmail.com>
	<9c4c518e-7678-4d91-bd7d-49b3dd811a46@email.android.com>
Message-ID: <CAK7YrFUS8Z9X8xq0=DxZxh3+NMKRN5G1QcCc7WbxdGX04eaBFQ@mail.gmail.com>

Yes, I've followed the instructions described here:
http://cran.r-project.org/bin/linux/ubuntu/README

I've added
deb http://<my.favorite.cran.mirror>/bin/linux/ubuntu precise/
to the /etc/apt/sources.list file.

Any idea?

Thanks a lot!

-- Davide

2014-09-17 2:42 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
> Are you using the apt sources described on CRAN for Ubuntu? I don't expect stock 12.04 would give you R3.1.1, yet I have not seen this problem on machines using the CRAN apt repositories.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On September 16, 2014 6:40:31 PM PDT, "davide.chicco at gmail.com" <davide.chicco at gmail.com> wrote:
>>Sorry guys for the errors in my behavior. I apologize.
>>
>>I installed R by using commands:
>>apt-get install r-base
>>apt-get install r-base-dev
>>
>>Here's the output of sessioninfo();
>>
>>> sessionInfo()
>>R version 3.1.1 (2014-07-10)
>>Platform: i686-pc-linux-gnu (32-bit)
>>
>>locale:
>> [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=it_IT.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=it_IT.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>>attached base packages:
>>[1] graphics  grDevices utils     datasets  methods   base
>>
>>loaded via a namespace (and not attached):
>>[1] tcltk_3.1.1 tools_3.1.1
>>
>>
>>Any idea? Thanks!
>>
>>-- Davide
>>
>>2014-09-16 17:15 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:
>>>
>>> On Sep 16, 2014, at 12:19 PM, davide.chicco at gmail.com wrote:
>>>
>>>> Hi guys
>>>> I'm having some troubles in installing the "topicmodels" package in
>>my
>>>> R system on a Linux Ubuntu machine.
>>>> I also described the problem here: http://bit.ly/1m8Ah6Z
>>>
>>> (You were asked in the Posting Guide to not crosspost. And when you
>>post to Stack Overflow you should respond to requests for clarification
>>which you have not done either. You will never get useful answers if
>>you don't respond to requests for clarification.)
>>>
>>>>
>>>> I have just installed R 3.1.1 on my Linux Ubuntu 12.04.5 LTS.
>>>
>>> More details are needed. How did you do this?
>>>
>>>
>>>> Then Iwanted to install the topicmodels package, and so I type
>>>> install.packages("topicmodels"), but the installation did not work.
>>>
>>>> It seems that I do not have the "stats" package installed in my
>>>> default packages.
>>>
>>> That would be somewhat unusual, but possible. You were asked in the
>>Rhelp Posting Guide to provide the output of sessionInfo().
>>>
>>>
>>>
>>> --
>>> David.
>>>
>>>
>>> ]
>>>> Here's the log:
>>>>
>>>> ++++++LOG+START++++++++++++++++++++
>>>>
>>>>> install.packages("topicmodels");
>>>> Installing package into ?/usr/local/lib/R/site-library?
>>>> (as ?lib? is unspecified)
>>>> --- Please select a CRAN mirror for use in this session ---
>>>> also installing the dependencies ?modeltools?, ?slam?, ?tm?
>>>>
>>>> provo con l'URL
>>>>
>>'http://cran.utstat.utoronto.ca/src/contrib/modeltools_0.2-21.tar.gz'
>>>> Content type 'application/x-gzip' length 14794 bytes (14 Kb)
>>>> URL aperto
>>>> ==================================================
>>>> downloaded 14 Kb
>>>>
>>>> provo con l'URL
>>'http://cran.utstat.utoronto.ca/src/contrib/slam_0.1-32.tar.gz'
>>>> Content type 'application/x-gzip' length 46672 bytes (45 Kb)
>>>> URL aperto
>>>> ==================================================
>>>> downloaded 45 Kb
>>>>
>>>> provo con l'URL
>>'http://cran.utstat.utoronto.ca/src/contrib/tm_0.6.tar.gz'
>>>> Content type 'application/x-gzip' length 505212 bytes (493 Kb)
>>>> URL aperto
>>>> ==================================================
>>>> downloaded 493 Kb
>>>>
>>>> provo con l'URL
>>>>
>>'http://cran.utstat.utoronto.ca/src/contrib/topicmodels_0.2-1.tar.gz'
>>>> Content type 'application/x-gzip' length 847889 bytes (828 Kb)
>>>> URL aperto
>>>> ==================================================
>>>> downloaded 828 Kb
>>>>
>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>> unable to load shared object
>>'/usr/lib/R/library/stats/libs/stats.so':
>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>> Durante l'avvio - Warning message:
>>>> package ?stats? in options("defaultPackages") was not found
>>>> * installing *source* package ?modeltools? ...
>>>> ** package ?modeltools? successfully unpacked and MD5 sums checked
>>>> ** R
>>>> ** inst
>>>> ** preparing package for lazy loading
>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>> unable to load shared object
>>'/usr/lib/R/library/stats/libs/stats.so':
>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>> Error : package ?stats? could not be loaded
>>>> ERROR: lazy loading failed for package ?modeltools?
>>>> * removing ?/usr/local/lib/R/site-library/modeltools?
>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>> unable to load shared object
>>'/usr/lib/R/library/stats/libs/stats.so':
>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>> Durante l'avvio - Warning message:
>>>> package ?stats? in options("defaultPackages") was not found
>>>> * installing *source* package ?slam? ...
>>>> ** package ?slam? successfully unpacked and MD5 sums checked
>>>> ** libs
>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>-Wformat-security
>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c apply.c -o
>>apply.o
>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>-Wformat-security
>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c grouped.c -o
>>>> grouped.o
>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>-Wformat-security
>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c sparse.c -o
>>>> sparse.o
>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>-Wformat-security
>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c util.c -o util.o
>>>> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o
>>>> slam.so apply.o grouped.o sparse.o util.o -lblas -lgfortran -lm
>>>> -lquadmath -L/usr/lib/R/lib -lR
>>>> installing to /usr/local/lib/R/site-library/slam/libs
>>>> ** R
>>>> ** preparing package for lazy loading
>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>> unable to load shared object
>>'/usr/lib/R/library/stats/libs/stats.so':
>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>> ERROR: lazy loading failed for package ?slam?
>>>> * removing ?/usr/local/lib/R/site-library/slam?
>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>> unable to load shared object
>>'/usr/lib/R/library/stats/libs/stats.so':
>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>> Durante l'avvio - Warning message:
>>>> package ?stats? in options("defaultPackages") was not found
>>>> ERROR: dependency ?slam? is not available for package ?tm?
>>>> * removing ?/usr/local/lib/R/site-library/tm?
>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>> unable to load shared object
>>'/usr/lib/R/library/stats/libs/stats.so':
>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>> Durante l'avvio - Warning message:
>>>> package ?stats? in options("defaultPackages") was not found
>>>> ERROR: dependencies ?modeltools?, ?slam?, ?tm? are not available for
>>>> package ?topicmodels?
>>>> * removing ?/usr/local/lib/R/site-library/topicmodels?
>>>>
>>>> The downloaded source packages are in
>>>>   ?/tmp/RtmpIppG4O/downloaded_packages?
>>>> Warning messages:
>>>> 1: In install.packages("topicmodels") :
>>>> installation of package ?modeltools? had non-zero exit status
>>>> 2: In install.packages("topicmodels") :
>>>> installation of package ?slam? had non-zero exit status
>>>> 3: In install.packages("topicmodels") :
>>>> installation of package ?tm? had non-zero exit status
>>>> 4: In install.packages("topicmodels") :
>>>> installation of package ?topicmodels? had non-zero exit status
>>>>
>>>> ++++++LOG+END++++++++++++++++++++
>>>>
>>>> Here's the output of the dpkg -l | grep "blas\|atlas" command:
>>>>
>>>> ii  libatlas3gf-base   3.8.4-3build1  Automatically Tuned Linear
>>>> Algebra Software, generic shared
>>>> ii  libblas-dev        1.2.20110419-2ubuntu1  Basic Linear Algebra
>>>> Subroutines 3, static library
>>>> ii  libblas3gf         1.2.20110419-2ubuntu1  Basic Linear Algebra
>>>> Reference implementations, shared library
>>>> ii  libopenblas-base   0.1alpha2.2-3  Optimized BLAS (linear
>>algebra)
>>>> library based on GotoBLAS2
>>>> ii  libopenblas-dev    0.1alpha2.2-3  Optimized BLAS (linear
>>algebra)
>>>> library based on GotoBLAS2
>>>>
>>>> Do you have any idea on how to solve this problem?
>>>>
>>>> Thanks a lot!
>>>>
>>>> -- Davide
>>>>
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From stefanML at collocations.de  Wed Sep 17 15:39:16 2014
From: stefanML at collocations.de (Stefan Evert (Mailing Lists))
Date: Wed, 17 Sep 2014 19:09:16 +0530
Subject: [R] R "write" strange behavior in huge file
In-Reply-To: <D03E06C1.65E77%ValleeM@iarc.fr>
References: <D03E06C1.65E77%ValleeM@iarc.fr>
Message-ID: <1DBFB800-916F-4972-BADB-7C106AA099F8@collocations.de>

You probably told R to write out the file as a single long line with fields separated alternately by 380 TABs and one newline ? that?s what the ncol argument does (write is just a small wrapper around cat()).

cat() doesn?t print lines that are longer than 2 GiB, so it will insert an extra \n after every 2 GiB of data. (IIRC, this is because in the C code, fill=FALSE is replaced by fill=MAX_INT or so.)

The only way around this limitation that I can think of is to write a wrapper function that breaks up the matrix or list of vectors in smaller chunks and appends them separately to the output file.  I?m planning to add such a function to one of my packages, so I?d be interested if somebody has a better solution.

Best,
Stefan


On 16 Sep 2014, at 18:54, Maxime Vallee <ValleeM at iarc.fr> wrote:

> In my script I have one list of 1,132,533 vectors (each vector contains
> 381 elements). 
> 
> When I use "write" to save this list in a flat text file (I unlist my
> list, separate by tabs, and set ncol to 381), I end up with a file of
> 1,132,535 lines (2 additional lines). I checked back, my R list do not
> have those two additional items before writing.
> 
> With awk, I determined if lines where not made of 381 fields: there were
> two, separated by around 400k lines.
> 
> I made sub-files, using those "incomplete" lines as boundaries. My files
> are very close in size : 1.9 GB (respectively 1971841853 B and 1972614897
> B). It feels like a 32 bit / 64 bit issue.
> 
> My R version is this:
> ./Rscript -e 'sessionInfo()$platform'
> [1] "x86_64-unknown-linux-gnu (64-bit)"
> 
> There is somewhere, reaching 1.9 GB, something that is changing my tabs to
> unwanted carriage returns...
> Any idea that might cause this, and if it looks solvable in R?


	[[alternative HTML version deleted]]


From eliza_botto at hotmail.com  Wed Sep 17 15:43:36 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 17 Sep 2014 13:43:36 +0000
Subject: [R] column names to row names
In-Reply-To: <CAAxdm-4k97171Dn50xsyRtxoDnViVg947M-ZPLCeYhjt3DeEtA@mail.gmail.com>
References: <BLU170-W109CF38C484D9F7B9F3BEFB89B60@phx.gbl>,
	<CAAxdm-4k97171Dn50xsyRtxoDnViVg947M-ZPLCeYhjt3DeEtA@mail.gmail.com>
Message-ID: <BLU170-W74AC56242D0832BCF44AF089B60@phx.gbl>

Thankyou very much jim. you always have something new for the R-ookies. 
Eliza

> Date: Wed, 17 Sep 2014 09:26:07 -0400
> Subject: Re: [R] column names to row names
> From: jholtman at gmail.com
> To: eliza_botto at hotmail.com
> CC: r-help at r-project.org
> 
> Use the 'tidyr' package:  your 'month' does not match your desired output -
> 
> > x <- structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3
> +         , 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14
> +         , 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27
> +         , 28, 29, 30, 31, 32, 33, 34, 35, 36)
> +     , .Dim = c(4L, 12L)
> +     , .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C"
> +         , "D", "E", "F", "G", "H", "I"))
> +     )
> > xdf <- as.data.frame(x)
> > xdf
>   year month day A B  C  D  E  F  G  H  I
> 1 1961     1   1 1 5  9 13 17 21 25 29 33
> 2 1961     1   2 2 6 10 14 18 22 26 30 34
> 3 1961     1   3 3 7 11 15 19 23 27 31 35
> 4 1961     1   4 4 8 12 16 20 24 28 32 36
> > require(tidyr)
> > require(dplyr)
> > xdf %>% gather(station, discharge, -year, -month, -day)
>    year month day station discharge
> 1  1961     1   1       A         1
> 2  1961     1   2       A         2
> 3  1961     1   3       A         3
> 4  1961     1   4       A         4
> 5  1961     1   1       B         5
> 6  1961     1   2       B         6
> 7  1961     1   3       B         7
> 8  1961     1   4       B         8
> 9  1961     1   1       C         9
> 10 1961     1   2       C        10
> 11 1961     1   3       C        11
> 12 1961     1   4       C        12
> 13 1961     1   1       D        13
> 14 1961     1   2       D        14
> 15 1961     1   3       D        15
> 16 1961     1   4       D        16
> 17 1961     1   1       E        17
> 18 1961     1   2       E        18
> 19 1961     1   3       E        19
> 20 1961     1   4       E        20
> 21 1961     1   1       F        21
> 22 1961     1   2       F        22
> 23 1961     1   3       F        23
> 24 1961     1   4       F        24
> 25 1961     1   1       G        25
> 26 1961     1   2       G        26
> 27 1961     1   3       G        27
> 28 1961     1   4       G        28
> 29 1961     1   1       H        29
> 30 1961     1   2       H        30
> 31 1961     1   3       H        31
> 32 1961     1   4       H        32
> 33 1961     1   1       I        33
> 34 1961     1   2       I        34
> 35 1961     1   3       I        35
> 36 1961     1   4       I        36
> >
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> 
> On Wed, Sep 17, 2014 at 8:28 AM, eliza botto <eliza_botto at hotmail.com> wrote:
> > Dear useRs,
> > I have a data frame "y"  starting from 1961 to 2010 in the following manner (where A,B,C ......, I are station names and the values uder these are "discharge" values.)
> >> dput(y)
> > structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36), .Dim = c(4L, 12L), .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C", "D", "E", "F", "G", "H", "I")))
> >
> > I want it to be in the following manner "E" where the stations names are in a seperate column and all discharge values are in one column.
> >> dput(E)
> >
> > structure(list(year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1961", class = "factor"),     month = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,     2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,     4), day = c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L,     1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L,     4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L), discharge = structure(c(1L,     12L, 23L, 31L, 32L, 33L, 34L, 35L, 36L, 2L, 3L, 4L, 5L, 6L,     7L, 8L, 9L, 10L, 11L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,     20L, 21L, 22L, 24L, 25L, 26L, 27L, 28L, 29L, 30L), .Label = c("1",     "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",     "2", "20", "21", "22", "23", "24", "25", "26", "27", "28",     "29", "3", "30", "31", "32", "33", "34", "35", "36", "4",     "5", "6", "7", "8", "9"), class = "factor"), station = c("A",    !
> >   "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "C", "D",     "D", "D", "D", "E", "E", "E", "E", "F", "F", "F", "F", "G",     "G", "G", "G", "H", "H", "H", "H", "I", "I", "I", "I")), .Names = c("year", "month", "day", "discharge", "station"), row.names = c(NA, 36L), class = "data.frame")
> >
> > I hope I followed all the instructions given to be by some fellows.
> > Thankyou very much in advance.
> > Eliza
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From zadig_1 at excite.com  Wed Sep 17 15:51:21 2014
From: zadig_1 at excite.com (ce)
Date: Wed, 17 Sep 2014 09:51:21 -0400
Subject: [R] ANN ARIMA or ANN ES Examples ?
Message-ID: <20140917095121.15266@web007.roc2.bluetie.com>


Hello,

I am looking for ANN ARIMA or ANN ES  ( Artificial Neural Networks Hybrid with  ARIMA or Exponential Smoothing ) R examples or packages ?
as referenced in http://cs.uni-muenster.de/Professoren/Lippe/diplomarbeiten/html/eisenbach/Untersuchte%20Artikel/Zhan03.pdf

regards


From dcarlson at tamu.edu  Wed Sep 17 16:04:52 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 17 Sep 2014 14:04:52 +0000
Subject: [R] column names to row names
In-Reply-To: <CAAxdm-4k97171Dn50xsyRtxoDnViVg947M-ZPLCeYhjt3DeEtA@mail.gmail.com>
References: <BLU170-W109CF38C484D9F7B9F3BEFB89B60@phx.gbl>
	<CAAxdm-4k97171Dn50xsyRtxoDnViVg947M-ZPLCeYhjt3DeEtA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F985CB@mb02.ads.tamu.edu>

Here's another approach using stack():
> y <- data.frame(y)
> E <- with(y, data.frame(year, month, day, 
     stack(data.frame(y), select=4:12)))
> colnames(E)[4:5] <- c("discharge", "station")

But there are some differences. For my E:
> str(E)
'data.frame':   36 obs. of  5 variables:
 $ year     : num  1961 1961 1961 1961 1961 ...
 $ month    : num  1 1 1 1 1 1 1 1 1 1 ...
 $ day      : num  1 2 3 4 1 2 3 4 1 2 ...
 $ discharge: num  1 2 3 4 5 6 7 8 9 10 ...
 $ station  : Factor w/ 9 levels "A","B","C","D",..: 1 1 1 1 2 2 2 2 3 3 ...

But for your E:

> str(E)
'data.frame':   36 obs. of  5 variables:
 $ year     : Factor w/ 1 level "1961": 1 1 1 1 1 1 1 1 1 1 ...
 $ month    : num  1 1 1 1 1 1 1 1 1 2 ...
 $ day      : int  1 2 3 4 1 2 3 4 1 2 ...
 $ discharge: Factor w/ 36 levels "1","10","11",..: 1 12 23 31 32 33 34 35 36 2 ...
 $ station  : chr  "A" "A" "A" "A" ...

It seems strange that the discharge and year would be factors and station would be character.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of jim holtman
Sent: Wednesday, September 17, 2014 8:26 AM
To: eliza botto
Cc: r-help at r-project.org
Subject: Re: [R] column names to row names

Use the 'tidyr' package:  your 'month' does not match your desired output -

> x <- structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3
+         , 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14
+         , 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27
+         , 28, 29, 30, 31, 32, 33, 34, 35, 36)
+     , .Dim = c(4L, 12L)
+     , .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C"
+         , "D", "E", "F", "G", "H", "I"))
+     )
> xdf <- as.data.frame(x)
> xdf
  year month day A B  C  D  E  F  G  H  I
1 1961     1   1 1 5  9 13 17 21 25 29 33
2 1961     1   2 2 6 10 14 18 22 26 30 34
3 1961     1   3 3 7 11 15 19 23 27 31 35
4 1961     1   4 4 8 12 16 20 24 28 32 36
> require(tidyr)
> require(dplyr)
> xdf %>% gather(station, discharge, -year, -month, -day)
   year month day station discharge
1  1961     1   1       A         1
2  1961     1   2       A         2
3  1961     1   3       A         3
4  1961     1   4       A         4
5  1961     1   1       B         5
6  1961     1   2       B         6
7  1961     1   3       B         7
8  1961     1   4       B         8
9  1961     1   1       C         9
10 1961     1   2       C        10
11 1961     1   3       C        11
12 1961     1   4       C        12
13 1961     1   1       D        13
14 1961     1   2       D        14
15 1961     1   3       D        15
16 1961     1   4       D        16
17 1961     1   1       E        17
18 1961     1   2       E        18
19 1961     1   3       E        19
20 1961     1   4       E        20
21 1961     1   1       F        21
22 1961     1   2       F        22
23 1961     1   3       F        23
24 1961     1   4       F        24
25 1961     1   1       G        25
26 1961     1   2       G        26
27 1961     1   3       G        27
28 1961     1   4       G        28
29 1961     1   1       H        29
30 1961     1   2       H        30
31 1961     1   3       H        31
32 1961     1   4       H        32
33 1961     1   1       I        33
34 1961     1   2       I        34
35 1961     1   3       I        35
36 1961     1   4       I        36
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Sep 17, 2014 at 8:28 AM, eliza botto <eliza_botto at hotmail.com> wrote:
> Dear useRs,
> I have a data frame "y"  starting from 1961 to 2010 in the following manner (where A,B,C ......, I are station names and the values uder these are "discharge" values.)
>> dput(y)
> structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36), .Dim = c(4L, 12L), .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C", "D", "E", "F", "G", "H", "I")))
>
> I want it to be in the following manner "E" where the stations names are in a seperate column and all discharge values are in one column.
>> dput(E)
>
> structure(list(year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1961", class = "factor"),     month = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,     2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,     4), day = c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L,     1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L,     4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L), discharge = structure(c(1L,     12L, 23L, 31L, 32L, 33L, 34L, 35L, 36L, 2L, 3L, 4L, 5L, 6L,     7L, 8L, 9L, 10L, 11L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,     20L, 21L, 22L, 24L, 25L, 26L, 27L, 28L, 29L, 30L), .Label = c("1",     "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",     "2", "20", "21", "22", "23", "24", "25", "26", "27", "28",     "29", "3", "30", "31", "32", "33", "34", "35", "36", "4",     "5", "6", "7", "8", "9"), class = "factor"), station = c("A",  !
   !
>   "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "C", "D",     "D", "D", "D", "E", "E", "E", "E", "F", "F", "F", "F", "G",     "G", "G", "G", "H", "H", "H", "H", "I", "I", "I", "I")), .Names = c("year", "month", "day", "discharge", "station"), row.names = c(NA, 36L), class = "data.frame")
>
> I hope I followed all the instructions given to be by some fellows.
> Thankyou very much in advance.
> Eliza
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Sep 17 16:39:51 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 17 Sep 2014 07:39:51 -0700
Subject: [R] =?utf-8?b?Ui9VYnVudHUsIOKAnHBhY2thZ2Ug4oCYc3RhdHPigJkgaW4g?=
	=?utf-8?b?b3B0aW9ucyjigJ1kZWZhdWx0UGFja2FnZXPigJwpIHdhcyBub3QgZm91?=
	=?utf-8?b?bmTigJ0=?=
In-Reply-To: <CAK7YrFUS8Z9X8xq0=DxZxh3+NMKRN5G1QcCc7WbxdGX04eaBFQ@mail.gmail.com>
References: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
	<02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>
	<CAK7YrFWnu2fW314azzjLA3QdL_UdZ+_WbW80g2wJzKtDz3DegQ@mail.gmail.com>
	<9c4c518e-7678-4d91-bd7d-49b3dd811a46@email.android.com>
	<CAK7YrFUS8Z9X8xq0=DxZxh3+NMKRN5G1QcCc7WbxdGX04eaBFQ@mail.gmail.com>
Message-ID: <6cec176b-4601-4141-b079-94cce61ab5f8@email.android.com>

Try a different mirror? Precise is getting kind of old... they may not be keeping all of the old files on that mirror.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 17, 2014 5:51:08 AM PDT, "davide.chicco at gmail.com" <davide.chicco at gmail.com> wrote:
>Yes, I've followed the instructions described here:
>http://cran.r-project.org/bin/linux/ubuntu/README
>
>I've added
>deb http://<my.favorite.cran.mirror>/bin/linux/ubuntu precise/
>to the /etc/apt/sources.list file.
>
>Any idea?
>
>Thanks a lot!
>
>-- Davide
>
>2014-09-17 2:42 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> Are you using the apt sources described on CRAN for Ubuntu? I don't
>expect stock 12.04 would give you R3.1.1, yet I have not seen this
>problem on machines using the CRAN apt repositories.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 16, 2014 6:40:31 PM PDT, "davide.chicco at gmail.com"
><davide.chicco at gmail.com> wrote:
>>>Sorry guys for the errors in my behavior. I apologize.
>>>
>>>I installed R by using commands:
>>>apt-get install r-base
>>>apt-get install r-base-dev
>>>
>>>Here's the output of sessioninfo();
>>>
>>>> sessionInfo()
>>>R version 3.1.1 (2014-07-10)
>>>Platform: i686-pc-linux-gnu (32-bit)
>>>
>>>locale:
>>> [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
>>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=it_IT.UTF-8
>>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=it_IT.UTF-8
>>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>>attached base packages:
>>>[1] graphics  grDevices utils     datasets  methods   base
>>>
>>>loaded via a namespace (and not attached):
>>>[1] tcltk_3.1.1 tools_3.1.1
>>>
>>>
>>>Any idea? Thanks!
>>>
>>>-- Davide
>>>
>>>2014-09-16 17:15 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:
>>>>
>>>> On Sep 16, 2014, at 12:19 PM, davide.chicco at gmail.com wrote:
>>>>
>>>>> Hi guys
>>>>> I'm having some troubles in installing the "topicmodels" package
>in
>>>my
>>>>> R system on a Linux Ubuntu machine.
>>>>> I also described the problem here: http://bit.ly/1m8Ah6Z
>>>>
>>>> (You were asked in the Posting Guide to not crosspost. And when you
>>>post to Stack Overflow you should respond to requests for
>clarification
>>>which you have not done either. You will never get useful answers if
>>>you don't respond to requests for clarification.)
>>>>
>>>>>
>>>>> I have just installed R 3.1.1 on my Linux Ubuntu 12.04.5 LTS.
>>>>
>>>> More details are needed. How did you do this?
>>>>
>>>>
>>>>> Then Iwanted to install the topicmodels package, and so I type
>>>>> install.packages("topicmodels"), but the installation did not
>work.
>>>>
>>>>> It seems that I do not have the "stats" package installed in my
>>>>> default packages.
>>>>
>>>> That would be somewhat unusual, but possible. You were asked in the
>>>Rhelp Posting Guide to provide the output of sessionInfo().
>>>>
>>>>
>>>>
>>>> --
>>>> David.
>>>>
>>>>
>>>> ]
>>>>> Here's the log:
>>>>>
>>>>> ++++++LOG+START++++++++++++++++++++
>>>>>
>>>>>> install.packages("topicmodels");
>>>>> Installing package into ?/usr/local/lib/R/site-library?
>>>>> (as ?lib? is unspecified)
>>>>> --- Please select a CRAN mirror for use in this session ---
>>>>> also installing the dependencies ?modeltools?, ?slam?, ?tm?
>>>>>
>>>>> provo con l'URL
>>>>>
>>>'http://cran.utstat.utoronto.ca/src/contrib/modeltools_0.2-21.tar.gz'
>>>>> Content type 'application/x-gzip' length 14794 bytes (14 Kb)
>>>>> URL aperto
>>>>> ==================================================
>>>>> downloaded 14 Kb
>>>>>
>>>>> provo con l'URL
>>>'http://cran.utstat.utoronto.ca/src/contrib/slam_0.1-32.tar.gz'
>>>>> Content type 'application/x-gzip' length 46672 bytes (45 Kb)
>>>>> URL aperto
>>>>> ==================================================
>>>>> downloaded 45 Kb
>>>>>
>>>>> provo con l'URL
>>>'http://cran.utstat.utoronto.ca/src/contrib/tm_0.6.tar.gz'
>>>>> Content type 'application/x-gzip' length 505212 bytes (493 Kb)
>>>>> URL aperto
>>>>> ==================================================
>>>>> downloaded 493 Kb
>>>>>
>>>>> provo con l'URL
>>>>>
>>>'http://cran.utstat.utoronto.ca/src/contrib/topicmodels_0.2-1.tar.gz'
>>>>> Content type 'application/x-gzip' length 847889 bytes (828 Kb)
>>>>> URL aperto
>>>>> ==================================================
>>>>> downloaded 828 Kb
>>>>>
>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>> unable to load shared object
>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>> Durante l'avvio - Warning message:
>>>>> package ?stats? in options("defaultPackages") was not found
>>>>> * installing *source* package ?modeltools? ...
>>>>> ** package ?modeltools? successfully unpacked and MD5 sums checked
>>>>> ** R
>>>>> ** inst
>>>>> ** preparing package for lazy loading
>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>> unable to load shared object
>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>> Error : package ?stats? could not be loaded
>>>>> ERROR: lazy loading failed for package ?modeltools?
>>>>> * removing ?/usr/local/lib/R/site-library/modeltools?
>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>> unable to load shared object
>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>> Durante l'avvio - Warning message:
>>>>> package ?stats? in options("defaultPackages") was not found
>>>>> * installing *source* package ?slam? ...
>>>>> ** package ?slam? successfully unpacked and MD5 sums checked
>>>>> ** libs
>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>-Wformat-security
>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c apply.c -o
>>>apply.o
>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>-Wformat-security
>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c grouped.c -o
>>>>> grouped.o
>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>-Wformat-security
>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c sparse.c -o
>>>>> sparse.o
>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>-Wformat-security
>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c util.c -o
>util.o
>>>>> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o
>>>>> slam.so apply.o grouped.o sparse.o util.o -lblas -lgfortran -lm
>>>>> -lquadmath -L/usr/lib/R/lib -lR
>>>>> installing to /usr/local/lib/R/site-library/slam/libs
>>>>> ** R
>>>>> ** preparing package for lazy loading
>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>> unable to load shared object
>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>> ERROR: lazy loading failed for package ?slam?
>>>>> * removing ?/usr/local/lib/R/site-library/slam?
>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>> unable to load shared object
>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>> Durante l'avvio - Warning message:
>>>>> package ?stats? in options("defaultPackages") was not found
>>>>> ERROR: dependency ?slam? is not available for package ?tm?
>>>>> * removing ?/usr/local/lib/R/site-library/tm?
>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>> unable to load shared object
>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>> Durante l'avvio - Warning message:
>>>>> package ?stats? in options("defaultPackages") was not found
>>>>> ERROR: dependencies ?modeltools?, ?slam?, ?tm? are not available
>for
>>>>> package ?topicmodels?
>>>>> * removing ?/usr/local/lib/R/site-library/topicmodels?
>>>>>
>>>>> The downloaded source packages are in
>>>>>   ?/tmp/RtmpIppG4O/downloaded_packages?
>>>>> Warning messages:
>>>>> 1: In install.packages("topicmodels") :
>>>>> installation of package ?modeltools? had non-zero exit status
>>>>> 2: In install.packages("topicmodels") :
>>>>> installation of package ?slam? had non-zero exit status
>>>>> 3: In install.packages("topicmodels") :
>>>>> installation of package ?tm? had non-zero exit status
>>>>> 4: In install.packages("topicmodels") :
>>>>> installation of package ?topicmodels? had non-zero exit status
>>>>>
>>>>> ++++++LOG+END++++++++++++++++++++
>>>>>
>>>>> Here's the output of the dpkg -l | grep "blas\|atlas" command:
>>>>>
>>>>> ii  libatlas3gf-base   3.8.4-3build1  Automatically Tuned Linear
>>>>> Algebra Software, generic shared
>>>>> ii  libblas-dev        1.2.20110419-2ubuntu1  Basic Linear Algebra
>>>>> Subroutines 3, static library
>>>>> ii  libblas3gf         1.2.20110419-2ubuntu1  Basic Linear Algebra
>>>>> Reference implementations, shared library
>>>>> ii  libopenblas-base   0.1alpha2.2-3  Optimized BLAS (linear
>>>algebra)
>>>>> library based on GotoBLAS2
>>>>> ii  libopenblas-dev    0.1alpha2.2-3  Optimized BLAS (linear
>>>algebra)
>>>>> library based on GotoBLAS2
>>>>>
>>>>> Do you have any idea on how to solve this problem?
>>>>>
>>>>> Thanks a lot!
>>>>>
>>>>> -- Davide
>>>>>
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Sep 17 18:09:20 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 17 Sep 2014 18:09:20 +0200
Subject: [R] Error in predict.lm() for models without intercept?
In-Reply-To: <56278.1410926330@ghement.ca>
References: <56278.1410926330@ghement.ca>
Message-ID: <68C58D55-4B0F-4D32-8A76-4A2803345A15@gmail.com>


On 17 Sep 2014, at 05:58 , isabella at ghement.ca wrote:

> 
> 	The example is based on a real data set (please keep it
> confidential), which is attached to this e-mail as mod.data.csv.  

"Don't worry, it will stay between you two and the Internet...."

(Actually, the list software seems to have scrubbed it, but that's probably only because your mailer sends with non-text mime-type.) 


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at inbox.com  Wed Sep 17 18:14:08 2014
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 17 Sep 2014 08:14:08 -0800
Subject: [R] Efficient frontier
In-Reply-To: <5A52AC39-612B-40C9-AEBE-753BA8309136@gmail.com>
Message-ID: <0667D874E82.0000038Ajrkrideau@inbox.com>

https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: aparna.eco04 at gmail.com
> Sent: Mon, 15 Sep 2014 14:40:37 -0500
> To: r-help at r-project.org
> Subject: [R] Efficient frontier
> 
> Hi I need help for plotting efficient frontier, I have expected return
> and covariance matrix. I am using tseries and downloaded portfolio
> package too. The suggestion says to use efficient.frontier, but it looks
> you replaces it by something in R 3.1.1 as it says this is not available.
> At current R version, what is the way to draw efficient frontier?
> 
> Sent from my iPad
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From radhakrishnan.mohan at gmail.com  Wed Sep 17 20:04:20 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 17 Sep 2014 23:34:20 +0530
Subject: [R] Training a model using glm
In-Reply-To: <CADv2QyHBHPCNz6MXCZdhMukX4N_c6gADd9Wu+bOduRZ5fr8E4w@mail.gmail.com>
References: <CAOoXFP-JrLfvfwWSKUnu1Jd1haYCLRF468Wf1W1VcoiSm+ds5A@mail.gmail.com>
	<CADv2QyHBHPCNz6MXCZdhMukX4N_c6gADd9Wu+bOduRZ5fr8E4w@mail.gmail.com>
Message-ID: <CAOoXFP_iZcdfdgmUhL=L0QVZb2depk241Fe9J+SXE1WP6-bzhQ@mail.gmail.com>

Hi Dennis,

                     Why is there that warning ? I think my syntax is
right. Isn't it not? So the warning can be ignored ?

Thanks,
Mohan

On Wed, Sep 17, 2014 at 9:48 PM, Dennis Murphy <djmuser at gmail.com> wrote:

> No reproducible example (i.e., no data) supplied, but the following
> should work in general, so I'm presuming this maps to the caret
> package as well. Thoroughly untested.
>
> library(caret)    # something you failed to mention
>
> ...
> modelFit <- train(diagnosis ~ ., data = training1)    # presumably a
> logistic regression
> confusionMatrix(test1$diagnosis, predict(modelFit, newdata = test1,
> type = "response"))
>
> For GLMs, there are several types of possible predictions. The default
> is 'link', which associates with the linear predictor. caret may have
> a different syntax so you should check its help pages re the supported
> predict methods.
>
> Hint: If a function takes a data = argument, you don't need to specify
> the variables as components of the data frame - the variable names are
> sufficient. You should also do some reading to understand why the
> model formula I used is correct if you're modeling one variable as
> response and all others in the data frame as covariates.
>
> Dennis
>
> On Tue, Sep 16, 2014 at 11:15 PM, Mohan Radhakrishnan
> <radhakrishnan.mohan at gmail.com> wrote:
> > I answered this question which was part of the online course correctly by
> > executing some commands and guessing.
> >
> > But I didn't get the gist of this approach though my R code works.
> >
> > I have a training and test dataset.
> >
> >> nrow(training)
> >
> > [1] 251
> >
> >> nrow(testing)
> >
> > [1] 82
> >
> >> head(training1)
> >
> >    diagnosis    IL_11    IL_13    IL_16   IL_17E IL_1alpha      IL_3
> > IL_4
> >
> > 6   Impaired 6.103215 1.282549 2.671032 3.637051 -8.180721 -3.863233
> > 1.208960
> >
> > 10  Impaired 4.593226 1.269463 3.476091 3.637051 -7.369791 -4.017384
> > 1.808289
> >
> > 11  Impaired 6.919778 1.274133 2.154845 4.749337 -7.849364 -4.509860
> > 1.568616
> >
> > 12  Impaired 3.218759 1.286356 3.593860 3.867347 -8.047190 -3.575551
> > 1.916923
> >
> > 13  Impaired 4.102821 1.274133 2.876338 5.731246 -7.849364 -4.509860
> > 1.808289
> >
> > 16  Impaired 4.360856 1.278484 2.776394 5.170380 -7.662778 -4.017384
> > 1.547563
> >
> >          IL_5       IL_6 IL_6_Receptor     IL_7     IL_8
> >
> > 6  -0.4004776  0.1856864   -0.51727788 2.776394 1.708270
> >
> > 10  0.1823216 -1.5342758    0.09668586 2.154845 1.701858
> >
> > 11  0.1823216 -1.0965412    0.35404039 2.924466 1.719944
> >
> > 12  0.3364722 -0.3987186    0.09668586 2.924466 1.675557
> >
> > 13  0.0000000  0.4223589   -0.53219115 1.564217 1.691393
> >
> > 16  0.2623643  0.4223589    0.18739989 1.269636 1.705116
> >
> > The testing dataset is similar with 13 columns. Number of rows vary.
> >
> >
> > training1 <- training[,grepl("^IL|^diagnosis",names(training))]
> >
> > test1 <- testing[,grepl("^IL|^diagnosis",names(testing))]
> >
> > modelFit <- train(training1$diagnosis ~ training1$IL_11 +
> training1$IL_13 +
> > training1$IL_16 + training1$IL_17E + training1$IL_1alpha +
> training1$IL_3 +
> > training1$IL_4 + training1$IL_5 + training1$IL_6 +
> training1$IL_6_Receptor
> > + training1$IL_7 + training1$IL_8,method="glm",data=training1)
> >
> > confusionMatrix(test1$diagnosis,predict(modelFit, test1))
> >
> > I get this error when I run the above command to get the confusion
> matrix.
> >
> > *'newdata' had 82 rows but variables found have 251 rows '*
> >
> > I thought this was simple. I train a model using the training dataset and
> > predict using the test dataset and get the accuracy.
> >
> > Am I missing the obvious here ?
> >
> > Thanks,
> >
> > Mohan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gpetris at uark.edu  Wed Sep 17 20:25:57 2014
From: gpetris at uark.edu (Giovanni Petris)
Date: Wed, 17 Sep 2014 18:25:57 +0000
Subject: [R] Generating unordered, with replacement, samples
Message-ID: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>


Hello,

I am trying to interface in my teaching some elementary probability with Monte Carlo ideas. In sampling from a finite population, the number of distinct samples of size 'k' from a population of size 'n' , when individuals are selected with replacement and the selection order does not matter, is choose(n + k -1, k). Does anyone have a suggestion about how to simulate (uniformly!) one of these possible samples? In a Monte Carlo framework I would like to do it repeatedly, so efficiency is of some relevance.

Thank you in advance!

Best,
Giovanni



Giovanni Petris
Associate Professor
Department of Mathematical Sciences
University of Arkansas - Fayetteville, AR 72701
Ph: (479) 575-6324, 575-8630 (fax)
http://definetti.uark.edu/~gpetris/



From ruipbarradas at sapo.pt  Wed Sep 17 20:49:55 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 17 Sep 2014 19:49:55 +0100
Subject: [R] Generating unordered, with replacement, samples
In-Reply-To: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>
References: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>
Message-ID: <5419D7D3.4090808@sapo.pt>

Hello,

Try function ?sample. Something like, if 'x' is a vector of size n,

sample(x, k, replace = TRUE)

If you want indices into 'x', try instead

sample(n, k, replace = TRUE)

Hope this helps,

Rui Barradas

Em 17-09-2014 19:25, Giovanni Petris escreveu:
>
> Hello,
>
> I am trying to interface in my teaching some elementary probability with Monte Carlo ideas. In sampling from a finite population, the number of distinct samples of size 'k' from a population of size 'n' , when individuals are selected with replacement and the selection order does not matter, is choose(n + k -1, k). Does anyone have a suggestion about how to simulate (uniformly!) one of these possible samples? In a Monte Carlo framework I would like to do it repeatedly, so efficiency is of some relevance.
>
> Thank you in advance!
>
> Best,
> Giovanni
>
>
>
> Giovanni Petris
> Associate Professor
> Department of Mathematical Sciences
> University of Arkansas - Fayetteville, AR 72701
> Ph: (479) 575-6324, 575-8630 (fax)
> http://definetti.uark.edu/~gpetris/
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mxkuhn at gmail.com  Wed Sep 17 20:51:01 2014
From: mxkuhn at gmail.com (Max Kuhn)
Date: Wed, 17 Sep 2014 14:51:01 -0400
Subject: [R] Training a model using glm
In-Reply-To: <CAOoXFP_iZcdfdgmUhL=L0QVZb2depk241Fe9J+SXE1WP6-bzhQ@mail.gmail.com>
References: <CAOoXFP-JrLfvfwWSKUnu1Jd1haYCLRF468Wf1W1VcoiSm+ds5A@mail.gmail.com>
	<CADv2QyHBHPCNz6MXCZdhMukX4N_c6gADd9Wu+bOduRZ5fr8E4w@mail.gmail.com>
	<CAOoXFP_iZcdfdgmUhL=L0QVZb2depk241Fe9J+SXE1WP6-bzhQ@mail.gmail.com>
Message-ID: <CAJ9CoWnWkJHZJz3b74WESQ2jfd2ycnC73pSuVkKrRBTjV5A-ZA@mail.gmail.com>

You have not shown all of your code and it is difficult to diagnose the
issue.

I assume that you are using the data from:

   library(AppliedPredictiveModeling)
   data(AlzheimerDisease)

If so, there is example code to analyze these data in that package. See
?scriptLocation.

We have no idea how you got to the `training` object (package versions
would be nice too).

I suspect that Dennis is correct. Try using more normal syntax without the
$ indexing in the formula. I wouldn't say it is (absolutely) wrong but it
doesn't look right either.

Max


On Wed, Sep 17, 2014 at 2:04 PM, Mohan Radhakrishnan <
radhakrishnan.mohan at gmail.com> wrote:

> Hi Dennis,
>
>                      Why is there that warning ? I think my syntax is
> right. Isn't it not? So the warning can be ignored ?
>
> Thanks,
> Mohan
>
> On Wed, Sep 17, 2014 at 9:48 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>
> > No reproducible example (i.e., no data) supplied, but the following
> > should work in general, so I'm presuming this maps to the caret
> > package as well. Thoroughly untested.
> >
> > library(caret)    # something you failed to mention
> >
> > ...
> > modelFit <- train(diagnosis ~ ., data = training1)    # presumably a
> > logistic regression
> > confusionMatrix(test1$diagnosis, predict(modelFit, newdata = test1,
> > type = "response"))
> >
> > For GLMs, there are several types of possible predictions. The default
> > is 'link', which associates with the linear predictor. caret may have
> > a different syntax so you should check its help pages re the supported
> > predict methods.
> >
> > Hint: If a function takes a data = argument, you don't need to specify
> > the variables as components of the data frame - the variable names are
> > sufficient. You should also do some reading to understand why the
> > model formula I used is correct if you're modeling one variable as
> > response and all others in the data frame as covariates.
> >
> > Dennis
> >
> > On Tue, Sep 16, 2014 at 11:15 PM, Mohan Radhakrishnan
> > <radhakrishnan.mohan at gmail.com> wrote:
> > > I answered this question which was part of the online course correctly
> by
> > > executing some commands and guessing.
> > >
> > > But I didn't get the gist of this approach though my R code works.
> > >
> > > I have a training and test dataset.
> > >
> > >> nrow(training)
> > >
> > > [1] 251
> > >
> > >> nrow(testing)
> > >
> > > [1] 82
> > >
> > >> head(training1)
> > >
> > >    diagnosis    IL_11    IL_13    IL_16   IL_17E IL_1alpha      IL_3
> > > IL_4
> > >
> > > 6   Impaired 6.103215 1.282549 2.671032 3.637051 -8.180721 -3.863233
> > > 1.208960
> > >
> > > 10  Impaired 4.593226 1.269463 3.476091 3.637051 -7.369791 -4.017384
> > > 1.808289
> > >
> > > 11  Impaired 6.919778 1.274133 2.154845 4.749337 -7.849364 -4.509860
> > > 1.568616
> > >
> > > 12  Impaired 3.218759 1.286356 3.593860 3.867347 -8.047190 -3.575551
> > > 1.916923
> > >
> > > 13  Impaired 4.102821 1.274133 2.876338 5.731246 -7.849364 -4.509860
> > > 1.808289
> > >
> > > 16  Impaired 4.360856 1.278484 2.776394 5.170380 -7.662778 -4.017384
> > > 1.547563
> > >
> > >          IL_5       IL_6 IL_6_Receptor     IL_7     IL_8
> > >
> > > 6  -0.4004776  0.1856864   -0.51727788 2.776394 1.708270
> > >
> > > 10  0.1823216 -1.5342758    0.09668586 2.154845 1.701858
> > >
> > > 11  0.1823216 -1.0965412    0.35404039 2.924466 1.719944
> > >
> > > 12  0.3364722 -0.3987186    0.09668586 2.924466 1.675557
> > >
> > > 13  0.0000000  0.4223589   -0.53219115 1.564217 1.691393
> > >
> > > 16  0.2623643  0.4223589    0.18739989 1.269636 1.705116
> > >
> > > The testing dataset is similar with 13 columns. Number of rows vary.
> > >
> > >
> > > training1 <- training[,grepl("^IL|^diagnosis",names(training))]
> > >
> > > test1 <- testing[,grepl("^IL|^diagnosis",names(testing))]
> > >
> > > modelFit <- train(training1$diagnosis ~ training1$IL_11 +
> > training1$IL_13 +
> > > training1$IL_16 + training1$IL_17E + training1$IL_1alpha +
> > training1$IL_3 +
> > > training1$IL_4 + training1$IL_5 + training1$IL_6 +
> > training1$IL_6_Receptor
> > > + training1$IL_7 + training1$IL_8,method="glm",data=training1)
> > >
> > > confusionMatrix(test1$diagnosis,predict(modelFit, test1))
> > >
> > > I get this error when I run the above command to get the confusion
> > matrix.
> > >
> > > *'newdata' had 82 rows but variables found have 251 rows '*
> > >
> > > I thought this was simple. I train a model using the training dataset
> and
> > > predict using the test dataset and get the accuracy.
> > >
> > > Am I missing the obvious here ?
> > >
> > > Thanks,
> > >
> > > Mohan
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gpetris at uark.edu  Wed Sep 17 20:55:30 2014
From: gpetris at uark.edu (Giovanni Petris)
Date: Wed, 17 Sep 2014 18:55:30 +0000
Subject: [R] Generating unordered, with replacement, samples
In-Reply-To: <5419D7D3.4090808@sapo.pt>
References: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>,
	<5419D7D3.4090808@sapo.pt>
Message-ID: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9D0@ex-mbx2.uark.edu>


Thank you, Rui, but I have the feeling that in this way you are drawing uniformly *ordered* samples, and you get a bias if you consider them to be unordered.

Best,
Giovanni

________________________________________
From: Rui Barradas [ruipbarradas at sapo.pt]
Sent: Wednesday, September 17, 2014 13:49
To: Giovanni Petris; r-help at R-project.org
Subject: Re: [R] Generating unordered, with replacement, samples

Hello,

Try function ?sample. Something like, if 'x' is a vector of size n,

sample(x, k, replace = TRUE)

If you want indices into 'x', try instead

sample(n, k, replace = TRUE)

Hope this helps,

Rui Barradas

Em 17-09-2014 19:25, Giovanni Petris escreveu:
>
> Hello,
>
> I am trying to interface in my teaching some elementary probability with Monte Carlo ideas. In sampling from a finite population, the number of distinct samples of size 'k' from a population of size 'n' , when individuals are selected with replacement and the selection order does not matter, is choose(n + k -1, k). Does anyone have a suggestion about how to simulate (uniformly!) one of these possible samples? In a Monte Carlo framework I would like to do it repeatedly, so efficiency is of some relevance.
>
> Thank you in advance!
>
> Best,
> Giovanni
>
>
>
> Giovanni Petris
> Associate Professor
> Department of Mathematical Sciences
> University of Arkansas - Fayetteville, AR 72701
> Ph: (479) 575-6324, 575-8630 (fax)
> http://definetti.uark.edu/~gpetris/
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Wed Sep 17 21:07:22 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 17 Sep 2014 15:07:22 -0400
Subject: [R] Generating unordered, with replacement, samples
In-Reply-To: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>
References: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>
Message-ID: <5419DBEA.7000007@gmail.com>

On 17/09/2014 2:25 PM, Giovanni Petris wrote:
> Hello,
>
> I am trying to interface in my teaching some elementary probability with Monte Carlo ideas. In sampling from a finite population, the number of distinct samples of size 'k' from a population of size 'n' , when individuals are selected with replacement and the selection order does not matter, is choose(n + k -1, k). Does anyone have a suggestion about how to simulate (uniformly!) one of these possible samples? In a Monte Carlo framework I would like to do it repeatedly, so efficiency is of some relevance.
>
> Thank you in advance!

I forget the details of the derivation of that count, but the number 
suggests it is found by selecting k things without replacement from 
n+k-1.  The sample() function in R can easily give you a sample of k 
integers from 1:(n+k-1); "all" you need to do is map those numbers into 
your original sample of k from n.  For that you need to remember the 
derivation of that formula!

Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Sep 17 21:45:11 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 17 Sep 2014 15:45:11 -0400
Subject: [R] Generating unordered, with replacement, samples
In-Reply-To: <5419DBEA.7000007@gmail.com>
References: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>
	<5419DBEA.7000007@gmail.com>
Message-ID: <5419E4C7.4060401@gmail.com>

On 17/09/2014 3:07 PM, Duncan Murdoch wrote:
> On 17/09/2014 2:25 PM, Giovanni Petris wrote:
> > Hello,
> >
> > I am trying to interface in my teaching some elementary probability with Monte Carlo ideas. In sampling from a finite population, the number of distinct samples of size 'k' from a population of size 'n' , when individuals are selected with replacement and the selection order does not matter, is choose(n + k -1, k). Does anyone have a suggestion about how to simulate (uniformly!) one of these possible samples? In a Monte Carlo framework I would like to do it repeatedly, so efficiency is of some relevance.
> >
> > Thank you in advance!
>
> I forget the details of the derivation of that count, but the number
> suggests it is found by selecting k things without replacement from
> n+k-1.  The sample() function in R can easily give you a sample of k
> integers from 1:(n+k-1); "all" you need to do is map those numbers into
> your original sample of k from n.  For that you need to remember the
> derivation of that formula!

The derivation is on this web page: 
http://mathworld.wolfram.com/Multichoose.html .

Duncan Murdoch


From gpetris at uark.edu  Wed Sep 17 21:46:32 2014
From: gpetris at uark.edu (Giovanni Petris)
Date: Wed, 17 Sep 2014 19:46:32 +0000
Subject: [R] Generating unordered, with replacement, samples
In-Reply-To: <5419DBEA.7000007@gmail.com>
References: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>,
	<5419DBEA.7000007@gmail.com>
Message-ID: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACEA05@ex-mbx2.uark.edu>


Hi Duncan,

You are right. The idea of the derivation consists in 'throwing' k placeholders ("*" in the example below) in the list of the individuals of the population. For example, if the population is letters[1:6], and the sample size is 4, the following code generates uniformly a 'sample'.

> n <- 6; k <- 4
> set.seed(2)
> xxx <- rep("*", n + k)
> ind <- sort(sample(2 : (n+k), k))
> xxx[setdiff(1 : (n+k), ind)] <- letters[seq.int(n)]
> noquote(xxx)
 [1] a b * c d * * e f *

This represents the sample (b, d, d, f). I am still missing the "all" I need to do that you mention, that is how I can transform the vector xxx into something more readily usable, like c(b, d, d, f), or even a summary of counts. I guess I am looking for a bit of R trickery here...

Thank you,
Giovanni

________________________________________
From: Duncan Murdoch [murdoch.duncan at gmail.com]
Sent: Wednesday, September 17, 2014 14:07
To: Giovanni Petris; r-help at R-project.org
Subject: Re: [R] Generating unordered, with replacement, samples

On 17/09/2014 2:25 PM, Giovanni Petris wrote:
> Hello,
>
> I am trying to interface in my teaching some elementary probability with Monte Carlo ideas. In sampling from a finite population, the number of distinct samples of size 'k' from a population of size 'n' , when individuals are selected with replacement and the selection order does not matter, is choose(n + k -1, k). Does anyone have a suggestion about how to simulate (uniformly!) one of these possible samples? In a Monte Carlo framework I would like to do it repeatedly, so efficiency is of some relevance.
>
> Thank you in advance!

I forget the details of the derivation of that count, but the number
suggests it is found by selecting k things without replacement from
n+k-1.  The sample() function in R can easily give you a sample of k
integers from 1:(n+k-1); "all" you need to do is map those numbers into
your original sample of k from n.  For that you need to remember the
derivation of that formula!

Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Sep 17 22:02:24 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 17 Sep 2014 16:02:24 -0400
Subject: [R] Generating unordered, with replacement, samples
In-Reply-To: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACEA05@ex-mbx2.uark.edu>
References: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>,
	<5419DBEA.7000007@gmail.com>
	<A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACEA05@ex-mbx2.uark.edu>
Message-ID: <5419E8D0.9060904@gmail.com>

On 17/09/2014 3:46 PM, Giovanni Petris wrote:
> Hi Duncan,
>
> You are right. The idea of the derivation consists in 'throwing' k placeholders ("*" in the example below) in the list of the individuals of the population. For example, if the population is letters[1:6], and the sample size is 4, the following code generates uniformly a 'sample'.
>
> > n <- 6; k <- 4
> > set.seed(2)
> > xxx <- rep("*", n + k)
> > ind <- sort(sample(2 : (n+k), k))
> > xxx[setdiff(1 : (n+k), ind)] <- letters[seq.int(n)]
> > noquote(xxx)
>   [1] a b * c d * * e f *
>
> This represents the sample (b, d, d, f). I am still missing the "all" I need to do that you mention, that is how I can transform the vector xxx into something more readily usable, like c(b, d, d, f), or even a summary of counts. I guess I am looking for a bit of R trickery here...

I think this works, but you'd better check!

Sample the placeholders:

ind <- sort( sample(n + k -1, n-1) )  # I don't think sort() is necessary...

Add placeholders at the start and end:

ind <- c(0, ind, n+k)

Take the diffs, and subtract one:

diff(ind) - 1

I think this gives the counts you want.

Duncan Murdoch


From sma.ali at fsjegj.rnu.tn  Wed Sep 17 20:13:36 2014
From: sma.ali at fsjegj.rnu.tn (Donia Smaali Bouhlila)
Date: Wed, 17 Sep 2014 19:13:36 +0100
Subject: [R] Pseudo R squared  for quantile regression with replicates
Message-ID: <d5effddfde31ac8ff59594fc8eda9223@pop.rnu.tn>

Hi,


I am running quantile regressions with replicates, but I don't know how 
to calculate the Pseudo R squared  for quantile regression with 
replicates. I have used the following commands:


rho <- function(u,tau=.5)u*(tau - (u < 0))
	V <- sum(rho(fit$resid, fit$tau))

where fit is my objective function


However, I get the following error message:


  Error in fit$resid : $ operator is invalid for atomic vectors



Any suggestion please
-- 
Dr. Donia Smaali Bouhlila
Associate-Professor
Department of Economics
Facult? des Sciences Economiques et de Gestion de Tunis


From ssignor at usc.edu  Wed Sep 17 21:54:28 2014
From: ssignor at usc.edu (Sarah Signor)
Date: Wed, 17 Sep 2014 12:54:28 -0700
Subject: [R] package "ape" read.dna diploid input data
Message-ID: <CAKL_LAGohyCrmQEezR2ww60K+THKR3BDGZhEh_RzPsNB=3CoGQ@mail.gmail.com>

I am fundamentally not understanding something about how this is set up,
but after a few hours of googling I am going to ask and I apologize if its
quite basic. I have sanger data that I am reading into ape with read.dna.

x<-read.dna("/Volumes/Storage/file.phy", format = "interleaved")

It has IUPAC codes in the data, which represent polymorphisms in a diploid
system. It is consistently read as haploid data, both in ape and when I
convert it for adegenet. What are you supposed to do to make the data read
as diploid? You can't just include duplicates of the sequences, it doesn't
work. I've tried it with sequential alignments and .fasta files.

Thanks

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Wed Sep 17 22:34:18 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 17 Sep 2014 16:34:18 -0400
Subject: [R] plots on log="y" scale with smooths
Message-ID: <5419F04A.1000008@yorku.ca>

In the following example, I am trying to plot a response on a log scale, 
and add one or more smoothed
curves, e.g., lowess and abline.  In base graphics, I'd like to do this 
using log="y", so that the Y axis is
spaced on the log scale, but labeled as the actual response values. 
Using ggplot2, I'm using
scale_y_log10 to achieve the same purpose.  However, my attempts to add 
the smooths differ
considerably, so I must be missing something.

Here's the data I'm working with for one example:

data("CodParasites", package = "countreg")
## omit NAs in response & predictor
CodParasites <- subset(CodParasites, !(is.na(intensity) | is.na(length)))
## plot only positive values of intensity
CPpos <- subset(CodParasites, intensity>0)

Here's the base graphics plot.  The abline() is clearly wrong and the 
lowess smooth looks too low.
How does one meld plots using log="y" with such additional plot 
annotations ?

plot(jitter(intensity) ~ length, data = CPpos, log = "y")
with(CPpos, lines(lowess(length, log(intensity)), col="red", lwd=2) )
abline(lm(log(intensity) ~ length, data=CPpos))

Here's an attempt at a ggplot2 version, that actually looks more 
reasonable, but I'm not sure that it
is correct:

library(ggplot2)
ggplot(CPpos, aes(x=length, y=intensity)) +
     geom_jitter(position=position_jitter(height=.1), alpha=0.25) +
     scale_y_log10(breaks=c(1,2,5,10,20,50,100, 200)) +
     stat_smooth(method="loess", color="red", size=1.5) +
     stat_smooth(method="lm")


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From daniela.droguett.leon at gmail.com  Wed Sep 17 22:45:57 2014
From: daniela.droguett.leon at gmail.com (Daniela Droguett)
Date: Wed, 17 Sep 2014 17:45:57 -0300
Subject: [R] svyby and vcov function problem (Survey Package)
Message-ID: <CABD9s95uUXZVq6w0EV+8JO3RUJ+gT+_bXtuTT_6hBrH6ApH-LA@mail.gmail.com>

Hi all,

I would like to apply the vcov function from the survey package for the
variables api00 and api99 grouped by the stype variable which can assume H,
M and E categories (see below)

I have tried svyby but as far as I know covariant matrices don't work with
this function
?
In the code example (survey package manual) they apply the as.svrepdesign
and then svyby with svymean function but I need svyby with svytotal without
as.svrepdesign.

data(api)
dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
rclus1<-as.svrepdesign(dclus1)
mns<-svyby(~api00, ~stype, rclus1, svymean,covmat=TRUE)
vcov(mns)

how to mix the different stypes to obtain terms like:

api00:H api00:H
api00:H api00:M
api00:H api00:E
api00:H api99:H
api00:H api99:M
api00:H api99:E

api00:E api00:E
api00:E api00:M
api00:E api99:H
api00:E api99:E
api00:E api99:M

api00:M api00:M
api00:M api99:H
api00:M api99:E
api00:M api99:M

api99:H api99:H
api99:H api99:E
api99:H api99:M

api99:E api99:E
api99:E api99:M

api99:M api99:M

I have no clue on how to implement that.

Thanks a lot!
?

?Daniela.?

	[[alternative HTML version deleted]]


From greg at warnes.net  Wed Sep 17 23:12:24 2014
From: greg at warnes.net (Gregory R. Warnes)
Date: Wed, 17 Sep 2014 17:12:24 -0400
Subject: [R] gplot heatmaps: clustering according to rowsidecolors +
	key.xtickfun
In-Reply-To: <540867EA.8030503@uni-bremen.de>
References: <540867EA.8030503@uni-bremen.de>
Message-ID: <30EC1811-AA02-4B8A-98A5-4291E00B2284@warnes.net>

Hello Tim,

Sorry about the slow response, I just found this message.

On Sep 4, 2014, at 9:23 AM, Tim Richter-Heitmann <trichter at uni-bremen.de> wrote:

> Hi there,
> 
> I have two questions about heatmap.2 in gplot.
> My input is a simple square matrix with numeric values between 75 and 100 (it is a similarity matrix based on bacterial DNA sequences).
> 
> 1. I can sort my input matrix into categories with rowsidecolors (in this case, very conveniently by bacterial taxa). I do a clustering and reordering of my matrix by Rowv=TRUE (and Colv="Rowv").
> The question is now, can i combine the two features that the clustering/reordering is done only for submatrices defined by the vectors given in rowsidecolors (so, in this case, that the original ordering by bacterial taxa is preserved)?
> 
> That would be very amazing.
> 

Hmm.    To get the individual species clustered within taxa would require doing the hierarchical clustering first separately, then combining the dendrograms.  This should do the trick:


set.seed(1234567)

## Dummy Distances
x <- matrix( rnorm(400, mean=87.5, sd=12.5/4), ncol=20)

## Dummy Taxa
taxa <- sample(letters[1:4], 20, replace=T)
taxa <- as.factor(taxa)

# sort the data by taxa
ord <- order(taxa)

x <- x[ord, ord]
taxa <- taxa[ord]
rownames(x) <- 1:nrow(x)


####
# stats:::merge.dendrogram is broken.  This is the corrected version.
# See R BUG 15648
# (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15648) for
# details
####
merge.dendrogram <- function(x, y, ..., height) {
  stopifnot(inherits(x,"dendrogram"), inherits(y,"dendrogram"))

  ### FIX
  inx.add <- function(inx, add) {
    if(is.leaf(inx)) {
      inx <- inx + add
    }
    return(inx)
  }
  y <- dendrapply(y,  inx.add, add=max(unlist(x)))
  ### FIX

  r <- list(x,y)
  if(length(xtr <- list(...))) {
    if(!all(is.d <- vapply(xtr, inherits, NA, what="dendrogram"))) {
        xpr <- substitute(c(...))
        nms <- sapply(xpr[-1][!is.d], deparse, nlines = 1L)
        ## do not simplify: xgettext needs this form
        msg <- ngettext(length(nms),
                        "extra argument %s is not of class \"%s\"",
                        "extra arguments %s are not of class \"%s\"s")
        stop(sprintf(msg, paste(nms, collapse=", "), "dendrogram"),
             domain = NA)
    }
    ## <GRW>
    for(i in 1:length(xtr))
        {
            add <- max(c(unlist(r), unlist(xtr)))
            print(add)
            xtr[[i]] <- dendrapply(xtr[[i]], inx.add, add=add)
        }
    ## </GRW>
    r <- c(r, xtr)
  }
  attr(r, "members") <- sum(vapply(r, attr, 0L, which="members"))
  h.max <- max(vapply(r, attr, 0., which="height"))
  if(missing(height) || is.null(height))
    height <- 1.1 * h.max
  else if(height < h.max) {
    msg <- gettextf("'height' must be at least %g, the maximal height of its components", h.max)
    stop(msg, domain = NA)
  }
  attr(r, "height") <- height
  class(r) <- "dendrogram"
  midcache.dendrogram(r, quiet=TRUE)
}


## Compute dendrograms within each taxum, then merge into a combined dendrogram
dendList <- list()
for( taxon in levels(taxa) )
    {
        items <- which(taxon==taxa)
        submatrix <- x[ items, items]
        dend <- as.dendrogram(hclust(dist(submatrix)))
        dendList[[taxon]] <- dend
    }
names(dendList) <- NULL
dends <- do.call("merge.dendrogram", dendList)

## Now generate the heatmap
heatmap.2(x,
          Rowv=dends,
          Colv=dends,
          symm=TRUE,
          RowSideColors=c("red","blue","green","black")[as.numeric(taxa)],
          ColSideColors=c("red","blue","green","black")[as.numeric(taxa)],
          trace="none"
          )

> 2. I have set my own coloring rules with:
> 
> mypal <- c("grey","blue", "green","yellow","orange","red")
> col_breaks = c(seq(0,74.9), seq(75.0,78.4), seq(78.5,81.9), seq(82.0,86.4), seq(86.5, 94.5),  seq(94.5,100.0))
> 
> Is it possible to pass this sequential ordering to key.xtickfun? May i ask for an example code?

Use the ?breaks? and ?col? arguements:


## Custom color key
mypal      <- c("grey","blue", "green","yellow","orange","red")
col_breaks <- c(0,75.0,78.5,82.0,86.5,94.5,100.0)


heatmap.2(x,
          Rowv=dends,
          Colv=dends,
          symm=TRUE,
          RowSideColors=c("red","blue","green","black")[as.numeric(taxa)],
          ColSideColors=c("red","blue","green","black")[as.numeric(taxa)],
          trace="none",
          breaks=col_breaks,
          col=mypal
          )

-Greg


	[[alternative HTML version deleted]]


From eliza_botto at hotmail.com  Wed Sep 17 23:46:58 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Wed, 17 Sep 2014 21:46:58 +0000
Subject: [R] column names to row names
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F985CB@mb02.ads.tamu.edu>
References: <BLU170-W109CF38C484D9F7B9F3BEFB89B60@phx.gbl>,
	<CAAxdm-4k97171Dn50xsyRtxoDnViVg947M-ZPLCeYhjt3DeEtA@mail.gmail.com>,
	<53BF8FB63FAF2E4A9455EF1EE94DA726F985CB@mb02.ads.tamu.edu>
Message-ID: <BLU170-W128EE76425C57DBA98623BC89B60@phx.gbl>

Thanyou David!!!
:)


> From: dcarlson at tamu.edu
> To: jholtman at gmail.com; eliza_botto at hotmail.com
> CC: r-help at r-project.org
> Subject: RE: [R] column names to row names
> Date: Wed, 17 Sep 2014 14:04:52 +0000
> 
> Here's another approach using stack():
> > y <- data.frame(y)
> > E <- with(y, data.frame(year, month, day, 
>      stack(data.frame(y), select=4:12)))
> > colnames(E)[4:5] <- c("discharge", "station")
> 
> But there are some differences. For my E:
> > str(E)
> 'data.frame':   36 obs. of  5 variables:
>  $ year     : num  1961 1961 1961 1961 1961 ...
>  $ month    : num  1 1 1 1 1 1 1 1 1 1 ...
>  $ day      : num  1 2 3 4 1 2 3 4 1 2 ...
>  $ discharge: num  1 2 3 4 5 6 7 8 9 10 ...
>  $ station  : Factor w/ 9 levels "A","B","C","D",..: 1 1 1 1 2 2 2 2 3 3 ...
> 
> But for your E:
> 
> > str(E)
> 'data.frame':   36 obs. of  5 variables:
>  $ year     : Factor w/ 1 level "1961": 1 1 1 1 1 1 1 1 1 1 ...
>  $ month    : num  1 1 1 1 1 1 1 1 1 2 ...
>  $ day      : int  1 2 3 4 1 2 3 4 1 2 ...
>  $ discharge: Factor w/ 36 levels "1","10","11",..: 1 12 23 31 32 33 34 35 36 2 ...
>  $ station  : chr  "A" "A" "A" "A" ...
> 
> It seems strange that the discharge and year would be factors and station would be character.
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> ----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of jim holtman
> Sent: Wednesday, September 17, 2014 8:26 AM
> To: eliza botto
> Cc: r-help at r-project.org
> Subject: Re: [R] column names to row names
> 
> Use the 'tidyr' package:  your 'month' does not match your desired output -
> 
> > x <- structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3
> +         , 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14
> +         , 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27
> +         , 28, 29, 30, 31, 32, 33, 34, 35, 36)
> +     , .Dim = c(4L, 12L)
> +     , .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C"
> +         , "D", "E", "F", "G", "H", "I"))
> +     )
> > xdf <- as.data.frame(x)
> > xdf
>   year month day A B  C  D  E  F  G  H  I
> 1 1961     1   1 1 5  9 13 17 21 25 29 33
> 2 1961     1   2 2 6 10 14 18 22 26 30 34
> 3 1961     1   3 3 7 11 15 19 23 27 31 35
> 4 1961     1   4 4 8 12 16 20 24 28 32 36
> > require(tidyr)
> > require(dplyr)
> > xdf %>% gather(station, discharge, -year, -month, -day)
>    year month day station discharge
> 1  1961     1   1       A         1
> 2  1961     1   2       A         2
> 3  1961     1   3       A         3
> 4  1961     1   4       A         4
> 5  1961     1   1       B         5
> 6  1961     1   2       B         6
> 7  1961     1   3       B         7
> 8  1961     1   4       B         8
> 9  1961     1   1       C         9
> 10 1961     1   2       C        10
> 11 1961     1   3       C        11
> 12 1961     1   4       C        12
> 13 1961     1   1       D        13
> 14 1961     1   2       D        14
> 15 1961     1   3       D        15
> 16 1961     1   4       D        16
> 17 1961     1   1       E        17
> 18 1961     1   2       E        18
> 19 1961     1   3       E        19
> 20 1961     1   4       E        20
> 21 1961     1   1       F        21
> 22 1961     1   2       F        22
> 23 1961     1   3       F        23
> 24 1961     1   4       F        24
> 25 1961     1   1       G        25
> 26 1961     1   2       G        26
> 27 1961     1   3       G        27
> 28 1961     1   4       G        28
> 29 1961     1   1       H        29
> 30 1961     1   2       H        30
> 31 1961     1   3       H        31
> 32 1961     1   4       H        32
> 33 1961     1   1       I        33
> 34 1961     1   2       I        34
> 35 1961     1   3       I        35
> 36 1961     1   4       I        36
> >
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> 
> On Wed, Sep 17, 2014 at 8:28 AM, eliza botto <eliza_botto at hotmail.com> wrote:
> > Dear useRs,
> > I have a data frame "y"  starting from 1961 to 2010 in the following manner (where A,B,C ......, I are station names and the values uder these are "discharge" values.)
> >> dput(y)
> > structure(c(1961, 1961, 1961, 1961, 1, 1, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36), .Dim = c(4L, 12L), .Dimnames = list(NULL, c("year", "month", "day", "A", "B", "C", "D", "E", "F", "G", "H", "I")))
> >
> > I want it to be in the following manner "E" where the stations names are in a seperate column and all discharge values are in one column.
> >> dput(E)
> >
> > structure(list(year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1961", class = "factor"),     month = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,     2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,     4), day = c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L,     1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L,     4L, 1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L), discharge = structure(c(1L,     12L, 23L, 31L, 32L, 33L, 34L, 35L, 36L, 2L, 3L, 4L, 5L, 6L,     7L, 8L, 9L, 10L, 11L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,     20L, 21L, 22L, 24L, 25L, 26L, 27L, 28L, 29L, 30L), .Label = c("1",     "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",     "2", "20", "21", "22", "23", "24", "25", "26", "27", "28",     "29", "3", "30", "31", "32", "33", "34", "35", "36", "4",     "5", "6", "7", "8", "9"), class = "factor"), station = c("A",  !
>    !
> >   "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "C", "D",     "D", "D", "D", "E", "E", "E", "E", "F", "F", "F", "F", "G",     "G", "G", "G", "H", "H", "H", "H", "I", "I", "I", "I")), .Names = c("year", "month", "day", "discharge", "station"), row.names = c(NA, 36L), class = "data.frame")
> >
> > I hope I followed all the instructions given to be by some fellows.
> > Thankyou very much in advance.
> > Eliza
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From btyner at gmail.com  Wed Sep 17 23:57:03 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Wed, 17 Sep 2014 17:57:03 -0400
Subject: [R] <NA> from cut.Date
In-Reply-To: <54197116.7040805@stats.ox.ac.uk>
References: <54197116.7040805@stats.ox.ac.uk>
Message-ID: <541A03AF.5070305@gmail.com>

Thanks Brian! 

The confusion was due to my failure to notice that these two functions have opposite defaults for 'right':

   > args(cut.default)
   function (x, breaks, labels = NULL, include.lowest = FALSE, right = TRUE, dig.lab = 3L, ordered_result = FALSE, ...) 

   > args(cut.Date)
   function (x, breaks, labels = NULL, start.on.monday = TRUE, right = FALSE, ...) 

I suppose the latter does make sense, given that days, months, years etc are right-continuous functions of time.

Regards
Ben

> On 17/09/2014 12:04, Benjamin Tyner wrote:
> >/ Hello,
> />/
> />/ I'm wondering if this is expected?
> /
> It is as documented!
> >/
> />/      > cut(structure(11111, class="Date"), structure(c(11100,11111),
> />/ class="Date"))
> />/      [1] <NA>
> />/      Levels: 2000-05-23
> />/
> />/ The help page says that "for ?"Date"? objects, only ?"day"?, ?"week"?,
> />/ ?"month"?, ?"quarter"? and ?"year"? are allowed" [for the 'breaks'
> />/ argument]. Though I am not sure whether this statement is only
> />/ applicable in the context of the previous sentence about interval
> />/ specification (i.e., a roundabout way of saying that ?"sec"?, ?"min"?,
> />/ ?"hour"?, and ?"DSTday"? are not allowed for 'Date' objects), or whether
> />/ it also means that a vector of cut points (as in my example) is likewise
> />/ not allowed? If the latter, then perhaps the function out to error out
> />/ rather than return <NA> in this case?
> /
> The NA is correct: the value you pass is not covered by the 'breaks' you 
> specified.  As the help says
>
>       Using both ?right = TRUE? and ?include.lowest = TRUE? will include
>       both ends of the range of dates.
>
> With the default values, only the lower end is included.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk <https://stat.ethz.ch/mailman/listinfo/r-help>
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK



From gpetris at uark.edu  Thu Sep 18 01:24:45 2014
From: gpetris at uark.edu (Giovanni Petris)
Date: Wed, 17 Sep 2014 23:24:45 +0000
Subject: [R] Generating unordered, with replacement, samples
In-Reply-To: <5419E8D0.9060904@gmail.com>
References: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACE9AC@ex-mbx2.uark.edu>,
	<5419DBEA.7000007@gmail.com>
	<A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACEA05@ex-mbx2.uark.edu>,
	<5419E8D0.9060904@gmail.com>
Message-ID: <A1F1A2DDE4BBE14F8DD8B25666C9D5A07CACEA91@ex-mbx2.uark.edu>


Thank you!

That does exactly what I was looking for.

Best,
Giovanni

________________________________________
From: Duncan Murdoch [murdoch.duncan at gmail.com]
Sent: Wednesday, September 17, 2014 15:02
To: Giovanni Petris; r-help at R-project.org
Subject: Re: [R] Generating unordered, with replacement, samples

On 17/09/2014 3:46 PM, Giovanni Petris wrote:
> Hi Duncan,
>
> You are right. The idea of the derivation consists in 'throwing' k placeholders ("*" in the example below) in the list of the individuals of the population. For example, if the population is letters[1:6], and the sample size is 4, the following code generates uniformly a 'sample'.
>
> > n <- 6; k <- 4
> > set.seed(2)
> > xxx <- rep("*", n + k)
> > ind <- sort(sample(2 : (n+k), k))
> > xxx[setdiff(1 : (n+k), ind)] <- letters[seq.int(n)]
> > noquote(xxx)
>   [1] a b * c d * * e f *
>
> This represents the sample (b, d, d, f). I am still missing the "all" I need to do that you mention, that is how I can transform the vector xxx into something more readily usable, like c(b, d, d, f), or even a summary of counts. I guess I am looking for a bit of R trickery here...

I think this works, but you'd better check!

Sample the placeholders:

ind <- sort( sample(n + k -1, n-1) )  # I don't think sort() is necessary...

Add placeholders at the start and end:

ind <- c(0, ind, n+k)

Take the diffs, and subtract one:

diff(ind) - 1

I think this gives the counts you want.

Duncan Murdoch


From dwinsemius at comcast.net  Thu Sep 18 03:02:51 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 17 Sep 2014 21:02:51 -0400
Subject: [R] plots on log="y" scale with smooths
In-Reply-To: <5419F04A.1000008@yorku.ca>
References: <5419F04A.1000008@yorku.ca>
Message-ID: <43DEC892-0366-46AB-A6E9-04ABD21CDF0C@comcast.net>


On Sep 17, 2014, at 4:34 PM, Michael Friendly wrote:

> In the following example, I am trying to plot a response on a log  
> scale, and add one or more smoothed
> curves, e.g., lowess and abline.  In base graphics, I'd like to do  
> this using log="y", so that the Y axis is
> spaced on the log scale, but labeled as the actual response values.  
> Using ggplot2, I'm using
> scale_y_log10 to achieve the same purpose.  However, my attempts to  
> add the smooths differ
> considerably, so I must be missing something.
>
> Here's the data I'm working with for one example:
>
> data("CodParasites", package = "countreg")
> ## omit NAs in response & predictor
> CodParasites <- subset(CodParasites, !(is.na(intensity) |  
> is.na(length)))
> ## plot only positive values of intensity
> CPpos <- subset(CodParasites, intensity>0)
>
> Here's the base graphics plot.  The abline() is clearly wrong and  
> the lowess smooth looks too low.
> How does one meld plots using log="y" with such additional plot  
> annotations ?
>
> plot(jitter(intensity) ~ length, data = CPpos, log = "y")
> with(CPpos, lines(lowess(length, log(intensity)), col="red", lwd=2) )
> abline(lm(log(intensity) ~ length, data=CPpos))

This is what I would have expected to be a more accurate plot of the  
estimated central tendencies:

with(CPpos, lines(lowess(length, exp(log(intensity))), col="red",  
lwd=2) )
lines( CPpos$length, exp( lm(log(intensity) ~ length, data=CPpos) 
$fitted)   )

Just because you have changed the scaling of the plot axis does not  
mean that you would plot log()-ed values.

>
> Here's an attempt at a ggplot2 version, that actually looks more  
> reasonable, but I'm not sure that it
> is correct:
>
> library(ggplot2)
> ggplot(CPpos, aes(x=length, y=intensity)) +
>    geom_jitter(position=position_jitter(height=.1), alpha=0.25) +
>    scale_y_log10(breaks=c(1,2,5,10,20,50,100, 200)) +
>    stat_smooth(method="loess", color="red", size=1.5) +
>    stat_smooth(method="lm")

The loess line is somewhat different but the lm() prediction is the  
same as I expected.

-- 
David.


David Winsemius, MD
Alameda, CA, USA


From greg at warnes.net  Thu Sep 18 00:44:15 2014
From: greg at warnes.net (Gregory Warnes)
Date: Wed, 17 Sep 2014 18:44:15 -0400
Subject: [R] gplot heatmaps: clustering according to rowsidecolors +
	key.xtickfun
In-Reply-To: <30EC1811-AA02-4B8A-98A5-4291E00B2284@warnes.net>
References: <540867EA.8030503@uni-bremen.de>
	<30EC1811-AA02-4B8A-98A5-4291E00B2284@warnes.net>
Message-ID: <CAKorm_siC=qkK7X6Ud+-qrBc9DCGRN2=jmt5HVOdtp5-QJevSg@mail.gmail.com>

Oops, I forgot to mention that an bug was preventing RowSideColors from
working properly.  It is fixed in version 2.14.2 of gplots which I've just
uploaded to CRAN and am attaching to this email.

-Greg

On Wed, Sep 17, 2014 at 5:12 PM, Gregory R. Warnes <greg at warnes.net> wrote:

> Hello Tim,
>
> Sorry about the slow response, I just found this message.
>
> On Sep 4, 2014, at 9:23 AM, Tim Richter-Heitmann <trichter at uni-bremen.de>
> wrote:
>
> Hi there,
>
> I have two questions about heatmap.2 in gplot.
> My input is a simple square matrix with numeric values between 75 and 100
> (it is a similarity matrix based on bacterial DNA sequences).
>
> 1. I can sort my input matrix into categories with rowsidecolors (in this
> case, very conveniently by bacterial taxa). I do a clustering and
> reordering of my matrix by Rowv=TRUE (and Colv="Rowv").
> The question is now, can i combine the two features that the
> clustering/reordering is done only for submatrices defined by the vectors
> given in rowsidecolors (so, in this case, that the original ordering by
> bacterial taxa is preserved)?
>
> That would be very amazing.
>
>
> Hmm.    To get the individual species clustered within taxa would require
> doing the hierarchical clustering first separately, then combining the
> dendrograms.  This should do the trick:
>
>
> set.seed(1234567)
>
> ## Dummy Distances
> x <- matrix( rnorm(400, mean=87.5, sd=12.5/4), ncol=20)
>
> ## Dummy Taxa
> taxa <- sample(letters[1:4], 20, replace=T)
> taxa <- as.factor(taxa)
>
> # sort the data by taxa
> ord <- order(taxa)
>
> x <- x[ord, ord]
> taxa <- taxa[ord]
> rownames(x) <- 1:nrow(x)
>
>
> ####
> # stats:::merge.dendrogram is broken.  This is the corrected version.
> # See R BUG 15648
> # (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15648) for
> # details
> ####
> merge.dendrogram <- function(x, y, ..., height) {
>   stopifnot(inherits(x,"dendrogram"), inherits(y,"dendrogram"))
>
>   ### FIX
>   inx.add <- function(inx, add) {
>     if(is.leaf(inx)) {
>       inx <- inx + add
>     }
>     return(inx)
>   }
>   y <- dendrapply(y,  inx.add, add=max(unlist(x)))
>   ### FIX
>
>   r <- list(x,y)
>   if(length(xtr <- list(...))) {
>     if(!all(is.d <- vapply(xtr, inherits, NA, what="dendrogram"))) {
>         xpr <- substitute(c(...))
>         nms <- sapply(xpr[-1][!is.d], deparse, nlines = 1L)
>         ## do not simplify: xgettext needs this form
>         msg <- ngettext(length(nms),
>                         "extra argument %s is not of class \"%s\"",
>                         "extra arguments %s are not of class \"%s\"s")
>         stop(sprintf(msg, paste(nms, collapse=", "), "dendrogram"),
>              domain = NA)
>     }
>     ## <GRW>
>     for(i in 1:length(xtr))
>         {
>             add <- max(c(unlist(r), unlist(xtr)))
>             print(add)
>             xtr[[i]] <- dendrapply(xtr[[i]], inx.add, add=add)
>         }
>     ## </GRW>
>     r <- c(r, xtr)
>   }
>   attr(r, "members") <- sum(vapply(r, attr, 0L, which="members"))
>   h.max <- max(vapply(r, attr, 0., which="height"))
>   if(missing(height) || is.null(height))
>     height <- 1.1 * h.max
>   else if(height < h.max) {
>     msg <- gettextf("'height' must be at least %g, the maximal height of
> its components", h.max)
>     stop(msg, domain = NA)
>   }
>   attr(r, "height") <- height
>   class(r) <- "dendrogram"
>   midcache.dendrogram(r, quiet=TRUE)
> }
>
>
> ## Compute dendrograms within each taxum, then merge into a combined
> dendrogram
> dendList <- list()
> for( taxon in levels(taxa) )
>     {
>         items <- which(taxon==taxa)
>         submatrix <- x[ items, items]
>         dend <- as.dendrogram(hclust(dist(submatrix)))
>         dendList[[taxon]] <- dend
>     }
> names(dendList) <- NULL
> dends <- do.call("merge.dendrogram", dendList)
>
> ## Now generate the heatmap
> heatmap.2(x,
>           Rowv=dends,
>           Colv=dends,
>           symm=TRUE,
>           RowSideColors=c("red","blue","green","black")[as.numeric(taxa)],
>           ColSideColors=c("red","blue","green","black")[as.numeric(taxa)],
>           trace="none"
>           )
>
> 2. I have set my own coloring rules with:
>
> mypal <- c("grey","blue", "green","yellow","orange","red")
> col_breaks = c(seq(0,74.9), seq(75.0,78.4), seq(78.5,81.9),
> seq(82.0,86.4), seq(86.5, 94.5),  seq(94.5,100.0))
>
> Is it possible to pass this sequential ordering to key.xtickfun? May i ask
> for an example code?
>
>
> Use the ?breaks? and ?col? arguements:
>
>
> ## Custom color key
> mypal      <- c("grey","blue", "green","yellow","orange","red")
> col_breaks <- c(0,75.0,78.5,82.0,86.5,94.5,100.0)
>
>
> heatmap.2(x,
>           Rowv=dends,
>           Colv=dends,
>           symm=TRUE,
>           RowSideColors=c("red","blue","green","black")[as.numeric(taxa)],
>           ColSideColors=c("red","blue","green","black")[as.numeric(taxa)],
>           trace="none",
>           breaks=col_breaks,
>           col=mypal
>           )
>
> -Greg
>
>


-- 
"Whereas true religion and good morals are the only solid foundations of
public liberty and happiness . . . it is hereby earnestly recommended to
the several States to take the most effectual measures for the
encouragement thereof." Continental Congress, 1778

From kevin511511 at gmail.com  Thu Sep 18 08:22:44 2014
From: kevin511511 at gmail.com (Hanze Zhang)
Date: Thu, 18 Sep 2014 02:22:44 -0400
Subject: [R] R2WINBUGS Error message
Message-ID: <CAB4W2n4LBmJzb9maWyqkq5_zL+D3pQD=1Ru0XVNaLgcOMpHLCA@mail.gmail.com>

Hi, guys,

I am a new user for package R2winbugs. When I run the code a=bugs(...), an
error message always comes out, see below:

Error in file(con, "wb") : cannot open the connection
In addition: Warning messages:
1: In file.create(to[okay]) :
  cannot create file 'c:/Program
Files/WinBUGS14//System/Rsrc/Registry_Rsave.odc', reason 'Permission denied'
2: In file(con, "wb") :
  cannot open file 'c:/Program Files/WinBUGS14//System/Rsrc/Registry.odc':
Permission denied

How to solve this issue?

Thanks a lot!

	[[alternative HTML version deleted]]


From radhakrishnan.mohan at gmail.com  Thu Sep 18 09:13:25 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Thu, 18 Sep 2014 12:43:25 +0530
Subject: [R] Training a model using glm
In-Reply-To: <CAJ9CoWnWkJHZJz3b74WESQ2jfd2ycnC73pSuVkKrRBTjV5A-ZA@mail.gmail.com>
References: <CAOoXFP-JrLfvfwWSKUnu1Jd1haYCLRF468Wf1W1VcoiSm+ds5A@mail.gmail.com>
	<CADv2QyHBHPCNz6MXCZdhMukX4N_c6gADd9Wu+bOduRZ5fr8E4w@mail.gmail.com>
	<CAOoXFP_iZcdfdgmUhL=L0QVZb2depk241Fe9J+SXE1WP6-bzhQ@mail.gmail.com>
	<CAJ9CoWnWkJHZJz3b74WESQ2jfd2ycnC73pSuVkKrRBTjV5A-ZA@mail.gmail.com>
Message-ID: <CAOoXFP-6BN-9yKcccSC5WOK6tGwWwBff8ntETyYDzkkWq7B9wQ@mail.gmail.com>

Oh. I understand now. There is nothing wrong with the logic. It is the
syntax.

> library(AppliedPredictiveModeling)

*Warning message:*

*package ?AppliedPredictiveModeling? was built under R version 3.1.1 *

> set.seed(3433)

> data(AlzheimerDisease)

> adData = data.frame(diagnosis,predictors)

> inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]

> training = adData[ inTrain,]

> testing = adData[-inTrain,]

> training1 <- training[,grepl("^IL|^diagnosis",names(training))]

>

> test1 <- testing[,grepl("^IL|^diagnosis",names(testing))]

> modelFit <- train(diagnosis ~ .,method="glm",data=training1)

> confusionMatrix(test1$diagnosis,predict(modelFit, test1))

Confusion Matrix and Statistics


          Reference

Prediction Impaired Control

  Impaired        2      20

  Control         9      51



               Accuracy : 0.6463

                 95% CI : (0.533, 0.7488)

    No Information Rate : 0.8659

    P-Value [Acc > NIR] : 1.00000



                  Kappa : -0.0702

 Mcnemar's Test P-Value : 0.06332



            Sensitivity : 0.18182

            Specificity : 0.71831

         Pos Pred Value : 0.09091

         Neg Pred Value : 0.85000

             Prevalence : 0.13415

         Detection Rate : 0.02439

   Detection Prevalence : 0.26829

      Balanced Accuracy : 0.45006



       'Positive' Class : Impaired


Thanks,

Mohan

On Thu, Sep 18, 2014 at 12:21 AM, Max Kuhn <mxkuhn at gmail.com> wrote:

> You have not shown all of your code and it is difficult to diagnose the
> issue.
>
> I assume that you are using the data from:
>
>    library(AppliedPredictiveModeling)
>    data(AlzheimerDisease)
>
> If so, there is example code to analyze these data in that package. See
> ?scriptLocation.
>
> We have no idea how you got to the `training` object (package versions
> would be nice too).
>
> I suspect that Dennis is correct. Try using more normal syntax without the
> $ indexing in the formula. I wouldn't say it is (absolutely) wrong but it
> doesn't look right either.
>
> Max
>
>
> On Wed, Sep 17, 2014 at 2:04 PM, Mohan Radhakrishnan <
> radhakrishnan.mohan at gmail.com> wrote:
>
>> Hi Dennis,
>>
>>                      Why is there that warning ? I think my syntax is
>> right. Isn't it not? So the warning can be ignored ?
>>
>> Thanks,
>> Mohan
>>
>> On Wed, Sep 17, 2014 at 9:48 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>>
>> > No reproducible example (i.e., no data) supplied, but the following
>> > should work in general, so I'm presuming this maps to the caret
>> > package as well. Thoroughly untested.
>> >
>> > library(caret)    # something you failed to mention
>> >
>> > ...
>> > modelFit <- train(diagnosis ~ ., data = training1)    # presumably a
>> > logistic regression
>> > confusionMatrix(test1$diagnosis, predict(modelFit, newdata = test1,
>> > type = "response"))
>> >
>> > For GLMs, there are several types of possible predictions. The default
>> > is 'link', which associates with the linear predictor. caret may have
>> > a different syntax so you should check its help pages re the supported
>> > predict methods.
>> >
>> > Hint: If a function takes a data = argument, you don't need to specify
>> > the variables as components of the data frame - the variable names are
>> > sufficient. You should also do some reading to understand why the
>> > model formula I used is correct if you're modeling one variable as
>> > response and all others in the data frame as covariates.
>> >
>> > Dennis
>> >
>> > On Tue, Sep 16, 2014 at 11:15 PM, Mohan Radhakrishnan
>> > <radhakrishnan.mohan at gmail.com> wrote:
>> > > I answered this question which was part of the online course
>> correctly by
>> > > executing some commands and guessing.
>> > >
>> > > But I didn't get the gist of this approach though my R code works.
>> > >
>> > > I have a training and test dataset.
>> > >
>> > >> nrow(training)
>> > >
>> > > [1] 251
>> > >
>> > >> nrow(testing)
>> > >
>> > > [1] 82
>> > >
>> > >> head(training1)
>> > >
>> > >    diagnosis    IL_11    IL_13    IL_16   IL_17E IL_1alpha      IL_3
>> > > IL_4
>> > >
>> > > 6   Impaired 6.103215 1.282549 2.671032 3.637051 -8.180721 -3.863233
>> > > 1.208960
>> > >
>> > > 10  Impaired 4.593226 1.269463 3.476091 3.637051 -7.369791 -4.017384
>> > > 1.808289
>> > >
>> > > 11  Impaired 6.919778 1.274133 2.154845 4.749337 -7.849364 -4.509860
>> > > 1.568616
>> > >
>> > > 12  Impaired 3.218759 1.286356 3.593860 3.867347 -8.047190 -3.575551
>> > > 1.916923
>> > >
>> > > 13  Impaired 4.102821 1.274133 2.876338 5.731246 -7.849364 -4.509860
>> > > 1.808289
>> > >
>> > > 16  Impaired 4.360856 1.278484 2.776394 5.170380 -7.662778 -4.017384
>> > > 1.547563
>> > >
>> > >          IL_5       IL_6 IL_6_Receptor     IL_7     IL_8
>> > >
>> > > 6  -0.4004776  0.1856864   -0.51727788 2.776394 1.708270
>> > >
>> > > 10  0.1823216 -1.5342758    0.09668586 2.154845 1.701858
>> > >
>> > > 11  0.1823216 -1.0965412    0.35404039 2.924466 1.719944
>> > >
>> > > 12  0.3364722 -0.3987186    0.09668586 2.924466 1.675557
>> > >
>> > > 13  0.0000000  0.4223589   -0.53219115 1.564217 1.691393
>> > >
>> > > 16  0.2623643  0.4223589    0.18739989 1.269636 1.705116
>> > >
>> > > The testing dataset is similar with 13 columns. Number of rows vary.
>> > >
>> > >
>> > > training1 <- training[,grepl("^IL|^diagnosis",names(training))]
>> > >
>> > > test1 <- testing[,grepl("^IL|^diagnosis",names(testing))]
>> > >
>> > > modelFit <- train(training1$diagnosis ~ training1$IL_11 +
>> > training1$IL_13 +
>> > > training1$IL_16 + training1$IL_17E + training1$IL_1alpha +
>> > training1$IL_3 +
>> > > training1$IL_4 + training1$IL_5 + training1$IL_6 +
>> > training1$IL_6_Receptor
>> > > + training1$IL_7 + training1$IL_8,method="glm",data=training1)
>> > >
>> > > confusionMatrix(test1$diagnosis,predict(modelFit, test1))
>> > >
>> > > I get this error when I run the above command to get the confusion
>> > matrix.
>> > >
>> > > *'newdata' had 82 rows but variables found have 251 rows '*
>> > >
>> > > I thought this was simple. I train a model using the training dataset
>> and
>> > > predict using the test dataset and get the accuracy.
>> > >
>> > > Am I missing the obvious here ?
>> > >
>> > > Thanks,
>> > >
>> > > Mohan
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From radhakrishnan.mohan at gmail.com  Thu Sep 18 09:53:40 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Thu, 18 Sep 2014 13:23:40 +0530
Subject: [R] Training a model using glm
In-Reply-To: <CAOoXFP-6BN-9yKcccSC5WOK6tGwWwBff8ntETyYDzkkWq7B9wQ@mail.gmail.com>
References: <CAOoXFP-JrLfvfwWSKUnu1Jd1haYCLRF468Wf1W1VcoiSm+ds5A@mail.gmail.com>
	<CADv2QyHBHPCNz6MXCZdhMukX4N_c6gADd9Wu+bOduRZ5fr8E4w@mail.gmail.com>
	<CAOoXFP_iZcdfdgmUhL=L0QVZb2depk241Fe9J+SXE1WP6-bzhQ@mail.gmail.com>
	<CAJ9CoWnWkJHZJz3b74WESQ2jfd2ycnC73pSuVkKrRBTjV5A-ZA@mail.gmail.com>
	<CAOoXFP-6BN-9yKcccSC5WOK6tGwWwBff8ntETyYDzkkWq7B9wQ@mail.gmail.com>
Message-ID: <CAOoXFP-sw+dVvwguL6gs+5MdqV-kafFFceHvbbMsv3ifAWsMOg@mail.gmail.com>

Thanks Max and Dennis. Based on the syntax change I got the result for the
PCA part also.

training2 <- training[,grepl("^IL",names(training))]


preProc <- preProcess(training2,method="pca",thresh=0.8)

test2 <- testing[,grepl("^IL",names(testing))]


trainpca <- predict(preProc, training2)

testpca <- predict(preProc, test2)


modelFitpca <- train(training1$diagnosis ~ .,method="glm",data=trainpca)


confusionMatrix(test1$diagnosis,predict(modelFitpca, testpca))


Mohan

On Thu, Sep 18, 2014 at 12:43 PM, Mohan Radhakrishnan <
radhakrishnan.mohan at gmail.com> wrote:

> Oh. I understand now. There is nothing wrong with the logic. It is the
> syntax.
>
> > library(AppliedPredictiveModeling)
>
> *Warning message:*
>
> *package ?AppliedPredictiveModeling? was built under R version 3.1.1 *
>
> > set.seed(3433)
>
> > data(AlzheimerDisease)
>
> > adData = data.frame(diagnosis,predictors)
>
> > inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
>
> > training = adData[ inTrain,]
>
> > testing = adData[-inTrain,]
>
> > training1 <- training[,grepl("^IL|^diagnosis",names(training))]
>
> >
>
> > test1 <- testing[,grepl("^IL|^diagnosis",names(testing))]
>
> > modelFit <- train(diagnosis ~ .,method="glm",data=training1)
>
> > confusionMatrix(test1$diagnosis,predict(modelFit, test1))
>
> Confusion Matrix and Statistics
>
>
>           Reference
>
> Prediction Impaired Control
>
>   Impaired        2      20
>
>   Control         9      51
>
>
>
>                Accuracy : 0.6463
>
>                  95% CI : (0.533, 0.7488)
>
>     No Information Rate : 0.8659
>
>     P-Value [Acc > NIR] : 1.00000
>
>
>
>                   Kappa : -0.0702
>
>  Mcnemar's Test P-Value : 0.06332
>
>
>
>             Sensitivity : 0.18182
>
>             Specificity : 0.71831
>
>          Pos Pred Value : 0.09091
>
>          Neg Pred Value : 0.85000
>
>              Prevalence : 0.13415
>
>          Detection Rate : 0.02439
>
>    Detection Prevalence : 0.26829
>
>       Balanced Accuracy : 0.45006
>
>
>
>        'Positive' Class : Impaired
>
>
> Thanks,
>
> Mohan
>
> On Thu, Sep 18, 2014 at 12:21 AM, Max Kuhn <mxkuhn at gmail.com> wrote:
>
>> You have not shown all of your code and it is difficult to diagnose the
>> issue.
>>
>> I assume that you are using the data from:
>>
>>    library(AppliedPredictiveModeling)
>>    data(AlzheimerDisease)
>>
>> If so, there is example code to analyze these data in that package. See
>> ?scriptLocation.
>>
>> We have no idea how you got to the `training` object (package versions
>> would be nice too).
>>
>> I suspect that Dennis is correct. Try using more normal syntax without
>> the $ indexing in the formula. I wouldn't say it is (absolutely) wrong but
>> it doesn't look right either.
>>
>> Max
>>
>>
>> On Wed, Sep 17, 2014 at 2:04 PM, Mohan Radhakrishnan <
>> radhakrishnan.mohan at gmail.com> wrote:
>>
>>> Hi Dennis,
>>>
>>>                      Why is there that warning ? I think my syntax is
>>> right. Isn't it not? So the warning can be ignored ?
>>>
>>> Thanks,
>>> Mohan
>>>
>>> On Wed, Sep 17, 2014 at 9:48 PM, Dennis Murphy <djmuser at gmail.com>
>>> wrote:
>>>
>>> > No reproducible example (i.e., no data) supplied, but the following
>>> > should work in general, so I'm presuming this maps to the caret
>>> > package as well. Thoroughly untested.
>>> >
>>> > library(caret)    # something you failed to mention
>>> >
>>> > ...
>>> > modelFit <- train(diagnosis ~ ., data = training1)    # presumably a
>>> > logistic regression
>>> > confusionMatrix(test1$diagnosis, predict(modelFit, newdata = test1,
>>> > type = "response"))
>>> >
>>> > For GLMs, there are several types of possible predictions. The default
>>> > is 'link', which associates with the linear predictor. caret may have
>>> > a different syntax so you should check its help pages re the supported
>>> > predict methods.
>>> >
>>> > Hint: If a function takes a data = argument, you don't need to specify
>>> > the variables as components of the data frame - the variable names are
>>> > sufficient. You should also do some reading to understand why the
>>> > model formula I used is correct if you're modeling one variable as
>>> > response and all others in the data frame as covariates.
>>> >
>>> > Dennis
>>> >
>>> > On Tue, Sep 16, 2014 at 11:15 PM, Mohan Radhakrishnan
>>> > <radhakrishnan.mohan at gmail.com> wrote:
>>> > > I answered this question which was part of the online course
>>> correctly by
>>> > > executing some commands and guessing.
>>> > >
>>> > > But I didn't get the gist of this approach though my R code works.
>>> > >
>>> > > I have a training and test dataset.
>>> > >
>>> > >> nrow(training)
>>> > >
>>> > > [1] 251
>>> > >
>>> > >> nrow(testing)
>>> > >
>>> > > [1] 82
>>> > >
>>> > >> head(training1)
>>> > >
>>> > >    diagnosis    IL_11    IL_13    IL_16   IL_17E IL_1alpha      IL_3
>>> > > IL_4
>>> > >
>>> > > 6   Impaired 6.103215 1.282549 2.671032 3.637051 -8.180721 -3.863233
>>> > > 1.208960
>>> > >
>>> > > 10  Impaired 4.593226 1.269463 3.476091 3.637051 -7.369791 -4.017384
>>> > > 1.808289
>>> > >
>>> > > 11  Impaired 6.919778 1.274133 2.154845 4.749337 -7.849364 -4.509860
>>> > > 1.568616
>>> > >
>>> > > 12  Impaired 3.218759 1.286356 3.593860 3.867347 -8.047190 -3.575551
>>> > > 1.916923
>>> > >
>>> > > 13  Impaired 4.102821 1.274133 2.876338 5.731246 -7.849364 -4.509860
>>> > > 1.808289
>>> > >
>>> > > 16  Impaired 4.360856 1.278484 2.776394 5.170380 -7.662778 -4.017384
>>> > > 1.547563
>>> > >
>>> > >          IL_5       IL_6 IL_6_Receptor     IL_7     IL_8
>>> > >
>>> > > 6  -0.4004776  0.1856864   -0.51727788 2.776394 1.708270
>>> > >
>>> > > 10  0.1823216 -1.5342758    0.09668586 2.154845 1.701858
>>> > >
>>> > > 11  0.1823216 -1.0965412    0.35404039 2.924466 1.719944
>>> > >
>>> > > 12  0.3364722 -0.3987186    0.09668586 2.924466 1.675557
>>> > >
>>> > > 13  0.0000000  0.4223589   -0.53219115 1.564217 1.691393
>>> > >
>>> > > 16  0.2623643  0.4223589    0.18739989 1.269636 1.705116
>>> > >
>>> > > The testing dataset is similar with 13 columns. Number of rows vary.
>>> > >
>>> > >
>>> > > training1 <- training[,grepl("^IL|^diagnosis",names(training))]
>>> > >
>>> > > test1 <- testing[,grepl("^IL|^diagnosis",names(testing))]
>>> > >
>>> > > modelFit <- train(training1$diagnosis ~ training1$IL_11 +
>>> > training1$IL_13 +
>>> > > training1$IL_16 + training1$IL_17E + training1$IL_1alpha +
>>> > training1$IL_3 +
>>> > > training1$IL_4 + training1$IL_5 + training1$IL_6 +
>>> > training1$IL_6_Receptor
>>> > > + training1$IL_7 + training1$IL_8,method="glm",data=training1)
>>> > >
>>> > > confusionMatrix(test1$diagnosis,predict(modelFit, test1))
>>> > >
>>> > > I get this error when I run the above command to get the confusion
>>> > matrix.
>>> > >
>>> > > *'newdata' had 82 rows but variables found have 251 rows '*
>>> > >
>>> > > I thought this was simple. I train a model using the training
>>> dataset and
>>> > > predict using the test dataset and get the accuracy.
>>> > >
>>> > > Am I missing the obvious here ?
>>> > >
>>> > > Thanks,
>>> > >
>>> > > Mohan
>>> > >
>>> > >         [[alternative HTML version deleted]]
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From Steve.Riley at pfizer.com  Thu Sep 18 15:33:24 2014
From: Steve.Riley at pfizer.com (Riley, Steve)
Date: Thu, 18 Sep 2014 13:33:24 +0000
Subject: [R] Extract model from deriv3 or nls
Message-ID: <941F9C738E7ABB459A4306D21D7177CBC8598EAD@NDHAMREXDE03.amer.pfizer.com>

Hello!

I am trying to figure out how to extract the model equation when using deriv3 with nls.

Here is my example:
#
#             Generate derivatives
#
Puro.fun2 <- deriv3(expr = ~(Vmax + VmaxT*state) * conc/(K + Kt * state + conc),
                    name = c("Vmax","VmaxT","K","Kt"),
                    function.arg = function(conc, state, Vmax, VmaxT, K, Kt) NULL)
#
#             Fit model using derivative function
#
Puro.fit1 <- nls(rate ~ Puro.fun2(conc, state == "treated", Vmax, VmaxT, K, Kt),
                 data = Puromycin,
                 start = c(Vmax = 160, VmaxT = 47, K = 0.043, Kt = 0.05))

Normally I would use summary(Puro.fit1)$formula to extract the model but because I am implementing deriv3, the following gets returned:

> summary(Puro.fit1)$formula
rate ~ Puro.fun2(conc, state == "treated", Vmax, VmaxT, K, Kt)

What I would like to do is find something that returns:

rate ~ (Vmax + VmaxT*state) * conc/(K + Kt * state + conc)

Is there a way to extract this? Please advise. Thanks for your time.

Steve
860-441-3435


	[[alternative HTML version deleted]]


From rl at openmailbox.org  Thu Sep 18 16:34:35 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Thu, 18 Sep 2014 14:34:35 +0000
Subject: [R] apply block of if statements with menu function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE33DB@SRVEXCHMBX.precheza.cz>
References: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
	<55db8485faf3fbd2cdbd75c8b0570b71@openmailbox.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE333E@SRVEXCHMBX.precheza.cz>
	<de9e90496abf9d4d16ea37b61f5e5c8d@openmailbox.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE33DB@SRVEXCHMBX.precheza.cz>
Message-ID: <460774e13cf2a35b71f1f7e8b4a2afe7@openmailbox.org>

On 2014-09-16 12:35, PIKAL Petr wrote:
> 
> So if result of menu is 0 (you did not choose anything) you can either
> stay with 0, then switch does not return anything or add 1 and let
> evaluate something meaningful specified in second and following
> positions of switch command.
> 

Thanks for your explanation, which completed my understanding! :) For 
the benefit of other novices, below is an example to demonstrate how 
'switch' and 'menu' can be used:

switch(menu(c(1,2),graphics=FALSE,title='select something'), 
{(seq(1:10))}, {(rnorm(20))})

However, how to make the option '0 to exit' to appear in the command 
terminal?


From ValleeM at iarc.fr  Thu Sep 18 16:40:40 2014
From: ValleeM at iarc.fr (Maxime Vallee)
Date: Thu, 18 Sep 2014 14:40:40 +0000
Subject: [R] R "write" strange behavior in huge file
In-Reply-To: <1DBFB800-916F-4972-BADB-7C106AA099F8@collocations.de>
References: <D03E06C1.65E77%ValleeM@iarc.fr>
	<1DBFB800-916F-4972-BADB-7C106AA099F8@collocations.de>
Message-ID: <D040BB15.65F29%ValleeM@iarc.fr>

Thank you, it is exactly that.

I have followed your idea of chunks (1 GB chunks, on the safe side), and appended them. Worked like charm, thank you.

--Maxime



From: "Stefan Evert (Mailing Lists)" <stefanML at collocations.de<mailto:stefanML at collocations.de>>
Date: mercredi 17 septembre 2014 15:39
To: Maxime Vall?e <valleem at iarc.fr<mailto:valleem at iarc.fr>>
Cc: R-help Mailing List <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] R "write" strange behavior in huge file

You probably told R to write out the file as a single long line with fields separated alternately by 380 TABs and one newline ? that?s what the ncol argument does (write is just a small wrapper around cat()).

cat() doesn?t print lines that are longer than 2 GiB, so it will insert an extra \n after every 2 GiB of data. (IIRC, this is because in the C code, fill=FALSE is replaced by fill=MAX_INT or so.)

The only way around this limitation that I can think of is to write a wrapper function that breaks up the matrix or list of vectors in smaller chunks and appends them separately to the output file.  I?m planning to add such a function to one of my packages, so I?d be interested if somebody has a better solution.

Best,
Stefan


On 16 Sep 2014, at 18:54, Maxime Vallee <ValleeM at iarc.fr<mailto:ValleeM at iarc.fr>> wrote:

In my script I have one list of 1,132,533 vectors (each vector contains
381 elements).

When I use "write" to save this list in a flat text file (I unlist my
list, separate by tabs, and set ncol to 381), I end up with a file of
1,132,535 lines (2 additional lines). I checked back, my R list do not
have those two additional items before writing.

With awk, I determined if lines where not made of 381 fields: there were
two, separated by around 400k lines.

I made sub-files, using those "incomplete" lines as boundaries. My files
are very close in size : 1.9 GB (respectively 1971841853 B and 1972614897
B). It feels like a 32 bit / 64 bit issue.

My R version is this:
./Rscript -e 'sessionInfo()$platform'
[1] "x86_64-unknown-linux-gnu (64-bit)"

There is somewhere, reaching 1.9 GB, something that is changing my tabs to
unwanted carriage returns...
Any idea that might cause this, and if it looks solvable in R?


-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:11}}


From sma.ali at fsjegj.rnu.tn  Thu Sep 18 16:53:50 2014
From: sma.ali at fsjegj.rnu.tn (Donia Smaali Bouhlila)
Date: Thu, 18 Sep 2014 15:53:50 +0100
Subject: [R] Pseudo R squared  for quantile regression with replicates
Message-ID: <f32c2295f53ae7fe7e9e906382cefb71@pop.rnu.tn>

Hi,


I am a new user of r software. I intend to do quantile regressions with 
complex survey data using replicate method. I have ran the following 
commands successfully:


  mydesign 
<-svydesign(ids=~IDSCHOOL,strata=~IDSTRATE,data=TUN,nest=TRUE,weights=~TOTWGT) 
bootdesign <- as.svrepdesign(mydesign,type="auto",replicates=150)

  fit<- 
withReplicates(bootdesign,quote(coef(rq(Math1~Female+Age+calculator+computer+desk+ 
+ 
dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2,tau=0.5,weights=.weights, 
method="fn"))))




I want get the pseudo R squared but I failed. I read a query dating from 
August 2006, [R] Pseudo R for Quant Reg and the answer to it:


rho <- function(u,tau=.5)u*(tau - (u < 0))
  V <- sum(rho(f$resid, f$tau))


  I copied it and paste it , replacing f by fit I get this error message:
Error in fit$resid : $ operator is invalid for atomic vectors, I don't 
know what it means

The fit object is likely to be quite complicated  I used str() to see 
what it looks like:



str (fit)
Class 'svrepstat'  atomic [1:19] 713.24 -24.01 -18.37 9.05 7.71 ...
   ..- attr(*, "var")= num [1:19, 1:19] 2839.3 10.2 -122.1 -332.4 -42.3 
...
   .. ..- attr(*, "dimnames")=List of 2
   .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age" "calculator" ...
   .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age" "calculator" ...
   .. ..- attr(*, "means")= Named num [1:19] 710.97 -24.03 -18.3 9.39 
7.58 ...
   .. .. ..- attr(*, "names")= chr [1:19] "(Intercept)" "Female" "Age" 
"calculator" ...
   ..- attr(*, "statistic")= chr "theta"

How can I retrieve the residuals?? and calculate the pseudo R squared??


Any help please


-- 
Dr. Donia Smaali Bouhlila
Associate-Professor
Department of Economics
Facult? des Sciences Economiques et de Gestion de Tunis


From gangchen6 at gmail.com  Thu Sep 18 17:18:59 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Thu, 18 Sep 2014 11:18:59 -0400
Subject: [R] Failure with .Rprofile on Mac OS X
Message-ID: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>

When R starts in GUI (e.g., /Applications/R.app/Contents/MacOS/R) on
my Mac OS X 10.7.5, the startup configuration in .Rprofile works fine.
However, when R starts on the terminal (e.g.,
/Library/Frameworks/R.framework/Resources/bin/R), it does not work at
all. What could be the reason for the failure?

Thanks,
Gang


From HDoran at air.org  Thu Sep 18 17:38:18 2014
From: HDoran at air.org (Doran, Harold)
Date: Thu, 18 Sep 2014 15:38:18 +0000
Subject: [R] Using read.csv.sql() to read in specific columns
Message-ID: <D04074A9.1F385%hdoran@air.org>

I am dealing with data frames that have thousands of columns and hundreds of thousands of rows and only need a few specific columns from the data. The data take various formats, but normally are tab-delimited.

I have written the following which is working as expected. However, because I?m so new at using sqldf(), just looking for some verification from users that this is in fact efficient and correct in the R-ish sense of the word and generalizable to larger data sets.

Harold

tmp <- data.frame(replicate(50, rnorm(10)))
names(tmp) <- paste('item', 1:50, sep='')
write.table(tmp, 'tmp.txt')
read.csv.sql("tmp.txt", sql = "select item1, item2, item50 from file", sep = ' ')

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Sep 18 19:55:01 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 18 Sep 2014 17:55:01 +0000
Subject: [R] Pseudo R squared  for quantile regression with replicates
In-Reply-To: <f32c2295f53ae7fe7e9e906382cefb71@pop.rnu.tn>
References: <f32c2295f53ae7fe7e9e906382cefb71@pop.rnu.tn>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F98C8C@mb02.ads.tamu.edu>

It is hard to say because we do not have enough information. R has approximately 6,000 packages and you have not told us which ones you are using. You have not told us much about your data and you have not told us where to find the query from August 2006. The basic problem is that your "fit" is not the same as the "f" in the query. Your fit object is not very complicated. If you look at the output from str(fit) you will see that fit is an "atomic" vector (note the wording in your error message) with a series of attributes that are probably documented in the help pages for the functions you are using. There is nothing called resid inside fit. It is likely that the post you are looking at refers to the output from rq(...) or perhaps predict(rq(...)), but not the output from withReplicates(..., quote(coef(rq(...)))) which is what fit is.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Donia Smaali Bouhlila
Sent: Thursday, September 18, 2014 9:54 AM
To: r-help at r-project.org
Subject: [R] Pseudo R squared for quantile regression with replicates

Hi,


I am a new user of r software. I intend to do quantile regressions with 
complex survey data using replicate method. I have ran the following 
commands successfully:


  mydesign 
<-svydesign(ids=~IDSCHOOL,strata=~IDSTRATE,data=TUN,nest=TRUE,weights=~TOTWGT) 
bootdesign <- as.svrepdesign(mydesign,type="auto",replicates=150)

  fit<- 
withReplicates(bootdesign,quote(coef(rq(Math1~Female+Age+calculator+computer+desk+ 
+ 
dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2,tau=0.5,weights=.weights, 
method="fn"))))




I want get the pseudo R squared but I failed. I read a query dating from 
August 2006, [R] Pseudo R for Quant Reg and the answer to it:


rho <- function(u,tau=.5)u*(tau - (u < 0))
  V <- sum(rho(f$resid, f$tau))


  I copied it and paste it , replacing f by fit I get this error message:
Error in fit$resid : $ operator is invalid for atomic vectors, I don't 
know what it means

The fit object is likely to be quite complicated  I used str() to see 
what it looks like:



str (fit)
Class 'svrepstat'  atomic [1:19] 713.24 -24.01 -18.37 9.05 7.71 ...
   ..- attr(*, "var")= num [1:19, 1:19] 2839.3 10.2 -122.1 -332.4 -42.3 
...
   .. ..- attr(*, "dimnames")=List of 2
   .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age" "calculator" ...
   .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age" "calculator" ...
   .. ..- attr(*, "means")= Named num [1:19] 710.97 -24.03 -18.3 9.39 
7.58 ...
   .. .. ..- attr(*, "names")= chr [1:19] "(Intercept)" "Female" "Age" 
"calculator" ...
   ..- attr(*, "statistic")= chr "theta"

How can I retrieve the residuals?? and calculate the pseudo R squared??


Any help please


-- 
Dr. Donia Smaali Bouhlila
Associate-Professor
Department of Economics
Facult? des Sciences Economiques et de Gestion de Tunis

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From pasupathym at gmail.com  Thu Sep 18 11:36:13 2014
From: pasupathym at gmail.com (Pasu)
Date: Thu, 18 Sep 2014 15:06:13 +0530
Subject: [R] Using R in our commercial business application
Message-ID: <CA+L24aOB8AH=+QVO0Fro9HMXzSu7c9d0P86mUNggJOpqzLHjnA@mail.gmail.com>

Hi

I would like to know how to use R in our commercial business application
which we plan to host in cloud or deploy on customer's premise.

1. Using R and its package, does it enforce that my commercial business
application should be distributed under GPL, as the statistical derivation
(output) by using R will be presented to the end users as part of of our
commercial business application
2. Whom to contact to get commercial license if required for using R?

Rgds
Pasupathy

	[[alternative HTML version deleted]]


From davide.chicco at gmail.com  Thu Sep 18 16:28:42 2014
From: davide.chicco at gmail.com (davide.chicco at gmail.com)
Date: Thu, 18 Sep 2014 10:28:42 -0400
Subject: [R] =?utf-8?b?Ui9VYnVudHUsIOKAnHBhY2thZ2Ug4oCYc3RhdHPigJkgaW4g?=
	=?utf-8?b?b3B0aW9ucyjigJ1kZWZhdWx0UGFja2FnZXPigJwpIHdhcyBub3QgZm91?=
	=?utf-8?b?bmTigJ0=?=
In-Reply-To: <6cec176b-4601-4141-b079-94cce61ab5f8@email.android.com>
References: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
	<02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>
	<CAK7YrFWnu2fW314azzjLA3QdL_UdZ+_WbW80g2wJzKtDz3DegQ@mail.gmail.com>
	<9c4c518e-7678-4d91-bd7d-49b3dd811a46@email.android.com>
	<CAK7YrFUS8Z9X8xq0=DxZxh3+NMKRN5G1QcCc7WbxdGX04eaBFQ@mail.gmail.com>
	<6cec176b-4601-4141-b079-94cce61ab5f8@email.android.com>
Message-ID: <CAK7YrFWOf2emtXw=ZrxFgdW_cQ5Mmz3gGeLySvPU+rEDDn9VRQ@mail.gmail.com>

I tried with a different mirror, but nothing changed...

Any other idea?

Thanks anyway

-- Davide

2014-09-17 10:39 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
> Try a different mirror? Precise is getting kind of old... they may not be keeping all of the old files on that mirror.
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On September 17, 2014 5:51:08 AM PDT, "davide.chicco at gmail.com" <davide.chicco at gmail.com> wrote:
>>Yes, I've followed the instructions described here:
>>http://cran.r-project.org/bin/linux/ubuntu/README
>>
>>I've added
>>deb http://<my.favorite.cran.mirror>/bin/linux/ubuntu precise/
>>to the /etc/apt/sources.list file.
>>
>>Any idea?
>>
>>Thanks a lot!
>>
>>-- Davide
>>
>>2014-09-17 2:42 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>> Are you using the apt sources described on CRAN for Ubuntu? I don't
>>expect stock 12.04 would give you R3.1.1, yet I have not seen this
>>problem on machines using the CRAN apt repositories.
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>>                                       Live:   OO#.. Dead: OO#..
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>>
>>---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On September 16, 2014 6:40:31 PM PDT, "davide.chicco at gmail.com"
>><davide.chicco at gmail.com> wrote:
>>>>Sorry guys for the errors in my behavior. I apologize.
>>>>
>>>>I installed R by using commands:
>>>>apt-get install r-base
>>>>apt-get install r-base-dev
>>>>
>>>>Here's the output of sessioninfo();
>>>>
>>>>> sessionInfo()
>>>>R version 3.1.1 (2014-07-10)
>>>>Platform: i686-pc-linux-gnu (32-bit)
>>>>
>>>>locale:
>>>> [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
>>>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=it_IT.UTF-8
>>>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=it_IT.UTF-8
>>>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>>attached base packages:
>>>>[1] graphics  grDevices utils     datasets  methods   base
>>>>
>>>>loaded via a namespace (and not attached):
>>>>[1] tcltk_3.1.1 tools_3.1.1
>>>>
>>>>
>>>>Any idea? Thanks!
>>>>
>>>>-- Davide
>>>>
>>>>2014-09-16 17:15 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:
>>>>>
>>>>> On Sep 16, 2014, at 12:19 PM, davide.chicco at gmail.com wrote:
>>>>>
>>>>>> Hi guys
>>>>>> I'm having some troubles in installing the "topicmodels" package
>>in
>>>>my
>>>>>> R system on a Linux Ubuntu machine.
>>>>>> I also described the problem here: http://bit.ly/1m8Ah6Z
>>>>>
>>>>> (You were asked in the Posting Guide to not crosspost. And when you
>>>>post to Stack Overflow you should respond to requests for
>>clarification
>>>>which you have not done either. You will never get useful answers if
>>>>you don't respond to requests for clarification.)
>>>>>
>>>>>>
>>>>>> I have just installed R 3.1.1 on my Linux Ubuntu 12.04.5 LTS.
>>>>>
>>>>> More details are needed. How did you do this?
>>>>>
>>>>>
>>>>>> Then Iwanted to install the topicmodels package, and so I type
>>>>>> install.packages("topicmodels"), but the installation did not
>>work.
>>>>>
>>>>>> It seems that I do not have the "stats" package installed in my
>>>>>> default packages.
>>>>>
>>>>> That would be somewhat unusual, but possible. You were asked in the
>>>>Rhelp Posting Guide to provide the output of sessionInfo().
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> David.
>>>>>
>>>>>
>>>>> ]
>>>>>> Here's the log:
>>>>>>
>>>>>> ++++++LOG+START++++++++++++++++++++
>>>>>>
>>>>>>> install.packages("topicmodels");
>>>>>> Installing package into ?/usr/local/lib/R/site-library?
>>>>>> (as ?lib? is unspecified)
>>>>>> --- Please select a CRAN mirror for use in this session ---
>>>>>> also installing the dependencies ?modeltools?, ?slam?, ?tm?
>>>>>>
>>>>>> provo con l'URL
>>>>>>
>>>>'http://cran.utstat.utoronto.ca/src/contrib/modeltools_0.2-21.tar.gz'
>>>>>> Content type 'application/x-gzip' length 14794 bytes (14 Kb)
>>>>>> URL aperto
>>>>>> ==================================================
>>>>>> downloaded 14 Kb
>>>>>>
>>>>>> provo con l'URL
>>>>'http://cran.utstat.utoronto.ca/src/contrib/slam_0.1-32.tar.gz'
>>>>>> Content type 'application/x-gzip' length 46672 bytes (45 Kb)
>>>>>> URL aperto
>>>>>> ==================================================
>>>>>> downloaded 45 Kb
>>>>>>
>>>>>> provo con l'URL
>>>>'http://cran.utstat.utoronto.ca/src/contrib/tm_0.6.tar.gz'
>>>>>> Content type 'application/x-gzip' length 505212 bytes (493 Kb)
>>>>>> URL aperto
>>>>>> ==================================================
>>>>>> downloaded 493 Kb
>>>>>>
>>>>>> provo con l'URL
>>>>>>
>>>>'http://cran.utstat.utoronto.ca/src/contrib/topicmodels_0.2-1.tar.gz'
>>>>>> Content type 'application/x-gzip' length 847889 bytes (828 Kb)
>>>>>> URL aperto
>>>>>> ==================================================
>>>>>> downloaded 828 Kb
>>>>>>
>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>> unable to load shared object
>>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>> Durante l'avvio - Warning message:
>>>>>> package ?stats? in options("defaultPackages") was not found
>>>>>> * installing *source* package ?modeltools? ...
>>>>>> ** package ?modeltools? successfully unpacked and MD5 sums checked
>>>>>> ** R
>>>>>> ** inst
>>>>>> ** preparing package for lazy loading
>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>> unable to load shared object
>>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>> Error : package ?stats? could not be loaded
>>>>>> ERROR: lazy loading failed for package ?modeltools?
>>>>>> * removing ?/usr/local/lib/R/site-library/modeltools?
>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>> unable to load shared object
>>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>> Durante l'avvio - Warning message:
>>>>>> package ?stats? in options("defaultPackages") was not found
>>>>>> * installing *source* package ?slam? ...
>>>>>> ** package ?slam? successfully unpacked and MD5 sums checked
>>>>>> ** libs
>>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>>-Wformat-security
>>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c apply.c -o
>>>>apply.o
>>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>>-Wformat-security
>>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c grouped.c -o
>>>>>> grouped.o
>>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>>-Wformat-security
>>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c sparse.c -o
>>>>>> sparse.o
>>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2
>>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>>-Wformat-security
>>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c util.c -o
>>util.o
>>>>>> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o
>>>>>> slam.so apply.o grouped.o sparse.o util.o -lblas -lgfortran -lm
>>>>>> -lquadmath -L/usr/lib/R/lib -lR
>>>>>> installing to /usr/local/lib/R/site-library/slam/libs
>>>>>> ** R
>>>>>> ** preparing package for lazy loading
>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>> unable to load shared object
>>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>> ERROR: lazy loading failed for package ?slam?
>>>>>> * removing ?/usr/local/lib/R/site-library/slam?
>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>> unable to load shared object
>>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>> Durante l'avvio - Warning message:
>>>>>> package ?stats? in options("defaultPackages") was not found
>>>>>> ERROR: dependency ?slam? is not available for package ?tm?
>>>>>> * removing ?/usr/local/lib/R/site-library/tm?
>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>> unable to load shared object
>>>>'/usr/lib/R/library/stats/libs/stats.so':
>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>> Durante l'avvio - Warning message:
>>>>>> package ?stats? in options("defaultPackages") was not found
>>>>>> ERROR: dependencies ?modeltools?, ?slam?, ?tm? are not available
>>for
>>>>>> package ?topicmodels?
>>>>>> * removing ?/usr/local/lib/R/site-library/topicmodels?
>>>>>>
>>>>>> The downloaded source packages are in
>>>>>>   ?/tmp/RtmpIppG4O/downloaded_packages?
>>>>>> Warning messages:
>>>>>> 1: In install.packages("topicmodels") :
>>>>>> installation of package ?modeltools? had non-zero exit status
>>>>>> 2: In install.packages("topicmodels") :
>>>>>> installation of package ?slam? had non-zero exit status
>>>>>> 3: In install.packages("topicmodels") :
>>>>>> installation of package ?tm? had non-zero exit status
>>>>>> 4: In install.packages("topicmodels") :
>>>>>> installation of package ?topicmodels? had non-zero exit status
>>>>>>
>>>>>> ++++++LOG+END++++++++++++++++++++
>>>>>>
>>>>>> Here's the output of the dpkg -l | grep "blas\|atlas" command:
>>>>>>
>>>>>> ii  libatlas3gf-base   3.8.4-3build1  Automatically Tuned Linear
>>>>>> Algebra Software, generic shared
>>>>>> ii  libblas-dev        1.2.20110419-2ubuntu1  Basic Linear Algebra
>>>>>> Subroutines 3, static library
>>>>>> ii  libblas3gf         1.2.20110419-2ubuntu1  Basic Linear Algebra
>>>>>> Reference implementations, shared library
>>>>>> ii  libopenblas-base   0.1alpha2.2-3  Optimized BLAS (linear
>>>>algebra)
>>>>>> library based on GotoBLAS2
>>>>>> ii  libopenblas-dev    0.1alpha2.2-3  Optimized BLAS (linear
>>>>algebra)
>>>>>> library based on GotoBLAS2
>>>>>>
>>>>>> Do you have any idea on how to solve this problem?
>>>>>>
>>>>>> Thanks a lot!
>>>>>>
>>>>>> -- Davide
>>>>>>
>>>>>>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>



-- 


::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
  Davide Chicco
Postdoctoral Fellow
Michael M. Hoffman Lab
Princess Margaret Cancer Centre, University of Toronto
Toronto Medical Discovery Tower 11-401
101 College St, Toronto, Ontario M5G 1L7, Canada
mail: davide.chicco at gmail.com
web: http://www.DavideChicco.it
::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::


From Doreen.Mueller at dza.de  Thu Sep 18 16:13:55 2014
From: Doreen.Mueller at dza.de (Doreen Mueller)
Date: Thu, 18 Sep 2014 16:13:55 +0200
Subject: [R] "missings=function(x) x[x==998|x==999]<-NA" doesn't work...
Message-ID: <OF98327B2F.1EEA0707-ONC1257D57.004CE36C-C1257D57.004E2D19@dza.de>

Hi!

I want to have a function that assigns NAs to certain values of my 
variable "var" in the dataset "d". This doesn't work:

> missings=function(x) x[x==998|x==999]<-NA
> missings(d$var)
> table(d$var, useNA="always")

    0      1  999 <NA> 
 220  752  321 5264 

I don't get any error messages, but "d$var" remains unchanged. The 
function:
> missings=function(x) x[x==90|x==99]<<-NA
doesn't work either, and I read that "<<-" is "dangerous" anyway?

It is important for me to work with variable names (and therefore with 
functions instead loops) because the number and order of variables in my 
dataset changes regularly.

Thank you,
Doreen
	[[alternative HTML version deleted]]


From f_j_rod at hotmail.com  Thu Sep 18 17:22:57 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Thu, 18 Sep 2014 17:22:57 +0200
Subject: [R] Data frame which includes a non-existent date
In-Reply-To: <BAY168-W5B1368619173B1DFC9FACBAB70@phx.gbl>
References: <BAY168-W5B1368619173B1DFC9FACBAB70@phx.gbl>
Message-ID: <BAY168-W1080FDD6524D10D75DD47DEBAB70@phx.gbl>



Hi to all members of the list,
 
I have a data frame with subjects who can get into a certain study from 2010-01-01 onwards. Small example:
 
DF <- data.frame(id=as.factor(1:3), born=as.Date(c("1939/10/28", "1946/02/23", "1948/02/29")))

  id       born
1  1 1939-10-28
2  2 1946-02-23
3  3 1948-02-29
 
Now, I add a new column "enter" as follows:
 
1) If the subject is 65 years old before 2010-01-01, then enter=2010-01-01.
2) If the subject i NOT 65 years old before 2010-01-01, then enter="Date on which subject reach 65"
 
DF_new <- data.frame(DF, 
 enter= as.Date( ifelse(unclass(round(difftime(open, DF$born)/365.25,1))<=65,
paste(year(DF$born)+65,substr(DF$born,6,10),sep="-"), paste(open))) )
 
The problem is that the DF_new output has a NA in subject id=3:
 
  id       born      enter
1  1 1939-10-28 2010-01-01
2  2 1946-02-23 2011-02-23
3  3 1948-02-29       <NA>
 
I'm afraid (I'm not really sure) that the matter is that subject id=3 would reach 65 yr at 2013-02-29, but this date does not exist,
so R gives a missing.
 
Can any help me?
 
Thank you!!!
 
 
 
 
 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Sep 18 20:08:16 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 18 Sep 2014 14:08:16 -0400
Subject: [R] "missings=function(x) x[x==998|x==999]<-NA" doesn't work...
In-Reply-To: <OF98327B2F.1EEA0707-ONC1257D57.004CE36C-C1257D57.004E2D19@dza.de>
References: <OF98327B2F.1EEA0707-ONC1257D57.004CE36C-C1257D57.004E2D19@dza.de>
Message-ID: <CAM_vjukYogPFDzxyGtqp5U9Yic_oNX0aMWtc8hJkzzDRk-KFNg@mail.gmail.com>

You need to assign the output of missings() to something. For that
matter, missings() needs some output.

d <- data.frame(a=1:5, b=6:10, var=c(1, 1, 998, 999, 2))

missings <- function(x) {
    x[x==998|x==999]<-NA
    x
}

d$var <- missings(d$var)


> d
  a  b var
1 1  6   1
2 2  7   1
3 3  8  NA
4 4  9  NA
5 5 10   2


Sarah

On Thu, Sep 18, 2014 at 10:13 AM, Doreen Mueller <Doreen.Mueller at dza.de> wrote:
> Hi!
>
> I want to have a function that assigns NAs to certain values of my
> variable "var" in the dataset "d". This doesn't work:
>
>> missings=function(x) x[x==998|x==999]<-NA
>> missings(d$var)
>> table(d$var, useNA="always")
>
>     0      1  999 <NA>
>  220  752  321 5264
>
> I don't get any error messages, but "d$var" remains unchanged. The
> function:
>> missings=function(x) x[x==90|x==99]<<-NA
> doesn't work either, and I read that "<<-" is "dangerous" anyway?
>
> It is important for me to work with variable names (and therefore with
> functions instead loops) because the number and order of variables in my
> dataset changes regularly.
>
> Thank you,
> Doreen



-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Thu Sep 18 20:35:00 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 18 Sep 2014 13:35:00 -0500
Subject: [R] Using R in our commercial business application
In-Reply-To: <CA+L24aOB8AH=+QVO0Fro9HMXzSu7c9d0P86mUNggJOpqzLHjnA@mail.gmail.com>
References: <CA+L24aOB8AH=+QVO0Fro9HMXzSu7c9d0P86mUNggJOpqzLHjnA@mail.gmail.com>
Message-ID: <9314C2B0-2E30-4859-B951-1B8C2B815BD9@me.com>

On Sep 18, 2014, at 4:36 AM, Pasu <pasupathym at gmail.com> wrote:

> Hi
> 
> I would like to know how to use R in our commercial business application
> which we plan to host in cloud or deploy on customer's premise.
> 
> 1. Using R and its package, does it enforce that my commercial business
> application should be distributed under GPL, as the statistical derivation
> (output) by using R will be presented to the end users as part of of our
> commercial business application
> 2. Whom to contact to get commercial license if required for using R?
> 
> Rgds
> Pasupathy


You will not get a definitive legal opinion here and my comments below do not represent any formal opinion on the part of any organization.

There is nothing preventing you or your company from using R as an end user. There are many of us who use R in commercial settings and in general, the output of a GPL'd application (text or binary) is not considered to be also GPL'd.

The subtleties get into the distribution of R (which you seem to plan to do), the nature of any additional functionality/code that you or your company may write/distribute, how that code interacts with R and/or modifies R source code copyrighted by the R Foundation and others. If you distribute R to clients, you will need to make R's source code available to them in some manner along with any modifications to that same code, while preserving appropriate copyrights.

A proprietary (closed source) application cannot be licensed under the GPL, but your company's application/code may be forced to be GPL (the so called viral aspect of the GPL) depending upon how your application is implemented as I noted in the prior paragraph. Thus, you may be forced to make your source code available to your clients as well.

If you plan to move forward, you should consult with an attorney well educated in software licensing and distribution issues, especially as they pertain to the GPL. The risks are not inconsequential of falling on the wrong side of the GPL.

The official R distribution is not available via a commercial or developer license, but there are commercial vendors of R and a Google search will point you in their direction, if desired. However, since their products are founded upon the official R distribution and the GPL, they will have similar issues with respect to any enhancements that they have created and therefore, your concerns do not necessarily go away. They will have also consulted legal counsel on these issues because the viability of their business depends upon it.

Regards,

Marc Schwartz


From rmh at temple.edu  Thu Sep 18 20:53:13 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 18 Sep 2014 14:53:13 -0400
Subject: [R] Data frame which includes a non-existent date
In-Reply-To: <BAY168-W1080FDD6524D10D75DD47DEBAB70@phx.gbl>
References: <BAY168-W5B1368619173B1DFC9FACBAB70@phx.gbl>
	<BAY168-W1080FDD6524D10D75DD47DEBAB70@phx.gbl>
Message-ID: <CAGx1TMC3ggmiWX8pdqOn2iOjmAmO-9dv=eNz3LhtUt1obueC1Q@mail.gmail.com>

Frank,

Dates are extremely difficult.  I recommend you do not attempt to do
your own data computations with paste().
Use the lubridate package.
> install.packages(lubridate)
> library(lubridate)
Read the end section of
> vignette("lubridate")

>From that you will most likely be wanting one of these
>  ymd("19480229") %m+% years(65)
[1] "2013-02-28 UTC"

> daydiff <-  ymd("19480229") - floor_date(ymd("19480229"), "month")
> floor_date(ymd("19480229"), "month") + years(65) + daydiff
[1] "2013-03-01 UTC"
>

Rich

On Thu, Sep 18, 2014 at 11:22 AM, Frank S. <f_j_rod at hotmail.com> wrote:
>
>
> Hi to all members of the list,
>
> I have a data frame with subjects who can get into a certain study from 2010-01-01 onwards. Small example:
>
> DF <- data.frame(id=as.factor(1:3), born=as.Date(c("1939/10/28", "1946/02/23", "1948/02/29")))
>
>   id       born
> 1  1 1939-10-28
> 2  2 1946-02-23
> 3  3 1948-02-29
>
> Now, I add a new column "enter" as follows:
>
> 1) If the subject is 65 years old before 2010-01-01, then enter=2010-01-01.
> 2) If the subject i NOT 65 years old before 2010-01-01, then enter="Date on which subject reach 65"
>
> DF_new <- data.frame(DF,
>  enter= as.Date( ifelse(unclass(round(difftime(open, DF$born)/365.25,1))<=65,
> paste(year(DF$born)+65,substr(DF$born,6,10),sep="-"), paste(open))) )
>
> The problem is that the DF_new output has a NA in subject id=3:
>
>   id       born      enter
> 1  1 1939-10-28 2010-01-01
> 2  2 1946-02-23 2011-02-23
> 3  3 1948-02-29       <NA>
>
> I'm afraid (I'm not really sure) that the matter is that subject id=3 would reach 65 yr at 2013-02-29, but this date does not exist,
> so R gives a missing.
>
> Can any help me?
>
> Thank you!!!
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ben.bighair at gmail.com  Thu Sep 18 20:15:25 2014
From: ben.bighair at gmail.com (Ben Tupper)
Date: Thu, 18 Sep 2014 14:15:25 -0400
Subject: [R] "missings=function(x) x[x==998|x==999]<-NA" doesn't work...
In-Reply-To: <OF98327B2F.1EEA0707-ONC1257D57.004CE36C-C1257D57.004E2D19@dza.de>
References: <OF98327B2F.1EEA0707-ONC1257D57.004CE36C-C1257D57.004E2D19@dza.de>
Message-ID: <7E205694-295F-438F-A108-21F7D885EA85@gmail.com>

Hi,

On Sep 18, 2014, at 10:13 AM, Doreen Mueller <Doreen.Mueller at dza.de> wrote:

> Hi!
> 
> I want to have a function that assigns NAs to certain values of my 
> variable "var" in the dataset "d". This doesn't work:
> 
>> missings=function(x) x[x==998|x==999]<-NA
>> missings(d$var)
>> table(d$var, useNA="always")
> 
>    0      1  999 <NA> 
> 220  752  321 5264 
> 
> I don't get any error messages, but "d$var" remains unchanged. The 
> function:
>> missings=function(x) x[x==90|x==99]<<-NA
> doesn't work either, and I read that "<<-" is "dangerous" anyway?
> 

You are so close.  R returns the value of the last thing evaluated in your function.  In this case, the *copy* of your input argument was modified within the function, but you didn't return the value of the copy to the calling environment.  You need to explicitly return the modified value.

> missings <- function(x) { x[ (x==998) | (x==999) ] <- NA ; return(x) }
> missings(990:1010)
 [1]  990  991  992  993  994  995  996  997   NA   NA 1000 1001 1002 1003 1004 1005 1006 1007
[19] 1008 1009 1010

By the way, don't forget to switch your email client to use text instead of html when sending a message to the list.

Cheers,
Ben





> It is important for me to work with variable names (and therefore with 
> functions instead loops) because the number and order of variables in my 
> dataset changes regularly.
> 
> Thank you,
> Doreen
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Sep 18 22:42:18 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 18 Sep 2014 16:42:18 -0400
Subject: [R] Using R in our commercial business application
In-Reply-To: <9314C2B0-2E30-4859-B951-1B8C2B815BD9@me.com>
References: <CA+L24aOB8AH=+QVO0Fro9HMXzSu7c9d0P86mUNggJOpqzLHjnA@mail.gmail.com>
	<9314C2B0-2E30-4859-B951-1B8C2B815BD9@me.com>
Message-ID: <541B43AA.1060500@gmail.com>

On 18/09/2014 2:35 PM, Marc Schwartz wrote:
> On Sep 18, 2014, at 4:36 AM, Pasu <pasupathym at gmail.com> wrote:
>
> > Hi
> >
> > I would like to know how to use R in our commercial business application
> > which we plan to host in cloud or deploy on customer's premise.
> >
> > 1. Using R and its package, does it enforce that my commercial business
> > application should be distributed under GPL, as the statistical derivation
> > (output) by using R will be presented to the end users as part of of our
> > commercial business application
> > 2. Whom to contact to get commercial license if required for using R?
> >
> > Rgds
> > Pasupathy
>
>
> You will not get a definitive legal opinion here and my comments below do not represent any formal opinion on the part of any organization.
>
> There is nothing preventing you or your company from using R as an end user. There are many of us who use R in commercial settings and in general, the output of a GPL'd application (text or binary) is not considered to be also GPL'd.
>
> The subtleties get into the distribution of R (which you seem to plan to do), the nature of any additional functionality/code that you or your company may write/distribute, how that code interacts with R and/or modifies R source code copyrighted by the R Foundation and others. If you distribute R to clients, you will need to make R's source code available to them in some manner along with any modifications to that same code, while preserving appropriate copyrights.
>
> A proprietary (closed source) application cannot be licensed under the GPL, but your company's application/code may be forced to be GPL (the so called viral aspect of the GPL) depending upon how your application is implemented as I noted in the prior paragraph. Thus, you may be forced to make your source code available to your clients as well.
>
> If you plan to move forward, you should consult with an attorney well educated in software licensing and distribution issues, especially as they pertain to the GPL. The risks are not inconsequential of falling on the wrong side of the GPL.
>
> The official R distribution is not available via a commercial or developer license, but there are commercial vendors of R and a Google search will point you in their direction, if desired. However, since their products are founded upon the official R distribution and the GPL, they will have similar issues with respect to any enhancements that they have created and therefore, your concerns do not necessarily go away. They will have also consulted legal counsel on these issues because the viability of their business depends upon it.

I agree with all of that but for one thing:  not all distributions are 
built on the GPL'd original.  I believe Tibco is selling an independent 
implementation.

Duncan Murdoch


From marc_schwartz at me.com  Thu Sep 18 22:54:40 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 18 Sep 2014 15:54:40 -0500
Subject: [R] Using R in our commercial business application
In-Reply-To: <541B43AA.1060500@gmail.com>
References: <CA+L24aOB8AH=+QVO0Fro9HMXzSu7c9d0P86mUNggJOpqzLHjnA@mail.gmail.com>
	<9314C2B0-2E30-4859-B951-1B8C2B815BD9@me.com>
	<541B43AA.1060500@gmail.com>
Message-ID: <F5032B16-0021-451F-A2C9-EF704EDD0D2F@me.com>


On Sep 18, 2014, at 3:42 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 18/09/2014 2:35 PM, Marc Schwartz wrote:
>> On Sep 18, 2014, at 4:36 AM, Pasu <pasupathym at gmail.com> wrote:
>> 
>> > Hi
>> >
>> > I would like to know how to use R in our commercial business application
>> > which we plan to host in cloud or deploy on customer's premise.
>> >
>> > 1. Using R and its package, does it enforce that my commercial business
>> > application should be distributed under GPL, as the statistical derivation
>> > (output) by using R will be presented to the end users as part of of our
>> > commercial business application
>> > 2. Whom to contact to get commercial license if required for using R?
>> >
>> > Rgds
>> > Pasupathy
>> 
>> 
>> You will not get a definitive legal opinion here and my comments below do not represent any formal opinion on the part of any organization.
>> 
>> There is nothing preventing you or your company from using R as an end user. There are many of us who use R in commercial settings and in general, the output of a GPL'd application (text or binary) is not considered to be also GPL'd.
>> 
>> The subtleties get into the distribution of R (which you seem to plan to do), the nature of any additional functionality/code that you or your company may write/distribute, how that code interacts with R and/or modifies R source code copyrighted by the R Foundation and others. If you distribute R to clients, you will need to make R's source code available to them in some manner along with any modifications to that same code, while preserving appropriate copyrights.
>> 
>> A proprietary (closed source) application cannot be licensed under the GPL, but your company's application/code may be forced to be GPL (the so called viral aspect of the GPL) depending upon how your application is implemented as I noted in the prior paragraph. Thus, you may be forced to make your source code available to your clients as well.
>> 
>> If you plan to move forward, you should consult with an attorney well educated in software licensing and distribution issues, especially as they pertain to the GPL. The risks are not inconsequential of falling on the wrong side of the GPL.
>> 
>> The official R distribution is not available via a commercial or developer license, but there are commercial vendors of R and a Google search will point you in their direction, if desired. However, since their products are founded upon the official R distribution and the GPL, they will have similar issues with respect to any enhancements that they have created and therefore, your concerns do not necessarily go away. They will have also consulted legal counsel on these issues because the viability of their business depends upon it.
> 
> I agree with all of that but for one thing:  not all distributions are built on the GPL'd original.  I believe Tibco is selling an independent implementation.
> 
> Duncan Murdoch


Thanks Duncan, I stand corrected. 

A quick Google search supports the point that the Tibco "TERR" system is an independent, closed-source, "re-implementation" of R, not based upon GPL R.

Regards,

Marc


From lawrence.michael at gene.com  Fri Sep 19 01:01:55 2014
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 18 Sep 2014 16:01:55 -0700
Subject: [R] RGtk2 drawing area as cairo device - no points
In-Reply-To: <541937B9.7050804@legs.cnrs-gif.fr>
References: <541937B9.7050804@legs.cnrs-gif.fr>
Message-ID: <CAOQ5Nyfd9C2sYm=73a2X2GLPn9fW8ZS9Z=TBzy-Yk7=ws6YpKg@mail.gmail.com>

Just wanted to acknowledge this. It's a known issue, and one that has been
tricky to solve, because it's platform-specific, so it's probably some sort
of bug in the abstraction (GDK).

On Wed, Sep 17, 2014 at 12:26 AM, Fran?ois Rebaudo <
francois.rebaudo at legs.cnrs-gif.fr> wrote:

> Hi,
> The following code adapted from Michael post (https://stat.ethz.ch/
> pipermail/r-help/2012-March/306069.html) works just fine on Linux Debian,
> but not on Windows 7 (no points on plots 2 and 3). More surprisingly, if the
> first plot is a boxplot, it works on both OS... and if I do a pdf (using
> pdf()), I get my points... Thanks in advance for your
> help.
>
> library(RGtk2)
> library(cairoDevice)
> win = gtkWindow(show = FALSE)
> win$setDefaultSize(500, 500)
> da = gtkDrawingArea()
> asCairoDevice(da)
> win$add(da)
> win$showAll()
> layout(matrix(c(1,1,2,3),2,2,byrow=TRUE))
> par(mar=c(0,0,0,0))
> plot(1:10) #boxplot(1:10)
> plot(1:10)
> plot(1:10)
>
>  sessionInfo()
>>
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
> [3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
> [5] LC_TIME=French_France.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.0
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From amos.elberg at gmail.com  Fri Sep 19 01:04:57 2014
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Thu, 18 Sep 2014 19:04:57 -0400
Subject: [R] Failure with .Rprofile on Mac OS X
In-Reply-To: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>
References: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>
Message-ID: <1CEBC003-79A0-45B3-AED2-B0AE9FE4B804@gmail.com>

The only reason that *should* happen is if there's an .Rprofile in the directory you're in when you start R.

Where *exactly* is the .Rprofile file you want loaded, what directory are you starting from, and what does R say is the user's home directory? Did you make *any* changes to Rprofile.site, or Renviron?

What is the output from Sys.getenv() in gui and cli, and do they differ?


> On Sep 18, 2014, at 11:18 AM, Gang Chen <gangchen6 at gmail.com> wrote:
> 
> When R starts in GUI (e.g., /Applications/R.app/Contents/MacOS/R) on
> my Mac OS X 10.7.5, the startup configuration in .Rprofile works fine.
> However, when R starts on the terminal (e.g.,
> /Library/Frameworks/R.framework/Resources/bin/R), it does not work at
> all. What could be the reason for the failure?
> 
> Thanks,
> Gang
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From honkit at stanford.edu  Fri Sep 19 01:48:35 2014
From: honkit at stanford.edu (Stephen HK Wong)
Date: Thu, 18 Sep 2014 16:48:35 -0700 (PDT)
Subject: [R] read.table() 1Gb text dataframe
Message-ID: <1391727814.8319228.1411084115662.JavaMail.zimbra@stanford.edu>

Dear All,

I have a table of 4 columns and many millions rows separated by tab-delimited. I don't have enough memory to read.table in that 1 Gb file. And actually I have 12 text files like that. Is there a way that I can just randomly read.table() in 10% of rows ? I was able to do that using colbycol package, but it is not not available. Many thanks!!



Stephen HK Wong
Stanford, California 94305-5324


From hb at biostat.ucsf.edu  Fri Sep 19 03:33:15 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 18 Sep 2014 18:33:15 -0700
Subject: [R] read.table() 1Gb text dataframe
In-Reply-To: <1391727814.8319228.1411084115662.JavaMail.zimbra@stanford.edu>
References: <1391727814.8319228.1411084115662.JavaMail.zimbra@stanford.edu>
Message-ID: <CAFDcVCQ-ZV3Rf0zbje7AMafdDMbjJzGmAMPwNb7yxjBJ7xKMhg@mail.gmail.com>

As a start, make sure you specify the 'colClasses' argument.  BTW,
using that you can even go to the extreme and read one column at the
time, if it comes down to that.

To read a 10% subset of the rows, you can use R.filesets as:

library(R.filesets)
db <- TabularTextFile(pathname)
n <- nbrOfRows(db)
data <- readDataFrame(db, rows=seq(from=1, to=n, length.out=0.10*n))

It is also useful to specify 'colClasses' here. In addition to
specifying them ordered by column, as for read.table(), you also
specify them by column names (or regular expressions of the column
names), e.g.

data <- readDataFrame(db, colClasses=c("*"="NULL", "(x|y)"="integer",
outcome="numeric", "id"="character"), rows=seq(from=1, to=n,
length.out=0.10*n))

That 'colClasses' specifies that the default is drop all columns, read
columns 'x' and 'y' as integers, and so on.

BTW, if you know 'n' upfront you can skip the setup of TabularTextFile
and just do:

data <- readDataFrame(pathname, rows=seq(from=1, to=n, length.out=0.10*n))


Hope this helps

Henrik

On Thu, Sep 18, 2014 at 4:48 PM, Stephen HK Wong <honkit at stanford.edu> wrote:
> Dear All,
>
> I have a table of 4 columns and many millions rows separated by tab-delimited. I don't have enough memory to read.table in that 1 Gb file. And actually I have 12 text files like that. Is there a way that I can just randomly read.table() in 10% of rows ? I was able to do that using colbycol package, but it is not not available. Many thanks!!
>
>
>
> Stephen HK Wong
> Stanford, California 94305-5324
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Fri Sep 19 05:19:26 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 18 Sep 2014 23:19:26 -0400
Subject: [R] Pseudo R squared for quantile regression with replicates
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F98C8C@mb02.ads.tamu.edu>
References: <f32c2295f53ae7fe7e9e906382cefb71@pop.rnu.tn>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F98C8C@mb02.ads.tamu.edu>
Message-ID: <CAOwvMDyq0snx=13hAVjWZqwZST9CRZpoHUkMyeOUqAn1T6OSzQ@mail.gmail.com>

here is a reproducible example, mostly from ?withReplicates.  i think
something would have to be done using return.replicates=TRUE to manually
compute survey-adjusted residuals, but i'm not really sure what nor whether
the pseudo r^2 would be meaningful  :/


library(survey)
library(quantreg)

data(api)

## one-stage cluster sample
dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)

## convert to bootstrap
bclus1<-as.svrepdesign(dclus1,type="bootstrap", replicates=100)

## median regression
fit <- withReplicates(bclus1, quote(coef(rq(api00~api99, tau=0.5,
weights=.weights,method="fn"))))

# # # no longer from ?withReplicates # # #
# from https://stat.ethz.ch/pipermail/r-help/2006-August/110386.html
rho <- function(u,tau=.5)u*(tau - (u < 0))

V <- sum(rho(fit$resid, fit$tau)) # # breaks


On Thu, Sep 18, 2014 at 1:55 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> It is hard to say because we do not have enough information. R has
> approximately 6,000 packages and you have not told us which ones you are
> using. You have not told us much about your data and you have not told us
> where to find the query from August 2006. The basic problem is that your
> "fit" is not the same as the "f" in the query. Your fit object is not very
> complicated. If you look at the output from str(fit) you will see that fit
> is an "atomic" vector (note the wording in your error message) with a
> series of attributes that are probably documented in the help pages for the
> functions you are using. There is nothing called resid inside fit. It is
> likely that the post you are looking at refers to the output from rq(...)
> or perhaps predict(rq(...)), but not the output from withReplicates(...,
> quote(coef(rq(...)))) which is what fit is.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Donia Smaali Bouhlila
> Sent: Thursday, September 18, 2014 9:54 AM
> To: r-help at r-project.org
> Subject: [R] Pseudo R squared for quantile regression with replicates
>
> Hi,
>
>
> I am a new user of r software. I intend to do quantile regressions with
> complex survey data using replicate method. I have ran the following
> commands successfully:
>
>
>   mydesign
>
> <-svydesign(ids=~IDSCHOOL,strata=~IDSTRATE,data=TUN,nest=TRUE,weights=~TOTWGT)
> bootdesign <- as.svrepdesign(mydesign,type="auto",replicates=150)
>
>   fit<-
>
> withReplicates(bootdesign,quote(coef(rq(Math1~Female+Age+calculator+computer+desk+
> +
>
> dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2,tau=0.5,weights=.weights,
> method="fn"))))
>
>
>
>
> I want get the pseudo R squared but I failed. I read a query dating from
> August 2006, [R] Pseudo R for Quant Reg and the answer to it:
>
>
> rho <- function(u,tau=.5)u*(tau - (u < 0))
>   V <- sum(rho(f$resid, f$tau))
>
>
>   I copied it and paste it , replacing f by fit I get this error message:
> Error in fit$resid : $ operator is invalid for atomic vectors, I don't
> know what it means
>
> The fit object is likely to be quite complicated  I used str() to see
> what it looks like:
>
>
>
> str (fit)
> Class 'svrepstat'  atomic [1:19] 713.24 -24.01 -18.37 9.05 7.71 ...
>    ..- attr(*, "var")= num [1:19, 1:19] 2839.3 10.2 -122.1 -332.4 -42.3
> ...
>    .. ..- attr(*, "dimnames")=List of 2
>    .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age" "calculator" ...
>    .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age" "calculator" ...
>    .. ..- attr(*, "means")= Named num [1:19] 710.97 -24.03 -18.3 9.39
> 7.58 ...
>    .. .. ..- attr(*, "names")= chr [1:19] "(Intercept)" "Female" "Age"
> "calculator" ...
>    ..- attr(*, "statistic")= chr "theta"
>
> How can I retrieve the residuals?? and calculate the pseudo R squared??
>
>
> Any help please
>
>
> --
> Dr. Donia Smaali Bouhlila
> Associate-Professor
> Department of Economics
> Facult? des Sciences Economiques et de Gestion de Tunis
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From emishiapersious57 at yahoo.com  Fri Sep 19 05:40:20 2014
From: emishiapersious57 at yahoo.com (EMISHIA PERSIOUS)
Date: Thu, 18 Sep 2014 20:40:20 -0700
Subject: [R] read.table() 1Gb text dataframe
In-Reply-To: <CAFDcVCQ-ZV3Rf0zbje7AMafdDMbjJzGmAMPwNb7yxjBJ7xKMhg@mail.gmail.com>
References: <1391727814.8319228.1411084115662.JavaMail.zimbra@stanford.edu>
	<CAFDcVCQ-ZV3Rf0zbje7AMafdDMbjJzGmAMPwNb7yxjBJ7xKMhg@mail.gmail.com>
Message-ID: <1411098020.82081.YahooMailNeo@web163103.mail.bf1.yahoo.com>

r code for the packages cstmr ,gRain,gRc,gRim,gRbase using probability models,


On Friday, September 19, 2014 7:05 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
 


As a start, make sure you specify the 'colClasses' argument.  BTW,
using that you can even go to the extreme and read one column at the
time, if it comes down to that.

To read a 10% subset of the rows, you can use R.filesets as:

library(R.filesets)
db <- TabularTextFile(pathname)
n <- nbrOfRows(db)
data <- readDataFrame(db, rows=seq(from=1, to=n, length.out=0.10*n))

It is also useful to specify 'colClasses' here. In addition to
specifying them ordered by column, as for read.table(), you also
specify them by column names (or regular expressions of the column
names), e.g.

data <- readDataFrame(db, colClasses=c("*"="NULL", "(x|y)"="integer",
outcome="numeric", "id"="character"), rows=seq(from=1, to=n,
length.out=0.10*n))

That 'colClasses' specifies that the default is drop all columns, read
columns 'x' and 'y' as integers, and so on.

BTW, if you know 'n' upfront you can skip the setup of TabularTextFile
and just do:

data <- readDataFrame(pathname, rows=seq(from=1, to=n, length.out=0.10*n))


Hope this helps

Henrik

On Thu, Sep 18, 2014 at 4:48 PM, Stephen HK Wong <honkit at stanford.edu> wrote:
> Dear All,
>
> I have a table of 4 columns and many millions rows separated by tab-delimited. I don't have enough memory to read.table in that 1 Gb file. And actually I have 12 text files like that. Is there a way that I can just randomly read.table() in 10% of rows ? I was able to do that using colbycol package, but it is not not available. Many thanks!!
>
>
>
> Stephen HK Wong
> Stanford, California 94305-5324
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From marie-eve.st-onge at outlook.com  Fri Sep 19 06:26:32 2014
From: marie-eve.st-onge at outlook.com (Marie-Eve St-Onge)
Date: Fri, 19 Sep 2014 02:26:32 -0200
Subject: [R] How to plot a similar graph
Message-ID: <COL129-W3836F06DC592A1F0CF99E3F2B40@phx.gbl>

Dear all, I would like to draw something similar to the following picture, does anyone know a better strategy to start?
http://www.psrd.hawaii.edu/WebImg/Pyx-thermometer.gif
Eve 		 	   		  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Sep 19 06:57:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 19 Sep 2014 00:57:49 -0400
Subject: [R] Failure with .Rprofile on Mac OS X
In-Reply-To: <1CEBC003-79A0-45B3-AED2-B0AE9FE4B804@gmail.com>
References: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>
	<1CEBC003-79A0-45B3-AED2-B0AE9FE4B804@gmail.com>
Message-ID: <AB86BF82-1939-436B-9408-F5BED23135D3@comcast.net>


Dear Gang Chen;

The .Rprofile is loaded from the startup directory. Terminal.app will  
start up in /Applications/ while your R.app session appears to be  
starting in a different directory. (We don't know what your startup  
directories are.)  I'm using R.app in /Applications/ so my .Rprofile  
has the same effect regardless of whether I run from R.app or from a  
bash console.

See this portion of the Mac-FAQ:

http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#The-current-and-startup-working-directories

  See ?Startup for more specifics that are generic to all R versions:


On Sep 18, 2014, at 7:04 PM, Amos B. Elberg wrote:

> The only reason that *should* happen is if there's an .Rprofile in  
> the directory you're in when you start R.
>
> Where *exactly* is the .Rprofile file you want loaded, what  
> directory are you starting from, and what does R say is the user's  
> home directory? Did you make *any* changes to Rprofile.site, or  
> Renviron?
>
> What is the output from Sys.getenv() in gui and cli, and do they  
> differ?

They might differ even if the default directories are the same (as  
they are on my setup). I have a somewhat older version on this laptop  
but there are names of environment variables that are not present in  
both directions:

I ran AppEnv <- dput( Sys.getenv() ) on my R.app session and then ran  
the corresponding command on a Terminal console session:

These are the difference (on a R 2.15.2 setup):

 > AppEnv[ !names(AppEnv) %in% names(conEnv)]
R_GUI_APP_REVISION  R_GUI_APP_VERSION
             "6435"             "1.53"
 > names( conEnv[ !names(conEnv) %in% names(AppEnv)] ) # i.e. missing  
in the GUI installation

  [1] "COLUMNS"              "DYLD_LIBRARY_PATH"     
"GDK_USE_XFT"          "INFOPATH"
  [5] "LINES"                "MANPATH"               
"PERL5LIB"             "PWD"
  [9] "SHLVL"                "TERM"                  
"TERM_PROGRAM"         "TERM_PROGRAM_VERSION"
[13] "XDG_CACHE_HOME"       "XDG_CONFIG_DIRS"       
"XDG_CONFIG_HOME"      "XDG_DATA_DIRS"
[17] "XDG_DATA_HOME"

  If there are further points of discussion they should be thrashed  
out (with greater details about sessionInfo() and startup settings),  
over on the R-MAC-SIG mailing list.


>
>
>> On Sep 18, 2014, at 11:18 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>>
>> When R starts in GUI (e.g., /Applications/R.app/Contents/MacOS/R) on
>> my Mac OS X 10.7.5, the startup configuration in .Rprofile works  
>> fine.
>> However, when R starts on the terminal (e.g.,
>> /Library/Frameworks/R.framework/Resources/bin/R), it does not work at
>> all. What could be the reason for the failure?
>>
>> Thanks,
>> Gang

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Sep 19 07:02:12 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 19 Sep 2014 01:02:12 -0400
Subject: [R]
 =?windows-1252?q?R/Ubuntu=2C_=93package_=91stats=92_in_option?=
 =?windows-1252?q?s=28=94defaultPackages=93=29_was_not_found=94?=
In-Reply-To: <CAK7YrFWOf2emtXw=ZrxFgdW_cQ5Mmz3gGeLySvPU+rEDDn9VRQ@mail.gmail.com>
References: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
	<02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>
	<CAK7YrFWnu2fW314azzjLA3QdL_UdZ+_WbW80g2wJzKtDz3DegQ@mail.gmail.com>
	<9c4c518e-7678-4d91-bd7d-49b3dd811a46@email.android.com>
	<CAK7YrFUS8Z9X8xq0=DxZxh3+NMKRN5G1QcCc7WbxdGX04eaBFQ@mail.gmail.com>
	<6cec176b-4601-4141-b079-94cce61ab5f8@email.android.com>
	<CAK7YrFWOf2emtXw=ZrxFgdW_cQ5Mmz3gGeLySvPU+rEDDn9VRQ@mail.gmail.com>
Message-ID: <B5640251-7BC5-47E6-BEE0-A8633C913D85@comcast.net>


On Sep 18, 2014, at 10:28 AM, davide.chicco at gmail.com wrote:

> I tried with a different mirror, but nothing changed...
>
> Any other idea?

Post to the r-SIG--debian mailing list?
Search that list's Archives?

--  
David.
>
> Thanks anyway
>
> -- Davide
>
> 2014-09-17 10:39 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> Try a different mirror? Precise is getting kind of old... they may  
>> not be keeping all of the old files on that mirror.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go  
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.   
>> Live Go...
>>                                      Live:   OO#.. Dead: OO#..   
>> Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.   
>> rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 17, 2014 5:51:08 AM PDT, "davide.chicco at gmail.com" <davide.chicco at gmail.com 
>> > wrote:
>>> Yes, I've followed the instructions described here:
>>> http://cran.r-project.org/bin/linux/ubuntu/README
>>>
>>> I've added
>>> deb http://<my.favorite.cran.mirror>/bin/linux/ubuntu precise/
>>> to the /etc/apt/sources.list file.
>>>
>>> Any idea?
>>>
>>> Thanks a lot!
>>>
>>> -- Davide
>>>
>>> 2014-09-17 2:42 GMT-04:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>>> Are you using the apt sources described on CRAN for Ubuntu? I don't
>>> expect stock 12.04 would give you R3.1.1, yet I have not seen this
>>> problem on machines using the CRAN apt repositories.
>>>>
>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.   
>>>> Live
>>> Go...
>>>>                                      Live:   OO#.. Dead: OO#..
>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.   
>>>> with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>>
>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On September 16, 2014 6:40:31 PM PDT, "davide.chicco at gmail.com"
>>> <davide.chicco at gmail.com> wrote:
>>>>> Sorry guys for the errors in my behavior. I apologize.
>>>>>
>>>>> I installed R by using commands:
>>>>> apt-get install r-base
>>>>> apt-get install r-base-dev
>>>>>
>>>>> Here's the output of sessioninfo();
>>>>>
>>>>>> sessionInfo()
>>>>> R version 3.1.1 (2014-07-10)
>>>>> Platform: i686-pc-linux-gnu (32-bit)
>>>>>
>>>>> locale:
>>>>> [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
>>>>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=it_IT.UTF-8
>>>>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=it_IT.UTF-8
>>>>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>>
>>>>> attached base packages:
>>>>> [1] graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] tcltk_3.1.1 tools_3.1.1
>>>>>
>>>>>
>>>>> Any idea? Thanks!
>>>>>
>>>>> -- Davide
>>>>>
>>>>> 2014-09-16 17:15 GMT-04:00 David Winsemius  
>>>>> <dwinsemius at comcast.net>:
>>>>>>
>>>>>> On Sep 16, 2014, at 12:19 PM, davide.chicco at gmail.com wrote:
>>>>>>
>>>>>>> Hi guys
>>>>>>> I'm having some troubles in installing the "topicmodels" package
>>> in
>>>>> my
>>>>>>> R system on a Linux Ubuntu machine.
>>>>>>> I also described the problem here: http://bit.ly/1m8Ah6Z
>>>>>>
>>>>>> (You were asked in the Posting Guide to not crosspost. And when  
>>>>>> you
>>>>> post to Stack Overflow you should respond to requests for
>>> clarification
>>>>> which you have not done either. You will never get useful  
>>>>> answers if
>>>>> you don't respond to requests for clarification.)
>>>>>>
>>>>>>>
>>>>>>> I have just installed R 3.1.1 on my Linux Ubuntu 12.04.5 LTS.
>>>>>>
>>>>>> More details are needed. How did you do this?
>>>>>>
>>>>>>
>>>>>>> Then Iwanted to install the topicmodels package, and so I type
>>>>>>> install.packages("topicmodels"), but the installation did not
>>> work.
>>>>>>
>>>>>>> It seems that I do not have the "stats" package installed in my
>>>>>>> default packages.
>>>>>>
>>>>>> That would be somewhat unusual, but possible. You were asked in  
>>>>>> the
>>>>> Rhelp Posting Guide to provide the output of sessionInfo().
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> David.
>>>>>>
>>>>>>
>>>>>> ]
>>>>>>> Here's the log:
>>>>>>>
>>>>>>> ++++++LOG+START++++++++++++++++++++
>>>>>>>
>>>>>>>> install.packages("topicmodels");
>>>>>>> Installing package into ?/usr/local/lib/R/site-library?
>>>>>>> (as ?lib? is unspecified)
>>>>>>> --- Please select a CRAN mirror for use in this session ---
>>>>>>> also installing the dependencies ?modeltools?, ?slam?, ?tm?
>>>>>>>
>>>>>>> provo con l'URL
>>>>>>>
>>>>> 'http://cran.utstat.utoronto.ca/src/contrib/modeltools_0.2-21.tar.gz'
>>>>>>> Content type 'application/x-gzip' length 14794 bytes (14 Kb)
>>>>>>> URL aperto
>>>>>>> ==================================================
>>>>>>> downloaded 14 Kb
>>>>>>>
>>>>>>> provo con l'URL
>>>>> 'http://cran.utstat.utoronto.ca/src/contrib/slam_0.1-32.tar.gz'
>>>>>>> Content type 'application/x-gzip' length 46672 bytes (45 Kb)
>>>>>>> URL aperto
>>>>>>> ==================================================
>>>>>>> downloaded 45 Kb
>>>>>>>
>>>>>>> provo con l'URL
>>>>> 'http://cran.utstat.utoronto.ca/src/contrib/tm_0.6.tar.gz'
>>>>>>> Content type 'application/x-gzip' length 505212 bytes (493 Kb)
>>>>>>> URL aperto
>>>>>>> ==================================================
>>>>>>> downloaded 493 Kb
>>>>>>>
>>>>>>> provo con l'URL
>>>>>>>
>>>>> 'http://cran.utstat.utoronto.ca/src/contrib/topicmodels_0.2-1.tar.gz'
>>>>>>> Content type 'application/x-gzip' length 847889 bytes (828 Kb)
>>>>>>> URL aperto
>>>>>>> ==================================================
>>>>>>> downloaded 828 Kb
>>>>>>>
>>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>>> unable to load shared object
>>>>> '/usr/lib/R/library/stats/libs/stats.so':
>>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>>> Durante l'avvio - Warning message:
>>>>>>> package ?stats? in options("defaultPackages") was not found
>>>>>>> * installing *source* package ?modeltools? ...
>>>>>>> ** package ?modeltools? successfully unpacked and MD5 sums  
>>>>>>> checked
>>>>>>> ** R
>>>>>>> ** inst
>>>>>>> ** preparing package for lazy loading
>>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>>> unable to load shared object
>>>>> '/usr/lib/R/library/stats/libs/stats.so':
>>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>>> Error : package ?stats? could not be loaded
>>>>>>> ERROR: lazy loading failed for package ?modeltools?
>>>>>>> * removing ?/usr/local/lib/R/site-library/modeltools?
>>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>>> unable to load shared object
>>>>> '/usr/lib/R/library/stats/libs/stats.so':
>>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>>> Durante l'avvio - Warning message:
>>>>>>> package ?stats? in options("defaultPackages") was not found
>>>>>>> * installing *source* package ?slam? ...
>>>>>>> ** package ?slam? successfully unpacked and MD5 sums checked
>>>>>>> ** libs
>>>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g - 
>>>>>>> O2
>>>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>>> -Wformat-security
>>>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c apply.c -o
>>>>> apply.o
>>>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g - 
>>>>>>> O2
>>>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>>> -Wformat-security
>>>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c grouped.c -o
>>>>>>> grouped.o
>>>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g - 
>>>>>>> O2
>>>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>>> -Wformat-security
>>>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c sparse.c -o
>>>>>>> sparse.o
>>>>>>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g - 
>>>>>>> O2
>>>>>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>>>> -Wformat-security
>>>>>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c util.c -o
>>> util.o
>>>>>>> gcc -std=gnu99 -shared -Wl,-Bsymbolic-functions -Wl,-z,relro -o
>>>>>>> slam.so apply.o grouped.o sparse.o util.o -lblas -lgfortran -lm
>>>>>>> -lquadmath -L/usr/lib/R/lib -lR
>>>>>>> installing to /usr/local/lib/R/site-library/slam/libs
>>>>>>> ** R
>>>>>>> ** preparing package for lazy loading
>>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>>> unable to load shared object
>>>>> '/usr/lib/R/library/stats/libs/stats.so':
>>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>>> ERROR: lazy loading failed for package ?slam?
>>>>>>> * removing ?/usr/local/lib/R/site-library/slam?
>>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>>> unable to load shared object
>>>>> '/usr/lib/R/library/stats/libs/stats.so':
>>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>>> Durante l'avvio - Warning message:
>>>>>>> package ?stats? in options("defaultPackages") was not found
>>>>>>> ERROR: dependency ?slam? is not available for package ?tm?
>>>>>>> * removing ?/usr/local/lib/R/site-library/tm?
>>>>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>>>>> unable to load shared object
>>>>> '/usr/lib/R/library/stats/libs/stats.so':
>>>>>>> /usr/lib/liblapack.so.3gf: undefined symbol: ATL_chemv
>>>>>>> Durante l'avvio - Warning message:
>>>>>>> package ?stats? in options("defaultPackages") was not found
>>>>>>> ERROR: dependencies ?modeltools?, ?slam?, ?tm? are not available
>>> for
>>>>>>> package ?topicmodels?
>>>>>>> * removing ?/usr/local/lib/R/site-library/topicmodels?
>>>>>>>
>>>>>>> The downloaded source packages are in
>>>>>>>  ?/tmp/RtmpIppG4O/downloaded_packages?
>>>>>>> Warning messages:
>>>>>>> 1: In install.packages("topicmodels") :
>>>>>>> installation of package ?modeltools? had non-zero exit status
>>>>>>> 2: In install.packages("topicmodels") :
>>>>>>> installation of package ?slam? had non-zero exit status
>>>>>>> 3: In install.packages("topicmodels") :
>>>>>>> installation of package ?tm? had non-zero exit status
>>>>>>> 4: In install.packages("topicmodels") :
>>>>>>> installation of package ?topicmodels? had non-zero exit status
>>>>>>>
>>>>>>> ++++++LOG+END++++++++++++++++++++
>>>>>>>
>>>>>>> Here's the output of the dpkg -l | grep "blas\|atlas" command:
>>>>>>>
>>>>>>> ii  libatlas3gf-base   3.8.4-3build1  Automatically Tuned Linear
>>>>>>> Algebra Software, generic shared
>>>>>>> ii  libblas-dev        1.2.20110419-2ubuntu1  Basic Linear  
>>>>>>> Algebra
>>>>>>> Subroutines 3, static library
>>>>>>> ii  libblas3gf         1.2.20110419-2ubuntu1  Basic Linear  
>>>>>>> Algebra
>>>>>>> Reference implementations, shared library
>>>>>>> ii  libopenblas-base   0.1alpha2.2-3  Optimized BLAS (linear
>>>>> algebra)
>>>>>>> library based on GotoBLAS2
>>>>>>> ii  libopenblas-dev    0.1alpha2.2-3  Optimized BLAS (linear
>>>>> algebra)
>>>>>>> library based on GotoBLAS2
>>>>>>>
>>>>>>> Do you have any idea on how to solve this problem?
>>>>>>>
>>>>>>> Thanks a lot!
>>>>>>>
>>>>>>> -- Davide
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible  
>>>>>>> code.
>>>>>>
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> -- 
>
>
> ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
>  Davide Chicco
> Postdoctoral Fellow
> Michael M. Hoffman Lab
> Princess Margaret Cancer Centre, University of Toronto
> Toronto Medical Discovery Tower 11-401
> 101 College St, Toronto, Ontario M5G 1L7, Canada
> mail: davide.chicco at gmail.com
> web: http://www.DavideChicco.it
> ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From evan.cooch at gmail.com  Fri Sep 19 06:55:04 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 19 Sep 2014 00:55:04 -0400
Subject: [R] optim, L-BFGS-B | constrained bounds on parms?
Message-ID: <541BB728.6030704@gmail.com>

Or, something to that effect. Following is an example of what I'm 
working with basic ABO blood type ML estimation from observed type 
(phenotypic) frequencies. First, I generate a log-likelihood function. 
mu[1] -> mu[2] are allele freqs for A and B alleles, respectively. Since 
freq of O allele is redundant, I use 1-mu[1]-mu[2] for that. The terms 
in the function are the probability expressions for the expected values 
of each phenotype.

But, that is somewhat besides the point:

f_abo <- function(mu) { 
25*log(mu[1]^2+2*mu[1]*(1-mu[1]-mu[2]))+25*log(mu[2]^2+2*mu[2]*(1-mu[1]-mu[2]))+50*log(2*mu[1]*mu[2])+15*log((1-mu[1]-mu[2])^2) 
}


So, I want to come up with MLE for mu[1] and mu[2] (for alleleic freqs 
for A and B alleles, respectively. Now, given the data, I know (from 
having maximized this likelihood outside of R) that the MLE for mu[1] is 
0.37176, and for mu[2], the same -- mu[2]=0.371763. I confirm this in 
MATLAB, and Maple, and Mathematica, using various non-linear 
solvers/optimization routines. They all yielded recisely the right answers.

But, stuck trying to come up with a general approach to getting the 
'right estimates' in R, that doesn't rely on strong prior knowledge of 
the parameters. I tried the following - I used L-BFGDS-B' because this 
is a 'boxed' optimzation: mu[1] and mu[2] are both parameters on the 
interval [0,1].

  results <- optim(c(0.3,0.3), f_abo,
      method = "L-BFGS-B", lower=c(0.1,0.1), upper=c(0.9,0.9),
       hessian = TRUE,control=list(fnscale=-1))

but that through the following error at me:

L-BFGS-B needs finite values of 'fn'

OK, fine. Taking that literally, and thinking a bit, clear that the 
problem is that the upper bound on the parms creates the problem. So, I 
try the crude approach of making the upper bound for each 0.5:


  results <- optim(c(0.3,0.3), f_abo,
      method = "L-BFGS-B", lower=c(0.1,0.1), upper=c(0.5,0.5),
       hessian = TRUE,control=list(fnscale=-1))


No errors this time, but no estimates either. At all.

OK -- so I 'cheat', and since I know that mu[1]=mu[2]=0.37176, I make 
another change to the upper limit, using 0.4 for both parms:



  results <- optim(c(0.3,0.3), f_abo,
      method = "L-BFGS-B", lower=c(0.1,0.1), upper=c(0.4,0.4),
       hessian = TRUE,control=list(fnscale=-1))


Works perfectly, and...right estimates too. ;-)

But, I could get there from here because I had prior knowledge of the 
parameter values. In other words, I cheated (not a thinly veiled 
suggestion that prior information is cheating, of course ;-)

What I'm trying to figure out is how to do a constrained optimization 
with R, where mu[1] and mu[2] are estimated subject to the constraint that

0 <= mu[1]+mu[2] <= 1

There seems to be no obvious way to impose that -- which creates a 
problem for optim since if I set 'vague' bounds on the parms (as per 
original attempt), optim tries combinations (like mu[1]=0.9, mu[2]=0.9), 
which aren't plausible, given the constraint that 0 <= mu[1]+mu[2] <= 1. 
Further, in this example, mu[1]=mu[2]. That might not be the case, and I 
might need to set upper bound on a parameter to be >0.5. But, without 
knowing which parameter, I'd need to set both from (say) 0.1 -> 0.9.

Is this possible with optim, or do I need to use a different package? If 
I can get there from here using optim, what do I need to do, either to 
my call to the optim routine, or the function that I pass to it?

This sort of thing is quite easy in (say) Maple. I simply execute

NLPSolve(f_abo,initialpoint={mu[1]=0.2,mu[2]=0.2},{mu[1]+mu[2]<=1},mu[1]=0.1..0.9,mu[2]=0.1..0.9,maximize);

where I'm telling the NLPSolve function that there is a constraint for 
mu[1] and mu[2] (as above), which lets me set bounds on the parameter 
over larger interval. Can I do the same in R?

Again, I'm trying to avoid having to use a 'good guess'. I know I can 
gene count to come up with a quick and dirty starting point (the basis 
for the EM algorithm commonly used for this), but again, I'm trying to 
avoid that.

Thanks very much in advance.

	[[alternative HTML version deleted]]


From amos.elberg at gmail.com  Fri Sep 19 07:18:52 2014
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Fri, 19 Sep 2014 01:18:52 -0400
Subject: [R] Failure with .Rprofile on Mac OS X
In-Reply-To: <AB86BF82-1939-436B-9408-F5BED23135D3@comcast.net>
References: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>
	<1CEBC003-79A0-45B3-AED2-B0AE9FE4B804@gmail.com>
	<AB86BF82-1939-436B-9408-F5BED23135D3@comcast.net>
Message-ID: <541BBCBC.5050007@gmail.com>

David - the startup directory for Terminal.app shouldn't affect where R
looks for .Rprofile.  If R is started from the command line, it should
look in whatever is the user's current directory (which will be ~/ if
Terminal was just launched), and then ~/  .  It shouldn't be looking in
/Applications/ unless you happen to have cd'd to /Applications before
launching R.

(You put up the environment variables present in one launch and absent
from another, but what I was really looking for is whether something in
his shell is changing a path.  Because mac environment variables are
funky that way.)
> David Winsemius <mailto:dwinsemius at comcast.net>
> September 19, 2014 at 12:57 AM
>
> Dear Gang Chen;
>
> The .Rprofile is loaded from the startup directory. Terminal.app will
> start up in /Applications/ while your R.app session appears to be
> starting in a different directory. (We don't know what your startup
> directories are.)  I'm using R.app in /Applications/ so my .Rprofile
> has the same effect regardless of whether I run from R.app or from a
> bash console.
>
> See this portion of the Mac-FAQ:
>
> http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#The-current-and-startup-working-directories
>
>
>  See ?Startup for more specifics that are generic to all R versions:
>
>
> On Sep 18, 2014, at 7:04 PM, Amos B. Elberg wrote:
>
>> The only reason that *should* happen is if there's an .Rprofile in
>> the directory you're in when you start R.
>>
>> Where *exactly* is the .Rprofile file you want loaded, what directory
>> are you starting from, and what does R say is the user's home
>> directory? Did you make *any* changes to Rprofile.site, or Renviron?
>>
>> What is the output from Sys.getenv() in gui and cli, and do they differ?
>
> They might differ even if the default directories are the same (as
> they are on my setup). I have a somewhat older version on this laptop
> but there are names of environment variables that are not present in
> both directions:
>
> I ran AppEnv <- dput( Sys.getenv() ) on my R.app session and then ran
> the corresponding command on a Terminal console session:
>
> These are the difference (on a R 2.15.2 setup):
>
> > AppEnv[ !names(AppEnv) %in% names(conEnv)]
> R_GUI_APP_REVISION  R_GUI_APP_VERSION
>             "6435"             "1.53"
> > names( conEnv[ !names(conEnv) %in% names(AppEnv)] ) # i.e. missing
> in the GUI installation
>
>  [1] "COLUMNS"              "DYLD_LIBRARY_PATH"   
> "GDK_USE_XFT"          "INFOPATH"
>  [5] "LINES"                "MANPATH"             
> "PERL5LIB"             "PWD"
>  [9] "SHLVL"                "TERM"                
> "TERM_PROGRAM"         "TERM_PROGRAM_VERSION"
> [13] "XDG_CACHE_HOME"       "XDG_CONFIG_DIRS"     
> "XDG_CONFIG_HOME"      "XDG_DATA_DIRS"
> [17] "XDG_DATA_HOME"
>
>  If there are further points of discussion they should be thrashed out
> (with greater details about sessionInfo() and startup settings), over
> on the R-MAC-SIG mailing list.
>
>
>>
>>
>>> On Sep 18, 2014, at 11:18 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>>>
>>> When R starts in GUI (e.g., /Applications/R.app/Contents/MacOS/R) on
>>> my Mac OS X 10.7.5, the startup configuration in .Rprofile works fine.
>>> However, when R starts on the terminal (e.g.,
>>> /Library/Frameworks/R.framework/Resources/bin/R), it does not work at
>>> all. What could be the reason for the failure?
>>>
>>> Thanks,
>>> Gang
>
> David Winsemius, MD
> Alameda, CA, USA
>
> Gang Chen <mailto:gangchen6 at gmail.com>
> September 18, 2014 at 11:18 AM
> When R starts in GUI (e.g., /Applications/R.app/Contents/MacOS/R) on
> my Mac OS X 10.7.5, the startup configuration in .Rprofile works fine.
> However, when R starts on the terminal (e.g.,
> /Library/Frameworks/R.framework/Resources/bin/R), it does not work at
> all. What could be the reason for the failure?
>
> Thanks,
> Gang
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From sma.ali at fsjegj.rnu.tn  Fri Sep 19 09:20:02 2014
From: sma.ali at fsjegj.rnu.tn (Donia Smaali Bouhlila)
Date: Fri, 19 Sep 2014 08:20:02 +0100
Subject: [R] Pseudo R squared for quantile regression with replicates
In-Reply-To: <CAOwvMDyq0snx=13hAVjWZqwZST9CRZpoHUkMyeOUqAn1T6OSzQ@mail.gmail.com>
References: <f32c2295f53ae7fe7e9e906382cefb71@pop.rnu.tn>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F98C8C@mb02.ads.tamu.edu>
	<CAOwvMDyq0snx=13hAVjWZqwZST9CRZpoHUkMyeOUqAn1T6OSzQ@mail.gmail.com>
Message-ID: <558c4d7d3cd5d677061dc50cede5d5c9@pop.rnu.tn>

Thank you for considering my email and replying.
Well, I am working with TIMSS 2007  survey data ( Trends in 
international mathematics and science study).

TIMSS is a stratified DATA, where the primary sampling unit is the 
school
I want to test the effect of some independent variables reflecting the 
socio-economic status of students on math achievement



I have 18 independent variables :Female+Age+calculator+computer+desk+
dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2


All my variables are binary variables except for age, and of course the 
dependent variable wich is the achievement score of the student (Math1 
in my regression)

I have a sample of 3169 observations (i.e students, 3169 achievement 
scores)

Data is missing at 23%.

The idea is to test the effect of these variables (known to reflect the 
socio-economic status of students) at the lower and upper quantiles 
taking into account the survey design features (sampling weight (which 
is in my case the studnt weight) clustering and stratification)

Why do I need th psudo-R squared? Because I want to calculate the 
increase in the pseudo r squared after introducing the school variales: 
I explain
I will do first regressions with the socio-economic variables (SES), and 
I calculate the pseudo R squared
In a second stage, I will introduce the school variables ( which are 
also binary variables), after controlling for socio-economic status, and 
calculate the pseudo R squared. The difference between the two pseudo R 
squared will tell me if SES variables account more or less  than school 
variables for students' achievement.


Why with replicates? To eliminate the intra-cluster correlations between 
schools.

I ran the following commands successfully:


mydesign
<-svydesign(ids=~IDSCHOOL,strata=~IDSTRATE,data=TUN,nest=TRUE,weights=~TOTWGT)

> bootdesign <- as.svrepdesign(mydesign,type="auto",replicates=150)

> ? 
> fit<-withReplicates(bootdesign,quote(coef(rq(Math1~Female+Age+calculator+computer+desk+
+dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2,tau=0.9,weights=.weights,
>> method="fn"))))



>> I want get the pseudo R squared but I failed. I read a query dating 
>> from
  August 2006, [R] Pseudo R for Quant Reg and the answer to it:

# from https://stat.ethz.ch/pipermail/r-help/2006-August/110386.html

>> rho <- function(u,tau=.5)u*(tau - (u < 0))
>> ? V <- sum(rho(f$resid, f$tau))


The structure of my fit object is the following:


>> str (fit)
>> Class 'svrepstat'? atomic [1:19] 713.24 -24.01 -18.37 9.05 7.71
>> ...
>> ? ?..- attr(*, "var")= num [1:19, 1:19] 2839.3 10.2 -122.1 -332.4
>> -42.3
>> ...
>> ? ?.. ..- attr(*, "dimnames")=List of 2
>> ? ?.. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age"
>> "calculator" ...
>> ? ?.. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age"
>> "calculator" ...
>> ? ?.. ..- attr(*, "means")= Named num [1:19] 710.97 -24.03 -18.3
>> 9.39
>> 7.58 ...
>> ? ?.. .. ..- attr(*, "names")= chr [1:19] "(Intercept)" "Female"
>> "Age"
>> "calculator" ...
>> ? ?..- attr(*, "statistic")= chr "theta"



Thank you in advance for replying and for your help







Le 2014-09-19 04:19, Anthony Damico a ?crit?:
> here is a reproducible example, mostly from ?withReplicates.? i think
> something would have to be done using return.replicates=TRUE to
> manually compute survey-adjusted residuals, but i'm not really sure
> what nor whether the pseudo r^2 would be meaningful? :/
> 
> library(survey)
> library(quantreg)
> 
> data(api)
> 
> ## one-stage cluster sample
> dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
> 
> ## convert to bootstrap
> bclus1<-as.svrepdesign(dclus1,type="bootstrap", replicates=100)
> ?
> ## median regression
> fit <- withReplicates(bclus1, quote(coef(rq(api00~api99, tau=0.5,
> weights=.weights,method="fn"))))
> 
> # # # no longer from ?withReplicates # # #
> # from https://stat.ethz.ch/pipermail/r-help/2006-August/110386.html
> [3]
> 
> rho <- function(u,tau=.5)u*(tau - (u < 0))
> 
> V <- sum(rho(fit$resid, fit$tau)) # # breaks
> 
> On Thu, Sep 18, 2014 at 1:55 PM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> 
>> It is hard to say because we do not have enough information. R has
>> approximately 6,000 packages and you have not told us which ones you
>> are using. You have not told us much about your data and you have
>> not told us where to find the query from August 2006. The basic
>> problem is that your "fit" is not the same as the "f" in the query.
>> Your fit object is not very complicated. If you look at the output
>> from str(fit) you will see that fit is an "atomic" vector (note the
>> wording in your error message) with a series of attributes that are
>> probably documented in the help pages for the functions you are
>> using. There is nothing called resid inside fit. It is likely that
>> the post you are looking at refers to the output from rq(...) or
>> perhaps predict(rq(...)), but not the output from
>> withReplicates(..., quote(coef(rq(...)))) which is what fit is.
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Donia Smaali
>> Bouhlila
>> Sent: Thursday, September 18, 2014 9:54 AM
>> To: r-help at r-project.org
>> Subject: [R] Pseudo R squared for quantile regression with
>> replicates
>> 
>> Hi,
>> 
>> I am a new user of r software. I intend to do quantile regressions
>> with
>> complex survey data using replicate method. I have ran the
>> following
>> commands successfully:
>> 
>> ? mydesign
>> 
> <-svydesign(ids=~IDSCHOOL,strata=~IDSTRATE,data=TUN,nest=TRUE,weights=~TOTWGT)
>> bootdesign <- as.svrepdesign(mydesign,type="auto",replicates=150)
>> 
>> ? fit<-
>> 
> withReplicates(bootdesign,quote(coef(rq(Math1~Female+Age+calculator+computer+desk+
>> +
>> 
> dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2,tau=0.5,weights=.weights,
>> method="fn"))))
>> 
>> I want get the pseudo R squared but I failed. I read a query dating
>> from
>> August 2006, [R] Pseudo R for Quant Reg and the answer to it:
>> 
>> rho <- function(u,tau=.5)u*(tau - (u < 0))
>> ? V <- sum(rho(f$resid, f$tau))
>> 
>> ? I copied it and paste it , replacing f by fit I get this error
>> message:
>> Error in fit$resid : $ operator is invalid for atomic vectors, I
>> don't
>> know what it means
>> 
>> The fit object is likely to be quite complicated? I used str() to
>> see
>> what it looks like:
>> 
>> str (fit)
>> Class 'svrepstat'? atomic [1:19] 713.24 -24.01 -18.37 9.05 7.71
>> ...
>> ? ?..- attr(*, "var")= num [1:19, 1:19] 2839.3 10.2 -122.1 -332.4
>> -42.3
>> ...
>> ? ?.. ..- attr(*, "dimnames")=List of 2
>> ? ?.. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age"
>> "calculator" ...
>> ? ?.. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age"
>> "calculator" ...
>> ? ?.. ..- attr(*, "means")= Named num [1:19] 710.97 -24.03 -18.3
>> 9.39
>> 7.58 ...
>> ? ?.. .. ..- attr(*, "names")= chr [1:19] "(Intercept)" "Female"
>> "Age"
>> "calculator" ...
>> ? ?..- attr(*, "statistic")= chr "theta"
>> 
>> How can I retrieve the residuals?? and calculate the pseudo R
>> squared??
>> 
>> Any help please
>> 
>> --
>> Dr. Donia Smaali Bouhlila
>> Associate-Professor
>> Department of Economics
>> Facult? des Sciences Economiques et de Gestion de Tunis
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help [1]
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html [2]
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help [1]
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html [2]
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> Links:
> ------
> [1] https://stat.ethz.ch/mailman/listinfo/r-help
> [2] http://www.R-project.org/posting-guide.html
> [3] https://stat.ethz.ch/pipermail/r-help/2006-August/110386.html

-- 
Dr. Donia Smaali Bouhlila
Associate-Professor
Department of Economics
Facult? des Sciences Economiques et de Gestion de Tunis


From francois.rebaudo at legs.cnrs-gif.fr  Fri Sep 19 09:32:17 2014
From: francois.rebaudo at legs.cnrs-gif.fr (=?UTF-8?B?RnJhbsOnb2lzIFJlYmF1ZG8=?=)
Date: Fri, 19 Sep 2014 09:32:17 +0200
Subject: [R] RGtk2 drawing area as cairo device - no points
In-Reply-To: <CAOQ5Nyfd9C2sYm=73a2X2GLPn9fW8ZS9Z=TBzy-Yk7=ws6YpKg@mail.gmail.com>
References: <541937B9.7050804@legs.cnrs-gif.fr>
	<CAOQ5Nyfd9C2sYm=73a2X2GLPn9fW8ZS9Z=TBzy-Yk7=ws6YpKg@mail.gmail.com>
Message-ID: <541BDC01.1080201@legs.cnrs-gif.fr>

Thanks !
Just in case it could be of any help, this is what I have done for MS 
Windows users :

library(RGtk2)
library(cairoDevice)
win = gtkWindow(show = FALSE)
win$setDefaultSize(500, 500)
hbox<-gtkHBoxNew(homogeneous=FALSE, spacing=0)
if (Sys.info()[1]=="Windows"){
     png(filename="temp.png", width = 500, height = 500)
         layout(matrix(c(1,1,2,3),2,2,byrow=TRUE))
         par(mar=c(4,4,1,1))
         plot(1:10) #boxplot(1:10)
         plot(1:10)
         plot(1:10)
     dev.off()
     myPLOT<-gtkImage(filename= paste(getwd(),"/temp.png",sep=""))
     hbox$add(myPLOT)
     win$add(hbox)
     win$showAll()
} else {
     da = gtkDrawingArea()
     asCairoDevice(da)
     hbox$packStart(da, expand = TRUE, fill = TRUE, padding = 0)
     win$add(hbox)
     win$showAll()
     layout(matrix(c(1,1,2,3),2,2,byrow=TRUE))
     par(mar=c(4,4,1,1))
     plot(1:10) #boxplot(1:10)
     plot(1:10)
     plot(1:10)
}

Le 19/09/2014 01:01, Michael Lawrence a ?crit :
> Just wanted to acknowledge this. It's a known issue, and one that has 
> been tricky to solve, because it's platform-specific, so it's probably 
> some sort of bug in the abstraction (GDK).
>
> On Wed, Sep 17, 2014 at 12:26 AM, FR wrote:
>
>     Hi,
>     The following code adapted from Michael post
>     (https://stat.ethz.ch/pipermail/r-help/2012-March/306069.html)
>     works just fine on Linux Debian, but not on Windows 7 (no points
>     on plots 2 and 3). More surprisingly, if the
>     first plot is a boxplot, it works on both OS... and if I do a pdf
>     (using pdf()), I get my points... Thanks in advance for your
>     help.
>
>     library(RGtk2)
>     library(cairoDevice)
>     win = gtkWindow(show = FALSE)
>     win$setDefaultSize(500, 500)
>     da = gtkDrawingArea()
>     asCairoDevice(da)
>     win$add(da)
>     win$showAll()
>     layout(matrix(c(1,1,2,3),2,2,byrow=TRUE))
>     par(mar=c(0,0,0,0))
>     plot(1:10) #boxplot(1:10)
>     plot(1:10)
>     plot(1:10)
>
>         sessionInfo()
>
>     R version 3.1.0 (2014-04-10)
>     Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>     locale:
>     [1] LC_COLLATE=French_France.1252 LC_CTYPE=French_France.1252
>     [3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
>     [5] LC_TIME=French_France.1252
>
>     attached base packages:
>     [1] stats     graphics  grDevices utils     datasets methods   base
>
>     loaded via a namespace (and not attached):
>     [1] tools_3.1.0
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From sma.ali at fsjegj.rnu.tn  Fri Sep 19 09:42:09 2014
From: sma.ali at fsjegj.rnu.tn (Donia Smaali Bouhlila)
Date: Fri, 19 Sep 2014 08:42:09 +0100
Subject: [R] Pseudo R squared  for quantile regression with replicates
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F98C8C@mb02.ads.tamu.edu>
References: <f32c2295f53ae7fe7e9e906382cefb71@pop.rnu.tn>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F98C8C@mb02.ads.tamu.edu>
Message-ID: <09b3c6163bb28eb94caa78d0bc8af4de@pop.rnu.tn>

Thank you for considering my email and replying.
Well, I am working with TIMSS 2007  survey data ( Trends in 
international mathematics and science study).

TIMSS is a stratified DATA, where the primary sampling unit is the 
school
I want to test the effect of some independent variables reflecting the 
socio-economic status of students on math achievement



I have 18 independent variables :Female+Age+calculator+computer+desk+
dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2


All my variables are binary variables except for age, and of course the 
dependent variable wich is the achievement score of the student (Math1 
in my regression)

I have a sample of 3169 observations (i.e students, 3169 achievement 
scores)

Data is missing at 23%.

The idea is to test the effect of these variables (known to reflect the 
socio-economic status of students) at the lower and upper quantiles 
taking into account the survey design features (sampling weight (which 
is in my case the studnt weight) clustering and stratification)

Why do I need th psudo-R squared? Because I want to calculate the 
increase in the pseudo r squared after introducing the school variales: 
I explain
I will do first regressions with the socio-economic variables (SES), and 
I calculate the pseudo R squared
In a second stage, I will introduce the school variables ( which are 
also binary variables), after controlling for socio-economic status, and 
calculate the pseudo R squared. The difference between the two pseudo R 
squared will tell me if SES variables account more or less  than school 
variables for students' achievement.


Why with replicates? To eliminate the intra-cluster correlations between 
schools.

I ran the following commands successfully:


mydesign
<-svydesign(ids=~IDSCHOOL,strata=~IDSTRATE,data=TUN,nest=TRUE,weights=~TOTWGT)

bootdesign <- as.svrepdesign(mydesign,type="auto",replicates=150)

   
fit<-withReplicates(bootdesign,quote(coef(rq(Math1~Female+Age+calculator+computer+desk+
+dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2,tau=0.9,weights=.weights,
method="fn"))))



I want get the pseudo R squared but I failed. I read a query dating from
  August 2006, [R] Pseudo R for Quant Reg and the answer to it:

# from https://stat.ethz.ch/pipermail/r-help/2006-August/110386.html

rho <- function(u,tau=.5)u*(tau - (u < 0))
   V <- sum(rho(f$resid, f$tau))


The structure of my fit object is the following:


str (fit)
Class 'svrepstat'  atomic [1:19] 713.24 -24.01 -18.37 9.05 7.71
...
    ..- attr(*, "var")= num [1:19, 1:19] 2839.3 10.2 -122.1 -332.4
-42.3
...
    .. ..- attr(*, "dimnames")=List of 2
    .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age"
"calculator" ...
    .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age"
"calculator" ...
    .. ..- attr(*, "means")= Named num [1:19] 710.97 -24.03 -18.3
9.39
7.58 ...
    .. .. ..- attr(*, "names")= chr [1:19] "(Intercept)" "Female"
"Age"
"calculator" ...
    ..- attr(*, "statistic")= chr "theta"



Thank you in advance for replying and for your help









Le 2014-09-18 18:55, David L Carlson a ?crit?:
> It is hard to say because we do not have enough information. R has
> approximately 6,000 packages and you have not told us which ones you
> are using. You have not told us much about your data and you have not
> told us where to find the query from August 2006. The basic problem is
> that your "fit" is not the same as the "f" in the query. Your fit
> object is not very complicated. If you look at the output from
> str(fit) you will see that fit is an "atomic" vector (note the wording
> in your error message) with a series of attributes that are probably
> documented in the help pages for the functions you are using. There is
> nothing called resid inside fit. It is likely that the post you are
> looking at refers to the output from rq(...) or perhaps
> predict(rq(...)), but not the output from withReplicates(...,
> quote(coef(rq(...)))) which is what fit is.
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Donia Smaali
> Bouhlila
> Sent: Thursday, September 18, 2014 9:54 AM
> To: r-help at r-project.org
> Subject: [R] Pseudo R squared for quantile regression with replicates
> 
> Hi,
> 
> 
> I am a new user of r software. I intend to do quantile regressions with
> complex survey data using replicate method. I have ran the following
> commands successfully:
> 
> 
>   mydesign
> <-svydesign(ids=~IDSCHOOL,strata=~IDSTRATE,data=TUN,nest=TRUE,weights=~TOTWGT)
> bootdesign <- as.svrepdesign(mydesign,type="auto",replicates=150)
> 
>   fit<-
> withReplicates(bootdesign,quote(coef(rq(Math1~Female+Age+calculator+computer+desk+
> +
> dictionary+internet+work+Book2+Book3+Book4+Book5+Pedu1+Pedu2+Pedu3+Pedu4+Born1+Born2,tau=0.5,weights=.weights,
> method="fn"))))
> 
> 
> 
> 
> I want get the pseudo R squared but I failed. I read a query dating 
> from
> August 2006, [R] Pseudo R for Quant Reg and the answer to it:
> 
> 
> rho <- function(u,tau=.5)u*(tau - (u < 0))
>   V <- sum(rho(f$resid, f$tau))
> 
> 
>   I copied it and paste it , replacing f by fit I get this error 
> message:
> Error in fit$resid : $ operator is invalid for atomic vectors, I don't
> know what it means
> 
> The fit object is likely to be quite complicated  I used str() to see
> what it looks like:
> 
> 
> 
> str (fit)
> Class 'svrepstat'  atomic [1:19] 713.24 -24.01 -18.37 9.05 7.71 ...
>    ..- attr(*, "var")= num [1:19, 1:19] 2839.3 10.2 -122.1 -332.4 -42.3
> ...
>    .. ..- attr(*, "dimnames")=List of 2
>    .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age" "calculator" ...
>    .. .. ..$ : chr [1:19] "(Intercept)" "Female" "Age" "calculator" ...
>    .. ..- attr(*, "means")= Named num [1:19] 710.97 -24.03 -18.3 9.39
> 7.58 ...
>    .. .. ..- attr(*, "names")= chr [1:19] "(Intercept)" "Female" "Age"
> "calculator" ...
>    ..- attr(*, "statistic")= chr "theta"
> 
> How can I retrieve the residuals?? and calculate the pseudo R squared??
> 
> 
> Any help please

-- 
Dr. Donia Smaali Bouhlila
Associate-Professor
Department of Economics
Facult? des Sciences Economiques et de Gestion de Tunis


From master at iaas.msu.ru  Fri Sep 19 09:39:11 2014
From: master at iaas.msu.ru (Michail Vidiassov)
Date: Fri, 19 Sep 2014 11:39:11 +0400
Subject: [R] beta package for 3D PDF output
In-Reply-To: <CALDha9NXuqzXtU3KDu2Wni2O9aC=PAnHmmqnp4t4bEU3REg7ig@mail.gmail.com>
References: <CALDha9PCwYQUEWV_wWiKq5q8BYAqfJgDpVG02v9v7cmt-dd79A@mail.gmail.com>
	<CALDha9NXuqzXtU3KDu2Wni2O9aC=PAnHmmqnp4t4bEU3REg7ig@mail.gmail.com>
Message-ID: <CALDha9Mm+5CVVSGKxFvXrrn7JYZRbPvfSq+v0Ptr0wMvxXgdWQ@mail.gmail.com>

Dear All,

my 3D PDF output package has got incompatible with recent rgl versions.
If someone needs a working version of rgl with 3D PDF export (sources
and Windows binaries) - send me a request.

  Sincerely, Michail


From pasupathym at gmail.com  Fri Sep 19 10:30:16 2014
From: pasupathym at gmail.com (Pasu)
Date: Fri, 19 Sep 2014 14:00:16 +0530
Subject: [R] Using R in our commercial business application
In-Reply-To: <541B43AA.1060500@gmail.com>
References: <CA+L24aOB8AH=+QVO0Fro9HMXzSu7c9d0P86mUNggJOpqzLHjnA@mail.gmail.com>
	<9314C2B0-2E30-4859-B951-1B8C2B815BD9@me.com>
	<541B43AA.1060500@gmail.com>
Message-ID: <CA+L24aMLJWTm1WG_7nO60vwptE7J79zhPZmrKu4ADq-kibK-yg@mail.gmail.com>

Hi

Thanks to all for the inputs. It will also be great to get inputs on the
procedure and the contact person for getting the commercial license on R

Rgds
Pasu
On 19-Sep-2014 2:13 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

> On 18/09/2014 2:35 PM, Marc Schwartz wrote:
>
>> On Sep 18, 2014, at 4:36 AM, Pasu <pasupathym at gmail.com> wrote:
>>
>> > Hi
>> >
>> > I would like to know how to use R in our commercial business application
>> > which we plan to host in cloud or deploy on customer's premise.
>> >
>> > 1. Using R and its package, does it enforce that my commercial business
>> > application should be distributed under GPL, as the statistical
>> derivation
>> > (output) by using R will be presented to the end users as part of of our
>> > commercial business application
>> > 2. Whom to contact to get commercial license if required for using R?
>> >
>> > Rgds
>> > Pasupathy
>>
>>
>> You will not get a definitive legal opinion here and my comments below do
>> not represent any formal opinion on the part of any organization.
>>
>> There is nothing preventing you or your company from using R as an end
>> user. There are many of us who use R in commercial settings and in general,
>> the output of a GPL'd application (text or binary) is not considered to be
>> also GPL'd.
>>
>> The subtleties get into the distribution of R (which you seem to plan to
>> do), the nature of any additional functionality/code that you or your
>> company may write/distribute, how that code interacts with R and/or
>> modifies R source code copyrighted by the R Foundation and others. If you
>> distribute R to clients, you will need to make R's source code available to
>> them in some manner along with any modifications to that same code, while
>> preserving appropriate copyrights.
>>
>> A proprietary (closed source) application cannot be licensed under the
>> GPL, but your company's application/code may be forced to be GPL (the so
>> called viral aspect of the GPL) depending upon how your application is
>> implemented as I noted in the prior paragraph. Thus, you may be forced to
>> make your source code available to your clients as well.
>>
>> If you plan to move forward, you should consult with an attorney well
>> educated in software licensing and distribution issues, especially as they
>> pertain to the GPL. The risks are not inconsequential of falling on the
>> wrong side of the GPL.
>>
>> The official R distribution is not available via a commercial or
>> developer license, but there are commercial vendors of R and a Google
>> search will point you in their direction, if desired. However, since their
>> products are founded upon the official R distribution and the GPL, they
>> will have similar issues with respect to any enhancements that they have
>> created and therefore, your concerns do not necessarily go away. They will
>> have also consulted legal counsel on these issues because the viability of
>> their business depends upon it.
>>
>
> I agree with all of that but for one thing:  not all distributions are
> built on the GPL'd original.  I believe Tibco is selling an independent
> implementation.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Sep 19 12:06:08 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 19 Sep 2014 12:06:08 +0200
Subject: [R] Using R in our commercial business application
In-Reply-To: <CA+L24aMLJWTm1WG_7nO60vwptE7J79zhPZmrKu4ADq-kibK-yg@mail.gmail.com>
References: <CA+L24aOB8AH=+QVO0Fro9HMXzSu7c9d0P86mUNggJOpqzLHjnA@mail.gmail.com>
	<9314C2B0-2E30-4859-B951-1B8C2B815BD9@me.com>
	<541B43AA.1060500@gmail.com>
	<CA+L24aMLJWTm1WG_7nO60vwptE7J79zhPZmrKu4ADq-kibK-yg@mail.gmail.com>
Message-ID: <4A2030A4-EA27-4E44-9DC8-C49AB12412C6@gmail.com>

There is no such person, because we don't do commercial licensing. This is pretty much impossible because the R developers do not own every piece of software that is used inside R. 

There are however companies that sell commercial support for R, and they will likely be able to help you about the dos and don'ts of using GPL'd software for commercial endeavours.

As others have indicated, it is not attractive to try and play amateur lawyer on the corner cases of the GPL. It hinges on the concepts of "derived work" contra "mere aggregation", and whether your plan involves distribution of the combined work. 

- Peter D. 

On 19 Sep 2014, at 10:30 , Pasu <pasupathym at gmail.com> wrote:

> Hi
> 
> Thanks to all for the inputs. It will also be great to get inputs on the
> procedure and the contact person for getting the commercial license on R
> 
> Rgds
> Pasu
> On 19-Sep-2014 2:13 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
> 
>> On 18/09/2014 2:35 PM, Marc Schwartz wrote:
>> 
>>> On Sep 18, 2014, at 4:36 AM, Pasu <pasupathym at gmail.com> wrote:
>>> 
>>>> Hi
>>>> 
>>>> I would like to know how to use R in our commercial business application
>>>> which we plan to host in cloud or deploy on customer's premise.
>>>> 
>>>> 1. Using R and its package, does it enforce that my commercial business
>>>> application should be distributed under GPL, as the statistical
>>> derivation
>>>> (output) by using R will be presented to the end users as part of of our
>>>> commercial business application
>>>> 2. Whom to contact to get commercial license if required for using R?
>>>> 
>>>> Rgds
>>>> Pasupathy
>>> 
>>> 
>>> You will not get a definitive legal opinion here and my comments below do
>>> not represent any formal opinion on the part of any organization.
>>> 
>>> There is nothing preventing you or your company from using R as an end
>>> user. There are many of us who use R in commercial settings and in general,
>>> the output of a GPL'd application (text or binary) is not considered to be
>>> also GPL'd.
>>> 
>>> The subtleties get into the distribution of R (which you seem to plan to
>>> do), the nature of any additional functionality/code that you or your
>>> company may write/distribute, how that code interacts with R and/or
>>> modifies R source code copyrighted by the R Foundation and others. If you
>>> distribute R to clients, you will need to make R's source code available to
>>> them in some manner along with any modifications to that same code, while
>>> preserving appropriate copyrights.
>>> 
>>> A proprietary (closed source) application cannot be licensed under the
>>> GPL, but your company's application/code may be forced to be GPL (the so
>>> called viral aspect of the GPL) depending upon how your application is
>>> implemented as I noted in the prior paragraph. Thus, you may be forced to
>>> make your source code available to your clients as well.
>>> 
>>> If you plan to move forward, you should consult with an attorney well
>>> educated in software licensing and distribution issues, especially as they
>>> pertain to the GPL. The risks are not inconsequential of falling on the
>>> wrong side of the GPL.
>>> 
>>> The official R distribution is not available via a commercial or
>>> developer license, but there are commercial vendors of R and a Google
>>> search will point you in their direction, if desired. However, since their
>>> products are founded upon the official R distribution and the GPL, they
>>> will have similar issues with respect to any enhancements that they have
>>> created and therefore, your concerns do not necessarily go away. They will
>>> have also consulted legal counsel on these issues because the viability of
>>> their business depends upon it.
>>> 
>> 
>> I agree with all of that but for one thing:  not all distributions are
>> built on the GPL'd original.  I believe Tibco is selling an independent
>> implementation.
>> 
>> Duncan Murdoch
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From angel.rodriguez at matiainstituto.net  Fri Sep 19 12:53:16 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Fri, 19 Sep 2014 12:53:16 +0200
Subject: [R] See the numeric codes of a factor
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>

Dear Subscribers,
 
I want to label a numeric variable 0="Bad" /1="Good". I understand the only way is to transform it into a factor variable. 
 
Is there a way to check that the numeric values of the new factor variable are 0 and 1 and not 1 and 2?
 
Thank you very much.
 
Angel Rodriguez-Laso

	[[alternative HTML version deleted]]


From Karline.Soetaert at nioz.nl  Fri Sep 19 13:01:56 2014
From: Karline.Soetaert at nioz.nl (Karline Soetaert)
Date: Fri, 19 Sep 2014 11:01:56 +0000
Subject: [R] Control color palette and legend in filled.contour
Message-ID: <4f4aeca3c8fd4d69976b56eedbccf6e5@livia.nioz.nl>

Thiago,

This will not be simple using filled.contour, as this changes the layout from the figure.
You might try the function image2D from plot3D:

require(plot3D)
par(mfrow = c(2, 1))
par(mar = c(0, 4, 4, 2))
plot(0, axes = FALSE, frame.plot = TRUE)   # upper plot
par(mar = c(4, 4, 0, 2))
Col <- ramp.col(c("blue", "red"))
image2D(z = volcano, col = Col, xlab = "", contour = TRUE,
  colkey = list(side = 1, length = 0.5))


Hope it helps,

Karline Soetaert

>Original Message: 1
>Date: Wed, 17 Sep 2014 01:53:05 -0700
>From: "Thiago V. dos Santos" <thi_veloso at yahoo.com.br>
>To: "r-help at r-project.org" <r-help at r-project.org>
>Subject: [R] Control color palette and legend in filled.contour
>Message-ID:
>	<1410943985.1852.YahooMailNeo at web121903.mail.ne1.yahoo.com>
>Content-Type: text/plain; charset="UTF-8"
>>Dear all,

>I am having some difficulties trying to control color palette and legend of a filled.countour plot. 
>
>Basically, I am plotting volumetric soil moisture which ranges from 0 to 1 (although the data excerpt I'm providing here ranges from 0 to 0.4, my complete dataset ranges from 0 to 1). Low values mean dry soil and higher values denote wet soil.
>
>Instead of the default color palette, I would like to set a 'red to blue' palette with legend ranging from 0 (red) to 1 (blue). My final goal is to achive a color palette and legend similar to this figure: https://imageshack.com/i/exmVz5QSp. 
>
>A sample of my data (as well as an attemptive plot) can be reproduced with this code:
>....
>>>>


From jim at bitwrit.com.au  Fri Sep 19 13:31:13 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 19 Sep 2014 21:31:13 +1000
Subject: [R] See the numeric codes of a factor
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
Message-ID: <5326327.tB2K0j7O9j@localhost.localdomain>

On Fri, 19 Sep 2014 12:53:16 PM Angel Rodriguez wrote:
> Dear Subscribers,
> 
> I want to label a numeric variable 0="Bad" /1="Good". I understand 
the only
> way is to transform it into a factor variable.
> 
> Is there a way to check that the numeric values of the new factor 
variable
> are 0 and 1 and not 1 and 2?
> 
> Thank you very much.
> 
> Angel Rodriguez-Laso
> 
Hi Angel,
As far as I know, the numeric values of factors always begin with 1. If your 
factor (badgood) is constructed from the values "Bad" and "Good":

as.numeric(badgood) - 1

will produce a vector of zeros and ones.

If you have a numeric vector of zeros and ones and want the 
corresponding vector of "Bad" and "Good":

ifelse(badgood,"Good","Bad")

Jim


From murdoch.duncan at gmail.com  Fri Sep 19 13:32:56 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Sep 2014 07:32:56 -0400
Subject: [R] See the numeric codes of a factor
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
Message-ID: <541C1468.4040308@gmail.com>

On 19/09/2014, 6:53 AM, Angel Rodriguez wrote:
> Dear Subscribers,
>  
> I want to label a numeric variable 0="Bad" /1="Good". I understand the only way is to transform it into a factor variable. 
>  
> Is there a way to check that the numeric values of the new factor variable are 0 and 1 and not 1 and 2?

If you apply as.numeric() to a factor, you won't get a zero value.
Internal factor values start at 1.

So I wouldn't rely on the internal storage to achieve whatever it is you
want to achieve.  Use explicit computation, e.g.

words <- ifelse(var == 0, "Bad", ifelse(var == 1, "Good", NA))
values <- ifelse(words == "Bad", 0, ifelse(words == "Good", 1, NA))

Duncan Murdoch


From angel.rodriguez at matiainstituto.net  Fri Sep 19 14:12:01 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Fri, 19 Sep 2014 14:12:01 +0200
Subject: [R] See the numeric codes of a factor
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
	<541C1468.4040308@gmail.com>
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B2AA@MATIAEXCH.matiaf.local>

Thank you, Duncan. So isn't it possible to add labels to a variable with numeric values 0/1? This kind of variable is very useful for logistic regression, for example, but I'd rather have its categories labelled.
 
Angel

________________________________

De: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
Enviado el: vie 19/09/2014 13:32
Para: Angel Rodriguez; r-help at r-project.org
Asunto: Re: [R] See the numeric codes of a factor



On 19/09/2014, 6:53 AM, Angel Rodriguez wrote:
> Dear Subscribers,
> 
> I want to label a numeric variable 0="Bad" /1="Good". I understand the only way is to transform it into a factor variable.
> 
> Is there a way to check that the numeric values of the new factor variable are 0 and 1 and not 1 and 2?

If you apply as.numeric() to a factor, you won't get a zero value.
Internal factor values start at 1.

So I wouldn't rely on the internal storage to achieve whatever it is you
want to achieve.  Use explicit computation, e.g.

words <- ifelse(var == 0, "Bad", ifelse(var == 1, "Good", NA))
values <- ifelse(words == "Bad", 0, ifelse(words == "Good", 1, NA))

Duncan Murdoch






	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Sep 19 14:22:44 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Sep 2014 08:22:44 -0400
Subject: [R] See the numeric codes of a factor
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B2AA@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
	<541C1468.4040308@gmail.com>
	<8564BCD7D26E0D40872F1A132C8BBB250258B2AA@MATIAEXCH.matiaf.local>
Message-ID: <541C2014.3000704@gmail.com>

On 19/09/2014 8:12 AM, Angel Rodriguez wrote:
> Re: [R] See the numeric codes of a factor
> Thank you, Duncan. So isn't it possible to add labels to a variable 
> with numeric values 0/1? This kind of variable is very useful for 
> logistic regression, for example, but I'd rather have its 
> categories labelled.

I think you are thinking of how you have done things in some other 
system.  In R, a factor is fine in logistic regression, regardless of 
the fact that internally values are stored as 1 and 2.

Duncan Murdoch

> Angel
>
> ------------------------------------------------------------------------
> *De:* Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> *Enviado el:* vie 19/09/2014 13:32
> *Para:* Angel Rodriguez; r-help at r-project.org
> *Asunto:* Re: [R] See the numeric codes of a factor
>
> On 19/09/2014, 6:53 AM, Angel Rodriguez wrote:
> > Dear Subscribers,
> >
> > I want to label a numeric variable 0="Bad" /1="Good". I understand 
> the only way is to transform it into a factor variable.
> >
> > Is there a way to check that the numeric values of the new factor 
> variable are 0 and 1 and not 1 and 2?
>
> If you apply as.numeric() to a factor, you won't get a zero value.
> Internal factor values start at 1.
>
> So I wouldn't rely on the internal storage to achieve whatever it is you
> want to achieve.  Use explicit computation, e.g.
>
> words <- ifelse(var == 0, "Bad", ifelse(var == 1, "Good", NA))
> values <- ifelse(words == "Bad", 0, ifelse(words == "Good", 1, NA))
>
> Duncan Murdoch
>
>
>


From angel.rodriguez at matiainstituto.net  Fri Sep 19 14:55:42 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Fri, 19 Sep 2014 14:55:42 +0200
Subject: [R] See the numeric codes of a factor
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
	<541C1468.4040308@gmail.com>
	<8564BCD7D26E0D40872F1A132C8BBB250258B2AA@MATIAEXCH.matiaf.local>
	<541C2014.3000704@gmail.com>
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B2AE@MATIAEXCH.matiaf.local>

Well, a variable with values 0/1 is useful for calculating observed probabilities by groups. But it is not diffcult to have the same variable both as numeric and as a factor in the dataframe and use each variation depending on the analysis.
 
Angel 

________________________________

De: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
Enviado el: vie 19/09/2014 14:22
Para: Angel Rodriguez; r-help at r-project.org
Asunto: Re: [R] See the numeric codes of a factor



On 19/09/2014 8:12 AM, Angel Rodriguez wrote:
> Re: [R] See the numeric codes of a factor
> Thank you, Duncan. So isn't it possible to add labels to a variable
> with numeric values 0/1? This kind of variable is very useful for
> logistic regression, for example, but I'd rather have its
> categories labelled.

I think you are thinking of how you have done things in some other
system.  In R, a factor is fine in logistic regression, regardless of
the fact that internally values are stored as 1 and 2.

Duncan Murdoch

> Angel
>
> ------------------------------------------------------------------------
> *De:* Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> *Enviado el:* vie 19/09/2014 13:32
> *Para:* Angel Rodriguez; r-help at r-project.org
> *Asunto:* Re: [R] See the numeric codes of a factor
>
> On 19/09/2014, 6:53 AM, Angel Rodriguez wrote:
> > Dear Subscribers,
> >
> > I want to label a numeric variable 0="Bad" /1="Good". I understand
> the only way is to transform it into a factor variable.
> >
> > Is there a way to check that the numeric values of the new factor
> variable are 0 and 1 and not 1 and 2?
>
> If you apply as.numeric() to a factor, you won't get a zero value.
> Internal factor values start at 1.
>
> So I wouldn't rely on the internal storage to achieve whatever it is you
> want to achieve.  Use explicit computation, e.g.
>
> words <- ifelse(var == 0, "Bad", ifelse(var == 1, "Good", NA))
> values <- ifelse(words == "Bad", 0, ifelse(words == "Good", 1, NA))
>
> Duncan Murdoch
>
>
>




	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Sep 19 15:49:45 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 19 Sep 2014 06:49:45 -0700
Subject: [R] See the numeric codes of a factor
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B2AE@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
	<541C1468.4040308@gmail.com>
	<8564BCD7D26E0D40872F1A132C8BBB250258B2AA@MATIAEXCH.matiaf.local>
	<541C2014.3000704@gmail.com>
	<8564BCD7D26E0D40872F1A132C8BBB250258B2AE@MATIAEXCH.matiaf.local>
Message-ID: <1444fd38-eee8-463f-b66d-b8752be4897d@email.android.com>

Sounds like a factor to me. You are just inappropriately focused on the underlying representation. Once you start using factors in regression you will get it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 19, 2014 5:55:42 AM PDT, Angel Rodriguez <angel.rodriguez at matiainstituto.net> wrote:
>Well, a variable with values 0/1 is useful for calculating observed
>probabilities by groups. But it is not diffcult to have the same
>variable both as numeric and as a factor in the dataframe and use each
>variation depending on the analysis.
> 
>Angel 
>
>________________________________
>
>De: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>Enviado el: vie 19/09/2014 14:22
>Para: Angel Rodriguez; r-help at r-project.org
>Asunto: Re: [R] See the numeric codes of a factor
>
>
>
>On 19/09/2014 8:12 AM, Angel Rodriguez wrote:
>> Re: [R] See the numeric codes of a factor
>> Thank you, Duncan. So isn't it possible to add labels to a variable
>> with numeric values 0/1? This kind of variable is very useful for
>> logistic regression, for example, but I'd rather have its
>> categories labelled.
>
>I think you are thinking of how you have done things in some other
>system.  In R, a factor is fine in logistic regression, regardless of
>the fact that internally values are stored as 1 and 2.
>
>Duncan Murdoch
>
>> Angel
>>
>>
>------------------------------------------------------------------------
>> *De:* Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> *Enviado el:* vie 19/09/2014 13:32
>> *Para:* Angel Rodriguez; r-help at r-project.org
>> *Asunto:* Re: [R] See the numeric codes of a factor
>>
>> On 19/09/2014, 6:53 AM, Angel Rodriguez wrote:
>> > Dear Subscribers,
>> >
>> > I want to label a numeric variable 0="Bad" /1="Good". I understand
>> the only way is to transform it into a factor variable.
>> >
>> > Is there a way to check that the numeric values of the new factor
>> variable are 0 and 1 and not 1 and 2?
>>
>> If you apply as.numeric() to a factor, you won't get a zero value.
>> Internal factor values start at 1.
>>
>> So I wouldn't rely on the internal storage to achieve whatever it is
>you
>> want to achieve.  Use explicit computation, e.g.
>>
>> words <- ifelse(var == 0, "Bad", ifelse(var == 1, "Good", NA))
>> values <- ifelse(words == "Bad", 0, ifelse(words == "Good", 1, NA))
>>
>> Duncan Murdoch
>>
>>
>>
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Fri Sep 19 16:12:04 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 19 Sep 2014 07:12:04 -0700
Subject: [R] See the numeric codes of a factor
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B2AE@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2A8@MATIAEXCH.matiaf.local>
	<541C1468.4040308@gmail.com>
	<8564BCD7D26E0D40872F1A132C8BBB250258B2AA@MATIAEXCH.matiaf.local>
	<541C2014.3000704@gmail.com>
	<8564BCD7D26E0D40872F1A132C8BBB250258B2AE@MATIAEXCH.matiaf.local>
Message-ID: <CACk-te3c6Mov+q+R-JLEsuwi55iJ7T3+oE+xtqmw6PKBM0gf5Q@mail.gmail.com>

Talk to a local statistician or study a book on regression. You do not
understand how regression works.

In R, see ?contrasts  .

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Sep 19, 2014 at 5:55 AM, Angel Rodriguez
<angel.rodriguez at matiainstituto.net> wrote:
> Well, a variable with values 0/1 is useful for calculating observed probabilities by groups. But it is not diffcult to have the same variable both as numeric and as a factor in the dataframe and use each variation depending on the analysis.
>
> Angel
>
> ________________________________
>
> De: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Enviado el: vie 19/09/2014 14:22
> Para: Angel Rodriguez; r-help at r-project.org
> Asunto: Re: [R] See the numeric codes of a factor
>
>
>
> On 19/09/2014 8:12 AM, Angel Rodriguez wrote:
>> Re: [R] See the numeric codes of a factor
>> Thank you, Duncan. So isn't it possible to add labels to a variable
>> with numeric values 0/1? This kind of variable is very useful for
>> logistic regression, for example, but I'd rather have its
>> categories labelled.
>
> I think you are thinking of how you have done things in some other
> system.  In R, a factor is fine in logistic regression, regardless of
> the fact that internally values are stored as 1 and 2.
>
> Duncan Murdoch
>
>> Angel
>>
>> ------------------------------------------------------------------------
>> *De:* Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> *Enviado el:* vie 19/09/2014 13:32
>> *Para:* Angel Rodriguez; r-help at r-project.org
>> *Asunto:* Re: [R] See the numeric codes of a factor
>>
>> On 19/09/2014, 6:53 AM, Angel Rodriguez wrote:
>> > Dear Subscribers,
>> >
>> > I want to label a numeric variable 0="Bad" /1="Good". I understand
>> the only way is to transform it into a factor variable.
>> >
>> > Is there a way to check that the numeric values of the new factor
>> variable are 0 and 1 and not 1 and 2?
>>
>> If you apply as.numeric() to a factor, you won't get a zero value.
>> Internal factor values start at 1.
>>
>> So I wouldn't rely on the internal storage to achieve whatever it is you
>> want to achieve.  Use explicit computation, e.g.
>>
>> words <- ifelse(var == 0, "Bad", ifelse(var == 1, "Good", NA))
>> values <- ifelse(words == "Bad", 0, ifelse(words == "Good", 1, NA))
>>
>> Duncan Murdoch
>>
>>
>>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Dylan.Tevlin at kochind.com  Fri Sep 19 16:49:36 2014
From: Dylan.Tevlin at kochind.com (Tevlin, Dylan)
Date: Fri, 19 Sep 2014 09:49:36 -0500
Subject: [R] package Parallel - accessing remote cores on Windows using
 plink (PuTTY)
Message-ID: <9D606AC27145D74F845B5AA9F37F9D9DEF60E76C0F@MSGICTB.kochind.com>

Hello all.

My system information:

R 2.14.1 x64
Windows 7

I'm attempting to access cores on other machines in my LAN.  As setup, I can ping all the machines successfully and it's a private office network where I have access to all computers, so there really shouldn't be any problems arising from the network itself.

All machines I am connecting to have identical system information.

I issue the following command to make a connection to the remote machine and access one of its cores.

cl<-makePSOCKcluster(c(remoteHostIP), rshcmd="plink", outfile="")

The parallel package, to make remote connections, issues a system command (found in the file snowSOCK.R, function newPSOCKnode of the source) of the following form on the remote machine

ssh -l user otherhost '/usr/lib/R/bin/Rscript' -e 'parallel:::.slaveRSOCK()' MASTER=myhost PORT=10187 OUT=/dev/null TIMEOUT=2592000 METHODS=TRUE XDR=TRUE

Where the specific command (ssh) can be specified by the rshcmd parameter of the command makePSOCKcluster.  Given that a command such as ssh must be present on the machine, I installed PuTTY on both the master and host, and added the pertinent path to the system PATH variable so that plink is always accessible from the command line.   I'm not set on PuTTY, it's just free and I've used it before.

Here are my two cases.  If I issue my above command, the process hangs indefinitely.  If I set the manual flag equal to TRUE, as in the following

cl<-makePSOCKcluster(c(remoteHostIP), rshcmd="plink", outfile="", manual=TRUE)

I'm able to make the connection to the remote host just fine.  This indicates to me that there is something wrong with the system command that is being issued with manual=FALSE (the default).

Another problem with this is that it is seemingly very hard to test, as the hanging process gives me no information on what is actually occurring.  Has anyone had any success with this?  Are there any ideas on steps I could take to fix or debug this issue?

Regards,

Dylan



Dylan Tevlin
(480) 419-3611


	[[alternative HTML version deleted]]


From nashjc at uottawa.ca  Fri Sep 19 17:21:02 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Fri, 19 Sep 2014 11:21:02 -0400
Subject: [R]  Extract model from deriv3 or nls
In-Reply-To: <mailman.23.1411120807.23892.r-help@r-project.org>
References: <mailman.23.1411120807.23892.r-help@r-project.org>
Message-ID: <541C49DE.8020100@uottawa.ca>

If it is possible, I think you will need to get the expression for
Puro.fun2 and then (essentially manually) put it into nls (or perhaps
better nlmrt or minpack.lm which have better numerics and allow bounds;
nlmrt even has masks or temporarily fixed parameters, but I need to
writa a vignette about that). That is, I believe you essentially need to
do the analytic derivatives to get what you want.

There is also an experimental nls14 on r-forge in the optimizer project,
which Duncan Murdoch and I have been working on. It even includes all-R
replacements for D and deriv (I don't think Duncan implemented deriv3
though). It is, however,
experimental, and we welcome people trying it and letting us know of
bugs and glitches. Note that nlmrt and nls14 try to use analytic
derivatives for the Jacobian of the nonlinear least squares, while nls()
uses numeric approximations. When it works, nls() is generally more
efficient, but it is much more fragile -- trade-offs abound.

Best, JN



On 14-09-19 06:00 AM, r-help-request at r-project.org wrote:
> Date: Thu, 18 Sep 2014 13:33:24 +0000
> From: "Riley, Steve" <Steve.Riley at pfizer.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] Extract model from deriv3 or nls
> Message-ID:
> 	<941F9C738E7ABB459A4306D21D7177CBC8598EAD at NDHAMREXDE03.amer.pfizer.com>
> 	
> Content-Type: text/plain; charset="UTF-8"
> 
> Hello!
> 
> I am trying to figure out how to extract the model equation when using deriv3 with nls.
> 
> Here is my example:
> #
> #             Generate derivatives
> #
> Puro.fun2 <- deriv3(expr = ~(Vmax + VmaxT*state) * conc/(K + Kt * state + conc),
>                     name = c("Vmax","VmaxT","K","Kt"),
>                     function.arg = function(conc, state, Vmax, VmaxT, K, Kt) NULL)
> #
> #             Fit model using derivative function
> #
> Puro.fit1 <- nls(rate ~ Puro.fun2(conc, state == "treated", Vmax, VmaxT, K, Kt),
>                  data = Puromycin,
>                  start = c(Vmax = 160, VmaxT = 47, K = 0.043, Kt = 0.05))
> 
> Normally I would use summary(Puro.fit1)$formula to extract the model but because I am implementing deriv3, the following gets returned:
> 
>> > summary(Puro.fit1)$formula
> rate ~ Puro.fun2(conc, state == "treated", Vmax, VmaxT, K, Kt)
> 
> What I would like to do is find something that returns:
> 
> rate ~ (Vmax + VmaxT*state) * conc/(K + Kt * state + conc)
> 
> Is there a way to extract this? Please advise. Thanks for your time.
> 
> Steve
> 860-441-3435


From nashjc at uottawa.ca  Fri Sep 19 17:32:37 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Fri, 19 Sep 2014 11:32:37 -0400
Subject: [R]  optim, L-BFGS-B | constrained bounds on parms?
In-Reply-To: <mailman.23.1411120807.23892.r-help@r-project.org>
References: <mailman.23.1411120807.23892.r-help@r-project.org>
Message-ID: <541C4C95.7080902@uottawa.ca>

One choice is to add a penalty to the objective to enforce the
constraint(s) along with bounds to keep the parameters from going wild.

This generally works reasonably well. Sometimes it helps to run just a
few iterations with a big penalty scale to force the parameters into a
feasible region, though a lot depends on the particular problem in my
experience, with some being straightforward and others needing a lot of
fiddle.

I suspect a math programming approach is overkill, though R does have
some packages for that. Your mileage may vary.

Note that L-BFGS-B used by R is a version for which Nocedal et al.
reported a bug in 2011 and provided a new Fortran code. I've recently
put up an implementation of the new code on r-forge under the optimizer
project. Still testing, but I think it's OK. You could also use Rvmmin
that has bounds, or nmkb from dfoptim (though you cannot start on bounds).

Best, JN

On 14-09-19 06:00 AM, r-help-request at r-project.org wrote:
> Message: 27
> Date: Fri, 19 Sep 2014 00:55:04 -0400
> From: Evan Cooch <evan.cooch at gmail.com>
> To: r-help at r-project.org
> Subject: [R] optim, L-BFGS-B | constrained bounds on parms?
> Message-ID: <541BB728.6030704 at gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> Or, something to that effect. Following is an example of what I'm 
> working with basic ABO blood type ML estimation from observed type 
> (phenotypic) frequencies. First, I generate a log-likelihood function. 
> mu[1] -> mu[2] are allele freqs for A and B alleles, respectively. Since 
> freq of O allele is redundant, I use 1-mu[1]-mu[2] for that. The terms 
> in the function are the probability expressions for the expected values 
> of each phenotype.
> 
> But, that is somewhat besides the point:
> 
> f_abo <- function(mu) { 
> 25*log(mu[1]^2+2*mu[1]*(1-mu[1]-mu[2]))+25*log(mu[2]^2+2*mu[2]*(1-mu[1]-mu[2]))+50*log(2*mu[1]*mu[2])+15*log((1-mu[1]-mu[2])^2) 
> }
> 
> 
> So, I want to come up with MLE for mu[1] and mu[2] (for alleleic freqs 
> for A and B alleles, respectively. Now, given the data, I know (from 
> having maximized this likelihood outside of R) that the MLE for mu[1] is 
> 0.37176, and for mu[2], the same -- mu[2]=0.371763. I confirm this in 
> MATLAB, and Maple, and Mathematica, using various non-linear 
> solvers/optimization routines. They all yielded recisely the right answers.
> 
> But, stuck trying to come up with a general approach to getting the 
> 'right estimates' in R, that doesn't rely on strong prior knowledge of 
> the parameters. I tried the following - I used L-BFGDS-B' because this 
> is a 'boxed' optimzation: mu[1] and mu[2] are both parameters on the 
> interval [0,1].
> 
>   results <- optim(c(0.3,0.3), f_abo,
>       method = "L-BFGS-B", lower=c(0.1,0.1), upper=c(0.9,0.9),
>        hessian = TRUE,control=list(fnscale=-1))
> 
> but that through the following error at me:
> 
> L-BFGS-B needs finite values of 'fn'
> 
> OK, fine. Taking that literally, and thinking a bit, clear that the 
> problem is that the upper bound on the parms creates the problem. So, I 
> try the crude approach of making the upper bound for each 0.5:
> 
> 
>   results <- optim(c(0.3,0.3), f_abo,
>       method = "L-BFGS-B", lower=c(0.1,0.1), upper=c(0.5,0.5),
>        hessian = TRUE,control=list(fnscale=-1))
> 
> 
> No errors this time, but no estimates either. At all.
> 
> OK -- so I 'cheat', and since I know that mu[1]=mu[2]=0.37176, I make 
> another change to the upper limit, using 0.4 for both parms:
> 
> 
> 
>   results <- optim(c(0.3,0.3), f_abo,
>       method = "L-BFGS-B", lower=c(0.1,0.1), upper=c(0.4,0.4),
>        hessian = TRUE,control=list(fnscale=-1))
> 
> 
> Works perfectly, and...right estimates too. ;-)
> 
> But, I could get there from here because I had prior knowledge of the 
> parameter values. In other words, I cheated (not a thinly veiled 
> suggestion that prior information is cheating, of course ;-)
> 
> What I'm trying to figure out is how to do a constrained optimization 
> with R, where mu[1] and mu[2] are estimated subject to the constraint that
> 
> 0 <= mu[1]+mu[2] <= 1
> 
> There seems to be no obvious way to impose that -- which creates a 
> problem for optim since if I set 'vague' bounds on the parms (as per 
> original attempt), optim tries combinations (like mu[1]=0.9, mu[2]=0.9), 
> which aren't plausible, given the constraint that 0 <= mu[1]+mu[2] <= 1. 
> Further, in this example, mu[1]=mu[2]. That might not be the case, and I 
> might need to set upper bound on a parameter to be >0.5. But, without 
> knowing which parameter, I'd need to set both from (say) 0.1 -> 0.9.
> 
> Is this possible with optim, or do I need to use a different package? If 
> I can get there from here using optim, what do I need to do, either to 
> my call to the optim routine, or the function that I pass to it?
> 
> This sort of thing is quite easy in (say) Maple. I simply execute
> 
> NLPSolve(f_abo,initialpoint={mu[1]=0.2,mu[2]=0.2},{mu[1]+mu[2]<=1},mu[1]=0.1..0.9,mu[2]=0.1..0.9,maximize);
> 
> where I'm telling the NLPSolve function that there is a constraint for 
> mu[1] and mu[2] (as above), which lets me set bounds on the parameter 
> over larger interval. Can I do the same in R?
> 
> Again, I'm trying to avoid having to use a 'good guess'. I know I can 
> gene count to come up with a quick and dirty starting point (the basis 
> for the EM algorithm commonly used for this), but again, I'm trying to 
> avoid that.
> 
> Thanks very much in advance.
> 
> 	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Sep 19 17:40:40 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 19 Sep 2014 08:40:40 -0700
Subject: [R] package Parallel - accessing remote cores on Windows using
	plink (PuTTY)
In-Reply-To: <9D606AC27145D74F845B5AA9F37F9D9DEF60E76C0F@MSGICTB.kochind.com>
References: <9D606AC27145D74F845B5AA9F37F9D9DEF60E76C0F@MSGICTB.kochind.com>
Message-ID: <6e44e133-f867-498f-a240-f5977b1112f0@email.android.com>

While I hope someone with first hand experience or time to try it out pipes up, I noticed something wrong in your description. The ssh command is executed on the local machine, not the remote machine. That command must succeed on the local machine in order to start Rscript on the remote machine. Since the remote machine is a windows box, the given path to Rscript on the remote machine won't be usable unless the sshd running there is part of cygwin to simulate a standard Unix directory structure. So you need to change the path in the ssh arguments or make sure the remote machine understands the given path.
I don't see you describing how the remote machine is supposed to receive the ssh connection request, but you say that is working. 
The plink command is supposed to be a replacement for ssh... but I don't know if R is compatible with plink.. someone else will have to chime in. If it is, renaming it would seem logical.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 19, 2014 7:49:36 AM PDT, "Tevlin, Dylan" <Dylan.Tevlin at kochind.com> wrote:
>Hello all.
>
>My system information:
>
>R 2.14.1 x64
>Windows 7
>
>I'm attempting to access cores on other machines in my LAN.  As setup,
>I can ping all the machines successfully and it's a private office
>network where I have access to all computers, so there really shouldn't
>be any problems arising from the network itself.
>
>All machines I am connecting to have identical system information.
>
>I issue the following command to make a connection to the remote
>machine and access one of its cores.
>
>cl<-makePSOCKcluster(c(remoteHostIP), rshcmd="plink", outfile="")
>
>The parallel package, to make remote connections, issues a system
>command (found in the file snowSOCK.R, function newPSOCKnode of the
>source) of the following form on the remote machine
>
>ssh -l user otherhost '/usr/lib/R/bin/Rscript' -e
>'parallel:::.slaveRSOCK()' MASTER=myhost PORT=10187 OUT=/dev/null
>TIMEOUT=2592000 METHODS=TRUE XDR=TRUE
>
>Where the specific command (ssh) can be specified by the rshcmd
>parameter of the command makePSOCKcluster.  Given that a command such
>as ssh must be present on the machine, I installed PuTTY on both the
>master and host, and added the pertinent path to the system PATH
>variable so that plink is always accessible from the command line.  
>I'm not set on PuTTY, it's just free and I've used it before.
>
>Here are my two cases.  If I issue my above command, the process hangs
>indefinitely.  If I set the manual flag equal to TRUE, as in the
>following
>
>cl<-makePSOCKcluster(c(remoteHostIP), rshcmd="plink", outfile="",
>manual=TRUE)
>
>I'm able to make the connection to the remote host just fine.  This
>indicates to me that there is something wrong with the system command
>that is being issued with manual=FALSE (the default).
>
>Another problem with this is that it is seemingly very hard to test, as
>the hanging process gives me no information on what is actually
>occurring.  Has anyone had any success with this?  Are there any ideas
>on steps I could take to fix or debug this issue?
>
>Regards,
>
>Dylan
>
>
>
>Dylan Tevlin
>(480) 419-3611
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Dylan.Tevlin at kochind.com  Fri Sep 19 17:51:02 2014
From: Dylan.Tevlin at kochind.com (Tevlin, Dylan)
Date: Fri, 19 Sep 2014 10:51:02 -0500
Subject: [R] package Parallel - accessing remote cores on Windows using
 plink (PuTTY)
In-Reply-To: <6e44e133-f867-498f-a240-f5977b1112f0@email.android.com>
References: <9D606AC27145D74F845B5AA9F37F9D9DEF60E76C0F@MSGICTB.kochind.com>
	<6e44e133-f867-498f-a240-f5977b1112f0@email.android.com>
Message-ID: <9D606AC27145D74F845B5AA9F37F9D9DEF60E76C4B@MSGICTB.kochind.com>

Thanks for your input Jeff, yes that was a misunderstanding on my part about where the system command was actually run, and I think you're right on point, that path to Rscript doesn't make any sense!  Big oversight by me.  Nicely enough, there is a parameter for specifying the path to Rscript, so fingers crossed that works

Dylan Tevlin
(480) 419-3611

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
Sent: Friday, September 19, 2014 8:41 AM
To: Tevlin, Dylan; r-help at r-project.org
Subject: Re: [R] package Parallel - accessing remote cores on Windows using plink (PuTTY)

While I hope someone with first hand experience or time to try it out pipes up, I noticed something wrong in your description. The ssh command is executed on the local machine, not the remote machine. That command must succeed on the local machine in order to start Rscript on the remote machine. Since the remote machine is a windows box, the given path to Rscript on the remote machine won't be usable unless the sshd running there is part of cygwin to simulate a standard Unix directory structure. So you need to change the path in the ssh arguments or make sure the remote machine understands the given path.
I don't see you describing how the remote machine is supposed to receive the ssh connection request, but you say that is working. 
The plink command is supposed to be a replacement for ssh... but I don't know if R is compatible with plink.. someone else will have to chime in. If it is, renaming it would seem logical.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On September 19, 2014 7:49:36 AM PDT, "Tevlin, Dylan" <Dylan.Tevlin at kochind.com> wrote:
>Hello all.
>
>My system information:
>
>R 2.14.1 x64
>Windows 7
>
>I'm attempting to access cores on other machines in my LAN.  As setup, 
>I can ping all the machines successfully and it's a private office 
>network where I have access to all computers, so there really shouldn't 
>be any problems arising from the network itself.
>
>All machines I am connecting to have identical system information.
>
>I issue the following command to make a connection to the remote 
>machine and access one of its cores.
>
>cl<-makePSOCKcluster(c(remoteHostIP), rshcmd="plink", outfile="")
>
>The parallel package, to make remote connections, issues a system 
>command (found in the file snowSOCK.R, function newPSOCKnode of the
>source) of the following form on the remote machine
>
>ssh -l user otherhost '/usr/lib/R/bin/Rscript' -e 
>'parallel:::.slaveRSOCK()' MASTER=myhost PORT=10187 OUT=/dev/null
>TIMEOUT=2592000 METHODS=TRUE XDR=TRUE
>
>Where the specific command (ssh) can be specified by the rshcmd 
>parameter of the command makePSOCKcluster.  Given that a command such 
>as ssh must be present on the machine, I installed PuTTY on both the 
>master and host, and added the pertinent path to the system PATH 
>variable so that plink is always accessible from the command line.
>I'm not set on PuTTY, it's just free and I've used it before.
>
>Here are my two cases.  If I issue my above command, the process hangs 
>indefinitely.  If I set the manual flag equal to TRUE, as in the 
>following
>
>cl<-makePSOCKcluster(c(remoteHostIP), rshcmd="plink", outfile="",
>manual=TRUE)
>
>I'm able to make the connection to the remote host just fine.  This 
>indicates to me that there is something wrong with the system command 
>that is being issued with manual=FALSE (the default).
>
>Another problem with this is that it is seemingly very hard to test, as 
>the hanging process gives me no information on what is actually 
>occurring.  Has anyone had any success with this?  Are there any ideas 
>on steps I could take to fix or debug this issue?
>
>Regards,
>
>Dylan
>
>
>
>Dylan Tevlin
>(480) 419-3611
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Fri Sep 19 17:57:37 2014
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 19 Sep 2014 09:57:37 -0600
Subject: [R] read.table() 1Gb text dataframe
In-Reply-To: <1391727814.8319228.1411084115662.JavaMail.zimbra@stanford.edu>
References: <1391727814.8319228.1411084115662.JavaMail.zimbra@stanford.edu>
Message-ID: <CAFEqCdxhEzi7QzqbUuWVy8ih4ZdWdLDYzQKsNYa=b3A9AbKoJA@mail.gmail.com>

When working with datasets too large to fit in memory it is usually
best to use an actual database, read the data into the database, then
pull the records that you want into R.  There are several packages for
working with databases, but 2 of the simplest are the RSQLite and
sqldf packages (installing them will install the database backend for
you).  The read.csv.sql function in the sqldf package will read in a
csv file by first reading it into the database, then pulling the
desired subset (you need to know some basic sql) into R, all the
database stuff is handled in the background for you.

On Thu, Sep 18, 2014 at 5:48 PM, Stephen HK Wong <honkit at stanford.edu> wrote:
> Dear All,
>
> I have a table of 4 columns and many millions rows separated by tab-delimited. I don't have enough memory to read.table in that 1 Gb file. And actually I have 12 text files like that. Is there a way that I can just randomly read.table() in 10% of rows ? I was able to do that using colbycol package, but it is not not available. Many thanks!!
>
>
>
> Stephen HK Wong
> Stanford, California 94305-5324
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From Dylan.Tevlin at kochind.com  Fri Sep 19 18:02:06 2014
From: Dylan.Tevlin at kochind.com (Tevlin, Dylan)
Date: Fri, 19 Sep 2014 11:02:06 -0500
Subject: [R] package Parallel - accessing remote cores on Windows using
 plink (PuTTY)
References: <9D606AC27145D74F845B5AA9F37F9D9DEF60E76C0F@MSGICTB.kochind.com>
	<6e44e133-f867-498f-a240-f5977b1112f0@email.android.com> 
Message-ID: <9D606AC27145D74F845B5AA9F37F9D9DEF60E76C58@MSGICTB.kochind.com>

After specifying the path to Rscript we're still hanging.  

As for Jeff's comment on how the remote machine is receiving the ssh request, I don't know.  My assumption is that, given the ssh request going through, it's attempting to make the command Rscript.exe parallel:::.slaveRSOCK(), which presumably spins up a process and uses the rest of the parameters to tell the process where to send data back to.   I'm not well versed in network programming though

Dylan 


-----Original Message-----
From: Tevlin, Dylan 
Sent: Friday, September 19, 2014 8:51 AM
To: 'Jeff Newmiller'; 'r-help at r-project.org'
Subject: RE: [R] package Parallel - accessing remote cores on Windows using plink (PuTTY)

Thanks for your input Jeff, yes that was a misunderstanding on my part about where the system command was actually run, and I think you're right on point, that path to Rscript doesn't make any sense!  Big oversight by me.  Nicely enough, there is a parameter for specifying the path to Rscript, so fingers crossed that works

Dylan 

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
Sent: Friday, September 19, 2014 8:41 AM
To: Tevlin, Dylan; r-help at r-project.org
Subject: Re: [R] package Parallel - accessing remote cores on Windows using plink (PuTTY)

While I hope someone with first hand experience or time to try it out pipes up, I noticed something wrong in your description. The ssh command is executed on the local machine, not the remote machine. That command must succeed on the local machine in order to start Rscript on the remote machine. Since the remote machine is a windows box, the given path to Rscript on the remote machine won't be usable unless the sshd running there is part of cygwin to simulate a standard Unix directory structure. So you need to change the path in the ssh arguments or make sure the remote machine understands the given path.
I don't see you describing how the remote machine is supposed to receive the ssh connection request, but you say that is working. 
The plink command is supposed to be a replacement for ssh... but I don't know if R is compatible with plink.. someone else will have to chime in. If it is, renaming it would seem logical.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On September 19, 2014 7:49:36 AM PDT, "Tevlin, Dylan" <Dylan.Tevlin at kochind.com> wrote:
>Hello all.
>
>My system information:
>
>R 2.14.1 x64
>Windows 7
>
>I'm attempting to access cores on other machines in my LAN.  As setup, 
>I can ping all the machines successfully and it's a private office 
>network where I have access to all computers, so there really shouldn't 
>be any problems arising from the network itself.
>
>All machines I am connecting to have identical system information.
>
>I issue the following command to make a connection to the remote 
>machine and access one of its cores.
>
>cl<-makePSOCKcluster(c(remoteHostIP), rshcmd="plink", outfile="")
>
>The parallel package, to make remote connections, issues a system 
>command (found in the file snowSOCK.R, function newPSOCKnode of the
>source) of the following form on the remote machine
>
>ssh -l user otherhost '/usr/lib/R/bin/Rscript' -e 
>'parallel:::.slaveRSOCK()' MASTER=myhost PORT=10187 OUT=/dev/null
>TIMEOUT=2592000 METHODS=TRUE XDR=TRUE
>
>Where the specific command (ssh) can be specified by the rshcmd 
>parameter of the command makePSOCKcluster.  Given that a command such 
>as ssh must be present on the machine, I installed PuTTY on both the 
>master and host, and added the pertinent path to the system PATH 
>variable so that plink is always accessible from the command line.
>I'm not set on PuTTY, it's just free and I've used it before.
>
>Here are my two cases.  If I issue my above command, the process hangs 
>indefinitely.  If I set the manual flag equal to TRUE, as in the 
>following
>
>cl<-makePSOCKcluster(c(remoteHostIP), rshcmd="plink", outfile="",
>manual=TRUE)
>
>I'm able to make the connection to the remote host just fine.  This 
>indicates to me that there is something wrong with the system command 
>that is being issued with manual=FALSE (the default).
>
>Another problem with this is that it is seemingly very hard to test, as 
>the hanging process gives me no information on what is actually 
>occurring.  Has anyone had any success with this?  Are there any ideas 
>on steps I could take to fix or debug this issue?
>
>Regards,
>
>Dylan
>
>
>
>Dylan Tevlin
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gangchen6 at gmail.com  Fri Sep 19 18:24:41 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Fri, 19 Sep 2014 12:24:41 -0400
Subject: [R] Failure with .Rprofile on Mac OS X
In-Reply-To: <1CEBC003-79A0-45B3-AED2-B0AE9FE4B804@gmail.com>
References: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>
	<1CEBC003-79A0-45B3-AED2-B0AE9FE4B804@gmail.com>
Message-ID: <CAHmzXO45Kqiz81VCZt-ZzaOWLj_XS1=3C3QssC1yvOtSW3ULPw@mail.gmail.com>

Thanks for the help, Amos!

> The only reason that *should* happen is if there's an .Rprofile in the directory you're in when you start R.

There is only one .Rprofil, which is in my home directory ~/

> Where *exactly* is the .Rprofile file you want loaded

The only one is in my home directory.

> what directory are you starting from

It does not matter where I start R because on my Mac the CLI R is
linked to /Library/Frameworks/R.framework/Resources/bin/R while the
GUI R is linked to /Applications/R.app/Contents/MacOS/R

> what does R say is the user's home directory? Did you make *any* changes to Rprofile.site, or Renviron?

> R.home()
[1] "/Library/Frameworks/R.framework/Resources"

> What is the output from Sys.getenv() in gui and cli, and do they differ?

They differ slightly. I have trouble pinpointing the exact difference
because the format is a little different and vim does not help much in
tracking the differences. I just noticed that the CLI version has a
few extra terms such as

COLUMNS
"130"
...
DYLD_FALLBACK_LIBRARY_PATH
"/Library/Frameworks/R.framework/Resources/lib"

Thanks,
Gang


On Thu, Sep 18, 2014 at 7:04 PM, Amos B. Elberg <amos.elberg at gmail.com> wrote:
> The only reason that *should* happen is if there's an .Rprofile in the directory you're in when you start R.
>
> Where *exactly* is the .Rprofile file you want loaded, what directory are you starting from, and what does R say is the user's home directory? Did you make *any* changes to Rprofile.site, or Renviron?
>
> What is the output from Sys.getenv() in gui and cli, and do they differ?
>
>
>> On Sep 18, 2014, at 11:18 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>>
>> When R starts in GUI (e.g., /Applications/R.app/Contents/MacOS/R) on
>> my Mac OS X 10.7.5, the startup configuration in .Rprofile works fine.
>> However, when R starts on the terminal (e.g.,
>> /Library/Frameworks/R.framework/Resources/bin/R), it does not work at
>> all. What could be the reason for the failure?
>>
>> Thanks,
>> Gang
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Sep 19 18:52:01 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 19 Sep 2014 12:52:01 -0400
Subject: [R] Failure with .Rprofile on Mac OS X
In-Reply-To: <541BBCBC.5050007@gmail.com>
References: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>
	<1CEBC003-79A0-45B3-AED2-B0AE9FE4B804@gmail.com>
	<AB86BF82-1939-436B-9408-F5BED23135D3@comcast.net>
	<541BBCBC.5050007@gmail.com>
Message-ID: <201409BF-9066-42F0-AC31-1A685DC62084@comcast.net>

Good point. I see the behavior you describe.

Sent from my iPhone

> On Sep 19, 2014, at 1:18 AM, "Amos B. Elberg" <amos.elberg at gmail.com> wrote:
> 
> David - the startup directory for Terminal.app shouldn't affect where R looks for .Rprofile.  If R is started from the command line, it should look in whatever is the user's current directory (which will be ~/ if Terminal was just launched), and then ~/  .  It shouldn't be looking in /Applications/ unless you happen to have cd'd to /Applications before launching R. 
> 
> (You put up the environment variables present in one launch and absent from another, but what I was really looking for is whether something in his shell is changing a path.  Because mac environment variables are funky that way.)
>> <compose-unknown-contact.jpg>	David Winsemius	September 19, 2014 at 12:57 AM
>> 
>> Dear Gang Chen; 
>> 
>> The .Rprofile is loaded from the startup directory. Terminal.app will start up in /Applications/ while your R.app session appears to be starting in a different directory. (We don't know what your startup directories are.)  I'm using R.app in /Applications/ so my .Rprofile has the same effect regardless of whether I run from R.app or from a bash console. 
>> 
>> See this portion of the Mac-FAQ: 
>> 
>> http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#The-current-and-startup-working-directories 
>> 
>>  See ?Startup for more specifics that are generic to all R versions: 
>> 
>> 
>>> On Sep 18, 2014, at 7:04 PM, Amos B. Elberg wrote: 
>>> 
>>> The only reason that *should* happen is if there's an .Rprofile in the directory you're in when you start R. 
>>> 
>>> Where *exactly* is the .Rprofile file you want loaded, what directory are you starting from, and what does R say is the user's home directory? Did you make *any* changes to Rprofile.site, or Renviron? 
>>> 
>>> What is the output from Sys.getenv() in gui and cli, and do they differ?
>> 
>> They might differ even if the default directories are the same (as they are on my setup). I have a somewhat older version on this laptop but there are names of environment variables that are not present in both directions: 
>> 
>> I ran AppEnv <- dput( Sys.getenv() ) on my R.app session and then ran the corresponding command on a Terminal console session: 
>> 
>> These are the difference (on a R 2.15.2 setup): 
>> 
>> > AppEnv[ !names(AppEnv) %in% names(conEnv)] 
>> R_GUI_APP_REVISION  R_GUI_APP_VERSION 
>>             "6435"             "1.53" 
>> > names( conEnv[ !names(conEnv) %in% names(AppEnv)] ) # i.e. missing in the GUI installation 
>> 
>>  [1] "COLUMNS"              "DYLD_LIBRARY_PATH"    "GDK_USE_XFT"          "INFOPATH" 
>>  [5] "LINES"                "MANPATH"              "PERL5LIB"             "PWD" 
>>  [9] "SHLVL"                "TERM"                 "TERM_PROGRAM"         "TERM_PROGRAM_VERSION" 
>> [13] "XDG_CACHE_HOME"       "XDG_CONFIG_DIRS"       "XDG_CONFIG_HOME"      "XDG_DATA_DIRS" 
>> [17] "XDG_DATA_HOME" 
>> 
>>  If there are further points of discussion they should be thrashed out (with greater details about sessionInfo() and startup settings), over on the R-MAC-SIG mailing list. 
>> 
>> 
>>> 
>>> 
>>>> On Sep 18, 2014, at 11:18 AM, Gang Chen <gangchen6 at gmail.com> wrote: 
>>>> 
>>>> When R starts in GUI (e.g., /Applications/R.app/Contents/MacOS/R) on 
>>>> my Mac OS X 10.7.5, the startup configuration in .Rprofile works fine. 
>>>> However, when R starts on the terminal (e.g., 
>>>> /Library/Frameworks/R.framework/Resources/bin/R), it does not work at 
>>>> all. What could be the reason for the failure? 
>>>> 
>>>> Thanks, 
>>>> Gang
>> 
>> David Winsemius, MD 
>> Alameda, CA, USA 
>> 
>> <compose-unknown-contact.jpg>	Gang Chen	September 18, 2014 at 11:18 AM
>> When R starts in GUI (e.g., /Applications/R.app/Contents/MacOS/R) on
>> my Mac OS X 10.7.5, the startup configuration in .Rprofile works fine.
>> However, when R starts on the terminal (e.g.,
>> /Library/Frameworks/R.framework/Resources/bin/R), it does not work at
>> all. What could be the reason for the failure?
>> 
>> Thanks,
>> Gang
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From f.harrell at vanderbilt.edu  Fri Sep 19 18:56:38 2014
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Fri, 19 Sep 2014 11:56:38 -0500
Subject: [R] [R-pkgs] CRAN submission of Hmisc 3.14-5
Message-ID: <541C6046.1060602@vanderbilt.edu>

An update to the Hmisc package is now on CRAN.  Some recent changes:

    * latex.summaryM: fixed bug in caption with test=TRUE.  Thanks: 
Yonghao Pua
    * combined.levels: sensed all NA vector, now return non-factor 
numeric instead
    * dataframeReduce: handle all-NA factor variable
    * subplot: replaced with latest version from TeachingDemos package 
by Greg Snow
    * latexTabular: fixed error in example in help file; result is not a 
file
    * latex: another test added in tests/latex.s
    * summaryP: removed observations with a right-hand-side variable missing
    * latex.summaryP: fixed bug with wrong column labels due to reshape 
reordering columns coming from factor levels alphabetically instead of 
by original levels
    * format.df: added % & <= >= to list of characters handled, the last 
two by going into math mode
    * latex.summaryP: use blank if denominator 0, instead of NaN
    * summary.formula: fixed problem with deparse formula.  Thanks: 
Andreas Kiermeier
    * describe: added relative information measure for numeric variables 
- a measure of how continuous the variable is
    * wtd.table: detect duplications using duplicated() instead of 
diff(x) to handle Inf.  Thanks: Benjamin Tyner
    * DESCRIPTION, NAMESPACE: multiple function changes to work in R-devel

See http://biostat.mc.vanderbilt.edu/Hmisc, 
https://github.com/harrelfe/Hmisc for more information.

Frank Harrell
Vanderbilt University

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From f.harrell at vanderbilt.edu  Fri Sep 19 19:00:52 2014
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Fri, 19 Sep 2014 12:00:52 -0500
Subject: [R] [R-pkgs] CRAN update: rms 4.2-1
Message-ID: <541C6144.2030204@vanderbilt.edu>

An update to the rms package is now on CRAN.  Some recent changes:

    * plot.summary.rms: allowed a vector for lwd, and passed lwd to 
confbar.  Thanks: Michael Friendly
    * gendata: Starting in R 3.1.0, as.data.frame.labelled or 
as.data.frame.list quit working when length vary; workaround
    * predictrms, ols: handle offset in formula.  Thanks: Max Gordon
    * pentrace: neatened code, added new argument noaddzero if user 
wants to prevent unpenalized model from being tried; add new test script 
in tests
    * bplot: fixed bug whereby xlabrot was ignored.  Thanks: Sven 
Krackow <sven.krackow at gmail.com>; new test for bplot in tests directory
    * plot.Predict: fixed bug in which 2nd argument to perim was not correct
    * validate.ols: Shane McIntosh fixed the passing of the tolerance 
argument to predab.resample
    * predictrms: computed offset earlier so always defined no matter 
the value of type
    * plot.Predict: added scaletrans argument, fixed use of subscripts 
in pan
    * lrm, lrm.fit: added scale argument
    * orm, orm.fit: added scale argument
    * vcov.orm: accounted for scale when extracting covariance matrix
    * npsurv: was not passing type argument
    * npsurv: start storing all classes created by survfit.formula
    * logLik.Gls: added.  Makes AIC(Gls object) work.
    * NAMESPACE: several changes


See http://biostat.mc.vanderbilt.edu/rms and 
https://github.com/harrelfe/rms for more information.

Frank Harrell
Vanderbilt University

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From honkit at stanford.edu  Fri Sep 19 19:07:30 2014
From: honkit at stanford.edu (Stephen HK Wong)
Date: Fri, 19 Sep 2014 10:07:30 -0700 (PDT)
Subject: [R] read.table() 1Gb text dataframe
In-Reply-To: <CAFDcVCQ-ZV3Rf0zbje7AMafdDMbjJzGmAMPwNb7yxjBJ7xKMhg@mail.gmail.com>
References: <1391727814.8319228.1411084115662.JavaMail.zimbra@stanford.edu>
	<CAFDcVCQ-ZV3Rf0zbje7AMafdDMbjJzGmAMPwNb7yxjBJ7xKMhg@mail.gmail.com>
Message-ID: <418274300.9415027.1411146450014.JavaMail.zimbra@stanford.edu>

Thanks Henrick. Seems it fits my needs. One my question is the argument, length.out=0.10*n, is it "randomly" taking out 10% ? I found it basically takes every 10th row if I put length.out=0.1*n, and every 100th row if I put length.out=0.01*n till the end. I couldn't find this information on documentation.

Stephen HK Wong
Stanford, California 94305-5324 

----- Original Message -----
From: Henrik Bengtsson <hb at biostat.ucsf.edu>
To: Stephen HK Wong <honkit at stanford.edu>
Cc: r-help at r-project.org
Sent: Thu, 18 Sep 2014 18:33:15 -0700 (PDT)
Subject: Re: [R] read.table() 1Gb text dataframe

As a start, make sure you specify the 'colClasses' argument.  BTW,
using that you can even go to the extreme and read one column at the
time, if it comes down to that.

To read a 10% subset of the rows, you can use R.filesets as:

library(R.filesets)
db <- TabularTextFile(pathname)
n <- nbrOfRows(db)
data <- readDataFrame(db, rows=seq(from=1, to=n, length.out=0.10*n))

It is also useful to specify 'colClasses' here. In addition to
specifying them ordered by column, as for read.table(), you also
specify them by column names (or regular expressions of the column
names), e.g.

data <- readDataFrame(db, colClasses=c("*"="NULL", "(x|y)"="integer",
outcome="numeric", "id"="character"), rows=seq(from=1, to=n,
length.out=0.10*n))

That 'colClasses' specifies that the default is drop all columns, read
columns 'x' and 'y' as integers, and so on.

BTW, if you know 'n' upfront you can skip the setup of TabularTextFile
and just do:

data <- readDataFrame(pathname, rows=seq(from=1, to=n, length.out=0.10*n))


Hope this helps

Henrik

On Thu, Sep 18, 2014 at 4:48 PM, Stephen HK Wong <honkit at stanford.edu> wrote:
> Dear All,
>
> I have a table of 4 columns and many millions rows separated by tab-delimited. I don't have enough memory to read.table in that 1 Gb file. And actually I have 12 text files like that. Is there a way that I can just randomly read.table() in 10% of rows ? I was able to do that using colbycol package, but it is not not available. Many thanks!!
>
>
>
> Stephen HK Wong
> Stanford, California 94305-5324
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michel.arnaud at cirad.fr  Fri Sep 19 19:15:18 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Fri, 19 Sep 2014 19:15:18 +0200
Subject: [R] To Add a variable from Df1 to Df2 which have a same common
	variable
Message-ID: <541C64A6.4070902@cirad.fr>

Hello
I have the two dataframes Df1 and Df2 which have the common variable 
AgeSexeCadNCad
I would like to add the new variable Df2$Pourcent which correspond at 
the value of Df1$AgeSexeCadNCad.
Thank you for your help.
Michel

Df1 <- structure(list(AgeSexeCadNCad = structure(1:36, .Label = 
c("60-Femme-Cadre",
"60-Femme-Non Cadre", "60-Homme-Cadre", "60-Homme-Non Cadre",
"61-Femme-Cadre", "61-Femme-Non Cadre", "61-Homme-Cadre", "61-Homme-Non 
Cadre",
"62-Femme-Cadre", "62-Femme-Non Cadre", "62-Homme-Cadre", "62-Homme-Non 
Cadre",
"63-Femme-Cadre", "63-Femme-Non Cadre", "63-Homme-Cadre", "63-Homme-Non 
Cadre",
"64-Femme-Cadre", "64-Femme-Non Cadre", "64-Homme-Cadre", "64-Homme-Non 
Cadre",
"65-Femme-Cadre", "65-Femme-Non Cadre", "65-Homme-Cadre", "65-Homme-Non 
Cadre",
"66-Femme-Cadre", "66-Femme-Non Cadre", "66-Homme-Cadre", "66-Homme-Non 
Cadre",
"67-Femme-Cadre", "67-Femme-Non Cadre", "67-Homme-Cadre", "67-Homme-Non 
Cadre",
"68-Femme-Cadre", "68-Femme-Non Cadre", "68-Homme-Cadre", "68-Homme-Non 
Cadre"
), class = "factor"), Pourcent = c(0.157849638357511, 0.157849638357511,
0.0562149664637629, 0.419279916358023, 0.180720729132166, 
0.180720729132166,
0.092720981524322, 0.272158156192425, 0.145668562090518, 0.145668562090518,
0.101319648271574, 0.159207521192769, 0.0997898095090109, 
0.0997898095090109,
0.110753346057845, 0.0193586234067497, 0.0795236495990374, 
0.0795236495990374,
0.18014205547984, 0.00968491550180694, 0.0750838561972432, 
0.0750838561972432,
0.237072554382218, 0.0650665901855087, 0.0587392216209752, 
0.0587392216209752,
0.126427289344211, 0.00961707878904615, 0.0409034699088397, 
0.0409034699088397,
0.0537806700836756, 3.11172383820597e-05, 0.0285360029533433,
0.0285360029533433, 0.0220930854712636, 2.20203747900568e-09)), .Names = 
c("AgeSexeCadNCad",
"Pourcent"), row.names = c(28L, 19L, 10L, 1L, 29L, 20L, 11L,
2L, 30L, 21L, 12L, 3L, 31L, 22L, 13L, 4L, 32L, 23L, 14L, 5L,
33L, 24L, 15L, 6L, 34L, 25L, 16L, 7L, 35L, 26L, 17L, 8L, 36L,
27L, 18L, 9L), class = "data.frame")

Df2 <- structure(list(Matricule = c(410, 453, 501, 544, 653, 765, 833,
851, 927, 1050, 1074, 1278, 1379, 1428, 359, 379, 408, 417, 424,
426, 483, 490, 528, 538, 567, 596, 603, 604, 647, 675, 677, 681,
735, 743, 787, 817, 823, 896, 917, 1071, 1144, 1157, 1823, 2497,
2868, 3556, 3614, 3632, 3646, 3656, 3660, 4162, 4503, 4711, 5531,
330, 447, 467, 546, 627, 637, 780, 892, 1487, 1492, 3324, 4873,
409, 415, 441, 579, 619, 697, 716, 719, 728, 737, 807, 832, 989,
1299, 1320, 1352, 1427, 1484, 1548, 2447, 2914, 2929, 2941, 3524,
3527, 3631, 4324, 400, 572, 1095, 1097, 1105, 2966, 392, 418,
440, 457, 466, 472, 488, 491, 506, 533, 543, 547, 552, 553, 920,
1034, 1179, 1454, 1485, 1540, 3620, 4672, 13899, 342, 1089, 1208,
1234, 2153, 3545, 253, 504, 529, 558, 578, 745, 933, 935, 2099,
16785, 356, 460, 634, 959, 1429, 1591, 1720, 3602, 3644, 322,
361, 404, 430, 525, 706, 804, 1010, 1012, 1108, 1185, 1294, 2264,
3567, 3633, 4990, 264, 298, 352, 388, 503, 508, 691, 1509, 2192,
3060, 3683, 877, 1130, 1963, 188, 327, 331, 363, 437, 445, 462,
723, 1259, 1381, 3617, 427, 1402, 3624, 141, 256, 308, 377, 414,
640, 157, 560), AgeSexeCadNCad = c("60-Femme-Non Cadre", "60-Femme-Non 
Cadre",
"60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
"60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
"60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
"60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
"60-Homme-Non Cadre", "60-Homme-Non Cadre", "61-Femme-Non Cadre",
"61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
"61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
"61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
"61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
"61-Homme-Non Cadre", "61-Homme-Non Cadre", "62-Femme-Non Cadre",
"62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Femme-Non Cadre",
"62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Homme-Non Cadre",
"62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
"62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
"62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
"62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
"62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
"62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
"62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
"62-Homme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
"63-Femme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
"63-Femme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
"63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
"63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
"63-Homme-Non Cadre", "63-Homme-Non Cadre", "64-Femme-Non Cadre",
"64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
"64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
"64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Homme-Non Cadre",
"64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
"64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
"64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
"64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
"64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
"65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
"65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
"65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
"65-Homme-Non Cadre", "65-Homme-Non Cadre", "66-Femme-Non Cadre",
"66-Femme-Non Cadre", "66-Femme-Non Cadre", "66-Homme-Non Cadre",
"66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
"66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
"66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
"66-Homme-Non Cadre", "67-Homme-Non Cadre", "67-Homme-Non Cadre",
"67-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
"68-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
"68-Homme-Non Cadre", "69-Homme-Non Cadre", "69-Homme-Non Cadre"
)), .Names = c("Matricule", "AgeSexeCadNCad"), class = "data.frame", 
row.names = c("37",
"58", "79", "104", "163", "220", "263", "276", "333", "422",
"442", "587", "653", "684", "21", "25", "35", "42", "45", "47",
"73", "76", "93", "100", "118", "133", "137", "138", "158", "174",
"176", "179", "204", "208", "231", "249", "254", "312", "325",
"439", "491", "500", "825", "928", "954", "1093", "1116", "1128",
"1136", "1141", "1143", "1212", "1232", "1270", "1396", "14",
"56", "66", "106", "148", "153", "226", "308", "717", "720",
"1046", "1287", "36", "41", "54", "124", "144", "188", "197",
"198", "201", "206", "242", "262", "377", "598", "611", "633",
"683", "714", "742", "919", "980", "993", "1000", "1071", "1073",
"1127", "1223", "32", "121", "456", "458", "462", "1013", "27",
"43", "53", "59", "65", "67", "75", "77", "83", "97", "103",
"107", "109", "110", "328", "412", "516", "698", "715", "740",
"1122", "1267", "1824", "16", "452", "540", "557", "870", "1086",
"5", "82", "94", "115", "123", "209", "339", "341", "862", "2211",
"20", "61", "152", "358", "685", "760", "803", "1111", "1134",
"11", "22", "33", "49", "92", "193", "241", "394", "396", "463",
"522", "595", "896", "1097", "1129", "1302", "7", "9", "18",
"26", "81", "85", "185", "728", "884", "1029", "1155", "297",
"479", "842", "3", "13", "15", "23", "51", "55", "63", "199",
"574", "655", "1119", "48", "668", "1125", "1", "6", "10", "24",
"40", "154", "2", "117"))



-- 
Michel ARNAUD
CIRAD
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From sarah.goslee at gmail.com  Fri Sep 19 19:30:58 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 19 Sep 2014 13:30:58 -0400
Subject: [R] To Add a variable from Df1 to Df2 which have a same common
	variable
In-Reply-To: <541C64A6.4070902@cirad.fr>
References: <541C64A6.4070902@cirad.fr>
Message-ID: <CAM_vju=8s96sSAY1T0rrQ04wJPm_8Se7Gz6a2sRiWi1cJBDm3Q@mail.gmail.com>

Is merge() what you're looking for?


On Fri, Sep 19, 2014 at 1:15 PM, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
> Hello
> I have the two dataframes Df1 and Df2 which have the common variable
> AgeSexeCadNCad
> I would like to add the new variable Df2$Pourcent which correspond at the
> value of Df1$AgeSexeCadNCad.
> Thank you for your help.
> Michel
>
> Df1 <- structure(list(AgeSexeCadNCad = structure(1:36, .Label =
> c("60-Femme-Cadre",
> "60-Femme-Non Cadre", "60-Homme-Cadre", "60-Homme-Non Cadre",
> "61-Femme-Cadre", "61-Femme-Non Cadre", "61-Homme-Cadre", "61-Homme-Non
> Cadre",
> "62-Femme-Cadre", "62-Femme-Non Cadre", "62-Homme-Cadre", "62-Homme-Non
> Cadre",
> "63-Femme-Cadre", "63-Femme-Non Cadre", "63-Homme-Cadre", "63-Homme-Non
> Cadre",
> "64-Femme-Cadre", "64-Femme-Non Cadre", "64-Homme-Cadre", "64-Homme-Non
> Cadre",
> "65-Femme-Cadre", "65-Femme-Non Cadre", "65-Homme-Cadre", "65-Homme-Non
> Cadre",
> "66-Femme-Cadre", "66-Femme-Non Cadre", "66-Homme-Cadre", "66-Homme-Non
> Cadre",
> "67-Femme-Cadre", "67-Femme-Non Cadre", "67-Homme-Cadre", "67-Homme-Non
> Cadre",
> "68-Femme-Cadre", "68-Femme-Non Cadre", "68-Homme-Cadre", "68-Homme-Non
> Cadre"
> ), class = "factor"), Pourcent = c(0.157849638357511, 0.157849638357511,
> 0.0562149664637629, 0.419279916358023, 0.180720729132166, 0.180720729132166,
> 0.092720981524322, 0.272158156192425, 0.145668562090518, 0.145668562090518,
> 0.101319648271574, 0.159207521192769, 0.0997898095090109,
> 0.0997898095090109,
> 0.110753346057845, 0.0193586234067497, 0.0795236495990374,
> 0.0795236495990374,
> 0.18014205547984, 0.00968491550180694, 0.0750838561972432,
> 0.0750838561972432,
> 0.237072554382218, 0.0650665901855087, 0.0587392216209752,
> 0.0587392216209752,
> 0.126427289344211, 0.00961707878904615, 0.0409034699088397,
> 0.0409034699088397,
> 0.0537806700836756, 3.11172383820597e-05, 0.0285360029533433,
> 0.0285360029533433, 0.0220930854712636, 2.20203747900568e-09)), .Names =
> c("AgeSexeCadNCad",
> "Pourcent"), row.names = c(28L, 19L, 10L, 1L, 29L, 20L, 11L,
> 2L, 30L, 21L, 12L, 3L, 31L, 22L, 13L, 4L, 32L, 23L, 14L, 5L,
> 33L, 24L, 15L, 6L, 34L, 25L, 16L, 7L, 35L, 26L, 17L, 8L, 36L,
> 27L, 18L, 9L), class = "data.frame")
>
> Df2 <- structure(list(Matricule = c(410, 453, 501, 544, 653, 765, 833,
> 851, 927, 1050, 1074, 1278, 1379, 1428, 359, 379, 408, 417, 424,
> 426, 483, 490, 528, 538, 567, 596, 603, 604, 647, 675, 677, 681,
> 735, 743, 787, 817, 823, 896, 917, 1071, 1144, 1157, 1823, 2497,
> 2868, 3556, 3614, 3632, 3646, 3656, 3660, 4162, 4503, 4711, 5531,
> 330, 447, 467, 546, 627, 637, 780, 892, 1487, 1492, 3324, 4873,
> 409, 415, 441, 579, 619, 697, 716, 719, 728, 737, 807, 832, 989,
> 1299, 1320, 1352, 1427, 1484, 1548, 2447, 2914, 2929, 2941, 3524,
> 3527, 3631, 4324, 400, 572, 1095, 1097, 1105, 2966, 392, 418,
> 440, 457, 466, 472, 488, 491, 506, 533, 543, 547, 552, 553, 920,
> 1034, 1179, 1454, 1485, 1540, 3620, 4672, 13899, 342, 1089, 1208,
> 1234, 2153, 3545, 253, 504, 529, 558, 578, 745, 933, 935, 2099,
> 16785, 356, 460, 634, 959, 1429, 1591, 1720, 3602, 3644, 322,
> 361, 404, 430, 525, 706, 804, 1010, 1012, 1108, 1185, 1294, 2264,
> 3567, 3633, 4990, 264, 298, 352, 388, 503, 508, 691, 1509, 2192,
> 3060, 3683, 877, 1130, 1963, 188, 327, 331, 363, 437, 445, 462,
> 723, 1259, 1381, 3617, 427, 1402, 3624, 141, 256, 308, 377, 414,
> 640, 157, 560), AgeSexeCadNCad = c("60-Femme-Non Cadre", "60-Femme-Non
> Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "62-Femme-Non Cadre",
> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Femme-Non Cadre",
> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
> "63-Femme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
> "63-Femme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "66-Femme-Non Cadre",
> "66-Femme-Non Cadre", "66-Femme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "67-Homme-Non Cadre", "67-Homme-Non Cadre",
> "67-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
> "68-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
> "68-Homme-Non Cadre", "69-Homme-Non Cadre", "69-Homme-Non Cadre"
> )), .Names = c("Matricule", "AgeSexeCadNCad"), class = "data.frame",
> row.names = c("37",
> "58", "79", "104", "163", "220", "263", "276", "333", "422",
> "442", "587", "653", "684", "21", "25", "35", "42", "45", "47",
> "73", "76", "93", "100", "118", "133", "137", "138", "158", "174",
> "176", "179", "204", "208", "231", "249", "254", "312", "325",
> "439", "491", "500", "825", "928", "954", "1093", "1116", "1128",
> "1136", "1141", "1143", "1212", "1232", "1270", "1396", "14",
> "56", "66", "106", "148", "153", "226", "308", "717", "720",
> "1046", "1287", "36", "41", "54", "124", "144", "188", "197",
> "198", "201", "206", "242", "262", "377", "598", "611", "633",
> "683", "714", "742", "919", "980", "993", "1000", "1071", "1073",
> "1127", "1223", "32", "121", "456", "458", "462", "1013", "27",
> "43", "53", "59", "65", "67", "75", "77", "83", "97", "103",
> "107", "109", "110", "328", "412", "516", "698", "715", "740",
> "1122", "1267", "1824", "16", "452", "540", "557", "870", "1086",
> "5", "82", "94", "115", "123", "209", "339", "341", "862", "2211",
> "20", "61", "152", "358", "685", "760", "803", "1111", "1134",
> "11", "22", "33", "49", "92", "193", "241", "394", "396", "463",
> "522", "595", "896", "1097", "1129", "1302", "7", "9", "18",
> "26", "81", "85", "185", "728", "884", "1029", "1155", "297",
> "479", "842", "3", "13", "15", "23", "51", "55", "63", "199",
> "574", "655", "1119", "48", "668", "1125", "1", "6", "10", "24",
> "40", "154", "2", "117"))
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ruipbarradas at sapo.pt  Fri Sep 19 19:39:49 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 19 Sep 2014 18:39:49 +0100
Subject: [R] To Add a variable from Df1 to Df2 which have a same common
 variable
In-Reply-To: <541C64A6.4070902@cirad.fr>
References: <541C64A6.4070902@cirad.fr>
Message-ID: <541C6A65.9050500@sapo.pt>

Hello,

Try ?merge:

Df3 <- merge(Df2, Df1, by = "AgeSexeCadNCad")

Hope this helps,

Rui Barradas

Em 19-09-2014 18:15, Arnaud Michel escreveu:
> Hello
> I have the two dataframes Df1 and Df2 which have the common variable
> AgeSexeCadNCad
> I would like to add the new variable Df2$Pourcent which correspond at
> the value of Df1$AgeSexeCadNCad.
> Thank you for your help.
> Michel
>
> Df1 <- structure(list(AgeSexeCadNCad = structure(1:36, .Label =
> c("60-Femme-Cadre",
> "60-Femme-Non Cadre", "60-Homme-Cadre", "60-Homme-Non Cadre",
> "61-Femme-Cadre", "61-Femme-Non Cadre", "61-Homme-Cadre", "61-Homme-Non
> Cadre",
> "62-Femme-Cadre", "62-Femme-Non Cadre", "62-Homme-Cadre", "62-Homme-Non
> Cadre",
> "63-Femme-Cadre", "63-Femme-Non Cadre", "63-Homme-Cadre", "63-Homme-Non
> Cadre",
> "64-Femme-Cadre", "64-Femme-Non Cadre", "64-Homme-Cadre", "64-Homme-Non
> Cadre",
> "65-Femme-Cadre", "65-Femme-Non Cadre", "65-Homme-Cadre", "65-Homme-Non
> Cadre",
> "66-Femme-Cadre", "66-Femme-Non Cadre", "66-Homme-Cadre", "66-Homme-Non
> Cadre",
> "67-Femme-Cadre", "67-Femme-Non Cadre", "67-Homme-Cadre", "67-Homme-Non
> Cadre",
> "68-Femme-Cadre", "68-Femme-Non Cadre", "68-Homme-Cadre", "68-Homme-Non
> Cadre"
> ), class = "factor"), Pourcent = c(0.157849638357511, 0.157849638357511,
> 0.0562149664637629, 0.419279916358023, 0.180720729132166,
> 0.180720729132166,
> 0.092720981524322, 0.272158156192425, 0.145668562090518, 0.145668562090518,
> 0.101319648271574, 0.159207521192769, 0.0997898095090109,
> 0.0997898095090109,
> 0.110753346057845, 0.0193586234067497, 0.0795236495990374,
> 0.0795236495990374,
> 0.18014205547984, 0.00968491550180694, 0.0750838561972432,
> 0.0750838561972432,
> 0.237072554382218, 0.0650665901855087, 0.0587392216209752,
> 0.0587392216209752,
> 0.126427289344211, 0.00961707878904615, 0.0409034699088397,
> 0.0409034699088397,
> 0.0537806700836756, 3.11172383820597e-05, 0.0285360029533433,
> 0.0285360029533433, 0.0220930854712636, 2.20203747900568e-09)), .Names =
> c("AgeSexeCadNCad",
> "Pourcent"), row.names = c(28L, 19L, 10L, 1L, 29L, 20L, 11L,
> 2L, 30L, 21L, 12L, 3L, 31L, 22L, 13L, 4L, 32L, 23L, 14L, 5L,
> 33L, 24L, 15L, 6L, 34L, 25L, 16L, 7L, 35L, 26L, 17L, 8L, 36L,
> 27L, 18L, 9L), class = "data.frame")
>
> Df2 <- structure(list(Matricule = c(410, 453, 501, 544, 653, 765, 833,
> 851, 927, 1050, 1074, 1278, 1379, 1428, 359, 379, 408, 417, 424,
> 426, 483, 490, 528, 538, 567, 596, 603, 604, 647, 675, 677, 681,
> 735, 743, 787, 817, 823, 896, 917, 1071, 1144, 1157, 1823, 2497,
> 2868, 3556, 3614, 3632, 3646, 3656, 3660, 4162, 4503, 4711, 5531,
> 330, 447, 467, 546, 627, 637, 780, 892, 1487, 1492, 3324, 4873,
> 409, 415, 441, 579, 619, 697, 716, 719, 728, 737, 807, 832, 989,
> 1299, 1320, 1352, 1427, 1484, 1548, 2447, 2914, 2929, 2941, 3524,
> 3527, 3631, 4324, 400, 572, 1095, 1097, 1105, 2966, 392, 418,
> 440, 457, 466, 472, 488, 491, 506, 533, 543, 547, 552, 553, 920,
> 1034, 1179, 1454, 1485, 1540, 3620, 4672, 13899, 342, 1089, 1208,
> 1234, 2153, 3545, 253, 504, 529, 558, 578, 745, 933, 935, 2099,
> 16785, 356, 460, 634, 959, 1429, 1591, 1720, 3602, 3644, 322,
> 361, 404, 430, 525, 706, 804, 1010, 1012, 1108, 1185, 1294, 2264,
> 3567, 3633, 4990, 264, 298, 352, 388, 503, 508, 691, 1509, 2192,
> 3060, 3683, 877, 1130, 1963, 188, 327, 331, 363, 437, 445, 462,
> 723, 1259, 1381, 3617, 427, 1402, 3624, 141, 256, 308, 377, 414,
> 640, 157, 560), AgeSexeCadNCad = c("60-Femme-Non Cadre", "60-Femme-Non
> Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "62-Femme-Non Cadre",
> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Femme-Non Cadre",
> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
> "63-Femme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
> "63-Femme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "66-Femme-Non Cadre",
> "66-Femme-Non Cadre", "66-Femme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "67-Homme-Non Cadre", "67-Homme-Non Cadre",
> "67-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
> "68-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
> "68-Homme-Non Cadre", "69-Homme-Non Cadre", "69-Homme-Non Cadre"
> )), .Names = c("Matricule", "AgeSexeCadNCad"), class = "data.frame",
> row.names = c("37",
> "58", "79", "104", "163", "220", "263", "276", "333", "422",
> "442", "587", "653", "684", "21", "25", "35", "42", "45", "47",
> "73", "76", "93", "100", "118", "133", "137", "138", "158", "174",
> "176", "179", "204", "208", "231", "249", "254", "312", "325",
> "439", "491", "500", "825", "928", "954", "1093", "1116", "1128",
> "1136", "1141", "1143", "1212", "1232", "1270", "1396", "14",
> "56", "66", "106", "148", "153", "226", "308", "717", "720",
> "1046", "1287", "36", "41", "54", "124", "144", "188", "197",
> "198", "201", "206", "242", "262", "377", "598", "611", "633",
> "683", "714", "742", "919", "980", "993", "1000", "1071", "1073",
> "1127", "1223", "32", "121", "456", "458", "462", "1013", "27",
> "43", "53", "59", "65", "67", "75", "77", "83", "97", "103",
> "107", "109", "110", "328", "412", "516", "698", "715", "740",
> "1122", "1267", "1824", "16", "452", "540", "557", "870", "1086",
> "5", "82", "94", "115", "123", "209", "339", "341", "862", "2211",
> "20", "61", "152", "358", "685", "760", "803", "1111", "1134",
> "11", "22", "33", "49", "92", "193", "241", "394", "396", "463",
> "522", "595", "896", "1097", "1129", "1302", "7", "9", "18",
> "26", "81", "85", "185", "728", "884", "1029", "1155", "297",
> "479", "842", "3", "13", "15", "23", "51", "55", "63", "199",
> "574", "655", "1119", "48", "668", "1125", "1", "6", "10", "24",
> "40", "154", "2", "117"))
>
>
>


From ruipbarradas at sapo.pt  Fri Sep 19 19:45:55 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 19 Sep 2014 18:45:55 +0100
Subject: [R] To Add a variable from Df1 to Df2 which have a same common
 variable
In-Reply-To: <541C6A65.9050500@sapo.pt>
References: <541C64A6.4070902@cirad.fr> <541C6A65.9050500@sapo.pt>
Message-ID: <541C6BD3.4040409@sapo.pt>

You might also want to try argument all.x:

Df3 <- merge(Df2, Df1, by = "AgeSexeCadNCad", all.x = TRUE)

This is because there are 2 rows in Df2 without a corresponding 
'AgeSexeCadNCad' in Df1.

Rui Barradas

Em 19-09-2014 18:39, Rui Barradas escreveu:
> Hello,
>
> Try ?merge:
>
> Df3 <- merge(Df2, Df1, by = "AgeSexeCadNCad")
>
> Hope this helps,
>
> Rui Barradas
>
> Em 19-09-2014 18:15, Arnaud Michel escreveu:
>> Hello
>> I have the two dataframes Df1 and Df2 which have the common variable
>> AgeSexeCadNCad
>> I would like to add the new variable Df2$Pourcent which correspond at
>> the value of Df1$AgeSexeCadNCad.
>> Thank you for your help.
>> Michel
>>
>> Df1 <- structure(list(AgeSexeCadNCad = structure(1:36, .Label =
>> c("60-Femme-Cadre",
>> "60-Femme-Non Cadre", "60-Homme-Cadre", "60-Homme-Non Cadre",
>> "61-Femme-Cadre", "61-Femme-Non Cadre", "61-Homme-Cadre", "61-Homme-Non
>> Cadre",
>> "62-Femme-Cadre", "62-Femme-Non Cadre", "62-Homme-Cadre", "62-Homme-Non
>> Cadre",
>> "63-Femme-Cadre", "63-Femme-Non Cadre", "63-Homme-Cadre", "63-Homme-Non
>> Cadre",
>> "64-Femme-Cadre", "64-Femme-Non Cadre", "64-Homme-Cadre", "64-Homme-Non
>> Cadre",
>> "65-Femme-Cadre", "65-Femme-Non Cadre", "65-Homme-Cadre", "65-Homme-Non
>> Cadre",
>> "66-Femme-Cadre", "66-Femme-Non Cadre", "66-Homme-Cadre", "66-Homme-Non
>> Cadre",
>> "67-Femme-Cadre", "67-Femme-Non Cadre", "67-Homme-Cadre", "67-Homme-Non
>> Cadre",
>> "68-Femme-Cadre", "68-Femme-Non Cadre", "68-Homme-Cadre", "68-Homme-Non
>> Cadre"
>> ), class = "factor"), Pourcent = c(0.157849638357511, 0.157849638357511,
>> 0.0562149664637629, 0.419279916358023, 0.180720729132166,
>> 0.180720729132166,
>> 0.092720981524322, 0.272158156192425, 0.145668562090518,
>> 0.145668562090518,
>> 0.101319648271574, 0.159207521192769, 0.0997898095090109,
>> 0.0997898095090109,
>> 0.110753346057845, 0.0193586234067497, 0.0795236495990374,
>> 0.0795236495990374,
>> 0.18014205547984, 0.00968491550180694, 0.0750838561972432,
>> 0.0750838561972432,
>> 0.237072554382218, 0.0650665901855087, 0.0587392216209752,
>> 0.0587392216209752,
>> 0.126427289344211, 0.00961707878904615, 0.0409034699088397,
>> 0.0409034699088397,
>> 0.0537806700836756, 3.11172383820597e-05, 0.0285360029533433,
>> 0.0285360029533433, 0.0220930854712636, 2.20203747900568e-09)), .Names =
>> c("AgeSexeCadNCad",
>> "Pourcent"), row.names = c(28L, 19L, 10L, 1L, 29L, 20L, 11L,
>> 2L, 30L, 21L, 12L, 3L, 31L, 22L, 13L, 4L, 32L, 23L, 14L, 5L,
>> 33L, 24L, 15L, 6L, 34L, 25L, 16L, 7L, 35L, 26L, 17L, 8L, 36L,
>> 27L, 18L, 9L), class = "data.frame")
>>
>> Df2 <- structure(list(Matricule = c(410, 453, 501, 544, 653, 765, 833,
>> 851, 927, 1050, 1074, 1278, 1379, 1428, 359, 379, 408, 417, 424,
>> 426, 483, 490, 528, 538, 567, 596, 603, 604, 647, 675, 677, 681,
>> 735, 743, 787, 817, 823, 896, 917, 1071, 1144, 1157, 1823, 2497,
>> 2868, 3556, 3614, 3632, 3646, 3656, 3660, 4162, 4503, 4711, 5531,
>> 330, 447, 467, 546, 627, 637, 780, 892, 1487, 1492, 3324, 4873,
>> 409, 415, 441, 579, 619, 697, 716, 719, 728, 737, 807, 832, 989,
>> 1299, 1320, 1352, 1427, 1484, 1548, 2447, 2914, 2929, 2941, 3524,
>> 3527, 3631, 4324, 400, 572, 1095, 1097, 1105, 2966, 392, 418,
>> 440, 457, 466, 472, 488, 491, 506, 533, 543, 547, 552, 553, 920,
>> 1034, 1179, 1454, 1485, 1540, 3620, 4672, 13899, 342, 1089, 1208,
>> 1234, 2153, 3545, 253, 504, 529, 558, 578, 745, 933, 935, 2099,
>> 16785, 356, 460, 634, 959, 1429, 1591, 1720, 3602, 3644, 322,
>> 361, 404, 430, 525, 706, 804, 1010, 1012, 1108, 1185, 1294, 2264,
>> 3567, 3633, 4990, 264, 298, 352, 388, 503, 508, 691, 1509, 2192,
>> 3060, 3683, 877, 1130, 1963, 188, 327, 331, 363, 437, 445, 462,
>> 723, 1259, 1381, 3617, 427, 1402, 3624, 141, 256, 308, 377, 414,
>> 640, 157, 560), AgeSexeCadNCad = c("60-Femme-Non Cadre", "60-Femme-Non
>> Cadre",
>> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "61-Femme-Non Cadre",
>> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
>> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
>> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
>> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "62-Femme-Non Cadre",
>> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Femme-Non Cadre",
>> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
>> "63-Femme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
>> "63-Femme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
>> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
>> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
>> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "64-Femme-Non Cadre",
>> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
>> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
>> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
>> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
>> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
>> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "66-Femme-Non Cadre",
>> "66-Femme-Non Cadre", "66-Femme-Non Cadre", "66-Homme-Non Cadre",
>> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
>> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
>> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
>> "66-Homme-Non Cadre", "67-Homme-Non Cadre", "67-Homme-Non Cadre",
>> "67-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
>> "68-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
>> "68-Homme-Non Cadre", "69-Homme-Non Cadre", "69-Homme-Non Cadre"
>> )), .Names = c("Matricule", "AgeSexeCadNCad"), class = "data.frame",
>> row.names = c("37",
>> "58", "79", "104", "163", "220", "263", "276", "333", "422",
>> "442", "587", "653", "684", "21", "25", "35", "42", "45", "47",
>> "73", "76", "93", "100", "118", "133", "137", "138", "158", "174",
>> "176", "179", "204", "208", "231", "249", "254", "312", "325",
>> "439", "491", "500", "825", "928", "954", "1093", "1116", "1128",
>> "1136", "1141", "1143", "1212", "1232", "1270", "1396", "14",
>> "56", "66", "106", "148", "153", "226", "308", "717", "720",
>> "1046", "1287", "36", "41", "54", "124", "144", "188", "197",
>> "198", "201", "206", "242", "262", "377", "598", "611", "633",
>> "683", "714", "742", "919", "980", "993", "1000", "1071", "1073",
>> "1127", "1223", "32", "121", "456", "458", "462", "1013", "27",
>> "43", "53", "59", "65", "67", "75", "77", "83", "97", "103",
>> "107", "109", "110", "328", "412", "516", "698", "715", "740",
>> "1122", "1267", "1824", "16", "452", "540", "557", "870", "1086",
>> "5", "82", "94", "115", "123", "209", "339", "341", "862", "2211",
>> "20", "61", "152", "358", "685", "760", "803", "1111", "1134",
>> "11", "22", "33", "49", "92", "193", "241", "394", "396", "463",
>> "522", "595", "896", "1097", "1129", "1302", "7", "9", "18",
>> "26", "81", "85", "185", "728", "884", "1029", "1155", "297",
>> "479", "842", "3", "13", "15", "23", "51", "55", "63", "199",
>> "574", "655", "1119", "48", "668", "1125", "1", "6", "10", "24",
>> "40", "154", "2", "117"))
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri Sep 19 19:46:23 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 19 Sep 2014 12:46:23 -0500
Subject: [R] To Add a variable from Df1 to Df2 which have a same
	common	variable
In-Reply-To: <541C64A6.4070902@cirad.fr>
References: <541C64A6.4070902@cirad.fr>
Message-ID: <DB5C2BD6-B617-468F-9141-F8991F3F770D@me.com>


On Sep 19, 2014, at 12:15 PM, Arnaud Michel <michel.arnaud at cirad.fr> wrote:

> Hello
> I have the two dataframes Df1 and Df2 which have the common variable AgeSexeCadNCad
> I would like to add the new variable Df2$Pourcent which correspond at the value of Df1$AgeSexeCadNCad.
> Thank you for your help.
> Michel
> 
> Df1 <- structure(list(AgeSexeCadNCad = structure(1:36, .Label = c("60-Femme-Cadre",
> "60-Femme-Non Cadre", "60-Homme-Cadre", "60-Homme-Non Cadre",
> "61-Femme-Cadre", "61-Femme-Non Cadre", "61-Homme-Cadre", "61-Homme-Non Cadre",
> "62-Femme-Cadre", "62-Femme-Non Cadre", "62-Homme-Cadre", "62-Homme-Non Cadre",
> "63-Femme-Cadre", "63-Femme-Non Cadre", "63-Homme-Cadre", "63-Homme-Non Cadre",
> "64-Femme-Cadre", "64-Femme-Non Cadre", "64-Homme-Cadre", "64-Homme-Non Cadre",
> "65-Femme-Cadre", "65-Femme-Non Cadre", "65-Homme-Cadre", "65-Homme-Non Cadre",
> "66-Femme-Cadre", "66-Femme-Non Cadre", "66-Homme-Cadre", "66-Homme-Non Cadre",
> "67-Femme-Cadre", "67-Femme-Non Cadre", "67-Homme-Cadre", "67-Homme-Non Cadre",
> "68-Femme-Cadre", "68-Femme-Non Cadre", "68-Homme-Cadre", "68-Homme-Non Cadre"
> ), class = "factor"), Pourcent = c(0.157849638357511, 0.157849638357511,
> 0.0562149664637629, 0.419279916358023, 0.180720729132166, 0.180720729132166,
> 0.092720981524322, 0.272158156192425, 0.145668562090518, 0.145668562090518,
> 0.101319648271574, 0.159207521192769, 0.0997898095090109, 0.0997898095090109,
> 0.110753346057845, 0.0193586234067497, 0.0795236495990374, 0.0795236495990374,
> 0.18014205547984, 0.00968491550180694, 0.0750838561972432, 0.0750838561972432,
> 0.237072554382218, 0.0650665901855087, 0.0587392216209752, 0.0587392216209752,
> 0.126427289344211, 0.00961707878904615, 0.0409034699088397, 0.0409034699088397,
> 0.0537806700836756, 3.11172383820597e-05, 0.0285360029533433,
> 0.0285360029533433, 0.0220930854712636, 2.20203747900568e-09)), .Names = c("AgeSexeCadNCad",
> "Pourcent"), row.names = c(28L, 19L, 10L, 1L, 29L, 20L, 11L,
> 2L, 30L, 21L, 12L, 3L, 31L, 22L, 13L, 4L, 32L, 23L, 14L, 5L,
> 33L, 24L, 15L, 6L, 34L, 25L, 16L, 7L, 35L, 26L, 17L, 8L, 36L,
> 27L, 18L, 9L), class = "data.frame")
> 
> Df2 <- structure(list(Matricule = c(410, 453, 501, 544, 653, 765, 833,
> 851, 927, 1050, 1074, 1278, 1379, 1428, 359, 379, 408, 417, 424,
> 426, 483, 490, 528, 538, 567, 596, 603, 604, 647, 675, 677, 681,
> 735, 743, 787, 817, 823, 896, 917, 1071, 1144, 1157, 1823, 2497,
> 2868, 3556, 3614, 3632, 3646, 3656, 3660, 4162, 4503, 4711, 5531,
> 330, 447, 467, 546, 627, 637, 780, 892, 1487, 1492, 3324, 4873,
> 409, 415, 441, 579, 619, 697, 716, 719, 728, 737, 807, 832, 989,
> 1299, 1320, 1352, 1427, 1484, 1548, 2447, 2914, 2929, 2941, 3524,
> 3527, 3631, 4324, 400, 572, 1095, 1097, 1105, 2966, 392, 418,
> 440, 457, 466, 472, 488, 491, 506, 533, 543, 547, 552, 553, 920,
> 1034, 1179, 1454, 1485, 1540, 3620, 4672, 13899, 342, 1089, 1208,
> 1234, 2153, 3545, 253, 504, 529, 558, 578, 745, 933, 935, 2099,
> 16785, 356, 460, 634, 959, 1429, 1591, 1720, 3602, 3644, 322,
> 361, 404, 430, 525, 706, 804, 1010, 1012, 1108, 1185, 1294, 2264,
> 3567, 3633, 4990, 264, 298, 352, 388, 503, 508, 691, 1509, 2192,
> 3060, 3683, 877, 1130, 1963, 188, 327, 331, 363, 437, 445, 462,
> 723, 1259, 1381, 3617, 427, 1402, 3624, 141, 256, 308, 377, 414,
> 640, 157, 560), AgeSexeCadNCad = c("60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "62-Femme-Non Cadre",
> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Femme-Non Cadre",
> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
> "62-Homme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
> "63-Femme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
> "63-Femme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "66-Femme-Non Cadre",
> "66-Femme-Non Cadre", "66-Femme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
> "66-Homme-Non Cadre", "67-Homme-Non Cadre", "67-Homme-Non Cadre",
> "67-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
> "68-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
> "68-Homme-Non Cadre", "69-Homme-Non Cadre", "69-Homme-Non Cadre"
> )), .Names = c("Matricule", "AgeSexeCadNCad"), class = "data.frame", row.names = c("37",
> "58", "79", "104", "163", "220", "263", "276", "333", "422",
> "442", "587", "653", "684", "21", "25", "35", "42", "45", "47",
> "73", "76", "93", "100", "118", "133", "137", "138", "158", "174",
> "176", "179", "204", "208", "231", "249", "254", "312", "325",
> "439", "491", "500", "825", "928", "954", "1093", "1116", "1128",
> "1136", "1141", "1143", "1212", "1232", "1270", "1396", "14",
> "56", "66", "106", "148", "153", "226", "308", "717", "720",
> "1046", "1287", "36", "41", "54", "124", "144", "188", "197",
> "198", "201", "206", "242", "262", "377", "598", "611", "633",
> "683", "714", "742", "919", "980", "993", "1000", "1071", "1073",
> "1127", "1223", "32", "121", "456", "458", "462", "1013", "27",
> "43", "53", "59", "65", "67", "75", "77", "83", "97", "103",
> "107", "109", "110", "328", "412", "516", "698", "715", "740",
> "1122", "1267", "1824", "16", "452", "540", "557", "870", "1086",
> "5", "82", "94", "115", "123", "209", "339", "341", "862", "2211",
> "20", "61", "152", "358", "685", "760", "803", "1111", "1134",
> "11", "22", "33", "49", "92", "193", "241", "394", "396", "463",
> "522", "595", "896", "1097", "1129", "1302", "7", "9", "18",
> "26", "81", "85", "185", "728", "884", "1029", "1155", "297",
> "479", "842", "3", "13", "15", "23", "51", "55", "63", "199",
> "574", "655", "1119", "48", "668", "1125", "1", "6", "10", "24",
> "40", "154", "2", "117"))


Hi,

Thanks for including data.

See ?merge, which performs an SQL-like join.

Since you have non-matching values between Df1 and Df2, you will need to decide if you want non-matching rows included in the resultant data frame or not (eg. a right/left outer or inner join). See the all, all.x and all.y arguments to merge(). 

The default (all = FALSE) is an inner join on matching rows only:

  Df3 <- merge(Df1, Df2, by = "AgeSexeCadNCad")

If you include non-matching values in the resultant data frame (eg. all = TRUE), Pourcent will contains NA's in those rows.

Regards,

Marc Schwartz


From jwd at surewest.net  Fri Sep 19 19:44:00 2014
From: jwd at surewest.net (jwd)
Date: Fri, 19 Sep 2014 10:44:00 -0700
Subject: [R] =?utf-8?b?Ui9VYnVudHUsIOKAnHBhY2thZ2Ug4oCYc3RhdHPigJkgaW4g?=
 =?utf-8?q?options=28=E2=80=9DdefaultPackages=E2=80=9C=29_was_not_found?=
 =?utf-8?b?4oCd?=
In-Reply-To: <CAK7YrFWOf2emtXw=ZrxFgdW_cQ5Mmz3gGeLySvPU+rEDDn9VRQ@mail.gmail.com>
References: <CAK7YrFVU2aTJpDfptmPgCqEW4pLo93YpsgzBRTyY7mriHaEh7g@mail.gmail.com>
	<02DB59A6-8284-4D41-8994-0D4CEC8A5E8A@comcast.net>
	<CAK7YrFWnu2fW314azzjLA3QdL_UdZ+_WbW80g2wJzKtDz3DegQ@mail.gmail.com>
	<9c4c518e-7678-4d91-bd7d-49b3dd811a46@email.android.com>
	<CAK7YrFUS8Z9X8xq0=DxZxh3+NMKRN5G1QcCc7WbxdGX04eaBFQ@mail.gmail.com>
	<6cec176b-4601-4141-b079-94cce61ab5f8@email.android.com>
	<CAK7YrFWOf2emtXw=ZrxFgdW_cQ5Mmz3gGeLySvPU+rEDDn9VRQ@mail.gmail.com>
Message-ID: <20140919104400.0b8314bc@draco>

On Thu, 18 Sep 2014 10:28:42 -0400
"davide.chicco at gmail.com" <davide.chicco at gmail.com> wrote:

> I tried with a different mirror, but nothing changed...
> 
> Any other idea?
> 
> Thanks anyway
> 
> -- Davide

What is the output of library()?

JWDougherty


From bhh at xs4all.nl  Fri Sep 19 20:18:21 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 19 Sep 2014 20:18:21 +0200
Subject: [R] Failure with .Rprofile on Mac OS X
In-Reply-To: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>
References: <CAHmzXO6UT7=Fw6ifsyBB0pjujMS467uXgmD3SfQHhx3ART49sw@mail.gmail.com>
Message-ID: <3FF84A19-0310-4EB8-BE66-50811EE83456@xs4all.nl>


On 18-09-2014, at 17:18, Gang Chen <gangchen6 at gmail.com> wrote:

> When R starts in GUI (e.g.,/Library/Frameworks/R.framework/Resources/bin/R) on
> my Mac OS X 10.7.5, the startup configuration in .Rprofile works fine.
> However, when R starts on the terminal (e.g.,
> /Library/Frameworks/R.framework/Resources/bin/R), it does not work at
> all. What could be the reason for the failure?
> 

This belongs on the R-SIG-Mac mailing list.

1. Are you running T in Terminal with the command "/Library/Frameworks/R.framework/Resources/bin/R??
You can use just R because /usr/bin is in PATH (or it should be).

2. Are you running R GUI with the command "/Applications/R.app/Contents/MacOS/R??
From Terminal? if so use open -a R.

3. Most importantly: what differences are happening? Differences in PATH environment variable? ?..

I just tried R GUI and R in Terminal and my ~/.Rprofile is being read by both.

Berend

> Thanks,
> Gang
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michel.arnaud at cirad.fr  Fri Sep 19 20:53:40 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Fri, 19 Sep 2014 20:53:40 +0200
Subject: [R] To Add a variable from Df1 to Df2 which have a same common
 variable
In-Reply-To: <DB5C2BD6-B617-468F-9141-F8991F3F770D@me.com>
References: <541C64A6.4070902@cirad.fr>
	<DB5C2BD6-B617-468F-9141-F8991F3F770D@me.com>
Message-ID: <541C7BB4.2030904@cirad.fr>

Thank you to Marc Schwartz, Rui Barrada and Sarah Goslee
Michel
Le 19/09/2014 19:46, Marc Schwartz a ?crit :
> On Sep 19, 2014, at 12:15 PM, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>
>> Hello
>> I have the two dataframes Df1 and Df2 which have the common variable AgeSexeCadNCad
>> I would like to add the new variable Df2$Pourcent which correspond at the value of Df1$AgeSexeCadNCad.
>> Thank you for your help.
>> Michel
>>
>> Df1 <- structure(list(AgeSexeCadNCad = structure(1:36, .Label = c("60-Femme-Cadre",
>> "60-Femme-Non Cadre", "60-Homme-Cadre", "60-Homme-Non Cadre",
>> "61-Femme-Cadre", "61-Femme-Non Cadre", "61-Homme-Cadre", "61-Homme-Non Cadre",
>> "62-Femme-Cadre", "62-Femme-Non Cadre", "62-Homme-Cadre", "62-Homme-Non Cadre",
>> "63-Femme-Cadre", "63-Femme-Non Cadre", "63-Homme-Cadre", "63-Homme-Non Cadre",
>> "64-Femme-Cadre", "64-Femme-Non Cadre", "64-Homme-Cadre", "64-Homme-Non Cadre",
>> "65-Femme-Cadre", "65-Femme-Non Cadre", "65-Homme-Cadre", "65-Homme-Non Cadre",
>> "66-Femme-Cadre", "66-Femme-Non Cadre", "66-Homme-Cadre", "66-Homme-Non Cadre",
>> "67-Femme-Cadre", "67-Femme-Non Cadre", "67-Homme-Cadre", "67-Homme-Non Cadre",
>> "68-Femme-Cadre", "68-Femme-Non Cadre", "68-Homme-Cadre", "68-Homme-Non Cadre"
>> ), class = "factor"), Pourcent = c(0.157849638357511, 0.157849638357511,
>> 0.0562149664637629, 0.419279916358023, 0.180720729132166, 0.180720729132166,
>> 0.092720981524322, 0.272158156192425, 0.145668562090518, 0.145668562090518,
>> 0.101319648271574, 0.159207521192769, 0.0997898095090109, 0.0997898095090109,
>> 0.110753346057845, 0.0193586234067497, 0.0795236495990374, 0.0795236495990374,
>> 0.18014205547984, 0.00968491550180694, 0.0750838561972432, 0.0750838561972432,
>> 0.237072554382218, 0.0650665901855087, 0.0587392216209752, 0.0587392216209752,
>> 0.126427289344211, 0.00961707878904615, 0.0409034699088397, 0.0409034699088397,
>> 0.0537806700836756, 3.11172383820597e-05, 0.0285360029533433,
>> 0.0285360029533433, 0.0220930854712636, 2.20203747900568e-09)), .Names = c("AgeSexeCadNCad",
>> "Pourcent"), row.names = c(28L, 19L, 10L, 1L, 29L, 20L, 11L,
>> 2L, 30L, 21L, 12L, 3L, 31L, 22L, 13L, 4L, 32L, 23L, 14L, 5L,
>> 33L, 24L, 15L, 6L, 34L, 25L, 16L, 7L, 35L, 26L, 17L, 8L, 36L,
>> 27L, 18L, 9L), class = "data.frame")
>>
>> Df2 <- structure(list(Matricule = c(410, 453, 501, 544, 653, 765, 833,
>> 851, 927, 1050, 1074, 1278, 1379, 1428, 359, 379, 408, 417, 424,
>> 426, 483, 490, 528, 538, 567, 596, 603, 604, 647, 675, 677, 681,
>> 735, 743, 787, 817, 823, 896, 917, 1071, 1144, 1157, 1823, 2497,
>> 2868, 3556, 3614, 3632, 3646, 3656, 3660, 4162, 4503, 4711, 5531,
>> 330, 447, 467, 546, 627, 637, 780, 892, 1487, 1492, 3324, 4873,
>> 409, 415, 441, 579, 619, 697, 716, 719, 728, 737, 807, 832, 989,
>> 1299, 1320, 1352, 1427, 1484, 1548, 2447, 2914, 2929, 2941, 3524,
>> 3527, 3631, 4324, 400, 572, 1095, 1097, 1105, 2966, 392, 418,
>> 440, 457, 466, 472, 488, 491, 506, 533, 543, 547, 552, 553, 920,
>> 1034, 1179, 1454, 1485, 1540, 3620, 4672, 13899, 342, 1089, 1208,
>> 1234, 2153, 3545, 253, 504, 529, 558, 578, 745, 933, 935, 2099,
>> 16785, 356, 460, 634, 959, 1429, 1591, 1720, 3602, 3644, 322,
>> 361, 404, 430, 525, 706, 804, 1010, 1012, 1108, 1185, 1294, 2264,
>> 3567, 3633, 4990, 264, 298, 352, 388, 503, 508, 691, 1509, 2192,
>> 3060, 3683, 877, 1130, 1963, 188, 327, 331, 363, 437, 445, 462,
>> 723, 1259, 1381, 3617, 427, 1402, 3624, 141, 256, 308, 377, 414,
>> 640, 157, 560), AgeSexeCadNCad = c("60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Femme-Non Cadre", "60-Femme-Non Cadre", "60-Femme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "60-Homme-Non Cadre",
>> "60-Homme-Non Cadre", "60-Homme-Non Cadre", "61-Femme-Non Cadre",
>> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
>> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
>> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Femme-Non Cadre",
>> "61-Femme-Non Cadre", "61-Femme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "61-Homme-Non Cadre",
>> "61-Homme-Non Cadre", "61-Homme-Non Cadre", "62-Femme-Non Cadre",
>> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Femme-Non Cadre",
>> "62-Femme-Non Cadre", "62-Femme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "62-Homme-Non Cadre", "62-Homme-Non Cadre",
>> "62-Homme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
>> "63-Femme-Non Cadre", "63-Femme-Non Cadre", "63-Femme-Non Cadre",
>> "63-Femme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
>> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
>> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "63-Homme-Non Cadre",
>> "63-Homme-Non Cadre", "63-Homme-Non Cadre", "64-Femme-Non Cadre",
>> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
>> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Femme-Non Cadre",
>> "64-Femme-Non Cadre", "64-Femme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "64-Homme-Non Cadre", "64-Homme-Non Cadre", "64-Homme-Non Cadre",
>> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
>> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
>> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "65-Homme-Non Cadre",
>> "65-Homme-Non Cadre", "65-Homme-Non Cadre", "66-Femme-Non Cadre",
>> "66-Femme-Non Cadre", "66-Femme-Non Cadre", "66-Homme-Non Cadre",
>> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
>> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
>> "66-Homme-Non Cadre", "66-Homme-Non Cadre", "66-Homme-Non Cadre",
>> "66-Homme-Non Cadre", "67-Homme-Non Cadre", "67-Homme-Non Cadre",
>> "67-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
>> "68-Homme-Non Cadre", "68-Homme-Non Cadre", "68-Homme-Non Cadre",
>> "68-Homme-Non Cadre", "69-Homme-Non Cadre", "69-Homme-Non Cadre"
>> )), .Names = c("Matricule", "AgeSexeCadNCad"), class = "data.frame", row.names = c("37",
>> "58", "79", "104", "163", "220", "263", "276", "333", "422",
>> "442", "587", "653", "684", "21", "25", "35", "42", "45", "47",
>> "73", "76", "93", "100", "118", "133", "137", "138", "158", "174",
>> "176", "179", "204", "208", "231", "249", "254", "312", "325",
>> "439", "491", "500", "825", "928", "954", "1093", "1116", "1128",
>> "1136", "1141", "1143", "1212", "1232", "1270", "1396", "14",
>> "56", "66", "106", "148", "153", "226", "308", "717", "720",
>> "1046", "1287", "36", "41", "54", "124", "144", "188", "197",
>> "198", "201", "206", "242", "262", "377", "598", "611", "633",
>> "683", "714", "742", "919", "980", "993", "1000", "1071", "1073",
>> "1127", "1223", "32", "121", "456", "458", "462", "1013", "27",
>> "43", "53", "59", "65", "67", "75", "77", "83", "97", "103",
>> "107", "109", "110", "328", "412", "516", "698", "715", "740",
>> "1122", "1267", "1824", "16", "452", "540", "557", "870", "1086",
>> "5", "82", "94", "115", "123", "209", "339", "341", "862", "2211",
>> "20", "61", "152", "358", "685", "760", "803", "1111", "1134",
>> "11", "22", "33", "49", "92", "193", "241", "394", "396", "463",
>> "522", "595", "896", "1097", "1129", "1302", "7", "9", "18",
>> "26", "81", "85", "185", "728", "884", "1029", "1155", "297",
>> "479", "842", "3", "13", "15", "23", "51", "55", "63", "199",
>> "574", "655", "1119", "48", "668", "1125", "1", "6", "10", "24",
>> "40", "154", "2", "117"))
>
> Hi,
>
> Thanks for including data.
>
> See ?merge, which performs an SQL-like join.
>
> Since you have non-matching values between Df1 and Df2, you will need to decide if you want non-matching rows included in the resultant data frame or not (eg. a right/left outer or inner join). See the all, all.x and all.y arguments to merge().
>
> The default (all = FALSE) is an inner join on matching rows only:
>
>    Df3 <- merge(Df1, Df2, by = "AgeSexeCadNCad")
>
> If you include non-matching values in the resultant data frame (eg. all = TRUE), Pourcent will contains NA's in those rows.
>
> Regards,
>
> Marc Schwartz
>
>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From evan.cooch at gmail.com  Fri Sep 19 17:34:46 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 19 Sep 2014 11:34:46 -0400
Subject: [R] optim, L-BFGS-B | constrained bounds on parms?
In-Reply-To: <541C4C95.7080902@uottawa.ca>
References: <mailman.23.1411120807.23892.r-help@r-project.org>
	<541C4C95.7080902@uottawa.ca>
Message-ID: <541C4D16.9080905@gmail.com>



On 9/19/2014 11:32 AM, Prof J C Nash (U30A) wrote:
> One choice is to add a penalty to the objective to enforce the
> constraint(s) along with bounds to keep the parameters from going wild.
>
> This generally works reasonably well. Sometimes it helps to run just a
> few iterations with a big penalty scale to force the parameters into a
> feasible region, though a lot depends on the particular problem in my
> experience, with some being straightforward and others needing a lot of
> fiddle.
>
> I suspect a math programming approach is overkill, though R does have
> some packages for that. Your mileage may vary.
>
> Note that L-BFGS-B used by R is a version for which Nocedal et al.
> reported a bug in 2011 and provided a new Fortran code. I've recently
> put up an implementation of the new code on r-forge under the optimizer
> project. Still testing, but I think it's OK. You could also use Rvmmin
> that has bounds, or nmkb from dfoptim (though you cannot start on bounds).
>
> Best, JN
>

Thanks very much. I've found that for most of my current problems, 
optimx is working well, but there are trade-offs. Good to have multiple 
options in the toolkit.

Cheers...


From jacksonjordancm at gmail.com  Fri Sep 19 16:10:20 2014
From: jacksonjordancm at gmail.com (Chris Jackson-Jordan)
Date: Fri, 19 Sep 2014 10:10:20 -0400
Subject: [R] Error in rownames
Message-ID: <CAPtX2qmikCozPmLQXWgWfO35aBV3yD0XsCwoOvdQ_tC-ukhajg@mail.gmail.com>

Dear fellow R users,

I am trying to run the random forest and Yaimpute packages in R to
impute a grid to project in a gis. However, after running the
imputation I keep getting an error in the rownames. This sounds simple
enough, but I cannot figure out what these rownames are reffering to.
Any ideas? I am fairly new to R so im sure it is an easy fix. Any help
would be awesome.

Thanks,

Chris


> training <- read.csv("D:/R_Desktop_Data/RF_RespSurf/RndmPts_RespSurfMIII.csv")> y <- subset(training, select = c(ResponseSu))> x <- subset(training, select = c(sinaspect, habitat, slope, elevation, cosaspect, disttoroad, disttowat))> type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression", ntree= 2000)> outfile <- list(Type = "D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc")> xfile <-list(sinaspect ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/sinaspect.asc", habitat ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/habitat.asc", elevation ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/elevation.asc", disttowat ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttowat.asc", disttoroad ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttoroad.asc", slope ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/slope.asc", cosaspect ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/cosaspect.asc")> AsciiGridImpute(type.rf, xfile, outfile)Rows per dot:  19  Rows to do: 1900
ToDo: ....................................................................................................
Done: .Error in `rownames<-`(`*tmp*`, value = c("23x0049", "23x0050",
"23x0051",  :
  attempt to set rownames on object with no dimensions

	[[alternative HTML version deleted]]


From bannert at kof.ethz.ch  Fri Sep 19 16:36:51 2014
From: bannert at kof.ethz.ch (Bannert  Matthias)
Date: Fri, 19 Sep 2014 14:36:51 +0000
Subject: [R] Propensity Score Matching with Restrictions (Matching package)
Message-ID: <8586FCA42D306C4DB0BD46EF9F1B580236E2A3DA@MBX110.d.ethz.ch>

Dear listers,

I am using Jas Sekhon's Matching package to perform propensity score matching and like it a lot so far.
Still though I wonder whether it is possible to impose restrictions on the Matching. I've seen the restriction parameter, but I doubt this is what I want (or I don't get how to use it more neatly).

Here's what I  do:
I used a pool several years of observations into one dataset and estimate a propensity score
using a standard glm / probit approach. I then use the fitted values as propensity scores and perform the
matching.

Here's what I would like to do (in addition):
restrict the matching in way that only allows for matches within the same year, so that only propensity scores within the same year are considered for a respective match. Note that I don't what to estimate the years separately.

Is there a way to do so?

best regards

matthias

---
Matthias Bannert
KOF Swiss Economic Institute
Leonhardstrasse 21
8045 Z?rich
Switzerland


From jwijffels at bnosac.be  Fri Sep 19 14:01:28 2014
From: jwijffels at bnosac.be (Jan Wijffels)
Date: Fri, 19 Sep 2014 14:01:28 +0200
Subject: [R] [R-pkgs] RMOA data stream modelling using MOA (Massive
	Online	Analysis)
Message-ID: <CAJ9GNa=7X6YDaCFu3JOHdg2S15_VKUvdGaUkWiQ73Z7jBhcD7w@mail.gmail.com>

Dear R community,

For users interested in streaming classification or building classification
models with limited amounts of RAM on your whole data set, I would like to
announce the release of a new package called RMOA on CRAN (
http://cran.r-project.org/web/packages/RMOA).

MOA is the most popular open source framework for data stream mining and is
being developed at the University of Waikato: http://moa.cms.waikato.ac.nz.
RMOA interfaces with MOA version 2014.04 and focusses on building streaming
classification & regression models on data streams (the stream package in R
already allows clustering).

Classification models which are possible through RMOA are:

- Classification trees:
  * AdaHoeffdingOptionTree
  * ASHoeffdingTree
  * DecisionStump
  * HoeffdingAdaptiveTree
  * HoeffdingOptionTree
  * HoeffdingTree
  * LimAttHoeffdingTree
  * RandomHoeffdingTree
- Bayesian classification:
  * NaiveBayes
  * NaiveBayesMultinomial
- Active learning classification:
  * ActiveClassifier
- Ensemble (meta) classifiers:
  * Bagging
      + LeveragingBag
      + OzaBag
      + OzaBagAdwin
      + OzaBagASHT
  * Boosting
      + OCBoost
      + OzaBoost
      + OzaBoostAdwin
  * Stacking
      + LimAttClassifier
  * Other
      + AccuracyUpdatedEnsemble
      + AccuracyWeightedEnsemble
      + ADACC
      + DACC
      + OnlineAccuracyUpdatedEnsemble
      + TemporallyAugmentedClassifier
      + WeightedMajorityAlgorithm

Interfaces are implemented to model data in standard files (csv, txt,
delimited), ffdf data (from the ff package), data.frames and matrices.

Documentation of MOA directed towards RMOA users can be found at
http://jwijffels.github.io/RMOA/
Examples on the use of RMOA can be found in the documentation, on github at
https://github.com/jwijffels/RMOA or e.g. by viewing the showcase at
http://bnosac.be/index.php/blog/32-rmoa-massive-online-data-stream-classifications-with-r-a-moa

I you have any remarks or requests, don't hesitate to get into contact.

stream on,
Jan


Jan Wijffels
Statistical Data Miner
www.bnosac.be  | +32 486 611708

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From evan.cooch at gmail.com  Fri Sep 19 17:36:43 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 19 Sep 2014 11:36:43 -0400
Subject: [R] optim, L-BFGS-B | constrained bounds on parms?
In-Reply-To: <541C4C95.7080902@uottawa.ca>
References: <mailman.23.1411120807.23892.r-help@r-project.org>
	<541C4C95.7080902@uottawa.ca>
Message-ID: <541C4D8B.80301@gmail.com>

  You could also use Rvmmin
> that has bounds, or nmkb from dfoptim (though you cannot start on bounds).
>

One 'negative' for dfoptim is that is doesn't automatically generate the 
Hessian (as far as I can tell). Rather nice to be able to do so for 
other calculations that usual follow after the optimization. optimx has 
a control option for that.


From ishaqbaba at yahoo.com  Fri Sep 19 17:48:49 2014
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Fri, 19 Sep 2014 08:48:49 -0700
Subject: [R] plot
Message-ID: <1411141729.70365.YahooMailNeo@web142506.mail.bf1.yahoo.com>

Hi,
kindly give me some guide on how to plot the following data in a single line graph that is ( y1,y2,y3,y4 against x) including title and key

y1<-c(0.84,1.03,0.96)
y2<-c(1.30,1.46,1.48)
y3<-c(1.32,1.47,1.5)
y4<-c(0.07,0.07,0.07)
x<-c(500,1000,2000)

Thanks
Ishaq

	[[alternative HTML version deleted]]


From gchak at circulumvite.com  Fri Sep 19 20:28:40 2014
From: gchak at circulumvite.com (Gaurav Chakravorty)
Date: Fri, 19 Sep 2014 14:28:40 -0400
Subject: [R] X11/Intrinsic.h preventing build on rhel
Message-ID: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>

I am trying to build R-3.1.0 on RHEL
But configure returns with an error due to X11/Intrinsic.h missing

Is there a workaround ?


Gaurav Chakravorty
Circulum Vite LLC | www.circulumvite.com
2500 PLAZA 5 . Harborside Financial Center, Jersey City, NJ 07311-4026
Tel: 201-377-2302      Fax: 201-604-5422     Cell: 201-500-7416

This communication and any attachments may be privileged or
confidential. Copying
or forwarding without permission of sender is prohibited. If you are
not the intended recipient, you have received this in error and any review,
distribution or copying of this communication is strictly prohibited. In
such an event, please notify us immediately by reply email or by phone
(+1-201-377-2302) and immediately delete this message and all
attachments. E-mail
transmission cannot be guaranteed to be secure or error-free as
information could
be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or
contain viruses. The sender therefore does not accept liability for any
errors or omissions in the contents of this message, which arise as a
result of e-mail transmission. The authenticity of the sender cannot be
claimed in any litigation.

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Fri Sep 19 21:11:50 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 19 Sep 2014 14:11:50 -0500
Subject: [R] plot
In-Reply-To: <1411141729.70365.YahooMailNeo@web142506.mail.bf1.yahoo.com>
References: <1411141729.70365.YahooMailNeo@web142506.mail.bf1.yahoo.com>
Message-ID: <84A4353F-40F4-417E-92A3-1D4C2216C761@me.com>

On Sep 19, 2014, at 10:48 AM, IZHAK shabsogh <ishaqbaba at yahoo.com> wrote:

> Hi,
> kindly give me some guide on how to plot the following data in a single line graph that is ( y1,y2,y3,y4 against x) including title and key
> 
> y1<-c(0.84,1.03,0.96)
> y2<-c(1.30,1.46,1.48)
> y3<-c(1.32,1.47,1.5)
> y4<-c(0.07,0.07,0.07)
> x<-c(500,1000,2000)
> 
> Thanks
> Ishaq


See ?matplot and ?legend

matplot(x, cbind(y1, y2, y3, y4), type = "l", 
        main = "Plot Title", ylab = "Y Vals", 
        xlab = "X Vals")

legend("right", lty = 1:4, col = 1:4, 
       legend = c("y1", "y2", "y3", "y4"))


Regards,

Marc Schwartz


From marc_schwartz at me.com  Fri Sep 19 21:19:00 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 19 Sep 2014 14:19:00 -0500
Subject: [R] X11/Intrinsic.h preventing build on rhel
In-Reply-To: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>
References: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>
Message-ID: <0B245651-EDAC-4908-8024-6A40FF06F769@me.com>


On Sep 19, 2014, at 1:28 PM, Gaurav Chakravorty <gchak at circulumvite.com> wrote:

> I am trying to build R-3.1.0 on RHEL
> But configure returns with an error due to X11/Intrinsic.h missing
> 
> Is there a workaround ?
> 


In most Linuxen, the header files are contained in *-dev[el] packages. For RHEL, this is likely to be libX11-devel, so you will need to install that RPM.

Note that a pre-compiled binary RPM for R is available from the EPEL for RHEL:

  https://fedoraproject.org/wiki/EPEL

Also note that there is the R-SIG-Fedora list, which covers support for RH based distros specifically:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Regards,

Marc Schwartz


From marc_schwartz at me.com  Fri Sep 19 21:19:00 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 19 Sep 2014 14:19:00 -0500
Subject: [R] X11/Intrinsic.h preventing build on rhel
In-Reply-To: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>
References: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>
Message-ID: <C2A71E63-D626-465E-A830-745B01EAE9B4@me.com>


On Sep 19, 2014, at 1:28 PM, Gaurav Chakravorty <gchak at circulumvite.com> wrote:

> I am trying to build R-3.1.0 on RHEL
> But configure returns with an error due to X11/Intrinsic.h missing
> 
> Is there a workaround ?
> 


In most Linuxen, the header files are contained in *-dev[el] packages. For RHEL, this is likely to be libX11-devel, so you will need to install that RPM.

Note that a pre-compiled binary RPM for R is available from the EPEL for RHEL:

  https://fedoraproject.org/wiki/EPEL

Also note that there is the R-SIG-Fedora list, which covers support for RH based distros specifically:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Regards,

Marc Schwartz


From ripley at stats.ox.ac.uk  Fri Sep 19 21:25:28 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Sep 2014 20:25:28 +0100
Subject: [R] X11/Intrinsic.h preventing build on rhel
In-Reply-To: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>
References: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>
Message-ID: <541C8328.8010809@stats.ox.ac.uk>

On 19/09/2014 19:28, Gaurav Chakravorty wrote:
> I am trying to build R-3.1.0 on RHEL
> But configure returns with an error due to X11/Intrinsic.h missing
>
> Is there a workaround ?

Yes, install it!

If you need more help, read the posting guide and note the appropriate 
list from

'Platform-specific questions: There are lists R-sig-Mac, R-sig-Debian 
and R-sig-Fedora for R on Mac OS X, Debian/Ubuntu and Fedora/Redhat 
respectively.'

But before you do, read carefully the manual at 
http://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Essential-programs-and-libraries: 
it hints what RPMs need to be installed.

> Gaurav Chakravorty
> Circulum Vite LLC | www.circulumvite.com
> 2500 PLAZA 5 . Harborside Financial Center, Jersey City, NJ 07311-4026
> Tel: 201-377-2302      Fax: 201-604-5422     Cell: 201-500-7416
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From tom at maladmin.com  Fri Sep 19 21:25:31 2014
From: tom at maladmin.com (Tom Wright)
Date: Fri, 19 Sep 2014 15:25:31 -0400
Subject: [R] plot
In-Reply-To: <84A4353F-40F4-417E-92A3-1D4C2216C761@me.com>
References: <1411141729.70365.YahooMailNeo@web142506.mail.bf1.yahoo.com>
	<84A4353F-40F4-417E-92A3-1D4C2216C761@me.com>
Message-ID: <1411154731.9472.11.camel@tom-laptop>

plot(x=range(x),y=range(c(y1,y2,y3.y4),type='n')
lines(x=x,y=y1,lty=1)
lines(x=x,y=y2,lty=2)
lines(x=x,y=y3,lty=3)
lines(x=x,y=y4,lty=4)

legend('bottomright',c('Y1','Y2','Y3','Y4','Y5'),lty=1:4)


or something like that.


On Fri, 2014-09-19 at 14:11 -0500, Marc Schwartz wrote:
> On Sep 19, 2014, at 10:48 AM, IZHAK shabsogh <ishaqbaba at yahoo.com> wrote:
> 
> > Hi,
> > kindly give me some guide on how to plot the following data in a single line graph that is ( y1,y2,y3,y4 against x) including title and key
> > 
> > y1<-c(0.84,1.03,0.96)
> > y2<-c(1.30,1.46,1.48)
> > y3<-c(1.32,1.47,1.5)
> > y4<-c(0.07,0.07,0.07)
> > x<-c(500,1000,2000)
> > 
> > Thanks
> > Ishaq
> 
> 
> See ?matplot and ?legend
> 
> matplot(x, cbind(y1, y2, y3, y4), type = "l", 
>         main = "Plot Title", ylab = "Y Vals", 
>         xlab = "X Vals")
> 
> legend("right", lty = 1:4, col = 1:4, 
>        legend = c("y1", "y2", "y3", "y4"))
> 
> 
> Regards,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Fri Sep 19 21:27:44 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 19 Sep 2014 14:27:44 -0500
Subject: [R] X11/Intrinsic.h preventing build on rhel
In-Reply-To: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>
References: <CAP4q0jnaAM7Rk-StRMLwusr=gn9UsS+FH34ReJDyXwfkb9LKuw@mail.gmail.com>
Message-ID: <CAAJSdjjU_bxT6swg_ZDi5SQBXY2mBNF1-T19q41iu1xDQ6G5JQ@mail.gmail.com>

On Fri, Sep 19, 2014 at 1:28 PM, Gaurav Chakravorty
<gchak at circulumvite.com> wrote:
> I am trying to build R-3.1.0 on RHEL
> But configure returns with an error due to X11/Intrinsic.h missing
>
> Is there a workaround ?
>

yum install libXt-devel

This from my Fedora 20 x86_64 installation.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From lbajuk at tibco.com  Fri Sep 19 21:32:20 2014
From: lbajuk at tibco.com (Louis Bajuk-Yorgan)
Date: Fri, 19 Sep 2014 12:32:20 -0700
Subject: [R]  Using R in our commercial business application
Message-ID: <CAHxTkZEj2SNUFrvOa_VjgR5dLCjuSXcwhzt-6a5idssq5KEJnw@mail.gmail.com>

TERR (TIBCO Enterprise Runtime for R) is an independent implementation of an
R-compatible engine (based on our long history and expertise with S+). One
of the features of TERR is that it can be licensed for embedding and
redistribution, since it is not subject to the GPL license.

For more information on TERR, Google "TIBCO TERR", and you will find an
overview website, a white paper, and link to download the free TERR
Developer's Edition (which is available to everyone in the R community, and
is compatible with RStudio).

If you'd like information on licensing TERR, or have any other questions,
please contact me directly (I'm the product manager for TERR).
TIBCOmmunity.com also has a TERR community site for answering questions
about TERR.

Regards
Lou Bajuk-Yorgan

-- 
Lou Bajuk-Yorgan
Sr. Director, Product Management
Spotfire, TIBCO Software
lbajuk at tibco.com
Twitter: @LouBajuk


On 19 Sep 2014, at 10:30 , Pasu <pasupathym at gmail.com
<https://stat.ethz.ch/mailman/listinfo/r-help>> wrote:

>* Hi
*> >* Thanks to all for the inputs. It will also be great to get inputs on the
*>* procedure and the contact person for getting the commercial license on R
*> >* Rgds
*>* Pasu
*>* On 19-Sep-2014 2:13 AM, "Duncan Murdoch" <murdoch.duncan at
gmail.com <https://stat.ethz.ch/mailman/listinfo/r-help>> wrote:
*> >>* On 18/09/2014 2:35 PM, Marc Schwartz wrote:
*>> >>>* On Sep 18, 2014, at 4:36 AM, Pasu <pasupathym at gmail.com
<https://stat.ethz.ch/mailman/listinfo/r-help>> wrote:
*>>> >>>>* Hi
*>>>> >>>>* I would like to know how to use R in our commercial
business application
*>>>>* which we plan to host in cloud or deploy on customer's premise.
*>>>> >>>>* 1. Using R and its package, does it enforce that my
commercial business
*>>>>* application should be distributed under GPL, as the statistical
*>>>* derivation
*>>>>* (output) by using R will be presented to the end users as part of of our
*>>>>* commercial business application
*>>>>* 2. Whom to contact to get commercial license if required for using R?
*>>>> >>>>* Rgds
*>>>>* Pasupathy
*>>> >>> >>>* You will not get a definitive legal opinion here and my
comments below do
*>>>* not represent any formal opinion on the part of any organization.
*>>> >>>* There is nothing preventing you or your company from using R as an end
*>>>* user. There are many of us who use R in commercial settings and
in general,
*>>>* the output of a GPL'd application (text or binary) is not considered to be
*>>>* also GPL'd.
*>>> >>>* The subtleties get into the distribution of R (which you
seem to plan to
*>>>* do), the nature of any additional functionality/code that you or your
*>>>* company may write/distribute, how that code interacts with R and/or
*>>>* modifies R source code copyrighted by the R Foundation and others. If you
*>>>* distribute R to clients, you will need to make R's source code
available to
*>>>* them in some manner along with any modifications to that same code, while
*>>>* preserving appropriate copyrights.
*>>> >>>* A proprietary (closed source) application cannot be licensed under the
*>>>* GPL, but your company's application/code may be forced to be GPL (the so
*>>>* called viral aspect of the GPL) depending upon how your application is
*>>>* implemented as I noted in the prior paragraph. Thus, you may be forced to
*>>>* make your source code available to your clients as well.
*>>> >>>* If you plan to move forward, you should consult with an attorney well
*>>>* educated in software licensing and distribution issues, especially as they
*>>>* pertain to the GPL. The risks are not inconsequential of falling on the
*>>>* wrong side of the GPL.
*>>> >>>* The official R distribution is not available via a commercial or
*>>>* developer license, but there are commercial vendors of R and a Google
*>>>* search will point you in their direction, if desired. However, since their
*>>>* products are founded upon the official R distribution and the GPL, they
*>>>* will have similar issues with respect to any enhancements that they have
*>>>* created and therefore, your concerns do not necessarily go away. They will
*>>>* have also consulted legal counsel on these issues because the viability of
*>>>* their business depends upon it.
*>>> >> >>* I agree with all of that but for one thing:  not all
distributions are
*>>* built on the GPL'd original.  I believe Tibco is selling an independent
*>>* implementation.
*>>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Fri Sep 19 22:46:22 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 19 Sep 2014 15:46:22 -0500
Subject: [R] Error in rownames
In-Reply-To: <CAPtX2qmikCozPmLQXWgWfO35aBV3yD0XsCwoOvdQ_tC-ukhajg@mail.gmail.com>
References: <CAPtX2qmikCozPmLQXWgWfO35aBV3yD0XsCwoOvdQ_tC-ukhajg@mail.gmail.com>
Message-ID: <CAN5YmCHTNyGr9QydfuDPzgk3xNNamyi1UxKTY7F0TOpqYq2Mpw@mail.gmail.com>

Chris,

It's hard to troubleshoot without reproducible code.  I suggest you post a
simple example of code that we can run.  For example, use
     dput(training[1:20, ])
to spit out the first 20 lines of the training data.  Then simplify the
rest of the code as much as possible.

library(yaImpute)
training <- <<< insert output from dput(training[1:20, ]) here >>>
y <- subset(training, select = c(ResponseSu))
x <- subset(training, select = c(sinaspect, habitat, slope, elevation,
cosaspect, disttoroad, disttowat))
type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression", ntree=
20)
outfile <- list(Type = "RespSurf_Reg.asc")
xfile <-list(sinaspect ="sinaspect.asc", habitat ="habitat.asc", elevation
="elevation.asc",
disttowat ="disttowat.asc", disttoroad ="disttoroad.asc", slope
="slope.asc", cosaspect ="cosaspect.asc")
AsciiGridImpute(type.rf, xfile, outfile)

Jean


On Fri, Sep 19, 2014 at 9:10 AM, Chris Jackson-Jordan <
jacksonjordancm at gmail.com> wrote:

> Dear fellow R users,
>
> I am trying to run the random forest and Yaimpute packages in R to
> impute a grid to project in a gis. However, after running the
> imputation I keep getting an error in the rownames. This sounds simple
> enough, but I cannot figure out what these rownames are reffering to.
> Any ideas? I am fairly new to R so im sure it is an easy fix. Any help
> would be awesome.
>
> Thanks,
>
> Chris
>
>
> > training <-
> read.csv("D:/R_Desktop_Data/RF_RespSurf/RndmPts_RespSurfMIII.csv")> y <-
> subset(training, select = c(ResponseSu))> x <- subset(training, select =
> c(sinaspect, habitat, slope, elevation, cosaspect, disttoroad, disttowat))>
> type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression", ntree=
> 2000)> outfile <- list(Type =
> "D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc")> xfile <-list(sinaspect
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/sinaspect.asc",
> habitat
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/habitat.asc",
> elevation
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/elevation.asc",
> disttowat
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttowat.asc",
> disttoroad
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttoroad.asc",
> slope ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_N!
>  Nimp/ModelI/ASCII_Files2/slope.asc", cosaspect
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/cosaspect.asc")>
> AsciiGridImpute(type.rf, xfile, outfile)Rows per dot:  19  Rows to do: 1900
> ToDo:
> ....................................................................................................
> Done: .Error in `rownames<-`(`*tmp*`, value = c("23x0049", "23x0050",
> "23x0051",  :
>   attempt to set rownames on object with no dimensions
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From oriolebaltimore at gmail.com  Fri Sep 19 22:58:59 2014
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Fri, 19 Sep 2014 16:58:59 -0400
Subject: [R] Combining two data frames
Message-ID: <CAL2fYnOph1iCWOzhbiSexhdsPa79pRTG7C3z0JLNpzQu+-WAug@mail.gmail.com>

Hi:
Appreciate if I could get some help.

I have two data frames.

I want to combine these two dfs bases on first column.


df1 :

Subject    G1     G2    G3

A              10     1       0

B              20      2        20


df2:

Subject     m1    m2   m3

A              20      9     30

B                0      1    10


Resulting df :

Subject        G1    G2   G3     m1   m2  m3
A                  10      1    0       20     9    30
B                   20      2  20      0       1   10


Sometimes subjects in both df don't match.  since the data is large,
if I do cbind I am not sure about order and common subjects.



Thanks a lot for your help.


Following is dput of real data:


df1 <- structure(list(Subject = c("A-04-1332", "A-04-1336", "A-04-1337",
"A-04-1341", "A-04-1342", "A-04-1343", "A-04-1346",
"A-04-1347", "A-04-1348", "A-04-1349"), hsa.let.7a.1 = c(8788L,
2745L, 11447L, 8081L, 9291L, 44912L, 72521L, 2401L, 61251L, 134859L
), hsa.let.7a.2 = c(17806L, 5517L, 22864L, 16271L, 19194L, 89333L,
146114L, 4992L, 122469L, 270005L), hsa.let.7a.3 = c(8865L, 2743L,
11669L, 8235L, 9710L, 44633L, 73427L, 2540L, 61533L, 136403L),
    hsa.let.7b = c(72280L, 56297L, 70053L, 42974L, 56710L, 283102L,
    236254L, 5966L, 310874L, 596434L), hsa.let.7c = c(20743L,
    4848L, 10001L, 4070L, 10773L, 45697L, 60397L, 2313L, 35303L,
    51923L), hsa.let.7d = c(8187L, 12983L, 14028L, 14611L, 14971L,
    17719L, 7028L, 610L, 13165L, 20890L), hsa.let.7e = c(2745L,
    1068L, 4637L, 3747L, 4716L, 17202L, 25589L, 2147L, 8244L,
    21777L), hsa.let.7f.1 = c(1L, 0L, 5L, 3L, 5L, 11L, 5L, 0L,
    24L, 30L), hsa.let.7f.2 = c(404L, 176L, 1081L, 1130L, 1055L,
    3097L, 3998L, 119L, 5612L, 14844L)), .Names = c("Subject",
"hsa.let.7a.1", "hsa.let.7a.2", "hsa.let.7a.3", "hsa.let.7b",
"hsa.let.7c", "hsa.let.7d", "hsa.let.7e", "hsa.let.7f.1", "hsa.let.7f.2"
), row.names = c(NA, 10L), class = "data.frame")


df2 <- structure(list(Subject = c("A-04-1332", "A-04-1337", "A-04-1338",
"A-04-1341", "A-04-1343", "A-04-1347", "A-04-1348",
"A-04-1350", "A-04-1356", "A-04-1357"), A1BG = c(404L,
1387L, 436L, 2225L, 2444L, 838L, 618L, 1035L, 2812L, 309L), A1CF = c(0L,
1L, 3L, 1L, 2L, 0L, 0L, 0L, 1L, 0L), A2BP1 = c(454L, 7L, 18L,
117L, 9L, 1L, 3L, 3193L, 123L, 2L), A2LD1 = c(413L, 1100L, 334L,
882L, 990L, 697L, 2151L, 1102L, 1088L, 578L), A2M = c(44670L,
40872L, 8162L, 8183L, 29555L, 5252L, 46763L, 2099L, 11868L, 31205L
), A2ML1 = c(667L, 6L, 420L, 82L, 33L, 303L, 88L, 225L, 181L,
244L), A4GALT = c(2384L, 2821L, 491L, 1588L, 3685L, 151L, 702L,
528L, 2564L, 1005L), A4GNT = c(13L, 15L, 2L, 0L, 2L, 2L, 4L,
1L, 0L, 0L), AAA1 = c(0L, 2L, 0L, 0L, 2L, 0L, 0L, 4L, 2L, 0L)), .Names
= c("Subject",
"A1BG", "A1CF", "A2BP1", "A2LD1", "A2M", "A2ML1", "A4GALT", "A4GNT",
"AAA1"), row.names = c(NA, 10L), class = "data.frame")



Thanks


From nebuloso78 at gmx.ch  Fri Sep 19 22:55:07 2014
From: nebuloso78 at gmx.ch (nebulo help)
Date: Fri, 19 Sep 2014 22:55:07 +0200
Subject: [R] Converting xy plot arguments into a point argument and fixed
 x-axis scaling
Message-ID: <trinity-3843ab08-45ce-4f20-a267-124c76fe6d26-1411160107826@3capp-gmx-bs36>

Dear all,?
??
I have a data.frame xy which I am plotting like in the code below (provided is a small data sample with dummy data that should work).?
??
Is there a way how I could convert my xx and yy in the xy plot to a points command so that I could set type='n' and add points afterwards in order to control it better??
??
In the end what I am also aiming for is a fixed x-axis range (e.g. from 1940 to 2014) and if values before 1940 are present the x axis should be automatic. The y axis should always be in the range of the values generated for each plot.?
??
Thank you for your help!?

Kind regards,
Kurt
??
###########################?
??
Here is my code with sample data:?
??
# read in sample data?
xy <- data.frame(NAME=c("NAME1","NAME1","NAME1","NAME2","NAME2","NAME2"),ID=c(87,87,87,199,199,199), X_START_YEAR=c(1984,1986,1984,1899,1909,1924),Y_START_VALUE=c(75,25,-90,-8,-55,-10),X_END_YEAR=c(1986,1994,1999,1909,1924,1927), Y_END_VALUE=c(20,50,-15,-70,-80,-100))?
????
# split data.frame into groups (defined by ID in this case)?
ind <- split(xy,xy$ID)?
# plot data by group?
for (x in ind){?
? xx = unlist(x[,grep('X_',colnames(x))])?
? yy = unlist(x[,grep('Y_',colnames(x))]) ? ??
? ? fname <- paste0(x[1, 'ID'], '.png')?
? ? png(fname, width=1679, height=1165, res=150)?
? ? par(mar=c(6,8,6,5))?
? ? plot(xx,?
? ? ? ? ?yy,?
? ? ? ? ?main=unique(x[,1]),?
? ? ? ? ?xlab="Time [Years]",?
? ? ? ? ?ylab="Value [m]")?
? ? axis(1, at = seq(1000, 2050, 5), cex.axis=1, labels=FALSE, tcl=-0.3)?
? ? axis(2, at = seq(-100000, 100000, 500), cex.axis=1, labels=FALSE, tcl=-0.3)?
? ? x <- x[,-1]?
? ? segments(x[,2],x[,3],x[,4],x[,5],lwd=2)?
? ? dev.off()?
? }


From mb3058 at columbia.edu  Fri Sep 19 21:15:02 2014
From: mb3058 at columbia.edu (mb3058 at columbia.edu)
Date: Fri, 19 Sep 2014 15:15:02 -0400
Subject: [R] Issue labelling datapoints in xyplot with two Y-axis
Message-ID: <20140919151502.ypih922tt4ooo8ss@cubmail.cc.columbia.edu>

Hello R friends,

I am trying to add label to each of my datapoints in an xyplot which  
has two Y-axis. When I run my code with only 1 xyplot it labels the  
datapoints just fine. However when I have two xyplots plotted  
together,I am unable to label the data points. Any suggestion will be  
greatly appreciated.

Below is my code:

panel=function(x, y,labels) {
                panel.xyplot(x, y,);
                ltext(x=x, y=y, labels=data$z,pos=1, offset=1, cex=0.8)}

			p1<- xyplot(x1~x2|x3, data=data, type="o",
			col="blue", cex=0.2, pch=16,axes=F,xaxt="n",par.strip.text =  
list(cex = 0.4),
			scales=list(x=list(cex=0.5, rot=90), y=list(cex=0.5)),panel=panel)

			p2<- xyplot(x4~x2|x3, data=data,
			axes=F,yaxt="n", xlab="", col="magenta",
			main="", type='o', cex=0.3,grid= TRUE,
			par.strip.text = list(cex = 0.4),
			scales=list(x=list(cex=0.5, rot=90),y=list(cex=0.5))
			)

			p12<-doubleYScale(p1,p2,add.ylab2=TRUE)

		print(p12)


From ligges at statistik.tu-dortmund.de  Fri Sep 19 23:03:00 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 19 Sep 2014 23:03:00 +0200
Subject: [R] Combining two data frames
In-Reply-To: <CAL2fYnOph1iCWOzhbiSexhdsPa79pRTG7C3z0JLNpzQu+-WAug@mail.gmail.com>
References: <CAL2fYnOph1iCWOzhbiSexhdsPa79pRTG7C3z0JLNpzQu+-WAug@mail.gmail.com>
Message-ID: <541C9A04.2010404@statistik.tu-dortmund.de>

See ?merge

Best,
Uwe Ligges

On 19.09.2014 22:58, Adrian Johnson wrote:
> Hi:
> Appreciate if I could get some help.
>
> I have two data frames.
>
> I want to combine these two dfs bases on first column.
>
>
> df1 :
>
> Subject    G1     G2    G3
>
> A              10     1       0
>
> B              20      2        20
>
>
> df2:
>
> Subject     m1    m2   m3
>
> A              20      9     30
>
> B                0      1    10
>
>
> Resulting df :
>
> Subject        G1    G2   G3     m1   m2  m3
> A                  10      1    0       20     9    30
> B                   20      2  20      0       1   10
>
>
> Sometimes subjects in both df don't match.  since the data is large,
> if I do cbind I am not sure about order and common subjects.
>
>
>
> Thanks a lot for your help.
>
>
> Following is dput of real data:
>
>
> df1 <- structure(list(Subject = c("A-04-1332", "A-04-1336", "A-04-1337",
> "A-04-1341", "A-04-1342", "A-04-1343", "A-04-1346",
> "A-04-1347", "A-04-1348", "A-04-1349"), hsa.let.7a.1 = c(8788L,
> 2745L, 11447L, 8081L, 9291L, 44912L, 72521L, 2401L, 61251L, 134859L
> ), hsa.let.7a.2 = c(17806L, 5517L, 22864L, 16271L, 19194L, 89333L,
> 146114L, 4992L, 122469L, 270005L), hsa.let.7a.3 = c(8865L, 2743L,
> 11669L, 8235L, 9710L, 44633L, 73427L, 2540L, 61533L, 136403L),
>      hsa.let.7b = c(72280L, 56297L, 70053L, 42974L, 56710L, 283102L,
>      236254L, 5966L, 310874L, 596434L), hsa.let.7c = c(20743L,
>      4848L, 10001L, 4070L, 10773L, 45697L, 60397L, 2313L, 35303L,
>      51923L), hsa.let.7d = c(8187L, 12983L, 14028L, 14611L, 14971L,
>      17719L, 7028L, 610L, 13165L, 20890L), hsa.let.7e = c(2745L,
>      1068L, 4637L, 3747L, 4716L, 17202L, 25589L, 2147L, 8244L,
>      21777L), hsa.let.7f.1 = c(1L, 0L, 5L, 3L, 5L, 11L, 5L, 0L,
>      24L, 30L), hsa.let.7f.2 = c(404L, 176L, 1081L, 1130L, 1055L,
>      3097L, 3998L, 119L, 5612L, 14844L)), .Names = c("Subject",
> "hsa.let.7a.1", "hsa.let.7a.2", "hsa.let.7a.3", "hsa.let.7b",
> "hsa.let.7c", "hsa.let.7d", "hsa.let.7e", "hsa.let.7f.1", "hsa.let.7f.2"
> ), row.names = c(NA, 10L), class = "data.frame")
>
>
> df2 <- structure(list(Subject = c("A-04-1332", "A-04-1337", "A-04-1338",
> "A-04-1341", "A-04-1343", "A-04-1347", "A-04-1348",
> "A-04-1350", "A-04-1356", "A-04-1357"), A1BG = c(404L,
> 1387L, 436L, 2225L, 2444L, 838L, 618L, 1035L, 2812L, 309L), A1CF = c(0L,
> 1L, 3L, 1L, 2L, 0L, 0L, 0L, 1L, 0L), A2BP1 = c(454L, 7L, 18L,
> 117L, 9L, 1L, 3L, 3193L, 123L, 2L), A2LD1 = c(413L, 1100L, 334L,
> 882L, 990L, 697L, 2151L, 1102L, 1088L, 578L), A2M = c(44670L,
> 40872L, 8162L, 8183L, 29555L, 5252L, 46763L, 2099L, 11868L, 31205L
> ), A2ML1 = c(667L, 6L, 420L, 82L, 33L, 303L, 88L, 225L, 181L,
> 244L), A4GALT = c(2384L, 2821L, 491L, 1588L, 3685L, 151L, 702L,
> 528L, 2564L, 1005L), A4GNT = c(13L, 15L, 2L, 0L, 2L, 2L, 4L,
> 1L, 0L, 0L), AAA1 = c(0L, 2L, 0L, 0L, 2L, 0L, 0L, 4L, 2L, 0L)), .Names
> = c("Subject",
> "A1BG", "A1CF", "A2BP1", "A2LD1", "A2M", "A2ML1", "A4GALT", "A4GNT",
> "AAA1"), row.names = c(NA, 10L), class = "data.frame")
>
>
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From oriolebaltimore at gmail.com  Fri Sep 19 23:11:04 2014
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Fri, 19 Sep 2014 17:11:04 -0400
Subject: [R] Combining two data frames
In-Reply-To: <541C9A04.2010404@statistik.tu-dortmund.de>
References: <CAL2fYnOph1iCWOzhbiSexhdsPa79pRTG7C3z0JLNpzQu+-WAug@mail.gmail.com>
	<541C9A04.2010404@statistik.tu-dortmund.de>
Message-ID: <CAL2fYnOe5EpjXX43C-nBrrJVeG3Z7=zS8ptkkFbE7RPcP3AMkw@mail.gmail.com>

thanks it works I guess:

merge(b1,b2,by='Subject')

On Fri, Sep 19, 2014 at 5:03 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
> See ?merge
>
> Best,
> Uwe Ligges
>
>
> On 19.09.2014 22:58, Adrian Johnson wrote:
>>
>> Hi:
>> Appreciate if I could get some help.
>>
>> I have two data frames.
>>
>> I want to combine these two dfs bases on first column.
>>
>>
>> df1 :
>>
>> Subject    G1     G2    G3
>>
>> A              10     1       0
>>
>> B              20      2        20
>>
>>
>> df2:
>>
>> Subject     m1    m2   m3
>>
>> A              20      9     30
>>
>> B                0      1    10
>>
>>
>> Resulting df :
>>
>> Subject        G1    G2   G3     m1   m2  m3
>> A                  10      1    0       20     9    30
>> B                   20      2  20      0       1   10
>>
>>
>> Sometimes subjects in both df don't match.  since the data is large,
>> if I do cbind I am not sure about order and common subjects.
>>
>>
>>
>> Thanks a lot for your help.
>>
>>
>> Following is dput of real data:
>>
>>
>> df1 <- structure(list(Subject = c("A-04-1332", "A-04-1336", "A-04-1337",
>> "A-04-1341", "A-04-1342", "A-04-1343", "A-04-1346",
>> "A-04-1347", "A-04-1348", "A-04-1349"), hsa.let.7a.1 = c(8788L,
>> 2745L, 11447L, 8081L, 9291L, 44912L, 72521L, 2401L, 61251L, 134859L
>> ), hsa.let.7a.2 = c(17806L, 5517L, 22864L, 16271L, 19194L, 89333L,
>> 146114L, 4992L, 122469L, 270005L), hsa.let.7a.3 = c(8865L, 2743L,
>> 11669L, 8235L, 9710L, 44633L, 73427L, 2540L, 61533L, 136403L),
>>      hsa.let.7b = c(72280L, 56297L, 70053L, 42974L, 56710L, 283102L,
>>      236254L, 5966L, 310874L, 596434L), hsa.let.7c = c(20743L,
>>      4848L, 10001L, 4070L, 10773L, 45697L, 60397L, 2313L, 35303L,
>>      51923L), hsa.let.7d = c(8187L, 12983L, 14028L, 14611L, 14971L,
>>      17719L, 7028L, 610L, 13165L, 20890L), hsa.let.7e = c(2745L,
>>      1068L, 4637L, 3747L, 4716L, 17202L, 25589L, 2147L, 8244L,
>>      21777L), hsa.let.7f.1 = c(1L, 0L, 5L, 3L, 5L, 11L, 5L, 0L,
>>      24L, 30L), hsa.let.7f.2 = c(404L, 176L, 1081L, 1130L, 1055L,
>>      3097L, 3998L, 119L, 5612L, 14844L)), .Names = c("Subject",
>> "hsa.let.7a.1", "hsa.let.7a.2", "hsa.let.7a.3", "hsa.let.7b",
>> "hsa.let.7c", "hsa.let.7d", "hsa.let.7e", "hsa.let.7f.1", "hsa.let.7f.2"
>> ), row.names = c(NA, 10L), class = "data.frame")
>>
>>
>> df2 <- structure(list(Subject = c("A-04-1332", "A-04-1337", "A-04-1338",
>> "A-04-1341", "A-04-1343", "A-04-1347", "A-04-1348",
>> "A-04-1350", "A-04-1356", "A-04-1357"), A1BG = c(404L,
>> 1387L, 436L, 2225L, 2444L, 838L, 618L, 1035L, 2812L, 309L), A1CF = c(0L,
>> 1L, 3L, 1L, 2L, 0L, 0L, 0L, 1L, 0L), A2BP1 = c(454L, 7L, 18L,
>> 117L, 9L, 1L, 3L, 3193L, 123L, 2L), A2LD1 = c(413L, 1100L, 334L,
>> 882L, 990L, 697L, 2151L, 1102L, 1088L, 578L), A2M = c(44670L,
>> 40872L, 8162L, 8183L, 29555L, 5252L, 46763L, 2099L, 11868L, 31205L
>> ), A2ML1 = c(667L, 6L, 420L, 82L, 33L, 303L, 88L, 225L, 181L,
>> 244L), A4GALT = c(2384L, 2821L, 491L, 1588L, 3685L, 151L, 702L,
>> 528L, 2564L, 1005L), A4GNT = c(13L, 15L, 2L, 0L, 2L, 2L, 4L,
>> 1L, 0L, 0L), AAA1 = c(0L, 2L, 0L, 0L, 2L, 0L, 0L, 4L, 2L, 0L)), .Names
>> = c("Subject",
>> "A1BG", "A1CF", "A2BP1", "A2LD1", "A2M", "A2ML1", "A4GALT", "A4GNT",
>> "AAA1"), row.names = c(NA, 10L), class = "data.frame")
>>
>>
>>
>> Thanks
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From agony_jah at yahoo.com  Fri Sep 19 23:14:20 2014
From: agony_jah at yahoo.com (Agony)
Date: Fri, 19 Sep 2014 14:14:20 -0700
Subject: [R] Help on tidy_source
Message-ID: <1411161260.40026.YahooMailBasic@web120405.mail.ne1.yahoo.com>

Dear all,
Good time.

Could anybody can help me with my below code on Windows 7 and R 3.1.0
when I run this code:

tidy_source (
 "ugly script.R",
 file = "beautiful script.R"
 )


I encounter this error message:

Error in parse(text = x, keep.source = TRUE) : 
  <text>:11:14: unexpected '=='
10: 
11: Crtl+Alt+N ====
                 ^


Bunch of thanks in advance
Best,
Amir


From r.turner at auckland.ac.nz  Sat Sep 20 06:30:43 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 20 Sep 2014 16:30:43 +1200
Subject: [R] plot
In-Reply-To: <1411141729.70365.YahooMailNeo@web142506.mail.bf1.yahoo.com>
References: <1411141729.70365.YahooMailNeo@web142506.mail.bf1.yahoo.com>
Message-ID: <541D02F3.2050008@auckland.ac.nz>



Looks like homework to me.

cheers,

Rolf

P. S.  In any case, so some basic reading of introductory R material, 
available from the R web page.

R.

On 20/09/14 03:48, IZHAK shabsogh wrote:
> Hi,
> kindly give me some guide on how to plot the following data in a single line graph that is ( y1,y2,y3,y4 against x) including title and key
>
> y1<-c(0.84,1.03,0.96)
> y2<-c(1.30,1.46,1.48)
> y3<-c(1.32,1.47,1.5)
> y4<-c(0.07,0.07,0.07)
> x<-c(500,1000,2000)

-- 
Rolf Turner
Technical Editor ANZJS


From abhinabaroy09 at gmail.com  Sat Sep 20 08:46:22 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Sat, 20 Sep 2014 12:16:22 +0530
Subject: [R] Logging and writing error messages to a dataframe
Message-ID: <CANtKHPU7vZJESvk+U3ENM-aN1CUrw1qJuV2ndB7yVeJVe9bUjA@mail.gmail.com>

Hi R-helpers,

I intend to record the errors in my R code while calling functions in a
dataframe (ERR_LOG, say). I want to use 'try' to identify errors while
calling a function,if any.The dataframe(ERR_LOG) will have the following
columns :

Time : The time at which the function was called (Sys.time)
Loc : For which function call was this error recorded (name of the function)
Desc : Description of the error which R throws at us (Error message in R)

Example :

First I would like to initialize a blank dataframe 'ERR_LOG' with these
columns

Then write the function
f <- function(a){
  x <- a*100
  return(x)
}

Now I put the output of the call to 'f' in 'chk'
chk <- try(f())

The above call gives the error 'Error in a * 100 : 'a' is missing'
(description of the error)

Check
if(inherits(chk,'try-error'))
{then I want to populate ERR_LOG and stop the code execution}

How can this be done in R?

	[[alternative HTML version deleted]]


From ujjwalsinha00 at gmail.com  Sat Sep 20 08:52:28 2014
From: ujjwalsinha00 at gmail.com (Ujjwal Kumar)
Date: Sat, 20 Sep 2014 12:22:28 +0530
Subject: [R] need help
Message-ID: <CAGV0xWkkV0pgm2ZJ5NKp4HoFCzfnU3U0MxScgpUQ8WxuBbikng@mail.gmail.com>

I have the datafram like "fxmale"

head(fxmale)
       x       y         D.fx         D.nc        D.sum1 445350
2463450 1.046935e-06 0.0002627856 0.00026383262 445350 2463950
1.314861e-06 0.0002618268 0.00026314163 445350 2464450 1.435987e-06
0.0002627193 0.00026415534 445350 2464950 1.362894e-06 0.0002652938
0.00026665675 445350 2465450 1.122175e-06 0.0002690738 0.00027019606
445350 2465950 7.998899e-07 0.0002734074 0.0002742073

when I am trying to export as csv I am getting only the first two columns
(x & y) not others columns. This is the structure of the data.

> str(fxmale)
Classes ?Dsurface?, ?mask? and 'data.frame':    5735 obs. of  2 variables:
 $ x: int  445350 445350 445350 445350 445350 445350 445350 445350
445350 445350 ...
 $ y: int  2463450 2463950 2464450 2464950 2465450 2465950 2470950
2471450 2471950 2472450 ...
 - attr(*, "covariates")='data.frame':  5735 obs. of  3 variables:
  ..$ D.fx : num  1.05e-06 1.31e-06 1.44e-06 1.36e-06 1.12e-06 ...
  ..$ D.nc : num  0.000263 0.000262 0.000263 0.000265 0.000269 ...
  ..$ D.sum: num  0.000264 0.000263 0.000264 0.000267 0.00027 ...
 - attr(*, "type")= chr "user"
 - attr(*, "meanSD")='data.frame':      2 obs. of  2 variables:
  ..$ x: num  475535 17942
  ..$ y: num  2458930 10937
 - attr(*, "area")= num 25
 - attr(*, "spacing")= num 500
 - attr(*, "boundingbox")='data.frame': 4 obs. of  2 variables:
  ..$ x: num  445100 507600 507600 445100
  ..$ y: num  2434700 2434700 2483700 2483700
  ..- attr(*, "out.attrs")=List of 2
  .. ..$ dim     : Named int  2 2
  .. .. ..- attr(*, "names")= chr  "x" "y"
  .. ..$ dimnames:List of 2
  .. .. ..$ x: chr  "x=445100" "x=507600"
  .. .. ..$ y: chr  "y=2434700" "y=2483700"

can any body help me???

-- 
with regards
Ujjwal Kumar
*Research Fellow*
Project: "Monitoring Source Population of Tigers in Kanha Tiger Reserve"
Wildlife Institute of India
mobile: +91 9808712591(Dehradun)
                +919407344453  (Kanha)

   P.O. Box 18 Chandrabani
  Dehradun (Uttarakhand) 248001

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Sep 20 14:53:20 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 20 Sep 2014 13:53:20 +0100
Subject: [R] need help
In-Reply-To: <CAGV0xWkkV0pgm2ZJ5NKp4HoFCzfnU3U0MxScgpUQ8WxuBbikng@mail.gmail.com>
References: <CAGV0xWkkV0pgm2ZJ5NKp4HoFCzfnU3U0MxScgpUQ8WxuBbikng@mail.gmail.com>
Message-ID: <541D78C0.4080201@sapo.pt>

Hello,

Your data.frame only has 2 columns, x and y. The rest are attributes of 
the column y. To access those attributes you can use something like

attr(fxmale, "covariates")  # This is the one you want
attr(fxmale, "meanSD")
attr(fxmale, "boundingbox")

and save them in other csv files (most probably not with the same 
write.csv command).

Or maybe

df2 <- cbind(fxmale, attr(fxmale, "covariates"))

and then save df2

Hope this helps,

Rui Barradas

Em 20-09-2014 07:52, Ujjwal Kumar escreveu:
> I have the datafram like "fxmale"
>
> head(fxmale)
>         x       y         D.fx         D.nc        D.sum1 445350
> 2463450 1.046935e-06 0.0002627856 0.00026383262 445350 2463950
> 1.314861e-06 0.0002618268 0.00026314163 445350 2464450 1.435987e-06
> 0.0002627193 0.00026415534 445350 2464950 1.362894e-06 0.0002652938
> 0.00026665675 445350 2465450 1.122175e-06 0.0002690738 0.00027019606
> 445350 2465950 7.998899e-07 0.0002734074 0.0002742073
>
> when I am trying to export as csv I am getting only the first two columns
> (x & y) not others columns. This is the structure of the data.
>
>> str(fxmale)
> Classes ?Dsurface?, ?mask? and 'data.frame':    5735 obs. of  2 variables:
>   $ x: int  445350 445350 445350 445350 445350 445350 445350 445350
> 445350 445350 ...
>   $ y: int  2463450 2463950 2464450 2464950 2465450 2465950 2470950
> 2471450 2471950 2472450 ...
>   - attr(*, "covariates")='data.frame':  5735 obs. of  3 variables:
>    ..$ D.fx : num  1.05e-06 1.31e-06 1.44e-06 1.36e-06 1.12e-06 ...
>    ..$ D.nc : num  0.000263 0.000262 0.000263 0.000265 0.000269 ...
>    ..$ D.sum: num  0.000264 0.000263 0.000264 0.000267 0.00027 ...
>   - attr(*, "type")= chr "user"
>   - attr(*, "meanSD")='data.frame':      2 obs. of  2 variables:
>    ..$ x: num  475535 17942
>    ..$ y: num  2458930 10937
>   - attr(*, "area")= num 25
>   - attr(*, "spacing")= num 500
>   - attr(*, "boundingbox")='data.frame': 4 obs. of  2 variables:
>    ..$ x: num  445100 507600 507600 445100
>    ..$ y: num  2434700 2434700 2483700 2483700
>    ..- attr(*, "out.attrs")=List of 2
>    .. ..$ dim     : Named int  2 2
>    .. .. ..- attr(*, "names")= chr  "x" "y"
>    .. ..$ dimnames:List of 2
>    .. .. ..$ x: chr  "x=445100" "x=507600"
>    .. .. ..$ y: chr  "y=2434700" "y=2483700"
>
> can any body help me???
>


From suharto_anggono at yahoo.com  Sat Sep 20 12:52:15 2014
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 20 Sep 2014 03:52:15 -0700
Subject: [R] factor(300000, levels=1:300000) gives NA
Message-ID: <1411210335.13894.YahooMailBasic@web125101.mail.ne1.yahoo.com>

In R:

> factor(300000, levels=1:300000)
[1] <NA>
300000 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... 300000

The NA above is undesirable in my view, because 300000 is in 1:300000.


I have just got bitten by it.


I have figured out why it happens. The results of 'as.character' are different.

> as.character(300000)
[1] "3e+05"
> as.character((1:300000)[300000])
[1] "300000"


> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From jdnewmil at dcn.davis.CA.us  Sat Sep 20 17:51:25 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 20 Sep 2014 08:51:25 -0700
Subject: [R] factor(300000, levels=1:300000) gives NA
In-Reply-To: <1411210335.13894.YahooMailBasic@web125101.mail.ne1.yahoo.com>
References: <1411210335.13894.YahooMailBasic@web125101.mail.ne1.yahoo.com>
Message-ID: <fc3f643d-bca2-4ccc-878a-804f4ba2dbea@email.android.com>

I would say having 300000 levels is a bad idea... You should be re-thinking your analysis.

If you are still convinced that this is necessary, then do it right:

factor(300000L, levels=1:300000)

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 20, 2014 3:52:15 AM PDT, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:
>In R:
>
>> factor(300000, levels=1:300000)
>[1] <NA>
>300000 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
>23 ... 300000
>
>The NA above is undesirable in my view, because 300000 is in 1:300000.
>
>
>I have just got bitten by it.
>
>
>I have figured out why it happens. The results of 'as.character' are
>different.
>
>> as.character(300000)
>[1] "3e+05"
>> as.character((1:300000)[300000])
>[1] "300000"
>
>
>> sessionInfo()
>R version 3.1.1 (2014-07-10)
>Platform: i386-w64-mingw32/i386 (32-bit)
>
>locale:
>[1] LC_COLLATE=English_United States.1252
>[2] LC_CTYPE=English_United States.1252
>[3] LC_MONETARY=English_United States.1252
>[4] LC_NUMERIC=C
>[5] LC_TIME=English_United States.1252
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Sat Sep 20 18:01:09 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 20 Sep 2014 16:01:09 +0000
Subject: [R]
	=?utf-8?q?optim=2C_L-BFGS-B_=7C_constrained_bounds_on_parms?=
	=?utf-8?q?=3F?=
References: <mailman.23.1411120807.23892.r-help@r-project.org>
	<541C4C95.7080902@uottawa.ca> <541C4D8B.80301@gmail.com>
Message-ID: <loom.20140920T175940-144@post.gmane.org>

Evan Cooch <evan.cooch <at> gmail.com> writes:

> 
>   You could also use Rvmmin
> > that has bounds, or nmkb from dfoptim (though you
> cannot start on bounds).
> >
> 
> One 'negative' for dfoptim is that is doesn't automatically generate the 
> Hessian (as far as I can tell). Rather nice to be able to do so for 
> other calculations that usual follow after the optimization. optimx has 
> a control option for that.
> 

  I think Rvmmin requires the gradient function to be defined (don't
remember whether that's easy for you or not).
  Some more options for bounded optimization are bobyqa from the 
minqa package, or the equivalent from the nloptr package -- neither
computes the hessian, but the numDeriv package makes that pretty
easy ...

   Ben Bolker


From wdunlap at tibco.com  Sat Sep 20 18:10:01 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 20 Sep 2014 09:10:01 -0700
Subject: [R] factor(300000, levels=1:300000) gives NA
In-Reply-To: <1411210335.13894.YahooMailBasic@web125101.mail.ne1.yahoo.com>
References: <1411210335.13894.YahooMailBasic@web125101.mail.ne1.yahoo.com>
Message-ID: <CAF8bMcb6yCq9QKhEKarJOWVU4NEsbEaDayZSkJDxsKQX13NULg@mail.gmail.com>

You can work around this issue by matching the types of the the 'x'
and 'levels' arguments to factor():
  > factor(300000, as.numeric(299999:300001)) # both are floating
point ('numeric')
  [1] 3e+05
  Levels: 299999 3e+05 300001
  > factor(as.integer(300000), 299999:300001) # both are integer
  [1] 300000
  Levels: 299999 300000 300001

If the types do not match you get undesirable results
  > factor(300000, 299999:300001) # x is numeric, levels is integer
  [1] <NA>
  Levels: 299999 300000 300001
  > factor(300000L, as.numeric(299999:300001)) # x is integer, levels is numeric
  [1] <NA>
  Levels: 299999 3e+05 300001

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Sep 20, 2014 at 3:52 AM, Suharto Anggono Suharto Anggono
<suharto_anggono at yahoo.com> wrote:
> In R:
>
>> factor(300000, levels=1:300000)
> [1] <NA>
> 300000 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... 300000
>
> The NA above is undesirable in my view, because 300000 is in 1:300000.
>
>
> I have just got bitten by it.
>
>
> I have figured out why it happens. The results of 'as.character' are different.
>
>> as.character(300000)
> [1] "3e+05"
>> as.character((1:300000)[300000])
> [1] "300000"
>
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Sat Sep 20 20:03:19 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 20 Sep 2014 11:03:19 -0700
Subject: [R] read.table() 1Gb text dataframe
In-Reply-To: <418274300.9415027.1411146450014.JavaMail.zimbra@stanford.edu>
References: <1391727814.8319228.1411084115662.JavaMail.zimbra@stanford.edu>
	<CAFDcVCQ-ZV3Rf0zbje7AMafdDMbjJzGmAMPwNb7yxjBJ7xKMhg@mail.gmail.com>
	<418274300.9415027.1411146450014.JavaMail.zimbra@stanford.edu>
Message-ID: <CAFDcVCShOkDo7RajT8UHBGfs+80Gvbtk-ZE50K0b5GDCeH6w2w@mail.gmail.com>

On Fri, Sep 19, 2014 at 10:07 AM, Stephen HK Wong <honkit at stanford.edu> wrote:
> Thanks Henrick. Seems it fits my needs. One my question is the argument, length.out=0.10*n, is it "randomly" taking out 10% ? I found it basically takes every 10th row if I put length.out=0.1*n, and every 100th row if I put length.out=0.01*n till the end. I couldn't find this information on documentation.

If you look at the call, argument 'rows' is just an integer (index)
vector that specified which rows to read.  I used

  seq(from=1, to=n, length.out=0.10*n)

as an illustration.  See ?seq for how that works.  If you want to get
a random sample, I recommend to use sample() to generate that index
vector.

If you're going to read the same data file many many times, I
recommend to also look into what Greg suggested, particularly 'sqldf'
which does not take that much to learn.

/Henrik

>
> Stephen HK Wong
> Stanford, California 94305-5324
>
> ----- Original Message -----
> From: Henrik Bengtsson <hb at biostat.ucsf.edu>
> To: Stephen HK Wong <honkit at stanford.edu>
> Cc: r-help at r-project.org
> Sent: Thu, 18 Sep 2014 18:33:15 -0700 (PDT)
> Subject: Re: [R] read.table() 1Gb text dataframe
>
> As a start, make sure you specify the 'colClasses' argument.  BTW,
> using that you can even go to the extreme and read one column at the
> time, if it comes down to that.
>
> To read a 10% subset of the rows, you can use R.filesets as:
>
> library(R.filesets)
> db <- TabularTextFile(pathname)
> n <- nbrOfRows(db)
> data <- readDataFrame(db, rows=seq(from=1, to=n, length.out=0.10*n))
>
> It is also useful to specify 'colClasses' here. In addition to
> specifying them ordered by column, as for read.table(), you also
> specify them by column names (or regular expressions of the column
> names), e.g.
>
> data <- readDataFrame(db, colClasses=c("*"="NULL", "(x|y)"="integer",
> outcome="numeric", "id"="character"), rows=seq(from=1, to=n,
> length.out=0.10*n))
>
> That 'colClasses' specifies that the default is drop all columns, read
> columns 'x' and 'y' as integers, and so on.
>
> BTW, if you know 'n' upfront you can skip the setup of TabularTextFile
> and just do:
>
> data <- readDataFrame(pathname, rows=seq(from=1, to=n, length.out=0.10*n))
>
>
> Hope this helps
>
> Henrik
>
> On Thu, Sep 18, 2014 at 4:48 PM, Stephen HK Wong <honkit at stanford.edu> wrote:
>> Dear All,
>>
>> I have a table of 4 columns and many millions rows separated by tab-delimited. I don't have enough memory to read.table in that 1 Gb file. And actually I have 12 text files like that. Is there a way that I can just randomly read.table() in 10% of rows ? I was able to do that using colbycol package, but it is not not available. Many thanks!!
>>
>>
>>
>> Stephen HK Wong
>> Stanford, California 94305-5324
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From dwinsemius at comcast.net  Sat Sep 20 21:55:18 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 20 Sep 2014 12:55:18 -0700
Subject: [R] Converting xy plot arguments into a point argument and
	fixed x-axis scaling
In-Reply-To: <trinity-3843ab08-45ce-4f20-a267-124c76fe6d26-1411160107826@3capp-gmx-bs36>
References: <trinity-3843ab08-45ce-4f20-a267-124c76fe6d26-1411160107826@3capp-gmx-bs36>
Message-ID: <64A2583A-B112-40DA-8126-E3CE8269F6DB@comcast.net>


On Sep 19, 2014, at 1:55 PM, nebulo help wrote:

> Dear all, 
>   
> I have a data.frame xy which I am plotting like in the code below (provided is a small data sample with dummy data that should work). 
>   
> Is there a way how I could convert my xx and yy in the xy plot to a points command so that I could set type='n' and add points afterwards in order to control it better? 
>   
> In the end what I am also aiming for is a fixed x-axis range (e.g. from 1940 to 2014) and if values before 1940 are present the x axis should be automatic. The y axis should always be in the range of the values generated for each plot. 

I would think the general strategy would be to call `plot` and axis (twice) just once and axis (twice) with the xlim, ylim, xlab and ylab set to your specifications and then within the loop, use `points`.


-- 

David.
>   
> Thank you for your help! 
> 
> Kind regards,
> Kurt
>   
> ########################### 
>   
> Here is my code with sample data: 
>   
> # read in sample data 
> xy <- data.frame(NAME=c("NAME1","NAME1","NAME1","NAME2","NAME2","NAME2"),ID=c(87,87,87,199,199,199), X_START_YEAR=c(1984,1986,1984,1899,1909,1924),Y_START_VALUE=c(75,25,-90,-8,-55,-10),X_END_YEAR=c(1986,1994,1999,1909,1924,1927), Y_END_VALUE=c(20,50,-15,-70,-80,-100)) 
>     
> # split data.frame into groups (defined by ID in this case) 
> ind <- split(xy,xy$ID) 
> # plot data by group 
> for (x in ind){ 
>   xx = unlist(x[,grep('X_',colnames(x))]) 
>   yy = unlist(x[,grep('Y_',colnames(x))])     
>     fname <- paste0(x[1, 'ID'], '.png') 
>     png(fname, width=1679, height=1165, res=150) 
>     par(mar=c(6,8,6,5)) 
>     plot(xx, 
>          yy, 
>          main=unique(x[,1]), 
>          xlab="Time [Years]", 
>          ylab="Value [m]") 
>     axis(1, at = seq(1000, 2050, 5), cex.axis=1, labels=FALSE, tcl=-0.3) 
>     axis(2, at = seq(-100000, 100000, 500), cex.axis=1, labels=FALSE, tcl=-0.3) 
>     x <- x[,-1] 
>     segments(x[,2],x[,3],x[,4],x[,5],lwd=2) 
>     dev.off() 
>   }
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ligges at statistik.tu-dortmund.de  Sun Sep 21 00:16:19 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 21 Sep 2014 00:16:19 +0200
Subject: [R] R2WINBUGS Error message
In-Reply-To: <CAB4W2n4LBmJzb9maWyqkq5_zL+D3pQD=1Ru0XVNaLgcOMpHLCA@mail.gmail.com>
References: <CAB4W2n4LBmJzb9maWyqkq5_zL+D3pQD=1Ru0XVNaLgcOMpHLCA@mail.gmail.com>
Message-ID: <541DFCB3.6020703@statistik.tu-dortmund.de>



On 18.09.2014 08:22, Hanze Zhang wrote:
> Hi, guys,
>
> I am a new user for package R2winbugs. When I run the code a=bugs(...), an
> error message always comes out, see below:
>
> Error in file(con, "wb") : cannot open the connection
> In addition: Warning messages:
> 1: In file.create(to[okay]) :
>    cannot create file 'c:/Program
> Files/WinBUGS14//System/Rsrc/Registry_Rsave.odc', reason 'Permission denied'
> 2: In file(con, "wb") :
>    cannot open file 'c:/Program Files/WinBUGS14//System/Rsrc/Registry.odc':
> Permission denied
>
> How to solve this issue?


Run with Admin privileges or install WinBUGS in a plcce where you have 
write permissions.

Best,
Uwe Ligges




>
> Thanks a lot!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wickedpuppy at gmail.com  Sun Sep 21 15:06:45 2014
From: wickedpuppy at gmail.com (billy am)
Date: Sun, 21 Sep 2014 21:06:45 +0800
Subject: [R] A new environment within the main function
Message-ID: <CAJ_FNV7foBFkmxXeDmztoh0FNPyJRTGTnXPa49GqLQ4x1CADCw@mail.gmail.com>

Hi Everyone ,

I am having an issue with the following code and would need kind assistant.

For a specific reason , I would need to create a new environment for
variables within the function and use them and I am having issue with it on
the project I am doing.

The issue is that no matter what I do , I am getting the following error on

"Error in eval(expr, envir, enclos) : object 'x3' not found"

and it is the x3 that is within the groupedData(y~-1 + x3 | g

and not in the data.frame

fun1 <- function()
{
  ee <- new.env()
  t <- 10
  x <- 5
  g<- 8

  assign("x2",x,envir = as.environment(ee))

  x3 <- get("x2" , envir = as.environment(ee))

  if(t == 10)
  {
    if(g == 8)
      {

         data.fr <- groupedData(y~-1 + x3 | g,
                    data=data.frame(y,x3,h, dummy))
    }

  }

}

Thanks and Regards
Billy

	[[alternative HTML version deleted]]


From chabot.denis at gmail.com  Sun Sep 21 15:11:54 2014
From: chabot.denis at gmail.com (Denis Chabot)
Date: Sun, 21 Sep 2014 09:11:54 -0400
Subject: [R] puzzled by time zone quirk
Message-ID: <C68FF557-34F2-497A-9BF7-8C774FB08CD7@gmail.com>

Hi,

I have to deal with time-stamped data coming from outside my own time zone, so the problem is likely poor knowledge of European time zones on my part. But I am puzzled just the same.

I thought that setting a time zone of "Europe/Copenhagen" would be the same as "CET" in winter and "CEST" in summer.

This test in winter works as expected:

> a = as.POSIXct("2013-02-25 01:00:00", tz="Europe/Copenhagen"); a
[1] "2013-02-25 01:00:00 CET"
> b = as.POSIXct("2013-02-25 01:00:00", tz="CET"); b
[1] "2013-02-25 01:00:00 CET"
> a-b
Time difference of 0 secs

But this one is summer does not work as I expected:

> c = as.POSIXct("2013-07-25 01:00:00", tz="Europe/Copenhagen"); c
[1] "2013-07-25 01:00:00 CEST"
> d = as.POSIXct("2013-07-25 01:00:00", tz="CEST"); d
[1] "2013-07-25 01:00:00 UTC"
> e = as.POSIXct("2013-07-25 01:00:00", tz="CET"); e
[1] "2013-07-25 01:00:00 CEST"
> c-d
Time difference of -2 hours
> c-e
Time difference of 0 secs

Setting tz to "Europe/Copenhagen" in summer in c first appears to be the same as setting it to "CEST" because the output is showing "CEST".

But d should then be the same as c, and it is not.

What is happening?

Thanks in advance,

Denis Chabot


From ripley at stats.ox.ac.uk  Sun Sep 21 16:00:59 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 21 Sep 2014 15:00:59 +0100
Subject: [R] puzzled by time zone quirk
In-Reply-To: <C68FF557-34F2-497A-9BF7-8C774FB08CD7@gmail.com>
References: <C68FF557-34F2-497A-9BF7-8C774FB08CD7@gmail.com>
Message-ID: <541EDA1B.7000503@stats.ox.ac.uk>

On 21/09/2014 14:11, Denis Chabot wrote:
> Hi,
>
> I have to deal with time-stamped data coming from outside my own time zone, so the problem is likely poor knowledge of European time zones on my part. But I am puzzled just the same.
>
> I thought that setting a time zone of "Europe/Copenhagen" would be the same as "CET" in winter and "CEST" in summer.

You thought wrong: CEST is not a valid timezone on most (maybe all) R 
platforms.

You failed to tell us the 'at a minimum' information required by the 
posting guide.  ?Sys.timezone says OlsonNames() tells you the timezone 
names supported on your unstated platform, and  ?as.POSIXct says

       tz: A time zone specification to be used for the conversion, _if
           one is required_.  System-specific (see time zones), but ?""?
           is the current time zone, and ?"GMT"? is UTC (Universal Time,
           Coordinated). Invalid values are most commonly treated as
           UTC, on some platforms with a warning.


As the posting guide asks, please do your own homework.


> This test in winter works as expected:
>
>> a = as.POSIXct("2013-02-25 01:00:00", tz="Europe/Copenhagen"); a
> [1] "2013-02-25 01:00:00 CET"
>> b = as.POSIXct("2013-02-25 01:00:00", tz="CET"); b
> [1] "2013-02-25 01:00:00 CET"
>> a-b
> Time difference of 0 secs
>
> But this one is summer does not work as I expected:
>
>> c = as.POSIXct("2013-07-25 01:00:00", tz="Europe/Copenhagen"); c
> [1] "2013-07-25 01:00:00 CEST"
>> d = as.POSIXct("2013-07-25 01:00:00", tz="CEST"); d
> [1] "2013-07-25 01:00:00 UTC"
>> e = as.POSIXct("2013-07-25 01:00:00", tz="CET"); e
> [1] "2013-07-25 01:00:00 CEST"
>> c-d
> Time difference of -2 hours
>> c-e
> Time difference of 0 secs
>
> Setting tz to "Europe/Copenhagen" in summer in c first appears to be the same as setting it to "CEST" because the output is showing "CEST".
>
> But d should then be the same as c, and it is not.
>
> What is happening?
>
> Thanks in advance,
>
> Denis Chabot
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From chabot.denis at gmail.com  Sun Sep 21 16:39:59 2014
From: chabot.denis at gmail.com (Denis Chabot)
Date: Sun, 21 Sep 2014 16:39:59 +0200
Subject: [R] puzzled by time zone quirk
In-Reply-To: <541EDA1B.7000503@stats.ox.ac.uk>
References: <C68FF557-34F2-497A-9BF7-8C774FB08CD7@gmail.com>
	<541EDA1B.7000503@stats.ox.ac.uk>
Message-ID: <4013D7C6-50EE-4456-94D7-734E1D133B04@gmail.com>

Sorry, I had not posted in a long time and I remembered this as I pushed the "send" button.

And I am not surprised that I thought wrong!

I'll start with the missing information:

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.0.2

Then I'll admit that some of the very useful details you provided had escaped me, but in my defense, I took to heart one element found in ?Sys.timezone:

It is not in general possible to retrieve the system's own name(s) for the current timezone, but Sys.timezone will retrieve the name it uses for the current time (and the name may differ depending on whether daylight saving time is in effect).

When I tell my computer that I am in Europe, I get 
Sys.time()
[1] "2014-09-21 16:38:45 CEST"

As the output of my "c" also displayed "CEST", I assumed this was the preferred way to refer to that time zone. Because of this, I had expected c and d to be the same. The output of c is deceiving. But at least I now know not to use "CEST".

Denis

Le 2014-09-21 ? 10:00, Prof Brian Ripley <ripley at stats.ox.ac.uk> a ?crit :

> On 21/09/2014 14:11, Denis Chabot wrote:
>> Hi,
>> 
>> I have to deal with time-stamped data coming from outside my own time zone, so the problem is likely poor knowledge of European time zones on my part. But I am puzzled just the same.
>> 
>> I thought that setting a time zone of "Europe/Copenhagen" would be the same as "CET" in winter and "CEST" in summer.
> 
> You thought wrong: CEST is not a valid timezone on most (maybe all) R platforms.
> 
> You failed to tell us the 'at a minimum' information required by the posting guide.  ?Sys.timezone says OlsonNames() tells you the timezone names supported on your unstated platform, and  ?as.POSIXct says
> 
>      tz: A time zone specification to be used for the conversion, _if
>          one is required_.  System-specific (see time zones), but ?""?
>          is the current time zone, and ?"GMT"? is UTC (Universal Time,
>          Coordinated). Invalid values are most commonly treated as
>          UTC, on some platforms with a warning.
> 
> 
> As the posting guide asks, please do your own homework.
> 
> 
>> This test in winter works as expected:
>> 
>>> a = as.POSIXct("2013-02-25 01:00:00", tz="Europe/Copenhagen"); a
>> [1] "2013-02-25 01:00:00 CET"
>>> b = as.POSIXct("2013-02-25 01:00:00", tz="CET"); b
>> [1] "2013-02-25 01:00:00 CET"
>>> a-b
>> Time difference of 0 secs
>> 
>> But this one is summer does not work as I expected:
>> 
>>> c = as.POSIXct("2013-07-25 01:00:00", tz="Europe/Copenhagen"); c
>> [1] "2013-07-25 01:00:00 CEST"
>>> d = as.POSIXct("2013-07-25 01:00:00", tz="CEST"); d
>> [1] "2013-07-25 01:00:00 UTC"
>>> e = as.POSIXct("2013-07-25 01:00:00", tz="CET"); e
>> [1] "2013-07-25 01:00:00 CEST"
>>> c-d
>> Time difference of -2 hours
>>> c-e
>> Time difference of 0 secs
>> 
>> Setting tz to "Europe/Copenhagen" in summer in c first appears to be the same as setting it to "CEST" because the output is showing "CEST".
>> 
>> But d should then be the same as c, and it is not.
>> 
>> What is happening?
>> 
>> Thanks in advance,
>> 
>> Denis Chabot
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sun Sep 21 16:44:58 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 21 Sep 2014 15:44:58 +0100
Subject: [R] puzzled by time zone quirk
In-Reply-To: <4013D7C6-50EE-4456-94D7-734E1D133B04@gmail.com>
References: <C68FF557-34F2-497A-9BF7-8C774FB08CD7@gmail.com>
	<541EDA1B.7000503@stats.ox.ac.uk>
	<4013D7C6-50EE-4456-94D7-734E1D133B04@gmail.com>
Message-ID: <541EE46A.4010301@stats.ox.ac.uk>

You neglected to update before posting as required by the posting guide.

R 3.0.2 is far from current, and on OS X the timezone internals were 
replaced in R 3.1.x (the previous version did not handle 64-bit time_t 
correctly, even though that is what OS X uses).  And the documentation 
is different.


On 21/09/2014 15:39, Denis Chabot wrote:
> Sorry, I had not posted in a long time and I remembered this as I pushed the "send" button.
>
> And I am not surprised that I thought wrong!
>
> I'll start with the missing information:
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.2
>
> Then I'll admit that some of the very useful details you provided had escaped me, but in my defense, I took to heart one element found in ?Sys.timezone:
>
> It is not in general possible to retrieve the system's own name(s) for the current timezone, but Sys.timezone will retrieve the name it uses for the current time (and the name may differ depending on whether daylight saving time is in effect).
>
> When I tell my computer that I am in Europe, I get
> Sys.time()
> [1] "2014-09-21 16:38:45 CEST"
>
> As the output of my "c" also displayed "CEST", I assumed this was the preferred way to refer to that time zone. Because of this, I had expected c and d to be the same. The output of c is deceiving. But at least I now know not to use "CEST".
>
> Denis
>
> Le 2014-09-21 ? 10:00, Prof Brian Ripley <ripley at stats.ox.ac.uk> a ?crit :
>
>> On 21/09/2014 14:11, Denis Chabot wrote:
>>> Hi,
>>>
>>> I have to deal with time-stamped data coming from outside my own time zone, so the problem is likely poor knowledge of European time zones on my part. But I am puzzled just the same.
>>>
>>> I thought that setting a time zone of "Europe/Copenhagen" would be the same as "CET" in winter and "CEST" in summer.
>>
>> You thought wrong: CEST is not a valid timezone on most (maybe all) R platforms.
>>
>> You failed to tell us the 'at a minimum' information required by the posting guide.  ?Sys.timezone says OlsonNames() tells you the timezone names supported on your unstated platform, and  ?as.POSIXct says
>>
>>       tz: A time zone specification to be used for the conversion, _if
>>           one is required_.  System-specific (see time zones), but ?""?
>>           is the current time zone, and ?"GMT"? is UTC (Universal Time,
>>           Coordinated). Invalid values are most commonly treated as
>>           UTC, on some platforms with a warning.
>>
>>
>> As the posting guide asks, please do your own homework.
>>
>>
>>> This test in winter works as expected:
>>>
>>>> a = as.POSIXct("2013-02-25 01:00:00", tz="Europe/Copenhagen"); a
>>> [1] "2013-02-25 01:00:00 CET"
>>>> b = as.POSIXct("2013-02-25 01:00:00", tz="CET"); b
>>> [1] "2013-02-25 01:00:00 CET"
>>>> a-b
>>> Time difference of 0 secs
>>>
>>> But this one is summer does not work as I expected:
>>>
>>>> c = as.POSIXct("2013-07-25 01:00:00", tz="Europe/Copenhagen"); c
>>> [1] "2013-07-25 01:00:00 CEST"
>>>> d = as.POSIXct("2013-07-25 01:00:00", tz="CEST"); d
>>> [1] "2013-07-25 01:00:00 UTC"
>>>> e = as.POSIXct("2013-07-25 01:00:00", tz="CET"); e
>>> [1] "2013-07-25 01:00:00 CEST"
>>>> c-d
>>> Time difference of -2 hours
>>>> c-e
>>> Time difference of 0 secs
>>>
>>> Setting tz to "Europe/Copenhagen" in summer in c first appears to be the same as setting it to "CEST" because the output is showing "CEST".
>>>
>>> But d should then be the same as c, and it is not.
>>>
>>> What is happening?
>>>
>>> Thanks in advance,
>>>
>>> Denis Chabot
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>> 1 South Parks Road, Oxford OX1 3TG, UK
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From chabot.denis at gmail.com  Sun Sep 21 17:36:18 2014
From: chabot.denis at gmail.com (Denis Chabot)
Date: Sun, 21 Sep 2014 11:36:18 -0400
Subject: [R] puzzled by time zone quirk
In-Reply-To: <541EE46A.4010301@stats.ox.ac.uk>
References: <C68FF557-34F2-497A-9BF7-8C774FB08CD7@gmail.com>
	<541EDA1B.7000503@stats.ox.ac.uk>
	<4013D7C6-50EE-4456-94D7-734E1D133B04@gmail.com>
	<541EE46A.4010301@stats.ox.ac.uk>
Message-ID: <C728BA4E-7F83-4DC0-A265-9C2FB5F91271@gmail.com>

Hi again,

With the new installation:
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.1.1

I do get a warning that "CEST" is not a valid time zone, but "c" is still displayed with "CEST" as time zone, which remains confusing. 

> c = as.POSIXct("2013-07-25 01:00:00", tz="Europe/Copenhagen"); c
[1] "2013-07-25 01:00:00 CEST"
> d = as.POSIXct("2013-07-25 01:00:00", tz="CEST"); d
Messages d'avis :
1: In strptime(xx, f <- "%Y-%m-%d %H:%M:%OS", tz = tz) :
  unknown timezone 'CEST'
2: In as.POSIXct.POSIXlt(x) : unknown timezone 'CEST'
3: In strptime(x, f, tz = tz) : unknown timezone 'CEST'
4: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
  unknown timezone 'CEST'
[1] "2013-07-25 01:00:00 GMT"
Message d'avis :
In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'CEST'

It is fine now that I am warned, but I wish CEST did not appear at all.

Denis

Le 2014-09-21 ? 10:44, Prof Brian Ripley <ripley at stats.ox.ac.uk> a ?crit :

> You neglected to update before posting as required by the posting guide.
> 
> R 3.0.2 is far from current, and on OS X the timezone internals were replaced in R 3.1.x (the previous version did not handle 64-bit time_t correctly, even though that is what OS X uses).  And the documentation is different.
> 
> 
> ...

> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK


From murdoch.duncan at gmail.com  Sun Sep 21 22:08:00 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 21 Sep 2014 16:08:00 -0400
Subject: [R] A new environment within the main function
In-Reply-To: <CAJ_FNV7foBFkmxXeDmztoh0FNPyJRTGTnXPa49GqLQ4x1CADCw@mail.gmail.com>
References: <CAJ_FNV7foBFkmxXeDmztoh0FNPyJRTGTnXPa49GqLQ4x1CADCw@mail.gmail.com>
Message-ID: <541F3020.6000903@gmail.com>

On 21/09/2014, 9:06 AM, billy am wrote:
> Hi Everyone ,
> 
> I am having an issue with the following code and would need kind assistant.
> 
> For a specific reason , I would need to create a new environment for
> variables within the function and use them and I am having issue with it on
> the project I am doing.
> 
> The issue is that no matter what I do , I am getting the following error on
> 
> "Error in eval(expr, envir, enclos) : object 'x3' not found"
> 
> and it is the x3 that is within the groupedData(y~-1 + x3 | g
> 
> and not in the data.frame

It's not at all clear what you are attempting to do, but there are a few
strange things in your code:

> 
> fun1 <- function()
> {
>   ee <- new.env()
>   t <- 10
>   x <- 5
>   g<- 8
> 
>   assign("x2",x,envir = as.environment(ee))

ee is already an environment; why use as.environment?

> 
>   x3 <- get("x2" , envir = as.environment(ee))

Ditto.

> 
>   if(t == 10)
>   {
>     if(g == 8)
>       {

What have those got to do with the problem of interest?  It's a good
idea to post "minimal" examples; distractions are distracting.

> 
>          data.fr <- groupedData(y~-1 + x3 | g,
>                     data=data.frame(y,x3,h, dummy))

What is groupedData?  We also ask for self-contained examples, and that
isn't in the default packages.  Are you talking about the function in
nlme?  If so, do you expect it to make use of ee?  It never sees ee.

And where does y come from?

Duncan Murdoch


>     }
> 
>   }
> 
> }
> 
> Thanks and Regards
> Billy
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From xijia.liu at umu.se  Sun Sep 21 14:56:15 2014
From: xijia.liu at umu.se (Xijia Liu)
Date: Sun, 21 Sep 2014 14:56:15 +0200
Subject: [R]  About the unit of shapefile and raster
Message-ID: <77871034E6314440AE3D09023B5A913202259B78@UMDAC-CCR2.ad.umu.se>

Dear Roger,

I want to make a raster for my shapefile. I am try to apply function "rasterize". However I get a problem of the unit of plot.

If I make a plot for my shapefile, then the unit is "degree". However, when I apply raster() and make a plot for it, the unit is not "degree". Please see the two plots I attached. I do not know if there is any problem... Is it due to the proj4string? And how to fix it?

Many thanks for your time!

Best regads

Xijia
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot1.png
Type: image/png
Size: 7760 bytes
Desc: Rplot1.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140921/541e824b/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot01.png
Type: image/png
Size: 10369 bytes
Desc: Rplot01.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140921/541e824b/attachment-0001.png>

From cranatic at gmail.com  Mon Sep 22 00:40:05 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 21 Sep 2014 18:40:05 -0400
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <541f53c5c3f2b_16cb3a7b93c1bc@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* adaptDA (1.0)
  Maintainer: Charles Bouveyron
  Author(s): Charles Bouveyron
  License: GPL-2
  http://crantastic.org/packages/adaptDA

  The adaptive mixture discriminant analysis (AMDA) allows to adapt a
  model-based classifier to the situation where a class represented in
  the test set may have not been encountered earlier in the learning
  phase.

* aRxiv (0.5.2)
  Maintainer: Karl W Broman
  Author(s): Karthik Ram [aut], Karl Broman [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/aRxiv

  An interface to the API for arXiv, a repository of electronic
  preprints for computer science, mathematics, physics, quantitative
  biology, quantitative finance, and statistics.

* audited (1.9)
  Maintainer: Tim Bergsma
  Author(s): Tim Bergsma
  License: GPL
  http://crantastic.org/packages/audited

  Classifies a data.frame such that row deletions and additions are
  tracked.  A mechanism exists to give formal names to the row subsets
  that are coming or going.  These names are used to populate a
  directed graph giving an account of all the transactions
  contributing to the state of the data.frame.  The generic
  as.audited() has a method for keyed data.frames that creates an
  audited data.frame. Methods exist that track row count changes for
  the generics: Ops, !, ^, |, [, subset, head, tail, unique, cast,
  melt, aggregate, and merge. audit() extracts the transaction table
  from the audited object, while write.audit() and read.audit()
  control exchange with the file system. An audit method for
  as.igraph() creates a graph object that can be displayed with the
  corresponding plot method.  Use options(audit= )  to provide an
  extra level of classification. Use options(artifact=TRUE)  and
  as.xlsx() to save dropped records to file.

* BEANSP (1.0)
  Maintainer: Yiqun Yang
  Author(s): Chong He, Yiqun Yang, Jing Cao
  License: GPL-2
  http://crantastic.org/packages/BEANSP

  Computing age specific nest survival rates based on a Bayesian
  hierarchical model. This package can handle unknown nest age,
  irregular visiting schedule and nest-specific covariates.

* binequality (0.6.1)
  Maintainer: Samuel V. Scarpino
  Author(s): Samuel V. Scarpino, Paul von Hippel, and Igor Holas
  License: GPL (>= 3.0)
  http://crantastic.org/packages/binequality

  Methods for model selection, model averaging, and calculating metrics,
  such as the Gini, Theil, Mean Log Deviation, etc, on binned income
  data where the topmost bin is right-censored.  We provide both a
  non-parametric method, termed the bounded midpoint estimator (BME),
  which assigns cases to their bin midpoints; except for the censored
  bins, where cases are assigned to an income estimated by fitting a
  Pareto distribution. Because the usual Pareto estimate can be
  inaccurate or undefined, especially in small samples, we implement a
  bounded Pareto estimate that yields much better results.  We also
  provide a parametric approach, which fits distributions from the
  generalized beta (GB) family. Because some GB distributions can have
  poor fit or undefined estimates, we fit 10 GB-family distributions
  and use multimodel inference to obtain definite estimates from the
  best-fitting distributions. We also provide binned income data from
  all United States of America school districts, counties, and states.

* BOIN (1.0)
  Maintainer: Ying Yuan
  Author(s): Ying Yuan and Suyu Liu
  License: GPL-2
  http://crantastic.org/packages/BOIN

  The Bayesian optimal interval (BOIN) design is a novel phase I
  clinical trial design for finding the maximum tolerated dose (MTD).
  The BOIN design is motivated by the top priority and concern of
  clinicians when testing a new drug, which is to effectively treat
  patients and minimize the chance of exposing them to subtherapeutic
  or overly toxic doses. The prominent advantage of the BOIN design is
  that it achieves simplicity and superior performance at the same
  time. The BOIN design is algorithm-based and can be implemented in a
  simple way similar to the traditional 3+3 design. The BOIN design
  yields average performance comparable to the continual reassessment
  method (CRM, one of the best model-based design) in terms of
  selecting the MTD, but has a substantially lower risk of assigning
  patients to subtherapeutic or overly toxic doses.

* confidence (1.0-0)
  Maintainer: Dennis Walvoort
  Author(s): Willem M. G. M. van Loon [aut, cph], Dennis J. J. Walvoort [aut, cre]
  License: GPL (>= 3)
  http://crantastic.org/packages/confidence

  Functions for estimating and reporting multiyear averages and
  corresponding confidence intervals and distributions. A potential
  use case is reporting the chemical and ecological status of surface
  waters according to the European Water Framework Directive.

* GlobalOptions (0.0.1)
  Maintainer: Zuguang Gu
  Author(s): Zuguang Gu
  License: GPL (>= 2)
  http://crantastic.org/packages/GlobalOptions

  Generate functions to get or set global options

* hot.deck (1.0)
  Maintainer: Dave Armstrong
  Author(s): Skyler Cranmer, Jeff Gill, Natalie Jackson, Andreas Murr, Dave
             Armstrong
  License: GPL (>= 2)
  http://crantastic.org/packages/hot-deck

  Performs multiple hot-deck imputation of categorical and continuous
  variables in a data frame.

* iki.dataclim (1.0)
  Maintainer: Boris Orlowsky
  Author(s): Boris Orlowsky
  License: GPL-3
  http://crantastic.org/packages/iki-dataclim

  The package offers an S4 infrastructure to store climatological
  station data of various temporal aggregation scales. In-built
  quality control and homogeneity tests follow the methodology from
  the European Climate Assessment &amp; Dataset project. Wrappers for
  climate indices defined by the Expert Team on Climate Change
  Detection and Indices (ETCCDI), a quick summary of important climate
  statistics and climate diagram plots provide a fast overview of
  climatological characteristics of the station.

* kselection (0.1.0)
  Maintainer: Daniel Rodriguez Perez
  Author(s): Daniel Rodriguez Perez
  License: GPL-3
  http://crantastic.org/packages/kselection

  Selection of k in k-means clustering based on Pham et al. paper
  ``Selection of k in k-means clustering&#39;&#39;

* m4fe (0.1)
  Maintainer: Nathan Esau
  Author(s): Nathan Esau <nesau at sfu.ca>
  License: GPL-2
  http://crantastic.org/packages/m4fe

  Provides binomial tree models for European, American and Asian Options
  as well as Interest Rates. Monte Carlo Simulation and Methods for
  Solving Differential Equations are also included.

* MatchingFrontier (0.3.17)
  Maintainer: Christopher Lucas
  Author(s): Gary King, Christopher Lucas, and Richard Nielsen
  License: GPL-3
  http://crantastic.org/packages/MatchingFrontier

  MatchingFrontier returns the subset of the data with the minimum
  imbalance for  	     every possible subset size (N - 1, N - 2, ...),
  down to the data set with the  	     minimum possible imbalance. The
  package also includes tools for the estimation 	     of causal
  effects for each subset size, as well as functions for visualization
  and data export.

* MST (1.0)
  Maintainer: Peter Calhoun
  Author(s): Xiaogang Su, Peter Calhoun, and Juanjuan Fan
  License: GPL-2
  http://crantastic.org/packages/MST

  Constructs trees for multivariate survival data using marginal and
  frailty models

* multipleNCC (1.0)
  Maintainer: Nathalie C. Stoer
  Author(s): Nathalie C. Stoer, Sven Ove Samuelsen
  License: GPL-2
  http://crantastic.org/packages/multipleNCC

  This package fit Cox proportional hazard models with a weighted 
  partial likelihood. It handles one or multiple endpoints, additional
  matching  and makes it possible to reuse controls for other
  endpoints.

* nat.nblast (1.5)
  Maintainer: James Manton
  Author(s): Greg Jefferis and James Manton
  License: GPL-3
  http://crantastic.org/packages/nat-nblast

  Extends package nat (NeuroAnatomy Toolbox) by providing a collection
  of NBLAST-related functions.

* nat.templatebrains (0.4.1)
  Maintainer: James Manton
  Author(s): James Manton and Greg Jefferis
  License: GPL-3
  http://crantastic.org/packages/nat-templatebrains

  Extends package nat (NeuroAnatomy Toolbox) by providing objects and
  functions for handling template brains.

* nlWaldTest (1.0.1)
  Maintainer: Oleh Komashko
  Author(s): Oleh Komashko
  License: GPL (>= 2)
  http://crantastic.org/packages/nlWaldTest

  Nonlinear restrictions Wald Test for regression parameters using
  delta-method

* opentraj (1.0)
  Maintainer: Thalles Silva
  Author(s): Thalles Santos Silva
  License: GPL-2
  http://crantastic.org/packages/opentraj

  opentraj uses the Hybrid Single Particle Lagrangian Integrated
  Trajectory Model (HYSPLIT) for computing simple air parcel
  trajectories. The functions in this package allow users to run
  HYSPLIT for trajectory calculations, as well as get its results,
  directly from R without using any GUI interface.

* polidata (0.1.0)
  Maintainer: Eunjeong Park
  Author(s): Eunjeong Park [aut, cre], Jong Hee Park [aut]
  License: MIT + file LICENSE
  http://crantastic.org/packages/polidata

  This package provides easy access to various political data APIs
  directly from R. For example, you can access Google Civic
  Information API (https://developers.google.com/civic-information/)
  or Sunlight Congress API (https://sunlightlabs.github.io/congress/)
  for US Congress data, and POPONG API (http://data.popong.com/) for
  South Korea National Assembly data.

* powerr (0.1-3)
  Maintainer: Jingfan Sun
  Author(s): Jingfan Sun [aut, cre]
  License: GPL (>= 2)
  http://crantastic.org/packages/powerr

  &#39;powerr&#39; is used for electric power system analysis and control,
  including basic power flow analysis and CASCADE analysis. Other
  features will be updated soon.

* propOverlap (1.0)
  Maintainer: Osama Mahmoud
  Author(s): Osama Mahmoud, Andrew Harrison, Aris Perperoglou, Asma Gul, Zardad
             Khan, Berthold Lausen
  License: GPL (>= 2)
  http://crantastic.org/packages/propOverlap

  A package for selecting the most relevant features (genes) in the
  high-dimensional binary classification problems. The discriminative
  features are identified using analyzing the overlap between the
  expression values across both classes. The package includes
  functions for measuring the proportional overlapping score for each
  gene avoiding the outliers effect. The used measure for the overlap
  is the one defined in the &quot;Proportional Overlapping Score (POS)&quot;
  technique for feature selection. A gene mask which represents a
  gene&#39;s classification power can also be produced for each gene
  (feature). The set size of the selected genes might be set by the
  user. The minimum set of genes that correctly classify the maximum
  number of the given tissue samples (observations) can be also
  produced.

* qdapRegex (0.1.1)
  Maintainer: Tyler Rinker
  Author(s): Jason Gray [ctb], Tyler Rinker [aut, cre]
  License: GPL-2
  http://crantastic.org/packages/qdapRegex

  A collection of regex tools associated with the qdap package that may
  be useful outside of the context of discourse analysis.  Tools
  include removal/extraction/replacement of abbreviations, dates,
  dollar amounts, email addresses, hash tags, numbers, percentages,
  person tags, phone numbers, times, and zip codes.

* qgtools (1.0)
  Maintainer: Jixiang Wu
  Author(s): Jixiang Wu (South Dakota State University), Johnie N. Jenkins and Jack
             C. McCarty (USDA-ARS)
  License: GPL-2
  http://crantastic.org/packages/qgtools

  Two linear mixed model approaches: REML(restricted maximum likelihood)
  and MINQUE (minimum norm quadratic unbiased estimation) approaches
  and several resampling techniques are integrated for various
  quantitative genetics analyses. With these two types of approaches,
  various unbalanced data structures, missing data, and any irregular
  genetic  mating designs can be analyzed and statistically tested.
  This package also offers fast computations for many large data sets.
  Other functions will be added to this R tool in the future.

* redcapAPI (1.0)
  Maintainer: Benjamin Nutter
  Author(s): Benjamin Nutter. Initiated by Jeffrey Horner and Will Gray with
             contributions from Jeremy Stephens, and Will Beasley
  License: GPL-2
  http://crantastic.org/packages/redcapAPI

  Access data stored in REDCap databases using the Application
  Programming Interface (API).  REDCap (Research Electronic Data
  CAPture) is a web application for building and managing online
  surveys and databases developed at Vanderbilt University.  The API
  allows users to access data and project meta data (such as the data
  dictionary) from the web programmatically.  The redcapAPI package
  facilitates the process of accessing data with options to prepare an
  analysis-ready data set consistent with the definitions in a
  database&#39;s data dictionary.

* REDCapR (0.4-28)
  Maintainer: Will Beasley
  Author(s): Will Beasley [aut, cre], David Bard [ctb], Thomas Wilson [ctb], John J
             Aponte [ctb], Rollie Parrish [ctb]
  License: GPL-3
  http://crantastic.org/packages/REDCapR

  Encapsulates functions to streamline calls from R

* rmarkdown (0.3.3)
  Maintainer: JJ Allaire
  Author(s): JJ Allaire, Jonathan McPherson, Yihui Xie, Hadley Wickham, Joe Cheng,
             Jeff Allen
  License: GPL-3
  http://crantastic.org/packages/rmarkdown

  Convert R Markdown documents into a variety of formats including HTML,
  MS Word, PDF, and Beamer.

* RMOA (1.0)
  Maintainer: Jan Wijffels
  Author(s): Jan Wijffels [aut, cre], BNOSAC [cph]
  License: GPL-3
  http://crantastic.org/packages/RMOA

  Connect R with MOA (Massive Online Analysis -
  http://moa.cms.waikato.ac.nz) to build classification models and
  regression models on streaming data or out-of-RAM data

* RMOAjars (1.0)
  Maintainer: Jan Wijffels
  Author(s): See file AUTHORS
  License: GPL-3
  http://crantastic.org/packages/RMOAjars

  External jars required for package RMOA. RMOA is a framework to build
  data stream models on top of MOA (Massive Online Analysis -
  http://moa.cms.waikato.ac.nz)

* RRreg (0.1.3)
  Maintainer: Daniel W. Heck
  Author(s): Daniel W. Heck [aut, cre], Morten Moshagen [aut]
  License: GPL-2
  http://crantastic.org/packages/RRreg

  RRreg provides univariate and multivariate methods to analyze
  randomized response (RR) survey designs (e.g., Warner, S. L. (1965).
  Randomized response: A survey technique for eliminating evasive
  answer bias. Journal of the American Statistical Association, 60,
  63???69). Besides univariate estimates of true proportions, RR
  variables can be used for correlations, as dependent variable in a
  logistic regression and as predictors in a linear regression. For
  simulation and bootstrap purposes, RR data can be generated
  according to several models.

* smoother (1.0.0.0)
  Maintainer: Nicholas Hamilton
  Author(s): Nicholas Hamilton
  License: GPL-2
  http://crantastic.org/packages/smoother

  A port of the matlab gaussian window smoothing function

* SOR (0.22)
  Maintainer: Lee S. McDaniel
  Author(s): Lee S. McDaniel, Jonathan S. Schildcrout
  License: GPL (>= 2)
  http://crantastic.org/packages/SOR

  Estimation for longitudinal data following outcome dependent sampling
  using the sequential offsetted regression technique.  Includes
  support for binary, count, and continuous data.

* spatialnbda (1.0)
  Maintainer: Glenna Nightingale
  Author(s): Glenna Nightingale
  License: GPL
  http://crantastic.org/packages/spatialnbda

  Network based diffusion analysis (NBDA) allows inference on the
  asocial and social transmission of information.  This may involve
  the social transmission of a particular behaviour such as tool use,
  for example. For the NBDA, the key parameters estimated are the
  social effect and baseline rate  parameters.  The baseline rate
  parameter gives the rate at which the behaviour is first performed
  (or acquired) asocially amongst the individuals in a given
  population. The social effect parameter quantifies the effect of the
  social associations amongst  the individuals on the rate at which
  each individual first performs or displays the behaviour.  Spatial
  NBDA involves incorporating spatial information in the analysis.  
  This is done by incorporating social networks derived from  spatial
  point patterns (of the home bases of the individuals under study). 
  In addition,  a spatial covariate such as vegetation cover, or slope
  may be included in the modelling process.

* UPMASK (1.0)
  Maintainer: Alberto Krone-Martins
  Author(s): Alberto Krone-Martins, Andre Moitinho
  License: GPL (>= 3)
  http://crantastic.org/packages/UPMASK

  An implementation of the UPMASK method for performing membership
  assignment in stellar clusters in R. It is prepared to use
  photometry and spatial positions, but it can take into account other
  types of data. The method is able to take into account arbitrary
  error models, and it is unsupervised, data-driven,
  physical-model-free and relies on as few assumptions as possible.
  The approach followed for membership assessment is based on an
  iterative process, principal component analysis, a clustering
  algorithm and a kernel density estimation.

* uskewFactors (1.0)
  Maintainer: Paula M. Murray
  Author(s): Paula M. Murray, Ryan P. Browne, and Paul D. McNicholas
  License: GPL (>= 2)
  http://crantastic.org/packages/uskewFactors

  Implements mixtures of unrestricted skew-t factor analyzer models via
  the EM algorithm

* vdmR (0.1.0)
  Maintainer: Tomokazu Fujino
  Author(s): Tomokazu Fujino
  License: GPL-2
  http://crantastic.org/packages/vdmR

  This provides web based visual data mining tools by adding interactive
  functions to ggplot2 graphics. Brushing and linking between the
  multiple plots is one of the main feature of this package. Currently
  scatter plot, histogram, parallel coordinate plot and choropleth map
  are supported.


Updated packages
----------------

allelematch (2.5), bbo (0.2), beanplot (1.2), betategarch (3.2),
bReeze (0.4-0), coin (1.0-24), compute.es (0.2-4), corHMM (1.15),
demography (1.18), DirichletReg (0.5-2), DirichletReg (0.5-1),
Distance (0.9.2), dlm (1.1-4), dsm (2.2.5), fCopulae (3011.81), fmsb
(0.5.1), fRegression (3011.81), gamlr (1.12), gamlss (4.3-1),
gamlss.dist (4.3-1), gdsfmt (1.1.0.1), genlasso (1.3), geostatsp
(1.0.0), geostatsp (1.0.1), gplots (2.14.2), GuardianR (0.5),
intervals (0.15.0), investr (1.1.2), ivbma (1.05), LiblineaR
(1.80-10), llama (0.7.2), LogicForest (2.1.0), mclust (4.4), mco
(1.0.13), mitools (2.3), modTempEff (1.5.2), mrds (2.1.8), ncdf4
(1.13), nontarget (1.5), OrdLogReg (1.1), party (1.0-17), pcaPP
(1.9-50), PerformanceAnalytics (1.4.3541), PivotalR (0.1.17.3),
protViz (0.2.06), qat (0.73), qpcR (1.4-0), RadioSonde (1.4),
RcppOctave (0.14.5), refGenome (1.3.0), repmis (0.3), rgdal (0.9-1),
rms (4.2-1), rredis (1.6.9), RUnit (0.4.27), RVAideMemoire (0.9-39),
shapes (1.1-10), SmoothHazard (1.2.0), SmoothHazard (1.2.3), spdep
(0.5-77), spMC (0.3.4), SSDforR (1.4.7), Taxonstand (1.4), TreeSim
(2.1)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From dwinsemius at comcast.net  Mon Sep 22 00:48:39 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 21 Sep 2014 15:48:39 -0700
Subject: [R] A new environment within the main function
In-Reply-To: <CAJ_FNV7foBFkmxXeDmztoh0FNPyJRTGTnXPa49GqLQ4x1CADCw@mail.gmail.com>
References: <CAJ_FNV7foBFkmxXeDmztoh0FNPyJRTGTnXPa49GqLQ4x1CADCw@mail.gmail.com>
Message-ID: <21E6DCB1-2E18-4C14-A4AE-F367C770C824@comcast.net>


On Sep 21, 2014, at 6:06 AM, billy am wrote:

> Hi Everyone ,
>
> I am having an issue with the following code and would need kind  
> assistant.
>
> For a specific reason , I would need to create a new environment for
> variables within the function and use them and I am having issue  
> with it on
> the project I am doing.
>
> The issue is that no matter what I do , I am getting the following  
> error on
>
> "Error in eval(expr, envir, enclos) : object 'x3' not found"
>
> and it is the x3 that is within the groupedData(y~-1 + x3 | g
>
> and not in the data.frame
>
> fun1 <- function()
> {
>  ee <- new.env()
>  t <- 10
>  x <- 5
>  g<- 8
>
>  assign("x2",x,envir = as.environment(ee))
>
>  x3 <- get("x2" , envir = as.environment(ee))
>
>  if(t == 10)
>  {
>    if(g == 8)
>      {
>
>         data.fr <- groupedData(y~-1 + x3 | g,
>                    data=data.frame(y,x3,h, dummy))
>    }
>
>  }
>
> }

I don't get that error;  I get the perfectly understandable error:

 > fun1()
Error in data.frame(y, x3, h, dummy) : object 'y' not found

And if you create a `y` variable I would expect both h and dummy to be  
"not found" as well.


>
> Thanks and Regards
> Billy
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From Yuhlong.Lio at usd.edu  Mon Sep 22 04:10:19 2014
From: Yuhlong.Lio at usd.edu (Lio, Yuhlong)
Date: Sun, 21 Sep 2014 21:10:19 -0500
Subject: [R] Help with R solve
In-Reply-To: <mailman.19.1411207207.1808.r-help@r-project.org>
References: <mailman.19.1411207207.1808.r-help@r-project.org>
Message-ID: <6C66B379BE90504481FF3F1CAA1324A12CE2306D49@USD-EXMB04.usd.local>


I need someone to help with solution for a system of linear equations  A%*%x =b, where A is the coefficient matrix and b is right hand-side constant column.  

My question is that is there any option in the qr.solve to get a non-negative solution for x column, when more than one possible solution happens in the system.

Thanks,
Y.L. 

From murtaza.haider at ryerson.ca  Mon Sep 22 02:51:57 2014
From: murtaza.haider at ryerson.ca (Murtaza Haider)
Date: Sun, 21 Sep 2014 20:51:57 -0400
Subject: [R] bivariate ordered probit model
Message-ID: <CADGVuc8jKGFYvBO7-fYFjA_2B97dpfYR60nUOUFR+PnG3aWRCA@mail.gmail.com>

Dear colleagues:

I am searching for an R package that could estimate a bivariate ordered
probit model. I am aware of the bivariate probit model in R:

http://cran.r-project.org/web/packages/ZeligChoice/vignettes/ZeligChoice-manual.pdf

However, I am searching for a model that is similar to the one described in
http://www.adeptanalytics.org/download/ado/bioprobit/bioprobit.pdf.

I truly appreciate your help with this.

Best regards,

Murtaza

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Sep 22 05:49:32 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 21 Sep 2014 20:49:32 -0700
Subject: [R] Help with R solve
In-Reply-To: <6C66B379BE90504481FF3F1CAA1324A12CE2306D49@USD-EXMB04.usd.local>
References: <mailman.19.1411207207.1808.r-help@r-project.org>
	<6C66B379BE90504481FF3F1CAA1324A12CE2306D49@USD-EXMB04.usd.local>
Message-ID: <079bb8d6-10df-44cb-97a4-28cd94653527@email.android.com>

This question is about linear algebra theory, or perhaps linear programming, not about R. There is no magic parameter to solve this for you... either there is a non-negative solution or there isn't.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 21, 2014 7:10:19 PM PDT, "Lio, Yuhlong" <Yuhlong.Lio at usd.edu> wrote:
>
>I need someone to help with solution for a system of linear equations 
>A%*%x =b, where A is the coefficient matrix and b is right hand-side
>constant column.  
>
>My question is that is there any option in the qr.solve to get a
>non-negative solution for x column, when more than one possible
>solution happens in the system.
>
>Thanks,
>Y.L. 
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From madhvi.gupta at orkash.com  Mon Sep 22 08:28:38 2014
From: madhvi.gupta at orkash.com (madhvi.gupta)
Date: Mon, 22 Sep 2014 11:58:38 +0530
Subject: [R] How to get data from elastic search
Message-ID: <541FC196.60407@orkash.com>

Hi,

I want to get daat from elastic search in R.I am using package elastic 
to get data but it is not giving data as a data frame in R.It is 
returning data as a list which is giving following error when i am 
viewing it.It is giving same problem when I am using fromjson() function 
of rjson package.



 >View(sample)

Error in data.frame(wasRetweetedByMe = FALSE, entityLocation = 
"Bakhundole Lalitpur, Nepal",  :
   arguments imply differing number of rows: 1, 2, 0


Please help me how to get data from elastic search as a data frame to 
analyse it.

Thanks
Madhvi


From bhh at xs4all.nl  Mon Sep 22 08:51:08 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 22 Sep 2014 08:51:08 +0200
Subject: [R] Help with R solve
In-Reply-To: <6C66B379BE90504481FF3F1CAA1324A12CE2306D49@USD-EXMB04.usd.local>
References: <mailman.19.1411207207.1808.r-help@r-project.org>
	<6C66B379BE90504481FF3F1CAA1324A12CE2306D49@USD-EXMB04.usd.local>
Message-ID: <87E90DB3-D1F5-4725-92EA-34DD7303B13B@xs4all.nl>


On 22-09-2014, at 04:10, Lio, Yuhlong <Yuhlong.Lio at usd.edu> wrote:

> 
> I need someone to help with solution for a system of linear equations  A%*%x =b, where A is the coefficient matrix and b is right hand-side constant column.  
> 
> My question is that is there any option in the qr.solve to get a non-negative solution for x column, when more than one possible solution happens in the system.


If you are referring to an underdetermined system of linear equations have a look here:

http://en.wikipedia.org/wiki/System_of_linear_equations

section Matrix solution.

Berend


From alfonso.carfora at uniparthenope.it  Mon Sep 22 11:16:09 2014
From: alfonso.carfora at uniparthenope.it (alfonso.carfora at uniparthenope.it)
Date: Mon, 22 Sep 2014 11:16:09 +0200
Subject: [R] splm package: Spatial weights matrix of the 103 Italian
	provinces
Message-ID: <20140922111609.196352lw1o1r1t5l@webmail.uniparthenope.it>

Hello,

I'm using the spatial weights matrix of the 103 Italian provinces  
"itaww" of the package splm
example:

library(splm)

data(itaww)

itaww

It is a matrix of 103 rows and 103 columns. Each row (and each column)  
corresponds to an italian province and I would like to know the row's  
names of the matrix (currently defined by numeric ID).

Thank you for your help

Alfonso





******************************************************************************	
IL MERITO DEGLI STUDENTI VIENE RICONOSCIUTO
 
Il 5 per mille all'Universita' degli Studi di Napoli "Parthenope" incrementa le borse di studio agli studenti - codice fiscale 80018240632
http://www.uniparthenope.it/index.php/5xmille 
 
Questa informativa e' inserita in automatico dal sistema al fine esclusivo della realizzazione dei fini istituzionali dell'ente.


From petr.pikal at precheza.cz  Mon Sep 22 11:27:42 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 22 Sep 2014 09:27:42 +0000
Subject: [R] apply block of if statements with menu function
In-Reply-To: <460774e13cf2a35b71f1f7e8b4a2afe7@openmailbox.org>
References: <eb4cde6f90a194657e53038765e926df@openmailbox.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F97B0E@mb02.ads.tamu.edu>
	<55db8485faf3fbd2cdbd75c8b0570b71@openmailbox.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE333E@SRVEXCHMBX.precheza.cz>
	<de9e90496abf9d4d16ea37b61f5e5c8d@openmailbox.org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE33DB@SRVEXCHMBX.precheza.cz>
	<460774e13cf2a35b71f1f7e8b4a2afe7@openmailbox.org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE6535@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: rl at openmailbox.org [mailto:rl at openmailbox.org]
> Sent: Thursday, September 18, 2014 4:35 PM
> To: PIKAL Petr
> Cc: r-help at r-project.org
> Subject: RE: [R] apply block of if statements with menu function
>
> On 2014-09-16 12:35, PIKAL Petr wrote:
> >
> > So if result of menu is 0 (you did not choose anything) you can
> either
> > stay with 0, then switch does not return anything or add 1 and let
> > evaluate something meaningful specified in second and following
> > positions of switch command.
> >
>
> Thanks for your explanation, which completed my understanding! :) For
> the benefit of other novices, below is an example to demonstrate how
> 'switch' and 'menu' can be used:
>
> switch(menu(c(1,2),graphics=FALSE,title='select something'),
> {(seq(1:10))}, {(rnorm(20))})
>
> However, how to make the option '0 to exit' to appear in the command
> terminal?

Hm. Put it in a title.

switch(menu(c(1,2), title="select item from menu, 0 to exit"), {(seq(1:10))}, {(rnorm(20))})

Or modify source code of menu function to suite your needs. Nobody can restrain you to change it.

Regards
Petr

>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ruipbarradas at sapo.pt  Mon Sep 22 11:40:21 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 22 Sep 2014 10:40:21 +0100
Subject: [R] splm package: Spatial weights matrix of the 103 Italian
	provinces
In-Reply-To: <20140922111609.196352lw1o1r1t5l@webmail.uniparthenope.it>
References: <20140922111609.196352lw1o1r1t5l@webmail.uniparthenope.it>
Message-ID: <541FEE85.20304@sapo.pt>

Hello,

I have no knoledge of that package, but you could try

rownames(itaww)
colnames(itaww)

or ask the package maintainer

maintainer("splm")

Hope this helps,

Rui Barradas

Em 22-09-2014 10:16, alfonso.carfora at uniparthenope.it escreveu:
> Hello,
>
> I'm using the spatial weights matrix of the 103 Italian provinces
> "itaww" of the package splm
> example:
>
> library(splm)
>
> data(itaww)
>
> itaww
>
> It is a matrix of 103 rows and 103 columns. Each row (and each column)
> corresponds to an italian province and I would like to know the row's
> names of the matrix (currently defined by numeric ID).
>
> Thank you for your help
>
> Alfonso
>
>
>
>
>
> ******************************************************************************
>
> IL MERITO DEGLI STUDENTI VIENE RICONOSCIUTO
>
> Il 5 per mille all'Universita' degli Studi di Napoli "Parthenope"
> incrementa le borse di studio agli studenti - codice fiscale 80018240632
> http://www.uniparthenope.it/index.php/5xmille
> Questa informativa e' inserita in automatico dal sistema al fine
> esclusivo della realizzazione dei fini istituzionali dell'ente.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From highstat at highstat.com  Mon Sep 22 14:42:46 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 22 Sep 2014 06:42:46 -0600
Subject: [R] Course Lisbon: Introduction to Linear mixed effects models,
 GLMM and MCMC with R
Message-ID: <54201946.9020307@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course:

Course:   Introduction to Linear mixed effects models,  GLMM and MCMC with R
Location: Lisbon, Portugal
Date:       9 - 13 February, 2015

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2015_2Lisbon_GLMM.pdf


Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From f_j_rod at hotmail.com  Mon Sep 22 12:47:46 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Mon, 22 Sep 2014 12:47:46 +0200
Subject: [R] Data frame which includes a non-existent date
In-Reply-To: <CAGx1TMC3ggmiWX8pdqOn2iOjmAmO-9dv=eNz3LhtUt1obueC1Q@mail.gmail.com>
References: <BAY168-W5B1368619173B1DFC9FACBAB70@phx.gbl>,
	<BAY168-W1080FDD6524D10D75DD47DEBAB70@phx.gbl>,
	<CAGx1TMC3ggmiWX8pdqOn2iOjmAmO-9dv=eNz3LhtUt1obueC1Q@mail.gmail.com>
Message-ID: <BAY168-W71AE0B56605A5564E39581BAB30@phx.gbl>

Thanks Richard!
 		 	   		  
	[[alternative HTML version deleted]]


From drf28 at cornell.edu  Mon Sep 22 15:16:54 2014
From: drf28 at cornell.edu (Daniel Fuka)
Date: Mon, 22 Sep 2014 09:16:54 -0400
Subject: [R] Dynamic regex/sub changes to function
Message-ID: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>

Howdy,

I have searched the lists and can not seem to find a solution to my
problem. I need to be able to dynamically modify a string inside a
function to build a new function. "sub" replaces with a quoted
string... and "parse" of "sub" returns expression... How can I get an
unquoted string from a regex to stick into a "body" of a function?

Thanks for your help!
dan

# Original Function
fsong=function(x){
 song=paste("my name is fuka,",x)
 return(song)
}
fsong("I live on the second floor")
#
# Copy and modify using "sub" returns quoted string with escaped quotes
#   internally... as expected.. which can not be evaluated.
nsong=fsong
body(nsong)[[grep("fuka",body(nsong))]]=
   sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))

nsong("I live on the second floor") # broken

#
# Copy and modify with "parse" of  "sub",  returns expression.. but
without quotes,
# o getting closer.
#
nsong=fsong
body(nsong)[[grep("fuka",body(nsong))]]=
   parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))


From giovanni.millo at generali.com  Mon Sep 22 11:48:44 2014
From: giovanni.millo at generali.com (Millo Giovanni)
Date: Mon, 22 Sep 2014 09:48:44 +0000
Subject: [R] splm package: Spatial weights matrix of the 103 Italian
 provinces
In-Reply-To: <541FEE85.20304@sapo.pt>
References: <20140922111609.196352lw1o1r1t5l@webmail.uniparthenope.it>,
	<541FEE85.20304@sapo.pt>
Message-ID: <DB36B6DC36CFD746A374F62BE5B5C5BD04B0C30F@D3MBXSRVPD1.corp.generali.net>

Hello. The row numbers correspond to the standard Istat codes for Italian provinces, 103-version of course. I.e., 1=Torino, 2=Vercelli, ...
I am sending you a correspondence table by separate email.

Best,
Giovanni

> Hello,
>
> I'm using the spatial weights matrix of the 103 Italian provinces
> "itaww" of the package splm
> example:
>
> library(splm)
>
> data(itaww)
>
> itaww
>
> It is a matrix of 103 rows and 103 columns. Each row (and each column)
> corresponds to an italian province and I would like to know the row's
> names of the matrix (currently defined by numeric ID).
>
> Thank you for your help
>
> Alfonso

Ai sensi del D.Lgs. 196/2003 si precisa che le informazi...{{dropped:12}}


From wickedpuppy at gmail.com  Mon Sep 22 16:11:01 2014
From: wickedpuppy at gmail.com (billy am)
Date: Mon, 22 Sep 2014 22:11:01 +0800
Subject: [R] A new environment within the main function
In-Reply-To: <21E6DCB1-2E18-4C14-A4AE-F367C770C824@comcast.net>
References: <CAJ_FNV7foBFkmxXeDmztoh0FNPyJRTGTnXPa49GqLQ4x1CADCw@mail.gmail.com>
	<21E6DCB1-2E18-4C14-A4AE-F367C770C824@comcast.net>
Message-ID: <CAJ_FNV497cYXD+3L=YOYN8RFiEykSRVz_W6CaZ29JLp3AGfOzw@mail.gmail.com>

Hi Everyone ,

Thanks for the input.



On Mon, Sep 22, 2014 at 6:48 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Sep 21, 2014, at 6:06 AM, billy am wrote:
>
>  Hi Everyone ,
>>
>> I am having an issue with the following code and would need kind
>> assistant.
>>
>> For a specific reason , I would need to create a new environment for
>> variables within the function and use them and I am having issue with it
>> on
>> the project I am doing.
>>
>> The issue is that no matter what I do , I am getting the following error
>> on
>>
>> "Error in eval(expr, envir, enclos) : object 'x3' not found"
>>
>> and it is the x3 that is within the groupedData(y~-1 + x3 | g
>>
>> and not in the data.frame
>>
>> fun1 <- function()
>> {
>>  ee <- new.env()
>>  t <- 10
>>  x <- 5
>>  g<- 8
>>
>>  assign("x2",x,envir = as.environment(ee))
>>
>>  x3 <- get("x2" , envir = as.environment(ee))
>>
>>  if(t == 10)
>>  {
>>    if(g == 8)
>>      {
>>
>>         data.fr <- groupedData(y~-1 + x3 | g,
>>                    data=data.frame(y,x3,h, dummy))
>>    }
>>
>>  }
>>
>> }
>>
>
> I don't get that error;  I get the perfectly understandable error:
>
> > fun1()
> Error in data.frame(y, x3, h, dummy) : object 'y' not found
>
> And if you create a `y` variable I would expect both h and dummy to be
> "not found" as well.
>
>
>
>> Thanks and Regards
>> Billy
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> David Winsemius, MD
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Sep 22 16:37:15 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Sep 2014 10:37:15 -0400
Subject: [R] Dynamic regex/sub changes to function
In-Reply-To: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>
Message-ID: <5420341B.8070604@gmail.com>

On 22/09/2014 9:16 AM, Daniel Fuka wrote:
> Howdy,
>
> I have searched the lists and can not seem to find a solution to my
> problem. I need to be able to dynamically modify a string inside a
> function to build a new function. "sub" replaces with a quoted
> string... and "parse" of "sub" returns expression... How can I get an
> unquoted string from a regex to stick into a "body" of a function?

It's possible to do what you want, though you don't want to be using 
parse(), you can just edit the language expression that body(fsong) 
gives you, and assign it back.  But that's a messy way to solve your 
problem.

Why not create a new function containing the new string?  e.g.

makefsong <- function(name = "fuka") {
   line1 <- paste("my name is", name)
   function(x) {
     song <- paste(line1, x)
     return(song)
   }
}

f1 <- makefsong()
f1("I live on the second floor")
f2 <- makefsong("muka")
f2("I live on the second floor")

Duncan Murdoch

>
> Thanks for your help!
> dan
>
> # Original Function
> fsong=function(x){
>   song=paste("my name is fuka,",x)
>   return(song)
> }
> fsong("I live on the second floor")
> #
> # Copy and modify using "sub" returns quoted string with escaped quotes
> #   internally... as expected.. which can not be evaluated.
> nsong=fsong
> body(nsong)[[grep("fuka",body(nsong))]]=
>     sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))
>
> nsong("I live on the second floor") # broken
>
> #
> # Copy and modify with "parse" of  "sub",  returns expression.. but
> without quotes,
> # o getting closer.
> #
> nsong=fsong
> body(nsong)[[grep("fuka",body(nsong))]]=
>     parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drf28 at cornell.edu  Mon Sep 22 17:34:48 2014
From: drf28 at cornell.edu (Daniel Fuka)
Date: Mon, 22 Sep 2014 11:34:48 -0400
Subject: [R] Dynamic regex/sub changes to function
In-Reply-To: <5420341B.8070604@gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>
	<5420341B.8070604@gmail.com>
Message-ID: <CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>

Howdy Duncan,

Thanks for the quick reply!  I must be missing something
simple/obvious. I need to have the "sub()" not return quoted and
escaped characters to "just edit the language expression". In my
problem, there is a function that is supported from a different
package. So I always want to use the supported function as my base...
but a url in the supported function needs to be changed dynamically
for my application, which is easiest using "sub()".

I am trying to do what you correctly indicate I would need to do:
"just edit the language expression that body(fsong) gives you, and
assign it back"
BUT, using sub, I get back a quoted string in my example if I just use sed:

> fsong
function(x){
 song=paste("my name is fuka,",x)
 return(song)
}
# Using "sub()" becomes:
> nsong
function (x)
{
    "song = paste(\"my name is muka,\", x)"
    return(song)
}

Thanks again for the quick reply and help you are giving me!
dan

On Mon, Sep 22, 2014 at 10:37 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 22/09/2014 9:16 AM, Daniel Fuka wrote:
>>
>> Howdy,
>>
>> I have searched the lists and can not seem to find a solution to my
>> problem. I need to be able to dynamically modify a string inside a
>> function to build a new function. "sub" replaces with a quoted
>> string... and "parse" of "sub" returns expression... How can I get an
>> unquoted string from a regex to stick into a "body" of a function?
>
>
> It's possible to do what you want, though you don't want to be using
> parse(), you can just edit the language expression that body(fsong) gives
> you, and assign it back.  But that's a messy way to solve your problem.
>
> Why not create a new function containing the new string?  e.g.
>
> makefsong <- function(name = "fuka") {
>   line1 <- paste("my name is", name)
>   function(x) {
>     song <- paste(line1, x)
>     return(song)
>   }
> }
>
> f1 <- makefsong()
> f1("I live on the second floor")
> f2 <- makefsong("muka")
> f2("I live on the second floor")
>
> Duncan Murdoch
>
>>
>> Thanks for your help!
>> dan
>>
>> # Original Function
>> fsong=function(x){
>>   song=paste("my name is fuka,",x)
>>   return(song)
>> }
>> fsong("I live on the second floor")
>> #
>> # Copy and modify using "sub" returns quoted string with escaped quotes
>> #   internally... as expected.. which can not be evaluated.
>> nsong=fsong
>> body(nsong)[[grep("fuka",body(nsong))]]=
>>     sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))
>>
>> nsong("I live on the second floor") # broken
>>
>> #
>> # Copy and modify with "parse" of  "sub",  returns expression.. but
>> without quotes,
>> # o getting closer.
>> #
>> nsong=fsong
>> body(nsong)[[grep("fuka",body(nsong))]]=
>>
>> parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From David.Reiner at xrtrading.com  Mon Sep 22 17:37:57 2014
From: David.Reiner at xrtrading.com (David Reiner)
Date: Mon, 22 Sep 2014 10:37:57 -0500
Subject: [R] Using read.csv.sql() to read in specific columns
In-Reply-To: <D04074A9.1F385%hdoran@air.org>
References: <D04074A9.1F385%hdoran@air.org>
Message-ID: <9DE405308A6AA24AA794B76282C6C00F5231DDA7BA@HQ-POST1>

That seems right to me.

You might want to look into a persistent connection as in Example 10 at
  https://code.google.com/p/sqldf/#Example_10._Persistent_Connections

This will save reloading the DB for every query.

You might even want to create a permanent DB as in Example 9.

This is one of my favorite packages - kudos to Gabor again!
-- David

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: Thursday, September 18, 2014 10:38 AM
To: r-help at r-project.org
Subject: [R] Using read.csv.sql() to read in specific columns

I am dealing with data frames that have thousands of columns and hundreds of thousands of rows and only need a few specific columns from the data. The data take various formats, but normally are tab-delimited.

I have written the following which is working as expected. However, because I?m so new at using sqldf(), just looking for some verification from users that this is in fact efficient and correct in the R-ish sense of the word and generalizable to larger data sets.

Harold

tmp <- data.frame(replicate(50, rnorm(10)))
names(tmp) <- paste('item', 1:50, sep='')
write.table(tmp, 'tmp.txt')
read.csv.sql("tmp.txt", sql = "select item1, item2, item50 from file", sep = ' ')

        [[alternative HTML version deleted]]



This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON?S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.

From wdunlap at tibco.com  Mon Sep 22 18:01:11 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 22 Sep 2014 09:01:11 -0700
Subject: [R] Dynamic regex/sub changes to function
In-Reply-To: <CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>
	<5420341B.8070604@gmail.com>
	<CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>
Message-ID: <CAF8bMcadi9txej24f3bZZJ+m-O8w47WC0MLc4JNjmCa6ziFhCw@mail.gmail.com>

If you really want to continue to use the function in the supported
package, then you could try asking the maintainer of the package to
make the problematic URL an argument to the function.  I thnk that
changing the function on the fly, no matter how you do it, is likely
to cause problems when the maintainer changes the function in a future
release of the package.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Sep 22, 2014 at 8:34 AM, Daniel Fuka <drf28 at cornell.edu> wrote:
> Howdy Duncan,
>
> Thanks for the quick reply!  I must be missing something
> simple/obvious. I need to have the "sub()" not return quoted and
> escaped characters to "just edit the language expression". In my
> problem, there is a function that is supported from a different
> package. So I always want to use the supported function as my base...
> but a url in the supported function needs to be changed dynamically
> for my application, which is easiest using "sub()".
>
> I am trying to do what you correctly indicate I would need to do:
> "just edit the language expression that body(fsong) gives you, and
> assign it back"
> BUT, using sub, I get back a quoted string in my example if I just use sed:
>
>> fsong
> function(x){
>  song=paste("my name is fuka,",x)
>  return(song)
> }
> # Using "sub()" becomes:
>> nsong
> function (x)
> {
>     "song = paste(\"my name is muka,\", x)"
>     return(song)
> }
>
> Thanks again for the quick reply and help you are giving me!
> dan
>
> On Mon, Sep 22, 2014 at 10:37 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 22/09/2014 9:16 AM, Daniel Fuka wrote:
>>>
>>> Howdy,
>>>
>>> I have searched the lists and can not seem to find a solution to my
>>> problem. I need to be able to dynamically modify a string inside a
>>> function to build a new function. "sub" replaces with a quoted
>>> string... and "parse" of "sub" returns expression... How can I get an
>>> unquoted string from a regex to stick into a "body" of a function?
>>
>>
>> It's possible to do what you want, though you don't want to be using
>> parse(), you can just edit the language expression that body(fsong) gives
>> you, and assign it back.  But that's a messy way to solve your problem.
>>
>> Why not create a new function containing the new string?  e.g.
>>
>> makefsong <- function(name = "fuka") {
>>   line1 <- paste("my name is", name)
>>   function(x) {
>>     song <- paste(line1, x)
>>     return(song)
>>   }
>> }
>>
>> f1 <- makefsong()
>> f1("I live on the second floor")
>> f2 <- makefsong("muka")
>> f2("I live on the second floor")
>>
>> Duncan Murdoch
>>
>>>
>>> Thanks for your help!
>>> dan
>>>
>>> # Original Function
>>> fsong=function(x){
>>>   song=paste("my name is fuka,",x)
>>>   return(song)
>>> }
>>> fsong("I live on the second floor")
>>> #
>>> # Copy and modify using "sub" returns quoted string with escaped quotes
>>> #   internally... as expected.. which can not be evaluated.
>>> nsong=fsong
>>> body(nsong)[[grep("fuka",body(nsong))]]=
>>>     sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))
>>>
>>> nsong("I live on the second floor") # broken
>>>
>>> #
>>> # Copy and modify with "parse" of  "sub",  returns expression.. but
>>> without quotes,
>>> # o getting closer.
>>> #
>>> nsong=fsong
>>> body(nsong)[[grep("fuka",body(nsong))]]=
>>>
>>> parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drf28 at cornell.edu  Mon Sep 22 19:11:31 2014
From: drf28 at cornell.edu (Daniel Fuka)
Date: Mon, 22 Sep 2014 13:11:31 -0400
Subject: [R] Dynamic regex/sub changes to function
In-Reply-To: <CAF8bMcadi9txej24f3bZZJ+m-O8w47WC0MLc4JNjmCa6ziFhCw@mail.gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>
	<5420341B.8070604@gmail.com>
	<CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>
	<CAF8bMcadi9txej24f3bZZJ+m-O8w47WC0MLc4JNjmCa6ziFhCw@mail.gmail.com>
Message-ID: <CAB9w6XxvJsQfV_1VZXCTUX5kvJ6TMyRqt6WToG7Y_rHgz8ELHQ@mail.gmail.com>

Unfortunately in this specific case the owner/maintainer is a complete
idiot and a major jerk... he is.. well.. me in this case. But, this is
something I have also been wanting to figure out for some time as it
is often the case when a quick and simple regex based "patch" to a
function can be useful. I do not see why even when I "noquote()" the
assignment into a line of a "body()" it keeps adding the quotes and
associated escapes.



On Mon, Sep 22, 2014 at 12:01 PM, William Dunlap <wdunlap at tibco.com> wrote:
> If you really want to continue to use the function in the supported
> package, then you could try asking the maintainer of the package to
> make the problematic URL an argument to the function.  I thnk that
> changing the function on the fly, no matter how you do it, is likely
> to cause problems when the maintainer changes the function in a future
> release of the package.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Sep 22, 2014 at 8:34 AM, Daniel Fuka <drf28 at cornell.edu> wrote:
>> Howdy Duncan,
>>
>> Thanks for the quick reply!  I must be missing something
>> simple/obvious. I need to have the "sub()" not return quoted and
>> escaped characters to "just edit the language expression". In my
>> problem, there is a function that is supported from a different
>> package. So I always want to use the supported function as my base...
>> but a url in the supported function needs to be changed dynamically
>> for my application, which is easiest using "sub()".
>>
>> I am trying to do what you correctly indicate I would need to do:
>> "just edit the language expression that body(fsong) gives you, and
>> assign it back"
>> BUT, using sub, I get back a quoted string in my example if I just use sed:
>>
>>> fsong
>> function(x){
>>  song=paste("my name is fuka,",x)
>>  return(song)
>> }
>> # Using "sub()" becomes:
>>> nsong
>> function (x)
>> {
>>     "song = paste(\"my name is muka,\", x)"
>>     return(song)
>> }
>>
>> Thanks again for the quick reply and help you are giving me!
>> dan
>>
>> On Mon, Sep 22, 2014 at 10:37 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 22/09/2014 9:16 AM, Daniel Fuka wrote:
>>>>
>>>> Howdy,
>>>>
>>>> I have searched the lists and can not seem to find a solution to my
>>>> problem. I need to be able to dynamically modify a string inside a
>>>> function to build a new function. "sub" replaces with a quoted
>>>> string... and "parse" of "sub" returns expression... How can I get an
>>>> unquoted string from a regex to stick into a "body" of a function?
>>>
>>>
>>> It's possible to do what you want, though you don't want to be using
>>> parse(), you can just edit the language expression that body(fsong) gives
>>> you, and assign it back.  But that's a messy way to solve your problem.
>>>
>>> Why not create a new function containing the new string?  e.g.
>>>
>>> makefsong <- function(name = "fuka") {
>>>   line1 <- paste("my name is", name)
>>>   function(x) {
>>>     song <- paste(line1, x)
>>>     return(song)
>>>   }
>>> }
>>>
>>> f1 <- makefsong()
>>> f1("I live on the second floor")
>>> f2 <- makefsong("muka")
>>> f2("I live on the second floor")
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> Thanks for your help!
>>>> dan
>>>>
>>>> # Original Function
>>>> fsong=function(x){
>>>>   song=paste("my name is fuka,",x)
>>>>   return(song)
>>>> }
>>>> fsong("I live on the second floor")
>>>> #
>>>> # Copy and modify using "sub" returns quoted string with escaped quotes
>>>> #   internally... as expected.. which can not be evaluated.
>>>> nsong=fsong
>>>> body(nsong)[[grep("fuka",body(nsong))]]=
>>>>     sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))
>>>>
>>>> nsong("I live on the second floor") # broken
>>>>
>>>> #
>>>> # Copy and modify with "parse" of  "sub",  returns expression.. but
>>>> without quotes,
>>>> # o getting closer.
>>>> #
>>>> nsong=fsong
>>>> body(nsong)[[grep("fuka",body(nsong))]]=
>>>>
>>>> parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Sep 22 19:24:16 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Sep 2014 13:24:16 -0400
Subject: [R] Dynamic regex/sub changes to function
In-Reply-To: <CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>	<5420341B.8070604@gmail.com>
	<CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>
Message-ID: <54205B40.9040005@gmail.com>

On 22/09/2014 11:34 AM, Daniel Fuka wrote:
> Howdy Duncan,
>
> Thanks for the quick reply!  I must be missing something
> simple/obvious. I need to have the "sub()" not return quoted and
> escaped characters to "just edit the language expression". In my
> problem, there is a function that is supported from a different
> package. So I always want to use the supported function as my base...
> but a url in the supported function needs to be changed dynamically
> for my application, which is easiest using "sub()".
>
> I am trying to do what you correctly indicate I would need to do:
> "just edit the language expression that body(fsong) gives you, and
> assign it back"
> BUT, using sub, I get back a quoted string in my example if I just use sed:
>
> > fsong
> function(x){
>   song=paste("my name is fuka,",x)
>   return(song)
> }
> # Using "sub()" becomes:
> > nsong
> function (x)
> {
>      "song = paste(\"my name is muka,\", x)"
>      return(song)
> }

You didn't do it right :-).   With fsong as above, the string to edit is 
body(fsong)[[c(2,3,2)]].  (Why c(2,3,2)?  Because that's where the 
string is in the parse tree.  Try looking at variations on 
body(fsong)[[c(2,3,2)]] to figure it out, e.g.
body(fsong)[[c(2,3)]], or body(fsong)[[c(2,3,3)]], etc.)

So this code would work:

orig <- body(fsong)[[c(2,3,2)]]
new <- sub("fuka", "muka", orig)

# Now put it back in nsong:
nsong <- fsong
body(nsong)[[c(2,3,2)]] <- new

But as Bill said, this is a really bad idea.  If you just *think* about 
changing that fsong function, it will break.

Duncan Murdoch

>
> Thanks again for the quick reply and help you are giving me!
> dan
>
> On Mon, Sep 22, 2014 at 10:37 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 22/09/2014 9:16 AM, Daniel Fuka wrote:
> >>
> >> Howdy,
> >>
> >> I have searched the lists and can not seem to find a solution to my
> >> problem. I need to be able to dynamically modify a string inside a
> >> function to build a new function. "sub" replaces with a quoted
> >> string... and "parse" of "sub" returns expression... How can I get an
> >> unquoted string from a regex to stick into a "body" of a function?
> >
> >
> > It's possible to do what you want, though you don't want to be using
> > parse(), you can just edit the language expression that body(fsong) gives
> > you, and assign it back.  But that's a messy way to solve your problem.
> >
> > Why not create a new function containing the new string?  e.g.
> >
> > makefsong <- function(name = "fuka") {
> >   line1 <- paste("my name is", name)
> >   function(x) {
> >     song <- paste(line1, x)
> >     return(song)
> >   }
> > }
> >
> > f1 <- makefsong()
> > f1("I live on the second floor")
> > f2 <- makefsong("muka")
> > f2("I live on the second floor")
> >
> > Duncan Murdoch
> >
> >>
> >> Thanks for your help!
> >> dan
> >>
> >> # Original Function
> >> fsong=function(x){
> >>   song=paste("my name is fuka,",x)
> >>   return(song)
> >> }
> >> fsong("I live on the second floor")
> >> #
> >> # Copy and modify using "sub" returns quoted string with escaped quotes
> >> #   internally... as expected.. which can not be evaluated.
> >> nsong=fsong
> >> body(nsong)[[grep("fuka",body(nsong))]]=
> >>     sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))
> >>
> >> nsong("I live on the second floor") # broken
> >>
> >> #
> >> # Copy and modify with "parse" of  "sub",  returns expression.. but
> >> without quotes,
> >> # o getting closer.
> >> #
> >> nsong=fsong
> >> body(nsong)[[grep("fuka",body(nsong))]]=
> >>
> >> parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >


From jacksonjordancm at gmail.com  Mon Sep 22 18:13:08 2014
From: jacksonjordancm at gmail.com (Chris Jackson-Jordan)
Date: Mon, 22 Sep 2014 12:13:08 -0400
Subject: [R] error in rownames
Message-ID: <CAPtX2q=siOx6FQT9s3mNbcGcppMNv4OjmAnU7btT48u6WYppWw@mail.gmail.com>

Dear fellow R users,

I am trying to run the random forest and Yaimpute packages in R to
impute a grid to project in a gis. However, after running the
imputation I keep getting an error in the rownames. This sounds simple
enough, but I cannot figure out what these rownames are reffering to.
Any ideas? I am fairly new to R so im sure it is an easy fix. Any help
would be awesome.

Thanks,

Chris


> y <- subset(training, select = c(ResponseSu)) > x <- subset(training,
select = c(sinaspect, habitat, slope, elevation, cosaspect, disttoroad,
disttowat)) > type.rf <- yai(x=x, y=y, method="randomForest",
rfMode="regression", ntree= 2000) > outfile <- list(Type =
"D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc") > xfile <-list(sinaspect
="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/sinaspect.asc",
habitat
="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/habitat.asc",
elevation
="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/elevation.asc",
disttowat
="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttowat.asc",
disttoroad
="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttoroad.asc",
slope
="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/slope.asc",
cosaspect
="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/cosaspect.asc")
> AsciiGridImpute(type.rf, xfile, outfile) Rows per dot: 19 Rows to do:
1900 ToDo:
....................................................................................................
Done: . Error in `rownames<-`(`*tmp*`, value = c("23x0049", "23x0050",
"23x0051", : attempt to set rownames on object with no dimensions

here is an example of my training data


 > dput(training[1:20, ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
-0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
-0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
-0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect = c(0.915474,
-0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
-0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
-0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
-0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
516073.554503, 516019.068701, 515506.165434, 517353.141738, 520076.487742,
517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
515714.490202, 518829.909017, 519385.491579, 518659.851297, 516654.780318,
519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912, 4818923.42436,
4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774, 4814503.57051,
4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
"elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
"ResponseSu"), row.names = c(NA, 20L), class = "data.frame")>
library("randomForest", lib.loc="~/RStudio/R/library")

	[[alternative HTML version deleted]]


From alain.dubreuil at cae.com  Mon Sep 22 17:27:46 2014
From: alain.dubreuil at cae.com (Alain Dubreuil)
Date: Mon, 22 Sep 2014 11:27:46 -0400
Subject: [R] Plotting boundary lines from shapefiles overtop a map of Canada
Message-ID: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>

Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.

To plot the map of Canada, I have used the following line of code:

      map(database= "worldHires","Canada", ylim=c(39,90), xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE, projection="lambert", param=c(50,65))

Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.

To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:

      lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
      lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
      coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long 
      points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red", 0.5))  #plot converted points

As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.

Using readOGR:

      region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
      plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), col=alpha("lightgreen", 0.6), border=TRUE)

Using read.shp and draw.shp:

      region <- read.shp("C:/myRfolder/mySARshapefile.shp")
      draw.shape(shape=region, type="poly", col="red")

Using readShapePoly:

      region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
      plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), col=alpha("lightgreen", 0.6), border=TRUE)

Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:

      region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
      lines(region, col=alpha("black", 0.6))

I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")

I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.

Thanks

Alain Dubreuil
Ottawa, Canada


From c.danyluck at gmail.com  Mon Sep 22 22:31:46 2014
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Mon, 22 Sep 2014 16:31:46 -0400
Subject: [R] Error in quantile.default(resids) : missing values and NaN's
 not allowed if 'na.rm' is FALSE
Message-ID: <CA+_f+RGhPSppHymFTx7ZM59XH24QGEKkh64rMjktu76kbqnkKg@mail.gmail.com>

About a year ago I ran some analyses using lmer. The general syntax was:

mlm <- lmer(var1 ~ (1|dyad) + var2 + var3*var4*var5, na.action=na.exclude);
summary(mlm)

The model ran fine and I saved the output. I've recently turned back to
those analyses, however, the model no longer runs. I get the following
error:

Error in quantile.default(resids) :
  missing values and NaN's not allowed if 'na.rm' is FALSE

I've searched the online forums and found that this topic has not been
touched upon since 2006, and at that time someone had indicated that it was
a bug that had been resolved. I am using the most current version of lme4,
so if the bug is fixed I am unsure why I am experiencing this problem.

I have since run the model using lmer's default for handling missing data
(na.omit), but found the results do not match what I had saved previously
when using na.exclude.

If anyone has an insight here I'd be very appreciative.

Kind regards,

Chad

-- 
Chad M. Danyluck
PhD Candidate, Psychology
University of Toronto
Lab: http://embodiedsocialcognition.com


?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Sep 22 22:56:44 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 22 Sep 2014 20:56:44 +0000
Subject: [R] Error in quantile.default(resids) : missing values and
	NaN's not allowed if 'na.rm' is FALSE
References: <CA+_f+RGhPSppHymFTx7ZM59XH24QGEKkh64rMjktu76kbqnkKg@mail.gmail.com>
Message-ID: <loom.20140922T225156-919@post.gmane.org>

Chad Danyluck <c.danyluck <at> gmail.com> writes:

> 
> About a year ago I ran some analyses using lmer. The general syntax was:
> 
> mlm <- lmer(var1 ~ (1|dyad) + 
> var2 + var3*var4*var5, na.action=na.exclude);
> summary(mlm)
> 
> The model ran fine and I saved the output. I've recently turned back to
> those analyses, however, the model no longer runs. I get the following
> error:
> 
> Error in quantile.default(resids) :
>   missing values and NaN's not allowed if 'na.rm' is FALSE
> 
> I've searched the online forums and found that this topic has not been
> touched upon since 2006, and at that time someone
>  had indicated that it was
> a bug that had been resolved. I am using the most current version of lme4,
> so if the bug is fixed I am unsure why I am experiencing this problem.

   You missed

https://mailman.stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022616.html

and the subsequent thread, which describes a recent issue.

This was fixed two weeks ago, at

https://github.com/lme4/lme4/commit/e68b7475d1d254bfbdae6cd3efb2d9c8dbe0b899

but hasn't made it into a released version of lme4, although at least
a Windows binary should be available @ http://lme4.r-forge.r-project.org/repos
(and you can install from Github via devtools::install_github() if you
have compilation tools available on your machine).

> I have since run the model using lmer's default for handling missing data
> (na.omit), but found the results do not match what I had saved previously
> when using na.exclude.
> 
> If anyone has an insight here I'd be very appreciative.
> 
> Kind regards,
> 
> Chad


  Perhaps worth noting that this bug only affects the summary print
method, not anything in the actual model fitting process.


From rshepard at appl-ecosys.com  Tue Sep 23 00:32:23 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 22 Sep 2014 15:32:23 -0700 (PDT)
Subject: [R] robCompositions: Using impCoda
Message-ID: <alpine.LNX.2.11.1409221525580.3951@localhost>

   I need to learn how to apply the methods in robCompositions and have read
the package docs. Two of my six data sets of proportions contain missing
values (not collected or not present); one set has a single missing value,
the other has 3 missing values. So my first task is to learn how to properly
apply the impCoda() method to my data to impute values for those that are
missing. After reading ?impData and emulating the syntax on that help page,
without understanding how to select appropriate options for the various
components, I end up with errors and have no clue how to correctly format
the command.

The data frame:
burns.co
                Filterer Gatherer Grazer Predator Shredder
date2000-07-18   0.0550   0.5596 0.0734   0.2294   0.0826
date2003-07-08   0.0734   0.6147 0.0183   0.2294   0.0642
date2005-07-13   0.1161   0.5714 0.0357   0.1696   0.1071
date2006-06-28   0.1000   0.4667 0.1500   0.1333   0.1500
date2010-09-14   0.0778   0.6111 0.0444   0.1889   0.0778
date2011-07-13   0.0879   0.5714 0.0659   0.2747       NA
date2012-07-11   0.1042   0.5313 0.0625   0.2396   0.0625
date2013-07-11   0.0723   0.5542 0.0602   0.2651   0.0482

has this structure:

str(burns.co)
'data.frame':	8 obs. of  5 variables:
  $ Filterer: num  0.055 0.0734 0.1161 0.1 0.0778 ...
  $ Gatherer: num  0.56 0.615 0.571 0.467 0.611 ...
  $ Grazer  : num  0.0734 0.0183 0.0357 0.15 0.0444 0.0659 0.0625 0.0602
  $ Predator: num  0.229 0.229 0.17 0.133 0.189 ...
  $ Shredder: num  0.0826 0.0642 0.1071 0.15 0.0778 ...

   Emulating the syntax in ?impCoda produces this result:

burnsImp <- impCoda(burns.co, maxit = 10, eps = 0.5, method = 'ltsReg',
closed = TRUE, init = 'KNN', k = 5, noise = 0.1, bruteforce = FALSE)
Error in ltsReg.default(x, y, intercept = (xint > 0), ...) :
   Need more than twice as many observations as variables.
In addition: Warning message:
In impCoda(burns.co, maxit = 10, eps = 0.5, method = "ltsReg", closed =
TRUE,  :
   k might be too large

   Please provide pointers so I can read and learn how to correctly specify
impCoda parameters for my data sets.

TIA,

Rich


From drf28 at cornell.edu  Tue Sep 23 01:38:03 2014
From: drf28 at cornell.edu (Daniel Fuka)
Date: Mon, 22 Sep 2014 19:38:03 -0400
Subject: [R] Dynamic regex/sub changes to function
In-Reply-To: <54205B40.9040005@gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>
	<5420341B.8070604@gmail.com>
	<CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>
	<54205B40.9040005@gmail.com>
Message-ID: <CAB9w6XxHk1EbpH4HsyLdSoEKG58T-P5ECobV7WC_xXYtoqwyrg@mail.gmail.com>

Thanks everyone for the help. I need to step back and refresh my
memory on expressions as I am still unclear as to why I can not
directly edit:
body(nsong)[[2]]
# Which can be located from a grep:
body(nsong)[[grep("fuka",body(nsong))]]
# though I believe
class(body(nsong)[[2]])
[1] "="
# is trying to give me a pretty blatant hint... {: -)

On Mon, Sep 22, 2014 at 1:24 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 22/09/2014 11:34 AM, Daniel Fuka wrote:
>>
>> Howdy Duncan,
>>
>> Thanks for the quick reply!  I must be missing something
>> simple/obvious. I need to have the "sub()" not return quoted and
>> escaped characters to "just edit the language expression". In my
>> problem, there is a function that is supported from a different
>> package. So I always want to use the supported function as my base...
>> but a url in the supported function needs to be changed dynamically
>> for my application, which is easiest using "sub()".
>>
>> I am trying to do what you correctly indicate I would need to do:
>> "just edit the language expression that body(fsong) gives you, and
>> assign it back"
>> BUT, using sub, I get back a quoted string in my example if I just use
>> sed:
>>
>> > fsong
>> function(x){
>>   song=paste("my name is fuka,",x)
>>   return(song)
>> }
>> # Using "sub()" becomes:
>> > nsong
>> function (x)
>> {
>>      "song = paste(\"my name is muka,\", x)"
>>      return(song)
>> }
>
>
> You didn't do it right :-).   With fsong as above, the string to edit is
> body(fsong)[[c(2,3,2)]].  (Why c(2,3,2)?  Because that's where the string is
> in the parse tree.  Try looking at variations on body(fsong)[[c(2,3,2)]] to
> figure it out, e.g.
> body(fsong)[[c(2,3)]], or body(fsong)[[c(2,3,3)]], etc.)
>
> So this code would work:
>
> orig <- body(fsong)[[c(2,3,2)]]
> new <- sub("fuka", "muka", orig)
>
> # Now put it back in nsong:
> nsong <- fsong
> body(nsong)[[c(2,3,2)]] <- new
>
> But as Bill said, this is a really bad idea.  If you just *think* about
> changing that fsong function, it will break.
>
> Duncan Murdoch
>
>>
>> Thanks again for the quick reply and help you are giving me!
>> dan
>>
>> On Mon, Sep 22, 2014 at 10:37 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>> > On 22/09/2014 9:16 AM, Daniel Fuka wrote:
>> >>
>> >> Howdy,
>> >>
>> >> I have searched the lists and can not seem to find a solution to my
>> >> problem. I need to be able to dynamically modify a string inside a
>> >> function to build a new function. "sub" replaces with a quoted
>> >> string... and "parse" of "sub" returns expression... How can I get an
>> >> unquoted string from a regex to stick into a "body" of a function?
>> >
>> >
>> > It's possible to do what you want, though you don't want to be using
>> > parse(), you can just edit the language expression that body(fsong)
>> > gives
>> > you, and assign it back.  But that's a messy way to solve your problem.
>> >
>> > Why not create a new function containing the new string?  e.g.
>> >
>> > makefsong <- function(name = "fuka") {
>> >   line1 <- paste("my name is", name)
>> >   function(x) {
>> >     song <- paste(line1, x)
>> >     return(song)
>> >   }
>> > }
>> >
>> > f1 <- makefsong()
>> > f1("I live on the second floor")
>> > f2 <- makefsong("muka")
>> > f2("I live on the second floor")
>> >
>> > Duncan Murdoch
>> >
>> >>
>> >> Thanks for your help!
>> >> dan
>> >>
>> >> # Original Function
>> >> fsong=function(x){
>> >>   song=paste("my name is fuka,",x)
>> >>   return(song)
>> >> }
>> >> fsong("I live on the second floor")
>> >> #
>> >> # Copy and modify using "sub" returns quoted string with escaped quotes
>> >> #   internally... as expected.. which can not be evaluated.
>> >> nsong=fsong
>> >> body(nsong)[[grep("fuka",body(nsong))]]=
>> >>     sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))
>> >>
>> >> nsong("I live on the second floor") # broken
>> >>
>> >> #
>> >> # Copy and modify with "parse" of  "sub",  returns expression.. but
>> >> without quotes,
>> >> # o getting closer.
>> >> #
>> >> nsong=fsong
>> >> body(nsong)[[grep("fuka",body(nsong))]]=
>> >>
>> >>
>> >> parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>
>


From gunter.berton at gene.com  Tue Sep 23 02:18:01 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 22 Sep 2014 17:18:01 -0700
Subject: [R] Fwd:  Dynamic regex/sub changes to function
In-Reply-To: <CACk-te3A3c=XdQ73QPFbAhwf12gsfd7vs8zv4HQJ6R1aJPUvOw@mail.gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>
	<5420341B.8070604@gmail.com>
	<CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>
	<54205B40.9040005@gmail.com>
	<CAB9w6XxHk1EbpH4HsyLdSoEKG58T-P5ECobV7WC_xXYtoqwyrg@mail.gmail.com>
	<CACk-te3A3c=XdQ73QPFbAhwf12gsfd7vs8zv4HQJ6R1aJPUvOw@mail.gmail.com>
Message-ID: <CACk-te1CgptfJNu6rnN9Omzf0Oz7MXj7dXvUnq2eR1FHPJ0YDA@mail.gmail.com>

(failed to cc the list)

Daniel:

Do you understand what a parse tree is?

Try this:

 f <- function(x){
+ y <- x^2
+ z <- sin(y+2)
+ }

> body(f)
{
    y <- x^2
    z <- sin(y + 2)
}

> as.list(body(f))
[[1]]
`{`

[[2]]
y <- x^2

[[3]]
z <- sin(y + 2)

> body(f)[[c(3,3,1)]]
sin

> class(body(f))
[1] "{"


You should listen to your elders (Bill and Duncan) and **don't do this. **

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Sep 22, 2014 at 4:38 PM, Daniel Fuka <drf28 at cornell.edu> wrote:
> Thanks everyone for the help. I need to step back and refresh my
> memory on expressions as I am still unclear as to why I can not
> directly edit:
> body(nsong)[[2]]
> # Which can be located from a grep:
> body(nsong)[[grep("fuka",body(nsong))]]
> # though I believe
> class(body(nsong)[[2]])
> [1] "="
> # is trying to give me a pretty blatant hint... {: -)
>
> On Mon, Sep 22, 2014 at 1:24 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 22/09/2014 11:34 AM, Daniel Fuka wrote:
>>>
>>> Howdy Duncan,
>>>
>>> Thanks for the quick reply!  I must be missing something
>>> simple/obvious. I need to have the "sub()" not return quoted and
>>> escaped characters to "just edit the language expression". In my
>>> problem, there is a function that is supported from a different
>>> package. So I always want to use the supported function as my base...
>>> but a url in the supported function needs to be changed dynamically
>>> for my application, which is easiest using "sub()".
>>>
>>> I am trying to do what you correctly indicate I would need to do:
>>> "just edit the language expression that body(fsong) gives you, and
>>> assign it back"
>>> BUT, using sub, I get back a quoted string in my example if I just use
>>> sed:
>>>
>>> > fsong
>>> function(x){
>>>   song=paste("my name is fuka,",x)
>>>   return(song)
>>> }
>>> # Using "sub()" becomes:
>>> > nsong
>>> function (x)
>>> {
>>>      "song = paste(\"my name is muka,\", x)"
>>>      return(song)
>>> }
>>
>>
>> You didn't do it right :-).   With fsong as above, the string to edit is
>> body(fsong)[[c(2,3,2)]].  (Why c(2,3,2)?  Because that's where the string is
>> in the parse tree.  Try looking at variations on body(fsong)[[c(2,3,2)]] to
>> figure it out, e.g.
>> body(fsong)[[c(2,3)]], or body(fsong)[[c(2,3,3)]], etc.)
>>
>> So this code would work:
>>
>> orig <- body(fsong)[[c(2,3,2)]]
>> new <- sub("fuka", "muka", orig)
>>
>> # Now put it back in nsong:
>> nsong <- fsong
>> body(nsong)[[c(2,3,2)]] <- new
>>
>> But as Bill said, this is a really bad idea.  If you just *think* about
>> changing that fsong function, it will break.
>>
>> Duncan Murdoch
>>
>>>
>>> Thanks again for the quick reply and help you are giving me!
>>> dan
>>>
>>> On Mon, Sep 22, 2014 at 10:37 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>> > On 22/09/2014 9:16 AM, Daniel Fuka wrote:
>>> >>
>>> >> Howdy,
>>> >>
>>> >> I have searched the lists and can not seem to find a solution to my
>>> >> problem. I need to be able to dynamically modify a string inside a
>>> >> function to build a new function. "sub" replaces with a quoted
>>> >> string... and "parse" of "sub" returns expression... How can I get an
>>> >> unquoted string from a regex to stick into a "body" of a function?
>>> >
>>> >
>>> > It's possible to do what you want, though you don't want to be using
>>> > parse(), you can just edit the language expression that body(fsong)
>>> > gives
>>> > you, and assign it back.  But that's a messy way to solve your problem.
>>> >
>>> > Why not create a new function containing the new string?  e.g.
>>> >
>>> > makefsong <- function(name = "fuka") {
>>> >   line1 <- paste("my name is", name)
>>> >   function(x) {
>>> >     song <- paste(line1, x)
>>> >     return(song)
>>> >   }
>>> > }
>>> >
>>> > f1 <- makefsong()
>>> > f1("I live on the second floor")
>>> > f2 <- makefsong("muka")
>>> > f2("I live on the second floor")
>>> >
>>> > Duncan Murdoch
>>> >
>>> >>
>>> >> Thanks for your help!
>>> >> dan
>>> >>
>>> >> # Original Function
>>> >> fsong=function(x){
>>> >>   song=paste("my name is fuka,",x)
>>> >>   return(song)
>>> >> }
>>> >> fsong("I live on the second floor")
>>> >> #
>>> >> # Copy and modify using "sub" returns quoted string with escaped quotes
>>> >> #   internally... as expected.. which can not be evaluated.
>>> >> nsong=fsong
>>> >> body(nsong)[[grep("fuka",body(nsong))]]=
>>> >>     sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))
>>> >>
>>> >> nsong("I live on the second floor") # broken
>>> >>
>>> >> #
>>> >> # Copy and modify with "parse" of  "sub",  returns expression.. but
>>> >> without quotes,
>>> >> # o getting closer.
>>> >> #
>>> >> nsong=fsong
>>> >> body(nsong)[[grep("fuka",body(nsong))]]=
>>> >>
>>> >>
>>> >> parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> >
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Sep 23 03:42:14 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Sep 2014 21:42:14 -0400
Subject: [R] Dynamic regex/sub changes to function
In-Reply-To: <CAB9w6XxHk1EbpH4HsyLdSoEKG58T-P5ECobV7WC_xXYtoqwyrg@mail.gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>	<5420341B.8070604@gmail.com>	<CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>	<54205B40.9040005@gmail.com>
	<CAB9w6XxHk1EbpH4HsyLdSoEKG58T-P5ECobV7WC_xXYtoqwyrg@mail.gmail.com>
Message-ID: <5420CFF6.2040204@gmail.com>

On 22/09/2014, 7:38 PM, Daniel Fuka wrote:
> Thanks everyone for the help. I need to step back and refresh my
> memory on expressions as I am still unclear as to why I can not
> directly edit:
> body(nsong)[[2]]
> # Which can be located from a grep:
> body(nsong)[[grep("fuka",body(nsong))]]
> # though I believe
> class(body(nsong)[[2]])
> [1] "="
> # is trying to give me a pretty blatant hint... {: -)

Here's another hint:  everything in R is a function call.  You're
looking at a call to the function named "=".

Duncan Murdoch

> 
> On Mon, Sep 22, 2014 at 1:24 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 22/09/2014 11:34 AM, Daniel Fuka wrote:
>>>
>>> Howdy Duncan,
>>>
>>> Thanks for the quick reply!  I must be missing something
>>> simple/obvious. I need to have the "sub()" not return quoted and
>>> escaped characters to "just edit the language expression". In my
>>> problem, there is a function that is supported from a different
>>> package. So I always want to use the supported function as my base...
>>> but a url in the supported function needs to be changed dynamically
>>> for my application, which is easiest using "sub()".
>>>
>>> I am trying to do what you correctly indicate I would need to do:
>>> "just edit the language expression that body(fsong) gives you, and
>>> assign it back"
>>> BUT, using sub, I get back a quoted string in my example if I just use
>>> sed:
>>>
>>>> fsong
>>> function(x){
>>>   song=paste("my name is fuka,",x)
>>>   return(song)
>>> }
>>> # Using "sub()" becomes:
>>>> nsong
>>> function (x)
>>> {
>>>      "song = paste(\"my name is muka,\", x)"
>>>      return(song)
>>> }
>>
>>
>> You didn't do it right :-).   With fsong as above, the string to edit is
>> body(fsong)[[c(2,3,2)]].  (Why c(2,3,2)?  Because that's where the string is
>> in the parse tree.  Try looking at variations on body(fsong)[[c(2,3,2)]] to
>> figure it out, e.g.
>> body(fsong)[[c(2,3)]], or body(fsong)[[c(2,3,3)]], etc.)
>>
>> So this code would work:
>>
>> orig <- body(fsong)[[c(2,3,2)]]
>> new <- sub("fuka", "muka", orig)
>>
>> # Now put it back in nsong:
>> nsong <- fsong
>> body(nsong)[[c(2,3,2)]] <- new
>>
>> But as Bill said, this is a really bad idea.  If you just *think* about
>> changing that fsong function, it will break.
>>
>> Duncan Murdoch
>>
>>>
>>> Thanks again for the quick reply and help you are giving me!
>>> dan
>>>
>>> On Mon, Sep 22, 2014 at 10:37 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> On 22/09/2014 9:16 AM, Daniel Fuka wrote:
>>>>>
>>>>> Howdy,
>>>>>
>>>>> I have searched the lists and can not seem to find a solution to my
>>>>> problem. I need to be able to dynamically modify a string inside a
>>>>> function to build a new function. "sub" replaces with a quoted
>>>>> string... and "parse" of "sub" returns expression... How can I get an
>>>>> unquoted string from a regex to stick into a "body" of a function?
>>>>
>>>>
>>>> It's possible to do what you want, though you don't want to be using
>>>> parse(), you can just edit the language expression that body(fsong)
>>>> gives
>>>> you, and assign it back.  But that's a messy way to solve your problem.
>>>>
>>>> Why not create a new function containing the new string?  e.g.
>>>>
>>>> makefsong <- function(name = "fuka") {
>>>>   line1 <- paste("my name is", name)
>>>>   function(x) {
>>>>     song <- paste(line1, x)
>>>>     return(song)
>>>>   }
>>>> }
>>>>
>>>> f1 <- makefsong()
>>>> f1("I live on the second floor")
>>>> f2 <- makefsong("muka")
>>>> f2("I live on the second floor")
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>
>>>>> Thanks for your help!
>>>>> dan
>>>>>
>>>>> # Original Function
>>>>> fsong=function(x){
>>>>>   song=paste("my name is fuka,",x)
>>>>>   return(song)
>>>>> }
>>>>> fsong("I live on the second floor")
>>>>> #
>>>>> # Copy and modify using "sub" returns quoted string with escaped quotes
>>>>> #   internally... as expected.. which can not be evaluated.
>>>>> nsong=fsong
>>>>> body(nsong)[[grep("fuka",body(nsong))]]=
>>>>>     sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]]))
>>>>>
>>>>> nsong("I live on the second floor") # broken
>>>>>
>>>>> #
>>>>> # Copy and modify with "parse" of  "sub",  returns expression.. but
>>>>> without quotes,
>>>>> # o getting closer.
>>>>> #
>>>>> nsong=fsong
>>>>> body(nsong)[[grep("fuka",body(nsong))]]=
>>>>>
>>>>>
>>>>> parse(text=sub("fuka","muka",list(body(fsong)[[grep("fuka",body(fsong))]])))
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>>


From terran at consistent.org  Tue Sep 23 04:59:19 2014
From: terran at consistent.org (Terran Melconian)
Date: Mon, 22 Sep 2014 22:59:19 -0400
Subject: [R] Confused by dlnorm - densities do not match histogram
Message-ID: <20140923025919.A943F880773@you-are-going-to-die.consistent.org>

Good evening!  I'm running into some surprising behavior with dlnorm() and
trying to understand it.

To set the stage, I'll plot the density and overlay a normal distribution.
This works exactly as expected; the two graphs align quite closely:

qplot(data=data.frame(x=rnorm(1e5,4,2)),x=x,stat='density',geom='area') +
stat_function(fun=dnorm,args=list(4,2),colour='blue')

but then I change to a log normal distribution and the behaviour gets
odd.  The distribution looks nothing like the density plot:

qplot(data=data.frame(x=rlnorm(1e5,4,2)),x=x,log='x',stat='density',geom='area') + stat_function(fun=dlnorm,args=list(4,2),colour='blue')

I thought the issue might be scale transformation - if dlnorm is giving the
density per unit x this is not the same as the density after transforming
to log(x).  So I tried to effect this scale transformation manually by
dividing by the derivative of log(x) - i.e. by multiplying by x - but this
also did not match:

qplot(data=data.frame(x=rlnorm(1e5,4,2)),x=x,log='x',stat='density',geom='area') + stat_function(fun=function(x,...){dlnorm(x,...)*x},args=list(4,2),colour='blue')

I also tried plotting without the log scale to eliminate that
transformation as a source of discrepancy, and they still don't match:

qplot(data=data.frame(x=rlnorm(1e5,4,2)),x=x,stat='density',geom='area',xlim=c(0,50)) + stat_function(fun=dlnorm,args=list(4,2),colour='blue')

I'd appreciate any help in understanding what I'm missing.


From r.turner at auckland.ac.nz  Tue Sep 23 06:24:52 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 23 Sep 2014 16:24:52 +1200
Subject: [R] Fwd:  Dynamic regex/sub changes to function
In-Reply-To: <CACk-te1CgptfJNu6rnN9Omzf0Oz7MXj7dXvUnq2eR1FHPJ0YDA@mail.gmail.com>
References: <CAB9w6XwHpgGN=QD09QGGh0jXnUmpcSQm80+qWn2_aEN785uUNA@mail.gmail.com>	<5420341B.8070604@gmail.com>	<CAB9w6Xx7ev7hAS+TfC=Qbu08Az5DjRGbkP3cyLHxfxwdyadKug@mail.gmail.com>	<54205B40.9040005@gmail.com>	<CAB9w6XxHk1EbpH4HsyLdSoEKG58T-P5ECobV7WC_xXYtoqwyrg@mail.gmail.com>	<CACk-te3A3c=XdQ73QPFbAhwf12gsfd7vs8zv4HQJ6R1aJPUvOw@mail.gmail.com>
	<CACk-te1CgptfJNu6rnN9Omzf0Oz7MXj7dXvUnq2eR1FHPJ0YDA@mail.gmail.com>
Message-ID: <5420F614.2050306@auckland.ac.nz>

On 23/09/14 12:18, Bert Gunter wrote:

<SNIP>

> Daniel:
>
> Do you understand what a parse tree is?

<SNIP>

Paraphrasing a quote attributed to Feynman:  "If you think you 
understand what a parse tree is, then you don't understand what a parse 
tree is." :-)

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS


From loris.bennett at fu-berlin.de  Tue Sep 23 09:05:36 2014
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 23 Sep 2014 09:05:36 +0200
Subject: [R] Using factor levels as coordinates with geom_rect
Message-ID: <87sijierzz.fsf@hornfels.zedat.fu-berlin.de>

Hi,

With ggplot2 I can use the following to create a rectangle 

geom_rect(aes(ymin=as.Date("8-Apr-2014", format="%d-%b-%Y"),
                ymax=as.Date("30-Apr-2014", format="%d-%b-%Y"),
                xmin="node002",xmax="node098"),

where the x values are levels of a factor.  This works if I want the
rectangle to extend across a range of factor level.  My question is this:

How can I create a similar rectangle around a single factor level?

My assumption is that I should be able to convert the factor to a
numerical value.  I could then subtract and add a smaller number to
obtain xmin and xmax, respectively.  However, I don't know how to
convert the factor level to a value which corresponds to its
x-coordinate on the plot.

I posted a longer version of this question on StackOverflow with the
full code, input data, and a plot of the output:

http://stackoverflow.com/questions/25872633/using-factor-levels-with-geom-rect

Unfortunately, I didn't get an answer.

Cheers,

Loris

-- 
This signature is currently under construction.


From stephane.adamowicz at avignon.inra.fr  Tue Sep 23 09:14:24 2014
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Tue, 23 Sep 2014 09:14:24 +0200
Subject: [R] ANOVA and permutation tests : beware of traps
Message-ID: <1D038291-F4E4-435E-8CCE-8052192A5D30@avignon.inra.fr>

Recently, I came across a strange and potentially troublesome behaviour of the lm and aov functions that ask questions about calculation accuracy. Let us consider the 2 following datasets dat1 & dat2 :

> (dat1 <- data.frame(Y=c(1:3, 10+1:3), F=c(rep("A",3), rep("B",3))))
   Y F
1  1 A
2  2 A
3  3 A
4 11 B
5 12 B
6 13 B
> (dat2 <- data.frame(Y=c(10+1:3, 1:3), F=c(rep("A",3), rep("B",3))))
   Y F
1 11 A
2 12 A
3 13 A
4  1 B
5  2 B
6  3 B

They only differ in the order of values that were exchanged between samples A and B. Thus the sd is 1 for each sample in either data sets, and the absolute mean difference |A-B| is 10 in both datasets.
Now, let us perform an anova to compare samples A and B in both datasets (of course, in such simple case, a bilateral T test would do the job, but an anova is nevertheless allowed and should give the same probability than Student's test):

> (anova1 <- anova(lm(Y~F, dat1)))
Analysis of Variance Table

Response: Y
          Df Sum Sq Mean Sq F value    Pr(>F)    
F          1    150     150     150 0.0002552 ***
Residuals  4      4       1                      

> (anova2 <- anova(lm(Y~F, dat2)))
Analysis of Variance Table

Response: Y
          Df Sum Sq Mean Sq F value    Pr(>F)    
F          1    150     150     150 0.0002552 ***
Residuals  4      4       1

As expected, both datasets give a same anova table, but this is only apparent. Indeed :

> anova1$F[1] == anova2$F[1]
[1] FALSE
> anova1$F[1] - anova2$F[1]
[1] 5.684342e-14

In fact the F values differ slightly, and this holds also for the aov function. I checked also (not shown) that both the residual and factorial sums of squares differ between dat1 and dat2. Thus, for some undocumented reason (at least for the end user), the F values depend on the order of data!
While such tiny differences (e-14 in this example) are devoid of consequences on the risk evaluation by Fisher's distribution, they may have huge consequences on the risk evaluation by the permutation method. Indeed, the shift from continuous to discrete distributions is far from being insignificant.

For instance, the following code in R is at the basis of many permutation algorithms found in the internet and in teaching because it seems quite straightforward (see for example http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permutation%20Anova/PermTestsAnova.html
http://www.usna.edu/Users/math/jager/courses/sm439/labs/Lab7.pdf
http://biostatistics1014.blogspot.fr/2013/04/one-way-anova-permutation-test-and.html
http://adn.biol.umontreal.ca/~numericalecology/Rcode/):

> nperm <- 1000	# number of permutations
> Fperm <- replicate(n=nperm, anova(lm(sample(Y) ~ F, dat1))$F[1]) # calculates nperm F values
> (prob <- (sum(anova1$F[1] <= Fperm) + 1)/(nperm +1))	# risk calculation	
[1] 0.04695305

Of course, because of the sample function, repeating this code gives different prob values, but they remain always close to 5% instead of the exact probability of 10%. Indeed, there are only choose(6,3) = 20 possible permutations, but because they are symmetric, they give only 10 absolute mean differences. Thus, the only exact probabilities are 10%, 20% ... 100%. In our example where samples do not overlap, 10% is obviously the right answer.

Thus, the use of lm and aov functions in permutation methods does not seem a good idea as it results in biases that underestimate the exact risk. In the simple case of one-way anova, it is quite simple to remedy this problem. As the total Sums of squares and the degrees of freedom do not change with permutations, it is easier and much faster to compare the residual sums of squares. For instance, the exact probabilities can be calculated that way :

> combi <- combn(6, 3, FUN=function(i) {append(dat1$Y[i], dat1$Y[-i])}) # all permutations
> SCEResid <- apply(combi, 2, FUN=function(x) sum(tapply(x, dat1$F, function(x) sum((x - mean(x))^2)))) # all resi SS
> (prob <- mean(SCEResid <= SCEResid[1])) # risk calculation
[1] 0.1

10% is indeed the exact risk.

Finally, my problem is : How can we know if R libraries that use randomization procedures are not biased ? In the basic case of one way anova, it seems easy to submit the above example (by the way, the defunct lmPerm library does not succeed ...), but how can we check more complex anova models ?




	[[alternative HTML version deleted]]


From jwiley.psych at gmail.com  Tue Sep 23 10:36:56 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 23 Sep 2014 18:36:56 +1000
Subject: [R] ANOVA and permutation tests : beware of traps
In-Reply-To: <1D038291-F4E4-435E-8CCE-8052192A5D30@avignon.inra.fr>
References: <1D038291-F4E4-435E-8CCE-8052192A5D30@avignon.inra.fr>
Message-ID: <CANz9Z_JO45da0rRkOC3h94nzbrnyoXcMLK0Z4yTmnr2BHJq7HA@mail.gmail.com>

Hi Stephane,

This is the well known result of limitted floating point precision (e.g.,
http://www.validlab.com/goldberg/addendum.html).  Using a test of
approximate rather than exact equality shows R yields the correct answer:

nperm <- 10000
Fperm <- replicate(n=nperm, anova(lm(sample(Y) ~ F, dat1))$F[1]) #
calculates nperm F values
(prob <- (sum(anova1$F[1] <= (Fperm + .Machine$double.eps ^ 0.5)) +
1)/(nperm +1))  # risk calculation

yields

0.10009

I picked .Machine$double.eps ^ 0.5 somewhat arbitrarily as the default for
equality testing from ?all.equal

Cheers,

Josh



On Tue, Sep 23, 2014 at 5:14 PM, St?phane Adamowicz <
stephane.adamowicz at avignon.inra.fr> wrote:

> Recently, I came across a strange and potentially troublesome behaviour of
> the lm and aov functions that ask questions about calculation accuracy. Let
> us consider the 2 following datasets dat1 & dat2 :
>
> > (dat1 <- data.frame(Y=c(1:3, 10+1:3), F=c(rep("A",3), rep("B",3))))
>    Y F
> 1  1 A
> 2  2 A
> 3  3 A
> 4 11 B
> 5 12 B
> 6 13 B
> > (dat2 <- data.frame(Y=c(10+1:3, 1:3), F=c(rep("A",3), rep("B",3))))
>    Y F
> 1 11 A
> 2 12 A
> 3 13 A
> 4  1 B
> 5  2 B
> 6  3 B
>
> They only differ in the order of values that were exchanged between
> samples A and B. Thus the sd is 1 for each sample in either data sets, and
> the absolute mean difference |A-B| is 10 in both datasets.
> Now, let us perform an anova to compare samples A and B in both datasets
> (of course, in such simple case, a bilateral T test would do the job, but
> an anova is nevertheless allowed and should give the same probability than
> Student's test):
>
> > (anova1 <- anova(lm(Y~F, dat1)))
> Analysis of Variance Table
>
> Response: Y
>           Df Sum Sq Mean Sq F value    Pr(>F)
> F          1    150     150     150 0.0002552 ***
> Residuals  4      4       1
>
> > (anova2 <- anova(lm(Y~F, dat2)))
> Analysis of Variance Table
>
> Response: Y
>           Df Sum Sq Mean Sq F value    Pr(>F)
> F          1    150     150     150 0.0002552 ***
> Residuals  4      4       1
>
> As expected, both datasets give a same anova table, but this is only
> apparent. Indeed :
>
> > anova1$F[1] == anova2$F[1]
> [1] FALSE
> > anova1$F[1] - anova2$F[1]
> [1] 5.684342e-14
>
> In fact the F values differ slightly, and this holds also for the aov
> function. I checked also (not shown) that both the residual and factorial
> sums of squares differ between dat1 and dat2. Thus, for some undocumented
> reason (at least for the end user), the F values depend on the order of
> data!
> While such tiny differences (e-14 in this example) are devoid of
> consequences on the risk evaluation by Fisher's distribution, they may have
> huge consequences on the risk evaluation by the permutation method. Indeed,
> the shift from continuous to discrete distributions is far from being
> insignificant.
>
> For instance, the following code in R is at the basis of many permutation
> algorithms found in the internet and in teaching because it seems quite
> straightforward (see for example
> http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permutation%20Anova/PermTestsAnova.html
> http://www.usna.edu/Users/math/jager/courses/sm439/labs/Lab7.pdf
>
> http://biostatistics1014.blogspot.fr/2013/04/one-way-anova-permutation-test-and.html
> http://adn.biol.umontreal.ca/~numericalecology/Rcode/):
>
> > nperm <- 1000 # number of permutations
> > Fperm <- replicate(n=nperm, anova(lm(sample(Y) ~ F, dat1))$F[1]) #
> calculates nperm F values
> > (prob <- (sum(anova1$F[1] <= Fperm) + 1)/(nperm +1))  # risk calculation
> [1] 0.04695305
>
> Of course, because of the sample function, repeating this code gives
> different prob values, but they remain always close to 5% instead of the
> exact probability of 10%. Indeed, there are only choose(6,3) = 20 possible
> permutations, but because they are symmetric, they give only 10 absolute
> mean differences. Thus, the only exact probabilities are 10%, 20% ... 100%.
> In our example where samples do not overlap, 10% is obviously the right
> answer.
>
> Thus, the use of lm and aov functions in permutation methods does not seem
> a good idea as it results in biases that underestimate the exact risk. In
> the simple case of one-way anova, it is quite simple to remedy this
> problem. As the total Sums of squares and the degrees of freedom do not
> change with permutations, it is easier and much faster to compare the
> residual sums of squares. For instance, the exact probabilities can be
> calculated that way :
>
> > combi <- combn(6, 3, FUN=function(i) {append(dat1$Y[i], dat1$Y[-i])}) #
> all permutations
> > SCEResid <- apply(combi, 2, FUN=function(x) sum(tapply(x, dat1$F,
> function(x) sum((x - mean(x))^2)))) # all resi SS
> > (prob <- mean(SCEResid <= SCEResid[1])) # risk calculation
> [1] 0.1
>
> 10% is indeed the exact risk.
>
> Finally, my problem is : How can we know if R libraries that use
> randomization procedures are not biased ? In the basic case of one way
> anova, it seems easy to submit the above example (by the way, the defunct
> lmPerm library does not succeed ...), but how can we check more complex
> anova models ?
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

	[[alternative HTML version deleted]]


From Ray.Brownrigg at ecs.vuw.ac.nz  Tue Sep 23 10:41:04 2014
From: Ray.Brownrigg at ecs.vuw.ac.nz (Ray Brownrigg)
Date: Tue, 23 Sep 2014 20:41:04 +1200
Subject: [R] Plotting boundary lines from shapefiles overtop a map of
 Canada
In-Reply-To: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>
References: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>
Message-ID: <54213220.5030809@ecs.vuw.ac.nz>

On 23/09/2014 3:27 a.m., Alain Dubreuil wrote:
> Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.
>
> To plot the map of Canada, I have used the following line of code:
>
>        map(database= "worldHires","Canada", ylim=c(39,90), xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE, projection="lambert", param=c(50,65))
>
> Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.
>
> To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:
>
>        lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
>        lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
>        coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long
>        points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red", 0.5))  #plot converted points
>
> As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.
>
> Using readOGR:
>
>        region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
>        plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), col=alpha("lightgreen", 0.6), border=TRUE)
You don't state which package readOGR() comes from, but it is not part 
of the maps package, which doesn't understand shapefiles, so just using 
plot() on top of a (projected) map() is unlikely to succeed.

I believe what you have to do is go back to your lat/long pairs for your 
SAR regions and use mapproject() to convert them to the coordinates used 
by the plotted projection. Note that you don't need the proj="lambert" 
option when you call mapproject() after a call to map() with a 
projection because the most recent projection (and its parameters) are 
"remembered".  Also I suspect (though untested) is that if you put NA 
pairs in between your lists of projected SAR regions, then you can just 
use lines() to draw them all at once.

Hope this helps,
Ray Brownrigg
> Using read.shp and draw.shp:
>
>        region <- read.shp("C:/myRfolder/mySARshapefile.shp")
>        draw.shape(shape=region, type="poly", col="red")
>
> Using readShapePoly:
>
>        region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
>        plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), col=alpha("lightgreen", 0.6), border=TRUE)
>
> Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:
>
>        region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
>        lines(region, col=alpha("black", 0.6))
>
> I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")
>
> I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.
>
> Thanks
>
> Alain Dubreuil
> Ottawa, Canada
>


From ripley at stats.ox.ac.uk  Tue Sep 23 11:49:01 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 23 Sep 2014 10:49:01 +0100
Subject: [R] ANOVA and permutation tests : beware of traps
In-Reply-To: <1D038291-F4E4-435E-8CCE-8052192A5D30@avignon.inra.fr>
References: <1D038291-F4E4-435E-8CCE-8052192A5D30@avignon.inra.fr>
Message-ID: <5421420D.2000203@stats.ox.ac.uk>

Beware of the trap of listening to people with no knowledge of basic 
numerical methods!

It really is basic that the results of floating-point computer 
calculations depends on the order in which they are done (and the 
compiler can change the order).  Using == on such calculations is warned 
about on its help page.

The same warning applies to using <= if equality is important.

It bears repeating that the problems are exacerbated on platforms which 
use extended-precision registers for some but not all of their 
calculations (and most R platforms do).  The classic reference is pp. 
248ff of http://www.validlab.com/goldberg/paper.pdf (part of a Sun manual).


On 23/09/2014 08:14, St?phane Adamowicz wrote:
> Recently, I came across a strange and potentially troublesome behaviour of the lm and aov functions that ask questions about calculation accuracy. Let us consider the 2 following datasets dat1 & dat2 :
>
>> (dat1 <- data.frame(Y=c(1:3, 10+1:3), F=c(rep("A",3), rep("B",3))))
>     Y F
> 1  1 A
> 2  2 A
> 3  3 A
> 4 11 B
> 5 12 B
> 6 13 B
>> (dat2 <- data.frame(Y=c(10+1:3, 1:3), F=c(rep("A",3), rep("B",3))))
>     Y F
> 1 11 A
> 2 12 A
> 3 13 A
> 4  1 B
> 5  2 B
> 6  3 B
>
> They only differ in the order of values that were exchanged between samples A and B. Thus the sd is 1 for each sample in either data sets, and the absolute mean difference |A-B| is 10 in both datasets.
> Now, let us perform an anova to compare samples A and B in both datasets (of course, in such simple case, a bilateral T test would do the job, but an anova is nevertheless allowed and should give the same probability than Student's test):
>
>> (anova1 <- anova(lm(Y~F, dat1)))
> Analysis of Variance Table
>
> Response: Y
>            Df Sum Sq Mean Sq F value    Pr(>F)
> F          1    150     150     150 0.0002552 ***
> Residuals  4      4       1
>
>> (anova2 <- anova(lm(Y~F, dat2)))
> Analysis of Variance Table
>
> Response: Y
>            Df Sum Sq Mean Sq F value    Pr(>F)
> F          1    150     150     150 0.0002552 ***
> Residuals  4      4       1
>
> As expected, both datasets give a same anova table, but this is only apparent. Indeed :
>
>> anova1$F[1] == anova2$F[1]
> [1] FALSE
>> anova1$F[1] - anova2$F[1]
> [1] 5.684342e-14
>
> In fact the F values differ slightly, and this holds also for the aov function. I checked also (not shown) that both the residual and factorial sums of squares differ between dat1 and dat2. Thus, for some undocumented reason (at least for the end user), the F values depend on the order of data!
> While such tiny differences (e-14 in this example) are devoid of consequences on the risk evaluation by Fisher's distribution, they may have huge consequences on the risk evaluation by the permutation method. Indeed, the shift from continuous to discrete distributions is far from being insignificant.
>
> For instance, the following code in R is at the basis of many permutation algorithms found in the internet and in teaching because it seems quite straightforward (see for example http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Permutation%20Anova/PermTestsAnova.html
> http://www.usna.edu/Users/math/jager/courses/sm439/labs/Lab7.pdf
> http://biostatistics1014.blogspot.fr/2013/04/one-way-anova-permutation-test-and.html
> http://adn.biol.umontreal.ca/~numericalecology/Rcode/):
>
>> nperm <- 1000	# number of permutations
>> Fperm <- replicate(n=nperm, anova(lm(sample(Y) ~ F, dat1))$F[1]) # calculates nperm F values
>> (prob <- (sum(anova1$F[1] <= Fperm) + 1)/(nperm +1))	# risk calculation	
> [1] 0.04695305
>
> Of course, because of the sample function, repeating this code gives different prob values, but they remain always close to 5% instead of the exact probability of 10%. Indeed, there are only choose(6,3) = 20 possible permutations, but because they are symmetric, they give only 10 absolute mean differences. Thus, the only exact probabilities are 10%, 20% ... 100%. In our example where samples do not overlap, 10% is obviously the right answer.
>
> Thus, the use of lm and aov functions in permutation methods does not seem a good idea as it results in biases that underestimate the exact risk. In the simple case of one-way anova, it is quite simple to remedy this problem. As the total Sums of squares and the degrees of freedom do not change with permutations, it is easier and much faster to compare the residual sums of squares. For instance, the exact probabilities can be calculated that way :
>
>> combi <- combn(6, 3, FUN=function(i) {append(dat1$Y[i], dat1$Y[-i])}) # all permutations
>> SCEResid <- apply(combi, 2, FUN=function(x) sum(tapply(x, dat1$F, function(x) sum((x - mean(x))^2)))) # all resi SS
>> (prob <- mean(SCEResid <= SCEResid[1])) # risk calculation
> [1] 0.1
>
> 10% is indeed the exact risk.
>
> Finally, my problem is : How can we know if R libraries that use randomization procedures are not biased ? In the basic case of one way anova, it seems easy to submit the above example (by the way, the defunct lmPerm library does not succeed ...), but how can we check more complex anova models ?
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From angel.rodriguez at matiainstituto.net  Tue Sep 23 15:04:22 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Tue, 23 Sep 2014 15:04:22 +0200
Subject: [R] Copying tables from R to Excel
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B2BC@MATIAEXCH.matiaf.local>

Dear Subscribers,

I've found this recommendation to paste an R table to Excel:

HTML.matrix( summary(iris), file("clipboard", "w"), append=F )
   # paste into Excel

After installing R2HTML and writting that command, I get:

Error: could not find function "HTML.matrix"

Any clue?

Thank you very much,

Angel Rodr?guez-Laso

	[[alternative HTML version deleted]]


From ivan.calandra at u-bourgogne.fr  Tue Sep 23 15:12:19 2014
From: ivan.calandra at u-bourgogne.fr (Ivan Calandra)
Date: Tue, 23 Sep 2014 15:12:19 +0200
Subject: [R] Copying tables from R to Excel
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B2BC@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2BC@MATIAEXCH.matiaf.local>
Message-ID: <542171B3.2000808@u-bourgogne.fr>

library(R2HTML) ??

Le 23/09/14 15:04, Angel Rodriguez a ?crit :
> Dear Subscribers,
>
> I've found this recommendation to paste an R table to Excel:
>
> HTML.matrix( summary(iris), file("clipboard", "w"), append=F )
>     # paste into Excel
>
> After installing R2HTML and writting that command, I get:
>
> Error: could not find function "HTML.matrix"
>
> Any clue?
>
> Thank you very much,
>
> Angel Rodr?guez-Laso
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Sep 23 16:10:55 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 23 Sep 2014 10:10:55 -0400
Subject: [R] Copying tables from R to Excel
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B2BC@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2BC@MATIAEXCH.matiaf.local>
Message-ID: <54217F6F.60002@gmail.com>

On 23/09/2014 9:04 AM, Angel Rodriguez wrote:
> Dear Subscribers,
>
> I've found this recommendation to paste an R table to Excel:
>
> HTML.matrix( summary(iris), file("clipboard", "w"), append=F )
>     # paste into Excel
>
> After installing R2HTML and writting that command, I get:
>
> Error: could not find function "HTML.matrix"
>
> Any clue?

HTML.matrix is the HTML method for matrix objects.  You just need to write

HTML( summary(iris), file("clipboard", "w"), append=F )

(I'd guess the information you were reading may have worked when it was 
written, but the R2HTML package stopped exporting the HTML.matrix 
function at some point.  Or maybe the author just never tried it.)

Duncan Murdoch


From dcarlson at tamu.edu  Tue Sep 23 16:15:00 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 23 Sep 2014 14:15:00 +0000
Subject: [R] Copying tables from R to Excel
In-Reply-To: <542171B3.2000808@u-bourgogne.fr>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2BC@MATIAEXCH.matiaf.local>
	<542171B3.2000808@u-bourgogne.fr>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9ADDD@mb02.ads.tamu.edu>

If you looked at the documentation for R2HTML you might have noticed that there is no function HTML.matrix. Perhaps your recommendation from an unnamed source is out of date? Assuming you loaded the package with library(R2HTML) as Ivan suggested, the command would be

HTML( summary(iris), file("clipboard", "w"), append=F )

Which will work just fine as long as you are using the Windows operating system. More technically, HTML() is a generic function with methods (156 in this case) for many different data types including matrices and tables. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
Sent: Tuesday, September 23, 2014 8:12 AM
To: r-help at r-project.org
Subject: Re: [R] Copying tables from R to Excel

library(R2HTML) ??

Le 23/09/14 15:04, Angel Rodriguez a ?crit :
> Dear Subscribers,
>
> I've found this recommendation to paste an R table to Excel:
>
> HTML.matrix( summary(iris), file("clipboard", "w"), append=F )
>     # paste into Excel
>
> After installing R2HTML and writting that command, I get:
>
> Error: could not find function "HTML.matrix"
>
> Any clue?
>
> Thank you very much,
>
> Angel Rodr?guez-Laso
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From wht_crl at yahoo.com  Tue Sep 23 17:10:37 2014
From: wht_crl at yahoo.com (carol white)
Date: Tue, 23 Sep 2014 08:10:37 -0700
Subject: [R] division of col by the sum of the col
Message-ID: <1411485037.57007.YahooMailNeo@web121505.mail.ne1.yahoo.com>

Hi,
If I want to divide the column of a matrix by the sum of the column, should I loop over the columns or can I use apply family? 


Regards,

Carol
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Sep 23 17:22:39 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 23 Sep 2014 08:22:39 -0700
Subject: [R] division of col by the sum of the col
In-Reply-To: <1411485037.57007.YahooMailNeo@web121505.mail.ne1.yahoo.com>
References: <1411485037.57007.YahooMailNeo@web121505.mail.ne1.yahoo.com>
Message-ID: <CACk-te0bCBPNVghP=93ZKPAPyov55BreVZZW3J8PW=c1UAj2Yg@mail.gmail.com>

Neither. Unless I misjudge, you really really need to do your homework
and read some basic R documentation -- e.g. An Intro to R, which ships
with R (and also the Posting Guide) -- before posting here further.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Sep 23, 2014 at 8:10 AM, carol white <wht_crl at yahoo.com> wrote:
> Hi,
> If I want to divide the column of a matrix by the sum of the column, should I loop over the columns or can I use apply family?
>
>
> Regards,
>
> Carol
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pollaroid at gmail.com  Tue Sep 23 17:41:39 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Tue, 23 Sep 2014 17:41:39 +0200
Subject: [R] How to combine character month and year columns into one column
Message-ID: <CAAC1QdD21hor4vgZfRaS1q53Pex1v_j+OnJfUM4FArLJjTpXiQ@mail.gmail.com>

Dear R users,

I have a data with  month and year columns which are both characters
and wanted to create a new column like Jan-1999
with the following code. The result is all NA for the month part. What
is wrong with the and what is the right way to combine the two?

ddf$MonthDay <- paste(month.abb[ddf$month], ddf$Year, sep="-" )


Thanks

> dput(ddf)
structure(list(month = c("01", "02", "03", "04", "05", "06",
"07", "08", "09", "10", "11", "12"), Year = c("1999", "1999",
"1999", "1999", "1999", "1999", "1999", "1999", "1999", "1999",
"1999", "1999"), views = c(42, 49, 44, 38, 37, 35, 38, 39, 38,
39, 38, 46), MonthDay = c("NA-1999", "NA-1999", "NA-1999", "NA-1999",
"NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999",
"NA-1999", "NA-1999")), .Names = c("month", "Year", "views",
"MonthDay"), row.names = 109:120, class = "data.frame")
>


From zadig_1 at excite.com  Tue Sep 23 17:50:28 2014
From: zadig_1 at excite.com (ce)
Date: Tue, 23 Sep 2014 11:50:28 -0400
Subject: [R] R Inter Process Communication tools/packages ?
Message-ID: <20140923115028.4902@web006.roc2.bluetie.com>


Hello All,

Is there any IPC tools like in UNIX/Linux systems in R ?
I know there is mmap package but I am looking something more like sockets . 
Any example appreciated . 

Thx .


From john.archie.mckown at gmail.com  Tue Sep 23 17:57:30 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 23 Sep 2014 10:57:30 -0500
Subject: [R] R Inter Process Communication tools/packages ?
In-Reply-To: <20140923115028.4902@web006.roc2.bluetie.com>
References: <20140923115028.4902@web006.roc2.bluetie.com>
Message-ID: <CAAJSdjgKY_HC-WXf=sNuwVWzxAWTTKhh_BZ_xt1ejmFOWCAW-g@mail.gmail.com>

On Tue, Sep 23, 2014 at 10:50 AM, ce <zadig_1 at excite.com> wrote:
>
> Hello All,
>
> Is there any IPC tools like in UNIX/Linux systems in R ?
> I know there is mmap package but I am looking something more like sockets .
> Any example appreciated .
>
> Thx .
>

Try looking at the documentation for socketConnection()
?socketConnection

addresses TCPIP sockets, UNIX pipes, and FIFOs.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From marc_schwartz at me.com  Tue Sep 23 18:03:25 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 23 Sep 2014 11:03:25 -0500
Subject: [R] How to combine character month and year columns into one
	column
In-Reply-To: <CAAC1QdD21hor4vgZfRaS1q53Pex1v_j+OnJfUM4FArLJjTpXiQ@mail.gmail.com>
References: <CAAC1QdD21hor4vgZfRaS1q53Pex1v_j+OnJfUM4FArLJjTpXiQ@mail.gmail.com>
Message-ID: <A34EF362-D69F-4CF3-8007-133F38029D87@me.com>

On Sep 23, 2014, at 10:41 AM, Kuma Raj <pollaroid at gmail.com> wrote:

> Dear R users,
> 
> I have a data with  month and year columns which are both characters
> and wanted to create a new column like Jan-1999
> with the following code. The result is all NA for the month part. What
> is wrong with the and what is the right way to combine the two?
> 
> ddf$MonthDay <- paste(month.abb[ddf$month], ddf$Year, sep="-" )
> 
> 
> Thanks
> 
>> dput(ddf)
> structure(list(month = c("01", "02", "03", "04", "05", "06",
> "07", "08", "09", "10", "11", "12"), Year = c("1999", "1999",
> "1999", "1999", "1999", "1999", "1999", "1999", "1999", "1999",
> "1999", "1999"), views = c(42, 49, 44, 38, 37, 35, 38, 39, 38,
> 39, 38, 46), MonthDay = c("NA-1999", "NA-1999", "NA-1999", "NA-1999",
> "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999",
> "NA-1999", "NA-1999")), .Names = c("month", "Year", "views",
> "MonthDay"), row.names = 109:120, class = "data.frame")
>> 
> 



Since you are trying to use ddf$month as an index into month.abb, you will either need to coerce ddf$month to numeric in your code, or adjust how the data frame is created.

In the case of the former approach:

> paste(month.abb[as.numeric(ddf$month)], ddf$Year, sep="-" )
 [1] "Jan-1999" "Feb-1999" "Mar-1999" "Apr-1999" "May-1999" "Jun-1999"
 [7] "Jul-1999" "Aug-1999" "Sep-1999" "Oct-1999" "Nov-1999" "Dec-1999"


Regards,

Marc Schwartz


From alain.dubreuil at cae.com  Tue Sep 23 18:17:20 2014
From: alain.dubreuil at cae.com (Alain Dubreuil)
Date: Tue, 23 Sep 2014 12:17:20 -0400
Subject: [R] Plotting boundary lines from shapefiles overtop a map of
 Canada
In-Reply-To: <54213220.5030809@ecs.vuw.ac.nz>
References: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>
	<54213220.5030809@ecs.vuw.ac.nz>
Message-ID: <F9A1252A5C3CEF4C8C2F70752F372BF63891C4B663@CAEMEX80.caecorp.cae.com>

Hi all,

Based on Ray's suggestions, I have tried the following script:

library(mapproj)
library(maps)
resuPdfFileName="C:/linesTest.pdf"
pdf(resuPdfFileName)
# Create a map of Canada in Lambert projection
map(database= "worldHires","Canada", ylim=c(39,90), xlim=c(-145,-25), col=alpha("grey90",0.5), fill=TRUE, projection="lambert", param=c(50,65))
# Use test position vectors to draw lines
yValue <- c(49.0, 49.0, 60.0, 60.0)
xValue <- c(105.0, 120.0, 120.0, 105.0)
# Convert the test vectors into lambert and then draw the lines
testLines <- mapproject(yValue, xValue, proj="lambert", param=c(50,65))
lines(testLines)
dev.off()

The script draws the map of Canada, but fails to draw the lines.  Please let me know what I'm doing wrong because I can't see it.  By the way, not specifying the lambert projection in the call to mapproject yields different results than specifying it which seems contrary to the documentation (?).

Thanks

Alain Dubreuil
Ottawa, Canada


-----Original Message-----
From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz] 
Sent: September-23-14 4:41 AM
To: Alain Dubreuil; r-help at r-project.org
Subject: Re: [R] Plotting boundary lines from shapefiles overtop a map of Canada

On 23/09/2014 3:27 a.m., Alain Dubreuil wrote:
> Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.
>
> To plot the map of Canada, I have used the following line of code:
>
>        map(database= "worldHires","Canada", ylim=c(39,90), 
> xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE, 
> projection="lambert", param=c(50,65))
>
> Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.
>
> To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:
>
>        lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
>        lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
>        coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long
>        points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red", 0.5))  
> #plot converted points
>
> As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.
>
> Using readOGR:
>
>        region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
>        plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), 
> col=alpha("lightgreen", 0.6), border=TRUE)
You don't state which package readOGR() comes from, but it is not part of the maps package, which doesn't understand shapefiles, so just using
plot() on top of a (projected) map() is unlikely to succeed.

I believe what you have to do is go back to your lat/long pairs for your SAR regions and use mapproject() to convert them to the coordinates used by the plotted projection. Note that you don't need the proj="lambert" 
option when you call mapproject() after a call to map() with a projection because the most recent projection (and its parameters) are "remembered".  Also I suspect (though untested) is that if you put NA pairs in between your lists of projected SAR regions, then you can just use lines() to draw them all at once.

Hope this helps,
Ray Brownrigg
> Using read.shp and draw.shp:
>
>        region <- read.shp("C:/myRfolder/mySARshapefile.shp")
>        draw.shape(shape=region, type="poly", col="red")
>
> Using readShapePoly:
>
>        region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
>        plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), 
> col=alpha("lightgreen", 0.6), border=TRUE)
>
> Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:
>
>        region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
>        lines(region, col=alpha("black", 0.6))
>
> I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")
>
> I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.
>
> Thanks
>
> Alain Dubreuil
> Ottawa, Canada
>


From roger.bos at rothschild.com  Tue Sep 23 18:34:16 2014
From: roger.bos at rothschild.com (Bos, Roger)
Date: Tue, 23 Sep 2014 16:34:16 +0000
Subject: [R] Copying tables from R to Excel
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9ADDD@mb02.ads.tamu.edu>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2BC@MATIAEXCH.matiaf.local>
	<542171B3.2000808@u-bourgogne.fr>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9ADDD@mb02.ads.tamu.edu>
Message-ID: <0765308CD028654885F30322557308D81ECDE4D9@NYCSM0208.rth.ad.rothschild.com>

Here is a simple method I saw mentioned on this list a few years ago:

toExcel <- function(x, tag=FALSE) {write.table(x, "clipboard-128", sep="\t", row.names=tag)}




***************************************************************
This message and any attachments are for the named person's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies. You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Tuesday, September 23, 2014 10:15 AM
To: ivan.calandra at univ-reims.fr; r-help at r-project.org
Subject: Re: [R] Copying tables from R to Excel

If you looked at the documentation for R2HTML you might have noticed that there is no function HTML.matrix. Perhaps your recommendation from an unnamed source is out of date? Assuming you loaded the package with library(R2HTML) as Ivan suggested, the command would be

HTML( summary(iris), file("clipboard", "w"), append=F )

Which will work just fine as long as you are using the Windows operating system. More technically, HTML() is a generic function with methods (156 in this case) for many different data types including matrices and tables.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
Sent: Tuesday, September 23, 2014 8:12 AM
To: r-help at r-project.org
Subject: Re: [R] Copying tables from R to Excel

library(R2HTML) ??

Le 23/09/14 15:04, Angel Rodriguez a ?crit :
> Dear Subscribers,
>
> I've found this recommendation to paste an R table to Excel:
>
> HTML.matrix( summary(iris), file("clipboard", "w"), append=F )
>     # paste into Excel
>
> After installing R2HTML and writting that command, I get:
>
> Error: could not find function "HTML.matrix"
>
> Any clue?
>
> Thank you very much,
>
> Angel Rodr?guez-Laso
>
>       [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From wdunlap at tibco.com  Tue Sep 23 18:36:48 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 23 Sep 2014 09:36:48 -0700
Subject: [R] Plotting boundary lines from shapefiles overtop a map of
	Canada
In-Reply-To: <F9A1252A5C3CEF4C8C2F70752F372BF63891C4B663@CAEMEX80.caecorp.cae.com>
References: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>
	<54213220.5030809@ecs.vuw.ac.nz>
	<F9A1252A5C3CEF4C8C2F70752F372BF63891C4B663@CAEMEX80.caecorp.cae.com>
Message-ID: <CAF8bMcaSxrJ58OmODMWa2C-tQYSvtq9YjnCWRTzBS-5gqQD8jg@mail.gmail.com>

> testLines <- mapproject(yValue, xValue, proj="lambert", param=c(50,65))

For starters, if you give the x,y values in reverse order of what the
mapproject function expects you need to label them: y=yValue,
x=xValue.

(Also, I would have expected longitudes in the Americas to be
negative, but mapproject doesn't appear to care.)



Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Sep 23, 2014 at 9:17 AM, Alain Dubreuil <alain.dubreuil at cae.com> wrote:
> Hi all,
>
> Based on Ray's suggestions, I have tried the following script:
>
> library(mapproj)
> library(maps)
> resuPdfFileName="C:/linesTest.pdf"
> pdf(resuPdfFileName)
> # Create a map of Canada in Lambert projection
> map(database= "worldHires","Canada", ylim=c(39,90), xlim=c(-145,-25), col=alpha("grey90",0.5), fill=TRUE, projection="lambert", param=c(50,65))
> # Use test position vectors to draw lines
> yValue <- c(49.0, 49.0, 60.0, 60.0)
> xValue <- c(105.0, 120.0, 120.0, 105.0)
> # Convert the test vectors into lambert and then draw the lines
> testLines <- mapproject(yValue, xValue, proj="lambert", param=c(50,65))
> lines(testLines)
> dev.off()
>
> The script draws the map of Canada, but fails to draw the lines.  Please let me know what I'm doing wrong because I can't see it.  By the way, not specifying the lambert projection in the call to mapproject yields different results than specifying it which seems contrary to the documentation (?).
>
> Thanks
>
> Alain Dubreuil
> Ottawa, Canada
>
>
> -----Original Message-----
> From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz]
> Sent: September-23-14 4:41 AM
> To: Alain Dubreuil; r-help at r-project.org
> Subject: Re: [R] Plotting boundary lines from shapefiles overtop a map of Canada
>
> On 23/09/2014 3:27 a.m., Alain Dubreuil wrote:
>> Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.
>>
>> To plot the map of Canada, I have used the following line of code:
>>
>>        map(database= "worldHires","Canada", ylim=c(39,90),
>> xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE,
>> projection="lambert", param=c(50,65))
>>
>> Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.
>>
>> To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:
>>
>>        lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
>>        lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
>>        coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long
>>        points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red", 0.5))
>> #plot converted points
>>
>> As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.
>>
>> Using readOGR:
>>
>>        region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
>>        plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90),
>> col=alpha("lightgreen", 0.6), border=TRUE)
> You don't state which package readOGR() comes from, but it is not part of the maps package, which doesn't understand shapefiles, so just using
> plot() on top of a (projected) map() is unlikely to succeed.
>
> I believe what you have to do is go back to your lat/long pairs for your SAR regions and use mapproject() to convert them to the coordinates used by the plotted projection. Note that you don't need the proj="lambert"
> option when you call mapproject() after a call to map() with a projection because the most recent projection (and its parameters) are "remembered".  Also I suspect (though untested) is that if you put NA pairs in between your lists of projected SAR regions, then you can just use lines() to draw them all at once.
>
> Hope this helps,
> Ray Brownrigg
>> Using read.shp and draw.shp:
>>
>>        region <- read.shp("C:/myRfolder/mySARshapefile.shp")
>>        draw.shape(shape=region, type="poly", col="red")
>>
>> Using readShapePoly:
>>
>>        region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
>>        plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90),
>> col=alpha("lightgreen", 0.6), border=TRUE)
>>
>> Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:
>>
>>        region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
>>        lines(region, col=alpha("black", 0.6))
>>
>> I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")
>>
>> I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.
>>
>> Thanks
>>
>> Alain Dubreuil
>> Ottawa, Canada
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Tue Sep 23 18:42:11 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 23 Sep 2014 17:42:11 +0100
Subject: [R] division of col by the sum of the col
In-Reply-To: <1411485037.57007.YahooMailNeo@web121505.mail.ne1.yahoo.com>
References: <1411485037.57007.YahooMailNeo@web121505.mail.ne1.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED64125C9CD4@GOLD.corp.lgc-group.com>

> If I want to divide the column of a matrix by the sum of the column, should I
> loop over the columns or can I use apply family?

Looping's unnecessary.
See ?scale  or ?sweep, with  ?colSums for two non-looping answers; apply() also works if you give it a suitable function argument.

S



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From wdunlap at tibco.com  Tue Sep 23 18:45:27 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 23 Sep 2014 09:45:27 -0700
Subject: [R] Plotting boundary lines from shapefiles overtop a map of
	Canada
In-Reply-To: <CAF8bMcaSxrJ58OmODMWa2C-tQYSvtq9YjnCWRTzBS-5gqQD8jg@mail.gmail.com>
References: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>
	<54213220.5030809@ecs.vuw.ac.nz>
	<F9A1252A5C3CEF4C8C2F70752F372BF63891C4B663@CAEMEX80.caecorp.cae.com>
	<CAF8bMcaSxrJ58OmODMWa2C-tQYSvtq9YjnCWRTzBS-5gqQD8jg@mail.gmail.com>
Message-ID: <CAF8bMcatqPnn-yH8vc5D3YW33BTNvV7JReri5ki1tqrkF5AExg@mail.gmail.com>

Try:
  map(database= "worldHires","Canada", ylim=c(39,90),
xlim=c(-145,-25), col="grey95", fill=TRUE, projection="lambert",
param=c(50,65))
  lines(mapproject(y=yValue, x=-xValue))

mapproject does care about the sign of the longitude, but if you
incompletely reset the projection it messes things up.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Sep 23, 2014 at 9:36 AM, William Dunlap <wdunlap at tibco.com> wrote:
>> testLines <- mapproject(yValue, xValue, proj="lambert", param=c(50,65))
>
> For starters, if you give the x,y values in reverse order of what the
> mapproject function expects you need to label them: y=yValue,
> x=xValue.
>
> (Also, I would have expected longitudes in the Americas to be
> negative, but mapproject doesn't appear to care.)
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Sep 23, 2014 at 9:17 AM, Alain Dubreuil <alain.dubreuil at cae.com> wrote:
>> Hi all,
>>
>> Based on Ray's suggestions, I have tried the following script:
>>
>> library(mapproj)
>> library(maps)
>> resuPdfFileName="C:/linesTest.pdf"
>> pdf(resuPdfFileName)
>> # Create a map of Canada in Lambert projection
>> map(database= "worldHires","Canada", ylim=c(39,90), xlim=c(-145,-25), col=alpha("grey90",0.5), fill=TRUE, projection="lambert", param=c(50,65))
>> # Use test position vectors to draw lines
>> yValue <- c(49.0, 49.0, 60.0, 60.0)
>> xValue <- c(105.0, 120.0, 120.0, 105.0)
>> # Convert the test vectors into lambert and then draw the lines
>> testLines <- mapproject(yValue, xValue, proj="lambert", param=c(50,65))
>> lines(testLines)
>> dev.off()
>>
>> The script draws the map of Canada, but fails to draw the lines.  Please let me know what I'm doing wrong because I can't see it.  By the way, not specifying the lambert projection in the call to mapproject yields different results than specifying it which seems contrary to the documentation (?).
>>
>> Thanks
>>
>> Alain Dubreuil
>> Ottawa, Canada
>>
>>
>> -----Original Message-----
>> From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz]
>> Sent: September-23-14 4:41 AM
>> To: Alain Dubreuil; r-help at r-project.org
>> Subject: Re: [R] Plotting boundary lines from shapefiles overtop a map of Canada
>>
>> On 23/09/2014 3:27 a.m., Alain Dubreuil wrote:
>>> Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.
>>>
>>> To plot the map of Canada, I have used the following line of code:
>>>
>>>        map(database= "worldHires","Canada", ylim=c(39,90),
>>> xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE,
>>> projection="lambert", param=c(50,65))
>>>
>>> Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.
>>>
>>> To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:
>>>
>>>        lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
>>>        lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
>>>        coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long
>>>        points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red", 0.5))
>>> #plot converted points
>>>
>>> As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.
>>>
>>> Using readOGR:
>>>
>>>        region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
>>>        plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90),
>>> col=alpha("lightgreen", 0.6), border=TRUE)
>> You don't state which package readOGR() comes from, but it is not part of the maps package, which doesn't understand shapefiles, so just using
>> plot() on top of a (projected) map() is unlikely to succeed.
>>
>> I believe what you have to do is go back to your lat/long pairs for your SAR regions and use mapproject() to convert them to the coordinates used by the plotted projection. Note that you don't need the proj="lambert"
>> option when you call mapproject() after a call to map() with a projection because the most recent projection (and its parameters) are "remembered".  Also I suspect (though untested) is that if you put NA pairs in between your lists of projected SAR regions, then you can just use lines() to draw them all at once.
>>
>> Hope this helps,
>> Ray Brownrigg
>>> Using read.shp and draw.shp:
>>>
>>>        region <- read.shp("C:/myRfolder/mySARshapefile.shp")
>>>        draw.shape(shape=region, type="poly", col="red")
>>>
>>> Using readShapePoly:
>>>
>>>        region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
>>>        plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90),
>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>>
>>> Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:
>>>
>>>        region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
>>>        lines(region, col=alpha("black", 0.6))
>>>
>>> I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")
>>>
>>> I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.
>>>
>>> Thanks
>>>
>>> Alain Dubreuil
>>> Ottawa, Canada
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pollaroid at gmail.com  Tue Sep 23 19:04:57 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Tue, 23 Sep 2014 19:04:57 +0200
Subject: [R] How to combine character month and year columns into one
	column
In-Reply-To: <A34EF362-D69F-4CF3-8007-133F38029D87@me.com>
References: <CAAC1QdD21hor4vgZfRaS1q53Pex1v_j+OnJfUM4FArLJjTpXiQ@mail.gmail.com>
	<A34EF362-D69F-4CF3-8007-133F38029D87@me.com>
Message-ID: <CAAC1QdD31Vdrw9qrB5HLA17hG1bUsdAvnUORjcVf7aXTGeMHFQ@mail.gmail.com>

Many thanks for your quick answer which has created what I wished. May
I ask followup question on the same issue. I failed to convert the new
column into date format with this code. The class of MonthDay is still
character

df$MonthDay <- format(df$MonthDay, format=c("%b %Y"))
I would appreciate if you could suggest a working solution
Thanks


On 23 September 2014 18:03, Marc Schwartz <marc_schwartz at me.com> wrote:
> On Sep 23, 2014, at 10:41 AM, Kuma Raj <pollaroid at gmail.com> wrote:
>
>> Dear R users,
>>
>> I have a data with  month and year columns which are both characters
>> and wanted to create a new column like Jan-1999
>> with the following code. The result is all NA for the month part. What
>> is wrong with the and what is the right way to combine the two?
>>
>> ddf$MonthDay <- paste(month.abb[ddf$month], ddf$Year, sep="-" )
>>
>>
>> Thanks
>>
>>> dput(ddf)
>> structure(list(month = c("01", "02", "03", "04", "05", "06",
>> "07", "08", "09", "10", "11", "12"), Year = c("1999", "1999",
>> "1999", "1999", "1999", "1999", "1999", "1999", "1999", "1999",
>> "1999", "1999"), views = c(42, 49, 44, 38, 37, 35, 38, 39, 38,
>> 39, 38, 46), MonthDay = c("NA-1999", "NA-1999", "NA-1999", "NA-1999",
>> "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999",
>> "NA-1999", "NA-1999")), .Names = c("month", "Year", "views",
>> "MonthDay"), row.names = 109:120, class = "data.frame")
>>>
>>
>
>
>
> Since you are trying to use ddf$month as an index into month.abb, you will either need to coerce ddf$month to numeric in your code, or adjust how the data frame is created.
>
> In the case of the former approach:
>
>> paste(month.abb[as.numeric(ddf$month)], ddf$Year, sep="-" )
>  [1] "Jan-1999" "Feb-1999" "Mar-1999" "Apr-1999" "May-1999" "Jun-1999"
>  [7] "Jul-1999" "Aug-1999" "Sep-1999" "Oct-1999" "Nov-1999" "Dec-1999"
>
>
> Regards,
>
> Marc Schwartz
>


From marc_schwartz at me.com  Tue Sep 23 19:18:48 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 23 Sep 2014 12:18:48 -0500
Subject: [R] How to combine character month and year columns into one
	column
In-Reply-To: <CAAC1QdD31Vdrw9qrB5HLA17hG1bUsdAvnUORjcVf7aXTGeMHFQ@mail.gmail.com>
References: <CAAC1QdD21hor4vgZfRaS1q53Pex1v_j+OnJfUM4FArLJjTpXiQ@mail.gmail.com>
	<A34EF362-D69F-4CF3-8007-133F38029D87@me.com>
	<CAAC1QdD31Vdrw9qrB5HLA17hG1bUsdAvnUORjcVf7aXTGeMHFQ@mail.gmail.com>
Message-ID: <6EF3C02B-367C-497D-BCB7-7DA78BD10CF7@me.com>

Two things:

1. You need to convert the result of the paste() to a Date related class.

2. R's standard Date classes require a full date, so you would have to add in some default day of the month:

See ?as.Date

NewDate <- as.Date(paste(month.abb[as.numeric(ddf$month)], "01", ddf$Year, sep="-"), 
                   format = "%b-%d-%Y")

or without using month.abb, which is not really needed. Note the difference in the format argument:

NewDate <- as.Date(paste(as.numeric(ddf$month), "01", ddf$Year, sep="-"), 
                   format = "%m-%d-%Y")

> class(NewDate)
[1] "Date"

> str(NewDate)
 Date[1:12], format: "1999-01-01" "1999-02-01" "1999-03-01" "1999-04-01" ...


You can then format the output of NewDate as you might require:

> format(NewDate, format = "%b-%d-%Y")
 [1] "Jan-01-1999" "Feb-01-1999" "Mar-01-1999" "Apr-01-1999"
 [5] "May-01-1999" "Jun-01-1999" "Jul-01-1999" "Aug-01-1999"
 [9] "Sep-01-1999" "Oct-01-1999" "Nov-01-1999" "Dec-01-1999"


Note that the output of the last step is a character vector:

> str(format(NewDate, format = "%b-%d-%Y"))
 chr [1:12] "Jan-01-1999" "Feb-01-1999" "Mar-01-1999" ...

which is fine for formatting/printing, even though NewDate is a Date class object.


Alternatively, I believe that Gabor's 'zoo' package on CRAN has a 'yearmon' class for this type of partial date.

Regards,

Marc


On Sep 23, 2014, at 12:04 PM, Kuma Raj <pollaroid at gmail.com> wrote:

> Many thanks for your quick answer which has created what I wished. May
> I ask followup question on the same issue. I failed to convert the new
> column into date format with this code. The class of MonthDay is still
> character
> 
> df$MonthDay <- format(df$MonthDay, format=c("%b %Y"))
> I would appreciate if you could suggest a working solution
> Thanks
> 
> 
> On 23 September 2014 18:03, Marc Schwartz <marc_schwartz at me.com> wrote:
>> On Sep 23, 2014, at 10:41 AM, Kuma Raj <pollaroid at gmail.com> wrote:
>> 
>>> Dear R users,
>>> 
>>> I have a data with  month and year columns which are both characters
>>> and wanted to create a new column like Jan-1999
>>> with the following code. The result is all NA for the month part. What
>>> is wrong with the and what is the right way to combine the two?
>>> 
>>> ddf$MonthDay <- paste(month.abb[ddf$month], ddf$Year, sep="-" )
>>> 
>>> 
>>> Thanks
>>> 
>>>> dput(ddf)
>>> structure(list(month = c("01", "02", "03", "04", "05", "06",
>>> "07", "08", "09", "10", "11", "12"), Year = c("1999", "1999",
>>> "1999", "1999", "1999", "1999", "1999", "1999", "1999", "1999",
>>> "1999", "1999"), views = c(42, 49, 44, 38, 37, 35, 38, 39, 38,
>>> 39, 38, 46), MonthDay = c("NA-1999", "NA-1999", "NA-1999", "NA-1999",
>>> "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999",
>>> "NA-1999", "NA-1999")), .Names = c("month", "Year", "views",
>>> "MonthDay"), row.names = 109:120, class = "data.frame")
>>>> 
>>> 
>> 
>> 
>> 
>> Since you are trying to use ddf$month as an index into month.abb, you will either need to coerce ddf$month to numeric in your code, or adjust how the data frame is created.
>> 
>> In the case of the former approach:
>> 
>>> paste(month.abb[as.numeric(ddf$month)], ddf$Year, sep="-" )
>> [1] "Jan-1999" "Feb-1999" "Mar-1999" "Apr-1999" "May-1999" "Jun-1999"
>> [7] "Jul-1999" "Aug-1999" "Sep-1999" "Oct-1999" "Nov-1999" "Dec-1999"
>> 
>> 
>> Regards,
>> 
>> Marc Schwartz
>> 


From dwinsemius at comcast.net  Tue Sep 23 19:47:56 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Sep 2014 10:47:56 -0700
Subject: [R] How to combine character month and year columns into one
	column
In-Reply-To: <A34EF362-D69F-4CF3-8007-133F38029D87@me.com>
References: <CAAC1QdD21hor4vgZfRaS1q53Pex1v_j+OnJfUM4FArLJjTpXiQ@mail.gmail.com>
	<A34EF362-D69F-4CF3-8007-133F38029D87@me.com>
Message-ID: <8CBA783F-22E5-4945-BF18-994C0821513E@comcast.net>

Marc;

Feature request:

Would it make sense to construct month.abb as a named vector so that the operation that was attempted would have succeeded? Adding alphanumeric names c("01", "02", "03", "04", "05", "06",
"07", "08", "09", "10", "11", "12") would allow character extraction from substring or regex extracted month values which are always character-class.

Example:

> names(month.abb) <- c("01", "02", "03", "04", "05", "06",
+ "07", "08", "09", "10", "11", "12")
> month.abb
   01    02    03    04    05    06    07    08    09    10    11    12 
"Jan" "Feb" "Mar" "Apr" "May" "Jun" "Jul" "Aug" "Sep" "Oct" "Nov" "Dec" 


> month.abb[ substr(Sys.Date(), 6,7) ]
   09 
"Sep" 

-- 
David.

On Sep 23, 2014, at 9:03 AM, Marc Schwartz wrote:

> On Sep 23, 2014, at 10:41 AM, Kuma Raj <pollaroid at gmail.com> wrote:
> 
>> Dear R users,
>> 
>> I have a data with  month and year columns which are both characters
>> and wanted to create a new column like Jan-1999
>> with the following code. The result is all NA for the month part. What
>> is wrong with the and what is the right way to combine the two?
>> 
>> ddf$MonthDay <- paste(month.abb[ddf$month], ddf$Year, sep="-" )
>> 
>> 
>> Thanks
>> 
>>> dput(ddf)
>> structure(list(month = c("01", "02", "03", "04", "05", "06",
>> "07", "08", "09", "10", "11", "12"), Year = c("1999", "1999",
>> "1999", "1999", "1999", "1999", "1999", "1999", "1999", "1999",
>> "1999", "1999"), views = c(42, 49, 44, 38, 37, 35, 38, 39, 38,
>> 39, 38, 46), MonthDay = c("NA-1999", "NA-1999", "NA-1999", "NA-1999",
>> "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999",
>> "NA-1999", "NA-1999")), .Names = c("month", "Year", "views",
>> "MonthDay"), row.names = 109:120, class = "data.frame")
>>> 
>> 
> 
> 
> 
> Since you are trying to use ddf$month as an index into month.abb, you will either need to coerce ddf$month to numeric in your code, or adjust how the data frame is created.
> 
> In the case of the former approach:
> 
>> paste(month.abb[as.numeric(ddf$month)], ddf$Year, sep="-" )
> [1] "Jan-1999" "Feb-1999" "Mar-1999" "Apr-1999" "May-1999" "Jun-1999"
> [7] "Jul-1999" "Aug-1999" "Sep-1999" "Oct-1999" "Nov-1999" "Dec-1999"
> 
> 
> Regards,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marc_schwartz at me.com  Tue Sep 23 20:38:39 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 23 Sep 2014 13:38:39 -0500
Subject: [R] How to combine character month and year columns into one
	column
In-Reply-To: <8CBA783F-22E5-4945-BF18-994C0821513E@comcast.net>
References: <CAAC1QdD21hor4vgZfRaS1q53Pex1v_j+OnJfUM4FArLJjTpXiQ@mail.gmail.com>
	<A34EF362-D69F-4CF3-8007-133F38029D87@me.com>
	<8CBA783F-22E5-4945-BF18-994C0821513E@comcast.net>
Message-ID: <C47A27E0-7A96-4B77-B063-CD8EF79FC760@me.com>

Hi David,

My initial reaction (not that the decision is mine to make), is that from a technical perspective, obviously indexing by name is common.

There are two considerations, off the top of my head:

1. There would be a difference, of course, between:

> month.abb["1"]
<NA> 
  NA 

and

> month.abb["01"]
   01 
"Jan" 


Thus, is this approach overly fragile and potentially going to create more problems (bugs, head scratching, etc.) than it solves.


2. From a consistency standpoint, I don't see an indication that other built-in constants have similar name attributes, not that I did an exhaustive review. So I suspect that if there were reasonable justification for it here, it would also need to at least be considered for other constants, which increases the scope of work a good bit.


If there is a desire for this, one could file an RFE at https://bugs.r-project.org to gauge the reactions from R Core, unless they comment here first.

Regards,

Marc


On Sep 23, 2014, at 12:47 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> Marc;
> 
> Feature request:
> 
> Would it make sense to construct month.abb as a named vector so that the operation that was attempted would have succeeded? Adding alphanumeric names c("01", "02", "03", "04", "05", "06",
> "07", "08", "09", "10", "11", "12") would allow character extraction from substring or regex extracted month values which are always character-class.
> 
> Example:
> 
>> names(month.abb) <- c("01", "02", "03", "04", "05", "06",
> + "07", "08", "09", "10", "11", "12")
>> month.abb
>   01    02    03    04    05    06    07    08    09    10    11    12 
> "Jan" "Feb" "Mar" "Apr" "May" "Jun" "Jul" "Aug" "Sep" "Oct" "Nov" "Dec" 
> 
> 
>> month.abb[ substr(Sys.Date(), 6,7) ]
>   09 
> "Sep" 
> 
> -- 
> David.
> 
> On Sep 23, 2014, at 9:03 AM, Marc Schwartz wrote:
> 
>> On Sep 23, 2014, at 10:41 AM, Kuma Raj <pollaroid at gmail.com> wrote:
>> 
>>> Dear R users,
>>> 
>>> I have a data with  month and year columns which are both characters
>>> and wanted to create a new column like Jan-1999
>>> with the following code. The result is all NA for the month part. What
>>> is wrong with the and what is the right way to combine the two?
>>> 
>>> ddf$MonthDay <- paste(month.abb[ddf$month], ddf$Year, sep="-" )
>>> 
>>> 
>>> Thanks
>>> 
>>>> dput(ddf)
>>> structure(list(month = c("01", "02", "03", "04", "05", "06",
>>> "07", "08", "09", "10", "11", "12"), Year = c("1999", "1999",
>>> "1999", "1999", "1999", "1999", "1999", "1999", "1999", "1999",
>>> "1999", "1999"), views = c(42, 49, 44, 38, 37, 35, 38, 39, 38,
>>> 39, 38, 46), MonthDay = c("NA-1999", "NA-1999", "NA-1999", "NA-1999",
>>> "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999", "NA-1999",
>>> "NA-1999", "NA-1999")), .Names = c("month", "Year", "views",
>>> "MonthDay"), row.names = 109:120, class = "data.frame")
>>>> 
>>> 
>> 
>> 
>> 
>> Since you are trying to use ddf$month as an index into month.abb, you will either need to coerce ddf$month to numeric in your code, or adjust how the data frame is created.
>> 
>> In the case of the former approach:
>> 
>>> paste(month.abb[as.numeric(ddf$month)], ddf$Year, sep="-" )
>> [1] "Jan-1999" "Feb-1999" "Mar-1999" "Apr-1999" "May-1999" "Jun-1999"
>> [7] "Jul-1999" "Aug-1999" "Sep-1999" "Oct-1999" "Nov-1999" "Dec-1999"
>> 
>> 
>> Regards,
>> 
>> Marc Schwartz
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 


From r.turner at auckland.ac.nz  Tue Sep 23 23:30:04 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 Sep 2014 09:30:04 +1200
Subject: [R] division of col by the sum of the col
In-Reply-To: <1411485037.57007.YahooMailNeo@web121505.mail.ne1.yahoo.com>
References: <1411485037.57007.YahooMailNeo@web121505.mail.ne1.yahoo.com>
Message-ID: <5421E65C.3040205@auckland.ac.nz>

On 24/09/14 03:10, carol white wrote:
> Hi, If I want to divide the column of a matrix by the sum of the
> column, should I loop over the columns or can I use apply family?

m1 <- apply(m,2,function(x){x/sum(x)})

should do what you want IIUYC.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From pdalgd at gmail.com  Wed Sep 24 00:10:19 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 24 Sep 2014 00:10:19 +0200
Subject: [R] division of col by the sum of the col
In-Reply-To: <5421E65C.3040205@auckland.ac.nz>
References: <1411485037.57007.YahooMailNeo@web121505.mail.ne1.yahoo.com>
	<5421E65C.3040205@auckland.ac.nz>
Message-ID: <DDE2E241-8140-46A8-9E90-C8B10B9A69A7@gmail.com>


On 23 Sep 2014, at 23:30 , Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 24/09/14 03:10, carol white wrote:
>> Hi, If I want to divide the column of a matrix by the sum of the
>> column, should I loop over the columns or can I use apply family?
> 
> m1 <- apply(m,2,function(x){x/sum(x)})
> 
> should do what you want IIUYC.

It might, but there's a surprise if you do the same thing with rows.

The canonical construction is

sweep(M, 2, apply(M, 2, sum), "/")

although efficiency suggests replacing the apply() with colSums(M) nowadays.

> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Rolf Turner
> Technical Editor ANZJS
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Pradip.Muhuri at samhsa.hhs.gov  Wed Sep 24 02:36:59 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Wed, 24 Sep 2014 00:36:59 +0000
Subject: [R] Error Reading from Connection
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F44916@pl-emsmb11>

Hello,



I am running Rx64 3.03 under Windows 8 environment. I have been getting the following error.

 when running some of my old R applications. Below is a mock-up example.





Could someone please help me resolve the issue?



Thanks,



Pradip Muhuri







setwd ("D:/")
>
>
> #load Rdata file
>
> load("heroin.rdata")
Error: error reading from connection
>
> str(heroin)
Error in str(heroin) : object 'heroin' not found

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Sep 24 03:20:13 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 23 Sep 2014 18:20:13 -0700
Subject: [R] Error Reading from Connection
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F44916@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F44916@pl-emsmb11>
Message-ID: <fce8db80-a341-44c2-9ebb-43a702a08699@email.android.com>

Insufficient information, and irrelevant information (the second error is a direct consequence of the first).

We have no way of knowing based on this input that your file is there. (?list.files). We also don't know if you have read access to that file (?file.access).

Since you posted in HTML and failed to provide the requested minimum information, you should probably (re-)read the Posting Guide mentioned at the bottom of this (and any other) message on this mailing list. You should probably also follow the advice given there to update your R software to the latest version so we don't go chasing any problems in R for your operating system that have already been solved.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 23, 2014 5:36:59 PM PDT, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>Hello,
>
>
>
>I am running Rx64 3.03 under Windows 8 environment. I have been getting
>the following error.
>
>when running some of my old R applications. Below is a mock-up example.
>
>
>
>
>
>Could someone please help me resolve the issue?
>
>
>
>Thanks,
>
>
>
>Pradip Muhuri
>
>
>
>
>
>
>
>setwd ("D:/")
>>
>>
>> #load Rdata file
>>
>> load("heroin.rdata")
>Error: error reading from connection
>>
>> str(heroin)
>Error in str(heroin) : object 'heroin' not found
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Pradip.Muhuri at samhsa.hhs.gov  Wed Sep 24 05:26:41 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Wed, 24 Sep 2014 03:26:41 +0000
Subject: [R] Error Reading from Connection
In-Reply-To: <fce8db80-a341-44c2-9ebb-43a702a08699@email.android.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F44916@pl-emsmb11>,
	<fce8db80-a341-44c2-9ebb-43a702a08699@email.android.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F4493C@pl-emsmb11>

Hello,

Thank you so much for your guidance. This time I am providing more information. R Script and R Console are appended below.

The list.files() below provides evidence the existence of this file in the "temp" directory.  Please note that the "heroin.rdata" file was created from the SAS data set using the Stat Transfer utility software.

The file.access() below did not return mode=4.  Does this mean that I don't have read access to the file?  Is that the reason I could not load the file?

I would appreciate receiving help resolve the issue.

Pradip Muhuri

************R Script ***************
setwd ("D:/temp")
list.files()
file.access("heroin.rdata", mode=4)
load("heroin.rdata")

********* R Console *********

> setwd ("D:/temp")
> list.files()
[1] "heroin.rdata"
> file.access("heroin.rdata", mode=4)
heroin.rdata 
           0 
> load("heroin.rdata")
Error: error reading from connection

________________________________________
From: Jeff Newmiller [jdnewmil at dcn.davis.CA.us]
Sent: Tuesday, September 23, 2014 9:20 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
Subject: Re: [R] Error Reading from Connection

Insufficient information, and irrelevant information (the second error is a direct consequence of the first).

We have no way of knowing based on this input that your file is there. (?list.files). We also don't know if you have read access to that file (?file.access).

Since you posted in HTML and failed to provide the requested minimum information, you should probably (re-)read the Posting Guide mentioned at the bottom of this (and any other) message on this mailing list. You should probably also follow the advice given there to update your R software to the latest version so we don't go chasing any problems in R for your operating system that have already been solved.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On September 23, 2014 5:36:59 PM PDT, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>Hello,
>
>
>
>I am running Rx64 3.03 under Windows 8 environment. I have been getting
>the following error.
>
>when running some of my old R applications. Below is a mock-up example.
>
>
>
>
>
>Could someone please help me resolve the issue?
>
>
>
>Thanks,
>
>
>
>Pradip Muhuri
>
>
>
>
>
>
>
>setwd ("D:/")
>>
>>
>> #load Rdata file
>>
>> load("heroin.rdata")
>Error: error reading from connection
>>
>> str(heroin)
>Error in str(heroin) : object 'heroin' not found
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From QLi2 at its.jnj.com  Tue Sep 23 20:29:32 2014
From: QLi2 at its.jnj.com (Li, Qingqin [JRDUS])
Date: Tue, 23 Sep 2014 18:29:32 +0000
Subject: [R] Is there a log file on Window keeping track of the history of
 package installation (when was a package installed and what package was
 installed)?
Message-ID: <155288F5DC202F40B695EB79FB4056CE69136E62@ITSUSRAGMDGE02.jnj.com>

I'm using a package and need to keep track of the version of the database used. Initially, I was under the impression that the package was querying a remote database live and therefore the data version would be the date of my query. This turned out to be an incorrect assumption, and the database actually came  with the package. Unfortunately, as I encountered discrepancy between different version of the data, I reinstalled the package and overwrite the original installation date. I wonder whether there is a log file keeping track of when and what package was installed in the system (I think Linux has one). Many thanks! -Qingqin

	[[alternative HTML version deleted]]


From b_u_l_m_a at hotmail.com  Tue Sep 23 15:40:22 2014
From: b_u_l_m_a at hotmail.com (maria cabello)
Date: Tue, 23 Sep 2014 13:40:22 +0000
Subject: [R] taking daily modes from hourly data
Message-ID: <DUB130-W68C74B3ED00B2AFD232995B8B00@phx.gbl>

Dear all,
I have a data frame (datos) of hourly wind speed and direction with 4columns (1st date, 2nd hour, 3rd wind speed and 4rth wind direction). I have been able to do the daily mean of the wind speed, but when I try to get the more frequent wind direction of every day, it doesn't work. I have tried to do it with aggregate function, but it only works for mean, max, min...

mean_wind<- aggregate(datos[range_of_dates,col_wind_speed], 
list(date=format(as.Date(datos[range_of_dates,col_dates],"%d/%m/%Y"),"%d/%m/%Y")),
 FUN=mean, na.rm=TRUE)  #it works perfectly

mode_wind<- aggregate(datos[range_of_dates,col_wind_direction], list(date=format(as.Date(datos[range_of_dates,col_dates],"%d/%m/%Y"),"%d/%m/%Y")), FUN=mode)  #it tells me "numeric"

Can anyone help me? My data have not the same length for each day, I mean, for example it is possible that for 1st of January I have 20 hours of data, but for the 2nd of January I have 24, or the 3rd of January I have 18...so I need to aggregate the data to calculate the mean and the mode from the column of my date...
Thanks in advance
Mar?a



 		 	   		  
	[[alternative HTML version deleted]]


From tony.p at healthcare-specialists.com  Tue Sep 23 23:50:01 2014
From: tony.p at healthcare-specialists.com (Tony Parker)
Date: Tue, 23 Sep 2014 16:50:01 -0500
Subject: [R] Optometrists and Ophthalmologists dataset
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAPrqbl8S1w9KhVPYm7ciMv3CgAAAEAAAAKuPgOcZ0rZPuCLfjdAj9UMBAAAAAA==@healthcare-specialists.com>

Hi,

 

Hope you are doing well.

 

My name is Tony I came across your company website and I could see
Optometrists and Ophthalmologists is your one of the targeted specialist, so
I thought of asking if you would be interested in acquiring a complete
data-set of Optometrists and Ophthalmologists?

 

Total contacts available:

 

?  Optometrists: 27,471 contacts

?  Ophthalmologists: 22,585 contacts

 

List contains ? Opt-in business and Contact Name, Email Address, Phone
Number, URL, Specialty, Fax Number, Mailing Address, Title, and Revenue.

 

We are a specialized Healthcare Database provider, we can provide you
contacts of Anesthesiology, Cardiology, Dentist, Dermatology, Emergency
Medicine, Endocrinology, Diabetes & Metabolism, Family Medicine (Family
Practice), Hematology, Internal Medicine, Neurology, Nurse, Obstetrics &
Gynecology, Oncology, Orthopedic, Pathology, Physical Therapy, Physician,
Psychiatry, Psychology, Pulmonology, Radiology, Speech Pathology, Urology,
Veterinarian, etc. and any other specialty that you may target.

 

We can also provide you contacts of Top decision makers from Hospitals like
IT managers, CEO, Medical directors, Medical CTOs and CIOs, Operations
Managers, etc.

 

Let me know if I should be talking to some other person in your organization
regards to this. Alternatively, it would be great if you could forward this
mail to the right person. I appreciate your time and value of your business.

 

Looking forward to hearing from you,

 

Regards,

 

Tony Parker

Marketing consultant


	[[alternative HTML version deleted]]


From richardl at uchicago.edu  Wed Sep 24 04:20:07 2014
From: richardl at uchicago.edu (Richard Lerner)
Date: Tue, 23 Sep 2014 22:20:07 -0400
Subject: [R] Need help with R in Boston area this Friday-Sunday paid gig
Message-ID: <CAEPc0XdjS0eXsLGSZs=Z3CZVHXo=BX7+u_qRgvbat-7+YHxvXA@mail.gmail.com>

I have a project that I have to do this Friday-Sunday. I have 2 dirty excel
spreadsheets that I need brought into R, cleaned up, and then some
descriptive statistics run. I am very new to R and not having fun. I can
pay, but you will need to 1) be expert and 2) be willing to show me how the
work is done and 3) be patient.

respond if interested.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Sep 24 05:49:07 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 23 Sep 2014 20:49:07 -0700
Subject: [R] Error Reading from Connection
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F4493C@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F44916@pl-emsmb11>,
	<fce8db80-a341-44c2-9ebb-43a702a08699@email.android.com>
	<E18C153EBB81024CB60FCE9B4C34D57C37F4493C@pl-emsmb11>
Message-ID: <d49b02d4-893c-4e06-97f0-aded865a2418@email.android.com>

The "Value" section of the help page describes what the function returns... in this case a vector of 1 named integer element that is zero (success), based on the question you asked (is it readable).

Given this input I would suggest that you confirm that the software that produced this file was actually writing in RData format. Just telling it to stick an RData extension on the name you tell it to write to rarely does that. However, I have never used "Stat Transfer utility" software so I have no idea how to help with that. You might also consider using a different format for data transfer, such as CSV. While this can entail some care in specifying formats for data columns in your R script, I have found this to be the most transparent way to get data into R, since other formats don't tell you what went wrong.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 23, 2014 8:26:41 PM PDT, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>Hello,
>
>Thank you so much for your guidance. This time I am providing more
>information. R Script and R Console are appended below.
>
>The list.files() below provides evidence the existence of this file in
>the "temp" directory.  Please note that the "heroin.rdata" file was
>created from the SAS data set using the Stat Transfer utility software.
>
>The file.access() below did not return mode=4.  Does this mean that I
>don't have read access to the file?  Is that the reason I could not
>load the file?
>
>I would appreciate receiving help resolve the issue.
>
>Pradip Muhuri
>
>************R Script ***************
>setwd ("D:/temp")
>list.files()
>file.access("heroin.rdata", mode=4)
>load("heroin.rdata")
>
>********* R Console *********
>
>> setwd ("D:/temp")
>> list.files()
>[1] "heroin.rdata"
>> file.access("heroin.rdata", mode=4)
>heroin.rdata 
>           0 
>> load("heroin.rdata")
>Error: error reading from connection
>
>________________________________________
>From: Jeff Newmiller [jdnewmil at dcn.davis.CA.us]
>Sent: Tuesday, September 23, 2014 9:20 PM
>To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
>Subject: Re: [R] Error Reading from Connection
>
>Insufficient information, and irrelevant information (the second error
>is a direct consequence of the first).
>
>We have no way of knowing based on this input that your file is there.
>(?list.files). We also don't know if you have read access to that file
>(?file.access).
>
>Since you posted in HTML and failed to provide the requested minimum
>information, you should probably (re-)read the Posting Guide mentioned
>at the bottom of this (and any other) message on this mailing list. You
>should probably also follow the advice given there to update your R
>software to the latest version so we don't go chasing any problems in R
>for your operating system that have already been solved.
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>Sent from my phone. Please excuse my brevity.
>
>On September 23, 2014 5:36:59 PM PDT, "Muhuri, Pradip (SAMHSA/CBHSQ)"
><Pradip.Muhuri at samhsa.hhs.gov> wrote:
>>Hello,
>>
>>
>>
>>I am running Rx64 3.03 under Windows 8 environment. I have been
>getting
>>the following error.
>>
>>when running some of my old R applications. Below is a mock-up
>example.
>>
>>
>>
>>
>>
>>Could someone please help me resolve the issue?
>>
>>
>>
>>Thanks,
>>
>>
>>
>>Pradip Muhuri
>>
>>
>>
>>
>>
>>
>>
>>setwd ("D:/")
>>>
>>>
>>> #load Rdata file
>>>
>>> load("heroin.rdata")
>>Error: error reading from connection
>>>
>>> str(heroin)
>>Error in str(heroin) : object 'heroin' not found
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From radhakrishnan.mohan at gmail.com  Wed Sep 24 07:31:39 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 24 Sep 2014 11:01:39 +0530
Subject: [R] Median of streaming data
Message-ID: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>

Hi,

         I have streaming data(1 TB) that can't fit in memory. Is there a
way for me to find the median of these streaming integers assuming I can
fit only a small part in memory ? This is about the statistical approach to
find the median of a large number of values when I can inspect only a part
of them due to memory constraints.

Thanks,
Mohan

	[[alternative HTML version deleted]]


From olivier.crouzet at univ-nantes.fr  Wed Sep 24 08:35:07 2014
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Wed, 24 Sep 2014 06:35:07 +0000
Subject: [R] Need help with R in Boston area this Friday-Sunday paid gig
In-Reply-To: <CAEPc0XdjS0eXsLGSZs=Z3CZVHXo=BX7+u_qRgvbat-7+YHxvXA@mail.gmail.com>
References: <CAEPc0XdjS0eXsLGSZs=Z3CZVHXo=BX7+u_qRgvbat-7+YHxvXA@mail.gmail.com>
Message-ID: <1081147339-1411540509-cardhu_decombobulator_blackberry.rim.net-2054134685-@b4.c6.bise7.blackberry>

This list is not here to do your homework... Even if you plan to pay !

Olivier.

--
Olivier Crouzet
LLING - Laboratoire de Linguistique de Nantes - EA3827
Universit? de Nantes

-----Original Message-----
From: Richard Lerner <richardl at uchicago.edu>
Sender: r-help-bounces at r-project.orgDate: Tue, 23 Sep 2014 22:20:07 
To: <r-help at r-project.org>
Reply-To: richardl at uchicago.edu
Subject: [R] Need help with R in Boston area this Friday-Sunday paid gig

I have a project that I have to do this Friday-Sunday. I have 2 dirty excel
spreadsheets that I need brought into R, cleaned up, and then some
descriptive statistics run. I am very new to R and not having fun. I can
pay, but you will need to 1) be expert and 2) be willing to show me how the
work is done and 3) be patient.

respond if interested.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From r.turner at auckland.ac.nz  Wed Sep 24 08:43:34 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 Sep 2014 18:43:34 +1200
Subject: [R] Median of streaming data
In-Reply-To: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>
Message-ID: <54226816.700@auckland.ac.nz>

On 24/09/14 17:31, Mohan Radhakrishnan wrote:
> Hi,
>
>           I have streaming data(1 TB) that can't fit in memory. Is there a
> way for me to find the median of these streaming integers assuming I can
> fit only a small part in memory ? This is about the statistical approach to
> find the median of a large number of values when I can inspect only a part
> of them due to memory constraints.

You cannot, I'm pretty sure, calculate the median recursively.  However 
there are "approximate" recursive median algorithms which provide an 
estimate of location that has the same asymptotic properties as the median.

See:

* U. Holst, Recursive estimators of location.  Commun. Statist. Theory 
Meth., vol. 16, 1987, pp. 2201--2226.

and

* Murray A. Cameron and T. Rolf Turner, Recursive location and scale 
estimators, Commun. Statist. Theory Meth., vol. 22, 1993,
pp. 2503--2515.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From maechler at stat.math.ethz.ch  Wed Sep 24 10:16:58 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 24 Sep 2014 10:16:58 +0200
Subject: [R] Median of streaming data
In-Reply-To: <54226816.700@auckland.ac.nz>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>
	<54226816.700@auckland.ac.nz>
Message-ID: <21538.32250.67575.749398@stat.math.ethz.ch>

>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>     on Wed, 24 Sep 2014 18:43:34 +1200 writes:

    > On 24/09/14 17:31, Mohan Radhakrishnan wrote:
    >> Hi,
    >> 
    >> I have streaming data(1 TB) that can't fit in memory. Is
    >> there a way for me to find the median of these streaming
    >> integers assuming I can fit only a small part in memory ?
    >> This is about the statistical approach to find the median
    >> of a large number of values when I can inspect only a
    >> part of them due to memory constraints.

    > You cannot, I'm pretty sure, calculate the median
    > recursively.  However there are "approximate" recursive
    > median algorithms which provide an estimate of location
    > that has the same asymptotic properties as the median.

    > See:

    > * U. Holst, Recursive estimators of location.
    > Commun. Statist. Theory Meth., vol. 16, 1987,
    > pp. 2201--2226.

    > and

    > * Murray A. Cameron and T. Rolf Turner, Recursive location
    > and scale estimators, Commun. Statist. Theory Meth.,
    > vol. 22, 1993, pp. 2503--2515.

This is really interesting to me, thank you, Rolf!

OTOH,

1) has your proposal ever been provided in R?
   I'd be happy to add it to the robustX
   (http://cran.ch.r-project.org/web/packages/robustX) or even
   robustbase (http://cran.ch.r-project.org/web/packages/robustbase) package.

2) Would anybody know of more recent research on the subject?
   (I quickly "googled around" and found research more geared
    for the time series situation which is more involved anyway)

   --> Hence CC'ing the experts' list  R-SIG-robust


Martin Maechler,  ETH Zurich


    > cheers,
    > Rolf Turner

    > -- 
    > Rolf Turner Technical Editor ANZJS


From jim at bitwrit.com.au  Wed Sep 24 10:37:14 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 24 Sep 2014 18:37:14 +1000
Subject: [R] taking daily modes from hourly data
In-Reply-To: <DUB130-W68C74B3ED00B2AFD232995B8B00@phx.gbl>
References: <DUB130-W68C74B3ED00B2AFD232995B8B00@phx.gbl>
Message-ID: <3574870.79ME5uYh33@localhost.localdomain>

On Tue, 23 Sep 2014 01:40:22 PM maria cabello wrote:
> Dear all,
> I have a data frame (datos) of hourly wind speed and direction with 
4columns
> (1st date, 2nd hour, 3rd wind speed and 4rth wind direction). I have 
been
> able to do the daily mean of the wind speed, but when I try to get the 
more
> frequent wind direction of every day, it doesn't work. I have tried to do
> it with aggregate function, but it only works for mean, max, min...
> 
> mean_wind<- aggregate(datos[range_of_dates,col_wind_speed],
> 
list(date=format(as.Date(datos[range_of_dates,col_dates],"%d/%m/%Y"),"%d/%m/
> %Y")), FUN=mean, na.rm=TRUE)  #it works perfectly
> 
> mode_wind<- aggregate(datos[range_of_dates,col_wind_direction],
> 
list(date=format(as.Date(datos[range_of_dates,col_dates],"%d/%m/%Y"),"%d/%m
> /%Y")), FUN=mode)  #it tells me "numeric"
> 
> Can anyone help me? My data have not the same length for each day, 
I mean,
> for example it is possible that for 1st of January I have 20 hours of 
data,
> but for the 2nd of January I have 24, or the 3rd of January I have 18...so
> I need to aggregate the data to calculate the mean and the mode 
from the
> column of my date... Thanks in advance

Hi Maria,
Have a look at the Mode function in the prettyR package.

Jim


From radhakrishnan.mohan at gmail.com  Wed Sep 24 11:07:33 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 24 Sep 2014 14:37:33 +0530
Subject: [R] Median of streaming data
In-Reply-To: <21538.32250.67575.749398@stat.math.ethz.ch>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>
	<54226816.700@auckland.ac.nz>
	<21538.32250.67575.749398@stat.math.ethz.ch>
Message-ID: <CAOoXFP_QR1TuM91dvRGsMATPFRGKVa3wc=X2m01+7z5JndQ7aA@mail.gmail.com>

Hi,
      Are these free ? :-)

Thanks,
Mohan

On Wed, Sep 24, 2014 at 1:46 PM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> Rolf Turner <r.turner at auckland.ac.nz>
> >>>>>     on Wed, 24 Sep 2014 18:43:34 +1200 writes:
>
>     > On 24/09/14 17:31, Mohan Radhakrishnan wrote:
>     >> Hi,
>     >>
>     >> I have streaming data(1 TB) that can't fit in memory. Is
>     >> there a way for me to find the median of these streaming
>     >> integers assuming I can fit only a small part in memory ?
>     >> This is about the statistical approach to find the median
>     >> of a large number of values when I can inspect only a
>     >> part of them due to memory constraints.
>
>     > You cannot, I'm pretty sure, calculate the median
>     > recursively.  However there are "approximate" recursive
>     > median algorithms which provide an estimate of location
>     > that has the same asymptotic properties as the median.
>
>     > See:
>
>     > * U. Holst, Recursive estimators of location.
>     > Commun. Statist. Theory Meth., vol. 16, 1987,
>     > pp. 2201--2226.
>
>     > and
>
>     > * Murray A. Cameron and T. Rolf Turner, Recursive location
>     > and scale estimators, Commun. Statist. Theory Meth.,
>     > vol. 22, 1993, pp. 2503--2515.
>
> This is really interesting to me, thank you, Rolf!
>
> OTOH,
>
> 1) has your proposal ever been provided in R?
>    I'd be happy to add it to the robustX
>    (http://cran.ch.r-project.org/web/packages/robustX) or even
>    robustbase (http://cran.ch.r-project.org/web/packages/robustbase)
> package.
>
> 2) Would anybody know of more recent research on the subject?
>    (I quickly "googled around" and found research more geared
>     for the time series situation which is more involved anyway)
>
>    --> Hence CC'ing the experts' list  R-SIG-robust
>
>
> Martin Maechler,  ETH Zurich
>
>
>     > cheers,
>     > Rolf Turner
>
>     > --
>     > Rolf Turner Technical Editor ANZJS
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Sep 24 12:14:47 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 Sep 2014 22:14:47 +1200
Subject: [R] Median of streaming data
In-Reply-To: <21538.32250.67575.749398@stat.math.ethz.ch>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>	<54226816.700@auckland.ac.nz>
	<21538.32250.67575.749398@stat.math.ethz.ch>
Message-ID: <54229997.3080504@auckland.ac.nz>

On 24/09/14 20:16, Martin Maechler wrote:
>>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>>      on Wed, 24 Sep 2014 18:43:34 +1200 writes:
>
>      > On 24/09/14 17:31, Mohan Radhakrishnan wrote:
>      >> Hi,
>      >>
>      >> I have streaming data(1 TB) that can't fit in memory. Is
>      >> there a way for me to find the median of these streaming
>      >> integers assuming I can fit only a small part in memory ?
>      >> This is about the statistical approach to find the median
>      >> of a large number of values when I can inspect only a
>      >> part of them due to memory constraints.
>
>      > You cannot, I'm pretty sure, calculate the median
>      > recursively.  However there are "approximate" recursive
>      > median algorithms which provide an estimate of location
>      > that has the same asymptotic properties as the median.
>
>      > See:
>
>      > * U. Holst, Recursive estimators of location.
>      > Commun. Statist. Theory Meth., vol. 16, 1987,
>      > pp. 2201--2226.
>
>      > and
>
>      > * Murray A. Cameron and T. Rolf Turner, Recursive location
>      > and scale estimators, Commun. Statist. Theory Meth.,
>      > vol. 22, 1993, pp. 2503--2515.
>
> This is really interesting to me, thank you, Rolf!
>
> OTOH,
>
> 1) has your proposal ever been provided in R?
>     I'd be happy to add it to the robustX
>     (http://cran.ch.r-project.org/web/packages/robustX) or even
>     robustbase (http://cran.ch.r-project.org/web/packages/robustbase) package.

I coded the stuff up when Murray and I wrote the paper referred to, but 
I'm not sure if I'll be able to find the code now.  I think I was 
probably using Splus r.t. R at the time.

I'll have a bit of a search in my ancient archives and see what I can find.

> 2) Would anybody know of more recent research on the subject?
>     (I quickly "googled around" and found research more geared
>      for the time series situation which is more involved anyway)
>
>     --> Hence CC'ing the experts' list  R-SIG-robust

I don't know of anything more recent.  Some sort of citation search 
might help to turn up things that are out there.

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS


From martyn.byng at nag.co.uk  Wed Sep 24 12:29:33 2014
From: martyn.byng at nag.co.uk (Martyn Byng)
Date: Wed, 24 Sep 2014 10:29:33 +0000
Subject: [R] Median of streaming data
In-Reply-To: <21538.32250.67575.749398@stat.math.ethz.ch>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>
	<54226816.700@auckland.ac.nz>
	<21538.32250.67575.749398@stat.math.ethz.ch>
Message-ID: <1f0222b00ed54745a80df5e552ecd524@AM3PR05MB545.eurprd05.prod.outlook.com>

Something else that might be of interest ...

Zhang Q and Wang W (2007) A fast algorithm for approximate quantiles in high speed data streams Proceedings of the 19th International Conference on Scientific and Statistical Database Management IEEE Computer Society 29

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Martin Maechler
Sent: 24 September 2014 09:17
To: Rolf Turner
Cc: R-help at r-project.org; R-SIG-robust at r-project.org
Subject: Re: [R] Median of streaming data

>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>     on Wed, 24 Sep 2014 18:43:34 +1200 writes:

    > On 24/09/14 17:31, Mohan Radhakrishnan wrote:
    >> Hi,
    >> 
    >> I have streaming data(1 TB) that can't fit in memory. Is
    >> there a way for me to find the median of these streaming
    >> integers assuming I can fit only a small part in memory ?
    >> This is about the statistical approach to find the median
    >> of a large number of values when I can inspect only a
    >> part of them due to memory constraints.

    > You cannot, I'm pretty sure, calculate the median
    > recursively.  However there are "approximate" recursive
    > median algorithms which provide an estimate of location
    > that has the same asymptotic properties as the median.

    > See:

    > * U. Holst, Recursive estimators of location.
    > Commun. Statist. Theory Meth., vol. 16, 1987,
    > pp. 2201--2226.

    > and

    > * Murray A. Cameron and T. Rolf Turner, Recursive location
    > and scale estimators, Commun. Statist. Theory Meth.,
    > vol. 22, 1993, pp. 2503--2515.

This is really interesting to me, thank you, Rolf!

OTOH,

1) has your proposal ever been provided in R?
   I'd be happy to add it to the robustX
   (http://cran.ch.r-project.org/web/packages/robustX) or even
   robustbase (http://cran.ch.r-project.org/web/packages/robustbase) package.

2) Would anybody know of more recent research on the subject?
   (I quickly "googled around" and found research more geared
    for the time series situation which is more involved anyway)

   --> Hence CC'ing the experts' list  R-SIG-robust


Martin Maechler,  ETH Zurich


    > cheers,
    > Rolf Turner

    > -- 
    > Rolf Turner Technical Editor ANZJS

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:3}}


From angel.rodriguez at matiainstituto.net  Wed Sep 24 12:32:14 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Wed, 24 Sep 2014 12:32:14 +0200
Subject: [R] Copying tables from R to Excel
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B2BE@MATIAEXCH.matiaf.local>

Dear Ivan, Duncan, David and Roger,

Thank you for your answers. 

Yes, I had typed library(R2HTML)

I've typed also:

> library("mediation")
> library("sandwich")
> set.seed(2014)
> med.fit <- glm(estuprimas ~ edad_c + sexo + regalf + deprinf, family="binomial" ,data=child65)
> out.fit <- glm(benvii ~ edad_c + sexo + regalf + deprinf + estuprimas, family="binomial" ,data=child65)
> med.out <- mediate(med.fit, out.fit, treat = "deprinf", mediator = "estuprimas", robustSE = TRUE, sims=1000, control.value = "no", treat.value = "s\xed")
> summary(med.out)


If I type now:

> HTML( summary(med.out), file("clipboard", "w"), append=F )

I can paste to Excel but results are not organized in columns.

If I try:

> toExcel <- function(x, tag=FALSE) {write.table(x, "clipboard-128", sep="\t", row.names=tag)}
> 
> toExcel(summary(med.out))
 Show Traceback
 
 Rerun with Debug
 Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : 
  cannot coerce class "c("summary.mediate", "mediate")" to a data.frame 


Angel Rodr?guez-Laso

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Sep 24 13:24:00 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 Sep 2014 07:24:00 -0400
Subject: [R] Copying tables from R to Excel
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B2BE@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B2BE@MATIAEXCH.matiaf.local>
Message-ID: <5422A9D0.7040706@gmail.com>

On 24/09/2014, 6:32 AM, Angel Rodriguez wrote:
> Dear Ivan, Duncan, David and Roger,
> 
> Thank you for your answers. 
> 
> Yes, I had typed library(R2HTML)
> 
> I've typed also:
> 
>> library("mediation")
>> library("sandwich")
>> set.seed(2014)
>> med.fit <- glm(estuprimas ~ edad_c + sexo + regalf + deprinf, family="binomial" ,data=child65)
>> out.fit <- glm(benvii ~ edad_c + sexo + regalf + deprinf + estuprimas, family="binomial" ,data=child65)
>> med.out <- mediate(med.fit, out.fit, treat = "deprinf", mediator = "estuprimas", robustSE = TRUE, sims=1000, control.value = "no", treat.value = "s\xed")
>> summary(med.out)

I don't know those packages, but I would assume that med.out is not a
dataframe or matrix.  What you'll need to do to get this to work is to
find out what class it is, and write an HTML.<whatever> method to handle
that class.  It probably won't involve actually writing an HTML, it'll
just be something like

HTML.<whatever> <- function(x, ...) {
  df <- < some code to create a dataframe containing the values you want
to transfer >
  HTML(df)
}

Duncan Murdoch

> 
> 
> If I type now:
> 
>> HTML( summary(med.out), file("clipboard", "w"), append=F )
> 
> I can paste to Excel but results are not organized in columns.
> 
> If I try:
> 
>> toExcel <- function(x, tag=FALSE) {write.table(x, "clipboard-128", sep="\t", row.names=tag)}
>>
>> toExcel(summary(med.out))
>  Show Traceback
>  
>  Rerun with Debug
>  Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors = stringsAsFactors) : 
>   cannot coerce class "c("summary.mediate", "mediate")" to a data.frame 
> 
> 
> Angel Rodr?guez-Laso
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Ray.Brownrigg at ecs.vuw.ac.nz  Wed Sep 24 13:36:32 2014
From: Ray.Brownrigg at ecs.vuw.ac.nz (Ray Brownrigg)
Date: Wed, 24 Sep 2014 23:36:32 +1200
Subject: [R] Plotting boundary lines from shapefiles overtop a map of
 Canada
In-Reply-To: <CAF8bMcatqPnn-yH8vc5D3YW33BTNvV7JReri5ki1tqrkF5AExg@mail.gmail.com>
References: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>
	<54213220.5030809@ecs.vuw.ac.nz>
	<F9A1252A5C3CEF4C8C2F70752F372BF63891C4B663@CAEMEX80.caecorp.cae.com>
	<CAF8bMcaSxrJ58OmODMWa2C-tQYSvtq9YjnCWRTzBS-5gqQD8jg@mail.gmail.com>
	<CAF8bMcatqPnn-yH8vc5D3YW33BTNvV7JReri5ki1tqrkF5AExg@mail.gmail.com>
Message-ID: <5422ACC0.1070501@ecs.vuw.ac.nz>

Thanks Bill for picking this up "while I was sleeping".

An enhancement that I have tested for in the case where the SAR regions 
are not defined as closed polygons is e.g.:
xValue <- c(105.0, 120.0, 120.0, 105.0, NA, 110, 119, 106)
yValue <- c(49.0, 49.0, 60.0, 60.0, NA, 50, 55, 59)
polygon(mapproject(y = yValue, x = -xValue))

Cheers,
Ray

On 24/09/2014 4:45 a.m., William Dunlap wrote:
> Try:
>    map(database= "worldHires","Canada", ylim=c(39,90),
> xlim=c(-145,-25), col="grey95", fill=TRUE, projection="lambert",
> param=c(50,65))
>    lines(mapproject(y=yValue, x=-xValue))
>
> mapproject does care about the sign of the longitude, but if you
> incompletely reset the projection it messes things up.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Sep 23, 2014 at 9:36 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>> testLines <- mapproject(yValue, xValue, proj="lambert", param=c(50,65))
>> For starters, if you give the x,y values in reverse order of what the
>> mapproject function expects you need to label them: y=yValue,
>> x=xValue.
>>
>> (Also, I would have expected longitudes in the Americas to be
>> negative, but mapproject doesn't appear to care.)
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Tue, Sep 23, 2014 at 9:17 AM, Alain Dubreuil <alain.dubreuil at cae.com> wrote:
>>> Hi all,
>>>
>>> Based on Ray's suggestions, I have tried the following script:
>>>
>>> library(mapproj)
>>> library(maps)
>>> resuPdfFileName="C:/linesTest.pdf"
>>> pdf(resuPdfFileName)
>>> # Create a map of Canada in Lambert projection
>>> map(database= "worldHires","Canada", ylim=c(39,90), xlim=c(-145,-25), col=alpha("grey90",0.5), fill=TRUE, projection="lambert", param=c(50,65))
>>> # Use test position vectors to draw lines
>>> yValue <- c(49.0, 49.0, 60.0, 60.0)
>>> xValue <- c(105.0, 120.0, 120.0, 105.0)
>>> # Convert the test vectors into lambert and then draw the lines
>>> testLines <- mapproject(yValue, xValue, proj="lambert", param=c(50,65))
>>> lines(testLines)
>>> dev.off()
>>>
>>> The script draws the map of Canada, but fails to draw the lines.  Please let me know what I'm doing wrong because I can't see it.  By the way, not specifying the lambert projection in the call to mapproject yields different results than specifying it which seems contrary to the documentation (?).
>>>
>>> Thanks
>>>
>>> Alain Dubreuil
>>> Ottawa, Canada
>>>
>>>
>>> -----Original Message-----
>>> From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz]
>>> Sent: September-23-14 4:41 AM
>>> To: Alain Dubreuil; r-help at r-project.org
>>> Subject: Re: [R] Plotting boundary lines from shapefiles overtop a map of Canada
>>>
>>> On 23/09/2014 3:27 a.m., Alain Dubreuil wrote:
>>>> Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.
>>>>
>>>> To plot the map of Canada, I have used the following line of code:
>>>>
>>>>         map(database= "worldHires","Canada", ylim=c(39,90),
>>>> xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE,
>>>> projection="lambert", param=c(50,65))
>>>>
>>>> Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.
>>>>
>>>> To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:
>>>>
>>>>         lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
>>>>         lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
>>>>         coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long
>>>>         points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red", 0.5))
>>>> #plot converted points
>>>>
>>>> As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.
>>>>
>>>> Using readOGR:
>>>>
>>>>         region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
>>>>         plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90),
>>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>> You don't state which package readOGR() comes from, but it is not part of the maps package, which doesn't understand shapefiles, so just using
>>> plot() on top of a (projected) map() is unlikely to succeed.
>>>
>>> I believe what you have to do is go back to your lat/long pairs for your SAR regions and use mapproject() to convert them to the coordinates used by the plotted projection. Note that you don't need the proj="lambert"
>>> option when you call mapproject() after a call to map() with a projection because the most recent projection (and its parameters) are "remembered".  Also I suspect (though untested) is that if you put NA pairs in between your lists of projected SAR regions, then you can just use lines() to draw them all at once.
>>>
>>> Hope this helps,
>>> Ray Brownrigg
>>>> Using read.shp and draw.shp:
>>>>
>>>>         region <- read.shp("C:/myRfolder/mySARshapefile.shp")
>>>>         draw.shape(shape=region, type="poly", col="red")
>>>>
>>>> Using readShapePoly:
>>>>
>>>>         region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
>>>>         plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90),
>>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>>>
>>>> Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:
>>>>
>>>>         region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
>>>>         lines(region, col=alpha("black", 0.6))
>>>>
>>>> I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")
>>>>
>>>> I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.
>>>>
>>>> Thanks
>>>>
>>>> Alain Dubreuil
>>>> Ottawa, Canada
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From loris.bennett at fu-berlin.de  Wed Sep 24 10:39:00 2014
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Wed, 24 Sep 2014 10:39:00 +0200
Subject: [R] Using factor levels as coordinates with geom_rect
References: <87sijierzz.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <874mvxmmzf.fsf@hornfels.zedat.fu-berlin.de>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> Hi,
>
> With ggplot2 I can use the following to create a rectangle 
>
> geom_rect(aes(ymin=as.Date("8-Apr-2014", format="%d-%b-%Y"),
>                 ymax=as.Date("30-Apr-2014", format="%d-%b-%Y"),
>                 xmin="node002",xmax="node098"),
>
> where the x values are levels of a factor.  This works if I want the
> rectangle to extend across a range of factor level.  My question is this:
>
> How can I create a similar rectangle around a single factor level?
>
> My assumption is that I should be able to convert the factor to a
> numerical value.  I could then subtract and add a smaller number to
> obtain xmin and xmax, respectively.  However, I don't know how to
> convert the factor level to a value which corresponds to its
> x-coordinate on the plot.
>
> I posted a longer version of this question on StackOverflow with the
> full code, input data, and a plot of the output:
>
> http://stackoverflow.com/questions/25872633/using-factor-levels-with-geom-rect
>
> Unfortunately, I didn't get an answer.
>
> Cheers,
>
> Loris

I was sent a comment via email which helped me along.  The gist was that
factor levels are internally converted to integers for plotting
purposes.  Thus, I just needed to extract the correct integers for the
level I was interested in.

I did this by creating a sorted list of the factor levels:

  nodelist <- sort(levels(flatdata$value))

and then extracted the index corresponding to the level by using
'which'.  I could then construct the rectangle with the following:

  geom_rect(aes(ymin=as.Date("8-Apr-2014", format="%d-%b-%Y"),
                ymax=as.Date("30-Apr-2014", format="%d-%b-%Y"),
                xmin=which(nodelist=="node004")-0.5,
                xmax=which(nodelist=="node004")+0.5,
                fill="red", alpha=0.25))

Cheers,

Loris

-- 
This signature is currently under construction.


From stephane.adamowicz at avignon.inra.fr  Wed Sep 24 14:00:52 2014
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Wed, 24 Sep 2014 14:00:52 +0200
Subject: [R] =?iso-8859-1?q?R=E9p_=3A__ANOVA_and_permutation_tests_=3A_bew?=
 =?iso-8859-1?q?are_of_traps?=
Message-ID: <04A83D4A-281D-44E2-9401-6309D6E4B7A9@avignon.inra.fr>

Many thanks to J. Wiley and B. Ripley for their quick answers.
I suppose that many end users are aware of problems in calculation accuracy with computers. However, I would like to comment that it was not that obvious for me that the data order matters. First, I do not find any clear mention of this particular problem in the == help page, but perhaps I am experiencing difficulties with the English. Second, I do not encounter this problem neither with the piece of code I proposed to replace the dubious one, or in the following experiments :

> # experiment 1 : comparing total variances
> var(dat1$Y) == var(dat2$Y)
[1] TRUE
> # experiment 2 : comparing bilateral T tests
> abs(t.test(Y~F, dat1)$statistic) == abs(t.test(Y~F, dat2)$statistic)
   t 
TRUE 
> # experiment 3 : applying permutations to T tests
> nperm <- 10000
> T <- abs(t.test(Y~F, dat1)$statistic)
> Tperm <- replicate(n=nperm, abs(t.test(sample(Y)~F, dat1)$statistic))
[1] 0.1018898	# that's nice !

Thus, why a naive end user as I am should expect such pitfalls with F values given by the lm function ? Furthermore, codes similar to the one I criticized can be found in the teaching documents of various Universities and thus are spreading out. I would not be surprised that some scientific papers already rely on it ...

In fact, even in R web pages, under Books ("This page gives a partially annotated list of books that are related to S or R and may be useful to the R user community"), I found only one book clearly devoted to randomization methods : "[32] Laura Chihara and Tim Hesterberg. Mathematical Statistics with Resampling and R. Wiley, 1st edition, 2011. ISBN 978-1-1180-2985-5". Looking at the author's profiles, I would say that "Beware of the trap of listening to people with no knowledge of basic numerical methods!" does not apply to them. Here is their recommended R code for one-way anova (chapter 12, but adapted to my example data):

> observed <- anova(lm(Y ~ F, dat1))$F[1]
> n <- length(dat1$Y)
> B <- 10^5 - 1
> results <- numeric(B)
> for (i in 1:B)
+ {
+ 	index <- sample(n)
+ 	Y.perm <- dat1$Y[index]
+ 	results[i] <- anova(lm(Y.perm ~ dat1$F))$F[1]
+ }
> (sum(results> observed) + 1) / (B + 1)	# P value
[1] 0.03969

Well, it seems that I am not the only guy who does not find the trap obvious ...

Thus, my final question remains : How can we evaluate the reliability of CRAN packages that propose randomization (or bootstrap) methods ?

Cheers, St?phane

_______________________________________________________
St?phane Adamowicz
stephane.adamowicz at avignon.inra.fr
_______________________________________________________




UR 1115 Plantes et Syst?mes de Culture Horticoles (PSH)
228, route de l'a?rodrome
CS 40509
domaine St Paul, site agroparc
84914 Avignon, cedex 9
France
Tel  +33 (0)4 32 72 24 35
Fax +33 (0)4 32 72 24 32

http://www.inra.fr/
https://www6.paca.inra.fr/psh
_______________________________________________________


From ziad.elmously at tnsglobal.com  Wed Sep 24 13:30:37 2014
From: ziad.elmously at tnsglobal.com (ziad.elmously at tnsglobal.com)
Date: Wed, 24 Sep 2014 06:30:37 -0500
Subject: [R] Text Mining in Non English Speaking Countries
Message-ID: <465A7684C5F43E4E9F45258F01964E6F0131A06454@ktnapxch101.kt.group.local>

Hello All,

I am interested in conducting text mining in languages other English.  My understanding is the following R packages can analyze alternative (to English) languages:


1.       "topicmodels"

2.       "snowball"

3.       "tm"

Can anyone confirm?  Specifically, I am interested in Hindi and Chinese (2 or so most popular dialects).  If so, can you recommend relevant documentation and share your experiences with these packages.

Thank you in advance.

Ziad Elmously





http://www.kantar.com/disclaimer.html



	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Sep 24 14:24:37 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 Sep 2014 08:24:37 -0400
Subject: [R]
 =?iso-8859-1?q?R=E9p_=3A__ANOVA_and_permutation_tests_=3A_bew?=
 =?iso-8859-1?q?are_of_traps?=
In-Reply-To: <04A83D4A-281D-44E2-9401-6309D6E4B7A9@avignon.inra.fr>
References: <04A83D4A-281D-44E2-9401-6309D6E4B7A9@avignon.inra.fr>
Message-ID: <5422B805.2080405@gmail.com>

On 24/09/2014 8:00 AM, St?phane Adamowicz wrote:
> Many thanks to J. Wiley and B. Ripley for their quick answers.
> I suppose that many end users are aware of problems in calculation accuracy with computers. However, I would like to comment that it was not that obvious for me that the data order matters. First, I do not find any clear mention of this particular problem in the == help page, but perhaps I am experiencing difficulties with the English. Second, I do not encounter this problem neither with the piece of code I proposed to replace the dubious one, or in the following experiments :

I suspect that there would be situations where your code failed as 
well.  Now that I know about this potential error, I would not trust 
code that doesn't defend against it, even if I could not find an example 
where it failed:  it depends on tests of exact equality in floating 
point values, and that is known to be a source of errors in numerical 
methods.
>
> > # experiment 1 : comparing total variances
> > var(dat1$Y) == var(dat2$Y)
> [1] TRUE
> > # experiment 2 : comparing bilateral T tests
> > abs(t.test(Y~F, dat1)$statistic) == abs(t.test(Y~F, dat2)$statistic)
>     t
> TRUE
> > # experiment 3 : applying permutations to T tests
> > nperm <- 10000
> > T <- abs(t.test(Y~F, dat1)$statistic)
> > Tperm <- replicate(n=nperm, abs(t.test(sample(Y)~F, dat1)$statistic))
> [1] 0.1018898	# that's nice !
>
> Thus, why a naive end user as I am should expect such pitfalls with F values given by the lm function ? Furthermore, codes similar to the one I criticized can be found in the teaching documents of various Universities and thus are spreading out. I would not be surprised that some scientific papers already rely on it ...
>
> In fact, even in R web pages, under Books ("This page gives a partially annotated list of books that are related to S or R and may be useful to the R user community"), I found only one book clearly devoted to randomization methods : "[32] Laura Chihara and Tim Hesterberg. Mathematical Statistics with Resampling and R. Wiley, 1st edition, 2011. ISBN 978-1-1180-2985-5". Looking at the author's profiles, I would say that "Beware of the trap of listening to people with no knowledge of basic numerical methods!" does not apply to them. Here is their recommended R code for one-way anova (chapter 12, but adapted to my example data):

You should tell the authors that their code doesn't work.  Many books 
contain errors, but they only get corrected when authors are informed 
about them.
>
> > observed <- anova(lm(Y ~ F, dat1))$F[1]
> > n <- length(dat1$Y)
> > B <- 10^5 - 1
> > results <- numeric(B)
> > for (i in 1:B)
> + {
> + 	index <- sample(n)
> + 	Y.perm <- dat1$Y[index]
> + 	results[i] <- anova(lm(Y.perm ~ dat1$F))$F[1]
> + }
> > (sum(results> observed) + 1) / (B + 1)	# P value
> [1] 0.03969
>
> Well, it seems that I am not the only guy who does not find the trap obvious ...
>
> Thus, my final question remains : How can we evaluate the reliability of CRAN packages that propose randomization (or bootstrap) methods ?
The same way as you evaluate the reliability of any software:  you 
examine the code for common errors, you apply tests to problems that you 
know to be difficult, etc.  At least all CRAN packages provide you with 
source code.

Duncan Murdoch


From alain.dubreuil at cae.com  Wed Sep 24 14:27:14 2014
From: alain.dubreuil at cae.com (Alain Dubreuil)
Date: Wed, 24 Sep 2014 08:27:14 -0400
Subject: [R] Plotting boundary lines from shapefiles overtop a map of
 Canada
In-Reply-To: <5422ACC0.1070501@ecs.vuw.ac.nz>
References: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>
	<54213220.5030809@ecs.vuw.ac.nz>
	<F9A1252A5C3CEF4C8C2F70752F372BF63891C4B663@CAEMEX80.caecorp.cae.com>
	<CAF8bMcaSxrJ58OmODMWa2C-tQYSvtq9YjnCWRTzBS-5gqQD8jg@mail.gmail.com>
	<CAF8bMcatqPnn-yH8vc5D3YW33BTNvV7JReri5ki1tqrkF5AExg@mail.gmail.com>
	<5422ACC0.1070501@ecs.vuw.ac.nz>
Message-ID: <F9A1252A5C3CEF4C8C2F70752F372BF63891CC58E3@CAEMEX80.caecorp.cae.com>

Bill and Ray,

Thank you to both of you for your input.  I am now able to display the lines.  Both the "polygon" and the "lines" commands that you suggested work.  I do have an extra question for you (or anyone else that can help): when I plot the map of Canada, I specify that I want to show from 25  to 145 degrees W.  However, what shows up is more constrained (probably something like 40 to 125 degrees W).  Is there a way to show just the map of Canada (without the USA) while still showing the desired width?  I assumed that it was constraining the width because of the "Canada" specification in the map command, so I removed it but it ended up showing the entire USA territory (minus Hawaii) in addition to Canada.

Thanks

Alain

-----Original Message-----
From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz] 
Sent: September-24-14 7:37 AM
To: William Dunlap; Alain Dubreuil
Cc: r-help at r-project.org
Subject: Re: [R] Plotting boundary lines from shapefiles overtop a map of Canada

Thanks Bill for picking this up "while I was sleeping".

An enhancement that I have tested for in the case where the SAR regions are not defined as closed polygons is e.g.:
xValue <- c(105.0, 120.0, 120.0, 105.0, NA, 110, 119, 106) yValue <- c(49.0, 49.0, 60.0, 60.0, NA, 50, 55, 59) polygon(mapproject(y = yValue, x = -xValue))

Cheers,
Ray

On 24/09/2014 4:45 a.m., William Dunlap wrote:
> Try:
>    map(database= "worldHires","Canada", ylim=c(39,90), 
> xlim=c(-145,-25), col="grey95", fill=TRUE, projection="lambert",
> param=c(50,65))
>    lines(mapproject(y=yValue, x=-xValue))
>
> mapproject does care about the sign of the longitude, but if you 
> incompletely reset the projection it messes things up.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Sep 23, 2014 at 9:36 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>> testLines <- mapproject(yValue, xValue, proj="lambert", 
>>> param=c(50,65))
>> For starters, if you give the x,y values in reverse order of what the 
>> mapproject function expects you need to label them: y=yValue, 
>> x=xValue.
>>
>> (Also, I would have expected longitudes in the Americas to be 
>> negative, but mapproject doesn't appear to care.)
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Tue, Sep 23, 2014 at 9:17 AM, Alain Dubreuil <alain.dubreuil at cae.com> wrote:
>>> Hi all,
>>>
>>> Based on Ray's suggestions, I have tried the following script:
>>>
>>> library(mapproj)
>>> library(maps)
>>> resuPdfFileName="C:/linesTest.pdf"
>>> pdf(resuPdfFileName)
>>> # Create a map of Canada in Lambert projection map(database= 
>>> "worldHires","Canada", ylim=c(39,90), xlim=c(-145,-25), 
>>> col=alpha("grey90",0.5), fill=TRUE, projection="lambert", 
>>> param=c(50,65)) # Use test position vectors to draw lines yValue <- 
>>> c(49.0, 49.0, 60.0, 60.0) xValue <- c(105.0, 120.0, 120.0, 105.0) # 
>>> Convert the test vectors into lambert and then draw the lines 
>>> testLines <- mapproject(yValue, xValue, proj="lambert", 
>>> param=c(50,65))
>>> lines(testLines)
>>> dev.off()
>>>
>>> The script draws the map of Canada, but fails to draw the lines.  Please let me know what I'm doing wrong because I can't see it.  By the way, not specifying the lambert projection in the call to mapproject yields different results than specifying it which seems contrary to the documentation (?).
>>>
>>> Thanks
>>>
>>> Alain Dubreuil
>>> Ottawa, Canada
>>>
>>>
>>> -----Original Message-----
>>> From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz]
>>> Sent: September-23-14 4:41 AM
>>> To: Alain Dubreuil; r-help at r-project.org
>>> Subject: Re: [R] Plotting boundary lines from shapefiles overtop a 
>>> map of Canada
>>>
>>> On 23/09/2014 3:27 a.m., Alain Dubreuil wrote:
>>>> Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.
>>>>
>>>> To plot the map of Canada, I have used the following line of code:
>>>>
>>>>         map(database= "worldHires","Canada", ylim=c(39,90), 
>>>> xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE, 
>>>> projection="lambert", param=c(50,65))
>>>>
>>>> Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.
>>>>
>>>> To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:
>>>>
>>>>         lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
>>>>         lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
>>>>         coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long
>>>>         points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red", 
>>>> 0.5)) #plot converted points
>>>>
>>>> As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.
>>>>
>>>> Using readOGR:
>>>>
>>>>         region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
>>>>         plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), 
>>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>> You don't state which package readOGR() comes from, but it is not 
>>> part of the maps package, which doesn't understand shapefiles, so 
>>> just using
>>> plot() on top of a (projected) map() is unlikely to succeed.
>>>
>>> I believe what you have to do is go back to your lat/long pairs for your SAR regions and use mapproject() to convert them to the coordinates used by the plotted projection. Note that you don't need the proj="lambert"
>>> option when you call mapproject() after a call to map() with a projection because the most recent projection (and its parameters) are "remembered".  Also I suspect (though untested) is that if you put NA pairs in between your lists of projected SAR regions, then you can just use lines() to draw them all at once.
>>>
>>> Hope this helps,
>>> Ray Brownrigg
>>>> Using read.shp and draw.shp:
>>>>
>>>>         region <- read.shp("C:/myRfolder/mySARshapefile.shp")
>>>>         draw.shape(shape=region, type="poly", col="red")
>>>>
>>>> Using readShapePoly:
>>>>
>>>>         region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
>>>>         plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), 
>>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>>>
>>>> Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:
>>>>
>>>>         region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
>>>>         lines(region, col=alpha("black", 0.6))
>>>>
>>>> I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")
>>>>
>>>> I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.
>>>>
>>>> Thanks
>>>>
>>>> Alain Dubreuil
>>>> Ottawa, Canada
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Wed Sep 24 14:57:26 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 24 Sep 2014 07:57:26 -0500
Subject: [R] Optometrists and Ophthalmologists dataset
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAPrqbl8S1w9KhVPYm7ciMv3CgAAAEAAAAKuPgOcZ0rZPuCLfjdAj9UMBAAAAAA==@healthcare-specialists.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAPrqbl8S1w9KhVPYm7ciMv3CgAAAEAAAAKuPgOcZ0rZPuCLfjdAj9UMBAAAAAA==@healthcare-specialists.com>
Message-ID: <CAAJSdjjm9jEZOhWE_Qd5f6ZU7Lm+Otd2UiPKGPJ0=LYvkijsNg@mail.gmail.com>

CAUTION: SARCASM FOLLOWS!

I'd like to thank Mr Tony Parker of <elided> for informing the entire
R-HELP community that his company is a strong believer in UCE and
hires marketing people who are completely clueless. The list of
companies which I know to avoid has increased by one. Good on ya,
mate!

===

Oh, did I mention that the email address from the original post is now
in my autodelete list?

On Tue, Sep 23, 2014 at 4:50 PM, Tony Parker <elided> wrote:
<elided>

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From syen04 at gmail.com  Wed Sep 24 16:19:25 2014
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 24 Sep 2014 10:19:25 -0400
Subject: [R] Overwriting a procedure
In-Reply-To: <CAFEqCdw2UpyecMkiCQvvT+aGB299UKeF3n_45d0jpXWmhAF4ZQ@mail.g
	mail.com>
References: <54061061.060bec0a.7505.ffffb8b1@mx.google.com>
	<CAFEqCdw2UpyecMkiCQvvT+aGB299UKeF3n_45d0jpXWmhAF4ZQ@mail.gmail.com>
Message-ID: <5422d2ef.282cec0a.6315.ffff9286@mx.google.com>

Thank you all. Various ideas led to a simple solution.
I include an argument in the calling function, i.e., v.transform, 
default being FALSE. Function fixzx is removed entirely from the 
package, which is OK by default. The function is called only when 
v.transform=TRUE:

if (v.transform){
   v<-fixzx(z1,x1); z1<-v$z; x1<-v$x
}

Then, when I do need to transform variable(s), I include function 
fixx(x) in the main program (which I had meant to do anyway as 
transformations are problem specific):

fixzx <- function(z,x){
z[,4]=z[,3]^2/10; x[,4]=z[,4];
x[,18]<-x[,17]^2/10
result <- list(z=z,x=x)
return(result)
}

This works out nicely. The fact that a function fixx is not needed 
when v.transform=FALSE is very convenient. Other programming 
languages, e.g., Gauss, do not allow the function to be missing when 
v.transform=FALSE. Thank you all.

At 04:41 PM 9/2/2014, Greg Snow wrote:
>A perhaps better approach would be to have the functions that
>currently call fixx accept an argument of a function to use.  It could
>default to fixx, but if the caller passed in a new function it would
>use that function instead.
>
>If you really want to overwrite a function inside of a package
>namespace then look at the assignInNamespace function in the utils
>package (but note the warning in the description on the help page).
>
>On Tue, Sep 2, 2014 at 12:45 PM, Steven Yen <syen04 at gmail.com> wrote:
> > Is there a way to over-write a procedure (subroutine)?
> >
> > I include a default procedure fixx in a list of procedures which are
> > compiled into a package. By default, the procedure deliver the data matrix
> > x.
> >
> > fixx <- function(x){
> > result <- list(x=x)
> > return(result)
> > }
> >
> > In some applications, I have transformations (such as squared 
> terms) in some
> > column(s) in x. So I include the following procedure in the mail (calling)
> > program, hoping to over-write the default procedure under the same name in
> > the package (which is the way other languages works, e.g., Gauss):
> >
> > fixx <- function(x){
> > x[,6]<-x[,5]^2/10
> > result <- list(x=x)
> > return(result)
> > }
> >
> > This does not seem to work. The procedure in the main (calling) program
> > seems to get ignored. Any idea? Thanks.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>--
>Gregory (Greg) L. Snow Ph.D.
>538280 at gmail.com


From radhakrishnan.mohan at gmail.com  Wed Sep 24 16:55:46 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Wed, 24 Sep 2014 20:25:46 +0530
Subject: [R] Median of streaming data
In-Reply-To: <1f0222b00ed54745a80df5e552ecd524@AM3PR05MB545.eurprd05.prod.outlook.com>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>
	<54226816.700@auckland.ac.nz>
	<21538.32250.67575.749398@stat.math.ethz.ch>
	<1f0222b00ed54745a80df5e552ecd524@AM3PR05MB545.eurprd05.prod.outlook.com>
Message-ID: <CAOoXFP-0UPR+KWo71khz4bV5u5r5u-AjqmPo8sAwesjc2+-XhQ@mail.gmail.com>

I meant the papers. I hit a paywall. Can we reconstruct the code from the
papers ?

Thanks,
Mohan

On Wed, Sep 24, 2014 at 3:59 PM, Martyn Byng <martyn.byng at nag.co.uk> wrote:

> Something else that might be of interest ...
>
> Zhang Q and Wang W (2007) A fast algorithm for approximate quantiles in
> high speed data streams Proceedings of the 19th International Conference on
> Scientific and Statistical Database Management IEEE Computer Society 29
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Martin Maechler
> Sent: 24 September 2014 09:17
> To: Rolf Turner
> Cc: R-help at r-project.org; R-SIG-robust at r-project.org
> Subject: Re: [R] Median of streaming data
>
> >>>>> Rolf Turner <r.turner at auckland.ac.nz>
> >>>>>     on Wed, 24 Sep 2014 18:43:34 +1200 writes:
>
>     > On 24/09/14 17:31, Mohan Radhakrishnan wrote:
>     >> Hi,
>     >>
>     >> I have streaming data(1 TB) that can't fit in memory. Is
>     >> there a way for me to find the median of these streaming
>     >> integers assuming I can fit only a small part in memory ?
>     >> This is about the statistical approach to find the median
>     >> of a large number of values when I can inspect only a
>     >> part of them due to memory constraints.
>
>     > You cannot, I'm pretty sure, calculate the median
>     > recursively.  However there are "approximate" recursive
>     > median algorithms which provide an estimate of location
>     > that has the same asymptotic properties as the median.
>
>     > See:
>
>     > * U. Holst, Recursive estimators of location.
>     > Commun. Statist. Theory Meth., vol. 16, 1987,
>     > pp. 2201--2226.
>
>     > and
>
>     > * Murray A. Cameron and T. Rolf Turner, Recursive location
>     > and scale estimators, Commun. Statist. Theory Meth.,
>     > vol. 22, 1993, pp. 2503--2515.
>
> This is really interesting to me, thank you, Rolf!
>
> OTOH,
>
> 1) has your proposal ever been provided in R?
>    I'd be happy to add it to the robustX
>    (http://cran.ch.r-project.org/web/packages/robustX) or even
>    robustbase (http://cran.ch.r-project.org/web/packages/robustbase)
> package.
>
> 2) Would anybody know of more recent research on the subject?
>    (I quickly "googled around" and found research more geared
>     for the time series situation which is more involved anyway)
>
>    --> Hence CC'ing the experts' list  R-SIG-robust
>
>
> Martin Maechler,  ETH Zurich
>
>
>     > cheers,
>     > Rolf Turner
>
>     > --
>     > Rolf Turner Technical Editor ANZJS
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________________________________________________
> This e-mail has been scanned for all viruses by Star.\ _...{{dropped:3}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sohailk at hcpipa.com  Wed Sep 24 16:13:36 2014
From: sohailk at hcpipa.com (Sohail Khan)
Date: Wed, 24 Sep 2014 10:13:36 -0400
Subject: [R] Cluster -- Agnes function
Message-ID: <DFAF2BB901355046A467FDA584619F450DD82DDC@hcp-email.hcpipa.com>

Dear All,

I have clustered a patient data set by agnes.

I want to extract information for each cluster, I.E. all row ids
belonging to each cluster.

Thank you.

 

 


	[[alternative HTML version deleted]]


From matt at considine.net  Wed Sep 24 17:26:10 2014
From: matt at considine.net (matt at considine.net)
Date: Wed, 24 Sep 2014 10:26:10 -0500
Subject: [R] Help with continuous color plot
Message-ID: <d55b8014c88a6e07d24819b9e57b50d9@considine.net>

Hi,
I have a matrix of data, with the rows representing observations and the 
columns representing various values that the observation can take on.  
In other words, each row can be thought of as a sampling of the density 
function/histogram associated with the range of values for that 
observation.

I'd like to graph these with a shaded color, rather than as lines.  So a 
given observation would have the darkest shade at the mean and the 
shading would lighten for values that approached the tails.  In a sense 
this is like a ribbon chart, but where there are many confidence bands.

I think the example near the bottom of this page
   http://bconnelly.net/2013/10/creating-colorblind-friendly-figures/
starts to get at what I want.  But when I tried to get a ribbon, I get 
an error message saying that "Error: Aesthetics can not vary with a 
ribbon"

Can anyone point me to an example that accomplishes my task, or give me 
some ideas as to how to code this?

Below is a reproducible dataset and the code I ran that generated the 
above error.  And apologies in advance if I have overlooked some obvious 
source - I'm not exactly sure what keywords to search for.

Regards,
Matt

testdataset <- structure(c(0.703482475602795, 0.708141442616021, 
0.696373713631662,
                            0.670284015871304, 0.675183812793659, 
0.690440437259122, 0.717483375152826,
                            0.775328205198994, 0.848374059782512, 
0.869939471712489, 0.86329313061477,
                            0.842138830353923, 0.819853961383293, 
0.808038546509378, 0.826626282345039,
                            0.855428819162732, 0.873943618483253, 
0.906412218904192, 0.95345525957727,
                            0.941481792397259, 0.923791753474186, 
0.909206164221341, 0.847283523824235,
                            0.774333551860785, 0.723440114819687, 
0.653247411286407, 0.585889004137383,
                            0.516531935718585, 0.458855598305008, 
0.422596378188962, 0.385800210249005,
                            0.363663809831211, 0.703482475602795, 
0.708055808109959, 0.696379276680681,
                            0.686643131558789, 0.702628930558265, 
0.736010723583024, 0.790795207667811,
                            0.843997296035071, 0.872447231982615, 
0.876357159885425, 0.852095141662599,
                            0.815122741092172, 0.759163100114952, 
0.737079598996168, 0.755626127703219,
                            0.76375495269533, 0.757290640161052, 
0.754301244147121, 0.738872719902144,
                            0.712590028244082, 0.707690675037336, 
0.707234385372842, 0.708720518303698,
                            0.723271948541464, 0.738173079905318, 
0.772161522113349, 0.776237486574842,
                            0.775666977944939, 0.764229462885737, 
0.758916671383124, 0.742887393474484,
                            0.741362343479079, 0.703482475602795, 
0.70722192044612, 0.694934601341247,
                            0.675623005679584, 0.67355293987199, 
0.67514195581405, 0.701338223542176,
                            0.770084545123592, 0.826615555391194, 
0.815331595124185, 0.801265437257298,
                            0.768736104243487, 0.698903427959817, 
0.654393072393584, 0.646507677289504,
                            0.606308031283892, 0.574521529688064, 
0.550931914275617, 0.518538683619987,
                            0.495773346159491, 0.482784058725618, 
0.473031502762785, 0.462940836756943,
                            0.455472910452526, 0.457374752189383, 
0.468449683385787, 0.469177346159405,
                            0.47981744053419, 0.500517935694715, 
0.521161553352487, 0.538278248678118,
                            0.545834896270532, 0.703482475602795, 
0.707475643569319, 0.695699528962731,
                            0.695460540915422, 0.705063229294573, 
0.694190083263775, 0.676451221936696,
                            0.661139999162065, 0.627150885842318, 
0.592467979293877, 0.556197511727567,
                            0.524883713023224, 0.484571801496662, 
0.427784904562, 0.370137413134906,
                            0.331233866457343, 0.292181528642806, 
0.265504971226103, 0.239129968439056,
                            0.21258454640671, 0.184521419432522, 
0.160633576032345, 0.135729972994914,
                            0.115111431576686, 0.0933784744252792, 
0.0672765522562478, 0.0397992726679255,
                            0.0118179662548541, NA, NA, NA, NA, 
0.703482475602795, 0.70791132542366,
                            0.696508162877812, 0.672357035115831, 
0.679831378223931, 0.702075998432084,
                            0.736057349706643, 0.759252979404642, 
0.739391321260192, 0.706608353324493,
                            0.653481111693474, 0.607986236497692, 
0.600942686427268, 0.602450590412635,
                            0.594096281507138, 0.598414292518021, 
0.570859444977738, 0.50462737404968,
                            0.441225469913529, 0.37010584373766, 
0.299554326292306, 0.250957120974181,
                            0.231147047662909, 0.218081437060998, 
0.209354124252359, 0.212236940966109,
                            0.213898409405384, 0.200693009702681, 
0.189880443626695, 0.175663436717225,
                            0.160910269517771, 0.14423774751828, 
0.703482475602795, 0.707648742091919,
                            0.696092540716741, 0.656540853310246, 
0.6051367218461, 0.591695064299013,
                            0.596015810648035, 0.603800534715597, 
0.630728546677123, 0.658732672149451,
                            0.660216960664134, 0.675188962779905, 
0.680940355728037, 0.677371529164165,
                            0.678862966955137, 0.706307948099043, 
0.72103331978575, 0.71201796002067,
                            0.695266699409018, 0.685297231486624, 
0.661576951062559, 0.643301885602357,
                            0.619830526453808, 0.608129873046412, 
0.594283830084397, 0.562317115717112,
                            0.530350595536459, 0.506782526041746, 
0.485311767855001, 0.473335687828819,
                            0.47767850215973, 0.47780651839627, 
0.703482475602795, 0.708970958906805,
                            0.697551150784402, 0.661080016538957, 
0.61232038566617, 0.587787379274781,
                            0.593431699246192, 0.585207322444761, 
0.568559116457046, 0.548048255621954,
                            0.530114701694855, 0.534118004338362, 
0.551070523651917, 0.575923824458594,
                            0.601811119913484, 0.599679943614892, 
0.571040665848032, 0.537593347467274,
                            0.517448133546794, 0.509401266935977, 
0.506839184709813, 0.513795796376072,
                            0.538416419444161, 0.54431580354862, 
0.533416582151419, 0.536830327067308,
                            0.536462655629334, 0.513629165635279, 
0.478995218355945, 0.438690505845544,
                            0.382567436102273, 0.34023179757446, 
0.703482475602795, 0.708469004078862,
                            0.697978508894162, 0.676172179276398, 
0.653999136795877, 0.621901773418305,
                            0.611086726778221, 0.593857278888487, 
0.59772372401201, 0.615523307201519,
                            0.639972290824288, 0.642201950188424, 
0.640462288885887, 0.599634050862654,
                            0.556922658075191, 0.51984992524725, 
0.500551878868105, 0.481116358620079,
                            0.46280476578578, 0.439079916934238, 
0.426481043460678, 0.4046073777228,
                            0.384894885963074, 0.387418227322783, 
0.397735327855843, 0.382421337902373,
                            0.364609477937235, 0.351141834403433, 
0.326023299419572, 0.298998310511409,
                            0.279388702747555, 0.265729633371279, 
0.703482475602795, 0.708084110634261,
                            0.695308105608089, 0.680512620916581, 
0.674409687648891, 0.64479397663385,
                            0.611185461407328, 0.574633943767944, 
0.531967082066137, 0.509238294683539,
                            0.539380037981121, 0.605934156503129, 
0.67139250700667, 0.692111261722321,
                            0.681033453581129, 0.649259774238939, 
0.61340010828123, 0.601868728090964,
                            0.626623248125788, 0.630474601620122, 
0.632877115180945, 0.622655315896617,
                            0.602457206226614, 0.577755838513823, 
0.575613491077747, 0.56693811567409,
                            0.538199408312755, 0.508731518312269, 
0.488361667141151, 0.462965384850233,
                            0.438776128537772, 0.433205440295598, 
0.703482475602795, 0.708955081210283,
                            0.696337276771488, 0.675657944024044, 
0.682199731001736, 0.713302322144747,
                            0.780735831443758, 0.836330924875064, 
0.920042864888473, 0.993749005071184,
                            1.09383447176433, 1.13919188883409, 
1.17120759930688, 1.20149479327377,
                            1.21627978424244, 1.16585978639785, 
1.11758399725948, 1.04238685207932,
                            0.937208207066276, 0.862384770704829, 
0.774099878399983, 0.701556273005073,
                            0.670583202198987, 0.686968300073611, 
0.732378201300416, 0.820191766252091,
                            0.855392362283012, 0.845365464014818, 
0.803317719342587, 0.757849795095728,
                            0.711624608771727, 0.674398052370244), .Dim = 
c(32L, 10L))
matplot(testdataset, type = 'l', las = 1, xlab = 'x values',
         ylab = 'y values', main = 'title - testdataset')
library(ggplot2,RColorBrewer,reshape2)
testdataset[ is.na(testdataset) ] <- 0
testdataset2 <- melt(testdataset)
ggplot(testdataset2, aes(x=Var1,y=factor(value))) +
   stat_density(aes(fill=..density..), position="identity") +
   scale_fill_gradientn(colours=brewer.pal(n=8, name="PuBuGn"))


From kasterma at kasterma.net  Wed Sep 24 18:56:25 2014
From: kasterma at kasterma.net (Bart Kastermans)
Date: Wed, 24 Sep 2014 18:56:25 +0200
Subject: [R] Cluster -- Agnes function
In-Reply-To: <DFAF2BB901355046A467FDA584619F450DD82DDC@hcp-email.hcpipa.com>
References: <DFAF2BB901355046A467FDA584619F450DD82DDC@hcp-email.hcpipa.com>
Message-ID: <5422F7B9.8050804@kasterma.net>

On 24/09/14 16:13, Sohail Khan wrote:
> Dear All,
> 
> I have clustered a patient data set by agnes.
> 
> I want to extract information for each cluster, I.E. all row ids
> belonging to each cluster.

Fascinating, thank you for sharing.

Best,
Bart


From dcarlson at tamu.edu  Wed Sep 24 19:04:41 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 Sep 2014 17:04:41 +0000
Subject: [R] Cluster -- Agnes function
In-Reply-To: <DFAF2BB901355046A467FDA584619F450DD82DDC@hcp-email.hcpipa.com>
References: <DFAF2BB901355046A467FDA584619F450DD82DDC@hcp-email.hcpipa.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9B40D@mb02.ads.tamu.edu>

Read the documentation for cutree(). You will have to decide how many clusters you want to use since agnes() provides results for everything from n clusters (where n is the number of observations) to 1 cluster.

?cutree

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Sohail Khan
Sent: Wednesday, September 24, 2014 9:14 AM
To: r-help at r-project.org
Subject: [R] Cluster -- Agnes function

Dear All,

I have clustered a patient data set by agnes.

I want to extract information for each cluster, I.E. all row ids
belonging to each cluster.

Thank you.






	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Wed Sep 24 20:04:06 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 24 Sep 2014 11:04:06 -0700 (PDT)
Subject: [R] Package 'compositions' and R-3.1.0 [UPDATE]
In-Reply-To: <5373008D.6020903@stats.ox.ac.uk>
References: <alpine.LNX.2.11.1405131419070.11126@localhost>
	<537295B5.1090904@auckland.ac.nz>
	<B550960F-5F5F-496F-9400-7B49D6881B46@comcast.net>
	<5373008D.6020903@stats.ox.ac.uk>
Message-ID: <alpine.LNX.2.11.1409241101150.29487@localhost>

On Wed, 14 May 2014, Prof Brian Ripley wrote:

>>> The compositions package has apparently been archived:

> Yes, but not giving correct results ....

   There is a new version, 1.40 released in June that is in CRAN and loads in
R-3.1.1. Cannot attest to its correctness, but I'll read all the docs
(including their book) and test it on my data sets.

Rich


From rshepard at appl-ecosys.com  Wed Sep 24 20:22:55 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 24 Sep 2014 11:22:55 -0700 (PDT)
Subject: [R] Masked from package
Message-ID: <alpine.LNX.2.11.1409241120200.29487@localhost>

   When a library is loaded messages such as these are displayed:

The following object is masked from ?package:base?:

     norm

The following object is masked from ?package:NADA?:

     cor

   What do I read to understand just what being masked means?

Rich


From maitra.mbox.ignored at inbox.com  Wed Sep 24 20:31:27 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Wed, 24 Sep 2014 13:31:27 -0500
Subject: [R] Masked from package
In-Reply-To: <alpine.LNX.2.11.1409241120200.29487@localhost>
References: <alpine.LNX.2.11.1409241120200.29487@localhost>
Message-ID: <20140924133127.e690c4daccdccf076f9ac083@inbox.com>

Hi Rich,

I believe it means that when called, the function norm() in the 'base'
and the function cor () in the 'NADA' packages are not going to be
used, but rather functions of the same name (norm and cor) in the
package that you loaded with your library () function.

Same applies to other objects also.

HTH,
Ranjan

On Wed, 24 Sep 2014 11:22:55 -0700 Rich Shepard
<rshepard at appl-ecosys.com> wrote:

>    When a library is loaded messages such as these are displayed:
> 
> The following object is masked from ?package:base?:
> 
>      norm
> 
> The following object is masked from ?package:NADA?:
> 
>      cor
> 
>    What do I read to understand just what being masked means?
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From murdoch.duncan at gmail.com  Wed Sep 24 20:35:48 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 Sep 2014 14:35:48 -0400
Subject: [R] Masked from package
In-Reply-To: <alpine.LNX.2.11.1409241120200.29487@localhost>
References: <alpine.LNX.2.11.1409241120200.29487@localhost>
Message-ID: <54230F04.4030904@gmail.com>

On 24/09/2014 2:22 PM, Rich Shepard wrote:
>     When a library is loaded messages such as these are displayed:
>
> The following object is masked from ?package:base?:
>
>       norm
>
> The following object is masked from ?package:NADA?:
>
>       cor
>
>     What do I read to understand just what being masked means?

I'm not sure if the word "masked" is used, but the R Language Definition 
manual talks about the scope of variables.  The messages say that 
something just loaded has an object named "norm", and it is hiding the 
function of that name in the base package.  Similarly, you just loaded a 
function called "cor", so the one in NADA is hidden.  (When you loaded 
NADA you probably got a warning that its "cor" was hiding the one in the 
stats package.   So there are 3 "cor" functions now, and you really need 
to be careful that you're using the right one.)

Duncan Murdoch


From kw.stat at gmail.com  Wed Sep 24 20:56:30 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 24 Sep 2014 13:56:30 -0500
Subject: [R] How do I really, I mean really, unload a package?
Message-ID: <CAKFxdiTi-dJXbbM+roFEtLc0j0_5zr1kpfRf9mZOEOaA2MR69A@mail.gmail.com>

Sorry if this is well-known, but I can't find an answer or maybe just don't
know how to ask Google the right question.  If I run the following code in
R (3.1.1), I find that lattice:::xyplot.formula is still available (or
maybe just a promise to it ... ???) even though I've used detach and
unloadNamespace.  Is there another step I'm missing?

require(lattice)
head(lattice:::xyplot.formula)
detach(package:lattice)
search() # No longer on search list
loadedNamespaces() # But namespace is still loaded
unloadNamespace("lattice")
loadedNamespaces() # Namespace not loaded
head(lattice:::xyplot.formula)  # It is still accessible

Kevin

	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Wed Sep 24 20:58:04 2014
From: wht_crl at yahoo.com (carol white)
Date: Wed, 24 Sep 2014 11:58:04 -0700
Subject: [R] ubuntu 14.04
Message-ID: <1411585084.59067.YahooMailNeo@web121504.mail.ne1.yahoo.com>

Hi,
Can R be run on ubuntu 14.04 LTS without problem or is there any incompatibility?

Thanks

Carol

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Wed Sep 24 21:06:23 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 24 Sep 2014 14:06:23 -0500
Subject: [R] How do I really, I mean really, unload a package?
In-Reply-To: <CAKFxdiTi-dJXbbM+roFEtLc0j0_5zr1kpfRf9mZOEOaA2MR69A@mail.gmail.com>
References: <CAKFxdiTi-dJXbbM+roFEtLc0j0_5zr1kpfRf9mZOEOaA2MR69A@mail.gmail.com>
Message-ID: <CAKFxdiRkzt08UF1RGo-k6oRYZ=XweWiNVt--_z=TxB=by9QuJQ@mail.gmail.com>

Ah, here is the answer from the man page for :::

"...pkg:::name returns the value of the internal variable name. The
namespace will be loaded if it was not loaded before the call, but the
package will not be attached to the search path."

Kevin


On Wed, Sep 24, 2014 at 1:56 PM, Kevin Wright <kw.stat at gmail.com> wrote:
>
>
> Sorry if this is well-known, but I can't find an answer or maybe just don't know how to ask Google the right question.  If I run the following code in R (3.1.1), I find that lattice:::xyplot.formula is still available (or maybe just a promise to it ... ???) even though I've used detach and unloadNamespace.  Is there another step I'm missing?
>
> require(lattice)
> head(lattice:::xyplot.formula)
> detach(package:lattice)
> search() # No longer on search list
> loadedNamespaces() # But namespace is still loaded
> unloadNamespace("lattice")
> loadedNamespaces() # Namespace not loaded
> head(lattice:::xyplot.formula)  # It is still accessible
>
> Kevin
>



-- 
Kevin Wright


From ripley at stats.ox.ac.uk  Wed Sep 24 21:09:33 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 Sep 2014 20:09:33 +0100
Subject: [R] How do I really, I mean really, unload a package?
In-Reply-To: <CAKFxdiTi-dJXbbM+roFEtLc0j0_5zr1kpfRf9mZOEOaA2MR69A@mail.gmail.com>
References: <CAKFxdiTi-dJXbbM+roFEtLc0j0_5zr1kpfRf9mZOEOaA2MR69A@mail.gmail.com>
Message-ID: <542316ED.90401@stats.ox.ac.uk>

On 24/09/2014 19:56, Kevin Wright wrote:
> Sorry if this is well-known, but I can't find an answer or maybe just don't
> know how to ask Google the right question.  If I run the following code in
> R (3.1.1), I find that lattice:::xyplot.formula is still available (or
> maybe just a promise to it ... ???) even though I've used detach and
> unloadNamespace.  Is there another step I'm missing?

You just loaded it again.  Read ?`:::` .

The only way to make a package's namespace really unavailable is to 
uninstall it.

>
> require(lattice)
> head(lattice:::xyplot.formula)
> detach(package:lattice)
> search() # No longer on search list
> loadedNamespaces() # But namespace is still loaded
> unloadNamespace("lattice")
> loadedNamespaces() # Namespace not loaded
> head(lattice:::xyplot.formula)  # It is still accessible
>
> Kevin
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
PLEASE do: no HTML, do your homework before posting.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From felasa at gmail.com  Wed Sep 24 21:14:03 2014
From: felasa at gmail.com (Federico Lasa)
Date: Wed, 24 Sep 2014 14:14:03 -0500
Subject: [R] Help with continuous color plot
In-Reply-To: <d55b8014c88a6e07d24819b9e57b50d9@considine.net>
References: <d55b8014c88a6e07d24819b9e57b50d9@considine.net>
Message-ID: <CAE8W1T0OjtKkcrvTUzcnhPkmNBuhmo9waaW3TOVU9JFp=uR9Rg@mail.gmail.com>

Does this resemble what you're after?

library(reshape2)
tst <- melt(testdataset)
library(ggplot2)

ggplot(tst, aes(x=Var1, y=Var2, fill=value)) +
  geom_tile() +
  scale_fill_gradient2(low="white",
    high="white",
    mid=scales::muted("blue"),
    midpoint=0.6148377)

On Wed, Sep 24, 2014 at 10:26 AM,  <matt at considine.net> wrote:
> Hi,
> I have a matrix of data, with the rows representing observations and the
> columns representing various values that the observation can take on.  In
> other words, each row can be thought of as a sampling of the density
> function/histogram associated with the range of values for that observation.
>
> I'd like to graph these with a shaded color, rather than as lines.  So a
> given observation would have the darkest shade at the mean and the shading
> would lighten for values that approached the tails.  In a sense this is like
> a ribbon chart, but where there are many confidence bands.
>
> I think the example near the bottom of this page
>   http://bconnelly.net/2013/10/creating-colorblind-friendly-figures/
> starts to get at what I want.  But when I tried to get a ribbon, I get an
> error message saying that "Error: Aesthetics can not vary with a ribbon"
>
> Can anyone point me to an example that accomplishes my task, or give me some
> ideas as to how to code this?
>
> Below is a reproducible dataset and the code I ran that generated the above
> error.  And apologies in advance if I have overlooked some obvious source -
> I'm not exactly sure what keywords to search for.
>
> Regards,
> Matt
>
> testdataset <- structure(c(0.703482475602795, 0.708141442616021,
> 0.696373713631662,
>                            0.670284015871304, 0.675183812793659,
> 0.690440437259122, 0.717483375152826,
>                            0.775328205198994, 0.848374059782512,
> 0.869939471712489, 0.86329313061477,
>                            0.842138830353923, 0.819853961383293,
> 0.808038546509378, 0.826626282345039,
>                            0.855428819162732, 0.873943618483253,
> 0.906412218904192, 0.95345525957727,
>                            0.941481792397259, 0.923791753474186,
> 0.909206164221341, 0.847283523824235,
>                            0.774333551860785, 0.723440114819687,
> 0.653247411286407, 0.585889004137383,
>                            0.516531935718585, 0.458855598305008,
> 0.422596378188962, 0.385800210249005,
>                            0.363663809831211, 0.703482475602795,
> 0.708055808109959, 0.696379276680681,
>                            0.686643131558789, 0.702628930558265,
> 0.736010723583024, 0.790795207667811,
>                            0.843997296035071, 0.872447231982615,
> 0.876357159885425, 0.852095141662599,
>                            0.815122741092172, 0.759163100114952,
> 0.737079598996168, 0.755626127703219,
>                            0.76375495269533, 0.757290640161052,
> 0.754301244147121, 0.738872719902144,
>                            0.712590028244082, 0.707690675037336,
> 0.707234385372842, 0.708720518303698,
>                            0.723271948541464, 0.738173079905318,
> 0.772161522113349, 0.776237486574842,
>                            0.775666977944939, 0.764229462885737,
> 0.758916671383124, 0.742887393474484,
>                            0.741362343479079, 0.703482475602795,
> 0.70722192044612, 0.694934601341247,
>                            0.675623005679584, 0.67355293987199,
> 0.67514195581405, 0.701338223542176,
>                            0.770084545123592, 0.826615555391194,
> 0.815331595124185, 0.801265437257298,
>                            0.768736104243487, 0.698903427959817,
> 0.654393072393584, 0.646507677289504,
>                            0.606308031283892, 0.574521529688064,
> 0.550931914275617, 0.518538683619987,
>                            0.495773346159491, 0.482784058725618,
> 0.473031502762785, 0.462940836756943,
>                            0.455472910452526, 0.457374752189383,
> 0.468449683385787, 0.469177346159405,
>                            0.47981744053419, 0.500517935694715,
> 0.521161553352487, 0.538278248678118,
>                            0.545834896270532, 0.703482475602795,
> 0.707475643569319, 0.695699528962731,
>                            0.695460540915422, 0.705063229294573,
> 0.694190083263775, 0.676451221936696,
>                            0.661139999162065, 0.627150885842318,
> 0.592467979293877, 0.556197511727567,
>                            0.524883713023224, 0.484571801496662,
> 0.427784904562, 0.370137413134906,
>                            0.331233866457343, 0.292181528642806,
> 0.265504971226103, 0.239129968439056,
>                            0.21258454640671, 0.184521419432522,
> 0.160633576032345, 0.135729972994914,
>                            0.115111431576686, 0.0933784744252792,
> 0.0672765522562478, 0.0397992726679255,
>                            0.0118179662548541, NA, NA, NA, NA,
> 0.703482475602795, 0.70791132542366,
>                            0.696508162877812, 0.672357035115831,
> 0.679831378223931, 0.702075998432084,
>                            0.736057349706643, 0.759252979404642,
> 0.739391321260192, 0.706608353324493,
>                            0.653481111693474, 0.607986236497692,
> 0.600942686427268, 0.602450590412635,
>                            0.594096281507138, 0.598414292518021,
> 0.570859444977738, 0.50462737404968,
>                            0.441225469913529, 0.37010584373766,
> 0.299554326292306, 0.250957120974181,
>                            0.231147047662909, 0.218081437060998,
> 0.209354124252359, 0.212236940966109,
>                            0.213898409405384, 0.200693009702681,
> 0.189880443626695, 0.175663436717225,
>                            0.160910269517771, 0.14423774751828,
> 0.703482475602795, 0.707648742091919,
>                            0.696092540716741, 0.656540853310246,
> 0.6051367218461, 0.591695064299013,
>                            0.596015810648035, 0.603800534715597,
> 0.630728546677123, 0.658732672149451,
>                            0.660216960664134, 0.675188962779905,
> 0.680940355728037, 0.677371529164165,
>                            0.678862966955137, 0.706307948099043,
> 0.72103331978575, 0.71201796002067,
>                            0.695266699409018, 0.685297231486624,
> 0.661576951062559, 0.643301885602357,
>                            0.619830526453808, 0.608129873046412,
> 0.594283830084397, 0.562317115717112,
>                            0.530350595536459, 0.506782526041746,
> 0.485311767855001, 0.473335687828819,
>                            0.47767850215973, 0.47780651839627,
> 0.703482475602795, 0.708970958906805,
>                            0.697551150784402, 0.661080016538957,
> 0.61232038566617, 0.587787379274781,
>                            0.593431699246192, 0.585207322444761,
> 0.568559116457046, 0.548048255621954,
>                            0.530114701694855, 0.534118004338362,
> 0.551070523651917, 0.575923824458594,
>                            0.601811119913484, 0.599679943614892,
> 0.571040665848032, 0.537593347467274,
>                            0.517448133546794, 0.509401266935977,
> 0.506839184709813, 0.513795796376072,
>                            0.538416419444161, 0.54431580354862,
> 0.533416582151419, 0.536830327067308,
>                            0.536462655629334, 0.513629165635279,
> 0.478995218355945, 0.438690505845544,
>                            0.382567436102273, 0.34023179757446,
> 0.703482475602795, 0.708469004078862,
>                            0.697978508894162, 0.676172179276398,
> 0.653999136795877, 0.621901773418305,
>                            0.611086726778221, 0.593857278888487,
> 0.59772372401201, 0.615523307201519,
>                            0.639972290824288, 0.642201950188424,
> 0.640462288885887, 0.599634050862654,
>                            0.556922658075191, 0.51984992524725,
> 0.500551878868105, 0.481116358620079,
>                            0.46280476578578, 0.439079916934238,
> 0.426481043460678, 0.4046073777228,
>                            0.384894885963074, 0.387418227322783,
> 0.397735327855843, 0.382421337902373,
>                            0.364609477937235, 0.351141834403433,
> 0.326023299419572, 0.298998310511409,
>                            0.279388702747555, 0.265729633371279,
> 0.703482475602795, 0.708084110634261,
>                            0.695308105608089, 0.680512620916581,
> 0.674409687648891, 0.64479397663385,
>                            0.611185461407328, 0.574633943767944,
> 0.531967082066137, 0.509238294683539,
>                            0.539380037981121, 0.605934156503129,
> 0.67139250700667, 0.692111261722321,
>                            0.681033453581129, 0.649259774238939,
> 0.61340010828123, 0.601868728090964,
>                            0.626623248125788, 0.630474601620122,
> 0.632877115180945, 0.622655315896617,
>                            0.602457206226614, 0.577755838513823,
> 0.575613491077747, 0.56693811567409,
>                            0.538199408312755, 0.508731518312269,
> 0.488361667141151, 0.462965384850233,
>                            0.438776128537772, 0.433205440295598,
> 0.703482475602795, 0.708955081210283,
>                            0.696337276771488, 0.675657944024044,
> 0.682199731001736, 0.713302322144747,
>                            0.780735831443758, 0.836330924875064,
> 0.920042864888473, 0.993749005071184,
>                            1.09383447176433, 1.13919188883409,
> 1.17120759930688, 1.20149479327377,
>                            1.21627978424244, 1.16585978639785,
> 1.11758399725948, 1.04238685207932,
>                            0.937208207066276, 0.862384770704829,
> 0.774099878399983, 0.701556273005073,
>                            0.670583202198987, 0.686968300073611,
> 0.732378201300416, 0.820191766252091,
>                            0.855392362283012, 0.845365464014818,
> 0.803317719342587, 0.757849795095728,
>                            0.711624608771727, 0.674398052370244), .Dim =
> c(32L, 10L))
> matplot(testdataset, type = 'l', las = 1, xlab = 'x values',
>         ylab = 'y values', main = 'title - testdataset')
> library(ggplot2,RColorBrewer,reshape2)
> testdataset[ is.na(testdataset) ] <- 0
> testdataset2 <- melt(testdataset)
> ggplot(testdataset2, aes(x=Var1,y=factor(value))) +
>   stat_density(aes(fill=..density..), position="identity") +
>   scale_fill_gradientn(colours=brewer.pal(n=8, name="PuBuGn"))
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Sep 24 21:16:12 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 24 Sep 2014 12:16:12 -0700
Subject: [R] How do I really, I mean really, unload a package?
In-Reply-To: <CAKFxdiTi-dJXbbM+roFEtLc0j0_5zr1kpfRf9mZOEOaA2MR69A@mail.gmail.com>
References: <CAKFxdiTi-dJXbbM+roFEtLc0j0_5zr1kpfRf9mZOEOaA2MR69A@mail.gmail.com>
Message-ID: <CAF8bMcZG9U4ZG6KgAvXQEBUOJvuPRU+MZK1k3=N_2ggfuqg3ZA@mail.gmail.com>

Running pkg::func or pkg:::func has the side effect of loading pkg's
namespace, if it is not already loaded.  Use remove.packages() to
remove the package from your machine if you want to make its namespace
unloadable.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Sep 24, 2014 at 11:56 AM, Kevin Wright <kw.stat at gmail.com> wrote:
> Sorry if this is well-known, but I can't find an answer or maybe just don't
> know how to ask Google the right question.  If I run the following code in
> R (3.1.1), I find that lattice:::xyplot.formula is still available (or
> maybe just a promise to it ... ???) even though I've used detach and
> unloadNamespace.  Is there another step I'm missing?
>
> require(lattice)
> head(lattice:::xyplot.formula)
> detach(package:lattice)
> search() # No longer on search list
> loadedNamespaces() # But namespace is still loaded
> unloadNamespace("lattice")
> loadedNamespaces() # Namespace not loaded
> head(lattice:::xyplot.formula)  # It is still accessible
>
> Kevin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ray.Brownrigg at ecs.vuw.ac.nz  Wed Sep 24 21:17:32 2014
From: Ray.Brownrigg at ecs.vuw.ac.nz (Ray Brownrigg)
Date: Thu, 25 Sep 2014 07:17:32 +1200
Subject: [R] Plotting boundary lines from shapefiles overtop a map of
 Canada
In-Reply-To: <F9A1252A5C3CEF4C8C2F70752F372BF63891CC58E3@CAEMEX80.caecorp.cae.com>
References: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>	<54213220.5030809@ecs.vuw.ac.nz>	<F9A1252A5C3CEF4C8C2F70752F372BF63891C4B663@CAEMEX80.caecorp.cae.com>	<CAF8bMcaSxrJ58OmODMWa2C-tQYSvtq9YjnCWRTzBS-5gqQD8jg@mail.gmail.com>	<CAF8bMcatqPnn-yH8vc5D3YW33BTNvV7JReri5ki1tqrkF5AExg@mail.gmail.com>	<5422ACC0.1070501@ecs.vuw.ac.nz>
	<F9A1252A5C3CEF4C8C2F70752F372BF63891CC58E3@CAEMEX80.caecorp.cae.com>
Message-ID: <542318CC.9020608@ecs.vuw.ac.nz>

Hi Alain:

The issue is that map() is "too clever" and will only plot those map 
boundaries that fall within the defined limits, and even the myborder 
option will not override this.

What you can do, with somewhat better results, is something like:
map(database= "worldHires", ylim=c(39, 90), xlim=c(-145, -25), 
col="white", projection="lambert", param=c(50, 65))
map(database= "worldHires", "Canada", ylim=c(39,90), xlim=c(-145,-25), 
col="grey95", fill=TRUE, projection="lambert", param=c(50, 65), add=T)

[Apologies for the HTML formatting in my previous message, I have now 
turned this off for my home computer.]

Hope this helps,
Ray

On 25/09/2014 12:27 a.m., Alain Dubreuil wrote:
> Bill and Ray,
>
> Thank you to both of you for your input.  I am now able to display the lines.  Both the "polygon" and the "lines" commands that you suggested work.  I do have an extra question for you (or anyone else that can help): when I plot the map of Canada, I specify that I want to show from 25  to 145 degrees W.  However, what shows up is more constrained (probably something like 40 to 125 degrees W).  Is there a way to show just the map of Canada (without the USA) while still showing the desired width?  I assumed that it was constraining the width because of the "Canada" specification in the map command, so I removed it but it ended up showing the entire USA territory (minus Hawaii) in addition to Canada.
>
> Thanks
>
> Alain
>
> -----Original Message-----
> From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz]
> Sent: September-24-14 7:37 AM
> To: William Dunlap; Alain Dubreuil
> Cc: r-help at r-project.org
> Subject: Re: [R] Plotting boundary lines from shapefiles overtop a map of Canada
>
> Thanks Bill for picking this up "while I was sleeping".
>
> An enhancement that I have tested for in the case where the SAR regions are not defined as closed polygons is e.g.:
> xValue <- c(105.0, 120.0, 120.0, 105.0, NA, 110, 119, 106) yValue <- c(49.0, 49.0, 60.0, 60.0, NA, 50, 55, 59) polygon(mapproject(y = yValue, x = -xValue))
>
> Cheers,
> Ray
>
> On 24/09/2014 4:45 a.m., William Dunlap wrote:
>> Try:
>>     map(database= "worldHires","Canada", ylim=c(39,90),
>> xlim=c(-145,-25), col="grey95", fill=TRUE, projection="lambert",
>> param=c(50,65))
>>     lines(mapproject(y=yValue, x=-xValue))
>>
>> mapproject does care about the sign of the longitude, but if you
>> incompletely reset the projection it messes things up.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Tue, Sep 23, 2014 at 9:36 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> testLines <- mapproject(yValue, xValue, proj="lambert",
>>>> param=c(50,65))
>>> For starters, if you give the x,y values in reverse order of what the
>>> mapproject function expects you need to label them: y=yValue,
>>> x=xValue.
>>>
>>> (Also, I would have expected longitudes in the Americas to be
>>> negative, but mapproject doesn't appear to care.)
>>>
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Tue, Sep 23, 2014 at 9:17 AM, Alain Dubreuil <alain.dubreuil at cae.com> wrote:
>>>> Hi all,
>>>>
>>>> Based on Ray's suggestions, I have tried the following script:
>>>>
>>>> library(mapproj)
>>>> library(maps)
>>>> resuPdfFileName="C:/linesTest.pdf"
>>>> pdf(resuPdfFileName)
>>>> # Create a map of Canada in Lambert projection map(database=
>>>> "worldHires","Canada", ylim=c(39,90), xlim=c(-145,-25),
>>>> col=alpha("grey90",0.5), fill=TRUE, projection="lambert",
>>>> param=c(50,65)) # Use test position vectors to draw lines yValue <-
>>>> c(49.0, 49.0, 60.0, 60.0) xValue <- c(105.0, 120.0, 120.0, 105.0) #
>>>> Convert the test vectors into lambert and then draw the lines
>>>> testLines <- mapproject(yValue, xValue, proj="lambert",
>>>> param=c(50,65))
>>>> lines(testLines)
>>>> dev.off()
>>>>
>>>> The script draws the map of Canada, but fails to draw the lines.  Please let me know what I'm doing wrong because I can't see it.  By the way, not specifying the lambert projection in the call to mapproject yields different results than specifying it which seems contrary to the documentation (?).
>>>>
>>>> Thanks
>>>>
>>>> Alain Dubreuil
>>>> Ottawa, Canada
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz]
>>>> Sent: September-23-14 4:41 AM
>>>> To: Alain Dubreuil; r-help at r-project.org
>>>> Subject: Re: [R] Plotting boundary lines from shapefiles overtop a
>>>> map of Canada
>>>>
>>>> On 23/09/2014 3:27 a.m., Alain Dubreuil wrote:
>>>>> Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.
>>>>>
>>>>> To plot the map of Canada, I have used the following line of code:
>>>>>
>>>>>          map(database= "worldHires","Canada", ylim=c(39,90),
>>>>> xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE,
>>>>> projection="lambert", param=c(50,65))
>>>>>
>>>>> Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.
>>>>>
>>>>> To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:
>>>>>
>>>>>          lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
>>>>>          lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
>>>>>          coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long
>>>>>          points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red",
>>>>> 0.5)) #plot converted points
>>>>>
>>>>> As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.
>>>>>
>>>>> Using readOGR:
>>>>>
>>>>>          region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
>>>>>          plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90),
>>>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>>> You don't state which package readOGR() comes from, but it is not
>>>> part of the maps package, which doesn't understand shapefiles, so
>>>> just using
>>>> plot() on top of a (projected) map() is unlikely to succeed.
>>>>
>>>> I believe what you have to do is go back to your lat/long pairs for your SAR regions and use mapproject() to convert them to the coordinates used by the plotted projection. Note that you don't need the proj="lambert"
>>>> option when you call mapproject() after a call to map() with a projection because the most recent projection (and its parameters) are "remembered".  Also I suspect (though untested) is that if you put NA pairs in between your lists of projected SAR regions, then you can just use lines() to draw them all at once.
>>>>
>>>> Hope this helps,
>>>> Ray Brownrigg
>>>>> Using read.shp and draw.shp:
>>>>>
>>>>>          region <- read.shp("C:/myRfolder/mySARshapefile.shp")
>>>>>          draw.shape(shape=region, type="poly", col="red")
>>>>>
>>>>> Using readShapePoly:
>>>>>
>>>>>          region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
>>>>>          plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90),
>>>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>>>>
>>>>> Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:
>>>>>
>>>>>          region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
>>>>>          lines(region, col=alpha("black", 0.6))
>>>>>
>>>>> I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")
>>>>>
>>>>> I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.
>>>>>
>>>>> Thanks
>>>>>
>>>>> Alain Dubreuil
>>>>> Ottawa, Canada
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Wed Sep 24 21:18:43 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 24 Sep 2014 12:18:43 -0700
Subject: [R] Masked from package
In-Reply-To: <20140924133127.e690c4daccdccf076f9ac083@inbox.com>
References: <alpine.LNX.2.11.1409241120200.29487@localhost>
	<20140924133127.e690c4daccdccf076f9ac083@inbox.com>
Message-ID: <alpine.LNX.2.11.1409241218150.29487@localhost>

On Wed, 24 Sep 2014, Ranjan Maitra wrote:

> I believe it means that when called, the function norm() in the 'base' and
> the function cor () in the 'NADA' packages are not going to be used, but
> rather functions of the same name (norm and cor) in the package that you
> loaded with your library () function.

Ranjan,

   Thank you. Makes sense to me.

Rich


From alain.dubreuil at cae.com  Wed Sep 24 21:27:40 2014
From: alain.dubreuil at cae.com (Alain Dubreuil)
Date: Wed, 24 Sep 2014 15:27:40 -0400
Subject: [R] Plotting boundary lines from shapefiles overtop a map of
 Canada
In-Reply-To: <542318CC.9020608@ecs.vuw.ac.nz>
References: <F9A1252A5C3CEF4C8C2F70752F372BF63891BCC17C@CAEMEX80.caecorp.cae.com>
	<54213220.5030809@ecs.vuw.ac.nz>
	<F9A1252A5C3CEF4C8C2F70752F372BF63891C4B663@CAEMEX80.caecorp.cae.com>
	<CAF8bMcaSxrJ58OmODMWa2C-tQYSvtq9YjnCWRTzBS-5gqQD8jg@mail.gmail.com>
	<CAF8bMcatqPnn-yH8vc5D3YW33BTNvV7JReri5ki1tqrkF5AExg@mail.gmail.com>
	<5422ACC0.1070501@ecs.vuw.ac.nz>
	<F9A1252A5C3CEF4C8C2F70752F372BF63891CC58E3@CAEMEX80.caecorp.cae.com>
	<542318CC.9020608@ecs.vuw.ac.nz>
Message-ID: <F9A1252A5C3CEF4C8C2F70752F372BF63891D49415@CAEMEX80.caecorp.cae.com>

Thanks Ray, that works very well!  This is my first venture into the R world, and I'm quite impressed with the community's dedication and helpfulness.  Thank you again.

Alain

-----Original Message-----
From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz] 
Sent: September-24-14 3:18 PM
To: Alain Dubreuil; Ray Brownrigg; William Dunlap
Cc: r-help at r-project.org
Subject: Re: [R] Plotting boundary lines from shapefiles overtop a map of Canada

Hi Alain:

The issue is that map() is "too clever" and will only plot those map boundaries that fall within the defined limits, and even the myborder option will not override this.

What you can do, with somewhat better results, is something like:
map(database= "worldHires", ylim=c(39, 90), xlim=c(-145, -25), col="white", projection="lambert", param=c(50, 65)) map(database= "worldHires", "Canada", ylim=c(39,90), xlim=c(-145,-25), col="grey95", fill=TRUE, projection="lambert", param=c(50, 65), add=T)

[Apologies for the HTML formatting in my previous message, I have now turned this off for my home computer.]

Hope this helps,
Ray

On 25/09/2014 12:27 a.m., Alain Dubreuil wrote:
> Bill and Ray,
>
> Thank you to both of you for your input.  I am now able to display the lines.  Both the "polygon" and the "lines" commands that you suggested work.  I do have an extra question for you (or anyone else that can help): when I plot the map of Canada, I specify that I want to show from 25  to 145 degrees W.  However, what shows up is more constrained (probably something like 40 to 125 degrees W).  Is there a way to show just the map of Canada (without the USA) while still showing the desired width?  I assumed that it was constraining the width because of the "Canada" specification in the map command, so I removed it but it ended up showing the entire USA territory (minus Hawaii) in addition to Canada.
>
> Thanks
>
> Alain
>
> -----Original Message-----
> From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz]
> Sent: September-24-14 7:37 AM
> To: William Dunlap; Alain Dubreuil
> Cc: r-help at r-project.org
> Subject: Re: [R] Plotting boundary lines from shapefiles overtop a map 
> of Canada
>
> Thanks Bill for picking this up "while I was sleeping".
>
> An enhancement that I have tested for in the case where the SAR regions are not defined as closed polygons is e.g.:
> xValue <- c(105.0, 120.0, 120.0, 105.0, NA, 110, 119, 106) yValue <- 
> c(49.0, 49.0, 60.0, 60.0, NA, 50, 55, 59) polygon(mapproject(y = 
> yValue, x = -xValue))
>
> Cheers,
> Ray
>
> On 24/09/2014 4:45 a.m., William Dunlap wrote:
>> Try:
>>     map(database= "worldHires","Canada", ylim=c(39,90), 
>> xlim=c(-145,-25), col="grey95", fill=TRUE, projection="lambert",
>> param=c(50,65))
>>     lines(mapproject(y=yValue, x=-xValue))
>>
>> mapproject does care about the sign of the longitude, but if you 
>> incompletely reset the projection it messes things up.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Tue, Sep 23, 2014 at 9:36 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> testLines <- mapproject(yValue, xValue, proj="lambert",
>>>> param=c(50,65))
>>> For starters, if you give the x,y values in reverse order of what 
>>> the mapproject function expects you need to label them: y=yValue, 
>>> x=xValue.
>>>
>>> (Also, I would have expected longitudes in the Americas to be 
>>> negative, but mapproject doesn't appear to care.)
>>>
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Tue, Sep 23, 2014 at 9:17 AM, Alain Dubreuil <alain.dubreuil at cae.com> wrote:
>>>> Hi all,
>>>>
>>>> Based on Ray's suggestions, I have tried the following script:
>>>>
>>>> library(mapproj)
>>>> library(maps)
>>>> resuPdfFileName="C:/linesTest.pdf"
>>>> pdf(resuPdfFileName)
>>>> # Create a map of Canada in Lambert projection map(database= 
>>>> "worldHires","Canada", ylim=c(39,90), xlim=c(-145,-25), 
>>>> col=alpha("grey90",0.5), fill=TRUE, projection="lambert",
>>>> param=c(50,65)) # Use test position vectors to draw lines yValue <- 
>>>> c(49.0, 49.0, 60.0, 60.0) xValue <- c(105.0, 120.0, 120.0, 105.0) # 
>>>> Convert the test vectors into lambert and then draw the lines 
>>>> testLines <- mapproject(yValue, xValue, proj="lambert",
>>>> param=c(50,65))
>>>> lines(testLines)
>>>> dev.off()
>>>>
>>>> The script draws the map of Canada, but fails to draw the lines.  Please let me know what I'm doing wrong because I can't see it.  By the way, not specifying the lambert projection in the call to mapproject yields different results than specifying it which seems contrary to the documentation (?).
>>>>
>>>> Thanks
>>>>
>>>> Alain Dubreuil
>>>> Ottawa, Canada
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: Ray Brownrigg [mailto:Ray.Brownrigg at ecs.vuw.ac.nz]
>>>> Sent: September-23-14 4:41 AM
>>>> To: Alain Dubreuil; r-help at r-project.org
>>>> Subject: Re: [R] Plotting boundary lines from shapefiles overtop a 
>>>> map of Canada
>>>>
>>>> On 23/09/2014 3:27 a.m., Alain Dubreuil wrote:
>>>>> Hi.  I have a requirement to plot a series of points on a map of Canada along with boundaries defining search and rescue (SAR) regions.  I have been successful in plotting the map of Canada (Lambert projection) and the points, but I have been unable thus far to plot the SAR regions on top of the map.  I'm at the point now where I need help to resolve the issue.
>>>>>
>>>>> To plot the map of Canada, I have used the following line of code:
>>>>>
>>>>>          map(database= "worldHires","Canada", ylim=c(39,90), 
>>>>> xlim=c(-150,-25), col=alpha("grey90",0.5), fill=TRUE, 
>>>>> projection="lambert", param=c(50,65))
>>>>>
>>>>> Note that the ylim and xlim limits go wider that the actual coordinates of Canada, but that is necessary because the SAR regions go out to sea quite a distance.  Also, I need the map to go all the way to the North Pole.
>>>>>
>>>>> To plot the points, I have used a "dummy" list of points which I will eventually replace with my real data.  I convert the points to the lambert projection on the fly using the following lines of code:
>>>>>
>>>>>          lon <- c(-60, -60, -80, -80.1, -90, -105, -140)  #a test longitude vector
>>>>>          lat <- c(42.5, 42.6, 54.6, 54.4, 75, 68.3, 60)  #a test latitude vector
>>>>>          coord <- mapproject(lon, lat, proj="lambert", param=c(50,65))  #convert points to projected lat/long
>>>>>          points(coord, add=TRUE, pch=20, cex=1.2, col=alpha("red",
>>>>> 0.5)) #plot converted points
>>>>>
>>>>> As stated, plotting the SAR regions has not worked thus far.  The best I have ever gotten is a square box around the map.  I have data files that list the coordinates of the SAR regions, which is a succession of up to 12100 lat & long points.  A colleague converted those data files into shapefiles defining polygons, with the coordinates already projected to Lambert.  I have tried various options to plot the regions, but none have worked.
>>>>>
>>>>> Using readOGR:
>>>>>
>>>>>          region <- readOGR(dsn="C:/myRfolder",layer="mySARshapefile")
>>>>>          plot(region, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), 
>>>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>>> You don't state which package readOGR() comes from, but it is not 
>>>> part of the maps package, which doesn't understand shapefiles, so 
>>>> just using
>>>> plot() on top of a (projected) map() is unlikely to succeed.
>>>>
>>>> I believe what you have to do is go back to your lat/long pairs for your SAR regions and use mapproject() to convert them to the coordinates used by the plotted projection. Note that you don't need the proj="lambert"
>>>> option when you call mapproject() after a call to map() with a projection because the most recent projection (and its parameters) are "remembered".  Also I suspect (though untested) is that if you put NA pairs in between your lists of projected SAR regions, then you can just use lines() to draw them all at once.
>>>>
>>>> Hope this helps,
>>>> Ray Brownrigg
>>>>> Using read.shp and draw.shp:
>>>>>
>>>>>          region <- read.shp("C:/myRfolder/mySARshapefile.shp")
>>>>>          draw.shape(shape=region, type="poly", col="red")
>>>>>
>>>>> Using readShapePoly:
>>>>>
>>>>>          region <- readShapePoly("C:/ myRfolder/mySARshapefile.shp")
>>>>>          plot(halRegion, add=TRUE, xlim=c(-150,-25),ylim=c(39,90), 
>>>>> col=alpha("lightgreen", 0.6), border=TRUE)
>>>>>
>>>>> Using readShapeLines after converting the region coordinates to a Lines shapefile instead of a Polygon shapefile:
>>>>>
>>>>>          region <- readShapeLines("C:/myRfolder/mySARshapefile_lines.shp")
>>>>>          lines(region, col=alpha("black", 0.6))
>>>>>
>>>>> I have tried playing with spplot, but I haven't quite understood how this one works yet (gives me an error message: "Error in stack.SpatialPointsDataFrame(as(data, "SpatialPointsDataFrame"),  :   all factors should have identical levels")
>>>>>
>>>>> I would appreciate any help or insight that you could provide to help me get those boundaries drawn on-top of the country map.
>>>>>
>>>>> Thanks
>>>>>
>>>>> Alain Dubreuil
>>>>> Ottawa, Canada
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From felasa at gmail.com  Wed Sep 24 21:29:35 2014
From: felasa at gmail.com (Federico Lasa)
Date: Wed, 24 Sep 2014 14:29:35 -0500
Subject: [R] Help with continuous color plot
In-Reply-To: <CAE8W1T0OjtKkcrvTUzcnhPkmNBuhmo9waaW3TOVU9JFp=uR9Rg@mail.gmail.com>
References: <d55b8014c88a6e07d24819b9e57b50d9@considine.net>
	<CAE8W1T0OjtKkcrvTUzcnhPkmNBuhmo9waaW3TOVU9JFp=uR9Rg@mail.gmail.com>
Message-ID: <CAE8W1T3TD3nv60yCM+Uz3Bc4-AHnvcXAW0ztDY2UbUWbbME79w@mail.gmail.com>

You missed a few things when copying the example, try

ggplot(testdataset2, aes(y=factor(Var2),x=value)) +
  stat_density(aes(fill=..density..), position="identity", geom="tile") +
  scale_fill_gradientn(colours=brewer.pal(n=8, name="PuBuGn"))

needed to add tile geom, and factor the correct variable.

On Wed, Sep 24, 2014 at 2:14 PM, Federico Lasa <felasa at gmail.com> wrote:
> Does this resemble what you're after?
>
> library(reshape2)
> tst <- melt(testdataset)
> library(ggplot2)
>
> ggplot(tst, aes(x=Var1, y=Var2, fill=value)) +
>   geom_tile() +
>   scale_fill_gradient2(low="white",
>     high="white",
>     mid=scales::muted("blue"),
>     midpoint=0.6148377)
>
> On Wed, Sep 24, 2014 at 10:26 AM,  <matt at considine.net> wrote:
>> Hi,
>> I have a matrix of data, with the rows representing observations and the
>> columns representing various values that the observation can take on.  In
>> other words, each row can be thought of as a sampling of the density
>> function/histogram associated with the range of values for that observation.
>>
>> I'd like to graph these with a shaded color, rather than as lines.  So a
>> given observation would have the darkest shade at the mean and the shading
>> would lighten for values that approached the tails.  In a sense this is like
>> a ribbon chart, but where there are many confidence bands.
>>
>> I think the example near the bottom of this page
>>   http://bconnelly.net/2013/10/creating-colorblind-friendly-figures/
>> starts to get at what I want.  But when I tried to get a ribbon, I get an
>> error message saying that "Error: Aesthetics can not vary with a ribbon"
>>
>> Can anyone point me to an example that accomplishes my task, or give me some
>> ideas as to how to code this?
>>
>> Below is a reproducible dataset and the code I ran that generated the above
>> error.  And apologies in advance if I have overlooked some obvious source -
>> I'm not exactly sure what keywords to search for.
>>
>> Regards,
>> Matt
>>
>> testdataset <- structure(c(0.703482475602795, 0.708141442616021,
>> 0.696373713631662,
>>                            0.670284015871304, 0.675183812793659,
>> 0.690440437259122, 0.717483375152826,
>>                            0.775328205198994, 0.848374059782512,
>> 0.869939471712489, 0.86329313061477,
>>                            0.842138830353923, 0.819853961383293,
>> 0.808038546509378, 0.826626282345039,
>>                            0.855428819162732, 0.873943618483253,
>> 0.906412218904192, 0.95345525957727,
>>                            0.941481792397259, 0.923791753474186,
>> 0.909206164221341, 0.847283523824235,
>>                            0.774333551860785, 0.723440114819687,
>> 0.653247411286407, 0.585889004137383,
>>                            0.516531935718585, 0.458855598305008,
>> 0.422596378188962, 0.385800210249005,
>>                            0.363663809831211, 0.703482475602795,
>> 0.708055808109959, 0.696379276680681,
>>                            0.686643131558789, 0.702628930558265,
>> 0.736010723583024, 0.790795207667811,
>>                            0.843997296035071, 0.872447231982615,
>> 0.876357159885425, 0.852095141662599,
>>                            0.815122741092172, 0.759163100114952,
>> 0.737079598996168, 0.755626127703219,
>>                            0.76375495269533, 0.757290640161052,
>> 0.754301244147121, 0.738872719902144,
>>                            0.712590028244082, 0.707690675037336,
>> 0.707234385372842, 0.708720518303698,
>>                            0.723271948541464, 0.738173079905318,
>> 0.772161522113349, 0.776237486574842,
>>                            0.775666977944939, 0.764229462885737,
>> 0.758916671383124, 0.742887393474484,
>>                            0.741362343479079, 0.703482475602795,
>> 0.70722192044612, 0.694934601341247,
>>                            0.675623005679584, 0.67355293987199,
>> 0.67514195581405, 0.701338223542176,
>>                            0.770084545123592, 0.826615555391194,
>> 0.815331595124185, 0.801265437257298,
>>                            0.768736104243487, 0.698903427959817,
>> 0.654393072393584, 0.646507677289504,
>>                            0.606308031283892, 0.574521529688064,
>> 0.550931914275617, 0.518538683619987,
>>                            0.495773346159491, 0.482784058725618,
>> 0.473031502762785, 0.462940836756943,
>>                            0.455472910452526, 0.457374752189383,
>> 0.468449683385787, 0.469177346159405,
>>                            0.47981744053419, 0.500517935694715,
>> 0.521161553352487, 0.538278248678118,
>>                            0.545834896270532, 0.703482475602795,
>> 0.707475643569319, 0.695699528962731,
>>                            0.695460540915422, 0.705063229294573,
>> 0.694190083263775, 0.676451221936696,
>>                            0.661139999162065, 0.627150885842318,
>> 0.592467979293877, 0.556197511727567,
>>                            0.524883713023224, 0.484571801496662,
>> 0.427784904562, 0.370137413134906,
>>                            0.331233866457343, 0.292181528642806,
>> 0.265504971226103, 0.239129968439056,
>>                            0.21258454640671, 0.184521419432522,
>> 0.160633576032345, 0.135729972994914,
>>                            0.115111431576686, 0.0933784744252792,
>> 0.0672765522562478, 0.0397992726679255,
>>                            0.0118179662548541, NA, NA, NA, NA,
>> 0.703482475602795, 0.70791132542366,
>>                            0.696508162877812, 0.672357035115831,
>> 0.679831378223931, 0.702075998432084,
>>                            0.736057349706643, 0.759252979404642,
>> 0.739391321260192, 0.706608353324493,
>>                            0.653481111693474, 0.607986236497692,
>> 0.600942686427268, 0.602450590412635,
>>                            0.594096281507138, 0.598414292518021,
>> 0.570859444977738, 0.50462737404968,
>>                            0.441225469913529, 0.37010584373766,
>> 0.299554326292306, 0.250957120974181,
>>                            0.231147047662909, 0.218081437060998,
>> 0.209354124252359, 0.212236940966109,
>>                            0.213898409405384, 0.200693009702681,
>> 0.189880443626695, 0.175663436717225,
>>                            0.160910269517771, 0.14423774751828,
>> 0.703482475602795, 0.707648742091919,
>>                            0.696092540716741, 0.656540853310246,
>> 0.6051367218461, 0.591695064299013,
>>                            0.596015810648035, 0.603800534715597,
>> 0.630728546677123, 0.658732672149451,
>>                            0.660216960664134, 0.675188962779905,
>> 0.680940355728037, 0.677371529164165,
>>                            0.678862966955137, 0.706307948099043,
>> 0.72103331978575, 0.71201796002067,
>>                            0.695266699409018, 0.685297231486624,
>> 0.661576951062559, 0.643301885602357,
>>                            0.619830526453808, 0.608129873046412,
>> 0.594283830084397, 0.562317115717112,
>>                            0.530350595536459, 0.506782526041746,
>> 0.485311767855001, 0.473335687828819,
>>                            0.47767850215973, 0.47780651839627,
>> 0.703482475602795, 0.708970958906805,
>>                            0.697551150784402, 0.661080016538957,
>> 0.61232038566617, 0.587787379274781,
>>                            0.593431699246192, 0.585207322444761,
>> 0.568559116457046, 0.548048255621954,
>>                            0.530114701694855, 0.534118004338362,
>> 0.551070523651917, 0.575923824458594,
>>                            0.601811119913484, 0.599679943614892,
>> 0.571040665848032, 0.537593347467274,
>>                            0.517448133546794, 0.509401266935977,
>> 0.506839184709813, 0.513795796376072,
>>                            0.538416419444161, 0.54431580354862,
>> 0.533416582151419, 0.536830327067308,
>>                            0.536462655629334, 0.513629165635279,
>> 0.478995218355945, 0.438690505845544,
>>                            0.382567436102273, 0.34023179757446,
>> 0.703482475602795, 0.708469004078862,
>>                            0.697978508894162, 0.676172179276398,
>> 0.653999136795877, 0.621901773418305,
>>                            0.611086726778221, 0.593857278888487,
>> 0.59772372401201, 0.615523307201519,
>>                            0.639972290824288, 0.642201950188424,
>> 0.640462288885887, 0.599634050862654,
>>                            0.556922658075191, 0.51984992524725,
>> 0.500551878868105, 0.481116358620079,
>>                            0.46280476578578, 0.439079916934238,
>> 0.426481043460678, 0.4046073777228,
>>                            0.384894885963074, 0.387418227322783,
>> 0.397735327855843, 0.382421337902373,
>>                            0.364609477937235, 0.351141834403433,
>> 0.326023299419572, 0.298998310511409,
>>                            0.279388702747555, 0.265729633371279,
>> 0.703482475602795, 0.708084110634261,
>>                            0.695308105608089, 0.680512620916581,
>> 0.674409687648891, 0.64479397663385,
>>                            0.611185461407328, 0.574633943767944,
>> 0.531967082066137, 0.509238294683539,
>>                            0.539380037981121, 0.605934156503129,
>> 0.67139250700667, 0.692111261722321,
>>                            0.681033453581129, 0.649259774238939,
>> 0.61340010828123, 0.601868728090964,
>>                            0.626623248125788, 0.630474601620122,
>> 0.632877115180945, 0.622655315896617,
>>                            0.602457206226614, 0.577755838513823,
>> 0.575613491077747, 0.56693811567409,
>>                            0.538199408312755, 0.508731518312269,
>> 0.488361667141151, 0.462965384850233,
>>                            0.438776128537772, 0.433205440295598,
>> 0.703482475602795, 0.708955081210283,
>>                            0.696337276771488, 0.675657944024044,
>> 0.682199731001736, 0.713302322144747,
>>                            0.780735831443758, 0.836330924875064,
>> 0.920042864888473, 0.993749005071184,
>>                            1.09383447176433, 1.13919188883409,
>> 1.17120759930688, 1.20149479327377,
>>                            1.21627978424244, 1.16585978639785,
>> 1.11758399725948, 1.04238685207932,
>>                            0.937208207066276, 0.862384770704829,
>> 0.774099878399983, 0.701556273005073,
>>                            0.670583202198987, 0.686968300073611,
>> 0.732378201300416, 0.820191766252091,
>>                            0.855392362283012, 0.845365464014818,
>> 0.803317719342587, 0.757849795095728,
>>                            0.711624608771727, 0.674398052370244), .Dim =
>> c(32L, 10L))
>> matplot(testdataset, type = 'l', las = 1, xlab = 'x values',
>>         ylab = 'y values', main = 'title - testdataset')
>> library(ggplot2,RColorBrewer,reshape2)
>> testdataset[ is.na(testdataset) ] <- 0
>> testdataset2 <- melt(testdataset)
>> ggplot(testdataset2, aes(x=Var1,y=factor(value))) +
>>   stat_density(aes(fill=..density..), position="identity") +
>>   scale_fill_gradientn(colours=brewer.pal(n=8, name="PuBuGn"))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Sep 24 21:39:23 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 24 Sep 2014 12:39:23 -0700
Subject: [R] ubuntu 14.04
In-Reply-To: <1411585084.59067.YahooMailNeo@web121504.mail.ne1.yahoo.com>
References: <1411585084.59067.YahooMailNeo@web121504.mail.ne1.yahoo.com>
Message-ID: <db86e8b5-44ed-49cc-97a6-373538dae152@email.android.com>

"Any" incompatibility is a high standard, but I run it just fine on that platform.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 24, 2014 11:58:04 AM PDT, carol white <wht_crl at yahoo.com> wrote:
>Hi,
>Can R be run on ubuntu 14.04 LTS without problem or is there any
>incompatibility?
>
>Thanks
>
>Carol
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kw.stat at gmail.com  Wed Sep 24 22:24:22 2014
From: kw.stat at gmail.com (Kevin Wright)
Date: Wed, 24 Sep 2014 15:24:22 -0500
Subject: [R] How do I really, I mean really, unload a package?
In-Reply-To: <CAF8bMcZG9U4ZG6KgAvXQEBUOJvuPRU+MZK1k3=N_2ggfuqg3ZA@mail.gmail.com>
References: <CAKFxdiTi-dJXbbM+roFEtLc0j0_5zr1kpfRf9mZOEOaA2MR69A@mail.gmail.com>
	<CAF8bMcZG9U4ZG6KgAvXQEBUOJvuPRU+MZK1k3=N_2ggfuqg3ZA@mail.gmail.com>
Message-ID: <CAKFxdiR62VdH+jmxC8X8eYH_bF0Qcb4cMyQQ1cWXWeSVh_3Tug@mail.gmail.com>

To follow up, my attempt at creating a minimal example went a bit too minimal.

What I _think_ actually happened to me is that I loaded two packages
with identical-named S3 methods for a generic.  Even after unloading
the second package, the S3 methods for that package were still
registered and somehow re-loaded (?) when I tried to print an object
(of the same class) that had been created using the first package.

I found a post by Professor Ripley which seems to confirm something to
the effect that it is not possible to unregister S3 methods:
http://tolstoy.newcastle.edu.au/R/help/06/07/30791.html

In that sense, it appears that it is not possible to completely undo
the loading of a package.

Thanks to Bill Dunlap and Professor Ripley.

Kevin Wright



On Wed, Sep 24, 2014 at 2:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Running pkg::func or pkg:::func has the side effect of loading pkg's
> namespace, if it is not already loaded.  Use remove.packages() to
> remove the package from your machine if you want to make its namespace
> unloadable.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Sep 24, 2014 at 11:56 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>> Sorry if this is well-known, but I can't find an answer or maybe just don't
>> know how to ask Google the right question.  If I run the following code in
>> R (3.1.1), I find that lattice:::xyplot.formula is still available (or
>> maybe just a promise to it ... ???) even though I've used detach and
>> unloadNamespace.  Is there another step I'm missing?
>>
>> require(lattice)
>> head(lattice:::xyplot.formula)
>> detach(package:lattice)
>> search() # No longer on search list
>> loadedNamespaces() # But namespace is still loaded
>> unloadNamespace("lattice")
>> loadedNamespaces() # Namespace not loaded
>> head(lattice:::xyplot.formula)  # It is still accessible
>>
>> Kevin
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Kevin Wright


From tea3rd at gmail.com  Wed Sep 24 22:41:39 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Wed, 24 Sep 2014 14:41:39 -0600
Subject: [R] ubuntu 14.04
In-Reply-To: <db86e8b5-44ed-49cc-97a6-373538dae152@email.android.com>
References: <1411585084.59067.YahooMailNeo@web121504.mail.ne1.yahoo.com>
	<db86e8b5-44ed-49cc-97a6-373538dae152@email.android.com>
Message-ID: <CAGxgkWhy3dvLNS4iuOm3wz5fnxV4keaJbAvsUQmMGQihGK9NJA@mail.gmail.com>

As do I...



On Wednesday, September 24, 2014, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> "Any" incompatibility is a high standard, but I run it just fine on that
> platform.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us <javascript:;>>        Basics: ##.#.
>  ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On September 24, 2014 11:58:04 AM PDT, carol white <wht_crl at yahoo.com
> <javascript:;>> wrote:
> >Hi,
> >Can R be run on ubuntu 14.04 LTS without problem or is there any
> >incompatibility?
> >
> >Thanks
> >
> >Carol
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org <javascript:;> mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Thomas E Adams, III
718 McBurney Drive
Lebanon, OH 45036

1 (513) 739-9512 (cell)

	[[alternative HTML version deleted]]


From matt at considine.net  Wed Sep 24 21:36:58 2014
From: matt at considine.net (matt at considine.net)
Date: Wed, 24 Sep 2014 14:36:58 -0500
Subject: [R] Help with continuous color plot
In-Reply-To: <CAE8W1T0OjtKkcrvTUzcnhPkmNBuhmo9waaW3TOVU9JFp=uR9Rg@mail.gmail.com>
References: <d55b8014c88a6e07d24819b9e57b50d9@considine.net>
	<CAE8W1T0OjtKkcrvTUzcnhPkmNBuhmo9waaW3TOVU9JFp=uR9Rg@mail.gmail.com>
Message-ID: <42007e5e2608fa4bbecc5de73659da28@considine.net>

No, I don't think so.  And I've wondered if I described the problem 
clearly, so I put together the following hack, which seems to be what I 
want :

#create a matrix to hold the values corresponding to various percentiles
vals<-matrix(0,32,21)
#for each row in the data, collect info on the distribution
for(i in 1:32){
   obs <- testdataset[i,]
   vals[i,] <- quantile(obs, probs=seq(0,1,0.05))
}

#pick the last observation to get a distrbution of colors
cols <- sort(densCols(vals[32,]))

#set up a blank plot
matplot(vals, type="n", xlab = 'yrs', ylab = 'Ratio',
         main = 'Projected ratios')

#plot confidence bands as polygons, ideally overlaying light to dark
for (i in 1:10){
   lines(vals[,i],col=cols[22-i])
   lines(vals[,22-i],col=cols[22-i])
   
polygon(c(seq(1:32),rev(seq(1:32))),c(vals[,22-i],rev(vals[,i])),col=cols[22-i],border="NA")
}

#plot a line for the average case
lines(vals[,11],col="black")

If anyone can suggest a more efficient/effective/better/etc/etc way of 
doing this, I'd be grateful.  In a nutshell, I am trying to find a 
visually clean way of showing the output of a Monte Carlo analysis.

Thanks again for everyone's attention.
Matt


On 2014-09-24 14:14, Federico Lasa wrote:
> Does this resemble what you're after?
> 
> library(reshape2)
> tst <- melt(testdataset)
> library(ggplot2)
> 
> ggplot(tst, aes(x=Var1, y=Var2, fill=value)) +
>   geom_tile() +
>   scale_fill_gradient2(low="white",
>     high="white",
>     mid=scales::muted("blue"),
>     midpoint=0.6148377)
> 
> On Wed, Sep 24, 2014 at 10:26 AM,  <matt at considine.net> wrote:
>> Hi,
>> I have a matrix of data, with the rows representing observations and 
>> the
>> columns representing various values that the observation can take on.  
>> In
>> other words, each row can be thought of as a sampling of the density
>> function/histogram associated with the range of values for that 
>> observation.
>> 
>> I'd like to graph these with a shaded color, rather than as lines.  So 
>> a
>> given observation would have the darkest shade at the mean and the 
>> shading
>> would lighten for values that approached the tails.  In a sense this 
>> is like
>> a ribbon chart, but where there are many confidence bands.
>> 
>> I think the example near the bottom of this page
>>   http://bconnelly.net/2013/10/creating-colorblind-friendly-figures/
>> starts to get at what I want.  But when I tried to get a ribbon, I get 
>> an
>> error message saying that "Error: Aesthetics can not vary with a 
>> ribbon"
>> 
>> Can anyone point me to an example that accomplishes my task, or give 
>> me some
>> ideas as to how to code this?
>> 
>> Below is a reproducible dataset and the code I ran that generated the 
>> above
>> error.  And apologies in advance if I have overlooked some obvious 
>> source -
>> I'm not exactly sure what keywords to search for.
>> 
>> Regards,
>> Matt
>> 
>> testdataset <- structure(c(0.703482475602795, 0.708141442616021,
>> 0.696373713631662,
>>                            0.670284015871304, 0.675183812793659,
>> 0.690440437259122, 0.717483375152826,
>>                            0.775328205198994, 0.848374059782512,
>> 0.869939471712489, 0.86329313061477,
>>                            0.842138830353923, 0.819853961383293,
>> 0.808038546509378, 0.826626282345039,
>>                            0.855428819162732, 0.873943618483253,
>> 0.906412218904192, 0.95345525957727,
>>                            0.941481792397259, 0.923791753474186,
>> 0.909206164221341, 0.847283523824235,
>>                            0.774333551860785, 0.723440114819687,
>> 0.653247411286407, 0.585889004137383,
>>                            0.516531935718585, 0.458855598305008,
>> 0.422596378188962, 0.385800210249005,
>>                            0.363663809831211, 0.703482475602795,
>> 0.708055808109959, 0.696379276680681,
>>                            0.686643131558789, 0.702628930558265,
>> 0.736010723583024, 0.790795207667811,
>>                            0.843997296035071, 0.872447231982615,
>> 0.876357159885425, 0.852095141662599,
>>                            0.815122741092172, 0.759163100114952,
>> 0.737079598996168, 0.755626127703219,
>>                            0.76375495269533, 0.757290640161052,
>> 0.754301244147121, 0.738872719902144,
>>                            0.712590028244082, 0.707690675037336,
>> 0.707234385372842, 0.708720518303698,
>>                            0.723271948541464, 0.738173079905318,
>> 0.772161522113349, 0.776237486574842,
>>                            0.775666977944939, 0.764229462885737,
>> 0.758916671383124, 0.742887393474484,
>>                            0.741362343479079, 0.703482475602795,
>> 0.70722192044612, 0.694934601341247,
>>                            0.675623005679584, 0.67355293987199,
>> 0.67514195581405, 0.701338223542176,
>>                            0.770084545123592, 0.826615555391194,
>> 0.815331595124185, 0.801265437257298,
>>                            0.768736104243487, 0.698903427959817,
>> 0.654393072393584, 0.646507677289504,
>>                            0.606308031283892, 0.574521529688064,
>> 0.550931914275617, 0.518538683619987,
>>                            0.495773346159491, 0.482784058725618,
>> 0.473031502762785, 0.462940836756943,
>>                            0.455472910452526, 0.457374752189383,
>> 0.468449683385787, 0.469177346159405,
>>                            0.47981744053419, 0.500517935694715,
>> 0.521161553352487, 0.538278248678118,
>>                            0.545834896270532, 0.703482475602795,
>> 0.707475643569319, 0.695699528962731,
>>                            0.695460540915422, 0.705063229294573,
>> 0.694190083263775, 0.676451221936696,
>>                            0.661139999162065, 0.627150885842318,
>> 0.592467979293877, 0.556197511727567,
>>                            0.524883713023224, 0.484571801496662,
>> 0.427784904562, 0.370137413134906,
>>                            0.331233866457343, 0.292181528642806,
>> 0.265504971226103, 0.239129968439056,
>>                            0.21258454640671, 0.184521419432522,
>> 0.160633576032345, 0.135729972994914,
>>                            0.115111431576686, 0.0933784744252792,
>> 0.0672765522562478, 0.0397992726679255,
>>                            0.0118179662548541, NA, NA, NA, NA,
>> 0.703482475602795, 0.70791132542366,
>>                            0.696508162877812, 0.672357035115831,
>> 0.679831378223931, 0.702075998432084,
>>                            0.736057349706643, 0.759252979404642,
>> 0.739391321260192, 0.706608353324493,
>>                            0.653481111693474, 0.607986236497692,
>> 0.600942686427268, 0.602450590412635,
>>                            0.594096281507138, 0.598414292518021,
>> 0.570859444977738, 0.50462737404968,
>>                            0.441225469913529, 0.37010584373766,
>> 0.299554326292306, 0.250957120974181,
>>                            0.231147047662909, 0.218081437060998,
>> 0.209354124252359, 0.212236940966109,
>>                            0.213898409405384, 0.200693009702681,
>> 0.189880443626695, 0.175663436717225,
>>                            0.160910269517771, 0.14423774751828,
>> 0.703482475602795, 0.707648742091919,
>>                            0.696092540716741, 0.656540853310246,
>> 0.6051367218461, 0.591695064299013,
>>                            0.596015810648035, 0.603800534715597,
>> 0.630728546677123, 0.658732672149451,
>>                            0.660216960664134, 0.675188962779905,
>> 0.680940355728037, 0.677371529164165,
>>                            0.678862966955137, 0.706307948099043,
>> 0.72103331978575, 0.71201796002067,
>>                            0.695266699409018, 0.685297231486624,
>> 0.661576951062559, 0.643301885602357,
>>                            0.619830526453808, 0.608129873046412,
>> 0.594283830084397, 0.562317115717112,
>>                            0.530350595536459, 0.506782526041746,
>> 0.485311767855001, 0.473335687828819,
>>                            0.47767850215973, 0.47780651839627,
>> 0.703482475602795, 0.708970958906805,
>>                            0.697551150784402, 0.661080016538957,
>> 0.61232038566617, 0.587787379274781,
>>                            0.593431699246192, 0.585207322444761,
>> 0.568559116457046, 0.548048255621954,
>>                            0.530114701694855, 0.534118004338362,
>> 0.551070523651917, 0.575923824458594,
>>                            0.601811119913484, 0.599679943614892,
>> 0.571040665848032, 0.537593347467274,
>>                            0.517448133546794, 0.509401266935977,
>> 0.506839184709813, 0.513795796376072,
>>                            0.538416419444161, 0.54431580354862,
>> 0.533416582151419, 0.536830327067308,
>>                            0.536462655629334, 0.513629165635279,
>> 0.478995218355945, 0.438690505845544,
>>                            0.382567436102273, 0.34023179757446,
>> 0.703482475602795, 0.708469004078862,
>>                            0.697978508894162, 0.676172179276398,
>> 0.653999136795877, 0.621901773418305,
>>                            0.611086726778221, 0.593857278888487,
>> 0.59772372401201, 0.615523307201519,
>>                            0.639972290824288, 0.642201950188424,
>> 0.640462288885887, 0.599634050862654,
>>                            0.556922658075191, 0.51984992524725,
>> 0.500551878868105, 0.481116358620079,
>>                            0.46280476578578, 0.439079916934238,
>> 0.426481043460678, 0.4046073777228,
>>                            0.384894885963074, 0.387418227322783,
>> 0.397735327855843, 0.382421337902373,
>>                            0.364609477937235, 0.351141834403433,
>> 0.326023299419572, 0.298998310511409,
>>                            0.279388702747555, 0.265729633371279,
>> 0.703482475602795, 0.708084110634261,
>>                            0.695308105608089, 0.680512620916581,
>> 0.674409687648891, 0.64479397663385,
>>                            0.611185461407328, 0.574633943767944,
>> 0.531967082066137, 0.509238294683539,
>>                            0.539380037981121, 0.605934156503129,
>> 0.67139250700667, 0.692111261722321,
>>                            0.681033453581129, 0.649259774238939,
>> 0.61340010828123, 0.601868728090964,
>>                            0.626623248125788, 0.630474601620122,
>> 0.632877115180945, 0.622655315896617,
>>                            0.602457206226614, 0.577755838513823,
>> 0.575613491077747, 0.56693811567409,
>>                            0.538199408312755, 0.508731518312269,
>> 0.488361667141151, 0.462965384850233,
>>                            0.438776128537772, 0.433205440295598,
>> 0.703482475602795, 0.708955081210283,
>>                            0.696337276771488, 0.675657944024044,
>> 0.682199731001736, 0.713302322144747,
>>                            0.780735831443758, 0.836330924875064,
>> 0.920042864888473, 0.993749005071184,
>>                            1.09383447176433, 1.13919188883409,
>> 1.17120759930688, 1.20149479327377,
>>                            1.21627978424244, 1.16585978639785,
>> 1.11758399725948, 1.04238685207932,
>>                            0.937208207066276, 0.862384770704829,
>> 0.774099878399983, 0.701556273005073,
>>                            0.670583202198987, 0.686968300073611,
>> 0.732378201300416, 0.820191766252091,
>>                            0.855392362283012, 0.845365464014818,
>> 0.803317719342587, 0.757849795095728,
>>                            0.711624608771727, 0.674398052370244), .Dim 
>> =
>> c(32L, 10L))
>> matplot(testdataset, type = 'l', las = 1, xlab = 'x values',
>>         ylab = 'y values', main = 'title - testdataset')
>> library(ggplot2,RColorBrewer,reshape2)
>> testdataset[ is.na(testdataset) ] <- 0
>> testdataset2 <- melt(testdataset)
>> ggplot(testdataset2, aes(x=Var1,y=factor(value))) +
>>   stat_density(aes(fill=..density..), position="identity") +
>>   scale_fill_gradientn(colours=brewer.pal(n=8, name="PuBuGn"))
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Wed Sep 24 22:58:44 2014
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Wed, 24 Sep 2014 13:58:44 -0700
Subject: [R] ubuntu 14.04
In-Reply-To: <1411585084.59067.YahooMailNeo@web121504.mail.ne1.yahoo.com>
References: <1411585084.59067.YahooMailNeo@web121504.mail.ne1.yahoo.com>
Message-ID: <CACdH2ZakLJN5sJwi=jNObcW=GLFauhTeOqNs84VmA5XqwRFyCw@mail.gmail.com>

As others have noted, it does run.  You might want to have a look at:

    http://cran.r-project.org/bin/linux/ubuntu/README

Following the instructions there will allow you to get (automatically)
an up-to-date version of R.

-- Mike


On Wed, Sep 24, 2014 at 11:58 AM, carol white <wht_crl at yahoo.com> wrote:
> Hi,
> Can R be run on ubuntu 14.04 LTS without problem or is there any incompatibility?
>
> Thanks
>
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Wed Sep 24 23:00:49 2014
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 24 Sep 2014 17:00:49 -0400
Subject: [R] Writing .csv file
Message-ID: <54233104.a71aec0a.226d.0e7d@mx.google.com>

I use the following command to write data to a .csv file:

     write.csv(yxz,file="foo.csv")

And I get the following in the file, with one column appended to the file:

"","fsp","fsec","cincome",
"1",0,3,2.25,...
"2",0,1,2.75,...
"3",1,1,0.625,...

Question: is there a way to avoid the first column? Thanks.


From dmck at u.washington.edu  Wed Sep 24 23:06:31 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 24 Sep 2014 14:06:31 -0700
Subject: [R] Writing .csv file
In-Reply-To: <54233104.a71aec0a.226d.0e7d@mx.google.com>
References: <54233104.a71aec0a.226d.0e7d@mx.google.com>
Message-ID: <C81C2ABF-031B-487C-AD55-096800696B78@u.washington.edu>

I believe you need to specify row.names = FALSE

See the help for write.table()

On Sep 24, 2014, at 2:00 PM, Steven Yen <syen04 at gmail.com> wrote:

> I use the following command to write data to a .csv file:
> 
>    write.csv(yxz,file="foo.csv")
> 
> And I get the following in the file, with one column appended to the file:
> 
> "","fsp","fsec","cincome",
> "1",0,3,2.25,...
> "2",0,1,2.75,...
> "3",1,1,0.625,...
> 
> Question: is there a way to avoid the first column? Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor 
School of Environmental and Forest Sciences 
University of Washington 
 
dmck at uw.edu


From gunter.berton at gene.com  Wed Sep 24 23:08:58 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 24 Sep 2014 14:08:58 -0700
Subject: [R] Writing .csv file
In-Reply-To: <54233104.a71aec0a.226d.0e7d@mx.google.com>
References: <54233104.a71aec0a.226d.0e7d@mx.google.com>
Message-ID: <CACk-te0SEeP0chaSnYAO2dbNYOGjfheZxA+1rCWY3A+znt=DHg@mail.gmail.com>

Read the help docs?

( pay attention to the row.names argument)

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Sep 24, 2014 at 2:00 PM, Steven Yen <syen04 at gmail.com> wrote:
> I use the following command to write data to a .csv file:
>
>     write.csv(yxz,file="foo.csv")
>
> And I get the following in the file, with one column appended to the file:
>
> "","fsp","fsec","cincome",
> "1",0,3,2.25,...
> "2",0,1,2.75,...
> "3",1,1,0.625,...
>
> Question: is there a way to avoid the first column? Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From clint at ecy.wa.gov  Wed Sep 24 23:10:22 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 24 Sep 2014 14:10:22 -0700 (PDT)
Subject: [R] Writing .csv file
In-Reply-To: <54233104.a71aec0a.226d.0e7d@mx.google.com>
References: <54233104.a71aec0a.226d.0e7d@mx.google.com>
Message-ID: <alpine.LRH.2.11.1409241409370.25108@aeolus.ecy.wa.gov>

?write.csv 2nd line of Usage: example

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Wed, 24 Sep 2014, Steven Yen wrote:

> I use the following command to write data to a .csv file:
>
>    write.csv(yxz,file="foo.csv")
>
> And I get the following in the file, with one column appended to the file:
>
> "","fsp","fsec","cincome",
> "1",0,3,2.25,...
> "2",0,1,2.75,...
> "3",1,1,0.625,...
>
> Question: is there a way to avoid the first column? Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From syen04 at gmail.com  Wed Sep 24 23:10:46 2014
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 24 Sep 2014 17:10:46 -0400
Subject: [R] Writing .csv file
In-Reply-To: <C81C2ABF-031B-487C-AD55-096800696B78@u.washington.edu>
References: <54233104.a71aec0a.226d.0e7d@mx.google.com>
	<C81C2ABF-031B-487C-AD55-096800696B78@u.washington.edu>
Message-ID: <54233359.a7d1ec0a.6750.0f05@mx.google.com>

Wonderful. It worked like charms and I love it! Thank you Don.
Steven

At 05:06 PM 9/24/2014, Don McKenzie wrote:
>I believe you need to specify row.names = FALSE
>
>See the help for write.table()
>
>On Sep 24, 2014, at 2:00 PM, Steven Yen <syen04 at gmail.com> wrote:
>
> > I use the following command to write data to a .csv file:
> >
> >    write.csv(yxz,file="foo.csv")
> >
> > And I get the following in the file, with one column appended to the file:
> >
> > "","fsp","fsec","cincome",
> > "1",0,3,2.25,...
> > "2",0,1,2.75,...
> > "3",1,1,0.625,...
> >
> > Question: is there a way to avoid the first column? Thanks.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>Don McKenzie
>Research Ecologist
>Pacific Wildland Fire Sciences Lab
>US Forest Service
>
>Affiliate Professor
>School of Environmental and Forest Sciences
>University of Washington
>
>dmck at uw.edu


From john.archie.mckown at gmail.com  Wed Sep 24 23:13:45 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 24 Sep 2014 16:13:45 -0500
Subject: [R] Writing .csv file
In-Reply-To: <54233104.a71aec0a.226d.0e7d@mx.google.com>
References: <54233104.a71aec0a.226d.0e7d@mx.google.com>
Message-ID: <CAAJSdjhPwusZTgjT2YzKyziw227yxbntfJndiedV1CnSu-uS5w@mail.gmail.com>

On Wed, Sep 24, 2014 at 4:00 PM, Steven Yen <syen04 at gmail.com> wrote:
> I use the following command to write data to a .csv file:
>
>     write.csv(yxz,file="foo.csv")
>
> And I get the following in the file, with one column appended to the file:
>
> "","fsp","fsec","cincome",
> "1",0,3,2.25,...
> "2",0,1,2.75,...
> "3",1,1,0.625,...
>
> Question: is there a way to avoid the first column? Thanks.
>

I'm fairly sure you need:

write.csv(yxz,file="foo.csv",row.names=FALSE);

If you don't want the header row at the top, you might want to try:

write.table(yxz,file="foo.csv",row.names=FALSE,col.names=FALSE,sep=',',qmethod="double");


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From matias at stat.ubc.ca  Wed Sep 24 23:15:13 2014
From: matias at stat.ubc.ca (Matias Salibian-Barrera)
Date: Wed, 24 Sep 2014 14:15:13 -0700
Subject: [R] [RsR]  Median of streaming data
In-Reply-To: <21538.32250.67575.749398@stat.math.ethz.ch>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>	<54226816.700@auckland.ac.nz>
	<21538.32250.67575.749398@stat.math.ethz.ch>
Message-ID: <54233461.9010908@stat.ubc.ca>

Martin,

There's also the work of a former PhD student in our Dept:

http://arxiv.org/pdf/1007.1032.pdf

Matias




On 24/09/2014 1:16 AM, Martin Maechler wrote:
>>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>>      on Wed, 24 Sep 2014 18:43:34 +1200 writes:
>      > On 24/09/14 17:31, Mohan Radhakrishnan wrote:
>      >> Hi,
>      >>
>      >> I have streaming data(1 TB) that can't fit in memory. Is
>      >> there a way for me to find the median of these streaming
>      >> integers assuming I can fit only a small part in memory ?
>      >> This is about the statistical approach to find the median
>      >> of a large number of values when I can inspect only a
>      >> part of them due to memory constraints.
>
>      > You cannot, I'm pretty sure, calculate the median
>      > recursively.  However there are "approximate" recursive
>      > median algorithms which provide an estimate of location
>      > that has the same asymptotic properties as the median.
>
>      > See:
>
>      > * U. Holst, Recursive estimators of location.
>      > Commun. Statist. Theory Meth., vol. 16, 1987,
>      > pp. 2201--2226.
>
>      > and
>
>      > * Murray A. Cameron and T. Rolf Turner, Recursive location
>      > and scale estimators, Commun. Statist. Theory Meth.,
>      > vol. 22, 1993, pp. 2503--2515.
>
> This is really interesting to me, thank you, Rolf!
>
> OTOH,
>
> 1) has your proposal ever been provided in R?
>     I'd be happy to add it to the robustX
>     (http://cran.ch.r-project.org/web/packages/robustX) or even
>     robustbase (http://cran.ch.r-project.org/web/packages/robustbase) package.
>
> 2) Would anybody know of more recent research on the subject?
>     (I quickly "googled around" and found research more geared
>      for the time series situation which is more involved anyway)
>
>     --> Hence CC'ing the experts' list  R-SIG-robust
>
>
> Martin Maechler,  ETH Zurich
>
>
>      > cheers,
>      > Rolf Turner
>
>      > --
>      > Rolf Turner Technical Editor ANZJS
>
> _______________________________________________
> R-SIG-Robust at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-robust


From r.turner at auckland.ac.nz  Wed Sep 24 23:25:57 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 25 Sep 2014 09:25:57 +1200
Subject: [R] Median of streaming data
In-Reply-To: <CAOoXFP-0UPR+KWo71khz4bV5u5r5u-AjqmPo8sAwesjc2+-XhQ@mail.gmail.com>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>	<54226816.700@auckland.ac.nz>	<21538.32250.67575.749398@stat.math.ethz.ch>	<1f0222b00ed54745a80df5e552ecd524@AM3PR05MB545.eurprd05.prod.outlook.com>
	<CAOoXFP-0UPR+KWo71khz4bV5u5r5u-AjqmPo8sAwesjc2+-XhQ@mail.gmail.com>
Message-ID: <542336E5.9060808@auckland.ac.nz>

On 25/09/14 02:55, Mohan Radhakrishnan wrote:
>
> I meant the papers. I hit a paywall. Can we reconstruct the code from
> the papers ?

Shouldn't be too tough; the algorithm (in the Cameron and Turner paper) 
is actually pretty simple.

I intend to code it up again; could not find any trace of the old 
(Splus?) code in my chaotic archives.

Should be able to get it done "real soon now".

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS


From tim at mlhim.org  Thu Sep 25 00:49:16 2014
From: tim at mlhim.org (Timothy W. Cook)
Date: Wed, 24 Sep 2014 19:49:16 -0300
Subject: [R] ubuntu 14.04
In-Reply-To: <1411585084.59067.YahooMailNeo@web121504.mail.ne1.yahoo.com>
References: <1411585084.59067.YahooMailNeo@web121504.mail.ne1.yahoo.com>
Message-ID: <CA+=OU3XR0irFYRJEZi7B7P3TAgxXYf7HMe5N=qW38oLS+8L3-g@mail.gmail.com>

Works great for me.

On Wed, Sep 24, 2014 at 3:58 PM, carol white <wht_crl at yahoo.com> wrote:

> Hi,
> Can R be run on ubuntu 14.04 LTS without problem or is there any
> incompatibility?
>
> Thanks
>
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

============================================
Timothy Cook
LinkedIn Profile:http://www.linkedin.com/in/timothywaynecook
MLHIM http://www.mlhim.org

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Sep 25 01:44:38 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 25 Sep 2014 11:44:38 +1200
Subject: [R] Median of streaming data
In-Reply-To: <21538.32250.67575.749398@stat.math.ethz.ch>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>	<54226816.700@auckland.ac.nz>
	<21538.32250.67575.749398@stat.math.ethz.ch>
Message-ID: <54235766.3070400@auckland.ac.nz>

On 24/09/14 20:16, Martin Maechler wrote:

<SNIP>

> 1) has your proposal ever been provided in R?
>     I'd be happy to add it to the robustX
>     (http://cran.ch.r-project.org/web/packages/robustX) or even
>     robustbase (http://cran.ch.r-project.org/web/packages/robustbase) package.

<SNIP>

I have coded up the algorithm from the Cameron and Turner paper.  Dunno 
if it gives exactly the same results as my (Splus?) code from lo these 
many years ago (the code that is lost in the mists of time), but it 
*seems* to work.

It is not designed to work with actual "streaming" data --- I don't know 
how to do that.  It takes a complete data vector as input.  Someone who 
knows about streaming data should be able to adapt it pretty easily. 
Said he, the proverbial optimist.

The function code and a help file are attached.  These files have had 
their names changed to end in ".txt" so that they will get through the 
mailing list processor without being stripped.  With a bit of luck.

If they *don't* get through, anyone who is interested should contact me 
and I will send them to you "privately".

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
-------------- next part --------------
rlas <- function(y,b=0.2,mfn=function(n){0.1*n^(-0.25)},
                 nstart=30,scon=NULL) {
# Initialize:
y0    <- y[1:nstart]
alpha <- median(y0)
s     <- if(is.null(scon)) mean(abs(y0-alpha)) else scon
mu    <- mfn(nstart)/s
eps   <- s/nstart^b
kount <- sum(abs(alpha-y0) < eps)
g     <- kount/(eps*nstart)
ny    <- length(y)
n     <- nstart+1
locn  <- numeric(ny)
locn[1:(nstart-1)] <- NA
locn[nstart] <- alpha
scale  <- numeric(ny)
scale[1:(nstart-1)] <- NA
scale[nstart] <- s

# Calculate recursively:
while(n <= ny) {
   s     <- if(is.null(scon)) ((n-1)*s + abs(y[n]-alpha))/n else scon
   mu    <- mfn(n)/s
   eye   <- if(abs(alpha - y[n]) < s/n^b) 1 else 0
   g     <- (1-1/n)*g + n^(b-1)*eye/s
   a     <- max(mu,g)
   alpha <- alpha + sign(y[n]-alpha)/(a*n)
   locn[n]  <- alpha
   scale[n] <- s
   n <- n+1
}
list(locn=locn,scale=scale)
}
-------------- next part --------------
\name{rlas}
\alias{rlas}
\title{
  Recursive location and scale.
}
\description{
  Calculate a recursive estimate of location, asymptotically
  equivalent to the median, and a recursive estimate of scale
  equal to the \bold{MEAN} absolute deviation.
}
\usage{
rlas(y, b = 0.2, mfn = function(n){0.1 * n^(-0.25)},
     nstart = 30, scon = NULL)
}
\arguments{
  \item{y}{
  A numeric vector of i.i.d. data whose location and scale
  parameters are to be estimated.
}
  \item{b}{
  A tuning parameter (default value equal to that used by
  Holst, 1987).
}
  \item{mfn}{
  Function of the index of the data which must be positive and
  and tend to 0 as the index tends to infinity.  The default
  function is that used by Holst, 1987.
}
  \item{nstart}{
  Starting values for the algorithm are formed from the first
  \code{nstart} values of \code{y}.
}
  \item{scon}{
  A constant value for the scale parameter \code{s}. If this
  is provided then the algorithm becomes equivalent to the
  algorithm of Holst, 1987.
}
}
\value{
A list with entries
  \item{locn}{The successive recursive estimates of location.  The
  first \code{nstart - 1} of these are \code{NA}.}
  \item{scale}{The successive recursive estimates of scale. If
  \code{scon} is specified these are all equal to \code{scon}.}
}
\references{
Cameron, Murray A. and Turner, T. Rolf (1993). Recursive location and
scale estimators. \emph{Commun. Statist. --- Theory Meth.} \bold{22}
(9) 2503--2515.

Holst, U. (1987). Recursive estimators of location.
\emph{Commun. Statist. --- Theory Meth.} \bold{16} (8) 2201--2226.
}
\author{
 \email{r.turner at auckland.ac.nz}
 \url{http://www.stat.auckland.ac.nz/~rolf}
}
\examples{
set.seed(42)
y  <- rnorm(10000)
z1 <- rlas(y)
z2 <- rlas(y,scon=1)
z3 <- rlas(y,scon=100)
OP <- par(mfrow=c(3,1))
plot(z1$locn,type="l")
abline(h=median(y),col="red")
plot(z2$locn,type="l")
abline(h=median(y),col="red")
plot(z3$locn,type="l")
abline(h=median(y),col="red")
par(OP)
}
}
\keyword{ univar }
\keyword{ robust }

From flaviomargarito at gmail.com  Thu Sep 25 02:37:02 2014
From: flaviomargarito at gmail.com (Flavio Barros)
Date: Wed, 24 Sep 2014 21:37:02 -0300
Subject: [R] Text Mining in Non English Speaking Countries
In-Reply-To: <465A7684C5F43E4E9F45258F01964E6F0131A06454@ktnapxch101.kt.group.local>
References: <465A7684C5F43E4E9F45258F01964E6F0131A06454@ktnapxch101.kt.group.local>
Message-ID: <CAOKagtOLfOe4h-Z-8rxzz+qFhH6swycKAy6n_Vor++LA5Y0RTQ@mail.gmail.com>

I used already with portuguese. No problems.


Flavio Barros

www.flaviobarros.net
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.flaviobarros.net&sn=>
[image: Facebook]
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.facebook.com%2Fflavio.barros.1650%3Fref%3Dtn_tnmn&sn=>
[image:
LinkedIn]
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.linkedin.com%2Fprofile%2Fview%3Fid%3D61839390%26trk%3Dtab_pro&sn=>
[image:
about.me]
<http://s.wisestamp.com/links?url=http%3A%2F%2Fabout.me%2Fflavio_barros&sn=>
Contact me: [image: Google Talk] flaviomargarito at gmail.com
?"We are not victims by nature...we are programmed to be victims...for good
reason...if we truly embraced our power, we would never be controlled. Live
WISE~" - Gail Blackman
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.quotesdaddy.com%2Fquote%2F1403644%2Fgail-blackman%2Fwe-are-not-victims-by-naturewe-are-programmed-to-be&sn=>
?  Get this email app!
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.wisestamp.com%2Fapps%2Fquotes%3Futm_source%3Dextension%26utm_medium%3Demail%26utm_term%3Dquotes%26utm_campaign%3Dapps&sn=>

[image: WordPress Blog Posts]
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.flaviobarros.net&sn=>My
latest post:Data Preparation ? Part II
<http://s.wisestamp.com/links?url=http%3A%2F%2Ffeedproxy.google.com%2F~r%2FFlavioBarros%2F~3%2F9MTu1M40mhE%2F&sn=>
Read more
<http://s.wisestamp.com/links?url=http%3A%2F%2Ffeedproxy.google.com%2F~r%2FFlavioBarros%2F~3%2F9MTu1M40mhE%2F&sn=>
| My blog
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.flaviobarros.net&sn=>
[image: Share on Facebook]
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.facebook.com%2Fsharer.php%3Fu%3Dhttp%253A%252F%252Ffeedproxy.google.com%252F~r%252FFlavioBarros%252F~3%252F9MTu1M40mhE%252F&sn=>
[image:
Share on Twitter]
<http://s.wisestamp.com/links?url=https%3A%2F%2Ftwitter.com%2Fintent%2Ftweet%3Ftext%3DData%2520Preparation%2520%25E2%2580%2593%2520Part%2520II%2520%2520(via%2520%2540wisestamp)&sn=>
  Get this email app!
<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.wisestamp.com%2Fapps%2Fwordpress%3Futm_source%3Dextension%26utm_medium%3Demail%26utm_term%3Dwordpress%26utm_campaign%3Dapps&sn=>


<http://s.wisestamp.com/links?url=http%3A%2F%2Fwww.linkedin.com%2Fin%2F&sn=>
 Create your free signature:
<http://s.wisestamp.com/links?url=http%3A%2F%2Fr1.wisestamp.com%2Fr%2Flanding%3Fpromo%3D33%26dest%3Dhttp%253A%252F%252Fwww.wisestamp.com%252Femail-install%253Futm_source%253Dextension%2526utm_medium%253Demail%2526utm_campaign%253Dpromo_33&sn=>
CLICK
HERE!
<http://s.wisestamp.com/links?url=http%3A%2F%2Fr1.wisestamp.com%2Fr%2Flanding%3Fpromo%3D33%26amp%3Bdest%3Dhttp%253A%252F%252Fwww.wisestamp.com%252Femail-install%253Futm_source%253Dextension%2526utm_medium%253Demail%2526utm_campaign%253Dpromo_33&sn=>
?

On Wed, Sep 24, 2014 at 8:30 AM, <ziad.elmously at tnsglobal.com> wrote:

> Hello All,
>
> I am interested in conducting text mining in languages other English.  My
> understanding is the following R packages can analyze alternative (to
> English) languages:
>
>
> 1.       "topicmodels"
>
> 2.       "snowball"
>
> 3.       "tm"
>
> Can anyone confirm?  Specifically, I am interested in Hindi and Chinese (2
> or so most popular dialects).  If so, can you recommend relevant
> documentation and share your experiences with these packages.
>
> Thank you in advance.
>
> Ziad Elmously
>
>
>
>
>
> http://www.kantar.com/disclaimer.html
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From radhakrishnan.mohan at gmail.com  Thu Sep 25 11:00:29 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Thu, 25 Sep 2014 14:30:29 +0530
Subject: [R] Agreement accuracy
Message-ID: <CAOoXFP_s2M8beMafMAQ-KHccWj1EekmkBVRj8wBr0s=1Sj3nbA@mail.gmail.com>

Hi,

I have trained my data using two models(gbm and rf). I get the accuracies
shown below.

How does one get the aggreement accuracy%  ? Is that the comparison of the
two confusion matrices ?




Confusion Matrix and Statistics


          Reference

Prediction  1  2  3  4  5  6  7  8  9 10 11

        1  33  1  0  0  0  0  0  0  0  0  0

        2  13 17  4  0  0  0  0  0  0  0  0

        3   0  3 25  3  0  0  0  0  0  0  3

        4   0  0  0 29  0  5  0  0  0  0  0

        5   0  0  0  0 18  4 10  0  0  0  2

        6   0  0  0  7  2 16  3  0  0  0  6

        7   0  0  3  1  1  0 26  3  0  0  0

        8   0  0  0  0  0  0  2 25  3  4  0

        9   0  0  0  0  0  0  2  1 21 10  0

        10  0  0  0  0  0  0  1  0  9 24  0

        11  0  0  0  0  2  4  0  0  2  0 26


Overall Statistics



               Accuracy : 0.6952

--------------------------------------------------------------------------------------------------

Confusion Matrix and Statistics


          Reference

Prediction  1  2  3  4  5  6  7  8  9 10 11

        1  34  0  0  0  0  0  0  0  0  0  0

        2   9 19  6  0  0  0  0  0  0  0  0

        3   0  1 33  0  0  0  0  0  0  0  0

        4   0  0  0 30  0  4  0  0  0  0  0

        5   0  0  0  0 21  4  8  0  0  0  1

        6   0  0  0  6  3 22  0  0  0  0  3

        7   0  0  3  0  1  0 24  5  1  0  0

        8   0  0  0  0  0  0  1 32  1  0  0

        9   0  0  0  0  0  0  0  0 25  9  0

        10  0  0  0  0  0  0  1  0  8 25  0

        11  0  0  0  0  0  0  0  0  2  0 32


Overall Statistics



               Accuracy : 0.7941

Thanks,
Mohan

	[[alternative HTML version deleted]]


From christian.kamenik at astra.admin.ch  Thu Sep 25 11:45:56 2014
From: christian.kamenik at astra.admin.ch (christian.kamenik at astra.admin.ch)
Date: Thu, 25 Sep 2014 09:45:56 +0000
Subject: [R] subset ffdf does not accept bit vector anymore (package ffbase)
Message-ID: <F3DDE626408063448975429A27B423DC45744C9E@sb00111a.adb.intra.admin.ch>

Hi everyone

Since I updated package 'ffbase', subset.ffdf does not work with bit vectors anymore. Here is a short example:

data(iris)

library(ffbase)
iris.ffdf <- as.ffdf(iris)
index <- sample(c(FALSE,TRUE), nrow(iris), TRUE)
index.bit <- as.bit(index)

subset(iris.ffdf, subset=index.bit)

results in the error message:
Error in which(eval(e, nl, envir)) : argument to 'which' is not logical


My code was working prior to the update...
and help on subset.ffdf sais:

subset:             an expression, ri, bit or logical ff vector that can be used to index x

Any help would be highly appreciated.

Many thanks
Christian



> R.Version()



$platform

[1] "i386-w64-mingw32"



$arch

[1] "i386"



$os

[1] "mingw32"



$system

[1] "i386, mingw32"



$status

[1] ""



$major

[1] "3"



$minor

[1] "1.1"



$year

[1] "2014"



$month

[1] "07"



$day

[1] "10"



$`svn rev`

[1] "66115"



$language

[1] "R"



$version.string

[1] "R version 3.1.1 (2014-07-10)"



$nickname

[1] "Sock it to Me"



> sessionInfo()



R version 3.1.1 (2014-07-10)

Platform: i386-w64-mingw32/i386 (32-bit)



locale:

[1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252    LC_MONETARY=German_Switzerland.1252

[4] LC_NUMERIC=C                        LC_TIME=German_Switzerland.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



other attached packages:

[1] stringr_0.6.2 ffbase_0.11.3 ff_2.2-13     bit_1.1-12    track_1.0-15



loaded via a namespace (and not attached):

[1] fastmatch_1.0-4 tools_3.1.1



	[[alternative HTML version deleted]]


From btyner at gmail.com  Thu Sep 25 12:48:07 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Thu, 25 Sep 2014 06:48:07 -0400
Subject: [R] scaling of Amat still recommended for quadprog::solve.QP ?
Message-ID: <5423F2E7.9080802@gmail.com>

Greetings,

I ran across this recommendation, to keep the norms of the columns of
the Amat on similar
scales,

    https://stat.ethz.ch/pipermail/r-help/2007-September/141335.html

However, when I looked at the code, I noticed that the norms are already
being calculated:

    c
    c calculate the norm of each column of the A matrix
    c
          do 51 i=1,q
             sum = 0.d0
             do 52 j=1,n
                sum = sum + amat(j,i)*amat(j,i)
     52      continue
             work(iwnbv+i) = sqrt(sum)
     51   continue
          nact = 0
          iter(1) = 0
          iter(2) = 0
     50   continue

though I am not sure exactly how these norms get used subsequently. My
question is, is it no longer necessary to follow Berwin's recommendation
from 2007? Or are the norms being calculated for some other purpose, and
the recommendation still applies?

Regards
Ben


From jim at bitwrit.com.au  Thu Sep 25 13:59:49 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 25 Sep 2014 21:59:49 +1000
Subject: [R] Help with continuous color plot
In-Reply-To: <42007e5e2608fa4bbecc5de73659da28@considine.net>
References: <d55b8014c88a6e07d24819b9e57b50d9@considine.net>
	<CAE8W1T0OjtKkcrvTUzcnhPkmNBuhmo9waaW3TOVU9JFp=uR9Rg@mail.gmail.com>
	<42007e5e2608fa4bbecc5de73659da28@considine.net>
Message-ID: <7240551.FOMUQQffIV@localhost.localdomain>

On Wed, 24 Sep 2014 02:36:58 PM matt at considine.net wrote:
> No, I don't think so.  And I've wondered if I described the problem
> clearly, so I put together the following hack, which seems to be what 
I
> want :
> 
> #create a matrix to hold the values corresponding to various 
percentiles
> vals<-matrix(0,32,21)
> #for each row in the data, collect info on the distribution
> for(i in 1:32){
>    obs <- testdataset[i,]
>    vals[i,] <- quantile(obs, probs=seq(0,1,0.05))
> }
> 
> #pick the last observation to get a distrbution of colors
> cols <- sort(densCols(vals[32,]))
> 
> #set up a blank plot
> matplot(vals, type="n", xlab = 'yrs', ylab = 'Ratio',
>          main = 'Projected ratios')
> 
> #plot confidence bands as polygons, ideally overlaying light to dark
> for (i in 1:10){
>    lines(vals[,i],col=cols[22-i])
>    lines(vals[,22-i],col=cols[22-i])
> 
> polygon(c(seq(1:32),rev(seq(1:32))),c(vals[,22-
i],rev(vals[,i])),col=cols[22
> -i],border="NA") }
> 
> #plot a line for the average case
> lines(vals[,11],col="black")
> 
> If anyone can suggest a more efficient/effective/better/etc/etc way 
of
> doing this, I'd be grateful.  In a nutshell, I am trying to find a
> visually clean way of showing the output of a Monte Carlo analysis.
> 
> Thanks again for everyone's attention.
> Matt
> 
Hi Matt,
That is probably as good a method as any. You could wrap it up as a 
function if you want to do a lot of these. You might want to try 
something like:

library(plotrix)
cols <- color.scale(1:10,extremes=c("green","blue"))

and then use cols[i] for your lines and polygons - it looks better to me.

Jim


From radhakrishnan.mohan at gmail.com  Thu Sep 25 16:50:01 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Thu, 25 Sep 2014 20:20:01 +0530
Subject: [R] Agreement accuracy
In-Reply-To: <CAOoXFP_s2M8beMafMAQ-KHccWj1EekmkBVRj8wBr0s=1Sj3nbA@mail.gmail.com>
References: <CAOoXFP_s2M8beMafMAQ-KHccWj1EekmkBVRj8wBr0s=1Sj3nbA@mail.gmail.com>
Message-ID: <CAOoXFP9rF3obRE5xZdqppr-aZN0jJ-vhrzXwgbC+MgpSXSMeOA@mail.gmail.com>

I am also wondering how the Accuracy reported by the confusion matrix for
gbm and rf could vary with the type of machines. The seed is the same. What
other factors could affect the accuracy ? library is caret.

Thanks,
Mohan

On Thu, Sep 25, 2014 at 2:30 PM, Mohan Radhakrishnan <
radhakrishnan.mohan at gmail.com> wrote:

> Hi,
>
> I have trained my data using two models(gbm and rf). I get the accuracies
> shown below.
>
> How does one get the aggreement accuracy%  ? Is that the comparison of the
> two confusion matrices ?
>
>
>
>
> Confusion Matrix and Statistics
>
>
>           Reference
>
> Prediction  1  2  3  4  5  6  7  8  9 10 11
>
>         1  33  1  0  0  0  0  0  0  0  0  0
>
>         2  13 17  4  0  0  0  0  0  0  0  0
>
>         3   0  3 25  3  0  0  0  0  0  0  3
>
>         4   0  0  0 29  0  5  0  0  0  0  0
>
>         5   0  0  0  0 18  4 10  0  0  0  2
>
>         6   0  0  0  7  2 16  3  0  0  0  6
>
>         7   0  0  3  1  1  0 26  3  0  0  0
>
>         8   0  0  0  0  0  0  2 25  3  4  0
>
>         9   0  0  0  0  0  0  2  1 21 10  0
>
>         10  0  0  0  0  0  0  1  0  9 24  0
>
>         11  0  0  0  0  2  4  0  0  2  0 26
>
>
> Overall Statistics
>
>
>
>                Accuracy : 0.6952
>
>
> --------------------------------------------------------------------------------------------------
>
> Confusion Matrix and Statistics
>
>
>           Reference
>
> Prediction  1  2  3  4  5  6  7  8  9 10 11
>
>         1  34  0  0  0  0  0  0  0  0  0  0
>
>         2   9 19  6  0  0  0  0  0  0  0  0
>
>         3   0  1 33  0  0  0  0  0  0  0  0
>
>         4   0  0  0 30  0  4  0  0  0  0  0
>
>         5   0  0  0  0 21  4  8  0  0  0  1
>
>         6   0  0  0  6  3 22  0  0  0  0  3
>
>         7   0  0  3  0  1  0 24  5  1  0  0
>
>         8   0  0  0  0  0  0  1 32  1  0  0
>
>         9   0  0  0  0  0  0  0  0 25  9  0
>
>         10  0  0  0  0  0  0  1  0  8 25  0
>
>         11  0  0  0  0  0  0  0  0  2  0 32
>
>
> Overall Statistics
>
>
>
>                Accuracy : 0.7941
>
> Thanks,
> Mohan
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Sep 25 16:53:17 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 25 Sep 2014 14:53:17 +0000
Subject: [R] Masked from package
In-Reply-To: <alpine.LNX.2.11.1409241120200.29487@localhost>
References: <alpine.LNX.2.11.1409241120200.29487@localhost>
Message-ID: <D0497920.10CBBE%macqueen1@llnl.gov>

And to answer the ?What do I read ...?? question

  help.search('masked?)

returns quite a few things on my system, and the one you want is

  base::conflicts         Search for Masked Objects on the Search Path

Then of course
  ?conflicts

Also, having seen those messages, you can do
  find(?norm?)
  find(?cor?)

-Don  


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/24/14, 11:22 AM, "Rich Shepard" <rshepard at appl-ecosys.com> wrote:

>   When a library is loaded messages such as these are displayed:
>
>The following object is masked from ?package:base?:
>
>     norm
>
>The following object is masked from ?package:NADA?:
>
>     cor
>
>   What do I read to understand just what being masked means?
>
>Rich
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Thu Sep 25 17:06:24 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 25 Sep 2014 10:06:24 -0500
Subject: [R] error in rownames
In-Reply-To: <CAPtX2q=siOx6FQT9s3mNbcGcppMNv4OjmAnU7btT48u6WYppWw@mail.gmail.com>
References: <CAPtX2q=siOx6FQT9s3mNbcGcppMNv4OjmAnU7btT48u6WYppWw@mail.gmail.com>
Message-ID: <CAN5YmCEZPPRqucCTchb_8+v+_as-MCzJj4dd_Sn=URcSYwcbKA@mail.gmail.com>

Chris,

You are not making it easy for R help folks to help you.

You need to supply *** reproducible *** code, so that folks can simply copy
and paste directly from your e-mail to R and reproduce the error that you
are getting.  Do you need a guide to follow?  See the first 60-some lines
of code provided in the example of the help for AsciiGridImpute,
     ?AsciiGridImpute
I can copy that code into R and make it run.  You need to do the same thing
in your e-mail.  Don't refer to directories on your PC.

I submitted a simplified version of the code you shared (below), but ran
into an error because the *.asc files were not already created.  So, I
suggest that you insert some general code to get that done for your
example, and resubmit your question.

Jean


training <- structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
-0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
-0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
-0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect = c(0.915474,
-0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
-0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
-0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
-0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
516073.554503, 516019.068701, 515506.165434, 517353.141738, 520076.487742,
517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
515714.490202, 518829.909017, 519385.491579, 518659.851297, 516654.780318,
519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912, 4818923.42436,
4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774, 4814503.57051,
4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
"elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
"ResponseSu"), row.names = c(NA, 20L), class = "data.frame")

library(yaImpute)

y <- subset(training, select = c(ResponseSu))
x <- subset(training, select = c(sinaspect, habitat, elevation, disttowat,
disttoroad, slope, cosaspect))
type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression",
ntree=20)
outfile <- list(Type="RespSurf_Reg.asc")
xfile <-list(sinaspect="sinaspect.asc", habitat="habitat.asc",
elevation="elevation.asc",
disttowat="disttowat.asc", disttoroad="disttoroad.asc", slope="slope.asc",
cosaspect="cosaspect.asc")

# insert lines of code here to create the *.asc files
# see the example with the iris data in ?AsciiGridImpute

AsciiGridImpute(type.rf, xfile, outfile)


On Mon, Sep 22, 2014 at 11:13 AM, Chris Jackson-Jordan <
jacksonjordancm at gmail.com> wrote:

> Dear fellow R users,
>
> I am trying to run the random forest and Yaimpute packages in R to
> impute a grid to project in a gis. However, after running the
> imputation I keep getting an error in the rownames. This sounds simple
> enough, but I cannot figure out what these rownames are reffering to.
> Any ideas? I am fairly new to R so im sure it is an easy fix. Any help
> would be awesome.
>
> Thanks,
>
> Chris
>
>
> > y <- subset(training, select = c(ResponseSu)) > x <- subset(training,
> select = c(sinaspect, habitat, slope, elevation, cosaspect, disttoroad,
> disttowat)) > type.rf <- yai(x=x, y=y, method="randomForest",
> rfMode="regression", ntree= 2000) > outfile <- list(Type =
> "D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc") > xfile <-list(sinaspect
>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/sinaspect.asc",
> habitat
>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/habitat.asc",
> elevation
>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/elevation.asc",
> disttowat
>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttowat.asc",
> disttoroad
>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttoroad.asc",
> slope
>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/slope.asc",
> cosaspect
>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/cosaspect.asc")
> > AsciiGridImpute(type.rf, xfile, outfile) Rows per dot: 19 Rows to do:
> 1900 ToDo:
>
> ....................................................................................................
> Done: . Error in `rownames<-`(`*tmp*`, value = c("23x0049", "23x0050",
> "23x0051", : attempt to set rownames on object with no dimensions
>
> here is an example of my training data
>
>
>  > dput(training[1:20, ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect = c(0.915474,
> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
> 516073.554503, 516019.068701, 515506.165434, 517353.141738, 520076.487742,
> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
> 515714.490202, 518829.909017, 519385.491579, 518659.851297, 516654.780318,
> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912, 4818923.42436,
> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774, 4814503.57051,
> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")>
> library("randomForest", lib.loc="~/RStudio/R/library")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Thu Sep 25 17:19:14 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 25 Sep 2014 08:19:14 -0700 (PDT)
Subject: [R] Masked from package
In-Reply-To: <D0497920.10CBBE%macqueen1@llnl.gov>
References: <alpine.LNX.2.11.1409241120200.29487@localhost>
	<D0497920.10CBBE%macqueen1@llnl.gov>
Message-ID: <alpine.LNX.2.11.1409250814410.12417@localhost>

On Thu, 25 Sep 2014, MacQueen, Don wrote:

> And to answer the ?What do I read ...?? question
>  help.search('masked?)
> returns quite a few things on my system, and the one you want is

Don, et al.:

   Further research led me to re-read the beginning of "Analyzing
Compositional Data with R" where the authors describe the masking as
analgous (my interpretation) to instatiating an object as in Python or
wxPython. With the package compositions, there are functions with the same
name as functions in other packages. The compositions package extends
functionality and implies that the parent functionality is inherited, not
replaced.

   Perhaps this is the norm for all R packages.

Thanks very much to all,

Rich


From jdnewmil at dcn.davis.CA.us  Thu Sep 25 17:46:55 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 25 Sep 2014 08:46:55 -0700
Subject: [R] Masked from package
In-Reply-To: <alpine.LNX.2.11.1409250814410.12417@localhost>
References: <alpine.LNX.2.11.1409241120200.29487@localhost>
	<D0497920.10CBBE%macqueen1@llnl.gov>
	<alpine.LNX.2.11.1409250814410.12417@localhost>
Message-ID: <452d9f0a-a75b-4bb9-9ecc-97b07001cd25@email.android.com>

No, masking does not imply inheritance. Simply that "foo" now refers to a different function, so you have to use "oldpkg::foo" if you want to get at the old function from your normal working environment.

Note that packages that call "foo" will continue to find the versions they intended to call if they are constructed correctly.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 25, 2014 8:19:14 AM PDT, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>On Thu, 25 Sep 2014, MacQueen, Don wrote:
>
>> And to answer the ?What do I read ...?? question
>>  help.search('masked?)
>> returns quite a few things on my system, and the one you want is
>
>Don, et al.:
>
>   Further research led me to re-read the beginning of "Analyzing
>Compositional Data with R" where the authors describe the masking as
>analgous (my interpretation) to instatiating an object as in Python or
>wxPython. With the package compositions, there are functions with the
>same
>name as functions in other packages. The compositions package extends
>functionality and implies that the parent functionality is inherited,
>not
>replaced.
>
>   Perhaps this is the norm for all R packages.
>
>Thanks very much to all,
>
>Rich
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jacksonjordancm at gmail.com  Thu Sep 25 17:51:35 2014
From: jacksonjordancm at gmail.com (Chris Jackson-Jordan)
Date: Thu, 25 Sep 2014 11:51:35 -0400
Subject: [R] error in rownames
In-Reply-To: <CAN5YmCEZPPRqucCTchb_8+v+_as-MCzJj4dd_Sn=URcSYwcbKA@mail.gmail.com>
References: <CAPtX2q=siOx6FQT9s3mNbcGcppMNv4OjmAnU7btT48u6WYppWw@mail.gmail.com>
	<CAN5YmCEZPPRqucCTchb_8+v+_as-MCzJj4dd_Sn=URcSYwcbKA@mail.gmail.com>
Message-ID: <CAPtX2qkXCOfxrR2GdGKxVGi9ythq0-hCrWWQE1oNJesmTrPxXw@mail.gmail.com>

Thanks again for your help, I am obviously a novice programmer. That said,
I think I am confused as to what you mean by reproducible code. Were the 20
lines of code not reproducible? Also, what do you mean by the help for
Ascii Grid Impute. I'm not able to find it online or within the R platform.
Finally, I know that mapping to files on my PC is problematic, should I be
attaching the files in my email? Like I said, this is all quite new to me.
Sorry if my questions are painfully naive. I am hoping to get this project
going but just can't get past this stumbling block. Thanks again for the
help thus far.

Chris

On Thu, Sep 25, 2014 at 11:06 AM, Adams, Jean <jvadams at usgs.gov> wrote:

> Chris,
>
> You are not making it easy for R help folks to help you.
>
> You need to supply *** reproducible *** code, so that folks can simply
> copy and paste directly from your e-mail to R and reproduce the error that
> you are getting.  Do you need a guide to follow?  See the first 60-some
> lines of code provided in the example of the help for AsciiGridImpute,
>      ?AsciiGridImpute
> I can copy that code into R and make it run.  You need to do the same
> thing in your e-mail.  Don't refer to directories on your PC.
>
> I submitted a simplified version of the code you shared (below), but ran
> into an error because the *.asc files were not already created.  So, I
> suggest that you insert some general code to get that done for your
> example, and resubmit your question.
>
> Jean
>
>
> training <- structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect = c(0.915474,
> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
> 516073.554503, 516019.068701, 515506.165434, 517353.141738, 520076.487742,
> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
> 515714.490202, 518829.909017, 519385.491579, 518659.851297, 516654.780318,
> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912, 4818923.42436,
> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774, 4814503.57051,
> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")
>
> library(yaImpute)
>
> y <- subset(training, select = c(ResponseSu))
> x <- subset(training, select = c(sinaspect, habitat, elevation, disttowat,
> disttoroad, slope, cosaspect))
> type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression",
> ntree=20)
> outfile <- list(Type="RespSurf_Reg.asc")
> xfile <-list(sinaspect="sinaspect.asc", habitat="habitat.asc",
> elevation="elevation.asc",
> disttowat="disttowat.asc", disttoroad="disttoroad.asc", slope="slope.asc",
> cosaspect="cosaspect.asc")
>
> # insert lines of code here to create the *.asc files
> # see the example with the iris data in ?AsciiGridImpute
>
> AsciiGridImpute(type.rf, xfile, outfile)
>
>
> On Mon, Sep 22, 2014 at 11:13 AM, Chris Jackson-Jordan <
> jacksonjordancm at gmail.com> wrote:
>
>> Dear fellow R users,
>>
>> I am trying to run the random forest and Yaimpute packages in R to
>> impute a grid to project in a gis. However, after running the
>> imputation I keep getting an error in the rownames. This sounds simple
>> enough, but I cannot figure out what these rownames are reffering to.
>> Any ideas? I am fairly new to R so im sure it is an easy fix. Any help
>> would be awesome.
>>
>> Thanks,
>>
>> Chris
>>
>>
>> > y <- subset(training, select = c(ResponseSu)) > x <- subset(training,
>> select = c(sinaspect, habitat, slope, elevation, cosaspect, disttoroad,
>> disttowat)) > type.rf <- yai(x=x, y=y, method="randomForest",
>> rfMode="regression", ntree= 2000) > outfile <- list(Type =
>> "D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc") > xfile <-list(sinaspect
>>
>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/sinaspect.asc",
>> habitat
>>
>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/habitat.asc",
>> elevation
>>
>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/elevation.asc",
>> disttowat
>>
>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttowat.asc",
>> disttoroad
>>
>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttoroad.asc",
>> slope
>>
>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/slope.asc",
>> cosaspect
>>
>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/cosaspect.asc")
>> > AsciiGridImpute(type.rf, xfile, outfile) Rows per dot: 19 Rows to do:
>> 1900 ToDo:
>>
>> ....................................................................................................
>> Done: . Error in `rownames<-`(`*tmp*`, value = c("23x0049", "23x0050",
>> "23x0051", : attempt to set rownames on object with no dimensions
>>
>> here is an example of my training data
>>
>>
>>  > dput(training[1:20, ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
>>
>> 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
>> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
>> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
>> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
>> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
>> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
>> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
>> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
>> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
>> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
>> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
>> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
>> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
>> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
>> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect = c(0.915474,
>> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
>> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
>> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
>> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
>> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
>> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
>> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
>> 516073.554503, 516019.068701, 515506.165434, 517353.141738, 520076.487742,
>> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
>> 515714.490202, 518829.909017, 519385.491579, 518659.851297, 516654.780318,
>> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
>> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912, 4818923.42436,
>> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
>> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774, 4814503.57051,
>> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
>> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
>> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
>> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
>> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
>> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
>> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")>
>> library("randomForest", lib.loc="~/RStudio/R/library")
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jacksonjordancm at gmail.com  Thu Sep 25 17:57:25 2014
From: jacksonjordancm at gmail.com (Chris Jackson-Jordan)
Date: Thu, 25 Sep 2014 11:57:25 -0400
Subject: [R] error in rownames
In-Reply-To: <CAPtX2qkXCOfxrR2GdGKxVGi9ythq0-hCrWWQE1oNJesmTrPxXw@mail.gmail.com>
References: <CAPtX2q=siOx6FQT9s3mNbcGcppMNv4OjmAnU7btT48u6WYppWw@mail.gmail.com>
	<CAN5YmCEZPPRqucCTchb_8+v+_as-MCzJj4dd_Sn=URcSYwcbKA@mail.gmail.com>
	<CAPtX2qkXCOfxrR2GdGKxVGi9ythq0-hCrWWQE1oNJesmTrPxXw@mail.gmail.com>
Message-ID: <CAPtX2qnenxyQOFUEHWS9aJbZJMVcbDfODhunDwO+F4_bQMJvuA@mail.gmail.com>

Sorry to respond again so quickly, but is this what you meant?


y <- subset(training, select = c(ResponseSu))> x <- subset(training,
select = c(sinaspect, habitat, elevation, disttowat, disttoroad,
slope, cosaspect))> type.rf <- yai(x=x, y=y, method="randomForest",
rfMode="regression", ntree=20)> outfile <-
list(Type="RespSurf_Reg.asc")> xfile <-list(sinaspect="sinaspect.asc",
habitat="habitat.asc", elevation="elevation.asc",+
disttowat="disttowat.asc", disttoroad="disttoroad.asc",
slope="slope.asc",+ cosaspect="cosaspect.asc")> dput(training[1:60,
])structure(list(CID = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L), cosaspect = c(-0.546873, 0.333357, 0.796074, -0.906097,
0.546751, -0.903426, 0.55381, 0.761338, 0.858955, -0.784384,
0.790582, 0.0429794, 0.89785, 0.998368, 0.991524, -0.769041,
-0.104549, -0.565003, -0.56414, 0.432783, -0.652663, -0.477157,
-0.642625, 0.0719997, 0.0202113, -0.444488, -0.38204, -0.3565,
-0.199093, 0.545715, -0.99322, 0.852507, -0.524166, 0.999378,
-0.980175, -0.922242, -0.954118, -0.902187, -0.354786, 0.112082,
-0.198151, -0.502453, -0.676458, -0.0673507, -0.999526, -0.840507,
0.989883, -0.832413, -0.733279, -0.993005, -0.479475, -0.326237,
-0.848538, -0.546614, -0.986488, -0.948983, -0.993527, -0.964193,
-0.971359, -0.287455), disttoroad = c(368.767, 880.661, 563.239,
72.1515, 227.697, 313.486, 265.001, 227.697, 219.137, 518.349,
23.048, 10.3074, 41.2294, 103.074, 497.857, 494.968, 524.968,
674.01, 10.3074, 133.996, 10.3074, 10.3074, 10.3074, 20.6147,
226.058, 10.3074, 272.122, 226.762, 177.933, 204.075, 82.4589,
61.8442, 14.5768, 20.6147, 29.1536, 92.1918, 75.0387, 113.849,
133.996, 46.0959, 123.688, 120.645, 185.533, 133.996, 61.8442,
103.074, 120.203, 154.61, 138.671, 150.077, 51.5368, 190.058,
72.884, 20.6147, 115.24, 30.9221, 83.1006, 333.041, 30.9221,
288.606), disttowat = c(981.15, 1448.98, 729.496, 509.146, 171.549,
322.671, 566.998, 631.783, 783.359, 407.76, 1036.59, 352.264,
306.113, 235.27, 241.289, 269.769, 342.633, 660.476, 578.04,
1844.99, 1753.65, 408.801, 543.951, 756.661, 632.875, 540.031,
927.09, 1120.47, 1166.24, 65.9993, 474.586, 437.911, 162.974,
576.66, 557.932, 547.844, 793.667, 420.586, 208.708, 10.3074,
497.857, 383.595, 371.78, 130.379, 449.406, 111.014, 162.974,
393.574, 463.831, 360.021, 404.096, 43.7304, 140.195, 182.647,
277.343, 84.9967, 87.4609, 633.546, 60.1017, 42.4983), elevation = c(2000.9,
2198.18, 2194.78, 1863.8, 1902.25, 1867.29, 1943.94, 1912.35,
1920.11, 1870.94, 1914.56, 1904.4, 1900.92, 1893.94, 1888.02,
1889.71, 1890.95, 1894.32, 1896.11, 2011.99, 2025.01, 1902.45,
1901.99, 2030.09, 2038.39, 1910.48, 2054.46, 1918.92, 1951.15,
1941.24, 1853.78, 1863.76, 1875.9, 1863.6, 1864.91, 1864.18,
1872.85, 1866.81, 1863.06, 1896.47, 1863.95, 1873.13, 1873.44,
1888.06, 1874.35, 1888.06, 1911.09, 1872.43, 1854.83, 1866.98,
1876.95, 1875.88, 1875.19, 1888.27, 1900.82, 1870.49, 1903.17,
1871.52, 1902.28, 1862.18), habitat = c(14L, 1L, 9L, 2L, 5L,
2L, 5L, 1L, 1L, 2L, 1L, 4L, 10L, 8L, 2L, 2L, 2L, 2L, 4L, 10L,
5L, 4L, 4L, 3L, 5L, 4L, 3L, 3L, 7L, 6L, 2L, 2L, 2L, 13L, 2L,
2L, 2L, 2L, 2L, 11L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 10L, 2L, 2L, 2L, 2L, 2L), sinaspect = c(-0.837215,
-0.942801, -0.6052, 0.42307, -0.837295, -0.428745, -0.832643,
-0.648355, -0.512051, -0.620276, -0.612357, -0.999076, -0.440302,
-0.0571153, 0.129924, -0.6392, -0.99452, -0.825089, 0.825679,
-0.901498, -0.757648, 0.878818, 0.766181, -0.997405, -0.999796,
0.895785, 0.924146, 0.934295, 0.979981, -0.837971, 0.11625, -0.522717,
-0.851616, -0.0352723, 0.198133, -0.386614, -0.29943, -0.431345,
-0.934948, -0.993699, -0.980172, -0.864605, -0.736481, 0.997729,
-0.0307994, -0.541801, 0.141883, -0.554156, 0.679928, 0.118074,
-0.877556, -0.945288, -0.529134, -0.837385, -0.163837, -0.315329,
-0.113595, 0.265202, -0.237618, -0.957794), slope = c(28.8435,
2.74077, 34.8524, 0.151366, 18.6671, 0.132943, 17.6102, 16.0996,
9.36435, 0.452752, 1.9657, 0.996516, 1.74535, 0.148506, 0.0372119,
0.695029, 0.455934, 0.514605, 12.6356, 16.0089, 8.21627, 1.038,
0.498378, 3.6306, 4.11395, 10.3384, 15.5258, 16.5868, 30.8142,
11.3484, 0.041589, 0.102877, 0.277677, 0.642031, 0.663088, 0.289154,
1.05732, 0.216892, 0.233333, 0.248217, 0.176358, 0.193456, 0.245883,
0.108306, 0.583814, 0.106767, 0.102823, 0.395655, 1.33206, 0.243522,
0.811744, 0.116737, 0.573048, 0.672642, 0.415712, 0.396212, 0.447255,
0.13081, 0.410137, 0.727014), POINT_X = c(518112.161959, 517972.063651,
517506.021145, 514057.581202, 517528.545479, 514676.488847, 513464.270056,
513494.888654, 513586.036568, 515116.814902, 514135.06997, 519325.532909,
519683.204101, 519319.141302, 516830.545136, 516920.973864, 516979.229306,
517071.772928, 519951.348487, 515653.777436, 515800.193588, 520379.011629,
520642.986006, 519523.715662, 519637.527771, 521060.390222, 516952.842708,
517668.222196, 517617.227048, 520449.447941, 517052.212122, 514140.686317,
516431.927756, 514013.562097, 514243.405122, 514221.174814, 515311.187185,
514481.609078, 516589.086276, 517741.589283, 514186.085127, 515664.921099,
515733.804812, 517203.924014, 515751.253306, 517234.791292, 518427.782061,
515550.127549, 517048.546153, 514494.364954, 516677.023244, 516310.352775,
516408.158711, 517318.540292, 517974.751913, 515658.214168, 517623.031178,
514989.975043, 517581.921764, 516383.86435), POINT_Y = c(4808806.0847,
4810255.98377, 4811945.72636, 4812470.84981, 4812715.02483, 4813198.79081,
4813211.23833, 4813295.64352, 4813440.86864, 4813568.04148, 4813679.00767,
4813733.06168, 4814419.5912, 4814825.63894, 4816350.24526, 4816582.01425,
4816699.05741, 4817224.27439, 4817499.81568, 4817609.1733, 4817984.23946,
4818382.23486, 4818760.15577, 4819648.35709, 4819860.27227, 4819904.21184,
4820486.25819, 4820487.64551, 4820517.62914, 4820967.31897, 4809549.90161,
4812476.57785, 4813749.28092, 4812522.41608, 4812915.00417, 4812798.13954,
4813967.9282, 4813155.89553, 4811594.81676, 4817137.5718, 4812661.71143,
4813651.06428, 4813725.92053, 4816265.95688, 4813846.96134, 4816303.22503,
4819272.23858, 4813534.92529, 4809713.38594, 4813053.33525, 4813732.08346,
4813902.3087, 4813642.82751, 4816248.7419, 4817916.27765, 4813224.05382,
4818419.86058, 4813769.26218, 4818313.11043, 4811436.27069),
    ResponseSu = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.394676,
    1.435637, 1.449758, 1.461653, 1.471431, 1.475303, 1.475902,
    1.481716, 1.490055, 1.493364, 1.493391, 1.495781, 1.509532,
    1.51392, 1.519015, 1.522284, 1.52319, 1.525427, 1.527304,
    1.534297, 1.534883, 1.535686, 1.536898, 1.539433, 1.544022,
    1.553086, 1.555488, 1.581577, 1.585341, 1.585509)), .Names = c("CID",
"cosaspect", "disttoroad", "disttowat", "elevation", "habitat",
"sinaspect", "slope", "POINT_X", "POINT_Y", "ResponseSu"), row.names = c(NA,
60L), class = "data.frame")> AsciiGridImpute(type.rf, xfile, outfile)


On Thu, Sep 25, 2014 at 11:51 AM, Chris Jackson-Jordan <
jacksonjordancm at gmail.com> wrote:

> Thanks again for your help, I am obviously a novice programmer. That said,
> I think I am confused as to what you mean by reproducible code. Were the 20
> lines of code not reproducible? Also, what do you mean by the help for
> Ascii Grid Impute. I'm not able to find it online or within the R platform.
> Finally, I know that mapping to files on my PC is problematic, should I be
> attaching the files in my email? Like I said, this is all quite new to me.
> Sorry if my questions are painfully naive. I am hoping to get this project
> going but just can't get past this stumbling block. Thanks again for the
> help thus far.
>
> Chris
>
> On Thu, Sep 25, 2014 at 11:06 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>
>> Chris,
>>
>> You are not making it easy for R help folks to help you.
>>
>> You need to supply *** reproducible *** code, so that folks can simply
>> copy and paste directly from your e-mail to R and reproduce the error that
>> you are getting.  Do you need a guide to follow?  See the first 60-some
>> lines of code provided in the example of the help for AsciiGridImpute,
>>      ?AsciiGridImpute
>> I can copy that code into R and make it run.  You need to do the same
>> thing in your e-mail.  Don't refer to directories on your PC.
>>
>> I submitted a simplified version of the code you shared (below), but ran
>> into an error because the *.asc files were not already created.  So, I
>> suggest that you insert some general code to get that done for your
>> example, and resubmit your question.
>>
>> Jean
>>
>>
>> training <- structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
>> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
>> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
>> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
>> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
>> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
>> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
>> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
>> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
>> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
>> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
>> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
>> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
>> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
>> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect = c(0.915474,
>> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
>> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
>> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
>> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
>> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
>> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
>> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
>> 516073.554503, 516019.068701, 515506.165434, 517353.141738, 520076.487742,
>> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
>> 515714.490202, 518829.909017, 519385.491579, 518659.851297, 516654.780318,
>> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
>> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912, 4818923.42436,
>> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
>> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774, 4814503.57051,
>> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
>> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
>> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
>> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
>> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
>> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
>> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")
>>
>> library(yaImpute)
>>
>> y <- subset(training, select = c(ResponseSu))
>> x <- subset(training, select = c(sinaspect, habitat, elevation,
>> disttowat, disttoroad, slope, cosaspect))
>> type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression",
>> ntree=20)
>> outfile <- list(Type="RespSurf_Reg.asc")
>> xfile <-list(sinaspect="sinaspect.asc", habitat="habitat.asc",
>> elevation="elevation.asc",
>> disttowat="disttowat.asc", disttoroad="disttoroad.asc",
>> slope="slope.asc",
>> cosaspect="cosaspect.asc")
>>
>> # insert lines of code here to create the *.asc files
>> # see the example with the iris data in ?AsciiGridImpute
>>
>> AsciiGridImpute(type.rf, xfile, outfile)
>>
>>
>> On Mon, Sep 22, 2014 at 11:13 AM, Chris Jackson-Jordan <
>> jacksonjordancm at gmail.com> wrote:
>>
>>> Dear fellow R users,
>>>
>>> I am trying to run the random forest and Yaimpute packages in R to
>>> impute a grid to project in a gis. However, after running the
>>> imputation I keep getting an error in the rownames. This sounds simple
>>> enough, but I cannot figure out what these rownames are reffering to.
>>> Any ideas? I am fairly new to R so im sure it is an easy fix. Any help
>>> would be awesome.
>>>
>>> Thanks,
>>>
>>> Chris
>>>
>>>
>>> > y <- subset(training, select = c(ResponseSu)) > x <- subset(training,
>>> select = c(sinaspect, habitat, slope, elevation, cosaspect, disttoroad,
>>> disttowat)) > type.rf <- yai(x=x, y=y, method="randomForest",
>>> rfMode="regression", ntree= 2000) > outfile <- list(Type =
>>> "D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc") > xfile
>>> <-list(sinaspect
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/sinaspect.asc",
>>> habitat
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/habitat.asc",
>>> elevation
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/elevation.asc",
>>> disttowat
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttowat.asc",
>>> disttoroad
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttoroad.asc",
>>> slope
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/slope.asc",
>>> cosaspect
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/cosaspect.asc")
>>> > AsciiGridImpute(type.rf, xfile, outfile) Rows per dot: 19 Rows to do:
>>> 1900 ToDo:
>>>
>>> ....................................................................................................
>>> Done: . Error in `rownames<-`(`*tmp*`, value = c("23x0049", "23x0050",
>>> "23x0051", : attempt to set rownames on object with no dimensions
>>>
>>> here is an example of my training data
>>>
>>>
>>>  > dput(training[1:20, ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
>>>
>>> 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
>>> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
>>> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
>>> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
>>> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
>>> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
>>> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
>>> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
>>> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
>>> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
>>> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
>>> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
>>> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
>>> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
>>> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect =
>>> c(0.915474,
>>> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
>>> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
>>> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
>>> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
>>> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
>>> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
>>> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
>>> 516073.554503, 516019.068701, 515506.165434, 517353.141738,
>>> 520076.487742,
>>> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
>>> 515714.490202, 518829.909017, 519385.491579, 518659.851297,
>>> 516654.780318,
>>> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
>>> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912,
>>> 4818923.42436,
>>> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
>>> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774,
>>> 4814503.57051,
>>> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
>>> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
>>> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
>>> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
>>> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
>>> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
>>> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")>
>>> library("randomForest", lib.loc="~/RStudio/R/library")
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Sep 25 18:05:25 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Sep 2014 09:05:25 -0700
Subject: [R] error in rownames
In-Reply-To: <CAPtX2qnenxyQOFUEHWS9aJbZJMVcbDfODhunDwO+F4_bQMJvuA@mail.gmail.com>
References: <CAPtX2q=siOx6FQT9s3mNbcGcppMNv4OjmAnU7btT48u6WYppWw@mail.gmail.com>
	<CAN5YmCEZPPRqucCTchb_8+v+_as-MCzJj4dd_Sn=URcSYwcbKA@mail.gmail.com>
	<CAPtX2qkXCOfxrR2GdGKxVGi9ythq0-hCrWWQE1oNJesmTrPxXw@mail.gmail.com>
	<CAPtX2qnenxyQOFUEHWS9aJbZJMVcbDfODhunDwO+F4_bQMJvuA@mail.gmail.com>
Message-ID: <F38331D8-6BAF-44EC-9002-F52632FA458B@comcast.net>

Chris;

You are posting in HTML. You have apparently not read the Posting Guide. This is a plain-text mailing list. Please do read it now:

http://www.R-project.org/posting-guide.html

The code scraped from you consoles comes through without any linebreaks. (It's pretty easy to configure gmail to send plain text, so no excuses will be accepted on this issue.)

-- 
David


 And before posting again I suggest you
On Sep 25, 2014, at 8:57 AM, Chris Jackson-Jordan wrote:

> Sorry to respond again so quickly, but is this what you meant?
> 
> 
> y <- subset(training, select = c(ResponseSu))> x <- subset(training,
> select = c(sinaspect, habitat, elevation, disttowat, disttoroad,
> slope, cosaspect))> type.rf <- yai(x=x, y=y, method="randomForest",
> rfMode="regression", ntree=20)> outfile <-
> list(Type="RespSurf_Reg.asc")> xfile <-list(sinaspect="sinaspect.asc",
> habitat="habitat.asc", elevation="elevation.asc",+
> disttowat="disttowat.asc", disttoroad="disttoroad.asc",
> slope="slope.asc",+ cosaspect="cosaspect.asc")> dput(training[1:60,
> ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L), cosaspect = c(-0.546873, 0.333357, 0.796074, -0.906097,
> 0.546751, -0.903426, 0.55381, 0.761338, 0.858955, -0.784384,
> 0.790582, 0.0429794, 0.89785, 0.998368, 0.991524, -0.769041,
> -0.104549, -0.565003, -0.56414, 0.432783, -0.652663, -0.477157,
> -0.642625, 0.0719997, 0.0202113, -0.444488, -0.38204, -0.3565,
> -0.199093, 0.545715, -0.99322, 0.852507, -0.524166, 0.999378,
> -0.980175, -0.922242, -0.954118, -0.902187, -0.354786, 0.112082,
> -0.198151, -0.502453, -0.676458, -0.0673507, -0.999526, -0.840507,
> 0.989883, -0.832413, -0.733279, -0.993005, -0.479475, -0.326237,
> -0.848538, -0.546614, -0.986488, -0.948983, -0.993527, -0.964193,
> -0.971359, -0.287455), disttoroad = c(368.767, 880.661, 563.239,
> 72.1515, 227.697, 313.486, 265.001, 227.697, 219.137, 518.349,
> 23.048, 10.3074, 41.2294, 103.074, 497.857, 494.968, 524.968,
> 674.01, 10.3074, 133.996, 10.3074, 10.3074, 10.3074, 20.6147,
> 226.058, 10.3074, 272.122, 226.762, 177.933, 204.075, 82.4589,
> 61.8442, 14.5768, 20.6147, 29.1536, 92.1918, 75.0387, 113.849,
> 133.996, 46.0959, 123.688, 120.645, 185.533, 133.996, 61.8442,
> 103.074, 120.203, 154.61, 138.671, 150.077, 51.5368, 190.058,
> 72.884, 20.6147, 115.24, 30.9221, 83.1006, 333.041, 30.9221,
> 288.606), disttowat = c(981.15, 1448.98, 729.496, 509.146, 171.549,
> 322.671, 566.998, 631.783, 783.359, 407.76, 1036.59, 352.264,
> 306.113, 235.27, 241.289, 269.769, 342.633, 660.476, 578.04,
> 1844.99, 1753.65, 408.801, 543.951, 756.661, 632.875, 540.031,
> 927.09, 1120.47, 1166.24, 65.9993, 474.586, 437.911, 162.974,
> 576.66, 557.932, 547.844, 793.667, 420.586, 208.708, 10.3074,
> 497.857, 383.595, 371.78, 130.379, 449.406, 111.014, 162.974,
> 393.574, 463.831, 360.021, 404.096, 43.7304, 140.195, 182.647,
> 277.343, 84.9967, 87.4609, 633.546, 60.1017, 42.4983), elevation = c(2000.9,
> 2198.18, 2194.78, 1863.8, 1902.25, 1867.29, 1943.94, 1912.35,
> 1920.11, 1870.94, 1914.56, 1904.4, 1900.92, 1893.94, 1888.02,
> 1889.71, 1890.95, 1894.32, 1896.11, 2011.99, 2025.01, 1902.45,
> 1901.99, 2030.09, 2038.39, 1910.48, 2054.46, 1918.92, 1951.15,
> 1941.24, 1853.78, 1863.76, 1875.9, 1863.6, 1864.91, 1864.18,
> 1872.85, 1866.81, 1863.06, 1896.47, 1863.95, 1873.13, 1873.44,
> 1888.06, 1874.35, 1888.06, 1911.09, 1872.43, 1854.83, 1866.98,
> 1876.95, 1875.88, 1875.19, 1888.27, 1900.82, 1870.49, 1903.17,
> 1871.52, 1902.28, 1862.18), habitat = c(14L, 1L, 9L, 2L, 5L,
> 2L, 5L, 1L, 1L, 2L, 1L, 4L, 10L, 8L, 2L, 2L, 2L, 2L, 4L, 10L,
> 5L, 4L, 4L, 3L, 5L, 4L, 3L, 3L, 7L, 6L, 2L, 2L, 2L, 13L, 2L,
> 2L, 2L, 2L, 2L, 11L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 10L, 2L, 2L, 2L, 2L, 2L), sinaspect = c(-0.837215,
> -0.942801, -0.6052, 0.42307, -0.837295, -0.428745, -0.832643,
> -0.648355, -0.512051, -0.620276, -0.612357, -0.999076, -0.440302,
> -0.0571153, 0.129924, -0.6392, -0.99452, -0.825089, 0.825679,
> -0.901498, -0.757648, 0.878818, 0.766181, -0.997405, -0.999796,
> 0.895785, 0.924146, 0.934295, 0.979981, -0.837971, 0.11625, -0.522717,
> -0.851616, -0.0352723, 0.198133, -0.386614, -0.29943, -0.431345,
> -0.934948, -0.993699, -0.980172, -0.864605, -0.736481, 0.997729,
> -0.0307994, -0.541801, 0.141883, -0.554156, 0.679928, 0.118074,
> -0.877556, -0.945288, -0.529134, -0.837385, -0.163837, -0.315329,
> -0.113595, 0.265202, -0.237618, -0.957794), slope = c(28.8435,
> 2.74077, 34.8524, 0.151366, 18.6671, 0.132943, 17.6102, 16.0996,
> 9.36435, 0.452752, 1.9657, 0.996516, 1.74535, 0.148506, 0.0372119,
> 0.695029, 0.455934, 0.514605, 12.6356, 16.0089, 8.21627, 1.038,
> 0.498378, 3.6306, 4.11395, 10.3384, 15.5258, 16.5868, 30.8142,
> 11.3484, 0.041589, 0.102877, 0.277677, 0.642031, 0.663088, 0.289154,
> 1.05732, 0.216892, 0.233333, 0.248217, 0.176358, 0.193456, 0.245883,
> 0.108306, 0.583814, 0.106767, 0.102823, 0.395655, 1.33206, 0.243522,
> 0.811744, 0.116737, 0.573048, 0.672642, 0.415712, 0.396212, 0.447255,
> 0.13081, 0.410137, 0.727014), POINT_X = c(518112.161959, 517972.063651,
> 517506.021145, 514057.581202, 517528.545479, 514676.488847, 513464.270056,
> 513494.888654, 513586.036568, 515116.814902, 514135.06997, 519325.532909,
> 519683.204101, 519319.141302, 516830.545136, 516920.973864, 516979.229306,
> 517071.772928, 519951.348487, 515653.777436, 515800.193588, 520379.011629,
> 520642.986006, 519523.715662, 519637.527771, 521060.390222, 516952.842708,
> 517668.222196, 517617.227048, 520449.447941, 517052.212122, 514140.686317,
> 516431.927756, 514013.562097, 514243.405122, 514221.174814, 515311.187185,
> 514481.609078, 516589.086276, 517741.589283, 514186.085127, 515664.921099,
> 515733.804812, 517203.924014, 515751.253306, 517234.791292, 518427.782061,
> 515550.127549, 517048.546153, 514494.364954, 516677.023244, 516310.352775,
> 516408.158711, 517318.540292, 517974.751913, 515658.214168, 517623.031178,
> 514989.975043, 517581.921764, 516383.86435), POINT_Y = c(4808806.0847,
> 4810255.98377, 4811945.72636, 4812470.84981, 4812715.02483, 4813198.79081,
> 4813211.23833, 4813295.64352, 4813440.86864, 4813568.04148, 4813679.00767,
> 4813733.06168, 4814419.5912, 4814825.63894, 4816350.24526, 4816582.01425,
> 4816699.05741, 4817224.27439, 4817499.81568, 4817609.1733, 4817984.23946,
> 4818382.23486, 4818760.15577, 4819648.35709, 4819860.27227, 4819904.21184,
> 4820486.25819, 4820487.64551, 4820517.62914, 4820967.31897, 4809549.90161,
> 4812476.57785, 4813749.28092, 4812522.41608, 4812915.00417, 4812798.13954,
> 4813967.9282, 4813155.89553, 4811594.81676, 4817137.5718, 4812661.71143,
> 4813651.06428, 4813725.92053, 4816265.95688, 4813846.96134, 4816303.22503,
> 4819272.23858, 4813534.92529, 4809713.38594, 4813053.33525, 4813732.08346,
> 4813902.3087, 4813642.82751, 4816248.7419, 4817916.27765, 4813224.05382,
> 4818419.86058, 4813769.26218, 4818313.11043, 4811436.27069),
>    ResponseSu = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.394676,
>    1.435637, 1.449758, 1.461653, 1.471431, 1.475303, 1.475902,
>    1.481716, 1.490055, 1.493364, 1.493391, 1.495781, 1.509532,
>    1.51392, 1.519015, 1.522284, 1.52319, 1.525427, 1.527304,
>    1.534297, 1.534883, 1.535686, 1.536898, 1.539433, 1.544022,
>    1.553086, 1.555488, 1.581577, 1.585341, 1.585509)), .Names = c("CID",
> "cosaspect", "disttoroad", "disttowat", "elevation", "habitat",
> "sinaspect", "slope", "POINT_X", "POINT_Y", "ResponseSu"), row.names = c(NA,
> 60L), class = "data.frame")> AsciiGridImpute(type.rf, xfile, outfile)
> 
> 
> On Thu, Sep 25, 2014 at 11:51 AM, Chris Jackson-Jordan <
> jacksonjordancm at gmail.com> wrote:
> 
>> Thanks again for your help, I am obviously a novice programmer. That said,
>> I think I am confused as to what you mean by reproducible code. Were the 20
>> lines of code not reproducible? Also, what do you mean by the help for
>> Ascii Grid Impute. I'm not able to find it online or within the R platform.
>> Finally, I know that mapping to files on my PC is problematic, should I be
>> attaching the files in my email? Like I said, this is all quite new to me.
>> Sorry if my questions are painfully naive. I am hoping to get this project
>> going but just can't get past this stumbling block. Thanks again for the
>> help thus far.
>> 
>> Chris
>> 
>> On Thu, Sep 25, 2014 at 11:06 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>> 
>>> Chris,
>>> 
>>> You are not making it easy for R help folks to help you.
>>> 
>>> You need to supply *** reproducible *** code, so that folks can simply
>>> copy and paste directly from your e-mail to R and reproduce the error that
>>> you are getting.  Do you need a guide to follow?  See the first 60-some
>>> lines of code provided in the example of the help for AsciiGridImpute,
>>>     ?AsciiGridImpute
>>> I can copy that code into R and make it run.  You need to do the same
>>> thing in your e-mail.  Don't refer to directories on your PC.
>>> 
>>> I submitted a simplified version of the code you shared (below), but ran
>>> into an error because the *.asc files were not already created.  So, I
>>> suggest that you insert some general code to get that done for your
>>> example, and resubmit your question.
>>> 
>>> Jean
>>> 
>>> 
>>> training <- structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
>>> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
>>> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
>>> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
>>> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
>>> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
>>> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
>>> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
>>> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
>>> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
>>> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
>>> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
>>> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
>>> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
>>> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect = c(0.915474,
>>> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
>>> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
>>> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
>>> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
>>> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
>>> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
>>> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
>>> 516073.554503, 516019.068701, 515506.165434, 517353.141738, 520076.487742,
>>> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
>>> 515714.490202, 518829.909017, 519385.491579, 518659.851297, 516654.780318,
>>> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
>>> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912, 4818923.42436,
>>> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
>>> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774, 4814503.57051,
>>> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
>>> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
>>> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
>>> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
>>> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
>>> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
>>> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")
>>> 
>>> library(yaImpute)
>>> 
>>> y <- subset(training, select = c(ResponseSu))
>>> x <- subset(training, select = c(sinaspect, habitat, elevation,
>>> disttowat, disttoroad, slope, cosaspect))
>>> type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression",
>>> ntree=20)
>>> outfile <- list(Type="RespSurf_Reg.asc")
>>> xfile <-list(sinaspect="sinaspect.asc", habitat="habitat.asc",
>>> elevation="elevation.asc",
>>> disttowat="disttowat.asc", disttoroad="disttoroad.asc",
>>> slope="slope.asc",
>>> cosaspect="cosaspect.asc")
>>> 
>>> # insert lines of code here to create the *.asc files
>>> # see the example with the iris data in ?AsciiGridImpute
>>> 
>>> AsciiGridImpute(type.rf, xfile, outfile)
>>> 
>>> 
>>> On Mon, Sep 22, 2014 at 11:13 AM, Chris Jackson-Jordan <
>>> jacksonjordancm at gmail.com> wrote:
>>> 
>>>> Dear fellow R users,
>>>> 
>>>> I am trying to run the random forest and Yaimpute packages in R to
>>>> impute a grid to project in a gis. However, after running the
>>>> imputation I keep getting an error in the rownames. This sounds simple
>>>> enough, but I cannot figure out what these rownames are reffering to.
>>>> Any ideas? I am fairly new to R so im sure it is an easy fix. Any help
>>>> would be awesome.
>>>> 
>>>> Thanks,
>>>> 
>>>> Chris
>>>> 
>>>> 
>>>>> y <- subset(training, select = c(ResponseSu)) > x <- subset(training,
>>>> select = c(sinaspect, habitat, slope, elevation, cosaspect, disttoroad,
>>>> disttowat)) > type.rf <- yai(x=x, y=y, method="randomForest",
>>>> rfMode="regression", ntree= 2000) > outfile <- list(Type =
>>>> "D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc") > xfile
>>>> <-list(sinaspect
>>>> 
>>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/sinaspect.asc",
>>>> habitat
>>>> 
>>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/habitat.asc",
>>>> elevation
>>>> 
>>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/elevation.asc",
>>>> disttowat
>>>> 
>>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttowat.asc",
>>>> disttoroad
>>>> 
>>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttoroad.asc",
>>>> slope
>>>> 
>>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/slope.asc",
>>>> cosaspect
>>>> 
>>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/cosaspect.asc")
>>>>> AsciiGridImpute(type.rf, xfile, outfile) Rows per dot: 19 Rows to do:
>>>> 1900 ToDo:
>>>> 
>>>> ....................................................................................................
>>>> Done: . Error in `rownames<-`(`*tmp*`, value = c("23x0049", "23x0050",
>>>> "23x0051", : attempt to set rownames on object with no dimensions
>>>> 
>>>> here is an example of my training data
>>>> 
>>>> 
>>>>> dput(training[1:20, ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
>>>> 
>>>> 0L, 0L, 0L, 0L, 0L,
>>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
>>>> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
>>>> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
>>>> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
>>>> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
>>>> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
>>>> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
>>>> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
>>>> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
>>>> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
>>>> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
>>>> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
>>>> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
>>>> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
>>>> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect =
>>>> c(0.915474,
>>>> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
>>>> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
>>>> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
>>>> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
>>>> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
>>>> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
>>>> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
>>>> 516073.554503, 516019.068701, 515506.165434, 517353.141738,
>>>> 520076.487742,
>>>> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
>>>> 515714.490202, 518829.909017, 519385.491579, 518659.851297,
>>>> 516654.780318,
>>>> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
>>>> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912,
>>>> 4818923.42436,
>>>> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
>>>> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774,
>>>> 4814503.57051,
>>>> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
>>>> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
>>>> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
>>>> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
>>>> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
>>>> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
>>>> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")>
>>>> library("randomForest", lib.loc="~/RStudio/R/library")
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Thu Sep 25 18:37:32 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 25 Sep 2014 12:37:32 -0400
Subject: [R] Masked from package
In-Reply-To: <452d9f0a-a75b-4bb9-9ecc-97b07001cd25@email.android.com>
References: <alpine.LNX.2.11.1409241120200.29487@localhost>	<D0497920.10CBBE%macqueen1@llnl.gov>	<alpine.LNX.2.11.1409250814410.12417@localhost>
	<452d9f0a-a75b-4bb9-9ecc-97b07001cd25@email.android.com>
Message-ID: <542444CC.4080108@gmail.com>

On 25/09/2014 11:46 AM, Jeff Newmiller wrote:
> No, masking does not imply inheritance. Simply that "foo" now refers to a different function, so you have to use "oldpkg::foo" if you want to get at the old function from your normal working environment.

I haven't read the book (?), but I'd guess what they refer to is the way 
that package uses masking, rather than a claim about masking in general.

The cor() function in base R isn't a generic function, but it is masked 
by one in the compositions package, which provides a variety of methods 
for it.  The default method calls the stats::cor function.  So in that 
sense it really does provide a kind of inheritance.

Duncan Murdoch

>
> Note that packages that call "foo" will continue to find the versions they intended to call if they are constructed correctly.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On September 25, 2014 8:19:14 AM PDT, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> >On Thu, 25 Sep 2014, MacQueen, Don wrote:
> >
> >> And to answer the ?What do I read ...?? question
> >>  help.search('masked?)
> >> returns quite a few things on my system, and the one you want is
> >
> >Don, et al.:
> >
> >   Further research led me to re-read the beginning of "Analyzing
> >Compositional Data with R" where the authors describe the masking as
> >analgous (my interpretation) to instatiating an object as in Python or
> >wxPython. With the package compositions, there are functions with the
> >same
> >name as functions in other packages. The compositions package extends
> >functionality and implies that the parent functionality is inherited,
> >not
> >replaced.
> >
> >   Perhaps this is the norm for all R packages.
> >
> >Thanks very much to all,
> >
> >Rich
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rebecca.yuan at bankofamerica.com  Thu Sep 25 20:02:16 2014
From: rebecca.yuan at bankofamerica.com (Yuan, Rebecca)
Date: Thu, 25 Sep 2014 18:02:16 +0000
Subject: [R] Error : '.path.package' is defunct.
Message-ID: <419EED2318C2164DB95FBB20AA8810D8015FB376@smtp_mail.bankofamerica.com>

Hello all,

After this reinstallation of R 3.1.1 and Rstudio 0.98.1028, I have the following error messages whenever I tried to load a library to it:

> library('zoo')
Error : '.path.package' is defunct.
Use 'path.package' instead.
See help("Defunct")

Attaching package: 'zoo'

The following objects are masked from 'package:base':

    as.Date, as.Date.numeric

Could you please help on this?

Thanks!

Rebecca

----------------------------------------------------------------------
This message, and any attachments, is for the intended r...{{dropped:5}}


From ruipbarradas at sapo.pt  Thu Sep 25 20:40:39 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 25 Sep 2014 19:40:39 +0100
Subject: [R] Error : '.path.package' is defunct.
In-Reply-To: <419EED2318C2164DB95FBB20AA8810D8015FB376@smtp_mail.bankofamerica.com>
References: <419EED2318C2164DB95FBB20AA8810D8015FB376@smtp_mail.bankofamerica.com>
Message-ID: <542461A7.4000801@sapo.pt>

Hello,

This seems to be an RStudio issue, to load package zoo works on R 3.1.1 
on Windows, at least when using RGui. RStudio has its own help list, 
maybe you should contact them, at https://support.rstudio.com.

 > library(zoo)

Attaching package: ?zoo?

The following objects are masked from ?package:base?:

     as.Date, as.Date.numeric

 > sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] zoo_1.7-11

Hope this helps,

Rui Barradas


Em 25-09-2014 19:02, Yuan, Rebecca escreveu:
> Hello all,
>
> After this reinstallation of R 3.1.1 and Rstudio 0.98.1028, I have the following error messages whenever I tried to load a library to it:
>
>> library('zoo')
> Error : '.path.package' is defunct.
> Use 'path.package' instead.
> See help("Defunct")
>
> Attaching package: 'zoo'
>
> The following objects are masked from 'package:base':
>
>      as.Date, as.Date.numeric
>
> Could you please help on this?
>
> Thanks!
>
> Rebecca
>
> ----------------------------------------------------------------------
> This message, and any attachments, is for the intended r...{{dropped:5}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Thu Sep 25 20:43:16 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Sep 2014 13:43:16 -0500
Subject: [R] Error : '.path.package' is defunct.
In-Reply-To: <419EED2318C2164DB95FBB20AA8810D8015FB376@smtp_mail.bankofamerica.com>
References: <419EED2318C2164DB95FBB20AA8810D8015FB376@smtp_mail.bankofamerica.com>
Message-ID: <A4E37CA9-4CBA-4FA4-AE33-41AFD611A925@me.com>

On Sep 25, 2014, at 1:02 PM, Yuan, Rebecca <rebecca.yuan at bankofamerica.com> wrote:

> Hello all,
> 
> After this reinstallation of R 3.1.1 and Rstudio 0.98.1028, I have the following error messages whenever I tried to load a library to it:
> 
>> library('zoo')
> Error : '.path.package' is defunct.
> Use 'path.package' instead.
> See help("Defunct")
> 
> Attaching package: 'zoo'
> 
> The following objects are masked from 'package:base':
> 
>    as.Date, as.Date.numeric
> 
> Could you please help on this?
> 
> Thanks!
> 
> Rebecca


Check the version of 'zoo' that you have installed by using:

  library(help = zoo)

More than likely, you have an old version of the package installed (current is 1.7-11) that still uses the now defunct function, hence the error message.

You can run:

  update.packages(checkBuilt = TRUE)

to update all of your installed packages and be sure that they are built for the current version of R that you now have running.

There may be other nuances here, such as OS, having Admin access and where the CRAN packages are installed, but at least checking the version of zoo will be a good staring point.

Regards,

Marc Schwartz


From emma.white at sdstate.edu  Thu Sep 25 20:08:12 2014
From: emma.white at sdstate.edu (White, Emma)
Date: Thu, 25 Sep 2014 13:08:12 -0500
Subject: [R] writeRaster dataType changes
Message-ID: <54245A0C.1080102@sdstate.edu>

Hi,

I am reading in some raster files and converting them to GeoTiff (using 
the raster package), I want them to be 8 bit unsigned integer (values in 
the case of this particular raster range from 0 to 55). However when 
writing the raster to GeoTiff R seems to assign it to dataType "FLT4S" 
despite specifying the dataType. See example code below:

foo<- raster(raster.files[1],datatype = INT1U)
dataType(foo)
[1] "INT1U"
fool<- 
writeRaster(foo,filename=paste("../test/",raster.files[1],sep=""), 
format="GTiff",dataType = 'INT1U',overwrite=TRUE)
dataType(fool)
[1] "FLT4S"

Any help/ insight would be appreciated. Thanks!


Emma

-- 
Emma White
PhD Candidate
Geospatial Science Center of Excellence
South Dakota State University
Email: Emma.White at sdstate.edu
Web: http://globalmonitoring.sdstate.edu/people.php?view=3&a=show&id=86


From baccts at hotmail.com  Thu Sep 25 20:21:38 2014
From: baccts at hotmail.com (C Lin)
Date: Thu, 25 Sep 2014 14:21:38 -0400
Subject: [R] modify function in a package
Message-ID: <COL129-W23882AB8B804B8BD4E8992CBBE0@phx.gbl>

Dear R users,?
There is a package called NanoStringNorm with a function called NanoStringNorm.
What I want to do is to change the NanoStringNorm function from the package with my own copy that is written in my.nanostringnorm.R.?
But if I do the following:?

source('my.nanostringnorm.R")
unlockBinding("NanoStringNorm", as.environment("package:NanoStringNorm")) ;?
assign("NanoStringNorm", NanoStringNorm, "package:NanoStringNorm") ;?

Although, it now correctly called my NanoStringNorm, it doesn't recognize a function called inside my NanoStringNorm that called another functions in the NanoStringNorm package.?
So, I have to change all such functionswith NanoStringNorm:::function.name.?
How should I replace the NanoStringNorm function but still able to call other function in the package??
I still have package NanoStringNorm in my search path but somehow it can't find the other function.?

TIA,?
Lin 		 	   		  

From CBattles at startllc.com  Thu Sep 25 20:30:08 2014
From: CBattles at startllc.com (Christopher Battles)
Date: Thu, 25 Sep 2014 14:30:08 -0400
Subject: [R] Performance (speed) of ggplot
Message-ID: <61082859DB498E4A86977CB0DEEF77212951F899D7@SBS02.startllc.local>

Hello list,

I have been working on learning ggplot for its extraordinary flexibility compared to base plotting and have been developing a function to create a "Minitab-like" process capability chart.  

*sigh* some of the people I interface with can only understand the data when it is presented in Minitab format

The function creates a ggplot container to hold 10 ggplot items which are the main process capability chart, a Q-Q plot, and the text boxes with all the capabilities data.  When I run the function, the elapsed time is on the order of 3 seconds, the gross majority of which is user time.  sys time is very small.  A bit of hacking shows that the calls to 

gt1 <- ggplot_gtable(ggplot_build(p)), 

etc., each take on the order of 1/3 of a second. These times are on a 3.2GHz Xeon workstation.  I'd like to see the entire function complete in less than a second.  My questions are: 1) Am I misusing ggplot, hence the performance hit? 2) Is there any way to increase the speed of this portion of the code? 3) Am I simply asking ggplot to crunch so much that it is inevitable that it will take a while to process?

To that end, the function, vectis.cap(), can be downloaded from http://pastebin.com/05s5RKYw .  It runs to 962 lines of code, so I won't paste it here.  The offending ggplot_gtable calls are at lines 909 - 918.

Usage:
vectis.cap(chickwts$weight, target = 300, USL = 400, LSL = 100)

Thank you,

Christopher Battles


From eliza_botto at hotmail.com  Thu Sep 25 21:50:49 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 25 Sep 2014 19:50:49 +0000
Subject: [R] adding rows
Message-ID: <BLU170-W83435F2792F94710ED3CD189BE0@phx.gbl>

Dear useRs,
Here is my data with two columns and 20 rows.
> dput(TT)
structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480), .Dim = c(20L, 2L), .Dimnames = list(NULL, c("", "SS")))
I first of all want to sum up continuously  two rows (1 & 2, 3 & 4, 5 & 6 and so on) of each column.
Then I want to sum up 3 rows as (1-2-3,4-5-6,..... 16-17-18) and since 19th and 20th rows do not up 3 rows, so they should be ignored.
Similarly with 4 sets of rows and 5 sets of rows and even 6.
I hope I was clear.
Thankyou so very much in advance,
Eliza  		 	   		  
	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Sep 25 22:34:16 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 25 Sep 2014 21:34:16 +0100
Subject: [R] adding rows
In-Reply-To: <BLU170-W83435F2792F94710ED3CD189BE0@phx.gbl>
References: <BLU170-W83435F2792F94710ED3CD189BE0@phx.gbl>
Message-ID: <54247C48.9020209@sapo.pt>

Hello,

Try the following.

fun <- function(x, r){
	if(r > 0){
		m <- length(x) %/% r
		y <- numeric(m)
		for(i in seq_len(m)){
			y[i] <- sum(x[((i - 1)*r + 1):(i*r)])
		}
		y
	}else{
		NULL
	}
}

apply(TT, 2, fun, r = 2)
apply(TT, 2, fun, r = 3)
etc


Hope this helps,

Rui Barradas


Em 25-09-2014 20:50, eliza botto escreveu:
> Dear useRs,
> Here is my data with two columns and 20 rows.
>> dput(TT)
> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480), .Dim = c(20L, 2L), .Dimnames = list(NULL, c("", "SS")))
> I first of all want to sum up continuously  two rows (1 & 2, 3 & 4, 5 & 6 and so on) of each column.
> Then I want to sum up 3 rows as (1-2-3,4-5-6,..... 16-17-18) and since 19th and 20th rows do not up 3 rows, so they should be ignored.
> Similarly with 4 sets of rows and 5 sets of rows and even 6.
> I hope I was clear.
> Thankyou so very much in advance,
> Eliza  		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Thu Sep 25 23:05:17 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 25 Sep 2014 21:05:17 +0000
Subject: [R] adding rows
In-Reply-To: <54247C48.9020209@sapo.pt>
References: <BLU170-W83435F2792F94710ED3CD189BE0@phx.gbl>
	<54247C48.9020209@sapo.pt>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9B9AA@mb02.ads.tamu.edu>

Another approach

fun <- function(i, dat=x) {
     grp <- rep(1:(nrow(dat)/i), each=i)
     aggregate(dat[1:length(grp),]~grp, FUN=sum)
}

lapply(2:6, fun, dat=TT)


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Thursday, September 25, 2014 3:34 PM
To: eliza botto; r-help at r-project.org
Subject: Re: [R] adding rows

Hello,

Try the following.

fun <- function(x, r){
	if(r > 0){
		m <- length(x) %/% r
		y <- numeric(m)
		for(i in seq_len(m)){
			y[i] <- sum(x[((i - 1)*r + 1):(i*r)])
		}
		y
	}else{
		NULL
	}
}

apply(TT, 2, fun, r = 2)
apply(TT, 2, fun, r = 3)
etc


Hope this helps,

Rui Barradas


Em 25-09-2014 20:50, eliza botto escreveu:
> Dear useRs,
> Here is my data with two columns and 20 rows.
>> dput(TT)
> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480), .Dim = c(20L, 2L), .Dimnames = list(NULL, c("", "SS")))
> I first of all want to sum up continuously  two rows (1 & 2, 3 & 4, 5 & 6 and so on) of each column.
> Then I want to sum up 3 rows as (1-2-3,4-5-6,..... 16-17-18) and since 19th and 20th rows do not up 3 rows, so they should be ignored.
> Similarly with 4 sets of rows and 5 sets of rows and even 6.
> I hope I was clear.
> Thankyou so very much in advance,
> Eliza  		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sven.templer at gmail.com  Fri Sep 26 00:28:23 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Fri, 26 Sep 2014 00:28:23 +0200
Subject: [R] adding rows
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9B9AA@mb02.ads.tamu.edu>
References: <BLU170-W83435F2792F94710ED3CD189BE0@phx.gbl>
	<54247C48.9020209@sapo.pt>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9B9AA@mb02.ads.tamu.edu>
Message-ID: <CAHuTOvqc6kcRrP6g1nQ7BxyEZGwVmsbyjaCeQJ+aAPwoz6dd1A@mail.gmail.com>

see inline for another vectorized example.

On 25 September 2014 23:05, David L Carlson <dcarlson at tamu.edu> wrote:
> Another approach
>
> fun <- function(i, dat=x) {
>      grp <- rep(1:(nrow(dat)/i), each=i)
>      aggregate(dat[1:length(grp),]~grp, FUN=sum)
> }
>
> lapply(2:6, fun, dat=TT)
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
> Sent: Thursday, September 25, 2014 3:34 PM
> To: eliza botto; r-help at r-project.org
> Subject: Re: [R] adding rows
>
> Hello,
>
> Try the following.
>
> fun <- function(x, r){
>         if(r > 0){
>                 m <- length(x) %/% r
>                 y <- numeric(m)
>                 for(i in seq_len(m)){
>                         y[i] <- sum(x[((i - 1)*r + 1):(i*r)])
>                 }
>                 y
>         }else{
>                 NULL
>         }
> }



fun <- function(x,r) {
  i <- length(x)%/%r
  tapply(x[1:(i*r)], gl(i,r), sum)
}



>
> apply(TT, 2, fun, r = 2)
> apply(TT, 2, fun, r = 3)
> etc
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 25-09-2014 20:50, eliza botto escreveu:
>> Dear useRs,
>> Here is my data with two columns and 20 rows.
>>> dput(TT)
>> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480), .Dim = c(20L, 2L), .Dimnames = list(NULL, c("", "SS")))
>> I first of all want to sum up continuously  two rows (1 & 2, 3 & 4, 5 & 6 and so on) of each column.
>> Then I want to sum up 3 rows as (1-2-3,4-5-6,..... 16-17-18) and since 19th and 20th rows do not up 3 rows, so they should be ignored.
>> Similarly with 4 sets of rows and 5 sets of rows and even 6.
>> I hope I was clear.
>> Thankyou so very much in advance,
>> Eliza
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maicel at infomed.sld.cu  Fri Sep 26 01:53:38 2014
From: maicel at infomed.sld.cu (=?iso-8859-1?Q?Maicel_Monz=F3n_P=E9rez?=)
Date: Thu, 25 Sep 2014 19:53:38 -0400
Subject: [R] Unique values in dataframe columns
Message-ID: <000001cfd91b$f036a090$d0a3e1b0$@infomed.sld.cu>

Hello  list
I would like to know how can  i detect  dataframe columns that have as
unique values elements of a list.
For example, at a  given dataframe to look for columns that unique values
are elements of a list like this one
 

dataframe<-data.frame(
x = c("yes?, "1?, "no?, "no?),
y = c("black?, "red?, "NA?, "white?),
z= c(T,F,T,T),
J= c(2,7,8,9))
Library(DescTools)

list<-GetAllSubsets(c(NA,0,1,2,"yes","y","no"),min.n = 2, max.n = 5)

......and to obtain  the following vector..
TRUE,FALSE, FALSE, FALSE

Best regards
Maicel Monzon


--
Nunca digas nunca, di mejor: gracias, permiso, disculpe.

Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/


From gunter.berton at gene.com  Fri Sep 26 02:04:31 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 25 Sep 2014 17:04:31 -0700
Subject: [R] adding rows
In-Reply-To: <CAHuTOvqc6kcRrP6g1nQ7BxyEZGwVmsbyjaCeQJ+aAPwoz6dd1A@mail.gmail.com>
References: <BLU170-W83435F2792F94710ED3CD189BE0@phx.gbl>
	<54247C48.9020209@sapo.pt>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9B9AA@mb02.ads.tamu.edu>
	<CAHuTOvqc6kcRrP6g1nQ7BxyEZGwVmsbyjaCeQJ+aAPwoz6dd1A@mail.gmail.com>
Message-ID: <CACk-te229MWg_j2GeoYU2W2QFP-SQCr8MR1qGm7qJHCxW3Seyg@mail.gmail.com>

Inline.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Sep 25, 2014 at 3:28 PM, Sven E. Templer <sven.templer at gmail.com> wrote:
> see inline for another vectorized example.

Nope. x-apply family functions are disguised (Interpreter level, not C
level) loops. Rarely more efficient than for() loops, but often
clearer and more convenient.

Cheers,
Bert

>
> On 25 September 2014 23:05, David L Carlson <dcarlson at tamu.edu> wrote:
>> Another approach
>>
>> fun <- function(i, dat=x) {
>>      grp <- rep(1:(nrow(dat)/i), each=i)
>>      aggregate(dat[1:length(grp),]~grp, FUN=sum)
>> }
>>
>> lapply(2:6, fun, dat=TT)
>>
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>> Sent: Thursday, September 25, 2014 3:34 PM
>> To: eliza botto; r-help at r-project.org
>> Subject: Re: [R] adding rows
>>
>> Hello,
>>
>> Try the following.
>>
>> fun <- function(x, r){
>>         if(r > 0){
>>                 m <- length(x) %/% r
>>                 y <- numeric(m)
>>                 for(i in seq_len(m)){
>>                         y[i] <- sum(x[((i - 1)*r + 1):(i*r)])
>>                 }
>>                 y
>>         }else{
>>                 NULL
>>         }
>> }
>
>
>
> fun <- function(x,r) {
>   i <- length(x)%/%r
>   tapply(x[1:(i*r)], gl(i,r), sum)
> }
>
>
>
>>
>> apply(TT, 2, fun, r = 2)
>> apply(TT, 2, fun, r = 3)
>> etc
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Em 25-09-2014 20:50, eliza botto escreveu:
>>> Dear useRs,
>>> Here is my data with two columns and 20 rows.
>>>> dput(TT)
>>> structure(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 48, 72, 96, 120, 144, 168, 192, 216, 240, 264, 288, 312, 336, 360, 384, 408, 432, 456, 480), .Dim = c(20L, 2L), .Dimnames = list(NULL, c("", "SS")))
>>> I first of all want to sum up continuously  two rows (1 & 2, 3 & 4, 5 & 6 and so on) of each column.
>>> Then I want to sum up 3 rows as (1-2-3,4-5-6,..... 16-17-18) and since 19th and 20th rows do not up 3 rows, so they should be ignored.
>>> Similarly with 4 sets of rows and 5 sets of rows and even 6.
>>> I hope I was clear.
>>> Thankyou so very much in advance,
>>> Eliza
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Sep 26 02:14:30 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Sep 2014 17:14:30 -0700
Subject: [R] modify function in a package
In-Reply-To: <COL129-W23882AB8B804B8BD4E8992CBBE0@phx.gbl>
References: <COL129-W23882AB8B804B8BD4E8992CBBE0@phx.gbl>
Message-ID: <CA70B43E-E7D5-45C0-B04B-F468AA9C89F2@comcast.net>


On Sep 25, 2014, at 11:21 AM, C Lin wrote:

> Dear R users, 
> There is a package called NanoStringNorm with a function called NanoStringNorm.
> What I want to do is to change the NanoStringNorm function from the package with my own copy that is written in my.nanostringnorm.R. 
> But if I do the following: 
> 
> source('my.nanostringnorm.R")
> unlockBinding("NanoStringNorm", as.environment("package:NanoStringNorm")) ; 
> assign("NanoStringNorm", NanoStringNorm, "package:NanoStringNorm") ; 
> 
> Although, it now correctly called my NanoStringNorm, it doesn't recognize a function called inside my NanoStringNorm that called another functions in the NanoStringNorm package. 
> So, I have to change all such functionswith NanoStringNorm:::function.name. 
> How should I replace the NanoStringNorm function but still able to call other function in the package? 
> I still have package NanoStringNorm in my search path but somehow it can't find the other function. 

Take a look at assignInNamespace. It's also possible to set teh environment of a function:

?assignInNamespace
?`environment<-`


-- 
David Winsemius
Alameda, CA, USA


From kridox at ymail.com  Fri Sep 26 04:45:18 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 26 Sep 2014 11:45:18 +0900
Subject: [R] writeRaster dataType changes
In-Reply-To: <54245A0C.1080102@sdstate.edu>
References: <54245A0C.1080102@sdstate.edu>
Message-ID: <CAAcyNCyMYhZ-KrW6_=Y5kRt+N1nQQRfxryatUhqG=KbBMxTWNw@mail.gmail.com>

Hi Emma,

In writeRaster(), the argument is "datatype", not "dataType".

Hope this helps,
Pascal


On Fri, Sep 26, 2014 at 3:08 AM, White, Emma <emma.white at sdstate.edu> wrote:
> Hi,
>
> I am reading in some raster files and converting them to GeoTiff (using the
> raster package), I want them to be 8 bit unsigned integer (values in the
> case of this particular raster range from 0 to 55). However when writing the
> raster to GeoTiff R seems to assign it to dataType "FLT4S" despite
> specifying the dataType. See example code below:
>
> foo<- raster(raster.files[1],datatype = INT1U)
> dataType(foo)
> [1] "INT1U"
> fool<- writeRaster(foo,filename=paste("../test/",raster.files[1],sep=""),
> format="GTiff",dataType = 'INT1U',overwrite=TRUE)
> dataType(fool)
> [1] "FLT4S"
>
> Any help/ insight would be appreciated. Thanks!
>
>
> Emma
>
> --
> Emma White
> PhD Candidate
> Geospatial Science Center of Excellence
> South Dakota State University
> Email: Emma.White at sdstate.edu
> Web: http://globalmonitoring.sdstate.edu/people.php?view=3&a=show&id=86
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From kw1958 at gmail.com  Fri Sep 26 05:25:44 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Thu, 25 Sep 2014 23:25:44 -0400
Subject: [R] Can't seem to get lapply to work.
Message-ID: <442BC96F-AE25-4E92-9FD7-12F1813998D6@gmail.com>

Folks,

I have the following problem.

tstSet<-structure(list(corr = c(0.59, 0.62), term = c(7, 7), am = c("AmYes", 
"AmNo"), prem = c(19.5, 14.75)), .Names = c("corr", "term", "am", 
"prem"), out.attrs = structure(list(dim = structure(c(3L, 2L, 
2L, 41L), .Names = c("corr", "term", "am", "prem")), dimnames = structure(list(
    corr = c("corr=0.59", "corr=0.62", "corr=0.65"), term = c("term=5", 
    "term=7"), am = c("am=AmYes", "am=AmNo"), prem = c("prem=10.00", 
    "prem=10.25", "prem=10.50", "prem=10.75", "prem=11.00", "prem=11.25", 
    "prem=11.50", "prem=11.75", "prem=12.00", "prem=12.25", "prem=12.50", 
    "prem=12.75", "prem=13.00", "prem=13.25", "prem=13.50", "prem=13.75", 
    "prem=14.00", "prem=14.25", "prem=14.50", "prem=14.75", "prem=15.00", 
    "prem=15.25", "prem=15.50", "prem=15.75", "prem=16.00", "prem=16.25", 
    "prem=16.50", "prem=16.75", "prem=17.00", "prem=17.25", "prem=17.50", 
    "prem=17.75", "prem=18.00", "prem=18.25", "prem=18.50", "prem=18.75", 
    "prem=19.00", "prem=19.25", "prem=19.50", "prem=19.75", "prem=20.00"
    )), .Names = c("corr", "term", "am", "prem"))), .Names = c("dim", 
"dimnames")), row.names = c(460L, 239L), class = "data.frame")

> tstSet
    corr term    am  prem
460 0.59    7 AmYes 19.50
239 0.62    7  AmNo 14.75

A function:

twoRun<-function(aRow, inp) {
  aRow[["term"]] + inp
}

When I try the following:
lapply(tstSet, twoRun, 1)

I get the following error:
Error in aRow[["term"]] : subscript out of bounds

Any suggestions?

Thanks much for your time,
KW




--


From jdnewmil at dcn.davis.CA.us  Fri Sep 26 06:23:53 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 25 Sep 2014 21:23:53 -0700
Subject: [R] Can't seem to get lapply to work.
In-Reply-To: <442BC96F-AE25-4E92-9FD7-12F1813998D6@gmail.com>
References: <442BC96F-AE25-4E92-9FD7-12F1813998D6@gmail.com>
Message-ID: <292e719c-f4de-423d-9bb5-bd82ab277063@email.android.com>

On suggestion is to tell us what you want to accomplish, because that error makes perfect sense to me and your intent is rather opaque. Data frames are not lists of rows, they are lists of columns.

One solution could be

tstSet[["term"]] + 1

Another might be

tstSet <- within(tstSet,{term <- term +1})

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 25, 2014 8:25:44 PM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>Folks,
>
>I have the following problem.
>
>tstSet<-structure(list(corr = c(0.59, 0.62), term = c(7, 7), am =
>c("AmYes", 
>"AmNo"), prem = c(19.5, 14.75)), .Names = c("corr", "term", "am", 
>"prem"), out.attrs = structure(list(dim = structure(c(3L, 2L, 
>2L, 41L), .Names = c("corr", "term", "am", "prem")), dimnames =
>structure(list(
>   corr = c("corr=0.59", "corr=0.62", "corr=0.65"), term = c("term=5", 
>    "term=7"), am = c("am=AmYes", "am=AmNo"), prem = c("prem=10.00", 
> "prem=10.25", "prem=10.50", "prem=10.75", "prem=11.00", "prem=11.25", 
> "prem=11.50", "prem=11.75", "prem=12.00", "prem=12.25", "prem=12.50", 
> "prem=12.75", "prem=13.00", "prem=13.25", "prem=13.50", "prem=13.75", 
> "prem=14.00", "prem=14.25", "prem=14.50", "prem=14.75", "prem=15.00", 
> "prem=15.25", "prem=15.50", "prem=15.75", "prem=16.00", "prem=16.25", 
> "prem=16.50", "prem=16.75", "prem=17.00", "prem=17.25", "prem=17.50", 
> "prem=17.75", "prem=18.00", "prem=18.25", "prem=18.50", "prem=18.75", 
>   "prem=19.00", "prem=19.25", "prem=19.50", "prem=19.75", "prem=20.00"
>    )), .Names = c("corr", "term", "am", "prem"))), .Names = c("dim", 
>"dimnames")), row.names = c(460L, 239L), class = "data.frame")
>
>> tstSet
>    corr term    am  prem
>460 0.59    7 AmYes 19.50
>239 0.62    7  AmNo 14.75
>
>A function:
>
>twoRun<-function(aRow, inp) {
>  aRow[["term"]] + inp
>}
>
>When I try the following:
>lapply(tstSet, twoRun, 1)
>
>I get the following error:
>Error in aRow[["term"]] : subscript out of bounds
>
>Any suggestions?
>
>Thanks much for your time,
>KW
>
>
>
>
>--
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Sep 26 07:34:36 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 25 Sep 2014 22:34:36 -0700
Subject: [R] Unique values in dataframe columns
In-Reply-To: <000001cfd91b$f036a090$d0a3e1b0$@infomed.sld.cu>
References: <000001cfd91b$f036a090$d0a3e1b0$@infomed.sld.cu>
Message-ID: <61f7565d-5585-4c46-9b33-4d329bb75095@email.android.com>

You messed up the quote marks and the "library" function is not capitalized. You defined your search list by the name "list", which is also the name of a commonly used base function in R. Also, the vector you gave to GetAllSubsets had several misleading invisible conversions to character because you concatenated various types together. This will in turn lead to more invisible conversions to character when testing of columns z and J occurs. Try using a decent text editor to create your email, and keep studying the Introduction to R document that comes with the software.

I don't know of a computationally efficient solution to this problem as you have described it, and with the type conversions going on I am not sure it is even possible to get a correct solution, but the code below is my attempt. I renamed your "list" to "lst".

lapply(
    dataframe
  , function(x){
      tst <- function(x){all(x %in% y)}
    !is.na( Position( tst,lst ) )
    }
)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 25, 2014 4:53:38 PM PDT, "Maicel Monz?n P?rez" <maicel at infomed.sld.cu> wrote:
>Hello  list
>I would like to know how can  i detect  dataframe columns that have as
>unique values elements of a list.
>For example, at a  given dataframe to look for columns that unique
>values
>are elements of a list like this one
> 
>
>dataframe<-data.frame(
>x = c("yes?, "1?, "no?, "no?),
>y = c("black?, "red?, "NA?, "white?),
>z= c(T,F,T,T),
>J= c(2,7,8,9))
>Library(DescTools)
>
>list<-GetAllSubsets(c(NA,0,1,2,"yes","y","no"),min.n = 2, max.n = 5)
>
>......and to obtain  the following vector..
>TRUE,FALSE, FALSE, FALSE
>
>Best regards
>Maicel Monzon
>
>
>--
>Nunca digas nunca, di mejor: gracias, permiso, disculpe.
>
>Este mensaje le ha llegado mediante el servicio de correo electronico
>que ofrece Infomed para respaldar el cumplimiento de las misiones del
>Sistema Nacional de Salud. La persona que envia este correo asume el
>compromiso de usar el servicio a tales fines y cumplir con las
>regulaciones establecidas
>
>Infomed: http://www.sld.cu/
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Sep 26 08:02:02 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 25 Sep 2014 23:02:02 -0700
Subject: [R] Performance (speed) of ggplot
In-Reply-To: <61082859DB498E4A86977CB0DEEF77212951F899D7@SBS02.startllc.local>
References: <61082859DB498E4A86977CB0DEEF77212951F899D7@SBS02.startllc.local>
Message-ID: <d7079f2d-2cf3-4ed8-8352-f99cecf464e5@email.android.com>

You are asked in the Posting Guide to provide a small, reproducible example. Your function is Byzantine, and depends on who knows what, and I can't even see what your end product is intended to be.

I will say that I think you have missed the point with your approach to using ggplot... you might well do better with base graphics if coding each display element is necessary for your application.

ggplot is intended for a data-driven approach, where you set up data frames that contain the bulk of your graphic information, and then you should rarely need more than one call for each type of graphic element in a given plot.

That said, ggplot can be noticeably slow sometimes, so I cannot predict whether you will achieve your stated speed goal by reconfiguring the code at this point.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 25, 2014 11:30:08 AM PDT, Christopher Battles <CBattles at startllc.com> wrote:
>Hello list,
>
>I have been working on learning ggplot for its extraordinary
>flexibility compared to base plotting and have been developing a
>function to create a "Minitab-like" process capability chart.  
>
>*sigh* some of the people I interface with can only understand the data
>when it is presented in Minitab format
>
>The function creates a ggplot container to hold 10 ggplot items which
>are the main process capability chart, a Q-Q plot, and the text boxes
>with all the capabilities data.  When I run the function, the elapsed
>time is on the order of 3 seconds, the gross majority of which is user
>time.  sys time is very small.  A bit of hacking shows that the calls
>to 
>
>gt1 <- ggplot_gtable(ggplot_build(p)), 
>
>etc., each take on the order of 1/3 of a second. These times are on a
>3.2GHz Xeon workstation.  I'd like to see the entire function complete
>in less than a second.  My questions are: 1) Am I misusing ggplot,
>hence the performance hit? 2) Is there any way to increase the speed of
>this portion of the code? 3) Am I simply asking ggplot to crunch so
>much that it is inevitable that it will take a while to process?
>
>To that end, the function, vectis.cap(), can be downloaded from
>http://pastebin.com/05s5RKYw .  It runs to 962 lines of code, so I
>won't paste it here.  The offending ggplot_gtable calls are at lines
>909 - 918.
>
>Usage:
>vectis.cap(chickwts$weight, target = 300, USL = 400, LSL = 100)
>
>Thank you,
>
>Christopher Battles
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Sep 26 11:42:08 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Sep 2014 09:42:08 +0000
Subject: [R] error in rownames
In-Reply-To: <CAPtX2qnenxyQOFUEHWS9aJbZJMVcbDfODhunDwO+F4_bQMJvuA@mail.gmail.com>
References: <CAPtX2q=siOx6FQT9s3mNbcGcppMNv4OjmAnU7btT48u6WYppWw@mail.gmail.com>
	<CAN5YmCEZPPRqucCTchb_8+v+_as-MCzJj4dd_Sn=URcSYwcbKA@mail.gmail.com>
	<CAPtX2qkXCOfxrR2GdGKxVGi9ythq0-hCrWWQE1oNJesmTrPxXw@mail.gmail.com>
	<CAPtX2qnenxyQOFUEHWS9aJbZJMVcbDfODhunDwO+F4_bQMJvuA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE7FC7@SRVEXCHMBX.precheza.cz>

Hi.

Partly. You got response from David regarding HTML formating. I polished scrammbled text but I got

> AsciiGridImpute(type.rf, xfile, outfile)
Error in file(xfiles[[i]], open = "rt") : cannot open the connection
In addition: Warning message:
In file(xfiles[[i]], open = "rt") :
  cannot open file 'sinaspect.asc': No such file or directory
>

So still something is missing.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Chris Jackson-Jordan
> Sent: Thursday, September 25, 2014 5:57 PM
> To: Adams, Jean
> Cc: R help
> Subject: Re: [R] error in rownames
>
> Sorry to respond again so quickly, but is this what you meant?
>
>
> y <- subset(training, select = c(ResponseSu))> x <- subset(training,
> select = c(sinaspect, habitat, elevation, disttowat, disttoroad,
> slope, cosaspect))> type.rf <- yai(x=x, y=y, method="randomForest",
> rfMode="regression", ntree=20)> outfile <-
> list(Type="RespSurf_Reg.asc")> xfile <-list(sinaspect="sinaspect.asc",
> habitat="habitat.asc", elevation="elevation.asc",+
> disttowat="disttowat.asc", disttoroad="disttoroad.asc",
> slope="slope.asc",+ cosaspect="cosaspect.asc")> dput(training[1:60,
> ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L), cosaspect = c(-0.546873, 0.333357, 0.796074, -0.906097,
> 0.546751, -0.903426, 0.55381, 0.761338, 0.858955, -0.784384,
> 0.790582, 0.0429794, 0.89785, 0.998368, 0.991524, -0.769041,
> -0.104549, -0.565003, -0.56414, 0.432783, -0.652663, -0.477157,
> -0.642625, 0.0719997, 0.0202113, -0.444488, -0.38204, -0.3565,
> -0.199093, 0.545715, -0.99322, 0.852507, -0.524166, 0.999378,
> -0.980175, -0.922242, -0.954118, -0.902187, -0.354786, 0.112082,
> -0.198151, -0.502453, -0.676458, -0.0673507, -0.999526, -0.840507,
> 0.989883, -0.832413, -0.733279, -0.993005, -0.479475, -0.326237,
> -0.848538, -0.546614, -0.986488, -0.948983, -0.993527, -0.964193,
> -0.971359, -0.287455), disttoroad = c(368.767, 880.661, 563.239,
> 72.1515, 227.697, 313.486, 265.001, 227.697, 219.137, 518.349,
> 23.048, 10.3074, 41.2294, 103.074, 497.857, 494.968, 524.968,
> 674.01, 10.3074, 133.996, 10.3074, 10.3074, 10.3074, 20.6147,
> 226.058, 10.3074, 272.122, 226.762, 177.933, 204.075, 82.4589,
> 61.8442, 14.5768, 20.6147, 29.1536, 92.1918, 75.0387, 113.849,
> 133.996, 46.0959, 123.688, 120.645, 185.533, 133.996, 61.8442,
> 103.074, 120.203, 154.61, 138.671, 150.077, 51.5368, 190.058,
> 72.884, 20.6147, 115.24, 30.9221, 83.1006, 333.041, 30.9221,
> 288.606), disttowat = c(981.15, 1448.98, 729.496, 509.146, 171.549,
> 322.671, 566.998, 631.783, 783.359, 407.76, 1036.59, 352.264,
> 306.113, 235.27, 241.289, 269.769, 342.633, 660.476, 578.04,
> 1844.99, 1753.65, 408.801, 543.951, 756.661, 632.875, 540.031,
> 927.09, 1120.47, 1166.24, 65.9993, 474.586, 437.911, 162.974,
> 576.66, 557.932, 547.844, 793.667, 420.586, 208.708, 10.3074,
> 497.857, 383.595, 371.78, 130.379, 449.406, 111.014, 162.974,
> 393.574, 463.831, 360.021, 404.096, 43.7304, 140.195, 182.647,
> 277.343, 84.9967, 87.4609, 633.546, 60.1017, 42.4983), elevation =
> c(2000.9,
> 2198.18, 2194.78, 1863.8, 1902.25, 1867.29, 1943.94, 1912.35,
> 1920.11, 1870.94, 1914.56, 1904.4, 1900.92, 1893.94, 1888.02,
> 1889.71, 1890.95, 1894.32, 1896.11, 2011.99, 2025.01, 1902.45,
> 1901.99, 2030.09, 2038.39, 1910.48, 2054.46, 1918.92, 1951.15,
> 1941.24, 1853.78, 1863.76, 1875.9, 1863.6, 1864.91, 1864.18,
> 1872.85, 1866.81, 1863.06, 1896.47, 1863.95, 1873.13, 1873.44,
> 1888.06, 1874.35, 1888.06, 1911.09, 1872.43, 1854.83, 1866.98,
> 1876.95, 1875.88, 1875.19, 1888.27, 1900.82, 1870.49, 1903.17,
> 1871.52, 1902.28, 1862.18), habitat = c(14L, 1L, 9L, 2L, 5L,
> 2L, 5L, 1L, 1L, 2L, 1L, 4L, 10L, 8L, 2L, 2L, 2L, 2L, 4L, 10L,
> 5L, 4L, 4L, 3L, 5L, 4L, 3L, 3L, 7L, 6L, 2L, 2L, 2L, 13L, 2L,
> 2L, 2L, 2L, 2L, 11L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 10L, 2L, 2L, 2L, 2L, 2L), sinaspect = c(-0.837215,
> -0.942801, -0.6052, 0.42307, -0.837295, -0.428745, -0.832643,
> -0.648355, -0.512051, -0.620276, -0.612357, -0.999076, -0.440302,
> -0.0571153, 0.129924, -0.6392, -0.99452, -0.825089, 0.825679,
> -0.901498, -0.757648, 0.878818, 0.766181, -0.997405, -0.999796,
> 0.895785, 0.924146, 0.934295, 0.979981, -0.837971, 0.11625, -0.522717,
> -0.851616, -0.0352723, 0.198133, -0.386614, -0.29943, -0.431345,
> -0.934948, -0.993699, -0.980172, -0.864605, -0.736481, 0.997729,
> -0.0307994, -0.541801, 0.141883, -0.554156, 0.679928, 0.118074,
> -0.877556, -0.945288, -0.529134, -0.837385, -0.163837, -0.315329,
> -0.113595, 0.265202, -0.237618, -0.957794), slope = c(28.8435,
> 2.74077, 34.8524, 0.151366, 18.6671, 0.132943, 17.6102, 16.0996,
> 9.36435, 0.452752, 1.9657, 0.996516, 1.74535, 0.148506, 0.0372119,
> 0.695029, 0.455934, 0.514605, 12.6356, 16.0089, 8.21627, 1.038,
> 0.498378, 3.6306, 4.11395, 10.3384, 15.5258, 16.5868, 30.8142,
> 11.3484, 0.041589, 0.102877, 0.277677, 0.642031, 0.663088, 0.289154,
> 1.05732, 0.216892, 0.233333, 0.248217, 0.176358, 0.193456, 0.245883,
> 0.108306, 0.583814, 0.106767, 0.102823, 0.395655, 1.33206, 0.243522,
> 0.811744, 0.116737, 0.573048, 0.672642, 0.415712, 0.396212, 0.447255,
> 0.13081, 0.410137, 0.727014), POINT_X = c(518112.161959, 517972.063651,
> 517506.021145, 514057.581202, 517528.545479, 514676.488847,
> 513464.270056,
> 513494.888654, 513586.036568, 515116.814902, 514135.06997,
> 519325.532909,
> 519683.204101, 519319.141302, 516830.545136, 516920.973864,
> 516979.229306,
> 517071.772928, 519951.348487, 515653.777436, 515800.193588,
> 520379.011629,
> 520642.986006, 519523.715662, 519637.527771, 521060.390222,
> 516952.842708,
> 517668.222196, 517617.227048, 520449.447941, 517052.212122,
> 514140.686317,
> 516431.927756, 514013.562097, 514243.405122, 514221.174814,
> 515311.187185,
> 514481.609078, 516589.086276, 517741.589283, 514186.085127,
> 515664.921099,
> 515733.804812, 517203.924014, 515751.253306, 517234.791292,
> 518427.782061,
> 515550.127549, 517048.546153, 514494.364954, 516677.023244,
> 516310.352775,
> 516408.158711, 517318.540292, 517974.751913, 515658.214168,
> 517623.031178,
> 514989.975043, 517581.921764, 516383.86435), POINT_Y = c(4808806.0847,
> 4810255.98377, 4811945.72636, 4812470.84981, 4812715.02483,
> 4813198.79081,
> 4813211.23833, 4813295.64352, 4813440.86864, 4813568.04148,
> 4813679.00767,
> 4813733.06168, 4814419.5912, 4814825.63894, 4816350.24526,
> 4816582.01425,
> 4816699.05741, 4817224.27439, 4817499.81568, 4817609.1733,
> 4817984.23946,
> 4818382.23486, 4818760.15577, 4819648.35709, 4819860.27227,
> 4819904.21184,
> 4820486.25819, 4820487.64551, 4820517.62914, 4820967.31897,
> 4809549.90161,
> 4812476.57785, 4813749.28092, 4812522.41608, 4812915.00417,
> 4812798.13954,
> 4813967.9282, 4813155.89553, 4811594.81676, 4817137.5718,
> 4812661.71143,
> 4813651.06428, 4813725.92053, 4816265.95688, 4813846.96134,
> 4816303.22503,
> 4819272.23858, 4813534.92529, 4809713.38594, 4813053.33525,
> 4813732.08346,
> 4813902.3087, 4813642.82751, 4816248.7419, 4817916.27765,
> 4813224.05382,
> 4818419.86058, 4813769.26218, 4818313.11043, 4811436.27069),
>     ResponseSu = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.394676,
>     1.435637, 1.449758, 1.461653, 1.471431, 1.475303, 1.475902,
>     1.481716, 1.490055, 1.493364, 1.493391, 1.495781, 1.509532,
>     1.51392, 1.519015, 1.522284, 1.52319, 1.525427, 1.527304,
>     1.534297, 1.534883, 1.535686, 1.536898, 1.539433, 1.544022,
>     1.553086, 1.555488, 1.581577, 1.585341, 1.585509)), .Names =
> c("CID",
> "cosaspect", "disttoroad", "disttowat", "elevation", "habitat",
> "sinaspect", "slope", "POINT_X", "POINT_Y", "ResponseSu"), row.names =
> c(NA,
> 60L), class = "data.frame")> AsciiGridImpute(type.rf, xfile, outfile)
>
>
> On Thu, Sep 25, 2014 at 11:51 AM, Chris Jackson-Jordan <
> jacksonjordancm at gmail.com> wrote:
>
> > Thanks again for your help, I am obviously a novice programmer. That
> said,
> > I think I am confused as to what you mean by reproducible code. Were
> the 20
> > lines of code not reproducible? Also, what do you mean by the help
> for
> > Ascii Grid Impute. I'm not able to find it online or within the R
> platform.
> > Finally, I know that mapping to files on my PC is problematic, should
> I be
> > attaching the files in my email? Like I said, this is all quite new
> to me.
> > Sorry if my questions are painfully naive. I am hoping to get this
> project
> > going but just can't get past this stumbling block. Thanks again for
> the
> > help thus far.
> >
> > Chris
> >
> > On Thu, Sep 25, 2014 at 11:06 AM, Adams, Jean <jvadams at usgs.gov>
> wrote:
> >
> >> Chris,
> >>
> >> You are not making it easy for R help folks to help you.
> >>
> >> You need to supply *** reproducible *** code, so that folks can
> simply
> >> copy and paste directly from your e-mail to R and reproduce the
> error that
> >> you are getting.  Do you need a guide to follow?  See the first 60-
> some
> >> lines of code provided in the example of the help for
> AsciiGridImpute,
> >>      ?AsciiGridImpute
> >> I can copy that code into R and make it run.  You need to do the
> same
> >> thing in your e-mail.  Don't refer to directories on your PC.
> >>
> >> I submitted a simplified version of the code you shared (below), but
> ran
> >> into an error because the *.asc files were not already created.  So,
> I
> >> suggest that you insert some general code to get that done for your
> >> example, and resubmit your question.
> >>
> >> Jean
> >>
> >>
> >> training <- structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
> >> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
> >> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
> >> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
> >> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
> >> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
> >> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
> >> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
> >> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
> >> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
> >> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
> >> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
> >> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
> >> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
> >> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect =
> c(0.915474,
> >> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
> >> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
> >> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
> >> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
> >> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
> >> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
> >> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
> >> 516073.554503, 516019.068701, 515506.165434, 517353.141738,
> 520076.487742,
> >> 517973.141394, 516823.388106, 514784.035218, 518298.237046,
> 519796.43389,
> >> 515714.490202, 518829.909017, 519385.491579, 518659.851297,
> 516654.780318,
> >> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487,
> 4816762.97919,
> >> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912,
> 4818923.42436,
> >> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581,
> 4816674.91138,
> >> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774,
> 4814503.57051,
> >> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu =
> c(1.822784,
> >> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
> >> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
> >> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336,
> 141.478417,
> >> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad",
> "disttowat",
> >> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
> >> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")
> >>
> >> library(yaImpute)
> >>
> >> y <- subset(training, select = c(ResponseSu))
> >> x <- subset(training, select = c(sinaspect, habitat, elevation,
> >> disttowat, disttoroad, slope, cosaspect))
> >> type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression",
> >> ntree=20)
> >> outfile <- list(Type="RespSurf_Reg.asc")
> >> xfile <-list(sinaspect="sinaspect.asc", habitat="habitat.asc",
> >> elevation="elevation.asc",
> >> disttowat="disttowat.asc", disttoroad="disttoroad.asc",
> >> slope="slope.asc",
> >> cosaspect="cosaspect.asc")
> >>
> >> # insert lines of code here to create the *.asc files
> >> # see the example with the iris data in ?AsciiGridImpute
> >>
> >> AsciiGridImpute(type.rf, xfile, outfile)
> >>
> >>
> >> On Mon, Sep 22, 2014 at 11:13 AM, Chris Jackson-Jordan <
> >> jacksonjordancm at gmail.com> wrote:
> >>
> >>> Dear fellow R users,
> >>>
> >>> I am trying to run the random forest and Yaimpute packages in R to
> >>> impute a grid to project in a gis. However, after running the
> >>> imputation I keep getting an error in the rownames. This sounds
> simple
> >>> enough, but I cannot figure out what these rownames are reffering
> to.
> >>> Any ideas? I am fairly new to R so im sure it is an easy fix. Any
> help
> >>> would be awesome.
> >>>
> >>> Thanks,
> >>>
> >>> Chris
> >>>
> >>>
> >>> > y <- subset(training, select = c(ResponseSu)) > x <-
> subset(training,
> >>> select = c(sinaspect, habitat, slope, elevation, cosaspect,
> disttoroad,
> >>> disttowat)) > type.rf <- yai(x=x, y=y, method="randomForest",
> >>> rfMode="regression", ntree= 2000) > outfile <- list(Type =
> >>> "D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc") > xfile
> >>> <-list(sinaspect
> >>>
> >>>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII
> _Files2/sinaspect.asc",
> >>> habitat
> >>>
> >>>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII
> _Files2/habitat.asc",
> >>> elevation
> >>>
> >>>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII
> _Files2/elevation.asc",
> >>> disttowat
> >>>
> >>>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII
> _Files2/disttowat.asc",
> >>> disttoroad
> >>>
> >>>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII
> _Files2/disttoroad.asc",
> >>> slope
> >>>
> >>>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII
> _Files2/slope.asc",
> >>> cosaspect
> >>>
> >>>
> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII
> _Files2/cosaspect.asc")
> >>> > AsciiGridImpute(type.rf, xfile, outfile) Rows per dot: 19 Rows to
> do:
> >>> 1900 ToDo:
> >>>
> >>>
> .......................................................................
> .............................
> >>> Done: . Error in `rownames<-`(`*tmp*`, value = c("23x0049",
> "23x0050",
> >>> "23x0051", : attempt to set rownames on object with no dimensions
> >>>
> >>> here is an example of my training data
> >>>
> >>>
> >>>  > dput(training[1:20, ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
> >>>
> >>> 0L, 0L, 0L, 0L, 0L,
> >>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
> >>> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
> >>> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
> >>> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
> >>> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
> >>> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
> >>> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
> >>> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536,
> 1039.97,
> >>> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
> >>> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
> >>> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
> >>> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
> >>> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
> >>> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
> >>> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect =
> >>> c(0.915474,
> >>> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
> >>> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
> >>> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
> >>> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
> >>> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
> >>> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
> >>> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
> >>> 516073.554503, 516019.068701, 515506.165434, 517353.141738,
> >>> 520076.487742,
> >>> 517973.141394, 516823.388106, 514784.035218, 518298.237046,
> 519796.43389,
> >>> 515714.490202, 518829.909017, 519385.491579, 518659.851297,
> >>> 516654.780318,
> >>> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487,
> 4816762.97919,
> >>> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912,
> >>> 4818923.42436,
> >>> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581,
> 4816674.91138,
> >>> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774,
> >>> 4814503.57051,
> >>> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu =
> c(1.822784,
> >>> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
> >>> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186,
> 91.843573,
> >>> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336,
> 141.478417,
> >>> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad",
> "disttowat",
> >>> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
> >>> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")>
> >>> library("randomForest", lib.loc="~/RStudio/R/library")
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From maechler at stat.math.ethz.ch  Fri Sep 26 11:48:49 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 26 Sep 2014 11:48:49 +0200
Subject: [R] Median of streaming data
In-Reply-To: <54235766.3070400@auckland.ac.nz>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>
	<54226816.700@auckland.ac.nz>
	<21538.32250.67575.749398@stat.math.ethz.ch>
	<54235766.3070400@auckland.ac.nz>
Message-ID: <21541.13953.417228.646860@stat.math.ethz.ch>

>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>     on Thu, 25 Sep 2014 11:44:38 +1200 writes:

    > On 24/09/14 20:16, Martin Maechler wrote: <SNIP>

    >> 1) has your proposal ever been provided in R?  I'd be
    >> happy to add it to the robustX
    >> (http://cran.ch.r-project.org/web/packages/robustX) or
    >> even robustbase
    >> (http://cran.ch.r-project.org/web/packages/robustbase)
    >> package.

    > <SNIP>

    > I have coded up the algorithm from the Cameron and Turner
    > paper.  Dunno if it gives exactly the same results as my
    > (Splus?) code from lo these many years ago (the code that
    > is lost in the mists of time), but it *seems* to work.

excellent, thank you, Rolf!

    > It is not designed to work with actual "streaming" data
    > --- I don't know how to do that.  It takes a complete data
    > vector as input.  Someone who knows about streaming data
    > should be able to adapt it pretty easily.  Said he, the
    > proverbial optimist.

I agree; that should not be hard. 
One way is to replace   'y[ind]' by   'getY(ind)' everywhere in the code
and let 'getY' be an argument to rlas() provided by the user.

    > The function code and a help file are attached.  These
    > files have had their names changed to end in ".txt" so
    > that they will get through the mailing list processor
    > without being stripped.  With a bit of luck.
;-)

It did work indeed.
I've added them to  'robustX' -- on R-forge,
including a plot() method and some little more flexibility.

  --> https://r-forge.r-project.org/R/?group_id=59

Thank you for all the other pointers to litterature (but none to
software), some of which quite recent.


One old idea that was not directly mentioned I think is the
"Remedian"  of Rouseeuw and Basset:

  Peter J. Rousseeuw and Gilbert W. Bassett, Jr. (1998)
  The Remedian: A Robust Averaging Method for Large Data Sets
  Journal of the American Statistical Association, Vol. 85, No. 409, pp. 97-104
	  [URL: http://www.jstor.org/stable/2289530]

which is also easy to implement and I plan to add to robustbase
(as I'd want to use the C code already in robustbase) as a
"reference" estimator.

Personally, I think there is quite some room for research and
implementation, not the least because the litterature seems to
always be a bit incomplete {one "school" not knowning about, or
at least not citing works of the other "school", etc...}

Martin

--
Martin Maechler, ETH Zurich


    > If they *don't* get through, anyone who is interested
    > should contact me and I will send them to you "privately".

    > cheers,
    > Rolf

    > -- 
    > Rolf Turner Technical Editor ANZJS 
    > 
    > external: rlas.R, plain text]
    > external: rlas.Rd, plain text]


From petr.pikal at precheza.cz  Fri Sep 26 11:54:32 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Sep 2014 09:54:32 +0000
Subject: [R] Performance (speed) of ggplot
In-Reply-To: <d7079f2d-2cf3-4ed8-8352-f99cecf464e5@email.android.com>
References: <61082859DB498E4A86977CB0DEEF77212951F899D7@SBS02.startllc.local>
	<d7079f2d-2cf3-4ed8-8352-f99cecf464e5@email.android.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE800B@SRVEXCHMBX.precheza.cz>

Hi

I will second Jeff. If you want several plots on one page it could be more convenient to use standard plot.

see
?layout or ?split.screen
for complex figures

or ?par mfrow

for simple layout.

In all cases it is difficult to combine base and grid graphics though.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Jeff Newmiller
> Sent: Friday, September 26, 2014 8:02 AM
> To: Christopher Battles; r-help at r-project.org
> Subject: Re: [R] Performance (speed) of ggplot
>
> You are asked in the Posting Guide to provide a small, reproducible
> example. Your function is Byzantine, and depends on who knows what, and
> I can't even see what your end product is intended to be.
>
> I will say that I think you have missed the point with your approach to
> using ggplot... you might well do better with base graphics if coding
> each display element is necessary for your application.
>
> ggplot is intended for a data-driven approach, where you set up data
> frames that contain the bulk of your graphic information, and then you
> should rarely need more than one call for each type of graphic element
> in a given plot.
>
> That said, ggplot can be noticeably slow sometimes, so I cannot predict
> whether you will achieve your stated speed goal by reconfiguring the
> code at this point.
> -----------------------------------------------------------------------
> ----
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> -----------------------------------------------------------------------
> ----
> Sent from my phone. Please excuse my brevity.
>
> On September 25, 2014 11:30:08 AM PDT, Christopher Battles
> <CBattles at startllc.com> wrote:
> >Hello list,
> >
> >I have been working on learning ggplot for its extraordinary
> >flexibility compared to base plotting and have been developing a
> >function to create a "Minitab-like" process capability chart.
> >
> >*sigh* some of the people I interface with can only understand the
> data
> >when it is presented in Minitab format
> >
> >The function creates a ggplot container to hold 10 ggplot items which
> >are the main process capability chart, a Q-Q plot, and the text boxes
> >with all the capabilities data.  When I run the function, the elapsed
> >time is on the order of 3 seconds, the gross majority of which is user
> >time.  sys time is very small.  A bit of hacking shows that the calls
> >to
> >
> >gt1 <- ggplot_gtable(ggplot_build(p)),
> >
> >etc., each take on the order of 1/3 of a second. These times are on a
> >3.2GHz Xeon workstation.  I'd like to see the entire function complete
> >in less than a second.  My questions are: 1) Am I misusing ggplot,
> >hence the performance hit? 2) Is there any way to increase the speed
> of
> >this portion of the code? 3) Am I simply asking ggplot to crunch so
> >much that it is inevitable that it will take a while to process?
> >
> >To that end, the function, vectis.cap(), can be downloaded from
> >http://pastebin.com/05s5RKYw .  It runs to 962 lines of code, so I
> >won't paste it here.  The offending ggplot_gtable calls are at lines
> >909 - 918.
> >
> >Usage:
> >vectis.cap(chickwts$weight, target = 300, USL = 400, LSL = 100)
> >
> >Thank you,
> >
> >Christopher Battles
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Thierry.ONKELINX at inbo.be  Fri Sep 26 12:09:27 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 26 Sep 2014 10:09:27 +0000
Subject: [R] Performance (speed) of ggplot
In-Reply-To: <61082859DB498E4A86977CB0DEEF77212951F899D7@SBS02.startllc.local>
References: <61082859DB498E4A86977CB0DEEF77212951F899D7@SBS02.startllc.local>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AF6517@inbomail.inbo.be>

You are using ggplot2 very inefficiently. Many geom's plot only one data point. You can combine several of them in a single geom. Have a look at this gridExtra package which has some useful functions like grid.arrange and tableGrob.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Christopher Battles
Verzonden: donderdag 25 september 2014 20:30
Aan: r-help at r-project.org
Onderwerp: [R] Performance (speed) of ggplot

Hello list,

I have been working on learning ggplot for its extraordinary flexibility compared to base plotting and have been developing a function to create a "Minitab-like" process capability chart.

*sigh* some of the people I interface with can only understand the data when it is presented in Minitab format

The function creates a ggplot container to hold 10 ggplot items which are the main process capability chart, a Q-Q plot, and the text boxes with all the capabilities data.  When I run the function, the elapsed time is on the order of 3 seconds, the gross majority of which is user time.  sys time is very small.  A bit of hacking shows that the calls to

gt1 <- ggplot_gtable(ggplot_build(p)),

etc., each take on the order of 1/3 of a second. These times are on a 3.2GHz Xeon workstation.  I'd like to see the entire function complete in less than a second.  My questions are: 1) Am I misusing ggplot, hence the performance hit? 2) Is there any way to increase the speed of this portion of the code? 3) Am I simply asking ggplot to crunch so much that it is inevitable that it will take a while to process?

To that end, the function, vectis.cap(), can be downloaded from http://pastebin.com/05s5RKYw .  It runs to 962 lines of code, so I won't paste it here.  The offending ggplot_gtable calls are at lines 909 - 918.

Usage:
vectis.cap(chickwts$weight, target = 300, USL = 400, LSL = 100)

Thank you,

Christopher Battles

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From kw1958 at gmail.com  Fri Sep 26 12:51:59 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Fri, 26 Sep 2014 06:51:59 -0400
Subject: [R] Can't seem to get lapply to work.
In-Reply-To: <292e719c-f4de-423d-9bb5-bd82ab277063@email.android.com>
References: <442BC96F-AE25-4E92-9FD7-12F1813998D6@gmail.com>
	<292e719c-f4de-423d-9bb5-bd82ab277063@email.android.com>
Message-ID: <193B1212-BF63-418B-9E9B-C5CF846B6BD3@gmail.com>

Jeff,
Of course a data.frame is a list of columns. Duh!

Sorry about that. Was working about 10 hours straight.

Also sorry about the excess attributes. They were created by via expand.grid.

Here is my current solution which seems to be working:

    lapply(1:nrow(tstSet), function(x, y, z) oneRun(y[x,],z), tstSet, inp)

Thanks so much for your timely help,
Best,
KW


--

On Sep 26, 2014, at 12:23 AM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:

> On suggestion is to tell us what you want to accomplish, because that error makes perfect sense to me and your intent is rather opaque. Data frames are not lists of rows, they are lists of columns.
> 
> One solution could be
> 
> tstSet[["term"]] + 1
> 
> Another might be
> 
> tstSet <- within(tstSet,{term <- term +1})
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On September 25, 2014 8:25:44 PM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>> Folks,
>> 
>> I have the following problem.
>> 
>> tstSet<-structure(list(corr = c(0.59, 0.62), term = c(7, 7), am =
>> c("AmYes", 
>> "AmNo"), prem = c(19.5, 14.75)), .Names = c("corr", "term", "am", 
>> "prem"), out.attrs = structure(list(dim = structure(c(3L, 2L, 
>> 2L, 41L), .Names = c("corr", "term", "am", "prem")), dimnames =
>> structure(list(
>>  corr = c("corr=0.59", "corr=0.62", "corr=0.65"), term = c("term=5", 
>>   "term=7"), am = c("am=AmYes", "am=AmNo"), prem = c("prem=10.00", 
>> "prem=10.25", "prem=10.50", "prem=10.75", "prem=11.00", "prem=11.25", 
>> "prem=11.50", "prem=11.75", "prem=12.00", "prem=12.25", "prem=12.50", 
>> "prem=12.75", "prem=13.00", "prem=13.25", "prem=13.50", "prem=13.75", 
>> "prem=14.00", "prem=14.25", "prem=14.50", "prem=14.75", "prem=15.00", 
>> "prem=15.25", "prem=15.50", "prem=15.75", "prem=16.00", "prem=16.25", 
>> "prem=16.50", "prem=16.75", "prem=17.00", "prem=17.25", "prem=17.50", 
>> "prem=17.75", "prem=18.00", "prem=18.25", "prem=18.50", "prem=18.75", 
>>  "prem=19.00", "prem=19.25", "prem=19.50", "prem=19.75", "prem=20.00"
>>   )), .Names = c("corr", "term", "am", "prem"))), .Names = c("dim", 
>> "dimnames")), row.names = c(460L, 239L), class = "data.frame")
>> 
>>> tstSet
>>   corr term    am  prem
>> 460 0.59    7 AmYes 19.50
>> 239 0.62    7  AmNo 14.75
>> 
>> A function:
>> 
>> twoRun<-function(aRow, inp) {
>> aRow[["term"]] + inp
>> }
>> 
>> When I try the following:
>> lapply(tstSet, twoRun, 1)
>> 
>> I get the following error:
>> Error in aRow[["term"]] : subscript out of bounds
>> 
>> Any suggestions?
>> 
>> Thanks much for your time,
>> KW
>> 
>> 
>> 
>> 
>> --
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From otto.pichlhoefer at meduniwien.ac.at  Fri Sep 26 12:21:14 2014
From: otto.pichlhoefer at meduniwien.ac.at (Otto =?utf-8?b?UGljaGxow7ZmZXI=?=)
Date: Fri, 26 Sep 2014 10:21:14 +0000
Subject: [R] Help with conversion of variable labels (Hmisc and Epicalc)
Message-ID: <loom.20140926T121801-156@post.gmane.org>

For my epidemiological analysis I use the packages Epicalc and Hmisc ? 
among others. Both packages allow to assign variable labels that will 
appear in the output of the respective packages? own functions. The modes 
of storage of the labels in a dataframe are very different. I am 
wonderiung if there is a function that would allow to easily convert 
Epicalc labels to Hmisc labels and possibly the other way around. 

Unfortunately I am not adept enough in R to write such a function myself.

--
Otto Pichlh?fer


From thiebault at artenum.com  Fri Sep 26 13:55:45 2014
From: thiebault at artenum.com (=?iso-8859-1?Q?Beno=EEt_Thi=E9bault?=)
Date: Fri, 26 Sep 2014 13:55:45 +0200
Subject: [R] [rJava] RJavaClassLoader and system classloader
Message-ID: <A7A9DDD1-65BE-45EA-9BD1-EEC43738D9BC@artenum.com>

Hi everyone,

I want to call a Java application from R and have encountered some problems with the way rJava deals with the system class loader.

To run my application, I use the following R script:

> library(rJava)
> .jinit()
> .jaddClassPath("myApp.jar")
> rWrapper <- .jnew("org/test/RWrapper")
> .jcall(rWrapper,"V","start")

My Java application has a plugins loading mechanism that uses a specific PluginClassLoader to load plugins stored in additional JAR files (e.g. plugin.jar). This PluginClassLoader is programed so that it knows and loads the plugins JARs. As any Java classloader, it is a child of the system class loader.

Finally, plugins not only use classes stored in their plugin.jar file, they also depend on classes contained in the main myApp.jar file (the Plugin interface is for example defined in the myApp.far)

In a pure Java environment, myApp.jar is known from the system class loader (it is in the classpath) and thus the PluginClassLoader can load classes from the plugin (it knows both about the plugin.jar and the myApp.jar files)

In the R context however, using the above script, its the RJavaClassLoader that knows about the myApp.jar file. The org.test.RWrapper class is instatiated by the RJavaClassLoader. The system class loader however does not know about myApp.jar anymore. Neither does the PluginClassLoader. So when the PluginClassLoader loads a plugin class, it can only load classes that are in the plugin.jar file and as soon as a class from the myApp.jar file is required by the plugin, it crashes with a java.lang.NoClassDefFoundError message.

My question is: how can I force rJava to load the classpath in the system classloader and not only in the RJavaClassLoader?

I cannot make the PluginClassLoader know the RJavaClassLoader as my application also has to run in a non-R environment.

Thanks for your time,

Kind regards,

Ben

From erickokuto at gmail.com  Fri Sep 26 09:32:42 2014
From: erickokuto at gmail.com (Erick Okuto)
Date: Fri, 26 Sep 2014 10:32:42 +0300
Subject: [R] Savitzky-Golay Smoother
Message-ID: <CAB-=SDXJqE8MQ113EOZF02PLJCYT75jQkrdz+mUEE9LTc1fYFw@mail.gmail.com>

Dear Paul and Henrik,
I have a time series with some missing data points that i need smoothed
using Savitzky-Golay filter. Related question was asked  here
http://thr3ads.net/r-help/2012/11/2121748-Savitzky-Golay-filtering-with-missing-data
but no straight forward answer was posted. However, Henrik (cc'd here) did
ask related question on smoothing for reflectance here
http://thr3ads.net/r-help/2004/02/835137-Savitzky-Golay-smoothing-for-reflectance-data
which i have as well been unable to follow up. I will be glad if you could
assist me with some insights on the way forward or point to a relevant
source of help.

I have attached a simple test data plus the R code which only work with non
missing data. I will appreciate any possible assistance.

Thanks,
Erick.
-- 
*Erick Okuto, Ph.D.*
* Candidate*
*School of Mathematics & Actuarial Science*
*Jaramogi Oginga Odinga University of Science & Technology (JOOUST)/ World
Agroforestry Centre (ICRAF), **Climate Change Unit, Nairobi-Kenya. *
Voice:  +254207224154?    Mobile: +254725005276    Skype id:  erickokuto
Email: erickokuto at gmail.com

From dwinsemius at comcast.net  Fri Sep 26 16:12:07 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Sep 2014 07:12:07 -0700
Subject: [R] Help with conversion of variable labels (Hmisc and Epicalc)
In-Reply-To: <loom.20140926T121801-156@post.gmane.org>
References: <loom.20140926T121801-156@post.gmane.org>
Message-ID: <199F7E89-5BBD-4206-B39F-7B728CFFFBF6@comcast.net>


On Sep 26, 2014, at 3:21 AM, Otto Pichlh?fer wrote:

> For my epidemiological analysis I use the packages Epicalc and Hmisc ? 
> among others. Both packages allow to assign variable labels that will 
> appear in the output of the respective packages? own functions. The modes 
> of storage of the labels in a dataframe are very different. I am 
> wonderiung if there is a function that would allow to easily convert 
> Epicalc labels to Hmisc labels and possibly the other way around. 
> 
> Unfortunately I am not adept enough in R to write such a function myself.

You needt to use the attributes function to display hte names and structures of the "labels" in the two packages. Firts look at help(pack=Hmisc) and help(pack=Epicalc) to see how the package-specific functions are documented.

-- 

David Winsemius
Alameda, CA, USA


From cryan at binghamton.edu  Fri Sep 26 16:38:42 2014
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Fri, 26 Sep 2014 10:38:42 -0400
Subject: [R] package loadable in R 3.1.1 Rterm but not in emacs/ESS
Message-ID: <CAM+rpYnDyRw-K434fcydhcmDwYGHMjH-r58W_b_LX1zZkVN3Qw@mail.gmail.com>

I'm running R on Windows 7. Clean install on a brand new computer
yesterday.  I installed Protext then R then Vincent Goulet's emacs
with ESS, in that order.

I then installed some R packages, in the R terminal window.  Among them was car

Today I opened emacs, hit M-x R to start an R session, and tried to
load the car library. Results looked like the following:


R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: i386-w64-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> > options(chmhelp=FALSE, help_type="text")
> options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient.exe', show.error.locations=TRUE)
>
> library(car)
Error in library(car) : there is no package called 'car'
>



However, in an R terminal (that is, outside of emacs) the car package
loads fine:

R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: i386-w64-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(car)
>

I have not encountered this before and am confused. Why would R 3.1.1
in its terminal "see" a library, whereas it would not in emacs?  (car
is just an example; the same thing happens with zoo, stringr, Hmisc,
and others.)

Thanks.

--Chris Ryan


From jluo.rhelp at gmail.com  Fri Sep 26 19:59:14 2014
From: jluo.rhelp at gmail.com (Jack Luo)
Date: Fri, 26 Sep 2014 13:59:14 -0400
Subject: [R] question regarding pcalg package
Message-ID: <CAD-E8+4=QRd93sg-bKp8jAQLbvxYaF7a8HgH__sM=-Pc3SfNzw@mail.gmail.com>

Hi,

I am trying to use the pcalg package to do some causal inference on some
high dimensional omics data (~ 30k variables). It takes forever to run and
my machine get stuck. I just realized that conditional independence test
can be calculated without using the correlation matrix (I think it's just
looping through all the partial correlation calculation), I am wondering
after getting all the edges (maybe in a format of two column matrix with
source and targets in each one), then how to use pc, fci, rfci, etc to do
the causal inference. Right now it seems that we need to supply a
correlation matrix into those algorithms in the sufficient statistics
argument.

Thanks,

-Jack

	[[alternative HTML version deleted]]


From pkienzle at gmail.com  Fri Sep 26 16:07:35 2014
From: pkienzle at gmail.com (Paul Kienzle)
Date: Fri, 26 Sep 2014 10:07:35 -0400
Subject: [R] Savitzky-Golay Smoother
In-Reply-To: <CAB-=SDXJqE8MQ113EOZF02PLJCYT75jQkrdz+mUEE9LTc1fYFw@mail.gmail.com>
References: <CAB-=SDXJqE8MQ113EOZF02PLJCYT75jQkrdz+mUEE9LTc1fYFw@mail.gmail.com>
Message-ID: <CAGc_=hnSvJQbgBH67r=C1oFmaL2-XxXNRnQLBOJ-KSGr5UW7CQ@mail.gmail.com>

You can perform the equivalent filtering by hand using something like:

    k = (window_length - 1) / 2
    for i in k to len(x) - k
        xh,yh = x[points-k:points+k], y[points-k:points+k]
        idx = isfinite(xh) and isfinite(yh)
        xh,yh = xh[idx],yh[idx]
        p = polyfit(xh,yh, degree=filter_order)
        filtered_y[i] = polyval(p,x[i])

Points at the beginning use xh,yh from 1 to window_length, and at the end
from n-window_length to n.

Savitsky-Golay uses the fact that the x points are equally spaced to
precompute the weights on an FIR filter, so that

    filtered_y[i] = yh dot filter_coefficients

The FIR filter coefficients for order p on window 2k+1 are determined from
the top row of the pseudo inverse of the overdetermined polynomial equation
C whose elements, Cij are (-k+i)^(p-j) for i in 0 to 2k, j in 0 to p.  For
an order 2 solver with 5 points, this would be:

4 -2 1
1 -1  1
0  0  1
1  1  1
4  2  1

Computing the pseudo-inverse, this gives filter coefficients:

[ 0.14285714, -0.07142857, -0.14285714, -0.07142857,  0.14285714]

If the central point were NA, the coefficients would have to be:

[ 0.16666667, -0.16666667, NA, -0.16666667,  0.16666667]

Sliding the window forward one, the coefficients become:

[ 0.11363636, NA, -0.18181818, -0.09090909,  0.15909091]

Clearly, there is not going to be a trivial operation on the data stream or
filter coefficients which will handle the missing data.

You have a few options.

(1) if your data set is small, just do the filter manually.
(2) if your data set is large but the missing data is sparse, replace
missing data by infinity, then run the filter as normal.  For each
nonfinite number in the result, compute the filtered value manually.
(3) if you are not too concerned about full precision (this is, after all,
a smoothing operation), you could try replacing each missing value with the
average of the surrounding values, and hopefully this will not disturb the
polynomial approximations for the surrounding points too much.

- Paul


On Fri, Sep 26, 2014 at 3:32 AM, Erick Okuto <erickokuto at gmail.com> wrote:

> Dear Paul and Henrik,
> I have a time series with some missing data points that i need smoothed
> using Savitzky-Golay filter. Related question was asked  here
> http://thr3ads.net/r-help/2012/11/2121748-Savitzky-Golay-filtering-with-missing-data
> but no straight forward answer was posted. However, Henrik (cc'd here) did
> ask related question on smoothing for reflectance here
> http://thr3ads.net/r-help/2004/02/835137-Savitzky-Golay-smoothing-for-reflectance-data
> which i have as well been unable to follow up. I will be glad if you could
> assist me with some insights on the way forward or point to a relevant
> source of help.
>
> I have attached a simple test data plus the R code which only work with
> non missing data. I will appreciate any possible assistance.
>
> Thanks,
> Erick.
> --
> *Erick Okuto, Ph.D.*
> * Candidate*
> *School of Mathematics & Actuarial Science*
> *Jaramogi Oginga Odinga University of Science & Technology (JOOUST)/ World
> Agroforestry Centre (ICRAF), **Climate Change Unit, Nairobi-Kenya. *
> Voice:  +254207224154?    Mobile: +254725005276    Skype id:  erickokuto
> Email: erickokuto at gmail.com
>
>
>
>
>

	[[alternative HTML version deleted]]


From richardl at uchicago.edu  Fri Sep 26 19:57:35 2014
From: richardl at uchicago.edu (Richard Lerner)
Date: Fri, 26 Sep 2014 13:57:35 -0400
Subject: [R] Histogram from a single column of a data frame
Message-ID: <CAEPc0XewKSiM0miH0kROhZPP5_rxBHVG=Qy3X6gXibUAY1eVCg@mail.gmail.com>

Column 7 of "oded" is "Breed". If I enter
> summary(Breed)
I get the counts of the numbers in each breed.
However, if I enter


I have tried

> hist($Breed)
Error: unexpected '$' in "hist($"

> hist(Breed)
Error in hist(Breed) : object 'Breed' not found

> hist("Breed")
Error in hist.default("Breed") : 'x' must be numeric

FYI

> colnames(oded)
[1] "Subject.Name"       "Date"               "Species"
"Age"                "Sex"
[6] "Spayed....Neutered" "Breed"              "Breed.Code"

How do I get a histogram of the counts in column 7?


Thanks
Richard

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Sep 27 00:14:33 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Sep 2014 16:14:33 -0600
Subject: [R] Help with conversion of variable labels (Hmisc and Epicalc)
In-Reply-To: <loom.20140926T121801-156@post.gmane.org>
References: <loom.20140926T121801-156@post.gmane.org>
Message-ID: <6AEF0FB1-B277-4B3A-B0A7-DB37C6C76EF7@comcast.net>


On Sep 26, 2014, at 4:21 AM, Otto Pichlh?fer wrote:

> For my epidemiological analysis I use the packages Epicalc and Hmisc ?
> among others. Both packages allow to assign variable labels that will
> appear in the output of the respective packages? own functions. The  
> modes
> of storage of the labels in a dataframe are very different. I am
> wonderiung if there is a function that would allow to easily convert
> Epicalc labels to Hmisc labels and possibly the other way around.
>
> Unfortunately I am not adept enough in R to write such a function  
> myself.

Here's some further explorations on the topic. You should be able to  
see that epicalc (not "Epicalc") uses labeling at a dataframe levels  
of attribute assignment while rms/Hmisc uses a column-level attribute  
creation. So you could actually have both systems working in the same  
dataframe. (Which could get pretty confusing if your short-term memory  
is as limited as mine.)

require(epicalc)
require(rms) # which loads Hmisc
# This is the first section of the examples in
 > sbp <- c(120, 100, 110, 120, 140, 120,  NA,  NA)
 > dbp <- c( 80,  80,  70,  80,  70,  NA,  70,  60)
 > .data <- data.frame(sbp, dbp)
 > use(.data)

I'm guessing that this `use`-function is sort of like R's attach  
function
I strongly recommend against using `attach` and I suspect also against  
using `use`

 > pack()   # I have no idea what that does.
 > des()   # or that

  No. of observations =  8
   Variable      Class           Description
1 sbp           numeric
2 dbp           numeric
 > label.var(sbp, "systolic BP")
 > str(.data$sbp)
  num [1:8] 120 100 110 120 140 120 NA NA
 > str(.data)
'data.frame':	8 obs. of  2 variables:
  $ sbp: num  120 100 110 120 140 120 NA NA
  $ dbp: num  80 80 70 80 70 NA 70 60
  - attr(*, "var.labels")= chr  "systolic BP" ""

That shows that the attributes are assigned to the dataframe by  
epicalc's `var.labels`
 >
 > ?label
 > label(.data$sbp) <- "test.sbp"
 > str(.data)
'data.frame':	8 obs. of  2 variables:
  $ sbp:Classes 'labelled', 'numeric'  atomic [1:8] 120 100 110 120  
140 120 NA NA
   .. ..- attr(*, "label")= chr "test.sbp"
  $ dbp: num  80 80 70 80 70 NA 70 60
  - attr(*, "var.labels")= chr  "systolic BP" ""

And that shows that `Hmisc::label` does its assignment to the  
individual column vector.

If you wanted to assign Hmisc-type labels to the columns of a  
dataframe that has some or all of its columns lableded in the epicalc  
method then this loop succeeds:

 > for( coln in seq_along(.data) ) { label(.data[[coln]]) <-  
attr(.data, "var.labels")[coln]}
 > str(.data)
'data.frame':	8 obs. of  2 variables:
  $ sbp:Classes 'labelled', 'numeric'  atomic [1:8] 120 100 110 120  
140 120 NA NA
   .. ..- attr(*, "label")= chr "systolic BP"
  $ dbp:Classes 'labelled', 'numeric'  atomic [1:8] 80 80 70 80 70 NA  
70 60
   .. ..- attr(*, "label")= chr ""
  - attr(*, "var.labels")= chr  "systolic BP" ""

-- 

David Winsemius, MD
Alameda, CA, USA


From wdunlap at tibco.com  Sat Sep 27 00:25:07 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 26 Sep 2014 15:25:07 -0700
Subject: [R] Histogram from a single column of a data frame
In-Reply-To: <CAEPc0XewKSiM0miH0kROhZPP5_rxBHVG=Qy3X6gXibUAY1eVCg@mail.gmail.com>
References: <CAEPc0XewKSiM0miH0kROhZPP5_rxBHVG=Qy3X6gXibUAY1eVCg@mail.gmail.com>
Message-ID: <CAF8bMcZ57yziNk1pWFDCZDAYiNvavo_HK0AS0J_mgBXBjG+2Mw@mail.gmail.com>

Try
  hist(oded$Breed)

(I suspect that summary(Breed) does not work in your current session either -
perhaps you had a dataset named just Breed or had attached the data.frame
oded in the session where summary(Breed) works.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Sep 26, 2014 at 10:57 AM, Richard Lerner <richardl at uchicago.edu> wrote:
> Column 7 of "oded" is "Breed". If I enter
>> summary(Breed)
> I get the counts of the numbers in each breed.
> However, if I enter
>
>
> I have tried
>
>> hist($Breed)
> Error: unexpected '$' in "hist($"
>
>> hist(Breed)
> Error in hist(Breed) : object 'Breed' not found
>
>> hist("Breed")
> Error in hist.default("Breed") : 'x' must be numeric
>
> FYI
>
>> colnames(oded)
> [1] "Subject.Name"       "Date"               "Species"
> "Age"                "Sex"
> [6] "Spayed....Neutered" "Breed"              "Breed.Code"
>
> How do I get a histogram of the counts in column 7?
>
>
> Thanks
> Richard
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sat Sep 27 00:32:03 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 27 Sep 2014 10:32:03 +1200
Subject: [R] Histogram from a single column of a data frame
In-Reply-To: <CAEPc0XewKSiM0miH0kROhZPP5_rxBHVG=Qy3X6gXibUAY1eVCg@mail.gmail.com>
References: <CAEPc0XewKSiM0miH0kROhZPP5_rxBHVG=Qy3X6gXibUAY1eVCg@mail.gmail.com>
Message-ID: <5425E963.9080509@auckland.ac.nz>

On 27/09/14 05:57, Richard Lerner wrote:
> Column 7 of "oded" is "Breed". If I enter
>> summary(Breed)
> I get the counts of the numbers in each breed.
> However, if I enter
>
>
> I have tried
>
>> hist($Breed)
> Error: unexpected '$' in "hist($"
>
>> hist(Breed)
> Error in hist(Breed) : object 'Breed' not found
>
>> hist("Breed")
> Error in hist.default("Breed") : 'x' must be numeric
>
> FYI
>
>> colnames(oded)
> [1] "Subject.Name"       "Date"               "Species"
> "Age"                "Sex"
> [6] "Spayed....Neutered" "Breed"              "Breed.Code"
>
> How do I get a histogram of the counts in column 7?


Are you for real, or is this some kind of joke?

Assuming it's not a joke:

(1) Look at ?"$".

(2) WTF do you expect hist($Breed) to do?  Where is "Breed" going to be 
found, for pity's sake?  You appear to have no understanding of how R 
(or any programming language) works.

Read the Introduction to R manual and *get* some understanding if you 
are going to use R.

(3) The correct usage obviously (and I mean ***really***; it *IS* 
obvious) is hist(oded$Breed) --- which tells hist() where to find "Breed".

(4) You could also use

	with(oded,hist(Breed))

which is a useful syntax in some circumstances.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From r.turner at auckland.ac.nz  Sat Sep 27 00:53:08 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 27 Sep 2014 10:53:08 +1200
Subject: [R] Median of streaming data
In-Reply-To: <21541.13953.417228.646860@stat.math.ethz.ch>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>	<54226816.700@auckland.ac.nz>	<21538.32250.67575.749398@stat.math.ethz.ch>	<54235766.3070400@auckland.ac.nz>
	<21541.13953.417228.646860@stat.math.ethz.ch>
Message-ID: <5425EE54.20107@auckland.ac.nz>

On 26/09/14 21:48, Martin Maechler wrote:
>>>>>> Rolf Turner <r.turner at auckland.ac.nz>

<SNIP>

>
>      > I have coded up the algorithm from the Cameron and Turner
>      > paper.  Dunno if it gives exactly the same results as my
>      > (Splus?) code from lo these many years ago (the code that
>      > is lost in the mists of time), but it *seems* to work.
>
> excellent, thank you, Rolf!
>
>      > It is not designed to work with actual "streaming" data
>      > --- I don't know how to do that.  It takes a complete data
>      > vector as input.  Someone who knows about streaming data
>      > should be able to adapt it pretty easily.  Said he, the
>      > proverbial optimist.
>
> I agree; that should not be hard.
> One way is to replace   'y[ind]' by   'getY(ind)' everywhere in the code
> and let 'getY' be an argument to rlas() provided by the user.
>
>      > The function code and a help file are attached.  These
>      > files have had their names changed to end in ".txt" so
>      > that they will get through the mailing list processor
>      > without being stripped.  With a bit of luck.
> ;-)
>
> It did work indeed.
> I've added them to  'robustX' -- on R-forge,
> including a plot() method and some little more flexibility.
>
>    --> https://r-forge.r-project.org/R/?group_id=59
>


<SNIP>

Since I posted my previous email I have found some typos in the 
documentation and made some adjustments to the code.

I also realized that the name "rlas" sounds a bit too much like a random 
number generator, according to R's conventions.  So I have decided that 
"lasr" would be a better name.

I hope this change of horses in midstream doesn't mess things up too 
much for you.  If it does, of course feel free to stick with "rlas".

I have attached revised *.R and *.Rd files.  Not sure that the *.Rd file 
will get through as-is.  Please let me know if it doesn't.

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS
-------------- next part --------------
lasr <- function(y,b=0.2,mfn=function(n){0.1*n^(-0.25)},
                 nstart=30,scon=NULL) {
# Initialize:
y0    <- y[1:nstart]
alpha <- median(y0)
s     <- if(is.null(scon)) mean(abs(y0-alpha)) else scon
mu    <- mfn(nstart)/s
eps   <- s/nstart^b
kount <- sum(abs(alpha-y0) < eps)
g     <- kount/(eps*nstart)
ny    <- length(y)
n     <- nstart+1
locn  <- numeric(ny)
locn[1:(nstart-1)] <- NA
locn[nstart] <- alpha
scale  <- numeric(ny)
scale[1:(nstart-1)] <- if(is.null(scon)) NA else scon
scale[nstart] <- s

# Calculate recursively:
while(n <= ny) {
   s     <- if(is.null(scon)) ((n-1)*s + abs(y[n]-alpha))/n else scon
   mu    <- mfn(n)/s
   eye   <- if(abs(alpha - y[n]) < s/n^b) 1 else 0
   g     <- (1-1/n)*g + n^(b-1)*eye/s
   a     <- max(mu,g)
   alpha <- alpha + sign(y[n]-alpha)/(a*n)
   locn[n]  <- alpha
   scale[n] <- s
   n <- n+1
}
list(locn=locn,scale=scale)
}
-------------- next part --------------
\name{lasr}
\alias{lasr}
\title{
  Recursive location and scale.
}
\description{
  Calculate an estimate of location, asymptotically
  equivalent to the median, and an estimate of scale
  equal to the \bold{MEAN} absolute deviation.  Both
  done recursively.
}
\usage{
lasr(y, b = 0.2, mfn = function(n){0.1 * n^(-0.25)},
     nstart = 30, scon = NULL)
}
\arguments{
  \item{y}{
  A numeric vector of i.i.d. data whose location and scale
  parameters are to be estimated.
}
  \item{b}{
  A tuning parameter (default value equal to that used by
  Holst, 1987).
}
  \item{mfn}{
  Function of the index of the data which must be positive
  and tend to 0 as the index tends to infinity.  The default
  function is that used by Holst, 1987.
}
  \item{nstart}{
  Starting values for the algorithm are formed from the first
  \code{nstart} values of \code{y}.  The default value is that
  used in Cameron and Turner, 1993.
}
  \item{scon}{
  A constant value for the scale parameter \code{s}. If this
  is provided then the algorithm becomes equivalent to the
  algorithm of Holst, 1987.
}
}
\value{
A list with entries
  \item{locn}{The successive recursive estimates of location.  The
  first \code{nstart - 1} of these are \code{NA}.}
  \item{scale}{The successive recursive estimates of scale. If
  \code{scon} is specified these are all equal to \code{scon}. Otherwise
  the first \code{nstart - 1} values are \code{NA}.}
}

\section{Remark}{
The \bold{mean} absolute deviation is used as an estimate of scale
(rather than the more expected \bold{median} absolute deviation) simply
because the former can be calculated recursively.
}

\references{
Cameron, Murray A. and Turner, T. Rolf (1993). Recursive location and
scale estimators. \emph{Commun. Statist. --- Theory Meth.} \bold{22}
(9) 2503--2515.

Holst, U. (1987). Recursive estimators of location.
\emph{Commun. Statist. --- Theory Meth.} \bold{16} (8) 2201--2226.
}
\author{
 \email{r.turner at auckland.ac.nz}
 \url{http://www.stat.auckland.ac.nz/~rolf}
}
\examples{
set.seed(42)
y  <- rnorm(10000)
z1 <- lasr(y)
z2 <- lasr(y,scon=1)
z3 <- lasr(y,scon=100)
OP <- par(mfrow=c(3,1))
plot(z1$locn,type="l")
abline(h=median(y),col="red")
plot(z2$locn,type="l")
abline(h=median(y),col="red")
plot(z3$locn,type="l")
abline(h=median(y),col="red")
par(OP)
}

\keyword{ univar }
\keyword{ robust }

From ggrothendieck at gmail.com  Sat Sep 27 01:23:35 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Sep 2014 19:23:35 -0400
Subject: [R] Savitzky-Golay Smoother
In-Reply-To: <CAB-=SDXJqE8MQ113EOZF02PLJCYT75jQkrdz+mUEE9LTc1fYFw@mail.gmail.com>
References: <CAB-=SDXJqE8MQ113EOZF02PLJCYT75jQkrdz+mUEE9LTc1fYFw@mail.gmail.com>
Message-ID: <CAP01uRkznyxJt3YSXSoPb8TqZW4vj0fyRzSGiAYG2aO=twmw5A@mail.gmail.com>

On Fri, Sep 26, 2014 at 3:32 AM, Erick Okuto <erickokuto at gmail.com> wrote:
> Dear Paul and Henrik,
> I have a time series with some missing data points that i need smoothed
> using Savitzky-Golay filter. Related question was asked  here
> http://thr3ads.net/r-help/2012/11/2121748-Savitzky-Golay-filtering-with-missing-data
> but no straight forward answer was posted. However, Henrik (cc'd here) did
> ask related question on smoothing for reflectance here
> http://thr3ads.net/r-help/2004/02/835137-Savitzky-Golay-smoothing-for-reflectance-data
> which i have as well been unable to follow up. I will be glad if you could
> assist me with some insights on the way forward or point to a relevant
> source of help.


Not Savitzky-Golay but if z is a time series then

library(zoo)
na.spline(z)

will fill in NAs with spline curve fits.  See ?na.spline

There are other NA filling routines in zoo too:

> ls(pattern = "^na[.]", "package:zoo")
 [1] "na.aggregate"         "na.aggregate.default" "na.approx"
 [4] "na.approx.default"    "na.fill"              "na.fill.default"
 [7] "na.locf"              "na.locf.default"      "na.spline"
[10] "na.spline.default"    "na.StructTS"          "na.trim"
[13] "na.trim.default"      "na.trim.ts"



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From btyner at gmail.com  Sat Sep 27 04:26:10 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Fri, 26 Sep 2014 22:26:10 -0400
Subject: [R] quadprog::solve.QP sometimes returns NaNs
Message-ID: <54262042.5050208@gmail.com>

Hello,

Here is an example; hopefully it is reproducible on others' platform:

    library(quadprog)

    n <- 66L

    set.seed(6860)
    X <- matrix(1e-20, n, n)
    diag(X) <- 1
    Dmat <- crossprod(X)
    y <- seq_len(n)
    dvec <- crossprod(X, y)

    Amat <- diag(n)
    bvec <- y + runif(n)

    sol <- solve.QP(Dmat, dvec, Amat, bvec, meq = n)

    print(sol$solution) # this gives all NaNs

under sessionInfo():

    R version 3.0.2 (2013-09-25)
    Platform: x86_64-pc-linux-gnu (64-bit)

    locale:
     [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C             
     [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8   
     [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8  
     [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                
     [9] LC_ADDRESS=C               LC_TELEPHONE=C           
    [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C      

    attached base packages:
    [1] stats     graphics  grDevices utils     datasets  methods  
base    

    other attached packages:
    [1] quadprog_1.5-5

Any ideas?

Thanks
Ben


From acefix at rocketmail.com  Sat Sep 27 00:15:14 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Fri, 26 Sep 2014 22:15:14 +0000 (UTC)
Subject: [R] how to get the rows that satisfy a specific condition
Message-ID: <786321833.106818.1411769714177.JavaMail.yahoo@jws10741.mail.gq1.yahoo.com>

Hello, there,
I wonder if there is an easier way that I would only get the rows that satisfies some condition. For example:I have the following matrix, and I would like to output only the 3rd row and 4th row, since only these two rows contain the numbers greater than 11
> a
???? [,1] [,2] [,3] [,4] [,5]
[1,]??? 1??? 5??? 9?? 13?? 17
[2,]??? 2??? 6?? 10?? 14?? 18
[3,]??? 3??? 7?? 11?? 15?? 19
[4,]??? 4??? 8?? 12?? 16?? 20
> a>11
????? [,1]? [,2]? [,3] [,4] [,5]
[1,] FALSE FALSE FALSE TRUE TRUE
[2,] FALSE FALSE FALSE TRUE TRUE
[3,] FALSE FALSE FALSE TRUE TRUE
[4,] FALSE FALSE? TRUE TRUE TRUE
I have tried to use a[a>11, ] and it did not work.
Thanks a lot for the help:)


	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Sat Sep 27 12:23:00 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 27 Sep 2014 20:23 +1000
Subject: [R] how to get the rows that satisfy a specific condition
In-Reply-To: <786321833.106818.1411769714177.JavaMail.yahoo@jws10741.mail.gq1.yahoo.com>
References: <786321833.106818.1411769714177.JavaMail.yahoo@jws10741.mail.gq1.yahoo.com>
Message-ID: <2026871.bv5yRtQ72j@localhost.localdomain>

On Fri, 26 Sep 2014 10:15:14 PM Fix Ace wrote:
> Hello, there,
> I wonder if there is an easier way that I would only get the rows that
> satisfies some condition. For example:I have the following matrix, and I
> would like to output only the 3rd row and 4th row, since only these two
> rows contain the numbers greater than 11
> > a
> 
>      [,1] [,2] [,3] [,4] [,5]
> [1,]    1    5    9   13   17
> [2,]    2    6   10   14   18
> [3,]    3    7   11   15   19
> [4,]    4    8   12   16   20
> 
> > a>11
> 
>       [,1]  [,2]  [,3] [,4] [,5]
> [1,] FALSE FALSE FALSE TRUE TRUE
> [2,] FALSE FALSE FALSE TRUE TRUE
> [3,] FALSE FALSE FALSE TRUE TRUE
> [4,] FALSE FALSE  TRUE TRUE TRUE
> I have tried to use a[a>11, ] and it did not work.
> Thanks a lot for the help:)

Hi Fix Ace,
I have to admit that I am unfamiliar with the system of arithmetic that 
you are employing in the above example. In no system with which I am 
conversant are 13, 17, 14 and 18 less than or equal to 11. I can only 
offer the desperate conjecture that you want the third to fifth columns of 
the matrix rather than the third and fourth rows. If this wild surmise 
happens to be the case, I suggest that you try this:

testmat[,apply(testmat,2,function(x) return(max(x) > 11))]

Jim


From smileismystyl at gmail.com  Sat Sep 27 10:36:53 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Sat, 27 Sep 2014 14:06:53 +0530
Subject: [R] could not plot my spatial species points on the raster data
Message-ID: <CAG1d=2D54gb9ju8+Jfxz2JEYad7cD97TG-g2CVEx4N6p31R_oA@mail.gmail.com>

Dear Group,

I working with species distribution modeling in R.
I have a raster file (stacked with environmental layers around 24 layers),
i have a shape file.
Both the arster and shape file are of same projections.
I confirmed it.
I have a csv file read which has my species data, but the problem here is
my species aren't getting plotted on the raster data. What could be the
proble.


raster <- raster(choose.files())
plot(raster)
#input the species occurence file
hippo <-read.csv(choose.files())
hippo <- read.table(hippo, header=TRUE, sep=",")
hippo <- hippo[,2:3]
points(hippo$lon,hippo$lat,col="blue",pch=19,cex=0.75,
xlab="Longitude",ylab="Latitude")
map<- readOGR(".", layer= 'lahul')
plot(map, col="grey")
hip <- data.frame(hippo$lon,hippo$lat)
points(hip$lon,hip$lat,col="blue",pch=19,xlab="Longitude",ylab="Latitude")

......
 Any help wil be highly appreciated.
Thanx in advance

	[[alternative HTML version deleted]]


From smileismystyl at gmail.com  Sat Sep 27 10:40:36 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Sat, 27 Sep 2014 14:10:36 +0530
Subject: [R] EXTENTS DO NOT OVERLAP
Message-ID: <CAG1d=2CsaB8mAbCo91Ji=E6nCYTE+7qGVS7CrO-Zn=h-2bxp2Q@mail.gmail.com>

WHEN I CHECK MY IMAGE AND SHAPE FILE IN ERDAS, IT IS OVERALYING.

BUT WHEN I WANTED TO OVERLAY IT IN R.

I GET THE FOLLOWING ERROR.


Error in .local(x, y, ...) : extents do not overlap In addition: Warning
message: In intersect(extent(x), extent(y)) : Objects do not overlap


BUT RASTER EXTENTS SHOW UP IN METERS AND POLYGON IS IN LAT/LON


THE FOLLOWING IS MY BOUNDING BOX RANGE
> bbox(raster)       min     max
s1  571045 1006045
s2 3405030 3788030> bbox(map)      min     max
x 3663120 3875470
y 4845817 5013605


 THE FOLLOWING ARE MY PROJECTIONS

> proj4string(map)[1] "+proj=lcc +lat_1=35.17280444444445 +lat_2=12.472955 +lat_0=24 +lon_0=80 +x_0=4000000 +y_0=4000000 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"> proj4string(raster)[1] "+proj=utm +zone=43 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"

	[[alternative HTML version deleted]]


From frtog at vestas.com  Sat Sep 27 10:50:31 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Sat, 27 Sep 2014 10:50:31 +0200
Subject: [R] [ESS] package loadable in R 3.1.1 Rterm but not in emacs/ESS
Message-ID: <spbqxa524uwan5hfadof272k.1411807860249@email.android.com>

Hi

If you execute .libPaths() in both instances of R what do you see then?

There shouldn't be any differences.

Br.

Frede T?gersen


Sendt fra Samsung mobil


-------- Oprindelig meddelelse --------
Fra: Christopher W Ryan
Dato:26/09/2014 16.41 (GMT+01:00)
Til: R-help ,ess-help at stat.math.ethz.ch
Emne: [ESS] package loadable in R 3.1.1 Rterm but not in emacs/ESS

I'm running R on Windows 7. Clean install on a brand new computer
yesterday.  I installed Protext then R then Vincent Goulet's emacs
with ESS, in that order.

I then installed some R packages, in the R terminal window.  Among them was car

Today I opened emacs, hit M-x R to start an R session, and tried to
load the car library. Results looked like the following:


R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: i386-w64-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> > options(chmhelp=FALSE, help_type="text")
> options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient.exe', show.error.locations=TRUE)
>
> library(car)
Error in library(car) : there is no package called 'car'
>



However, in an R terminal (that is, outside of emacs) the car package
loads fine:

R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: i386-w64-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(car)
>

I have not encountered this before and am confused. Why would R 3.1.1
in its terminal "see" a library, whereas it would not in emacs?  (car
is just an example; the same thing happens with zoo, stringr, Hmisc,
and others.)

Thanks.

--Chris Ryan

______________________________________________
ESS-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/ess-help

	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Sun Sep 28 05:17:47 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 28 Sep 2014 13:17:47 +1000
Subject: [R] EXTENTS DO NOT OVERLAP
In-Reply-To: <CAG1d=2CsaB8mAbCo91Ji=E6nCYTE+7qGVS7CrO-Zn=h-2bxp2Q@mail.gmail.com>
References: <CAG1d=2CsaB8mAbCo91Ji=E6nCYTE+7qGVS7CrO-Zn=h-2bxp2Q@mail.gmail.com>
Message-ID: <2448258.Ob6lEdAHTm@localhost.localdomain>

On Sat, 27 Sep 2014 02:10:36 PM Girija Kalyani wrote:
> WHEN I CHECK MY IMAGE AND SHAPE FILE IN ERDAS, IT IS 
OVERALYING.
> 
> BUT WHEN I WANTED TO OVERLAY IT IN R.
> 
> I GET THE FOLLOWING ERROR.
> 
> 
> Error in .local(x, y, ...) : extents do not overlap In addition: Warning
> message: In intersect(extent(x), extent(y)) : Objects do not overlap
> 
> 
> BUT RASTER EXTENTS SHOW UP IN METERS AND POLYGON IS IN 
LAT/LON
> 
> 
> THE FOLLOWING IS MY BOUNDING BOX RANGE
> 
> > bbox(raster)       min     max
> 
> s1  571045 1006045
> s2 3405030 3788030> bbox(map)      min     max
> x 3663120 3875470
> y 4845817 5013605
> 
> 
>  THE FOLLOWING ARE MY PROJECTIONS
> 
> > proj4string(map)[1] "+proj=lcc +lat_1=35.17280444444445 
+lat_2=12.472955
> > +lat_0=24 +lon_0=80 +x_0=4000000 +y_0=4000000 
+datum=WGS84 +units=m
> > +no_defs +ellps=WGS84 +towgs84=0,0,0"> proj4string(raster)
[1] "+proj=utm
> > +zone=43 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_defs"
> 	[[alternative HTML version deleted]]
> 
Hi Girija,
Try this and you will see what is happening:

plot(0,xlim=c(57000,3900000),
 ylim=c(3410000,5020000),type="n",
 main="The case of the non-overlapping rectangles")
rect(571045,3405030,1006045,3788030,col="green")
rect(3663120,4845817,3875470,5013605,col="blue")

Jim


From kate.ignatius at gmail.com  Sun Sep 28 06:49:41 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sun, 28 Sep 2014 00:49:41 -0400
Subject: [R] Ifelse statement on a factor level data frame
Message-ID: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>

Quick question:

I am running the following code on some variables that are factors:

dbpmn$IID1new <- ifelse(as.character(dbpmn[,2]) ==
as.character(dbpmn[,(21)]), dbpmn[,20], '')

Instead of returning some value it gives me this:

c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))

Playing around with the code, gives me some kind of variation to it.
Is there some way to get me what I want.  The variable that its
suppose to give back is a bunch of sampleIDs.

Thanks!


From jdnewmil at dcn.davis.CA.us  Sun Sep 28 07:13:54 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 27 Sep 2014 22:13:54 -0700
Subject: [R] Ifelse statement on a factor level data frame
In-Reply-To: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
References: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
Message-ID: <7784B95E-D8EE-4112-A1BC-87A229614BED@dcn.davis.CA.us>

Not reproducible, ball in your court. However, in the meantime, my suggestion is to not do that. Convert to character before you alter the factor, then convert back when you are done.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 27, 2014 9:49:41 PM PDT, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>Quick question:
>
>I am running the following code on some variables that are factors:
>
>dbpmn$IID1new <- ifelse(as.character(dbpmn[,2]) ==
>as.character(dbpmn[,(21)]), dbpmn[,20], '')
>
>Instead of returning some value it gives me this:
>
>c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
>
>Playing around with the code, gives me some kind of variation to it.
>Is there some way to get me what I want.  The variable that its
>suppose to give back is a bunch of sampleIDs.
>
>Thanks!
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Sun Sep 28 07:15:25 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 28 Sep 2014 15:15:25 +1000
Subject: [R] Ifelse statement on a factor level data frame
In-Reply-To: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
References: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
Message-ID: <14556813.0ud9qF7JP1@localhost.localdomain>

On Sun, 28 Sep 2014 12:49:41 AM Kate Ignatius wrote:
> Quick question:
> 
> I am running the following code on some variables that are factors:
> 
> dbpmn$IID1new <- ifelse(as.character(dbpmn[,2]) ==
> as.character(dbpmn[,(21)]), dbpmn[,20], '')
> 
> Instead of returning some value it gives me this:
> 
> c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
> 
> Playing around with the code, gives me some kind of variation to it.
> Is there some way to get me what I want.  The variable that its
> suppose to give back is a bunch of sampleIDs.
> 
Hi Kate,
If I create a little example:

dbpmn<-data.frame(V1=factor(sample(LETTERS[1:4],20,TRUE)),
  V2=factor(sample(LETTERS[1:4],20,TRUE)),
  V3=factor(sample(LETTERS[1:4],20,TRUE)))
dbpmn[4]<-
 ifelse(as.character(dbpmn[,1]) == as.character(dbpmn[,(2)]),
 dbpmn[,3],"")
dbpmn
   V1 V2 V3 V4
1   B  D  C   
2   C  A  D   
3   C  B  A   
4   A  B  C   
5   B  D  B   
6   D  D  A  1
7   D  D  D  4
8   B  C  A   
9   B  D  B   
10  D  C  A   
11  A  D  C   
12  A  C  B   
13  A  A  A  1
14  D  C  A   
15  C  D  B   
16  A  A  B  2
17  A  C  C   
18  B  B  C  3
19  C  C  C  3
20  D  D  D  4

I get what I expect, the numeric value of the third element in dbpmn 
where the first two elements are equal. I think what you want is:

dbpmn[4]<-
 ifelse(as.character(dbpmn[,1]) == as.character(dbpmn[,(2)]),
 as.character(dbpmn[,3]),"")
dbpmn
   V1 V2 V3 V4
1   B  D  C   
2   C  A  D   
3   C  B  A   
4   A  B  C   
5   B  D  B   
6   D  D  A  A
7   D  D  D  D
8   B  C  A   
9   B  D  B   
10  D  C  A   
11  A  D  C   
12  A  C  B   
13  A  A  A  A
14  D  C  A   
15  C  D  B   
16  A  A  B  B
17  A  C  C   
18  B  B  C  C
19  C  C  C  C
20  D  D  D  D

Jim


From pburns at pburns.seanet.com  Sun Sep 28 12:40:04 2014
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sun, 28 Sep 2014 11:40:04 +0100
Subject: [R] Ifelse statement on a factor level data frame
In-Reply-To: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
References: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
Message-ID: <5427E584.1030306@pburns.seanet.com>

I believe you are in Circle 8.2.7 of
The R Inferno.

http://www.burns-stat.com/documents/books/the-r-inferno/

Pat

On 28/09/2014 05:49, Kate Ignatius wrote:
> Quick question:
>
> I am running the following code on some variables that are factors:
>
> dbpmn$IID1new <- ifelse(as.character(dbpmn[,2]) ==
> as.character(dbpmn[,(21)]), dbpmn[,20], '')
>
> Instead of returning some value it gives me this:
>
> c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
>
> Playing around with the code, gives me some kind of variation to it.
> Is there some way to get me what I want.  The variable that its
> suppose to give back is a bunch of sampleIDs.
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From sven.templer at gmail.com  Sun Sep 28 13:51:42 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Sun, 28 Sep 2014 13:51:42 +0200
Subject: [R] how to get the rows that satisfy a specific condition
In-Reply-To: <2026871.bv5yRtQ72j@localhost.localdomain>
References: <786321833.106818.1411769714177.JavaMail.yahoo@jws10741.mail.gq1.yahoo.com>
	<2026871.bv5yRtQ72j@localhost.localdomain>
Message-ID: <CAHuTOvrY5H-0wvLe=P8jVSiThUHiwTib=oGt21P2XPO=ksQ2QQ@mail.gmail.com>

in ?which read about arr.ind

following jims assumption (column instead of row indices is what you
want) this also works:

m <- matrix(1:20,4)
unique(which(m>11, arr.ind = T)[,"col"])

On 27 September 2014 12:23, Jim Lemon <jim at bitwrit.com.au> wrote:
> On Fri, 26 Sep 2014 10:15:14 PM Fix Ace wrote:
>> Hello, there,
>> I wonder if there is an easier way that I would only get the rows that
>> satisfies some condition. For example:I have the following matrix, and I
>> would like to output only the 3rd row and 4th row, since only these two
>> rows contain the numbers greater than 11
>> > a
>>
>>      [,1] [,2] [,3] [,4] [,5]
>> [1,]    1    5    9   13   17
>> [2,]    2    6   10   14   18
>> [3,]    3    7   11   15   19
>> [4,]    4    8   12   16   20
>>
>> > a>11
>>
>>       [,1]  [,2]  [,3] [,4] [,5]
>> [1,] FALSE FALSE FALSE TRUE TRUE
>> [2,] FALSE FALSE FALSE TRUE TRUE
>> [3,] FALSE FALSE FALSE TRUE TRUE
>> [4,] FALSE FALSE  TRUE TRUE TRUE
>> I have tried to use a[a>11, ] and it did not work.
>> Thanks a lot for the help:)
>
> Hi Fix Ace,
> I have to admit that I am unfamiliar with the system of arithmetic that
> you are employing in the above example. In no system with which I am
> conversant are 13, 17, 14 and 18 less than or equal to 11. I can only
> offer the desperate conjecture that you want the third to fifth columns of
> the matrix rather than the third and fourth rows. If this wild surmise
> happens to be the case, I suggest that you try this:
>
> testmat[,apply(testmat,2,function(x) return(max(x) > 11))]
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Sun Sep 28 15:38:33 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sun, 28 Sep 2014 09:38:33 -0400
Subject: [R] Ifelse statement on a factor level data frame
In-Reply-To: <14556813.0ud9qF7JP1@localhost.localdomain>
References: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
	<14556813.0ud9qF7JP1@localhost.localdomain>
Message-ID: <CAE6QMsb-H73fLZg+aJFN5BOcyh2NcSeqKuFn=yGacMz+qkvTnA@mail.gmail.com>

Strange that,

I did put everything with as.character but all I got was the same...

class of dbpmn[,2]) = factor
class of dbpmn[,21]  = factor
class of  dbpmn[,20] = data.frame

This has to be a problem ???

I can put reproducible output here but not sure if this going to of
help here. I think its all about factors and data frames and
characters...

K.

On Sun, Sep 28, 2014 at 1:15 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
> On Sun, 28 Sep 2014 12:49:41 AM Kate Ignatius wrote:
>> Quick question:
>>
>> I am running the following code on some variables that are factors:
>>
>> dbpmn$IID1new <- ifelse(as.character(dbpmn[,2]) ==
>> as.character(dbpmn[,(21)]), dbpmn[,20], '')
>>
>> Instead of returning some value it gives me this:
>>
>> c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
>>
>> Playing around with the code, gives me some kind of variation to it.
>> Is there some way to get me what I want.  The variable that its
>> suppose to give back is a bunch of sampleIDs.
>>
> Hi Kate,
> If I create a little example:
>
> dbpmn<-data.frame(V1=factor(sample(LETTERS[1:4],20,TRUE)),
>   V2=factor(sample(LETTERS[1:4],20,TRUE)),
>   V3=factor(sample(LETTERS[1:4],20,TRUE)))
> dbpmn[4]<-
>  ifelse(as.character(dbpmn[,1]) == as.character(dbpmn[,(2)]),
>  dbpmn[,3],"")
> dbpmn
>    V1 V2 V3 V4
> 1   B  D  C
> 2   C  A  D
> 3   C  B  A
> 4   A  B  C
> 5   B  D  B
> 6   D  D  A  1
> 7   D  D  D  4
> 8   B  C  A
> 9   B  D  B
> 10  D  C  A
> 11  A  D  C
> 12  A  C  B
> 13  A  A  A  1
> 14  D  C  A
> 15  C  D  B
> 16  A  A  B  2
> 17  A  C  C
> 18  B  B  C  3
> 19  C  C  C  3
> 20  D  D  D  4
>
> I get what I expect, the numeric value of the third element in dbpmn
> where the first two elements are equal. I think what you want is:
>
> dbpmn[4]<-
>  ifelse(as.character(dbpmn[,1]) == as.character(dbpmn[,(2)]),
>  as.character(dbpmn[,3]),"")
> dbpmn
>    V1 V2 V3 V4
> 1   B  D  C
> 2   C  A  D
> 3   C  B  A
> 4   A  B  C
> 5   B  D  B
> 6   D  D  A  A
> 7   D  D  D  D
> 8   B  C  A
> 9   B  D  B
> 10  D  C  A
> 11  A  D  C
> 12  A  C  B
> 13  A  A  A  A
> 14  D  C  A
> 15  C  D  B
> 16  A  A  B  B
> 17  A  C  C
> 18  B  B  C  C
> 19  C  C  C  C
> 20  D  D  D  D
>
> Jim
>


From motyocska at yahoo.com  Sun Sep 28 15:41:41 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Sun, 28 Sep 2014 06:41:41 -0700
Subject: [R] help with splitting parts of data frame
Message-ID: <1411911701.6686.YahooMailNeo@web161603.mail.bf1.yahoo.com>

Dear All,

please help with the following if you can:

we have:

simt <-seq(0,147,by=1)
simc <-50*exp(-0.01*simt)
out1.2 <-data.frame(simt,simc)

AUC <-c(0,apply(matrix(simc),2,function(x) (diff(simt)*(x[-1]+x[-length(x)]))/2 ))
df <-cbind(out1.2,AUC)

z <-cumsum(rep(24,max(out1.2$simt/24)))

####
first24 <-sum(unlist(c(subset(df, df[, 'simt'] > 0 & df[, 'simt'] <= z[1], 3))))
second24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[1] & df[, 'simt'] <= z[2], 3))))
third24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[2] & df[, 'simt'] <= z[3], 3))))
fourth24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[3] & df[, 'simt'] <= z[4], 3))))
fifth24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[4] & df[, 'simt'] <= z[5], 3))))
sixth24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[5] & df[, 'simt'] <= z[6], 3))))

last24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[6] , 3))))

my end result is to get this vector:

c(first24,second24,third24,fourth24,fifth24,sixth24,last24)

####

the important aspect is that z can be of different length, depending on simt,  so what I am trying to do is to code the section between the #### tags above to accommodate any length of z that is greater then 0. I thought of  split( df , f = df$id ), where we would need to add a column with name id to df based on the values in z in such a way where for example all rows of id where simt <=z[1] would be 1 (or a o whatever) , and 2 (or b or whatever)  if simt >z[1] and <=z[2], and so on,  then we could split df based on id and could work with respective columns... This is one thought, but having a hard time figuring out how to add the id column as such that may accommodate z of changing lengths... Or any other ideas that are more suitable would be welcome,

thanks,

Andras
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Sep 28 16:22:36 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 28 Sep 2014 07:22:36 -0700
Subject: [R] Ifelse statement on a factor level data frame
In-Reply-To: <CAE6QMsb-H73fLZg+aJFN5BOcyh2NcSeqKuFn=yGacMz+qkvTnA@mail.gmail.com>
References: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
	<14556813.0ud9qF7JP1@localhost.localdomain>
	<CAE6QMsb-H73fLZg+aJFN5BOcyh2NcSeqKuFn=yGacMz+qkvTnA@mail.gmail.com>
Message-ID: <CACk-te07ktHSgT9J3fa6e8n+1BGFkELeZin_MFSEy+oHpUXp8g@mail.gmail.com>

Inline.

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Sep 28, 2014 at 6:38 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> Strange that,
>
> I did put everything with as.character but all I got was the same...
>
> class of dbpmn[,2]) = factor
> class of dbpmn[,21]  = factor
> class of  dbpmn[,20] = data.frame
>
> This has to be a problem ???

Indeed -- your failure to read documentation.

I suggest you do your due diligence, read Pat Burns's link, and follow
the advice given you by posting a reproducible example. More than
likely the last will be unnecessary as you will figure it out in the
course of doing what you should do.

Cheers,
Bert

>
> I can put reproducible output here but not sure if this going to of
> help here. I think its all about factors and data frames and
> characters...
>
> K.
>
> On Sun, Sep 28, 2014 at 1:15 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
>> On Sun, 28 Sep 2014 12:49:41 AM Kate Ignatius wrote:
>>> Quick question:
>>>
>>> I am running the following code on some variables that are factors:
>>>
>>> dbpmn$IID1new <- ifelse(as.character(dbpmn[,2]) ==
>>> as.character(dbpmn[,(21)]), dbpmn[,20], '')
>>>
>>> Instead of returning some value it gives me this:
>>>
>>> c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
>>>
>>> Playing around with the code, gives me some kind of variation to it.
>>> Is there some way to get me what I want.  The variable that its
>>> suppose to give back is a bunch of sampleIDs.
>>>
>> Hi Kate,
>> If I create a little example:
>>
>> dbpmn<-data.frame(V1=factor(sample(LETTERS[1:4],20,TRUE)),
>>   V2=factor(sample(LETTERS[1:4],20,TRUE)),
>>   V3=factor(sample(LETTERS[1:4],20,TRUE)))
>> dbpmn[4]<-
>>  ifelse(as.character(dbpmn[,1]) == as.character(dbpmn[,(2)]),
>>  dbpmn[,3],"")
>> dbpmn
>>    V1 V2 V3 V4
>> 1   B  D  C
>> 2   C  A  D
>> 3   C  B  A
>> 4   A  B  C
>> 5   B  D  B
>> 6   D  D  A  1
>> 7   D  D  D  4
>> 8   B  C  A
>> 9   B  D  B
>> 10  D  C  A
>> 11  A  D  C
>> 12  A  C  B
>> 13  A  A  A  1
>> 14  D  C  A
>> 15  C  D  B
>> 16  A  A  B  2
>> 17  A  C  C
>> 18  B  B  C  3
>> 19  C  C  C  3
>> 20  D  D  D  4
>>
>> I get what I expect, the numeric value of the third element in dbpmn
>> where the first two elements are equal. I think what you want is:
>>
>> dbpmn[4]<-
>>  ifelse(as.character(dbpmn[,1]) == as.character(dbpmn[,(2)]),
>>  as.character(dbpmn[,3]),"")
>> dbpmn
>>    V1 V2 V3 V4
>> 1   B  D  C
>> 2   C  A  D
>> 3   C  B  A
>> 4   A  B  C
>> 5   B  D  B
>> 6   D  D  A  A
>> 7   D  D  D  D
>> 8   B  C  A
>> 9   B  D  B
>> 10  D  C  A
>> 11  A  D  C
>> 12  A  C  B
>> 13  A  A  A  A
>> 14  D  C  A
>> 15  C  D  B
>> 16  A  A  B  B
>> 17  A  C  C
>> 18  B  B  C  C
>> 19  C  C  C  C
>> 20  D  D  D  D
>>
>> Jim
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Sun Sep 28 18:04:35 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sun, 28 Sep 2014 12:04:35 -0400
Subject: [R] Ifelse statement on a factor level data frame
In-Reply-To: <CACk-te07ktHSgT9J3fa6e8n+1BGFkELeZin_MFSEy+oHpUXp8g@mail.gmail.com>
References: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
	<14556813.0ud9qF7JP1@localhost.localdomain>
	<CAE6QMsb-H73fLZg+aJFN5BOcyh2NcSeqKuFn=yGacMz+qkvTnA@mail.gmail.com>
	<CACk-te07ktHSgT9J3fa6e8n+1BGFkELeZin_MFSEy+oHpUXp8g@mail.gmail.com>
Message-ID: <CAE6QMsaQZMDt_xL6OONLwiwH5LnW398ZZaruA55vUFK_Z2qyQQ@mail.gmail.com>

Apologies - you're right.  Missed it in the pdf.

K.

On Sun, Sep 28, 2014 at 10:22 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Inline.
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Sep 28, 2014 at 6:38 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>> Strange that,
>>
>> I did put everything with as.character but all I got was the same...
>>
>> class of dbpmn[,2]) = factor
>> class of dbpmn[,21]  = factor
>> class of  dbpmn[,20] = data.frame
>>
>> This has to be a problem ???
>
> Indeed -- your failure to read documentation.
>
> I suggest you do your due diligence, read Pat Burns's link, and follow
> the advice given you by posting a reproducible example. More than
> likely the last will be unnecessary as you will figure it out in the
> course of doing what you should do.
>
> Cheers,
> Bert
>
>>
>> I can put reproducible output here but not sure if this going to of
>> help here. I think its all about factors and data frames and
>> characters...
>>
>> K.
>>
>> On Sun, Sep 28, 2014 at 1:15 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
>>> On Sun, 28 Sep 2014 12:49:41 AM Kate Ignatius wrote:
>>>> Quick question:
>>>>
>>>> I am running the following code on some variables that are factors:
>>>>
>>>> dbpmn$IID1new <- ifelse(as.character(dbpmn[,2]) ==
>>>> as.character(dbpmn[,(21)]), dbpmn[,20], '')
>>>>
>>>> Instead of returning some value it gives me this:
>>>>
>>>> c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
>>>>
>>>> Playing around with the code, gives me some kind of variation to it.
>>>> Is there some way to get me what I want.  The variable that its
>>>> suppose to give back is a bunch of sampleIDs.
>>>>
>>> Hi Kate,
>>> If I create a little example:
>>>
>>> dbpmn<-data.frame(V1=factor(sample(LETTERS[1:4],20,TRUE)),
>>>   V2=factor(sample(LETTERS[1:4],20,TRUE)),
>>>   V3=factor(sample(LETTERS[1:4],20,TRUE)))
>>> dbpmn[4]<-
>>>  ifelse(as.character(dbpmn[,1]) == as.character(dbpmn[,(2)]),
>>>  dbpmn[,3],"")
>>> dbpmn
>>>    V1 V2 V3 V4
>>> 1   B  D  C
>>> 2   C  A  D
>>> 3   C  B  A
>>> 4   A  B  C
>>> 5   B  D  B
>>> 6   D  D  A  1
>>> 7   D  D  D  4
>>> 8   B  C  A
>>> 9   B  D  B
>>> 10  D  C  A
>>> 11  A  D  C
>>> 12  A  C  B
>>> 13  A  A  A  1
>>> 14  D  C  A
>>> 15  C  D  B
>>> 16  A  A  B  2
>>> 17  A  C  C
>>> 18  B  B  C  3
>>> 19  C  C  C  3
>>> 20  D  D  D  4
>>>
>>> I get what I expect, the numeric value of the third element in dbpmn
>>> where the first two elements are equal. I think what you want is:
>>>
>>> dbpmn[4]<-
>>>  ifelse(as.character(dbpmn[,1]) == as.character(dbpmn[,(2)]),
>>>  as.character(dbpmn[,3]),"")
>>> dbpmn
>>>    V1 V2 V3 V4
>>> 1   B  D  C
>>> 2   C  A  D
>>> 3   C  B  A
>>> 4   A  B  C
>>> 5   B  D  B
>>> 6   D  D  A  A
>>> 7   D  D  D  D
>>> 8   B  C  A
>>> 9   B  D  B
>>> 10  D  C  A
>>> 11  A  D  C
>>> 12  A  C  B
>>> 13  A  A  A  A
>>> 14  D  C  A
>>> 15  C  D  B
>>> 16  A  A  B  B
>>> 17  A  C  C
>>> 18  B  B  C  C
>>> 19  C  C  C  C
>>> 20  D  D  D  D
>>>
>>> Jim
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Sun Sep 28 18:33:57 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Sun, 28 Sep 2014 16:33:57 +0000
Subject: [R] help with splitting parts of data frame
References: <1411911701.6686.YahooMailNeo@web161603.mail.bf1.yahoo.com>
Message-ID: <loom.20140928T182133-666@post.gmane.org>

Andras Farkas <motyocska <at> yahoo.com> writes:

> 
> Dear All,
> 
> please help with the following if you can:
> 
[snip details]
> 
> ####
> first24 <-sum(unlist(c(subset(df, df[, 'simt'] > 0 & df[, 'simt'] <= 
> z[1], 3))))
> second24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[1] & df[, 'simt'] <= 
> z[2], 3))))
> third24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[2] & df[, 'simt'] <= 
> z[3], 3))))
> fourth24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[3] & df[, 'simt'] <= 
> z[4], 3))))
> fifth24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[4] & df[, 'simt'] <=
z[5], 3))))
> sixth24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[5] & df[, 'simt'] <= 
> z[6], 3))))
> 
> last24 <-sum(unlist(c(subset(df, df[, 'simt'] > z[6] , 3))))
> 
> my end result is to get this vector:
> 
> c(first24,second24,third24,fourth24,fifth24,sixth24,last24)
> 
> ####
> 

Some hints:

see 

   ?xtabs 

for weighted tabulations and 

   ?cut

for forming categories to tabulate. 

Try to solve this using just those functions, 'c', and the '~' operator.

It can be done in one line.

HTH,

Chuck


From arnab.killy at gmail.com  Sun Sep 28 13:47:20 2014
From: arnab.killy at gmail.com (Arnab Dutta)
Date: Sun, 28 Sep 2014 17:17:20 +0530
Subject: [R] Robust Standard Error in R
Message-ID: <CA+i-=4sv2WOjV9K+rJXFQBHmUHuLUUX8h1tc2DsQcenssPFB7A@mail.gmail.com>

Hi,

    In order to have robust standard errors in R, what would be the command
that can generate results similar to the "robust" option in STATA? I tried
using the "lmrob" command from the package "robustbase". With that, the
Adjusted R squared is quite different from the normal "lm" command. This
does not happen in STATA. Can anybody please enlighten me on this?

-Regards
 Arnab

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Sep 28 19:08:37 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 28 Sep 2014 17:08:37 +0000
Subject: [R] Robust Standard Error in R
References: <CA+i-=4sv2WOjV9K+rJXFQBHmUHuLUUX8h1tc2DsQcenssPFB7A@mail.gmail.com>
Message-ID: <loom.20140928T190617-429@post.gmane.org>

Arnab Dutta <arnab.killy <at> gmail.com> writes:

> 
> Hi,
> 
>     In order to have robust standard errors in R, what would be the command
> that can generate results similar to the "robust" option in STATA? I tried
> using the "lmrob" command from the package "robustbase". With that, the
> Adjusted R squared is quite different from the normal "lm" command. This
> does not happen in STATA. Can anybody please enlighten me on this?
> 
> -Regards
>  Arnab


  I think you're looking for the sandwich package

example(lm)
library(sandwich)
sqrt(diag(vcov(lm.D9)))
sqrt(diag(vcovHAC(lm.D9)))

(or see example(vcovHAC)


From Achim.Zeileis at uibk.ac.at  Sun Sep 28 19:10:43 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 28 Sep 2014 19:10:43 +0200 (CEST)
Subject: [R] Robust Standard Error in R
In-Reply-To: <CA+i-=4sv2WOjV9K+rJXFQBHmUHuLUUX8h1tc2DsQcenssPFB7A@mail.gmail.com>
References: <CA+i-=4sv2WOjV9K+rJXFQBHmUHuLUUX8h1tc2DsQcenssPFB7A@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1409281905360.25002@paninaro.uibk.ac.at>

On Sun, 28 Sep 2014, Arnab Dutta wrote:

> Hi,
>
>    In order to have robust standard errors in R, what would be the command
> that can generate results similar to the "robust" option in STATA?

This usually refers to sandwich standard errors aka HC or HC0 in case of 
the linear regression model. These are available in package "car" or 
package "sandwich". See vignette("sandwich", package = "sandwich") for a 
detailed overview.

> I tried using the "lmrob" command from the package "robustbase". With 
> that, the Adjusted R squared is quite different from the normal "lm" 
> command.

This performs robust estimation of the linear model while robust standard 
errors employ the usual OLS estimation and just adjust the subsequent 
inference. The robustness properties are quite different. While robust 
standard errors still require that the linear equation for the conditional 
mean holds for all observations, this is relaxed in robust estimates of 
the regression coefficients. More details can be found in the reference of 
the corresponding manuals.

> This does not happen in STATA. Can anybody please enlighten me on this?
>
> -Regards
> Arnab
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Sun Sep 28 19:24:39 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 28 Sep 2014 10:24:39 -0700
Subject: [R] Ifelse statement on a factor level data frame
In-Reply-To: <7784B95E-D8EE-4112-A1BC-87A229614BED@dcn.davis.CA.us>
References: <CAE6QMsbQes9-xJY6ZSc6MzT2TxxQa3L-_ENXZKUBty7tfDmsiQ@mail.gmail.com>
	<7784B95E-D8EE-4112-A1BC-87A229614BED@dcn.davis.CA.us>
Message-ID: <CAF8bMcZDsyKm_==WPnXpkr74QSc3V0Tm-3SbeOwP3Tw-Lmvhtg@mail.gmail.com>

ifelse() often has problems constructing the right type of return value.

if you want to keep the data as a factor (with its existing levels)
use x[condition] <- value instead of ifelse(condition, value, x).  E.g.,
   > x <- factor(c("Large","Small","Small","XLarge"),
levels=c("Small","Med","Large","XLarge"))
   > x
   [1] Large  Small  Small  XLarge
   Levels: Small Med Large XLarge
   > XLarge2Large <- function(x) { x[x=="XLarge"] <- "Large" ; x }
   > XLarge2Large(x)
   [1] Large Small Small Large
   Levels: Small Med Large XLarge
instead of things like
   > ifelse(x=="XLarge", "Large", x)
   [1] "3"     "1"     "1"     "Large"

If you don't care about the factor levels, then convert x to a character vector.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Sep 27, 2014 at 10:13 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Not reproducible, ball in your court. However, in the meantime, my suggestion is to not do that. Convert to character before you alter the factor, then convert back when you are done.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On September 27, 2014 9:49:41 PM PDT, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>Quick question:
>>
>>I am running the following code on some variables that are factors:
>>
>>dbpmn$IID1new <- ifelse(as.character(dbpmn[,2]) ==
>>as.character(dbpmn[,(21)]), dbpmn[,20], '')
>>
>>Instead of returning some value it gives me this:
>>
>>c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1))
>>
>>Playing around with the code, gives me some kind of variation to it.
>>Is there some way to get me what I want.  The variable that its
>>suppose to give back is a bunch of sampleIDs.
>>
>>Thanks!
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Sun Sep 28 21:13:43 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sun, 28 Sep 2014 15:13:43 -0400
Subject: [R] if else statement in loop
Message-ID: <CAE6QMsaYDHMsN29HKqrN1WuSt-J0a7u=aFr8TOvBQkDKeAEe1g@mail.gmail.com>

I have two data frames

For simplicity:

X=

V1 V2 V3  V4 V5 V6
samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling

Y=

FID IID
FAM01 samas4
FAM01 samas5
FAM01 samas6

I want to set to create a new IID in Y using V4 V5 V6 in X using an
ifelse statement in a loop.  I've used something like the following
(after figuring out my factor problem):

for(i in length(1:(2*nrow(X)))){
    Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
}

But of course this tends to overwrite.

Is there an easy way to set up a loop to replace missing values? This
didn't work either but not sure if its as easy as this:

Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')

for(i in length(2:(2*nrow(X)))){
ifelse((as.character(Y[,i]) == as.character(Xl[,i])),
X[is.na(X$IID1new)] <- as.character(as.matrix(X[(2*nrow(X)+i)])),'')
}

Thanks!

K.


From ccfdexplorer at gmail.com  Sun Sep 28 21:26:59 2014
From: ccfdexplorer at gmail.com (Jason Eyerly)
Date: Sun, 28 Sep 2014 12:26:59 -0700
Subject: [R] Plotting Categorical/Numerical Data?
Message-ID: <CAC=Mo5ezsp+YAqBYx4_N7SGFcpBDTYts0t_zL8mAVoMOo4y1gA@mail.gmail.com>

Hello Everyone,
    I've created a sample of poker hands being dealt. How can I plot the
data visually in R/R-Studio where x=(Card1,Card2) and Y = Frequency Of
Occurence? I'm trying to visualize a simulation, to compare to an actual
dataset, to determine if the hands being dealt in the "actual" computer
game are fair and in fact "random".

For example:

    5
    4
    3
    2
    1
      QS AH, 1S 2C, 5H KH....

Thanks In Advance,
    Jason E.

	[[alternative HTML version deleted]]


From padmanandm at gmail.com  Sun Sep 28 23:26:45 2014
From: padmanandm at gmail.com (Padmanand Madhavan Nambiar)
Date: Sun, 28 Sep 2014 14:26:45 -0700
Subject: [R] optim for maximization
Message-ID: <CANUpFF8f7PXN4wFB9-kmW5Wu0Qfj2Z+VnCwOEobDBkOUN8wewQ@mail.gmail.com>

Hi Sir,

 How to use the "optim" for maximization. I don't understand the
 control$fnscale option that is given on help page. It says if the
control$fnscale is negative, the function will be maximized.

 Thanks a lot

Padmanand
-- 
Padmanand Madhavan Nambiar
Alternate e-mail id : anand at uga.edu

(Patience pays)

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Sep 29 00:31:31 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 28 Sep 2014 22:31:31 +0000
Subject: [R] optim for maximization
References: <CANUpFF8f7PXN4wFB9-kmW5Wu0Qfj2Z+VnCwOEobDBkOUN8wewQ@mail.gmail.com>
Message-ID: <loom.20140929T003026-205@post.gmane.org>

Padmanand Madhavan Nambiar <padmanandm <at> gmail.com> writes:

> 
> Hi Sir,
> 
>  How to use the "optim" for maximization. I don't understand the
>  control$fnscale option that is given on help page. It says if the
> control$fnscale is negative, the function will be maximized.
> 
>  Thanks a lot
> 
> Padmanand

  If 'fn' is your objective function and 'par' is your starting
parameter vector, just

   optim(par=par,fn=fn,control=list(fnscale=-1))


From cranatic at gmail.com  Mon Sep 29 00:40:06 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 28 Sep 2014 18:40:06 -0400
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <54288e46b251a_5caa24359341fc@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* ADDT (1.0)
  Maintainer: Yili Hong
  Author(s): Yili Hong, Yimeng Xie, and Caleb King
  License: GPL-2
  http://crantastic.org/packages/ADDT

  Accelerated destructive degradation tests (ADDT) are often used to
  collect necessary data for assessing the long-term properties of
  polymeric materials. Based on the collected data, a thermal index
  (TI) is estimated. The TI can be useful for material rating and
  comparison. This package performs the least squares (LS) and maximum
  likelihood (ML) procedures for estimating TI for polymeric
  materials. The LS approach is a two-step approach that is currently
  used in industrial standards, while the ML procedure is widely used
  in the statistical literature. The ML approach allows one to do
  statistical inference such as quantifying uncertainties in
  estimation, hypothesis testing, and predictions. Two publicly
  available datasets are provided to allow users to experiment and
  practice with the functions.

* ASMap (0.3)
  Maintainer: Julian Taylor
  Author(s): Julian Taylor <julian.taylor at adelaide.edu.au>, David Butler
             <david.butler at daff.qld.gov.au>.
  License: GPL (>= 2)
  http://crantastic.org/packages/ASMap

  Functions for (A)ccurate and (S)peedy linkage map construction,
  manipulation and diagnosis of double haploid, backcross and and RIL
  R/qtl objects. This includes extremely fast linkage map clustering
  and optimal marker ordering using MSTmap (see Wu et al.,2008).

* causaleffect (1.0)
  Maintainer: Santtu Tikka
  Author(s): Santtu Tikka
  License: GPL-2
  http://crantastic.org/packages/causaleffect

  An implementation of the complete identification algorithm constructed
  by Ilya Shpitser and Judea Pearl (2006) for deriving expressions of
  joint interventional distributions in causal models, which contain
  unobserved variables and induce directed acyclic graphs.

* Compind (1.0)
  Maintainer: Francesco Vidoli
  Author(s): Francesco Vidoli, Elisa Fusco
  License: GPL-3
  http://crantastic.org/packages/Compind

  Compind package contains several functions to enhance approaches to
  the Composite Indicators
  (http://stats.oecd.org/glossary/detail.asp?ID=6278},
  https://composite-indicators.jrc.ec.europa.eu/) methods, focusing,
  in particular, on the normalisation and weighting-aggregation steps.

* crayon (1.0.0)
  Maintainer: &quot;Gabor Csardi&quot;
  Author(s): "Gabor Csardi" [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/crayon

  Crayon adds support for colored terminal output on terminals that
  support ANSI color and highlight codes. ANSI color support is
  automatically detected. Colors and highlighting can be combined and
  nested. New styles can also be created easily. This package was
  inspired by the chalk JavaScript project.

* deming (1.0-1)
  Maintainer: Terry Therneau
  Author(s): Terry Therneau
  License: LGPL (>= 2)
  http://crantastic.org/packages/deming

  Generalized Deming regression, Theil-Sen regression and
  Passing-Bablock regression functions.

* documair (0.6-0)
  Maintainer: Jean-Baptiste Denis
  Author(s): Jean-Baptiste Denis <Jean-Baptiste.Denis at jouy.inra.fr>, Regis Pouillot
             <RPouillot at yahoo.fr>, Kien Kieu <Kien.Kieu at jouy.inra.fr>
  License: GPL (>= 2.15)
  http://crantastic.org/packages/documair

  Production of R packages from tagged comments introduced within the
  code  and a minimum of additional documentation files.

* GenWin (0.1)
  Maintainer: Timothy M. Beissinger
  Author(s): Timothy M. Beissinger <beissinger at ucdavis.edu>
  License: MIT + file LICENSE
  http://crantastic.org/packages/GenWin

  Defines window or bin boundaries for the analysis of genomic data.
  Boundaries are based on the inflection points of a cubic smoothing
  spline fitted to the raw data. Along with defining boundaries, a
  technique to evaluate results obtained from unequally-sized windows
  is provided. Applications are particularly pertinent for, though not
  limited to, genome scans for selection based on variability between
  populations (e.g. using Wright&#39;s fixations index, Fst, which
  measures variability in subpopulations relative to the total
  population).

* ivprobit (1.0)
  Maintainer: Zaghdoudi Taha
  Author(s): Zaghdoudi Taha
  License: Artistic-2.0
  http://crantastic.org/packages/ivprobit

  ivprobit fit an Instrumental variables probit model using the
  generalized least squares estimator

* kofnGA (1.0)
  Maintainer: Mark A. Wolters
  Author(s): Mark A. Wolters
  License: GPL-2
  http://crantastic.org/packages/kofnGA

  Function kofnGA uses a genetic algorithm to choose a subset of a 
  fixed size k from the integers 1:n, such that a user-supplied
  objective function  is minimized at that subset.  The selection step
  is done by tournament selection  based on ranks, and elitism may be
  used to retain a portion of the best solutions  from one generation
  to the next.

* MetFns (1.0)
  Maintainer: Kristina Veljkovic
  Author(s): Kristina Veljkovic
  License: GPL-2 | GPL-3
  http://crantastic.org/packages/MetFns

  Functions for selection of visual meteor data, calculations of
  Zenithal Hourly Rate (ZHR) and population index, graphics of ZHR and
  magnitude distribution

* mpath (0.1-15)
  Maintainer: Zhu Wang
  Author(s): Zhu Wang, with contributions from Achim Zeileis, Simon Jackman, Brian
             Ripley, Trevor Hastie, Rob Tibshirani, Balasubramanian
             Narasimhan, Gil Chu and Patrick Breheny
  License: GPL-2
  http://crantastic.org/packages/mpath

  Algorithms for fitting model-based penalized coefficient paths.
  Currently the models include penalized Poisson, negative binomial,
  zero-inflated Poisson and zero-inflated negative binomial regression
  models. The penalties include least absolute shrinkage and selection
  operator (LASSO), smoothly clipped absolute deviation (SCAD) and
  minimax concave penalty (MCP), and each possibly combining with L_2
  penalty.

* NHMM (3.3)
  Maintainer: Tracy Holsclaw
  Author(s): Tracy Holsclaw
  License: GPL (>= 3)
  http://crantastic.org/packages/NHMM

  Bayesian NHMM modeling for multiple time series. The emission
  distribution can be mixtures of Gammas, Poissons, Normals and zero
  inflation is possible.

* ordinalgmifs (1.0.0)
  Maintainer: Kellie J. Archer
  Author(s): Kellie J. Archer, Jiayi Hou, Qing Zhou, Kyle Ferber, John G. Layne,
             Amanda Gentry
  License: GPL (>= 2)
  http://crantastic.org/packages/ordinalgmifs

  This package provides a function for fitting cumulative link, adjacent
  category, forward and backward continuation ratio, and stereotype
  ordinal response models when the number of parameters exceeds the
  sample size, using the the generalized monotone incremental forward
  stagewise method.

* pingr (1.0.0)
  Maintainer: &quot;Gabor Csardi&quot;
  Author(s): "Gabor Csardi" [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/pingr

  Check if a remote computer is up. It can either just call the system
  ping command, or check a specified TCP port.

* RJSDMX (1.1)
  Maintainer: Attilio Mattiocco
  Author(s): Attilio Mattiocco, Diana Nicoletti, Gianpaolo Lopez, Banca d'Italia
  License: EUPL
  http://crantastic.org/packages/RJSDMX

  This package provides functions that can be used to retrieve  			 data
  and metadata from SDMX compliant data providers.

* SimplicialCubature (1.0)
  Maintainer: John P. Nolan
  Author(s): John P. Nolan, with parts based on code by Alan Genz
  License: GPL (>= 2)
  http://crantastic.org/packages/SimplicialCubature

  This package provides methods to integrate functions over
  m-dimensional simplices  in n-dimensional Euclidean space.  There
  are exact methods for polynomials and adaptive methods for
  integrating an arbitrary function.

* SPREDA (1.0)
  Maintainer: Yili Hong
  Author(s): Yili Hong, Yimeng Xie, and Zhibing Xu
  License: GPL-2
  http://crantastic.org/packages/SPREDA

  The Statistical Package for REliability Data Analysis (SPREDA)
  implements recently-developed statistical methods for the analysis
  of reliability data. Modern technological developments, such as
  sensors and smart chips, allow us to dynamically track
  product/system usage as well as other environmental variables, such
  as temperature and humidity. We refer to these variables as dynamic
  covariates. The package contains functions for the analysis of
  time-to-event data with dynamic covariates and degradation data with
  dynamic covariates. The package also contains functions that can be
  used for analyzing time-to-event data with right censoring, and with
  left truncation and right censoring. Financial support from NSF and
  DuPont are acknowledged.

* virtualspecies (1.0)
  Maintainer: Boris Leroy
  Author(s): Boris Leroy with help from C. N. Meynard, C. Bellard & F. Courchamp
  License: GPL (>= 2.0)
  http://crantastic.org/packages/virtualspecies

  Provides a framework for generating virtual species distributions,  a
  procedure increasingly used in ecology to improve species
  distribution models. This package integrates the existing
  methodological approaches with the  objective of generating virtual
  species distributions with increased  ecological realism.


Updated packages
----------------

agrmt (1.35), alr4 (1.0.5), aplpack (1.3.0), BatchExperiments (1.3),
BatchJobs (1.4), BDgraph (2.12), BDgraph (2.11), betareg (3.0-5),
BrailleR (0.11), cape (1.3), copBasic (1.6.0), datacheck (1.0.4), DBI
(0.3.1), Delaporte (2.2-1), devtools (1.6), diseasemapping (1.0.1),
eHOF (1.5), exactci (1.3-0), fAssets (3011.82), flexmix (2.3-12),
flexsurv (0.5), forecast (5.6), GENLIB (1.0.1), GSE (3.1), Guerry
(1.6-1), hglm (2.0-9), hht (2.1.0), HiddenMarkov (1.8-1), IBrokers
(0.9-12), indicspecies (1.7.3), ivivc (0.2.1), lessR (3.1.1),
lmSupport (2.9.1), lsmeans (2.12), maps (2.3-9), MAT (2.0), mmand
(1.1.0), Morpho (2.1), mpath (0.1-15), mrds (2.1.10), oc (0.95),
oro.pet (0.2.3), polysat (1.3-3), proxy (0.4-13), pvsR (0.3),
qdapRegex (0.1.2), RandomFields (3.0.42), Rcmdr (2.1-2), RcppArmadillo
(0.4.450.1.0), readBrukerFlexData (1.8), rentrez (0.3), rentrez
(0.3.1), rpf (0.39), RSurvey (0.8-2), RVAideMemoire (0.9-40), secr
(2.9.0), SemiPar (1.0-4.1), snpEnrichment (1.5-0), testthat (0.9),
TreePar (3.1), trip (1.1-18), trustOptim (0.8.4.1), VennDiagram
(1.6.9), wnominate (0.99)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From rhelp at numberland.de  Mon Sep 29 00:10:58 2014
From: rhelp at numberland.de (rhelp at numberland.de)
Date: Mon, 29 Sep 2014 00:10:58 +0200
Subject: [R] draw piecharts or histograms at the points of a scatterplot
Message-ID: <54288772.4010901@numberland.de>

Hi,

I?m fairly new to R and have a problem mentioned in the subject ...

I want to draw a scatterplot in 3d - either with scatterplot3d or - 
preferably - with the rgl package - but instead of points or text 
(text3d command of rgl) I would like to draw either histograms or pie 
charts to visualize further properties of the objects.

Is there a way to do this?

Many thanks in advance

spok

	[[alternative HTML version deleted]]


From davparker at gmail.com  Mon Sep 29 01:15:33 2014
From: davparker at gmail.com (David K Parker)
Date: Sun, 28 Sep 2014 18:15:33 -0500
Subject: [R] How do I install a Windows package built from source?
Message-ID: <CAPtbiZjWN7HpSoYHf35DYB-cH9KnG5darEGxK_nFOHmQVxOUDA@mail.gmail.com>

> Hello,
>
> I'm trying to connect to a MongoDB through the rmongodb package. Here is
> my system info:
>
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> I can install the rmongodb package but it won't load, see below:
> > install.packages("rmongodb")
> Installing package into ?C:/Users/David/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> trying URL '
> http://cran.revolutionanalytics.com/bin/windows/contrib/3.1/rmongodb_1.6.5.zip
> '
> Content type 'application/zip' length 1155000 bytes (1.1 Mb)
> opened URL
> downloaded 1.1 Mb
>
> package ?rmongodb? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
> C:\Users\David\AppData\Local\Temp\RtmpqSKJi9\downloaded_packages
> > library("rmongodb")
> Error in get(".packageName", where) : lazy-load database 'P' is corrupt
> In addition: Warning message:
> In get(".packageName", where) : internal error -3 in R_decompress1
> Error: package or namespace load failed for ?rmongodb?
>
> So, next I remove it, then try installing with devtools as shown here:
> library(devtools)
> install_github("rmongodb", "mongosoup")
>
> but that just flat out fails to install. So now I've downloaded the source
> and have successfully built the package with Visual Studio 2012 but I'm not
> sure how to load it into R.
> Here is the directory listing:
>
> ls  "Documents/visual studio 2012/Projects/rmongodb/Debug/rmongodb"
>
> App.xaml          Common         resources.pri              rmongodb.exe
>  rmongodb.ilk  rmongodb.pdb
> AppxManifest.xml  MainPage.xaml  rmongodb.build.appxrecipe  rmongodb.exp
>  rmongodb.lib  rmongodb.winmd
>
> Any help would be greatly appreciated,
> Thank you,
> David Parker
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Sep 29 03:51:52 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 28 Sep 2014 18:51:52 -0700
Subject: [R] Plotting Categorical/Numerical Data?
In-Reply-To: <CAC=Mo5ezsp+YAqBYx4_N7SGFcpBDTYts0t_zL8mAVoMOo4y1gA@mail.gmail.com>
References: <CAC=Mo5ezsp+YAqBYx4_N7SGFcpBDTYts0t_zL8mAVoMOo4y1gA@mail.gmail.com>
Message-ID: <CACk-te0d=dKN8AV2Vh5=kx3gCJoxvoCUg5ipS0iooh+Q87m7dQ@mail.gmail.com>

1. Homework? We don't do homework here.

2. I believe what you purport to do is unlikely answer the "is it
random" question. Or, more exactly, may very well give an incorrect
answer.

To learn what you should do:

3. Post to a statistics (or math) site like stats.stackexchange.com.
You gave no details, but it may well be complex.

4. Or consult someone locally with knowledge of probability and statistics.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Sep 28, 2014 at 12:26 PM, Jason Eyerly <ccfdexplorer at gmail.com> wrote:
> Hello Everyone,
>     I've created a sample of poker hands being dealt. How can I plot the
> data visually in R/R-Studio where x=(Card1,Card2) and Y = Frequency Of
> Occurence? I'm trying to visualize a simulation, to compare to an actual
> dataset, to determine if the hands being dealt in the "actual" computer
> game are fair and in fact "random".
>
> For example:
>
>     5
>     4
>     3
>     2
>     1
>       QS AH, 1S 2C, 5H KH....
>
> Thanks In Advance,
>     Jason E.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Sep 29 04:09:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 28 Sep 2014 19:09:16 -0700
Subject: [R] How do I install a Windows package built from source?
In-Reply-To: <CAPtbiZjWN7HpSoYHf35DYB-cH9KnG5darEGxK_nFOHmQVxOUDA@mail.gmail.com>
References: <CAPtbiZjWN7HpSoYHf35DYB-cH9KnG5darEGxK_nFOHmQVxOUDA@mail.gmail.com>
Message-ID: <D26D0998-5643-4FEF-9D9A-F05BCAF5BEF3@dcn.davis.CA.us>

1) This question belongs on R-devel. Please read the Posting Guide.

2) I am almost certain that unless you have built your R software using Visual Studio 2012, you will be unable to use a package built with that tool with your R software. Read the instructions regarding Rtools on CRAN regarding building packages for R on Windows.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 28, 2014 4:15:33 PM PDT, David K Parker <davparker at gmail.com> wrote:
>> Hello,
>>
>> I'm trying to connect to a MongoDB through the rmongodb package. Here
>is
>> my system info:
>>
>> R version 3.1.1 (2014-07-10)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> I can install the rmongodb package but it won't load, see below:
>> > install.packages("rmongodb")
>> Installing package into ?C:/Users/David/Documents/R/win-library/3.1?
>> (as ?lib? is unspecified)
>> trying URL '
>>
>http://cran.revolutionanalytics.com/bin/windows/contrib/3.1/rmongodb_1.6.5.zip
>> '
>> Content type 'application/zip' length 1155000 bytes (1.1 Mb)
>> opened URL
>> downloaded 1.1 Mb
>>
>> package ?rmongodb? successfully unpacked and MD5 sums checked
>>
>> The downloaded binary packages are in
>> C:\Users\David\AppData\Local\Temp\RtmpqSKJi9\downloaded_packages
>> > library("rmongodb")
>> Error in get(".packageName", where) : lazy-load database 'P' is
>corrupt
>> In addition: Warning message:
>> In get(".packageName", where) : internal error -3 in R_decompress1
>> Error: package or namespace load failed for ?rmongodb?
>>
>> So, next I remove it, then try installing with devtools as shown
>here:
>> library(devtools)
>> install_github("rmongodb", "mongosoup")
>>
>> but that just flat out fails to install. So now I've downloaded the
>source
>> and have successfully built the package with Visual Studio 2012 but
>I'm not
>> sure how to load it into R.
>> Here is the directory listing:
>>
>> ls  "Documents/visual studio 2012/Projects/rmongodb/Debug/rmongodb"
>>
>> App.xaml          Common         resources.pri             
>rmongodb.exe
>>  rmongodb.ilk  rmongodb.pdb
>> AppxManifest.xml  MainPage.xaml  rmongodb.build.appxrecipe 
>rmongodb.exp
>>  rmongodb.lib  rmongodb.winmd
>>
>> Any help would be greatly appreciated,
>> Thank you,
>> David Parker
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Sep 29 08:39:17 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 29 Sep 2014 06:39:17 +0000
Subject: [R] if else statement in loop
In-Reply-To: <CAE6QMsaYDHMsN29HKqrN1WuSt-J0a7u=aFr8TOvBQkDKeAEe1g@mail.gmail.com>
References: <CAE6QMsaYDHMsN29HKqrN1WuSt-J0a7u=aFr8TOvBQkDKeAEe1g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8334@SRVEXCHMBX.precheza.cz>

Hi

Please, be more clear in what do you want. I get many errors trying your code and your explanation does not help much.

> for(i in length(1:(2*nrow(X)))){
+     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) & X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
Error: unexpected ',' in:
"for(i in length(1:(2*nrow(X)))){
    Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) & X$IID1new != '') ,"
> }
Error: unexpected '}' in "}"
> for(i in length(1:(2*nrow(X)))){
+     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
+ X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
Error: unexpected ',' in:
"    Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
X$IID1new != '') ,"
> }


Beside, this column X$IID1new != '' does not exist in X

Here you clearly ask for nonexistent column, and why the heck you want to select column by number of rows?

> as.character(as.matrix(X[,(2*nrow(X)+1)]))
Error in `[.data.frame`(X, , (2 * nrow(X) + 1)) :
  undefined columns selected

So based on your toy data frames, what shall be the result after your computation.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Kate Ignatius
> Sent: Sunday, September 28, 2014 9:14 PM
> To: r-help
> Subject: [R] if else statement in loop
>
> I have two data frames
>
> For simplicity:
>
> X=
>
> V1 V2 V3  V4 V5 V6
> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
>
> Y=
>
> FID IID
> FAM01 samas4
> FAM01 samas5
> FAM01 samas6
>
> I want to set to create a new IID in Y using V4 V5 V6 in X using an
> ifelse statement in a loop.  I've used something like the following
> (after figuring out my factor problem):
>
> for(i in length(1:(2*nrow(X)))){
>     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
> X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
> }
>
> But of course this tends to overwrite.
>
> Is there an easy way to set up a loop to replace missing values? This
> didn't work either but not sure if its as easy as this:
>
> Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
> X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
>
> for(i in length(2:(2*nrow(X)))){
> ifelse((as.character(Y[,i]) == as.character(Xl[,i])),
> X[is.na(X$IID1new)] <- as.character(as.matrix(X[(2*nrow(X)+i)])),'')
> }
>
> Thanks!
>
> K.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From p_connolly at slingshot.co.nz  Mon Sep 29 09:24:47 2014
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Mon, 29 Sep 2014 20:24:47 +1300
Subject: [R] Unexpected behaviour of plyr::ddply
In-Reply-To: <CAFU=EkaeTDxjWGfGMOs4rFNtG_Tx6q39jPumNk1+4AVg1U8rtg@mail.gmail.com>
References: <CAFU=EkaeTDxjWGfGMOs4rFNtG_Tx6q39jPumNk1+4AVg1U8rtg@mail.gmail.com>
Message-ID: <20140929072447.GB3081@slingshot.co.nz>

On Wed, 17-Sep-2014 at 12:36AM -0300, walmes . wrote:

|> Hello R users,
|> 
|> I'm writing a brief tutorial of getting statistical measures by splitting
|> according strata and over columns. When I used plyr::ddply I got and
|> unexpected result, with NA/NaN for non existing cells. Below is a minimal
|> reproducible code with the result that I got. For comparison, the result of
|> aggregate is showed. Why this behaviour? What I can do to avoid it?
|> 
|> > require(plyr)
|> >
|> > hab <-
|> +     read.table("http://www.leg.ufpr.br/~walmes/data/ipea_habitacao.csv",
|> +                header=TRUE, sep=",", stringsAsFactors=FALSE, quote="",
|> +                encoding="utf-8")
|> >
|> > hab <- hab[,-ncol(hab)]
|> > names(hab) <- c("sig", "cod", "mun", "agua", "ener", "tel", "carro",
|> +                 "comp", "tot")
|> > hab <- transform(hab, sig=factor(sig))
|> > hab$siz <- cut(hab$tot, breaks=c(-Inf, 5000, Inf),
|> +                labels=c("P","G"))


However:
> summary(hab$tot)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
    227    1328    2640    8264    5440 3039000      89 

Those NAs interfere with the cut() statement.

The simplest work around is

> hab <- na.omit(hab)
> 
Then ddply will play nicely.

HTH

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From miaojpm at gmail.com  Mon Sep 29 11:05:50 2014
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 29 Sep 2014 17:05:50 +0800
Subject: [R] Could someone recommend a package for time series?
Message-ID: <CABcx46DsxQ+Nmr2_kKRQsedwmPJOctqHV+mrTpCppw-SH_pi+w@mail.gmail.com>

Hi,

   I've not used R for about one year and don't know well about the updates
on the time series-related package.

  My primary job is to do economic/financial time series data analysis -
annual, monthly, daily, etc. I usually read data by the package
"XLConnect", which can read xls or xlsx files directly. It's excellent.
However I can't find a package to manipulate time series data. For example,
I just want to do an easy manipulation , e.g, to label the dates of the
data from , say, 1991M10 to 2014M07, and then extract part of the data,
say, 2005M01 to 2010M12 and do analysis. Is there any package work well for
my purpose?

  I sometimes need to aggregate monthly data to quarterly data and I find
"aggregate" function helpful.

  In the past I used packages xts, zoo and don't find it really user
friendly. Maybe I haven't mastered it; maybe there're some updates (which I
don't know) now. Could someone recommend a package or provide an example
(or just the document, I can read it) for my purpose?

   Attached is an exemplary data set I talked about.

   Thanks,

Miao

From kridox at ymail.com  Mon Sep 29 11:10:57 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 29 Sep 2014 18:10:57 +0900
Subject: [R] Could someone recommend a package for time series?
In-Reply-To: <CABcx46DsxQ+Nmr2_kKRQsedwmPJOctqHV+mrTpCppw-SH_pi+w@mail.gmail.com>
References: <CABcx46DsxQ+Nmr2_kKRQsedwmPJOctqHV+mrTpCppw-SH_pi+w@mail.gmail.com>
Message-ID: <CAAcyNCxegmmw_1fbeeRNVjK68CTnnMYvRBeO1p_n0dArq5aAmA@mail.gmail.com>

Hi Miao,

You certainly will find useful answers here :
http://cran.r-project.org/web/views/TimeSeries.html

Regards,
Pascal Oettli

On Mon, Sep 29, 2014 at 6:05 PM, jpm miao <miaojpm at gmail.com> wrote:
> Hi,
>
>    I've not used R for about one year and don't know well about the updates
> on the time series-related package.
>
>   My primary job is to do economic/financial time series data analysis -
> annual, monthly, daily, etc. I usually read data by the package
> "XLConnect", which can read xls or xlsx files directly. It's excellent.
> However I can't find a package to manipulate time series data. For example,
> I just want to do an easy manipulation , e.g, to label the dates of the
> data from , say, 1991M10 to 2014M07, and then extract part of the data,
> say, 2005M01 to 2010M12 and do analysis. Is there any package work well for
> my purpose?
>
>   I sometimes need to aggregate monthly data to quarterly data and I find
> "aggregate" function helpful.
>
>   In the past I used packages xts, zoo and don't find it really user
> friendly. Maybe I haven't mastered it; maybe there're some updates (which I
> don't know) now. Could someone recommend a package or provide an example
> (or just the document, I can read it) for my purpose?
>
>    Attached is an exemplary data set I talked about.
>
>    Thanks,
>
> Miao
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From murdoch.duncan at gmail.com  Mon Sep 29 11:13:54 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Sep 2014 05:13:54 -0400
Subject: [R] draw piecharts or histograms at the points of a scatterplot
In-Reply-To: <54288772.4010901@numberland.de>
References: <54288772.4010901@numberland.de>
Message-ID: <542922D2.9030207@gmail.com>

On 28/09/2014, 6:10 PM, rhelp at numberland.de wrote:
> Hi,
> 
> I?m fairly new to R and have a problem mentioned in the subject ...
> 
> I want to draw a scatterplot in 3d - either with scatterplot3d or - 
> preferably - with the rgl package - but instead of points or text 
> (text3d command of rgl) I would like to draw either histograms or pie 
> charts to visualize further properties of the objects.
> 
> Is there a way to do this?

One way would be to use the symbols() function with scatterplot3d(), if
symbols() is sufficient to show the other properties.

A more complicated way would be to write the individual plots to .png
files, and then use sprites3d() in rgl to plot those pictures at the
point locations.  (These are 2d sprites, not 3d sprites.) I'm not sure
how good it would look:  sprites tend to look blurry because of all the
resizing that takes place.

Duncan Murdoch

> 
> Many thanks in advance
> 
> spok
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From erickokuto at gmail.com  Mon Sep 29 08:32:05 2014
From: erickokuto at gmail.com (Erick Okuto)
Date: Mon, 29 Sep 2014 09:32:05 +0300
Subject: [R] Savitzky-Golay Smoother
In-Reply-To: <CAP01uRkznyxJt3YSXSoPb8TqZW4vj0fyRzSGiAYG2aO=twmw5A@mail.gmail.com>
References: <CAB-=SDXJqE8MQ113EOZF02PLJCYT75jQkrdz+mUEE9LTc1fYFw@mail.gmail.com>
	<CAP01uRkznyxJt3YSXSoPb8TqZW4vj0fyRzSGiAYG2aO=twmw5A@mail.gmail.com>
Message-ID: <CAB-=SDVzi8w_AvA8m=odCtonvcOy7EEyrhT8Uq1LSGeEwryxhg@mail.gmail.com>

Dear Gabor, Paul and Ryan,
Many thanks for all your guidance concerning  the application of the
filter/smoother. I need to temporally smooth 32 years 5 km resolution
bi-monthly global NDVI dataset. On average each pixel have got up to 768
cases/images with data missing at random. I consider the data to be large
and with the nature of missing data, applying the filter manually might be
tricky. I have run a function which kind of combines Gabor and  Paul's
suggestion " sgolayfilt(zoo::na.spline(ydata)) " as suggested by Ryan (cc'd
here) on a few sampled time series data and observed/projections are
generally  matching well. If i understand the function, it first fill in
NAs with spline curve fits from zoo package and run Savitzky-Golay filter
on a continuous data. The problem is that data/observations on the end
points (like first and last 5 or 10) are poorly projected with some
projections being off the possible values that NDVI can take. Can we adjust
the algorithm  such that the problem is controlled? Thanks for your time.

Kind regards,
Erick.


On Sat, Sep 27, 2014 at 2:23 AM, Gabor Grothendieck <ggrothendieck at gmail.com
> wrote:

> On Fri, Sep 26, 2014 at 3:32 AM, Erick Okuto <erickokuto at gmail.com> wrote:
> > Dear Paul and Henrik,
> > I have a time series with some missing data points that i need smoothed
> > using Savitzky-Golay filter. Related question was asked  here
> >
> http://thr3ads.net/r-help/2012/11/2121748-Savitzky-Golay-filtering-with-missing-data
> > but no straight forward answer was posted. However, Henrik (cc'd here)
> did
> > ask related question on smoothing for reflectance here
> >
> http://thr3ads.net/r-help/2004/02/835137-Savitzky-Golay-smoothing-for-reflectance-data
> > which i have as well been unable to follow up. I will be glad if you
> could
> > assist me with some insights on the way forward or point to a relevant
> > source of help.
>
>
> Not Savitzky-Golay but if z is a time series then
>
> library(zoo)
> na.spline(z)
>
> will fill in NAs with spline curve fits.  See ?na.spline
>
> There are other NA filling routines in zoo too:
>
> > ls(pattern = "^na[.]", "package:zoo")
>  [1] "na.aggregate"         "na.aggregate.default" "na.approx"
>  [4] "na.approx.default"    "na.fill"              "na.fill.default"
>  [7] "na.locf"              "na.locf.default"      "na.spline"
> [10] "na.spline.default"    "na.StructTS"          "na.trim"
> [13] "na.trim.default"      "na.trim.ts"
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>



-- 
*Erick Okuto, Ph.D.*
* Candidate*
*School of Mathematics & Actuarial Science*
*Jaramogi Oginga Odinga University of Science & Technology (JOOUST)/ World
Agroforestry Centre (ICRAF), **Climate Change Unit, Nairobi-Kenya. *
Voice:  +254207224154?    Mobile: +254725005276    Skype id:  erickokuto
Email: erickokuto at gmail.com

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Mon Sep 29 11:47:01 2014
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 29 Sep 2014 17:47:01 +0800
Subject: [R] "timeDate" package: Read dates from xls or txt
Message-ID: <CABcx46BLy-X0DEd5QLb2C42Lck0e8qM0CQ9TK_K_yvFD0j3Dbg@mail.gmail.com>

Hi,

   timeDate package create a date vector like this:

   Dates <- c("1989-09-28","2001-01-15","2004-08-30","1990-02-09")


   I have a date whose size is large. Could this package read the dates
from xls or txt files? Could we convert the read vector (e.g., I usually
use XLConnect to read xls files) to the date?

   Thanks,

Miao

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Mon Sep 29 11:47:25 2014
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 29 Sep 2014 17:47:25 +0800
Subject: [R] Could someone recommend a package for time series?
In-Reply-To: <CAAcyNCxegmmw_1fbeeRNVjK68CTnnMYvRBeO1p_n0dArq5aAmA@mail.gmail.com>
References: <CABcx46DsxQ+Nmr2_kKRQsedwmPJOctqHV+mrTpCppw-SH_pi+w@mail.gmail.com>
	<CAAcyNCxegmmw_1fbeeRNVjK68CTnnMYvRBeO1p_n0dArq5aAmA@mail.gmail.com>
Message-ID: <CABcx46AULJ8PnWendodtM-8mMdcQpV+Ei3gK78UWj3uEobMuJA@mail.gmail.com>

Thanks Pascal! It certainly helps!

2014-09-29 17:10 GMT+08:00 Pascal Oettli <kridox at ymail.com>:

> Hi Miao,
>
> You certainly will find useful answers here :
> http://cran.r-project.org/web/views/TimeSeries.html
>
> Regards,
> Pascal Oettli
>
> On Mon, Sep 29, 2014 at 6:05 PM, jpm miao <miaojpm at gmail.com> wrote:
> > Hi,
> >
> >    I've not used R for about one year and don't know well about the
> updates
> > on the time series-related package.
> >
> >   My primary job is to do economic/financial time series data analysis -
> > annual, monthly, daily, etc. I usually read data by the package
> > "XLConnect", which can read xls or xlsx files directly. It's excellent.
> > However I can't find a package to manipulate time series data. For
> example,
> > I just want to do an easy manipulation , e.g, to label the dates of the
> > data from , say, 1991M10 to 2014M07, and then extract part of the data,
> > say, 2005M01 to 2010M12 and do analysis. Is there any package work well
> for
> > my purpose?
> >
> >   I sometimes need to aggregate monthly data to quarterly data and I find
> > "aggregate" function helpful.
> >
> >   In the past I used packages xts, zoo and don't find it really user
> > friendly. Maybe I haven't mastered it; maybe there're some updates
> (which I
> > don't know) now. Could someone recommend a package or provide an example
> > (or just the document, I can read it) for my purpose?
> >
> >    Attached is an exemplary data set I talked about.
> >
> >    Thanks,
> >
> > Miao
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
>

	[[alternative HTML version deleted]]


From barry.king at qlx.com  Mon Sep 29 11:59:02 2014
From: barry.king at qlx.com (Barry King)
Date: Mon, 29 Sep 2014 05:59:02 -0400
Subject: [R] How to get rid of my for loop
Message-ID: <CAP8Wkrx9v=Fo1=t7_PAF+u2RzKM51D4-XWwfPNbSytxfc7-XSQ@mail.gmail.com>

# Here are sample data, sample vectors, and a for loop
# that I am using now. I wish to get rid of the for loop
# and use functions and one of the apply functions to
# perform the work without needing a many iteration for loop.
A_01 <- 1:5
A_02 <- 6:10
A_03 <- 11:15
A_04 <- 16:20

B_01 <- 101:105
B_02 <- 106:110
B_03 <- 111:115
B_04 <- 116:120

# I am showing just two pairs, A_x with A_array and B_x with B_array.
# In actuality there are about a dozen such pairings.
A_array <- array(NA, dim=5)
B_array <- array(NA, dim=5)

VFD_ID <- c(3, 2, NA, 1, 3)
nobs <- length(VFD_ID)

# This for loop works fine but is not appropriate for
# a large number of observations in VFD_ID.
for (i in 1:nobs){
  if (is.na(VFD_ID[i])){
    A_array[i]<- 0
    B_array[i]<- 0
  } else if (VFD_ID[i] == 1){
    A_array[i]<-A_01[i]
    B_array[i]<-B_01[i]
  } else if (VFD_ID[i] == 2){
    A_array[i]<-A_02[i]
    B_array[i]<-B_02[i]
  } else if (VFD_ID[i] == 3){
    A_array[i]<-A_03[i]
    B_array[i]<-B_03[i]
  } else if (VFD_ID[i] == 4){
    A_array[i]<-A_04[i]
    B_array[i]<-B_04[i]
  }
}

# This does NOT work. It returns the entire vector,
# not just the corresponding element in VFD_ID.
# (Note: It seems like a switch function would work here
# but I was unable to get it to work correctly.)
A_array_fnc <- function(x){
  if (is.na(x)) return (0) else
    if (x == 1) return (A_01) else
      if (x == 2) return (A_02) else
        if (x == 3) return (A_03) else
          if (x == 4) return (A_04)
}

B_array_fnc <- function(x){
  if (is.na(x)) return (0) else
    if (x == 1) return (B_01) else
      if (x == 2) return (B_02) else
        if (x == 3) return (B_03) else
          if (x == 4) return (B_04)
}

A_array <- sapply(VFD_ID,A_array_fnc)
B_array <- sapply(VFD_ID,B_array_fnc)

# Is there a way to write the functions correctly so that
# the return value for, say A_array[4] is A_03[4] if VFD_ID == 3?
# Any assistance is greatly appreciated.


From kate.ignatius at gmail.com  Mon Sep 29 12:54:08 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Mon, 29 Sep 2014 06:54:08 -0400
Subject: [R] if else statement in loop
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8334@SRVEXCHMBX.precheza.cz>
References: <CAE6QMsaYDHMsN29HKqrN1WuSt-J0a7u=aFr8TOvBQkDKeAEe1g@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8334@SRVEXCHMBX.precheza.cz>
Message-ID: <CAE6QMsZtHJZR2BgjEp5=ZaOOrai_OfhchuZJmMwocFG7TuUdSQ@mail.gmail.com>

Ooops,

I edited the code wrong to make it more easier for interpretation and
got X and Y's mixed up.  Try this:

for(i in length(1:(nrow(X)))){
    Y$IID1new <- ifelse((as.character(Y[,2]) == as.character(X[,i]) &
Y$IID1new != ''), as.character(as.matrix(X[,(nrow(X)+i)])),'')
}

The second should be like this:

Y$IID1new <- ifelse((as.character(Y[,2]) == as.character(X[,1])),
as.character(as.matrix(X[,(nrow(X)+1)])),'')

for(i in length(2:(nrow(X)))){
ifelse((as.character(Y[,i]) == as.character(X[,i])),
Y$IID1new[is.na(Y$IID1new)] <-
as.character(as.matrix(X[,(nrow(X)+i)])),'')
}

The reason why I'm selecting for number of rows seems a little odd
here I know but in real life this actually relies on a third data
frame, say Z, which for simplicity I didn't include here. But I only
want to start looking at the Nth column after twice as many rows in Z.
For instance, if Z has 4 rows, I want to  take values for IID1new
starting from column 9 in X to make IID1new in Y. Does that make
sense? Will this cause a problem?

So maybe it will probably be more like this if there were a Z

for(i in length(1:(2*nrow(Z)))){
    Y$IID1new <- ifelse((as.character(Y[,2]) == as.character(X[,i]) &
Y$IID1new != ''), as.character(as.matrix(X[,(2*nrow(Z)+i)])),'')
}

But essentially what I would like is this:

FID IID IID1new
FAM01 samas4 samas4_father
FAM01 samas5 samas5_mother
FAM01 samas6 samas6_sibling

I hope this is a little clearer...

Let me know if there are more errors.

K.

On Mon, Sep 29, 2014 at 2:39 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> Please, be more clear in what do you want. I get many errors trying your code and your explanation does not help much.
>
>> for(i in length(1:(2*nrow(X)))){
> +     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) & X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
> Error: unexpected ',' in:
> "for(i in length(1:(2*nrow(X)))){
>     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) & X$IID1new != '') ,"
>> }
> Error: unexpected '}' in "}"
>> for(i in length(1:(2*nrow(X)))){
> +     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
> + X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
> Error: unexpected ',' in:
> "    Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
> X$IID1new != '') ,"
>> }
>
>
> Beside, this column X$IID1new != '' does not exist in X
>
> Here you clearly ask for nonexistent column, and why the heck you want to select column by number of rows?
>
>> as.character(as.matrix(X[,(2*nrow(X)+1)]))
> Error in `[.data.frame`(X, , (2 * nrow(X) + 1)) :
>   undefined columns selected
>
> So based on your toy data frames, what shall be the result after your computation.
>
> Regards
> Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Kate Ignatius
>> Sent: Sunday, September 28, 2014 9:14 PM
>> To: r-help
>> Subject: [R] if else statement in loop
>>
>> I have two data frames
>>
>> For simplicity:
>>
>> X=
>>
>> V1 V2 V3  V4 V5 V6
>> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
>> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
>> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
>>
>> Y=
>>
>> FID IID
>> FAM01 samas4
>> FAM01 samas5
>> FAM01 samas6
>>
>> I want to set to create a new IID in Y using V4 V5 V6 in X using an
>> ifelse statement in a loop.  I've used something like the following
>> (after figuring out my factor problem):
>>
>> for(i in length(1:(2*nrow(X)))){
>>     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
>> X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
>> }
>>
>> But of course this tends to overwrite.
>>
>> Is there an easy way to set up a loop to replace missing values? This
>> didn't work either but not sure if its as easy as this:
>>
>> Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
>> X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
>>
>> for(i in length(2:(2*nrow(X)))){
>> ifelse((as.character(Y[,i]) == as.character(Xl[,i])),
>> X[is.na(X$IID1new)] <- as.character(as.matrix(X[(2*nrow(X)+i)])),'')
>> }
>>
>> Thanks!
>>
>> K.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From Thierry.ONKELINX at inbo.be  Mon Sep 29 13:08:50 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 29 Sep 2014 11:08:50 +0000
Subject: [R] How to get rid of my for loop
In-Reply-To: <CAP8Wkrx9v=Fo1=t7_PAF+u2RzKM51D4-XWwfPNbSytxfc7-XSQ@mail.gmail.com>
References: <CAP8Wkrx9v=Fo1=t7_PAF+u2RzKM51D4-XWwfPNbSytxfc7-XSQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AF6B19@inbomail.inbo.be>

Dear Barry,

You have to rethink the input format. This is easy if you use a matrix.

A <- cbind(A_01, A_02, A_03, A_04)
index <- cbind(seq_along(VFD_ID), VFD_ID)
A[index]

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Barry King
Verzonden: maandag 29 september 2014 11:59
Aan: r-help at r-project.org
Onderwerp: [R] How to get rid of my for loop

# Here are sample data, sample vectors, and a for loop # that I am using now. I wish to get rid of the for loop # and use functions and one of the apply functions to # perform the work without needing a many iteration for loop.
A_01 <- 1:5
A_02 <- 6:10
A_03 <- 11:15
A_04 <- 16:20

B_01 <- 101:105
B_02 <- 106:110
B_03 <- 111:115
B_04 <- 116:120

# I am showing just two pairs, A_x with A_array and B_x with B_array.
# In actuality there are about a dozen such pairings.
A_array <- array(NA, dim=5)
B_array <- array(NA, dim=5)

VFD_ID <- c(3, 2, NA, 1, 3)
nobs <- length(VFD_ID)

# This for loop works fine but is not appropriate for # a large number of observations in VFD_ID.
for (i in 1:nobs){
  if (is.na(VFD_ID[i])){
    A_array[i]<- 0
    B_array[i]<- 0
  } else if (VFD_ID[i] == 1){
    A_array[i]<-A_01[i]
    B_array[i]<-B_01[i]
  } else if (VFD_ID[i] == 2){
    A_array[i]<-A_02[i]
    B_array[i]<-B_02[i]
  } else if (VFD_ID[i] == 3){
    A_array[i]<-A_03[i]
    B_array[i]<-B_03[i]
  } else if (VFD_ID[i] == 4){
    A_array[i]<-A_04[i]
    B_array[i]<-B_04[i]
  }
}

# This does NOT work. It returns the entire vector, # not just the corresponding element in VFD_ID.
# (Note: It seems like a switch function would work here # but I was unable to get it to work correctly.) A_array_fnc <- function(x){
  if (is.na(x)) return (0) else
    if (x == 1) return (A_01) else
      if (x == 2) return (A_02) else
        if (x == 3) return (A_03) else
          if (x == 4) return (A_04)
}

B_array_fnc <- function(x){
  if (is.na(x)) return (0) else
    if (x == 1) return (B_01) else
      if (x == 2) return (B_02) else
        if (x == 3) return (B_03) else
          if (x == 4) return (B_04)
}

A_array <- sapply(VFD_ID,A_array_fnc)
B_array <- sapply(VFD_ID,B_array_fnc)

# Is there a way to write the functions correctly so that # the return value for, say A_array[4] is A_03[4] if VFD_ID == 3?
# Any assistance is greatly appreciated.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bannert at kof.ethz.ch  Mon Sep 29 12:26:30 2014
From: bannert at kof.ethz.ch (Bannert  Matthias)
Date: Mon, 29 Sep 2014 10:26:30 +0000
Subject: [R] Could someone recommend a package for time series?
In-Reply-To: <CABcx46AULJ8PnWendodtM-8mMdcQpV+Ei3gK78UWj3uEobMuJA@mail.gmail.com>
References: <CABcx46DsxQ+Nmr2_kKRQsedwmPJOctqHV+mrTpCppw-SH_pi+w@mail.gmail.com>
	<CAAcyNCxegmmw_1fbeeRNVjK68CTnnMYvRBeO1p_n0dArq5aAmA@mail.gmail.com>,
	<CABcx46AULJ8PnWendodtM-8mMdcQpV+Ei3gK78UWj3uEobMuJA@mail.gmail.com>
Message-ID: <8586FCA42D306C4DB0BD46EF9F1B580236E35E5B@MBX210.d.ethz.ch>

Hi, 

the Cran Task View about time series that pascal just send is certainly helpful. 
Personally I think the standard ts() already can do a lot for you. Apart from that I like zoo particularly if you have other than yearly frequencies like quarterly or even irregular frequencies to handle. 

This is a pretty nice applied course that uses R for illustration: https://stat.ethz.ch/education/semesters/ss2012/atsa

apart from this course, I think Prof. Rob Hyndman (who also has a blog) has a lot of useful stuff to say when it comes time series analysis with R

best

Matthias Bannert

KOF Swiss Economic Institute, Switzerland 

________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of jpm miao [miaojpm at gmail.com]
Sent: Monday, September 29, 2014 11:47 AM
To: Pascal Oettli
Cc: mailman, r-help
Subject: Re: [R] Could someone recommend a package for time series?

Thanks Pascal! It certainly helps!

2014-09-29 17:10 GMT+08:00 Pascal Oettli <kridox at ymail.com>:

> Hi Miao,
>
> You certainly will find useful answers here :
> http://cran.r-project.org/web/views/TimeSeries.html
>
> Regards,
> Pascal Oettli
>
> On Mon, Sep 29, 2014 at 6:05 PM, jpm miao <miaojpm at gmail.com> wrote:
> > Hi,
> >
> >    I've not used R for about one year and don't know well about the
> updates
> > on the time series-related package.
> >
> >   My primary job is to do economic/financial time series data analysis -
> > annual, monthly, daily, etc. I usually read data by the package
> > "XLConnect", which can read xls or xlsx files directly. It's excellent.
> > However I can't find a package to manipulate time series data. For
> example,
> > I just want to do an easy manipulation , e.g, to label the dates of the
> > data from , say, 1991M10 to 2014M07, and then extract part of the data,
> > say, 2005M01 to 2010M12 and do analysis. Is there any package work well
> for
> > my purpose?
> >
> >   I sometimes need to aggregate monthly data to quarterly data and I find
> > "aggregate" function helpful.
> >
> >   In the past I used packages xts, zoo and don't find it really user
> > friendly. Maybe I haven't mastered it; maybe there're some updates
> (which I
> > don't know) now. Could someone recommend a package or provide an example
> > (or just the document, I can read it) for my purpose?
> >
> >    Attached is an exemplary data set I talked about.
> >
> >    Thanks,
> >
> > Miao
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jayuan2008 at yahoo.com  Mon Sep 29 12:11:15 2014
From: jayuan2008 at yahoo.com (Yuan Jian)
Date: Mon, 29 Sep 2014 03:11:15 -0700
Subject: [R] residuals of glm
Message-ID: <1411985475.94778.YahooMailNeo@web160405.mail.bf1.yahoo.com>

Hello,
I found the residuals of glm is not the same as calculated manually.
 >y=c(12,14,33,50,67,74,123,141,165,204,253,246,240)
> t=1:13
> m1=glm(y~t+I(t^2),family=poisson(link="log"))
> coefficients(m1)[1]+coefficients(m1)[2]*log(t)+coefficients(m1)[3]*log(t^2)
 [1] 1.901459 2.257258 2.465388 2.613058 2.727600 2.821188 2.900315 2.968858
 [9] 3.029318 3.083400 3.132324 3.176988 3.218075
> log(y)-m1$residuals
       1        2        3        4        5        6        7        8 
2.434906 2.890062 3.369962 3.775366 4.146170 4.456127 4.745377 4.982733 
       9       10       11       12       13 
5.174013 5.326826 5.429551 5.499618 5.521138 


i hope the last two sentences have the same result. could anyone help me out?
thanks
Jay

	[[alternative HTML version deleted]]


From teamtraders3564 at gmail.com  Mon Sep 29 03:57:41 2014
From: teamtraders3564 at gmail.com (Jason Eyerly)
Date: Sun, 28 Sep 2014 18:57:41 -0700
Subject: [R] Plotting Categorical/Numerical Data?
In-Reply-To: <CACk-te0d=dKN8AV2Vh5=kx3gCJoxvoCUg5ipS0iooh+Q87m7dQ@mail.gmail.com>
References: <CAC=Mo5ezsp+YAqBYx4_N7SGFcpBDTYts0t_zL8mAVoMOo4y1gA@mail.gmail.com>
	<CACk-te0d=dKN8AV2Vh5=kx3gCJoxvoCUg5ipS0iooh+Q87m7dQ@mail.gmail.com>
Message-ID: <CAHhBSjrOu2j3CUcNa2Jgv=pzOcXLeGW0Q7WpFS5iqNnqdhV4sg@mail.gmail.com>

1. Okay?

2. It was also said to be unlikely that the Wright brothers would take
flight, or that the earth orbited the moon.

3. One step ahead.

-Jason
On Sep 28, 2014 6:53 PM, "Bert Gunter" <gunter.berton at gene.com> wrote:

> 1. Homework? We don't do homework here.
>
> 2. I believe what you purport to do is unlikely answer the "is it
> random" question. Or, more exactly, may very well give an incorrect
> answer.
>
> To learn what you should do:
>
> 3. Post to a statistics (or math) site like stats.stackexchange.com.
> You gave no details, but it may well be complex.
>
> 4. Or consult someone locally with knowledge of probability and statistics.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Sep 28, 2014 at 12:26 PM, Jason Eyerly <ccfdexplorer at gmail.com>
> wrote:
> > Hello Everyone,
> >     I've created a sample of poker hands being dealt. How can I plot the
> > data visually in R/R-Studio where x=(Card1,Card2) and Y = Frequency Of
> > Occurence? I'm trying to visualize a simulation, to compare to an actual
> > dataset, to determine if the hands being dealt in the "actual" computer
> > game are fair and in fact "random".
> >
> > For example:
> >
> >     5
> >     4
> >     3
> >     2
> >     1
> >       QS AH, 1S 2C, 5H KH....
> >
> > Thanks In Advance,
> >     Jason E.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Sep 29 14:18:59 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 29 Sep 2014 12:18:59 +0000
Subject: [R] if else statement in loop
In-Reply-To: <CAE6QMsZtHJZR2BgjEp5=ZaOOrai_OfhchuZJmMwocFG7TuUdSQ@mail.gmail.com>
References: <CAE6QMsaYDHMsN29HKqrN1WuSt-J0a7u=aFr8TOvBQkDKeAEe1g@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8334@SRVEXCHMBX.precheza.cz>
	<CAE6QMsZtHJZR2BgjEp5=ZaOOrai_OfhchuZJmMwocFG7TuUdSQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE84EE@SRVEXCHMBX.precheza.cz>

Hi

Still cloudy, still errors.

> for(i in length(1:(nrow(X)))){
+     Y$IID1new <- ifelse((as.character(Y[,2]) == as.character(X[,i]) &
+ Y$IID1new != ''), as.character(as.matrix(X[,(nrow(X)+i)])),'')
+ }
Error in `$<-.data.frame`(`*tmp*`, "IID1new", value = logical(0)) :
  replacement has 0 rows, data has 3

You need first to add column IID1new to your Y data frame to use this piece of code. After that no errors from the code

However I wonder why the result shall be like this? What is the logic behind this.

>
> FID IID IID1new
> FAM01 samas4 samas4_father
> FAM01 samas5 samas5_mother
> FAM01 samas6 samas6_sibling

The only pattern I can see is that in first row (Y) you want item from column V4 (X), in second from V5 and in third you wan item from column V6. Is it always true? Or the pattern can change in following rows.

Based on your explanation you want to fill a column in Y from some column of X based on rownumber of Z?

For your special case it is like this.

Y$IID1new<-diag(as.matrix(X[,4:6]))

Anyway, it seems to me that you want some kind of

?merge

Regards
Petr

Here are data I use for your code.

> dput(X)
structure(list(V1 = structure(c(1L, 1L, 1L), .Label = "samas4", class = "factor"),
    V2 = structure(c(1L, 1L, 1L), .Label = "samas5", class = "factor"),
    V3 = structure(c(1L, 1L, 1L), .Label = "samas6", class = "factor"),
    V4 = structure(c(1L, 1L, 1L), .Label = "samas4_father", class = "factor"),
    V5 = structure(c(1L, 1L, 1L), .Label = "samas5_mother", class = "factor"),
    V6 = structure(c(1L, 1L, 1L), .Label = "samas6_sibling", class = "factor")), .Names = c("V1",
"V2", "V3", "V4", "V5", "V6"), class = "data.frame", row.names = c(NA,
-3L))
> dput(Y)
structure(list(FID = structure(c(1L, 1L, 1L), .Label = "FAM01", class = "factor"),
    IID = structure(1:3, .Label = c("samas4", "samas5", "samas6"
    ), class = "factor")), .Names = c("FID", "IID"), class = "data.frame", row.names = c(NA,
-3L))



> -----Original Message-----
> From: Kate Ignatius [mailto:kate.ignatius at gmail.com]
> Sent: Monday, September 29, 2014 12:54 PM
> To: PIKAL Petr
> Cc: r-help
> Subject: Re: [R] if else statement in loop
>
> Ooops,
>
> I edited the code wrong to make it more easier for interpretation and
> got X and Y's mixed up.  Try this:
>
> for(i in length(1:(nrow(X)))){
>     Y$IID1new <- ifelse((as.character(Y[,2]) == as.character(X[,i]) &
> Y$IID1new != ''), as.character(as.matrix(X[,(nrow(X)+i)])),'')
> }
>
> The second should be like this:
>
> Y$IID1new <- ifelse((as.character(Y[,2]) == as.character(X[,1])),
> as.character(as.matrix(X[,(nrow(X)+1)])),'')
>
> for(i in length(2:(nrow(X)))){
> ifelse((as.character(Y[,i]) == as.character(X[,i])),
> Y$IID1new[is.na(Y$IID1new)] <-
> as.character(as.matrix(X[,(nrow(X)+i)])),'')
> }
>
> The reason why I'm selecting for number of rows seems a little odd
> here I know but in real life this actually relies on a third data
> frame, say Z, which for simplicity I didn't include here. But I only
> want to start looking at the Nth column after twice as many rows in Z.
> For instance, if Z has 4 rows, I want to  take values for IID1new
> starting from column 9 in X to make IID1new in Y. Does that make
> sense? Will this cause a problem?
>
> So maybe it will probably be more like this if there were a Z
>
> for(i in length(1:(2*nrow(Z)))){
>     Y$IID1new <- ifelse((as.character(Y[,2]) == as.character(X[,i]) &
> Y$IID1new != ''), as.character(as.matrix(X[,(2*nrow(Z)+i)])),'')
> }
>
> But essentially what I would like is this:
>
> FID IID IID1new
> FAM01 samas4 samas4_father
> FAM01 samas5 samas5_mother
> FAM01 samas6 samas6_sibling
>
> I hope this is a little clearer...
>
> Let me know if there are more errors.
>
> K.
>
> On Mon, Sep 29, 2014 at 2:39 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Hi
> >
> > Please, be more clear in what do you want. I get many errors trying
> your code and your explanation does not help much.
> >
> >> for(i in length(1:(2*nrow(X)))){
> > +     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i])
> & X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
> > Error: unexpected ',' in:
> > "for(i in length(1:(2*nrow(X)))){
> >     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
> X$IID1new != '') ,"
> >> }
> > Error: unexpected '}' in "}"
> >> for(i in length(1:(2*nrow(X)))){
> > +     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i])
> &
> > + X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
> > Error: unexpected ',' in:
> > "    Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i])
> &
> > X$IID1new != '') ,"
> >> }
> >
> >
> > Beside, this column X$IID1new != '' does not exist in X
> >
> > Here you clearly ask for nonexistent column, and why the heck you
> want to select column by number of rows?
> >
> >> as.character(as.matrix(X[,(2*nrow(X)+1)]))
> > Error in `[.data.frame`(X, , (2 * nrow(X) + 1)) :
> >   undefined columns selected
> >
> > So based on your toy data frames, what shall be the result after your
> computation.
> >
> > Regards
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Kate Ignatius
> >> Sent: Sunday, September 28, 2014 9:14 PM
> >> To: r-help
> >> Subject: [R] if else statement in loop
> >>
> >> I have two data frames
> >>
> >> For simplicity:
> >>
> >> X=
> >>
> >> V1 V2 V3  V4 V5 V6
> >> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
> >> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
> >> samas4 samas5 samas6 samas4_father samas5_mother samas6_sibling
> >>
> >> Y=
> >>
> >> FID IID
> >> FAM01 samas4
> >> FAM01 samas5
> >> FAM01 samas6
> >>
> >> I want to set to create a new IID in Y using V4 V5 V6 in X using an
> >> ifelse statement in a loop.  I've used something like the following
> >> (after figuring out my factor problem):
> >>
> >> for(i in length(1:(2*nrow(X)))){
> >>     Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i])
> &
> >> X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
> >> }
> >>
> >> But of course this tends to overwrite.
> >>
> >> Is there an easy way to set up a loop to replace missing values?
> This
> >> didn't work either but not sure if its as easy as this:
> >>
> >> Y$IID1new <- ifelse((as.character(Y[,2]) == as.characterXl[,i]) &
> >> X$IID1new != '') , as.character(as.matrix(X[,(2*nrow(X)+i)])),'')
> >>
> >> for(i in length(2:(2*nrow(X)))){
> >> ifelse((as.character(Y[,i]) == as.character(Xl[,i])),
> >> X[is.na(X$IID1new)] <- as.character(as.matrix(X[(2*nrow(X)+i)])),'')
> >> }
> >>
> >> Thanks!
> >>
> >> K.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering
> into a contract in any time, for any reason, and without stating any
> reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> > - the sender insists on that the respective contract is concluded
> only upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ggrothendieck at gmail.com  Mon Sep 29 15:00:17 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 29 Sep 2014 09:00:17 -0400
Subject: [R] Could someone recommend a package for time series?
In-Reply-To: <CABcx46DsxQ+Nmr2_kKRQsedwmPJOctqHV+mrTpCppw-SH_pi+w@mail.gmail.com>
References: <CABcx46DsxQ+Nmr2_kKRQsedwmPJOctqHV+mrTpCppw-SH_pi+w@mail.gmail.com>
Message-ID: <CAP01uRmBSy9nDHQ8-iKpzTyfjSTGA_27bkwqpteGwkRjPC0n8g@mail.gmail.com>

On Mon, Sep 29, 2014 at 5:05 AM, jpm miao <miaojpm at gmail.com> wrote:
> Hi,
>
>    I've not used R for about one year and don't know well about the updates
> on the time series-related package.
>
>   My primary job is to do economic/financial time series data analysis -
> annual, monthly, daily, etc. I usually read data by the package
> "XLConnect", which can read xls or xlsx files directly. It's excellent.
> However I can't find a package to manipulate time series data. For example,
> I just want to do an easy manipulation , e.g, to label the dates of the
> data from , say, 1991M10 to 2014M07, and then extract part of the data,
> say, 2005M01 to 2010M12 and do analysis. Is there any package work well for
> my purpose?
>
>   I sometimes need to aggregate monthly data to quarterly data and I find
> "aggregate" function helpful.
>
>   In the past I used packages xts, zoo and don't find it really user
> friendly. Maybe I haven't mastered it; maybe there're some updates (which I
> don't know) now. Could someone recommend a package or provide an example
> (or just the document, I can read it) for my purpose?
>

The built in "ts" class works well with regularly spaced monthly and
quarterly data but is less suitable for daily data since it cannot
represent exact dates.

What you have described is very easy to do with zoo and/or xts.

If you are familiar with the core functions of R then zoo is pretty
easy to use since nearly all its functions are methods of core
generics allowing you to leverage your knowledge of R.   See:
  vignette("zoo-design")
for the design principles used and all 5 vignettes:
  vignette(package = "zoo")..

xts (which works with zoo) could also be of interest as well as 139
other packages that work with zoo and/or xts which means that in many
cases whatever functionality you need already exists.  See the bottom
of each of these pages for links to the other packages:
http://cran.r-project.org/package=zoo
http://cran.r-project.org/package=xts

Regarding your problem, zoo does have built in yearmon and yearqtr
classes for monthly and quarterly data.  Here is an example which
creates some daily test data, aggregates to monthly, extracts a subset
and displays the first few data points.  Then it aggregates to
quarterly and displays the first few data points   At the end it plots
the data using zoo's classic graphics plot.zoo method. ( zoo also has
direct support for ggplot2 (autoplot.zoo) and lattice graphics
(xyplot.zoo).)

library(zoo)

# create test data, z
tt <- seq(as.Date("2000-10-01"), as.Date("2013-12-31"), by = "day")
z <- zoo(seq_along(tt), tt)

# aggregate to monthly series and change time scale to year/month
zm <- aggregate(z, as.yearmon, mean)

# extract part of it
zm0 <- window(zm, start = "2005-01", end = "2010-12")

head(zm0)
## Jan 2005 Feb 2005 Mar 2005 Apr 2005 May 2005 Jun 2005
##  1569.0   1598.5   1628.0   1658.5   1689.0   1719.5

# aggregate to quarterly
zq <- aggregate(zm0, as.yearqtr, mean)

head(zq)
## 2005 Q1  2005 Q2  2005 Q3  2005 Q4  2006 Q1  2006 Q2
## 1598.500 1689.000 1780.833 1872.500 1963.500 2054.000

plot(zq)


From jvadams at usgs.gov  Mon Sep 29 15:22:39 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 29 Sep 2014 08:22:39 -0500
Subject: [R] error in rownames
In-Reply-To: <CAPtX2qkXCOfxrR2GdGKxVGi9ythq0-hCrWWQE1oNJesmTrPxXw@mail.gmail.com>
References: <CAPtX2q=siOx6FQT9s3mNbcGcppMNv4OjmAnU7btT48u6WYppWw@mail.gmail.com>
	<CAN5YmCEZPPRqucCTchb_8+v+_as-MCzJj4dd_Sn=URcSYwcbKA@mail.gmail.com>
	<CAPtX2qkXCOfxrR2GdGKxVGi9ythq0-hCrWWQE1oNJesmTrPxXw@mail.gmail.com>
Message-ID: <CAN5YmCFQ2cQp=X3EsXKjmW+ftUujeGR9xdDSF6EbO9xHXqcteg@mail.gmail.com>

Chris,

I think your best bet is to find someone locally that is familiar with R,
and show them this correspondence.  They will be able to help you post your
question so that you have the best chance of getting an answer.  Or,
perhaps, they will be able to answer the question themselves.

Jean

On Thu, Sep 25, 2014 at 10:51 AM, Chris Jackson-Jordan <
jacksonjordancm at gmail.com> wrote:

> Thanks again for your help, I am obviously a novice programmer. That said,
> I think I am confused as to what you mean by reproducible code. Were the 20
> lines of code not reproducible? Also, what do you mean by the help for
> Ascii Grid Impute. I'm not able to find it online or within the R platform.
> Finally, I know that mapping to files on my PC is problematic, should I be
> attaching the files in my email? Like I said, this is all quite new to me.
> Sorry if my questions are painfully naive. I am hoping to get this project
> going but just can't get past this stumbling block. Thanks again for the
> help thus far.
>
> Chris
>
> On Thu, Sep 25, 2014 at 11:06 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>
>> Chris,
>>
>> You are not making it easy for R help folks to help you.
>>
>> You need to supply *** reproducible *** code, so that folks can simply
>> copy and paste directly from your e-mail to R and reproduce the error that
>> you are getting.  Do you need a guide to follow?  See the first 60-some
>> lines of code provided in the example of the help for AsciiGridImpute,
>>      ?AsciiGridImpute
>> I can copy that code into R and make it run.  You need to do the same
>> thing in your e-mail.  Don't refer to directories on your PC.
>>
>> I submitted a simplified version of the code you shared (below), but ran
>> into an error because the *.asc files were not already created.  So, I
>> suggest that you insert some general code to get that done for your
>> example, and resubmit your question.
>>
>> Jean
>>
>>
>> training <- structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
>> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
>> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
>> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
>> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
>> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
>> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
>> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
>> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
>> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
>> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
>> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
>> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
>> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
>> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect = c(0.915474,
>> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
>> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
>> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
>> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
>> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
>> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
>> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
>> 516073.554503, 516019.068701, 515506.165434, 517353.141738, 520076.487742,
>> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
>> 515714.490202, 518829.909017, 519385.491579, 518659.851297, 516654.780318,
>> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
>> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912, 4818923.42436,
>> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
>> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774, 4814503.57051,
>> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
>> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
>> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
>> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
>> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
>> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
>> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")
>>
>> library(yaImpute)
>>
>> y <- subset(training, select = c(ResponseSu))
>> x <- subset(training, select = c(sinaspect, habitat, elevation,
>> disttowat, disttoroad, slope, cosaspect))
>> type.rf <- yai(x=x, y=y, method="randomForest", rfMode="regression",
>> ntree=20)
>> outfile <- list(Type="RespSurf_Reg.asc")
>> xfile <-list(sinaspect="sinaspect.asc", habitat="habitat.asc",
>> elevation="elevation.asc",
>> disttowat="disttowat.asc", disttoroad="disttoroad.asc",
>> slope="slope.asc",
>> cosaspect="cosaspect.asc")
>>
>> # insert lines of code here to create the *.asc files
>> # see the example with the iris data in ?AsciiGridImpute
>>
>> AsciiGridImpute(type.rf, xfile, outfile)
>>
>>
>> On Mon, Sep 22, 2014 at 11:13 AM, Chris Jackson-Jordan <
>> jacksonjordancm at gmail.com> wrote:
>>
>>> Dear fellow R users,
>>>
>>> I am trying to run the random forest and Yaimpute packages in R to
>>> impute a grid to project in a gis. However, after running the
>>> imputation I keep getting an error in the rownames. This sounds simple
>>> enough, but I cannot figure out what these rownames are reffering to.
>>> Any ideas? I am fairly new to R so im sure it is an easy fix. Any help
>>> would be awesome.
>>>
>>> Thanks,
>>>
>>> Chris
>>>
>>>
>>> > y <- subset(training, select = c(ResponseSu)) > x <- subset(training,
>>> select = c(sinaspect, habitat, slope, elevation, cosaspect, disttoroad,
>>> disttowat)) > type.rf <- yai(x=x, y=y, method="randomForest",
>>> rfMode="regression", ntree= 2000) > outfile <- list(Type =
>>> "D:/R_Desktop_Data/RF_RespSurf/RespSurf_Reg.asc") > xfile
>>> <-list(sinaspect
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/sinaspect.asc",
>>> habitat
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/habitat.asc",
>>> elevation
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/elevation.asc",
>>> disttowat
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttowat.asc",
>>> disttoroad
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/disttoroad.asc",
>>> slope
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/slope.asc",
>>> cosaspect
>>>
>>> ="C:/Users/jacksonjordancm/Desktop/R_Desktop_Data/RF_NNimp/ModelI/ASCII_Files2/cosaspect.asc")
>>> > AsciiGridImpute(type.rf, xfile, outfile) Rows per dot: 19 Rows to do:
>>> 1900 ToDo:
>>>
>>> ....................................................................................................
>>> Done: . Error in `rownames<-`(`*tmp*`, value = c("23x0049", "23x0050",
>>> "23x0051", : attempt to set rownames on object with no dimensions
>>>
>>> here is an example of my training data
>>>
>>>
>>>  > dput(training[1:20, ])structure(list(CID = c(0L, 0L, 0L, 0L, 0L,
>>>
>>> 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), cosaspect = c(-0.402376,
>>> -0.263312, -0.978401, 0.0364174, 0.975655, -0.954148, -0.982731,
>>> 0.949282, -0.827262, -0.300375, -0.211474, -0.63658, 0.892831,
>>> -0.0395686, 0.649339, 0.0129927, -0.428111, -0.970759, 0.891974,
>>> -0.901187), disttoroad = c(475.928, 245.003, 671.958, 10.3074,
>>> 384.839, 180.305, 620.157, 290.441, 587.61, 72.1515, 10.3074,
>>> 43.7304, 20.6147, 10.3074, 428.717, 72.884, 106.121, 175.225,
>>> 249.302, 30.9221), disttowat = c(535.685, 309.907, 291.536, 1039.97,
>>> 258.507, 202.508, 387.315, 1233.18, 666.481, 457.721, 1553.81,
>>> 679.505, 1115.53, 515.162, 692.974, 498.604, 204.075, 388.138,
>>> 885.474, 343.097), elevation = c(1901.69, 1992.82, 1911.9, 1985.14,
>>> 1979.67, 1870.83, 1909.5, 2111.45, 1913.09, 1922.76, 1996.68,
>>> 2092.64, 2066.89, 1872.85, 2047.7, 1923.03, 1981.28, 1875.6,
>>> 2074.82, 1866.82), habitat = c(2L, 5L, 2L, 10L, 1L, 2L, 2L, 3L,
>>> 2L, 16L, 3L, 3L, 1L, 4L, 1L, 5L, 6L, 2L, 3L, 10L), sinaspect =
>>> c(0.915474,
>>> -0.964711, 0.206717, 0.999337, 0.21931, -0.299336, -0.185039,
>>> -0.314428, -0.561817, -0.953821, -0.977384, -0.771211, -0.450392,
>>> -0.999217, -0.760499, 0.999916, 0.903726, -0.240057, -0.452087,
>>> -0.433431), slope = c(0.768307, 11.4002, 1.34928, 3.42667, 19.6776,
>>> 0.341443, 3.14869, 7.14637, 1.1572, 24.4974, 11.0014, 19.4188,
>>> 16.3333, 5.23936, 9.95699, 17.1475, 21.374, 0.475218, 7.23375,
>>> 0.29158), POINT_X = c(517098.970249, 517940.940865, 517526.253849,
>>> 516073.554503, 516019.068701, 515506.165434, 517353.141738,
>>> 520076.487742,
>>> 517973.141394, 516823.388106, 514784.035218, 518298.237046, 519796.43389,
>>> 515714.490202, 518829.909017, 519385.491579, 518659.851297,
>>> 516654.780318,
>>> 519063.701155, 516270.975247), POINT_Y = c(4818385.61487, 4816762.97919,
>>> 4819015.00611, 4816604.93198, 4814958.09214, 4813316.65912,
>>> 4818923.42436,
>>> 4819217.24161, 4820124.20539, 4814172.9439, 4815372.65581, 4816674.91138,
>>> 4819393.11718, 4812616.30708, 4818780.85554, 4816287.01774,
>>> 4814503.57051,
>>> 4813614.51134, 4818804.92703, 4812168.6041), ResponseSu = c(1.822784,
>>> 398.591262, 5.565648, 69.106734, 235.114325, 2.162961, 8.170528,
>>> 389.107013, 11.32454, 4880.467707, 192.215083, 160.17186, 91.843573,
>>> 63.863233, 113.728819, 100.03871, 1288.273717, 14.032336, 141.478417,
>>> 10.020201)), .Names = c("CID", "cosaspect", "disttoroad", "disttowat",
>>> "elevation", "habitat", "sinaspect", "slope", "POINT_X", "POINT_Y",
>>> "ResponseSu"), row.names = c(NA, 20L), class = "data.frame")>
>>> library("randomForest", lib.loc="~/RStudio/R/library")
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From markleeds2 at gmail.com  Mon Sep 29 17:59:51 2014
From: markleeds2 at gmail.com (Mark Leeds)
Date: Mon, 29 Sep 2014 11:59:51 -0400
Subject: [R] hadley's book
Message-ID: <CAHz+bWYO7aVQRuQ3G-s1NGidjLR_Ff337Ou2i0-jxKC-4xnBbA@mail.gmail.com>

Just a heads up to list: I don't know about other book sites but,  on U.S
Amazon, Hadley's Advanced R book is no longer in pre-order mode. You can
purchase the book now without pre-ordering it.

                                                                   Mark

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Mon Sep 29 18:13:51 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 29 Sep 2014 11:13:51 -0500
Subject: [R] hadley's book
In-Reply-To: <CAHz+bWYO7aVQRuQ3G-s1NGidjLR_Ff337Ou2i0-jxKC-4xnBbA@mail.gmail.com>
References: <CAHz+bWYO7aVQRuQ3G-s1NGidjLR_Ff337Ou2i0-jxKC-4xnBbA@mail.gmail.com>
Message-ID: <CAAJSdjhgo9fZ9tpVt36SExc2wj_UzAS5JJJWE1QwLDHYeE3gHw@mail.gmail.com>

Thanks for the heads up. I just ordered it. Curiously, I can't read it
using the "Cloud Reader" in my browser, so I'll wait until I get home
to look at it on my Nexus 10.

On Mon, Sep 29, 2014 at 10:59 AM, Mark Leeds <markleeds2 at gmail.com> wrote:
> Just a heads up to list: I don't know about other book sites but,  on U.S
> Amazon, Hadley's Advanced R book is no longer in pre-order mode. You can
> purchase the book now without pre-ordering it.
>
>                                                                    Mark
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From radhakrishnan.mohan at gmail.com  Mon Sep 29 18:23:03 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Mon, 29 Sep 2014 21:53:03 +0530
Subject: [R] hadley's book
In-Reply-To: <CAAJSdjhgo9fZ9tpVt36SExc2wj_UzAS5JJJWE1QwLDHYeE3gHw@mail.gmail.com>
References: <CAHz+bWYO7aVQRuQ3G-s1NGidjLR_Ff337Ou2i0-jxKC-4xnBbA@mail.gmail.com>
	<CAAJSdjhgo9fZ9tpVt36SExc2wj_UzAS5JJJWE1QwLDHYeE3gHw@mail.gmail.com>
Message-ID: <CAOoXFP8pGqMniCB4OvwGEhyx9_-fwEZHzx7JHkZM3vD5yjDYRQ@mail.gmail.com>

Does this shed some light on advanced R that ML tools h2o use ? MapR could
also be using distributed R.

Thanks,
Mohan

On Mon, Sep 29, 2014 at 9:43 PM, John McKown <john.archie.mckown at gmail.com>
wrote:

> Thanks for the heads up. I just ordered it. Curiously, I can't read it
> using the "Cloud Reader" in my browser, so I'll wait until I get home
> to look at it on my Nexus 10.
>
> On Mon, Sep 29, 2014 at 10:59 AM, Mark Leeds <markleeds2 at gmail.com> wrote:
> > Just a heads up to list: I don't know about other book sites but,  on U.S
> > Amazon, Hadley's Advanced R book is no longer in pre-order mode. You can
> > purchase the book now without pre-ordering it.
> >
> >                                                                    Mark
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From martina.ozan at helsinki.fi  Mon Sep 29 15:17:19 2014
From: martina.ozan at helsinki.fi (Martina Ozan)
Date: Mon, 29 Sep 2014 16:17:19 +0300
Subject: [R] Univariate results from MANOVA with Adonis?
Message-ID: <20140929161719.Horde.L0BQbGLjYNYuhZ4EtCRgBg1@webmail.helsinki.fi>

Hi,

I am using function Adonis in Vegan to do MANOVA. My response variable  
is a chemical profile of an insect composed of different chemical  
compounds (=my data columns). My predictors include factors as well as  
continuous variables. My question is: Is it possible to get out from  
adonis, in addition the multivariate result, also univariate results  
per chemical compounds versus each predictor? I would like to be able  
to pick out individual chemical compounds that are of interest from  
the rest (=those significantly associated/correlated with predictors).

thanks in advance
Martina


-- 
Martina Ozan, PhD researcher
Centre of Excellence in Biological Interactions
Department of Biosciences
PL 65 (Viikinkaari, 1)
FI-00014 Helsinki University
e-mail: martina.ozan (at) helsinki.fi
http://www.helsinki.fi/science/ants


From rshepard at appl-ecosys.com  Mon Sep 29 19:53:15 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 29 Sep 2014 10:53:15 -0700 (PDT)
Subject: [R] Package 'compositions', function acomp() With Missing Data
Message-ID: <alpine.LNX.2.11.1409291049420.13132@localhost>

   The acomp() function works well on data sets with no missing data. For
example:

win.acomp <- acomp(win.cast, parts=2:6)
> win.acomp
      Filterer   Gatherer  Grazer     Predator  Shredder 
[1,] 0.06670000 0.6000000 0.06670000 0.2444000 0.02220000
[2,] 0.06120612 0.5714571 0.06120612 0.2653265 0.04080408
[3,] 0.04350000 0.6232000 0.10140000 0.2174000 0.01450000
[4,] 0.04400000 0.5934000 0.06590000 0.2637000 0.03300000
[5,] 0.05000000 0.4333000 0.06670000 0.3667000 0.08330000
[6,] 0.01610000 0.6290000 0.03230000 0.2903000 0.03230000
attr(,"class")
[1] acomp

   When the data set has one missing value, acomp() produces output but
changes the missing value from MAR (Missing At Random) to MNAR (Missing Not
At Random) when the missing variable is in quotes ...

> burns.cast
     sampdate Filterer Gatherer Grazer Predator Shredder
1 2000-07-18   0.0550   0.5596 0.0734   0.2294   0.0826
2 2003-07-08   0.0734   0.6147 0.0183   0.2294   0.0642
3 2005-07-13   0.1161   0.5714 0.0357   0.1696   0.1071
4 2006-06-28   0.1000   0.4667 0.1500   0.1333   0.1500
5 2010-09-14   0.0778   0.6111 0.0444   0.1889   0.0778
6 2011-07-13   0.0879   0.5714 0.0659   0.2747       NA
7 2012-07-11   0.1042   0.5313 0.0625   0.2396   0.0625
8 2013-07-11   0.0723   0.5542 0.0602   0.2651   0.0482

> burns.acomp <- acomp(burns.cast, parts=2:6, MAR='NA')
> burns.acomp
      Filterer   Gatherer  Grazer     Predator  Shredder 
[1,] 0.05500000 0.5596000 0.07340000 0.2294000 0.08260000
[2,] 0.07340000 0.6147000 0.01830000 0.2294000 0.06420000
[3,] 0.11611161 0.5714571 0.03570357 0.1696170 0.10711071
[4,] 0.10000000 0.4667000 0.15000000 0.1333000 0.15000000
[5,] 0.07780000 0.6111000 0.04440000 0.1889000 0.07780000
[6,] 0.08790879 0.5714571 0.06590659 0.2747275       MNAR
[7,] 0.10418958 0.5312469 0.06249375 0.2395760 0.06249375
[8,] 0.07230000 0.5542000 0.06020000 0.2651000 0.04820000
attr(,"class")
[1] acomp

... or BDL (Below Detection Limits) when the missing variable is without
quotes:

burns.acomp <- acomp(burns.cast, parts=2:6, MAR=NA)
> burns.acomp
      Filterer   Gatherer  Grazer     Predator  Shredder 
[1,] 0.05500000 0.5596000 0.07340000 0.2294000 0.08260000
[2,] 0.07340000 0.6147000 0.01830000 0.2294000 0.06420000
[3,] 0.11611161 0.5714571 0.03570357 0.1696170 0.10711071
[4,] 0.10000000 0.4667000 0.15000000 0.1333000 0.15000000
[5,] 0.07780000 0.6111000 0.04440000 0.1889000 0.07780000
[6,] 0.08790879 0.5714571 0.06590659 0.2747275        BDL
[7,] 0.10418958 0.5312469 0.06249375 0.2395760 0.06249375
[8,] 0.07230000 0.5542000 0.06020000 0.2651000 0.04820000
attr(,"class")
[1] acomp

   The dput() output for burns.cast is attached.

   How should the acomp() command be formated when there are values missing
at random?

Rich
-------------- next part --------------
structure(list(sampdate = structure(c(11156, 12241, 12977, 13327, 
14866, 15168, 15532, 15897), class = "Date"), Filterer = c(0.055, 
0.0734, 0.1161, 0.1, 0.0778, 0.0879, 0.1042, 0.0723), Gatherer = c(0.5596, 
0.6147, 0.5714, 0.4667, 0.6111, 0.5714, 0.5313, 0.5542), Grazer = c(0.0734, 
0.0183, 0.0357, 0.15, 0.0444, 0.0659, 0.0625, 0.0602), Predator = c(0.2294, 
0.2294, 0.1696, 0.1333, 0.1889, 0.2747, 0.2396, 0.2651), Shredder = c(0.0826, 
0.0642, 0.1071, 0.15, 0.0778, NA, 0.0625, 0.0482)), .Names = c("sampdate", 
"Filterer", "Gatherer", "Grazer", "Predator", "Shredder"), row.names = c(NA, 
-8L), class = "data.frame")

From f_j_rod at hotmail.com  Mon Sep 29 21:17:12 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Mon, 29 Sep 2014 21:17:12 +0200
Subject: [R] Loop does not work: Error in else statement
Message-ID: <BAY168-W1276E960BB649734656151FBABA0@phx.gbl>

Hi to all members of R list,

 

I?m working with data.table package, and with 6
variables: "ID" (Identifier), "born" (Birthdate), "start" (Starting date), "register" (date of measurement), "value"and "end" (date of expiration). So, the natural order of dates would be: born
=< start =< register =< end.  As an example, I have: DT <- data.table(ID = as.factor(rep(1:4,each=2)), 

     born =
as.Date(rep(c("1955-02-20", "1990-07-25",
"1972-03-18", "1988-05-03"),each=2)),

     start =
as.Date(rep(c("1953-03-28", "1990-07-01",
"1983-09-05", "1988-07-18"),each=2)),

     register =
as.Date(c("1955-08-11", "1958-03-28",
"1990-07-09", "1992-07-01", 

                "1983-09-05",
"2002-09-28", "1992-07-10", "1993-03-12")),

     value =
c(205, 346, 34, 76, 320, 148, 209, 274),

     end =
as.Date(rep(c("1960-11-05", "1997-10-15",
"2002-09-27", "1997-03-02"),each=2)))



I would want to make 3 operations:1. First: Remove
entire ID?s where "start" is previous to "born" date (excepting those subjects whose
month and year values are the same in "start" and "born" variables: I assign "born"
date to "start" date in these cases).Afterwords:2. Remove only
specific rows (not all ID) where ?register? is previous to ?start?.3.Remove only
specific rows (not all ID) where ?end? is previous to ?register?.

I have: DT[ , {    if (all(born > start))       {     indx <- which(paste(year(born)) == paste(year(start)) &  paste(month(born)) == paste(month(start)))      result <- list(born=born[indx], start=born[indx], register=register[indx], value=value[indx], end=end[indx])      }        if (all(register > start) | all(end > register))         {         indx <- which((register > start) | (end > register))         result <- list(born=born[indx], start=start[indx], register=register[indx], value=value[indx], end=end[indx])          }      else         {         NULL         }   else     {     indx <- which(all(register > start) | all(end > register))     result <- list(born=born[indx], start=start[indx], register=register[indx], value=value[indx], end=end[indx])      }   result   }, by=ID] BUT I GET AN ERROR MESSAGE: Error: syntax error, unexpected ELSE in "else"  Please, can anyone help me? Thank you!!  

 		 	   		  
	[[alternative HTML version deleted]]


From s.ouellette1 at gmail.com  Mon Sep 29 19:42:56 2014
From: s.ouellette1 at gmail.com (Simon Ouellette)
Date: Mon, 29 Sep 2014 13:42:56 -0400
Subject: [R] Chen.Deo test
Message-ID: <CAAKgVLrttZzUU4tXe=0VydX8Ju8VgV_C=Db8ByaNWuOSO4K50A@mail.gmail.com>

I made artificial random walk signals in a spreadsheet, and ran them
through the Chen.Deo (vrtest package) test in R.

When the "k vector" contains only, say, 2-3 values, I get the correct VR
sum = approximately 1. However, when I add one or two more k values,
suddenly the VR sum goes up to around 1.6. Eventually, if I add all k
values from 2 to 10 inclusively, I end up with a VR sum around 3.45.

I don't understand why having more k values to check affects the result of
the VR sum. Is that a normal behavior of the Chen Deo test?

Thanks

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Mon Sep 29 21:36:53 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 29 Sep 2014 21:36:53 +0200
Subject: [R] Loop does not work: Error in else statement
In-Reply-To: <BAY168-W1276E960BB649734656151FBABA0@phx.gbl>
References: <BAY168-W1276E960BB649734656151FBABA0@phx.gbl>
Message-ID: <922DDFC0-949B-463B-91B2-7F5B70465E19@xs4all.nl>


Please, please do not post in HTML as the Posting guide requests. See the tail of each message to R-help.
Your code is completely messed up and unreadable.

Berend

On 29-09-2014, at 21:17, Frank S. <f_j_rod at hotmail.com> wrote:

> Hi to all members of R list,
> 
> 
> 
> I?m working with data.table package, and with 6
> variables: "ID" (Identifier), "born" (Birthdate), "start" (Starting date), "register" (date of measurement), "value"and "end" (date of expiration). So, the natural order of dates would be: born
> =< start =< register =< end.  As an example, I have: DT <- data.table(ID = as.factor(rep(1:4,each=2)), 
> 
>     born =
> as.Date(rep(c("1955-02-20", "1990-07-25",
> "1972-03-18", "1988-05-03"),each=2)),
> 
>     start =
> as.Date(rep(c("1953-03-28", "1990-07-01",
> "1983-09-05", "1988-07-18"),each=2)),
> 
>     register =
> as.Date(c("1955-08-11", "1958-03-28",
> "1990-07-09", "1992-07-01", 
> 
>                "1983-09-05",
> "2002-09-28", "1992-07-10", "1993-03-12")),
> 
>     value =
> c(205, 346, 34, 76, 320, 148, 209, 274),
> 
>     end =
> as.Date(rep(c("1960-11-05", "1997-10-15",
> "2002-09-27", "1997-03-02"),each=2)))
> 
> 
> 
> I would want to make 3 operations:1. First: Remove
> entire ID?s where "start" is previous to "born" date (excepting those subjects whose
> month and year values are the same in "start" and "born" variables: I assign "born"
> date to "start" date in these cases).Afterwords:2. Remove only
> specific rows (not all ID) where ?register? is previous to ?start?.3.Remove only
> specific rows (not all ID) where ?end? is previous to ?register?.
> 
> I have: DT[ , {    if (all(born > start))       {     indx <- which(paste(year(born)) == paste(year(start)) &  paste(month(born)) == paste(month(start)))      result <- list(born=born[indx], start=born[indx], register=register[indx], value=value[indx], end=end[indx])      }        if (all(register > start) | all(end > register))         {         indx <- which((register > start) | (end > register))         result <- list(born=born[indx], start=start[indx], register=register[indx], value=value[indx], end=end[indx])          }      else         {         NULL         }   else     {     indx <- which(all(register > start) | all(end > register))     result <- list(born=born[indx], start=start[indx], register=register[indx], value=value[indx], end=end[indx])      }   result   }, by=ID] BUT I GET AN ERROR MESSAGE: Error: syntax error, unexpected ELSE in "else"  Please, can anyone help me? Thank you!!  
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Mon Sep 29 23:51:14 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 29 Sep 2014 21:51:14 +0000
Subject: [R] residuals of glm
References: <1411985475.94778.YahooMailNeo@web160405.mail.bf1.yahoo.com>
Message-ID: <loom.20140929T234710-579@post.gmane.org>

Yuan Jian <jayuan2008 <at> yahoo.com> writes:

> 
> Hello,
> I found the residuals of glm is not the same as calculated manually.
>  >y=c(12,14,33,50,67,74,123,141,165,204,253,246,240)
> > t=1:13
> > m1=glm(y~t+I(t^2),family=poisson(link="log"))
> > coefficients(m1)[1]+coefficients(m1)[2]*log(t)+
> coefficients(m1)[3]*log(t^2)

 [snip]

> > log(y)-m1$residuals
>        1        2        3        4        5        6        7        8 
> 2.434906 2.890062 3.369962 3.775366 4.146170 4.456127 4.745377 4.982733 
>        9       10       11       12       13 
> 5.174013 5.326826 5.429551 5.499618 5.521138 
> 
> i hope the last two sentences have the same result. 
> could anyone help me out?
> thanks
> Jay

  I'm afraid you may be misunderstanding the way GLMs work.
A log link does *not* mean that the predictors get log-transformed,
nor does it mean that the observed response gets log-transformed; rather, it
means that the predicted response (i.e., the linear predictor based on
the underlying linear model) gets exponentiated.  You will have
better luck (1) summing coefficients * (untransformed) predictor variables;
(2) exponentiating the result; (3) comparing the differences
between the predicted and observed values to residuals(m1,"response")
(see ?residuals.glm).


From macqueen1 at llnl.gov  Mon Sep 29 23:56:47 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 29 Sep 2014 21:56:47 +0000
Subject: [R] could not plot my spatial species points on the raster data
In-Reply-To: <CAG1d=2D54gb9ju8+Jfxz2JEYad7cD97TG-g2CVEx4N6p31R_oA@mail.gmail.com>
References: <CAG1d=2D54gb9ju8+Jfxz2JEYad7cD97TG-g2CVEx4N6p31R_oA@mail.gmail.com>
Message-ID: <D04F1B24.10D517%macqueen1@llnl.gov>

Possibly, not much help is possible without the data, or a reproducible
example.

This is probably better asked on r-sig-geo

A few more comments, inserted below

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/27/14, 1:36 AM, "Girija Kalyani" <smileismystyl at gmail.com> wrote:

>Dear Group,
>
>I working with species distribution modeling in R.
>I have a raster file (stacked with environmental layers around 24 layers),
>i have a shape file.
>Both the arster and shape file are of same projections.
>I confirmed it.
>I have a csv file read which has my species data, but the problem here is
>my species aren't getting plotted on the raster data. What could be the
>proble.
>
>
>raster <- raster(choose.files())
>plot(raster)

raster() is a function, it is a bad idea to also give one of your own
objects the same name

>#input the species occurence file
>hippo <-read.csv(choose.files())
This gives you a data frame, but given what you do next, you need a
character string instead.
In my R it is
   file.choose()

Therefore, you should do

  hippo <- file.choose()

>hippo <- read.table(hippo, header=TRUE, sep=",")
>hippo <- hippo[,2:3]

hippo <- hippo[,2:3] is not necessary, but also harmless.
But make sure that columns 2 and 3 are ?lon? and ?lat? ( or ?lat? and
?lon?), otherwise it?s a mistake.

Better would be
  hippo <- hippo[ , c(?lon?,?lat?)]

>points(hippo$lon,hippo$lat,col="blue",pch=19,cex=0.75,
>xlab="Longitude",ylab="Latitude")

xlab and ylab are normally arguments to a plot() command, not a points()
command

try
  require(sp)
  bbox(raster)
followed by
  range(hippo$lon)
  range(hippo$lat)
are the ranges of lon and lat within the bounding box?

Now you are starting a second plot. Which one is it that you want?

>map<- readOGR(".", layer= 'lahul')
>plot(map, col="grey")
>hip <- data.frame(hippo$lon,hippo$lat)

The above may be the problem. Probably, the columns in hip are not named
?lon? and ?lat?.
What does
  names(hip)
return?

Better would be
  hip <- hippo[ , c(?lon?,?lat?) ]
But in fact this is pointless, because now hip and hippo are identical.

>points(hip$lon,hip$lat,col="blue",pch=19,xlab="Longitude",ylab="Latitude")



Try replacing the whole thing with

## get the raster
inrast <- file.choose()
myraster <- raster(inrast)

#input the species occurence file
infile <- file.choose()
hippo <- read.table(infile, header=TRUE, sep=?,?)

require(sp)
coordinates(hippo) <- c(?lon?,?lat?)
proj4string(hippo) <- CRS(proj4string(myraster)))

plot(myraster)
plot(hippo, col="blue?, pch=19, add=TRUE)



## you could also try
plot(map, col=?grey?)
plot(hippo, col="blue?, pch=19, add=TRUE)



>
>......
> Any help wil be highly appreciated.
>Thanx in advance
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From eliza_botto at hotmail.com  Tue Sep 30 00:38:21 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Mon, 29 Sep 2014 22:38:21 +0000
Subject: [R] fitting distribution
Message-ID: <BLU170-W483BE8E10725C8ED3A9DBA89BA0@phx.gbl>


Dear UseRs,
I have a dataset in the following form.
> dput(Da)
structure(c(0.0238095238095238, 0.0476190476190476, 0.0714285714285714, 0.0952380952380952, 0.119047619047619, 0.142857142857143, 0.166666666666667, 0.19047619047619, 0.214285714285714, 0.238095238095238, 0.261904761904762, 0.285714285714286, 0.30952380952381, 0.333333333333333, 0.357142857142857, 0.380952380952381, 0.404761904761905, 0.428571428571429, 0.452380952380952, 0.476190476190476, 0.5, 0.523809523809524, 0.547619047619048, 0.571428571428571, 0.595238095238095, 0.619047619047619, 0.642857142857143, 0.666666666666667, 0.69047619047619, 0.714285714285714, 0.738095238095238, 0.761904761904762, 0.785714285714286, 0.80952380952381, 0.833333333333333, 0.857142857142857, 0.880952380952381, 0.904761904761905, 0.928571428571429, 0.952380952380952, 0.976190476190476, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500), .Dim = c(41L, 2L), .Dimnames = list(NULL, c("P", "RP")))

Column number 1 is the probability of non execeedance and column 2 is return period of the event. I plotted the dataset in the following way
>plot(Da[,2],Da[,1],log="x")
I now want to fit gumbel distribution, LN3 and GEV distributions on the data and plot them on the same window to see which distribution actually fits good to the data. I know there are other ways of determining best fitted distribution in R but I just wanted to know that if I can actually plot it on actual distribution or not. I want it to try for my thesis.
Thankyou very much in advance
Eliza
 		 	   		  
	[[alternative HTML version deleted]]


From nebuloso78 at gmx.ch  Tue Sep 30 01:05:54 2014
From: nebuloso78 at gmx.ch (Nebulo Archae)
Date: Tue, 30 Sep 2014 01:05:54 +0200
Subject: [R] If statement not working in a for loop when making it
	independent
Message-ID: <trinity-b4e189e2-c033-4247-afc8-51dfc80d6fdd-1412031954506@3capp-gmx-bs36>

Dear all,

I have a data.frame xy that contains numeric data and data_qual which contains qualitative data which I want to include in a for loop with an if statement (commented out in the code below).
The if statement should be applied if the ID in data_qual$ID is the same than in xy$ID.

I am trying to make it independent by doing this:

if(i$ID %in% data_qual[data_qual$ID %in% i$ID,]$ID){...}
?
but it doesn't work when I incorporate it in the for loop. The logical result is correct but it only works for the first element when implemented in the for loop. Can anyone see what I am doing wrong here?

#######################
Here is my code:
xy <-data.frame(NAME=c("NAME1","NAME1","NAME1","NAME2","NAME2","NAME2","NAME3","NAME3"),ID=c(87,87,87,199,199,199,233,233),X_START_YEAR=c(1950,1988,1994,1899,1909,1924,1945,1948),Y_START_VALUE=c(75,25,-90,-8,-55,-10,-9,12),X_END_YEAR=c(1985,1994,1999,1904,1924,1987,1946,1949), Y_END_VALUE=c(20,50,-15,-70,-80,-100,24,59))
?
data_qual <- data.frame(NAME=c("NAME2","NAME3"),ID=c(199,233),X_START_YEAR=c(1986,1905), Y_START_VALUE=c("-X","ST"),X_END_YEAR=c(1987,1907),Y_END_VALUE=c("-X","ST"))
?
# split xy by group as defined by ID
ind <- split(xy,xy$ID)
?
for (i in ind){xx = unlist(i[,grep('X_',colnames(i))])?
?? ? ? ? ? ? ? yy = unlist(i[,grep('Y_',colnames(i))])?
?? ? ? ? ? ? ? fname <- paste0(i[1, 'ID'], '.png')?
?? ? ? ? ? ? ? png(fname, width=1679, height=1165, res=150)
? if(any(xx < 1946)) {my_x_lim <- c(min(xx), 2014)} else {my_x_lim <- c(1946, 2014)}?
? par(mar=c(6,8,6,5))
? plot(xx, yy,main=unique(i[,1]),xlab="Time [Years]",ylab="Value [m]",pch=21,xlim = my_x_lim,font.lab=2, cex.lab=1.2, cex.axis=1.1)
? i <- i[,-1]
? segments(i[,2],i[,3],i[,4],i[,5],lwd=2)
?
?# if(i$ID %in% data_qual[data_qual$ID %in% i$ID,]$ID){
?# ? ? rel_data_qual <- data_qual[data_qual$ID %in% i$ID,]
?# ? ? text(x = rel_data_qual$X_END_YEAR,
?#? ? ? ? ? y = min(i$Y_END_VALUE + 3),
?# ? ? labels = rel_data_qual$Y_END_VALUE) ?
?# ? }
?
? dev.off()
}

Thanks, Kurt


From gcr at wisdomandwonder.com  Tue Sep 30 01:27:48 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Mon, 29 Sep 2014 18:27:48 -0500
Subject: [R] hadley's book
In-Reply-To: <CAHz+bWYO7aVQRuQ3G-s1NGidjLR_Ff337Ou2i0-jxKC-4xnBbA@mail.gmail.com>
References: <CAHz+bWYO7aVQRuQ3G-s1NGidjLR_Ff337Ou2i0-jxKC-4xnBbA@mail.gmail.com>
Message-ID: <CAAjq1me-2Ce4jzA3W9ws0PNgycom_49k+sWVdgkWwg0TtUovYQ@mail.gmail.com>

On Mon, Sep 29, 2014 at 10:59 AM, Mark Leeds <markleeds2 at gmail.com> wrote:
> Just a heads up to list: I don't know about other book sites but,  on U.S
> Amazon, Hadley's Advanced R book is no longer in pre-order mode. You can
> purchase the book now without pre-ordering it.

Thank you for the notice. Just bought it for the Kindle.

Having already started reading it on the website, it is clearly a
valuable resource.


From jdnewmil at dcn.davis.CA.us  Tue Sep 30 02:33:38 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Sep 2014 17:33:38 -0700
Subject: [R] If statement not working in a for loop when making
	it	independent
In-Reply-To: <trinity-b4e189e2-c033-4247-afc8-51dfc80d6fdd-1412031954506@3capp-gmx-bs36>
References: <trinity-b4e189e2-c033-4247-afc8-51dfc80d6fdd-1412031954506@3capp-gmx-bs36>
Message-ID: <33BCB65B-5DC9-42F5-97ED-51C1B569DD20@dcn.davis.CA.us>

You have really tied yourself up in a knot here. Last I checked, when A==B, then B==A. You also need to study the difference between ?if and ?ifelse, since you are not giving the if function the scalar it expects. For example, i$ID is a vector of three (identical, due to your use of split) values, so %in% will return three logical values.
I think one way to do this is to replace

i$ID %in% data_qual[data_qual$ID %in% i$ID,]$ID

with

i[ 1, "ID" ] %in% data_qual[ , "ID"]

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 29, 2014 4:05:54 PM PDT, Nebulo Archae <nebuloso78 at gmx.ch> wrote:
>Dear all,
>
>I have a data.frame xy that contains numeric data and data_qual which
>contains qualitative data which I want to include in a for loop with an
>if statement (commented out in the code below).
>The if statement should be applied if the ID in data_qual$ID is the
>same than in xy$ID.
>
>I am trying to make it independent by doing this:
>
>if(i$ID %in% data_qual[data_qual$ID %in% i$ID,]$ID){...}
>?
>but it doesn't work when I incorporate it in the for loop. The logical
>result is correct but it only works for the first element when
>implemented in the for loop. Can anyone see what I am doing wrong here?
>
>#######################
>Here is my code:
>xy
><-data.frame(NAME=c("NAME1","NAME1","NAME1","NAME2","NAME2","NAME2","NAME3","NAME3"),ID=c(87,87,87,199,199,199,233,233),X_START_YEAR=c(1950,1988,1994,1899,1909,1924,1945,1948),Y_START_VALUE=c(75,25,-90,-8,-55,-10,-9,12),X_END_YEAR=c(1985,1994,1999,1904,1924,1987,1946,1949),
>Y_END_VALUE=c(20,50,-15,-70,-80,-100,24,59))
>?
>data_qual <-
>data.frame(NAME=c("NAME2","NAME3"),ID=c(199,233),X_START_YEAR=c(1986,1905),
>Y_START_VALUE=c("-X","ST"),X_END_YEAR=c(1987,1907),Y_END_VALUE=c("-X","ST"))
>?
># split xy by group as defined by ID
>ind <- split(xy,xy$ID)
>?
>for (i in ind){xx = unlist(i[,grep('X_',colnames(i))])?
>?? ? ? ? ? ? ? yy = unlist(i[,grep('Y_',colnames(i))])?
>?? ? ? ? ? ? ? fname <- paste0(i[1, 'ID'], '.png')?
>?? ? ? ? ? ? ? png(fname, width=1679, height=1165, res=150)
>? if(any(xx < 1946)) {my_x_lim <- c(min(xx), 2014)} else {my_x_lim <-
>c(1946, 2014)}?
>? par(mar=c(6,8,6,5))
>? plot(xx, yy,main=unique(i[,1]),xlab="Time [Years]",ylab="Value
>[m]",pch=21,xlim = my_x_lim,font.lab=2, cex.lab=1.2, cex.axis=1.1)
>? i <- i[,-1]
>? segments(i[,2],i[,3],i[,4],i[,5],lwd=2)
>?
>?# if(i$ID %in% data_qual[data_qual$ID %in% i$ID,]$ID){
>?# ? ? rel_data_qual <- data_qual[data_qual$ID %in% i$ID,]
>?# ? ? text(x = rel_data_qual$X_END_YEAR,
>?#? ? ? ? ? y = min(i$Y_END_VALUE + 3),
>?# ? ? labels = rel_data_qual$Y_END_VALUE) ?
>?# ? }
>?
>? dev.off()
>}
>
>Thanks, Kurt
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Sep 30 03:01:11 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Sep 2014 18:01:11 -0700
Subject: [R] "timeDate" package: Read dates from xls or txt
In-Reply-To: <CABcx46BLy-X0DEd5QLb2C42Lck0e8qM0CQ9TK_K_yvFD0j3Dbg@mail.gmail.com>
References: <CABcx46BLy-X0DEd5QLb2C42Lck0e8qM0CQ9TK_K_yvFD0j3Dbg@mail.gmail.com>
Message-ID: <EED40E1B-C4B7-4775-9C1D-E4DD10728F42@dcn.davis.CA.us>

If you read the documentation for that package you will find that the answer is no, for the simple reason that it doesn't do input or output. It does help you with conversions between POSIXt types, and can help figure out which days are holidays or weekends, but you need the date in character format to start.

For reading in CSV data I use as.is=TRUE or stringsAsFactors=FALSE in my call to read.csv. For reading xls files I have had difficulties, which is why I prefer to export Excel data to CSV before reading it into R.  One XLConnect bug workaround I have used is to convert the timestamp column into character using as.character with specified format and then back using as.POSIXct and a specified timezone, but it was borne of desperation and may not always be necessary or even sufficient.

Please post using plain text rather than HTML format on this list. Only you can prevent your postings from being garbled.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 29, 2014 2:47:01 AM PDT, jpm miao <miaojpm at gmail.com> wrote:
>Hi,
>
>   timeDate package create a date vector like this:
>
>   Dates <- c("1989-09-28","2001-01-15","2004-08-30","1990-02-09")
>
>
>   I have a date whose size is large. Could this package read the dates
>from xls or txt files? Could we convert the read vector (e.g., I
>usually
>use XLConnect to read xls files) to the date?
>
>   Thanks,
>
>Miao
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lopez235 at llnl.gov  Tue Sep 30 03:07:57 2014
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 30 Sep 2014 01:07:57 +0000
Subject: [R] Custom Function Not Completely working
Message-ID: <56180B40A4F72A4083C75B30DA8629733A8C5714@PRDEXMBX-05.the-lab.llnl.gov>

Hi R Experts,

I'm in the process of creating a set of convenience functions for myself. I am somewhat new to writing functions in r.

In this example I wanted to load both existing files called KuhnPerform.Rdata and KuhnPerform.Rhistory. However it only works for loading the .Rhistory file and not the .Rdata file. Can someone please tell me how to fix this so that it loads both .Rdata and .Rhistory?

I checked dir() that these files are in my working directory and are spelled correctly

loads<-function(filename="KuhnPerform"){
load(paste0(filename,".Rdata")) # Load a previously saved workspace.
loadhistory(paste0(filename,".Rhistory")) # Load a previously saved history file.
}

Dan
Workforce Analyst
LLNL


	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Tue Sep 30 03:10:01 2014
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 30 Sep 2014 09:10:01 +0800
Subject: [R] "timeDate" package: Read dates from xls or txt
In-Reply-To: <EED40E1B-C4B7-4775-9C1D-E4DD10728F42@dcn.davis.CA.us>
References: <CABcx46BLy-X0DEd5QLb2C42Lck0e8qM0CQ9TK_K_yvFD0j3Dbg@mail.gmail.com>
	<EED40E1B-C4B7-4775-9C1D-E4DD10728F42@dcn.davis.CA.us>
Message-ID: <CABcx46C5o5yDHZti=oKTBPqwj5=cmVOhz-o2Z=u5csDE67S5oA@mail.gmail.com>

Thanks. Could "timeDate" object be transformed to/from "zoo" or "xts"?

2014-09-30 9:01 GMT+08:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> If you read the documentation for that package you will find that the
> answer is no, for the simple reason that it doesn't do input or output. It
> does help you with conversions between POSIXt types, and can help figure
> out which days are holidays or weekends, but you need the date in character
> format to start.
>
> For reading in CSV data I use as.is=TRUE or stringsAsFactors=FALSE in my
> call to read.csv. For reading xls files I have had difficulties, which is
> why I prefer to export Excel data to CSV before reading it into R.  One
> XLConnect bug workaround I have used is to convert the timestamp column
> into character using as.character with specified format and then back using
> as.POSIXct and a specified timezone, but it was borne of desperation and
> may not always be necessary or even sufficient.
>
> Please post using plain text rather than HTML format on this list. Only
> you can prevent your postings from being garbled.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On September 29, 2014 2:47:01 AM PDT, jpm miao <miaojpm at gmail.com> wrote:
> >Hi,
> >
> >   timeDate package create a date vector like this:
> >
> >   Dates <- c("1989-09-28","2001-01-15","2004-08-30","1990-02-09")
> >
> >
> >   I have a date whose size is large. Could this package read the dates
> >from xls or txt files? Could we convert the read vector (e.g., I
> >usually
> >use XLConnect to read xls files) to the date?
> >
> >   Thanks,
> >
> >Miao
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From yara_abuawad at yahoo.com  Tue Sep 30 02:03:30 2014
From: yara_abuawad at yahoo.com (Yara Abu Awad)
Date: Mon, 29 Sep 2014 17:03:30 -0700
Subject: [R] Issue with a function
Message-ID: <1412035410.69001.YahooMailNeo@web141405.mail.bf1.yahoo.com>

Hi,

I'm trying to use a function to multiply a matrix (newX) with a simple list (beta).
I know that I can simply use matrix multiplication i.e. newX %*%as.matrix(beta)
and this works fine. However, the matrix multiplication gives me the sum of each row. What I really need are the new values of all the columns in newX if they were multiplied by beta (so the first column of newX should be multiplied by the first value in beta, second column by the second value etc..)

This is the function I'm trying to use:

Terms <-NULL
count <- 0

for (i in 1: ncol(newX)){
  for (j in 1: length(beta)){
    Terms <- cbind (Terms,(newX[,i]*beta[j]))
  }
}

I don't get an error message, however the function runs for a long time (about an hour) without resolving and I end up stopping it.



Now, if I multiply every individual column by each value of beta, the calculation works (code is below):
newX[,1]*beta[1]
newX[,2]*beta[2]

but since newX has 520 columns and beta has 520 values, I'd rather use a shortcut!!


I can't figure out why the above function doesn't work. I've used it to multiply two matrices and it works just fine.
Any insight would be appreciated.

Yara


From murdoch.duncan at gmail.com  Tue Sep 30 03:23:24 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Sep 2014 21:23:24 -0400
Subject: [R] Custom Function Not Completely working
In-Reply-To: <56180B40A4F72A4083C75B30DA8629733A8C5714@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA8629733A8C5714@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <542A060C.3070204@gmail.com>

On 29/09/2014, 9:07 PM, Lopez, Dan wrote:
> Hi R Experts,
> 
> I'm in the process of creating a set of convenience functions for myself. I am somewhat new to writing functions in r.
> 
> In this example I wanted to load both existing files called KuhnPerform.Rdata and KuhnPerform.Rhistory. However it only works for loading the .Rhistory file and not the .Rdata file. Can someone please tell me how to fix this so that it loads both .Rdata and .Rhistory?
> 
> I checked dir() that these files are in my working directory and are spelled correctly
> 
> loads<-function(filename="KuhnPerform"){
> load(paste0(filename,".Rdata")) # Load a previously saved workspace.
> loadhistory(paste0(filename,".Rhistory")) # Load a previously saved history file.
> }

You're loading the objects from the Rdata file into the evaluation frame
of your function, and they go away afterwards.  You need to specify
where they should be loaded using the envir argument, e.g.


load(paste0(filename,".Rdata"), envir = parent.frame())

(The funny thing here is that the default for envir is parent.frame(),
but it means something different in that context.)

Duncan Murdoch

> 
> Dan
> Workforce Analyst
> LLNL
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Tue Sep 30 03:27:33 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Sep 2014 18:27:33 -0700
Subject: [R] "timeDate" package: Read dates from xls or txt
In-Reply-To: <CABcx46C5o5yDHZti=oKTBPqwj5=cmVOhz-o2Z=u5csDE67S5oA@mail.gmail.com>
References: <CABcx46BLy-X0DEd5QLb2C42Lck0e8qM0CQ9TK_K_yvFD0j3Dbg@mail.gmail.com>
	<EED40E1B-C4B7-4775-9C1D-E4DD10728F42@dcn.davis.CA.us>
	<CABcx46C5o5yDHZti=oKTBPqwj5=cmVOhz-o2Z=u5csDE67S5oA@mail.gmail.com>
Message-ID: <570CB175-2D31-498C-A7BD-0F78C76AB666@dcn.davis.CA.us>

Your questions still don't make sense. Can you use a car to make lunch? You could use it to drive to the store and get ingredients for lunch, but it isn't a very useful question.

The timeDate package is a package of useful functions, not a class of data. Re-read my description below, or better yet read the documentation for that package. Zoo is both a package and a class of data defined in that package, but it allows you to choose which kind of time object you want to use as the index of your time series. POSIXct is one type that zoo can use, and the functions in the timeDate package might even be helpful to you in getting that index vector ready to give to the zoo function... or not. Depends what you need to do to your time data to make it useful.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 29, 2014 6:10:01 PM PDT, jpm miao <miaojpm at gmail.com> wrote:
>Thanks. Could "timeDate" object be transformed to/from "zoo" or "xts"?
>
>2014-09-30 9:01 GMT+08:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> If you read the documentation for that package you will find that the
>> answer is no, for the simple reason that it doesn't do input or
>output. It
>> does help you with conversions between POSIXt types, and can help
>figure
>> out which days are holidays or weekends, but you need the date in
>character
>> format to start.
>>
>> For reading in CSV data I use as.is=TRUE or stringsAsFactors=FALSE in
>my
>> call to read.csv. For reading xls files I have had difficulties,
>which is
>> why I prefer to export Excel data to CSV before reading it into R. 
>One
>> XLConnect bug workaround I have used is to convert the timestamp
>column
>> into character using as.character with specified format and then back
>using
>> as.POSIXct and a specified timezone, but it was borne of desperation
>and
>> may not always be necessary or even sufficient.
>>
>> Please post using plain text rather than HTML format on this list.
>Only
>> you can prevent your postings from being garbled.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 29, 2014 2:47:01 AM PDT, jpm miao <miaojpm at gmail.com>
>wrote:
>> >Hi,
>> >
>> >   timeDate package create a date vector like this:
>> >
>> >   Dates <- c("1989-09-28","2001-01-15","2004-08-30","1990-02-09")
>> >
>> >
>> >   I have a date whose size is large. Could this package read the
>dates
>> >from xls or txt files? Could we convert the read vector (e.g., I
>> >usually
>> >use XLConnect to read xls files) to the date?
>> >
>> >   Thanks,
>> >
>> >Miao
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From jdnewmil at dcn.davis.CA.us  Tue Sep 30 03:47:46 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Sep 2014 18:47:46 -0700
Subject: [R] Issue with a function
In-Reply-To: <1412035410.69001.YahooMailNeo@web141405.mail.bf1.yahoo.com>
References: <1412035410.69001.YahooMailNeo@web141405.mail.bf1.yahoo.com>
Message-ID: <29EDF7D3-8CA3-4720-8F60-E5E4B676E68F@dcn.davis.CA.us>

library(Matrix)
result <- newX %*% Diagonal( unlist(beta) )

Is beta really a list, or is it a vector? The str function can help with this... in most cases it is a numeric mode vector and the unlist is not needed.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On September 29, 2014 5:03:30 PM PDT, Yara Abu Awad <yara_abuawad at yahoo.com> wrote:
>Hi,
>
>I'm trying to use a function to multiply a matrix (newX) with a simple
>list (beta).
>I know that I can simply use matrix multiplication i.e. newX
>%*%as.matrix(beta)
>and this works fine. However, the matrix multiplication gives me the
>sum of each row. What I really need are the new values of all the
>columns in newX if they were multiplied by beta (so the first column of
>newX should be multiplied by the first value in beta, second column by
>the second value etc..)
>
>This is the function I'm trying to use:
>
>Terms <-NULL
>count <- 0
>
>for (i in 1: ncol(newX)){
>  for (j in 1: length(beta)){
>    Terms <- cbind (Terms,(newX[,i]*beta[j]))
>  }
>}
>
>I don't get an error message, however the function runs for a long time
>(about an hour) without resolving and I end up stopping it.
>
>
>
>Now, if I multiply every individual column by each value of beta, the
>calculation works (code is below):
>newX[,1]*beta[1]
>newX[,2]*beta[2]
>
>but since newX has 520 columns and beta has 520 values, I'd rather use
>a shortcut!!
>
>
>I can't figure out why the above function doesn't work. I've used it to
>multiply two matrices and it works just fine.
>Any insight would be appreciated.
>
>Yara
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From acefix at rocketmail.com  Tue Sep 30 05:35:50 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 30 Sep 2014 03:35:50 +0000 (UTC)
Subject: [R] how to get the rows that satisfy a specific condition
In-Reply-To: <CAHuTOvrY5H-0wvLe=P8jVSiThUHiwTib=oGt21P2XPO=ksQ2QQ@mail.gmail.com>
References: <CAHuTOvrY5H-0wvLe=P8jVSiThUHiwTib=oGt21P2XPO=ksQ2QQ@mail.gmail.com>
Message-ID: <1979940602.65881.1412048150106.JavaMail.yahoo@jws10722.mail.gq1.yahoo.com>

Sorry for my confusing question. Thanks for all the inputs. I think Sven E. Templer gave the answer I needed...


 

     On Sunday, September 28, 2014 4:51 AM, Sven E. Templer <sven.templer at gmail.com> wrote:
   

 in ?which read about arr.ind

following jims assumption (column instead of row indices is what you
want) this also works:

m <- matrix(1:20,4)
unique(which(m>11, arr.ind = T)[,"col"])

On 27 September 2014 12:23, Jim Lemon <jim at bitwrit.com.au> wrote:
> On Fri, 26 Sep 2014 10:15:14 PM Fix Ace wrote:
>> Hello, there,
>> I wonder if there is an easier way that I would only get the rows that
>> satisfies some condition. For example:I have the following matrix, and I
>> would like to output only the 3rd row and 4th row, since only these two
>> rows contain the numbers greater than 11
>> > a
>>
>>? ? ? [,1] [,2] [,3] [,4] [,5]
>> [1,]? ? 1? ? 5? ? 9? 13? 17
>> [2,]? ? 2? ? 6? 10? 14? 18
>> [3,]? ? 3? ? 7? 11? 15? 19
>> [4,]? ? 4? ? 8? 12? 16? 20
>>
>> > a>11
>>
>>? ? ? [,1]? [,2]? [,3] [,4] [,5]
>> [1,] FALSE FALSE FALSE TRUE TRUE
>> [2,] FALSE FALSE FALSE TRUE TRUE
>> [3,] FALSE FALSE FALSE TRUE TRUE
>> [4,] FALSE FALSE? TRUE TRUE TRUE
>> I have tried to use a[a>11, ] and it did not work.
>> Thanks a lot for the help:)
>
> Hi Fix Ace,
> I have to admit that I am unfamiliar with the system of arithmetic that
> you are employing in the above example. In no system with which I am
> conversant are 13, 17, 14 and 18 less than or equal to 11. I can only
> offer the desperate conjecture that you want the third to fifth columns of
> the matrix rather than the third and fourth rows. If this wild surmise
> happens to be the case, I suggest that you try this:
>
> testmat[,apply(testmat,2,function(x) return(max(x) > 11))]
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Sep 30 08:46:43 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 30 Sep 2014 06:46:43 +0000
Subject: [R] Loop does not work: Error in else statement
In-Reply-To: <BAY168-W1276E960BB649734656151FBABA0@phx.gbl>
References: <BAY168-W1276E960BB649734656151FBABA0@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE85F0@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Frank S.
> Sent: Monday, September 29, 2014 9:17 PM
> To: r-help at r-project.org
> Subject: [R] Loop does not work: Error in else statement
>
> Hi to all members of R list,
>
>
>
> I m working with data.table package, and with 6
> variables: "ID" (Identifier), "born" (Birthdate), "start" (Starting
> date), "register" (date of measurement), "value"and "end" (date of
> expiration). So, the natural order of dates would be: born =< start =<
> register =< end.  As an example, I have: DT <- data.table(ID =
> as.factor(rep(1:4,each=2)),
>
>      born =
> as.Date(rep(c("1955-02-20", "1990-07-25", "1972-03-18", "1988-05-
> 03"),each=2)),
>
>      start =
> as.Date(rep(c("1953-03-28", "1990-07-01", "1983-09-05", "1988-07-
> 18"),each=2)),
>
>      register =
> as.Date(c("1955-08-11", "1958-03-28",
> "1990-07-09", "1992-07-01",
>
>                 "1983-09-05",
> "2002-09-28", "1992-07-10", "1993-03-12")),
>
>      value =
> c(205, 346, 34, 76, 320, 148, 209, 274),
>
>      end =
> as.Date(rep(c("1960-11-05", "1997-10-15", "2002-09-27", "1997-03-
> 02"),each=2)))
>
>
>
> I would want to make 3 operations:1. First: Remove entire ID s where
> "start" is previous to "born" date (excepting those subjects whose
> month and year values are the same in "start" and "born" variables: I
> assign "born"
> date to "start" date in these cases).Afterwords:2. Remove only specific
> rows (not all ID) where  register  is previous to  start .3.Remove only
> specific rows (not all ID) where  end  is previous to  register .
>
> I have: DT[ , {    if (all(born > start))       {     indx <-
> which(paste(year(born)) == paste(year(start)) &  paste(month(born)) ==
> paste(month(start)))      result <- list(born=born[indx],
> start=born[indx], register=register[indx], value=value[indx],
> end=end[indx])      }        if (all(register > start) | all(end >
> register))         {         indx <- which((register > start) | (end >
> register))         result <- list(born=born[indx], start=start[indx],
> register=register[indx], value=value[indx], end=end[indx])          }
> else         {         NULL         }   else     {     indx <-
> which(all(register > start) | all(end > register))     result <-
> list(born=born[indx], start=start[indx], register=register[indx],
> value=value[indx], end=end[indx])      }   result   }, by=ID] BUT I GET
> AN ERROR MESSAGE: Error: syntax error, unexpected ELSE in "else"
> Please, can anyone help me? Thank you!!

Missing parentheses? Missing comma? Syntactically valid expression before else?

From HTML scrambled post hard to tell.

Wild guess.

some if statement could be evaluated without before else statement as valid.

if (something) {do this}
else {do that}

results in error as first line is evaluated and else is not needed for this evaluation. Therefore you start the second line without leading if.

if (something) {do this} else
{do that}

is valid and does not throw error.

Maybe it is covered in FAQs

Regards
Petr




>
>
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Tue Sep 30 09:38:16 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 30 Sep 2014 09:38:16 +0200
Subject: [R] Issue with a function
In-Reply-To: <29EDF7D3-8CA3-4720-8F60-E5E4B676E68F@dcn.davis.CA.us>
References: <1412035410.69001.YahooMailNeo@web141405.mail.bf1.yahoo.com>
	<29EDF7D3-8CA3-4720-8F60-E5E4B676E68F@dcn.davis.CA.us>
Message-ID: <2142422D-B58F-4C22-893E-105B63254B4D@gmail.com>


On 30 Sep 2014, at 03:47 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> library(Matrix)
> result <- newX %*% Diagonal( unlist(beta) )

The code in Matrix does this efficiently, I hope?

Otherwise, sweep() is the traditional ticket:

result <- sweep(newX, 2, unlist(beta), "*")

Some of my students do

t(t(newX) * unlist(beta))

(utilizing recycling of beta) which I think looks horrible, but it does work. 

The problem with the original code is that the cbind() reallocates storage every time a column is added to the result. This can be alleviated by preallocating. Also note that the double for loop in


for (i in 1: ncol(newX)){
 for (j in 1: length(beta)){
   Terms <- cbind (Terms,(newX[,i]*beta[j]))
 }
}

generates 520*520 columns of pairwise products, which I presume was not the intention.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From radhakrishnan.mohan at gmail.com  Tue Sep 30 09:57:08 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Tue, 30 Sep 2014 13:27:08 +0530
Subject: [R] Median of streaming data
In-Reply-To: <5425EE54.20107@auckland.ac.nz>
References: <CAOoXFP9vQ6Cirtebeq509xEUr2iMvVw2aP5nbSxDO-G=10sNhA@mail.gmail.com>
	<54226816.700@auckland.ac.nz>
	<21538.32250.67575.749398@stat.math.ethz.ch>
	<54235766.3070400@auckland.ac.nz>
	<21541.13953.417228.646860@stat.math.ethz.ch>
	<5425EE54.20107@auckland.ac.nz>
Message-ID: <CAOoXFP_5zKsTbYL_fTVAGeQAPu+mQFPJsQyY_8V5+0iepo2kkg@mail.gmail.com>

Hi,
       I came across this project(http://jwijffels.github.io/RMOA/) which
seems to be directly addressing streaming prediction.

>From the manual :

A data stream environment has different requirements from the traditional
setting. The most significant are the following:
Requirement 1 Process an example at a time, and inspect it only once (at
most)
Requirement 2 Use a limited amount of memory
Requirement 3 Work in a limited amount of time
Requirement 4 Be ready to predict at any time

Thanks,
Mohan

On Sat, Sep 27, 2014 at 4:23 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 26/09/14 21:48, Martin Maechler wrote:
>
>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>>>
>>>>>>
> <SNIP>
>
>
>>      > I have coded up the algorithm from the Cameron and Turner
>>      > paper.  Dunno if it gives exactly the same results as my
>>      > (Splus?) code from lo these many years ago (the code that
>>      > is lost in the mists of time), but it *seems* to work.
>>
>> excellent, thank you, Rolf!
>>
>>      > It is not designed to work with actual "streaming" data
>>      > --- I don't know how to do that.  It takes a complete data
>>      > vector as input.  Someone who knows about streaming data
>>      > should be able to adapt it pretty easily.  Said he, the
>>      > proverbial optimist.
>>
>> I agree; that should not be hard.
>> One way is to replace   'y[ind]' by   'getY(ind)' everywhere in the code
>> and let 'getY' be an argument to rlas() provided by the user.
>>
>>      > The function code and a help file are attached.  These
>>      > files have had their names changed to end in ".txt" so
>>      > that they will get through the mailing list processor
>>      > without being stripped.  With a bit of luck.
>> ;-)
>>
>> It did work indeed.
>> I've added them to  'robustX' -- on R-forge,
>> including a plot() method and some little more flexibility.
>>
>>    --> https://r-forge.r-project.org/R/?group_id=59
>>
>>
>
> <SNIP>
>
> Since I posted my previous email I have found some typos in the
> documentation and made some adjustments to the code.
>
> I also realized that the name "rlas" sounds a bit too much like a random
> number generator, according to R's conventions.  So I have decided that
> "lasr" would be a better name.
>
> I hope this change of horses in midstream doesn't mess things up too much
> for you.  If it does, of course feel free to stick with "rlas".
>
> I have attached revised *.R and *.Rd files.  Not sure that the *.Rd file
> will get through as-is.  Please let me know if it doesn't.
>
>
> cheers,
>
> Rolf
>
>
> --
> Rolf Turner
> Technical Editor ANZJS
>

	[[alternative HTML version deleted]]


From lenz99 at gmail.com  Tue Sep 30 10:13:15 2014
From: lenz99 at gmail.com (Matthias Kuhn)
Date: Tue, 30 Sep 2014 10:13:15 +0200
Subject: [R] ..nlme: start values necessary even though using self-start
	function?..
Message-ID: <CAFOoapLXwvKmPjnnmmRC=Qqvb9xz62ss5sfVWj7Qgm5Da-bM4A@mail.gmail.com>

Dear list.

I am stuck with an "subscript out of bounds" error when I play with an
nlme-example from the yellow Pinheiro/Bates book. It is about using
nlme() using the formula interface for non-linear mixed models.

The following code snippet is inspired by the book (in section 8.2),
using the Orange-example data from R datasets containing repeated
measures of trunk circumferences over time for 5 trees. It is a
nfnGroupedData with structure circumference ~ age | Tree.


nlme( circumference ~ SSlogis(age, Asym, xmid, scal), data=Orange,
                      fixed= Asym + xmid + scal ~ 1)

It results in the following error:
Error in nlme.formula(circumference ~ SSlogis(age, Asym, xmid, scal),  :
  subscript out of bounds

Specifiying the grouping as in groups=~Tree does not help, either.

When I do provide start values, it works, though.

nlme( circumference ~ SSlogis(age, Asym, xmid, scal), data=Orange,
                      start=c(Asym = 200, xmid=725, scal=350),
                      fixed= Asym + xmid + scal ~ 1)

Beginning of result output:

Nonlinear mixed-effects model fit by maximum likelihood
Model: circumference ~ SSlogis(age, Asym, xmid, scal)
Data: Orange
Log-likelihood: -129.9907
Fixed: Asym + xmid + scal ~ 1
    Asym     xmid     scal
192.0959 727.5887 356.6011
...



SSlogis() is a selfStart object and should be able to get its own
starting values like so:
getInitial(circumference ~ SSlogis(age, Asym, xmid, scal), data=Orange)


So start= argument should not be necessary.
What am I missing here? Any ideas?

Thanks in advance..

-m



ps> This is my setting:

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-117 devtools_1.5

loaded via a namespace (and not attached):
 [1] digest_0.6.4    evaluate_0.5.5  grid_3.1.1      httr_0.5
lattice_0.20-29 memoise_0.2.1   parallel_3.1.1  RCurl_1.95-4.3
stringr_0.6.2   tools_3.1.1     whisker_0.3-2



And regarding my nlme-package from CRAN:

Information on package ?nlme?


Description:


Package:            nlme

Version:            3.1-117

Date:               2014-03-31

Priority:           recommended

Title:              Linear and Nonlinear Mixed Effects Models

Authors at R:          c(person("Jos?", "Pinheiro", role = "aut", comment
= "S version"), person("Douglas", "Bates", role = "aut", comment = "up
to 2007"), person("Saikat", "DebRoy", role = "ctb", comment = "up
              to 2002"), person("Deepayan", "Sarkar", role = "ctb",
comment = "up to 2005"), person("EISPACK authors", role = "ctb",
comment = "src/rs.f"), person("R-core", email =

                    "R-core at R-project.org", role = c("aut", "cre")))

Description:        Fit and compare Gaussian linear and nonlinear
mixed-effects models.

Depends:            graphics, stats, R (>= 3.0.0)

Imports:            lattice

Suggests:           Hmisc, MASS

LazyData:           yes

ByteCompile:        yes

Encoding:           UTF-8

License:            GPL (>= 2)

BugReports:         http://bugs.r-project.org

Packaged:           2014-03-31 07:56:40 UTC; ripley

Author:             Jos? Pinheiro [aut] (S version), Douglas Bates
[aut] (up to 2007), Saikat DebRoy [ctb] (up to 2002), Deepayan Sarkar
[ctb] (up to 2005), EISPACK authors [ctb] (src/rs.f), R-core [aut,

                    cre]

Maintainer:         R-core <R-core at R-project.org>

NeedsCompilation:   yes

Repository:         CRAN

Date/Publication:   2014-03-31 10:16:43

Built:              R 3.1.1; x86_64-apple-darwin13.1.0; 2014-07-11
12:37:41 UTC; unix


From sven.templer at gmail.com  Tue Sep 30 11:41:32 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Tue, 30 Sep 2014 11:41:32 +0200
Subject: [R] Obtain 00Index.html
Message-ID: <CAHuTOvq2Q6MpEGBXoLqWEv9ck9xVv6fyRQNbodjG9Em82=HtAQ@mail.gmail.com>

Hello,

how can I open (by an R command) the index page in html mode, as obtained by:

options(browser="firefox") # or any other
options(help_type="html")
?help
# and then following the html reference on the page bottom named "Index"

In text mode I know library(help='utils') to open the utils package
index (as in the example above). Setting options(text_mode="html") and
options(browser="firefox") does not affect this behaviour. Also in
?help.start and ?help (or ?"?") I found no clues.

Thank you for any hints,
Sven.


From radhakrishnan.mohan at gmail.com  Tue Sep 30 12:23:25 2014
From: radhakrishnan.mohan at gmail.com (Mohan Radhakrishnan)
Date: Tue, 30 Sep 2014 15:53:25 +0530
Subject: [R] [rJava] RJavaClassLoader and system classloader
In-Reply-To: <A7A9DDD1-65BE-45EA-9BD1-EEC43738D9BC@artenum.com>
References: <A7A9DDD1-65BE-45EA-9BD1-EEC43738D9BC@artenum.com>
Message-ID: <CAOoXFP_AjKVYMSRrAiw45S1Qwkm+C91VkKdO46u0rNW80NJd_w@mail.gmail.com>

Hi,
         You could ask the author or post an issue here .(
https://github.com/s-u/rJava)
I had faced a problem and I got a response from him.

In my case I am streaming JVM data and this(
http://www.openanalytics.eu/r-service-bus) may be a better idea. I haven't
still tried this.

Thanks,
Mohan

On Fri, Sep 26, 2014 at 5:25 PM, Beno?t Thi?bault <thiebault at artenum.com>
wrote:

> Hi everyone,
>
> I want to call a Java application from R and have encountered some
> problems with the way rJava deals with the system class loader.
>
> To run my application, I use the following R script:
>
> > library(rJava)
> > .jinit()
> > .jaddClassPath("myApp.jar")
> > rWrapper <- .jnew("org/test/RWrapper")
> > .jcall(rWrapper,"V","start")
>
> My Java application has a plugins loading mechanism that uses a specific
> PluginClassLoader to load plugins stored in additional JAR files (e.g.
> plugin.jar). This PluginClassLoader is programed so that it knows and loads
> the plugins JARs. As any Java classloader, it is a child of the system
> class loader.
>
> Finally, plugins not only use classes stored in their plugin.jar file,
> they also depend on classes contained in the main myApp.jar file (the
> Plugin interface is for example defined in the myApp.far)
>
> In a pure Java environment, myApp.jar is known from the system class
> loader (it is in the classpath) and thus the PluginClassLoader can load
> classes from the plugin (it knows both about the plugin.jar and the
> myApp.jar files)
>
> In the R context however, using the above script, its the RJavaClassLoader
> that knows about the myApp.jar file. The org.test.RWrapper class is
> instatiated by the RJavaClassLoader. The system class loader however does
> not know about myApp.jar anymore. Neither does the PluginClassLoader. So
> when the PluginClassLoader loads a plugin class, it can only load classes
> that are in the plugin.jar file and as soon as a class from the myApp.jar
> file is required by the plugin, it crashes with a
> java.lang.NoClassDefFoundError message.
>
> My question is: how can I force rJava to load the classpath in the system
> classloader and not only in the RJavaClassLoader?
>
> I cannot make the PluginClassLoader know the RJavaClassLoader as my
> application also has to run in a non-R environment.
>
> Thanks for your time,
>
> Kind regards,
>
> Ben
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marco.helbich at gmx.at  Tue Sep 30 12:33:11 2014
From: marco.helbich at gmx.at (Marco Helbich)
Date: Tue, 30 Sep 2014 12:33:11 +0200
Subject: [R] coplot: extract regression output
Message-ID: <542A86E7.6060001@gmx.at>

Dear list,

I would like to extract the model details (coefficients, p-values etc.) 
for the regression lines within a coplot. How are these results 
accessible? A code example is as follows:

dat <- data.frame(a=rnorm(111), b=rnorm(111), c=rnorm(111))
coplot(dat$a ~ dat$b | dat$c, data=dat,
cex=1, number=3, columns=3, col="black", pch=16, overlap = 0.1,
panel=function(x,y,...) {
points(x,y,pch=16)
panel.smooth(x,y,span=.8,iter=5,...)
abline(lm(y ~ x), col="blue")} )

Thank you.
Marco


From murdoch.duncan at gmail.com  Tue Sep 30 13:32:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 30 Sep 2014 07:32:12 -0400
Subject: [R] Obtain 00Index.html
In-Reply-To: <CAHuTOvq2Q6MpEGBXoLqWEv9ck9xVv6fyRQNbodjG9Em82=HtAQ@mail.gmail.com>
References: <CAHuTOvq2Q6MpEGBXoLqWEv9ck9xVv6fyRQNbodjG9Em82=HtAQ@mail.gmail.com>
Message-ID: <542A94BC.8000507@gmail.com>

On 30/09/2014, 5:41 AM, Sven E. Templer wrote:
> Hello,
> 
> how can I open (by an R command) the index page in html mode, as obtained by:
> 
> options(browser="firefox") # or any other
> options(help_type="html")
> ?help
> # and then following the html reference on the page bottom named "Index"
> 
> In text mode I know library(help='utils') to open the utils package
> index (as in the example above). Setting options(text_mode="html") and
> options(browser="firefox") does not affect this behaviour. Also in
> ?help.start and ?help (or ?"?") I found no clues.
> 

There is no built-in function that opens that page.  If you want to
write one, the URL is

http://127.0.0.1:XXXXXX/library/PPPPPP/html/00Index.html

where

  -- XXXXXX is the port being used for the help system, available via
tools:::httpdPort.  (If that is 0, call tools::startDynamicHelp() to
start it up.)

  -- PPPPPP is the name of the package whose index you want.

You can look through the tools:::httpd function for other patterns.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Tue Sep 30 13:46:58 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 Sep 2014 12:46:58 +0100
Subject: [R] ..nlme: start values necessary even though using self-start
 function?..
In-Reply-To: <CAFOoapLXwvKmPjnnmmRC=Qqvb9xz62ss5sfVWj7Qgm5Da-bM4A@mail.gmail.com>
References: <CAFOoapLXwvKmPjnnmmRC=Qqvb9xz62ss5sfVWj7Qgm5Da-bM4A@mail.gmail.com>
Message-ID: <542A9832.3030303@stats.ox.ac.uk>

This seems to be a bug in the package.  Maybe the code was written for 
S, or maybe R has changed in the many years since the former maintainer 
decided to be unhelpful.

I'll put this on the list for the next release.


On 30/09/2014 09:13, Matthias Kuhn wrote:
> Dear list.
>
> I am stuck with an "subscript out of bounds" error when I play with an
> nlme-example from the yellow Pinheiro/Bates book. It is about using
> nlme() using the formula interface for non-linear mixed models.
>
> The following code snippet is inspired by the book (in section 8.2),
> using the Orange-example data from R datasets containing repeated
> measures of trunk circumferences over time for 5 trees. It is a
> nfnGroupedData with structure circumference ~ age | Tree.
>
>
> nlme( circumference ~ SSlogis(age, Asym, xmid, scal), data=Orange,
>                        fixed= Asym + xmid + scal ~ 1)
>
> It results in the following error:
> Error in nlme.formula(circumference ~ SSlogis(age, Asym, xmid, scal),  :
>    subscript out of bounds
>
> Specifiying the grouping as in groups=~Tree does not help, either.
>
> When I do provide start values, it works, though.
>
> nlme( circumference ~ SSlogis(age, Asym, xmid, scal), data=Orange,
>                        start=c(Asym = 200, xmid=725, scal=350),
>                        fixed= Asym + xmid + scal ~ 1)
>
> Beginning of result output:
>
> Nonlinear mixed-effects model fit by maximum likelihood
> Model: circumference ~ SSlogis(age, Asym, xmid, scal)
> Data: Orange
> Log-likelihood: -129.9907
> Fixed: Asym + xmid + scal ~ 1
>      Asym     xmid     scal
> 192.0959 727.5887 356.6011
> ...
>
>
>
> SSlogis() is a selfStart object and should be able to get its own
> starting values like so:
> getInitial(circumference ~ SSlogis(age, Asym, xmid, scal), data=Orange)
>
>
> So start= argument should not be necessary.
> What am I missing here? Any ideas?
>
> Thanks in advance..
>
> -m
>
>
>
> ps> This is my setting:
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] nlme_3.1-117 devtools_1.5
>
> loaded via a namespace (and not attached):
>   [1] digest_0.6.4    evaluate_0.5.5  grid_3.1.1      httr_0.5
> lattice_0.20-29 memoise_0.2.1   parallel_3.1.1  RCurl_1.95-4.3
> stringr_0.6.2   tools_3.1.1     whisker_0.3-2
>
>
>
> And regarding my nlme-package from CRAN:
>
> Information on package ?nlme?
>
>
> Description:
>
>
> Package:            nlme
>
> Version:            3.1-117
>
> Date:               2014-03-31
>
> Priority:           recommended
>
> Title:              Linear and Nonlinear Mixed Effects Models
>
> Authors at R:          c(person("Jos?", "Pinheiro", role = "aut", comment
> = "S version"), person("Douglas", "Bates", role = "aut", comment = "up
> to 2007"), person("Saikat", "DebRoy", role = "ctb", comment = "up
>                to 2002"), person("Deepayan", "Sarkar", role = "ctb",
> comment = "up to 2005"), person("EISPACK authors", role = "ctb",
> comment = "src/rs.f"), person("R-core", email =
>
>                      "R-core at R-project.org", role = c("aut", "cre")))
>
> Description:        Fit and compare Gaussian linear and nonlinear
> mixed-effects models.
>
> Depends:            graphics, stats, R (>= 3.0.0)
>
> Imports:            lattice
>
> Suggests:           Hmisc, MASS
>
> LazyData:           yes
>
> ByteCompile:        yes
>
> Encoding:           UTF-8
>
> License:            GPL (>= 2)
>
> BugReports:         http://bugs.r-project.org
>
> Packaged:           2014-03-31 07:56:40 UTC; ripley
>
> Author:             Jos? Pinheiro [aut] (S version), Douglas Bates
> [aut] (up to 2007), Saikat DebRoy [ctb] (up to 2002), Deepayan Sarkar
> [ctb] (up to 2005), EISPACK authors [ctb] (src/rs.f), R-core [aut,
>
>                      cre]
>
> Maintainer:         R-core <R-core at R-project.org>
>
> NeedsCompilation:   yes
>
> Repository:         CRAN
>
> Date/Publication:   2014-03-31 10:16:43
>
> Built:              R 3.1.1; x86_64-apple-darwin13.1.0; 2014-07-11
> 12:37:41 UTC; unix
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From f_j_rod at hotmail.com  Tue Sep 30 14:54:53 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Tue, 30 Sep 2014 14:54:53 +0200
Subject: [R] Loop does not work: Error in else statement (II)
Message-ID: <BAY168-W58D5D19C3A6387D8BDF85BBABB0@phx.gbl>

 

Hi to all members of R list,

 

I?m working with data.table package, and with 6
variables:

 

ID: Subject identifier

born: Birthdate

start: Starting date 

register: date of measurement 

value: Value of measurement

end: date of expiration of the measurements.

 

So, the natural order of date variables would be: born
=< start =< register =< end. As an example, I have:

 

DT <- data.table(ID =
as.factor(rep(1:4,each=2)), 

      born=as.Date(rep(c("1955-02-20","1990-07-25","1972-03-18",
"1988-05-03"),each=2)),

      start=as.Date(rep(c("1953-03-28","1990-07-01","1983-09-05","1988-07-18"),each=2)),

      register = as.Date(c("1955-08-11",
"1958-03-28", "1990-07-09", "1992-07-01", 

                  "1983-09-05", "2002-09-28",
"1992-07-10", "1993-03-12")),

      value=c(205, 346, 34, 76, 320, 148, 209, 274),

      end=as.Date(rep(c("1960-11-05",
"1997-10-15", "2002-09-27",
"1997-03-02"),each=2)))

 

I would want to make 3 operations:

a)      Remove
entire ID?s where start is previous to born date (excepting those subjects
whose month and year values are the same in ?start? and ?born? variables: I
assign ?born? date to ?start? date in these cases).

b)      Remove
only specific rows (not all ID) where ?register? is previous to ?start?.

c)       Remove
only specific rows (not all ID) where ?end? is previous to ?register?.

 

DT[ , 

  {


   
if (all(born > start))  

   
{

   
indx <- which(paste(year(born))==paste(year(start)) &  paste(month(born))==paste(month(start))) 

   
result <- list(born=born[indx],start=born[indx],register=register[indx],

value=value[indx], end=end[indx]) 

   
}  

     
if (all(register > start) | all(end > register))

      {

     
      indx <- which((register
> start) | (end > register))

     
      result <-
list(born=born[indx],start=start[indx], register=register[indx], 

value=value[indx], end=end[indx]) 

}

      else

      {

      
     NULL

     
      }

  else

   
{

   
indx <- which(all(register > start) | all(end > register))

   
result <- list(born=born[indx], start=start[indx],
register=register[indx], 

value=value[indx], end=end[indx]) 

    
}

  
result

  
}, by=ID]

 

Error: unexpected 'else' in:

"      }

  else"

 

 		 	   		  
	[[alternative HTML version deleted]]


From f_j_rod at hotmail.com  Tue Sep 30 15:00:01 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Tue, 30 Sep 2014 15:00:01 +0200
Subject: [R] Loop does not work: Error in else statement
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE85F0@SRVEXCHMBX.precheza.cz>
References: <BAY168-W1276E960BB649734656151FBABA0@phx.gbl>,
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE85F0@SRVEXCHMBX.precheza.cz>
Message-ID: <BAY168-W39854D46903E0D53D8B644BABB0@phx.gbl>

Dear Berend and Petr,
 
I do apologise for the disorderly code I posted. I have tried to solve it in a new mail.
 
Frank S. 
 		 	   		  
	[[alternative HTML version deleted]]


From thiebault at artenum.com  Tue Sep 30 15:01:30 2014
From: thiebault at artenum.com (=?iso-8859-1?Q?Beno=EEt_Thi=E9bault?=)
Date: Tue, 30 Sep 2014 15:01:30 +0200
Subject: [R] [rJava] RJavaClassLoader and system classloader
In-Reply-To: <CAOoXFP_AjKVYMSRrAiw45S1Qwkm+C91VkKdO46u0rNW80NJd_w@mail.gmail.com>
References: <A7A9DDD1-65BE-45EA-9BD1-EEC43738D9BC@artenum.com>
	<CAOoXFP_AjKVYMSRrAiw45S1Qwkm+C91VkKdO46u0rNW80NJd_w@mail.gmail.com>
Message-ID: <A837F674-A39A-4169-8DDE-9172025AE167@artenum.com>

Thank you very much for your answer. I will look further into R Service Bus.

In the meantime, I have posted an issue on GitHub https://github.com/s-u/rJava/issues/32 where I describe a way to reproduce the unexpected behaviour.

Kind regards,

Ben

Le 30 sept. 2014 ? 12:23, Mohan Radhakrishnan <radhakrishnan.mohan at gmail.com> a ?crit :

> Hi,
>          You could ask the author or post an issue here .(https://github.com/s-u/rJava)
> I had faced a problem and I got a response from him.
> 
> In my case I am streaming JVM data and this(http://www.openanalytics.eu/r-service-bus) may be a better idea. I haven't still tried this.
> 
> Thanks,
> Mohan
> 
> On Fri, Sep 26, 2014 at 5:25 PM, Beno?t Thi?bault <thiebault at artenum.com> wrote:
> Hi everyone,
> 
> I want to call a Java application from R and have encountered some problems with the way rJava deals with the system class loader.
> 
> To run my application, I use the following R script:
> 
> > library(rJava)
> > .jinit()
> > .jaddClassPath("myApp.jar")
> > rWrapper <- .jnew("org/test/RWrapper")
> > .jcall(rWrapper,"V","start")
> 
> My Java application has a plugins loading mechanism that uses a specific PluginClassLoader to load plugins stored in additional JAR files (e.g. plugin.jar). This PluginClassLoader is programed so that it knows and loads the plugins JARs. As any Java classloader, it is a child of the system class loader.
> 
> Finally, plugins not only use classes stored in their plugin.jar file, they also depend on classes contained in the main myApp.jar file (the Plugin interface is for example defined in the myApp.far)
> 
> In a pure Java environment, myApp.jar is known from the system class loader (it is in the classpath) and thus the PluginClassLoader can load classes from the plugin (it knows both about the plugin.jar and the myApp.jar files)
> 
> In the R context however, using the above script, its the RJavaClassLoader that knows about the myApp.jar file. The org.test.RWrapper class is instatiated by the RJavaClassLoader. The system class loader however does not know about myApp.jar anymore. Neither does the PluginClassLoader. So when the PluginClassLoader loads a plugin class, it can only load classes that are in the plugin.jar file and as soon as a class from the myApp.jar file is required by the plugin, it crashes with a java.lang.NoClassDefFoundError message.
> 
> My question is: how can I force rJava to load the classpath in the system classloader and not only in the RJavaClassLoader?
> 
> I cannot make the PluginClassLoader know the RJavaClassLoader as my application also has to run in a non-R environment.
> 
> Thanks for your time,
> 
> Kind regards,
> 
> Ben
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Beno?t Thi?bault
Project Manager

  Artenum Toulouse - Science & Groupware
  http://www.artenum.com

      B?timent Calfocenter
      10, rue Marguerite-Long
      31320 Castanet-Tolosan
      France
      Phone: +33 (0)5 82 95 19 00



	[[alternative HTML version deleted]]


From Michael.Laviolette at dhhs.state.nh.us  Tue Sep 30 15:17:28 2014
From: Michael.Laviolette at dhhs.state.nh.us (Michael.Laviolette at dhhs.state.nh.us)
Date: Tue, 30 Sep 2014 09:17:28 -0400
Subject: [R] Using "survey" package with ACS PUMS
Message-ID: <OF472B4806.88FE696E-ON85257D62.004FEC5A-85257D63.004902A6@dhhs.state.nh.us>


I'm trying to reproduce some results from the American Community Survey
PUMS data using the "survey" package. I'm using the one-year 2012 estimates
for New Hampshire
(http://www2.census.gov/acs2012_1yr/pums/csv_pnh.zip) and comparing to the
estimates for user verification from
http://www.census.gov/acs/www/Downloads/data_documentation/pums/Estimates/pums_estimates_12.csv

Once the age groups are set up as specified in the verification estimates,
the following SAS code produces the correct estimated totals with standard
errors:

proc surveyfreq data = acs2012 varmethod = jackknife;
  weight pwgtp;
  repweights pwgtp1 -- pwgtp80 / jkcoefs = 0.05;
  table SEX agegroup;
run;

I've not been successful in reproducing the standard errors with R,
although they are very close. My code follows; what revisions do I need to
make?

Thanks,
Mike L.

# load estimates for verification
pums_est <- read.csv("pums_estimates_12.csv")
pums_est[,4] <- as.integer(gsub(",", "", pums_est[,4]))

# load PUMS data
pums_p <- read.csv("ss12pnh.csv")
# convert sex and age group to factors
pums_p$SEX <- factor(pums_p$SEX, labels = c("M","F"))
pums_p$agegrp <- cut(pums_p$AGEP,
                     c(0,5,10,15,20,25,35,45,55,60,65,75,85,100),
                     right = FALSE)

# create replicate-weight survey object
library(survey)
pums_p.rep <- svrepdesign(repweights = pums_p[207:286],
                          weights = pums_p[,7],
                          combined.weights = TRUE,
                          type = "Fay", rho = 1 - 1/sqrt(4),
                          scale = 1, rscales = 1,
                          data = pums_p)

# using type "JK1" with scale = 4/80 and rscales = rep(1,80)
#   seems to produce the same results

# total population by sex with SE's
by.sex <- svyby(~SEX, ~ST, pums_p.rep, svytotal, na.rm = TRUE)
round(by.sex[1,4:5])
#     se1  se2
# 33 1606 1606
# compare results with Census
pums_est[966:967, 5]
#[1] 1610 1610

# total population by age group with SE's
by.agegrp <- svyby(~agegrp, ~ST, pums_p.rep, svytotal, na.rm = TRUE)
round((by.agegrp)[15:27])
#       se1  se2  se3  se4  se5  se6  se7  se8  se9 se10 se11 se12 se13
#    33 874 2571 2613 1463 1398 1475 1492 1552 2191 2200  880 1700 1678
# compare results with Census
pums_est[968:980, 5]
#  [1]  874 2578 2613 1463 1399 1476 1493 1555 2191 2200  880 1702 1684


From ajdamico at gmail.com  Tue Sep 30 15:29:42 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 30 Sep 2014 09:29:42 -0400
Subject: [R] Using "survey" package with ACS PUMS
In-Reply-To: <OF472B4806.88FE696E-ON85257D62.004FEC5A-85257D63.004902A6@dhhs.state.nh.us>
References: <OF472B4806.88FE696E-ON85257D62.004FEC5A-85257D63.004902A6@dhhs.state.nh.us>
Message-ID: <CAOwvMDyUmWiUo2WUWqzu_Hnhhxm=NSejKbyNtP0CKSp-_JGdAw@mail.gmail.com>

hi michael, you probably need

options( "survey.replicates.mse" = TRUE )


i also think you don't want type = "Fay" and you do want scale = 4/80 and
rscales = rep( 1 , 80 )  as well, but what you have might be equivalent
(not sure)


regardless, this blog post details how to precisely replicate the census
bureau's estimates using the acs pums with R

http://www.asdfree.com/search/label/american%20community%20survey%20%28acs%29









On Tue, Sep 30, 2014 at 9:17 AM, <Michael.Laviolette at dhhs.state.nh.us>
wrote:

>
> I'm trying to reproduce some results from the American Community Survey
> PUMS data using the "survey" package. I'm using the one-year 2012 estimates
> for New Hampshire
> (http://www2.census.gov/acs2012_1yr/pums/csv_pnh.zip) and comparing to the
> estimates for user verification from
>
> http://www.census.gov/acs/www/Downloads/data_documentation/pums/Estimates/pums_estimates_12.csv
>
> Once the age groups are set up as specified in the verification estimates,
> the following SAS code produces the correct estimated totals with standard
> errors:
>
> proc surveyfreq data = acs2012 varmethod = jackknife;
>   weight pwgtp;
>   repweights pwgtp1 -- pwgtp80 / jkcoefs = 0.05;
>   table SEX agegroup;
> run;
>
> I've not been successful in reproducing the standard errors with R,
> although they are very close. My code follows; what revisions do I need to
> make?
>
> Thanks,
> Mike L.
>
> # load estimates for verification
> pums_est <- read.csv("pums_estimates_12.csv")
> pums_est[,4] <- as.integer(gsub(",", "", pums_est[,4]))
>
> # load PUMS data
> pums_p <- read.csv("ss12pnh.csv")
> # convert sex and age group to factors
> pums_p$SEX <- factor(pums_p$SEX, labels = c("M","F"))
> pums_p$agegrp <- cut(pums_p$AGEP,
>                      c(0,5,10,15,20,25,35,45,55,60,65,75,85,100),
>                      right = FALSE)
>
> # create replicate-weight survey object
> library(survey)
> pums_p.rep <- svrepdesign(repweights = pums_p[207:286],
>                           weights = pums_p[,7],
>                           combined.weights = TRUE,
>                           type = "Fay", rho = 1 - 1/sqrt(4),
>                           scale = 1, rscales = 1,
>                           data = pums_p)
>
> # using type "JK1" with scale = 4/80 and rscales = rep(1,80)
> #   seems to produce the same results
>
> # total population by sex with SE's
> by.sex <- svyby(~SEX, ~ST, pums_p.rep, svytotal, na.rm = TRUE)
> round(by.sex[1,4:5])
> #     se1  se2
> # 33 1606 1606
> # compare results with Census
> pums_est[966:967, 5]
> #[1] 1610 1610
>
> # total population by age group with SE's
> by.agegrp <- svyby(~agegrp, ~ST, pums_p.rep, svytotal, na.rm = TRUE)
> round((by.agegrp)[15:27])
> #       se1  se2  se3  se4  se5  se6  se7  se8  se9 se10 se11 se12 se13
> #    33 874 2571 2613 1463 1398 1475 1492 1552 2191 2200  880 1700 1678
> # compare results with Census
> pums_est[968:980, 5]
> #  [1]  874 2578 2613 1463 1399 1476 1493 1555 2191 2200  880 1702 1684
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Michael.Laviolette at dhhs.state.nh.us  Tue Sep 30 15:51:11 2014
From: Michael.Laviolette at dhhs.state.nh.us (Michael.Laviolette at dhhs.state.nh.us)
Date: Tue, 30 Sep 2014 09:51:11 -0400
Subject: [R] Using "survey" package with ACS PUMS
In-Reply-To: <CAOwvMDyUmWiUo2WUWqzu_Hnhhxm=NSejKbyNtP0CKSp-_JGdAw@mail.gmail.com>
References: <OF472B4806.88FE696E-ON85257D62.004FEC5A-85257D63.004902A6@dhhs.state.nh.us>
	<CAOwvMDyUmWiUo2WUWqzu_Hnhhxm=NSejKbyNtP0CKSp-_JGdAw@mail.gmail.com>
Message-ID: <OFAB484ED6.6CC21509-ON85257D63.004BC38C-85257D63.004C18EC@dhhs.state.nh.us>

Setting the options did the trick. The code using "Fay" came from another
post, but this works:

options( "survey.replicates.mse" = TRUE)
pums_p.rep <- svrepdesign(repweights = pums_p[207:286],
                          weights = ~PWGTP,
                          combined.weights = TRUE,
                          type = "JK1",
                          scale = 4/80, rscales = rep(1, 80),
                          data = pums_p)

Thanks!
Mike L.


hi michael, you probably need

options( "survey.replicates.mse" = TRUE )


i also think you don't want type = "Fay" and you do want scale = 4/80 and
rscales = rep( 1 , 80 )? as well, but what you have might be equivalent
(not sure)


regardless, this blog post details how to precisely replicate the census
bureau's estimates using the acs pums with R

http://www.asdfree.com/search/label/american%20community%20survey%20%28acs%29




On Tue, Sep 30, 2014 at 9:17 AM, <Michael.Laviolette at dhhs.state.nh.us>
wrote:

  I'm trying to reproduce some results from the American Community Survey
  PUMS data using the "survey" package. I'm using the one-year 2012
  estimates
  for New Hampshire
  (http://www2.census.gov/acs2012_1yr/pums/csv_pnh.zip) and comparing to
  the
  estimates for user verification from
  http://www.census.gov/acs/www/Downloads/data_documentation/pums/Estimates/pums_estimates_12.csv


  Once the age groups are set up as specified in the verification
  estimates,
  the following SAS code produces the correct estimated totals with
  standard
  errors:

  proc surveyfreq data = acs2012 varmethod = jackknife;
  ? weight pwgtp;
  ? repweights pwgtp1 -- pwgtp80 / jkcoefs = 0.05;
  ? table SEX agegroup;
  run;

  I've not been successful in reproducing the standard errors with R,
  although they are very close. My code follows; what revisions do I need
  to
  make?

  Thanks,
  Mike L.

  # load estimates for verification
  pums_est <- read.csv("pums_estimates_12.csv")
  pums_est[,4] <- as.integer(gsub(",", "", pums_est[,4]))

  # load PUMS data
  pums_p <- read.csv("ss12pnh.csv")
  # convert sex and age group to factors
  pums_p$SEX <- factor(pums_p$SEX, labels = c("M","F"))
  pums_p$agegrp <- cut(pums_p$AGEP,
  ? ? ? ? ? ? ? ? ? ? ?c(0,5,10,15,20,25,35,45,55,60,65,75,85,100),
  ? ? ? ? ? ? ? ? ? ? ?right = FALSE)

  # create replicate-weight survey object
  library(survey)
  pums_p.rep <- svrepdesign(repweights = pums_p[207:286],
  ? ? ? ? ? ? ? ? ? ? ? ? ? weights = pums_p[,7],
  ? ? ? ? ? ? ? ? ? ? ? ? ? combined.weights = TRUE,
  ? ? ? ? ? ? ? ? ? ? ? ? ? type = "Fay", rho = 1 - 1/sqrt(4),
  ? ? ? ? ? ? ? ? ? ? ? ? ? scale = 1, rscales = 1,
  ? ? ? ? ? ? ? ? ? ? ? ? ? data = pums_p)

  # using type "JK1" with scale = 4/80 and rscales = rep(1,80)
  #? ?seems to produce the same results

  # total population by sex with SE's
  by.sex <- svyby(~SEX, ~ST, pums_p.rep, svytotal, na.rm = TRUE)
  round(by.sex[1,4:5])
  #? ? ?se1? se2
  # 33 1606 1606
  # compare results with Census
  pums_est[966:967, 5]
  #[1] 1610 1610

  # total population by age group with SE's
  by.agegrp <- svyby(~agegrp, ~ST, pums_p.rep, svytotal, na.rm = TRUE)
  round((by.agegrp)[15:27])
  #? ? ? ?se1? se2? se3? se4? se5? se6? se7? se8? se9 se10 se11 se12 se13
  #? ? 33 874 2571 2613 1463 1398 1475 1492 1552 2191 2200? 880 1700 1678
  # compare results with Census
  pums_est[968:980, 5]
  #? [1]? 874 2578 2613 1463 1399 1476 1493 1555 2191 2200? 880 1702 1684




From shivaliit05 at gmail.com  Tue Sep 30 13:58:43 2014
From: shivaliit05 at gmail.com (shivali gangwar)
Date: Tue, 30 Sep 2014 17:28:43 +0530
Subject: [R] Regarding R package spatstat
Message-ID: <CAG5d0=--HP=YdXX=BErTRTg20hsVSF7noP8OHWB8_sA1+Za9xg@mail.gmail.com>

Hi ,

I am installing a R Package as following -
 R CMD INSTALL spatstat_1.26-0.tar.gz

It seems my installation hangs at

 "byte-compile and prepare package for lazy loading"
I kept on waiting for 1/2anhr but it hanged at below stage.
Please help.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Target "all" is up to date.
installing to
/gpfs1/home/shivali/R-3.1.0/R-3.1.0/lib/R/library/spatstat/libs
** R
** data
*** moving datasets to lazyload DB
** demo
** inst
** byte-compile and prepare package for lazy loading

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~````

[ncmr0202][/gpfs1/home/shivali]> ps -ef | grep R-3.1.0
 shivali 438938 446478   0 17:23:40  pts/9  0:00 grep R-3.1.0
 shivali 635448 381678   0 17:12:03 pts/14  0:00 sh
/gpfs1/home/shivali/R-3.1.0/R-3.1.0/lib/R/bin/Rcmd INSTALL
spatstat_1.26-0.tar.gz
 shivali 316220 635448 118 17:12:04 pts/14 10:58
/gpfs1/home/shivali/R-3.1.0/R-3.1.0/lib/R/bin/exec/R --args --args --args
nextArgspatstat_1.26-0.tar.gz
 shivali 344832      1 118 16:23:05 pts/14 60:26
/gpfs1/home/shivali/R-3.1.0/R-3.1.0/lib/R/bin/exec/R --args --args --args
nextArgSpatialVx_0.2-1.tar.gz
[ncmr0202][/gpfs1/home/shivali]>


Regards,
Shivali Gangwar

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Sep 30 17:01:47 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 30 Sep 2014 15:01:47 +0000
Subject: [R] Loop does not work: Error in else statement (II)
In-Reply-To: <BAY168-W58D5D19C3A6387D8BDF85BBABB0@phx.gbl>
References: <BAY168-W58D5D19C3A6387D8BDF85BBABB0@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8782@SRVEXCHMBX.precheza.cz>

Hi

Slightly better but still html scrambled.

see in line

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Frank S.
> Sent: Tuesday, September 30, 2014 2:55 PM
> To: r-help at r-project.org
> Subject: [R] Loop does not work: Error in else statement (II)
>
>
>
> Hi to all members of R list,
>
>
>
> I m working with data.table package, and with 6
> variables:
>
>
>
> ID: Subject identifier
>
> born: Birthdate
>
> start: Starting date
>
> register: date of measurement
>
> value: Value of measurement
>
> end: date of expiration of the measurements.
>
>
>
> So, the natural order of date variables would be: born =< start =<
> register =< end. As an example, I have:
>
>
>
> DT <- data.table(ID =
> as.factor(rep(1:4,each=2)),
>
>       born=as.Date(rep(c("1955-02-20","1990-07-25","1972-03-18",
> "1988-05-03"),each=2)),
>
>       start=as.Date(rep(c("1953-03-28","1990-07-01","1983-09-05","1988-
> 07-18"),each=2)),
>
>       register = as.Date(c("1955-08-11", "1958-03-28", "1990-07-09",
> "1992-07-01",
>
>                   "1983-09-05", "2002-09-28", "1992-07-10", "1993-03-
> 12")),
>
>       value=c(205, 346, 34, 76, 320, 148, 209, 274),
>
>       end=as.Date(rep(c("1960-11-05",
> "1997-10-15", "2002-09-27",
> "1997-03-02"),each=2)))
>
>
>
> I would want to make 3 operations:
>
> a)      Remove
> entire ID s where start is previous to born date (excepting those
> subjects whose month and year values are the same in  start  and  born
> variables: I assign  born  date to  start  date in these cases).

> DT$start-DT$born
Time differences in days
[1] -694 -694  -24  -24 4188 4188   76   76

suggests you can remove line 1 and 2 and check line 3 and 4

as.numeric(format(DT$start, "%Y.%m"))- as.numeric(format(DT$born, "%Y.%m"))

[1] -1.99 -1.99  0.00  0.00 11.06 11.06  0.02  0.02

so only lines 1 and 2 shall be removed

#first change born to start where appropriate
cond1 <- which((as.numeric(format(DT$start, "%Y.%m"))- as.numeric(format(DT$born, "%Y.%m")))==0)
DT$born[cond1] <- DT$start[cond1]

#then select rows for which start is earlier than born
cond2 <-((DT$start-DT$born)<0)

#remove rows
DT2<-DT[!cond2,]

If there are rows which does not hold for some ID it is trickier.

Hint
DT$ID[cond2]

>
> b)      Remove
> only specific rows (not all ID) where  register  is previous to  start

#select rows which hold your condition
cond3 <-((DT2$register-DT2$born)<0)
#no items does not result as TRUE but

#remove rows which are TRUE in cond3
DT2 <-DT2[!cond3,]


> .
>
> c)       Remove
> only specific rows (not all ID) where  end  is previous to  register .
>

the same principle applies here. You shall be able to do it yourself


No if, no else no loop, no error.

If there are NAs the solution would be slightly different but in principle similar.

Regards
Petr



>
>
> DT[ ,
>
>   {
>
>
>
> if (all(born > start))
>
>
> {
>
>
> indx <- which(paste(year(born))==paste(year(start)) &
> paste(month(born))==paste(month(start)))
>
>
> result <-
> list(born=born[indx],start=born[indx],register=register[indx],
>
> value=value[indx], end=end[indx])
>
>
> }
>
>
> if (all(register > start) | all(end > register))
>
>       {
>
>
>       indx <- which((register
> > start) | (end > register))
>
>
>       result <-
> list(born=born[indx],start=start[indx], register=register[indx],
>
> value=value[indx], end=end[indx])
>
> }
>
>       else
>
>       {
>
>
>      NULL
>
>
>       }
>
>   else
>
>
> {
>
>
> indx <- which(all(register > start) | all(end > register))
>
>
> result <- list(born=born[indx], start=start[indx],
> register=register[indx],
>
> value=value[indx], end=end[indx])
>
>
> }
>
>
> result
>
>
> }, by=ID]
>
>
>
> Error: unexpected 'else' in:
>
> "      }
>
>   else"
>
>
>
>
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From baccts at hotmail.com  Tue Sep 30 17:55:44 2014
From: baccts at hotmail.com (C Lin)
Date: Tue, 30 Sep 2014 11:55:44 -0400
Subject: [R] modify function in a package
In-Reply-To: <CA70B43E-E7D5-45C0-B04B-F468AA9C89F2@comcast.net>
References: <COL129-W23882AB8B804B8BD4E8992CBBE0@phx.gbl>,
	<CA70B43E-E7D5-45C0-B04B-F468AA9C89F2@comcast.net>
Message-ID: <COL129-W71535228579FB1AE55BCE8CBBB0@phx.gbl>

David, thank you for pointing me in the right direction!

For the record, I was able to override the NanoStringNorm function while still calling other functions in the package using the following:
source('my.nanostringnorm.R") # inside my.nanostringnorm.R, my modified function is called NanoStringNorm
assignInNamespace('NanoStringNorm',NanoStringNorm,ns='NanoStringNorm')
environment(NanoStringNorm)<-asNamespace('NanoStringNorm');

----------------------------------------
> Subject: Re: [R] modify function in a package
> From: dwinsemius at comcast.net
> Date: Thu, 25 Sep 2014 17:14:30 -0700
> CC: r-help at r-project.org
> To: baccts at hotmail.com
>
>
> On Sep 25, 2014, at 11:21 AM, C Lin wrote:
>
>> Dear R users,
>> There is a package called NanoStringNorm with a function called NanoStringNorm.
>> What I want to do is to change the NanoStringNorm function from the package with my own copy that is written in my.nanostringnorm.R.
>> But if I do the following:
>>
>> source('my.nanostringnorm.R")
>> unlockBinding("NanoStringNorm", as.environment("package:NanoStringNorm")) ;
>> assign("NanoStringNorm", NanoStringNorm, "package:NanoStringNorm") ;
>>
>> Although, it now correctly called my NanoStringNorm, it doesn't recognize a function called inside my NanoStringNorm that called another functions in the NanoStringNorm package.
>> So, I have to change all such functionswith NanoStringNorm:::function.name.
>> How should I replace the NanoStringNorm function but still able to call other function in the package?
>> I still have package NanoStringNorm in my search path but somehow it can't find the other function.
>
> Take a look at assignInNamespace. It's also possible to set the environment of a function:
>
> ?assignInNamespace
> ?`environment<-`
>
>
> --
> David Winsemius
> Alameda, CA, USA
>
 		 	   		  

From highstat at highstat.com  Tue Sep 30 18:39:25 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 30 Sep 2014 17:39:25 +0100
Subject: [R] Course Halifax: Introduction to Linear mixed effects models,
 GLMM and MCMC with R
Message-ID: <542ADCBD.2040608@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course:

Course:   Introduction to Linear mixed effects models,  GLMM and MCMC 
with R
Location: Halifax, Canada
Date:      19 - 23 January 2015
Remaining seats: 10

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2015_01Halifax.pdf


Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com


	[[alternative HTML version deleted]]


From yara_abuawad at yahoo.com  Tue Sep 30 18:04:44 2014
From: yara_abuawad at yahoo.com (Yara Abu Awad)
Date: Tue, 30 Sep 2014 09:04:44 -0700
Subject: [R] Issue with a function
In-Reply-To: <2142422D-B58F-4C22-893E-105B63254B4D@gmail.com>
References: <1412035410.69001.YahooMailNeo@web141405.mail.bf1.yahoo.com>
	<29EDF7D3-8CA3-4720-8F60-E5E4B676E68F@dcn.davis.CA.us>
	<2142422D-B58F-4C22-893E-105B63254B4D@gmail.com>
Message-ID: <1412093084.75761.YahooMailNeo@web141401.mail.bf1.yahoo.com>

Yes, thank you. I was able to resolve the issue using this code:
as.matrix(newX%*%Diagonal(length(beta), x=beta))




On Tuesday, September 30, 2014 3:38 AM, peter dalgaard <pdalgd at gmail.com> wrote:

On 30 Sep 2014, at 03:47 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> library(Matrix)
> result <- newX %*% Diagonal( unlist(beta) )

The code in Matrix does this efficiently, I hope?

Otherwise, sweep() is the traditional ticket:

result <- sweep(newX, 2, unlist(beta), "*")

Some of my students do

t(t(newX) * unlist(beta))

(utilizing recycling of beta) which I think looks horrible, but it does work. 

The problem with the original code is that the cbind() reallocates storage every time a column is added to the result. This can be alleviated by preallocating. Also note that the double for loop in





for (i in 1: ncol(newX)){
for (j in 1: length(beta)){
   Terms <- cbind (Terms,(newX[,i]*beta[j]))
}
}

generates 520*520 columns of pairwise products, which I presume was not the intention.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From geomodelers at gmail.com  Tue Sep 30 19:31:05 2014
From: geomodelers at gmail.com (Andre)
Date: Wed, 1 Oct 2014 00:31:05 +0700
Subject: [R] Inverse Student t-value
Message-ID: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>

Dear Sir/Madam,

I am trying to use calculation for two-tailed inverse of the student`s
t-distribution function presented by Excel functions like
=TINV(probability, deg_freedom).

For instance: The Excel function =TINV(0.0000408831,1221) =  returns
 4.0891672.

Would you like to show me a manual calculation for this?

Appreciate your helps in advance.


Cheers!  Andre

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Sep 30 20:01:11 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 30 Sep 2014 14:01:11 -0400
Subject: [R] Inverse Student t-value
In-Reply-To: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
Message-ID: <542AEFE7.4060601@gmail.com>

On 30/09/2014 1:31 PM, Andre wrote:
> Dear Sir/Madam,
>
> I am trying to use calculation for two-tailed inverse of the student`s
> t-distribution function presented by Excel functions like
> =TINV(probability, deg_freedom).
>
> For instance: The Excel function =TINV(0.0000408831,1221) =  returns
>   4.0891672.
>
> Would you like to show me a manual calculation for this?
>
> Appreciate your helps in advance.

That number looks pretty far off the true value.  Have you got a typo in 
your example?

You can compute the answer to your question as abs(qt(0.0000408831/2, 
df=1221)), but you'll get 4.117.

Duncan Murdoch


From murdoch.duncan at gmail.com  Tue Sep 30 20:20:39 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 30 Sep 2014 14:20:39 -0400
Subject: [R] Inverse Student t-value
In-Reply-To: <CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
Message-ID: <542AF477.9040603@gmail.com>

On 30/09/2014 2:11 PM, Andre wrote:
> Hi Duncan,
>
> No, that's correct. Actually, I have data set below;

Then it seems Excel is worse than I would have expected.  I confirmed 
R's value in two other pieces of software,
OpenOffice and some software I wrote a long time ago based on an 
algorithm published in 1977 in Applied Statistics.  (They are probably 
all using the same algorithm.  I wonder what Excel is doing?)

> N= 1223
> alpha= 0.05
>
> Then
> probability= 0.05/1223=0.0000408831
> degree of freedom= 1223-2= 1221
>
> So, TINV(0.0000408831,1221) returns 4.0891672
>
>
> Could you show me more detail a manual equation. I really appreciate 
> it if you may give more detail.

I already gave you the expression:  abs(qt(0.0000408831/2, df=1221)). 
For more detail, I suppose you could look at the help page for the qt 
function, using help("qt").

Duncan Murdoch

>
> Cheers!
>
>
> On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 30/09/2014 1:31 PM, Andre wrote:
>
>         Dear Sir/Madam,
>
>         I am trying to use calculation for two-tailed inverse of the
>         student`s
>         t-distribution function presented by Excel functions like
>         =TINV(probability, deg_freedom).
>
>         For instance: The Excel function =TINV(0.0000408831,1221) = 
>         returns
>           4.0891672.
>
>         Would you like to show me a manual calculation for this?
>
>         Appreciate your helps in advance.
>
>
>     That number looks pretty far off the true value.  Have you got a
>     typo in your example?
>
>     You can compute the answer to your question as
>     abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>
>     Duncan Murdoch
>
>
>


From Ted.Harding at wlandres.net  Tue Sep 30 20:35:50 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Tue, 30 Sep 2014 19:35:50 +0100 (BST)
Subject: [R] Inverse Student t-value
In-Reply-To: <542AF477.9040603@gmail.com>
Message-ID: <XFMail.20140930193550.Ted.Harding@wlandres.net>

And, with 1221 degrees of freedom, one cannot be far off a Normal
distribution. So:

  abs(qnorm(0.0000408831/2))
  [1] 4.102431

which is nearer to Duncan's answer (4.117, and a bit smaller, as it
should be) than to yours (4.0891672, which, if accurate, should
be greater than the Normal value 4.102431).

Ted.

On 30-Sep-2014 18:20:39 Duncan Murdoch wrote:
> On 30/09/2014 2:11 PM, Andre wrote:
>> Hi Duncan,
>>
>> No, that's correct. Actually, I have data set below;
> 
> Then it seems Excel is worse than I would have expected.  I confirmed 
> R's value in two other pieces of software,
> OpenOffice and some software I wrote a long time ago based on an 
> algorithm published in 1977 in Applied Statistics.  (They are probably 
> all using the same algorithm.  I wonder what Excel is doing?)
> 
>> N= 1223
>> alpha= 0.05
>>
>> Then
>> probability= 0.05/1223=0.0000408831
>> degree of freedom= 1223-2= 1221
>>
>> So, TINV(0.0000408831,1221) returns 4.0891672
>>
>>
>> Could you show me more detail a manual equation. I really appreciate 
>> it if you may give more detail.
> 
> I already gave you the expression:  abs(qt(0.0000408831/2, df=1221)). 
> For more detail, I suppose you could look at the help page for the qt 
> function, using help("qt").
> 
> Duncan Murdoch
> 
>>
>> Cheers!
>>
>>
>> On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch 
>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 30/09/2014 1:31 PM, Andre wrote:
>>
>>         Dear Sir/Madam,
>>
>>         I am trying to use calculation for two-tailed inverse of the
>>         student`s
>>         t-distribution function presented by Excel functions like
>>         =TINV(probability, deg_freedom).
>>
>>         For instance: The Excel function =TINV(0.0000408831,1221) = 
>>         returns
>>           4.0891672.
>>
>>         Would you like to show me a manual calculation for this?
>>
>>         Appreciate your helps in advance.
>>
>>
>>     That number looks pretty far off the true value.  Have you got a
>>     typo in your example?
>>
>>     You can compute the answer to your question as
>>     abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>>
>>     Duncan Murdoch
>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 30-Sep-2014  Time: 19:35:45
This message was sent by XFMail


From murdoch.duncan at gmail.com  Tue Sep 30 20:36:46 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 30 Sep 2014 14:36:46 -0400
Subject: [R] Inverse Student t-value
In-Reply-To: <CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>	<542AEFE7.4060601@gmail.com>	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
Message-ID: <542AF83E.40203@gmail.com>

On 30/09/2014 2:26 PM, Andre wrote:
> Hi Duncan,
>
> Actually, I am trying trace the formula for the "Critical value of Z" 
> and manual formula is 
> =(I7-1)/SQRT(I7)*SQRT((TINV(0.05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))
>
> So, I got new problem for TINV formula. I just need a manual equation 
> for TINV.

Sorry, can't help.  I'm not sure I understand what you want, but if it's 
a simple formula for quantiles of the t distribution, it doesn't exist.

Duncan Murdoch

>
> Hope solve this problem.
>
> Cheers!
>
>
> On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 30/09/2014 2:11 PM, Andre wrote:
>
>         Hi Duncan,
>
>         No, that's correct. Actually, I have data set below;
>
>
>     Then it seems Excel is worse than I would have expected.  I
>     confirmed R's value in two other pieces of software,
>     OpenOffice and some software I wrote a long time ago based on an
>     algorithm published in 1977 in Applied Statistics. (They are
>     probably all using the same algorithm.  I wonder what Excel is doing?)
>
>         N= 1223
>         alpha= 0.05
>
>         Then
>         probability= 0.05/1223=0.0000408831
>         degree of freedom= 1223-2= 1221
>
>         So, TINV(0.0000408831,1221) returns 4.0891672
>
>
>         Could you show me more detail a manual equation. I really
>         appreciate it if you may give more detail.
>
>
>     I already gave you the expression:  abs(qt(0.0000408831/2,
>     df=1221)). For more detail, I suppose you could look at the help
>     page for the qt function, using help("qt").
>
>     Duncan Murdoch
>
>
>         Cheers!
>
>
>         On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>         <mailto:murdoch.duncan at gmail.com
>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>
>             On 30/09/2014 1:31 PM, Andre wrote:
>
>                 Dear Sir/Madam,
>
>                 I am trying to use calculation for two-tailed inverse
>         of the
>                 student`s
>                 t-distribution function presented by Excel functions like
>                 =TINV(probability, deg_freedom).
>
>                 For instance: The Excel function
>         =TINV(0.0000408831,1221) =         returns
>                   4.0891672.
>
>                 Would you like to show me a manual calculation for this?
>
>                 Appreciate your helps in advance.
>
>
>             That number looks pretty far off the true value. Have you
>         got a
>             typo in your example?
>
>             You can compute the answer to your question as
>             abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>
>             Duncan Murdoch
>
>
>
>
>


From JLucke at ria.buffalo.edu  Tue Sep 30 20:49:10 2014
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Tue, 30 Sep 2014 14:49:10 -0400
Subject: [R] Inverse Student t-value
In-Reply-To: <542AF83E.40203@gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
	<542AF83E.40203@gmail.com>
Message-ID: <OF878A0A12.17B05669-ON85257D63.0066DA1D-85257D63.00676294@ria.buffalo.edu>

My Excel (2013) returns exactly what R does.   I used both T.INV and 
T.INV.T2    There is no TINV.  Has Excel been updated?





Duncan Murdoch <murdoch.duncan at gmail.com> 
Sent by: r-help-bounces at r-project.org
09/30/2014 02:36 PM

To
Andre <geomodelers at gmail.com>, 
cc
r-help at r-project.org
Subject
Re: [R] Inverse Student t-value






On 30/09/2014 2:26 PM, Andre wrote:
> Hi Duncan,
>
> Actually, I am trying trace the formula for the "Critical value of Z" 
> and manual formula is 
> =(I7-1)/SQRT(I7)*SQRT((TINV(0.05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))
>
> So, I got new problem for TINV formula. I just need a manual equation 
> for TINV.

Sorry, can't help.  I'm not sure I understand what you want, but if it's 
a simple formula for quantiles of the t distribution, it doesn't exist.

Duncan Murdoch

>
> Hope solve this problem.
>
> Cheers!
>
>
> On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 30/09/2014 2:11 PM, Andre wrote:
>
>         Hi Duncan,
>
>         No, that's correct. Actually, I have data set below;
>
>
>     Then it seems Excel is worse than I would have expected.  I
>     confirmed R's value in two other pieces of software,
>     OpenOffice and some software I wrote a long time ago based on an
>     algorithm published in 1977 in Applied Statistics. (They are
>     probably all using the same algorithm.  I wonder what Excel is 
doing?)
>
>         N= 1223
>         alpha= 0.05
>
>         Then
>         probability= 0.05/1223=0.0000408831
>         degree of freedom= 1223-2= 1221
>
>         So, TINV(0.0000408831,1221) returns 4.0891672
>
>
>         Could you show me more detail a manual equation. I really
>         appreciate it if you may give more detail.
>
>
>     I already gave you the expression:  abs(qt(0.0000408831/2,
>     df=1221)). For more detail, I suppose you could look at the help
>     page for the qt function, using help("qt").
>
>     Duncan Murdoch
>
>
>         Cheers!
>
>
>         On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>         <mailto:murdoch.duncan at gmail.com
>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>
>             On 30/09/2014 1:31 PM, Andre wrote:
>
>                 Dear Sir/Madam,
>
>                 I am trying to use calculation for two-tailed inverse
>         of the
>                 student`s
>                 t-distribution function presented by Excel functions 
like
>                 =TINV(probability, deg_freedom).
>
>                 For instance: The Excel function
>         =TINV(0.0000408831,1221) =         returns
>                   4.0891672.
>
>                 Would you like to show me a manual calculation for this?
>
>                 Appreciate your helps in advance.
>
>
>             That number looks pretty far off the true value. Have you
>         got a
>             typo in your example?
>
>             You can compute the answer to your question as
>             abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>
>             Duncan Murdoch
>
>
>
>
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Sep 30 20:59:03 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 30 Sep 2014 13:59:03 -0500
Subject: [R] Inverse Student t-value
In-Reply-To: <OF878A0A12.17B05669-ON85257D63.0066DA1D-85257D63.00676294@ria.buffalo.edu>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
	<542AF83E.40203@gmail.com>
	<OF878A0A12.17B05669-ON85257D63.0066DA1D-85257D63.00676294@ria.buffalo.edu>
Message-ID: <6B68F099-298A-4A8C-AF94-D624255E9A23@me.com>

FWIW, I get:

  4.117456652 in Excel 2011 on OS X

and:

  4.117457 in R 3.1.1 on OS X

There is a KB article on the TINV function here, suggesting that the threshold for the iterative algorithm in Excel has been tightened in recent versions:

  http://support.microsoft.com/kb/828340

Regards,

Marc Schwartz

On Sep 30, 2014, at 1:49 PM, JLucke at ria.buffalo.edu wrote:

> My Excel (2013) returns exactly what R does.   I used both T.INV and 
> T.INV.T2    There is no TINV.  Has Excel been updated?
> 
> 
> 
> 
> 
> Duncan Murdoch <murdoch.duncan at gmail.com> 
> Sent by: r-help-bounces at r-project.org
> 09/30/2014 02:36 PM
> 
> To
> Andre <geomodelers at gmail.com>, 
> cc
> r-help at r-project.org
> Subject
> Re: [R] Inverse Student t-value
> 
> 
> 
> 
> 
> 
> On 30/09/2014 2:26 PM, Andre wrote:
>> Hi Duncan,
>> 
>> Actually, I am trying trace the formula for the "Critical value of Z" 
>> and manual formula is 
>> =(I7-1)/SQRT(I7)*SQRT((TINV(0.05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))
>> 
>> So, I got new problem for TINV formula. I just need a manual equation 
>> for TINV.
> 
> Sorry, can't help.  I'm not sure I understand what you want, but if it's 
> a simple formula for quantiles of the t distribution, it doesn't exist.
> 
> Duncan Murdoch
> 
>> 
>> Hope solve this problem.
>> 
>> Cheers!
>> 
>> 
>> On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch 
>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>> 
>>    On 30/09/2014 2:11 PM, Andre wrote:
>> 
>>        Hi Duncan,
>> 
>>        No, that's correct. Actually, I have data set below;
>> 
>> 
>>    Then it seems Excel is worse than I would have expected.  I
>>    confirmed R's value in two other pieces of software,
>>    OpenOffice and some software I wrote a long time ago based on an
>>    algorithm published in 1977 in Applied Statistics. (They are
>>    probably all using the same algorithm.  I wonder what Excel is 
> doing?)
>> 
>>        N= 1223
>>        alpha= 0.05
>> 
>>        Then
>>        probability= 0.05/1223=0.0000408831
>>        degree of freedom= 1223-2= 1221
>> 
>>        So, TINV(0.0000408831,1221) returns 4.0891672
>> 
>> 
>>        Could you show me more detail a manual equation. I really
>>        appreciate it if you may give more detail.
>> 
>> 
>>    I already gave you the expression:  abs(qt(0.0000408831/2,
>>    df=1221)). For more detail, I suppose you could look at the help
>>    page for the qt function, using help("qt").
>> 
>>    Duncan Murdoch
>> 
>> 
>>        Cheers!
>> 
>> 
>>        On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
>>        <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>>        <mailto:murdoch.duncan at gmail.com
>>        <mailto:murdoch.duncan at gmail.com>>> wrote:
>> 
>>            On 30/09/2014 1:31 PM, Andre wrote:
>> 
>>                Dear Sir/Madam,
>> 
>>                I am trying to use calculation for two-tailed inverse
>>        of the
>>                student`s
>>                t-distribution function presented by Excel functions 
> like
>>                =TINV(probability, deg_freedom).
>> 
>>                For instance: The Excel function
>>        =TINV(0.0000408831,1221) =         returns
>>                  4.0891672.
>> 
>>                Would you like to show me a manual calculation for this?
>> 
>>                Appreciate your helps in advance.
>> 
>> 
>>            That number looks pretty far off the true value. Have you
>>        got a
>>            typo in your example?
>> 
>>            You can compute the answer to your question as
>>            abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>> 
>>            Duncan Murdoch
>> 
>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Tue Sep 30 21:04:50 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 30 Sep 2014 21:04:50 +0200
Subject: [R] Inverse Student t-value
In-Reply-To: <542AF83E.40203@gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>	<542AEFE7.4060601@gmail.com>	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
	<542AF83E.40203@gmail.com>
Message-ID: <00B847EA-7DC9-477E-8F85-8569078AEDAE@gmail.com>


On 30 Sep 2014, at 20:36 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

>> TINV(0.0000408831,1221)

Just for the record: The above _does_ give 

4.117456652

in Excel for Mac OS X.  

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From geomodelers at gmail.com  Tue Sep 30 20:11:46 2014
From: geomodelers at gmail.com (Andre)
Date: Wed, 1 Oct 2014 01:11:46 +0700
Subject: [R] Inverse Student t-value
In-Reply-To: <542AEFE7.4060601@gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
	<542AEFE7.4060601@gmail.com>
Message-ID: <CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>

Hi Duncan,

No, that's correct. Actually, I have data set below;
N= 1223
alpha= 0.05

Then
probability= 0.05/1223=0.0000408831
degree of freedom= 1223-2= 1221

So, TINV(0.0000408831,1221)  returns 4.0891672


Could you show me more detail a manual equation. I really appreciate it if
you may give more detail.

Cheers!


On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/09/2014 1:31 PM, Andre wrote:
>
>> Dear Sir/Madam,
>>
>> I am trying to use calculation for two-tailed inverse of the student`s
>> t-distribution function presented by Excel functions like
>> =TINV(probability, deg_freedom).
>>
>> For instance: The Excel function =TINV(0.0000408831,1221) =  returns
>>   4.0891672.
>>
>> Would you like to show me a manual calculation for this?
>>
>> Appreciate your helps in advance.
>>
>
> That number looks pretty far off the true value.  Have you got a typo in
> your example?
>
> You can compute the answer to your question as abs(qt(0.0000408831/2,
> df=1221)), but you'll get 4.117.
>
> Duncan Murdoch
>
>
>

	[[alternative HTML version deleted]]


From geomodelers at gmail.com  Tue Sep 30 20:26:37 2014
From: geomodelers at gmail.com (Andre)
Date: Wed, 1 Oct 2014 01:26:37 +0700
Subject: [R] Inverse Student t-value
In-Reply-To: <542AF477.9040603@gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
	<542AF477.9040603@gmail.com>
Message-ID: <CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>

Hi Duncan,

Actually, I am trying trace the formula for the "Critical value of Z" and
manual formula is
=(I7-1)/SQRT(I7)*SQRT((TINV(0.05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))

So, I got new problem for TINV formula. I just need a manual equation
for TINV.

Hope solve this problem.

Cheers!


On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/09/2014 2:11 PM, Andre wrote:
>
>> Hi Duncan,
>>
>> No, that's correct. Actually, I have data set below;
>>
>
> Then it seems Excel is worse than I would have expected.  I confirmed R's
> value in two other pieces of software,
> OpenOffice and some software I wrote a long time ago based on an algorithm
> published in 1977 in Applied Statistics.  (They are probably all using the
> same algorithm.  I wonder what Excel is doing?)
>
>  N= 1223
>> alpha= 0.05
>>
>> Then
>> probability= 0.05/1223=0.0000408831
>> degree of freedom= 1223-2= 1221
>>
>> So, TINV(0.0000408831,1221) returns 4.0891672
>>
>>
>> Could you show me more detail a manual equation. I really appreciate it
>> if you may give more detail.
>>
>
> I already gave you the expression:  abs(qt(0.0000408831/2, df=1221)). For
> more detail, I suppose you could look at the help page for the qt function,
> using help("qt").
>
> Duncan Murdoch
>
>
>> Cheers!
>>
>>
>> On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 30/09/2014 1:31 PM, Andre wrote:
>>
>>         Dear Sir/Madam,
>>
>>         I am trying to use calculation for two-tailed inverse of the
>>         student`s
>>         t-distribution function presented by Excel functions like
>>         =TINV(probability, deg_freedom).
>>
>>         For instance: The Excel function =TINV(0.0000408831,1221) =
>>    returns
>>           4.0891672.
>>
>>         Would you like to show me a manual calculation for this?
>>
>>         Appreciate your helps in advance.
>>
>>
>>     That number looks pretty far off the true value.  Have you got a
>>     typo in your example?
>>
>>     You can compute the answer to your question as
>>     abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>>
>>     Duncan Murdoch
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From geomodelers at gmail.com  Tue Sep 30 20:45:29 2014
From: geomodelers at gmail.com (Andre)
Date: Wed, 1 Oct 2014 01:45:29 +0700
Subject: [R] Inverse Student t-value
In-Reply-To: <542AF83E.40203@gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
	<542AF83E.40203@gmail.com>
Message-ID: <CALzoxKDOxpCYeWbwT-JAvKOMeZCzpXH1Av4ht4qk3spakOHg7A@mail.gmail.com>

Hi Duncan,

Let me explain again, I just need a manual expression for inverse student t
value.

You could go to web page
http://www.danielsoper.com/statcalc3/calc.aspx?id=10

That's inverse student t value calculator. Do you know a manual expression
use it.

Cheers!


On Wednesday, October 1, 2014, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/09/2014 2:26 PM, Andre wrote:
>
>> Hi Duncan,
>>
>> Actually, I am trying trace the formula for the "Critical value of Z" and
>> manual formula is =(I7-1)/SQRT(I7)*SQRT((TINV(0.
>> 05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))
>>
>> So, I got new problem for TINV formula. I just need a manual equation for
>> TINV.
>>
>
> Sorry, can't help.  I'm not sure I understand what you want, but if it's a
> simple formula for quantiles of the t distribution, it doesn't exist.
>
> Duncan Murdoch
>
>
>> Hope solve this problem.
>>
>> Cheers!
>>
>>
>> On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 30/09/2014 2:11 PM, Andre wrote:
>>
>>         Hi Duncan,
>>
>>         No, that's correct. Actually, I have data set below;
>>
>>
>>     Then it seems Excel is worse than I would have expected.  I
>>     confirmed R's value in two other pieces of software,
>>     OpenOffice and some software I wrote a long time ago based on an
>>     algorithm published in 1977 in Applied Statistics. (They are
>>     probably all using the same algorithm.  I wonder what Excel is doing?)
>>
>>         N= 1223
>>         alpha= 0.05
>>
>>         Then
>>         probability= 0.05/1223=0.0000408831
>>         degree of freedom= 1223-2= 1221
>>
>>         So, TINV(0.0000408831,1221) returns 4.0891672
>>
>>
>>         Could you show me more detail a manual equation. I really
>>         appreciate it if you may give more detail.
>>
>>
>>     I already gave you the expression:  abs(qt(0.0000408831/2,
>>     df=1221)). For more detail, I suppose you could look at the help
>>     page for the qt function, using help("qt").
>>
>>     Duncan Murdoch
>>
>>
>>         Cheers!
>>
>>
>>         On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
>>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>>         <mailto:murdoch.duncan at gmail.com
>>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>>
>>             On 30/09/2014 1:31 PM, Andre wrote:
>>
>>                 Dear Sir/Madam,
>>
>>                 I am trying to use calculation for two-tailed inverse
>>         of the
>>                 student`s
>>                 t-distribution function presented by Excel functions like
>>                 =TINV(probability, deg_freedom).
>>
>>                 For instance: The Excel function
>>         =TINV(0.0000408831,1221) =         returns
>>                   4.0891672.
>>
>>                 Would you like to show me a manual calculation for this?
>>
>>                 Appreciate your helps in advance.
>>
>>
>>             That number looks pretty far off the true value. Have you
>>         got a
>>             typo in your example?
>>
>>             You can compute the answer to your question as
>>             abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>>
>>             Duncan Murdoch
>>
>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From idnat at hotmail.com  Tue Sep 30 19:54:35 2014
From: idnat at hotmail.com (tandi perkins)
Date: Tue, 30 Sep 2014 12:54:35 -0500
Subject: [R] Converting factor data into Date-time format
Message-ID: <BAY179-W2140BC8DC38D20EFEE65A0B9BB0@phx.gbl>

Hello R help: 



I am
new to this forum so I apologize in advance for any protocol missteps.  I
have a data set that is comprised of eight birds with GPS; each of which
transmit everyday at 8:00 am, 4:00 pm, and midnight for 1 year (although I have
some missing relocation's).  I am trying to format my data to be run in
adehabitatLT but I am unsuccessful.  I have a "csv" file with
the following header: "Craneid, Date, Time, Long, Lat, Habitat,
BurstID".  R creates factor levels in the all of the data except Lat,
Long. I have attempted the following to correctly format my date and time
factors (data=l10): 



First
attempt: 

1.
 datetime=as.POSIXct(paste(l10$Date, l10$Time), format="%m/%d/%Y
%H:%M:%S", "America/Chicago") 



2.
coord=data.frame((l10$Longitude), (l10$Latitude)) 



3.
test=as.ltraj(coord, datetime, l10$Craneid, burst=l10$ID, typeII=TRUE) 



Results:Error
in as.ltraj(coord, datetime, l10$Craneid, burst = l10$ID, typeII = TRUE) : 

 
non unique dates for a given burst 



I
researched this error on the list serve and found that I could have duplicates
so I checked for duplicates in datetime and the return was NULL (I also check
for duplicates in Excel as I am in the learning stages in R).  Next I read
a thread posted on the R help in 2012 with a similar problem so I attempted
what was suggested as follows: 



1.
 datetime=as.POSIXct(strptime(as.character(l10$Date, l10$Time),
format="%m/%d/%Y %H:%M:%S")) 



2.test=as.ltraj(coord,
datetime, l10$Craneid, burst=l10$ID, typeII=TRUE) 



Results:
Same error. 



Finally,
I have tried: 



1.
 datetime=as.POSIXct(as.character(levels(l10$Date)(l10$Time)),
format="%m/%d/%Y %H:%M:%S")[l10$Date][l10$Time] 



Results:Error
in as.POSIXct(as.character(levels(l10$Date)(l10$Time)), format = "%m/%d/%Y
%H:%M:%S") : 

 
attempt to apply non-function 



Can
someone please explain what I am doing wrong?  My goal is to obtain
trajectories for all birds using each bird as a burst as is detailed in the
adehabitatLT manual and then to create Bias Random Bridges for each bird.
 I did not include my data but I can if that will be helpful. 



Thank
you in advance for your help,

TLP

 		 	   		  
	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Tue Sep 30 21:00:24 2014
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 30 Sep 2014 19:00:24 +0000
Subject: [R] Inverse Student t-value
In-Reply-To: <OF878A0A12.17B05669-ON85257D63.0066DA1D-85257D63.00676294@ria.buffalo.edu>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
	<542AF83E.40203@gmail.com>
	<OF878A0A12.17B05669-ON85257D63.0066DA1D-85257D63.00676294@ria.buffalo.edu>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623A7F544@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of JLucke at ria.buffalo.edu
> Sent: Tuesday, September 30, 2014 11:49 AM
> To: Andre
> Cc: r-help at r-project.org
> Subject: Re: [R] Inverse Student t-value
> 
> My Excel (2013) returns exactly what R does.   I used both T.INV and
> T.INV.T2    There is no TINV.  Has Excel been updated?
> 
> 

I have Excel 2007, and it does have the function TINV().  And, it also returns the same value as R-3.1.1. So, there appears to be a problem with whatever unstated system and version of Excel that the OP is using. 


Dan

Daniel J. Nordlund
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



> 
> 
> 
> Duncan Murdoch <murdoch.duncan at gmail.com>
> Sent by: r-help-bounces at r-project.org
> 09/30/2014 02:36 PM
> 
> To
> Andre <geomodelers at gmail.com>,
> cc
> r-help at r-project.org
> Subject
> Re: [R] Inverse Student t-value
> 
> 
> 
> 
> 
> 
> On 30/09/2014 2:26 PM, Andre wrote:
> > Hi Duncan,
> >
> > Actually, I am trying trace the formula for the "Critical value of Z"
> > and manual formula is
> > =(I7-1)/SQRT(I7)*SQRT((TINV(0.05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-
> 2)))
> >
> > So, I got new problem for TINV formula. I just need a manual equation
> > for TINV.
> 
> Sorry, can't help.  I'm not sure I understand what you want, but if
> it's
> a simple formula for quantiles of the t distribution, it doesn't exist.
> 
> Duncan Murdoch
> 
> >
> > Hope solve this problem.
> >
> > Cheers!
> >
> >
> > On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch
> > <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> >
> >     On 30/09/2014 2:11 PM, Andre wrote:
> >
> >         Hi Duncan,
> >
> >         No, that's correct. Actually, I have data set below;
> >
> >
> >     Then it seems Excel is worse than I would have expected.  I
> >     confirmed R's value in two other pieces of software,
> >     OpenOffice and some software I wrote a long time ago based on an
> >     algorithm published in 1977 in Applied Statistics. (They are
> >     probably all using the same algorithm.  I wonder what Excel is
> doing?)
> >
> >         N= 1223
> >         alpha= 0.05
> >
> >         Then
> >         probability= 0.05/1223=0.0000408831
> >         degree of freedom= 1223-2= 1221
> >
> >         So, TINV(0.0000408831,1221) returns 4.0891672
> >
> >
> >         Could you show me more detail a manual equation. I really
> >         appreciate it if you may give more detail.
> >
> >
> >     I already gave you the expression:  abs(qt(0.0000408831/2,
> >     df=1221)). For more detail, I suppose you could look at the help
> >     page for the qt function, using help("qt").
> >
> >     Duncan Murdoch
> >
> >
> >         Cheers!
> >
> >
> >         On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
> >         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
> >         <mailto:murdoch.duncan at gmail.com
> >         <mailto:murdoch.duncan at gmail.com>>> wrote:
> >
> >             On 30/09/2014 1:31 PM, Andre wrote:
> >
> >                 Dear Sir/Madam,
> >
> >                 I am trying to use calculation for two-tailed inverse
> >         of the
> >                 student`s
> >                 t-distribution function presented by Excel functions
> like
> >                 =TINV(probability, deg_freedom).
> >
> >                 For instance: The Excel function
> >         =TINV(0.0000408831,1221) =         returns
> >                   4.0891672.
> >
> >                 Would you like to show me a manual calculation for
> this?
> >
> >                 Appreciate your helps in advance.
> >
> >
> >             That number looks pretty far off the true value. Have you
> >         got a
> >             typo in your example?
> >
> >             You can compute the answer to your question as
> >             abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
> >
> >             Duncan Murdoch
> >
> >
> >
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From JLucke at ria.buffalo.edu  Tue Sep 30 21:39:42 2014
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Tue, 30 Sep 2014 15:39:42 -0400
Subject: [R] Inverse Student t-value
In-Reply-To: <CALzoxKDOxpCYeWbwT-JAvKOMeZCzpXH1Av4ht4qk3spakOHg7A@mail.gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>	<542AF83E.40203@gmail.com>
	<CALzoxKDOxpCYeWbwT-JAvKOMeZCzpXH1Av4ht4qk3spakOHg7A@mail.gmail.com>
Message-ID: <OF64AC775B.53D06187-ON85257D63.006B1EFA-85257D63.006C02CD@ria.buffalo.edu>

The website has your answer.  The t-distribution is a regularized 
incomplete beta function.  The incomplete beta function is given by R's 
pbeta function.  You regularize it with R's beta function.  Then you use 
R's uniroot function to find the inverse.  Good homework problem.



Andre <geomodelers at gmail.com> 
Sent by: r-help-bounces at r-project.org
09/30/2014 02:45 PM

To
Duncan Murdoch <murdoch.duncan at gmail.com>, 
cc
"r-help at r-project.org" <r-help at r-project.org>
Subject
Re: [R] Inverse Student t-value






Hi Duncan,

Let me explain again, I just need a manual expression for inverse student 
t
value.

You could go to web page
http://www.danielsoper.com/statcalc3/calc.aspx?id=10

That's inverse student t value calculator. Do you know a manual expression
use it.

Cheers!


On Wednesday, October 1, 2014, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/09/2014 2:26 PM, Andre wrote:
>
>> Hi Duncan,
>>
>> Actually, I am trying trace the formula for the "Critical value of Z" 
and
>> manual formula is =(I7-1)/SQRT(I7)*SQRT((TINV(0.
>> 05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))
>>
>> So, I got new problem for TINV formula. I just need a manual equation 
for
>> TINV.
>>
>
> Sorry, can't help.  I'm not sure I understand what you want, but if it's 
a
> simple formula for quantiles of the t distribution, it doesn't exist.
>
> Duncan Murdoch
>
>
>> Hope solve this problem.
>>
>> Cheers!
>>
>>
>> On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch 
<murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 30/09/2014 2:11 PM, Andre wrote:
>>
>>         Hi Duncan,
>>
>>         No, that's correct. Actually, I have data set below;
>>
>>
>>     Then it seems Excel is worse than I would have expected.  I
>>     confirmed R's value in two other pieces of software,
>>     OpenOffice and some software I wrote a long time ago based on an
>>     algorithm published in 1977 in Applied Statistics. (They are
>>     probably all using the same algorithm.  I wonder what Excel is 
doing?)
>>
>>         N= 1223
>>         alpha= 0.05
>>
>>         Then
>>         probability= 0.05/1223=0.0000408831
>>         degree of freedom= 1223-2= 1221
>>
>>         So, TINV(0.0000408831,1221) returns 4.0891672
>>
>>
>>         Could you show me more detail a manual equation. I really
>>         appreciate it if you may give more detail.
>>
>>
>>     I already gave you the expression:  abs(qt(0.0000408831/2,
>>     df=1221)). For more detail, I suppose you could look at the help
>>     page for the qt function, using help("qt").
>>
>>     Duncan Murdoch
>>
>>
>>         Cheers!
>>
>>
>>         On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
>>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>>         <mailto:murdoch.duncan at gmail.com
>>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>>
>>             On 30/09/2014 1:31 PM, Andre wrote:
>>
>>                 Dear Sir/Madam,
>>
>>                 I am trying to use calculation for two-tailed inverse
>>         of the
>>                 student`s
>>                 t-distribution function presented by Excel functions 
like
>>                 =TINV(probability, deg_freedom).
>>
>>                 For instance: The Excel function
>>         =TINV(0.0000408831,1221) =         returns
>>                   4.0891672.
>>
>>                 Would you like to show me a manual calculation for 
this?
>>
>>                 Appreciate your helps in advance.
>>
>>
>>             That number looks pretty far off the true value. Have you
>>         got a
>>             typo in your example?
>>
>>             You can compute the answer to your question as
>>             abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>>
>>             Duncan Murdoch
>>
>>
>>
>>
>>
>>
>

                 [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From eliza_botto at hotmail.com  Tue Sep 30 21:50:33 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 30 Sep 2014 19:50:33 +0000
Subject: [R] Best Distribution
Message-ID: <BLU170-W1308F77900877D55E6C065B89BB0@phx.gbl>

Dear useRs,
I have this following data
> dput(Prec)
c(42.2, 45.2, 46, 48, 54, 54.1, 59.4, 61, 62.2, 63.5, 65.024, 71.9, 73.4, 76.6, 76.708, 77.5, 77.724, 78, 81.3, 84.7, 84.836, 85.09, 88.2, 91.4, 94, 95.8, 96, 97.3, 101, 101, 101.5, 102.3, 102.87, 108.7, 109.5, 110.5, 110.7, 112, 114.3, 118.11, 121.412, 128.1, 131, 140, 142, 143.3, 151.4, 153.7, 189.4, 214.3)
I want to fit gumbel and log-normal distribution on it on the same window to see which distribution fits it the best way.
Thankyou very much in advance,
Eliza 		 	   		  
	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Sep 30 22:43:14 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 30 Sep 2014 20:43:14 +0000
Subject: [R] Converting factor data into Date-time format
In-Reply-To: <BAY179-W2140BC8DC38D20EFEE65A0B9BB0@phx.gbl>
References: <BAY179-W2140BC8DC38D20EFEE65A0B9BB0@phx.gbl>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9CA76@mb02.ads.tamu.edu>

First, use stringsAsFactors=FALSE with the read.csv() function. That will prevent the conversion to factors. Then try to convert date and time to datetime objects. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of tandi perkins
Sent: Tuesday, September 30, 2014 12:55 PM
To: r-help at r-project.org
Subject: [R] Converting factor data into Date-time format

Hello R help: 



I am
new to this forum so I apologize in advance for any protocol missteps.  I
have a data set that is comprised of eight birds with GPS; each of which
transmit everyday at 8:00 am, 4:00 pm, and midnight for 1 year (although I have
some missing relocation's).  I am trying to format my data to be run in
adehabitatLT but I am unsuccessful.  I have a "csv" file with
the following header: "Craneid, Date, Time, Long, Lat, Habitat,
BurstID".  R creates factor levels in the all of the data except Lat,
Long. I have attempted the following to correctly format my date and time
factors (data=l10): 



First
attempt: 

1.
 datetime=as.POSIXct(paste(l10$Date, l10$Time), format="%m/%d/%Y
%H:%M:%S", "America/Chicago") 



2.
coord=data.frame((l10$Longitude), (l10$Latitude)) 



3.
test=as.ltraj(coord, datetime, l10$Craneid, burst=l10$ID, typeII=TRUE) 



Results:Error
in as.ltraj(coord, datetime, l10$Craneid, burst = l10$ID, typeII = TRUE) : 


non unique dates for a given burst 



I
researched this error on the list serve and found that I could have duplicates
so I checked for duplicates in datetime and the return was NULL (I also check
for duplicates in Excel as I am in the learning stages in R).  Next I read
a thread posted on the R help in 2012 with a similar problem so I attempted
what was suggested as follows: 



1.
 datetime=as.POSIXct(strptime(as.character(l10$Date, l10$Time),
format="%m/%d/%Y %H:%M:%S")) 



2.test=as.ltraj(coord,
datetime, l10$Craneid, burst=l10$ID, typeII=TRUE) 



Results:
Same error. 



Finally,
I have tried: 



1.
 datetime=as.POSIXct(as.character(levels(l10$Date)(l10$Time)),
format="%m/%d/%Y %H:%M:%S")[l10$Date][l10$Time] 



Results:Error
in as.POSIXct(as.character(levels(l10$Date)(l10$Time)), format = "%m/%d/%Y
%H:%M:%S") : 


attempt to apply non-function 



Can
someone please explain what I am doing wrong?  My goal is to obtain
trajectories for all birds using each bird as a burst as is detailed in the
adehabitatLT manual and then to create Bias Random Bridges for each bird.
 I did not include my data but I can if that will be helpful. 



Thank
you in advance for your help,

TLP

 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Tue Sep 30 23:04:05 2014
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 30 Sep 2014 17:04:05 -0400
Subject: [R] Reading text file with fortran format
Message-ID: <542b1ac8.1228ec0a.1a92.23c7@mx.google.com>

Hello

I read data with fortran format:
mydata<-read.fortran('foo.txt',
                      c("4F10.4","F8.3","3F3.0","20F2.0"))
colnames(mydata)<-c("q1","q2","q3","q4","income","hhsize",
  "weekend","dietk","quart1","quart2","quart3","male","age35",
  "age50","age65","midwest","south","west","nonmetro",
  "suburb","black","asian","other","hispan","hhtype1",
  "hhtype2","hhtype3","emp_stat")
dstat(mydata,digits=6)

I produced the following sample statistics for the first 4
variables (q1,q2,q3,q4):

              Mean  Std.dev Min       Max  Obs
q1       0.000923 0.002509   0  0.035245 5649
q2       0.000698 0.001681   0  0.038330 5649
q3       0.000766 0.002138   0  0.040100 5649
q4       0.000373 0.001140   0  0.026374 5649

The correct sample statistics are:
Variable|       Mean       Std.Dev.     Minimum      Maximum
--------+----------------------------------------------------
       Q1|     9.227632     25.09311          0.0     352.4508
       Q2|     6.983078     16.80984          0.0     383.2995
       Q3|     7.657381     21.38337          0.0     400.9950
       Q4|     3.727952     11.40446          0.0     263.7398
   INCOME|     16.01603     13.70296          0.0        100.0
   HHSIZE|     2.586475     1.464282          1.0         16.0

In other words, values for q1-q4 were scaled down by a factor of 10,000.
My raw data look like (with proper format)

     0.0000    0.0000    0.0000    0.0000  48.108...
     0.0000    0.0000    0.0000    0.0000  11.640...
    35.3450    0.0000   95.7656    0.0000   4.667...
     0.0000    0.0000    0.0000    0.0000   9.000...
    84.0000    4.8038    0.0000    3.1886   2.923...
     0.0000    0.0000    0.0000    1.1636  10.000...
     0.0000   10.7818  109.7884    0.0000  17.000...
     0.0000    7.9528    0.0000    4.7829  35.000...

True that the data here are space delimited. But I need to read data 
elsewhere where data are not space delimited.

Any idea/suggestion would be appreciated.


	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Sep 30 23:17:47 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 01 Oct 2014 10:17:47 +1300
Subject: [R] Regarding R package spatstat
In-Reply-To: <CAG5d0=--HP=YdXX=BErTRTg20hsVSF7noP8OHWB8_sA1+Za9xg@mail.gmail.com>
References: <CAG5d0=--HP=YdXX=BErTRTg20hsVSF7noP8OHWB8_sA1+Za9xg@mail.gmail.com>
Message-ID: <542B1DFB.5030907@auckland.ac.nz>


Why are you trying to install version 1.26-0?  That is very ancient; it 
dates from April 2012.

The version currently on CRAN is 1.38-1.  I would suggest that you try that.

I have no idea why your installation is hanging at the byte-compile 
stage, nor any idea how to diagnose the problem.  I tried a test just
now and managed to do an install of version 1.26-0 with no problems and 
no hangup.

cheers,

Rolf Turner

P. S.  I am puzzled as to how you are getting 'Target "all" is up to 
date' given that you are installing from the tarball.  This should only 
happen when you install from the unpacked *directory* "spatstat" (after
a previous install which would have built the required shared object 
library). Also, when I go through that process I get

> make: Nothing to be done for `all'.

rather than  'Target "all" is up to date'.  So something has been 
altered in your system, it would appear.  Hard to say what.

R. T.

On 01/10/14 00:58, shivali gangwar wrote:
> Hi ,
>
> I am installing a R Package as following -
>   R CMD INSTALL spatstat_1.26-0.tar.gz
>
> It seems my installation hangs at
>
>   "byte-compile and prepare package for lazy loading"
> I kept on waiting for 1/2anhr but it hanged at below stage.
> Please help.
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Target "all" is up to date.
> installing to
> /gpfs1/home/shivali/R-3.1.0/R-3.1.0/lib/R/library/spatstat/libs
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** demo
> ** inst
> ** byte-compile and prepare package for lazy loading
>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~````
>
> [ncmr0202][/gpfs1/home/shivali]> ps -ef | grep R-3.1.0
>   shivali 438938 446478   0 17:23:40  pts/9  0:00 grep R-3.1.0
>   shivali 635448 381678   0 17:12:03 pts/14  0:00 sh
> /gpfs1/home/shivali/R-3.1.0/R-3.1.0/lib/R/bin/Rcmd INSTALL
> spatstat_1.26-0.tar.gz
>   shivali 316220 635448 118 17:12:04 pts/14 10:58
> /gpfs1/home/shivali/R-3.1.0/R-3.1.0/lib/R/bin/exec/R --args --args --args
> nextArgspatstat_1.26-0.tar.gz
>   shivali 344832      1 118 16:23:05 pts/14 60:26
> /gpfs1/home/shivali/R-3.1.0/R-3.1.0/lib/R/bin/exec/R --args --args --args
> nextArgSpatialVx_0.2-1.tar.gz
> [ncmr0202][/gpfs1/home/shivali]>


-- 
Rolf Turner
Technical Editor ANZJS


