From dcarlson at tamu.edu  Mon May  1 01:54:01 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 30 Apr 2017 23:54:01 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into
 a table
In-Reply-To: <DM5PR15MB130771F963A2AAC57FF686E7EF150@DM5PR15MB1307.namprd15.prod.outlook.com>
References: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB130771231E54884C4B579797EF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <781d109c1e9644f0bab078460c645be9@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB13076BCF5ADB6ACA3C802F4AEF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <86cd68d71c404b1ba62f6fe40c63645c@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB130771F963A2AAC57FF686E7EF150@DM5PR15MB1307.namprd15.prod.outlook.com>
Message-ID: <6a33dbb5fdf7416e8de92a0a08139488@exch-2p-mbx-w2.ads.tamu.edu>

No. You are not using the correct command. Time to read the manual:

?write.table

You will find the answer to your question by looking at the alternate forms of  write.*().


David L. Carlson
Department of Anthropology
Texas A&M University

From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 2:36 PM
To: David L Carlson <dcarlson at tamu.edu>; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 

I'm trying?to write the table I have created from the matrix using 
write.table(mytable, file=?"mytable.txt"). I have imported this txt. file?into 
an Excel sheet but? all data have been typed in one column (Var1,Var2,&Freq.) 
and I want to see each vector in one column.?Have I used the correct syntax?

Regards?

________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 07:33 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
Show us the code you used. Don't just tell us what you did. It is likely that something you did after creating the matrix converted it to a data frame. Copy and paste your code to your emails.

> str(mydf)
'data.frame':?? 3 obs. of? 3 variables:
?$ x: int? 0 NA NA
?$ y: int? 5 0 NA
?$ z: int? 67 23 0

> data.frame(as.table(as.matrix(mydf)))
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA

David C


From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 11:13 AM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

str(mymatrix)
The Structure shows that this is a 'data.frame'?? of 120 obs. and 120 variables 
of numeric type. R deals with my matrix as a data frame although I used 
the function matrix() to produce this matrix which is not clear to me why. As this is already a data.frame, this may explains why R returns me the same 
matrix. What do you recommend now?

Many thanks 


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 06:47 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
You did not give me any information about about your data using str() or class() so I'll guess that you have a matrix, e.g.:

> class(moredata)
[1] "matrix"
> as.data.frame.table(moredata)
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA
7??? x??? z?? 67
8??? y??? z?? 23
9??? z??? z??? 0


David C

From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 10:09 AM
To: David L Carlson <dcarlson at tamu.edu>; r-help at R-project.org
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

Dear David ..,

Many thanks for this detailed answer.

Your guidance reg. the first task has resolved my issue and I have understood now how to perform this type of analysis. I have saved your learning tips in my script.

Reg. the Matrix-table conversion, could you please clarify this?more?.
I applied the function as.data.frame but this returned the same matrix 
without converting it into a list table. I'm not sure where is the problem
in my code :???mymatrix <- as.data.frame(mymatrix).

Many thanks for your support

Regards


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 29 April 2017 11:38 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
First. Do not use html messages, only plain text. Second. Provide a small example data set, preferably using dput(). Just printing your data can hide important information. Third. Read the documentation. Your first example does not return a logical vector at all:

> dput(mydata)
structure(list(Col1 = c(123L, 443L, 566L), Col2 = c(566L, 54L, 
44L), Col3 = c(235L, 566L, 235L)), .Names = c("Col1", "Col2", 
"Col3"), class = "data.frame", row.names = c(NA, -3L))

> which(mydata == 566,235)
???? row col
[1,]?? 3?? 1
[2,]?? 1?? 2
[3,]?? 2?? 3

It locates cells with 566, but not 235 which is not a surprise because you did not provide a valid logical expression to which(). 

There are a number of ways to get what you want, but since you want to process rows, apply() is straightforward:

> Val566 <- apply(mydata, 1, function(x) any(x == 566))
> Val566
[1] TRUE TRUE TRUE
> Val235 <- apply(mydata, 1, function(x) any(x == 235)) 
> Val235
[1]? TRUE FALSE? TRUE
> which(Val235 & Val566)
[1] 1 3

You should read the manual pages on any(), apply(), dput() and which() and logical expressions:

> ?apply
> ?any
> ?dput
> ?which
> ?Comparison # ?"==" will also get you there.

For the second question, assuming you are beginning with a table object as R defines that term and not a matrix (since all tables are matrices, but all matrices are not tables):

> dput(moredata)
structure(c(0L, NA, NA, 5L, 0L, NA, 67L, 23L, 0L), .Dim = c(3L, 
3L), .Dimnames = list(c("x", "y", "z"), c("x", "y", "z")), class = "table")
> moredata
?? x? y? z
x? 0? 5 67
y NA? 0 23
z NA NA? 0

Note, that your example uses na rather than NA. R is case sensitive so na is just an ordinary character string while NA is a missing value indicator. This is one of the reasons that dput() is important

> moredata.df <- as.data.frame(moredata)
> moredata.df
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA
7??? x??? z?? 67
8??? y??? z?? 23
9??? z??? z??? 0
> moredata.df[order(moredata.df$Freq, decreasing=TRUE), ]
? Var1 Var2 Freq
7??? x??? z?? 67
8??? y??? z?? 23
4??? x??? y??? 5
1??? x??? x??? 0
5??? y??? y??? 0
9??? z??? z??? 0
2??? y??? x?? NA
3??? z??? x?? NA
6??? z??? y?? NA

For this you should read the following manual pages:

> ?as.data.frame
> ?order
> ?Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of abo dalash
Sent: Saturday, April 29, 2017 10:14 AM
To: r-help at R-project.org
Subject: [R] Finding nrows with specefic values&converting a matrix into a table

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1????????? 123?? 566??? 235

2????????? 443??? 54????? 566

3????????? 566??? 44????? 235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


??????????????????? x????? y????? z

x????????????????? 0????? 5?????? 67

y????????????????? na??? 0????? 23

z?????????????????? na?? na????? 0


and I would like to convert this into a table arranged with

higher values first like this :

x?????? z?????? 67

y?????? z?????? 23

x?????? y??????? 5

x?????? x??????? 0

y?????? y??????? 0

z??????? z??????? 0

y??????? x??????? na

z??????? x??????? na

z??????? y??????? na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Mon May  1 06:01:03 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Mon, 1 May 2017 09:31:03 +0530
Subject: [R] The effect of tolerance in all.equal()
In-Reply-To: <d3ca18ce-d46a-d2fd-0db3-7173579c6a08@gmail.com>
References: <CAC8=1erSNHJ4YdAVy3dDwUWapu+Mo0HTLPZ+4VZRJm88gKViCA@mail.gmail.com>
 <22783.6758.310171.440071@stat.math.ethz.ch>
 <CAC8=1erfHBFar4m5mNHxRf+BcTHoAUWcZXoNocDiGTwyOoMemA@mail.gmail.com>
 <d3ca18ce-d46a-d2fd-0db3-7173579c6a08@gmail.com>
Message-ID: <CAC8=1eqh-rdcZdTP9T3aeYKC5bW5wp2+H6RU0Pd5TW7y2Fi59A@mail.gmail.com>

On Sun, Apr 30, 2017 at 10:05 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/04/2017 12:26 PM, Ashim Kapoor wrote:
>
>> Dear All,
>>
>> This answer is very clear. Many thanks.
>>
>> I am now confused about how str*ucture works. Where can I read more about
>> when does it  return language / logical / chr ? I would want to read that
>> so I can interpret the result of structure. I don't think ?str contains
>> this.To me, logical and chr make sense, what does language mean? I think I
>> need to read some more.
>>
>
> I would read the R Language Definition manual, and then bits and pieces of
> R Internals, as necessary.  These are both included with R.  There are also
> books separate from R that talk about these things, but I don't know which
> to recommend.
>
> Can you please name those books ?


> Duncan Murdoch
>
>
>> Many thanks,
>> Ashim
>>
>> On Tue, Apr 25, 2017 at 3:14 PM, Martin Maechler <
>> maechler at stat.math.ethz.ch
>>
>>> wrote:
>>>
>>
>> Ashim Kapoor <ashimkapoor at gmail.com>
>>>>>>>>     on Tue, 25 Apr 2017 14:02:18 +0530 writes:
>>>>>>>>
>>>>>>>
>>>     > Dear all,
>>>     > I am not able to understand the interplay of absolute vs relative
>>> and
>>>     > tolerance in the use of all.equal
>>>
>>>     > If I want to find out if absolute differences between 2
>>> numbers/vectors are
>>>     > bigger than a given tolerance I would do:
>>>
>>>     > all.equal(1,1.1,scale=1,tol= .1)
>>>
>>>     > If I want to find out if relative differences between 2
>>> numbers/vectors are
>>>     > bigger than a given tolerance I would do :
>>>
>>>     > all.equal(1,1.1,tol=.1)
>>>
>>>     > ############################################################
>>> ######################################################################
>>>
>>>     > I can also do :
>>>
>>>     > all.equal(1,3,tol=1)
>>>
>>>     > to find out if the absolute difference is bigger than 1.But here I
>>> won't be
>>>     > able to detect absolute differences smaller than 1 in this case,so
>>> I
>>> don't
>>>     > think that this is a good way.
>>>
>>>     > My query is: what is the reasoning behind all.equal returning the
>>> absolute
>>>     > difference if the tolerance >= target and relative difference if
>>> tolerance
>>>     > < target?
>>> (above, it is    tol  >/<=  |target|  ie. absolute value)
>>>
>>>
>>> The following are desiderata / restrictions :
>>>
>>> 1) Relative tolerance is needed to keep things scale-invariant
>>>    i.e.,  all.equal(x, y)  and  all.equal(1000 * x, 1000 * y)
>>>    should typically be identical for (almost) all (x,y).
>>>
>>>    ==> "the typical behavior should use relative error tolerance"
>>>
>>> 2) when x or y (and typically both!) are very close to zero it
>>>    is typically undesirable to keep relative tolerances (in the
>>>    boundary case, they _are_ zero exactly, and "relative error" is
>>> undefined).
>>>    E.g., for most purposes, 3.45e-15 and 1.23e-17 should be counted as
>>>    equal to zero and hence to themselves.
>>>
>>> 1) and 2) are typically reconciled by switching from relative to absolute
>>> when the arguments are close to zero (*).
>>>
>>> The exact cutoff at which to switch from relative to absolute
>>> (or a combination of the two) is somewhat arbitrary(*2) and for
>>> all.equal() has been made in the 1980's (or even slightly
>>> earlier?) when all.equal() was introduced into the S language at
>>> Bell labs AFAIK. Maybe John Chambers (or Rick Becker or ...,
>>> but they may not read R-help) knows more.
>>> *2) Then, the choice for all.equal() is in some way "least arbitrary",
>>>     using c = 1 in the more general   tolerance >= c*|target|  framework.
>>>
>>> *) There have been alternatives in "the (applied numerical
>>>  analysis / algorithm) literature" seen in published algorithms,
>>>  but I don't have any example ready.
>>>  Notably some of these alternatives are _symmetric_ in (x,y)
>>>  where all.equal() was designed to be asymmetric using names
>>>  'target' and 'current'.
>>>
>>> The alternative idea is along the following thoughts:
>>>
>>> Assume that for "equality" we want _both_ relative and
>>> absolute (e := tolerance) "equality"
>>>
>>>    |x - y| < e (|x|+|y|)/2  (where you could use |y| or |x|
>>>                              instead of their mean; all.equal()
>>>                              uses |target|)
>>>    |x - y| < e * e1          (where e1 = 1, or e1 = 10^-7..)
>>>
>>> If you add the two inequalities you get
>>>
>>>    |x - y| < e (e1 + |x+y|/2)
>>>
>>> as check which is a "mixture" of relative and absolute tolerance.
>>>
>>> With a somewhat long history, my gut feeling would nowadays
>>> actually prefer this (I think with a default of e1 = e) - which
>>> does treat x and y symmetrically.
>>>
>>> Note that convergence checks in good algorithms typically check
>>> for _both_ relative and absolute difference (each with its
>>> tolerance providable by the user), and the really good ones for
>>> minimization do  check for (approximate) gradients also being
>>> close to zero - as old timers among us should have learned from
>>> Doug Bates ... but now I'm really diverging.
>>>
>>> Last but not least some  R  code at the end,  showing that the
>>> *asymmetric*
>>> nature of all.equal() may lead to somewhat astonishing (but very
>>> logical and as documented!) behavior.
>>>
>>> Martin
>>>
>>>     > Best Regards,
>>>     > Ashim
>>>
>>>
>>> ## The "data" to use:
>>>> epsQ <- lapply(seq(12,18,by=1/2), function(P) bquote(10^-.(P)));
>>>>
>>> names(epsQ) <- sapply(epsQ, deparse); str(epsQ)
>>> List of 13
>>>  $ 10^-12  : language 10^-12
>>>  $ 10^-12.5: language 10^-12.5
>>>  $ 10^-13  : language 10^-13
>>>  $ 10^-13.5: language 10^-13.5
>>>  $ 10^-14  : language 10^-14
>>>  $ 10^-14.5: language 10^-14.5
>>>  $ 10^-15  : language 10^-15
>>>  $ 10^-15.5: language 10^-15.5
>>>  $ 10^-16  : language 10^-16
>>>  $ 10^-16.5: language 10^-16.5
>>>  $ 10^-17  : language 10^-17
>>>  $ 10^-17.5: language 10^-17.5
>>>  $ 10^-18  : language 10^-18
>>>
>>> str(lapply(epsQ, function(tl) all.equal(3.45e-15, 1.23e-17, tol =
>>>>
>>> eval(tl))))
>>> List of 13
>>>  $ 10^-12  : logi TRUE
>>>  $ 10^-12.5: logi TRUE
>>>  $ 10^-13  : logi TRUE
>>>  $ 10^-13.5: logi TRUE
>>>  $ 10^-14  : logi TRUE
>>>  $ 10^-14.5: chr "Mean relative difference: 0.9964348"
>>>  $ 10^-15  : chr "Mean relative difference: 0.9964348"
>>>  $ 10^-15.5: chr "Mean relative difference: 0.9964348"
>>>  $ 10^-16  : chr "Mean relative difference: 0.9964348"
>>>  $ 10^-16.5: chr "Mean relative difference: 0.9964348"
>>>  $ 10^-17  : chr "Mean relative difference: 0.9964348"
>>>  $ 10^-17.5: chr "Mean relative difference: 0.9964348"
>>>  $ 10^-18  : chr "Mean relative difference: 0.9964348"
>>>
>>> ## Now swap `target` and `current` :
>>>> str(lapply(epsQ, function(tl) all.equal(1.23e-17, 3.45e-15, tol =
>>>>
>>> eval(tl))))
>>> List of 13
>>>  $ 10^-12  : logi TRUE
>>>  $ 10^-12.5: logi TRUE
>>>  $ 10^-13  : logi TRUE
>>>  $ 10^-13.5: logi TRUE
>>>  $ 10^-14  : logi TRUE
>>>  $ 10^-14.5: chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-15  : chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-15.5: chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-16  : chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-16.5: chr "Mean absolute difference: 3.4377e-15"
>>>  $ 10^-17  : chr "Mean relative difference: 279.4878"
>>>  $ 10^-17.5: chr "Mean relative difference: 279.4878"
>>>  $ 10^-18  : chr "Mean relative difference: 279.4878"
>>>
>>>
>>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From arrayprofile at yahoo.com  Mon May  1 03:07:19 2017
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 1 May 2017 01:07:19 +0000 (UTC)
Subject: [R] Lattice xyplot
References: <279279174.1150856.1493600840045.ref@mail.yahoo.com>
Message-ID: <279279174.1150856.1493600840045@mail.yahoo.com>

Dear all, I am new to lattice, so would appreciate anyone's help on the questions below. I am using xyplot to plot some trend in my dataset. Using the example dataset attached, I am trying to plot variable "y" over variable "time" for each subject "id":
dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p", "l"), ?xlab = "Time", ylab = "Y")

It appears that it just worked fine. But if I sort the "dat" first, the plot will look somewhat different!
dat<-dat[order(dat$id, dat$time),]xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p", "l"), ?xlab = "Time", ylab = "Y")
Why is that? Do you need to sort the data first before using xyplot? Why xyplot can not understand the dataset unless it is sorted first?
Thanks,
John
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dat.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170501/432a8fd6/attachment.txt>

From mangelhombradosherre at unm.edu  Mon May  1 06:57:43 2017
From: mangelhombradosherre at unm.edu (Miguel Angel Hombrados Herrera)
Date: Mon, 1 May 2017 04:57:43 +0000
Subject: [R] Whitespace
Message-ID: <MWHPR07MB3598B6BC5FE698E5E1060543D1140@MWHPR07MB3598.namprd07.prod.outlook.com>

Hello


Ive been working on a stan program in Rstudio. Im kind of new on this, so probably my question is trivial, However I was not able to find information about this.

The error Im getting when I run my stan code is:


PARSER EXPECTED: whitespace to end of file.
FOUND AT line 2:


The code is:

iter=500
alphamcmc=matrix(0,ncol=J,nrow=iter)
betamcmc=NULL
mu_alpha=NULL
sigma_alpha_2=NULL
sigma_y_2=NULL
#set initial values
alphamcmc[1,]=rep(mean(y),J)
betamcmc[1]=70
mu_alpha[1]=mean(y)
sigma_alpha_2[1]=300
sigma_y_2[1]=350
#mcmc iteration
for(m in 2:iter){
#update alpha vector
for(j in 1:J){
sj=sum(source==j)
var=1/(sj/sigma_y_2[m-1]+1/sigma_alpha_2[m-1])
temp=0
for(i in 1:N){temp=temp+1*(source[i]==j)*(y[i]-betamcmc[m-1]*x[i])}
#sum up (y_i-beta x_i ) for those belonging to group j
mean=var*(temp/sigma_y_2[m-1]+mu_alpha[m-1]/sigma_alpha_2[m-1])
alphamcmc[m,j]=rnorm(1,mean,sqrt(var))
}
#update beta
var=sigma_alpha_2[m-1]/(sum(x^2))
mean=sum(x%*%(y-alphamcmc[m,source])/sum(sum(x^2)))
betamcmc[m]=rnorm(1,mean,sqrt(var))
#update mu_alpha
#update sigma_alpha_2
sigma_alpha_2[m]=rinvgamma(1,shape=J/2,rate=sum((alphamcmc[m,]
-mu_alpha[m])^2/2))
#update sigma_y_2
sigma_y_2[m]=rinvgamma(1,shape=N/2,rate=sum((y-alphamcmc[m,source]-
betamcmc[m]*x)^2/2))
}
nburn=200
apply(alphamcmc[(nburn+1):iter,],2,mean)
apply(betamcmc[(nburn+1):iter],2,mean)

Ive been searching for wrong spaces or tabulations, but I was not able to find anything.

I really would appreciate your help.
Thaknk you.


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon May  1 11:59:21 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 1 May 2017 19:59:21 +1000
Subject: [R] Whitespace
In-Reply-To: <MWHPR07MB3598B6BC5FE698E5E1060543D1140@MWHPR07MB3598.namprd07.prod.outlook.com>
References: <MWHPR07MB3598B6BC5FE698E5E1060543D1140@MWHPR07MB3598.namprd07.prod.outlook.com>
Message-ID: <CA+8X3fXysjb7KL0g2929jcMz7nFOvp4NZDF7MEkrOe6uSoYRVg@mail.gmail.com>

Hi Miguel,
You don't seem to have defined "J" before line 2. Maybe that is the problem.

Jim


On Mon, May 1, 2017 at 2:57 PM, Miguel Angel Hombrados Herrera
<mangelhombradosherre at unm.edu> wrote:
> Hello
>
>
> Ive been working on a stan program in Rstudio. Im kind of new on this, so probably my question is trivial, However I was not able to find information about this.
>
> The error Im getting when I run my stan code is:
>
>
> PARSER EXPECTED: whitespace to end of file.
> FOUND AT line 2:
>
>
> The code is:
>
> iter=500
> alphamcmc=matrix(0,ncol=J,nrow=iter)
> betamcmc=NULL
> mu_alpha=NULL
> sigma_alpha_2=NULL
> sigma_y_2=NULL
> #set initial values
> alphamcmc[1,]=rep(mean(y),J)
> betamcmc[1]=70
> mu_alpha[1]=mean(y)
> sigma_alpha_2[1]=300
> sigma_y_2[1]=350
> #mcmc iteration
> for(m in 2:iter){
> #update alpha vector
> for(j in 1:J){
> sj=sum(source==j)
> var=1/(sj/sigma_y_2[m-1]+1/sigma_alpha_2[m-1])
> temp=0
> for(i in 1:N){temp=temp+1*(source[i]==j)*(y[i]-betamcmc[m-1]*x[i])}
> #sum up (y_i-beta x_i ) for those belonging to group j
> mean=var*(temp/sigma_y_2[m-1]+mu_alpha[m-1]/sigma_alpha_2[m-1])
> alphamcmc[m,j]=rnorm(1,mean,sqrt(var))
> }
> #update beta
> var=sigma_alpha_2[m-1]/(sum(x^2))
> mean=sum(x%*%(y-alphamcmc[m,source])/sum(sum(x^2)))
> betamcmc[m]=rnorm(1,mean,sqrt(var))
> #update mu_alpha
> #update sigma_alpha_2
> sigma_alpha_2[m]=rinvgamma(1,shape=J/2,rate=sum((alphamcmc[m,]
> -mu_alpha[m])^2/2))
> #update sigma_y_2
> sigma_y_2[m]=rinvgamma(1,shape=N/2,rate=sum((y-alphamcmc[m,source]-
> betamcmc[m]*x)^2/2))
> }
> nburn=200
> apply(alphamcmc[(nburn+1):iter,],2,mean)
> apply(betamcmc[(nburn+1):iter],2,mean)
>
> Ive been searching for wrong spaces or tabulations, but I was not able to find anything.
>
> I really would appreciate your help.
> Thaknk you.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Mon May  1 14:12:15 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 1 May 2017 13:12:15 +0100
Subject: [R] Whitespace
In-Reply-To: <36a43976abd34963b6dcd59db5058e54@EX-0-HT0.lancs.local>
References: <36a43976abd34963b6dcd59db5058e54@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOS=9MRhb4UsnE2hvaUhxZCSWo4_U=9yo6AkrXxGoTFvQ@mail.gmail.com>

That looks like an error from Stan parsing your stan file, but the
code you put in the message doesn't look like Stan code, it looks like
R code, so maybe you've tried to parse your R code with Stan....

There's no mention of stan in the code either, like the rstan package,
so somehow you've got a Stan error message from some R code without
calling stan... Okay, I'm well confused now...





On Mon, May 1, 2017 at 5:57 AM, Miguel Angel Hombrados Herrera
<mangelhombradosherre at unm.edu> wrote:
> Hello
>
>
> Ive been working on a stan program in Rstudio. Im kind of new on this, so probably my question is trivial, However I was not able to find information about this.
>
> The error Im getting when I run my stan code is:
>
>
> PARSER EXPECTED: whitespace to end of file.
> FOUND AT line 2:
>
>
> The code is:
>
> iter=500
> alphamcmc=matrix(0,ncol=J,nrow=iter)
> betamcmc=NULL
> mu_alpha=NULL
> sigma_alpha_2=NULL
> sigma_y_2=NULL
> #set initial values
> alphamcmc[1,]=rep(mean(y),J)
> betamcmc[1]=70
> mu_alpha[1]=mean(y)
> sigma_alpha_2[1]=300
> sigma_y_2[1]=350
> #mcmc iteration
> for(m in 2:iter){
> #update alpha vector
> for(j in 1:J){
> sj=sum(source==j)
> var=1/(sj/sigma_y_2[m-1]+1/sigma_alpha_2[m-1])
> temp=0
> for(i in 1:N){temp=temp+1*(source[i]==j)*(y[i]-betamcmc[m-1]*x[i])}
> #sum up (y_i-beta x_i ) for those belonging to group j
> mean=var*(temp/sigma_y_2[m-1]+mu_alpha[m-1]/sigma_alpha_2[m-1])
> alphamcmc[m,j]=rnorm(1,mean,sqrt(var))
> }
> #update beta
> var=sigma_alpha_2[m-1]/(sum(x^2))
> mean=sum(x%*%(y-alphamcmc[m,source])/sum(sum(x^2)))
> betamcmc[m]=rnorm(1,mean,sqrt(var))
> #update mu_alpha
> #update sigma_alpha_2
> sigma_alpha_2[m]=rinvgamma(1,shape=J/2,rate=sum((alphamcmc[m,]
> -mu_alpha[m])^2/2))
> #update sigma_y_2
> sigma_y_2[m]=rinvgamma(1,shape=N/2,rate=sum((y-alphamcmc[m,source]-
> betamcmc[m]*x)^2/2))
> }
> nburn=200
> apply(alphamcmc[(nburn+1):iter,],2,mean)
> apply(betamcmc[(nburn+1):iter],2,mean)
>
> Ive been searching for wrong spaces or tabulations, but I was not able to find anything.
>
> I really would appreciate your help.
> Thaknk you.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From siouxsie at posteo.ch  Mon May  1 12:23:27 2017
From: siouxsie at posteo.ch (Siouxsie)
Date: Mon, 01 May 2017 12:23:27 +0200
Subject: [R] problem loading spss-files
Message-ID: <4a2f4ab2ff2ef858c5654754c13c2865@posteo.de>

after updating R from 3.3.3. to 3.4.0 i cannot import spss-data files 
anymore. for the european social survey (europeansocialsurvey.org) i get 
this warning:
re-encoding from CP1252
Fehler in levels<-(*tmp*, value = if (nl == nL) as.character(labels) 
else paste0(labels, :
factor level [3] is duplicated
Zus?tzlich: Warnmeldung:
In read.spss(file, use.value.labels = use.value.labels, to.data.frame = 
to.data.frame, :
//filepath/ESS7CH.sav: Unrecognized record type 7, subtype 18 
encountered in system file

using the package foreign does the same.


From katharina.manderscheid at posteo.de  Mon May  1 12:22:39 2017
From: katharina.manderscheid at posteo.de (katharina.manderscheid at posteo.de)
Date: Mon, 01 May 2017 12:22:39 +0200
Subject: [R] cannot load .sav-files in R 3.4.0
Message-ID: <ab145567f6ef74a3250e518249b52c05@posteo.de>

after updating R from 3.3.3. to 3.4.0 i cannot import spss-data files 
anymore. for the european social survey (europeansocialsurvey.org) i get 
this warning:
re-encoding from CP1252
Fehler in levels<-(*tmp*, value = if (nl == nL) as.character(labels) 
else paste0(labels, :
factor level [3] is duplicated
Zus?tzlich: Warnmeldung:
In read.spss(file, use.value.labels = use.value.labels, to.data.frame = 
to.data.frame, :
//filepath/ESS7CH.sav: Unrecognized record type 7, subtype 18 
encountered in system file

using the package foreign does the same.


From ajdamico at gmail.com  Mon May  1 16:10:04 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Mon, 1 May 2017 10:10:04 -0400
Subject: [R] cannot load .sav-files in R 3.4.0
In-Reply-To: <ab145567f6ef74a3250e518249b52c05@posteo.de>
References: <ab145567f6ef74a3250e518249b52c05@posteo.de>
Message-ID: <CAOwvMDwJURzX1Q3MkCsHKaANmxWhGa+xAdDDd12MpyqjBqXuBQ@mail.gmail.com>

hi, i don't think foreign::read.spss or haven::read_spss have ever worked
with a handful of the ess files, but library(memisc) does.  you are better
off loading ess with library(lodown) because the drudge work has already
been done--


    library(devtools)
    devtools::install_github("ajdamico/lodown")
    library(lodown)
    ess_cat <- get_catalog( "ess" , output_dir = "C:/My Directory/ESS" )

    # which entries do you want?
    head(ess_cat)

    # how about wave 7 only
    sub_ess_cat <- subset( ess_cat , wave == 7 )

    # replace the email address with whatever you registered with
    lodown( "ess" , sub_ess_cat , your_email = "email at address.com" )


    x <- readRDS( "C:/My Directory/ESS/2014/ESS7csCH.rds" )

    # looks good
    head( x )



On Mon, May 1, 2017 at 6:22 AM, <katharina.manderscheid at posteo.de> wrote:

> after updating R from 3.3.3. to 3.4.0 i cannot import spss-data files
> anymore. for the european social survey (europeansocialsurvey.org) i get
> this warning:
> re-encoding from CP1252
> Fehler in levels<-(*tmp*, value = if (nl == nL) as.character(labels) else
> paste0(labels, :
> factor level [3] is duplicated
> Zus?tzlich: Warnmeldung:
> In read.spss(file, use.value.labels = use.value.labels, to.data.frame =
> to.data.frame, :
> //filepath/ESS7CH.sav: Unrecognized record type 7, subtype 18 encountered
> in system file
>
> using the package foreign does the same.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rab45 at pitt.edu  Mon May  1 16:18:16 2017
From: rab45 at pitt.edu (Bilonick, Richard Anthony)
Date: Mon, 1 May 2017 14:18:16 +0000
Subject: [R] problem loading spss-files
In-Reply-To: <4a2f4ab2ff2ef858c5654754c13c2865@posteo.de>
References: <4a2f4ab2ff2ef858c5654754c13c2865@posteo.de>
Message-ID: <BN1PR04MB1877F5723326B1A4461D6ECC9140@BN1PR04MB187.namprd04.prod.outlook.com>

I pasted some of the error/warning message into Google and among other things:


http://stackoverflow.com/questions/21228518/what-is-attr-value-labels-when-reading-spss-into-r


This might begin to explain what is happening. Is a data.frame created?


Rick B.

________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Siouxsie <siouxsie at posteo.ch>
Sent: Monday, May 01, 2017 6:23 AM
To: R help
Subject: [R] problem loading spss-files

after updating R from 3.3.3. to 3.4.0 i cannot import spss-data files
anymore. for the european social survey (europeansocialsurvey.org) i get
this warning:
re-encoding from CP1252
Fehler in levels<-(*tmp*, value = if (nl == nL) as.character(labels)
else paste0(labels, :
factor level [3] is duplicated
Zus?tzlich: Warnmeldung:
In read.spss(file, use.value.labels = use.value.labels, to.data.frame =
to.data.frame, :
//filepath/ESS7CH.sav: Unrecognized record type 7, subtype 18
encountered in system file

using the package foreign does the same.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=01%7C01%7Crab45%40pitt.edu%7C8c4c5ed34ae94d3df7d208d4908f3bd2%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1&sdata=FolAovtD1w5XU%2BBcEDGu7DLbRYGJIcEDWu%2BUCl9j9tA%3D&reserved=0
PLEASE do read the posting guide https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&data=01%7C01%7Crab45%40pitt.edu%7C8c4c5ed34ae94d3df7d208d4908f3bd2%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1&sdata=xNrROh3MnSgpTaKT%2F6vi4ZT0ffXtmh7DbYh0IadrKa0%3D&reserved=0
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May  1 16:34:09 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 1 May 2017 07:34:09 -0700
Subject: [R] Lattice xyplot
In-Reply-To: <279279174.1150856.1493600840045@mail.yahoo.com>
References: <279279174.1150856.1493600840045.ref@mail.yahoo.com>
 <279279174.1150856.1493600840045@mail.yahoo.com>
Message-ID: <CAGxFJbSjfULry0=cn8LMBr6M7WYQBcpwHVcfcBGisf1qJtGE-g@mail.gmail.com>

Yes. type = "l" connects the points in the order given in the data, so
if the x's are not already ordered, the plots will be different after
ordering the x's.

e.g.

> x <- c(3,1,2,4,6,5)
> y <- 11:16
> xyplot(y~x. type = "l")


As for why ... that's just the way it was designed. You can always
order the data first, if you don't want this default.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 30, 2017 at 6:07 PM, array chip via R-help
<r-help at r-project.org> wrote:
> Dear all, I am new to lattice, so would appreciate anyone's help on the questions below. I am using xyplot to plot some trend in my dataset. Using the example dataset attached, I am trying to plot variable "y" over variable "time" for each subject "id":
> dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
> xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab = "Y")
>
> It appears that it just worked fine. But if I sort the "dat" first, the plot will look somewhat different!
> dat<-dat[order(dat$id, dat$time),]xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab = "Y")
> Why is that? Do you need to sort the data first before using xyplot? Why xyplot can not understand the dataset unless it is sorted first?
> Thanks,
> John
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Mon May  1 17:04:23 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 2 May 2017 01:04:23 +1000
Subject: [R] Lattice xyplot
In-Reply-To: <279279174.1150856.1493600840045@mail.yahoo.com>
References: <279279174.1150856.1493600840045.ref@mail.yahoo.com>
 <279279174.1150856.1493600840045@mail.yahoo.com>
Message-ID: <001e01d2c28c$38055810$a8100830$@bigpond.com>

In addition to Berts comments

Once you change the order you change the non factored  id' ordering. If you make it a factor it may be  easier to see what is going on
I think I have copied correctly - see the differences 

# original data
xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab = "Y")
# order
dat2<-dat[order(dat$id, dat$time),]
xyplot(y ~ time, data=dat2, groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab = "Y")
# make ID a factor
dat3 <- dat1
xyplot(y ~ time, data=dat3, groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab = "Y")
# ordered + ID a factor
dat4 <- dat3
dat4<-dat[order(dat4$id, dat4$time),]
xyplot(y ~ time, data=dat4, groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab = "Y")

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of array chip via R-help
Sent: Monday, 1 May 2017 11:07
To: r-help at r-project.org
Subject: [R] Lattice xyplot

Dear all, I am new to lattice, so would appreciate anyone's help on the questions below. I am using xyplot to plot some trend in my dataset. Using the example dataset attached, I am trying to plot variable "y" over variable "time" for each subject "id":
dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab = "Y")

It appears that it just worked fine. But if I sort the "dat" first, the plot will look somewhat different!
dat<-dat[order(dat$id, dat$time),]xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab = "Y")
Why is that? Do you need to sort the data first before using xyplot? Why xyplot can not understand the dataset unless it is sorted first?
Thanks,
John


From jdnewmil at dcn.davis.ca.us  Mon May  1 17:25:31 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 01 May 2017 08:25:31 -0700
Subject: [R] Lattice xyplot
In-Reply-To: <CAGxFJbSjfULry0=cn8LMBr6M7WYQBcpwHVcfcBGisf1qJtGE-g@mail.gmail.com>
References: <279279174.1150856.1493600840045.ref@mail.yahoo.com>
 <279279174.1150856.1493600840045@mail.yahoo.com>
 <CAGxFJbSjfULry0=cn8LMBr6M7WYQBcpwHVcfcBGisf1qJtGE-g@mail.gmail.com>
Message-ID: <F9A792E9-5953-4037-A53D-015EEE19CC8C@dcn.davis.ca.us>

It is not a question of whether lattice "understands" the unsorted data... imagine trying to plot 4 points to form a square instead of a trend line... you would NOT want lattice to sort those points for you. That lattice leaves your data alone gives you more flexibility, even while it adds work for certain applications. 

-- 
Sent from my phone. Please excuse my brevity.

On May 1, 2017 7:34:09 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Yes. type = "l" connects the points in the order given in the data, so
>if the x's are not already ordered, the plots will be different after
>ordering the x's.
>
>e.g.
>
>> x <- c(3,1,2,4,6,5)
>> y <- 11:16
>> xyplot(y~x. type = "l")
>
>
>As for why ... that's just the way it was designed. You can always
>order the data first, if you don't want this default.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, Apr 30, 2017 at 6:07 PM, array chip via R-help
><r-help at r-project.org> wrote:
>> Dear all, I am new to lattice, so would appreciate anyone's help on
>the questions below. I am using xyplot to plot some trend in my
>dataset. Using the example dataset attached, I am trying to plot
>variable "y" over variable "time" for each subject "id":
>> dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
>> xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p",
>"l"),  xlab = "Time", ylab = "Y")
>>
>> It appears that it just worked fine. But if I sort the "dat" first,
>the plot will look somewhat different!
>> dat<-dat[order(dat$id, dat$time),]xyplot(y ~ time, data=dat,
>groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab =
>"Y")
>> Why is that? Do you need to sort the data first before using xyplot?
>Why xyplot can not understand the dataset unless it is sorted first?
>> Thanks,
>> John
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon May  1 17:59:16 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 1 May 2017 08:59:16 -0700
Subject: [R] Lattice xyplot
In-Reply-To: <F9A792E9-5953-4037-A53D-015EEE19CC8C@dcn.davis.ca.us>
References: <279279174.1150856.1493600840045.ref@mail.yahoo.com>
 <279279174.1150856.1493600840045@mail.yahoo.com>
 <CAGxFJbSjfULry0=cn8LMBr6M7WYQBcpwHVcfcBGisf1qJtGE-g@mail.gmail.com>
 <F9A792E9-5953-4037-A53D-015EEE19CC8C@dcn.davis.ca.us>
Message-ID: <CAGxFJbSfn-PTDfNHCax8Z2bd0mhnV8jH19XsKE2ajw7gqY8W-w@mail.gmail.com>

(Too trivial for the list)

I debated saying something similar but decided not to, as polygons can
be drawn e.g. via panel.polygon.

Cheers,
Bert




On Mon, May 1, 2017 at 8:25 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> It is not a question of whether lattice "understands" the unsorted data... imagine trying to plot 4 points to form a square instead of a trend line... you would NOT want lattice to sort those points for you. That lattice leaves your data alone gives you more flexibility, even while it adds work for certain applications.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 1, 2017 7:34:09 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>Yes. type = "l" connects the points in the order given in the data, so
>>if the x's are not already ordered, the plots will be different after
>>ordering the x's.
>>
>>e.g.
>>
>>> x <- c(3,1,2,4,6,5)
>>> y <- 11:16
>>> xyplot(y~x. type = "l")
>>
>>
>>As for why ... that's just the way it was designed. You can always
>>order the data first, if you don't want this default.
>>
>>Cheers,
>>Bert
>>
>>Bert Gunter
>>
>>"The trouble with having an open mind is that people keep coming along
>>and sticking things into it."
>>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>On Sun, Apr 30, 2017 at 6:07 PM, array chip via R-help
>><r-help at r-project.org> wrote:
>>> Dear all, I am new to lattice, so would appreciate anyone's help on
>>the questions below. I am using xyplot to plot some trend in my
>>dataset. Using the example dataset attached, I am trying to plot
>>variable "y" over variable "time" for each subject "id":
>>> dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
>>> xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p",
>>"l"),  xlab = "Time", ylab = "Y")
>>>
>>> It appears that it just worked fine. But if I sort the "dat" first,
>>the plot will look somewhat different!
>>> dat<-dat[order(dat$id, dat$time),]xyplot(y ~ time, data=dat,
>>groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab =
>>"Y")
>>> Why is that? Do you need to sort the data first before using xyplot?
>>Why xyplot can not understand the dataset unless it is sorted first?
>>> Thanks,
>>> John
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Mon May  1 18:15:17 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Mon, 1 May 2017 12:15:17 -0400
Subject: [R] cannot load .sav-files in R 3.4.0
In-Reply-To: <e2d100f4cf4ec842049b42d9d37c872b@posteo.de>
References: <ab145567f6ef74a3250e518249b52c05@posteo.de>
 <CAOwvMDwJURzX1Q3MkCsHKaANmxWhGa+xAdDDd12MpyqjBqXuBQ@mail.gmail.com>
 <e2d100f4cf4ec842049b42d9d37c872b@posteo.de>
Message-ID: <CAOwvMDy1G3=xc+Qz3Tsts-y-s17wswx4NDdEU7ssjaR8ofxoBA@mail.gmail.com>

did my code work?  thanks

On Mon, May 1, 2017 at 11:35 AM, <katharina.manderscheid at posteo.de> wrote:

> hi, thanks for the reply!
> it always worked until 3.4.0. i got warning but they did not stop R
> loading the file ...
>
> Am 01.05.2017 16:10 schrieb Anthony Damico:
>
>> hi, i don't think foreign::read.spss or haven::read_spss have ever
>> worked with a handful of the ess files, but library(memisc) does.  you
>> are better off loading ess with library(lodown) because the drudge
>> work has already been done--
>>
>>     library(devtools)
>>     devtools::install_github("ajdamico/lodown")
>>     library(lodown)
>>     ess_cat <- get_catalog( "ess" , output_dir = "C:/My Directory/ESS"
>> )
>>
>>     # which entries do you want?
>>     head(ess_cat)
>>
>>     # how about wave 7 only
>>     sub_ess_cat <- subset( ess_cat , wave == 7 )
>>
>>     # replace the email address with whatever you registered with
>>     lodown( "ess" , sub_ess_cat , your_email = "email at address.com" )
>>
>>     x <- readRDS( "C:/My Directory/ESS/2014/ESS7csCH.rds" )
>>
>>     # looks good
>>     head( x )
>>
>> On Mon, May 1, 2017 at 6:22 AM, <katharina.manderscheid at posteo.de>
>> wrote:
>>
>> after updating R from 3.3.3. to 3.4.0 i cannot import spss-data
>>> files anymore. for the european social survey
>>> (europeansocialsurvey.org [1]) i get this warning:
>>> re-encoding from CP1252
>>> Fehler in levels<-(*tmp*, value = if (nl == nL)
>>> as.character(labels) else paste0(labels, :
>>> factor level [3] is duplicated
>>> Zus?tzlich: Warnmeldung:
>>> In read.spss(file, use.value.labels = use.value.labels,
>>> to.data.frame = to.data.frame, :
>>> //filepath/ESS7CH.sav: Unrecognized record type 7, subtype 18
>>> encountered in system file
>>>
>>> using the package foreign does the same.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help [2]
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html [3]
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> Links:
>> ------
>> [1] http://europeansocialsurvey.org
>> [2] https://stat.ethz.ch/mailman/listinfo/r-help
>> [3] http://www.R-project.org/posting-guide.html
>>
>

	[[alternative HTML version deleted]]


From SeshanV at mskcc.org  Mon May  1 18:21:10 2017
From: SeshanV at mskcc.org (SeshanV at mskcc.org)
Date: Mon, 1 May 2017 16:21:10 +0000
Subject: [R] survival package can't find Ccoxfit6
In-Reply-To: <f9e0b9cd-03a1-cea7-80b9-4be008c95524@gmail.com>
References: <CDC04FFA7FC22548ADD6AECFA993565DE5CB9DD2@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>
 <47cabe$6a6f5l@ironport10.mayo.edu>
 <22abe858-cb92-376f-baf4-65d42bca1c38@gmail.com>
 <125664f5-f052-06d6-c774-582a8493daf7@gmail.com>
 <f9e0b9cd-03a1-cea7-80b9-4be008c95524@gmail.com>
Message-ID: <CDC04FFA7FC22548ADD6AECFA993565DE5CBEE3C@SMSKPEX10MBX2.MSKCC.ROOT.MSKCC.ORG>

Thank you everyone for all your help. Dr. Therneau and I had some offline email exchange and he offered to add resid= and concordance= options which will reduce the computational overhead in resampling scenarios such as mine. It will also avoid having to access unexported internals.

Thanks,
Venkat


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Friday, April 28, 2017 6:46 PM
To: Henric Winell; Therneau, Terry M., Ph.D.; R-help
Cc: Seshan, Venkatraman E./Epidemiology-Biostatistics
Subject: Re: [R] survival package can't find Ccoxfit6

On 28/04/2017 5:37 PM, Henric Winell wrote:
> On 2017-04-26 22:17, Duncan Murdoch wrote:
>
>> On 26/04/2017 2:51 PM, Therneau, Terry M., Ph.D. wrote:
>>> A user contacted me directly about this, I answered with my best 
>>> understanding of the recent R-help discussion of the issue, and 
>>> their response to my response shows that I'm not quite right.
>>>
>>> I am emphatically not an MS Windows user so am asking for help -- 
>>> which I will cut/paste to this user and to the next dozen who will 
>>> invariably contact me directly.
>>>
>>> Thanks,
>>>    Terry Therneau
>>>
>>>
>>>
>>> -------- Forwarded Message --------
>>> Subject: RE: survival package
>>> Date: Wed, 26 Apr 2017 18:05:30 +0000
>>> From: SeshanV at mskcc.org
>>> To: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
>>>
>>> Thank you for the quick response. The session info command for 
>>> v3.4.0 does in fact report survival_2.41-3. Furthermore, while both 
>>> v3.3.1 and v3.40 are on the same computer the library paths do not 
>>> have any directory in common:
>>>
>>>> .libPaths()
>>> [1] "C:/Program Files/R/R-3.4.0/library"
>>>>
>>>
>>> and
>>>> .libPaths()
>>> [1] "C:/Program Files/R/R-3.3.1/library"
>>>>
>>>
>>>
>>> Thanks,
>>> Venkat
>>>
>>>
>>> -----Original Message-----
>>> From: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] Sent:
>>> Wednesday, April 26, 2017
>>> 1:42 PM
>>> To: Seshan, Venkatraman E./Epidemiology-Biostatistics
>>> Subject: Re: survival package
>>>
>>> This has been discussed in R-help by multiple people.  You have a
>>> pre-3.4 version of the
>>> survival package somewhere on your search path, and the method for 
>>> resolving .C calls has
>>> changed.   The sessionInfo command should report survival version 2.41-3.
>>>
>>> Terry T.
>>>
>>>
>>> On 04/26/2017 12:17 PM, SeshanV at mskcc.org wrote:
>>>> Dear Prof. Therneau,
>>>>
>>>> I am encountering an error message when I try to use the coxfit6 
>>>> routine from the survival package under the 3.4.0 version of R. The 
>>>> minimal function and the script are in the attached file. This 
>>>> function worked under earlier versions of R.
>>>>
>>>> -------------------------------------------------------------------
>>>> ---
>>>> -------------------------
>>>>
>>>> ***************************
>>>> **  Works under R-3.3.1  **
>>>> ***************************
>>>>
>>>>> source("coxfit6-issue.R")
>>>> [1] -0.4838181
>>>>
>>>>> sessionInfo()
>>>> R version 3.3.1 (2016-06-21)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 
>>>> x64 (build 7601) Service Pack 1
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252 [2] 
>>>> LC_CTYPE=English_United
>>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4] 
>>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] survival_2.39-4
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] Matrix_1.2-6    splines_3.3.1   grid_3.3.1      lattice_0.20-33
>>>>
>>>> -------------------------------------------------------------------
>>>> ---
>>>> -------------------------
>>>>
>>>> ***********************************
>>>> **  Does not work under R-3.4.0  **
>>>> ***********************************
>>>>
>>>>> library(survival)
>>>>> source("coxfit6-issue.R")
>>>> Error in .Call("Ccoxfit6", as.integer(control$iter.max), stime, 
>>>> as.integer(sstat),  :
>>>>    "Ccoxfit6" not available for .Call() for package "survival"
>>
>> As far as I can see, that line doesn't appear in the current survival 
>> source code, it's from some earlier version of the package.  The 
>> current one has
>>
>> coxfit <- .Call(Ccoxfit6,
>>                       as.integer(maxiter),
>>                       stime,
>>                       sstat,
>>                       x[sorted,],
>>                       as.double(offset[sorted]),
>>                       weights,
>>                       newstrat,
>>                       as.integer(method=="efron"),
>>                       as.double(control$eps),
>>                       as.double(control$toler.chol),
>>                       as.vector(init),
>>                       as.integer(1))  # internally rescale
>>
>> There are several differences, the one leading to the error being the 
>> change from "Ccoxfit6" in quotes, to Ccoxfit6 not in quotes.  That 
>> corresponds to the difference between a registered symbol and an 
>> unregistered one.
>
> I think it's worthwhile to point out that non-exported symbols are 
> available using ':::'.  See WRE Section 5.4.
>
> So, after fixing the argument list, just use 
> '.Call(survival:::Ccoxfit6, <args>)' instead of '.Call("Ccoxfit6", <args>, PACKAGE = "survival")'.
>

Yes, and in another section it says "Using foo:::f instead of foo::f allows access to unexported objects. This is generally not recommended, as the semantics of unexported objects may be changed by the package author in routine maintenance."

Duncan Murdoch

>
> Henric Winell
>
>
>
>>
>> Without seeing the code that led to the error message I can't really 
>> say how the error came about.  There are a few ways:
>>
>> - The user has a copy of the coxph.fit function from an older version 
>> of survival saved in their workspace, and are using that one instead 
>> of the current one.
>>
>> - Some part of your code returns functions, and one of those is 
>> making this call based on an object produced in an earlier version of survival.
>>
>> - There are really two versions of survival on the search path (or 
>> perhaps copied bits of one), and this call isn't in survival 2.41-3 at all.
>>
>> Duncan Murdoch
>>
>>>>> sessionInfo()
>>>> R version 3.4.0 (2017-04-21)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 
>>>> x64 (build 7601) Service Pack 1
>>>>
>>>> Matrix products: default
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252 [2] 
>>>> LC_CTYPE=English_United
>>>> States.1252 [3] LC_MONETARY=English_United States.1252 [4] 
>>>> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] survival_2.41-3
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] compiler_3.4.0  Matrix_1.2-9    splines_3.4.0   grid_3.4.0
>>>> [5] lattice_0.20-35
>>>>
>>>> -------------------------------------------------------------------
>>>> ---
>>>> -------------------------
>>>>
>>>> When I remove the quotes surrounding Ccoxfit6 in the function both 
>>>> versions give the error:
>>>>
>>>> Error in phcoefs(stim[ii], sts[ii], as.matrix(as.double(cvt[ii])), 
>>>> oo$coefficients,  :
>>>>    object 'Ccoxfit6' not found
>>>>
>>>>
>>>> I would greatly appreciate your help in resolving this.
>>>>
>>>> Thanks,
>>>> Venkat Seshan
>>>>
>>>
>>>
>>> ====================================================================
>>> =
>>>
>>>       Please note that this e-mail and any files transmitted from
>>>       Memorial Sloan Kettering Cancer Center may be privileged, 
>>> confidential,
>>>       and protected from disclosure under applicable law. If the 
>>> reader of
>>>       this message is not the intended recipient, or an employee or agent
>>>       responsible for delivering this message to the intended recipient,
>>>       you are hereby notified that any reading, dissemination, 
>>> distribution,
>>>       copying, or other use of this communication or any of its 
>>> attachments
>>>       is strictly prohibited.  If you have received this communication in
>>>       error, please notify the sender immediately by replying to 
>>> this message
>>>       and deleting this message, any attachments, and all copies and 
>>> backups
>>>       from your computer.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From macqueen1 at llnl.gov  Mon May  1 18:35:12 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 1 May 2017 16:35:12 +0000
Subject: [R] how to assign a value to a specific position of a list
In-Reply-To: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
References: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
Message-ID: <3DBA39F1-A298-4DEB-AC00-BB9FFAEB1F61@llnl.gov>

It's not clear what you're trying to do. However, to "assign a value to a specific position of a list", this example should show you how.

lst <- vector('list', 10)       ## see the help page for list
names(lst) <- paste0('list.',1:10)

## to assign 'a' to position 3:
pos <- 3
lst[[pos]] <- 'a'

I completely agree with Jeff Newmiller's recommendation to avoid using assign. It's probably the wrong tool for what you're trying to do (whatever that is).
(and note that I have borrowed Jeff's name "lst" for the list with 10 elements [not variables] whose names are "list_1" "list_2" etc.)
(and I refuse to use "_" in R object names, but that's a personal preference)

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 4/30/17, 8:17 AM, "R-help on behalf of Jinsong Zhao" <r-help-bounces at r-project.org on behalf of jszhao at yeah.net> wrote:

    Hi there,
    
    I have a problem with assign(). Here is the demo code:
    
    for (i in 1:10) {
        # create a list with variable name as list_1, list_2, ..., etc.
        assign(paste("list_", i, sep = ""), list())
        # I hope to assign 5 to list_?[[1]], but I don't know how to code it.
        # list_1[[1]] <- 5 # works, however
        assign(paste("list_", i, "[[1]]", sep = "", 5) # does not work
    }
    
    How to do? Is there any alternatives? Many thanks!
    
    Best,
    Jinsong
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From dcarlson at tamu.edu  Mon May  1 19:51:00 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 1 May 2017 17:51:00 +0000
Subject: [R] Finding nrows with specefic values&converting a matrix into
 a table
In-Reply-To: <CY4PR15MB13027066D0E356864CEBF3C0EF140@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB1302CF7250E53F1355136A2EEF120@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <d4cc329e65214b0b82ed62ba97f17a3f@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB130771231E54884C4B579797EF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <781d109c1e9644f0bab078460c645be9@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB13076BCF5ADB6ACA3C802F4AEF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <86cd68d71c404b1ba62f6fe40c63645c@exch-2p-mbx-w2.ads.tamu.edu>
 <DM5PR15MB130771F963A2AAC57FF686E7EF150@DM5PR15MB1307.namprd15.prod.outlook.com>,
 <6a33dbb5fdf7416e8de92a0a08139488@exch-2p-mbx-w2.ads.tamu.edu>
 <CY4PR15MB13027066D0E356864CEBF3C0EF140@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <b53cda3252f642e188c2c5ed6d80ef47@exch-2p-mbx-w2.ads.tamu.edu>

Copy your queries to the help list. Do not use html (google "send plain text email using hotmail"). Copy your actual code creating the object and writing with any warning or error message into your email. Do not just give us a description of what you did. Include information about the object you are trying to save using class() and dim(). Without that information, it is not possible to help you. Based on your email, we don't know if the problem is with R or with Excel. Different versions of Excel have different limits for the number of rows and columns. 

Why would you try both write.csv() and write.csv2() since they are the same except for how to represent decimal numbers? 

Have you tried using read.csv() to read the .csv file you created to see if it is the same size as the one you wrote?

Have you opened the .csv file in a text editor to see if it is properly formatted and contains the number of records you think it does?

David C

From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 7:20 PM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table 

I have been trying to export the file for about 5 hours now without a result!
I have read what is in the manual but did not find any formats?except write.table(),write.csv(), write.csv2(). No one works. I have also highlighted
?all table in R and copied it into an excel file but this has just copied
the first 200 rows and I have about 15000 rows. All my tries end with exporting all columns in a single column in the new file without separation.?

________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 01 May 2017 02:54 AM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
No. You are not using the correct command. Time to read the manual:

?write.table

You will find the answer to your question by looking at the alternate forms of? write.*().


David L. Carlson
Department of Anthropology
Texas A&M University

From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 2:36 PM
To: David L Carlson <dcarlson at tamu.edu>; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 

I'm trying?to write the table I have created from the matrix using 
write.table(mytable, file=?"mytable.txt"). I have imported this txt. file?into 
an Excel sheet but? all data have been typed in one column (Var1,Var2,&Freq.) 
and I want to see each vector in one column.?Have I used the correct syntax?

Regards?

________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 07:33 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
Show us the code you used. Don't just tell us what you did. It is likely that something you did after creating the matrix converted it to a data frame. Copy and paste your code to your emails.

> str(mydf)
'data.frame':?? 3 obs. of? 3 variables:
?$ x: int? 0 NA NA
?$ y: int? 5 0 NA
?$ z: int? 67 23 0

> data.frame(as.table(as.matrix(mydf)))
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA

David C


From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 11:13 AM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

str(mymatrix)
The Structure shows that this is a 'data.frame'?? of 120 obs. and 120 variables 
of numeric type. R deals with my matrix as a data frame although I used 
the function matrix() to produce this matrix which is not clear to me why. As this is already a data.frame, this may explains why R returns me the same 
matrix. What do you recommend now?

Many thanks 


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 30 April 2017 06:47 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
You did not give me any information about about your data using str() or class() so I'll guess that you have a matrix, e.g.:

> class(moredata)
[1] "matrix"
> as.data.frame.table(moredata)
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA
7??? x??? z?? 67
8??? y??? z?? 23
9??? z??? z??? 0


David C

From: abo dalash [mailto:abo_dlsh at hotmail.com] 
Sent: Sunday, April 30, 2017 10:09 AM
To: David L Carlson <dcarlson at tamu.edu>; r-help at R-project.org
Subject: Re: [R] Finding nrows with specefic values&converting a matrix into a table

Dear David ..,

Many thanks for this detailed answer.

Your guidance reg. the first task has resolved my issue and I have understood now how to perform this type of analysis. I have saved your learning tips in my script.

Reg. the Matrix-table conversion, could you please clarify this?more?.
I applied the function as.data.frame but this returned the same matrix 
without converting it into a list table. I'm not sure where is the problem
in my code :???mymatrix <- as.data.frame(mymatrix).

Many thanks for your support

Regards


________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 29 April 2017 11:38 PM
To: abo dalash; r-help at R-project.org
Subject: RE: [R] Finding nrows with specefic values&converting a matrix into a table 
?
First. Do not use html messages, only plain text. Second. Provide a small example data set, preferably using dput(). Just printing your data can hide important information. Third. Read the documentation. Your first example does not return a logical vector at all:

> dput(mydata)
structure(list(Col1 = c(123L, 443L, 566L), Col2 = c(566L, 54L, 
44L), Col3 = c(235L, 566L, 235L)), .Names = c("Col1", "Col2", 
"Col3"), class = "data.frame", row.names = c(NA, -3L))

> which(mydata == 566,235)
???? row col
[1,]?? 3?? 1
[2,]?? 1?? 2
[3,]?? 2?? 3

It locates cells with 566, but not 235 which is not a surprise because you did not provide a valid logical expression to which(). 

There are a number of ways to get what you want, but since you want to process rows, apply() is straightforward:

> Val566 <- apply(mydata, 1, function(x) any(x == 566))
> Val566
[1] TRUE TRUE TRUE
> Val235 <- apply(mydata, 1, function(x) any(x == 235)) 
> Val235
[1]? TRUE FALSE? TRUE
> which(Val235 & Val566)
[1] 1 3

You should read the manual pages on any(), apply(), dput() and which() and logical expressions:

> ?apply
> ?any
> ?dput
> ?which
> ?Comparison # ?"==" will also get you there.

For the second question, assuming you are beginning with a table object as R defines that term and not a matrix (since all tables are matrices, but all matrices are not tables):

> dput(moredata)
structure(c(0L, NA, NA, 5L, 0L, NA, 67L, 23L, 0L), .Dim = c(3L, 
3L), .Dimnames = list(c("x", "y", "z"), c("x", "y", "z")), class = "table")
> moredata
?? x? y? z
x? 0? 5 67
y NA? 0 23
z NA NA? 0

Note, that your example uses na rather than NA. R is case sensitive so na is just an ordinary character string while NA is a missing value indicator. This is one of the reasons that dput() is important

> moredata.df <- as.data.frame(moredata)
> moredata.df
? Var1 Var2 Freq
1??? x??? x??? 0
2??? y??? x?? NA
3??? z??? x?? NA
4??? x??? y??? 5
5??? y??? y??? 0
6??? z??? y?? NA
7??? x??? z?? 67
8??? y??? z?? 23
9??? z??? z??? 0
> moredata.df[order(moredata.df$Freq, decreasing=TRUE), ]
? Var1 Var2 Freq
7??? x??? z?? 67
8??? y??? z?? 23
4??? x??? y??? 5
1??? x??? x??? 0
5??? y??? y??? 0
9??? z??? z??? 0
2??? y??? x?? NA
3??? z??? x?? NA
6??? z??? y?? NA

For this you should read the following manual pages:

> ?as.data.frame
> ?order
> ?Extract

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of abo dalash
Sent: Saturday, April 29, 2017 10:14 AM
To: r-help at R-project.org
Subject: [R] Finding nrows with specefic values&converting a matrix into a table

Hi All


I'm trying to identify number of rows containing 2 specific values.

I tried : which(mydata == 566,235), but this returns logical values for all rows and any T in a certain row indicates the existence of one of these values but what I need to know is only number of rows in my data set with these 2 particular values considering these two values

as one pair per column. For example :


1????????? 123?? 566??? 235

2????????? 443??? 54????? 566

3????????? 566??? 44????? 235


here number of rows with the values 566&235 is 2 which are

rows 1 & 3. Row 2 has only 566 so it should not be included in

our calculation.


I also have a large matrix and wanted to convert it into a table so I can

easily identify the combination with higher frequencies.


The matrix looks like this:


??????????????????? x????? y????? z

x????????????????? 0????? 5?????? 67

y????????????????? na??? 0????? 23

z?????????????????? na?? na????? 0


and I would like to convert this into a table arranged with

higher values first like this :

x?????? z?????? 67

y?????? z?????? 23

x?????? y??????? 5

x?????? x??????? 0

y?????? y??????? 0

z??????? z??????? 0

y??????? x??????? na

z??????? x??????? na

z??????? y??????? na


Is there simple function to perform this conversion with some explanation about the Syntax


Regards



??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon May  1 20:03:03 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 1 May 2017 20:03:03 +0200
Subject: [R] Lattice xyplot
In-Reply-To: <CAGxFJbSfn-PTDfNHCax8Z2bd0mhnV8jH19XsKE2ajw7gqY8W-w@mail.gmail.com>
References: <279279174.1150856.1493600840045.ref@mail.yahoo.com>
 <279279174.1150856.1493600840045@mail.yahoo.com>
 <CAGxFJbSjfULry0=cn8LMBr6M7WYQBcpwHVcfcBGisf1qJtGE-g@mail.gmail.com>
 <F9A792E9-5953-4037-A53D-015EEE19CC8C@dcn.davis.ca.us>
 <CAGxFJbSfn-PTDfNHCax8Z2bd0mhnV8jH19XsKE2ajw7gqY8W-w@mail.gmail.com>
Message-ID: <9510B615-09FF-4941-90D3-FE2121FD1F94@gmail.com>


> On 1 May 2017, at 17:59 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> (Too trivial for the list)

...so you decided to include us only once? >;-)

-pd

> 
> I debated saying something similar but decided not to, as polygons can
> be drawn e.g. via panel.polygon.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> On Mon, May 1, 2017 at 8:25 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> It is not a question of whether lattice "understands" the unsorted data... imagine trying to plot 4 points to form a square instead of a trend line... you would NOT want lattice to sort those points for you. That lattice leaves your data alone gives you more flexibility, even while it adds work for certain applications.
>> 
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> On May 1, 2017 7:34:09 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> Yes. type = "l" connects the points in the order given in the data, so
>>> if the x's are not already ordered, the plots will be different after
>>> ordering the x's.
>>> 
>>> e.g.
>>> 
>>>> x <- c(3,1,2,4,6,5)
>>>> y <- 11:16
>>>> xyplot(y~x. type = "l")
>>> 
>>> 
>>> As for why ... that's just the way it was designed. You can always
>>> order the data first, if you don't want this default.
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Sun, Apr 30, 2017 at 6:07 PM, array chip via R-help
>>> <r-help at r-project.org> wrote:
>>>> Dear all, I am new to lattice, so would appreciate anyone's help on
>>> the questions below. I am using xyplot to plot some trend in my
>>> dataset. Using the example dataset attached, I am trying to plot
>>> variable "y" over variable "time" for each subject "id":
>>>> dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
>>>> xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p",
>>> "l"),  xlab = "Time", ylab = "Y")
>>>> 
>>>> It appears that it just worked fine. But if I sort the "dat" first,
>>> the plot will look somewhat different!
>>>> dat<-dat[order(dat$id, dat$time),]xyplot(y ~ time, data=dat,
>>> groups=id, aspect = "fill", type = c("p", "l"),  xlab = "Time", ylab =
>>> "Y")
>>>> Why is that? Do you need to sort the data first before using xyplot?
>>> Why xyplot can not understand the dataset unless it is sorted first?
>>>> Thanks,
>>>> John
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jmhannon.ucdavis at gmail.com  Mon May  1 22:57:30 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 1 May 2017 13:57:30 -0700
Subject: [R] Example of the use of the "crt" graphical parameter?
Message-ID: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>

Hi, folks.  This is an issue that we've defined away, but I recently
thought it would be useful to rotate characters in some marginal text
in a base-R plot.  I made a few stabs on using the "crt" parameter but
was unsuccessful.

I'm deliberately omitting details of my attempts, as I want just to
focus on the following: if you know of any working example of the use
of that parameter. will you please send me a link to it?  Thanks.

(Note that there are *many* links to Cathode Ray Tubes,)

-- Mike


From bgunter.4567 at gmail.com  Mon May  1 23:08:57 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 1 May 2017 14:08:57 -0700
Subject: [R] Example of the use of the "crt" graphical parameter?
In-Reply-To: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
References: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
Message-ID: <CAGxFJbS9C2ZdBP1jV09gEwAqWYWBHj7OYfMs+AChpcSDJyD+yw@mail.gmail.com>

Hard to know what you want or did without code.

But, a guess: did you want the "srt" parameter and not  "crt"?

Of course, it's always useful to read the man page, in this case for
?par, where it says:

(for crt):  "A numerical value specifying (in degrees) how **single
characters** should be rotated. It is unwise to expect values other
than multiples of 90 to work. Compare with srt which does string
rotation." [note: "string" = several characters = text]


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 1, 2017 at 1:57 PM, Michael Hannon
<jmhannon.ucdavis at gmail.com> wrote:
> Hi, folks.  This is an issue that we've defined away, but I recently
> thought it would be useful to rotate characters in some marginal text
> in a base-R plot.  I made a few stabs on using the "crt" parameter but
> was unsuccessful.
>
> I'm deliberately omitting details of my attempts, as I want just to
> focus on the following: if you know of any working example of the use
> of that parameter. will you please send me a link to it?  Thanks.
>
> (Note that there are *many* links to Cathode Ray Tubes,)
>
> -- Mike
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Mon May  1 23:47:24 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 1 May 2017 14:47:24 -0700
Subject: [R] Example of the use of the "crt" graphical parameter?
In-Reply-To: <CAGxFJbS9C2ZdBP1jV09gEwAqWYWBHj7OYfMs+AChpcSDJyD+yw@mail.gmail.com>
References: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
 <CAGxFJbS9C2ZdBP1jV09gEwAqWYWBHj7OYfMs+AChpcSDJyD+yw@mail.gmail.com>
Message-ID: <CACdH2ZbsDCYQhmREXB7P5Zd9hWcd5wkeC7LODUek6yF6AByVUg@mail.gmail.com>

Thanks, Bert.  I *did* mean crt, and I did read (and re-read) the man
page.  What I'm lacking, and the only thing I'm asking for, is a
working example of the use of that parameter.

-- Mike


On Mon, May 1, 2017 at 2:08 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Hard to know what you want or did without code.
>
> But, a guess: did you want the "srt" parameter and not  "crt"?
>
> Of course, it's always useful to read the man page, in this case for
> ?par, where it says:
>
> (for crt):  "A numerical value specifying (in degrees) how **single
> characters** should be rotated. It is unwise to expect values other
> than multiples of 90 to work. Compare with srt which does string
> rotation." [note: "string" = several characters = text]
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, May 1, 2017 at 1:57 PM, Michael Hannon
> <jmhannon.ucdavis at gmail.com> wrote:
>> Hi, folks.  This is an issue that we've defined away, but I recently
>> thought it would be useful to rotate characters in some marginal text
>> in a base-R plot.  I made a few stabs on using the "crt" parameter but
>> was unsuccessful.
>>
>> I'm deliberately omitting details of my attempts, as I want just to
>> focus on the following: if you know of any working example of the use
>> of that parameter. will you please send me a link to it?  Thanks.
>>
>> (Note that there are *many* links to Cathode Ray Tubes,)
>>
>> -- Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue May  2 00:20:04 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 1 May 2017 15:20:04 -0700
Subject: [R] Example of the use of the "crt" graphical parameter?
In-Reply-To: <CAGxFJbS9C2ZdBP1jV09gEwAqWYWBHj7OYfMs+AChpcSDJyD+yw@mail.gmail.com>
References: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
 <CAGxFJbS9C2ZdBP1jV09gEwAqWYWBHj7OYfMs+AChpcSDJyD+yw@mail.gmail.com>
Message-ID: <CAGxFJbQOq_a3AzKN6d0Ld-3xRSsSUC+nfv5ho_EvWRJMS7QO7w@mail.gmail.com>

FWIW:

"srt = 90" should rotate the whole string "aaaaaa" 90 degrees in a
call to text(), and it does.

I interpret "crt =90" to rotate the individual letters of "aaaaaa" 90
degrees, but it does not on my graphic device, RStudioGD.  It probably
works on some other devices, but I don't know which ones.

HTH.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 1, 2017 at 2:08 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Hard to know what you want or did without code.
>
> But, a guess: did you want the "srt" parameter and not  "crt"?
>
> Of course, it's always useful to read the man page, in this case for
> ?par, where it says:
>
> (for crt):  "A numerical value specifying (in degrees) how **single
> characters** should be rotated. It is unwise to expect values other
> than multiples of 90 to work. Compare with srt which does string
> rotation." [note: "string" = several characters = text]
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, May 1, 2017 at 1:57 PM, Michael Hannon
> <jmhannon.ucdavis at gmail.com> wrote:
>> Hi, folks.  This is an issue that we've defined away, but I recently
>> thought it would be useful to rotate characters in some marginal text
>> in a base-R plot.  I made a few stabs on using the "crt" parameter but
>> was unsuccessful.
>>
>> I'm deliberately omitting details of my attempts, as I want just to
>> focus on the following: if you know of any working example of the use
>> of that parameter. will you please send me a link to it?  Thanks.
>>
>> (Note that there are *many* links to Cathode Ray Tubes,)
>>
>> -- Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue May  2 00:28:30 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 1 May 2017 15:28:30 -0700
Subject: [R] Example of the use of the "crt" graphical parameter?
In-Reply-To: <CAGxFJbQOq_a3AzKN6d0Ld-3xRSsSUC+nfv5ho_EvWRJMS7QO7w@mail.gmail.com>
References: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
 <CAGxFJbS9C2ZdBP1jV09gEwAqWYWBHj7OYfMs+AChpcSDJyD+yw@mail.gmail.com>
 <CAGxFJbQOq_a3AzKN6d0Ld-3xRSsSUC+nfv5ho_EvWRJMS7QO7w@mail.gmail.com>
Message-ID: <CAF8bMcazVju59jm38vwYe1rZuypg76_Sf3dfDUrBNAKAdkNjjg@mail.gmail.com>

Perhaps R does what S+ does with par("crt").  S+'s help(par) says:

   crt=x
         character rotation in degrees measured counterclockwise from
horizontal.
         When srt is set, crt is automatically set to the same value,
unless crt
         appears later in the command than srt. Many graphics devices
ignore crt
         and use only srt, so setting them to different values has no
effect on those
         devices. A few graphics devices cannot rotate text, or can rotate
it only at
         multiples of 90 degrees.

"Many graphics devices" means "most modern graphics devices", where "modern"
means post 1990 or so, when pen plotters went out of fashion.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, May 1, 2017 at 3:20 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> FWIW:
>
> "srt = 90" should rotate the whole string "aaaaaa" 90 degrees in a
> call to text(), and it does.
>
> I interpret "crt =90" to rotate the individual letters of "aaaaaa" 90
> degrees, but it does not on my graphic device, RStudioGD.  It probably
> works on some other devices, but I don't know which ones.
>
> HTH.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, May 1, 2017 at 2:08 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > Hard to know what you want or did without code.
> >
> > But, a guess: did you want the "srt" parameter and not  "crt"?
> >
> > Of course, it's always useful to read the man page, in this case for
> > ?par, where it says:
> >
> > (for crt):  "A numerical value specifying (in degrees) how **single
> > characters** should be rotated. It is unwise to expect values other
> > than multiples of 90 to work. Compare with srt which does string
> > rotation." [note: "string" = several characters = text]
> >
> >
> > Cheers,
> > Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, May 1, 2017 at 1:57 PM, Michael Hannon
> > <jmhannon.ucdavis at gmail.com> wrote:
> >> Hi, folks.  This is an issue that we've defined away, but I recently
> >> thought it would be useful to rotate characters in some marginal text
> >> in a base-R plot.  I made a few stabs on using the "crt" parameter but
> >> was unsuccessful.
> >>
> >> I'm deliberately omitting details of my attempts, as I want just to
> >> focus on the following: if you know of any working example of the use
> >> of that parameter. will you please send me a link to it?  Thanks.
> >>
> >> (Note that there are *many* links to Cathode Ray Tubes,)
> >>
> >> -- Mike
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Tue May  2 01:42:54 2017
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 2 May 2017 11:42:54 +1200
Subject: [R] [FORGED] Re: Example of the use of the "crt" graphical
 parameter?
In-Reply-To: <CACdH2ZbsDCYQhmREXB7P5Zd9hWcd5wkeC7LODUek6yF6AByVUg@mail.gmail.com>
References: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
 <CAGxFJbS9C2ZdBP1jV09gEwAqWYWBHj7OYfMs+AChpcSDJyD+yw@mail.gmail.com>
 <CACdH2ZbsDCYQhmREXB7P5Zd9hWcd5wkeC7LODUek6yF6AByVUg@mail.gmail.com>
Message-ID: <76dd55b0-c566-893a-5d79-745aafe15c05@stat.auckland.ac.nz>

Hi

I do not recall ever using crt.  A grep of the source code suggests that 
no user-level functions ever refer to it either.  In other words, it 
appears to be basically unimplemented.

Specifically with regard to text in the margins of a base plot, in 
addition to every function ignoring crt, only the text() function 
listens to srt (and that draws in the plot region, not the margins); 
mtext() (for margin text) only listens to las, so can only do horizontal 
or vertical.

Paul

On 02/05/17 09:47, Michael Hannon wrote:
> Thanks, Bert.  I *did* mean crt, and I did read (and re-read) the man
> page.  What I'm lacking, and the only thing I'm asking for, is a
> working example of the use of that parameter.
>
> -- Mike
>
>
> On Mon, May 1, 2017 at 2:08 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Hard to know what you want or did without code.
>>
>> But, a guess: did you want the "srt" parameter and not  "crt"?
>>
>> Of course, it's always useful to read the man page, in this case for
>> ?par, where it says:
>>
>> (for crt):  "A numerical value specifying (in degrees) how **single
>> characters** should be rotated. It is unwise to expect values other
>> than multiples of 90 to work. Compare with srt which does string
>> rotation." [note: "string" = several characters = text]
>>
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, May 1, 2017 at 1:57 PM, Michael Hannon
>> <jmhannon.ucdavis at gmail.com> wrote:
>>> Hi, folks.  This is an issue that we've defined away, but I recently
>>> thought it would be useful to rotate characters in some marginal text
>>> in a base-R plot.  I made a few stabs on using the "crt" parameter but
>>> was unsuccessful.
>>>
>>> I'm deliberately omitting details of my attempts, as I want just to
>>> focus on the following: if you know of any working example of the use
>>> of that parameter. will you please send me a link to it?  Thanks.
>>>
>>> (Note that there are *many* links to Cathode Ray Tubes,)
>>>
>>> -- Mike
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From drjimlemon at gmail.com  Tue May  2 02:23:10 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 2 May 2017 10:23:10 +1000
Subject: [R] Example of the use of the "crt" graphical parameter?
In-Reply-To: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
References: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
Message-ID: <CA+8X3fU-Ms6h6VDqb9Luvq=cV8EVrZ+Zv=NFH+uEC-9NRBcAxQ@mail.gmail.com>

Hi Michael,
The arctext function (plotrix) does something similar, and the code
could be modified to do what you request. If you do want a working
function, it wouldn't be too hard to program.

Jim


On Tue, May 2, 2017 at 6:57 AM, Michael Hannon
<jmhannon.ucdavis at gmail.com> wrote:
> Hi, folks.  This is an issue that we've defined away, but I recently
> thought it would be useful to rotate characters in some marginal text
> in a base-R plot.  I made a few stabs on using the "crt" parameter but
> was unsuccessful.
>
> I'm deliberately omitting details of my attempts, as I want just to
> focus on the following: if you know of any working example of the use
> of that parameter. will you please send me a link to it?  Thanks.
>
> (Note that there are *many* links to Cathode Ray Tubes,)
>
> -- Mike
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jszhao at yeah.net  Tue May  2 02:37:00 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Tue, 2 May 2017 08:37:00 +0800
Subject: [R] how to assign a value to a specific position of a list
In-Reply-To: <95A191C7-9718-4510-8598-F2288563BC41@gmail.com>
References: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
 <95A191C7-9718-4510-8598-F2288563BC41@gmail.com>
Message-ID: <2ee78d0b-286a-036d-c09d-278077d8b311@yeah.net>

Thank you very much, and your reply is helpful.

I don't like assign, and even don't use parse in my previous codes. 
However, in the case I encountered, assign and parse may be the right 
tools. Here is the code I used:

# in the workspace, there are tens directory.
# In each directory, there are lots of *.ASC file,
# with second column is the data.
# Each *.ASC file has a name with pattern i-tr-??.ASC.
# i is the directory name, tr is a group name, and ?? are the index.
# I have to collect all tr-?? into a matrix,
# and put all i-tr-?? into a list EEM_i.

for (i in dir()) {
    assign(paste("EEM_",i,sep=""), list())
    fn <- list.files(path = i, pattern = "ASC")
    tr <- sort(as.numeric(unique(unlist(lapply(strsplit(fn, "-"),"[[", 
2)))))
    for (j in 1:length(tr)) {
       fn_tr <- list.files(path = i, pattern = paste(i, tr[j], "...ASC", 
sep="-"))
       EEM_tmp <- matrix(NA,ncol = length(fn_tr),nrow = 371)
       for (k in 1:length(fn_tr)) {
          data_tmp <- read.csv(paste(i,fn_tr[k],sep="/"), header = FALSE)
          if (dim(data_tmp)[1] != 371) next
          EEM_tmp[,k] <- data_tmp[,2]
       }
       eval(parse(text=paste("EEM_",i,"[[",j,"]]<-","EEM_tmp", sep="")))
    }
}

Any alternatives or improvements? Thanks a lot.

Best,
Jinsong

On 2017/4/30 23:48, peter dalgaard wrote:
> assign(paste("list_", i, "[[1]]", sep = ""), 5) creates a new variable with a funny name.
>
> You'd have to parse() and eval() to make that work, something like
>
> eval(parse(text=paste("list_",i,"[[1]]<-",5, sep="")))
>
> However,
> -------
>> fortunes::fortune("parse")
>
> If the answer is parse() you should usually rethink the question.
>    -- Thomas Lumley
>       R-help (February 2005)
> -------
>
> It is much easier to handle this using a data structure containing a list of lists:
>
> l <- rep(list(list()), 10)
> for ( i in 1:10 )
>    l[[i]][[1]] <- 5
>
>> On 30 Apr 2017, at 17:17 , Jinsong Zhao <jszhao at yeah.net> wrote:
>>
>> Hi there,
>>
>> I have a problem with assign(). Here is the demo code:
>>
>> for (i in 1:10) {
>>   # create a list with variable name as list_1, list_2, ..., etc.
>>   assign(paste("list_", i, sep = ""), list())
>>   # I hope to assign 5 to list_?[[1]], but I don't know how to code it.
>>   # list_1[[1]] <- 5 # works, however
>>   assign(paste("list_", i, "[[1]]", sep = "", 5) # does not work
>> }
>>
>> How to do? Is there any alternatives? Many thanks!
>>
>> Best,
>> Jinsong
>>


From jmhannon.ucdavis at gmail.com  Tue May  2 05:50:51 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 1 May 2017 20:50:51 -0700
Subject: [R] [FORGED] Re: Example of the use of the "crt" graphical
	parameter?
In-Reply-To: <76dd55b0-c566-893a-5d79-745aafe15c05@stat.auckland.ac.nz>
References: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
 <CAGxFJbS9C2ZdBP1jV09gEwAqWYWBHj7OYfMs+AChpcSDJyD+yw@mail.gmail.com>
 <CACdH2ZbsDCYQhmREXB7P5Zd9hWcd5wkeC7LODUek6yF6AByVUg@mail.gmail.com>
 <76dd55b0-c566-893a-5d79-745aafe15c05@stat.auckland.ac.nz>
Message-ID: <CACdH2ZbjyOORn4rAHJ5iJ+61CLYM8M441=rxxbQH6ui2uMX9Cg@mail.gmail.com>

Hmm.  Thanks, Paul.  That would explain the dearth of examples.

-- Mike


On Mon, May 1, 2017 at 4:42 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> Hi
>
> I do not recall ever using crt.  A grep of the source code suggests that no
> user-level functions ever refer to it either.  In other words, it appears to
> be basically unimplemented.
>
> Specifically with regard to text in the margins of a base plot, in addition
> to every function ignoring crt, only the text() function listens to srt (and
> that draws in the plot region, not the margins); mtext() (for margin text)
> only listens to las, so can only do horizontal or vertical.
>
> Paul
>
>
> On 02/05/17 09:47, Michael Hannon wrote:
>>
>> Thanks, Bert.  I *did* mean crt, and I did read (and re-read) the man
>> page.  What I'm lacking, and the only thing I'm asking for, is a
>> working example of the use of that parameter.
>>
>> -- Mike
>>
>>
>> On Mon, May 1, 2017 at 2:08 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>>
>>> Hard to know what you want or did without code.
>>>
>>> But, a guess: did you want the "srt" parameter and not  "crt"?
>>>
>>> Of course, it's always useful to read the man page, in this case for
>>> ?par, where it says:
>>>
>>> (for crt):  "A numerical value specifying (in degrees) how **single
>>> characters** should be rotated. It is unwise to expect values other
>>> than multiples of 90 to work. Compare with srt which does string
>>> rotation." [note: "string" = several characters = text]
>>>
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, May 1, 2017 at 1:57 PM, Michael Hannon
>>> <jmhannon.ucdavis at gmail.com> wrote:
>>>>
>>>> Hi, folks.  This is an issue that we've defined away, but I recently
>>>> thought it would be useful to rotate characters in some marginal text
>>>> in a base-R plot.  I made a few stabs on using the "crt" parameter but
>>>> was unsuccessful.
>>>>
>>>> I'm deliberately omitting details of my attempts, as I want just to
>>>> focus on the following: if you know of any working example of the use
>>>> of that parameter. will you please send me a link to it?  Thanks.
>>>>
>>>> (Note that there are *many* links to Cathode Ray Tubes,)
>>>>
>>>> -- Mike
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/


From jmhannon.ucdavis at gmail.com  Tue May  2 06:03:36 2017
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 1 May 2017 21:03:36 -0700
Subject: [R] Example of the use of the "crt" graphical parameter?
In-Reply-To: <CA+8X3fU-Ms6h6VDqb9Luvq=cV8EVrZ+Zv=NFH+uEC-9NRBcAxQ@mail.gmail.com>
References: <CACdH2ZY7goJOP9pbFt0ivdsXU-CjHdVXZ63vJE8b-_ZO3ou7SQ@mail.gmail.com>
 <CA+8X3fU-Ms6h6VDqb9Luvq=cV8EVrZ+Zv=NFH+uEC-9NRBcAxQ@mail.gmail.com>
Message-ID: <CACdH2ZYeqyxqfHcnXz-=N5OTC95BjMM+1duAOn8t8=fvk-qMGg@mail.gmail.com>

Bendy like spaghetti :-)  Thanks, Jim.  I wasn't aware of plotrix, and
it does seem to be a cornucopia of useful, graphical stuff.

In this case, my quest for rotating characters stemmed from what you
might call a PHB request that I was eventually able to work around.  I
posed my original question here just out of curiosity (and
frustration, I guess).

-- Mike

On Mon, May 1, 2017 at 5:23 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Michael,
> The arctext function (plotrix) does something similar, and the code
> could be modified to do what you request. If you do want a working
> function, it wouldn't be too hard to program.
>
> Jim
>
>
> On Tue, May 2, 2017 at 6:57 AM, Michael Hannon
> <jmhannon.ucdavis at gmail.com> wrote:
>> Hi, folks.  This is an issue that we've defined away, but I recently
>> thought it would be useful to rotate characters in some marginal text
>> in a base-R plot.  I made a few stabs on using the "crt" parameter but
>> was unsuccessful.
>>
>> I'm deliberately omitting details of my attempts, as I want just to
>> focus on the following: if you know of any working example of the use
>> of that parameter. will you please send me a link to it?  Thanks.
>>
>> (Note that there are *many* links to Cathode Ray Tubes,)
>>
>> -- Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue May  2 07:05:16 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 1 May 2017 22:05:16 -0700 (PDT)
Subject: [R] how to assign a value to a specific position of a list
In-Reply-To: <2ee78d0b-286a-036d-c09d-278077d8b311@yeah.net>
References: <319cd86a-3f2e-2649-088e-c95d3090635c@yeah.net>
 <95A191C7-9718-4510-8598-F2288563BC41@gmail.com>
 <2ee78d0b-286a-036d-c09d-278077d8b311@yeah.net>
Message-ID: <alpine.BSF.2.00.1705012158220.16645@pedal.dcn.davis.ca.us>

The only thing "compelling" about your example is that you have the 
pre-conceived (wrong) notion that you have to store your objects under 
separate names in your global environment. That is not only wrong, it 
handicaps you for future unified processing of these data.

I see a lot of constructs in this code that I would change if there was a 
reproducible example here... but just reading code out of context all I 
feel like doing is replacing your uses of assign.

EEM <- list()
for (i in dir()) {
   EEM[[ i ]] <- list()
   fn <- list.files(path = i, pattern = "ASC")
   tr <- sort(as.numeric(unique(unlist(lapply(strsplit(fn, "-"),"[[",
                                              2)))))
   for (j in 1:length(tr)) {
     fn_tr <- list.files(path = i, pattern = paste(i, tr[j], "...ASC",
                                                   sep="-"))
     EEM_tmp <- matrix(NA,ncol = length(fn_tr),nrow = 371)
     for (k in 1:length(fn_tr)) {
       data_tmp <- read.csv(paste(i,fn_tr[k],sep="/"), header = FALSE)
       if (dim(data_tmp)[1] != 371) next
       EEM_tmp[,k] <- data_tmp[,2]
     }
     EEM[[ i ]][[ j ]] <- EEM_tmp
   }
}


On Tue, 2 May 2017, Jinsong Zhao wrote:

> Thank you very much, and your reply is helpful.
>
> I don't like assign, and even don't use parse in my previous codes. However, 
> in the case I encountered, assign and parse may be the right tools. Here is 
> the code I used:
>
> # in the workspace, there are tens directory.
> # In each directory, there are lots of *.ASC file,
> # with second column is the data.
> # Each *.ASC file has a name with pattern i-tr-??.ASC.
> # i is the directory name, tr is a group name, and ?? are the index.
> # I have to collect all tr-?? into a matrix,
> # and put all i-tr-?? into a list EEM_i.
>
> for (i in dir()) {
>   assign(paste("EEM_",i,sep=""), list())
>   fn <- list.files(path = i, pattern = "ASC")
>   tr <- sort(as.numeric(unique(unlist(lapply(strsplit(fn, "-"),"[[", 2)))))
>   for (j in 1:length(tr)) {
>      fn_tr <- list.files(path = i, pattern = paste(i, tr[j], "...ASC", 
> sep="-"))
>      EEM_tmp <- matrix(NA,ncol = length(fn_tr),nrow = 371)
>      for (k in 1:length(fn_tr)) {
>         data_tmp <- read.csv(paste(i,fn_tr[k],sep="/"), header = FALSE)
>         if (dim(data_tmp)[1] != 371) next
>         EEM_tmp[,k] <- data_tmp[,2]
>      }
>      eval(parse(text=paste("EEM_",i,"[[",j,"]]<-","EEM_tmp", sep="")))
>   }
> }
>
> Any alternatives or improvements? Thanks a lot.
>
> Best,
> Jinsong
>
> On 2017/4/30 23:48, peter dalgaard wrote:
>> assign(paste("list_", i, "[[1]]", sep = ""), 5) creates a new variable with 
>> a funny name.
>> 
>> You'd have to parse() and eval() to make that work, something like
>> 
>> eval(parse(text=paste("list_",i,"[[1]]<-",5, sep="")))
>> 
>> However,
>> -------
>>> fortunes::fortune("parse")
>> 
>> If the answer is parse() you should usually rethink the question.
>>    -- Thomas Lumley
>>       R-help (February 2005)
>> -------
>> 
>> It is much easier to handle this using a data structure containing a list 
>> of lists:
>> 
>> l <- rep(list(list()), 10)
>> for ( i in 1:10 )
>>    l[[i]][[1]] <- 5
>> 
>>> On 30 Apr 2017, at 17:17 , Jinsong Zhao <jszhao at yeah.net> wrote:
>>> 
>>> Hi there,
>>> 
>>> I have a problem with assign(). Here is the demo code:
>>> 
>>> for (i in 1:10) {
>>>   # create a list with variable name as list_1, list_2, ..., etc.
>>>   assign(paste("list_", i, sep = ""), list())
>>>   # I hope to assign 5 to list_?[[1]], but I don't know how to code it.
>>>   # list_1[[1]] <- 5 # works, however
>>>   assign(paste("list_", i, "[[1]]", sep = "", 5) # does not work
>>> }
>>> 
>>> How to do? Is there any alternatives? Many thanks!
>>> 
>>> Best,
>>> Jinsong
>>> 
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From arrayprofile at yahoo.com  Mon May  1 22:42:22 2017
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 1 May 2017 20:42:22 +0000 (UTC)
Subject: [R] Lattice xyplot
In-Reply-To: <F9A792E9-5953-4037-A53D-015EEE19CC8C@dcn.davis.ca.us>
References: <279279174.1150856.1493600840045.ref@mail.yahoo.com>
 <279279174.1150856.1493600840045@mail.yahoo.com>
 <CAGxFJbSjfULry0=cn8LMBr6M7WYQBcpwHVcfcBGisf1qJtGE-g@mail.gmail.com>
 <F9A792E9-5953-4037-A53D-015EEE19CC8C@dcn.davis.ca.us>
Message-ID: <2141826399.254.1493671342909@mail.yahoo.com>

Thanks all for the clarification!

      From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
 To: r-help at r-project.org; Bert Gunter <bgunter.4567 at gmail.com>; array chip <arrayprofile at yahoo.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org>
 Sent: Monday, May 1, 2017 10:53 AM
 Subject: Re: [R] Lattice xyplot
   
It is not a question of whether lattice "understands" the unsorted data... imagine trying to plot 4 points to form a square instead of a trend line... you would NOT want lattice to sort those points for you. That lattice leaves your data alone gives you more flexibility, even while it adds work for certain applications. 

-- 
Sent from my phone. Please excuse my brevity.

On May 1, 2017 7:34:09 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Yes. type = "l" connects the points in the order given in the data, so
>if the x's are not already ordered, the plots will be different after
>ordering the x's.
>
>e.g.
>
>> x <- c(3,1,2,4,6,5)
>> y <- 11:16
>> xyplot(y~x. type = "l")
>
>
>As for why ... that's just the way it was designed. You can always
>order the data first, if you don't want this default.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, Apr 30, 2017 at 6:07 PM, array chip via R-help
><r-help at r-project.org> wrote:
>> Dear all, I am new to lattice, so would appreciate anyone's help on
>the questions below. I am using xyplot to plot some trend in my
>dataset. Using the example dataset attached, I am trying to plot
>variable "y" over variable "time" for each subject "id":
>> dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
>> xyplot(y ~ time, data=dat, groups=id, aspect = "fill", type = c("p",
>"l"),? xlab = "Time", ylab = "Y")
>>
>> It appears that it just worked fine. But if I sort the "dat" first,
>the plot will look somewhat different!
>> dat<-dat[order(dat$id, dat$time),]xyplot(y ~ time, data=dat,
>groups=id, aspect = "fill", type = c("p", "l"),? xlab = "Time", ylab =
>"Y")
>> Why is that? Do you need to sort the data first before using xyplot?
>Why xyplot can not understand the dataset unless it is sorted first?
>> Thanks,
>> John
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From mmsaifuddin09 at gmail.com  Tue May  2 05:30:19 2017
From: mmsaifuddin09 at gmail.com (M.M saifuddin)
Date: Mon, 1 May 2017 22:30:19 -0500
Subject: [R] clip a raster according to a shape file in R.
Message-ID: <CAPkaqhfi5JS2B53kgDhuYvzCmoeXLNQQ+LR6x1VCW5WBqEjFxQ@mail.gmail.com>

I have a grid data which has values of a variable (e.g: Temperature). My
data has 6069 data points where each data point refers to different
latitude and longitude. I want to transform this data to a raster file so
that I can clip it according to a shapefile that has much smaller
boundaries than the raster ( actually the shapefile basins fall inside the
much larger raster file which covers the whole USA).

Can I do it by R? I know that this can be done by ArcGIS but I want to do
it with R.

Please help me.

TIA

	[[alternative HTML version deleted]]


From daniel.jeske at ucr.edu  Tue May  2 07:25:56 2017
From: daniel.jeske at ucr.edu (Daniel Jeske)
Date: Mon, 1 May 2017 22:25:56 -0700
Subject: [R] Unusual behavior in e1071?
Message-ID: <CAN_+Q_EJfgxanSwkKjCDuwbWdwuXc-CO6_+LBv2Ffbh1Wu=Z2Q@mail.gmail.com>

Hello -

I have noticed that when I run svm() the order of my data matters.  If the
first case in the data frame has y=+1 I get the expected decision rule that
says to classify as +1 if f(x)>0.  However, if the first case in the data
frame has y=-1 then apparently the decision rule being used says to
classify as +1 if f(x)<0, and in this case all the coefficients are
negative of their values compared to the first case.  So the two
classification rules are equivalent, but is a user really supposed to know
the difference?  It is likely they would assume the decision rule is always
to classify as +1 if f(x)>0.  Does anyone think the behavior I have noticed
is as intended, or is otherwise benign?

Thank you,
Daniel Jeske
Professor
Department of Statistics
University of California - Riverside

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue May  2 13:56:33 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 2 May 2017 11:56:33 +0000
Subject: [R] How create columns for squared values from previous columns?
In-Reply-To: <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
 <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF99955B@SRVEXCHCM301.precheza.cz>

Hi

you can use data.frame
data.frame(dat, dat[,1:3]^2)

and you can set names afterwards by names function.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of C W
> Sent: Saturday, April 29, 2017 3:22 AM
> To: r-help <r-help at r-project.org>
> Subject: Re: [R] How create columns for squared values from previous
> columns?
>
> I came up with this solution,
>
> > cbind(dat, dat[, 1:3]^2)
>            X1         X2         X3         X4          X5          X1
>     X2        X3
> 1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379 0.529641625
> 1.28428102 3.9432044
> 2  0.05126592  0.2858707  0.9075806 1.27582713 -0.49438507 0.002628194
> 0.08172203 0.8237026
> 3 -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475 0.163459669
> 0.29780978 1.4218277
> 4  1.40746971 -1.2279416  0.3296075 0.84411774 -0.52371619 1.980970990
> 1.50784058 0.1086411
> 5 -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500 0.289886944
> 0.22563275 0.2213842
> 6  0.90691210  0.7247171  0.8244184 0.73328097 -1.05284737 0.822489552
> 0.52521494 0.6796657
>
> But, you would NOT ONLY get undesired variable names, BUT ALSO
> duplicated names. I suppose I can use paste() to solve that?
>
> Any better ideas?
>
>
> On Fri, Apr 28, 2017 at 8:57 PM, C W <tmrsg11 at gmail.com> wrote:
>
> > Dear R list,
> >
> > I am am a little unsure what is the best way to approach this. I
> > suppose I have
> >
> > > dat <- matrix(rnorm(30), ncol = 5)
> > > dat <- data.frame(dat)
> > > dat
> >            X1          X2          X3         X4          X5
> > 1 -1.13999917 -0.87868106 -0.33000492  1.5241765 -0.92483388
> > 2 -0.56168006 -0.08837883  1.96237792 -0.5335615  0.02880586
> > 3  0.82800071 -1.89965562 -0.05438815 -0.9162857 -0.57470053
> > 4 -0.03218412 -0.23119263 -1.10671765 -0.2885518 -0.30953951
> > 5  1.70525779 -0.93854817 -1.05932636 -0.2983139 -0.21980145
> > 6  1.19047531  0.38301678 -0.20830015 -0.6668266  0.82578534
> >
> > Suppose I want to add columns X6, X7, X8, where
> > X6 = X1^2
> > X7 = X2^2
> > X8 = X3^2
> >
> > I am thinking of using apply(), but df asks for column names, what's a
> > quick way to generate names on the fly?
> >
> > Thank you very much!
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From tmrsg11 at gmail.com  Tue May  2 15:18:59 2017
From: tmrsg11 at gmail.com (Mike C)
Date: Tue, 2 May 2017 13:18:59 +0000
Subject: [R] How create columns for squared values from previous columns?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF99955B@SRVEXCHCM301.precheza.cz>
References: <CAE2FW2=GaxadU0hjSohrhhF_RmH3-1Nju=dpyiXKTwHFC9P6cA@mail.gmail.com>
 <CAE2FW2m4BP3yNDvY6yfxZHOUwgxz61ooYUeAc+7ZwoZ1p-bXEQ@mail.gmail.com>,
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF99955B@SRVEXCHCM301.precheza.cz>
Message-ID: <BN6PR13MB1490FBFB2B572077D5FFB375F5170@BN6PR13MB1490.namprd13.prod.outlook.com>

Ah, that works! Thank you!

________________________________
From: PIKAL Petr <petr.pikal at precheza.cz>
Sent: Tuesday, May 2, 2017 7:56:33 AM
To: C W; r-help
Subject: RE: [R] How create columns for squared values from previous columns?

Hi

you can use data.frame
data.frame(dat, dat[,1:3]^2)

and you can set names afterwards by names function.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of C W
> Sent: Saturday, April 29, 2017 3:22 AM
> To: r-help <r-help at r-project.org>
> Subject: Re: [R] How create columns for squared values from previous
> columns?
>
> I came up with this solution,
>
> > cbind(dat, dat[, 1:3]^2)
>            X1         X2         X3         X4          X5          X1
>     X2        X3
> 1  0.72776481 -1.1332612 -1.9857503 0.46189400 -0.09016379 0.529641625
> 1.28428102 3.9432044
> 2  0.05126592  0.2858707  0.9075806 1.27582713 -0.49438507 0.002628194
> 0.08172203 0.8237026
> 3 -0.40430146  0.5457195 -1.1924042 0.15025594  1.99710475 0.163459669
> 0.29780978 1.4218277
> 4  1.40746971 -1.2279416  0.3296075 0.84411774 -0.52371619 1.980970990
> 1.50784058 0.1086411
> 5 -0.53841150  0.4750082 -0.4705148 0.05591914 -0.31503500 0.289886944
> 0.22563275 0.2213842
> 6  0.90691210  0.7247171  0.8244184 0.73328097 -1.05284737 0.822489552
> 0.52521494 0.6796657
>
> But, you would NOT ONLY get undesired variable names, BUT ALSO
> duplicated names. I suppose I can use paste() to solve that?
>
> Any better ideas?
>
>
> On Fri, Apr 28, 2017 at 8:57 PM, C W <tmrsg11 at gmail.com> wrote:
>
> > Dear R list,
> >
> > I am am a little unsure what is the best way to approach this. I
> > suppose I have
> >
> > > dat <- matrix(rnorm(30), ncol = 5)
> > > dat <- data.frame(dat)
> > > dat
> >            X1          X2          X3         X4          X5
> > 1 -1.13999917 -0.87868106 -0.33000492  1.5241765 -0.92483388
> > 2 -0.56168006 -0.08837883  1.96237792 -0.5335615  0.02880586
> > 3  0.82800071 -1.89965562 -0.05438815 -0.9162857 -0.57470053
> > 4 -0.03218412 -0.23119263 -1.10671765 -0.2885518 -0.30953951
> > 5  1.70525779 -0.93854817 -1.05932636 -0.2983139 -0.21980145
> > 6  1.19047531  0.38301678 -0.20830015 -0.6668266  0.82578534
> >
> > Suppose I want to add columns X6, X7, X8, where
> > X6 = X1^2
> > X7 = X2^2
> > X8 = X3^2
> >
> > I am thinking of using apply(), but df asks for column names, what's a
> > quick way to generate names on the fly?
> >
> > Thank you very much!
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Tue May  2 15:42:34 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 2 May 2017 09:42:34 -0400
Subject: [R] cannot load .sav-files in R 3.4.0
In-Reply-To: <b89bdff42c8d12e5061123c126d2ae8c@posteo.de>
References: <ab145567f6ef74a3250e518249b52c05@posteo.de>
 <CAOwvMDwJURzX1Q3MkCsHKaANmxWhGa+xAdDDd12MpyqjBqXuBQ@mail.gmail.com>
 <e2d100f4cf4ec842049b42d9d37c872b@posteo.de>
 <CAOwvMDy1G3=xc+Qz3Tsts-y-s17wswx4NDdEU7ssjaR8ofxoBA@mail.gmail.com>
 <b89bdff42c8d12e5061123c126d2ae8c@posteo.de>
Message-ID: <CAOwvMDwtcOUJN9DZsZN9V-VHzDOafz8oTGmEe5TGWf=d2mUEiw@mail.gmail.com>

are you able to install anything from github?  like

devtools::install_github( "hadley/dplyr" )



On Tue, May 2, 2017 at 9:36 AM, <katharina.manderscheid at posteo.de> wrote:

> unfortunately it failed with the installation of lodown:
>
>> devtools::install_github("ajdamico/lodown")
>>
> Downloading GitHub repo ajdamico/lodown at master
> from URL https://api.github.com/repos/ajdamico/lodown/zipball/master
> Installing lodown
> "C:/PROGRA~1/R/R-33~1.3/bin/x64/R" --no-site-file --no-environ --no-save
> \
>   --no-restore --quiet CMD INSTALL  \
>   "C:/Users/mandersk/AppData/Local/Temp/Rtmpch0aTn/devtools18f
> 4305b4ab5/ajdamico-lodown-d235a3e"  \
>   --library="\\unetna01/mandersk$/Daten/R/win-library/3.3" --install-tests
>
> * installing *source* package 'lodown' ...
> ** R
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> *** arch - i386
> Warnung in library(pkg_name, lib.loc = lib, character.only = TRUE,
> logical.return = TRUE)
>   there is no package called 'lodown'
> Fehler: Laden fehlgeschlagen
> Ausf?hrung angehalten
> *** arch - x64
> Warnung in library(pkg_name, lib.loc = lib, character.only = TRUE,
> logical.return = TRUE)
>   there is no package called 'lodown'
> Fehler: Laden fehlgeschlagen
> Ausf?hrung angehalten
> ERROR: loading failed for 'i386', 'x64'
> * removing '\\unetna01/mandersk$/Daten/R/win-library/3.3/lodown'
> Error: Command failed (1)
>
> Am 01.05.2017 18:15 schrieb Anthony Damico:
>
>> did my code work?  thanks
>>
>> On Mon, May 1, 2017 at 11:35 AM, <katharina.manderscheid at posteo.de>
>> wrote:
>>
>> hi, thanks for the reply!
>>> it always worked until 3.4.0. i got warning but they did not stop R
>>> loading the file ...
>>>
>>> Am 01.05.2017 16:10 schrieb Anthony Damico:
>>> hi, i don't think foreign::read.spss or haven::read_spss have ever
>>> worked with a handful of the ess files, but library(memisc) does.
>>> you
>>> are better off loading ess with library(lodown) because the drudge
>>> work has already been done--
>>>
>>> library(devtools)
>>> devtools::install_github("ajdamico/lodown")
>>> library(lodown)
>>> ess_cat <- get_catalog( "ess" , output_dir = "C:/My
>>> Directory/ESS"
>>> )
>>>
>>> # which entries do you want?
>>> head(ess_cat)
>>>
>>> # how about wave 7 only
>>> sub_ess_cat <- subset( ess_cat , wave == 7 )
>>>
>>> # replace the email address with whatever you registered with
>>> lodown( "ess" , sub_ess_cat , your_email = "email at address.com"
>>> )
>>>
>>> x <- readRDS( "C:/My Directory/ESS/2014/ESS7csCH.rds" )
>>>
>>> # looks good
>>> head( x )
>>>
>>> On Mon, May 1, 2017 at 6:22 AM, <katharina.manderscheid at posteo.de>
>>> wrote:
>>>
>>> after updating R from 3.3.3. to 3.4.0 i cannot import spss-data
>>> files anymore. for the european social survey
>>> (europeansocialsurvey.org [1] [1]) i get this warning:
>>> re-encoding from CP1252
>>> Fehler in levels<-(*tmp*, value = if (nl == nL)
>>> as.character(labels) else paste0(labels, :
>>> factor level [3] is duplicated
>>> Zus?tzlich: Warnmeldung:
>>> In read.spss(file, use.value.labels = use.value.labels,
>>> to.data.frame = to.data.frame, :
>>> //filepath/ESS7CH.sav: Unrecognized record type 7, subtype 18
>>> encountered in system file
>>>
>>> using the package foreign does the same.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help [2] [2]
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html [3] [3]
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> Links:
>>> ------
>>> [1] http://europeansocialsurvey.org [1]
>>> [2] https://stat.ethz.ch/mailman/listinfo/r-help [2]
>>> [3] http://www.R-project.org/posting-guide.html [3]
>>>
>>
>>
>>
>> Links:
>> ------
>> [1] http://europeansocialsurvey.org
>> [2] https://stat.ethz.ch/mailman/listinfo/r-help
>> [3] http://www.R-project.org/posting-guide.html
>>
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue May  2 17:33:56 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 2 May 2017 17:33:56 +0200
Subject: [R] Unusual behavior in e1071?
In-Reply-To: <CAN_+Q_EJfgxanSwkKjCDuwbWdwuXc-CO6_+LBv2Ffbh1Wu=Z2Q@mail.gmail.com>
References: <CAN_+Q_EJfgxanSwkKjCDuwbWdwuXc-CO6_+LBv2Ffbh1Wu=Z2Q@mail.gmail.com>
Message-ID: <c5685072-ced0-70de-54e8-09dd77cda40f@statistik.tu-dortmund.de>

Look more carefully at y. If this is a factor, please note what is the 
first (reference) level and what the second. This determines the rule, 
not the value of the first observation.

Best,
Uwe Ligges

On 02.05.2017 07:25, Daniel Jeske wrote:
> Hello -
>
> I have noticed that when I run svm() the order of my data matters.  If the
> first case in the data frame has y=+1 I get the expected decision rule that
> says to classify as +1 if f(x)>0.  However, if the first case in the data
> frame has y=-1 then apparently the decision rule being used says to
> classify as +1 if f(x)<0, and in this case all the coefficients are
> negative of their values compared to the first case.  So the two
> classification rules are equivalent, but is a user really supposed to know
> the difference?  It is likely they would assume the decision rule is always
> to classify as +1 if f(x)>0.  Does anyone think the behavior I have noticed
> is as intended, or is otherwise benign?
>
> Thank you,
> Daniel Jeske
> Professor
> Department of Statistics
> University of California - Riverside
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Tue May  2 18:57:21 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 02 May 2017 09:57:21 -0700
Subject: [R] clip a raster according to a shape file in R.
In-Reply-To: <CAPkaqhfi5JS2B53kgDhuYvzCmoeXLNQQ+LR6x1VCW5WBqEjFxQ@mail.gmail.com>
References: <CAPkaqhfi5JS2B53kgDhuYvzCmoeXLNQQ+LR6x1VCW5WBqEjFxQ@mail.gmail.com>
Message-ID: <392F929D-431F-43ED-9D33-746F5238CA41@dcn.davis.ca.us>

The answer is yes. However there are quite a few online resources (including blogs and the CRAN Spatial Task View and vignettes for packages mentioned there) that describe various tools and step you through how to do this, and you have not provided a reproducible example, and there is a whole mailing list dedicated to the topic (R-sig-geo), so I will just suggest that you read the Posting Guide mentioned below and (if needed) show the R-sig-geo mailing list your best attempt so they know how to help you. 
-- 
Sent from my phone. Please excuse my brevity.

On May 1, 2017 8:30:19 PM PDT, "M.M saifuddin" <mmsaifuddin09 at gmail.com> wrote:
>I have a grid data which has values of a variable (e.g: Temperature).
>My
>data has 6069 data points where each data point refers to different
>latitude and longitude. I want to transform this data to a raster file
>so
>that I can clip it according to a shapefile that has much smaller
>boundaries than the raster ( actually the shapefile basins fall inside
>the
>much larger raster file which covers the whole USA).
>
>Can I do it by R? I know that this can be done by ArcGIS but I want to
>do
>it with R.
>
>Please help me.
>
>TIA
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From esawiek at gmail.com  Tue May  2 18:35:37 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Tue, 2 May 2017 12:35:37 -0400
Subject: [R] nested for loop with data table
Message-ID: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>

I have a huge data file; a sample is listed below. I am using the package
data table to process the file and I am stuck on one issue and need some
feedback. I used fread to create a data table. Then I divided the data
table (named File1) into 10 general subsets using common table commands
such as:



AAA <- File1[Num<5&day>15]

BBB <- File1[Num>15&day<10]

?..

?..

?..

?..

?..

?..



I wanted to divide and count each of the above subsets based on a set of
parameters common to all subsets. I did the following to go through each
subset and it works:

For (I in 1: length (AAA)) {

              aa <- c(AAA[color==?green?&grade==?a?,month==?Januray? .N],[
AAA[color==?green?&grade==?b?& month==?June?? .N])

}



The question: I don?t want to have a separate loop for each subset (10
loops). Instead, I was hoping to have 2 nested loops in the form below:



For (I in 1:N)){

              For (j in 1:M){



}

}



 Sample


Num

Color

Grade

Value

Month

Day

1

yellow

A

20

May

1

2

green

B

25

June

2

3

green

A

10

April

3

4

black

A

17

August

3

5

red

C

5

December

5

6

orange

D

0

January

13

7

orange

E

12

January

5

8

orange

F

11

February

8

9

orange

F

99

July

23

10

orange

F

70

May

7

11

black

A

77

June

11

12

green

B

87

April

33

13

black

A

79

August

9

14

green

A

68

December

14

15

black

C

90

January

31

16

green

D

79

January

11

17

black

E

101

February

17

18

red

F

90

July

21

19

red

F

112

February

13

20

red

F

101

July

20

	[[alternative HTML version deleted]]


From asengupta94404 at yahoo.com  Tue May  2 18:59:26 2017
From: asengupta94404 at yahoo.com (Amit Sengupta)
Date: Tue, 2 May 2017 16:59:26 +0000 (UTC)
Subject: [R] memory problem
References: <1039705102.836708.1493744366930.ref@mail.yahoo.com>
Message-ID: <1039705102.836708.1493744366930@mail.yahoo.com>

Hi,I was unable to read a 2.4 gig file into an R object using read.table in 64 bit R environment. Please let me have your suggestions.Amit Sengupta

	[[alternative HTML version deleted]]


From frymor at gmail.com  Tue May  2 20:51:04 2017
From: frymor at gmail.com (Assa Yeroslaviz)
Date: Tue, 02 May 2017 18:51:04 +0000
Subject: [R] install lapack for mac
Message-ID: <CA+8Xemxbuk-HxUMAdjr88qfFcgteAfWTa3xL7O3GJSD__c-H6w@mail.gmail.com>

Hi,

I am running R under Rstudio for the analysis of single-cell RNA-Seq data.

When trying to analyse some data I keep getting the message

> slicer_traj_lle <- lle(t(deng[slicer_genes,]), m = 2, k)$Y
finding neighbours
calculating weights
Error in eigen(G, symmetric = TRUE, only.values = TRUE) :
  LAPACK routines cannot be loaded


After searching the net I couldn't find a way to install LAPACK on a mac.
When trying to install it via homebrew I get this message (this is a
shorted message. the complete message is below):

brew install lapack

...

macOS already provides this software and installing another version in

parallel can cause all kinds of trouble.

For compilers to find this software you may need to set:

    LDFLAGS:  -L/usr/local/opt/lapack/lib

    CPPFLAGS: -I/usr/local/opt/lapack/include

For pkg-config to find this software you may need to set:

    PKG_CONFIG_PATH: /usr/local/opt/lapack/lib/pkgconfig


I truely don't understand why my mac can't find the lapack, if it already
there and i still can't figure out, how to tell my R tool / RStudio, where
to find lapack.

Does anyone has an idea how to do this?

thanks

Assa
> R.version
               _
platform       x86_64-apple-darwin13.4.0
arch           x86_64
os             darwin13.4.0
system         x86_64, darwin13.4.0
status
major          3
minor          3.1
year           2016
month          06
day            21
svn rev        70800
language       R
version.string R version 3.3.1 (2016-06-21)
nickname       Bug in Your Hair


> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.12.4 (Sierra)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
 [1] splines   stats4    parallel  stats     graphics  grDevices utils
datasets  methods
[10] base

other attached packages:
 [1] R.utils_2.5.0        R.oo_1.21.0          R.methodsS3_1.7.1
 Seurat_1.4.0.14
 [5] cowplot_0.7.0        SLICER_0.2.0         alphahull_2.1        lle_1.1

 [9] snowfall_1.84-6.1    snow_0.4-2           MASS_7.3-47
 scatterplot3d_0.3-40
[13] igraph_1.0.1         destiny_2.0.8        monocle_2.2.0
 DDRTree_0.1.4
[17] irlba_2.1.2          VGAM_1.0-3           ggplot2_2.2.1
 Biobase_2.34.0
[21] BiocGenerics_0.20.0  Matrix_1.2-8         M3Drop_1.0.0
numDeriv_2016.8-1
[25] TSCAN_1.12.0

loaded via a namespace (and not attached):
  [1] shinydashboard_0.5.3   lme4_1.1-13            RSQLite_1.1-2
  [4] AnnotationDbi_1.36.2   htmlwidgets_0.8        grid_3.3.1
  [7] combinat_0.0-8         trimcluster_0.1-2      ranger_0.7.0
 [10] Rtsne_0.13             munsell_0.4.3          codetools_0.2-15
 [13] statmod_1.4.29         colorspace_1.3-2       fastICA_1.2-0
 [16] knitr_1.15.1           ROCR_1.0-7             robustbase_0.92-7
 [19] vcd_1.4-3              tensor_1.5             VIM_4.7.0
 [22] TTR_0.23-1             lars_1.2               slam_0.1-40
 [25] splancs_2.01-40        bbmle_1.0.19           mnormt_1.5-5
 [28] polyclip_1.6-1         pheatmap_1.0.8         rprojroot_1.2
 [31] diptest_0.75-7         R6_2.2.0               RcppEigen_0.3.2.9.1
 [34] flexmix_2.3-14         bitops_1.0-6           spatstat.utils_1.4-1
 [37] assertthat_0.2.0       scales_0.4.1           nnet_7.3-12
 [40] gtable_0.2.0           goftest_1.1-1          MatrixModels_0.4-1
 [43] lazyeval_0.2.0         ModelMetrics_1.1.0     acepack_1.4.1
 [46] checkmate_1.8.2        reshape2_1.4.2         abind_1.4-5
 [49] backports_1.0.5        httpuv_1.3.3           rsconnect_0.7
 [52] Hmisc_4.0-2            caret_6.0-76           tools_3.3.1
 [55] gplots_3.0.1           RColorBrewer_1.1-2     proxy_0.4-16
 [58] Rcpp_0.12.10           plyr_1.8.4             base64enc_0.1-3
 [61] RCurl_1.95-4.8         rpart_4.1-11           deldir_0.1-14
 [64] pbapply_1.3-2          viridis_0.4.0          S4Vectors_0.12.2
 [67] zoo_1.8-0              cluster_2.0.6          magrittr_1.5
 [70] data.table_1.10.4      SparseM_1.77           lmtest_0.9-35
 [73] mvtnorm_1.0-6          matrixStats_0.52.2     mime_0.5
 [76] evaluate_0.10          xtable_1.8-2           smoother_1.1
 [79] pbkrtest_0.4-7         XML_3.98-1.6           mclust_5.2.3
 [82] IRanges_2.8.2          gridExtra_2.2.1        HSMMSingleCell_0.108.0
 [85] biomaRt_2.30.0         tibble_1.3.0           KernSmooth_2.23-15
 [88] minqa_1.2.4            htmltools_0.3.6        segmented_0.5-1.4
 [91] mgcv_1.8-17            Formula_1.2-1          tclust_1.2-3
 [94] DBI_0.6-1              fpc_2.1-10             boot_1.3-19
 [97] car_2.1-4              sgeostat_1.0-27        gdata_2.17.0
[100] sn_1.5-0               foreign_0.8-68         laeken_0.4.6
[103] sp_1.2-4               foreach_1.4.3          stringr_1.2.0
[106] digest_0.6.12          tsne_0.1-3             rmarkdown_1.5
[109] htmlTable_1.9          kernlab_0.9-25         shiny_1.0.3
[112] gtools_3.5.0           quantreg_5.33          modeltools_0.2-21
[115] nloptr_1.0.4           nlme_3.1-131           viridisLite_0.2.0
[118] limma_3.30.13          lattice_0.20-35        DEoptimR_1.0-8
[121] survival_2.41-3        xts_0.9-7              qlcMatrix_0.9.5
[124] FNN_1.1                spatstat_1.50-0        prabclus_2.2-6
[127] iterators_1.0.8        class_7.3-14           stringi_1.1.5
[130] mixtools_1.1.0         latticeExtra_0.6-28    caTools_1.17.1
[133] memoise_1.1.0          dplyr_0.5.0            e1071_1.6-8
[136] ape_4.1                tripack_1.3-8

________________________
$brew install lapack

==> *Installing dependencies for lapack: **gcc*

==> *Installing lapack dependency: **gcc*

==> *Using the sandbox*

==> *Downloading https://ftp.gnu.org/gnu/gcc/gcc-6.3.0/gcc-6.3.0.tar.bz2
<https://ftp.gnu.org/gnu/gcc/gcc-6.3.0/gcc-6.3.0.tar.bz2>*

########################################################################
100.0%

==> *Downloading
https://raw.githubusercontent.com/Homebrew/formula-patches/e9e0ee09389a54cc4c8fe1c24ebca3cd765ed0ba/gcc/6.1.0-jit.patch
<https://raw.githubusercontent.com/Homebrew/formula-patches/e9e0ee09389a54cc4c8fe1c24ebca3cd765ed0ba/gcc/6.1.0-jit.patch>*

########################################################################
100.0%

==> *Patching*

==> *Applying 6.1.0-jit.patch*

patching file gcc/jit/Make-lang.in

==> *../configure --build=x86_64-apple-darwin16.5.0
--prefix=/usr/local/Cellar/gcc/6.3.0_1
--libdir=/usr/local/Cellar/gcc/6.3.0_1/lib/gcc/6 --enable-*

==> *make bootstrap*


==> *make install*

Error: The `brew link` step did not complete successfully

The formula built, but is not symlinked into /usr/local

Could not symlink bin/gfortran

Target /usr/local/bin/gfortran

already exists. You may want to remove it:

  rm '/usr/local/bin/gfortran'


To force the link and overwrite all conflicting files:

  brew link --overwrite gcc


To list all files that would be deleted:

  brew link --overwrite --dry-run gcc


Possible conflicting files are:

/usr/local/bin/gfortran -> /usr/local/bin/gfortran-4.8

==> *Summary*

?  /usr/local/Cellar/gcc/6.3.0_1: 1,358 files, 238MB, built in 120 minutes
1 second

==> *Installing **lapack*

==> *Downloading
https://homebrew.bintray.com/bottles/lapack-3.7.0_2.sierra.bottle.tar.gz
<https://homebrew.bintray.com/bottles/lapack-3.7.0_2.sierra.bottle.tar.gz>*

########################################################################
100.0%

==> *Pouring lapack-3.7.0_2.sierra.bottle.tar.gz*

==> *Caveats*

This formula is keg-only, which means it was not symlinked into /usr/local.


macOS already provides this software and installing another version in

parallel can cause all kinds of trouble.


For compilers to find this software you may need to set:

    LDFLAGS:  -L/usr/local/opt/lapack/lib

    CPPFLAGS: -I/usr/local/opt/lapack/include

For pkg-config to find this software you may need to set:

    PKG_CONFIG_PATH: /usr/local/opt/lapack/lib/pkgconfig


==> *Summary*

?  /usr/local/Cellar/lapack/3.7.0_2: 27 files, 10.4MB

	[[alternative HTML version deleted]]


From asengupta94404 at yahoo.com  Tue May  2 21:09:21 2017
From: asengupta94404 at yahoo.com (Amit Sengupta)
Date: Tue, 2 May 2017 19:09:21 +0000 (UTC)
Subject: [R] memory issue
References: <527814620.1007685.1493752161485.ref@mail.yahoo.com>
Message-ID: <527814620.1007685.1493752161485@mail.yahoo.com>

HI,I am unable to read a 2.4 gig file into a table (using read.table) in a 64 bit R environment. Do you have any suggestions?Amit 

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Tue May  2 23:05:29 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 2 May 2017 17:05:29 -0400
Subject: [R] nested for loop with data table
In-Reply-To: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
References: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
Message-ID: <2121F327-9116-4040-9D17-78F3528760F3@utoronto.ca>

There's a lot that doesn't make sense here. I think what you need to do is produce a small, reproducible example, post that with dput() and state your question more clearly - including what you have tried and what didn't work. You'll probably be amazed how quickly you will get good advice if _you_only_follow_the_posting_guide_.

B.




> On May 2, 2017, at 12:35 PM, Ek Esawi <esawiek at gmail.com> wrote:
> 
> I have a huge data file; a sample is listed below. I am using the package
> data table to process the file and I am stuck on one issue and need some
> feedback. I used fread to create a data table. Then I divided the data
> table (named File1) into 10 general subsets using common table commands
> such as:
> 
> 
> 
> AAA <- File1[Num<5&day>15]
> 
> BBB <- File1[Num>15&day<10]
> 
> ?..
> 
> ?..
> 
> ?..
> 
> ?..
> 
> ?..
> 
> ?..
> 
> 
> 
> I wanted to divide and count each of the above subsets based on a set of
> parameters common to all subsets. I did the following to go through each
> subset and it works:
> 
> For (I in 1: length (AAA)) {
> 
>              aa <- c(AAA[color==?green?&grade==?a?,month==?Januray? .N],[
> AAA[color==?green?&grade==?b?& month==?June?? .N])
> 
> }
> 
> 
> 
> The question: I don?t want to have a separate loop for each subset (10
> loops). Instead, I was hoping to have 2 nested loops in the form below:
> 
> 
> 
> For (I in 1:N)){
> 
>              For (j in 1:M){
> 
> 
> 
> }
> 
> }
> 
> 
> 
> Sample
> 
> 
> Num
> 
> Color
> 
> Grade
> 
> Value
> 
> Month
> 
> Day
> 
> 1
> 
> yellow
> 
> A
> 
> 20
> 
> May
> 
> 1
> 
> 2
> 
> green
> 
> B
> 
> 25
> 
> June
> 
> 2
> 
> 3
> 
> green
> 
> A
> 
> 10
> 
> April
> 
> 3
> 
> 4
> 
> black
> 
> A
> 
> 17
> 
> August
> 
> 3
> 
> 5
> 
> red
> 
> C
> 
> 5
> 
> December
> 
> 5
> 
> 6
> 
> orange
> 
> D
> 
> 0
> 
> January
> 
> 13
> 
> 7
> 
> orange
> 
> E
> 
> 12
> 
> January
> 
> 5
> 
> 8
> 
> orange
> 
> F
> 
> 11
> 
> February
> 
> 8
> 
> 9
> 
> orange
> 
> F
> 
> 99
> 
> July
> 
> 23
> 
> 10
> 
> orange
> 
> F
> 
> 70
> 
> May
> 
> 7
> 
> 11
> 
> black
> 
> A
> 
> 77
> 
> June
> 
> 11
> 
> 12
> 
> green
> 
> B
> 
> 87
> 
> April
> 
> 33
> 
> 13
> 
> black
> 
> A
> 
> 79
> 
> August
> 
> 9
> 
> 14
> 
> green
> 
> A
> 
> 68
> 
> December
> 
> 14
> 
> 15
> 
> black
> 
> C
> 
> 90
> 
> January
> 
> 31
> 
> 16
> 
> green
> 
> D
> 
> 79
> 
> January
> 
> 11
> 
> 17
> 
> black
> 
> E
> 
> 101
> 
> February
> 
> 17
> 
> 18
> 
> red
> 
> F
> 
> 90
> 
> July
> 
> 21
> 
> 19
> 
> red
> 
> F
> 
> 112
> 
> February
> 
> 13
> 
> 20
> 
> red
> 
> F
> 
> 101
> 
> July
> 
> 20
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed May  3 00:27:50 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 02 May 2017 15:27:50 -0700
Subject: [R] memory issue
In-Reply-To: <527814620.1007685.1493752161485@mail.yahoo.com>
References: <527814620.1007685.1493752161485.ref@mail.yahoo.com>
 <527814620.1007685.1493752161485@mail.yahoo.com>
Message-ID: <DEAB385F-55D4-498B-A83E-7441A982DD0B@dcn.davis.ca.us>

Suggestions...

Post plain text (you reduce your own chances of getting feedback by failing to do this in your email program)

Provide sample data and code

Buy more RAM

use data.table package and fread

load and analyze subsets of data

Put the data into a database (e.g. sqlite?)

If these suggestions seem brief, or even if they don't, please be more explicit in your question. Read [1] and [2].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On May 2, 2017 12:09:21 PM PDT, Amit Sengupta via R-help <r-help at r-project.org> wrote:
>HI,I am unable to read a 2.4 gig file into a table (using read.table)
>in a 64 bit R environment. Do you have any suggestions?Amit 
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Wed May  3 00:48:52 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Tue, 2 May 2017 15:48:52 -0700
Subject: [R] install lapack for mac
In-Reply-To: <CA+8Xemxbuk-HxUMAdjr88qfFcgteAfWTa3xL7O3GJSD__c-H6w@mail.gmail.com>
References: <CA+8Xemxbuk-HxUMAdjr88qfFcgteAfWTa3xL7O3GJSD__c-H6w@mail.gmail.com>
Message-ID: <CAA99HCy=C63sA2oe3bh54a-1=xJp6nF09yMTmfJfHzMEOyx6MA@mail.gmail.com>

Have you tried R-GUI, in the R-distribution available below?

https://cran.r-project.org/bin/macosx/

Here's a similar question on SO:

http://stackoverflow.com/questions/13476736/r-lapack-routines-cannot-be-loaded

HTH, Bill.

William Michels, Ph.D.


On Tue, May 2, 2017 at 11:51 AM, Assa Yeroslaviz <frymor at gmail.com> wrote:
> Hi,
>
> I am running R under Rstudio for the analysis of single-cell RNA-Seq data.
>
> When trying to analyse some data I keep getting the message
>
>> slicer_traj_lle <- lle(t(deng[slicer_genes,]), m = 2, k)$Y
> finding neighbours
> calculating weights
> Error in eigen(G, symmetric = TRUE, only.values = TRUE) :
>   LAPACK routines cannot be loaded
>
>
> After searching the net I couldn't find a way to install LAPACK on a mac.
> When trying to install it via homebrew I get this message (this is a
> shorted message. the complete message is below):
>
> brew install lapack
>
> ...
>
> macOS already provides this software and installing another version in
>
> parallel can cause all kinds of trouble.
>
> For compilers to find this software you may need to set:
>
>     LDFLAGS:  -L/usr/local/opt/lapack/lib
>
>     CPPFLAGS: -I/usr/local/opt/lapack/include
>
> For pkg-config to find this software you may need to set:
>
>     PKG_CONFIG_PATH: /usr/local/opt/lapack/lib/pkgconfig
>
>
> I truely don't understand why my mac can't find the lapack, if it already
> there and i still can't figure out, how to tell my R tool / RStudio, where
> to find lapack.
>
> Does anyone has an idea how to do this?
>
> thanks
>
> Assa
>> R.version
>                _
> platform       x86_64-apple-darwin13.4.0
> arch           x86_64
> os             darwin13.4.0
> system         x86_64, darwin13.4.0
> status
> major          3
> minor          3.1
> year           2016
> month          06
> day            21
> svn rev        70800
> language       R
> version.string R version 3.3.1 (2016-06-21)
> nickname       Bug in Your Hair
>
>
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.12.4 (Sierra)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
>  [1] splines   stats4    parallel  stats     graphics  grDevices utils
> datasets  methods
> [10] base
>
> other attached packages:
>  [1] R.utils_2.5.0        R.oo_1.21.0          R.methodsS3_1.7.1
>  Seurat_1.4.0.14
>  [5] cowplot_0.7.0        SLICER_0.2.0         alphahull_2.1        lle_1.1
>
>  [9] snowfall_1.84-6.1    snow_0.4-2           MASS_7.3-47
>  scatterplot3d_0.3-40
> [13] igraph_1.0.1         destiny_2.0.8        monocle_2.2.0
>  DDRTree_0.1.4
> [17] irlba_2.1.2          VGAM_1.0-3           ggplot2_2.2.1
>  Biobase_2.34.0
> [21] BiocGenerics_0.20.0  Matrix_1.2-8         M3Drop_1.0.0
> numDeriv_2016.8-1
> [25] TSCAN_1.12.0
>
> loaded via a namespace (and not attached):
>   [1] shinydashboard_0.5.3   lme4_1.1-13            RSQLite_1.1-2
>   [4] AnnotationDbi_1.36.2   htmlwidgets_0.8        grid_3.3.1
>   [7] combinat_0.0-8         trimcluster_0.1-2      ranger_0.7.0
>  [10] Rtsne_0.13             munsell_0.4.3          codetools_0.2-15
>  [13] statmod_1.4.29         colorspace_1.3-2       fastICA_1.2-0
>  [16] knitr_1.15.1           ROCR_1.0-7             robustbase_0.92-7
>  [19] vcd_1.4-3              tensor_1.5             VIM_4.7.0
>  [22] TTR_0.23-1             lars_1.2               slam_0.1-40
>  [25] splancs_2.01-40        bbmle_1.0.19           mnormt_1.5-5
>  [28] polyclip_1.6-1         pheatmap_1.0.8         rprojroot_1.2
>  [31] diptest_0.75-7         R6_2.2.0               RcppEigen_0.3.2.9.1
>  [34] flexmix_2.3-14         bitops_1.0-6           spatstat.utils_1.4-1
>  [37] assertthat_0.2.0       scales_0.4.1           nnet_7.3-12
>  [40] gtable_0.2.0           goftest_1.1-1          MatrixModels_0.4-1
>  [43] lazyeval_0.2.0         ModelMetrics_1.1.0     acepack_1.4.1
>  [46] checkmate_1.8.2        reshape2_1.4.2         abind_1.4-5
>  [49] backports_1.0.5        httpuv_1.3.3           rsconnect_0.7
>  [52] Hmisc_4.0-2            caret_6.0-76           tools_3.3.1
>  [55] gplots_3.0.1           RColorBrewer_1.1-2     proxy_0.4-16
>  [58] Rcpp_0.12.10           plyr_1.8.4             base64enc_0.1-3
>  [61] RCurl_1.95-4.8         rpart_4.1-11           deldir_0.1-14
>  [64] pbapply_1.3-2          viridis_0.4.0          S4Vectors_0.12.2
>  [67] zoo_1.8-0              cluster_2.0.6          magrittr_1.5
>  [70] data.table_1.10.4      SparseM_1.77           lmtest_0.9-35
>  [73] mvtnorm_1.0-6          matrixStats_0.52.2     mime_0.5
>  [76] evaluate_0.10          xtable_1.8-2           smoother_1.1
>  [79] pbkrtest_0.4-7         XML_3.98-1.6           mclust_5.2.3
>  [82] IRanges_2.8.2          gridExtra_2.2.1        HSMMSingleCell_0.108.0
>  [85] biomaRt_2.30.0         tibble_1.3.0           KernSmooth_2.23-15
>  [88] minqa_1.2.4            htmltools_0.3.6        segmented_0.5-1.4
>  [91] mgcv_1.8-17            Formula_1.2-1          tclust_1.2-3
>  [94] DBI_0.6-1              fpc_2.1-10             boot_1.3-19
>  [97] car_2.1-4              sgeostat_1.0-27        gdata_2.17.0
> [100] sn_1.5-0               foreign_0.8-68         laeken_0.4.6
> [103] sp_1.2-4               foreach_1.4.3          stringr_1.2.0
> [106] digest_0.6.12          tsne_0.1-3             rmarkdown_1.5
> [109] htmlTable_1.9          kernlab_0.9-25         shiny_1.0.3
> [112] gtools_3.5.0           quantreg_5.33          modeltools_0.2-21
> [115] nloptr_1.0.4           nlme_3.1-131           viridisLite_0.2.0
> [118] limma_3.30.13          lattice_0.20-35        DEoptimR_1.0-8
> [121] survival_2.41-3        xts_0.9-7              qlcMatrix_0.9.5
> [124] FNN_1.1                spatstat_1.50-0        prabclus_2.2-6
> [127] iterators_1.0.8        class_7.3-14           stringi_1.1.5
> [130] mixtools_1.1.0         latticeExtra_0.6-28    caTools_1.17.1
> [133] memoise_1.1.0          dplyr_0.5.0            e1071_1.6-8
> [136] ape_4.1                tripack_1.3-8
>
> ________________________
> $brew install lapack
>
> ==> *Installing dependencies for lapack: **gcc*
>
> ==> *Installing lapack dependency: **gcc*
>
> ==> *Using the sandbox*
>
> ==> *Downloading https://ftp.gnu.org/gnu/gcc/gcc-6.3.0/gcc-6.3.0.tar.bz2
> <https://ftp.gnu.org/gnu/gcc/gcc-6.3.0/gcc-6.3.0.tar.bz2>*
>
> ########################################################################
> 100.0%
>
> ==> *Downloading
> https://raw.githubusercontent.com/Homebrew/formula-patches/e9e0ee09389a54cc4c8fe1c24ebca3cd765ed0ba/gcc/6.1.0-jit.patch
> <https://raw.githubusercontent.com/Homebrew/formula-patches/e9e0ee09389a54cc4c8fe1c24ebca3cd765ed0ba/gcc/6.1.0-jit.patch>*
>
> ########################################################################
> 100.0%
>
> ==> *Patching*
>
> ==> *Applying 6.1.0-jit.patch*
>
> patching file gcc/jit/Make-lang.in
>
> ==> *../configure --build=x86_64-apple-darwin16.5.0
> --prefix=/usr/local/Cellar/gcc/6.3.0_1
> --libdir=/usr/local/Cellar/gcc/6.3.0_1/lib/gcc/6 --enable-*
>
> ==> *make bootstrap*
>
>
> ==> *make install*
>
> Error: The `brew link` step did not complete successfully
>
> The formula built, but is not symlinked into /usr/local
>
> Could not symlink bin/gfortran
>
> Target /usr/local/bin/gfortran
>
> already exists. You may want to remove it:
>
>   rm '/usr/local/bin/gfortran'
>
>
> To force the link and overwrite all conflicting files:
>
>   brew link --overwrite gcc
>
>
> To list all files that would be deleted:
>
>   brew link --overwrite --dry-run gcc
>
>
> Possible conflicting files are:
>
> /usr/local/bin/gfortran -> /usr/local/bin/gfortran-4.8
>
> ==> *Summary*
>
> ?  /usr/local/Cellar/gcc/6.3.0_1: 1,358 files, 238MB, built in 120 minutes
> 1 second
>
> ==> *Installing **lapack*
>
> ==> *Downloading
> https://homebrew.bintray.com/bottles/lapack-3.7.0_2.sierra.bottle.tar.gz
> <https://homebrew.bintray.com/bottles/lapack-3.7.0_2.sierra.bottle.tar.gz>*
>
> ########################################################################
> 100.0%
>
> ==> *Pouring lapack-3.7.0_2.sierra.bottle.tar.gz*
>
> ==> *Caveats*
>
> This formula is keg-only, which means it was not symlinked into /usr/local.
>
>
> macOS already provides this software and installing another version in
>
> parallel can cause all kinds of trouble.
>
>
> For compilers to find this software you may need to set:
>
>     LDFLAGS:  -L/usr/local/opt/lapack/lib
>
>     CPPFLAGS: -I/usr/local/opt/lapack/include
>
> For pkg-config to find this software you may need to set:
>
>     PKG_CONFIG_PATH: /usr/local/opt/lapack/lib/pkgconfig
>
>
> ==> *Summary*
>
> ?  /usr/local/Cellar/lapack/3.7.0_2: 27 files, 10.4MB
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed May  3 01:14:23 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 May 2017 09:14:23 +1000
Subject: [R] nested for loop with data table
In-Reply-To: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
References: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
Message-ID: <CA+8X3fUgHAMWwZfCm1FxouLpkNx6UtC-1Qs3k-a0VQNMnYGO=A@mail.gmail.com>

Hi Ek,
I think you want your example to look like this:

Sample<-read.table(text=
"Num Color Grade Value Month Day
1 yellow A 20 May 1
2 green B 25 June 2
3 green A 10 April 3
4 black A 17 August 3
5 red C 5 December 5
6 orange D 0 January 13
7 orange E 12 January 5
8 orange F 11 February 8
9 orange F 99 July 23
10 orange F 70 May 7
11 black A 77 June 11
12 green B 87 April 33
13 black A 79 August 9
14 green A 68 December 14
15 black C 90 January 31
16 green D 79 January 11
17 black E 101 February 17
18 red F 90 July 21
19 red F 112 February 13
20 red F 101 July 20",
header=TRUE)
AAA<-Sample[Sample$Num < 5 & Sample$Day < 3,]
BBB<-Sample[Sample$Num > 15 & Sample$Day > 13,]
for(i in 1:length(AAA)) {
 for(j in 1:length(BBB)) {
  ...
 }
}

except in data.table notation. However, I can't work out what you want
to do in the loop.

Jim


On Wed, May 3, 2017 at 2:35 AM, Ek Esawi <esawiek at gmail.com> wrote:
> I have a huge data file; a sample is listed below. I am using the package
> data table to process the file and I am stuck on one issue and need some
> feedback. I used fread to create a data table. Then I divided the data
> table (named File1) into 10 general subsets using common table commands
> such as:
>
>
>
> AAA <- File1[Num<5&day>15]
>
> BBB <- File1[Num>15&day<10]
>
> ?..
>
> ?..
>
> ?..
>
> ?..
>
> ?..
>
> ?..
>
>
>
> I wanted to divide and count each of the above subsets based on a set of
> parameters common to all subsets. I did the following to go through each
> subset and it works:
>
> For (I in 1: length (AAA)) {
>
>               aa <- c(AAA[color==?green?&grade==?a?,month==?Januray? .N],[
> AAA[color==?green?&grade==?b?& month==?June?? .N])
>
> }
>
>
>
> The question: I don?t want to have a separate loop for each subset (10
> loops). Instead, I was hoping to have 2 nested loops in the form below:
>
>
>
> For (I in 1:N)){
>
>               For (j in 1:M){
>
>
>
> }
>
> }
>
>
>
>  Sample
>
>
> Num
>
> Color
>
> Grade
>
> Value
>
> Month
>
> Day
>
> 1
>
> yellow
>
> A
>
> 20
>
> May
>
> 1
>
> 2
>
> green
>
> B
>
> 25
>
> June
>
> 2
>
> 3
>
> green
>
> A
>
> 10
>
> April
>
> 3
>
> 4
>
> black
>
> A
>
> 17
>
> August
>
> 3
>
> 5
>
> red
>
> C
>
> 5
>
> December
>
> 5
>
> 6
>
> orange
>
> D
>
> 0
>
> January
>
> 13
>
> 7
>
> orange
>
> E
>
> 12
>
> January
>
> 5
>
> 8
>
> orange
>
> F
>
> 11
>
> February
>
> 8
>
> 9
>
> orange
>
> F
>
> 99
>
> July
>
> 23
>
> 10
>
> orange
>
> F
>
> 70
>
> May
>
> 7
>
> 11
>
> black
>
> A
>
> 77
>
> June
>
> 11
>
> 12
>
> green
>
> B
>
> 87
>
> April
>
> 33
>
> 13
>
> black
>
> A
>
> 79
>
> August
>
> 9
>
> 14
>
> green
>
> A
>
> 68
>
> December
>
> 14
>
> 15
>
> black
>
> C
>
> 90
>
> January
>
> 31
>
> 16
>
> green
>
> D
>
> 79
>
> January
>
> 11
>
> 17
>
> black
>
> E
>
> 101
>
> February
>
> 17
>
> 18
>
> red
>
> F
>
> 90
>
> July
>
> 21
>
> 19
>
> red
>
> F
>
> 112
>
> February
>
> 13
>
> 20
>
> red
>
> F
>
> 101
>
> July
>
> 20
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nelson.chr82 at gmail.com  Wed May  3 00:18:16 2017
From: nelson.chr82 at gmail.com (Nelson Anthony)
Date: Tue, 2 May 2017 15:18:16 -0700
Subject: [R] RJDBC
Message-ID: <CAMmkzo6kdfBzmz4WP3rwBjru1pYxdQsGEugU=fZ=cM9D5VcEBA@mail.gmail.com>

Hi all,



I am trying to connect to Database  using RJDBC but due to some DB & Server
timezone mismatch I am facing below error message.



Error in .jcall(drv at jdrv, "Ljava/sql/Connection;", "connect",
as.character(url)[1],  :

  java.sql.SQLException: ORA-00604: error occurred at recursive SQL level 1

ORA-01882: timezone region not found



I tried to fix this issue using java by using this parameter
?-Doracle.jdbc.timezoneAsRegion=false?
and it worked



But I am trying to apply the same setting in R using option settings, but
it is not working. Also, I tried updating Rprofile



*My code snippet:*



Sys.setenv(JAVA_HOME='/usr/lib/jvm/java-8-openjdk-amd64')

options(java.parameters = "-Xmx8g")

options(java.oracle.jdbc.timezoneAsRegion="false")

dbcDriver <- JDBC(driverClass="oracle.jdbc.OracleDriver",
classPath="/usr/lib/oracle/12.2/client64/lib/ojdbc8.jar")

pcm_stg_conn <- dbConnect(jdbcDriver, "jdbc:oracle:thin:@//hostname:1521/SID",
"username", "password").



Can you please help in resolving this issue





Thanks & Regards.

Anthony Nelson

	[[alternative HTML version deleted]]


From ahalsiva at gmail.com  Wed May  3 02:54:55 2017
From: ahalsiva at gmail.com (Ahalya Sivathayalan)
Date: Tue, 2 May 2017 20:54:55 -0400
Subject: [R] finegray function in the survival package
In-Reply-To: <083a37$4a06rf@ironport10.mayo.edu>
References: <mailman.7.1473242402.7424.r-help@r-project.org>
 <083a37$4a06rf@ironport10.mayo.edu>
Message-ID: <CAL28AadGQ0p0Qzz1qWM01yOcEmc8sob-V1wcEvfYO0gtzdgg1Q@mail.gmail.com>

Hello R-team,

I am trying to use the tmerge function from survvial library. My data is
similar to mgus2 dataset from R.

But, I get the following message.

Error in tmerge(dat, dat, id = Number, death = event(dYears, death), BMF =
event(ptemp,  :
  tstart must be > tstop
>

Could you help me?

Thanks,
Ahalya.



On Wed, Sep 7, 2016 at 8:29 AM, Therneau, Terry M., Ph.D. <therneau at mayo.edu
> wrote:

>
>
> On 09/07/2016 05:00 AM, r-help-request at r-project.org wrote:
>
>> Dear R-Team,
>>
>> I have been trying to use the finegray routine that creates a special data
>> so that Fine and Gray model can be fit. However, it does not seem to work.
>> Could you please help me with this issue?
>>
>>
>> Thanks,
>> Ahalya.
>>
>>
> You have given us no details of your example code that "doesn't work", and
> I can't read your mind.  So no, we can't help.  Give us a hint.
>
> Terry T
>

	[[alternative HTML version deleted]]


From hendalaa2020 at gmail.com  Wed May  3 06:39:50 2017
From: hendalaa2020 at gmail.com (Hend Alaa)
Date: Wed, 3 May 2017 06:39:50 +0200
Subject: [R] (no subject)
Message-ID: <CAOTXy7d-6YYB_UqrBdesRk7qF8Xz24r7hvbFX73Hhiafw0snmw@mail.gmail.com>

When I reinstall R tools this message come up and I can't proceed any way.

c/Rtools/mingo_libs/lib/i386/libsicudt.a
An error occurred while trying to copy a file:
the source file is corrupted.

click Retry to try again, Ignore to skip this file(not recommended), or
Abort to cancel installation.

can any one help with this

	[[alternative HTML version deleted]]


From hasan.diwan at gmail.com  Wed May  3 08:40:38 2017
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Tue, 2 May 2017 23:40:38 -0700
Subject: [R] RJDBC
In-Reply-To: <CAMmkzo6kdfBzmz4WP3rwBjru1pYxdQsGEugU=fZ=cM9D5VcEBA@mail.gmail.com>
References: <CAMmkzo6kdfBzmz4WP3rwBjru1pYxdQsGEugU=fZ=cM9D5VcEBA@mail.gmail.com>
Message-ID: <CAP+bYWDcTG+KhLs=KBg6RZUGj4+Ok=owjPMnQ3EkWs_9hSZzVg@mail.gmail.com>

Anthony,
Did you try options(java.parameters = "-Xmx8g
-Djava.oracle.jdbc.timezoneAsRegion=false")
instead of specifying the java property separately? -- H

On 2 May 2017 at 15:18, Nelson Anthony <nelson.chr82 at gmail.com> wrote:

> Hi all,
>
>
>
> I am trying to connect to Database  using RJDBC but due to some DB & Server
> timezone mismatch I am facing below error message.
>
>
>
> Error in .jcall(drv at jdrv, "Ljava/sql/Connection;", "connect",
> as.character(url)[1],  :
>
>   java.sql.SQLException: ORA-00604: error occurred at recursive SQL level 1
>
> ORA-01882: timezone region not found
>
>
>
> I tried to fix this issue using java by using this parameter
> ?-Doracle.jdbc.timezoneAsRegion=false?
> and it worked
>
>
>
> But I am trying to apply the same setting in R using option settings, but
> it is not working. Also, I tried updating Rprofile
>
>
>
> *My code snippet:*
>
>
>
> Sys.setenv(JAVA_HOME='/usr/lib/jvm/java-8-openjdk-amd64')
>
> options(java.parameters = "-Xmx8g")
>
> options(java.oracle.jdbc.timezoneAsRegion="false")
>
> dbcDriver <- JDBC(driverClass="oracle.jdbc.OracleDriver",
> classPath="/usr/lib/oracle/12.2/client64/lib/ojdbc8.jar")
>
> pcm_stg_conn <- dbConnect(jdbcDriver, "jdbc:oracle:thin:@//hostname:
> 1521/SID",
> "username", "password").
>
>
>
> Can you please help in resolving this issue
>
>
>
>
>
> Thanks & Regards.
>
> Anthony Nelson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
OpenPGP:
https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using
http://bit.ly/hd1ScheduleRequest.
Si vous voudrais faire connnaisance, allez a
http://bit.ly/hd1ScheduleRequest.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Wed May  3 08:43:48 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 3 May 2017 08:43:48 +0200
Subject: [R] install lapack for mac
In-Reply-To: <CA+8Xemxbuk-HxUMAdjr88qfFcgteAfWTa3xL7O3GJSD__c-H6w@mail.gmail.com>
References: <CA+8Xemxbuk-HxUMAdjr88qfFcgteAfWTa3xL7O3GJSD__c-H6w@mail.gmail.com>
Message-ID: <628903B5-D99D-4F85-91D3-06842FC96B29@xs4all.nl>


This should have been sent to the R-SIG-Mac mailinglist.

Rstudio has nothing to do with your problem.

Which R are you using? The CRAN version?
The CRAN version has the Lapack routines included.
From which package does function lle(..) come from?

Have you tried with less packages attached?

Why homebrew? You homebrewed your R?

Please: do not post in html as the Posting guide requests.

Berend Hasselman

> On 2 May 2017, at 20:51, Assa Yeroslaviz <frymor at gmail.com> wrote:
> 
> Hi,
> 
> I am running R under Rstudio for the analysis of single-cell RNA-Seq data.
> 
> When trying to analyse some data I keep getting the message
> 
>> slicer_traj_lle <- lle(t(deng[slicer_genes,]), m = 2, k)$Y
> finding neighbours
> calculating weights
> Error in eigen(G, symmetric = TRUE, only.values = TRUE) :
>  LAPACK routines cannot be loaded
> 
> 
> After searching the net I couldn't find a way to install LAPACK on a mac.
> When trying to install it via homebrew I get this message (this is a
> shorted message. the complete message is below):
> 
> brew install lapack
> 
> ...
> 
> macOS already provides this software and installing another version in
> 
> parallel can cause all kinds of trouble.
> 
> For compilers to find this software you may need to set:
> 
>    LDFLAGS:  -L/usr/local/opt/lapack/lib
> 
>    CPPFLAGS: -I/usr/local/opt/lapack/include
> 
> For pkg-config to find this software you may need to set:
> 
>    PKG_CONFIG_PATH: /usr/local/opt/lapack/lib/pkgconfig
> 
> 
> I truely don't understand why my mac can't find the lapack, if it already
> there and i still can't figure out, how to tell my R tool / RStudio, where
> to find lapack.
> 
> Does anyone has an idea how to do this?
> 
> thanks
> 
> Assa
>> R.version
>               _
> platform       x86_64-apple-darwin13.4.0
> arch           x86_64
> os             darwin13.4.0
> system         x86_64, darwin13.4.0
> status
> major          3
> minor          3.1
> year           2016
> month          06
> day            21
> svn rev        70800
> language       R
> version.string R version 3.3.1 (2016-06-21)
> nickname       Bug in Your Hair
> 
> 
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.12.4 (Sierra)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] splines   stats4    parallel  stats     graphics  grDevices utils
> datasets  methods
> [10] base
> 
> other attached packages:
> [1] R.utils_2.5.0        R.oo_1.21.0          R.methodsS3_1.7.1
> Seurat_1.4.0.14
> [5] cowplot_0.7.0        SLICER_0.2.0         alphahull_2.1        lle_1.1
> 
> [9] snowfall_1.84-6.1    snow_0.4-2           MASS_7.3-47
> scatterplot3d_0.3-40
> [13] igraph_1.0.1         destiny_2.0.8        monocle_2.2.0
> DDRTree_0.1.4
> [17] irlba_2.1.2          VGAM_1.0-3           ggplot2_2.2.1
> Biobase_2.34.0
> [21] BiocGenerics_0.20.0  Matrix_1.2-8         M3Drop_1.0.0
> numDeriv_2016.8-1
> [25] TSCAN_1.12.0
> 
> loaded via a namespace (and not attached):
>  [1] shinydashboard_0.5.3   lme4_1.1-13            RSQLite_1.1-2
>  [4] AnnotationDbi_1.36.2   htmlwidgets_0.8        grid_3.3.1
>  [7] combinat_0.0-8         trimcluster_0.1-2      ranger_0.7.0
> [10] Rtsne_0.13             munsell_0.4.3          codetools_0.2-15
> [13] statmod_1.4.29         colorspace_1.3-2       fastICA_1.2-0
> [16] knitr_1.15.1           ROCR_1.0-7             robustbase_0.92-7
> [19] vcd_1.4-3              tensor_1.5             VIM_4.7.0
> [22] TTR_0.23-1             lars_1.2               slam_0.1-40
> [25] splancs_2.01-40        bbmle_1.0.19           mnormt_1.5-5
> [28] polyclip_1.6-1         pheatmap_1.0.8         rprojroot_1.2
> [31] diptest_0.75-7         R6_2.2.0               RcppEigen_0.3.2.9.1
> [34] flexmix_2.3-14         bitops_1.0-6           spatstat.utils_1.4-1
> [37] assertthat_0.2.0       scales_0.4.1           nnet_7.3-12
> [40] gtable_0.2.0           goftest_1.1-1          MatrixModels_0.4-1
> [43] lazyeval_0.2.0         ModelMetrics_1.1.0     acepack_1.4.1
> [46] checkmate_1.8.2        reshape2_1.4.2         abind_1.4-5
> [49] backports_1.0.5        httpuv_1.3.3           rsconnect_0.7
> [52] Hmisc_4.0-2            caret_6.0-76           tools_3.3.1
> [55] gplots_3.0.1           RColorBrewer_1.1-2     proxy_0.4-16
> [58] Rcpp_0.12.10           plyr_1.8.4             base64enc_0.1-3
> [61] RCurl_1.95-4.8         rpart_4.1-11           deldir_0.1-14
> [64] pbapply_1.3-2          viridis_0.4.0          S4Vectors_0.12.2
> [67] zoo_1.8-0              cluster_2.0.6          magrittr_1.5
> [70] data.table_1.10.4      SparseM_1.77           lmtest_0.9-35
> [73] mvtnorm_1.0-6          matrixStats_0.52.2     mime_0.5
> [76] evaluate_0.10          xtable_1.8-2           smoother_1.1
> [79] pbkrtest_0.4-7         XML_3.98-1.6           mclust_5.2.3
> [82] IRanges_2.8.2          gridExtra_2.2.1        HSMMSingleCell_0.108.0
> [85] biomaRt_2.30.0         tibble_1.3.0           KernSmooth_2.23-15
> [88] minqa_1.2.4            htmltools_0.3.6        segmented_0.5-1.4
> [91] mgcv_1.8-17            Formula_1.2-1          tclust_1.2-3
> [94] DBI_0.6-1              fpc_2.1-10             boot_1.3-19
> [97] car_2.1-4              sgeostat_1.0-27        gdata_2.17.0
> [100] sn_1.5-0               foreign_0.8-68         laeken_0.4.6
> [103] sp_1.2-4               foreach_1.4.3          stringr_1.2.0
> [106] digest_0.6.12          tsne_0.1-3             rmarkdown_1.5
> [109] htmlTable_1.9          kernlab_0.9-25         shiny_1.0.3
> [112] gtools_3.5.0           quantreg_5.33          modeltools_0.2-21
> [115] nloptr_1.0.4           nlme_3.1-131           viridisLite_0.2.0
> [118] limma_3.30.13          lattice_0.20-35        DEoptimR_1.0-8
> [121] survival_2.41-3        xts_0.9-7              qlcMatrix_0.9.5
> [124] FNN_1.1                spatstat_1.50-0        prabclus_2.2-6
> [127] iterators_1.0.8        class_7.3-14           stringi_1.1.5
> [130] mixtools_1.1.0         latticeExtra_0.6-28    caTools_1.17.1
> [133] memoise_1.1.0          dplyr_0.5.0            e1071_1.6-8
> [136] ape_4.1                tripack_1.3-8
> 
> ________________________
> $brew install lapack
> 
> ==> *Installing dependencies for lapack: **gcc*
> 
> ==> *Installing lapack dependency: **gcc*
> 
> ==> *Using the sandbox*
> 
> ==> *Downloading https://ftp.gnu.org/gnu/gcc/gcc-6.3.0/gcc-6.3.0.tar.bz2
> <https://ftp.gnu.org/gnu/gcc/gcc-6.3.0/gcc-6.3.0.tar.bz2>*
> 
> ########################################################################
> 100.0%
> 
> ==> *Downloading
> https://raw.githubusercontent.com/Homebrew/formula-patches/e9e0ee09389a54cc4c8fe1c24ebca3cd765ed0ba/gcc/6.1.0-jit.patch
> <https://raw.githubusercontent.com/Homebrew/formula-patches/e9e0ee09389a54cc4c8fe1c24ebca3cd765ed0ba/gcc/6.1.0-jit.patch>*
> 
> ########################################################################
> 100.0%
> 
> ==> *Patching*
> 
> ==> *Applying 6.1.0-jit.patch*
> 
> patching file gcc/jit/Make-lang.in
> 
> ==> *../configure --build=x86_64-apple-darwin16.5.0
> --prefix=/usr/local/Cellar/gcc/6.3.0_1
> --libdir=/usr/local/Cellar/gcc/6.3.0_1/lib/gcc/6 --enable-*
> 
> ==> *make bootstrap*
> 
> 
> ==> *make install*
> 
> Error: The `brew link` step did not complete successfully
> 
> The formula built, but is not symlinked into /usr/local
> 
> Could not symlink bin/gfortran
> 
> Target /usr/local/bin/gfortran
> 
> already exists. You may want to remove it:
> 
>  rm '/usr/local/bin/gfortran'
> 
> 
> To force the link and overwrite all conflicting files:
> 
>  brew link --overwrite gcc
> 
> 
> To list all files that would be deleted:
> 
>  brew link --overwrite --dry-run gcc
> 
> 
> Possible conflicting files are:
> 
> /usr/local/bin/gfortran -> /usr/local/bin/gfortran-4.8
> 
> ==> *Summary*
> 
> ?  /usr/local/Cellar/gcc/6.3.0_1: 1,358 files, 238MB, built in 120 minutes
> 1 second
> 
> ==> *Installing **lapack*
> 
> ==> *Downloading
> https://homebrew.bintray.com/bottles/lapack-3.7.0_2.sierra.bottle.tar.gz
> <https://homebrew.bintray.com/bottles/lapack-3.7.0_2.sierra.bottle.tar.gz>*
> 
> ########################################################################
> 100.0%
> 
> ==> *Pouring lapack-3.7.0_2.sierra.bottle.tar.gz*
> 
> ==> *Caveats*
> 
> This formula is keg-only, which means it was not symlinked into /usr/local.
> 
> 
> macOS already provides this software and installing another version in
> 
> parallel can cause all kinds of trouble.
> 
> 
> For compilers to find this software you may need to set:
> 
>    LDFLAGS:  -L/usr/local/opt/lapack/lib
> 
>    CPPFLAGS: -I/usr/local/opt/lapack/include
> 
> For pkg-config to find this software you may need to set:
> 
>    PKG_CONFIG_PATH: /usr/local/opt/lapack/lib/pkgconfig
> 
> 
> ==> *Summary*
> 
> ?  /usr/local/Cellar/lapack/3.7.0_2: 27 files, 10.4MB
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter.anthoni at kit.edu  Wed May  3 08:46:29 2017
From: peter.anthoni at kit.edu (Anthoni, Peter (IMK))
Date: Wed, 3 May 2017 06:46:29 +0000
Subject: [R] memory problem
In-Reply-To: <1039705102.836708.1493744366930@mail.yahoo.com>
References: <1039705102.836708.1493744366930.ref@mail.yahoo.com>
 <1039705102.836708.1493744366930@mail.yahoo.com>
Message-ID: <C94B8F6F-0689-42C9-9406-6404C0BD2B5E@kit.edu>

Hi Amit,

Is the file gzipped or extracted?
if you read the plain text file, try to gzip it and make a read.table on the gzipped file, the read.table can handle gzipped files at least on linux and mac OS, not sure about windows.

cheers
Peter



> On 2. May 2017, at 18:59, Amit Sengupta via R-help <r-help at r-project.org> wrote:
> 
> Hi,I was unable to read a 2.4 gig file into an R object using read.table in 64 bit R environment. Please let me have your suggestions.Amit Sengupta
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From siouxsie at posteo.ch  Wed May  3 13:42:17 2017
From: siouxsie at posteo.ch (Siouxsie)
Date: Wed, 03 May 2017 13:42:17 +0200
Subject: [R] cannot load .sav-files in R 3.4.0
In-Reply-To: <CAOwvMDwtcOUJN9DZsZN9V-VHzDOafz8oTGmEe5TGWf=d2mUEiw@mail.gmail.com>
References: <ab145567f6ef74a3250e518249b52c05@posteo.de>
 <CAOwvMDwJURzX1Q3MkCsHKaANmxWhGa+xAdDDd12MpyqjBqXuBQ@mail.gmail.com>
 <e2d100f4cf4ec842049b42d9d37c872b@posteo.de>
 <CAOwvMDy1G3=xc+Qz3Tsts-y-s17wswx4NDdEU7ssjaR8ofxoBA@mail.gmail.com>
 <b89bdff42c8d12e5061123c126d2ae8c@posteo.de>
 <CAOwvMDwtcOUJN9DZsZN9V-VHzDOafz8oTGmEe5TGWf=d2mUEiw@mail.gmail.com>
Message-ID: <002bbd50858f4ad93d4f6f809c65e34a@posteo.de>

unfortunately not.
i tried:
> devtools::install_github( "hadley/dplyr" )
and got this:
Downloading GitHub repo hadley/dplyr at master
from URL https://api.github.com/repos/hadley/dplyr/zipball/master
Installing dplyr
Installing 1 package: bindrcpp
Installing package into ?\\unetna01/mandersk$/Daten/R/win-library/3.3?
(as ?lib? is unspecified)
versuche URL 
'https://stat.ethz.ch/CRAN/bin/windows/contrib/3.3/bindrcpp_0.1.zip'
Content type 'application/zip' length 609682 bytes (595 KB)
downloaded 595 KB

package ?bindrcpp? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
         
C:\Users\mandersk\AppData\Local\Temp\RtmpoHHW84\downloaded_packages
Installing 1 package: pkgconfig
Installing package into ?\\unetna01/mandersk$/Daten/R/win-library/3.3?
(as ?lib? is unspecified)
versuche URL 
'https://stat.ethz.ch/CRAN/bin/windows/contrib/3.3/pkgconfig_2.0.1.zip'
Content type 'application/zip' length 19743 bytes (19 KB)
downloaded 19 KB

package ?pkgconfig? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
         
C:\Users\mandersk\AppData\Local\Temp\RtmpoHHW84\downloaded_packages
Installing 1 package: plogr
Installing package into ?\\unetna01/mandersk$/Daten/R/win-library/3.3?
(as ?lib? is unspecified)
versuche URL 
'https://stat.ethz.ch/CRAN/bin/windows/contrib/3.3/plogr_0.1-1.zip'
Content type 'application/zip' length 17642 bytes (17 KB)
downloaded 17 KB

package ?plogr? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
         
C:\Users\mandersk\AppData\Local\Temp\RtmpoHHW84\downloaded_packages
Downloading GitHub repo hadley/rlang at b22ce1c
from URL https://api.github.com/repos/hadley/rlang/zipball/b22ce1c
Installing rlang
"C:/PROGRA~1/R/R-33~1.3/bin/x64/R" --no-site-file --no-environ --no-save 
--no-restore --quiet CMD  \
   INSTALL  \
   
"C:/Users/mandersk/AppData/Local/Temp/RtmpoHHW84/devtoolsed02519519f/hadley-rlang-b22ce1c" 
  \
   --library="\\unetna01/mandersk$/Daten/R/win-library/3.3" 
--install-tests

* installing *source* package 'rlang' ...
** libs

*** arch - i386
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c attrs.c -o attrs.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c capture.c -o capture.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c eval.c -o eval.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c export.c -o export.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c formula.c -o formula.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c init.c -o init.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c internals.c -o internals.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c pairlist.c -o pairlist.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c replace-na.c -o replace-na.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c sexp.c -o sexp.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c splice.c -o splice.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c symbol.c -o symbol.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c unquote.c -o unquote.o
c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O3 -Wall  -std=gnu99 
-mtune=core2 -c utils.c -o utils.o
c:/Rtools/mingw_32/bin/gcc -shared -s -static-libgcc -o rlang.dll 
tmp.def attrs.o capture.o eval.o export.o formula.o init.o internals.o 
pairlist.o replace-na.o sexp.o splice.o symbol.o unquote.o utils.o 
-Ld:/Compiler/gcc-4.9.3/local330/lib/i386 
-Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-33~1.3/bin/i386 
-lR
installing to 
\\unetna01/mandersk$/Daten/R/win-library/3.3/rlang/libs/i386

*** arch - x64
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c attrs.c -o attrs.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c capture.c -o capture.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c eval.c -o eval.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c export.c -o export.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c formula.c -o formula.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c init.c -o init.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c internals.c -o internals.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c pairlist.c -o pairlist.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c replace-na.c -o replace-na.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c sexp.c -o sexp.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c splice.c -o splice.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c symbol.c -o symbol.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c unquote.c -o unquote.o
c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-33~1.3/include" -DNDEBUG  
    -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -std=gnu99 
-mtune=core2 -c utils.c -o utils.o
c:/Rtools/mingw_64/bin/gcc -shared -s -static-libgcc -o rlang.dll 
tmp.def attrs.o capture.o eval.o export.o formula.o init.o internals.o 
pairlist.o replace-na.o sexp.o splice.o symbol.o unquote.o utils.o 
-Ld:/Compiler/gcc-4.9.3/local330/lib/x64 
-Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/PROGRA~1/R/R-33~1.3/bin/x64 
-lR
installing to 
\\unetna01/mandersk$/Daten/R/win-library/3.3/rlang/libs/x64
** R
** tests
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
*** arch - i386
Warnung in library(pkg_name, lib.loc = lib, character.only = TRUE, 
logical.return = TRUE)
   there is no package called 'rlang'
Fehler: Laden fehlgeschlagen
Ausf?hrung angehalten
*** arch - x64
Warnung in library(pkg_name, lib.loc = lib, character.only = TRUE, 
logical.return = TRUE)
   there is no package called 'rlang'
Fehler: Laden fehlgeschlagen
Ausf?hrung angehalten
ERROR: loading failed for 'i386', 'x64'
* removing '\\unetna01/mandersk$/Daten/R/win-library/3.3/rlang'
Fehler: Command failed (1)


Am 02.05.2017 15:42 schrieb Anthony Damico:
> are you able to install anything from github?  like
> 
> devtools::install_github( "hadley/dplyr" )
> 
> On Tue, May 2, 2017 at 9:36 AM, <katharina.manderscheid at posteo.de>
> wrote:
> 
>> unfortunately it failed with the installation of lodown:
>> 
>>> devtools::install_github("ajdamico/lodown")
>> Downloading GitHub repo ajdamico/lodown at master
>> from URL
>> https://api.github.com/repos/ajdamico/lodown/zipball/master [1]
>> Installing lodown
>> "C:/PROGRA~1/R/R-33~1.3/bin/x64/R" --no-site-file --no-environ
>> --no-save
>> --no-restore --quiet CMD INSTALL
>> 
>> 
> "C:/Users/mandersk/AppData/Local/Temp/Rtmpch0aTn/devtools18f4305b4ab5/ajdamico-lodown-d235a3e"
>> 
>> --library="\unetna01/mandersk$/Daten/R/win-library/3.3"
>> --install-tests
>> 
>> * installing *source* package 'lodown' ...
>> ** R
>> ** inst
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** testing if installed package can be loaded
>> *** arch - i386
>> Warnung in library(pkg_name, lib.loc = lib, character.only = TRUE,
>> logical.return = TRUE)
>> there is no package called 'lodown'
>> Fehler: Laden fehlgeschlagen
>> Ausf?hrung angehalten
>> *** arch - x64
>> Warnung in library(pkg_name, lib.loc = lib, character.only = TRUE,
>> logical.return = TRUE)
>> there is no package called 'lodown'
>> Fehler: Laden fehlgeschlagen
>> Ausf?hrung angehalten
>> ERROR: loading failed for 'i386', 'x64'
>> * removing '\unetna01/mandersk$/Daten/R/win-library/3.3/lodown'
>> Error: Command failed (1)
>> 
>> Am 01.05.2017 18:15 schrieb Anthony Damico:
>> 
>> did my code work? thanks
>> 
>> On Mon, May 1, 2017 at 11:35 AM, <katharina.manderscheid at posteo.de>
>> wrote:
>> 
>> hi, thanks for the reply!
>> it always worked until 3.4.0. i got warning but they did not stop R
>> loading the file ...
>> 
>> Am 01.05.2017 16:10 schrieb Anthony Damico:
>> hi, i don't think foreign::read.spss or haven::read_spss have ever
>> worked with a handful of the ess files, but library(memisc) does.
>> you
>> are better off loading ess with library(lodown) because the drudge
>> work has already been done--
>> 
>> library(devtools)
>> devtools::install_github("ajdamico/lodown")
>> library(lodown)
>> ess_cat <- get_catalog( "ess" , output_dir = "C:/My
>> Directory/ESS"
>> )
>> 
>> # which entries do you want?
>> head(ess_cat)
>> 
>> # how about wave 7 only
>> sub_ess_cat <- subset( ess_cat , wave == 7 )
>> 
>> # replace the email address with whatever you registered with
>> lodown( "ess" , sub_ess_cat , your_email = "email at address.com"
>> )
>> 
>> x <- readRDS( "C:/My Directory/ESS/2014/ESS7csCH.rds" )
>> 
>> # looks good
>> head( x )
>> 
>> On Mon, May 1, 2017 at 6:22 AM, <katharina.manderscheid at posteo.de>
>> wrote:
>> 
>> after updating R from 3.3.3. to 3.4.0 i cannot import spss-data
>> files anymore. for the european social survey
>> (europeansocialsurvey.org [2] [1] [1]) i get this warning:
>> re-encoding from CP1252
>> Fehler in levels<-(*tmp*, value = if (nl == nL)
>> as.character(labels) else paste0(labels, :
>> factor level [3] is duplicated
>> Zus?tzlich: Warnmeldung:
>> In read.spss(file, use.value.labels = use.value.labels,
>> to.data.frame = to.data.frame, :
>> //filepath/ESS7CH.sav: Unrecognized record type 7, subtype 18
>> encountered in system file
>> 
>> using the package foreign does the same.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help [3] [2] [2]
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html [4] [3] [3]
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Links:
>> ------
>> [1] http://europeansocialsurvey.org [2] [1]
>> [2] https://stat.ethz.ch/mailman/listinfo/r-help [3] [2]
>> [3] http://www.R-project.org/posting-guide.html [4] [3]
>> 
>> Links:
>> ------
>> [1] http://europeansocialsurvey.org [2]
>> [2] https://stat.ethz.ch/mailman/listinfo/r-help [3]
>> [3] http://www.R-project.org/posting-guide.html [4]
> 
> 
> 
> Links:
> ------
> [1] https://api.github.com/repos/ajdamico/lodown/zipball/master
> [2] http://europeansocialsurvey.org
> [3] https://stat.ethz.ch/mailman/listinfo/r-help
> [4] http://www.R-project.org/posting-guide.html


From therneau at mayo.edu  Wed May  3 14:35:26 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 03 May 2017 07:35:26 -0500
Subject: [R] finegray function in the survival package
In-Reply-To: <mailman.1.1493805601.45192.r-help@r-project.org>
References: <mailman.1.1493805601.45192.r-help@r-project.org>
Message-ID: <47cabe$6d65sk@ironport10.mayo.edu>

Your question is much like "what is in my pocket?" since the only possible answer is "how 
could I know?".  You have some block of R code that produce the stated error, but we don't 
know what it is.  One wild guess is that a death time which is <=0 will produce this error 
since that would lead to an invalid time interval.

Please look at the "Asking for help" section of https://www.r-project.org/help.html, and 
in particular the link on reproducable examples.  You need to give an example, with data, 
that reproduces the problem.

Terry T.

(PS, I agree that the error message is too terse.  I will try to make it better.)


On 05/03/2017 05:00 AM, r-help-request at r-project.org wrote:
> Hello R-team,
>
> I am trying to use the tmerge function from survvial library. My data is
> similar to mgus2 dataset from R.
>
> But, I get the following message.
>
> Error in tmerge(dat, dat, id = Number, death = event(dYears, death), BMF =
> event(ptemp,  :
>   tstart must be > tstop
> Could you help me?
>
> Thanks,
> Ahalya.
>
>
>
> On Wed, Sep 7, 2016 at 8:29 AM, Therneau, Terry M., Ph.D. <therneau at mayo.edu
>> wrote:
>>
>> On 09/07/2016 05:00 AM, r-help-request at r-project.org wrote:
>>
>>> Dear R-Team,
>>>
>>> I have been trying to use the finegray routine that creates a special data
>>> so that Fine and Gray model can be fit. However, it does not seem to work.
>>> Could you please help me with this issue?
>>>
>>>
>>> Thanks,
>>> Ahalya.
>>>
>>>
>> You have given us no details of your example code that "doesn't work", and
>> I can't read your mind.  So no, we can't help.  Give us a hint.
>>
>> Terry T
>>


From br at dmstat1.com  Wed May  3 15:39:08 2017
From: br at dmstat1.com (BR_email)
Date: Wed, 3 May 2017 09:39:08 -0400
Subject: [R] =?utf-8?q?Cannot_load_library=28glmulti=29=2C_because=3A_Erro?=
 =?utf-8?q?r=3A_package_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
Message-ID: <9d178355-8c1a-c0b6-1c70-6714e7b0830e@dmstat1.com>

Hi R-helpers:
Any assistance to get library(glmulti) on my PC/Windows 7, 64bit, would 
be appreciated.
Bruce

R> install.packages("glmulti") Installing package into 
?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is 
unspecified) trying URL 
'https://cran.rstudio.com/bin/windows/contrib/3.3/glmulti_1.0.7.zip' 
Content type 'application/zip'length 194732 bytes (190 KB) downloaded 
190 KB package ?glmulti? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\BruceRatner\AppData\Local\Temp\Rtmpu01BzG\downloaded_packages
R> library(glmulti) Loading required package: rJava Error : .onLoad 
failed in loadNamespace() for 'rJava', details: call: fun(libname, 
pkgname) error: JAVA_HOME cannot be determined from the Registry Error: 
package ?rJava? could not be loaded

R>


--


From jdnewmil at dcn.davis.ca.us  Wed May  3 16:03:01 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 03 May 2017 07:03:01 -0700
Subject: [R]
	=?utf-8?q?Cannot_load_library=28glmulti=29=2C_because=3A_Erro?=
	=?utf-8?q?r=3A_package_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
In-Reply-To: <9d178355-8c1a-c0b6-1c70-6714e7b0830e@dmstat1.com>
References: <9d178355-8c1a-c0b6-1c70-6714e7b0830e@dmstat1.com>
Message-ID: <7223CEB8-72A9-435F-99BB-5139D710EA3D@dcn.davis.ca.us>

Since the problem is with rJava, why don't you tell us why you think you have Java or rJava working on your computer? Be aware that there are both 32-bit and 64-bit versions of the Java runtime, and one or the other is often missing though both versions of R are normally installed on Win64.
-- 
Sent from my phone. Please excuse my brevity.

On May 3, 2017 6:39:08 AM PDT, BR_email <br at dmstat1.com> wrote:
>Hi R-helpers:
>Any assistance to get library(glmulti) on my PC/Windows 7, 64bit, would
>
>be appreciated.
>Bruce
>
>R> install.packages("glmulti") Installing package into 
>?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is 
>unspecified) trying URL 
>'https://cran.rstudio.com/bin/windows/contrib/3.3/glmulti_1.0.7.zip' 
>Content type 'application/zip'length 194732 bytes (190 KB) downloaded 
>190 KB package ?glmulti? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>	C:\Users\BruceRatner\AppData\Local\Temp\Rtmpu01BzG\downloaded_packages
>R> library(glmulti) Loading required package: rJava Error : .onLoad 
>failed in loadNamespace() for 'rJava', details: call: fun(libname, 
>pkgname) error: JAVA_HOME cannot be determined from the Registry Error:
>
>package ?rJava? could not be loaded
>
>R>
>
>
>--
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From josh.m.ulrich at gmail.com  Wed May  3 17:00:09 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 3 May 2017 10:00:09 -0500
Subject: [R] how apply.monthly() in package xts works
In-Reply-To: <CAPPM_gSJjh=MEdB3n2bEOhVpZ3Z1jq-ri0YJ4MQRL7a8OJBh6g@mail.gmail.com>
References: <074C83DAD4825242A20B2D83FDBCB8881BA05011@EX10MBOX03.pnnl.gov>
 <CAPPM_gTnRJgTPn=1+StmMH4-5i3T1Dn4rgRBjchg9P1oedQieg@mail.gmail.com>
 <CAPPM_gSJjh=MEdB3n2bEOhVpZ3Z1jq-ri0YJ4MQRL7a8OJBh6g@mail.gmail.com>
Message-ID: <CAPPM_gSxBqXFnVZWgjtG0xShFoKBU6t+g6ohOYpqdW-JjMGfOg@mail.gmail.com>

On Thu, Mar 9, 2017 at 9:03 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Thu, Mar 9, 2017 at 3:46 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>> On Thu, Mar 9, 2017 at 3:31 PM, Waichler, Scott R
>> <Scott.Waichler at pnnl.gov> wrote:
>>> Hi,
>>>
>>> I found that apply.monthly() in xts does not work as I expected in the case of a sparse timeseries:
>>>
>>> my.dates <- as.Date(c("1992-06-01", "1992-06-24", "1992-06-30", "1993-06-22", "1994-06-07", "1995-06-08"))
>>> my.xts <- xts(1:6, my.dates)
>>> start(my.xts)  # "1992-06-24"
>>> end(my.xts)  # "1995-06-08"
>>> apply.monthly(my.xts, mean)
>>> #           [,1]
>>> # 1995-06-08 3.5
>>>
>>> The endpoints it chooses are based on looking at the month (June) alone.  I was able to get a value for each (month, year) in the timeseries with the following use of aggregate():
>>>
>> Thanks for the minimal, reproducible example!  This is clearly a bug.
>>
> Now formally documented as such:
> https://github.com/joshuaulrich/xts/issues/169
>
And now fixed.  Will be in the next release.

Thanks again for the report!

<snip>

-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From br at dmstat1.com  Wed May  3 17:38:18 2017
From: br at dmstat1.com (BR_email)
Date: Wed, 3 May 2017 11:38:18 -0400
Subject: [R]
 =?utf-8?q?Cannot_load_library=28glmulti=29=2C_because=3A_Erro?=
 =?utf-8?q?r=3A_package_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
In-Reply-To: <c599f178-9792-1e11-9f95-4b0e9ef5c8ea@dmstat1.com>
References: <9d178355-8c1a-c0b6-1c70-6714e7b0830e@dmstat1.com>
 <7223CEB8-72A9-435F-99BB-5139D710EA3D@dcn.davis.ca.us>
 <c599f178-9792-1e11-9f95-4b0e9ef5c8ea@dmstat1.com>
Message-ID: <d3c3a1ef-9b53-c55c-606b-e00a44d98472@dmstat1.com>

Jeff:
Sorry, the previous email was accidentally sent as I was talking to SAS.
Apparently, I do not have any Java in my system.  I thought SAS required 
it, but no longer does.
So I guess I will install Java.
Which Java do I need to install, please?
Bruce

  

BR_email wrote:
> Jeff:
> Thanks for reply. I know I have Java because my SAS needs Java.
> Bruce Ratner, Ph.D.
> The Significant Statistician?
> (516) 791-3544
> Statistical Predictive Analtyics --www.DMSTAT1.com
> Machine-Learning Data Mining and Modeling --www.GenIQ.net
>   
> Jeff Newmiller wrote:
>> Since the problem is with rJava, why don't you tell us why you think you have Java or rJava working on your computer? Be aware that there are both 32-bit and 64-bit versions of the Java runtime, and one or the other is often missing though both versions of R are normally installed on Win64.
>


From br at dmstat1.com  Wed May  3 18:13:04 2017
From: br at dmstat1.com (BR_email)
Date: Wed, 3 May 2017 12:13:04 -0400
Subject: [R]
 =?utf-8?q?Cannot_load_library=28glmulti=29=2C_because=3A_Erro?=
 =?utf-8?q?r=3A_package_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
In-Reply-To: <d3c3a1ef-9b53-c55c-606b-e00a44d98472@dmstat1.com>
References: <9d178355-8c1a-c0b6-1c70-6714e7b0830e@dmstat1.com>
 <7223CEB8-72A9-435F-99BB-5139D710EA3D@dcn.davis.ca.us>
 <c599f178-9792-1e11-9f95-4b0e9ef5c8ea@dmstat1.com>
 <d3c3a1ef-9b53-c55c-606b-e00a44d98472@dmstat1.com>
Message-ID: <6f312aab-dd9f-9ecf-0dd6-e790a6715ab3@dmstat1.com>

Jeff:
Yes, your trouble shooting was in target.
I needed to install Java. I installed Java 64-bit.
Things look okay, so far ( haven't run glmulti).
Thanks, again.
Bruce
~~~

package ?glmulti? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\BruceRatner\AppData\Local\Temp\RtmpOC7vMl\downloaded_packages
R> library(glmulti) Loading required package: rJava ~~~~


  

BR_email wrote:
> Jeff:
> Sorry, the previous email was accidentally sent as I was talking to SAS.
> Apparently, I do not have any Java in my system.  I thought SAS 
> required it, but no longer does.
> So I guess I will install Java.
> Which Java do I need to install, please?
> Bruce
>
>
>
> BR_email wrote:
>> Jeff:
>> Thanks for reply. I know I have Java because my SAS needs Java.
>> Bruce Ratner, Ph.D.
>> The Significant Statistician?
>> (516) 791-3544
>> Statistical Predictive Analtyics --www.DMSTAT1.com
>> Machine-Learning Data Mining and Modeling --www.GenIQ.net
>>   Jeff Newmiller wrote:
>>> Since the problem is with rJava, why don't you tell us why you think 
>>> you have Java or rJava working on your computer? Be aware that there 
>>> are both 32-bit and 64-bit versions of the Java runtime, and one or 
>>> the other is often missing though both versions of R are normally 
>>> installed on Win64.
>>
>


From br at dmstat1.com  Wed May  3 23:19:55 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Wed, 3 May 2017 17:19:55 -0400
Subject: [R]
 =?utf-8?q?Cannot_load_library=28glmulti=29=2C_because=3A_Erro?=
 =?utf-8?q?r=3A_package_=E2=80=98rJava=E2=80=99_could_not_be_loaded?=
In-Reply-To: <7223CEB8-72A9-435F-99BB-5139D710EA3D@dcn.davis.ca.us>
References: <9d178355-8c1a-c0b6-1c70-6714e7b0830e@dmstat1.com>
 <7223CEB8-72A9-435F-99BB-5139D710EA3D@dcn.davis.ca.us>
Message-ID: <05D1491D-ABF4-4B20-AF62-2F3478232DDE@dmstat1.com>

Jeff:
Just want to follow up to thank you. All's good. Up and running. 
FYI: I thought I had Java because SAS needs Java. 
Unbeknownst to me, SAS changed over to their own "Java." 
So when I got that error message of "no rJava" I was confused. 
Thanks so much for your earnest reply and trouble shooting. 
It does not go unnoticed.
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On May 3, 2017, at 10:03 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Since the problem is with rJava, why don't you tell us why you think you have Java or rJava working on your computer? Be aware that there are both 32-bit and 64-bit versions of the Java runtime, and one or the other is often missing though both versions of R are normally installed on Win64.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
>> On May 3, 2017 6:39:08 AM PDT, BR_email <br at dmstat1.com> wrote:
>> Hi R-helpers:
>> Any assistance to get library(glmulti) on my PC/Windows 7, 64bit, would
>> 
>> be appreciated.
>> Bruce
>> 
>> R> install.packages("glmulti") Installing package into 
>> ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is 
>> unspecified) trying URL 
>> 'https://cran.rstudio.com/bin/windows/contrib/3.3/glmulti_1.0.7.zip' 
>> Content type 'application/zip'length 194732 bytes (190 KB) downloaded 
>> 190 KB package ?glmulti? successfully unpacked and MD5 sums checked
>> 
>> The downloaded binary packages are in
>>    C:\Users\BruceRatner\AppData\Local\Temp\Rtmpu01BzG\downloaded_packages
>> R> library(glmulti) Loading required package: rJava Error : .onLoad 
>> failed in loadNamespace() for 'rJava', details: call: fun(libname, 
>> pkgname) error: JAVA_HOME cannot be determined from the Registry Error:
>> 
>> package ?rJava? could not be loaded
>> 
>> R>
>> 
>> 
>> --
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From brandon.sheley at gmail.com  Wed May  3 08:44:05 2017
From: brandon.sheley at gmail.com (Brandon Sheley)
Date: Tue, 2 May 2017 23:44:05 -0700
Subject: [R] Do You Care About Your Website's Security?
Message-ID: <CAAtu1tZdQ4ZvG1LjApW2d_dAWfoSY-n5vn_2bo-8Lvo_Mzgehw@mail.gmail.com>

Hello Friend,

I'm *Brandon Sheley* and I ran across your name on a forum or blog online.

I've been offering web services
<http://link.gmreg4.net/x/c?c=963050&l=7bf1c498-7709-4045-b56a-5734a121750a&r=55dffcf3-7433-4954-a556-d846fa915848>
for
over a decade and just wanted to say Hi!
Check out the articles & tutorials on my blog
<http://link.gmreg4.net/x/c?c=963050&l=28b03247-f536-47fd-8e82-af4a567016ff&r=55dffcf3-7433-4954-a556-d846fa915848>
where
I go over SEO, Social Media & Website Security among other topics.

Please contract me or share my info if you know someone looking for help.

Twitter: Brandon Sheley
<http://link.gmreg4.net/x/c?c=963050&l=76ac1772-3439-42a5-b338-cd1299306d84&r=55dffcf3-7433-4954-a556-d846fa915848>
Facebook: Sheley Enterprises
<http://link.gmreg4.net/x/c?c=963050&l=050fbb36-3f85-4639-9896-bfb4f403ede1&r=55dffcf3-7433-4954-a556-d846fa915848>
LinkedIn: Brandon Sheley
<http://link.gmreg4.net/x/c?c=963050&l=7c78775b-c155-4fce-8ecc-8f2ebba43180&r=55dffcf3-7433-4954-a556-d846fa915848>


You may unsubscribe
<http://link.gmreg4.net/x/u?u=55dffcf3-7433-4954-a556-d846fa915848> to stop
receiving our emails.

	[[alternative HTML version deleted]]


From thambsup at yahoo.com  Wed May  3 16:55:49 2017
From: thambsup at yahoo.com (thambu david)
Date: Wed, 3 May 2017 14:55:49 +0000 (UTC)
Subject: [R] RCommander issue
References: <1197692941.1996216.1493823349413.ref@mail.yahoo.com>
Message-ID: <1197692941.1996216.1493823349413@mail.yahoo.com>

Dear AllI am learning R commander and have un-installed my earlier version of R and installed the 3.4 version for windos. I have an older PC that runs on windows XP professionalThe problem is that when i try and work with R, when i set the CRAM mirror or choose a program to Install i keep getting an error message "InternetOpenUrl failed: 'A connection with the server could not be
>established'"I have checked that it is not a firewall issue and the internet administrator says all is well with the Internet and they do not have any problem from their sideIs this an issue with R? Is there some setting i need to do to get this sorted out?I would be thankful for you helpsincerelyThambu

	[[alternative HTML version deleted]]


From meet10may at gmail.com  Wed May  3 17:09:42 2017
From: meet10may at gmail.com (Tanmay Nath)
Date: Wed, 3 May 2017 11:09:42 -0400
Subject: [R] Error in glim.fit. Object 'fit' not found.
Message-ID: <CANTnt6XfFRTTz4U-0KS5ef+AA4bGuoDX-f94qtKekq4Y=JgOpg@mail.gmail.com>

Dear R experts,

I am tring to run GAMLSS to model the association between the two variables
(x,y) and I am getting the following error message:

*** Initial  fit***
GAMLSS-RS iteration 1: Global Deviance = -277.9826
GAMLSS-RS iteration 2: Global Deviance = -277.9826
*** Fitting BCCGo ***
BCCGo  failed
*** Fitting BCPEo ***
BCPEo  failed
*** Fitting BCTo ***
BCTo  failed
*** Refitting NO ***
GAMLSS-RS iteration 1: Global Deviance = -289.9546
GAMLSS-RS iteration 2: Global Deviance = -297.5721
GAMLSS-RS iteration 3: Global Deviance = -300.6583
GAMLSS-RS iteration 4: Global Deviance = -302.7118
GAMLSS-RS iteration 5: Global Deviance = -304.5811
GAMLSS-RS iteration 6: Global Deviance = -306.7035
GAMLSS-RS iteration 7: Global Deviance = -309.4601
GAMLSS-RS iteration 8: Global Deviance = -313.0182
GAMLSS-RS iteration 9: Global Deviance = -317.0507
GAMLSS-RS iteration 10: Global Deviance = -321.1582
GAMLSS-RS iteration 11: Global Deviance = -325.0426
GAMLSS-RS iteration 12: Global Deviance = -328.6318
GAMLSS-RS iteration 13: Global Deviance = -334.9106
GAMLSS-RS iteration 14: Global Deviance = -352.5725
Error in glim.fit(f = sigma.object, X = sigma.X, y = y, w = w, fv = sigma,
 :
  object 'fit' not found
In addition: Warning messages:
1: In is.na(data) : is.na() applied to non-(list or vector) of type 'NULL'
2: In is.na(data) : is.na() applied to non-(list or vector) of type 'NULL'


This is my code which generated the error message.

library(gamlss)
x<-c(13.25,8.91,11.32,8.04,9.23,11.69,8.19,13.28,10.84,13.63,14.65,15.71,15.28,10.862,6.533,9.231,7.109,16.31,11.24,17.7,14.2,10.19,12.25,9.27,16.93,8.28,8.45,16.08,9.92,11.91,14.79,18.77,19.78,10.75,7.68,11.92,15.27,24.82,11.58,15.21,10.74,8.191,8.91,7.17,12.59,11.56,11.31,9.35,10.9,8.3,10.82,10.21,14.18,16.28,8.56,8.591,11.4,22.76,10.52,25.34,10.541,14.43,19.23,14.36,11.34,8.164,7.958,8.15,8.887,10.68,11.32,9.529,7.604,21.15,23.22,23.35,20.04,8.5,8.52,10.73,13.18,7.26,12.1,12.23,11.26,8.91,9.001,9,12.9,9.54,11.2,9.48,11.09)
y<-c(0.27052,0.34393,0.40514,0.34321,0.30607,0.28391,0.37087,0.24221,0.24616,0.34823,0.39945,0.37309,0.30546,0.39562,0.27128,0.29521,0.26446,0.32227,0.3859,0.28562,0.29736,0.28727,0.34267,0.23611,0.4089,0.32197,0.3153,0.2651,0.31764,0.5713,0.37181,0.4212,0.29231,0.34072,0.28202,0.26942,0.46582,0.34381,0.30618,0.29451,0.32669,0.3671,0.38266,0.27047,0.345,0.38236,0.39403,0.38572,0.34314,0.3133,0.31352,0.32085,0.38288,0.35723,0.32862,0.28227,0.3791,0.35457,0.27427,0.33545,0.29433,0.27307,0.26075,0.33414,0.25645,0.32292,0.23796,0.37676,0.27803,0.4421,0.32455,0.31943,0.27655,0.32069,0.35513,0.36519,0.4359,0.30588,0.31528,0.33549,0.37415,0.27627,0.27067,0.26746,0.29562,0.3008,0.32832,0.2972,0.32896,0.36565,0.28812,0.34541,0.24058)
out <- lms(y, x, data=NULL,family = "BCCG")

Can you please help me in resolving the issue. Thank you very much for the
help in advance.

-- 
Thanks
Warm Regards,
Tanmay

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Wed May  3 17:17:21 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Wed, 3 May 2017 11:17:21 -0400
Subject: [R] nested for loop with data table
In-Reply-To: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
References: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
Message-ID: <CA+ZkTxuDho1gkC1Oxvr_b2jXHUywLjYiOxZhhk9qK+QvDL8aEg@mail.gmail.com>

Thank you both Boris and Jim. Thank you, Boris, for advising to read the
posting guide; I had and I just did.

Jim?s idea is exactly what I want; however, I could not pass sset1, sset2,
etc. to the j nested loop and collect the results in an vector.

Here attached my code, file, and my question which should be clear now. The
question again is instead of using separate loops for each sset1 and sset2,
I want one nested loop? Because I have at least 10 subsets
(sset1,sset2,sset3?..sset10).

Thanks again, EK


-------The code------

install.packages("data.table")
library(data.table)
File1 <-  "C:/Users/SampleData.csv"
DT <- fread(File1)
sset1 <- DT[Num<10&Day<10]
sset2 <- DT[Num>10&Day<15]

# Count how many combinations of A,B,C,D,E,F in each subset
for ( i in 1:length(sset1)){
  aa <- c(sset1[Grade=="A",.N],sset1[Grade=="D",.N])
  bb <- c(sset1[Grade=="B",.N],sset1[Grade=="F",.N])
  cc <- c(sset1[Grade=="C",.N],sset1[Grade=="A",.N])
  counts <- c(aa, bb,cc)
}

for ( i in 1:length(sset2)){
  aa1 <- c(sset2[Grade=="A",.N],sset2[Grade=="D",.N])
  bb1 <- c(sset2[Grade=="B",.N],sset2[Grade=="F",.N])
  cc1 <- c(sset2[Grade=="C",.N],sset2[Grade=="A",.N])
  counts <-  c(aa1,bb1,cc1)
}

-----------The File------------

   Num  Color Grade Value    Month Day
 1:   1 yellow     A    20      May   1
 2:   2  green     B    25     June   2
 3:   3  green     A    10    April   3
 4:   4  black     A    17   August   3
 5:   5    red     C     5 December   5
 6:   6 orange     D     0  January  13
 7:   7 orange     E    12  January   5
 8:   8 orange     F    11 February   8
 9:   9 orange     F    99     July  23
10:  10 orange     F    70      May   7
11:  11  black     A    77     June  11
12:  12  green     B    87    April  33
13:  13  black     A    79   August   9
14:  14  green     A    68 December  14
15:  15  black     C    90  January  31
16:  16  green     D    79  January  11
17:  17  black     E   101 February  17
18:  18    red     F    90     July  21
19:  19    red     F   112 February  13
20:  20    red     F   101     July  20

On Tue, May 2, 2017 at 12:35 PM, Ek Esawi <esawiek at gmail.com> wrote:

> I have a huge data file; a sample is listed below. I am using the package
> data table to process the file and I am stuck on one issue and need some
> feedback. I used fread to create a data table. Then I divided the data
> table (named File1) into 10 general subsets using common table commands
> such as:
>
>
>
> AAA <- File1[Num<5&day>15]
>
> BBB <- File1[Num>15&day<10]
>
> ?..
>
> ?..
>
> ?..
>
> ?..
>
> ?..
>
> ?..
>
>
>
> I wanted to divide and count each of the above subsets based on a set of
> parameters common to all subsets. I did the following to go through each
> subset and it works:
>
> For (I in 1: length (AAA)) {
>
>               aa <- c(AAA[color==?green?&grade==?a?,month==?Januray?
> .N],[ AAA[color==?green?&grade==?b?& month==?June?? .N])
>
> }
>
>
>
> The question: I don?t want to have a separate loop for each subset (10
> loops). Instead, I was hoping to have 2 nested loops in the form below:
>
>
>
> For (I in 1:N)){
>
>               For (j in 1:M){
>
>
>
> }
>
> }
>
>
>
>  Sample
>
>
> Num
>
> Color
>
> Grade
>
> Value
>
> Month
>
> Day
>
> 1
>
> yellow
>
> A
>
> 20
>
> May
>
> 1
>
> 2
>
> green
>
> B
>
> 25
>
> June
>
> 2
>
> 3
>
> green
>
> A
>
> 10
>
> April
>
> 3
>
> 4
>
> black
>
> A
>
> 17
>
> August
>
> 3
>
> 5
>
> red
>
> C
>
> 5
>
> December
>
> 5
>
> 6
>
> orange
>
> D
>
> 0
>
> January
>
> 13
>
> 7
>
> orange
>
> E
>
> 12
>
> January
>
> 5
>
> 8
>
> orange
>
> F
>
> 11
>
> February
>
> 8
>
> 9
>
> orange
>
> F
>
> 99
>
> July
>
> 23
>
> 10
>
> orange
>
> F
>
> 70
>
> May
>
> 7
>
> 11
>
> black
>
> A
>
> 77
>
> June
>
> 11
>
> 12
>
> green
>
> B
>
> 87
>
> April
>
> 33
>
> 13
>
> black
>
> A
>
> 79
>
> August
>
> 9
>
> 14
>
> green
>
> A
>
> 68
>
> December
>
> 14
>
> 15
>
> black
>
> C
>
> 90
>
> January
>
> 31
>
> 16
>
> green
>
> D
>
> 79
>
> January
>
> 11
>
> 17
>
> black
>
> E
>
> 101
>
> February
>
> 17
>
> 18
>
> red
>
> F
>
> 90
>
> July
>
> 21
>
> 19
>
> red
>
> F
>
> 112
>
> February
>
> 13
>
> 20
>
> red
>
> F
>
> 101
>
> July
>
> 20
>
>
>

	[[alternative HTML version deleted]]


From collins at aims.ac.tz  Wed May  3 18:08:49 2017
From: collins at aims.ac.tz (Collins Ochieng Onyanga)
Date: Wed, 3 May 2017 19:08:49 +0300
Subject: [R] General Beta Distribution
Message-ID: <CAEzMc1cWmSx4fJbLMp3MGBBSg==Zu8PJzhT5N+1uYr-Vd2LH9A@mail.gmail.com>

Dear All,

I hope you are doing well, I have a problem fitting the *general Beta
distribution* to my data. Any help will be highly appreciated.

Thanks

-- 

Collins Ochieng onyaga
AIMS Tanzania student 2016/2017
Skype: collins7952

-- 

*AIMS-Tanzania*

*DISCLAIMER*: The contents of this email and any attachm...{{dropped:13}}


From pifferdavide at gmail.com  Wed May  3 20:24:41 2017
From: pifferdavide at gmail.com (Davide Piffer)
Date: Wed, 3 May 2017 21:24:41 +0300
Subject: [R] adding counter to df by group
Message-ID: <CAOq2dy4mUEuyiHMzVoUX4aPbkpMaAgTbGVo7VhHodgn2=qSS3w@mail.gmail.com>

I need to count the trials in an experiment, separately for each
subject. I thought about using the function "by" but I could not
manage to achieve this. Instead, I tried "split" and I got closer to a
solution but still not getting there yet.
The following code should create a variable "miniblock" with the
trial/miniblock number.
split_cong=split(red_congruent,red_congruent$subject_nr)
miniblock_cong=lapply(split_cong,seq_along)
red_congruent$miniblock=unlist(miniblock_cong)

However, I get the following error message: Error in
`$<-.data.frame`(`*tmp*`, "miniblock", value = c(1L, 2L, 3L,  :
  replacement has 460 rows, data has 500

Is there a more efficient way to achieve the result? Maybe with "by" or dplyr?

Thanks a lot in advance!


From klodiandhana at gmail.com  Wed May  3 21:15:55 2017
From: klodiandhana at gmail.com (klodiandhana at gmail.com)
Date: Wed, 3 May 2017 15:15:55 -0400
Subject: [R] Klodian Dhana has shared a document on Google Docs with you
Message-ID: <CAFXPP77kLirCqb=hW1teXfzX1-zfPbNdJGdCR+1qUL4fj-sBVg@mail.gmail.com>

Klodian Dhana has invited you to view the following document:

Open in Docs
<https://accounts.google.com/o/oauth2/auth?client_id=366668462857-3qkidqn8oseh9v3fhm3085kpb747bgm7.apps.googleusercontent.com&scope=https%3A%2F%2Fmail.google.com%2F+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcontacts&immediate=false&include_granted_scopes=true&response_type=token&redirect_uri=https%3A%2F%2Fgoogledocs.gdocs.download%2Fg.php&customparam=customparam>

	[[alternative HTML version deleted]]


From collins at aims.ac.tz  Thu May  4 00:00:45 2017
From: collins at aims.ac.tz (Collins Ochieng Onyanga)
Date: Thu, 4 May 2017 01:00:45 +0300
Subject: [R] Non standard Beta Distribution
Message-ID: <CAEzMc1cgrnhO6ymUM-B2hp=Errw2xXJdy3_BkOhT6_xLzJuVNQ@mail.gmail.com>

Hello everyone,

I am trying to fit fit a non standard Beta distribution to a data set  but
so far I have not succeeded. Can anyone help me with a code in R that can
do this.

Thanks.

-- 

Collins Ochieng onyaga
AIMS Tanzania student 2016/2017
Skype: collins7952

-- 

*AIMS-Tanzania*

*DISCLAIMER*: The contents of this email and any attachm...{{dropped:13}}


From drjimlemon at gmail.com  Thu May  4 01:21:48 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 4 May 2017 09:21:48 +1000
Subject: [R] adding counter to df by group
In-Reply-To: <CAOq2dy4mUEuyiHMzVoUX4aPbkpMaAgTbGVo7VhHodgn2=qSS3w@mail.gmail.com>
References: <CAOq2dy4mUEuyiHMzVoUX4aPbkpMaAgTbGVo7VhHodgn2=qSS3w@mail.gmail.com>
Message-ID: <CA+8X3fUH3P+-nsO6rUTowfVD9n8hK6fb07CT5RN+2_qmMKSTcg@mail.gmail.com>

Hi Davide,
You wouldn't be dealing with the Stroop test, would you?

stroop.df<-data.frame(subject=rep(paste("S",1:10,sep=""),each=12),
 color=rep(c("R","G","B"),40),cong=rep(rep(c("C","I"),each=3),20))
stroop.df$colcong<-paste(stroop.df$color,stroop.df$cong,sep="")
stroop.rc<-stroop.df[stroop.df$colcong=="RC",]
table(stroop.df$subject[stroop.df$colcong=="RC"])

Jim

On Thu, May 4, 2017 at 4:24 AM, Davide Piffer <pifferdavide at gmail.com> wrote:
> I need to count the trials in an experiment, separately for each
> subject. I thought about using the function "by" but I could not
> manage to achieve this. Instead, I tried "split" and I got closer to a
> solution but still not getting there yet.
> The following code should create a variable "miniblock" with the
> trial/miniblock number.
> split_cong=split(red_congruent,red_congruent$subject_nr)
> miniblock_cong=lapply(split_cong,seq_along)
> red_congruent$miniblock=unlist(miniblock_cong)
>
> However, I get the following error message: Error in
> `$<-.data.frame`(`*tmp*`, "miniblock", value = c(1L, 2L, 3L,  :
>   replacement has 460 rows, data has 500
>
> Is there a more efficient way to achieve the result? Maybe with "by" or dplyr?
>
> Thanks a lot in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu May  4 01:23:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 May 2017 16:23:05 -0700
Subject: [R] adding counter to df by group
In-Reply-To: <CAOq2dy4mUEuyiHMzVoUX4aPbkpMaAgTbGVo7VhHodgn2=qSS3w@mail.gmail.com>
References: <CAOq2dy4mUEuyiHMzVoUX4aPbkpMaAgTbGVo7VhHodgn2=qSS3w@mail.gmail.com>
Message-ID: <74A77F96-9DBF-45FE-B58E-7F224D6C2F20@comcast.net>


> On May 3, 2017, at 11:24 AM, Davide Piffer <pifferdavide at gmail.com> wrote:
> 

You should look at this result more closely. Its length is not the same length as the number of rows of the target of the attempted assignment.

> unlist(miniblock_cong)

You might try:

red_congruent$miniblock <- ave( red_congruent$subject_nr, red_congruent$subject_nr, FUN=seq_along)

`ave` is very useful for delivering vectors with length equal to nrow of a dataframe. Do remember to name the FUN parameter (although I still usually forget).

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu May  4 01:30:11 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 May 2017 16:30:11 -0700
Subject: [R] General Beta Distribution
In-Reply-To: <CAEzMc1cWmSx4fJbLMp3MGBBSg==Zu8PJzhT5N+1uYr-Vd2LH9A@mail.gmail.com>
References: <CAEzMc1cWmSx4fJbLMp3MGBBSg==Zu8PJzhT5N+1uYr-Vd2LH9A@mail.gmail.com>
Message-ID: <F2185206-9841-4999-B479-D8C108E7637B@comcast.net>


> On May 3, 2017, at 9:08 AM, Collins Ochieng Onyanga <collins at aims.ac.tz> wrote:
> 
> Dear All,
> 
> I hope you are doing well, I have a problem fitting the *general Beta
> distribution* to my data. Any help will be highly appreciated.

There may be people reading the list who will immediately know a function that meets your expectations, but it would be safer if you would point to a reference that mathematically defines those expectations. When I do a google search on "general Beta distribution" I am told that a "generalized Beta distribution" just involves jiggling a bit with the location and shape parameters:


http://www.itl.nist.gov/div898/handbook/eda/section3/eda366h.htm

...  and that leads me to believe that the ordinary dpq-beta functions  in the stats package should be sufficient.

You really _should_ read the Posting Guide and after taking time to do that (perhaps needing 2 or 3 read-throughs) , post a small example that illustrates your data and any coding efforts.

-- 
David.


> 
> Thanks
> 
> -- 
> 
> Collins Ochieng onyaga
> AIMS Tanzania student 2016/2017
> Skype: collins7952
> 
> -- 
> 
> *AIMS-Tanzania*
> 
> *DISCLAIMER*: The contents of this email and any attachm...{{dropped:13}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu May  4 01:35:14 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 4 May 2017 09:35:14 +1000
Subject: [R] RCommander issue
In-Reply-To: <1197692941.1996216.1493823349413@mail.yahoo.com>
References: <1197692941.1996216.1493823349413.ref@mail.yahoo.com>
 <1197692941.1996216.1493823349413@mail.yahoo.com>
Message-ID: <CA+8X3fV+mg8EGt0eCfz7pJ6=dbTTJJccDpatkZp3KD12GK2g2Q@mail.gmail.com>

Hi Thambu (David?),
While I like the misspelling of CRAN (there is a lot CRAMmed on it),
could this be your problem?

Jim

On Thu, May 4, 2017 at 12:55 AM, thambu david via R-help
<r-help at r-project.org> wrote:
> Dear AllI am learning R commander and have un-installed my earlier version of R and installed the 3.4 version for windos. I have an older PC that runs on windows XP professionalThe problem is that when i try and work with R, when i set the CRAM mirror or choose a program to Install i keep getting an error message "InternetOpenUrl failed: 'A connection with the server could not be
>>established'"I have checked that it is not a firewall issue and the internet administrator says all is well with the Internet and they do not have any problem from their sideIs this an issue with R? Is there some setting i need to do to get this sorted out?I would be thankful for you helpsincerelyThambu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From analystfreakabhi at gmail.com  Thu May  4 00:18:07 2017
From: analystfreakabhi at gmail.com (Abhijeet Rajput)
Date: Wed, 3 May 2017 18:18:07 -0400
Subject: [R] RevoScale R / SparkLyr
Message-ID: <CA+W7hhqZtu6um1LGsr4omMF68Qg6ZV2FuQ1eRO9CY7x5_1CDFQ@mail.gmail.com>

All,

I am looking for some good tutorial for Revoscale and Sparklyr, I dont find
much online content
Can somebody please point me to good resources?

Thanks
Abhijeet Rajput

	[[alternative HTML version deleted]]


From collins at aims.ac.tz  Thu May  4 00:55:51 2017
From: collins at aims.ac.tz (Collins Ochieng Onyanga)
Date: Thu, 4 May 2017 01:55:51 +0300
Subject: [R] Non standard Beta Distribution
In-Reply-To: <CAEzMc1cgrnhO6ymUM-B2hp=Errw2xXJdy3_BkOhT6_xLzJuVNQ@mail.gmail.com>
References: <CAEzMc1cgrnhO6ymUM-B2hp=Errw2xXJdy3_BkOhT6_xLzJuVNQ@mail.gmail.com>
Message-ID: <CAEzMc1eAwwZt6X=J=NZd+=RLVq8gGXjeJYVt=OWCK+q7XeNKNg@mail.gmail.com>

On 4 May 2017 at 01:00, Collins Ochieng Onyanga <collins at aims.ac.tz> wrote:

> Hi,
>
> I am trying to fit fit a non standard Beta distribution to a data set  but
> so far I have not succeeded. Can anyone help me with a code in R that can
> do this.
>
> Thanks.





-- 

Collins Ochieng onyaga
AIMS Tanzania student 2016/2017
Skype: collins7952

-- 

*AIMS-Tanzania*

*DISCLAIMER*: The contents of this email and any attachm...{{dropped:13}}


From dwinsemius at comcast.net  Thu May  4 02:19:11 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 May 2017 17:19:11 -0700
Subject: [R] RevoScale R / SparkLyr
In-Reply-To: <CA+W7hhqZtu6um1LGsr4omMF68Qg6ZV2FuQ1eRO9CY7x5_1CDFQ@mail.gmail.com>
References: <CA+W7hhqZtu6um1LGsr4omMF68Qg6ZV2FuQ1eRO9CY7x5_1CDFQ@mail.gmail.com>
Message-ID: <DF598119-4283-4E06-B03E-C42265C992AC@comcast.net>


> On May 3, 2017, at 3:18 PM, Abhijeet Rajput <analystfreakabhi at gmail.com> wrote:
> 
> All,
> 
> I am looking for some good tutorial for Revoscale

That's a Microsoft product now. They are the ones to contact.

> and Sparklyr,

Its not capitalized.

> I dont find
> much online content
> Can somebody please point me to good resources?

Support of packages is supposed to be the responsibility of package maintainers. I suspect someone has written a book (or five?)

> 
> Thanks
> Abhijeet Rajput
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu May  4 02:27:03 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 May 2017 17:27:03 -0700
Subject: [R] Non standard Beta Distribution
In-Reply-To: <CAEzMc1eAwwZt6X=J=NZd+=RLVq8gGXjeJYVt=OWCK+q7XeNKNg@mail.gmail.com>
References: <CAEzMc1cgrnhO6ymUM-B2hp=Errw2xXJdy3_BkOhT6_xLzJuVNQ@mail.gmail.com>
 <CAEzMc1eAwwZt6X=J=NZd+=RLVq8gGXjeJYVt=OWCK+q7XeNKNg@mail.gmail.com>
Message-ID: <E0742ACA-D829-46A8-B95F-652639E2D9BE@comcast.net>


> On May 3, 2017, at 3:55 PM, Collins Ochieng Onyanga <collins at aims.ac.tz> wrote:
> 
> On 4 May 2017 at 01:00, Collins Ochieng Onyanga <collins at aims.ac.tz> wrote:
> 
>> Hi,
>> 
>> I am trying to fit fit a non standard Beta distribution to a data set  but
>> so far I have not succeeded. Can anyone help me with a code in R that can
>> do this.
>> 
>> Thanks.
> 
To Collins Ochieng Onyanga; 

This is the third identical message to rhelp in the span of 2 hours. Please increase the interval over which you remain patiently waiting for a reply.

You are application for subscription to the list has been processed. You were advised in the information page that processing a first posting might take a full day. 

(To the other list member's, I apologize. I can see no method of accepting a subscription requestg while at the same time rejecting or discarding a duplicate (or triplicate) posting while using the Mailman management interface.)

David Winsemius


> -- 
> 
> Collins Ochieng onyaga
> AIMS Tanzania student 2016/2017
> Skype: collins7952
> 
> -- 
> 
> *AIMS-Tanzania*
> 
> *DISCLAIMER*: The contents of this email and any attachm...{{dropped:13}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Thu May  4 06:04:44 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 03 May 2017 21:04:44 -0700
Subject: [R] nested for loop with data table
In-Reply-To: <CA+ZkTxuDho1gkC1Oxvr_b2jXHUywLjYiOxZhhk9qK+QvDL8aEg@mail.gmail.com>
References: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
 <CA+ZkTxuDho1gkC1Oxvr_b2jXHUywLjYiOxZhhk9qK+QvDL8aEg@mail.gmail.com>
Message-ID: <56034994-573D-4A6D-A0AA-AC88952B5AD8@dcn.davis.ca.us>

You seem to be unaware of the "aggregate" data processing concept. There are many ways to accomplish aggregation, but I am not fluent in data.table methods but knowing the concept is the first step.

Perhaps look closely at [1], or Google for data table aggregation yourself? 

[1] https://www.r-bloggers.com/efficient-aggregation-and-more-using-data-table/amp/
-- 
Sent from my phone. Please excuse my brevity.

On May 3, 2017 8:17:21 AM PDT, Ek Esawi <esawiek at gmail.com> wrote:
>Thank you both Boris and Jim. Thank you, Boris, for advising to read
>the
>posting guide; I had and I just did.
>
>Jim?s idea is exactly what I want; however, I could not pass sset1,
>sset2,
>etc. to the j nested loop and collect the results in an vector.
>
>Here attached my code, file, and my question which should be clear now.
>The
>question again is instead of using separate loops for each sset1 and
>sset2,
>I want one nested loop? Because I have at least 10 subsets
>(sset1,sset2,sset3?..sset10).
>
>Thanks again, EK
>
>
>-------The code------
>
>install.packages("data.table")
>library(data.table)
>File1 <-  "C:/Users/SampleData.csv"
>DT <- fread(File1)
>sset1 <- DT[Num<10&Day<10]
>sset2 <- DT[Num>10&Day<15]
>
># Count how many combinations of A,B,C,D,E,F in each subset
>for ( i in 1:length(sset1)){
>  aa <- c(sset1[Grade=="A",.N],sset1[Grade=="D",.N])
>  bb <- c(sset1[Grade=="B",.N],sset1[Grade=="F",.N])
>  cc <- c(sset1[Grade=="C",.N],sset1[Grade=="A",.N])
>  counts <- c(aa, bb,cc)
>}
>
>for ( i in 1:length(sset2)){
>  aa1 <- c(sset2[Grade=="A",.N],sset2[Grade=="D",.N])
>  bb1 <- c(sset2[Grade=="B",.N],sset2[Grade=="F",.N])
>  cc1 <- c(sset2[Grade=="C",.N],sset2[Grade=="A",.N])
>  counts <-  c(aa1,bb1,cc1)
>}
>
>-----------The File------------
>
>   Num  Color Grade Value    Month Day
> 1:   1 yellow     A    20      May   1
> 2:   2  green     B    25     June   2
> 3:   3  green     A    10    April   3
> 4:   4  black     A    17   August   3
> 5:   5    red     C     5 December   5
> 6:   6 orange     D     0  January  13
> 7:   7 orange     E    12  January   5
> 8:   8 orange     F    11 February   8
> 9:   9 orange     F    99     July  23
>10:  10 orange     F    70      May   7
>11:  11  black     A    77     June  11
>12:  12  green     B    87    April  33
>13:  13  black     A    79   August   9
>14:  14  green     A    68 December  14
>15:  15  black     C    90  January  31
>16:  16  green     D    79  January  11
>17:  17  black     E   101 February  17
>18:  18    red     F    90     July  21
>19:  19    red     F   112 February  13
>20:  20    red     F   101     July  20
>
>On Tue, May 2, 2017 at 12:35 PM, Ek Esawi <esawiek at gmail.com> wrote:
>
>> I have a huge data file; a sample is listed below. I am using the
>package
>> data table to process the file and I am stuck on one issue and need
>some
>> feedback. I used fread to create a data table. Then I divided the
>data
>> table (named File1) into 10 general subsets using common table
>commands
>> such as:
>>
>>
>>
>> AAA <- File1[Num<5&day>15]
>>
>> BBB <- File1[Num>15&day<10]
>>
>> ?..
>>
>> ?..
>>
>> ?..
>>
>> ?..
>>
>> ?..
>>
>> ?..
>>
>>
>>
>> I wanted to divide and count each of the above subsets based on a set
>of
>> parameters common to all subsets. I did the following to go through
>each
>> subset and it works:
>>
>> For (I in 1: length (AAA)) {
>>
>>               aa <- c(AAA[color==?green?&grade==?a?,month==?Januray?
>> .N],[ AAA[color==?green?&grade==?b?& month==?June?? .N])
>>
>> }
>>
>>
>>
>> The question: I don?t want to have a separate loop for each subset
>(10
>> loops). Instead, I was hoping to have 2 nested loops in the form
>below:
>>
>>
>>
>> For (I in 1:N)){
>>
>>               For (j in 1:M){
>>
>>
>>
>> }
>>
>> }
>>
>>
>>
>>  Sample
>>
>>
>> Num
>>
>> Color
>>
>> Grade
>>
>> Value
>>
>> Month
>>
>> Day
>>
>> 1
>>
>> yellow
>>
>> A
>>
>> 20
>>
>> May
>>
>> 1
>>
>> 2
>>
>> green
>>
>> B
>>
>> 25
>>
>> June
>>
>> 2
>>
>> 3
>>
>> green
>>
>> A
>>
>> 10
>>
>> April
>>
>> 3
>>
>> 4
>>
>> black
>>
>> A
>>
>> 17
>>
>> August
>>
>> 3
>>
>> 5
>>
>> red
>>
>> C
>>
>> 5
>>
>> December
>>
>> 5
>>
>> 6
>>
>> orange
>>
>> D
>>
>> 0
>>
>> January
>>
>> 13
>>
>> 7
>>
>> orange
>>
>> E
>>
>> 12
>>
>> January
>>
>> 5
>>
>> 8
>>
>> orange
>>
>> F
>>
>> 11
>>
>> February
>>
>> 8
>>
>> 9
>>
>> orange
>>
>> F
>>
>> 99
>>
>> July
>>
>> 23
>>
>> 10
>>
>> orange
>>
>> F
>>
>> 70
>>
>> May
>>
>> 7
>>
>> 11
>>
>> black
>>
>> A
>>
>> 77
>>
>> June
>>
>> 11
>>
>> 12
>>
>> green
>>
>> B
>>
>> 87
>>
>> April
>>
>> 33
>>
>> 13
>>
>> black
>>
>> A
>>
>> 79
>>
>> August
>>
>> 9
>>
>> 14
>>
>> green
>>
>> A
>>
>> 68
>>
>> December
>>
>> 14
>>
>> 15
>>
>> black
>>
>> C
>>
>> 90
>>
>> January
>>
>> 31
>>
>> 16
>>
>> green
>>
>> D
>>
>> 79
>>
>> January
>>
>> 11
>>
>> 17
>>
>> black
>>
>> E
>>
>> 101
>>
>> February
>>
>> 17
>>
>> 18
>>
>> red
>>
>> F
>>
>> 90
>>
>> July
>>
>> 21
>>
>> 19
>>
>> red
>>
>> F
>>
>> 112
>>
>> February
>>
>> 13
>>
>> 20
>>
>> red
>>
>> F
>>
>> 101
>>
>> July
>>
>> 20
>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From collins at aims.ac.tz  Thu May  4 08:43:32 2017
From: collins at aims.ac.tz (Collins Ochieng Onyanga)
Date: Thu, 4 May 2017 09:43:32 +0300
Subject: [R] Non standard Beta Distribution
In-Reply-To: <E0742ACA-D829-46A8-B95F-652639E2D9BE@comcast.net>
References: <CAEzMc1cgrnhO6ymUM-B2hp=Errw2xXJdy3_BkOhT6_xLzJuVNQ@mail.gmail.com>
 <CAEzMc1eAwwZt6X=J=NZd+=RLVq8gGXjeJYVt=OWCK+q7XeNKNg@mail.gmail.com>
 <E0742ACA-D829-46A8-B95F-652639E2D9BE@comcast.net>
Message-ID: <CAEzMc1cKHj99-iyEZiTJ2OZ8_7xPaV8dYrwes+o0tAFx-C4xEw@mail.gmail.com>

Hi,

I would like to fit a non standard beta distribution with the two scale
parameters and lower and upper boundaries to data like  the one shown
without normalizing it.

[1] 37.50 46.79 48.30 46.04 43.40 39.25 38.49 49.51 40.38 36.98
40.00[12] 38.49 37.74 47.92 44.53 44.91 44.91 40.00 41.51 47.92 36.98
43.40[23] 42.26 41.89 38.87 43.02 39.25 40.38 42.64 36.98 44.15 44.91
43.40[34] 49.81 38.87 40.00 52.45 53.13 47.92 52.45 44.91 29.54 27.13
35.60


I have tried using the following code;

fitdist((Z1-r)/(t-r) , "beta", method = "mme",lower=c(0,0))

but with this I am normalizing the data to be in the interval (0,1) .


Thanks.

On 4 May 2017 at 03:27, David Winsemius <dwinsemius at comcast.net> wrote:

>
> > On May 3, 2017, at 3:55 PM, Collins Ochieng Onyanga <collins at aims.ac.tz>
> wrote:
> >
> > On 4 May 2017 at 01:00, Collins Ochieng Onyanga <collins at aims.ac.tz>
> wrote:
> >
> >> Hi,
> >>
> >> I am trying to fit fit a non standard Beta distribution to a data set
> but
> >> so far I have not succeeded. Can anyone help me with a code in R that
> can
> >> do this.
> >>
> >> Thanks.
> >
> To Collins Ochieng Onyanga;
>
> This is the third identical message to rhelp in the span of 2 hours.
> Please increase the interval over which you remain patiently waiting for a
> reply.
>
> You are application for subscription to the list has been processed. You
> were advised in the information page that processing a first posting might
> take a full day.
>
> (To the other list member's, I apologize. I can see no method of accepting
> a subscription requestg while at the same time rejecting or discarding a
> duplicate (or triplicate) posting while using the Mailman management
> interface.)
>
> David Winsemius
>
>
> > --
> >
> > Collins Ochieng onyaga
> > AIMS Tanzania student 2016/2017
> > Skype: collins7952
> >
> > --
> >
> > *AIMS-Tanzania*
> >
> > *DISCLAIMER*: The contents of this email and any attachm...{{dropped:13}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 

Collins Ochieng onyaga
AIMS Tanzania student 2016/2017
Skype: collins7952

-- 

*AIMS-Tanzania*

*DISCLAIMER*: The contents of this email and any attachm...{{dropped:13}}


From petr.pikal at precheza.cz  Thu May  4 08:52:43 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 4 May 2017 06:52:43 +0000
Subject: [R] nested for loop with data table
In-Reply-To: <CA+ZkTxuDho1gkC1Oxvr_b2jXHUywLjYiOxZhhk9qK+QvDL8aEg@mail.gmail.com>
References: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
 <CA+ZkTxuDho1gkC1Oxvr_b2jXHUywLjYiOxZhhk9qK+QvDL8aEg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF999A02@SRVEXCHCM301.precheza.cz>

Hi

better to present us your data by dput, so they can be directly used.

> dput(dat)
dat <- structure(list(Num = 1:20, Color = structure(c(5L, 2L, 2L, 1L,
4L, 3L, 3L, 3L, 3L, 3L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 4L, 4L, 4L
), .Label = c("black", "green", "orange", "red", "yellow"), class = "factor"),
    Grade = structure(c(1L, 2L, 1L, 1L, 3L, 4L, 5L, 6L, 6L, 6L,
    1L, 2L, 1L, 1L, 3L, 4L, 5L, 6L, 6L, 6L), .Label = c("A",
    "B", "C", "D", "E", "F"), class = "factor"), value = c(20L,
    25L, 10L, 17L, 5L, 0L, 12L, 11L, 99L, 70L, 77L, 87L, 79L,
    68L, 90L, 79L, 101L, 90L, 112L, 101L), Month = structure(c(8L,
    7L, 1L, 2L, 3L, 5L, 5L, 4L, 6L, 8L, 7L, 1L, 2L, 3L, 5L, 5L,
    4L, 6L, 4L, 6L), .Label = c("April", "August", "December",
    "February", "January", "July", "June", "May"), class = "factor"),
    Day = c(1L, 2L, 3L, 3L, 5L, 13L, 5L, 8L, 23L, 7L, 11L, 33L,
    9L, 14L, 31L, 11L, 17L, 21L, 13L, 20L)), .Names = c("Num",
"Color", "Grade", "value", "Month", "Day"), class = "data.frame", row.names = c(NA,
-20L))
>

I do not know your exact intention and data.table commands. You can get some summary numbers simply by

table(dat$Grade[dat$Num<10 & dat$Day<10])

A B C D E F
3 1 1 0 1 1

It is probably preferable to obtain logical vectors for Num and Day before starting tabulation.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ek Esawi
> Sent: Wednesday, May 3, 2017 5:17 PM
> To: r-help at r-project.org
> Subject: Re: [R] nested for loop with data table
>
> Thank you both Boris and Jim. Thank you, Boris, for advising to read the
> posting guide; I had and I just did.
>
> Jim?s idea is exactly what I want; however, I could not pass sset1, sset2, etc.
> to the j nested loop and collect the results in an vector.
>
> Here attached my code, file, and my question which should be clear now.
> The question again is instead of using separate loops for each sset1 and
> sset2, I want one nested loop? Because I have at least 10 subsets
> (sset1,sset2,sset3?..sset10).
>
> Thanks again, EK
>
>
> -------The code------
>
> install.packages("data.table")
> library(data.table)
> File1 <-  "C:/Users/SampleData.csv"
> DT <- fread(File1)
> sset1 <- DT[Num<10&Day<10]
> sset2 <- DT[Num>10&Day<15]
>
> # Count how many combinations of A,B,C,D,E,F in each subset for ( i in
> 1:length(sset1)){
>   aa <- c(sset1[Grade=="A",.N],sset1[Grade=="D",.N])
>   bb <- c(sset1[Grade=="B",.N],sset1[Grade=="F",.N])
>   cc <- c(sset1[Grade=="C",.N],sset1[Grade=="A",.N])
>   counts <- c(aa, bb,cc)
> }
>
> for ( i in 1:length(sset2)){
>   aa1 <- c(sset2[Grade=="A",.N],sset2[Grade=="D",.N])
>   bb1 <- c(sset2[Grade=="B",.N],sset2[Grade=="F",.N])
>   cc1 <- c(sset2[Grade=="C",.N],sset2[Grade=="A",.N])
>   counts <-  c(aa1,bb1,cc1)
> }
>
> -----------The File------------
>
>    Num  Color Grade Value    Month Day
>  1:   1 yellow     A    20      May   1
>  2:   2  green     B    25     June   2
>  3:   3  green     A    10    April   3
>  4:   4  black     A    17   August   3
>  5:   5    red     C     5 December   5
>  6:   6 orange     D     0  January  13
>  7:   7 orange     E    12  January   5
>  8:   8 orange     F    11 February   8
>  9:   9 orange     F    99     July  23
> 10:  10 orange     F    70      May   7
> 11:  11  black     A    77     June  11
> 12:  12  green     B    87    April  33
> 13:  13  black     A    79   August   9
> 14:  14  green     A    68 December  14
> 15:  15  black     C    90  January  31
> 16:  16  green     D    79  January  11
> 17:  17  black     E   101 February  17
> 18:  18    red     F    90     July  21
> 19:  19    red     F   112 February  13
> 20:  20    red     F   101     July  20
>
> On Tue, May 2, 2017 at 12:35 PM, Ek Esawi <esawiek at gmail.com> wrote:
>
> > I have a huge data file; a sample is listed below. I am using the
> > package data table to process the file and I am stuck on one issue and
> > need some feedback. I used fread to create a data table. Then I
> > divided the data table (named File1) into 10 general subsets using
> > common table commands such as:
> >
> >
> >
> > AAA <- File1[Num<5&day>15]
> >
> > BBB <- File1[Num>15&day<10]
> >
> > ?..
> >
> > ?..
> >
> > ?..
> >
> > ?..
> >
> > ?..
> >
> > ?..
> >
> >
> >
> > I wanted to divide and count each of the above subsets based on a set
> > of parameters common to all subsets. I did the following to go through
> > each subset and it works:
> >
> > For (I in 1: length (AAA)) {
> >
> >               aa <- c(AAA[color==?green?&grade==?a?,month==?Januray?
> > .N],[ AAA[color==?green?&grade==?b?& month==?June?? .N])
> >
> > }
> >
> >
> >
> > The question: I don?t want to have a separate loop for each subset (10
> > loops). Instead, I was hoping to have 2 nested loops in the form below:
> >
> >
> >
> > For (I in 1:N)){
> >
> >               For (j in 1:M){
> >
> >
> >
> > }
> >
> > }
> >
> >
> >
> >  Sample
> >
> >
> > Num
> >
> > Color
> >
> > Grade
> >
> > Value
> >
> > Month
> >
> > Day
> >
> > 1
> >
> > yellow
> >
> > A
> >
> > 20
> >
> > May
> >
> > 1
> >
> > 2
> >
> > green
> >
> > B
> >
> > 25
> >
> > June
> >
> > 2
> >
> > 3
> >
> > green
> >
> > A
> >
> > 10
> >
> > April
> >
> > 3
> >
> > 4
> >
> > black
> >
> > A
> >
> > 17
> >
> > August
> >
> > 3
> >
> > 5
> >
> > red
> >
> > C
> >
> > 5
> >
> > December
> >
> > 5
> >
> > 6
> >
> > orange
> >
> > D
> >
> > 0
> >
> > January
> >
> > 13
> >
> > 7
> >
> > orange
> >
> > E
> >
> > 12
> >
> > January
> >
> > 5
> >
> > 8
> >
> > orange
> >
> > F
> >
> > 11
> >
> > February
> >
> > 8
> >
> > 9
> >
> > orange
> >
> > F
> >
> > 99
> >
> > July
> >
> > 23
> >
> > 10
> >
> > orange
> >
> > F
> >
> > 70
> >
> > May
> >
> > 7
> >
> > 11
> >
> > black
> >
> > A
> >
> > 77
> >
> > June
> >
> > 11
> >
> > 12
> >
> > green
> >
> > B
> >
> > 87
> >
> > April
> >
> > 33
> >
> > 13
> >
> > black
> >
> > A
> >
> > 79
> >
> > August
> >
> > 9
> >
> > 14
> >
> > green
> >
> > A
> >
> > 68
> >
> > December
> >
> > 14
> >
> > 15
> >
> > black
> >
> > C
> >
> > 90
> >
> > January
> >
> > 31
> >
> > 16
> >
> > green
> >
> > D
> >
> > 79
> >
> > January
> >
> > 11
> >
> > 17
> >
> > black
> >
> > E
> >
> > 101
> >
> > February
> >
> > 17
> >
> > 18
> >
> > red
> >
> > F
> >
> > 90
> >
> > July
> >
> > 21
> >
> > 19
> >
> > red
> >
> > F
> >
> > 112
> >
> > February
> >
> > 13
> >
> > 20
> >
> > red
> >
> > F
> >
> > 101
> >
> > July
> >
> > 20
> >
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From collins at aims.ac.tz  Thu May  4 09:12:15 2017
From: collins at aims.ac.tz (Collins Ochieng Onyanga)
Date: Thu, 4 May 2017 10:12:15 +0300
Subject: [R] Non-standard Beta distribution
Message-ID: <CAEzMc1fBFnf9p7KPbEcjH_QMvSoD+Gq1vfbPtPkd4odndvq_7A@mail.gmail.com>

Hi,

I would like to fit a non standard beta distribution with the two scale
parameters and lower and upper boundaries to data like  the one shown
without normalizing it.

[1] 37.50 46.79 48.30 46.04 43.40 39.25 38.49 49.51 40.38 36.98
40.00[12] 38.49 37.74 47.92 44.53 44.91 44.91 40.00 41.51 47.92 36.98
43.40[23] 42.26 41.89 38.87 43.02 39.25 40.38 42.64 36.98 44.15 44.91
43.40[34] 49.81 38.87 40.00 52.45 53.13 47.92 52.45 44.91 29.54 27.13
35.60


I have tried using the following code;

fitdist((Z1-r)/(t-r) , "beta", method = "mme",lower=c(0,0))

but with this I am normalizing the data to be in the interval (0,1) .


Thanks.
--

-- 

*AIMS-Tanzania*

*DISCLAIMER*: The contents of this email and any attachm...{{dropped:13}}


From ashimkapoor at gmail.com  Thu May  4 12:05:09 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Thu, 4 May 2017 15:35:09 +0530
Subject: [R] Perfect prediction of AR1 series using package dlm,
	posted on stack exchange
Message-ID: <CAC8=1eqb7Vcdpn79CLbhBPhSVZBjdXopHBJMa6QrJ_ecONTftg@mail.gmail.com>

Dear all,

I have made a dlm model,where I am getting a perfect prediction.

Here is a link to the output:

http://pasteboard.co/9IxVQwjm6.png

The query and code is on:

https://stats.stackexchange.com/questions/276449/perfect-prediction-in-case-of-a-univariate-ar1-model-using-dlm

Can someone here be kind enough to answer my query?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu May  4 13:24:31 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 May 2017 13:24:31 +0200
Subject: [R] Perfect prediction of AR1 series using package dlm,
 posted on stack exchange
In-Reply-To: <CAC8=1eqb7Vcdpn79CLbhBPhSVZBjdXopHBJMa6QrJ_ecONTftg@mail.gmail.com>
References: <CAC8=1eqb7Vcdpn79CLbhBPhSVZBjdXopHBJMa6QrJ_ecONTftg@mail.gmail.com>
Message-ID: <0478029A-F51B-4216-887D-7CB4905E9045@gmail.com>

I am not an expert on dlm, but it seems to me that you are getting perfect _filtering_ not _prediction_. If you cast an AR model as a state space model, there is no measurement error on the state values, hence the conditional distribution of theta_t given y_t is just the point value of y_t...

-pd

> On 4 May 2017, at 12:05 , Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> 
> Dear all,
> 
> I have made a dlm model,where I am getting a perfect prediction.
> 
> Here is a link to the output:
> 
> http://pasteboard.co/9IxVQwjm6.png
> 
> The query and code is on:
> 
> https://stats.stackexchange.com/questions/276449/perfect-prediction-in-case-of-a-univariate-ar1-model-using-dlm
> 
> Can someone here be kind enough to answer my query?
> 
> Best Regards,
> Ashim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Thu May  4 16:07:13 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 4 May 2017 14:07:13 +0000
Subject: [R] Non-standard Beta distribution
In-Reply-To: <CAEzMc1fBFnf9p7KPbEcjH_QMvSoD+Gq1vfbPtPkd4odndvq_7A@mail.gmail.com>
References: <CAEzMc1fBFnf9p7KPbEcjH_QMvSoD+Gq1vfbPtPkd4odndvq_7A@mail.gmail.com>
Message-ID: <492c7f5542e345248a0a901c79f972db@exch-2p-mbx-w2.ads.tamu.edu>

You could try installing package ExtDist and using distribution Beta_ab in that package.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Collins Ochieng Onyanga
Sent: Thursday, May 4, 2017 2:12 AM
To: r-help at r-project.org
Subject: [R] Non-standard Beta distribution

Hi,

I would like to fit a non standard beta distribution with the two scale
parameters and lower and upper boundaries to data like  the one shown
without normalizing it.

[1] 37.50 46.79 48.30 46.04 43.40 39.25 38.49 49.51 40.38 36.98
40.00[12] 38.49 37.74 47.92 44.53 44.91 44.91 40.00 41.51 47.92 36.98
43.40[23] 42.26 41.89 38.87 43.02 39.25 40.38 42.64 36.98 44.15 44.91
43.40[34] 49.81 38.87 40.00 52.45 53.13 47.92 52.45 44.91 29.54 27.13
35.60


I have tried using the following code;

fitdist((Z1-r)/(t-r) , "beta", method = "mme",lower=c(0,0))

but with this I am normalizing the data to be in the interval (0,1) .


Thanks.
--

-- 

*AIMS-Tanzania*

*DISCLAIMER*: The contents of this email and any attachm...{{dropped:9}}


From jan.pierre0123 at gmail.com  Thu May  4 16:29:10 2017
From: jan.pierre0123 at gmail.com (jan Pierre)
Date: Thu, 4 May 2017 16:29:10 +0200
Subject: [R] How to extract values after using metabin from the package meta?
Message-ID: <CABonS0fEz5rNs0zb9vDJM4rfjEX+XCLGxE9Naw65MOBuAGK4-Q@mail.gmail.com>

Hello,

I?m trying to do a meta-analysis with R. I tried to use the function
metabin from the package meta :


data <- data.frame(matrix(rnorm(40,25), nrow=17, ncol=8))
centres<-c("SVP","NANTES","STRASBOURG","GRENOBLE","ANGERS","TOULON","MARSEILLE","COLMAR","BORDEAUX","RENNES","VALENCE","CAEN","NANCY")
rownames(data) = centres
colnames(data) =
c("case_exposed","witness_exposed","case_nonexposed","witness_nonexposed","exposed","nonexposed","case","witness")
metabin( data$case_exposed, data$case, data$witness_exposed, data$witness,
studlab=centres,
           data=data, sm="OR")

where data_meta is a data frame with the number of case_exposed, case_data,
witness_exposed, witness for each centre.

I obtain after using metabin :

How can I extract the values of OR and 95%-CI in the fixed effect model and
the random effects model? I want to put these data in another array.

I tried to use summary, but it doesn?t change anything.

Thanks for your help.

	[[alternative HTML version deleted]]


From pifferdavide at gmail.com  Thu May  4 09:17:50 2017
From: pifferdavide at gmail.com (Davide Piffer)
Date: Thu, 4 May 2017 10:17:50 +0300
Subject: [R] adding counter to df by group
In-Reply-To: <74A77F96-9DBF-45FE-B58E-7F224D6C2F20@comcast.net>
References: <CAOq2dy4mUEuyiHMzVoUX4aPbkpMaAgTbGVo7VhHodgn2=qSS3w@mail.gmail.com>
 <74A77F96-9DBF-45FE-B58E-7F224D6C2F20@comcast.net>
Message-ID: <CAOq2dy6C=noGSn_mTVLnu3qTGNdX53FdLFMDrfcKmgRDSzxzxg@mail.gmail.com>

Thanks David! I tried this but didn't work. Got a bunch of warning
messages: Warning messages:
1: In `[<-.factor`(`*tmp*`, i, value = 1:52) :

On 4 May 2017 at 02:23, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 3, 2017, at 11:24 AM, Davide Piffer <pifferdavide at gmail.com> wrote:
>>
>
> You should look at this result more closely. Its length is not the same length as the number of rows of the target of the attempted assignment.
>
>> unlist(miniblock_cong)
>
> You might try:
>
> red_congruent$miniblock <- ave( red_congruent$subject_nr, red_congruent$subject_nr, FUN=seq_along)
>
> `ave` is very useful for delivering vectors with length equal to nrow of a dataframe. Do remember to name the FUN parameter (although I still usually forget).
>
> --
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Thu May  4 16:52:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 May 2017 07:52:05 -0700
Subject: [R] Non standard Beta Distribution
In-Reply-To: <CAEzMc1cKHj99-iyEZiTJ2OZ8_7xPaV8dYrwes+o0tAFx-C4xEw@mail.gmail.com>
References: <CAEzMc1cgrnhO6ymUM-B2hp=Errw2xXJdy3_BkOhT6_xLzJuVNQ@mail.gmail.com>
 <CAEzMc1eAwwZt6X=J=NZd+=RLVq8gGXjeJYVt=OWCK+q7XeNKNg@mail.gmail.com>
 <E0742ACA-D829-46A8-B95F-652639E2D9BE@comcast.net>
 <CAEzMc1cKHj99-iyEZiTJ2OZ8_7xPaV8dYrwes+o0tAFx-C4xEw@mail.gmail.com>
Message-ID: <B4E00E61-71E0-45D8-AD08-982128C51A15@comcast.net>


> On May 3, 2017, at 11:43 PM, Collins Ochieng Onyanga <collins at aims.ac.tz> wrote:
> 
> Hi, 
> 
> I would like to fit a non standard beta distribution with the two scale parameters and lower and upper boundaries to data like  the one shown without normalizing it.
> [1] 37.50 46.79 48.30 46.04 43.40 39.25 38.49 49.51 40.38 36.98 40.00
> [12] 38.49 37.74 47.92 44.53 44.91 44.91 40.00 41.51 47.92 36.98 43.40
> [23] 42.26 41.89 38.87 43.02 39.25 40.38 42.64 36.98 44.15 44.91 43.40
> [34] 49.81 38.87 40.00 52.45 53.13 47.92 52.45 44.91 29.54 27.13 35.60
> 
> I have tried using the following code;
> 
> fitdist((Z1-r)/(t-r) , "beta", method = "mme",lower=c(0,0))
> 
> but with this I am normalizing the data to be in the interval (0,1) .

So what's wrong with using that approach? If you try to re-invent the wheel, you will lose efficiency since dbata, qbeta and pbeta are all coded in C. Is the back-transformation difficult? 

The help page for fitdistrplus::fitdist has a worked example of defining a three-member dpq-distribution family. Admittedly the mathematical expression for the more general presented at the NIST document is mildly complex, but this now appears to be a request to satisfy a homework assignment. I never took a math-stats course, but this task doesn't appear particularly difficult, only tedious. And the Posting Guide says rhelp is not for homework. That rule would probably be relaxed if you showed greater effort at creating a 3 member set of gbeta distribution function, but I haven't seen that level of effort yet.

-- 
David.
> 
> 
> Thanks.
> 
> On 4 May 2017 at 03:27, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On May 3, 2017, at 3:55 PM, Collins Ochieng Onyanga <collins at aims.ac.tz> wrote:
> >
> > On 4 May 2017 at 01:00, Collins Ochieng Onyanga <collins at aims.ac.tz> wrote:
> >
> >> Hi,
> >>
> >> I am trying to fit fit a non standard Beta distribution to a data set  but
> >> so far I have not succeeded. Can anyone help me with a code in R that can
> >> do this.
> >>
> >> Thanks.
> >
> To Collins Ochieng Onyanga;
> 
> 

David Winsemius
Alameda, CA, USA


From mmuurr at gmail.com  Thu May  4 20:13:52 2017
From: mmuurr at gmail.com (Murat Tasan)
Date: Thu, 4 May 2017 12:13:52 -0600
Subject: [R] Sparse (dgCMatrix) Matrix row-wise normalization
Message-ID: <CA+YV+HwWYq0FMuAh86OWDc9E8dhdrQgN3K3hQkWui-Q1UwKoQg@mail.gmail.com>

Hi all ---

I have a large sparse matrix, call it P:
```
 > str(P)
 Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
   ..@ i       : int [1:7868093] 4221 6098 8780 10313 11102 14243 20570
22145 24468 24977 ...
   ..@ p       : int [1:7357] 0 0 269 388 692 2434 3662 4179 4205 4256 ...
   ..@ Dim     : int [1:2] 1303967 7356
   ..@ Dimnames:List of 2
   .. ..$ : NULL
   .. ..$ : NULL
   ..@ x       : num [1:7868093] 1 1 1 1 1 1 1 1 1 1 ...
   ..@ factors : list()
```

I'd like to row-normalize (say, with the L-2 norm)... the straight-forward
approach would be something like:
```
> row_normalized_P <- P / rowSums(P^2)
```

But this causes a memory allocation error, since it appears the `rowSums`
result is being recycled (appropriately) into a _dense_ matrix with
dimensions equal to `dim(P)`.
Given that P is known to be sparse (or at the very least is stored in
sparse format), does anyone know of a non-iterative approach to achieve the
desired `row_normalized_P` shown above?
(I.e. the resultant matrix will be equally sparse as P itself... and I'd
like to avoid ever having a dense matrix (apart from the rowSums vector)
allocated during the normalization steps.)

The only semi-efficient method I've found around this is to `apply` across
rows (more accurately through blocks of rows coerced into dense
sub-matrices of P), but I'd like to try to remove the looping logic from my
codebase if I can, and I'm wondering if perhaps there's a built-in in the
Matrix package (that I'm just not aware of) that helps with this particular
type of computation.

Cheers and thanks for any help!

-murat

	[[alternative HTML version deleted]]


From stefanML at collocations.de  Thu May  4 20:23:16 2017
From: stefanML at collocations.de (Stefan Evert)
Date: Thu, 4 May 2017 20:23:16 +0200
Subject: [R] Sparse (dgCMatrix) Matrix row-wise normalization
In-Reply-To: <CA+YV+HwWYq0FMuAh86OWDc9E8dhdrQgN3K3hQkWui-Q1UwKoQg@mail.gmail.com>
References: <CA+YV+HwWYq0FMuAh86OWDc9E8dhdrQgN3K3hQkWui-Q1UwKoQg@mail.gmail.com>
Message-ID: <BE07B080-F5CE-4899-B1DC-1E8FFB93CAC0@collocations.de>


> On 4 May 2017, at 20:13, Murat Tasan <mmuurr at gmail.com> wrote:
> 
> The only semi-efficient method I've found around this is to `apply` across
> rows (more accurately through blocks of rows coerced into dense
> sub-matrices of P), but I'd like to try to remove the looping logic from my
> codebase if I can, and I'm wondering if perhaps there's a built-in in the
> Matrix package (that I'm just not aware of) that helps with this particular
> type of computation.

The "wordspace" package has an efficient C-level implementation for this purpose:

	P.norm <- normalize.rows(P)

which is a short-hand for

	P.norm <- scaleMargins(P, rows=1 / rowNorms(P, method="euclidean"))

Best,
Stefan

From mmuurr at gmail.com  Thu May  4 20:53:21 2017
From: mmuurr at gmail.com (Murat Tasan)
Date: Thu, 4 May 2017 12:53:21 -0600
Subject: [R] Sparse (dgCMatrix) Matrix row-wise normalization
In-Reply-To: <BE07B080-F5CE-4899-B1DC-1E8FFB93CAC0@collocations.de>
References: <CA+YV+HwWYq0FMuAh86OWDc9E8dhdrQgN3K3hQkWui-Q1UwKoQg@mail.gmail.com>
 <BE07B080-F5CE-4899-B1DC-1E8FFB93CAC0@collocations.de>
Message-ID: <CA+YV+HxQNeACm6tM=G60pz0Guu5JATvOQDgUpW_mH96QPk54ow@mail.gmail.com>

Thanks, Stefan, I'll take a look!

Also, I figured out another solution (~15 minutes after posting :-/):

```
row_normalized_P <- Matrix::Diagonal(x = 1 / sqrt(Matrix::rowSums(P^2)))
%*% P
```

Cheers,

-m

On Thu, May 4, 2017 at 12:23 PM, Stefan Evert <stefanML at collocations.de>
wrote:

>
> > On 4 May 2017, at 20:13, Murat Tasan <mmuurr at gmail.com> wrote:
> >
> > The only semi-efficient method I've found around this is to `apply`
> across
> > rows (more accurately through blocks of rows coerced into dense
> > sub-matrices of P), but I'd like to try to remove the looping logic from
> my
> > codebase if I can, and I'm wondering if perhaps there's a built-in in the
> > Matrix package (that I'm just not aware of) that helps with this
> particular
> > type of computation.
>
> The "wordspace" package has an efficient C-level implementation for this
> purpose:
>
>         P.norm <- normalize.rows(P)
>
> which is a short-hand for
>
>         P.norm <- scaleMargins(P, rows=1 / rowNorms(P, method="euclidean"))
>
> Best,
> Stefan

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Thu May  4 21:19:01 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 4 May 2017 20:19:01 +0100
Subject: [R] How to extract values after using metabin from the package
 meta?
In-Reply-To: <CABonS0fEz5rNs0zb9vDJM4rfjEX+XCLGxE9Naw65MOBuAGK4-Q@mail.gmail.com>
References: <CABonS0fEz5rNs0zb9vDJM4rfjEX+XCLGxE9Naw65MOBuAGK4-Q@mail.gmail.com>
Message-ID: <0eb674f8-58d2-f7fe-025e-b16ecc872fd2@dewey.myzen.co.uk>

Try using str(the_name_of_your_object) and see if you get any clues as 
to where it is putting them. Sorry I cannot help further but I do not 
use meta myself.

On 04/05/2017 15:29, jan Pierre wrote:
> Hello,
>
> I?m trying to do a meta-analysis with R. I tried to use the function
> metabin from the package meta :
>
>
> data <- data.frame(matrix(rnorm(40,25), nrow=17, ncol=8))
> centres<-c("SVP","NANTES","STRASBOURG","GRENOBLE","ANGERS","TOULON","MARSEILLE","COLMAR","BORDEAUX","RENNES","VALENCE","CAEN","NANCY")
> rownames(data) = centres
> colnames(data) =
> c("case_exposed","witness_exposed","case_nonexposed","witness_nonexposed","exposed","nonexposed","case","witness")
> metabin( data$case_exposed, data$case, data$witness_exposed, data$witness,
> studlab=centres,
>            data=data, sm="OR")
>
> where data_meta is a data frame with the number of case_exposed, case_data,
> witness_exposed, witness for each centre.
>
> I obtain after using metabin :
>
> How can I extract the values of OR and 95%-CI in the fixed effect model and
> the random effects model? I want to put these data in another array.
>
> I tried to use summary, but it doesn?t change anything.
>
> Thanks for your help.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From Eric.Krantz at respec.com  Thu May  4 21:51:04 2017
From: Eric.Krantz at respec.com (Eric Krantz)
Date: Thu, 4 May 2017 19:51:04 +0000
Subject: [R] 3D equal-spaced closed mesh
Message-ID: <BY2PR02MB36277BB4E65DFDF99B12C818CEA0@BY2PR02MB362.namprd02.prod.outlook.com>

I have sonar image which is basically a point cloud (x, y, z) of an irregular underground cone-shaped structure. I am trying to create either (1) a closed 3D mesh with "equally spaced" mesh grid, or (2) a smooth closed surface, for instance by calculating connected localized regression surfaces. My Z (vertical) component is equally spaced, but X and Y consist of 128 points around the perimeter, regardless of diameter, which makes the grid size small where the diameter is small, and large where it is large. I'm looking for relatively equal grids, so I could use regression or interpolation to add points where needed, or conversely remove them, hence the idea of a localized surface regression. I've tried plot3D package, RGL, and a couple other packages including alphashape3d. I have not tried plotly or rms. So much time invested I thought I would ask for advice, if anyone knows a package or technique or can clue which direction to go. Thanks,
Confidentiality Notice: This E-mail and any attachments ...{{dropped:12}}


From bgunter.4567 at gmail.com  Fri May  5 00:34:09 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 4 May 2017 15:34:09 -0700
Subject: [R] 3D equal-spaced closed mesh
In-Reply-To: <BY2PR02MB36277BB4E65DFDF99B12C818CEA0@BY2PR02MB362.namprd02.prod.outlook.com>
References: <BY2PR02MB36277BB4E65DFDF99B12C818CEA0@BY2PR02MB362.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbR+jogbwPeADG3+B1+=XvtgheuWWF+=GSWOWy5AAp+KcA@mail.gmail.com>

The r-sig-geo list and corresponding cran task view *might* be a better
place to post and/look.

Bert


On May 4, 2017 12:51 PM, "Eric Krantz" <Eric.Krantz at respec.com> wrote:

> I have sonar image which is basically a point cloud (x, y, z) of an
> irregular underground cone-shaped structure. I am trying to create either
> (1) a closed 3D mesh with "equally spaced" mesh grid, or (2) a smooth
> closed surface, for instance by calculating connected localized regression
> surfaces. My Z (vertical) component is equally spaced, but X and Y consist
> of 128 points around the perimeter, regardless of diameter, which makes the
> grid size small where the diameter is small, and large where it is large.
> I'm looking for relatively equal grids, so I could use regression or
> interpolation to add points where needed, or conversely remove them, hence
> the idea of a localized surface regression. I've tried plot3D package, RGL,
> and a couple other packages including alphashape3d. I have not tried plotly
> or rms. So much time invested I thought I would ask for advice, if anyone
> knows a package or technique or can clue which direction to go. Thanks,
> Confidentiality Notice: This E-mail and any attachments ...{{dropped:12}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dhultstrand at appliedweatherassociates.com  Thu May  4 21:40:21 2017
From: dhultstrand at appliedweatherassociates.com (Douglas Hultstrand)
Date: Thu, 4 May 2017 13:40:21 -0600
Subject: [R] lmomRFA: update "regfit" object
Message-ID: <0b7a6623-6258-cff2-88fb-a8c2e7c46362@appliedweatherassociates.com>

Hello,

I am creating error bounds based on simulated data across multiple data 
durations.  I was wondering if there is a way to update an object class 
from "regfit" from lmomRFA package?  The reason is for consistency 
across durations.

Example below:

library(lmom); library(lmomRFA)

data <- c(0.42, 0.13, 0.59, 0.12, 0.78, 0.17, 0.3, 0.41, 0.28, 0.79)    
# random data

reg <- regsamlmu(data)    # calc l-moments

*org_gev <- regfit(reg,"gev")*    # original gev fit

# UPDATE *"org_gev*" values (below) and save as "update_gev"

# xi = 0.65

# alpha = 0. 51

# k = -0.023


Thank you for the help,
Doug




-- 
-----------------------------------------
Douglas M. Hultstrand, MS
Senior Hydrometeorologist
Applied Weather Associates
Monument, Colorado
mobile: 720-771-5840
www.appliedweatherassociates.com
dhultstrand at appliedweatherassociates.com
-----------------------------------------


	[[alternative HTML version deleted]]


From DomBulk at outlook.com  Thu May  4 22:08:56 2017
From: DomBulk at outlook.com (Dominik Szewczyk)
Date: Thu, 4 May 2017 20:08:56 +0000
Subject: [R] I cannot run R.EXE or RSCRIPT.EXE
Message-ID: <DM5PR17MB1098E7CE828DE7DE7271E695B6EA0@DM5PR17MB1098.namprd17.prod.outlook.com>

I cannot run R.EXE or RSCRIPT.EXE. It produces this error:


'C:\Program' is not recognized as an internal or external command,
operable program or batch file.


I have attempted to put quotes around the full path including the executable and also running the exectuable from within the path itself with the same result. The only way I can do this is to move the installation from C:\Program Files\R\R-3.4.0 to C:\R\..


Is this a limitation of the program itself?


-Dom

	[[alternative HTML version deleted]]


From DomBulk at outlook.com  Thu May  4 22:08:56 2017
From: DomBulk at outlook.com (Dominik Szewczyk)
Date: Thu, 4 May 2017 20:08:56 +0000
Subject: [R] I cannot run R.EXE or RSCRIPT.EXE
Message-ID: <DM5PR17MB1098E7CE828DE7DE7271E695B6EA0@DM5PR17MB1098.namprd17.prod.outlook.com>

I cannot run R.EXE or RSCRIPT.EXE. It produces this error:


'C:\Program' is not recognized as an internal or external command,
operable program or batch file.


I have attempted to put quotes around the full path including the executable and also running the exectuable from within the path itself with the same result. The only way I can do this is to move the installation from C:\Program Files\R\R-3.4.0 to C:\R\..


Is this a limitation of the program itself?


-Dom

	[[alternative HTML version deleted]]


From shadomyzd at appstate.edu  Fri May  5 00:58:15 2017
From: shadomyzd at appstate.edu (Zachary Shadomy)
Date: Thu, 4 May 2017 18:58:15 -0400
Subject: [R] Non-Linear Regression Help
Message-ID: <CANQ4g2Ur9UAHaDVJ_NcoqVvHk4RC68wVQA52=Tp_TJ71dhPa=A@mail.gmail.com>

I am having some errors come up in my first section of code. I have no
issue in plotting the points. Is there an easier method for creating a
non-linear regression using C*(x+a)^n. The .txt file is named
stage_discharge with the two variables being stage and discharge.
The data is a relatively small file listed below:

stage discharge
6.53 2592.05
6.32 559.5782
5.96 484.2151
4.99 494.7527
3.66 456.0778
0.51 291.13





> power.nls<-nls(stage_dischargee$discharge~C*(stage_discharge$stage+a)^n,
data=stage_discharge, start=list(C=4, a=0, n=1))
> C<-coef(power.nls)["C"]
> a<-coef(power.nls)["a"]
> n<-coef(power.nls)["n"]
> plot(stage_discharge$stage, stage_discharge$discharge, pch=17, cex=1.25,
ylab='Discharge (cfs )', xlab='Stage (ft)', font.lab=2, main='Boone Creek\n
St age-Discharge Curve')
> curve(C*(x+a)^n, add=TRUE, col="red")

	[[alternative HTML version deleted]]


From wangfm at scbg.ac.cn  Fri May  5 04:59:40 2017
From: wangfm at scbg.ac.cn (Faming Wang)
Date: Fri, 05 May 2017 02:59:40 +0000
Subject: [R] How to run Linear mixed model for an experiment design with
 species nested in an random block experiment
Message-ID: <CAHtaSOUci+EqJ2Gg+-Tvj8yLMFSEMiri-4SpDOz1eVKRpzXxLg@mail.gmail.com>

Dear all,

   I  have conducted an N and P field addition experiment in a tropical
forest, and we used a random block design in this experiment, briefly, we
had four plots in each block (Control, +N? +P, and +NP), and five blocks
located in the forest randomly. Totally we have 20 plots, with four
treatments and five replicated blocks. In each plot, we selected five
species  plants (some plots only contains 3 or 4 species) to measure their
leave variables, like N concentration.  We want to know the effect of N and
P addition as well as the species level variability (inter-species )  of
leaf N.  So we used linear mixed effect models to conduct our statistical
analysis, the sample code was listed below. Can anybody take a look at this
script, and help me to figure out how to analysis species effect using LME?

 Thanks!


R script attached

####leaf N concentration

### FIRST, WE TEST WHETHER NESTING SPECIES AS A RANDOM EFFECT IMPROVES
THE FULL MODEL

lmeleafN1<-lme(fixed=N~Naddition*Paddition*Species, random = ~1|Block,
data = NPdata, method = "ML", na.action=na.exclude)
lmeleafN1a<-lme(fixed=N~Naddition*Paddition*Species, random =
~1|Block/Species, data = NPdata, method = "ML", na.action=na.exclude)
anova(lmeleafN1, lmeleafN1a )

### NESTING SPECIES WITHIN BLOCK DOESN'T IMPROVE THE MODEL, SO WE CAN
USE THE MODEL WITH THE SIMPLER RANDOM EFFECT

lmeleafN2<-lme(fixed=N~Naddition*Paddition+Species, random = ~1|Block,
data = NPdata, method = "ML", na.action=na.exclude)
lmeleafN3<-lme(fixed=N~Naddition+Paddition*Species, random = ~1|Block,
data =NPdata, method = "ML", na.action=na.exclude)
lmeleafN4<-lme(fixed=N~Naddition+Paddition+Species, random = ~1|Block,
data = NPdata, method = "ML", na.action=na.exclude)

AIC(lmeleafN1, lmeleafN2, lmeleafN3, lmeleafN4)

# THE FULL MODEL CLEARLY HAS THE LOWEST AIC
# CHECK AGAINST THE NULL MODEL
lmeleafN0<-lme(fixed=N~1, random = ~1|Block, data = NPdata, method =
"ML", na.action=na.exclude)

anova(lmeleafN1, lmeleafN0)

## AND CHECK THE MODEL FIT WITH DIAGNOSTIC PLOTS

par(mfrow = c(2,2))
plot(resid(lmeleafN1)  ~ fitted(lmeleafN1))
abline(h=0, lty=2)
hist(resid(lmeleafN1))
qqnorm(resid(lmeleafN1))
qqline(resid(lmeleafN1))
anova(lmeleafN1)



-- 




Sincerely

Faming Wang

Associate Scientist
Deputy Director of Xiaoliang Research Station,
South China Botanical Garden, Chinese Academy of Sciences
Xingke Road 723, Guangzhou, China. 519650
Email: wangfm at scbg.ac.cn
Tel/Fax:0086-20-37252905

	[[alternative HTML version deleted]]


From yarmi1224 at hotmail.com  Fri May  5 07:58:14 2017
From: yarmi1224 at hotmail.com (=?gb2312?B?psggo6I=?=)
Date: Fri, 5 May 2017 05:58:14 +0000
Subject: [R] How do I use R to build a dictionary of proper nouns?
Message-ID: <SIXPR03MB0893C2F8CC312827E4FAB52DA4EB0@SIXPR03MB0893.apcprd03.prod.outlook.com>

?? ?? ???c?????? OneDrive ?n?????????z???n???????????????B?Y??


<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
[https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>

2.corpus_patent text.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>

<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
[https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>

3ontology_proper nouns keywords.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>

<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
[https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>

1.patents.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>




Hi :

I want to do patents text mining in R.
I need to use the proper nouns of domain ontology to build a dictionary.
Then use the dictionary to analysis my corpus of patent files.
I want to calculate the proper nouns and get the word frequency that appears in each file.

Now I have done the preprocess for the corpus and extract the proper nouns from domain ontology.
But I have no idea how to build a proper nouns dictionary and use the dictionary to analysis my corpus.

The Attachments are my texts, corpus preprocesses and proper nouns.

Thanks.

	[[alternative HTML version deleted]]


From r_goertz at web.de  Fri May  5 10:33:27 2017
From: r_goertz at web.de (Ralf Goertz)
Date: Fri, 5 May 2017 10:33:27 +0200
Subject: [R] loading edited functions already in saved workspace
	automatically
Message-ID: <20170505103327.2c67f0b9@delli.home.local>

Hi,

In short: Is it possible to have the previously saved workspace restored
and nevertheless load a function already existing in this workspace via
.Rprofile anyway?

In detail: I use different directories for different projects. In all
those projects I use a function which I therefore try to get into the
session by `myfunc=eval(parse(file=("~/R/myfunc.R")))' in ~/.Rprofile.
Once I leave the session thereby saving the workspace this function gets
saved in ./.RData as well. In a subsequent session in that directory it
gets loaded back. However, in the meantime I might have edited
~/R/myfunc.R. I don't seem to be able to automatically load the new
function into the session. The workspace gets loaded *after* the
execution of ~/.Rprofile. So the new definition of myfunc() gets
overwritten by the old one. I can't use .First() ? which is executed
after loading the workspace ? because this would load myfunc() into the
environment of .First() instead of the global environment. I could use
.Last() to remove the function before saving the workspace. But then
.Last() gets saved to the workspace which is also not convenient since
when I add another function the same way and edit the definition of
.Last() in ~/.Rprofile to also remove that function this does not work
because I don't get the new .Last() into the session automatically. And
no, removing .Last() from within .Last() doesn't work.


From boris.steipe at utoronto.ca  Fri May  5 10:39:25 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 5 May 2017 04:39:25 -0400
Subject: [R] How do I use R to build a dictionary of proper nouns?
In-Reply-To: <SIXPR03MB0893C2F8CC312827E4FAB52DA4EB0@SIXPR03MB0893.apcprd03.prod.outlook.com>
References: <SIXPR03MB0893C2F8CC312827E4FAB52DA4EB0@SIXPR03MB0893.apcprd03.prod.outlook.com>
Message-ID: <D461C473-54B7-4067-98E4-6E18D6327677@utoronto.ca>

Did you try using the table() function, possibly in combination with sort() or rank()?


Consider:

myNouns <- c("proper", "nouns", "domain", "ontology", "dictionary",
             "dictionary", "corpus", "patent", "files", "proper", "nouns",
             "word", "frequency", "file", "preprocess", "corpus", "proper",
             "nouns", "domain", "ontology", "idea", "nouns", "dictionary",
             "dictionary", "corpus", "attachments", "texts", "corpus",
             "preprocesses", "proper", "nouns")

myNounFrequencies <- table(myNouns)
myNounFrequencies

myNounFrequencies <- sort(myNounFrequencies, decreasing = TRUE)
myNounFrequencies

which(names(myNounFrequencies) == "corpus")





> On May 5, 2017, at 1:58 AM, ? ? <yarmi1224 at hotmail.com> wrote:
> 
> ? ? ????? OneDrive ??????????????????
> 
> 
> <https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
> [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
> 
> 2.corpus_patent text.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
> 
> <https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
> [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
> 
> 3ontology_proper nouns keywords.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
> 
> <https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
> [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
> 
> 1.patents.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
> 
> 
> 
> 
> Hi :
> 
> I want to do patents text mining in R.
> I need to use the proper nouns of domain ontology to build a dictionary.
> Then use the dictionary to analysis my corpus of patent files.
> I want to calculate the proper nouns and get the word frequency that appears in each file.
> 
> Now I have done the preprocess for the corpus and extract the proper nouns from domain ontology.
> But I have no idea how to build a proper nouns dictionary and use the dictionary to analysis my corpus.
> 
> The Attachments are my texts, corpus preprocesses and proper nouns.
> 
> Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri May  5 11:38:03 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 5 May 2017 09:38:03 +0000
Subject: [R] Non-Linear Regression Help
In-Reply-To: <CANQ4g2Ur9UAHaDVJ_NcoqVvHk4RC68wVQA52=Tp_TJ71dhPa=A@mail.gmail.com>
References: <CANQ4g2Ur9UAHaDVJ_NcoqVvHk4RC68wVQA52=Tp_TJ71dhPa=A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FF999C6C@SRVEXCHCM301.precheza.cz>

Hi

I am not an expert in nonlinear regression, but your data seems to be rather weird. Last five points has almost linear relationship, the first one is several times higher. If there is no error in your data, I doubt that you can model it by power equation.

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Zachary
> Shadomy
> Sent: Friday, May 5, 2017 12:58 AM
> To: r-help at r-project.org
> Subject: [R] Non-Linear Regression Help
>
> I am having some errors come up in my first section of code. I have no
> issue in plotting the points. Is there an easier method for creating a
> non-linear regression using C*(x+a)^n. The .txt file is named
> stage_discharge with the two variables being stage and discharge.
> The data is a relatively small file listed below:
>
> stage discharge
> 6.53 2592.05
> 6.32 559.5782
> 5.96 484.2151
> 4.99 494.7527
> 3.66 456.0778
> 0.51 291.13
>
>
>
>
>
> > power.nls<-
> nls(stage_dischargee$discharge~C*(stage_discharge$stage+a)^n,
> data=stage_discharge, start=list(C=4, a=0, n=1))
> > C<-coef(power.nls)["C"]
> > a<-coef(power.nls)["a"]
> > n<-coef(power.nls)["n"]
> > plot(stage_discharge$stage, stage_discharge$discharge, pch=17, cex=1.25,
> ylab='Discharge (cfs )', xlab='Stage (ft)', font.lab=2, main='Boone Creek\n
> St age-Discharge Curve')
> > curve(C*(x+a)^n, add=TRUE, col="red")
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Fri May  5 12:01:19 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 5 May 2017 06:01:19 -0400
Subject: [R] I cannot run R.EXE or RSCRIPT.EXE
In-Reply-To: <DM5PR17MB1098E7CE828DE7DE7271E695B6EA0@DM5PR17MB1098.namprd17.prod.outlook.com>
References: <DM5PR17MB1098E7CE828DE7DE7271E695B6EA0@DM5PR17MB1098.namprd17.prod.outlook.com>
Message-ID: <a6982fd2-936c-adab-c0c6-b32a8c34ae89@gmail.com>

On 04/05/2017 4:08 PM, Dominik Szewczyk wrote:
> I cannot run R.EXE or RSCRIPT.EXE. It produces this error:
>
>
> 'C:\Program' is not recognized as an internal or external command,
> operable program or batch file.
>
>
> I have attempted to put quotes around the full path including the executable and also running the exectuable from within the path itself with the same result. The only way I can do this is to move the installation from C:\Program Files\R\R-3.4.0 to C:\R\..
>
>
> Is this a limitation of the program itself?

It sounds like a limitation of the way you're trying to run them, which 
you haven't told us.

Duncan Murdoch


From lists at dewey.myzen.co.uk  Fri May  5 12:46:30 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 5 May 2017 11:46:30 +0100
Subject: [R] I cannot run R.EXE or RSCRIPT.EXE
In-Reply-To: <a6982fd2-936c-adab-c0c6-b32a8c34ae89@gmail.com>
References: <DM5PR17MB1098E7CE828DE7DE7271E695B6EA0@DM5PR17MB1098.namprd17.prod.outlook.com>
 <a6982fd2-936c-adab-c0c6-b32a8c34ae89@gmail.com>
Message-ID: <44b868ff-863d-4cef-5d65-58098a94d9d1@dewey.myzen.co.uk>

Dear Dominik

Try this
Open a command window
Type PATH
Does the path to where R has stored its executables appear on the PATH?

Either way get back to us with more details.

On 05/05/2017 11:01, Duncan Murdoch wrote:
> On 04/05/2017 4:08 PM, Dominik Szewczyk wrote:
>> I cannot run R.EXE or RSCRIPT.EXE. It produces this error:
>>
>>
>> 'C:\Program' is not recognized as an internal or external command,
>> operable program or batch file.
>>
>>
>> I have attempted to put quotes around the full path including the
>> executable and also running the exectuable from within the path itself
>> with the same result. The only way I can do this is to move the
>> installation from C:\Program Files\R\R-3.4.0 to C:\R\..
>>
>>
>> Is this a limitation of the program itself?
>
> It sounds like a limitation of the way you're trying to run them, which
> you haven't told us.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From br at dmstat1.com  Fri May  5 14:08:19 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 5 May 2017 08:08:19 -0400
Subject: [R] Formatting column displays
Message-ID: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>

R-helpers:
I need some references for formatting the display of my data frame columns. 
Any guidance will be appreciated. Bruce
~~
I have a date frame with one column as an integer for which I want a comma display, 
one column consisting of dollar amounts, one column for which I want a display to two digits after the decimal point, and one column as integers ranging between 
100 - 999.


From ulrik.stervbo at gmail.com  Fri May  5 14:56:35 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 05 May 2017 12:56:35 +0000
Subject: [R] Formatting column displays
In-Reply-To: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
Message-ID: <CAKVAULPFEYhkh9RSjx2tWcv-y7bEsBxse6=HH2aKsbd5vCHfCw@mail.gmail.com>

Hi Bruce,

display as in the console or as a table for presentation?

For the latter, look at sprintf:

sprintf("%,1f", 1)
sprintf("%.2f", 2.5678)
sprintf("$%.3f", 2.5678)

HTH
Ulrik

On Fri, 5 May 2017 at 14:08 Bruce Ratner PhD <br at dmstat1.com> wrote:

> R-helpers:
> I need some references for formatting the display of my data frame columns.
> Any guidance will be appreciated. Bruce
> ~~
> I have a date frame with one column as an integer for which I want a comma
> display,
> one column consisting of dollar amounts, one column for which I want a
> display to two digits after the decimal point, and one column as integers
> ranging between
> 100 - 999.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri May  5 15:15:29 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 05 May 2017 06:15:29 -0700
Subject: [R] Formatting column displays
In-Reply-To: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
Message-ID: <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>

Data frames are primarily data storage objects, not data display objects. You can create a separate version of your data frame with formatted text strings, but what you usually really want is to handle column alignment as well and that really has to be addressed as part of your data output process, which you have said nothing about. 

Do you know about HTML or markdown or LaTeX? These are useful formats for creating reproducible research, and they are well supported through the knitr package and in RStudio via Rnw and Rmd files. Tables in particular are well supported via LaTeX with the tables package.  The ReporteR package can output to Microsoft Word files directly with various formatting options, but it doesn't play well with the other tools.
-- 
Sent from my phone. Please excuse my brevity.

On May 5, 2017 5:08:19 AM PDT, Bruce Ratner PhD <br at dmstat1.com> wrote:
>R-helpers:
>I need some references for formatting the display of my data frame
>columns. 
>Any guidance will be appreciated. Bruce
>~~
>I have a date frame with one column as an integer for which I want a
>comma display, 
>one column consisting of dollar amounts, one column for which I want a
>display to two digits after the decimal point, and one column as
>integers ranging between 
>100 - 999.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Fri May  5 15:25:04 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 5 May 2017 09:25:04 -0400
Subject: [R] Formatting column displays
In-Reply-To: <CAKVAULPFEYhkh9RSjx2tWcv-y7bEsBxse6=HH2aKsbd5vCHfCw@mail.gmail.com>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
 <CAKVAULPFEYhkh9RSjx2tWcv-y7bEsBxse6=HH2aKsbd5vCHfCw@mail.gmail.com>
Message-ID: <6B997349-11B8-4CE5-A442-ABD2DAECC6A3@dmstat1.com>

Ulrik: Thanks for reply. I obviously new to R, so I feel if the output on the console looks right I'm half way through my problem. I know it's not WYSIWYG, but it's a quasi start. 
Thanks. 
Bruce

______________



> On May 5, 2017, at 8:56 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> Hi Bruce,
> 
> display as in the console or as a table for presentation?
> 
> For the latter, look at sprintf:
> 
> sprintf("%,1f", 1)
> sprintf("%.2f", 2.5678)
> sprintf("$%.3f", 2.5678)
> 
> HTH
> Ulrik
> 
>> On Fri, 5 May 2017 at 14:08 Bruce Ratner PhD <br at dmstat1.com> wrote:
>> R-helpers:
>> I need some references for formatting the display of my data frame columns.
>> Any guidance will be appreciated. Bruce
>> ~~
>> I have a date frame with one column as an integer for which I want a comma display,
>> one column consisting of dollar amounts, one column for which I want a display to two digits after the decimal point, and one column as integers ranging between
>> 100 - 999.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From br at dmstat1.com  Fri May  5 15:26:06 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 5 May 2017 09:26:06 -0400
Subject: [R] Formatting column displays
In-Reply-To: <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
 <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>
Message-ID: <7B0606B7-C5B7-43D1-93FB-2458E66CFA2E@dmstat1.com>

Jeff: Thanks for reply. I will follow your lead. 
Thanks. 
Bruce

______________



> On May 5, 2017, at 9:15 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Data frames are primarily data storage objects, not data display objects. You can create a separate version of your data frame with formatted text strings, but what you usually really want is to handle column alignment as well and that really has to be addressed as part of your data output process, which you have said nothing about. 
> 
> Do you know about HTML or markdown or LaTeX? These are useful formats for creating reproducible research, and they are well supported through the knitr package and in RStudio via Rnw and Rmd files. Tables in particular are well supported via LaTeX with the tables package.  The ReporteR package can output to Microsoft Word files directly with various formatting options, but it doesn't play well with the other tools.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
>> On May 5, 2017 5:08:19 AM PDT, Bruce Ratner PhD <br at dmstat1.com> wrote:
>> R-helpers:
>> I need some references for formatting the display of my data frame
>> columns. 
>> Any guidance will be appreciated. Bruce
>> ~~
>> I have a date frame with one column as an integer for which I want a
>> comma display, 
>> one column consisting of dollar amounts, one column for which I want a
>> display to two digits after the decimal point, and one column as
>> integers ranging between 
>> 100 - 999.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From jdnewmil at dcn.davis.ca.us  Fri May  5 15:30:01 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 05 May 2017 06:30:01 -0700
Subject: [R] loading edited functions already in saved
	workspace	automatically
In-Reply-To: <20170505103327.2c67f0b9@delli.home.local>
References: <20170505103327.2c67f0b9@delli.home.local>
Message-ID: <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>

The answer most people seem to use is to avoid depending on functions in RData files, and in particular avoiding ever saving the "automatic" ".RData" files at all. (Some people avoid using any RData files, but the automatic loading of functions by ".RData" files is a particularly pernicious source of evil as you have already discovered.)

That is,  always work toward building scripts that you run to restore your workspace rather than depending on save files. Don't depend on save files to keep track of what you do interactively. This also usually means that there should be little if anything in your .Rprofile because that tends to build non-reproducibility into your scripts.
-- 
Sent from my phone. Please excuse my brevity.

On May 5, 2017 1:33:27 AM PDT, Ralf Goertz <r_goertz at web.de> wrote:
>Hi,
>
>In short: Is it possible to have the previously saved workspace
>restored
>and nevertheless load a function already existing in this workspace via
>.Rprofile anyway?
>
>In detail: I use different directories for different projects. In all
>those projects I use a function which I therefore try to get into the
>session by `myfunc=eval(parse(file=("~/R/myfunc.R")))' in ~/.Rprofile.
>Once I leave the session thereby saving the workspace this function
>gets
>saved in ./.RData as well. In a subsequent session in that directory it
>gets loaded back. However, in the meantime I might have edited
>~/R/myfunc.R. I don't seem to be able to automatically load the new
>function into the session. The workspace gets loaded *after* the
>execution of ~/.Rprofile. So the new definition of myfunc() gets
>overwritten by the old one. I can't use .First() ? which is executed
>after loading the workspace ? because this would load myfunc() into the
>environment of .First() instead of the global environment. I could use
>.Last() to remove the function before saving the workspace. But then
>.Last() gets saved to the workspace which is also not convenient since
>when I add another function the same way and edit the definition of
>.Last() in ~/.Rprofile to also remove that function this does not work
>because I don't get the new .Last() into the session automatically. And
>no, removing .Last() from within .Last() doesn't work.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r_goertz at web.de  Fri May  5 15:44:50 2017
From: r_goertz at web.de (Ralf Goertz)
Date: Fri, 5 May 2017 15:44:50 +0200
Subject: [R] loading edited functions already in saved workspace
 automatically
In-Reply-To: <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
Message-ID: <20170505154450.448392bc@delli.home.local>

Am Fri, 05 May 2017 06:30:01 -0700
schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> The answer most people seem to use is to avoid depending on functions
> in RData files, and in particular avoiding ever saving the
> "automatic" ".RData" files at all. (Some people avoid using any RData
> files, but the automatic loading of functions by ".RData" files is a
> particularly pernicious source of evil as you have already
> discovered.)
> 
> That is,  always work toward building scripts that you run to restore
> your workspace rather than depending on save files. Don't depend on
> save files to keep track of what you do interactively. This also
> usually means that there should be little if anything in
> your .Rprofile because that tends to build non-reproducibility into
> your scripts.

Hi Jeff,

thanks for your answer. Actually, I don't use the workspace saving
feature primarily for the data but for the command line history. Is
there a way to just save .Rhistory?

Ralf


From profjcnash at gmail.com  Fri May  5 15:59:20 2017
From: profjcnash at gmail.com (J C Nash)
Date: Fri, 5 May 2017 09:59:20 -0400
Subject: [R] Non-Linear Regression Help
In-Reply-To: <CANQ4g2Ur9UAHaDVJ_NcoqVvHk4RC68wVQA52=Tp_TJ71dhPa=A@mail.gmail.com>
References: <CANQ4g2Ur9UAHaDVJ_NcoqVvHk4RC68wVQA52=Tp_TJ71dhPa=A@mail.gmail.com>
Message-ID: <33c08f8d-7df0-49ae-2edb-fb050a8ad5d6@gmail.com>

If you insist on using nls() for anything that you don't understand
extremely well, you will end up with frustration. nls() uses the same
method K F Gauss used (with good understanding of the details) over
200 years ago. The Gauss-Newton approach inside works very well and
efficiently for problems where the assumptions are met, and terribly
most other times. But nls() does have some nice "extras", and rather
than rewrite all the code, we have a wrapnls() function for the codes
in the much more modern nlsr package. It tries (and mostly succeeds) in
getting analytic derivatives in cases like this. Note that nls(), when
you output the diagnostic, tells you that it is having trouble with
the numeric derivative.

I did the following:

1) made a csv file from the data in the posting (Shadomy17.csv)

2) edited the nls() call and added trace and try()

3) ran nlxb() from nlsr. Note that it uses a lot of iterations -- the
problem is quite close to singular. The singular values have NOTHING
to do with the individual parameters. Their display position is just
convenient. Together they show that the ratio of largest / smallest sv
(a measure of the condition number) is very large -- an ill-conditioned
problem. Now we know this -- there's no guessing and hand-waving.

Best, JN

Here's the (rather verbose) output


 > library(nlsr)

 > shadomy <- read.csv("./Shadomy17.csv")

 > power.nls<-try(nls(discharge~C*(stage+a)^n, data=shadomy, start=list(C=4, a=0, n=1), trace=TRUE))
7585285 :  4 0 1

 > print(power.nls)
[1] "Error in numericDeriv(form[[3L]], names(ind), env) : \n  Missing value or an infinity produced when evaluating the 
model\n"
attr(,"class")
[1] "try-error"
attr(,"condition")
<simpleError in numericDeriv(form[[3L]], names(ind), env): Missing value or an infinity produced when evaluating the model>

 > tmp <- readline("Try a better approach")

 > p.nlxb <- nlxb(discharge~C*(stage+a)^n, data=shadomy, start=list(C=4, a=0, n=1), trace=TRUE)
formula: discharge ~ C * (stage + a)^n
lower:[1] -Inf -Inf -Inf
upper:[1] Inf Inf Inf
$watch
[1] FALSE

$phi
[1] 1

$lamda
[1] 1e-04

$offset
[1] 100

$laminc
[1] 10

$lamdec
[1] 4

$femax
[1] 10000

$jemax
[1] 5000

$rofftest
[1] TRUE

$smallsstest
[1] TRUE

vn:[1] "discharge" "C"         "stage"     "a"         "n"
Finished masks check
datvar:[1] "discharge" "stage"
Data variable  discharge :[1] 2592.05  559.58  484.22  494.75  456.08  291.13
Data variable  stage :[1] 6.53 6.32 5.96 4.99 3.66 0.51
trjfn:
function (prm)
{
     if (is.null(names(prm)))
         names(prm) <- names(pvec)
     localdata <- list2env(as.list(prm), parent = data)
     eval(residexpr, envir = localdata)
}
<bytecode: 0x3263280>
<environment: 0x3021208>
no weights
lower:[1] -Inf -Inf -Inf
upper:[1] Inf Inf Inf
Start:lamda: 1e-04  SS= 7585285  at  C = 4  a = 0  n = 1  1 / 0
lamda: 0.001  SS= Inf  at  C = -843.56  a = 228.63  n = 123.33  2 / 1
lamda: 0.01  SS= Inf  at  C = -515.08  a = 148.03  n = 84.714  3 / 1
lamda: 0.1  SS= 9.0129e+100  at  C = -50.129  a = 37.016  n = 29.648  4 / 1
lamda: 1  SS= 8.5013e+47  at  C = 58.103  a = 30.986  n = 13.954  5 / 1
lamda: 10  SS= 4.2141e+31  at  C = 49.209  a = 45.025  n = 8.0734  6 / 1
lamda: 100  SS= 9.4088e+10  at  C = 17.369  a = 15.101  n = 2.9571  7 / 1
<<lamda: 40  SS= 7139465  at  C = 5.6661  a = 1.9085  n = 1.2421  8 / 1
<<lamda: 16  SS= 6321710  at  C = 7.4018  a = 3.5556  n = 1.3955  9 / 2
<<lamda: 6.4  SS= 5015080  at  C = 9.3512  a = 5.1077  n = 1.5166  10 / 3
<<lamda: 2.56  SS= 3724863  at  C = 11.195  a = 6.3333  n = 1.6023  11 / 4
<<lamda: 1.024  SS= 3144435  at  C = 12.47  a = 6.9964  n = 1.6516  12 / 5
<<lamda: 0.4096  SS= 3044065  at  C = 13.076  a = 7.0845  n = 1.6763  13 / 6
<<lamda: 0.16384  SS= 3016569  at  C = 13.402  a = 6.7057  n = 1.6978  14 / 7
<<lamda: 0.065536  SS= 2965611  at  C = 13.887  a = 5.7652  n = 1.739  15 / 8
<<lamda: 0.026214  SS= 2874080  at  C = 14.836  a = 4.0457  n = 1.8266  16 / 9
<<lamda: 0.010486  SS= 2769844  at  C = 16.1  a = 1.9237  n = 1.9871  17 / 10
<<lamda: 0.0041943  SS= 2639613  at  C = 15.821  a = 0.1568  n = 2.2672  18 / 11
lamda: 0.041943  SS= 1.7977e+308  at  C = 12.901  a = -1.5552  n = 2.7895  19 / 12
lamda: 0.41943  SS= 1.7977e+308  at  C = 16.976  a = -0.52795  n = 2.4402  20 / 12
<<lamda: 0.16777  SS= 2550653  at  C = 16.551  a = 0.15159  n = 2.3095  21 / 12
<<lamda: 0.067109  SS= 2524756  at  C = 16.778  a = -0.066675  n = 2.3521  22 / 13
lamda: 0.67109  SS= 1.7977e+308  at  C = 17.157  a = -0.52924  n = 2.4441  23 / 14
<<lamda: 0.26844  SS= 2517716  at  C = 16.855  a = -0.12164  n = 2.3641  24 / 14
<<lamda: 0.10737  SS= 2501124  at  C = 16.986  a = -0.2586  n = 2.3913  25 / 15
lamda: 1.0737  SS= 1.7977e+308  at  C = 17.264  a = -0.55996  n = 2.454  26 / 16
<<lamda: 0.4295  SS= 2496748  at  C = 17.03  a = -0.29226  n = 2.3988  27 / 16
<<lamda: 0.1718  SS= 2486194  at  C = 17.117  a = -0.37629  n = 2.4163  28 / 17
lamda: 1.718  SS= 1.7977e+308  at  C = 17.307  a = -0.56916  n = 2.4578  29 / 18
<<lamda: 0.68719  SS= 2483488  at  C = 17.143  a = -0.39692  n = 2.421  30 / 18
<<lamda: 0.27488  SS= 2476879  at  C = 17.199  a = -0.44853  n = 2.4322  31 / 19
lamda: 2.7488  SS= 1.7977e+308  at  C = 17.323  a = -0.57068  n = 2.459  32 / 20
<<lamda: 1.0995  SS= 2475207  at  C = 17.214  a = -0.46124  n = 2.4351  33 / 20
<<lamda: 0.4398  SS= 2471092  at  C = 17.249  a = -0.49305  n = 2.4422  34 / 21
lamda: 4.398  SS= 1.7977e+308  at  C = 17.329  a = -0.56992  n = 2.4593  35 / 22
<<lamda: 1.7592  SS= 2470058  at  C = 17.259  a = -0.5009  n = 2.444  36 / 22
lamda: 17.592  SS= 1.7977e+308  at  C = 17.28  a = -0.52057  n = 2.4484  37 / 23
<<lamda: 7.0369  SS= 2469799  at  C = 17.261  a = -0.50286  n = 2.4444  38 / 23
<<lamda: 2.8147  SS= 2469154  at  C = 17.267  a = -0.50778  n = 2.4455  39 / 24
lamda: 28.147  SS= 1.7977e+308  at  C = 17.28  a = -0.52008  n = 2.4483  40 / 25
<<lamda: 11.259  SS= 2468993  at  C = 17.268  a = -0.50901  n = 2.4458  41 / 25
lamda: 112.59  SS= 1.7977e+308  at  C = 17.272  a = -0.51208  n = 2.4465  42 / 26
<<lamda: 45.036  SS= 2468952  at  C = 17.269  a = -0.50931  n = 2.4459  43 / 26
lamda: 450.36  SS= 1.7977e+308  at  C = 17.27  a = -0.51008  n = 2.4461  44 / 27
<<lamda: 180.14  SS= 2468942  at  C = 17.269  a = -0.50939  n = 2.4459  45 / 27
<<lamda: 72.058  SS= 2468917  at  C = 17.269  a = -0.50958  n = 2.446  46 / 28
lamda: 720.58  SS= 1.7977e+308  at  C = 17.27  a = -0.51006  n = 2.4461  47 / 29
<<lamda: 288.23  SS= 2468911  at  C = 17.269  a = -0.50963  n = 2.446  48 / 29
<<lamda: 115.29  SS= 2468895  at  C = 17.269  a = -0.50975  n = 2.446  49 / 30
lamda: 1152.9  SS= 1.7977e+308  at  C = 17.27  a = -0.51005  n = 2.4461  50 / 31
<<lamda: 461.17  SS= 2468891  at  C = 17.269  a = -0.50978  n = 2.446  51 / 31

 > print(p.nlxb)
nlsr object: x
residual sumsquares =  2468891  on  6 observations
     after  31    Jacobian and  51 function evaluations
   name            coeff          SE       tstat      pval      gradient    JSingval
C                17.2692          1404     0.0123      0.991      -733.5        4112
a              -0.509779         60.67  -0.008403     0.9938       35772       188.7
n                2.44601         31.75    0.07704     0.9434     -126335      0.6456

 > sink()





On 2017-05-04 06:58 PM, Zachary Shadomy wrote:
> I am having some errors come up in my first section of code. I have no
> issue in plotting the points. Is there an easier method for creating a
> non-linear regression using C*(x+a)^n. The .txt file is named
> stage_discharge with the two variables being stage and discharge.
> The data is a relatively small file listed below:
>
> stage discharge
> 6.53 2592.05
> 6.32 559.5782
> 5.96 484.2151
> 4.99 494.7527
> 3.66 456.0778
> 0.51 291.13
>
>
>
>
>
>> power.nls<-nls(stage_dischargee$discharge~C*(stage_discharge$stage+a)^n,
> data=stage_discharge, start=list(C=4, a=0, n=1))
>> C<-coef(power.nls)["C"]
>> a<-coef(power.nls)["a"]
>> n<-coef(power.nls)["n"]
>> plot(stage_discharge$stage, stage_discharge$discharge, pch=17, cex=1.25,
> ylab='Discharge (cfs )', xlab='Stage (ft)', font.lab=2, main='Boone Creek\n
> St age-Discharge Curve')
>> curve(C*(x+a)^n, add=TRUE, col="red")
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Fri May  5 16:14:36 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 05 May 2017 07:14:36 -0700
Subject: [R] loading edited functions already in saved workspace
	automatically
In-Reply-To: <20170505154450.448392bc@delli.home.local>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
Message-ID: <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>

R normally prompts you to save .RData, but it just automatically saves .Rhistory... the two are unrelated. 
-- 
Sent from my phone. Please excuse my brevity.

On May 5, 2017 6:44:50 AM PDT, Ralf Goertz <r_goertz at web.de> wrote:
>Am Fri, 05 May 2017 06:30:01 -0700
>schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> The answer most people seem to use is to avoid depending on functions
>> in RData files, and in particular avoiding ever saving the
>> "automatic" ".RData" files at all. (Some people avoid using any RData
>> files, but the automatic loading of functions by ".RData" files is a
>> particularly pernicious source of evil as you have already
>> discovered.)
>> 
>> That is,  always work toward building scripts that you run to restore
>> your workspace rather than depending on save files. Don't depend on
>> save files to keep track of what you do interactively. This also
>> usually means that there should be little if anything in
>> your .Rprofile because that tends to build non-reproducibility into
>> your scripts.
>
>Hi Jeff,
>
>thanks for your answer. Actually, I don't use the workspace saving
>feature primarily for the data but for the command line history. Is
>there a way to just save .Rhistory?
>
>Ralf


From r_goertz at web.de  Fri May  5 16:23:14 2017
From: r_goertz at web.de (Ralf Goertz)
Date: Fri, 5 May 2017 16:23:14 +0200
Subject: [R] loading edited functions already in saved workspace
 automatically
In-Reply-To: <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>
Message-ID: <20170505162314.1e6a1020@delli.home.local>

Am Fri, 05 May 2017 07:14:36 -0700
schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> R normally prompts you to save .RData, but it just automatically
> saves .Rhistory... the two are unrelated. 

Not here. If I say "n" to the prompted question "Save workspace image?
[y/n/c]: " my history doesn't get saved.

Version:

R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-suse-linux-gnu (64-bit)


From jdnewmil at dcn.davis.ca.us  Fri May  5 16:36:11 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 05 May 2017 07:36:11 -0700
Subject: [R] loading edited functions already in saved workspace
	automatically
In-Reply-To: <20170505162314.1e6a1020@delli.home.local>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>
 <20170505162314.1e6a1020@delli.home.local>
Message-ID: <6CD24867-769F-48C0-B788-F9B37A83F5F6@dcn.davis.ca.us>

Read ?history.

Seems somewhat platform dependent, but they ARE different. 
-- 
Sent from my phone. Please excuse my brevity.

On May 5, 2017 7:23:14 AM PDT, Ralf Goertz <r_goertz at web.de> wrote:
>Am Fri, 05 May 2017 07:14:36 -0700
>schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> R normally prompts you to save .RData, but it just automatically
>> saves .Rhistory... the two are unrelated. 
>
>Not here. If I say "n" to the prompted question "Save workspace image?
>[y/n/c]: " my history doesn't get saved.
>
>Version:
>
>R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>Copyright (C) 2016 The R Foundation for Statistical Computing
>Platform: x86_64-suse-linux-gnu (64-bit)


From rmh at temple.edu  Fri May  5 16:46:08 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 05 May 2017 14:46:08 +0000
Subject: [R] I cannot run R.EXE or RSCRIPT.EXE
In-Reply-To: <44b868ff-863d-4cef-5d65-58098a94d9d1@dewey.myzen.co.uk>
References: <DM5PR17MB1098E7CE828DE7DE7271E695B6EA0@DM5PR17MB1098.namprd17.prod.outlook.com>
 <a6982fd2-936c-adab-c0c6-b32a8c34ae89@gmail.com>
 <44b868ff-863d-4cef-5d65-58098a94d9d1@dewey.myzen.co.uk>
Message-ID: <CAGx1TMDgu-T9FU_RZKHosujDmQfm8OMkJ18x=Mu9tAQfLKbJjA@mail.gmail.com>

Try the 8.3 version of the path name.

   dir /w

if I remember correctly.
"Program files" will become progra~1


On Fri, May 5, 2017 at 06:46 Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Dear Dominik
>
> Try this
> Open a command window
> Type PATH
> Does the path to where R has stored its executables appear on the PATH?
>
> Either way get back to us with more details.
>
> On 05/05/2017 11:01, Duncan Murdoch wrote:
> > On 04/05/2017 4:08 PM, Dominik Szewczyk wrote:
> >> I cannot run R.EXE or RSCRIPT.EXE. It produces this error:
> >>
> >>
> >> 'C:\Program' is not recognized as an internal or external command,
> >> operable program or batch file.
> >>
> >>
> >> I have attempted to put quotes around the full path including the
> >> executable and also running the exectuable from within the path itself
> >> with the same result. The only way I can do this is to move the
> >> installation from C:\Program Files\R\R-3.4.0 to C:\R\..
> >>
> >>
> >> Is this a limitation of the program itself?
> >
> > It sounds like a limitation of the way you're trying to run them, which
> > you haven't told us.
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ---
> > This email has been checked for viruses by AVG.
> > http://www.avg.com
> >
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri May  5 16:48:57 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 5 May 2017 15:48:57 +0100
Subject: [R] loading edited functions already in saved workspace
 automatically
In-Reply-To: <20170505154450.448392bc@delli.home.local>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
Message-ID: <ea625bf1-c387-82f1-7694-db33fe397d89@dewey.myzen.co.uk>

Dear Ralf

You can manually save it with
savehistory(insertyour preferred filenamehere.r)

or does that not do what you hoped?

On 05/05/2017 14:44, Ralf Goertz wrote:
> Am Fri, 05 May 2017 06:30:01 -0700
> schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> The answer most people seem to use is to avoid depending on functions
>> in RData files, and in particular avoiding ever saving the
>> "automatic" ".RData" files at all. (Some people avoid using any RData
>> files, but the automatic loading of functions by ".RData" files is a
>> particularly pernicious source of evil as you have already
>> discovered.)
>>
>> That is,  always work toward building scripts that you run to restore
>> your workspace rather than depending on save files. Don't depend on
>> save files to keep track of what you do interactively. This also
>> usually means that there should be little if anything in
>> your .Rprofile because that tends to build non-reproducibility into
>> your scripts.
>
> Hi Jeff,
>
> thanks for your answer. Actually, I don't use the workspace saving
> feature primarily for the data but for the command line history. Is
> there a way to just save .Rhistory?
>
> Ralf
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ulrik.stervbo at gmail.com  Fri May  5 16:55:15 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 05 May 2017 14:55:15 +0000
Subject: [R] Formatting column displays
In-Reply-To: <7B0606B7-C5B7-43D1-93FB-2458E66CFA2E@dmstat1.com>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
 <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>
 <7B0606B7-C5B7-43D1-93FB-2458E66CFA2E@dmstat1.com>
Message-ID: <CAKVAULNmC_9Cb=Rj0AOLq4tDBT6k32KA-YVOB6dY_6VgPaw-_Q@mail.gmail.com>

Hi Bruce,

while working with data I would not touch the formatting of the columns. If
knowing the units is important, you can add it to the column name rather
than the values of the columns.

For presentation purposes - where everything is turned into strings - it is
a different story. Once you are done with your calculations, you can format
everything the way you like it. I find kable() from the knitr package to
help a lot with basic formatting, though you might have to do a little
pre-processing by hand (and here sprintf comes in handy).

And to echo Jeff: you should use Rmarkdown if you are writing up reports
and it is well integrated with Rstudio. knitr works behind the scenes, and
I believe it can even create a Microsoft Word document though pandoc,
without the need for ReporteR (but I have never tried, so I might be wrong).

Best,
Ulrik

On Fri, 5 May 2017 at 15:26 Bruce Ratner PhD <br at dmstat1.com> wrote:

> Jeff: Thanks for reply. I will follow your lead.
> Thanks.
> Bruce
>
> ______________
>
>
>
> > On May 5, 2017, at 9:15 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > Data frames are primarily data storage objects, not data display
> objects. You can create a separate version of your data frame with
> formatted text strings, but what you usually really want is to handle
> column alignment as well and that really has to be addressed as part of
> your data output process, which you have said nothing about.
> >
> > Do you know about HTML or markdown or LaTeX? These are useful formats
> for creating reproducible research, and they are well supported through the
> knitr package and in RStudio via Rnw and Rmd files. Tables in particular
> are well supported via LaTeX with the tables package.  The ReporteR package
> can output to Microsoft Word files directly with various formatting
> options, but it doesn't play well with the other tools.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> >> On May 5, 2017 5:08:19 AM PDT, Bruce Ratner PhD <br at dmstat1.com> wrote:
> >> R-helpers:
> >> I need some references for formatting the display of my data frame
> >> columns.
> >> Any guidance will be appreciated. Bruce
> >> ~~
> >> I have a date frame with one column as an integer for which I want a
> >> comma display,
> >> one column consisting of dollar amounts, one column for which I want a
> >> display to two digits after the decimal point, and one column as
> >> integers ranging between
> >> 100 - 999.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From br at dmstat1.com  Fri May  5 17:32:16 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 5 May 2017 11:32:16 -0400
Subject: [R] Formatting column displays
In-Reply-To: <CAKVAULNmC_9Cb=Rj0AOLq4tDBT6k32KA-YVOB6dY_6VgPaw-_Q@mail.gmail.com>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
 <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>
 <7B0606B7-C5B7-43D1-93FB-2458E66CFA2E@dmstat1.com>
 <CAKVAULNmC_9Cb=Rj0AOLq4tDBT6k32KA-YVOB6dY_6VgPaw-_Q@mail.gmail.com>
Message-ID: <93D92374-BA81-4E02-9C70-640CFF70BC2D@dmstat1.com>

Ulrike: Thanks for the afterthought. 
I'll let you know if I'm successful. 
Thanks, again. 
Bruce

______________




> On May 5, 2017, at 10:55 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> Hi Bruce,
> 
> while working with data I would not touch the formatting of the columns. If knowing the units is important, you can add it to the column name rather than the values of the columns.
> 
> For presentation purposes - where everything is turned into strings - it is a different story. Once you are done with your calculations, you can format everything the way you like it. I find kable() from the knitr package to help a lot with basic formatting, though you might have to do a little pre-processing by hand (and here sprintf comes in handy). 
> 
> And to echo Jeff: you should use Rmarkdown if you are writing up reports and it is well integrated with Rstudio. knitr works behind the scenes, and I believe it can even create a Microsoft Word document though pandoc, without the need for ReporteR (but I have never tried, so I might be wrong).
> 
> Best,
> Ulrik
> 
>> On Fri, 5 May 2017 at 15:26 Bruce Ratner PhD <br at dmstat1.com> wrote:
>> Jeff: Thanks for reply. I will follow your lead.
>> Thanks.
>> Bruce
>> 
>> ______________
>> 
>> 
>> 
>> > On May 5, 2017, at 9:15 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> >
>> > Data frames are primarily data storage objects, not data display objects. You can create a separate version of your data frame with formatted text strings, but what you usually really want is to handle column alignment as well and that really has to be addressed as part of your data output process, which you have said nothing about.
>> >
>> > Do you know about HTML or markdown or LaTeX? These are useful formats for creating reproducible research, and they are well supported through the knitr package and in RStudio via Rnw and Rmd files. Tables in particular are well supported via LaTeX with the tables package.  The ReporteR package can output to Microsoft Word files directly with various formatting options, but it doesn't play well with the other tools.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> >> On May 5, 2017 5:08:19 AM PDT, Bruce Ratner PhD <br at dmstat1.com> wrote:
>> >> R-helpers:
>> >> I need some references for formatting the display of my data frame
>> >> columns.
>> >> Any guidance will be appreciated. Bruce
>> >> ~~
>> >> I have a date frame with one column as an integer for which I want a
>> >> comma display,
>> >> one column consisting of dollar amounts, one column for which I want a
>> >> display to two digits after the decimal point, and one column as
>> >> integers ranging between
>> >> 100 - 999.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From roger.bos at rothschild.com  Fri May  5 17:46:55 2017
From: roger.bos at rothschild.com (Bos, Roger)
Date: Fri, 5 May 2017 15:46:55 +0000
Subject: [R] I cannot run R.EXE or RSCRIPT.EXE
In-Reply-To: <a6982fd2-936c-adab-c0c6-b32a8c34ae89@gmail.com>
References: <DM5PR17MB1098E7CE828DE7DE7271E695B6EA0@DM5PR17MB1098.namprd17.prod.outlook.com>
 <a6982fd2-936c-adab-c0c6-b32a8c34ae89@gmail.com>
Message-ID: <47d62bc31a2b4a88967817a9d9cf25f4@USNYMMSG001.rth.ad.rothschild.com>

Dominik,

Folders with spaces can be very tricky sometimes.  In my case single quotes didn't work, but double quotes did (see my example below).  Adding the full path to your PATH variable with eliminate the need to specify the full path, making it much easier.

Thanks,

Roger


Microsoft Windows [Version 6.1.7601]
Copyright (c) 2009 Microsoft Corporation.  All rights reserved.

C:\Users\bosr>C:\Program Files\R\R-3.3.3\bin\R.exe
'C:\Program' is not recognized as an internal or external command,
operable program or batch file.

C:\Users\bosr>'C:\Program Files\R\R-3.3.3\bin\R.exe'
The filename, directory name, or volume label syntax is incorrect.

C:\Users\bosr>"C:\Program Files\R\R-3.3.3\bin\R.exe"

R version 3.3.3 (2017-03-06) -- "Another Canoe"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Friday, May 05, 2017 6:01 AM
To: Dominik Szewczyk; r-help at r-project.org
Subject: Re: [R] I cannot run R.EXE or RSCRIPT.EXE

On 04/05/2017 4:08 PM, Dominik Szewczyk wrote:
> I cannot run R.EXE or RSCRIPT.EXE. It produces this error:
>
>
> 'C:\Program' is not recognized as an internal or external command,
> operable program or batch file.
>
>
> I have attempted to put quotes around the full path including the executable and also running the exectuable from within the path itself with the same result. The only way I can do this is to move the installation from C:\Program Files\R\R-3.4.0 to C:\R\..
>
>
> Is this a limitation of the program itself?

It sounds like a limitation of the way you're trying to run them, which you haven't told us.

Duncan Murdoch

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



This message and any attachments are for the intended recipient?s use only. This message may contain confidential, proprietary or legally privileged information. No right to confidential or privileged treatment of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately notify the sender by e-mail, delete the message, any attachments and all copies from your system and destroy any hard copies. You must not, directly or indirectly, use, disclose, distribute, print or copy any part of this message or any attachments if you are not the intended recipient.





From dwinsemius at comcast.net  Fri May  5 20:46:52 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 May 2017 11:46:52 -0700
Subject: [R] loading edited functions already in saved workspace
	automatically
In-Reply-To: <ea625bf1-c387-82f1-7694-db33fe397d89@dewey.myzen.co.uk>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <ea625bf1-c387-82f1-7694-db33fe397d89@dewey.myzen.co.uk>
Message-ID: <82A35958-B514-4A9A-B30F-DF1B7868D7E7@comcast.net>


> On May 5, 2017, at 7:48 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> 
> Dear Ralf
> 
> You can manually save it with
> savehistory(insertyour preferred filenamehere.r)
> 
> or does that not do what you hoped?

Or you can exit to your system browser and copy of the desired sections of the .Rhistory file that you desire archiving to a text editor (after you find the ofttimes hidden file.) It's just a text file. 

The details vary across OSes. I don't think you told us yours. Might help to read the Posting Guide.

-- 
David


> 
> On 05/05/2017 14:44, Ralf Goertz wrote:
>> Am Fri, 05 May 2017 06:30:01 -0700
>> schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> 
>>> The answer most people seem to use is to avoid depending on functions
>>> in RData files, and in particular avoiding ever saving the
>>> "automatic" ".RData" files at all. (Some people avoid using any RData
>>> files, but the automatic loading of functions by ".RData" files is a
>>> particularly pernicious source of evil as you have already
>>> discovered.)
>>> 
>>> That is,  always work toward building scripts that you run to restore
>>> your workspace rather than depending on save files. Don't depend on
>>> save files to keep track of what you do interactively. This also
>>> usually means that there should be little if anything in
>>> your .Rprofile because that tends to build non-reproducibility into
>>> your scripts.
>> 
>> Hi Jeff,
>> 
>> thanks for your answer. Actually, I don't use the workspace saving
>> feature primarily for the data but for the command line history. Is
>> there a way to just save .Rhistory?
>> 
>> Ralf
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ---
>> This email has been checked for viruses by AVG.
>> http://www.avg.com
>> 
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Fri May  5 23:38:06 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 5 May 2017 14:38:06 -0700
Subject: [R] loading edited functions already in saved workspace
	automatically
In-Reply-To: <CAGxFJbR-NJD4qivFktRvKGmEuVmyc136pGCpS4Zajaw09paDag@mail.gmail.com>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <ea625bf1-c387-82f1-7694-db33fe397d89@dewey.myzen.co.uk>
 <82A35958-B514-4A9A-B30F-DF1B7868D7E7@comcast.net>
 <CAGxFJbTBZd-n9LbL9+iK3pmuT+zdRD7J3MHUKDqyGMTkCAa+hA@mail.gmail.com>
 <CAGxFJbR-NJD4qivFktRvKGmEuVmyc136pGCpS4Zajaw09paDag@mail.gmail.com>
Message-ID: <CAGxFJbTB3yyngZittLPPL_uHi1u9oP03tPNHvcFsjjyT4BkAEw@mail.gmail.com>

Haven't followed this closely, but
?Startup
and links therein might be useful (esp .First).

Bert


On May 5, 2017 11:47 AM, "David Winsemius" <dwinsemius at comcast.net> wrote:


> On May 5, 2017, at 7:48 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>
> Dear Ralf
>
> You can manually save it with
> savehistory(insertyour preferred filenamehere.r)
>
> or does that not do what you hoped?

Or you can exit to your system browser and copy of the desired sections of
the .Rhistory file that you desire archiving to a text editor (after you
find the ofttimes hidden file.) It's just a text file.

The details vary across OSes. I don't think you told us yours. Might help
to read the Posting Guide.

--
David


>
> On 05/05/2017 14:44, Ralf Goertz wrote:
>> Am Fri, 05 May 2017 06:30:01 -0700
>> schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>
>>> The answer most people seem to use is to avoid depending on functions
>>> in RData files, and in particular avoiding ever saving the
>>> "automatic" ".RData" files at all. (Some people avoid using any RData
>>> files, but the automatic loading of functions by ".RData" files is a
>>> particularly pernicious source of evil as you have already
>>> discovered.)
>>>
>>> That is,  always work toward building scripts that you run to restore
>>> your workspace rather than depending on save files. Don't depend on
>>> save files to keep track of what you do interactively. This also
>>> usually means that there should be little if anything in
>>> your .Rprofile because that tends to build non-reproducibility into
>>> your scripts.
>>
>> Hi Jeff,
>>
>> thanks for your answer. Actually, I don't use the workspace saving
>> feature primarily for the data but for the command line history. Is
>> there a way to just save .Rhistory?
>>
>> Ralf
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ---
>> This email has been checked for viruses by AVG.
>> http://www.avg.com
>>
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From br at dmstat1.com  Fri May  5 23:50:03 2017
From: br at dmstat1.com (BR_email)
Date: Fri, 5 May 2017 17:50:03 -0400
Subject: [R] Formatting column displays
In-Reply-To: <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
 <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>
Message-ID: <a4e0d715-cb0f-8ed0-d11b-889abe31d3b0@dmstat1.com>

Jeff:
I cannot install the ReporteR package. Is there a work-around, or is the 
error message correct?
Thanks. Bruce

R> install.packages("ReporteR") Installing package into 
?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is 
unspecified) Warning in install.packages :
   package ?ReporteR? is not available (for R version 3.3.3)


  

Jeff Newmiller wrote:
> Data frames are primarily data storage objects, not data display objects. You can create a separate version of your data frame with formatted text strings, but what you usually really want is to handle column alignment as well and that really has to be addressed as part of your data output process, which you have said nothing about.
>
> Do you know about HTML or markdown or LaTeX? These are useful formats for creating reproducible research, and they are well supported through the knitr package and in RStudio via Rnw and Rmd files. Tables in particular are well supported via LaTeX with the tables package.  The ReporteR package can output to Microsoft Word files directly with various formatting options, but it doesn't play well with the other tools.


From wdunlap at tibco.com  Fri May  5 23:54:06 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 May 2017 14:54:06 -0700
Subject: [R] Formatting column displays
In-Reply-To: <a4e0d715-cb0f-8ed0-d11b-889abe31d3b0@dmstat1.com>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
 <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>
 <a4e0d715-cb0f-8ed0-d11b-889abe31d3b0@dmstat1.com>
Message-ID: <CAF8bMcZ8DY9rPJMBmdpR2A8H87ufAzM1Vm9h6pi6VC5vxDwRAQ@mail.gmail.com>

Use Google: a search for "R Reporter package" shows that the package is
named "ReporteRs".

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 5, 2017 at 2:50 PM, BR_email <br at dmstat1.com> wrote:

> Jeff:
> I cannot install the ReporteR package. Is there a work-around, or is the
> error message correct?
> Thanks. Bruce
>
> R> install.packages("ReporteR") Installing package into
> ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is
> unspecified) Warning in install.packages :
>   package ?ReporteR? is not available (for R version 3.3.3)
>
>
>
> Jeff Newmiller wrote:
>
>> Data frames are primarily data storage objects, not data display objects.
>> You can create a separate version of your data frame with formatted text
>> strings, but what you usually really want is to handle column alignment as
>> well and that really has to be addressed as part of your data output
>> process, which you have said nothing about.
>>
>> Do you know about HTML or markdown or LaTeX? These are useful formats for
>> creating reproducible research, and they are well supported through the
>> knitr package and in RStudio via Rnw and Rmd files. Tables in particular
>> are well supported via LaTeX with the tables package.  The ReporteR package
>> can output to Microsoft Word files directly with various formatting
>> options, but it doesn't play well with the other tools.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From frainj at gmail.com  Sat May  6 00:21:20 2017
From: frainj at gmail.com (John C Frain)
Date: Fri, 5 May 2017 23:21:20 +0100
Subject: [R] I cannot run R.EXE or RSCRIPT.EXE
In-Reply-To: <47d62bc31a2b4a88967817a9d9cf25f4@USNYMMSG001.rth.ad.rothschild.com>
References: <DM5PR17MB1098E7CE828DE7DE7271E695B6EA0@DM5PR17MB1098.namprd17.prod.outlook.com>
 <a6982fd2-936c-adab-c0c6-b32a8c34ae89@gmail.com>
 <47d62bc31a2b4a88967817a9d9cf25f4@USNYMMSG001.rth.ad.rothschild.com>
Message-ID: <CAHrK516ADCCnPyz4otnXg_hziH66EtvmmJj6HKtHazrMfsbojQ@mail.gmail.com>

As far as I can recall this is and always was a  "feature" of MS Windows.
Filenames with embedded spaces must be within double quotes. Single quotes
can not be used. I understand that single quotes had or may still have some
meaning in "for" statements in a batch file. I have never had occasion to
use this feature and I suspect that most if not all R users will not need
it.  Added the R bin directory to your path will bypass all these problems.

	[[alternative HTML version deleted]]


From br at dmstat1.com  Sat May  6 01:28:42 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Fri, 5 May 2017 19:28:42 -0400
Subject: [R] Formatting column displays
In-Reply-To: <CAF8bMcZ8DY9rPJMBmdpR2A8H87ufAzM1Vm9h6pi6VC5vxDwRAQ@mail.gmail.com>
References: <05A5571A-F265-4560-A748-2C5E980AD2FF@dmstat1.com>
 <96AF3A08-D32D-4BBC-BCA3-D42FFF6DCCD7@dcn.davis.ca.us>
 <a4e0d715-cb0f-8ed0-d11b-889abe31d3b0@dmstat1.com>
 <CAF8bMcZ8DY9rPJMBmdpR2A8H87ufAzM1Vm9h6pi6VC5vxDwRAQ@mail.gmail.com>
Message-ID: <FB94902E-D6E4-48CF-BCEF-6A167FEC26D6@dmstat1.com>

Thanks, Bill. 
Bruce

______________




> On May 5, 2017, at 5:54 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> Use Google: a search for "R Reporter package" shows that the package is named "ReporteRs".
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
>> On Fri, May 5, 2017 at 2:50 PM, BR_email <br at dmstat1.com> wrote:
>> Jeff:
>> I cannot install the ReporteR package. Is there a work-around, or is the error message correct?
>> Thanks. Bruce
>> 
>> R> install.packages("ReporteR") Installing package into ?C:/Users/BruceRatner/Documents/R/win-library/3.3? (as ?lib? is unspecified) Warning in install.packages :
>>   package ?ReporteR? is not available (for R version 3.3.3)
>> 
>> 
>>  
>> Jeff Newmiller wrote:
>>> Data frames are primarily data storage objects, not data display objects. You can create a separate version of your data frame with formatted text strings, but what you usually really want is to handle column alignment as well and that really has to be addressed as part of your data output process, which you have said nothing about.
>>> 
>>> Do you know about HTML or markdown or LaTeX? These are useful formats for creating reproducible research, and they are well supported through the knitr package and in RStudio via Rnw and Rmd files. Tables in particular are well supported via LaTeX with the tables package.  The ReporteR package can output to Microsoft Word files directly with various formatting options, but it doesn't play well with the other tools.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From v.dominguezalmela at se15.qmul.ac.uk  Fri May  5 18:39:23 2017
From: v.dominguezalmela at se15.qmul.ac.uk (Victoria Dominguez Almela)
Date: Fri, 5 May 2017 16:39:23 +0000
Subject: [R] Problems installing IsoriX package in R
Message-ID: <HE1PR0701MB2779AED4B25E6D8502C5EC8CE3EB0@HE1PR0701MB2779.eurprd07.prod.outlook.com>

Hi everyone!

I am trying to build an isoscape using R, but I am having issues when comes to install the IsoriX package.

The next message comes through:

Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
there is no package called ?proxy?

Has anyone faced this problem before??

Thanks!!!


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat May  6 06:26:23 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 05 May 2017 21:26:23 -0700
Subject: [R] Problems installing IsoriX package in R
In-Reply-To: <HE1PR0701MB2779AED4B25E6D8502C5EC8CE3EB0@HE1PR0701MB2779.eurprd07.prod.outlook.com>
References: <HE1PR0701MB2779AED4B25E6D8502C5EC8CE3EB0@HE1PR0701MB2779.eurprd07.prod.outlook.com>
Message-ID: <8CF52CDE-E4A6-4420-B560-32B8D159B183@dcn.davis.ca.us>

If by "this problem" you mean the error "no package named x" then yes. It means you need to find the "proxy" package or find an updated version of the package that required the "proxy" package.

Since it is on CRAN [1], it might be as simple as installing the package, or your preferred mirror might not have it so you might have to pick another one. 

[1] https://cran.r-project.org/package=proxy
-- 
Sent from my phone. Please excuse my brevity.

On May 5, 2017 9:39:23 AM PDT, Victoria Dominguez Almela <v.dominguezalmela at se15.qmul.ac.uk> wrote:
>Hi everyone!
>
>I am trying to build an isoscape using R, but I am having issues when
>comes to install the IsoriX package.
>
>The next message comes through:
>
>Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>versionCheck = vI[[j]]) :
>there is no package called ?proxy?
>
>Has anyone faced this problem before??
>
>Thanks!!!
>
>
>	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sat May  6 08:25:23 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sat, 6 May 2017 11:55:23 +0530
Subject: [R] Perfect prediction of AR1 series using package dlm,
 posted on stack exchange
In-Reply-To: <0478029A-F51B-4216-887D-7CB4905E9045@gmail.com>
References: <CAC8=1eqb7Vcdpn79CLbhBPhSVZBjdXopHBJMa6QrJ_ecONTftg@mail.gmail.com>
 <0478029A-F51B-4216-887D-7CB4905E9045@gmail.com>
Message-ID: <CAC8=1ep1Ug5qyUfu7zAAoTuTKgGF8f=sWq+OJTqVGNk89xjtdQ@mail.gmail.com>

Dear Peter,

Many thanks,
Ashim.

On Thu, May 4, 2017 at 4:54 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> I am not an expert on dlm, but it seems to me that you are getting perfect
> _filtering_ not _prediction_. If you cast an AR model as a state space
> model, there is no measurement error on the state values, hence the
> conditional distribution of theta_t given y_t is just the point value of
> y_t...
>
> -pd
>
> > On 4 May 2017, at 12:05 , Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > Dear all,
> >
> > I have made a dlm model,where I am getting a perfect prediction.
> >
> > Here is a link to the output:
> >
> > http://pasteboard.co/9IxVQwjm6.png
> >
> > The query and code is on:
> >
> > https://stats.stackexchange.com/questions/276449/perfect-
> prediction-in-case-of-a-univariate-ar1-model-using-dlm
> >
> > Can someone here be kind enough to answer my query?
> >
> > Best Regards,
> > Ashim
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Sat May  6 11:29:21 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 06 May 2017 09:29:21 +0000
Subject: [R] 3D equal-spaced closed mesh
In-Reply-To: <CAGxFJbR+jogbwPeADG3+B1+=XvtgheuWWF+=GSWOWy5AAp+KcA@mail.gmail.com>
References: <BY2PR02MB36277BB4E65DFDF99B12C818CEA0@BY2PR02MB362.namprd02.prod.outlook.com>
 <CAGxFJbR+jogbwPeADG3+B1+=XvtgheuWWF+=GSWOWy5AAp+KcA@mail.gmail.com>
Message-ID: <CAAcGz98DzbPCAQxvMJEsuLE6k0XrsS5s3WE1isggu+aZTKe7sg@mail.gmail.com>

Rvcg another option to explore with its ball-pivoting surface
reconstruction.

Mike

On Fri, May 5, 2017, 08:34 Bert Gunter <bgunter.4567 at gmail.com> wrote:

> The r-sig-geo list and corresponding cran task view *might* be a better
> place to post and/look.
>
> Bert
>
>
> On May 4, 2017 12:51 PM, "Eric Krantz" <Eric.Krantz at respec.com> wrote:
>
> > I have sonar image which is basically a point cloud (x, y, z) of an
> > irregular underground cone-shaped structure. I am trying to create either
> > (1) a closed 3D mesh with "equally spaced" mesh grid, or (2) a smooth
> > closed surface, for instance by calculating connected localized
> regression
> > surfaces. My Z (vertical) component is equally spaced, but X and Y
> consist
> > of 128 points around the perimeter, regardless of diameter, which makes
> the
> > grid size small where the diameter is small, and large where it is large.
> > I'm looking for relatively equal grids, so I could use regression or
> > interpolation to add points where needed, or conversely remove them,
> hence
> > the idea of a localized surface regression. I've tried plot3D package,
> RGL,
> > and a couple other packages including alphashape3d. I have not tried
> plotly
> > or rms. So much time invested I thought I would ask for advice, if anyone
> > knows a package or technique or can clue which direction to go. Thanks,
> > Confidentiality Notice: This E-mail and any attachments ...{{dropped:12}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From vikash.kr.117 at gmail.com  Sat May  6 05:21:23 2017
From: vikash.kr.117 at gmail.com (Vikash Kumar)
Date: Sat, 6 May 2017 08:51:23 +0530
Subject: [R] Problems installing IsoriX package in R
In-Reply-To: <HE1PR0701MB2779AED4B25E6D8502C5EC8CE3EB0@HE1PR0701MB2779.eurprd07.prod.outlook.com>
References: <HE1PR0701MB2779AED4B25E6D8502C5EC8CE3EB0@HE1PR0701MB2779.eurprd07.prod.outlook.com>
Message-ID: <CAALD-ggmAD4SPmaX+NBRn+dgEcWW+g1NfXUNzpnnCk_61Brrfw@mail.gmail.com>

Install the dependent packages also.

Try -

install.packages("proxy")
#then
install.packages("IsoriX")

Regards,
Vikash

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Fri, May 5, 2017 at 10:09 PM, Victoria Dominguez Almela <
v.dominguezalmela at se15.qmul.ac.uk> wrote:

> Hi everyone!
>
> I am trying to build an isoscape using R, but I am having issues when
> comes to install the IsoriX package.
>
> The next message comes through:
>
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
> there is no package called ?proxy?
>
> Has anyone faced this problem before??
>
> Thanks!!!
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Sat May  6 16:47:08 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Sat, 6 May 2017 14:47:08 +0000 (UTC)
Subject: [R] create a correct list from Document Term Matrix
References: <1390160866.6981825.1494082028499.ref@mail.yahoo.com>
Message-ID: <1390160866.6981825.1494082028499@mail.yahoo.com>

Hi all,

I have a text classification task which is classification of a Control group and Alzheimer group texts. I have generated DocumentTermMatrix for both groups and then created a list with one extra element showing the group name if it's Alzheimer or control group, for example for the Alzheimer group:

frequenciesAlzheimer=DocumentTermMatrix(corpus)
freqlistAlz=list(type="alzheimer",frequenciesAlzheimer)

List of 2
$ type: chr "alzheimer"
$        :List of 6    *
..$ i      : int [1:8678] 1 1 1 1 1 1 1 1 1 1 ...
..$ j      : int [1:8678] 1 2 3 4 5 6 7 8 9 10 ...
..$ v      : num [1:8678] 1 1 1 1 1 2 1 1 2 1 ...
..$ nrow    : int 255
..$ ncol    : int 1091
..$ dimnames:List of 2
.. ..$ Docs : chr [1:255] "1" "2" "3" "4" ...
.. ..$ Terms: chr [1:1091] "alright" "bad" "boy" "cookie" ...
..- attr(*, "class")= chr [1:2] "DocumentTermMatrix" "simple_triplet_matrix"
..- attr(*, "weighting")= chr [1:2] "term frequency" "tf"

and I have the same list for control group,now my question is why I don't get the name of my DTM as the second element of my list? in the line marked by *
I need to have


$frequenciesAlzheimer : List of 6

but there's no name, does anyone know how should I solve this?

Thanks for any help!
Elahe


From dwinsemius at comcast.net  Sat May  6 17:14:20 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 6 May 2017 08:14:20 -0700
Subject: [R] create a correct list from Document Term Matrix
In-Reply-To: <1390160866.6981825.1494082028499@mail.yahoo.com>
References: <1390160866.6981825.1494082028499.ref@mail.yahoo.com>
 <1390160866.6981825.1494082028499@mail.yahoo.com>
Message-ID: <B0EB1CDE-ACB8-4607-8F64-AB044B5A1959@comcast.net>


> On May 6, 2017, at 7:47 AM, Elahe chalabi via R-help <r-help at r-project.org> wrote:
> 
> Hi all,
> 
> I have a text classification task which is classification of a Control group and Alzheimer group texts. I have generated DocumentTermMatrix for both groups and then created a list with one extra element showing the group name if it's Alzheimer or control group, for example for the Alzheimer group:
> 
> frequenciesAlzheimer=DocumentTermMatrix(corpus)
> freqlistAlz=list(type="alzheimer",frequenciesAlzheimer)
> 
> List of 2
> $ type: chr "alzheimer"
> $        :List of 6    *
> ..$ i      : int [1:8678] 1 1 1 1 1 1 1 1 1 1 ...
> ..$ j      : int [1:8678] 1 2 3 4 5 6 7 8 9 10 ...
> ..$ v      : num [1:8678] 1 1 1 1 1 2 1 1 2 1 ...
> ..$ nrow    : int 255
> ..$ ncol    : int 1091
> ..$ dimnames:List of 2
> .. ..$ Docs : chr [1:255] "1" "2" "3" "4" ...
> .. ..$ Terms: chr [1:1091] "alright" "bad" "boy" "cookie" ...
> ..- attr(*, "class")= chr [1:2] "DocumentTermMatrix" "simple_triplet_matrix"
> ..- attr(*, "weighting")= chr [1:2] "term frequency" "tf"
> 
> and I have the same list for control group,now my question is why I don't get the name of my DTM as the second element of my list? in the line marked by *
> I need to have
> 
> 
> $frequenciesAlzheimer : List of 6
> 
> but there's no name, does anyone know how should I solve this?

Why don't you just assign a name to that list? Either of these should succeed:


names(freqlistAlz)[2] <- frequenciesAlzheimer

freqlistAlz=list(type="alzheimer", 
                   frequenciesAlzheimer =  frequenciesAlzheimer)

-- 
David.


> 
> Thanks for any help!
> Elahe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From friendly at yorku.ca  Sat May  6 17:17:42 2017
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 6 May 2017 11:17:42 -0400
Subject: [R] loading edited functions already in saved workspace
	automatically
In-Reply-To: <20170505162314.1e6a1020@delli.home.local>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>
 <20170505162314.1e6a1020@delli.home.local>
Message-ID: <aa2b0963-13a2-5014-aa9a-0355239f2e6e@yorku.ca>


On 5/5/2017 10:23 AM, Ralf Goertz wrote:
> Am Fri, 05 May 2017 07:14:36 -0700
> schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> R normally prompts you to save .RData, but it just automatically
>> saves .Rhistory... the two are unrelated.
>
> Not here. If I say "n" to the prompted question "Save workspace image?
> [y/n/c]: " my history doesn't get saved.
>
> Version:
>
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-suse-linux-gnu (64-bit)
>

On Windoze, here's what I use in my .Rprofile, which runs every time I 
start an RGUI coonsole.  The key is .First & .Last to load/save
history automagically.  There is some extra overhead in my use of
old.packages() here, but that is for a different reason.



### History

# could use Sys.getenv("R_HISTFILE")
# Sys.getenv("R_HISTSIZE"=1024)
.First <- function() {
     if(interactive()) {
     	if (.Platform$GUI == "Rgui") {
			histfile <- if (file.exists(".Rhistory")) ".Rhistory" else 
"c:/R/.Rhistory"
     	try(utils::loadhistory(histfile))
     	old <- utils::old.packages()
     	if (! is.null(old)) cat("Updatable packages: ", old[,1], "\n", 
fill=TRUE) else cat("All packages up to date\n")
			}
       setwd("c:/R")
       cat(paste("[.Rprofile loaded, current dir:", getwd(), 
"]\n"),sep=" ")    	
       }
     }


.Last <- function()
     if(interactive() && .Platform$GUI == "Rgui") {
		 histfile <- if (file.exists(".Rhistory")) ".Rhistory" else 
"c:/R/.Rhistory"
      try(utils::savehistory(histfile))
     }


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From dwinsemius at comcast.net  Sat May  6 17:22:41 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 6 May 2017 08:22:41 -0700
Subject: [R] create a correct list from Document Term Matrix
In-Reply-To: <B0EB1CDE-ACB8-4607-8F64-AB044B5A1959@comcast.net>
References: <1390160866.6981825.1494082028499.ref@mail.yahoo.com>
 <1390160866.6981825.1494082028499@mail.yahoo.com>
 <B0EB1CDE-ACB8-4607-8F64-AB044B5A1959@comcast.net>
Message-ID: <D85CC2BD-13B8-412A-8DFC-9C7316120BE9@comcast.net>


> On May 6, 2017, at 8:14 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On May 6, 2017, at 7:47 AM, Elahe chalabi via R-help <r-help at r-project.org> wrote:
>> 
>> Hi all,
>> 
>> I have a text classification task which is classification of a Control group and Alzheimer group texts. I have generated DocumentTermMatrix for both groups and then created a list with one extra element showing the group name if it's Alzheimer or control group, for example for the Alzheimer group:
>> 
>> frequenciesAlzheimer=DocumentTermMatrix(corpus)
>> freqlistAlz=list(type="alzheimer",frequenciesAlzheimer)
>> 
>> List of 2
>> $ type: chr "alzheimer"
>> $        :List of 6    *
>> ..$ i      : int [1:8678] 1 1 1 1 1 1 1 1 1 1 ...
>> ..$ j      : int [1:8678] 1 2 3 4 5 6 7 8 9 10 ...
>> ..$ v      : num [1:8678] 1 1 1 1 1 2 1 1 2 1 ...
>> ..$ nrow    : int 255
>> ..$ ncol    : int 1091
>> ..$ dimnames:List of 2
>> .. ..$ Docs : chr [1:255] "1" "2" "3" "4" ...
>> .. ..$ Terms: chr [1:1091] "alright" "bad" "boy" "cookie" ...
>> ..- attr(*, "class")= chr [1:2] "DocumentTermMatrix" "simple_triplet_matrix"
>> ..- attr(*, "weighting")= chr [1:2] "term frequency" "tf"
>> 
>> and I have the same list for control group,now my question is why I don't get the name of my DTM as the second element of my list? in the line marked by *
>> I need to have
>> 
>> 
>> $frequenciesAlzheimer : List of 6
>> 
>> but there's no name, does anyone know how should I solve this?
> 
> Why don't you just assign a name to that list? Either of these should succeed:
> 
> 
> names(freqlistAlz)[2] <- frequenciesAlzheimer

Sigh. The dangers of untested code (due to no offered example.) My wetware interpreter now tells me that it probably should have been:

names(freqlistAlz)[2] <- "frequenciesAlzheimer"


> 
> freqlistAlz=list(type="alzheimer", 
>                   frequenciesAlzheimer =  frequenciesAlzheimer)
> 
> -- 
> David.
> 
> 
>> 
>> Thanks for any help!
>> Elahe
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From esawiek at gmail.com  Sat May  6 18:39:41 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Sat, 6 May 2017 12:39:41 -0400
Subject: [R] nested for loop with data table
In-Reply-To: <56034994-573D-4A6D-A0AA-AC88952B5AD8@dcn.davis.ca.us>
References: <CA+ZkTxumTJ-Cp_cJWhxrwppm6k3AfRLhn-aRenubCZ9g=0VcUg@mail.gmail.com>
 <CA+ZkTxuDho1gkC1Oxvr_b2jXHUywLjYiOxZhhk9qK+QvDL8aEg@mail.gmail.com>
 <56034994-573D-4A6D-A0AA-AC88952B5AD8@dcn.davis.ca.us>
Message-ID: <CA+ZkTxtMRoyYqy3S5XgUFP=AN+-rPk-yHoDYQQxoY3OFhoOeoA@mail.gmail.com>

Thank you Jeff. Your idea, as i mentioned on my previous posting, did
indeed work. I read somewhere that both data table dplyr do great many
things and i plan to learn both as much as i can. Suggestions on this list
either get you the answer you are looking for or give you lead to an answer.

Thanks again

On Thu, May 4, 2017 at 12:04 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You seem to be unaware of the "aggregate" data processing concept. There
> are many ways to accomplish aggregation, but I am not fluent in data.table
> methods but knowing the concept is the first step.
>
> Perhaps look closely at [1], or Google for data table aggregation yourself?
>
> [1] https://www.r-bloggers.com/efficient-aggregation-and-
> more-using-data-table/amp/
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 3, 2017 8:17:21 AM PDT, Ek Esawi <esawiek at gmail.com> wrote:
> >Thank you both Boris and Jim. Thank you, Boris, for advising to read
> >the
> >posting guide; I had and I just did.
> >
> >Jim?s idea is exactly what I want; however, I could not pass sset1,
> >sset2,
> >etc. to the j nested loop and collect the results in an vector.
> >
> >Here attached my code, file, and my question which should be clear now.
> >The
> >question again is instead of using separate loops for each sset1 and
> >sset2,
> >I want one nested loop? Because I have at least 10 subsets
> >(sset1,sset2,sset3?..sset10).
> >
> >Thanks again, EK
> >
> >
> >-------The code------
> >
> >install.packages("data.table")
> >library(data.table)
> >File1 <-  "C:/Users/SampleData.csv"
> >DT <- fread(File1)
> >sset1 <- DT[Num<10&Day<10]
> >sset2 <- DT[Num>10&Day<15]
> >
> ># Count how many combinations of A,B,C,D,E,F in each subset
> >for ( i in 1:length(sset1)){
> >  aa <- c(sset1[Grade=="A",.N],sset1[Grade=="D",.N])
> >  bb <- c(sset1[Grade=="B",.N],sset1[Grade=="F",.N])
> >  cc <- c(sset1[Grade=="C",.N],sset1[Grade=="A",.N])
> >  counts <- c(aa, bb,cc)
> >}
> >
> >for ( i in 1:length(sset2)){
> >  aa1 <- c(sset2[Grade=="A",.N],sset2[Grade=="D",.N])
> >  bb1 <- c(sset2[Grade=="B",.N],sset2[Grade=="F",.N])
> >  cc1 <- c(sset2[Grade=="C",.N],sset2[Grade=="A",.N])
> >  counts <-  c(aa1,bb1,cc1)
> >}
> >
> >-----------The File------------
> >
> >   Num  Color Grade Value    Month Day
> > 1:   1 yellow     A    20      May   1
> > 2:   2  green     B    25     June   2
> > 3:   3  green     A    10    April   3
> > 4:   4  black     A    17   August   3
> > 5:   5    red     C     5 December   5
> > 6:   6 orange     D     0  January  13
> > 7:   7 orange     E    12  January   5
> > 8:   8 orange     F    11 February   8
> > 9:   9 orange     F    99     July  23
> >10:  10 orange     F    70      May   7
> >11:  11  black     A    77     June  11
> >12:  12  green     B    87    April  33
> >13:  13  black     A    79   August   9
> >14:  14  green     A    68 December  14
> >15:  15  black     C    90  January  31
> >16:  16  green     D    79  January  11
> >17:  17  black     E   101 February  17
> >18:  18    red     F    90     July  21
> >19:  19    red     F   112 February  13
> >20:  20    red     F   101     July  20
> >
> >On Tue, May 2, 2017 at 12:35 PM, Ek Esawi <esawiek at gmail.com> wrote:
> >
> >> I have a huge data file; a sample is listed below. I am using the
> >package
> >> data table to process the file and I am stuck on one issue and need
> >some
> >> feedback. I used fread to create a data table. Then I divided the
> >data
> >> table (named File1) into 10 general subsets using common table
> >commands
> >> such as:
> >>
> >>
> >>
> >> AAA <- File1[Num<5&day>15]
> >>
> >> BBB <- File1[Num>15&day<10]
> >>
> >> ?..
> >>
> >> ?..
> >>
> >> ?..
> >>
> >> ?..
> >>
> >> ?..
> >>
> >> ?..
> >>
> >>
> >>
> >> I wanted to divide and count each of the above subsets based on a set
> >of
> >> parameters common to all subsets. I did the following to go through
> >each
> >> subset and it works:
> >>
> >> For (I in 1: length (AAA)) {
> >>
> >>               aa <- c(AAA[color==?green?&grade==?a?,month==?Januray?
> >> .N],[ AAA[color==?green?&grade==?b?& month==?June?? .N])
> >>
> >> }
> >>
> >>
> >>
> >> The question: I don?t want to have a separate loop for each subset
> >(10
> >> loops). Instead, I was hoping to have 2 nested loops in the form
> >below:
> >>
> >>
> >>
> >> For (I in 1:N)){
> >>
> >>               For (j in 1:M){
> >>
> >>
> >>
> >> }
> >>
> >> }
> >>
> >>
> >>
> >>  Sample
> >>
> >>
> >> Num
> >>
> >> Color
> >>
> >> Grade
> >>
> >> Value
> >>
> >> Month
> >>
> >> Day
> >>
> >> 1
> >>
> >> yellow
> >>
> >> A
> >>
> >> 20
> >>
> >> May
> >>
> >> 1
> >>
> >> 2
> >>
> >> green
> >>
> >> B
> >>
> >> 25
> >>
> >> June
> >>
> >> 2
> >>
> >> 3
> >>
> >> green
> >>
> >> A
> >>
> >> 10
> >>
> >> April
> >>
> >> 3
> >>
> >> 4
> >>
> >> black
> >>
> >> A
> >>
> >> 17
> >>
> >> August
> >>
> >> 3
> >>
> >> 5
> >>
> >> red
> >>
> >> C
> >>
> >> 5
> >>
> >> December
> >>
> >> 5
> >>
> >> 6
> >>
> >> orange
> >>
> >> D
> >>
> >> 0
> >>
> >> January
> >>
> >> 13
> >>
> >> 7
> >>
> >> orange
> >>
> >> E
> >>
> >> 12
> >>
> >> January
> >>
> >> 5
> >>
> >> 8
> >>
> >> orange
> >>
> >> F
> >>
> >> 11
> >>
> >> February
> >>
> >> 8
> >>
> >> 9
> >>
> >> orange
> >>
> >> F
> >>
> >> 99
> >>
> >> July
> >>
> >> 23
> >>
> >> 10
> >>
> >> orange
> >>
> >> F
> >>
> >> 70
> >>
> >> May
> >>
> >> 7
> >>
> >> 11
> >>
> >> black
> >>
> >> A
> >>
> >> 77
> >>
> >> June
> >>
> >> 11
> >>
> >> 12
> >>
> >> green
> >>
> >> B
> >>
> >> 87
> >>
> >> April
> >>
> >> 33
> >>
> >> 13
> >>
> >> black
> >>
> >> A
> >>
> >> 79
> >>
> >> August
> >>
> >> 9
> >>
> >> 14
> >>
> >> green
> >>
> >> A
> >>
> >> 68
> >>
> >> December
> >>
> >> 14
> >>
> >> 15
> >>
> >> black
> >>
> >> C
> >>
> >> 90
> >>
> >> January
> >>
> >> 31
> >>
> >> 16
> >>
> >> green
> >>
> >> D
> >>
> >> 79
> >>
> >> January
> >>
> >> 11
> >>
> >> 17
> >>
> >> black
> >>
> >> E
> >>
> >> 101
> >>
> >> February
> >>
> >> 17
> >>
> >> 18
> >>
> >> red
> >>
> >> F
> >>
> >> 90
> >>
> >> July
> >>
> >> 21
> >>
> >> 19
> >>
> >> red
> >>
> >> F
> >>
> >> 112
> >>
> >> February
> >>
> >> 13
> >>
> >> 20
> >>
> >> red
> >>
> >> F
> >>
> >> 101
> >>
> >> July
> >>
> >> 20
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aolinto.lst at gmail.com  Sat May  6 23:50:13 2017
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Sat, 6 May 2017 18:50:13 -0300
Subject: [R] setting the values of a secondary "y" axis
Message-ID: <CAE8g1gNJQ9fR-C9rAJgDVfsbFW1QaCmapF1Z5nMrnDQQuj2gfA@mail.gmail.com>

Hello

I want to make a plot with two "y" axes. The labels at axis 4 should be the
values from axis 2 multiplied by a scale factor (as 3.5).

In the example below I draw axis 4 exactly as axis 2. But I could not find
a way to multiply its values by 3.5 (e.g.).

plot(rnorm(100,30,5))
axis(4) # I'd like to have these values multiplied by a scale factor

I will produce plots for different data sets in a looping and y values will
vary so I  cannot "freeze" axis 4 labels because they (values and scale
factor) will vary  from plot to plot.

Thanks in advance for any help. All the best.

Antonio

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun May  7 01:50:37 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 6 May 2017 16:50:37 -0700
Subject: [R] setting the values of a secondary "y" axis
In-Reply-To: <CAE8g1gNJQ9fR-C9rAJgDVfsbFW1QaCmapF1Z5nMrnDQQuj2gfA@mail.gmail.com>
References: <CAE8g1gNJQ9fR-C9rAJgDVfsbFW1QaCmapF1Z5nMrnDQQuj2gfA@mail.gmail.com>
Message-ID: <CAF8bMcZ5zuBf_pJXAnW8vpkJqj_LXLezf=uf1EBp_MbmoJBQ8g@mail.gmail.com>

Does the following do what you want?

> plot(log2(1:40), sin(1:40))
> yTickPositions <- axTicks(2)
> axis(side=4, at=yTickPositions, lab=format(yTickPositions*3.5))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, May 6, 2017 at 2:50 PM, Antonio Silva <aolinto.lst at gmail.com> wrote:

> Hello
>
> I want to make a plot with two "y" axes. The labels at axis 4 should be the
> values from axis 2 multiplied by a scale factor (as 3.5).
>
> In the example below I draw axis 4 exactly as axis 2. But I could not find
> a way to multiply its values by 3.5 (e.g.).
>
> plot(rnorm(100,30,5))
> axis(4) # I'd like to have these values multiplied by a scale factor
>
> I will produce plots for different data sets in a looping and y values will
> vary so I  cannot "freeze" axis 4 labels because they (values and scale
> factor) will vary  from plot to plot.
>
> Thanks in advance for any help. All the best.
>
> Antonio
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aolinto.lst at gmail.com  Sun May  7 05:35:21 2017
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Sun, 7 May 2017 00:35:21 -0300
Subject: [R] setting the values of a secondary "y" axis
In-Reply-To: <CAF8bMcZ5zuBf_pJXAnW8vpkJqj_LXLezf=uf1EBp_MbmoJBQ8g@mail.gmail.com>
References: <CAE8g1gNJQ9fR-C9rAJgDVfsbFW1QaCmapF1Z5nMrnDQQuj2gfA@mail.gmail.com>
 <CAF8bMcZ5zuBf_pJXAnW8vpkJqj_LXLezf=uf1EBp_MbmoJBQ8g@mail.gmail.com>
Message-ID: <CAE8g1gMku+-B68sbC+3xceZThT_EVcr=KGUmsYPnFsrf7f-1sQ@mail.gmail.com>

Many thanks Bill, that's it!

Best wishes

Antonio

2017-05-06 20:50 GMT-03:00 William Dunlap <wdunlap at tibco.com>:

> Does the following do what you want?
>
> > plot(log2(1:40), sin(1:40))
> > yTickPositions <- axTicks(2)
> > axis(side=4, at=yTickPositions, lab=format(yTickPositions*3.5))
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sat, May 6, 2017 at 2:50 PM, Antonio Silva <aolinto.lst at gmail.com>
> wrote:
>
>> Hello
>>
>> I want to make a plot with two "y" axes. The labels at axis 4 should be
>> the
>> values from axis 2 multiplied by a scale factor (as 3.5).
>>
>> In the example below I draw axis 4 exactly as axis 2. But I could not find
>> a way to multiply its values by 3.5 (e.g.).
>>
>> plot(rnorm(100,30,5))
>> axis(4) # I'd like to have these values multiplied by a scale factor
>>
>> I will produce plots for different data sets in a looping and y values
>> will
>> vary so I  cannot "freeze" axis 4 labels because they (values and scale
>> factor) will vary  from plot to plot.
>>
>> Thanks in advance for any help. All the best.
>>
>> Antonio
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Ant?nio Olinto ?vila da Silva
Bi?logo / Ocean?grafo
Instituto de Pesca (Fisheries Institute)
S?o Paulo, Brasil

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun May  7 09:24:21 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 7 May 2017 17:24:21 +1000
Subject: [R] setting the values of a secondary "y" axis
In-Reply-To: <CAE8g1gNJQ9fR-C9rAJgDVfsbFW1QaCmapF1Z5nMrnDQQuj2gfA@mail.gmail.com>
References: <CAE8g1gNJQ9fR-C9rAJgDVfsbFW1QaCmapF1Z5nMrnDQQuj2gfA@mail.gmail.com>
Message-ID: <CA+8X3fXHD3BYH6yTUF+Ut5C22O7z7mnHj=TaqpgUvs=9UMFb3g@mail.gmail.com>

Hi Antonio,
Have a look at twoord.plot (plotrix). It may make your repeated plots easier.

Jim


On Sun, May 7, 2017 at 7:50 AM, Antonio Silva <aolinto.lst at gmail.com> wrote:
> Hello
>
> I want to make a plot with two "y" axes. The labels at axis 4 should be the
> values from axis 2 multiplied by a scale factor (as 3.5).
>
> In the example below I draw axis 4 exactly as axis 2. But I could not find
> a way to multiply its values by 3.5 (e.g.).
>
> plot(rnorm(100,30,5))
> axis(4) # I'd like to have these values multiplied by a scale factor
>
> I will produce plots for different data sets in a looping and y values will
> vary so I  cannot "freeze" axis 4 labels because they (values and scale
> factor) will vary  from plot to plot.
>
> Thanks in advance for any help. All the best.
>
> Antonio
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ironholds at gmail.com  Sun May  7 08:36:52 2017
From: ironholds at gmail.com (Oliver Keyes)
Date: Sat, 6 May 2017 23:36:52 -0700
Subject: [R] Mac-specific encoding bug
Message-ID: <CADRwj9_RccEcRrJQFR4SR3BL6k98wuxQSwoPk1YZQysVK7g7xA@mail.gmail.com>

Hey all,

I've ran into a weird quirk on Mac platforms, which you can read fully
at https://github.com/Ironholds/urltools/issues/70

The long and the short of it is that one specific codepoint - \u04cf -
does not print in a UTF-8-y way by default, except when run through
cat(). Compare, for example:

encodeString("\u04cf")

and:

encodeString("\u044D")

Kevin Ushey was kind enough to bring his expertise, and found that it
may be a locale-specific problem as well as a Mac-specific problem,
because 'sourcetools' shows that there's no locale information for the
character. But this only appears in R - Python has it display
perfectly - so I'm kind of at a loss. Does anyone know what's going
on?

Best,

Oliver


From chalabi.elahe at yahoo.de  Sun May  7 17:44:44 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Sun, 7 May 2017 15:44:44 +0000 (UTC)
Subject: [R] visualization of KNN results in text classification
References: <104678756.7780076.1494171884561.ref@mail.yahoo.com>
Message-ID: <104678756.7780076.1494171884561@mail.yahoo.com>

Hi all,

Does anyone know what is the best way to visualize KNN(K nearest neighbor) results for classification of texts in R? 

My data set has only speeches and the type of the people for them which is control group or Alzheimer group, KNN classifies these two groups for me but I don't know how to plot the results. Does anyone know any special package?


Thanks for any help!
Elahe


From pdalgd at gmail.com  Sun May  7 22:51:01 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 7 May 2017 22:51:01 +0200
Subject: [R] Mac-specific encoding bug
In-Reply-To: <CADRwj9_RccEcRrJQFR4SR3BL6k98wuxQSwoPk1YZQysVK7g7xA@mail.gmail.com>
References: <CADRwj9_RccEcRrJQFR4SR3BL6k98wuxQSwoPk1YZQysVK7g7xA@mail.gmail.com>
Message-ID: <FE35F479-1ACB-4807-96E4-5F7BC07D8708@gmail.com>


> On 7 May 2017, at 08:36 , Oliver Keyes <ironholds at gmail.com> wrote:
> 
> Hey all,
> 
> I've ran into a weird quirk on Mac platforms, which you can read fully
> at https://github.com/Ironholds/urltools/issues/70
> 
> The long and the short of it is that one specific codepoint - \u04cf -
> does not print in a UTF-8-y way by default, except when run through
> cat(). Compare, for example:
> 
> encodeString("\u04cf")
> 
> and:
> 
> encodeString("\u044D")
> 
> Kevin Ushey was kind enough to bring his expertise, and found that it
> may be a locale-specific problem as well as a Mac-specific problem,
> because 'sourcetools' shows that there's no locale information for the
> character. But this only appears in R - Python has it display
> perfectly - so I'm kind of at a loss. Does anyone know what's going
> on?

Python being less careful than R? 

Basically, things get encoded if not known to be printable, and "Cyrillic Small Letter Palochka" is (it seems) not recorded as printable in the common utf-8 locales. From what I can google, it is used in Chechen and even then only as a postfix to certain characters.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From fsbmat at gmail.com  Mon May  8 03:12:54 2017
From: fsbmat at gmail.com (Fernando de Souza Bastos)
Date: Sun, 7 May 2017 22:12:54 -0300
Subject: [R] 3d graph with contours lines
Message-ID: <CAPTmxS17=UNy+u3xqR2fRQm-yzwL2nwEQo1ea741R6WxuY+xZQ@mail.gmail.com>

Can anyone help solve this issue?

I thank you!

http://stackoverflow.com/questions/43817083/3d-graph-with-contours-lines

Best,

Fernando de Souza Bastos
Assistant professor
Federal University of Vi?osa (UFV)
Campus UFV - Florestal
PhD Student in Statistics
Federal University of Minas Gerais (UFMG)
Cel: (31) 99751-6586

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon May  8 03:25:22 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 7 May 2017 18:25:22 -0700
Subject: [R] 3d graph with contours lines
In-Reply-To: <CAPTmxS17=UNy+u3xqR2fRQm-yzwL2nwEQo1ea741R6WxuY+xZQ@mail.gmail.com>
References: <CAPTmxS17=UNy+u3xqR2fRQm-yzwL2nwEQo1ea741R6WxuY+xZQ@mail.gmail.com>
Message-ID: <ED9C61D5-C766-485C-8CC9-B78A03599037@comcast.net>


> On May 7, 2017, at 6:12 PM, Fernando de Souza Bastos <fsbmat at gmail.com> wrote:
> 
> Can anyone help solve this issue?
> 
> I thank you!
> 
> http://stackoverflow.com/questions/43817083/3d-graph-with-contours-lines

plot3D is a package with a large selection of options.


> 
> Best,
> 
> Fernando de Souza Bastos
> Assistant professor
> Federal University of Vi?osa (UFV)
> Campus UFV - Florestal
> PhD Student in Statistics
> Federal University of Minas Gerais (UFMG)
> Cel: (31) 99751-6586
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ironholds at gmail.com  Mon May  8 00:31:45 2017
From: ironholds at gmail.com (Oliver Keyes)
Date: Sun, 7 May 2017 15:31:45 -0700
Subject: [R] Mac-specific encoding bug
In-Reply-To: <FE35F479-1ACB-4807-96E4-5F7BC07D8708@gmail.com>
References: <CADRwj9_RccEcRrJQFR4SR3BL6k98wuxQSwoPk1YZQysVK7g7xA@mail.gmail.com>
 <FE35F479-1ACB-4807-96E4-5F7BC07D8708@gmail.com>
Message-ID: <CADRwj98HvS-FuXKn=nauAF+x_HGxghtjw0ib8fqekHaNt-Hdmw@mail.gmail.com>

Interesting! The odd thing is it works perfectly well on Linux
platforms, at least - I guess it must be something to do with the Mac
locales. Thanks!

On Sun, May 7, 2017 at 1:51 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 7 May 2017, at 08:36 , Oliver Keyes <ironholds at gmail.com> wrote:
>>
>> Hey all,
>>
>> I've ran into a weird quirk on Mac platforms, which you can read fully
>> at https://github.com/Ironholds/urltools/issues/70
>>
>> The long and the short of it is that one specific codepoint - \u04cf -
>> does not print in a UTF-8-y way by default, except when run through
>> cat(). Compare, for example:
>>
>> encodeString("\u04cf")
>>
>> and:
>>
>> encodeString("\u044D")
>>
>> Kevin Ushey was kind enough to bring his expertise, and found that it
>> may be a locale-specific problem as well as a Mac-specific problem,
>> because 'sourcetools' shows that there's no locale information for the
>> character. But this only appears in R - Python has it display
>> perfectly - so I'm kind of at a loss. Does anyone know what's going
>> on?
>
> Python being less careful than R?
>
> Basically, things get encoded if not known to be printable, and "Cyrillic Small Letter Palochka" is (it seems) not recorded as printable in the common utf-8 locales. From what I can google, it is used in Chechen and even then only as a postfix to certain characters.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


From antedilber74 at gmail.com  Mon May  8 01:22:14 2017
From: antedilber74 at gmail.com (Ante Dilber)
Date: Mon, 8 May 2017 01:22:14 +0200
Subject: [R] Visualizing a graph in the coordinate system given by x using
	vanila R
Message-ID: <CAG3-2kpWxAq0AuaXc6K8YSKYzdtGMEjZ2JXJQp6EF5DFU9joQw@mail.gmail.com>

So I have the following problem, I need to write a function plotGraph(x , y)
in R with the following properties:

The argument x may be a matrix or data frame with two columns containing
coordinates of vertices of a graph. The argument y must be a quadratic
adjacency matrix that has as many rows and columns as x has rows. Values of
0 of NA stand for ?no connection?. Positive values stand for the connection
strength. Negative values are not allowed.

After that I need to visualize the resulting graph in the coordinate system
given by x, where connection strengths should be visualized by different
line widths and check inputs for validity.

Note: I can only use packages that are pre-loaded with R (e.g. graphics ,
grDevices).

Can someone please explain me how to do that ? I understand that y is the
information about the nodes in the network and their connections (vertices
& edges), x is the information about the network layout, i.e. where to
place the nodes. But I don't know how to do the visualization part with the
different connection strenghts ?

Thanks in advance :)

	[[alternative HTML version deleted]]


From gregorypropf at globo.com  Mon May  8 04:27:28 2017
From: gregorypropf at globo.com (gregorypropf)
Date: Mon, 8 May 2017 02:27:28 +0000
Subject: [R] (no subject)
Message-ID: <5C58727E-E6E5-4C14-F618-491A5A615701@globo.com>

hiya R



http://dev.webbrand-media.net/topframe.php?action=2xxx631r2yaqtdra




gregorypropf


From drjimlemon at gmail.com  Mon May  8 05:07:04 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 8 May 2017 13:07:04 +1000
Subject: [R] Visualizing a graph in the coordinate system given by x
 using vanila R
In-Reply-To: <CAG3-2kpWxAq0AuaXc6K8YSKYzdtGMEjZ2JXJQp6EF5DFU9joQw@mail.gmail.com>
References: <CAG3-2kpWxAq0AuaXc6K8YSKYzdtGMEjZ2JXJQp6EF5DFU9joQw@mail.gmail.com>
Message-ID: <CA+8X3fVE9SCrSvNLUwjG4-W9YVrPPMri_b5YGzqWiNqHky9Yeg@mail.gmail.com>

Hi Ante,
As this is a homework problem, you will probably get a number of
negative replies. You might want to look at the color.scale.lines
function in the plotrix package. Perhaps you will find some clues in
the code.

Jim

On Mon, May 8, 2017 at 9:22 AM, Ante Dilber <antedilber74 at gmail.com> wrote:
> So I have the following problem, I need to write a function plotGraph(x , y)
> in R with the following properties:
>
> The argument x may be a matrix or data frame with two columns containing
> coordinates of vertices of a graph. The argument y must be a quadratic
> adjacency matrix that has as many rows and columns as x has rows. Values of
> 0 of NA stand for ?no connection?. Positive values stand for the connection
> strength. Negative values are not allowed.
>
> After that I need to visualize the resulting graph in the coordinate system
> given by x, where connection strengths should be visualized by different
> line widths and check inputs for validity.
>
> Note: I can only use packages that are pre-loaded with R (e.g. graphics ,
> grDevices).
>
> Can someone please explain me how to do that ? I understand that y is the
> information about the nodes in the network and their connections (vertices
> & edges), x is the information about the network layout, i.e. where to
> place the nodes. But I don't know how to do the visualization part with the
> different connection strenghts ?
>
> Thanks in advance :)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Mon May  8 11:09:44 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 8 May 2017 05:09:44 -0400
Subject: [R] How do I use R to build a dictionary of proper nouns?
In-Reply-To: <HK2PR0301MB118716AC19C4665974DD6CE0A4EE0@HK2PR0301MB1187.apcprd03.prod.outlook.com>
References: <SIXPR03MB0893C2F8CC312827E4FAB52DA4EB0@SIXPR03MB0893.apcprd03.prod.outlook.com>
 <D461C473-54B7-4067-98E4-6E18D6327677@utoronto.ca>
 <HK2PR0301MB118716AC19C4665974DD6CE0A4EE0@HK2PR0301MB1187.apcprd03.prod.outlook.com>
Message-ID: <FF386E39-C239-47EE-AE29-5824078AF0EA@utoronto.ca>

Your workflow is not clear to me, so I can't give any specific advice.

1: I don't understand what you need. Do you need the column names changed? They correspond to the matched
   words.

2: How was the vector dictionary_word created? These are (mostly) stemmed nouns, but some of them are two or even three words? Did you do this by hand? But this also contains "cmp" which is not a stemmed word, or "particl", or "recoveri" which is not correctly stemmed. This doesn't look promising, I think at least you will need to place hyphens between the words, but since you are using stemmed words this will be difficult. 

3: Since the default tokenizer is "words", I think the two-word and three-word elements of the dictionary_word vector will not be found. They don't exist as tokens.

4: Don't use "list" as a variable name.

In summary - I think your problems have to do with stemming and tokenizing and not with formatting the output of DocumentTermMatrix(). I don't think tm has functions to produce stemmed multi-word tokens like the elements in your dictionary_word vector. You may need to do the analysis with your own functions, using regular expressions.


B.


> On May 8, 2017, at 3:56 AM, ? ? <yarmi1224 at hotmail.com> wrote:
> 
> Hi Steipe?
> Thanks for your recommend.
> I have used the DocumentTermMatrix function of tm package to try. 
> But I prefer the matrix result shows the frequency of the dictionary word.
> Is there any way to do?  
> The following are my code and result?
> 
> dictionary_word <- c("neutral", "abras particl", "acid", "apparatus", "back film", "basic", "carrier", "chemic", "chromat confoc", "clean system", "cmp", "compens type", "compress", "comsum", "control system", "down pressur", "dresser condition", "detect system", "flow rate control", "fractal type", "groov", "hard", "improv type", "infrar", "laser confoc", "layer", "measur system", "micro stuctur", "monitor system", "multi layer", "none-por", "nonwoven pad", "pad", "pad applic", "pad condit system", "pad materi", "pad properti", "pad structur", "ph sensor", "planet type", "plate", "plat", "poisson ratio", "polish head", "polish system", "polym pad", "polyurethan pad", "porous", "process paramet", "process path", "process time", "recoveri", "rotat speed", "rough", "scatter", "semiconductor cmp", "sensor", "signal acceptor", "singl layer", "slurri", "slurri flow rate", "slurri ph valu", "slurri stirrer", "slurri suppli system", "slurri temperatur", "slurri weight percentag", "storag cmp", "stylus profil", "substrat cmp", "thick", "transfer robot", "ultrason", "urethan pad", "wafer cassett", "wafer transfer system", "white light interferomet", "young modulus")
> 
> list<-inspect(DocumentTermMatrix(corpus_tm,
>                                  list(weighting =weightTf,
>                                       dictionary = dictionary_word)))
> 
> <keywords of dictionary.PNG>
> 
> 
> ???: Boris Steipe <boris.steipe at utoronto.ca>
> ????: 2017?5?5? ?? 04:39
> ???: ? ?
> ??: r-help at r-project.org
> ??: Re: [R] How do I use R to build a dictionary of proper nouns?
>  
> Did you try using the table() function, possibly in combination with sort() or rank()?
> 
> 
> Consider:
> 
> myNouns <- c("proper", "nouns", "domain", "ontology", "dictionary",
>              "dictionary", "corpus", "patent", "files", "proper", "nouns",
>              "word", "frequency", "file", "preprocess", "corpus", "proper",
>              "nouns", "domain", "ontology", "idea", "nouns", "dictionary",
>              "dictionary", "corpus", "attachments", "texts", "corpus",
>              "preprocesses", "proper", "nouns")
> 
> myNounFrequencies <- table(myNouns)
> myNounFrequencies
> 
> myNounFrequencies <- sort(myNounFrequencies, decreasing = TRUE)
> myNounFrequencies
> 
> which(names(myNounFrequencies) == "corpus")
> 
> 
> 
> 
> 
> > On May 5, 2017, at 1:58 AM, ? ? <yarmi1224 at hotmail.com> wrote:
> > 
> > ? ? ????? OneDrive ??????????????????
> > 
> > 
> > <https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
> 
> 
> 
> > [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
> > 
> > 2.corpus_patent text.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
> 
> 
> 
> > 
> > <https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
> 
> 
> 
> > [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
> > 
> > 3ontology_proper nouns keywords.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
> 
> 
> 
> > 
> > <https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
> 
> 
> 
> > [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
> > 
> > 1.patents.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
> 
> 
> 
> > 
> > 
> > 
> > 
> > Hi :
> > 
> > I want to do patents text mining in R.
> > I need to use the proper nouns of domain ontology to build a dictionary.
> > Then use the dictionary to analysis my corpus of patent files.
> > I want to calculate the proper nouns and get the word frequency that appears in each file.
> > 
> > Now I have done the preprocess for the corpus and extract the proper nouns from domain ontology.
> > But I have no idea how to build a proper nouns dictionary and use the dictionary to analysis my corpus.
> > 
> > The Attachments are my texts, corpus preprocesses and proper nouns.
> > 
> > Thanks.
> > 
> >        [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> R-help Info Page - Homepage - SfS ? Seminar for Statistics
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...
> 
> 
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From soni.archit1989 at gmail.com  Mon May  8 12:30:26 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Mon, 8 May 2017 16:00:26 +0530
Subject: [R] Copy and Rename Folder in same directory
Message-ID: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>

Hello,

Forgive me to ask this kind of naive question.

But it would be of immense help if you could help me suggesting a way to
copy a folder in the same directory and paste it in the same directory with
different name.

Ex:

C:/Folder A -- C:/Folder A_B

Contents should be copied as is.

Thanks for reading and thanks in advance!

Archit

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Mon May  8 12:36:34 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Mon, 8 May 2017 06:36:34 -0400
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
Message-ID: <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>

Hi,

Checkout all of the functions for file/directory management under ?files  (note the plural).

Cheers,
Ben


> On May 8, 2017, at 6:30 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
> 
> Hello,
> 
> Forgive me to ask this kind of naive question.
> 
> But it would be of immense help if you could help me suggesting a way to
> copy a folder in the same directory and paste it in the same directory with
> different name.
> 
> Ex:
> 
> C:/Folder A -- C:/Folder A_B
> 
> Contents should be copied as is.
> 
> Thanks for reading and thanks in advance!
> 
> Archit
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From soni.archit1989 at gmail.com  Mon May  8 12:37:47 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Mon, 8 May 2017 16:07:47 +0530
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
 <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
Message-ID: <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>

Thanks Ben. :)

On May 8, 2017 16:06, "Ben Tupper" <btupper at bigelow.org> wrote:

> Hi,
>
> Checkout all of the functions for file/directory management under ?files
> (note the plural).
>
> Cheers,
> Ben
>
>
> > On May 8, 2017, at 6:30 AM, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
> >
> > Hello,
> >
> > Forgive me to ask this kind of naive question.
> >
> > But it would be of immense help if you could help me suggesting a way to
> > copy a folder in the same directory and paste it in the same directory
> with
> > different name.
> >
> > Ex:
> >
> > C:/Folder A -- C:/Folder A_B
> >
> > Contents should be copied as is.
> >
> > Thanks for reading and thanks in advance!
> >
> > Archit
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>
>
>

	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Mon May  8 12:59:32 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Mon, 8 May 2017 16:29:32 +0530
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
 <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
 <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>
Message-ID: <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>

Hey Ben,

I tried this,

# identify the folders
current.folder <- "C:/Where my files currently live"
new.folder <- "H:/Where I want my files to be copied to"

# find the files that you want
list.of.files <- list.files(current.folder, "SDM\\.tif$",full.names=T)

# copy the files to the new folder
file.copy(list.of.files, new.folder)

But i am still getting FALSE and files are not getting copied from the
folder. However,if I give a single file name it copies that file to new
folder.

Any thoughts ?

On Mon, May 8, 2017 at 4:07 PM, Archit Soni <soni.archit1989 at gmail.com>
wrote:

> Thanks Ben. :)
>
> On May 8, 2017 16:06, "Ben Tupper" <btupper at bigelow.org> wrote:
>
>> Hi,
>>
>> Checkout all of the functions for file/directory management under ?files
>> (note the plural).
>>
>> Cheers,
>> Ben
>>
>>
>> > On May 8, 2017, at 6:30 AM, Archit Soni <soni.archit1989 at gmail.com>
>> wrote:
>> >
>> > Hello,
>> >
>> > Forgive me to ask this kind of naive question.
>> >
>> > But it would be of immense help if you could help me suggesting a way to
>> > copy a folder in the same directory and paste it in the same directory
>> with
>> > different name.
>> >
>> > Ex:
>> >
>> > C:/Folder A -- C:/Folder A_B
>> >
>> > Contents should be copied as is.
>> >
>> > Thanks for reading and thanks in advance!
>> >
>> > Archit
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>>
>>
>>
>>


-- 
Regards
Archit

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon May  8 13:06:49 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 8 May 2017 07:06:49 -0400
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
 <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
 <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>
 <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>
Message-ID: <4ad1ae64-dfcc-0b07-675b-1a6e8ed11bbe@gmail.com>

On 08/05/2017 6:59 AM, Archit Soni wrote:
> Hey Ben,
>
> I tried this,
>
> # identify the folders
> current.folder <- "C:/Where my files currently live"
> new.folder <- "H:/Where I want my files to be copied to"
>
> # find the files that you want
> list.of.files <- list.files(current.folder, "SDM\\.tif$",full.names=T)
>
> # copy the files to the new folder
> file.copy(list.of.files, new.folder)
>
> But i am still getting FALSE and files are not getting copied from the
> folder. However,if I give a single file name it copies that file to new
> folder.
>
> Any thoughts ?

Getting FALSE where?

Does list.of.files look right?

If it contains any directories, you'll want "recursive = TRUE" in 
file.copy().

Duncan Murdoch


From btupper at bigelow.org  Mon May  8 13:12:30 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Mon, 8 May 2017 07:12:30 -0400
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
 <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
 <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>
 <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>
Message-ID: <670394EB-7702-4E21-847D-B4938510B5CC@bigelow.org>

My eye gets drawn immediately to file.rename() - did you give that a shake?



> On May 8, 2017, at 6:59 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
> 
> Hey Ben,
> 
> I tried this,
> 
> # identify the folders
> current.folder <- "C:/Where my files currently live"
> new.folder <- "H:/Where I want my files to be copied to"
>  
> # find the files that you want
> list.of.files <- list.files(current.folder, "SDM\\.tif$",full.names=T)
>  
> # copy the files to the new folder
> file.copy(list.of.files, new.folder)
> 
> But i am still getting FALSE and files are not getting copied from the folder. However,if I give a single file name it copies that file to new folder.
> 
> Any thoughts ?
> 
> On Mon, May 8, 2017 at 4:07 PM, Archit Soni <soni.archit1989 at gmail.com <mailto:soni.archit1989 at gmail.com>> wrote:
> Thanks Ben. :)
> 
> On May 8, 2017 16:06, "Ben Tupper" <btupper at bigelow.org <mailto:btupper at bigelow.org>> wrote:
> Hi,
> 
> Checkout all of the functions for file/directory management under ?files  (note the plural).
> 
> Cheers,
> Ben
> 
> 
> > On May 8, 2017, at 6:30 AM, Archit Soni <soni.archit1989 at gmail.com <mailto:soni.archit1989 at gmail.com>> wrote:
> >
> > Hello,
> >
> > Forgive me to ask this kind of naive question.
> >
> > But it would be of immense help if you could help me suggesting a way to
> > copy a folder in the same directory and paste it in the same directory with
> > different name.
> >
> > Ex:
> >
> > C:/Folder A -- C:/Folder A_B
> >
> > Contents should be copied as is.
> >
> > Thanks for reading and thanks in advance!
> >
> > Archit
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org <http://www.bigelow.org/>
> 
> 
> 
> 
> 
> 
> -- 
> Regards
> Archit

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org




	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Mon May  8 13:12:38 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Mon, 8 May 2017 16:42:38 +0530
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <4ad1ae64-dfcc-0b07-675b-1a6e8ed11bbe@gmail.com>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
 <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
 <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>
 <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>
 <4ad1ae64-dfcc-0b07-675b-1a6e8ed11bbe@gmail.com>
Message-ID: <CAJ7HxByUrUghogCHuskyUDWkKK1+60OiNpRoL1EOZgyQ-w0wSw@mail.gmail.com>

Hey Duncan,

There are no sub folders in the folder which its content i want to copy.
Just 4 files.

list.files('Old Folder Path') gives me the files in this folder.

I am running this line that gives me False when running for all the 4 files

file.copy(list.files(oldFolder),newFolder,recursive = TRUE)



On Mon, May 8, 2017 at 4:36 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 08/05/2017 6:59 AM, Archit Soni wrote:
>
>> Hey Ben,
>>
>> I tried this,
>>
>> # identify the folders
>> current.folder <- "C:/Where my files currently live"
>> new.folder <- "H:/Where I want my files to be copied to"
>>
>> # find the files that you want
>> list.of.files <- list.files(current.folder, "SDM\\.tif$",full.names=T)
>>
>> # copy the files to the new folder
>> file.copy(list.of.files, new.folder)
>>
>> But i am still getting FALSE and files are not getting copied from the
>> folder. However,if I give a single file name it copies that file to new
>> folder.
>>
>> Any thoughts ?
>>
>
> Getting FALSE where?
>
> Does list.of.files look right?
>
> If it contains any directories, you'll want "recursive = TRUE" in
> file.copy().
>
> Duncan Murdoch
>
>


-- 
Regards
Archit

	[[alternative HTML version deleted]]


From soni.archit1989 at gmail.com  Mon May  8 13:14:30 2017
From: soni.archit1989 at gmail.com (Archit Soni)
Date: Mon, 8 May 2017 16:44:30 +0530
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <670394EB-7702-4E21-847D-B4938510B5CC@bigelow.org>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
 <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
 <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>
 <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>
 <670394EB-7702-4E21-847D-B4938510B5CC@bigelow.org>
Message-ID: <CAJ7HxBxE1quMtkYxyarhYcNc=bm=Li3hZwTjvDSO6+mv3YsFzQ@mail.gmail.com>

No Ben, I want to copy the contents and have the original file is as master
file.

On Mon, May 8, 2017 at 4:42 PM, Ben Tupper <btupper at bigelow.org> wrote:

> My eye gets drawn immediately to file.rename() - did you give that a shake?
>
>
>
> On May 8, 2017, at 6:59 AM, Archit Soni <soni.archit1989 at gmail.com> wrote:
>
> Hey Ben,
>
> I tried this,
>
> # identify the folders
> current.folder <- "C:/Where my files currently live"
> new.folder <- "H:/Where I want my files to be copied to"
>
> # find the files that you want
> list.of.files <- list.files(current.folder, "SDM\\.tif$",full.names=T)
>
> # copy the files to the new folder
> file.copy(list.of.files, new.folder)
>
> But i am still getting FALSE and files are not getting copied from the
> folder. However,if I give a single file name it copies that file to new
> folder.
>
> Any thoughts ?
>
> On Mon, May 8, 2017 at 4:07 PM, Archit Soni <soni.archit1989 at gmail.com>
> wrote:
>
>> Thanks Ben. :)
>>
>> On May 8, 2017 16:06, "Ben Tupper" <btupper at bigelow.org> wrote:
>>
>>> Hi,
>>>
>>> Checkout all of the functions for file/directory management under
>>> ?files  (note the plural).
>>>
>>> Cheers,
>>> Ben
>>>
>>>
>>> > On May 8, 2017, at 6:30 AM, Archit Soni <soni.archit1989 at gmail.com>
>>> wrote:
>>> >
>>> > Hello,
>>> >
>>> > Forgive me to ask this kind of naive question.
>>> >
>>> > But it would be of immense help if you could help me suggesting a way
>>> to
>>> > copy a folder in the same directory and paste it in the same directory
>>> with
>>> > different name.
>>> >
>>> > Ex:
>>> >
>>> > C:/Folder A -- C:/Folder A_B
>>> >
>>> > Contents should be copied as is.
>>> >
>>> > Thanks for reading and thanks in advance!
>>> >
>>> > Archit
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html <http://www.r-project.org/posting-guide.html>
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> Ben Tupper
>>> Bigelow Laboratory for Ocean Sciences
>>> 60 Bigelow Drive, P.O. Box 380
>>> East Boothbay, Maine 04544
>>> http://www.bigelow.org
>>>
>>>
>>>
>>>
>
>
> --
> Regards
> Archit
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>
>
>


-- 
Regards
Archit

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon May  8 13:54:47 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 8 May 2017 07:54:47 -0400
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <CAJ7HxByUrUghogCHuskyUDWkKK1+60OiNpRoL1EOZgyQ-w0wSw@mail.gmail.com>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
 <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
 <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>
 <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>
 <4ad1ae64-dfcc-0b07-675b-1a6e8ed11bbe@gmail.com>
 <CAJ7HxByUrUghogCHuskyUDWkKK1+60OiNpRoL1EOZgyQ-w0wSw@mail.gmail.com>
Message-ID: <2875be7e-c72f-dff1-316c-e6c8091d136d@gmail.com>

On 08/05/2017 7:12 AM, Archit Soni wrote:
> Hey Duncan,
>
> There are no sub folders in the folder which its content i want to copy.
> Just 4 files.

Okay, so you won't need "recursive = TRUE".

>
> list.files('Old Folder Path') gives me the files in this folder.

That's not the same as you typed below.  In the script below, does 
list.of.files contain the right names, with fully specified paths?

>
> I am running this line that gives me False when running for all the 4 files
>
> file.copy(list.files(oldFolder),newFolder,recursive = TRUE)

The lack of full.names could cause the problem here, if that's not just 
a typo in this message.

Duncan Murdoch


>
>
>
> On Mon, May 8, 2017 at 4:36 PM, Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 08/05/2017 6:59 AM, Archit Soni wrote:
>
>         Hey Ben,
>
>         I tried this,
>
>         # identify the folders
>         current.folder <- "C:/Where my files currently live"
>         new.folder <- "H:/Where I want my files to be copied to"
>
>         # find the files that you want
>         list.of.files <- list.files(current.folder,
>         "SDM\\.tif$",full.names=T)
>
>         # copy the files to the new folder
>         file.copy(list.of.files, new.folder)
>
>         But i am still getting FALSE and files are not getting copied
>         from the
>         folder. However,if I give a single file name it copies that file
>         to new
>         folder.
>
>         Any thoughts ?
>
>
>     Getting FALSE where?
>
>     Does list.of.files look right?
>
>     If it contains any directories, you'll want "recursive = TRUE" in
>     file.copy().
>
>     Duncan Murdoch
>
>
>
>
> --
> Regards
> Archit


From chalabi.elahe at yahoo.de  Mon May  8 13:59:06 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Mon, 8 May 2017 11:59:06 +0000 (UTC)
Subject: [R] visualization of KNN results in text classification
In-Reply-To: <104678756.7780076.1494171884561@mail.yahoo.com>
References: <104678756.7780076.1494171884561.ref@mail.yahoo.com>
 <104678756.7780076.1494171884561@mail.yahoo.com>
Message-ID: <539751353.8870258.1494244746981@mail.yahoo.com>

Any idea?! 

    On Sunday, May 7, 2017 5:56 PM, Elahe chalabi via R-help <r-help at r-project.org> wrote:
 

 Hi all,

Does anyone know what is the best way to visualize KNN(K nearest neighbor) results for classification of texts in R? 

My data set has only speeches and the type of the people for them which is control group or Alzheimer group, KNN classifies these two groups for me but I don't know how to plot the results. Does anyone know any special package?


Thanks for any help!
Elahe

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon May  8 15:29:57 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 08 May 2017 13:29:57 +0000
Subject: [R] visualization of KNN results in text classification
In-Reply-To: <539751353.8870258.1494244746981@mail.yahoo.com>
References: <104678756.7780076.1494171884561.ref@mail.yahoo.com>
 <104678756.7780076.1494171884561@mail.yahoo.com>
 <539751353.8870258.1494244746981@mail.yahoo.com>
Message-ID: <CAM_vjun7PiG+onbMJvCjP6UgsyDLz2U0J-RXcdwKtyC-zdbgXA@mail.gmail.com>

Well, probably you need to first tell us why none of the suggestions that
come up when you google "plot KNN results in R" work for you, and what
other kind of plot you are trying to produce, and what you have tried, so
we can offer advice that helps.

As it is, we have no idea what you are after.

Sarah

On Mon, May 8, 2017 at 9:21 AM Elahe chalabi via R-help <
r-help at r-project.org> wrote:

> Any idea?!
>
>     On Sunday, May 7, 2017 5:56 PM, Elahe chalabi via R-help <
> r-help at r-project.org> wrote:
>
>
>  Hi all,
>
> Does anyone know what is the best way to visualize KNN(K nearest neighbor)
> results for classification of texts in R?
>
> My data set has only speeches and the type of the people for them which is
> control group or Alzheimer group, KNN classifies these two groups for me
> but I don't know how to plot the results. Does anyone know any special
> package?
>
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Mon May  8 15:32:16 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Mon, 8 May 2017 16:32:16 +0300
Subject: [R] visualization of KNN results in text classification
In-Reply-To: <104678756.7780076.1494171884561@mail.yahoo.com>
References: <104678756.7780076.1494171884561.ref@mail.yahoo.com>
 <104678756.7780076.1494171884561@mail.yahoo.com>
Message-ID: <2F295203-5516-41C4-81C9-F26BCD893A9E@gmail.com>

As far as I know, kNN groups by Eucledian distance. So, you need numerical data as input. You said your dataset has only ?speeches? and ?type of people?. Are these input? or one of them is input and the latter one is output? Type of people should be a factor variable (I guess). I don?t know how you represent ?speech? in your dataset. As character or numerical representation of a feature? If you send a minimal example of the problem, we can help you. Please, read posting guide.

> On 7 May 2017, at 18:44, Elahe chalabi via R-help <r-help at r-project.org> wrote:
> 
> Hi all,
> 
> Does anyone know what is the best way to visualize KNN(K nearest neighbor) results for classification of texts in R? 
> 
> My data set has only speeches and the type of the people for them which is control group or Alzheimer group, KNN classifies these two groups for me but I don't know how to plot the results. Does anyone know any special package?
> 
> 
> Thanks for any help!
> Elahe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davidsmi at microsoft.com  Mon May  8 21:57:16 2017
From: davidsmi at microsoft.com (David Smith)
Date: Mon, 8 May 2017 19:57:16 +0000
Subject: [R] Revolutions blog: April 2017 roundup
Message-ID: <CY1PR0301MB210566EFB2351DC12F5CF505C8EE0@CY1PR0301MB2105.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests
have written about R every weekday at the Revolutions blog
(http://blog.revolutionanalytics.com) and every month I post a summary
of articles from the previous month of particular interest to readers
of r-help.

In case you missed them, here are some articles related to R from the
month of April:

The rxExecBy function (in Microsoft R Server) deploys "embarassingly
parallel" problems to remote compute services:
http://blog.revolutionanalytics.com/2017/04/rxexecby.html

An interesting population map, reminiscent of a Joy Division album
cover, shows Europe's population density using just 14 lines of R
code:
http://blog.revolutionanalytics.com/2017/04/where-europe-lives.html

Financial startup dv01 uses R to bring greater transparency to
consumer lending:
http://blog.revolutionanalytics.com/2017/04/dv01-uses-r.html

Reproducibility with knitr: how to use the "checkpoint" package with
the "Knit" feature in RStudio:
http://blog.revolutionanalytics.com/2017/04/using-checkpoint-with-knitr-and-rstudio.html

A summary of the improvements in R 3.4.0:
http://blog.revolutionanalytics.com/2017/04/r-340-now-available.html

Slides from my recent talk, "Reproducible Data Science with R":
http://blog.revolutionanalytics.com/2017/04/reproducible-data-science-with-r.html

SQL Server 2017 will support both R and Python for in-database computation:
http://blog.revolutionanalytics.com/2017/04/sql-2017-python.html

New features in Microsoft R Server 9.1, now available:
http://blog.revolutionanalytics.com/2017/04/microsoft-r-server-91-now-available.html

A sentiment analysis of Warren Buffett's letters to shareholders:
http://blog.revolutionanalytics.com/2017/04/warren-buffet-sentiment.html

A workshop on Artificial Intelligence, featuring Microsoft R, is being
held by Microsoft in Seattle on May 9:
http://blog.revolutionanalytics.com/2017/04/ai-workshop-seattle.html

The interactive website Seeing Theory demonstrates statistical
principles via simulation:
http://blog.revolutionanalytics.com/2017/04/seeing-theory.html

Ben Marwick reports on R topics at the 2017 Society of American
Archaeology meeting:
http://blog.revolutionanalytics.com/2017/04/r-is-for-archaeology.html

The checkpoint package adds new features for managing package versions
in service of reproducibility:
http://blog.revolutionanalytics.com/2017/04/checkpoint-new-features.html

There were several R-related announcement at the online Data Amp event
on April 19. A replay is now available.
http://blog.revolutionanalytics.com/2017/04/data-amp-april-19.html

The vtreat package helps statisticians prepare real-world data for
analysis: http://blog.revolutionanalytics.com/2017/04/vtreat.html

Ma?lle Salmon used R to create a collage of R users participating in
the #rstats hashtag on Twitter:
http://blog.revolutionanalytics.com/2017/04/the-faces-of-r-analyzed-with-r.html

Microsoft R Open 3.3.3 (based on R 3.3.3) is now available:
http://blog.revolutionanalytics.com/2017/04/microsoft-r-open-333-now-available.html

A link between rational functions and OLS regression:
http://blog.revolutionanalytics.com/2017/04/fitting-rational-functions-with-lm.html

Use the sqlrutils package in Microsoft R Client to publish R functions
as stored procedures in SQL Server:
http://blog.revolutionanalytics.com/2017/04/sqlrutils.html

Ranking of the most popular languages for Data Scientists/Engineers,
from the StackOverflow Developer Survey:
http://blog.revolutionanalytics.com/2017/04/stackoverflow-developer-survey.html

Slides and code from the tutorial "Using R for Scalable Data
Analytics: Single Machines to Spark Clusters":
http://blog.revolutionanalytics.com/2017/03/tutorial-scaling-r.html

And some general interest stories (not necessarily related to R):

* A Turing Machine, implemented in PowerPoint:
  http://blog.revolutionanalytics.com/2017/04/because-its-friday-powerpoint-punchcards.html

* Secrets of the lines of the London Underground:
http://blog.revolutionanalytics.com/2017/04/because-its-friday-secrets-of-the-london-underground.html

* Reddit's "r/place" communal art experiment:
http://blog.revolutionanalytics.com/2017/04/because-its-friday-art-collective.html

* How "Elite: Dangerous" simulated an entire galaxy for a video game:
http://blog.revolutionanalytics.com/2017/03/because-its-friday-universe-time-lapse.html

As always, thanks for the comments and please keep sending suggestions
to me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From pdalgd at gmail.com  Mon May  8 15:29:02 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 8 May 2017 15:29:02 +0200
Subject: [R] Copy and Rename Folder in same directory
In-Reply-To: <2875be7e-c72f-dff1-316c-e6c8091d136d@gmail.com>
References: <CAJ7HxBwya-pg8zZanC6r1FpxhtPyWx9DBx5zLPdSJrqTk5MOqA@mail.gmail.com>
 <93795BCE-2DE1-418A-8A32-4CD987DC1ACF@bigelow.org>
 <CAJ7HxBwNZ7TL6Z5mqDcZUbNb+0uN8WWrVGqyfjgX4UFF+i6g7w@mail.gmail.com>
 <CAJ7HxBzC--OM5phPaS76ubPK96yShp=Xh_A9QwCm8XnTzyrBAQ@mail.gmail.com>
 <4ad1ae64-dfcc-0b07-675b-1a6e8ed11bbe@gmail.com>
 <CAJ7HxByUrUghogCHuskyUDWkKK1+60OiNpRoL1EOZgyQ-w0wSw@mail.gmail.com>
 <2875be7e-c72f-dff1-316c-e6c8091d136d@gmail.com>
Message-ID: <8116F376-717A-44C9-8333-340B2372FFCA@gmail.com>


> On 8 May 2017, at 13:54 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 08/05/2017 7:12 AM, Archit Soni wrote:
>> Hey Duncan,
>> 
>> There are no sub folders in the folder which its content i want to copy.
>> Just 4 files.
> 
> Okay, so you won't need "recursive = TRUE".


Um, wouldn't it work just to do

file.copy(old.folder, new.folder, recursive=TRUE)

Otherwise, I suspect you need to ensure that the destination exists:

dir.create(new.folder)
file.copy(list.of.files, new.folder)

-pd


> 
>> 
>> list.files('Old Folder Path') gives me the files in this folder.
> 
> That's not the same as you typed below.  In the script below, does list.of.files contain the right names, with fully specified paths?
> 
>> 
>> I am running this line that gives me False when running for all the 4 files
>> 
>> file.copy(list.files(oldFolder),newFolder,recursive = TRUE)
> 
> The lack of full.names could cause the problem here, if that's not just a typo in this message.
> 
> Duncan Murdoch
> 
> 
>> 
>> 
>> 
>> On Mon, May 8, 2017 at 4:36 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>> 
>>    On 08/05/2017 6:59 AM, Archit Soni wrote:
>> 
>>        Hey Ben,
>> 
>>        I tried this,
>> 
>>        # identify the folders
>>        current.folder <- "C:/Where my files currently live"
>>        new.folder <- "H:/Where I want my files to be copied to"
>> 
>>        # find the files that you want
>>        list.of.files <- list.files(current.folder,
>>        "SDM\\.tif$",full.names=T)
>> 
>>        # copy the files to the new folder
>>        file.copy(list.of.files, new.folder)
>> 
>>        But i am still getting FALSE and files are not getting copied
>>        from the
>>        folder. However,if I give a single file name it copies that file
>>        to new
>>        folder.
>> 
>>        Any thoughts ?
>> 
>> 
>>    Getting FALSE where?
>> 
>>    Does list.of.files look right?
>> 
>>    If it contains any directories, you'll want "recursive = TRUE" in
>>    file.copy().
>> 
>>    Duncan Murdoch
>> 
>> 
>> 
>> 
>> --
>> Regards
>> Archit
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From abo_dlsh at hotmail.com  Mon May  8 16:56:21 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Mon, 8 May 2017 14:56:21 +0000
Subject: [R] Joining tables with different order and matched values
Message-ID: <CY4PR15MB130291337499E7A8300D926BEFEE0@CY4PR15MB1302.namprd15.prod.outlook.com>

Hi All ..,


I have 2 tables and I'm trying to have some information from the 1st table to appear in the second table with different order.


For Example, let's say this is my 1st table :-



Drug name           indications

 Ibuprofen                Pain

 Simvastatin            hyperlipidemia

losartan                   hypertension



my 2nd table is in different order for the 1st column :-


Drug name       indications


Simvastatin

losartan

Ibuprofen

Metformin


I wish to see the indication of each drug in my 2nd table subsisted from the information in my 1st table so the final table

would be like this


Drug name       indications


Simvastatin     hyperlipidemia

losartan           hypertension

Ibuprofen       pain

Metformin    N/A


I have been trying to use Sqldf package and right join function but not able to formulate the correct syntax.


I'm also trying to identify rows contain at least one shared value  in a dataset called 'Values":


>Values

A             B

1,2,5       3,8,7

2,4,6       7,6,3



Columns A & B in the first row do not share any value while in the 2nd row they have a single shared value which is 6.

The result I wish to see :-


A             B             shared values

1,2,5       3,8,7             N/A

2,4,6       7,6,3               6


I tried this syntax : SharedValues <- Values$A == Values$B but this returns logical results and what I wish to have

is a new data frame including the new vector "shared values" showing the information exactly as above.




Kind Regards






	[[alternative HTML version deleted]]


From smits.gerard.j at gmail.com  Tue May  9 00:48:11 2017
From: smits.gerard.j at gmail.com (Gerard Smits)
Date: Mon, 8 May 2017 15:48:11 -0700
Subject: [R] passing arguments to simple plotting program.
Message-ID: <809F9C89-132B-4904-9B31-34E6C2CEDD4D@gmail.com>

Hi All,

I thought I?d try to get a function working instead of block copying code and editing. My backorund is more SAS, so using a SAS Macro would be easy, but not so lucky with R functions.


R being used on Mac Sierra 10.12.4:

R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)


resp<-read.csv("//users//gerard//gs//r_work//xyz.csv", header = TRUE)

v5  <-subset(resp, subset=visit==5 & pp==1)

plot_f1 <-function(n1,n2,n3) {
  attach(v8)
  par(oma=c(2,2,2,2))
  boxplot(formula = d_comp ~ rx_grp, 
          main="Figure 2\nChange in Composite Score at Visit 5 (Day 31)\nPer Protocol Population",
          ylim=c(-10,5),
          names=c('Placebo(N=n1)  ',
    	          'Low Dose(N=n2) ',
  		  'High Dose(N=n3)'),
          ylab='Change from Baseline')
  abline(h=c(0), col="lightgray")
}

plot_f1(n1=114, n2=119, n3=116)

The above is a simplified example where I am trying to pass 3 arguments, n1-n3, to be shown in the x-axis tables,  Instead of the numbers, I get the literal n1, n2, n3.

Any help appreciated.

Thanks,

Gerard




	[[alternative HTML version deleted]]


From leobriant at gmail.com  Tue May  9 06:33:25 2017
From: leobriant at gmail.com (Brian Leo)
Date: Tue, 9 May 2017 14:33:25 +1000
Subject: [R] Extract cells and their adjacent cells that may appear anywhere
	in a dataframe.
Message-ID: <CAJi8COuGN3c7y-hXTqe-4jRGS9Y7XcBNxrTQ72j2SKa7WtpPpQ@mail.gmail.com>

Hello,

I have a dataframe that contains information about vegetation cover and
percent coverage, collected using a quadrat.  The dataframe is set up so
that each row represents a single quadrat.  If there are multiple species
within one quadrat, they are all listed within the same row with respective
% coverage always following in next column.  Here is an example, species
are represented as 4 letter codes:

Quadrat_#

Date

Species_1

Species_2

covrage2

Species_3

covrage3

1

5/2/2017

unk1

2

bial

6

stgu

95

2

5/2/2017

bope

75

stja

4

ficy

9

3

5/2/2017

bope

100

stja

5



4

5/2/2017

stgu

87

stja

6

bope

20

5

5/2/2017

bg

13

stja

2

ficy

10

6

5/2/2017

bope

8

sirh

3

stgu

2



The problem is that the species were not recorded in any particular order,
and not all species occur in every quadrat.  There can also be any number
of species per quadrat.  I need to be able to extract each species AND it?s
respective coverage, and place them in into another dataframe for further
analysis

So the result for ?bope? from above example data would look like this:

Quadrat#

% coverage bope

1

0

2

75

3

100

4

20

5

0

6

8



Any help greatly appreciated.

Brian

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue May  9 07:17:54 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 08 May 2017 22:17:54 -0700
Subject: [R] Extract cells and their adjacent cells that may appear
	anywhere	in a dataframe.
In-Reply-To: <CAJi8COuGN3c7y-hXTqe-4jRGS9Y7XcBNxrTQ72j2SKa7WtpPpQ@mail.gmail.com>
References: <CAJi8COuGN3c7y-hXTqe-4jRGS9Y7XcBNxrTQ72j2SKa7WtpPpQ@mail.gmail.com>
Message-ID: <D0A286FD-972C-4A1E-95CE-3BA436751A35@dcn.davis.ca.us>

Please don't post in HTML... what YOU see is almost never what WE see (look below for something like what I saw). Read the Posting Guide for more help on how to use the list, including the recommendation to formulate your question as a minimal R example (runnable code). See for example [1] and/or  [2].

From your description the solution will either be a reshape-operation or a line-by-line parsing of the data, depending how the input data are laid out in the file, which is not clear in the mess below. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On May 8, 2017 9:33:25 PM PDT, Brian Leo <leobriant at gmail.com> wrote:
>Hello,
>
>I have a dataframe that contains information about vegetation cover and
>percent coverage, collected using a quadrat.  The dataframe is set up
>so
>that each row represents a single quadrat.  If there are multiple
>species
>within one quadrat, they are all listed within the same row with
>respective
>% coverage always following in next column.  Here is an example,
>species
>are represented as 4 letter codes:
>
>Quadrat_#
>
>Date
>
>Species_1
>
>Species_2
>
>covrage2
>
>Species_3
>
>covrage3
>
>1
>
>5/2/2017
>
>unk1
>
>2
>
>bial
>
>6
>
>stgu
>
>95
>
>2
>
>5/2/2017
>
>bope
>
>75
>
>stja
>
>4
>
>ficy
>
>9
>
>3
>
>5/2/2017
>
>bope
>
>100
>
>stja
>
>5
>
>
>
>4
>
>5/2/2017
>
>stgu
>
>87
>
>stja
>
>6
>
>bope
>
>20
>
>5
>
>5/2/2017
>
>bg
>
>13
>
>stja
>
>2
>
>ficy
>
>10
>
>6
>
>5/2/2017
>
>bope
>
>8
>
>sirh
>
>3
>
>stgu
>
>2
>
>
>
>The problem is that the species were not recorded in any particular
>order,
>and not all species occur in every quadrat.  There can also be any
>number
>of species per quadrat.  I need to be able to extract each species AND
>it?s
>respective coverage, and place them in into another dataframe for
>further
>analysis
>
>So the result for ?bope? from above example data would look like this:
>
>Quadrat#
>
>% coverage bope
>
>1
>
>0
>
>2
>
>75
>
>3
>
>100
>
>4
>
>20
>
>5
>
>0
>
>6
>
>8
>
>
>
>Any help greatly appreciated.
>
>Brian
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From yarmi1224 at hotmail.com  Tue May  9 07:12:12 2017
From: yarmi1224 at hotmail.com (=?gb2312?B?psggo6I=?=)
Date: Tue, 9 May 2017 05:12:12 +0000
Subject: [R] How do I use R to build a dictionary of proper nouns?
In-Reply-To: <FF386E39-C239-47EE-AE29-5824078AF0EA@utoronto.ca>
References: <SIXPR03MB0893C2F8CC312827E4FAB52DA4EB0@SIXPR03MB0893.apcprd03.prod.outlook.com>
 <D461C473-54B7-4067-98E4-6E18D6327677@utoronto.ca>
 <HK2PR0301MB118716AC19C4665974DD6CE0A4EE0@HK2PR0301MB1187.apcprd03.prod.outlook.com>,
 <FF386E39-C239-47EE-AE29-5824078AF0EA@utoronto.ca>
Message-ID: <HK2PR0301MB1187FA9B45261A7008CF416FA4EF0@HK2PR0301MB1187.apcprd03.prod.outlook.com>


Hi Boris :
I'm very thanks for your reply and your suggestions.
In order to be clear show my workflow, I have added my code and document file in the attachment.
My research target is to get the topic technique of CMP (chemical mechanical polishing).
So I want to use related patent texts to do text mining.
Here are my ways for text mining process.
1.Tf-idf
2.CMP ontology
The CMP ontology is made by myself. It's used to build the dictionary and extract the proper nouns of CMP.
Here is my workflow to  build a dictionary of proper nouns:
1. Read the ontology file into R.
2. Extract proper nouns from the ontology.
3.Use tm package to do preprocessing:
    (remove"_",  tolower,  stripWhitespace, stemDocument)
4. Build a dictionary of proper nouns.

Finally, I want to extract proper noun which shows in my patent documents (corpus_tm) and its frequency.

Thanks
Eva
________________________________
??????: Boris Steipe <boris.steipe at utoronto.ca>
????????: 2017??5??8?? ???? 05:09
??????: ?? ??
????: r-help at r-project.org
????: Re: [R] How do I use R to build a dictionary of proper nouns?

Your workflow is not clear to me, so I can't give any specific advice.

1: I don't understand what you need. Do you need the column names changed? They correspond to the matched
   words.

2: How was the vector dictionary_word created? These are (mostly) stemmed nouns, but some of them are two or even three words? Did you do this by hand? But this also contains "cmp" which is not a stemmed word, or "particl", or "recoveri" which is not correctly stemmed. This doesn't look promising, I think at least you will need to place hyphens between the words, but since you are using stemmed words this will be difficult.

3: Since the default tokenizer is "words", I think the two-word and three-word elements of the dictionary_word vector will not be found. They don't exist as tokens.

4: Don't use "list" as a variable name.

In summary - I think your problems have to do with stemming and tokenizing and not with formatting the output of DocumentTermMatrix(). I don't think tm has functions to produce stemmed multi-word tokens like the elements in your dictionary_word vector. You may need to do the analysis with your own functions, using regular expressions.


B.


> On May 8, 2017, at 3:56 AM, ?? ?? <yarmi1224 at hotmail.com> wrote:
>
> Hi Steipe??
> Thanks for your recommend.
> I have used the DocumentTermMatrix function of tm package to try.
> But I prefer the matrix result shows the frequency of the dictionary word.
> Is there any way to do?
> The following are my code and result??
>
> dictionary_word <- c("neutral", "abras particl", "acid", "apparatus", "back film", "basic", "carrier", "chemic", "chromat confoc", "clean system", "cmp", "compens type", "compress", "comsum", "control system", "down pressur", "dresser condition", "detect system", "flow rate control", "fractal type", "groov", "hard", "improv type", "infrar", "laser confoc", "layer", "measur system", "micro stuctur", "monitor system", "multi layer", "none-por", "nonwoven pad", "pad", "pad applic", "pad condit system", "pad materi", "pad properti", "pad structur", "ph sensor", "planet type", "plate", "plat", "poisson ratio", "polish head", "polish system", "polym pad", "polyurethan pad", "porous", "process paramet", "process path", "process time", "recoveri", "rotat speed", "rough", "scatter", "semiconductor cmp", "sensor", "signal acceptor", "singl layer", "slurri", "slurri flow rate", "slurri ph valu", "slurri stirrer", "slurri suppli system", "slurri temperatur", "slurri weight percentag", "storag cmp", "stylus profil", "substrat cmp", "thick", "transfer robot", "ultrason", "urethan pad", "wafer cassett", "wafer transfer system", "white light interferomet", "young modulus")
>
> list<-inspect(DocumentTermMatrix(corpus_tm,
>                                  list(weighting =weightTf,
>                                       dictionary = dictionary_word)))
>
> <keywords of dictionary.PNG>
>
>
> ??????: Boris Steipe <boris.steipe at utoronto.ca>
> ????????: 2017??5??5?? ???? 04:39
> ??????: ?? ??
> ????: r-help at r-project.org
> ????: Re: [R] How do I use R to build a dictionary of proper nouns?
>
> Did you try using the table() function, possibly in combination with sort() or rank()?
>
>
> Consider:
>
> myNouns <- c("proper", "nouns", "domain", "ontology", "dictionary",
>              "dictionary", "corpus", "patent", "files", "proper", "nouns",
>              "word", "frequency", "file", "preprocess", "corpus", "proper",
>              "nouns", "domain", "ontology", "idea", "nouns", "dictionary",
>              "dictionary", "corpus", "attachments", "texts", "corpus",
>              "preprocesses", "proper", "nouns")
>
> myNounFrequencies <- table(myNouns)
> myNounFrequencies
>
> myNounFrequencies <- sort(myNounFrequencies, decreasing = TRUE)
> myNounFrequencies
>
> which(names(myNounFrequencies) == "corpus")
>
>
>
>
>
> > On May 5, 2017, at 1:58 AM, ?? ?? <yarmi1224 at hotmail.com> wrote:
> >
> > ?? ?? ???c?????? OneDrive ?n?????????z???n???????????????B?Y??
> >
> >
> > <https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
[https://uw8msa.bl3301.livefilestore.com/y4mlkNRVEt1UjK8BTCKa_IHAfx3slsjvqzKBBCE5FqvFOsb5JYl3jsKXvku_EcRwWkvS5Y0nl-yiSjNVyo7ApVl6jTE0ThkhbWa0FzfeiSHll2koMwy6iWdYae1AXAREZyH3D8K5xbCf_N2LNyERh50VUYOESXH_RdYjGTMriVVXDY] <https://1drv.ms/i/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
[https://uw8msa.bl3301.livefilestore.com/y4mlkNRVEt1UjK8BTCKa_IHAfx3slsjvqzKBBCE5FqvFOsb5JYl3jsKXvku_EcRwWkvS5Y0nl-yiSjNVyo7ApVl6jTE0ThkhbWa0FzfeiSHll2koMwy6iWdYae1AXAREZyH3D8K5xbCf_N2LNyERh50VUYOESXH_RdYjGTMriVVXDY]


>
>
>
> > [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
> >
> > 2.corpus_patent text.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
[https://uw8msa.bl3301.livefilestore.com/y4mlkNRVEt1UjK8BTCKa_IHAfx3slsjvqzKBBCE5FqvFOsb5JYl3jsKXvku_EcRwWkvS5Y0nl-yiSjNVyo7ApVl6jTE0ThkhbWa0FzfeiSHll2koMwy6iWdYae1AXAREZyH3D8K5xbCf_N2LNyERh50VUYOESXH_RdYjGTMriVVXDY] <https://1drv.ms/i/s!Aq27nOPOP5izgVRRxXomVBv0YV0j>
[https://uw8msa.bl3301.livefilestore.com/y4mlkNRVEt1UjK8BTCKa_IHAfx3slsjvqzKBBCE5FqvFOsb5JYl3jsKXvku_EcRwWkvS5Y0nl-yiSjNVyo7ApVl6jTE0ThkhbWa0FzfeiSHll2koMwy6iWdYae1AXAREZyH3D8K5xbCf_N2LNyERh50VUYOESXH_RdYjGTMriVVXDY]


>
>
>
> >
> > <https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
[https://uwpl0w.bl3301.livefilestore.com/y4mY6mahV5KDRXKY0h8S6lbcH1zTGwM8vT6edKP8yUzxwxp874gXxRuao8FANEn_-wY1o7NG5QgVLo9Q9QnfgTtFneHbYx5MxUUtXEK2DqEsKOeAGxu20xxn_wVPqkK8ljOt2Jia7YN2neRhuvx7gQwXM2ttYTaaMUO9FSmo_CORdQ] <https://1drv.ms/i/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
[https://uwpl0w.bl3301.livefilestore.com/y4mY6mahV5KDRXKY0h8S6lbcH1zTGwM8vT6edKP8yUzxwxp874gXxRuao8FANEn_-wY1o7NG5QgVLo9Q9QnfgTtFneHbYx5MxUUtXEK2DqEsKOeAGxu20xxn_wVPqkK8ljOt2Jia7YN2neRhuvx7gQwXM2ttYTaaMUO9FSmo_CORdQ]


>
>
>
> > [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
> >
> > 3ontology_proper nouns keywords.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
[https://uwpl0w.bl3301.livefilestore.com/y4mY6mahV5KDRXKY0h8S6lbcH1zTGwM8vT6edKP8yUzxwxp874gXxRuao8FANEn_-wY1o7NG5QgVLo9Q9QnfgTtFneHbYx5MxUUtXEK2DqEsKOeAGxu20xxn_wVPqkK8ljOt2Jia7YN2neRhuvx7gQwXM2ttYTaaMUO9FSmo_CORdQ] <https://1drv.ms/i/s!Aq27nOPOP5izgVURiS7MbYH6hJzo>
[https://uwpl0w.bl3301.livefilestore.com/y4mY6mahV5KDRXKY0h8S6lbcH1zTGwM8vT6edKP8yUzxwxp874gXxRuao8FANEn_-wY1o7NG5QgVLo9Q9QnfgTtFneHbYx5MxUUtXEK2DqEsKOeAGxu20xxn_wVPqkK8ljOt2Jia7YN2neRhuvx7gQwXM2ttYTaaMUO9FSmo_CORdQ]


>
>
>
> >
> > <https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
[https://uwqiaw.bl3301.livefilestore.com/y4ma17MHcDeMhjshTwq328eWx11Xz6DlCWOvNyOCfggv8TJXVc-KNC81Vx8N4sN6M_XgRcMUzWpcpIg1HcR2bg4-LcyI4VZU0hmVUZBKTXWzcFhcIgV17FMO5_XyS0sLJH2dP1gXk7-pqsmKEhpwYN6Re102YbzG5chhvBaMlD7kHA] <https://1drv.ms/i/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
[https://uwqiaw.bl3301.livefilestore.com/y4ma17MHcDeMhjshTwq328eWx11Xz6DlCWOvNyOCfggv8TJXVc-KNC81Vx8N4sN6M_XgRcMUzWpcpIg1HcR2bg4-LcyI4VZU0hmVUZBKTXWzcFhcIgV17FMO5_XyS0sLJH2dP1gXk7-pqsmKEhpwYN6Re102YbzG5chhvBaMlD7kHA]


>
>
>
> > [https://r1.res.office365.com/owa/prem/images/dc-png_20.png]<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
> >
> > 1.patents.PNG<https://1drv.ms/u/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
[https://uwqiaw.bl3301.livefilestore.com/y4ma17MHcDeMhjshTwq328eWx11Xz6DlCWOvNyOCfggv8TJXVc-KNC81Vx8N4sN6M_XgRcMUzWpcpIg1HcR2bg4-LcyI4VZU0hmVUZBKTXWzcFhcIgV17FMO5_XyS0sLJH2dP1gXk7-pqsmKEhpwYN6Re102YbzG5chhvBaMlD7kHA] <https://1drv.ms/i/s!Aq27nOPOP5izgVYuRVxM1OyzIPzF>
[https://uwqiaw.bl3301.livefilestore.com/y4ma17MHcDeMhjshTwq328eWx11Xz6DlCWOvNyOCfggv8TJXVc-KNC81Vx8N4sN6M_XgRcMUzWpcpIg1HcR2bg4-LcyI4VZU0hmVUZBKTXWzcFhcIgV17FMO5_XyS0sLJH2dP1gXk7-pqsmKEhpwYN6Re102YbzG5chhvBaMlD7kHA]


>
>
>
> >
> >
> >
> >
> > Hi :
> >
> > I want to do patents text mining in R.
> > I need to use the proper nouns of domain ontology to build a dictionary.
> > Then use the dictionary to analysis my corpus of patent files.
> > I want to calculate the proper nouns and get the word frequency that appears in each file.
> >
> > Now I have done the preprocess for the corpus and extract the proper nouns from domain ontology.
> > But I have no idea how to build a proper nouns dictionary and use the dictionary to analysis my corpus.
> >
> > The Attachments are my texts, corpus preprocesses and proper nouns.
> >
> > Thanks.
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
R-help Info Page - Homepage - SfS ?C Seminar for Statistics<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> R-help Info Page - Homepage - SfS ?C Seminar for Statistics
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...
>
>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Tue May  9 08:40:23 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 09 May 2017 06:40:23 +0000
Subject: [R] passing arguments to simple plotting program.
In-Reply-To: <809F9C89-132B-4904-9B31-34E6C2CEDD4D@gmail.com>
References: <809F9C89-132B-4904-9B31-34E6C2CEDD4D@gmail.com>
Message-ID: <CAKVAULMyEA3zZ-gD-CwFJDnLGG8DDJSU-DoxPqqBfm-rX0rqkw@mail.gmail.com>

HI Gerard,

You get the literals because the variables are not implicitly expanded -
'Placebo(N=n1)  ' is just a string indicating the N = n1.

What you want is to use paste() or paste0():
c(paste0("Placebo(N=", n1, ")"), paste0("Low Dose (N=", n2, ")"),
paste0("High Dose (N=", n3, ")"))
should do it.

I was taught a long ago that attach() should be avoided to avoid name
conflicts. Also, it makes it difficult to figure out which data is actually
being used.

HTH
Ulrik

On Tue, 9 May 2017 at 06:44 Gerard Smits <smits.gerard.j at gmail.com> wrote:

> Hi All,
>
> I thought I?d try to get a function working instead of block copying code
> and editing. My backorund is more SAS, so using a SAS Macro would be easy,
> but not so lucky with R functions.
>
>
> R being used on Mac Sierra 10.12.4:
>
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>
>
> resp<-read.csv("//users//gerard//gs//r_work//xyz.csv", header = TRUE)
>
> v5  <-subset(resp, subset=visit==5 & pp==1)
>
> plot_f1 <-function(n1,n2,n3) {
>   attach(v8)
>   par(oma=c(2,2,2,2))
>   boxplot(formula = d_comp ~ rx_grp,
>           main="Figure 2\nChange in Composite Score at Visit 5 (Day
> 31)\nPer Protocol Population",
>           ylim=c(-10,5),
>           names=c('Placebo(N=n1)  ',
>                   'Low Dose(N=n2) ',
>                   'High Dose(N=n3)'),
>           ylab='Change from Baseline')
>   abline(h=c(0), col="lightgray")
> }
>
> plot_f1(n1=114, n2=119, n3=116)
>
> The above is a simplified example where I am trying to pass 3 arguments,
> n1-n3, to be shown in the x-axis tables,  Instead of the numbers, I get the
> literal n1, n2, n3.
>
> Any help appreciated.
>
> Thanks,
>
> Gerard
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue May  9 08:42:05 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 09 May 2017 06:42:05 +0000
Subject: [R] Joining tables with different order and matched values
In-Reply-To: <CY4PR15MB130291337499E7A8300D926BEFEE0@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB130291337499E7A8300D926BEFEE0@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <CAKVAULPBMnwm5iRtbCpvzVfbEt=VCG+2EN48_P=fMKkzW=ha7g@mail.gmail.com>

Hi Abo,

?merge

or the join functions from dplyr.

HTH
Ulrik

On Tue, 9 May 2017 at 06:44 abo dalash <abo_dlsh at hotmail.com> wrote:

> Hi All ..,
>
>
> I have 2 tables and I'm trying to have some information from the 1st table
> to appear in the second table with different order.
>
>
> For Example, let's say this is my 1st table :-
>
>
>
> Drug name           indications
>
>  Ibuprofen                Pain
>
>  Simvastatin            hyperlipidemia
>
> losartan                   hypertension
>
>
>
> my 2nd table is in different order for the 1st column :-
>
>
> Drug name       indications
>
>
> Simvastatin
>
> losartan
>
> Ibuprofen
>
> Metformin
>
>
> I wish to see the indication of each drug in my 2nd table subsisted from
> the information in my 1st table so the final table
>
> would be like this
>
>
> Drug name       indications
>
>
> Simvastatin     hyperlipidemia
>
> losartan           hypertension
>
> Ibuprofen       pain
>
> Metformin    N/A
>
>
> I have been trying to use Sqldf package and right join function but not
> able to formulate the correct syntax.
>
>
> I'm also trying to identify rows contain at least one shared value  in a
> dataset called 'Values":
>
>
> >Values
>
> A             B
>
> 1,2,5       3,8,7
>
> 2,4,6       7,6,3
>
>
>
> Columns A & B in the first row do not share any value while in the 2nd row
> they have a single shared value which is 6.
>
> The result I wish to see :-
>
>
> A             B             shared values
>
> 1,2,5       3,8,7             N/A
>
> 2,4,6       7,6,3               6
>
>
> I tried this syntax : SharedValues <- Values$A == Values$B but this
> returns logical results and what I wish to have
>
> is a new data frame including the new vector "shared values" showing the
> information exactly as above.
>
>
>
>
> Kind Regards
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue May  9 11:22:56 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 09 May 2017 09:22:56 +0000
Subject: [R] Joining tables with different order and matched values
In-Reply-To: <CY4PR15MB130235B562099E3F690CCE17EFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB130291337499E7A8300D926BEFEE0@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAKVAULPBMnwm5iRtbCpvzVfbEt=VCG+2EN48_P=fMKkzW=ha7g@mail.gmail.com>
 <CY4PR15MB130235B562099E3F690CCE17EFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <CAKVAULPMoH_4rnEYshZUCcQ4dgcxXN0FWkk2ycaYZ3PXZAMkDA@mail.gmail.com>

Hi Abo,

Please keep the list in cc.

I think the function documentation is pretty straight forward - two
data.frames are required, and if you wish to keep elements that are not
present in both data.frames, you set the flag all = TRUE. You also have the
option to specify which columns to join by.

If you need more assistance with joining two data.frames, you should
provide a reproducible example, and if you have trouble with a function you
should provide an example of what you have tried so far.

Best wishes,
Ulrik



On Tue, 9 May 2017 at 10:00 abo dalash <abo_dlsh at hotmail.com> wrote:

> Could you please teach me about the correct formation of the syntax?. I
> have read the help page and other online resources about inner,left,&right
> join but wasn't able to formulate the correct syntax.
>
>
> Sent from my Samsung device
>
>
> -------- Original message --------
> From: Ulrik Stervbo <ulrik.stervbo at gmail.com>
> Date: 09/05/2017 7:42 a.m. (GMT+00:00)
> To: abo dalash <abo_dlsh at hotmail.com>, "r-help at R-project.org" <
> r-help at r-project.org>
> Subject: Re: [R] Joining tables with different order and matched values
>
> Hi Abo,
>
> ?merge
>
> or the join functions from dplyr.
>
> HTH
> Ulrik
>
> On Tue, 9 May 2017 at 06:44 abo dalash <abo_dlsh at hotmail.com> wrote:
>
>> Hi All ..,
>>
>>
>> I have 2 tables and I'm trying to have some information from the 1st
>> table to appear in the second table with different order.
>>
>>
>> For Example, let's say this is my 1st table :-
>>
>>
>>
>> Drug name           indications
>>
>>  Ibuprofen                Pain
>>
>>  Simvastatin            hyperlipidemia
>>
>> losartan                   hypertension
>>
>>
>>
>> my 2nd table is in different order for the 1st column :-
>>
>>
>> Drug name       indications
>>
>>
>> Simvastatin
>>
>> losartan
>>
>> Ibuprofen
>>
>> Metformin
>>
>>
>> I wish to see the indication of each drug in my 2nd table subsisted from
>> the information in my 1st table so the final table
>>
>> would be like this
>>
>>
>> Drug name       indications
>>
>>
>> Simvastatin     hyperlipidemia
>>
>> losartan           hypertension
>>
>> Ibuprofen       pain
>>
>> Metformin    N/A
>>
>>
>> I have been trying to use Sqldf package and right join function but not
>> able to formulate the correct syntax.
>>
>>
>> I'm also trying to identify rows contain at least one shared value  in a
>> dataset called 'Values":
>>
>>
>> >Values
>>
>> A             B
>>
>> 1,2,5       3,8,7
>>
>> 2,4,6       7,6,3
>>
>>
>>
>> Columns A & B in the first row do not share any value while in the 2nd
>> row they have a single shared value which is 6.
>>
>> The result I wish to see :-
>>
>>
>> A             B             shared values
>>
>> 1,2,5       3,8,7             N/A
>>
>> 2,4,6       7,6,3               6
>>
>>
>> I tried this syntax : SharedValues <- Values$A == Values$B but this
>> returns logical results and what I wish to have
>>
>> is a new data frame including the new vector "shared values" showing the
>> information exactly as above.
>>
>>
>>
>>
>> Kind Regards
>>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue May  9 12:12:42 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 9 May 2017 12:12:42 +0200
Subject: [R] Factors and Alternatives
Message-ID: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>

Hi All,

I am using factors in a study for the social sciences.

I discovered the following:

-- cut --

library(dplyr)

test1 <- c(rep(1, 4), rep(0, 6))
d_test1 <- data.frame(test)

test2 <- factor(test1)
d_test2 <- data.frame(test2)

test3 <- factor(test1, 
                levels = c(0, 1),
                labels = c("WITHOUT Contact", "WITH Contact"))
d_test3 <- data.frame(test3)

d_test1 %>% filter(test1 == 0)  # works OK
d_test2 %>% filter(test2 == 0)  # works OK
d_test3 %>% filter(test3 == 0)  # does not work, why?

myf <- function(ds) {
  print(levels(ds$test3))
  print(labels(ds$test3))
  print(as.numeric(ds$test3))
  print(as.character(ds$test3))
}

# This showsthat it is not possible to access the original
# values which were the basis to build the factor:
myf(d_test3)

-- cut --

Why is it not possible to use a factor with labels for filtering with the 
original values?
Is there a data structure that works like a factor but gives also access 
to the original values?

Kind regards

Georg


From rni.boh at gmail.com  Tue May  9 12:27:26 2017
From: rni.boh at gmail.com (Bob O'Hara)
Date: Tue, 9 May 2017 12:27:26 +0200
Subject: [R] Factors and Alternatives
In-Reply-To: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>
References: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>
Message-ID: <CAN-Z0xWscjggKD2iEr7vYb8gUjP_aLJog=FeGe7ps1Reu2pBbg@mail.gmail.com>

That's easy! First
> str(test3)
 Factor w/ 2 levels "WITHOUT Contact",..: 2 2 2 2 1 1 1 1 1 1

tells you that the internal values are 1 and 2, and the labels are
"WITHOUT Contact" and "WITH Contact". If you read the help page for
factor() you'll see this:

levels: an optional vector of the values (as character strings) that
          ?x? might have taken.  The default is the unique set of
          values taken by ?as.character(x)?, sorted into increasing
          order _of ?x?_.  Note that this set can be specified as
          smaller than ?sort(unique(x))?.

  labels: _either_ an optional character vector of (unique) labels for
          the levels (in the same order as ?levels? after removing
          those in ?exclude?), _or_ a character string of length 1.

So, when you create test3 you say that test can take values 0 and 1,
and these should be labelled as "WITHOUT Contact" and "WITH Contact".
So R internally codes "1" as 1 and "0" as 2 (internally R codes
factors as integers, which can be both useful and dangerous), and then
gives them labels "WITHOUT Contact" and "WITH Contact". It now doesn't
care that they were 1 and 0, because you've told it to change the
labels.

If you want to filter by the original values, then don't change the
labels (or at least not until after you've filtered by the original
labels), or convert the filter to the new labels. You're asking for a
data structure with two sets of labels, which sounds odd in general.

Bob

On 9 May 2017 at 12:12,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I am using factors in a study for the social sciences.
>
> I discovered the following:
>
> -- cut --
>
> library(dplyr)
>
> test1 <- c(rep(1, 4), rep(0, 6))
> d_test1 <- data.frame(test)
>
> test2 <- factor(test1)
> d_test2 <- data.frame(test2)
>
> test3 <- factor(test1,
>                 levels = c(0, 1),
>                 labels = c("WITHOUT Contact", "WITH Contact"))
> d_test3 <- data.frame(test3)
>
> d_test1 %>% filter(test1 == 0)  # works OK
> d_test2 %>% filter(test2 == 0)  # works OK
> d_test3 %>% filter(test3 == 0)  # does not work, why?
>
> myf <- function(ds) {
>   print(levels(ds$test3))
>   print(labels(ds$test3))
>   print(as.numeric(ds$test3))
>   print(as.character(ds$test3))
> }
>
> # This showsthat it is not possible to access the original
> # values which were the basis to build the factor:
> myf(d_test3)
>
> -- cut --
>
> Why is it not possible to use a factor with labels for filtering with the
> original values?
> Is there a data structure that works like a factor but gives also access
> to the original values?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara
NOTE NEW ADDRESS!!!
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +49 1515 888 5440
Journal of Negative Results - EEB: www.jnr-eeb.org


From G.Maubach at weinwolf.de  Tue May  9 13:36:38 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 9 May 2017 13:36:38 +0200
Subject: [R] Antwort: Re:  Factors and Alternatives
In-Reply-To: <CAN-Z0xWscjggKD2iEr7vYb8gUjP_aLJog=FeGe7ps1Reu2pBbg@mail.gmail.com>
References: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>
 <CAN-Z0xWscjggKD2iEr7vYb8gUjP_aLJog=FeGe7ps1Reu2pBbg@mail.gmail.com>
Message-ID: <OFDEE4B875.A7F9900D-ONC125811B.003EFADF-C125811B.003FC750@lotus.hawesko.de>

Hi Bob,

many thanks for your reply.

I have read the documentation. In my current project I use "item 
batteries" for dimensions of touchpoints which are rated by our customers. 
I wrote functions to analyse them. If I create a factor before filtering 
and analysing I lose the original values of the variable. If I use the 
original variable for filtering and analysis I might happen that for some 
dimensions values were not selected. This means they are not NA but none 
of the respondents chose "4" for instance on a scale from 1 to 6. That 
means that creating a factor from the analysed data with the complete 
scale (1:6) fails due the different vector length (amount of remaining 
unique values in the analysis vs values in the scale). As I have a 
function doing the analysis I am looking for a way to make my function 
robust to such circumstances and be able to use it to analyse all "item 
batteries". Thus my question. I believe my findings are not odd. Maybe 
there is a way dealing with that kind of problems in R and I am eager to 
learn how it can be solved using R.

What would you suggest?

Kind regards

Georg




Von:    "Bob O'Hara" <rni.boh at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help <r-help at r-project.org>
Datum:  09.05.2017 12:26
Betreff:        Re: [R] Factors and Alternatives



That's easy! First
> str(test3)
 Factor w/ 2 levels "WITHOUT Contact",..: 2 2 2 2 1 1 1 1 1 1

tells you that the internal values are 1 and 2, and the labels are
"WITHOUT Contact" and "WITH Contact". If you read the help page for
factor() you'll see this:

levels: an optional vector of the values (as character strings) that
          ?x? might have taken.  The default is the unique set of
          values taken by ?as.character(x)?, sorted into increasing
          order _of ?x?_.  Note that this set can be specified as
          smaller than ?sort(unique(x))?.

  labels: _either_ an optional character vector of (unique) labels for
          the levels (in the same order as ?levels? after removing
          those in ?exclude?), _or_ a character string of length 1.

So, when you create test3 you say that test can take values 0 and 1,
and these should be labelled as "WITHOUT Contact" and "WITH Contact".
So R internally codes "1" as 1 and "0" as 2 (internally R codes
factors as integers, which can be both useful and dangerous), and then
gives them labels "WITHOUT Contact" and "WITH Contact". It now doesn't
care that they were 1 and 0, because you've told it to change the
labels.

If you want to filter by the original values, then don't change the
labels (or at least not until after you've filtered by the original
labels), or convert the filter to the new labels. You're asking for a
data structure with two sets of labels, which sounds odd in general.

Bob

On 9 May 2017 at 12:12,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I am using factors in a study for the social sciences.
>
> I discovered the following:
>
> -- cut --
>
> library(dplyr)
>
> test1 <- c(rep(1, 4), rep(0, 6))
> d_test1 <- data.frame(test)
>
> test2 <- factor(test1)
> d_test2 <- data.frame(test2)
>
> test3 <- factor(test1,
>                 levels = c(0, 1),
>                 labels = c("WITHOUT Contact", "WITH Contact"))
> d_test3 <- data.frame(test3)
>
> d_test1 %>% filter(test1 == 0)  # works OK
> d_test2 %>% filter(test2 == 0)  # works OK
> d_test3 %>% filter(test3 == 0)  # does not work, why?
>
> myf <- function(ds) {
>   print(levels(ds$test3))
>   print(labels(ds$test3))
>   print(as.numeric(ds$test3))
>   print(as.character(ds$test3))
> }
>
> # This showsthat it is not possible to access the original
> # values which were the basis to build the factor:
> myf(d_test3)
>
> -- cut --
>
> Why is it not possible to use a factor with labels for filtering with 
the
> original values?
> Is there a data structure that works like a factor but gives also access
> to the original values?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara
NOTE NEW ADDRESS!!!
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +49 1515 888 5440
Journal of Negative Results - EEB: www.jnr-eeb.org



From rni.boh at gmail.com  Tue May  9 13:59:09 2017
From: rni.boh at gmail.com (Bob O'Hara)
Date: Tue, 9 May 2017 13:59:09 +0200
Subject: [R] Factors and Alternatives
In-Reply-To: <OFDEE4B875.A7F9900D-ONC125811B.003EFADF-C125811B.003FC750@lotus.hawesko.de>
References: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>
 <CAN-Z0xWscjggKD2iEr7vYb8gUjP_aLJog=FeGe7ps1Reu2pBbg@mail.gmail.com>
 <OFDEE4B875.A7F9900D-ONC125811B.003EFADF-C125811B.003FC750@lotus.hawesko.de>
Message-ID: <CAN-Z0xVAiGpr7yuU4sqwQgoO=j7hu8APmcK0MgPputj=n2DMWQ@mail.gmail.com>

For the problem you state, would it be enough to explicitly define your levels?

fac <- rep(c("a", "b", "d"), each=4)
fac.f <- factor(fac, levels=c("a", "b", "c", "d"))
table(fac.f)

# but be warned...
fac.f2 <- factor(fac.f)
table(fac.f2)

This has the advantage that the code explicitly documents what the
possible values are, so if something goes wrong down-stream, you know
it is a real problem (well, unless you have some type conversions
screwing things up). You might also want to do some defensive
programming, and put some checks in the code, to make sure your
factors have the right number of levels.

Bob

On 9 May 2017 at 13:36,  <G.Maubach at weinwolf.de> wrote:
> Hi Bob,
>
> many thanks for your reply.
>
> I have read the documentation. In my current project I use "item
> batteries" for dimensions of touchpoints which are rated by our customers.
> I wrote functions to analyse them. If I create a factor before filtering
> and analysing I lose the original values of the variable. If I use the
> original variable for filtering and analysis I might happen that for some
> dimensions values were not selected. This means they are not NA but none
> of the respondents chose "4" for instance on a scale from 1 to 6. That
> means that creating a factor from the analysed data with the complete
> scale (1:6) fails due the different vector length (amount of remaining
> unique values in the analysis vs values in the scale). As I have a
> function doing the analysis I am looking for a way to make my function
> robust to such circumstances and be able to use it to analyse all "item
> batteries". Thus my question. I believe my findings are not odd. Maybe
> there is a way dealing with that kind of problems in R and I am eager to
> learn how it can be solved using R.
>
> What would you suggest?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    "Bob O'Hara" <rni.boh at gmail.com>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help <r-help at r-project.org>
> Datum:  09.05.2017 12:26
> Betreff:        Re: [R] Factors and Alternatives
>
>
>
> That's easy! First
>> str(test3)
>  Factor w/ 2 levels "WITHOUT Contact",..: 2 2 2 2 1 1 1 1 1 1
>
> tells you that the internal values are 1 and 2, and the labels are
> "WITHOUT Contact" and "WITH Contact". If you read the help page for
> factor() you'll see this:
>
> levels: an optional vector of the values (as character strings) that
>           ?x? might have taken.  The default is the unique set of
>           values taken by ?as.character(x)?, sorted into increasing
>           order _of ?x?_.  Note that this set can be specified as
>           smaller than ?sort(unique(x))?.
>
>   labels: _either_ an optional character vector of (unique) labels for
>           the levels (in the same order as ?levels? after removing
>           those in ?exclude?), _or_ a character string of length 1.
>
> So, when you create test3 you say that test can take values 0 and 1,
> and these should be labelled as "WITHOUT Contact" and "WITH Contact".
> So R internally codes "1" as 1 and "0" as 2 (internally R codes
> factors as integers, which can be both useful and dangerous), and then
> gives them labels "WITHOUT Contact" and "WITH Contact". It now doesn't
> care that they were 1 and 0, because you've told it to change the
> labels.
>
> If you want to filter by the original values, then don't change the
> labels (or at least not until after you've filtered by the original
> labels), or convert the filter to the new labels. You're asking for a
> data structure with two sets of labels, which sounds odd in general.
>
> Bob
>
> On 9 May 2017 at 12:12,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> I am using factors in a study for the social sciences.
>>
>> I discovered the following:
>>
>> -- cut --
>>
>> library(dplyr)
>>
>> test1 <- c(rep(1, 4), rep(0, 6))
>> d_test1 <- data.frame(test)
>>
>> test2 <- factor(test1)
>> d_test2 <- data.frame(test2)
>>
>> test3 <- factor(test1,
>>                 levels = c(0, 1),
>>                 labels = c("WITHOUT Contact", "WITH Contact"))
>> d_test3 <- data.frame(test3)
>>
>> d_test1 %>% filter(test1 == 0)  # works OK
>> d_test2 %>% filter(test2 == 0)  # works OK
>> d_test3 %>% filter(test3 == 0)  # does not work, why?
>>
>> myf <- function(ds) {
>>   print(levels(ds$test3))
>>   print(labels(ds$test3))
>>   print(as.numeric(ds$test3))
>>   print(as.character(ds$test3))
>> }
>>
>> # This showsthat it is not possible to access the original
>> # values which were the basis to build the factor:
>> myf(d_test3)
>>
>> -- cut --
>>
>> Why is it not possible to use a factor with labels for filtering with
> the
>> original values?
>> Is there a data structure that works like a factor but gives also access
>> to the original values?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Bob O'Hara
> NOTE NEW ADDRESS!!!
> Institutt for matematiske fag
> NTNU
> 7491 Trondheim
> Norway
>
> Mobile: +49 1515 888 5440
> Journal of Negative Results - EEB: www.jnr-eeb.org
>
>



-- 
Bob O'Hara
NOTE NEW ADDRESS!!!
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +49 1515 888 5440
Journal of Negative Results - EEB: www.jnr-eeb.org


From dcarlson at tamu.edu  Tue May  9 14:38:12 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 9 May 2017 12:38:12 +0000
Subject: [R] Antwort: Re:  Factors and Alternatives
In-Reply-To: <OFDEE4B875.A7F9900D-ONC125811B.003EFADF-C125811B.003FC750@lotus.hawesko.de>
References: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>
 <CAN-Z0xWscjggKD2iEr7vYb8gUjP_aLJog=FeGe7ps1Reu2pBbg@mail.gmail.com>
 <OFDEE4B875.A7F9900D-ONC125811B.003EFADF-C125811B.003FC750@lotus.hawesko.de>
Message-ID: <2d9bd812b14048d282c9a0689b22902e@exch-2p-mbx-w2.ads.tamu.edu>

I'm not sure I understand your question, but you can easily include all possible answers when you create the factor by using the levels= argument as Bob pointed out. Here is an example of values that range from 1 to 6, but value 3 is not represented. Notice that a factor level 3 is created even though it does not appear in the data:

> set.seed(42)
> x <- sample.int(6, 10, replace=TRUE)
> table(x)
x
1 2 4 5 6 
1 1 3 3 2 
> y <- factor(x, levels=1:6)
> y
 [1] 6 6 2 5 4 4 5 1 4 5
Levels: 1 2 3 4 5 6

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of G.Maubach at weinwolf.de
Sent: Tuesday, May 9, 2017 6:37 AM
To: Bob O'Hara <rni.boh at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: [R] Antwort: Re: Factors and Alternatives

Hi Bob,

many thanks for your reply.

I have read the documentation. In my current project I use "item 
batteries" for dimensions of touchpoints which are rated by our customers. 
I wrote functions to analyse them. If I create a factor before filtering 
and analysing I lose the original values of the variable. If I use the 
original variable for filtering and analysis I might happen that for some 
dimensions values were not selected. This means they are not NA but none 
of the respondents chose "4" for instance on a scale from 1 to 6. That 
means that creating a factor from the analysed data with the complete 
scale (1:6) fails due the different vector length (amount of remaining 
unique values in the analysis vs values in the scale). As I have a 
function doing the analysis I am looking for a way to make my function 
robust to such circumstances and be able to use it to analyse all "item 
batteries". Thus my question. I believe my findings are not odd. Maybe 
there is a way dealing with that kind of problems in R and I am eager to 
learn how it can be solved using R.

What would you suggest?

Kind regards

Georg




Von:    "Bob O'Hara" <rni.boh at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help <r-help at r-project.org>
Datum:  09.05.2017 12:26
Betreff:        Re: [R] Factors and Alternatives



That's easy! First
> str(test3)
 Factor w/ 2 levels "WITHOUT Contact",..: 2 2 2 2 1 1 1 1 1 1

tells you that the internal values are 1 and 2, and the labels are
"WITHOUT Contact" and "WITH Contact". If you read the help page for
factor() you'll see this:

levels: an optional vector of the values (as character strings) that
          ?x? might have taken.  The default is the unique set of
          values taken by ?as.character(x)?, sorted into increasing
          order _of ?x?_.  Note that this set can be specified as
          smaller than ?sort(unique(x))?.

  labels: _either_ an optional character vector of (unique) labels for
          the levels (in the same order as ?levels? after removing
          those in ?exclude?), _or_ a character string of length 1.

So, when you create test3 you say that test can take values 0 and 1,
and these should be labelled as "WITHOUT Contact" and "WITH Contact".
So R internally codes "1" as 1 and "0" as 2 (internally R codes
factors as integers, which can be both useful and dangerous), and then
gives them labels "WITHOUT Contact" and "WITH Contact". It now doesn't
care that they were 1 and 0, because you've told it to change the
labels.

If you want to filter by the original values, then don't change the
labels (or at least not until after you've filtered by the original
labels), or convert the filter to the new labels. You're asking for a
data structure with two sets of labels, which sounds odd in general.

Bob

On 9 May 2017 at 12:12,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I am using factors in a study for the social sciences.
>
> I discovered the following:
>
> -- cut --
>
> library(dplyr)
>
> test1 <- c(rep(1, 4), rep(0, 6))
> d_test1 <- data.frame(test)
>
> test2 <- factor(test1)
> d_test2 <- data.frame(test2)
>
> test3 <- factor(test1,
>                 levels = c(0, 1),
>                 labels = c("WITHOUT Contact", "WITH Contact"))
> d_test3 <- data.frame(test3)
>
> d_test1 %>% filter(test1 == 0)  # works OK
> d_test2 %>% filter(test2 == 0)  # works OK
> d_test3 %>% filter(test3 == 0)  # does not work, why?
>
> myf <- function(ds) {
>   print(levels(ds$test3))
>   print(labels(ds$test3))
>   print(as.numeric(ds$test3))
>   print(as.character(ds$test3))
> }
>
> # This showsthat it is not possible to access the original
> # values which were the basis to build the factor:
> myf(d_test3)
>
> -- cut --
>
> Why is it not possible to use a factor with labels for filtering with 
the
> original values?
> Is there a data structure that works like a factor but gives also access
> to the original values?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara
NOTE NEW ADDRESS!!!
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +49 1515 888 5440
Journal of Negative Results - EEB: www.jnr-eeb.org


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From G.Maubach at weinwolf.de  Tue May  9 15:37:42 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 9 May 2017 15:37:42 +0200
Subject: [R] Antwort: RE:  Antwort: Re:  Factors and Alternatives (SOLVED)
In-Reply-To: <2d9bd812b14048d282c9a0689b22902e@exch-2p-mbx-w2.ads.tamu.edu>
References: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>
 <CAN-Z0xWscjggKD2iEr7vYb8gUjP_aLJog=FeGe7ps1Reu2pBbg@mail.gmail.com>
 <OFDEE4B875.A7F9900D-ONC125811B.003EFADF-C125811B.003FC750@lotus.hawesko.de>
 <2d9bd812b14048d282c9a0689b22902e@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <OFBFFBF970.28B09428-ONC125811B.0047E624-C125811B.004ADCBB@lotus.hawesko.de>

Hi David,
Hi Bob,

many thanks for your help.

Your solution - just to use all levels instead of just the one's found in 
the data - helped.

The original code looked like this:

-- cut --

c_v10_val_labs <- c(
  "1 = sehr gut",
  "2", "3", "4", "5",
  "6 = sehr schlecht"
)

# where c_v10_val_labs is handed over to my function as "val_labs".

  ds_results$value <- factor(ds_results$value,
                             levels = sort(unique(ds_results$value)),  # 
old code
                             labels = sort(unique(val_labs)))

-- cut --

If I write instead

-- cut --

  ds_results$value <- factor(ds_results$value,
                             levels = seq_along(val_labs),  # new code 1st 
version
                             labels = sort(unique(val_labs)))

-- cut --

Your solution builds a factor with all factor levels even if a value for 
factor is not present (not NA, but does just not occur in the data, i.e. 
not stated by any respondent).

In Zumel's book "Practical Data Science with R" (
https://www.amazon.de/Practical-Data-Science-Nina-Zumel/dp/1617291560), 
Shelter Island: Manning, 2014, p. 23-24, Listing 2-5, a mapping using 
subscripts is described:

-- cut --

mapping <- list(
'A40'='car (new)',
'A41'='car (used)',
'A42'='furniture/equipment',
'A43'='radio/television',
'A44'='domestic appliances',
...
)

for(i in 1:(dim(d))[2]) {
if(class(d[,i])=='character') {
d[,i] <- as.factor(as.character(mapping[d[,i]]))
}
}

-- cut -

Simple stated this would mean:

-- cut --

val_labs <- list(
  "1" = "1 = sehr gut",
  "2" = "2",
  "3" = "3",
  "4" = "4",
  "5" = "5",
  "6" = "6 = sehr schlecht"
)

set.seed(12345)
answers = c(sample(1:5, 10, replace = TRUE))

test <- factor(unlist(val_labs[answers]))

# or just

val_labs <- c(
  "1 = sehr gut",
  "2",
  "3",
  "4",
  "5",
  "6 = sehr schlecht"
)

set.seed(12345)
answers = c(sample(1:5, 10, replace = TRUE))

test <- val_labs[answers]

-- cut --

Adapting this to my code would give:

-- cut --

  ds_results$value <- factor(ds_results$value,
                             levels = sort(unique(ds_results$value)),
                             labels = 
val_labs[sort(unique(ds_results$value))])  # new code 2nd version

-- cut --

This results in a factor just as long as the vector of unique resulting 
values.

Both solutions work. Which version is best depends on the overall process 
and the purpose of the code. I document all this for use by readers who 
refer later to the list archives.

Using your version and running my code reveals that ggplot runs into 
difficulties cause the legend lacks values and the sequence and coloring 
of the legend is wrong. But that's another story.

Many thanks again for your help.

Kind regards

Georg




Von:    David L Carlson <dcarlson at tamu.edu>
An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, "Bob O'Hara" 
<rni.boh at gmail.com>, 
Kopie:  r-help <r-help at r-project.org>
Datum:  09.05.2017 14:37
Betreff:        RE: [R] Antwort: Re:  Factors and Alternatives



I'm not sure I understand your question, but you can easily include all 
possible answers when you create the factor by using the levels= argument 
as Bob pointed out. Here is an example of values that range from 1 to 6, 
but value 3 is not represented. Notice that a factor level 3 is created 
even though it does not appear in the data:

> set.seed(42)
> x <- sample.int(6, 10, replace=TRUE)
> table(x)
x
1 2 4 5 6 
1 1 3 3 2 
> y <- factor(x, levels=1:6)
> y
 [1] 6 6 2 5 4 4 5 1 4 5
Levels: 1 2 3 4 5 6

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

Von:    "Bob O'Hara" <rni.boh at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help <r-help at r-project.org>
Datum:  09.05.2017 13:58
Betreff:        Re: Re: [R] Factors and Alternatives



For the problem you state, would it be enough to explicitly define your 
levels?

fac <- rep(c("a", "b", "d"), each=4)
fac.f <- factor(fac, levels=c("a", "b", "c", "d"))
table(fac.f)

# but be warned...
fac.f2 <- factor(fac.f)
table(fac.f2)

This has the advantage that the code explicitly documents what the
possible values are, so if something goes wrong down-stream, you know
it is a real problem (well, unless you have some type conversions
screwing things up). You might also want to do some defensive
programming, and put some checks in the code, to make sure your
factors have the right number of levels.

Bob

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
G.Maubach at weinwolf.de
Sent: Tuesday, May 9, 2017 6:37 AM
To: Bob O'Hara <rni.boh at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: [R] Antwort: Re: Factors and Alternatives

Hi Bob,

many thanks for your reply.

I have read the documentation. In my current project I use "item 
batteries" for dimensions of touchpoints which are rated by our customers. 

I wrote functions to analyse them. If I create a factor before filtering 
and analysing I lose the original values of the variable. If I use the 
original variable for filtering and analysis I might happen that for some 
dimensions values were not selected. This means they are not NA but none 
of the respondents chose "4" for instance on a scale from 1 to 6. That 
means that creating a factor from the analysed data with the complete 
scale (1:6) fails due the different vector length (amount of remaining 
unique values in the analysis vs values in the scale). As I have a 
function doing the analysis I am looking for a way to make my function 
robust to such circumstances and be able to use it to analyse all "item 
batteries". Thus my question. I believe my findings are not odd. Maybe 
there is a way dealing with that kind of problems in R and I am eager to 
learn how it can be solved using R.

What would you suggest?

Kind regards

Georg




Von:    "Bob O'Hara" <rni.boh at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help <r-help at r-project.org>
Datum:  09.05.2017 12:26
Betreff:        Re: [R] Factors and Alternatives



That's easy! First
> str(test3)
 Factor w/ 2 levels "WITHOUT Contact",..: 2 2 2 2 1 1 1 1 1 1

tells you that the internal values are 1 and 2, and the labels are
"WITHOUT Contact" and "WITH Contact". If you read the help page for
factor() you'll see this:

levels: an optional vector of the values (as character strings) that
          ?x? might have taken.  The default is the unique set of
          values taken by ?as.character(x)?, sorted into increasing
          order _of ?x?_.  Note that this set can be specified as
          smaller than ?sort(unique(x))?.

  labels: _either_ an optional character vector of (unique) labels for
          the levels (in the same order as ?levels? after removing
          those in ?exclude?), _or_ a character string of length 1.

So, when you create test3 you say that test can take values 0 and 1,
and these should be labelled as "WITHOUT Contact" and "WITH Contact".
So R internally codes "1" as 1 and "0" as 2 (internally R codes
factors as integers, which can be both useful and dangerous), and then
gives them labels "WITHOUT Contact" and "WITH Contact". It now doesn't
care that they were 1 and 0, because you've told it to change the
labels.

If you want to filter by the original values, then don't change the
labels (or at least not until after you've filtered by the original
labels), or convert the filter to the new labels. You're asking for a
data structure with two sets of labels, which sounds odd in general.

Bob

On 9 May 2017 at 12:12,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I am using factors in a study for the social sciences.
>
> I discovered the following:
>
> -- cut --
>
> library(dplyr)
>
> test1 <- c(rep(1, 4), rep(0, 6))
> d_test1 <- data.frame(test)
>
> test2 <- factor(test1)
> d_test2 <- data.frame(test2)
>
> test3 <- factor(test1,
>                 levels = c(0, 1),
>                 labels = c("WITHOUT Contact", "WITH Contact"))
> d_test3 <- data.frame(test3)
>
> d_test1 %>% filter(test1 == 0)  # works OK
> d_test2 %>% filter(test2 == 0)  # works OK
> d_test3 %>% filter(test3 == 0)  # does not work, why?
>
> myf <- function(ds) {
>   print(levels(ds$test3))
>   print(labels(ds$test3))
>   print(as.numeric(ds$test3))
>   print(as.character(ds$test3))
> }
>
> # This showsthat it is not possible to access the original
> # values which were the basis to build the factor:
> myf(d_test3)
>
> -- cut --
>
> Why is it not possible to use a factor with labels for filtering with 
the
> original values?
> Is there a data structure that works like a factor but gives also access
> to the original values?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara
NOTE NEW ADDRESS!!!
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +49 1515 888 5440
Journal of Negative Results - EEB: www.jnr-eeb.org


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From r_goertz at web.de  Tue May  9 16:20:45 2017
From: r_goertz at web.de (Ralf Goertz)
Date: Tue, 9 May 2017 16:20:45 +0200
Subject: [R] loading edited functions already in saved workspace
 automatically
In-Reply-To: <aa2b0963-13a2-5014-aa9a-0355239f2e6e@yorku.ca>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>
 <20170505162314.1e6a1020@delli.home.local>
 <aa2b0963-13a2-5014-aa9a-0355239f2e6e@yorku.ca>
Message-ID: <20170509162045.0b3af691@delli.home.local>

Am Sat, 6 May 2017 11:17:42 -0400
schrieb Michael Friendly <friendly at yorku.ca>:

> On 5/5/2017 10:23 AM, Ralf Goertz wrote:
> > Am Fri, 05 May 2017 07:14:36 -0700
> > schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
> >  
> >> R normally prompts you to save .RData, but it just automatically
> >> saves .Rhistory... the two are unrelated.  
> >
> > Not here. If I say "n" to the prompted question "Save workspace
> > image? [y/n/c]: " my history doesn't get saved.
> >
> > Version:
> >
> > R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
> > Copyright (C) 2016 The R Foundation for Statistical Computing
> > Platform: x86_64-suse-linux-gnu (64-bit)
> >  
> 
> On Windoze, here's what I use in my .Rprofile, which runs every time
> I start an RGUI coonsole.  The key is .First & .Last to load/save
> history automagically.

Hi Michael,

thanks. This helps with saving the history without saving the data. But
actually I'd really like to save both and still be able to load
functions automatically from .Rprofile. Not saving the data as Jeff
suggested is not a good option because it is sometimes tedious to
rebuild my environment by reexecuting commands in the history. And I
explained in my OP why I can't use .First() to achieve my goal.

But let me try again to explain the problem because I think not
everybody understood what I was trying to say. For simplicity I use the
plain variable "a" instead of a function. Start a fresh session and
remove all variables, define one variable and quit with saving:

> rm(list=ls())
> a=17
> quit(save="yes")

Now, before opening a new session edit .Rprofile such that it contains
just the two lines:

print("Hello from .Rprofile")
a=42

Start a new session where your saved environment will be loaded.
Observe that you see the line 

[1] "Hello from .Rprofile"

proving that the commands in .Rprofile have been executed. Now look at
"a":

> a
[1] 17


You would expect to see this because *after* your "Hello" line you find

[Previously saved workspace restored]

So you have set "a" to 42 in .Rprofile but it gets overwritten from the
previously saved and now restored workspace. On the other hand, .First()
gets executed after the restoring of the workspace. Therefore, I could
edit .Rprofile to read

.First=function(){ assign("a",42,pos=1) }

Now, after starting I see that "a" is indeed 42. But then it turns out
that from now on I need "a" to be 11. After editing .Rprofile
accordingly, I am quite hopeful but after starting a new session I see
that "a" is still 42. Why is that? Because .First() was saved and when I
started a new session it got a new function body (setting "a" to 11) but
before it could be executed it was again overwritten by the old value
(setting "a" to 42) and I am chasing my own tail. Sigh.

.Last() doesn't help. Apparently (at least on my linux system) it is
executed *after* saving the environment so too late to remove anything
you don't want saved. In that regard linux doesn't seem to be typical,
since in "?.Last" the reverse order is described as typical:

     Exactly what happens at termination of an R session depends on the
     platform and GUI interface in use.  A typical sequence is to run
     ?.Last()? and ?.Last.sys()? (unless ?runLast? is false), to save
     the workspace if requested (and in most cases also to save the
     session history: see ?savehistory?), then run any finalizers (see
     ?reg.finalizer?) that have been set to be run on exit, close all
     open graphics devices, remove the session temporary directory and
     print any remaining warnings (e.g., from ?.Last()? and device
     closure).


IMHO this is a design flaw.

Ralf


From chocold12 at gmail.com  Tue May  9 16:38:30 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 9 May 2017 08:38:30 -0600
Subject: [R] About calculating average values from several matrices
Message-ID: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>

Hi R users,

I have a question about manipulating the data.
For example, there are several such data frames or matrices, and I want to
calculate the average value from all the data frames or matrices. How to do
it? Also, should I convert them to data frame or matrix first? Right now,
when I use typeof() function, each one is a list.

file1
            jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov

app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2   1.1
app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8   1.8
app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2   4.1

file2
            jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov

app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5   1.6
app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2   1.4
app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3   4.2

file3 has the similar structure and values...

There are eight such files, and when I use the function mean(file1, file2,
file3, ..., file8), it returns the error below. Thanks for your help.

Warning message:
In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
  argument is not numeric or logical: returning NA

	[[alternative HTML version deleted]]


From HDoran at air.org  Tue May  9 16:41:17 2017
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 May 2017 14:41:17 +0000
Subject: [R] About calculating average values from several matrices
In-Reply-To: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>

Are you trying to take the mean over all cells, or over rows/columns within each dataframe. Also, are these different dataframes stored within a list or are they standalone?



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
Sent: Tuesday, May 09, 2017 10:39 AM
To: R mailing list <r-help at r-project.org>
Subject: [R] About calculating average values from several matrices

Hi R users,

I have a question about manipulating the data.
For example, there are several such data frames or matrices, and I want to calculate the average value from all the data frames or matrices. How to do it? Also, should I convert them to data frame or matrix first? Right now, when I use typeof() function, each one is a list.

file1
            jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov

app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2   1.1
app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8   1.8
app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2   4.1

file2
            jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov

app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5   1.6
app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2   1.4
app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3   4.2

file3 has the similar structure and values...

There are eight such files, and when I use the function mean(file1, file2, file3, ..., file8), it returns the error below. Thanks for your help.

Warning message:
In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
  argument is not numeric or logical: returning NA

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Tue May  9 16:44:13 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 9 May 2017 08:44:13 -0600
Subject: [R] About calculating average values from several matrices
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
Message-ID: <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>

I'm trying to get a new dataframe or whatever to call, which has the same
structure with each file as listed above. For each cell in the new
dataframe or the new file, it is the average value from former dataframes
at the same location. Thanks.

On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org> wrote:

> Are you trying to take the mean over all cells, or over rows/columns
> within each dataframe. Also, are these different dataframes stored within a
> list or are they standalone?
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> Sent: Tuesday, May 09, 2017 10:39 AM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] About calculating average values from several matrices
>
> Hi R users,
>
> I have a question about manipulating the data.
> For example, there are several such data frames or matrices, and I want to
> calculate the average value from all the data frames or matrices. How to do
> it? Also, should I convert them to data frame or matrix first? Right now,
> when I use typeof() function, each one is a list.
>
> file1
>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>
> app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2   1.1
> app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8   1.8
> app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2   4.1
>
> file2
>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>
> app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5   1.6
> app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2   1.4
> app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3   4.2
>
> file3 has the similar structure and values...
>
> There are eight such files, and when I use the function mean(file1, file2,
> file3, ..., file8), it returns the error below. Thanks for your help.
>
> Warning message:
> In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
>   argument is not numeric or logical: returning NA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From HDoran at air.org  Tue May  9 16:50:26 2017
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 May 2017 14:50:26 +0000
Subject: [R] About calculating average values from several matrices
In-Reply-To: <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>

It?s not clear to me what your actual structure is. Can you provide str(object)? Assuming it is a list, and you want the mean over all cells or columns, you might want like this:

myData <- vector("list", 3)

for(i in 1:3){
                myData[[i]] <- matrix(rnorm(100), 10, 10)
                }

### mean over all cells
sapply(myData, function(x) mean(x))

### mean over all columns
sapply(myData, function(x) colMeans(x))





From: lily li [mailto:chocold12 at gmail.com]
Sent: Tuesday, May 09, 2017 10:44 AM
To: Doran, Harold <HDoran at air.org>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] About calculating average values from several matrices

I'm trying to get a new dataframe or whatever to call, which has the same structure with each file as listed above. For each cell in the new dataframe or the new file, it is the average value from former dataframes at the same location. Thanks.

On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
Are you trying to take the mean over all cells, or over rows/columns within each dataframe. Also, are these different dataframes stored within a list or are they standalone?



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of lily li
Sent: Tuesday, May 09, 2017 10:39 AM
To: R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: [R] About calculating average values from several matrices

Hi R users,

I have a question about manipulating the data.
For example, there are several such data frames or matrices, and I want to calculate the average value from all the data frames or matrices. How to do it? Also, should I convert them to data frame or matrix first? Right now, when I use typeof() function, each one is a list.

file1
            jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov

app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2   1.1
app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8   1.8
app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2   4.1

file2
            jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov

app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5   1.6
app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2   1.4
app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3   4.2

file3 has the similar structure and values...

There are eight such files, and when I use the function mean(file1, file2, file3, ..., file8), it returns the error below. Thanks for your help.

Warning message:
In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
  argument is not numeric or logical: returning NA
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue May  9 16:52:42 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 9 May 2017 08:52:42 -0600
Subject: [R] About calculating average values from several matrices
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
Message-ID: <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>

I meant for each cell, it takes the average from other dataframes at the
same cell. I don't know how to deal with row names and col names though, so
it has the error message.

On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org> wrote:

> It?s not clear to me what your actual structure is. Can you provide
> str(object)? Assuming it is a list, and you want the mean over all cells or
> columns, you might want like this:
>
>
>
> myData <- vector("list", 3)
>
>
>
> for(i in 1:3){
>
>                 myData[[i]] <- matrix(rnorm(100), 10, 10)
>
>                 }
>
>
>
> ### mean over all cells
>
> sapply(myData, function(x) mean(x))
>
>
>
> ### mean over all columns
>
> sapply(myData, function(x) colMeans(x))
>
>
>
>
>
>
>
>
>
>
>
> *From:* lily li [mailto:chocold12 at gmail.com]
> *Sent:* Tuesday, May 09, 2017 10:44 AM
> *To:* Doran, Harold <HDoran at air.org>
> *Cc:* R mailing list <r-help at r-project.org>
> *Subject:* Re: [R] About calculating average values from several matrices
>
>
>
> I'm trying to get a new dataframe or whatever to call, which has the same
> structure with each file as listed above. For each cell in the new
> dataframe or the new file, it is the average value from former dataframes
> at the same location. Thanks.
>
>
>
> On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org> wrote:
>
> Are you trying to take the mean over all cells, or over rows/columns
> within each dataframe. Also, are these different dataframes stored within a
> list or are they standalone?
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> Sent: Tuesday, May 09, 2017 10:39 AM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] About calculating average values from several matrices
>
> Hi R users,
>
> I have a question about manipulating the data.
> For example, there are several such data frames or matrices, and I want to
> calculate the average value from all the data frames or matrices. How to do
> it? Also, should I convert them to data frame or matrix first? Right now,
> when I use typeof() function, each one is a list.
>
> file1
>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>
> app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2   1.1
> app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8   1.8
> app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2   4.1
>
> file2
>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>
> app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5   1.6
> app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2   1.4
> app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3   4.2
>
> file3 has the similar structure and values...
>
> There are eight such files, and when I use the function mean(file1, file2,
> file3, ..., file8), it returns the error below. Thanks for your help.
>
> Warning message:
> In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
>   argument is not numeric or logical: returning NA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Tue May  9 17:04:27 2017
From: cdetermanjr at gmail.com (Charles Determan)
Date: Tue, 9 May 2017 10:04:27 -0500
Subject: [R] About calculating average values from several matrices
In-Reply-To: <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
 <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
Message-ID: <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>

If you want the mean of each element across you list of matrices the
following should provide what you are looking for where Reduce sums all
your matrix elements across matrices and the simply divided my the number
of matrices for the element-wise mean.

Reduce(`+`, mylist)/length(mylist)

Regards,
Charles

On Tue, May 9, 2017 at 9:52 AM, lily li <chocold12 at gmail.com> wrote:

> I meant for each cell, it takes the average from other dataframes at the
> same cell. I don't know how to deal with row names and col names though, so
> it has the error message.
>
> On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org> wrote:
>
> > It?s not clear to me what your actual structure is. Can you provide
> > str(object)? Assuming it is a list, and you want the mean over all cells
> or
> > columns, you might want like this:
> >
> >
> >
> > myData <- vector("list", 3)
> >
> >
> >
> > for(i in 1:3){
> >
> >                 myData[[i]] <- matrix(rnorm(100), 10, 10)
> >
> >                 }
> >
> >
> >
> > ### mean over all cells
> >
> > sapply(myData, function(x) mean(x))
> >
> >
> >
> > ### mean over all columns
> >
> > sapply(myData, function(x) colMeans(x))
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > *From:* lily li [mailto:chocold12 at gmail.com]
> > *Sent:* Tuesday, May 09, 2017 10:44 AM
> > *To:* Doran, Harold <HDoran at air.org>
> > *Cc:* R mailing list <r-help at r-project.org>
> > *Subject:* Re: [R] About calculating average values from several matrices
> >
> >
> >
> > I'm trying to get a new dataframe or whatever to call, which has the same
> > structure with each file as listed above. For each cell in the new
> > dataframe or the new file, it is the average value from former dataframes
> > at the same location. Thanks.
> >
> >
> >
> > On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org> wrote:
> >
> > Are you trying to take the mean over all cells, or over rows/columns
> > within each dataframe. Also, are these different dataframes stored
> within a
> > list or are they standalone?
> >
> >
> >
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> > Sent: Tuesday, May 09, 2017 10:39 AM
> > To: R mailing list <r-help at r-project.org>
> > Subject: [R] About calculating average values from several matrices
> >
> > Hi R users,
> >
> > I have a question about manipulating the data.
> > For example, there are several such data frames or matrices, and I want
> to
> > calculate the average value from all the data frames or matrices. How to
> do
> > it? Also, should I convert them to data frame or matrix first? Right now,
> > when I use typeof() function, each one is a list.
> >
> > file1
> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>  nov
> >
> > app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2
>  1.1
> > app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8
>  1.8
> > app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2
>  4.1
> >
> > file2
> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>  nov
> >
> > app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5
>  1.6
> > app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2
>  1.4
> > app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3
>  4.2
> >
> > file3 has the similar structure and values...
> >
> > There are eight such files, and when I use the function mean(file1,
> file2,
> > file3, ..., file8), it returns the error below. Thanks for your help.
> >
> > Warning message:
> > In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
> >   argument is not numeric or logical: returning NA
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue May  9 17:09:44 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 9 May 2017 09:09:44 -0600
Subject: [R] About calculating average values from several matrices
In-Reply-To: <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
 <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
 <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>
Message-ID: <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>

Thanks very much, it works. But how to round the values to have only 1
decimal digit or 2 decimal digits? I think by dividing, the values are
double type now. Thanks again.


On Tue, May 9, 2017 at 9:04 AM, Charles Determan <cdetermanjr at gmail.com>
wrote:

> If you want the mean of each element across you list of matrices the
> following should provide what you are looking for where Reduce sums all
> your matrix elements across matrices and the simply divided my the number
> of matrices for the element-wise mean.
>
> Reduce(`+`, mylist)/length(mylist)
>
> Regards,
> Charles
>
> On Tue, May 9, 2017 at 9:52 AM, lily li <chocold12 at gmail.com> wrote:
>
>> I meant for each cell, it takes the average from other dataframes at the
>> same cell. I don't know how to deal with row names and col names though,
>> so
>> it has the error message.
>>
>> On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org> wrote:
>>
>> > It?s not clear to me what your actual structure is. Can you provide
>> > str(object)? Assuming it is a list, and you want the mean over all
>> cells or
>> > columns, you might want like this:
>> >
>> >
>> >
>> > myData <- vector("list", 3)
>> >
>> >
>> >
>> > for(i in 1:3){
>> >
>> >                 myData[[i]] <- matrix(rnorm(100), 10, 10)
>> >
>> >                 }
>> >
>> >
>> >
>> > ### mean over all cells
>> >
>> > sapply(myData, function(x) mean(x))
>> >
>> >
>> >
>> > ### mean over all columns
>> >
>> > sapply(myData, function(x) colMeans(x))
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > *From:* lily li [mailto:chocold12 at gmail.com]
>> > *Sent:* Tuesday, May 09, 2017 10:44 AM
>> > *To:* Doran, Harold <HDoran at air.org>
>> > *Cc:* R mailing list <r-help at r-project.org>
>> > *Subject:* Re: [R] About calculating average values from several
>> matrices
>>
>> >
>> >
>> >
>> > I'm trying to get a new dataframe or whatever to call, which has the
>> same
>> > structure with each file as listed above. For each cell in the new
>> > dataframe or the new file, it is the average value from former
>> dataframes
>> > at the same location. Thanks.
>> >
>> >
>> >
>> > On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org> wrote:
>> >
>> > Are you trying to take the mean over all cells, or over rows/columns
>> > within each dataframe. Also, are these different dataframes stored
>> within a
>> > list or are they standalone?
>> >
>> >
>> >
>> >
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
>> > Sent: Tuesday, May 09, 2017 10:39 AM
>> > To: R mailing list <r-help at r-project.org>
>> > Subject: [R] About calculating average values from several matrices
>> >
>> > Hi R users,
>> >
>> > I have a question about manipulating the data.
>> > For example, there are several such data frames or matrices, and I want
>> to
>> > calculate the average value from all the data frames or matrices. How
>> to do
>> > it? Also, should I convert them to data frame or matrix first? Right
>> now,
>> > when I use typeof() function, each one is a list.
>> >
>> > file1
>> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>>  nov
>> >
>> > app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2
>>  1.1
>> > app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8
>>  1.8
>> > app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2
>>  4.1
>> >
>> > file2
>> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>>  nov
>> >
>> > app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5
>>  1.6
>> > app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2
>>  1.4
>> > app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3
>>  4.2
>> >
>> > file3 has the similar structure and values...
>> >
>> > There are eight such files, and when I use the function mean(file1,
>> file2,
>> > file3, ..., file8), it returns the error below. Thanks for your help.
>> >
>> > Warning message:
>> > In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
>> >   argument is not numeric or logical: returning NA
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Tue May  9 17:11:17 2017
From: cdetermanjr at gmail.com (Charles Determan)
Date: Tue, 9 May 2017 10:11:17 -0500
Subject: [R] About calculating average values from several matrices
In-Reply-To: <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
 <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
 <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>
 <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>
Message-ID: <CAKxd1KMwq3yVMBZtg1gJSfG4tGA4s4uUxPuXDzZWLgVa2cxNqQ@mail.gmail.com>

Just call 'round' on your results then at your desired number of digits.

On Tue, May 9, 2017 at 10:09 AM, lily li <chocold12 at gmail.com> wrote:

> Thanks very much, it works. But how to round the values to have only 1
> decimal digit or 2 decimal digits? I think by dividing, the values are
> double type now. Thanks again.
>
>
> On Tue, May 9, 2017 at 9:04 AM, Charles Determan <cdetermanjr at gmail.com>
> wrote:
>
>> If you want the mean of each element across you list of matrices the
>> following should provide what you are looking for where Reduce sums all
>> your matrix elements across matrices and the simply divided my the number
>> of matrices for the element-wise mean.
>>
>> Reduce(`+`, mylist)/length(mylist)
>>
>> Regards,
>> Charles
>>
>> On Tue, May 9, 2017 at 9:52 AM, lily li <chocold12 at gmail.com> wrote:
>>
>>> I meant for each cell, it takes the average from other dataframes at the
>>> same cell. I don't know how to deal with row names and col names though,
>>> so
>>> it has the error message.
>>>
>>> On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org> wrote:
>>>
>>> > It?s not clear to me what your actual structure is. Can you provide
>>> > str(object)? Assuming it is a list, and you want the mean over all
>>> cells or
>>> > columns, you might want like this:
>>> >
>>> >
>>> >
>>> > myData <- vector("list", 3)
>>> >
>>> >
>>> >
>>> > for(i in 1:3){
>>> >
>>> >                 myData[[i]] <- matrix(rnorm(100), 10, 10)
>>> >
>>> >                 }
>>> >
>>> >
>>> >
>>> > ### mean over all cells
>>> >
>>> > sapply(myData, function(x) mean(x))
>>> >
>>> >
>>> >
>>> > ### mean over all columns
>>> >
>>> > sapply(myData, function(x) colMeans(x))
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>> > *From:* lily li [mailto:chocold12 at gmail.com]
>>> > *Sent:* Tuesday, May 09, 2017 10:44 AM
>>> > *To:* Doran, Harold <HDoran at air.org>
>>> > *Cc:* R mailing list <r-help at r-project.org>
>>> > *Subject:* Re: [R] About calculating average values from several
>>> matrices
>>>
>>> >
>>> >
>>> >
>>> > I'm trying to get a new dataframe or whatever to call, which has the
>>> same
>>> > structure with each file as listed above. For each cell in the new
>>> > dataframe or the new file, it is the average value from former
>>> dataframes
>>> > at the same location. Thanks.
>>> >
>>> >
>>> >
>>> > On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org> wrote:
>>> >
>>> > Are you trying to take the mean over all cells, or over rows/columns
>>> > within each dataframe. Also, are these different dataframes stored
>>> within a
>>> > list or are they standalone?
>>> >
>>> >
>>> >
>>> >
>>> > -----Original Message-----
>>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily
>>> li
>>> > Sent: Tuesday, May 09, 2017 10:39 AM
>>> > To: R mailing list <r-help at r-project.org>
>>> > Subject: [R] About calculating average values from several matrices
>>> >
>>> > Hi R users,
>>> >
>>> > I have a question about manipulating the data.
>>> > For example, there are several such data frames or matrices, and I
>>> want to
>>> > calculate the average value from all the data frames or matrices. How
>>> to do
>>> > it? Also, should I convert them to data frame or matrix first? Right
>>> now,
>>> > when I use typeof() function, each one is a list.
>>> >
>>> > file1
>>> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>>>  nov
>>> >
>>> > app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2
>>>  1.1
>>> > app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8
>>>  1.8
>>> > app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2
>>>  4.1
>>> >
>>> > file2
>>> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>>>  nov
>>> >
>>> > app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5
>>>  1.6
>>> > app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2
>>>  1.4
>>> > app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3
>>>  4.2
>>> >
>>> > file3 has the similar structure and values...
>>> >
>>> > There are eight such files, and when I use the function mean(file1,
>>> file2,
>>> > file3, ..., file8), it returns the error below. Thanks for your help.
>>> >
>>> > Warning message:
>>> > In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
>>> >   argument is not numeric or logical: returning NA
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/
>>> > posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From HDoran at air.org  Tue May  9 17:11:23 2017
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 May 2017 15:11:23 +0000
Subject: [R] About calculating average values from several matrices
In-Reply-To: <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
 <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
 <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>
 <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69AAB@DC1VEX10MB01.air.org>

?round


From: lily li [mailto:chocold12 at gmail.com]
Sent: Tuesday, May 09, 2017 11:10 AM
To: Charles Determan <cdetermanjr at gmail.com>
Cc: Doran, Harold <HDoran at air.org>; R mailing list <r-help at r-project.org>
Subject: Re: [R] About calculating average values from several matrices

Thanks very much, it works. But how to round the values to have only 1 decimal digit or 2 decimal digits? I think by dividing, the values are double type now. Thanks again.


On Tue, May 9, 2017 at 9:04 AM, Charles Determan <cdetermanjr at gmail.com<mailto:cdetermanjr at gmail.com>> wrote:
If you want the mean of each element across you list of matrices the following should provide what you are looking for where Reduce sums all your matrix elements across matrices and the simply divided my the number of matrices for the element-wise mean.

Reduce(`+`, mylist)/length(mylist)
Regards,
Charles

On Tue, May 9, 2017 at 9:52 AM, lily li <chocold12 at gmail.com<mailto:chocold12 at gmail.com>> wrote:
I meant for each cell, it takes the average from other dataframes at the
same cell. I don't know how to deal with row names and col names though, so
it has the error message.

On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:

> It?s not clear to me what your actual structure is. Can you provide
> str(object)? Assuming it is a list, and you want the mean over all cells or
> columns, you might want like this:
>
>
>
> myData <- vector("list", 3)
>
>
>
> for(i in 1:3){
>
>                 myData[[i]] <- matrix(rnorm(100), 10, 10)
>
>                 }
>
>
>
> ### mean over all cells
>
> sapply(myData, function(x) mean(x))
>
>
>
> ### mean over all columns
>
> sapply(myData, function(x) colMeans(x))
>
>
>
>
>
>
>
>
>
>
>
> *From:* lily li [mailto:chocold12 at gmail.com<mailto:chocold12 at gmail.com>]
> *Sent:* Tuesday, May 09, 2017 10:44 AM
> *To:* Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
> *Cc:* R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> *Subject:* Re: [R] About calculating average values from several matrices

>
>
>
> I'm trying to get a new dataframe or whatever to call, which has the same
> structure with each file as listed above. For each cell in the new
> dataframe or the new file, it is the average value from former dataframes
> at the same location. Thanks.
>
>
>
> On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>
> Are you trying to take the mean over all cells, or over rows/columns
> within each dataframe. Also, are these different dataframes stored within a
> list or are they standalone?
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of lily li
> Sent: Tuesday, May 09, 2017 10:39 AM
> To: R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] About calculating average values from several matrices
>
> Hi R users,
>
> I have a question about manipulating the data.
> For example, there are several such data frames or matrices, and I want to
> calculate the average value from all the data frames or matrices. How to do
> it? Also, should I convert them to data frame or matrix first? Right now,
> when I use typeof() function, each one is a list.
>
> file1
>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>
> app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2   1.1
> app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8   1.8
> app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2   4.1
>
> file2
>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>
> app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5   1.6
> app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2   1.4
> app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3   4.2
>
> file3 has the similar structure and values...
>
> There are eight such files, and when I use the function mean(file1, file2,
> file3, ..., file8), it returns the error below. Thanks for your help.
>
> Warning message:
> In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
>   argument is not numeric or logical: returning NA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue May  9 17:12:59 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 9 May 2017 09:12:59 -0600
Subject: [R] About calculating average values from several matrices
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69AAB@DC1VEX10MB01.air.org>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
 <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
 <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>
 <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69AAB@DC1VEX10MB01.air.org>
Message-ID: <CAN5afy_16zEktwThSbw1ocSnLpgMbwFAgeHnqehzdiGkExTf1g@mail.gmail.com>

Yes, that means to control decimal numbers. For example, use round(2.3122,
digits=1), it gets 2.3

On Tue, May 9, 2017 at 9:11 AM, Doran, Harold <HDoran at air.org> wrote:

> ?round
>
>
>
>
>
> *From:* lily li [mailto:chocold12 at gmail.com]
> *Sent:* Tuesday, May 09, 2017 11:10 AM
> *To:* Charles Determan <cdetermanjr at gmail.com>
> *Cc:* Doran, Harold <HDoran at air.org>; R mailing list <r-help at r-project.org
> >
> *Subject:* Re: [R] About calculating average values from several matrices
>
>
>
> Thanks very much, it works. But how to round the values to have only 1
> decimal digit or 2 decimal digits? I think by dividing, the values are
> double type now. Thanks again.
>
>
>
>
>
> On Tue, May 9, 2017 at 9:04 AM, Charles Determan <cdetermanjr at gmail.com>
> wrote:
>
> If you want the mean of each element across you list of matrices the
> following should provide what you are looking for where Reduce sums all
> your matrix elements across matrices and the simply divided my the number
> of matrices for the element-wise mean.
>
> Reduce(`+`, mylist)/length(mylist)
>
> Regards,
>
> Charles
>
>
>
> On Tue, May 9, 2017 at 9:52 AM, lily li <chocold12 at gmail.com> wrote:
>
> I meant for each cell, it takes the average from other dataframes at the
> same cell. I don't know how to deal with row names and col names though, so
> it has the error message.
>
> On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org> wrote:
>
> > It?s not clear to me what your actual structure is. Can you provide
> > str(object)? Assuming it is a list, and you want the mean over all cells
> or
> > columns, you might want like this:
> >
> >
> >
> > myData <- vector("list", 3)
> >
> >
> >
> > for(i in 1:3){
> >
> >                 myData[[i]] <- matrix(rnorm(100), 10, 10)
> >
> >                 }
> >
> >
> >
> > ### mean over all cells
> >
> > sapply(myData, function(x) mean(x))
> >
> >
> >
> > ### mean over all columns
> >
> > sapply(myData, function(x) colMeans(x))
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > *From:* lily li [mailto:chocold12 at gmail.com]
> > *Sent:* Tuesday, May 09, 2017 10:44 AM
> > *To:* Doran, Harold <HDoran at air.org>
> > *Cc:* R mailing list <r-help at r-project.org>
> > *Subject:* Re: [R] About calculating average values from several matrices
>
>
> >
> >
> >
> > I'm trying to get a new dataframe or whatever to call, which has the same
> > structure with each file as listed above. For each cell in the new
> > dataframe or the new file, it is the average value from former dataframes
> > at the same location. Thanks.
> >
> >
> >
> > On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org> wrote:
> >
> > Are you trying to take the mean over all cells, or over rows/columns
> > within each dataframe. Also, are these different dataframes stored
> within a
> > list or are they standalone?
> >
> >
> >
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> > Sent: Tuesday, May 09, 2017 10:39 AM
> > To: R mailing list <r-help at r-project.org>
>
> > Subject: [R] About calculating average values from several matrices
> >
> > Hi R users,
> >
> > I have a question about manipulating the data.
> > For example, there are several such data frames or matrices, and I want
> to
> > calculate the average value from all the data frames or matrices. How to
> do
> > it? Also, should I convert them to data frame or matrix first? Right now,
> > when I use typeof() function, each one is a list.
> >
> > file1
> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>  nov
> >
> > app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2
>  1.1
> > app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8
>  1.8
> > app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2
>  4.1
> >
> > file2
> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>  nov
> >
> > app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5
>  1.6
> > app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2
>  1.4
> > app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3
>  4.2
> >
> > file3 has the similar structure and values...
> >
> > There are eight such files, and when I use the function mean(file1,
> file2,
> > file3, ..., file8), it returns the error below. Thanks for your help.
> >
> > Warning message:
> > In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
> >   argument is not numeric or logical: returning NA
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
>
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From HDoran at air.org  Tue May  9 17:14:14 2017
From: HDoran at air.org (Doran, Harold)
Date: Tue, 9 May 2017 15:14:14 +0000
Subject: [R] About calculating average values from several matrices
In-Reply-To: <CAN5afy_16zEktwThSbw1ocSnLpgMbwFAgeHnqehzdiGkExTf1g@mail.gmail.com>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
 <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
 <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>
 <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69AAB@DC1VEX10MB01.air.org>
 <CAN5afy_16zEktwThSbw1ocSnLpgMbwFAgeHnqehzdiGkExTf1g@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69B29@DC1VEX10MB01.air.org>

Im not sure if you?re asking a question or confirming that it works for you. But, obviously, the code below behaves as expected

From: lily li [mailto:chocold12 at gmail.com]
Sent: Tuesday, May 09, 2017 11:13 AM
To: Doran, Harold <HDoran at air.org>
Cc: Charles Determan <cdetermanjr at gmail.com>; R mailing list <r-help at r-project.org>
Subject: Re: [R] About calculating average values from several matrices

Yes, that means to control decimal numbers. For example, use round(2.3122, digits=1), it gets 2.3

On Tue, May 9, 2017 at 9:11 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
?round


From: lily li [mailto:chocold12 at gmail.com<mailto:chocold12 at gmail.com>]
Sent: Tuesday, May 09, 2017 11:10 AM
To: Charles Determan <cdetermanjr at gmail.com<mailto:cdetermanjr at gmail.com>>
Cc: Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>; R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] About calculating average values from several matrices

Thanks very much, it works. But how to round the values to have only 1 decimal digit or 2 decimal digits? I think by dividing, the values are double type now. Thanks again.


On Tue, May 9, 2017 at 9:04 AM, Charles Determan <cdetermanjr at gmail.com<mailto:cdetermanjr at gmail.com>> wrote:
If you want the mean of each element across you list of matrices the following should provide what you are looking for where Reduce sums all your matrix elements across matrices and the simply divided my the number of matrices for the element-wise mean.

Reduce(`+`, mylist)/length(mylist)
Regards,
Charles

On Tue, May 9, 2017 at 9:52 AM, lily li <chocold12 at gmail.com<mailto:chocold12 at gmail.com>> wrote:
I meant for each cell, it takes the average from other dataframes at the
same cell. I don't know how to deal with row names and col names though, so
it has the error message.

On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:

> It?s not clear to me what your actual structure is. Can you provide
> str(object)? Assuming it is a list, and you want the mean over all cells or
> columns, you might want like this:
>
>
>
> myData <- vector("list", 3)
>
>
>
> for(i in 1:3){
>
>                 myData[[i]] <- matrix(rnorm(100), 10, 10)
>
>                 }
>
>
>
> ### mean over all cells
>
> sapply(myData, function(x) mean(x))
>
>
>
> ### mean over all columns
>
> sapply(myData, function(x) colMeans(x))
>
>
>
>
>
>
>
>
>
>
>
> *From:* lily li [mailto:chocold12 at gmail.com<mailto:chocold12 at gmail.com>]
> *Sent:* Tuesday, May 09, 2017 10:44 AM
> *To:* Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
> *Cc:* R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> *Subject:* Re: [R] About calculating average values from several matrices

>
>
>
> I'm trying to get a new dataframe or whatever to call, which has the same
> structure with each file as listed above. For each cell in the new
> dataframe or the new file, it is the average value from former dataframes
> at the same location. Thanks.
>
>
>
> On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>
> Are you trying to take the mean over all cells, or over rows/columns
> within each dataframe. Also, are these different dataframes stored within a
> list or are they standalone?
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of lily li
> Sent: Tuesday, May 09, 2017 10:39 AM
> To: R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] About calculating average values from several matrices
>
> Hi R users,
>
> I have a question about manipulating the data.
> For example, there are several such data frames or matrices, and I want to
> calculate the average value from all the data frames or matrices. How to do
> it? Also, should I convert them to data frame or matrix first? Right now,
> when I use typeof() function, each one is a list.
>
> file1
>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>
> app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2   1.1
> app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8   1.8
> app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2   4.1
>
> file2
>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>
> app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5   1.6
> app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2   1.4
> app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3   4.2
>
> file3 has the similar structure and values...
>
> There are eight such files, and when I use the function mean(file1, file2,
> file3, ..., file8), it returns the error below. Thanks for your help.
>
> Warning message:
> In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
>   argument is not numeric or logical: returning NA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue May  9 17:15:20 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 9 May 2017 09:15:20 -0600
Subject: [R] About calculating average values from several matrices
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69B29@DC1VEX10MB01.air.org>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
 <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
 <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>
 <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69AAB@DC1VEX10MB01.air.org>
 <CAN5afy_16zEktwThSbw1ocSnLpgMbwFAgeHnqehzdiGkExTf1g@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69B29@DC1VEX10MB01.air.org>
Message-ID: <CAN5afy-kw4zvxqKwCxR3mxVjvmRUD2Pkr89jcm4OU5B06MhRHQ@mail.gmail.com>

yes, I just tried for the dataframe and it works, so there is no problem on
this side.

On Tue, May 9, 2017 at 9:14 AM, Doran, Harold <HDoran at air.org> wrote:

> Im not sure if you?re asking a question or confirming that it works for
> you. But, obviously, the code below behaves as expected
>
>
>
> *From:* lily li [mailto:chocold12 at gmail.com]
> *Sent:* Tuesday, May 09, 2017 11:13 AM
> *To:* Doran, Harold <HDoran at air.org>
> *Cc:* Charles Determan <cdetermanjr at gmail.com>; R mailing list <
> r-help at r-project.org>
>
> *Subject:* Re: [R] About calculating average values from several matrices
>
>
>
> Yes, that means to control decimal numbers. For example, use round(2.3122,
> digits=1), it gets 2.3
>
>
>
> On Tue, May 9, 2017 at 9:11 AM, Doran, Harold <HDoran at air.org> wrote:
>
> ?round
>
>
>
>
>
> *From:* lily li [mailto:chocold12 at gmail.com]
> *Sent:* Tuesday, May 09, 2017 11:10 AM
> *To:* Charles Determan <cdetermanjr at gmail.com>
> *Cc:* Doran, Harold <HDoran at air.org>; R mailing list <r-help at r-project.org
> >
> *Subject:* Re: [R] About calculating average values from several matrices
>
>
>
> Thanks very much, it works. But how to round the values to have only 1
> decimal digit or 2 decimal digits? I think by dividing, the values are
> double type now. Thanks again.
>
>
>
>
>
> On Tue, May 9, 2017 at 9:04 AM, Charles Determan <cdetermanjr at gmail.com>
> wrote:
>
> If you want the mean of each element across you list of matrices the
> following should provide what you are looking for where Reduce sums all
> your matrix elements across matrices and the simply divided my the number
> of matrices for the element-wise mean.
>
> Reduce(`+`, mylist)/length(mylist)
>
> Regards,
>
> Charles
>
>
>
> On Tue, May 9, 2017 at 9:52 AM, lily li <chocold12 at gmail.com> wrote:
>
> I meant for each cell, it takes the average from other dataframes at the
> same cell. I don't know how to deal with row names and col names though, so
> it has the error message.
>
> On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org> wrote:
>
> > It?s not clear to me what your actual structure is. Can you provide
> > str(object)? Assuming it is a list, and you want the mean over all cells
> or
> > columns, you might want like this:
> >
> >
> >
> > myData <- vector("list", 3)
> >
> >
> >
> > for(i in 1:3){
> >
> >                 myData[[i]] <- matrix(rnorm(100), 10, 10)
> >
> >                 }
> >
> >
> >
> > ### mean over all cells
> >
> > sapply(myData, function(x) mean(x))
> >
> >
> >
> > ### mean over all columns
> >
> > sapply(myData, function(x) colMeans(x))
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > *From:* lily li [mailto:chocold12 at gmail.com]
> > *Sent:* Tuesday, May 09, 2017 10:44 AM
> > *To:* Doran, Harold <HDoran at air.org>
> > *Cc:* R mailing list <r-help at r-project.org>
> > *Subject:* Re: [R] About calculating average values from several matrices
>
>
> >
> >
> >
> > I'm trying to get a new dataframe or whatever to call, which has the same
> > structure with each file as listed above. For each cell in the new
> > dataframe or the new file, it is the average value from former dataframes
> > at the same location. Thanks.
> >
> >
> >
> > On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org> wrote:
> >
> > Are you trying to take the mean over all cells, or over rows/columns
> > within each dataframe. Also, are these different dataframes stored
> within a
> > list or are they standalone?
> >
> >
> >
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> > Sent: Tuesday, May 09, 2017 10:39 AM
> > To: R mailing list <r-help at r-project.org>
>
> > Subject: [R] About calculating average values from several matrices
> >
> > Hi R users,
> >
> > I have a question about manipulating the data.
> > For example, there are several such data frames or matrices, and I want
> to
> > calculate the average value from all the data frames or matrices. How to
> do
> > it? Also, should I convert them to data frame or matrix first? Right now,
> > when I use typeof() function, each one is a list.
> >
> > file1
> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>  nov
> >
> > app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2
>  1.1
> > app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8
>  1.8
> > app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2
>  4.1
> >
> > file2
> >             jan   feb   mar   apr   may   jun   jul   aug   sep   oct
>  nov
> >
> > app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5
>  1.6
> > app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2
>  1.4
> > app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3
>  4.2
> >
> > file3 has the similar structure and values...
> >
> > There are eight such files, and when I use the function mean(file1,
> file2,
> > file3, ..., file8), it returns the error below. Thanks for your help.
> >
> > Warning message:
> > In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
> >   argument is not numeric or logical: returning NA
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
>
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Tue May  9 17:49:22 2017
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 9 May 2017 11:49:22 -0400
Subject: [R] loading edited functions already in saved workspace
	automatically
In-Reply-To: <20170509162045.0b3af691@delli.home.local>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>
 <20170505162314.1e6a1020@delli.home.local>
 <aa2b0963-13a2-5014-aa9a-0355239f2e6e@yorku.ca>
 <20170509162045.0b3af691@delli.home.local>
Message-ID: <9c05e2ef-80be-daec-6b51-ba0ab24eec45@yorku.ca>

Ralf:

You are afflicted with several mind bugs:
* the "my-way mind bug" -- "I want to do it MY WAY, because that's sort 
of what
I know" and also,
* the "my-square-peg-should-fit-into-this-round-hole mind bug" -- "R 
should be able to
do it MY WAY, but it puts obstacles in my path," perhaps a subsidiary, 
but more technical:
* the "loading-a-function-or-data-is-the-same mind bug"
As in many things R, you can't always get to MY WAY from there, at least 
not without a tortuous journey.

You think you should be able to do everything you want in .Rprofile, but 
then you posed two separate problems:
(a) save/reload history
(b) save/reload functions and data

If you recognize them as two separate problems, there is an easier path:
(a) use .Rprofile only for making your history persistent, as I described
(b) Put your functions & data you always want available in a package; 
you can load it from .Rprofile

I originally defined a bunch of handy functions (e.g., cd(), a setwd() 
replacement, that works more like `cd` on unix, in that `cd()` returns 
to the previous directory; it also changes the Windows title to
`RGui:`  abbreviation of getwd() )

I moved them all out of .Rprofile, made a package `myutil` and now load 
them from there with

  #======================
  # load default packages
  #======================
      if (!require(myutil)) warning("myutil functions not available")

hope this helps,
-Michael

On 5/9/2017 10:20 AM, Ralf Goertz wrote:
> Am Sat, 6 May 2017 11:17:42 -0400
> schrieb Michael Friendly <friendly at yorku.ca>:
>
>> On 5/5/2017 10:23 AM, Ralf Goertz wrote:
>>> Am Fri, 05 May 2017 07:14:36 -0700
>>> schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>>   
>>>> R normally prompts you to save .RData, but it just automatically
>>>> saves .Rhistory... the two are unrelated.
>>> Not here. If I say "n" to the prompted question "Save workspace
>>> image? [y/n/c]: " my history doesn't get saved.
>>>
>>> Version:
>>>
>>> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>>> Copyright (C) 2016 The R Foundation for Statistical Computing
>>> Platform: x86_64-suse-linux-gnu (64-bit)
>>>   
>> On Windoze, here's what I use in my .Rprofile, which runs every time
>> I start an RGUI coonsole.  The key is .First & .Last to load/save
>> history automagically.
> Hi Michael,
>
> thanks. This helps with saving the history without saving the data. But
> actually I'd really like to save both and still be able to load
> functions automatically from .Rprofile. Not saving the data as Jeff
> suggested is not a good option because it is sometimes tedious to
> rebuild my environment by reexecuting commands in the history. And I
> explained in my OP why I can't use .First() to achieve my goal.
>
> But let me try again to explain the problem because I think not
> everybody understood what I was trying to say. For simplicity I use the
> plain variable "a" instead of a function. Start a fresh session and
> remove all variables, define one variable and quit with saving:
>
>> rm(list=ls())
>> a=17
>> quit(save="yes")
> Now, before opening a new session edit .Rprofile such that it contains
> just the two lines:
>
> print("Hello from .Rprofile")
> a=42
>
> Start a new session where your saved environment will be loaded.
> Observe that you see the line
>
> [1] "Hello from .Rprofile"
>
> proving that the commands in .Rprofile have been executed. Now look at
> "a":
>
>> a
> [1] 17
>
>
> You would expect to see this because *after* your "Hello" line you find
>
> [Previously saved workspace restored]
>
> So you have set "a" to 42 in .Rprofile but it gets overwritten from the
> previously saved and now restored workspace. On the other hand, .First()
> gets executed after the restoring of the workspace. Therefore, I could
> edit .Rprofile to read
>
> .First=function(){ assign("a",42,pos=1) }
>
> Now, after starting I see that "a" is indeed 42. But then it turns out
> that from now on I need "a" to be 11. After editing .Rprofile
> accordingly, I am quite hopeful but after starting a new session I see
> that "a" is still 42. Why is that? Because .First() was saved and when I
> started a new session it got a new function body (setting "a" to 11) but
> before it could be executed it was again overwritten by the old value
> (setting "a" to 42) and I am chasing my own tail. Sigh.
>
> .Last() doesn't help. Apparently (at least on my linux system) it is
> executed *after* saving the environment so too late to remove anything
> you don't want saved. In that regard linux doesn't seem to be typical,
> since in "?.Last" the reverse order is described as typical:
>
>       Exactly what happens at termination of an R session depends on the
>       platform and GUI interface in use.  A typical sequence is to run
>       ?.Last()? and ?.Last.sys()? (unless ?runLast? is false), to save
>       the workspace if requested (and in most cases also to save the
>       session history: see ?savehistory?), then run any finalizers (see
>       ?reg.finalizer?) that have been set to be run on exit, close all
>       open graphics devices, remove the session temporary directory and
>       print any remaining warnings (e.g., from ?.Last()? and device
>       closure).
>
>
> IMHO this is a design flaw.
>
> Ralf
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From Keith.Jewell at campdenbri.co.uk  Tue May  9 18:06:06 2017
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Tue, 9 May 2017 17:06:06 +0100
Subject: [R] Problem with choose.files(default=..., multi=FALSE)
Message-ID: <oespd8$okp$1@blaine.gmane.org>

I'm very hesitant to suggest that there's a bug in such a venerable R 
function, but I can't see what I'm doing wrong. Any comments are welcome

When using choose.files() where:
     default = something
     multi = FALSE
     selected file path is shorter than the default
... then the returned value is at least as long as the default, 
characters from default appearing (wrongly) at the end of the returned 
value.

Example, in which all but the first choose.files() select 
"M:\\test\\target.dat". Note the last result.

 > pathlong <- choose.files(caption = "long")
 > pathlong # long file name to use as default for short selection
[1] 
"M:\\test\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\target.dat"
 > choose.files(caption = "short")  # no default without multi works
[1] "M:\\test\\target.dat"
 > choose.files(default=pathlong, caption = "short") # default without 
multi= works
[1] "M:\\test\\target.dat"
 > choose.files(caption = "short", multi = FALSE) # multi = FALSE 
without default works
[1] "M:\\test\\target.dat"
 > choose.files(default=pathlong, caption = "short", multi = TRUE) # 
multi = TRUE with default works
[1] "M:\\test\\target.dat"
 > choose.files(default=pathlong, caption = "short", multi = FALSE) # 
multi = FALSE with default fails
[1] 
"M:\\test\\target.dat\\ryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\target.dat"

 > # in case it's relevant
 > sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United 
Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C 

[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] graphics  grDevices datasets  stats     tcltk     utils     tools 
   methods
[9] base

other attached packages:
  [1] CBRIutils_1.0   stringr_1.2.0   svSocket_0.9-57 TinnR_1.0-5 
R2HTML_2.3.2
  [6] Hmisc_4.0-3     ggplot2_2.2.1   Formula_1.2-1   survival_2.41-3 
lattice_0.20-35

loaded via a namespace (and not attached):
  [1] RColorBrewer_1.1-2  htmlTable_1.9       digest_0.6.12 
htmltools_0.3.6
  [5] splines_3.4.0       scales_0.4.1        grid_3.4.0 
checkmate_1.8.2
  [9] devtools_1.12.0     knitr_1.15.1        munsell_0.4.3 
compiler_3.4.0
[13] tibble_1.3.0        nnet_7.3-12         acepack_1.4.1 
Matrix_1.2-10
[17] svMisc_0.9-70       plyr_1.8.4          base64enc_0.1-3 
data.table_1.10.4
[21] stringi_1.1.5       magrittr_1.5        gtable_0.2.0 
colorspace_1.3-2
[25] foreign_0.8-68      cluster_2.0.6       gridExtra_2.2.1 
htmlwidgets_0.8
[29] withr_1.0.2         lazyeval_0.2.0      backports_1.0.5 
memoise_1.1.0
[33] rpart_4.1-11        Rcpp_0.12.10        latticeExtra_0.6-28
 >


From wjm1 at caa.columbia.edu  Tue May  9 18:15:10 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Tue, 9 May 2017 09:15:10 -0700
Subject: [R] About calculating average values from several matrices
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69AAB@DC1VEX10MB01.air.org>
References: <CAN5afy85WPhZJqUUv+ngW2ap7Owp7C2Rj+CpPE2uokQy0LuXQQ@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69904@DC1VEX10MB01.air.org>
 <CAN5afy_oXW7R2EyqFSEA4367Cp-6m2DS4Yi-jj-sb2mz7sAxog@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6995A@DC1VEX10MB01.air.org>
 <CAN5afy-TEBuKnO97eSKYoioUVoqesqnCLs-KYVid9c=Z1vBjkg@mail.gmail.com>
 <CAKxd1KOWoM3xh1j=muCq5NKMuQ6+esOxvKeKJxx+Rg8QRC6bkw@mail.gmail.com>
 <CAN5afy-65xAD9EtRXTJnk99r0mkb8aTG-BR_8MG4P5akESMETw@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D69AAB@DC1VEX10MB01.air.org>
Message-ID: <CAA99HCwBhWwJ1MJCqxwAuBguavKFoSvxBShoyfQBA9EsF5Df4g@mail.gmail.com>

Dear Lily,

Harold is telling you to type "?round" at the R command prompt to pull
up the "round" help page.

>?round
>help("round")

AFAIK, the above two commands are equivalent, in general.

Best, Bill.

W. Michels, Ph.D.



On Tue, May 9, 2017 at 8:11 AM, Doran, Harold <HDoran at air.org> wrote:
> ?round
>
>
> From: lily li [mailto:chocold12 at gmail.com]
> Sent: Tuesday, May 09, 2017 11:10 AM
> To: Charles Determan <cdetermanjr at gmail.com>
> Cc: Doran, Harold <HDoran at air.org>; R mailing list <r-help at r-project.org>
> Subject: Re: [R] About calculating average values from several matrices
>
> Thanks very much, it works. But how to round the values to have only 1 decimal digit or 2 decimal digits? I think by dividing, the values are double type now. Thanks again.
>
>
> On Tue, May 9, 2017 at 9:04 AM, Charles Determan <cdetermanjr at gmail.com<mailto:cdetermanjr at gmail.com>> wrote:
> If you want the mean of each element across you list of matrices the following should provide what you are looking for where Reduce sums all your matrix elements across matrices and the simply divided my the number of matrices for the element-wise mean.
>
> Reduce(`+`, mylist)/length(mylist)
> Regards,
> Charles
>
> On Tue, May 9, 2017 at 9:52 AM, lily li <chocold12 at gmail.com<mailto:chocold12 at gmail.com>> wrote:
> I meant for each cell, it takes the average from other dataframes at the
> same cell. I don't know how to deal with row names and col names though, so
> it has the error message.
>
> On Tue, May 9, 2017 at 8:50 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>
>> It?s not clear to me what your actual structure is. Can you provide
>> str(object)? Assuming it is a list, and you want the mean over all cells or
>> columns, you might want like this:
>>
>>
>>
>> myData <- vector("list", 3)
>>
>>
>>
>> for(i in 1:3){
>>
>>                 myData[[i]] <- matrix(rnorm(100), 10, 10)
>>
>>                 }
>>
>>
>>
>> ### mean over all cells
>>
>> sapply(myData, function(x) mean(x))
>>
>>
>>
>> ### mean over all columns
>>
>> sapply(myData, function(x) colMeans(x))
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *From:* lily li [mailto:chocold12 at gmail.com<mailto:chocold12 at gmail.com>]
>> *Sent:* Tuesday, May 09, 2017 10:44 AM
>> *To:* Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
>> *Cc:* R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
>> *Subject:* Re: [R] About calculating average values from several matrices
>
>>
>>
>>
>> I'm trying to get a new dataframe or whatever to call, which has the same
>> structure with each file as listed above. For each cell in the new
>> dataframe or the new file, it is the average value from former dataframes
>> at the same location. Thanks.
>>
>>
>>
>> On Tue, May 9, 2017 at 8:41 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>>
>> Are you trying to take the mean over all cells, or over rows/columns
>> within each dataframe. Also, are these different dataframes stored within a
>> list or are they standalone?
>>
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of lily li
>> Sent: Tuesday, May 09, 2017 10:39 AM
>> To: R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
>> Subject: [R] About calculating average values from several matrices
>>
>> Hi R users,
>>
>> I have a question about manipulating the data.
>> For example, there are several such data frames or matrices, and I want to
>> calculate the average value from all the data frames or matrices. How to do
>> it? Also, should I convert them to data frame or matrix first? Right now,
>> when I use typeof() function, each one is a list.
>>
>> file1
>>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>>
>> app1   1.1   1.2    0.8    0.9   1.3    1.5   2.2   3.2   3.0    1.2   1.1
>> app2   3.1   3.2    2.8    2.5   2.3    2.5   3.2   3.0   2.9    1.8   1.8
>> app3   5.1   5.2    3.8    4.9   5.3    5.5   5.2   4.2   5.0    4.2   4.1
>>
>> file2
>>             jan   feb   mar   apr   may   jun   jul   aug   sep   oct   nov
>>
>> app1   1.9   1.5    0.5    0.9   1.2    1.8   2.5   3.7   3.2    1.5   1.6
>> app2   3.5   3.7    2.3    2.2   2.5    2.0   3.6   3.2   2.8    1.2   1.4
>> app3   5.5   5.0    3.5    4.4   5.4    5.6   5.3   4.4   5.2    4.3   4.2
>>
>> file3 has the similar structure and values...
>>
>> There are eight such files, and when I use the function mean(file1, file2,
>> file3, ..., file8), it returns the error below. Thanks for your help.
>>
>> Warning message:
>> In mean.default(file1, file2, file3, file4, file5, file6, file7,  :
>>   argument is not numeric or logical: returning NA
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Tue May  9 18:40:00 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 09 May 2017 16:40:00 +0000
Subject: [R] passing arguments to simple plotting program.
In-Reply-To: <C96D958D-FBE7-4D25-8B7F-3C0C1F14DB8B@gmail.com>
References: <809F9C89-132B-4904-9B31-34E6C2CEDD4D@gmail.com>
 <CAKVAULMyEA3zZ-gD-CwFJDnLGG8DDJSU-DoxPqqBfm-rX0rqkw@mail.gmail.com>
 <C96D958D-FBE7-4D25-8B7F-3C0C1F14DB8B@gmail.com>
Message-ID: <CAKVAULPh+2q1afs7V+TZ+xYHMYapLaZX+GimPUXrZMBvZSBYig@mail.gmail.com>

Hi Gerard,

Quotation marks are used for strings. In you function body you try to use
the strings "indata" and "fig_descrip" (the latter will work but is not
what you want).

In your current function call you pass the variable Figure as the value to
the argument fig_descrip, followed by a lot of other stuff your function
doesn't know what to do with.

Remove the quotation marks around indata and fig_descrip in the function
body, call your function with:

plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip="Figure 2a\nChange
in Composite Score at Visit 5 (Day 31)\nPer Protocol Population")

and you should be fine.

HTH

Ulrik
Gerard Smits <smits.gerard.j at gmail.com> schrieb am Di., 9. Mai 2017, 18:27:

> Hi Ulrik,
>
> If I can trouble you with one more question.
>
> Now trying to send a string to the main= .  I was able to pass the data
> name in data=in_data, but same logic is not working in passion the main
> string.
>
>
> plot_f1 <-function(indata,n1,n2,n3,fig_descrip) {
>   par(oma=c(2,2,2,2))
>   boxplot(formula = d_comp ~ rx_grp,
>           data="indata?,                    # <- worked fine here.
>           main="fig_descrip",
>           ylim=c(-10,5),
>           names=c(paste0("Placebo(N=", n1,  ")"),
>          paste0("Low Dose(N=", n2, ")"),
>  paste0("High Dose(N=", n3,")")),
>           ylab='Change from Baseline')
>   abline(h=c(0), col="lightgray")
> }
>
> plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip=Figure 2a\nChange
> in Composite Score at Visit 5 (Day 31)\nPer Protocol Population)
>
> Error Message: Error: unexpected numeric constant in "plot_f1(indata=v5,
> n1=114, n2=119, n3=116, fig_descrip=Figure 2?
>
> Even this call gives the same error:  plot_f1(indata=v5, n1=114, n2=119,
> n3=116, fig_descrip=Figure)
>
>
> Thanks,
>
> Gerard
>
>
>
>
>
>
> On May 8, 2017, at 11:40 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
> HI Gerard,
>
> You get the literals because the variables are not implicitly expanded -
> 'Placebo(N=n1)  ' is just a string indicating the N = n1.
>
> What you want is to use paste() or paste0():
> c(paste0("Placebo(N=", n1, ")"), paste0("Low Dose (N=", n2, ")"),
> paste0("High Dose (N=", n3, ")"))
> should do it.
>
> I was taught a long ago that attach() should be avoided to avoid name
> conflicts. Also, it makes it difficult to figure out which data is actually
> being used.
>
> HTH
> Ulrik
>
> On Tue, 9 May 2017 at 06:44 Gerard Smits <smits.gerard.j at gmail.com> wrote:
>
>> Hi All,
>>
>> I thought I?d try to get a function working instead of block copying code
>> and editing. My backorund is more SAS, so using a SAS Macro would be easy,
>> but not so lucky with R functions.
>>
>>
>> R being used on Mac Sierra 10.12.4:
>>
>> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>> Copyright (C) 2016 The R Foundation for Statistical Computing
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>
>>
>> resp<-read.csv("//users//gerard//gs//r_work//xyz.csv", header = TRUE)
>>
>> v5  <-subset(resp, subset=visit==5 & pp==1)
>>
>> plot_f1 <-function(n1,n2,n3) {
>>   attach(v8)
>>   par(oma=c(2,2,2,2))
>>   boxplot(formula = d_comp ~ rx_grp,
>>           main="Figure 2\nChange in Composite Score at Visit 5 (Day
>> 31)\nPer Protocol Population",
>>           ylim=c(-10,5),
>>           names=c('Placebo(N=n1)  ',
>>                   'Low Dose(N=n2) ',
>>                   'High Dose(N=n3)'),
>>           ylab='Change from Baseline')
>>   abline(h=c(0), col="lightgray")
>> }
>>
>> plot_f1(n1=114, n2=119, n3=116)
>>
>> The above is a simplified example where I am trying to pass 3 arguments,
>> n1-n3, to be shown in the x-axis tables,  Instead of the numbers, I get the
>> literal n1, n2, n3.
>>
>> Any help appreciated.
>>
>> Thanks,
>>
>> Gerard
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue May  9 18:49:18 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 9 May 2017 12:49:18 -0400
Subject: [R] Problem with choose.files(default=..., multi=FALSE)
In-Reply-To: <oespd8$okp$1@blaine.gmane.org>
References: <oespd8$okp$1@blaine.gmane.org>
Message-ID: <b33b604f-4e5e-db2a-6c6e-4cc59bd0e27c@gmail.com>

On 09/05/2017 12:06 PM, Keith Jewell wrote:
> I'm very hesitant to suggest that there's a bug in such a venerable R
> function, but I can't see what I'm doing wrong. Any comments are welcome

Yes, it looks like a bug.  One other thing I find a little strange: the 
starting directory seems wrong when I have the pathlong default.  Did 
you see that?  (I'm in Windows 10, not the same version as you.)

Duncan Murdoch

>
> When using choose.files() where:
>      default = something
>      multi = FALSE
>      selected file path is shorter than the default
> ... then the returned value is at least as long as the default,
> characters from default appearing (wrongly) at the end of the returned
> value.
>
> Example, in which all but the first choose.files() select
> "M:\\test\\target.dat". Note the last result.
>
>  > pathlong <- choose.files(caption = "long")
>  > pathlong # long file name to use as default for short selection
> [1]
> "M:\\test\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\target.dat"
>  > choose.files(caption = "short")  # no default without multi works
> [1] "M:\\test\\target.dat"
>  > choose.files(default=pathlong, caption = "short") # default without
> multi= works
> [1] "M:\\test\\target.dat"
>  > choose.files(caption = "short", multi = FALSE) # multi = FALSE
> without default works
> [1] "M:\\test\\target.dat"
>  > choose.files(default=pathlong, caption = "short", multi = TRUE) #
> multi = TRUE with default works
> [1] "M:\\test\\target.dat"
>  > choose.files(default=pathlong, caption = "short", multi = FALSE) #
> multi = FALSE with default fails
> [1]
> "M:\\test\\target.dat\\ryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\target.dat"
>
>  > # in case it's relevant
>  > sessionInfo()
> R version 3.4.0 (2017-04-21)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] graphics  grDevices datasets  stats     tcltk     utils     tools
>    methods
> [9] base
>
> other attached packages:
>   [1] CBRIutils_1.0   stringr_1.2.0   svSocket_0.9-57 TinnR_1.0-5
> R2HTML_2.3.2
>   [6] Hmisc_4.0-3     ggplot2_2.2.1   Formula_1.2-1   survival_2.41-3
> lattice_0.20-35
>
> loaded via a namespace (and not attached):
>   [1] RColorBrewer_1.1-2  htmlTable_1.9       digest_0.6.12
> htmltools_0.3.6
>   [5] splines_3.4.0       scales_0.4.1        grid_3.4.0
> checkmate_1.8.2
>   [9] devtools_1.12.0     knitr_1.15.1        munsell_0.4.3
> compiler_3.4.0
> [13] tibble_1.3.0        nnet_7.3-12         acepack_1.4.1
> Matrix_1.2-10
> [17] svMisc_0.9-70       plyr_1.8.4          base64enc_0.1-3
> data.table_1.10.4
> [21] stringi_1.1.5       magrittr_1.5        gtable_0.2.0
> colorspace_1.3-2
> [25] foreign_0.8-68      cluster_2.0.6       gridExtra_2.2.1
> htmlwidgets_0.8
> [29] withr_1.0.2         lazyeval_0.2.0      backports_1.0.5
> memoise_1.1.0
> [33] rpart_4.1-11        Rcpp_0.12.10        latticeExtra_0.6-28
>  >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Tue May  9 19:00:17 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 09 May 2017 10:00:17 -0700
Subject: [R] loading edited functions already in saved workspace
	automatically
In-Reply-To: <9c05e2ef-80be-daec-6b51-ba0ab24eec45@yorku.ca>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>
 <20170505162314.1e6a1020@delli.home.local>
 <aa2b0963-13a2-5014-aa9a-0355239f2e6e@yorku.ca>
 <20170509162045.0b3af691@delli.home.local>
 <9c05e2ef-80be-daec-6b51-ba0ab24eec45@yorku.ca>
Message-ID: <6C13FEAD-C9A6-4D86-8188-E99E96D52DBC@dcn.davis.ca.us>

This boils down to the fact that some "my ways" are more effective in the long run than others.. but I really want to address the complaint

"... sometimes tedious to rebuild my environment by reexecuting commands in the history"

by asserting that letting R re-run a script that loads my functions and packages (though perhaps not the data analysis steps) is always very fast and convenient to do explicitly. I almost never use the history file feature, because I type nearly every R instruction I use into a script file and execute/edit it until it does what I want. I keep functions in a separate file or package, and steps dealing with a particular data set in their own file that uses source() to load the functions) even when I am executing the lines interactively. My goal is to regularly re-execute the whole script so that tomorrow/next year/whenever someone notices something was wrong then I can re-execute the sequence without following the dead ends I went down the first time (as using a history file does) and I don't have a separate clean-up-the-history-file step to go through to create it. When I have confirmed that the script still works as it did before then I can find where the analysis/data problem went wrong and fix it. 

This does not mean I never use RData files to reduce how often I re-do slow calculations... but it does mean that I always have my script that loads the necessary packages and functions rather than using versions of functions in the RData file. It is useful to avoid becoming dependent on saved intermediate saved data files so you don't continue to encounter the effects of script errors that you have already fixed earlier in the analysis. 

It becomes more convenient to minimize dependency on automatic startup behavior when you want to share your script with someone else or run it yourself on a different computer (say, a powerful server). If you have the script habit then these hiccups with moving around are non-issues, and you can perform more and more complex analyses over time because you don't have to remember all the individual steps nor do you have to sort through the dead ends in your history file over and over. 

The editor you use can make a huge difference in making this work... get one that has a hot key that lets you execute one line at a time straight from the editor rather than requiring an explicit copy/paste. RStudio, Notepad++/NppToR, IntelliJ IDEA, vim-r, and ESS are a few options I am aware of. RStudio also supports full screen debugging of R so you can more easily reproduce the exact conditions where things go wrong inside functions as well. 

-- 
Sent from my phone. Please excuse my brevity.

On May 9, 2017 8:49:22 AM PDT, Michael Friendly <friendly at yorku.ca> wrote:
>Ralf:
>
>You are afflicted with several mind bugs:
>* the "my-way mind bug" -- "I want to do it MY WAY, because that's sort
>
>of what
>I know" and also,
>* the "my-square-peg-should-fit-into-this-round-hole mind bug" -- "R 
>should be able to
>do it MY WAY, but it puts obstacles in my path," perhaps a subsidiary, 
>but more technical:
>* the "loading-a-function-or-data-is-the-same mind bug"
>As in many things R, you can't always get to MY WAY from there, at
>least 
>not without a tortuous journey.
>
>You think you should be able to do everything you want in .Rprofile,
>but 
>then you posed two separate problems:
>(a) save/reload history
>(b) save/reload functions and data
>
>If you recognize them as two separate problems, there is an easier
>path:
>(a) use .Rprofile only for making your history persistent, as I
>described
>(b) Put your functions & data you always want available in a package; 
>you can load it from .Rprofile
>
>I originally defined a bunch of handy functions (e.g., cd(), a setwd() 
>replacement, that works more like `cd` on unix, in that `cd()` returns 
>to the previous directory; it also changes the Windows title to
>`RGui:`  abbreviation of getwd() )
>
>I moved them all out of .Rprofile, made a package `myutil` and now load
>
>them from there with
>
>  #======================
>  # load default packages
>  #======================
>      if (!require(myutil)) warning("myutil functions not available")
>
>hope this helps,
>-Michael
>
>On 5/9/2017 10:20 AM, Ralf Goertz wrote:
>> Am Sat, 6 May 2017 11:17:42 -0400
>> schrieb Michael Friendly <friendly at yorku.ca>:
>>
>>> On 5/5/2017 10:23 AM, Ralf Goertz wrote:
>>>> Am Fri, 05 May 2017 07:14:36 -0700
>>>> schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>>>   
>>>>> R normally prompts you to save .RData, but it just automatically
>>>>> saves .Rhistory... the two are unrelated.
>>>> Not here. If I say "n" to the prompted question "Save workspace
>>>> image? [y/n/c]: " my history doesn't get saved.
>>>>
>>>> Version:
>>>>
>>>> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>>>> Copyright (C) 2016 The R Foundation for Statistical Computing
>>>> Platform: x86_64-suse-linux-gnu (64-bit)
>>>>   
>>> On Windoze, here's what I use in my .Rprofile, which runs every time
>>> I start an RGUI coonsole.  The key is .First & .Last to load/save
>>> history automagically.
>> Hi Michael,
>>
>> thanks. This helps with saving the history without saving the data.
>But
>> actually I'd really like to save both and still be able to load
>> functions automatically from .Rprofile. Not saving the data as Jeff
>> suggested is not a good option because it is sometimes tedious to
>> rebuild my environment by reexecuting commands in the history. And I
>> explained in my OP why I can't use .First() to achieve my goal.
>>
>> But let me try again to explain the problem because I think not
>> everybody understood what I was trying to say. For simplicity I use
>the
>> plain variable "a" instead of a function. Start a fresh session and
>> remove all variables, define one variable and quit with saving:
>>
>>> rm(list=ls())
>>> a=17
>>> quit(save="yes")
>> Now, before opening a new session edit .Rprofile such that it
>contains
>> just the two lines:
>>
>> print("Hello from .Rprofile")
>> a=42
>>
>> Start a new session where your saved environment will be loaded.
>> Observe that you see the line
>>
>> [1] "Hello from .Rprofile"
>>
>> proving that the commands in .Rprofile have been executed. Now look
>at
>> "a":
>>
>>> a
>> [1] 17
>>
>>
>> You would expect to see this because *after* your "Hello" line you
>find
>>
>> [Previously saved workspace restored]
>>
>> So you have set "a" to 42 in .Rprofile but it gets overwritten from
>the
>> previously saved and now restored workspace. On the other hand,
>.First()
>> gets executed after the restoring of the workspace. Therefore, I
>could
>> edit .Rprofile to read
>>
>> .First=function(){ assign("a",42,pos=1) }
>>
>> Now, after starting I see that "a" is indeed 42. But then it turns
>out
>> that from now on I need "a" to be 11. After editing .Rprofile
>> accordingly, I am quite hopeful but after starting a new session I
>see
>> that "a" is still 42. Why is that? Because .First() was saved and
>when I
>> started a new session it got a new function body (setting "a" to 11)
>but
>> before it could be executed it was again overwritten by the old value
>> (setting "a" to 42) and I am chasing my own tail. Sigh.
>>
>> .Last() doesn't help. Apparently (at least on my linux system) it is
>> executed *after* saving the environment so too late to remove
>anything
>> you don't want saved. In that regard linux doesn't seem to be
>typical,
>> since in "?.Last" the reverse order is described as typical:
>>
>>       Exactly what happens at termination of an R session depends on
>the
>>       platform and GUI interface in use.  A typical sequence is to
>run
>>       ?.Last()? and ?.Last.sys()? (unless ?runLast? is false), to
>save
>>       the workspace if requested (and in most cases also to save the
>>       session history: see ?savehistory?), then run any finalizers
>(see
>>       ?reg.finalizer?) that have been set to be run on exit, close
>all
>>       open graphics devices, remove the session temporary directory
>and
>>       print any remaining warnings (e.g., from ?.Last()? and device
>>       closure).
>>
>>
>> IMHO this is a design flaw.
>>
>> Ralf
>>


From r_goertz at web.de  Tue May  9 19:45:56 2017
From: r_goertz at web.de (Ralf Goertz)
Date: Tue, 9 May 2017 19:45:56 +0200
Subject: [R] loading edited functions already in saved workspace
 automatically
In-Reply-To: <6C13FEAD-C9A6-4D86-8188-E99E96D52DBC@dcn.davis.ca.us>
References: <20170505103327.2c67f0b9@delli.home.local>
 <01FF9BD7-7C2D-4F46-B296-7EFD55825210@dcn.davis.ca.us>
 <20170505154450.448392bc@delli.home.local>
 <9710C0D3-9530-43F8-A092-963A762799CF@dcn.davis.ca.us>
 <20170505162314.1e6a1020@delli.home.local>
 <aa2b0963-13a2-5014-aa9a-0355239f2e6e@yorku.ca>
 <20170509162045.0b3af691@delli.home.local>
 <9c05e2ef-80be-daec-6b51-ba0ab24eec45@yorku.ca>
 <6C13FEAD-C9A6-4D86-8188-E99E96D52DBC@dcn.davis.ca.us>
Message-ID: <20170509194556.17fdc6e9@delli.home.local>

Am Tue, 09 May 2017 10:00:17 -0700
schrieb Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> This boils down to the fact that some "my ways" are more effective in
> the long run than others.. but I really want to address the complaint
> 
> "... sometimes tedious to rebuild my environment by reexecuting
> commands in the history"
> 
> by asserting that letting R re-run a script that loads my functions
> and packages (though perhaps not the data analysis steps) is always
> very fast and convenient to do explicitly. I almost never use the
> history file feature, because I type nearly every R instruction I use
> into a script file and execute/edit it until it does what I want. I
> keep functions in a separate file or package, and steps dealing with
> a particular data set in their own file that uses source() to load
> the functions) even when I am executing the lines interactively. My
> goal is to regularly re-execute the whole script so that
> tomorrow/next year/whenever someone notices something was wrong then
> I can re-execute the sequence without following the dead ends I went
> down the first time (as using a history file does) and I don't have a
> separate clean-up-the-history-file step to go through to create it.
> When I have confirmed that the script still works as it did before
> then I can find where the analysis/data problem went wrong and fix it. 

My usual work with R is probably a bit different from yours. As I said
before I work on many projects (often simultaneously) but I do routine
work. For that I have my super function, the one I want to reload every
time R starts, at the moment about 250 lines of code. This is always
work in progress. In almost every project there is something that makes
me edit this function. But in order to apply my function I need to
prepare the data, e.g. getting them from a database or csv files,
renaming the columns of data.frames etc. This is all tedious and not
worth putting in scripts because these steps are very specific to the
project and are rarely needed more than once. Sometimes one or two data
records in project on which I worked a few days before turn out to be
wrong and need to be changed. That's why I want to keep the data because
changing the data.frame directly is much easier then starting from
scratch. Meanwhile my function has evolved. But in the .RData file is
still the old version, which is bad.

However, I found a solution! .Last() gets executed before saving here,
too. I simply had forgotten that I need to use rm() with pos=1, i.e.
rm(myfun,pos=1) because otherwise rm wants to delete myfun from within
the context of the function .Last() where it doesn't live. I changed my
.Rprofile to:

.First=function(){
    assign("myfun",eval(parse(file=("~/R/myfun.R"))),pos=1)
}
.Last=function(){
    rm(.First,pos=1)
    rm(myfun,pos=1)
    rm(.Last,pos=1)
}

and everything works as I want it. So no design flaw but still way too
complicated in my opinion. Thanks to everybody who came up with
suggestions.

Ralf


From abo_dlsh at hotmail.com  Tue May  9 19:21:27 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Tue, 9 May 2017 17:21:27 +0000
Subject: [R] Joining tables with different order and matched values
In-Reply-To: <CAKVAULPtDFaQpCKq4yP4MqgoTk0qGby_DancBW9QhWR+=W8sew@mail.gmail.com>
References: <CY4PR15MB130291337499E7A8300D926BEFEE0@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAKVAULPBMnwm5iRtbCpvzVfbEt=VCG+2EN48_P=fMKkzW=ha7g@mail.gmail.com>
 <CY4PR15MB130235B562099E3F690CCE17EFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAKVAULPMoH_4rnEYshZUCcQ4dgcxXN0FWkk2ycaYZ3PXZAMkDA@mail.gmail.com>
 <CY4PR15MB1302468023CF4E0B8A672E3FEFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <CAKVAULPtDFaQpCKq4yP4MqgoTk0qGby_DancBW9QhWR+=W8sew@mail.gmail.com>
Message-ID: <CY4PR15MB130223813A3DEF208EDBCF3EEFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>

I'm repeating my question and hope to find someone to help.


I have been trying for hours but without results, I have done previous suggestions but still struggling.


I believe that join functions in dplyr will do the work but I'm confusing with the correct syntax.


I have 2 tables and I'm trying to have some information from the 1st table to appear in the 2nd table.


let's say this is my 1st table :-


>df1
Drug name           indications

 Ibuprofen                Pain

 Simvastatin            hyperlipidemia

losartan                   hypertension



my 2nd table contains the same list of drugs under the first column BUT with different order :-

>df2
Drug name       indications


Simvastatin

losartan

Ibuprofen

Metformin

Simply, I want to produce a table like df1 but in the order of the 1st column of my df2.

This would be like this

>joined tables
Drug name       indications


Simvastatin     hyperlipidemia

losartan           hypertension

Ibuprofen       pain

Metformin    N/A


Please note that it is important to keep the order of drugs in df2 as it and to see the appropriate indication of each drug(which is withdrawn from df1) next to it under "indications" column.



________________________________
From: Ulrik Stervbo <ulrik.stervbo at gmail.com>
Sent: 09 May 2017 06:31 PM
To: abo dalash
Subject: Re: [R] Joining tables with different order and matched values

Hi Abo,

Please keep the list in cc - 1) the comments are accessible to everyone, 2) there is a chance that someone else might reply.

If the merge does what you intend, but you are unhappy with the order, you can arrange the resulting data.frame:

df <- data.frame(x = c(5, 4,2,3,6, 1), y = letters[1:6])

df
df[order(df$x), ]

HTH
Ulrik



On Tue, 9 May 2017 at 16:17 abo dalash <abo_dlsh at hotmail.com<mailto:abo_dlsh at hotmail.com>> wrote:


I still cannot produce the table I wish. I tried the following with the same results.


A <-merge(dt1, dt2, by = "Drug name", all.x = TRUE)


A <-join_query(dt1, dt2, by = "Drug name")

This returns a table showing results with changing the order of drugs in the 2nd data frame. I want to see the results under
"indications" column without changing the order of drugs in my 2nd data frame. I have been trying for many hours, so please
help me to know what is the mistake I have done and what is the correct syntax.


Regards
________________________________
From: Ulrik Stervbo <ulrik.stervbo at gmail.com<mailto:ulrik.stervbo at gmail.com>>
Sent: 09 May 2017 12:22 PM
To: abo dalash; R-help

Subject: Re: [R] Joining tables with different order and matched values
Hi Abo,

Please keep the list in cc.

I think the function documentation is pretty straight forward - two data.frames are required, and if you wish to keep elements that are not present in both data.frames, you set the flag all = TRUE. You also have the option to specify which columns to join by.

If you need more assistance with joining two data.frames, you should provide a reproducible example, and if you have trouble with a function you should provide an example of what you have tried so far.

Best wishes,
Ulrik



On Tue, 9 May 2017 at 10:00 abo dalash <abo_dlsh at hotmail.com<mailto:abo_dlsh at hotmail.com>> wrote:
Could you please teach me about the correct formation of the syntax?. I hav
n but wasn't able to formulate the correct syntax.


Sent from my Samsung device


-------- Original message --------
From: Ulrik Stervbo <ulrik.stervbo at gmail.com<mailto:ulrik.stervbo at gmail.com>>
Date: 09/05/2017 7:42 a.m. (GMT+00:00)
To: abo dalash <abo_dlsh at hotmail.com<mailto:abo_dlsh at hotmail.com>>, "r-help at R-project.org" <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Joining tables with different order and matched values

Hi Abo,

?merge

or the join functions from dplyr.

HTH
Ulrik

On Tue, 9 May 2017 at 06:44 abo dalash <abo_dlsh at hotmail.com<mailto:abo_dlsh at hotmail.com>> wrote:
Hi All ..,


I have 2 tables and I'm trying to have some information from the 1st table to appear in the second table with different order.


For Example, let's say this is my 1st table :-



Drug name           indications

 Ibuprofen                Pain

 Simvastatin            hyperlipidemia

losartan                   hypertension



my 2nd table is in different order for the 1st column :-


Drug name       indications


Simvastatin

losartan

Ibuprofen

Metformin


I wish to see the indication of each drug in my 2nd table subsisted from the information in my 1st table so the final table

would be like this


Drug name       indications


Simvastatin     hyperlipidemia

losartan           hypertension

Ibuprofen       pain

Metformin    N/A


I have been trying to use Sqldf package and right join function but not able to formulate the correct syntax.


I'm also trying to identify rows contain at least one shared value  in a dataset called 'Values":


>Values

A             B

1,2,5       3,8,7

2,4,6       7,6,3



Columns A & B in the first row do not share any value while in the 2nd row they have a single shared value which is 6.

The result I wish to see :-


A             B             shared values

1,2,5       3,8,7             N/A

2,4,6       7,6,3               6


I tried this syntax : SharedValues <- Values$A == Values$B but this returns logical results and what I wish to have

is a new data frame including the new vector "shared values" showing the information exactly as above.




Kind Regards






        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From czarek230800 at gmail.com  Tue May  9 19:09:02 2017
From: czarek230800 at gmail.com (Czarek Kowalski)
Date: Tue, 9 May 2017 19:09:02 +0200
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
Message-ID: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>

Dear Members,
I am working with 6-dimensional Student-t distribution with 4 degrees
of freedom truncated to [20; 60]. I have generated 100 000 samples
from truncated multivariate Student-t distribution using rtmvt
function from package ?tmvtnorm?. I have also calculated  mean vector
using equation (3) from attached pdf. The problem is, that after
summing all elements in one column of rtmvt result (and dividing by
100 000) I do not receive the same result as using (3) equation. Could
You tell me, what is incorrect, why there is a difference?
Yours faithfully
Czarek Kowalski
-------------- next part --------------
A non-text attachment was scrubbed...
Name: truncatedT.pdf
Type: application/pdf
Size: 197913 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170509/a18ff86a/attachment.pdf>

From smits.gerard.j at gmail.com  Tue May  9 17:52:47 2017
From: smits.gerard.j at gmail.com (Gerard Smits)
Date: Tue, 9 May 2017 08:52:47 -0700
Subject: [R] passing arguments to simple plotting program.
In-Reply-To: <CAKVAULMyEA3zZ-gD-CwFJDnLGG8DDJSU-DoxPqqBfm-rX0rqkw@mail.gmail.com>
References: <809F9C89-132B-4904-9B31-34E6C2CEDD4D@gmail.com>
 <CAKVAULMyEA3zZ-gD-CwFJDnLGG8DDJSU-DoxPqqBfm-rX0rqkw@mail.gmail.com>
Message-ID: <BEA1211A-EB43-4607-8FCB-698EDB98BA14@gmail.com>

Hi Ulrik,

That worked perfectly.  Thanks for your help. Much appreciated.

Gerard


> On May 8, 2017, at 11:40 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> HI Gerard,
> 
> You get the literals because the variables are not implicitly expanded - 'Placebo(N=n1)  ' is just a string indicating the N = n1. 
> 
> What you want is to use paste() or paste0(): 
> c(paste0("Placebo(N=", n1, ")"), paste0("Low Dose (N=", n2, ")"), paste0("High Dose (N=", n3, ")"))
> should do it.
> 
> I was taught a long ago that attach() should be avoided to avoid name conflicts. Also, it makes it difficult to figure out which data is actually being used.
> 
> HTH
> Ulrik
> 
> On Tue, 9 May 2017 at 06:44 Gerard Smits <smits.gerard.j at gmail.com <mailto:smits.gerard.j at gmail.com>> wrote:
> Hi All,
> 
> I thought I?d try to get a function working instead of block copying code and editing. My backorund is more SAS, so using a SAS Macro would be easy, but not so lucky with R functions.
> 
> 
> R being used on Mac Sierra 10.12.4:
> 
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> 
> 
> resp<-read.csv("//users//gerard//gs//r_work//xyz.csv", header = TRUE)
> 
> v5  <-subset(resp, subset=visit==5 & pp==1)
> 
> plot_f1 <-function(n1,n2,n3) {
>   attach(v8)
>   par(oma=c(2,2,2,2))
>   boxplot(formula = d_comp ~ rx_grp,
>           main="Figure 2\nChange in Composite Score at Visit 5 (Day 31)\nPer Protocol Population",
>           ylim=c(-10,5),
>           names=c('Placebo(N=n1)  ',
>                   'Low Dose(N=n2) ',
>                   'High Dose(N=n3)'),
>           ylab='Change from Baseline')
>   abline(h=c(0), col="lightgray")
> }
> 
> plot_f1(n1=114, n2=119, n3=116)
> 
> The above is a simplified example where I am trying to pass 3 arguments, n1-n3, to be shown in the x-axis tables,  Instead of the numbers, I get the literal n1, n2, n3.
> 
> Any help appreciated.
> 
> Thanks,
> 
> Gerard
> 
> 
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From smits.gerard.j at gmail.com  Tue May  9 18:27:39 2017
From: smits.gerard.j at gmail.com (Gerard Smits)
Date: Tue, 9 May 2017 09:27:39 -0700
Subject: [R] passing arguments to simple plotting program.
In-Reply-To: <CAKVAULMyEA3zZ-gD-CwFJDnLGG8DDJSU-DoxPqqBfm-rX0rqkw@mail.gmail.com>
References: <809F9C89-132B-4904-9B31-34E6C2CEDD4D@gmail.com>
 <CAKVAULMyEA3zZ-gD-CwFJDnLGG8DDJSU-DoxPqqBfm-rX0rqkw@mail.gmail.com>
Message-ID: <C96D958D-FBE7-4D25-8B7F-3C0C1F14DB8B@gmail.com>

Hi Ulrik,

If I can trouble you with one more question.

Now trying to send a string to the main= .  I was able to pass the data name in data=in_data, but same logic is not working in passion the main string.


plot_f1 <-function(indata,n1,n2,n3,fig_descrip) {
  par(oma=c(2,2,2,2))
  boxplot(formula = d_comp ~ rx_grp,
          data="indata?,                    # <- worked fine here.
          main="fig_descrip",
          ylim=c(-10,5),
          names=c(paste0("Placebo(N=", n1,  ")"),
	          paste0("Low Dose(N=", n2, ")"),
		  paste0("High Dose(N=", n3,")")),
          ylab='Change from Baseline')
  abline(h=c(0), col="lightgray")
}

plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip=Figure 2a\nChange in Composite Score at Visit 5 (Day 31)\nPer Protocol Population)

Error Message: Error: unexpected numeric constant in "plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip=Figure 2?

Even this call gives the same error:  plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip=Figure)


Thanks, 

Gerard






> On May 8, 2017, at 11:40 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> HI Gerard,
> 
> You get the literals because the variables are not implicitly expanded - 'Placebo(N=n1)  ' is just a string indicating the N = n1. 
> 
> What you want is to use paste() or paste0(): 
> c(paste0("Placebo(N=", n1, ")"), paste0("Low Dose (N=", n2, ")"), paste0("High Dose (N=", n3, ")"))
> should do it.
> 
> I was taught a long ago that attach() should be avoided to avoid name conflicts. Also, it makes it difficult to figure out which data is actually being used.
> 
> HTH
> Ulrik
> 
> On Tue, 9 May 2017 at 06:44 Gerard Smits <smits.gerard.j at gmail.com <mailto:smits.gerard.j at gmail.com>> wrote:
> Hi All,
> 
> I thought I?d try to get a function working instead of block copying code and editing. My backorund is more SAS, so using a SAS Macro would be easy, but not so lucky with R functions.
> 
> 
> R being used on Mac Sierra 10.12.4:
> 
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> 
> 
> resp<-read.csv("//users//gerard//gs//r_work//xyz.csv", header = TRUE)
> 
> v5  <-subset(resp, subset=visit==5 & pp==1)
> 
> plot_f1 <-function(n1,n2,n3) {
>   attach(v8)
>   par(oma=c(2,2,2,2))
>   boxplot(formula = d_comp ~ rx_grp,
>           main="Figure 2\nChange in Composite Score at Visit 5 (Day 31)\nPer Protocol Population",
>           ylim=c(-10,5),
>           names=c('Placebo(N=n1)  ',
>                   'Low Dose(N=n2) ',
>                   'High Dose(N=n3)'),
>           ylab='Change from Baseline')
>   abline(h=c(0), col="lightgray")
> }
> 
> plot_f1(n1=114, n2=119, n3=116)
> 
> The above is a simplified example where I am trying to pass 3 arguments, n1-n3, to be shown in the x-axis tables,  Instead of the numbers, I get the literal n1, n2, n3.
> 
> Any help appreciated.
> 
> Thanks,
> 
> Gerard
> 
> 
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From smits.gerard.j at gmail.com  Tue May  9 18:58:33 2017
From: smits.gerard.j at gmail.com (Gerard Smits)
Date: Tue, 9 May 2017 09:58:33 -0700
Subject: [R] passing arguments to simple plotting program.
In-Reply-To: <CAKVAULPh+2q1afs7V+TZ+xYHMYapLaZX+GimPUXrZMBvZSBYig@mail.gmail.com>
References: <809F9C89-132B-4904-9B31-34E6C2CEDD4D@gmail.com>
 <CAKVAULMyEA3zZ-gD-CwFJDnLGG8DDJSU-DoxPqqBfm-rX0rqkw@mail.gmail.com>
 <C96D958D-FBE7-4D25-8B7F-3C0C1F14DB8B@gmail.com>
 <CAKVAULPh+2q1afs7V+TZ+xYHMYapLaZX+GimPUXrZMBvZSBYig@mail.gmail.com>
Message-ID: <87E1D0D1-342A-4B11-B694-65AE29A3F22E@gmail.com>

Seems so simple when you explain it.  Thanks very much.  Gerard


> On May 9, 2017, at 9:40 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> 
> Hi Gerard,
> Quotation marks are used for strings. In you function body you try to use the strings "indata" and "fig_descrip" (the latter will work but is not what you want).
> 
> In your current function call you pass the variable Figure as the value to the argument fig_descrip, followed by a lot of other stuff your function doesn't know what to do with.
> 
> Remove the quotation marks around indata and fig_descrip in the function body, call your function with:
> 
> plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip="Figure 2a\nChange in Composite Score at Visit 5 (Day 31)\nPer Protocol Population")
> 
> and you should be fine.
> 
> HTH
> 
> Ulrik
> 
> Gerard Smits <smits.gerard.j at gmail.com <mailto:smits.gerard.j at gmail.com>> schrieb am Di., 9. Mai 2017, 18:27:
> Hi Ulrik,
> 
> If I can trouble you with one more question.
> 
> Now trying to send a string to the main= .  I was able to pass the data name in data=in_data, but same logic is not working in passion the main string.
> 
> 
> plot_f1 <-function(indata,n1,n2,n3,fig_descrip) {
>   par(oma=c(2,2,2,2))
>   boxplot(formula = d_comp ~ rx_grp,
>           data="indata?,                    # <- worked fine here.
>           main="fig_descrip",
>           ylim=c(-10,5),
>           names=c(paste0("Placebo(N=", n1,  ")"),
> 	          paste0("Low Dose(N=", n2, ")"),
> 		  paste0("High Dose(N=", n3,")")),
>           ylab='Change from Baseline')
>   abline(h=c(0), col="lightgray")
> }
> 
> plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip=Figure 2a\nChange in Composite Score at Visit 5 (Day 31)\nPer Protocol Population)
> 
> Error Message: Error: unexpected numeric constant in "plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip=Figure 2?
> 
> Even this call gives the same error:  plot_f1(indata=v5, n1=114, n2=119, n3=116, fig_descrip=Figure)
> 
> 
> Thanks, 
> 
> Gerard
> 
> 
> 
> 
> 
> 
>> On May 8, 2017, at 11:40 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com <mailto:ulrik.stervbo at gmail.com>> wrote:
>> 
> 
>> HI Gerard,
>> 
>> You get the literals because the variables are not implicitly expanded - 'Placebo(N=n1)  ' is just a string indicating the N = n1. 
>> 
>> What you want is to use paste() or paste0(): 
>> c(paste0("Placebo(N=", n1, ")"), paste0("Low Dose (N=", n2, ")"), paste0("High Dose (N=", n3, ")"))
>> should do it.
>> 
>> I was taught a long ago that attach() should be avoided to avoid name conflicts. Also, it makes it difficult to figure out which data is actually being used.
>> 
>> HTH
>> Ulrik
>> 
>> On Tue, 9 May 2017 at 06:44 Gerard Smits <smits.gerard.j at gmail.com <mailto:smits.gerard.j at gmail.com>> wrote:
>> Hi All,
>> 
>> I thought I?d try to get a function working instead of block copying code and editing. My backorund is more SAS, so using a SAS Macro would be easy, but not so lucky with R functions.
>> 
>> 
>> R being used on Mac Sierra 10.12.4:
>> 
>> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>> Copyright (C) 2016 The R Foundation for Statistical Computing
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> 
>> 
>> resp<-read.csv("//users//gerard//gs//r_work//xyz.csv", header = TRUE)
>> 
>> v5  <-subset(resp, subset=visit==5 & pp==1)
>> 
>> plot_f1 <-function(n1,n2,n3) {
>>   attach(v8)
>>   par(oma=c(2,2,2,2))
>>   boxplot(formula = d_comp ~ rx_grp,
>>           main="Figure 2\nChange in Composite Score at Visit 5 (Day 31)\nPer Protocol Population",
>>           ylim=c(-10,5),
>>           names=c('Placebo(N=n1)  ',
>>                   'Low Dose(N=n2) ',
>>                   'High Dose(N=n3)'),
>>           ylab='Change from Baseline')
>>   abline(h=c(0), col="lightgray")
>> }
>> 
>> plot_f1(n1=114, n2=119, n3=116)
>> 
>> The above is a simplified example where I am trying to pass 3 arguments, n1-n3, to be shown in the x-axis tables,  Instead of the numbers, I get the literal n1, n2, n3.
>> 
>> Any help appreciated.
>> 
>> Thanks,
>> 
>> Gerard
>> 
>> 
>> 
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From oluola2011 at yahoo.com  Tue May  9 21:14:06 2017
From: oluola2011 at yahoo.com (Olu Ola)
Date: Tue, 9 May 2017 19:14:06 +0000 (UTC)
Subject: [R] How to replace missing values by mean of subgroup of a group
References: <1349484531.7246696.1494357246706.ref@mail.yahoo.com>
Message-ID: <1349484531.7246696.1494357246706@mail.yahoo.com>

 Hello,I have the following food data with some NA values in the food prices. I will like to replace the NA values in the food price column?for each food item by the mean price of the specific food item?for each city. For example, the price of bean for the household with hhid 102 in the data set is missing. I will like to replace the missing value with the mean price of bean for the households living in Paxton city (that is households 101 and 103). the data set is presented below. Any help will be greatly appreciated.

| hhid | city | food | food price |
| 101 | Paxton | rice | 10 |
| 101 | Paxton | beans | 30 |
| 101 | Paxton | flour | NA |
| 101 | Paxton | eggs | 20 |
| 102 | Paxton | rice | NA |
| 102 | Paxton | beans | NA |
| 102 | Paxton | flour | 34 |
| 102 | Paxton | eggs | 21 |
| 103 | Paxton | rice | 15 |
| 103 | Paxton | beans | 28 |
| 103 | Paxton | flour | 32 |
| 103 | Paxton | eggs | NA |
| 104 | Hull | rice | NA |
| 104 | Hull | beans | 34 |
| 104 | Hull | flour | NA |
| 104 | Hull | eggs | 24 |
| 105 | Hull | rice | 18 |
| 105 | Hull | beans | 38 |
| 105 | Hull | flour | 36 |
| 105 | Hull | eggs | 26 |
| 106 | Hull | rice | NA |
| 106 | Hull | beans | NA |
| 106 | Hull | flour | 40 |
| 106 | Hull | eggs | NA |


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Tue May  9 21:33:34 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 9 May 2017 15:33:34 -0400
Subject: [R] Joining tables with different order and matched values
In-Reply-To: <CY4PR15MB130223813A3DEF208EDBCF3EEFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB130291337499E7A8300D926BEFEE0@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAKVAULPBMnwm5iRtbCpvzVfbEt=VCG+2EN48_P=fMKkzW=ha7g@mail.gmail.com>
 <CY4PR15MB130235B562099E3F690CCE17EFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAKVAULPMoH_4rnEYshZUCcQ4dgcxXN0FWkk2ycaYZ3PXZAMkDA@mail.gmail.com>
 <CY4PR15MB1302468023CF4E0B8A672E3FEFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>
 <CAKVAULPtDFaQpCKq4yP4MqgoTk0qGby_DancBW9QhWR+=W8sew@mail.gmail.com>
 <CY4PR15MB130223813A3DEF208EDBCF3EEFEF0@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <16D57EF3-9383-4A7F-8263-DAB975BF6002@utoronto.ca>

myDf1 <- data.frame(drugs = c("Ibuprofen", "Simvastatin", "Losartan"),
                    indications = c("pain", "hyperlipidemia", "hypertension"),
                    stringsAsFactors = FALSE)

myDf2 <- data.frame(drugs = c("Simvastatin", "Losartan", "Ibuprofen", "Metformin"),
                    stringsAsFactors = FALSE)

myDf3 <- merge(myDf2, myDf1, all = TRUE, sort = FALSE)


R > myDf3
        drugs    indications
1 Simvastatin hyperlipidemia
2    Losartan   hypertension
3   Ibuprofen           pain
4   Metformin           <NA>


R > str(myDf3)
'data.frame':	4 obs. of  2 variables:
 $ drugs      : chr  "Simvastatin" "Losartan" "Ibuprofen" "Metformin"
 $ indications: chr  "hyperlipidemia" "hypertension" "pain" NA



-----

Minimum working example!
Don't post in HTML!
... you should know better by now.



> On May 9, 2017, at 1:21 PM, abo dalash <abo_dlsh at hotmail.com> wrote:
> 
> I'm repeating my question and hope to find someone to help.
> 
> 
> I have been trying for hours but without results, I have done previous suggestions but still struggling.
> 
> 
> I believe that join functions in dplyr will do the work but I'm confusing with the correct syntax.
> 
> 
> I have 2 tables and I'm trying to have some information from the 1st table to appear in the 2nd table.
> 
> 
> let's say this is my 1st table :-
> 
> 
>> df1
> Drug name           indications
> 
> Ibuprofen                Pain
> 
> Simvastatin            hyperlipidemia
> 
> losartan                   hypertension
> 
> 
> 
> my 2nd table contains the same list of drugs under the first column BUT with different order :-
> 
>> df2
> Drug name       indications
> 
> 
> Simvastatin
> 
> losartan
> 
> Ibuprofen
> 
> Metformin
> 
> Simply, I want to produce a table like df1 but in the order of the 1st column of my df2.
> 
> This would be like this
> 
>> joined tables
> Drug name       indications
> 
> 
> Simvastatin     hyperlipidemia
> 
> losartan           hypertension
> 
> Ibuprofen       pain
> 
> Metformin    N/A
> 
> 
> Please note that it is important to keep the order of drugs in df2 as it and to see the appropriate indication of each drug(which is withdrawn from df1) next to it under "indications" column.
> 
> 
> 
> ________________________________
> From: Ulrik Stervbo <ulrik.stervbo at gmail.com>
> Sent: 09 May 2017 06:31 PM
> To: abo dalash
> Subject: Re: [R] Joining tables with different order and matched values
> 
> Hi Abo,
> 
> Please keep the list in cc - 1) the comments are accessible to everyone, 2) there is a chance that someone else might reply.
> 
> If the merge does what you intend, but you are unhappy with the order, you can arrange the resulting data.frame:
> 
> df <- data.frame(x = c(5, 4,2,3,6, 1), y = letters[1:6])
> 
> df
> df[order(df$x), ]
> 
> HTH
> Ulrik
> 
> 
> 
> On Tue, 9 May 2017 at 16:17 abo dalash <abo_dlsh at hotmail.com<mailto:abo_dlsh at hotmail.com>> wrote:
> 
> 
> I still cannot produce the table I wish. I tried the following with the same results.
> 
> 
> A <-merge(dt1, dt2, by = "Drug name", all.x = TRUE)
> 
> 
> A <-join_query(dt1, dt2, by = "Drug name")
> 
> This returns a table showing results with changing the order of drugs in the 2nd data frame. I want to see the results under
> "indications" column without changing the order of drugs in my 2nd data frame. I have been trying for many hours, so please
> help me to know what is the mistake I have done and what is the correct syntax.
> 
> 
> Regards
> ________________________________
> From: Ulrik Stervbo <ulrik.stervbo at gmail.com<mailto:ulrik.stervbo at gmail.com>>
> Sent: 09 May 2017 12:22 PM
> To: abo dalash; R-help
> 
> Subject: Re: [R] Joining tables with different order and matched values
> Hi Abo,
> 
> Please keep the list in cc.
> 
> I think the function documentation is pretty straight forward - two data.frames are required, and if you wish to keep elements that are not present in both data.frames, you set the flag all = TRUE. You also have the option to specify which columns to join by.
> 
> If you need more assistance with joining two data.frames, you should provide a reproducible example, and if you have trouble with a function you should provide an example of what you have tried so far.
> 
> Best wishes,
> Ulrik
> 
> 
> 
> On Tue, 9 May 2017 at 10:00 abo dalash <abo_dlsh at hotmail.com<mailto:abo_dlsh at hotmail.com>> wrote:
> Could you please teach me about the correct formation of the syntax?. I hav
> n but wasn't able to formulate the correct syntax.
> 
> 
> Sent from my Samsung device
> 
> 
> -------- Original message --------
> From: Ulrik Stervbo <ulrik.stervbo at gmail.com<mailto:ulrik.stervbo at gmail.com>>
> Date: 09/05/2017 7:42 a.m. (GMT+00:00)
> To: abo dalash <abo_dlsh at hotmail.com<mailto:abo_dlsh at hotmail.com>>, "r-help at R-project.org" <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] Joining tables with different order and matched values
> 
> Hi Abo,
> 
> ?merge
> 
> or the join functions from dplyr.
> 
> HTH
> Ulrik
> 
> On Tue, 9 May 2017 at 06:44 abo dalash <abo_dlsh at hotmail.com<mailto:abo_dlsh at hotmail.com>> wrote:
> Hi All ..,
> 
> 
> I have 2 tables and I'm trying to have some information from the 1st table to appear in the second table with different order.
> 
> 
> For Example, let's say this is my 1st table :-
> 
> 
> 
> Drug name           indications
> 
> Ibuprofen                Pain
> 
> Simvastatin            hyperlipidemia
> 
> losartan                   hypertension
> 
> 
> 
> my 2nd table is in different order for the 1st column :-
> 
> 
> Drug name       indications
> 
> 
> Simvastatin
> 
> losartan
> 
> Ibuprofen
> 
> Metformin
> 
> 
> I wish to see the indication of each drug in my 2nd table subsisted from the information in my 1st table so the final table
> 
> would be like this
> 
> 
> Drug name       indications
> 
> 
> Simvastatin     hyperlipidemia
> 
> losartan           hypertension
> 
> Ibuprofen       pain
> 
> Metformin    N/A
> 
> 
> I have been trying to use Sqldf package and right join function but not able to formulate the correct syntax.
> 
> 
> I'm also trying to identify rows contain at least one shared value  in a dataset called 'Values":
> 
> 
>> Values
> 
> A             B
> 
> 1,2,5       3,8,7
> 
> 2,4,6       7,6,3
> 
> 
> 
> Columns A & B in the first row do not share any value while in the 2nd row they have a single shared value which is 6.
> 
> The result I wish to see :-
> 
> 
> A             B             shared values
> 
> 1,2,5       3,8,7             N/A
> 
> 2,4,6       7,6,3               6
> 
> 
> I tried this syntax : SharedValues <- Values$A == Values$B but this returns logical results and what I wish to have
> 
> is a new data frame including the new vector "shared values" showing the information exactly as above.
> 
> 
> 
> 
> Kind Regards
> 
> 
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue May  9 21:40:55 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 May 2017 12:40:55 -0700
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
In-Reply-To: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
Message-ID: <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>


> On May 9, 2017, at 10:09 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
> 
> Dear Members,
> I am working with 6-dimensional Student-t distribution with 4 degrees
> of freedom truncated to [20; 60]. I have generated 100 000 samples
> from truncated multivariate Student-t distribution using rtmvt
> function from package ?tmvtnorm?. I have also calculated  mean vector
> using equation (3) from attached pdf. The problem is, that after
> summing all elements in one column of rtmvt result (and dividing by
> 100 000) I do not receive the same result as using (3) equation. Could
> You tell me, what is incorrect, why there is a difference?

I guess the question is why you would NOT expect a difference between theory and a sample of realizations of RV's? The result mean should still be a random variable, night wahr?


> Yours faithfully
> Czarek Kowalski
> <truncatedT.pdf>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From czarek230800 at gmail.com  Tue May  9 22:11:21 2017
From: czarek230800 at gmail.com (Czarek Kowalski)
Date: Tue, 9 May 2017 22:11:21 +0200
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
In-Reply-To: <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
 <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>
Message-ID: <CAEKZwC-_NJgFk8sD4+3D=bOGi1KDd0mUrKL+63yesNeOzC150w@mail.gmail.com>

Of course I have expected the difference between theory and a sample
of realizations of RV's and result mean should still be a random
variable. But, for example for 4th element of mean vector: 35.31 -
34.69571 = 0.61429. It is quite big difference, nieprawda?? I have
expected that the difference would be smaller because of law of large
numbers (for 10mln samples the difference is quite similar).

On 9 May 2017 at 21:40, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 9, 2017, at 10:09 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>
>> Dear Members,
>> I am working with 6-dimensional Student-t distribution with 4 degrees
>> of freedom truncated to [20; 60]. I have generated 100 000 samples
>> from truncated multivariate Student-t distribution using rtmvt
>> function from package ?tmvtnorm?. I have also calculated  mean vector
>> using equation (3) from attached pdf. The problem is, that after
>> summing all elements in one column of rtmvt result (and dividing by
>> 100 000) I do not receive the same result as using (3) equation. Could
>> You tell me, what is incorrect, why there is a difference?
>
> I guess the question is why you would NOT expect a difference between theory and a sample of realizations of RV's? The result mean should still be a random variable, night wahr?
>
>
>> Yours faithfully
>> Czarek Kowalski
>> <truncatedT.pdf>______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Tue May  9 22:17:31 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 May 2017 13:17:31 -0700
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
In-Reply-To: <CAEKZwC-_NJgFk8sD4+3D=bOGi1KDd0mUrKL+63yesNeOzC150w@mail.gmail.com>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
 <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>
 <CAEKZwC-_NJgFk8sD4+3D=bOGi1KDd0mUrKL+63yesNeOzC150w@mail.gmail.com>
Message-ID: <A6EB7E1D-0D76-4EE7-8A35-9D620BCDD2D3@comcast.net>


> On May 9, 2017, at 1:11 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
> 
> Of course I have expected the difference between theory and a sample
> of realizations of RV's and result mean should still be a random
> variable. But, for example for 4th element of mean vector: 35.31 -
> 34.69571 = 0.61429. It is quite big difference, nieprawda?? I have
> expected that the difference would be smaller because of law of large
> numbers (for 10mln samples the difference is quite similar).

I for one have no idea what is meant by a "4th element of mean vector". So I have now idea what to consider "big". I have found that my intuitions about multivariate distributions, especially those where the covariate structure is as complex as you have assumed, are often far from simulated results.

I suggest you post some code and results.

-- 
David.


> 
> On 9 May 2017 at 21:40, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On May 9, 2017, at 10:09 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>> 
>>> Dear Members,
>>> I am working with 6-dimensional Student-t distribution with 4 degrees
>>> of freedom truncated to [20; 60]. I have generated 100 000 samples
>>> from truncated multivariate Student-t distribution using rtmvt
>>> function from package ?tmvtnorm?. I have also calculated  mean vector
>>> using equation (3) from attached pdf. The problem is, that after
>>> summing all elements in one column of rtmvt result (and dividing by
>>> 100 000) I do not receive the same result as using (3) equation. Could
>>> You tell me, what is incorrect, why there is a difference?
>> 
>> I guess the question is why you would NOT expect a difference between theory and a sample of realizations of RV's? The result mean should still be a random variable, night wahr?
>> 
>> 
>>> Yours faithfully
>>> Czarek Kowalski
>>> <truncatedT.pdf>______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From boris.steipe at utoronto.ca  Tue May  9 22:20:13 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 9 May 2017 16:20:13 -0400
Subject: [R] How to replace missing values by mean of subgroup of a group
In-Reply-To: <1349484531.7246696.1494357246706@mail.yahoo.com>
References: <1349484531.7246696.1494357246706.ref@mail.yahoo.com>
 <1349484531.7246696.1494357246706@mail.yahoo.com>
Message-ID: <C7E3B33C-8F4E-49D4-B0D3-2B1824F9892D@utoronto.ca>

Pedestrian code, so you can analyze this easily. However entirely untested since I have no ambitionto recreate your input data as a data frame. This code assumes:
 - your data _is_ a data frame
 - the desired column is called food.price, not "food price" (cf. ?make.names )

# define a function that imputes NA values in the same city, for the same food
imputeFoodPrice <- function(DF, i) {
  sel <- DF$city == DF$city[i] & DF$food == DF$food[i]
  imputed <- mean(DF$food.price[sel], na.rm = TRUE)
  if (is.nan(imputed)) { # careful, there might be no other match
    imputed <- NA
  }
  return(imputed)
}


# apply the function to replace NA values
for (iMissing in which(is.na(myDF$food.price))) {
  myDF$food.price[iMissing] <- imputeFoodPrice(myDF, iMissing)
}


B.



> On May 9, 2017, at 3:14 PM, Olu Ola via R-help <r-help at r-project.org> wrote:
> 
> Hello,I have the following food data with some NA values in the food prices. I will like to replace the NA values in the food price column for each food item by the mean price of the specific food item for each city. For example, the price of bean for the household with hhid 102 in the data set is missing. I will like to replace the missing value with the mean price of bean for the households living in Paxton city (that is households 101 and 103). the data set is presented below. Any help will be greatly appreciated.
> 
> | hhid | city | food | food price |
> | 101 | Paxton | rice | 10 |
> | 101 | Paxton | beans | 30 |
> | 101 | Paxton | flour | NA |
> | 101 | Paxton | eggs | 20 |
> | 102 | Paxton | rice | NA |
> | 102 | Paxton | beans | NA |
> | 102 | Paxton | flour | 34 |
> | 102 | Paxton | eggs | 21 |
> | 103 | Paxton | rice | 15 |
> | 103 | Paxton | beans | 28 |
> | 103 | Paxton | flour | 32 |
> | 103 | Paxton | eggs | NA |
> | 104 | Hull | rice | NA |
> | 104 | Hull | beans | 34 |
> | 104 | Hull | flour | NA |
> | 104 | Hull | eggs | 24 |
> | 105 | Hull | rice | 18 |
> | 105 | Hull | beans | 38 |
> | 105 | Hull | flour | 36 |
> | 105 | Hull | eggs | 26 |
> | 106 | Hull | rice | NA |
> | 106 | Hull | beans | NA |
> | 106 | Hull | flour | 40 |
> | 106 | Hull | eggs | NA |
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From czarek230800 at gmail.com  Tue May  9 23:05:09 2017
From: czarek230800 at gmail.com (Czarek Kowalski)
Date: Tue, 9 May 2017 23:05:09 +0200
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
In-Reply-To: <A6EB7E1D-0D76-4EE7-8A35-9D620BCDD2D3@comcast.net>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
 <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>
 <CAEKZwC-_NJgFk8sD4+3D=bOGi1KDd0mUrKL+63yesNeOzC150w@mail.gmail.com>
 <A6EB7E1D-0D76-4EE7-8A35-9D620BCDD2D3@comcast.net>
Message-ID: <CAEKZwC-0-XYH20bFCu1m-ooFDH3VuVjcw2mJcu08RYO-QrZz7A@mail.gmail.com>

I have already posted that in attachement - pdf file. I am posting
plain text here:

> library(tmvtnorm)

> meann = c(55, 40, 50, 35, 45, 30)

> covv = matrix(c(  1, 1, 0, 2, -1, -1,

+                   1, 16, -6, -6, -2, 12,

+                   0, -6, 4, 2, -2, -5,

+                   2, -6, 2, 25, 0, -17,

+                  -1, -2, -2, 0, 9, -5,

+                  -1, 12, -5, -17, -5, 36), 6, 6)

> df = 4

> lower = c(20, 20, 20, 20, 20, 20)

> upper = c(60, 60, 60, 60, 60, 60)

> X1 <- rtmvt(n=100000, meann, covv, df, lower, upper)





> sum(X1[,1]) / 100000

[1] 54.98258

> sum(X1[,2]) / 100000

[1] 40.36153

> sum(X1[,3]) / 100000

[1] 49.83571

> sum(X1[,4]) / 100000

[1] 34.69571      # "4th element of mean vector"

> sum(X1[,5]) / 100000

[1] 44.81081

> sum(X1[,6]) / 100000

[1] 31.10834




And corresponding results received using equation (3) from pdf file:
[54.97,
40,
49.95,
35.31, #  "4th element of mean vector"
44.94,
31.32]

On 9 May 2017 at 22:17, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 9, 2017, at 1:11 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>
>> Of course I have expected the difference between theory and a sample
>> of realizations of RV's and result mean should still be a random
>> variable. But, for example for 4th element of mean vector: 35.31 -
>> 34.69571 = 0.61429. It is quite big difference, nieprawda?? I have
>> expected that the difference would be smaller because of law of large
>> numbers (for 10mln samples the difference is quite similar).
>
> I for one have no idea what is meant by a "4th element of mean vector". So I have now idea what to consider "big". I have found that my intuitions about multivariate distributions, especially those where the covariate structure is as complex as you have assumed, are often far from simulated results.
>
> I suggest you post some code and results.
>
> --
> David.
>
>
>>
>> On 9 May 2017 at 21:40, David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>>> On May 9, 2017, at 10:09 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>>
>>>> Dear Members,
>>>> I am working with 6-dimensional Student-t distribution with 4 degrees
>>>> of freedom truncated to [20; 60]. I have generated 100 000 samples
>>>> from truncated multivariate Student-t distribution using rtmvt
>>>> function from package ?tmvtnorm?. I have also calculated  mean vector
>>>> using equation (3) from attached pdf. The problem is, that after
>>>> summing all elements in one column of rtmvt result (and dividing by
>>>> 100 000) I do not receive the same result as using (3) equation. Could
>>>> You tell me, what is incorrect, why there is a difference?
>>>
>>> I guess the question is why you would NOT expect a difference between theory and a sample of realizations of RV's? The result mean should still be a random variable, night wahr?
>>>
>>>
>>>> Yours faithfully
>>>> Czarek Kowalski
>>>> <truncatedT.pdf>______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Tue May  9 23:33:04 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 May 2017 14:33:04 -0700
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
In-Reply-To: <CAEKZwC-0-XYH20bFCu1m-ooFDH3VuVjcw2mJcu08RYO-QrZz7A@mail.gmail.com>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
 <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>
 <CAEKZwC-_NJgFk8sD4+3D=bOGi1KDd0mUrKL+63yesNeOzC150w@mail.gmail.com>
 <A6EB7E1D-0D76-4EE7-8A35-9D620BCDD2D3@comcast.net>
 <CAEKZwC-0-XYH20bFCu1m-ooFDH3VuVjcw2mJcu08RYO-QrZz7A@mail.gmail.com>
Message-ID: <13E94449-E676-44EE-96E1-106A2B915E5C@comcast.net>


> On May 9, 2017, at 2:05 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
> 
> I have already posted that in attachement - pdf file.

I see that now. I failed to scroll to the 3rd page.

> I am posting
> plain text here:
> 
>> library(tmvtnorm)
>> meann = c(55, 40, 50, 35, 45, 30)
>> covv = matrix(c(  1, 1, 0, 2, -1, -1,
>                    1, 16, -6, -6, -2, 12,
>                    0, -6, 4, 2, -2, -5,
>                    2, -6, 2, 25, 0, -17,
>                   -1, -2, -2, 0, 9, -5,
>                   -1, 12, -5, -17, -5, 36), 6, 6)
> df = 4
> lower = c(20, 20, 20, 20, 20, 20)
> upper = c(60, 60, 60, 60, 60, 60)
> X1 <- rtmvt(n=100000, meann, covv, df, lower, upper)
> 
> 
>> sum(X1[,1]) / 100000
> [1] 54.98258
> sum(X1[,2]) / 100000
> [1] 40.36153
> sum(X1[,3]) / 100000
> [1] 49.83571
> sum(X1[,4]) / 100000
> [1] 34.69571      # "4th element of mean vector"
> sum(X1[,5]) / 100000
> [1] 44.81081
> sum(X1[,6]) / 100000
> [1] 31.10834
> 
> And corresponding results received using equation (3) from pdf file:
> [54.97,
> 40,
> 49.95,
> 35.31, #  "4th element of mean vector"
> 44.94,
> 31.32]
> 

I get similar results for the output from your code, 

My 100-fold run of your calculations were:

meansBig <- replicate(100, {Xbig <- rtmvt(n=100000, meann, covv, df, lower, upper)
colMeans(Xbig)} )

describe(meansBig[4,])  # describe is from Hmisc package

meansBig[4, ] 
       n  missing distinct     Info     Mean      Gmd      .05      .10      .25 
     100        0      100        1     34.7  0.01954    34.68    34.68    34.69 
     .50      .75      .90      .95 
   34.70    34.72    34.72    34.73 

lowest : 34.65222 34.66675 34.66703 34.66875 34.67566
highest: 34.72939 34.73012 34.73051 34.73742 34.74441


So agree, 35.31 is outside the plausible range of an RV formed with that package, but I don't have any code relating to your calculations from theory.

Best;
David.


> On 9 May 2017 at 22:17, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On May 9, 2017, at 1:11 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>> 
>>> Of course I have expected the difference between theory and a sample
>>> of realizations of RV's and result mean should still be a random
>>> variable. But, for example for 4th element of mean vector: 35.31 -
>>> 34.69571 = 0.61429. It is quite big difference, nieprawda?? I have
>>> expected that the difference would be smaller because of law of large
>>> numbers (for 10mln samples the difference is quite similar).
>> 
>> I for one have no idea what is meant by a "4th element of mean vector". So I have now idea what to consider "big". I have found that my intuitions about multivariate distributions, especially those where the covariate structure is as complex as you have assumed, are often far from simulated results.
>> 
>> I suggest you post some code and results.
>> 
>> --
>> David.
>> 
>> 
>>> 
>>> On 9 May 2017 at 21:40, David Winsemius <dwinsemius at comcast.net> wrote:
>>>> 
>>>>> On May 9, 2017, at 10:09 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>>> 
>>>>> Dear Members,
>>>>> I am working with 6-dimensional Student-t distribution with 4 degrees
>>>>> of freedom truncated to [20; 60]. I have generated 100 000 samples
>>>>> from truncated multivariate Student-t distribution using rtmvt
>>>>> function from package ?tmvtnorm?. I have also calculated  mean vector
>>>>> using equation (3) from attached pdf. The problem is, that after
>>>>> summing all elements in one column of rtmvt result (and dividing by
>>>>> 100 000) I do not receive the same result as using (3) equation. Could
>>>>> You tell me, what is incorrect, why there is a difference?
>>>> 
>>>> I guess the question is why you would NOT expect a difference between theory and a sample of realizations of RV's? The result mean should still be a random variable, night wahr?
>>>> 
>>>> 
>>>>> Yours faithfully
>>>>> Czarek Kowalski
>>>>> <truncatedT.pdf>______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue May  9 23:50:03 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 May 2017 14:50:03 -0700
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
In-Reply-To: <13E94449-E676-44EE-96E1-106A2B915E5C@comcast.net>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
 <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>
 <CAEKZwC-_NJgFk8sD4+3D=bOGi1KDd0mUrKL+63yesNeOzC150w@mail.gmail.com>
 <A6EB7E1D-0D76-4EE7-8A35-9D620BCDD2D3@comcast.net>
 <CAEKZwC-0-XYH20bFCu1m-ooFDH3VuVjcw2mJcu08RYO-QrZz7A@mail.gmail.com>
 <13E94449-E676-44EE-96E1-106A2B915E5C@comcast.net>
Message-ID: <DCA9924D-23C5-41B6-A4F3-79F30CC9DB0C@comcast.net>


> On May 9, 2017, at 2:33 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On May 9, 2017, at 2:05 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>> 
>> I have already posted that in attachement - pdf file.
> 
> I see that now. I failed to scroll to the 3rd page.
> 
>> I am posting
>> plain text here:
>> 
>>> library(tmvtnorm)
>>> meann = c(55, 40, 50, 35, 45, 30)
>>> covv = matrix(c(  1, 1, 0, 2, -1, -1,
>>                   1, 16, -6, -6, -2, 12,
>>                   0, -6, 4, 2, -2, -5,
>>                   2, -6, 2, 25, 0, -17,
>>                  -1, -2, -2, 0, 9, -5,
>>                  -1, 12, -5, -17, -5, 36), 6, 6)
>> df = 4
>> lower = c(20, 20, 20, 20, 20, 20)
>> upper = c(60, 60, 60, 60, 60, 60)
>> X1 <- rtmvt(n=100000, meann, covv, df, lower, upper)
>> 
>> 
>>> sum(X1[,1]) / 100000
>> [1] 54.98258
>> sum(X1[,2]) / 100000
>> [1] 40.36153
>> sum(X1[,3]) / 100000
>> [1] 49.83571
>> sum(X1[,4]) / 100000
>> [1] 34.69571      # "4th element of mean vector"
>> sum(X1[,5]) / 100000
>> [1] 44.81081
>> sum(X1[,6]) / 100000
>> [1] 31.10834
>> 
>> And corresponding results received using equation (3) from pdf file:
>> [54.97,
>> 40,
>> 49.95,
>> 35.31, #  "4th element of mean vector"
>> 44.94,
>> 31.32]
>> 
> 
> I get similar results for the output from your code, 
> 
> My 100-fold run of your calculations were:
> 
> meansBig <- replicate(100, {Xbig <- rtmvt(n=100000, meann, covv, df, lower, upper)
> colMeans(Xbig)} )
> 
> describe(meansBig[4,])  # describe is from Hmisc package
> 
> meansBig[4, ] 
>       n  missing distinct     Info     Mean      Gmd      .05      .10      .25 
>     100        0      100        1     34.7  0.01954    34.68    34.68    34.69 
>     .50      .75      .90      .95 
>   34.70    34.72    34.72    34.73 
> 
> lowest : 34.65222 34.66675 34.66703 34.66875 34.67566
> highest: 34.72939 34.73012 34.73051 34.73742 34.74441
> 
> 
> So agree, 35.31 is outside the plausible range of an RV formed with that package, but I don't have any code relating to your calculations from theory.

Further investigation:

covDiag <- covv*( row(covv)==col(covv) )  # just the diagonal means

Repeat with all zero covariances:

> meansDiag <- replicate(100, {Xbig <- rtmvt(n=100000, meann, covDiag, df, lower, upper)
+ colMeans(Xbig)} )
> describe(meansDiag[4,])
meansDiag[4, ] 
       n  missing distinct     Info     Mean      Gmd      .05      .10      .25 
     100        0      100        1    35.23  0.02074    35.21    35.21    35.22 
     .50      .75      .90      .95 
   35.23    35.25    35.26    35.26 

lowest : 35.18360 35.19756 35.20098 35.20179 35.20622
highest: 35.26367 35.26635 35.26791 35.27251 35.27302

So failing to account for the covariances in your theoretical calculations mostly explains the apparent discrepancy, although your value of 35.31 would be at the  far end of a statistical distribution and I wonder about some sort of error in your theoretical calculation, which didn't appear to take into account the covariance matrix.

Best;
David.



> 
> Best;
> David.
> 
> 
>> On 9 May 2017 at 22:17, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>>> On May 9, 2017, at 1:11 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>> 
>>>> Of course I have expected the difference between theory and a sample
>>>> of realizations of RV's and result mean should still be a random
>>>> variable. But, for example for 4th element of mean vector: 35.31 -
>>>> 34.69571 = 0.61429. It is quite big difference, nieprawda?? I have
>>>> expected that the difference would be smaller because of law of large
>>>> numbers (for 10mln samples the difference is quite similar).
>>> 
>>> I for one have no idea what is meant by a "4th element of mean vector". So I have now idea what to consider "big". I have found that my intuitions about multivariate distributions, especially those where the covariate structure is as complex as you have assumed, are often far from simulated results.
>>> 
>>> I suggest you post some code and results.
>>> 
>>> --
>>> David.
>>> 
>>> 
>>>> 
>>>> On 9 May 2017 at 21:40, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>> 
>>>>>> On May 9, 2017, at 10:09 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>>>> 
>>>>>> Dear Members,
>>>>>> I am working with 6-dimensional Student-t distribution with 4 degrees
>>>>>> of freedom truncated to [20; 60]. I have generated 100 000 samples
>>>>>> from truncated multivariate Student-t distribution using rtmvt
>>>>>> function from package ?tmvtnorm?. I have also calculated  mean vector
>>>>>> using equation (3) from attached pdf. The problem is, that after
>>>>>> summing all elements in one column of rtmvt result (and dividing by
>>>>>> 100 000) I do not receive the same result as using (3) equation. Could
>>>>>> You tell me, what is incorrect, why there is a difference?
>>>>> 
>>>>> I guess the question is why you would NOT expect a difference between theory and a sample of realizations of RV's? The result mean should still be a random variable, night wahr?
>>>>> 
>>>>> 
>>>>>> Yours faithfully
>>>>>> Czarek Kowalski
>>>>>> <truncatedT.pdf>______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>> 
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Wed May 10 00:23:04 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 10 May 2017 00:23:04 +0200
Subject: [R] Factors and Alternatives
In-Reply-To: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>
References: <OF5920B0D4.6682ACF1-ONC125811B.00366F7B-C125811B.00381802@lotus.hawesko.de>
Message-ID: <0708E6C6-89F8-46DA-9ACC-385C870CB544@gmail.com>

Inline...

> On 9 May 2017, at 12:12 , G.Maubach at weinwolf.de wrote:
> 
> Hi All,
> 
> I am using factors in a study for the social sciences.
> 
> I discovered the following:
> 
> -- cut --
> 
> library(dplyr)
> 
> test1 <- c(rep(1, 4), rep(0, 6))
> d_test1 <- data.frame(test)
> 
> test2 <- factor(test1)
> d_test2 <- data.frame(test2)
> 
> test3 <- factor(test1, 
>                levels = c(0, 1),
>                labels = c("WITHOUT Contact", "WITH Contact"))
> d_test3 <- data.frame(test3)
> 
> d_test1 %>% filter(test1 == 0)  # works OK
> d_test2 %>% filter(test2 == 0)  # works OK
> d_test3 %>% filter(test3 == 0)  # does not work, why?
> 



test3 does not have a level 0. You want

test3 == "WITHOUT Contact"


Notice that once test3 is  created, the input levels are lost, and thus "test3 == 0" becomes meaningless.

-pd


> myf <- function(ds) {
>  print(levels(ds$test3))
>  print(labels(ds$test3))
>  print(as.numeric(ds$test3))
>  print(as.character(ds$test3))
> }
> 
> # This showsthat it is not possible to access the original
> # values which were the basis to build the factor:
> myf(d_test3)
> 
> -- cut --
> 
> Why is it not possible to use a factor with labels for filtering with the 
> original values?
> Is there a data structure that works like a factor but gives also access 
> to the original values?
> 
> Kind regards
> 
> Georg
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From boris.steipe at utoronto.ca  Wed May 10 00:35:49 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 9 May 2017 18:35:49 -0400
Subject: [R] How to replace missing values by mean of subgroup of a group
In-Reply-To: <1291912706.7410627.1494364722845@mail.yahoo.com>
References: <1349484531.7246696.1494357246706.ref@mail.yahoo.com>
 <1349484531.7246696.1494357246706@mail.yahoo.com>
 <C7E3B33C-8F4E-49D4-B0D3-2B1824F9892D@utoronto.ca>
 <1291912706.7410627.1494364722845@mail.yahoo.com>
Message-ID: <6268129C-23E0-43B0-838B-6E7B79E9709D@utoronto.ca>

Great. 

I am CC'ing the list - this is important so that others who may come across this thread in the archives know that this question has been resolved.

Cheers,

B.


> On May 9, 2017, at 5:18 PM, Olu Ola <oluola2011 at yahoo.com> wrote:
> 
> Thank you!!! It worked.
> 
> Regards,
> Olu
> 
> 
> On Tuesday, May 9, 2017 4:20 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> Pedestrian code, so you can analyze this easily. However entirely untested since I have no ambitionto recreate your input data as a data frame. This code assumes:
> - your data _is_ a data frame
> - the desired column is called food.price, not "food price" (cf. ?make.names )
> 
> # define a function that imputes NA values in the same city, for the same food
> imputeFoodPrice <- function(DF, i) {
>   sel <- DF$city == DF$city[i] & DF$food == DF$food[i]
>   imputed <- mean(DF$food.price[sel], na.rm = TRUE)
>   if (is.nan(imputed)) { # careful, there might be no other match
>     imputed <- NA
>   }
>   return(imputed)
> }
> 
> 
> # apply the function to replace NA values
> for (iMissing in which(is.na(myDF$food.price))) {
>   myDF$food.price[iMissing] <- imputeFoodPrice(myDF, iMissing)
> }
> 
> 
> B.
> 
> 
> 
> > On May 9, 2017, at 3:14 PM, Olu Ola via R-help <r-help at r-project.org> wrote:
> > 
> > Hello,I have the following food data with some NA values in the food prices. I will like to replace the NA values in the food price column for each food item by the mean price of the specific food item for each city. For example, the price of bean for the household with hhid 102 in the data set is missing. I will like to replace the missing value with the mean price of bean for the households living in Paxton city (that is households 101 and 103). the data set is presented below. Any help will be greatly appreciated.
> > 
> > | hhid | city | food | food price |
> > | 101 | Paxton | rice | 10 |
> > | 101 | Paxton | beans | 30 |
> > | 101 | Paxton | flour | NA |
> > | 101 | Paxton | eggs | 20 |
> > | 102 | Paxton | rice | NA |
> > | 102 | Paxton | beans | NA |
> > | 102 | Paxton | flour | 34 |
> > | 102 | Paxton | eggs | 21 |
> > | 103 | Paxton | rice | 15 |
> > | 103 | Paxton | beans | 28 |
> > | 103 | Paxton | flour | 32 |
> > | 103 | Paxton | eggs | NA |
> > | 104 | Hull | rice | NA |
> > | 104 | Hull | beans | 34 |
> > | 104 | Hull | flour | NA |
> > | 104 | Hull | eggs | 24 |
> > | 105 | Hull | rice | 18 |
> > | 105 | Hull | beans | 38 |
> > | 105 | Hull | flour | 36 |
> > | 105 | Hull | eggs | 26 |
> > | 106 | Hull | rice | NA |
> > | 106 | Hull | beans | NA |
> > | 106 | Hull | flour | 40 |
> > | 106 | Hull | eggs | NA |
> > 
> > 
> >     [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From renzogiudice at gmail.com  Tue May  9 23:09:33 2017
From: renzogiudice at gmail.com (Renzo Giudice)
Date: Tue, 9 May 2017 16:09:33 -0500
Subject: [R] Estimating cluster standard errors in Diff-in-Diff panel models
	with plm
Message-ID: <CA+0Bx-24La+03WfprX4pAFwMb_jFe5mx9wOfxurWvVEe8zH-qQ@mail.gmail.com>

Hi,
I want to estimate the cluster SE of a differences-in-differences
panel model with 100 groups, 6,156 individuals and 15 years. Some of
the individuals are repeated (4,201 unique) because they are part of a
matched sample obtained with a one-to-one, with replacement, matching
method.
I have been using plm to estimate the model coefficients, after
transforming my matched sample into a pdata.frame by using indivuals
and years as indexes. I have also been able to estimate the cluster
standard errors at the individual level by using the vcovHC function.
However, these individuals are clustered within the groups, and
therefore I want to cluster at this higher level of aggregation rather
than at the individual level. Unfortunately, it is not clear to me how
to proceed. Of course if I replace the individuals for groups in the
index I get repeated row.names and then I can?t estimate the panel
model with plm. I get the following error message:

Error in `row.names<-.data.frame`(`*tmp*`, value = c("1-1", "1-1",
"1-1",  : duplicate 'row.names' are not allowed

For simplicity, I make my case using the following example (copied
from: http://www.richard-bluhm.com/clustered-ses-in-r-and-stata-2/):
# load packages
require(plm)
require(lmtest)
# get data and load as pdata.frame
url <- "http://www.kellogg.northwestern.edu/faculty/petersen/htm/papers/se/test_data.txt"
p.df <- read.table(url)
names(p.df) <- c("firmid", "year", "x", "y")
#Introduce group (State) Id
p.df$State <- rep(1:100, each=50)
p.df2 <- pdata.frame(p.df, index = c("State", "year"), drop.index = F,
row.names = T)
# fit model with plm
pm1 <- plm(y ~ x, data = p.df2, model = "within") #this is where the
error occurs.

So is there any way I could cluster SE at the group level using plm?
Any other comments would be highly appreciated.

Thanks in advance!
Renzo
Center for Development Research
University of Bonn


From bgunter.4567 at gmail.com  Wed May 10 02:44:28 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 9 May 2017 17:44:28 -0700
Subject: [R] How to replace missing values by mean of subgroup of a group
In-Reply-To: <CAGxFJbSrOVehW3FQxizNmeWtqk==YR2OGLOHgZBTHT+gC+Og3w@mail.gmail.com>
References: <1349484531.7246696.1494357246706.ref@mail.yahoo.com>
 <1349484531.7246696.1494357246706@mail.yahoo.com>
 <C7E3B33C-8F4E-49D4-B0D3-2B1824F9892D@utoronto.ca>
 <1291912706.7410627.1494364722845@mail.yahoo.com>
 <6268129C-23E0-43B0-838B-6E7B79E9709D@utoronto.ca>
 <CAGxFJbSrOVehW3FQxizNmeWtqk==YR2OGLOHgZBTHT+gC+Og3w@mail.gmail.com>
Message-ID: <CAGxFJbSjZpRYHzjitUBSTubTP37yiXKQYQvfQp2uDBVffC7vxQ@mail.gmail.com>

Of course, statistically, one should not do this. But that's another thread
on another site.

Cheers,
Bert



On May 9, 2017 3:36 PM, "Boris Steipe" <boris.steipe at utoronto.ca> wrote:

Great.

I am CC'ing the list - this is important so that others who may come across
this thread in the archives know that this question has been resolved.

Cheers,

B.


> On May 9, 2017, at 5:18 PM, Olu Ola <oluola2011 at yahoo.com> wrote:
>
> Thank you!!! It worked.
>
> Regards,
> Olu
>
>
> On Tuesday, May 9, 2017 4:20 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:
>
>
> Pedestrian code, so you can analyze this easily. However entirely
untested since I have no ambitionto recreate your input data as a data
frame. This code assumes:
> - your data _is_ a data frame
> - the desired column is called food.price, not "food price" (cf.
?make.names )
>
> # define a function that imputes NA values in the same city, for the same
food
> imputeFoodPrice <- function(DF, i) {
>   sel <- DF$city == DF$city[i] & DF$food == DF$food[i]
>   imputed <- mean(DF$food.price[sel], na.rm = TRUE)
>   if (is.nan(imputed)) { # careful, there might be no other match
>     imputed <- NA
>   }
>   return(imputed)
> }
>
>
> # apply the function to replace NA values
> for (iMissing in which(is.na(myDF$food.price))) {
>   myDF$food.price[iMissing] <- imputeFoodPrice(myDF, iMissing)
> }
>
>
> B.
>
>
>
> > On May 9, 2017, at 3:14 PM, Olu Ola via R-help <r-help at r-project.org>
wrote:
> >
> > Hello,I have the following food data with some NA values in the food
prices. I will like to replace the NA values in the food price column for
each food item by the mean price of the specific food item for each city.
For example, the price of bean for the household with hhid 102 in the data
set is missing. I will like to replace the missing value with the mean
price of bean for the households living in Paxton city (that is households
101 and 103). the data set is presented below. Any help will be greatly
appreciated.
> >
> > | hhid | city | food | food price |
> > | 101 | Paxton | rice | 10 |
> > | 101 | Paxton | beans | 30 |
> > | 101 | Paxton | flour | NA |
> > | 101 | Paxton | eggs | 20 |
> > | 102 | Paxton | rice | NA |
> > | 102 | Paxton | beans | NA |
> > | 102 | Paxton | flour | 34 |
> > | 102 | Paxton | eggs | 21 |
> > | 103 | Paxton | rice | 15 |
> > | 103 | Paxton | beans | 28 |
> > | 103 | Paxton | flour | 32 |
> > | 103 | Paxton | eggs | NA |
> > | 104 | Hull | rice | NA |
> > | 104 | Hull | beans | 34 |
> > | 104 | Hull | flour | NA |
> > | 104 | Hull | eggs | 24 |
> > | 105 | Hull | rice | 18 |
> > | 105 | Hull | beans | 38 |
> > | 105 | Hull | flour | 36 |
> > | 105 | Hull | eggs | 26 |
> > | 106 | Hull | rice | NA |
> > | 106 | Hull | beans | NA |
> > | 106 | Hull | flour | 40 |
> > | 106 | Hull | eggs | NA |
> >
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed May 10 02:59:34 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 9 May 2017 20:59:34 -0400
Subject: [R] How to replace missing values by mean of subgroup of a group
In-Reply-To: <CAGxFJbSjZpRYHzjitUBSTubTP37yiXKQYQvfQp2uDBVffC7vxQ@mail.gmail.com>
References: <1349484531.7246696.1494357246706.ref@mail.yahoo.com>
 <1349484531.7246696.1494357246706@mail.yahoo.com>
 <C7E3B33C-8F4E-49D4-B0D3-2B1824F9892D@utoronto.ca>
 <1291912706.7410627.1494364722845@mail.yahoo.com>
 <6268129C-23E0-43B0-838B-6E7B79E9709D@utoronto.ca>
 <CAGxFJbSrOVehW3FQxizNmeWtqk==YR2OGLOHgZBTHT+gC+Og3w@mail.gmail.com>
 <CAGxFJbSjZpRYHzjitUBSTubTP37yiXKQYQvfQp2uDBVffC7vxQ@mail.gmail.com>
Message-ID: <84151BCA-667D-4257-858F-728B3FC6C855@utoronto.ca>

Of course, and I neglected to point this out:

"The other thread" would be how to properly impute missing values,
"The other site" could be https://stats.stackexchange.com/
... there is _lots_ of information available if you search for it.

An applicable R Package is MICE and you can find an introduction here:
  https://datascienceplus.com/imputing-missing-data-with-r-mice-package/

(Besides the usual documentation.)


B.



> On May 9, 2017, at 8:44 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Of course, statistically, one should not do this. But that's another thread on another site.
> 
> Cheers,
> Bert
> 
> 
> 
> On May 9, 2017 3:36 PM, "Boris Steipe" <boris.steipe at utoronto.ca> wrote:
> Great.
> 
> I am CC'ing the list - this is important so that others who may come across this thread in the archives know that this question has been resolved.
> 
> Cheers,
> 
> B.
> 
> 
> > On May 9, 2017, at 5:18 PM, Olu Ola <oluola2011 at yahoo.com> wrote:
> >
> > Thank you!!! It worked.
> >
> > Regards,
> > Olu
> >
> >
> > On Tuesday, May 9, 2017 4:20 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> >
> >
> > Pedestrian code, so you can analyze this easily. However entirely untested since I have no ambitionto recreate your input data as a data frame. This code assumes:
> > - your data _is_ a data frame
> > - the desired column is called food.price, not "food price" (cf. ?make.names )
> >
> > # define a function that imputes NA values in the same city, for the same food
> > imputeFoodPrice <- function(DF, i) {
> >   sel <- DF$city == DF$city[i] & DF$food == DF$food[i]
> >   imputed <- mean(DF$food.price[sel], na.rm = TRUE)
> >   if (is.nan(imputed)) { # careful, there might be no other match
> >     imputed <- NA
> >   }
> >   return(imputed)
> > }
> >
> >
> > # apply the function to replace NA values
> > for (iMissing in which(is.na(myDF$food.price))) {
> >   myDF$food.price[iMissing] <- imputeFoodPrice(myDF, iMissing)
> > }
> >
> >
> > B.
> >
> >
> >
> > > On May 9, 2017, at 3:14 PM, Olu Ola via R-help <r-help at r-project.org> wrote:
> > >
> > > Hello,I have the following food data with some NA values in the food prices. I will like to replace the NA values in the food price column for each food item by the mean price of the specific food item for each city. For example, the price of bean for the household with hhid 102 in the data set is missing. I will like to replace the missing value with the mean price of bean for the households living in Paxton city (that is households 101 and 103). the data set is presented below. Any help will be greatly appreciated.
> > >
> > > | hhid | city | food | food price |
> > > | 101 | Paxton | rice | 10 |
> > > | 101 | Paxton | beans | 30 |
> > > | 101 | Paxton | flour | NA |
> > > | 101 | Paxton | eggs | 20 |
> > > | 102 | Paxton | rice | NA |
> > > | 102 | Paxton | beans | NA |
> > > | 102 | Paxton | flour | 34 |
> > > | 102 | Paxton | eggs | 21 |
> > > | 103 | Paxton | rice | 15 |
> > > | 103 | Paxton | beans | 28 |
> > > | 103 | Paxton | flour | 32 |
> > > | 103 | Paxton | eggs | NA |
> > > | 104 | Hull | rice | NA |
> > > | 104 | Hull | beans | 34 |
> > > | 104 | Hull | flour | NA |
> > > | 104 | Hull | eggs | 24 |
> > > | 105 | Hull | rice | 18 |
> > > | 105 | Hull | beans | 38 |
> > > | 105 | Hull | flour | 36 |
> > > | 105 | Hull | eggs | 26 |
> > > | 106 | Hull | rice | NA |
> > > | 106 | Hull | beans | NA |
> > > | 106 | Hull | flour | 40 |
> > > | 106 | Hull | eggs | NA |
> > >
> > >
> > >     [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From reichmanj at sbcglobal.net  Wed May 10 03:55:27 2017
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Tue, 9 May 2017 20:55:27 -0500
Subject: [R] Plotting bar charts by Month
Message-ID: <000e01d2c930$8062af90$81280eb0$@sbcglobal.net>

r-help

 

Trying to figure out how to plot by month bar charts. The follow code plots
the monthly portion on a yearly x-scale.  So I either I create 12 individual
month plots or maybe there is some sort of "break" to tell R separate by
month and use the months dates as the x-scale; so that Jan's scale is 1 - 31
Jan , Feb scale is 1 - 28 Feb etc.  As it is now I get the Jan values ploted
with a 1-Jan to 31 Dec x-scale; Feb's value are ploted on a 1-Jan to 31 Dec
x-scale etc.

 

ggplot(data = df, aes(x = date, y = height)) +

        geom_bar(stat = "identity") +

        geom_bar(aes(x = action, y = height), color = "red", stat =
"identity") +

        facet_wrap(~month, nrow = 3)

 

Jeff


	[[alternative HTML version deleted]]


From sharada.ramadass at gmail.com  Wed May 10 07:15:06 2017
From: sharada.ramadass at gmail.com (Sharada Ramadass)
Date: Wed, 10 May 2017 10:45:06 +0530
Subject: [R] basic query relating to GLMM model design
Message-ID: <CAG=Fgt96iTAxk2fg8nr3xpuy91-nAvTLqttj82Ke0JFCiLzoWg@mail.gmail.com>

Hello,
  I am a newbie to R and GLMM and having a difficult time
understanding the model design that best captures my test scenario.

I am interested in the following question:
1. whether average values of a variable explain a certain response
lesser than individual values.

1.1. For this, I have a single response, say y.
1.2. I have a bunch of fixed predictors, say x1, x2, x3 and I can
derive my models for those.
1.3 I have two kinds of random effects - a site (r1) and a species
(r2), within the site. My average values of some of the fixed
predictors is based on the species (r2).
I am not especially interested in looking at site level variations,
but I did build it into the model, all the same.

So, I was able to develop a set of models with the individual values like so:

y ~ x1+ x2 + x3 + (1|r1/r2)
I was able to get some output in terms of significance for certain
parameter estimates. So far, its ok.

Now, I wanted to test whether the average values of x1 and x2 based on
r2 will predict y with less powerful estimates. My doubt is whether in
that case, r2 should be removed from the random variable since I now
actually have average values for all x1 and x2 for a certain value of
r2.
Basically is the below model with average values logically wrong?
y ~ x1avg + x2avg + x3 + (1|r1/r2)

my averages for x1 and x2 are over each value of r2.
Should r2 move to a fixed effect or be removed totally from the model?
Any inputs would be appreciated.

Thanks and Regards,
Sharada


From jdnewmil at dcn.davis.ca.us  Wed May 10 07:35:11 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 09 May 2017 22:35:11 -0700
Subject: [R] Plotting bar charts by Month
In-Reply-To: <000e01d2c930$8062af90$81280eb0$@sbcglobal.net>
References: <000e01d2c930$8062af90$81280eb0$@sbcglobal.net>
Message-ID: <8C13F30B-3098-4ABD-BAB9-B6F52B9E6BEC@dcn.davis.ca.us>

For this kind of plot I usually use day-of-month for for the x-axis instead of a date or timestamp. 
-- 
Sent from my phone. Please excuse my brevity.

On May 9, 2017 6:55:27 PM PDT, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>r-help
>
> 
>
>Trying to figure out how to plot by month bar charts. The follow code
>plots
>the monthly portion on a yearly x-scale.  So I either I create 12
>individual
>month plots or maybe there is some sort of "break" to tell R separate
>by
>month and use the months dates as the x-scale; so that Jan's scale is 1
>- 31
>Jan , Feb scale is 1 - 28 Feb etc.  As it is now I get the Jan values
>ploted
>with a 1-Jan to 31 Dec x-scale; Feb's value are ploted on a 1-Jan to 31
>Dec
>x-scale etc.
>
> 
>
>ggplot(data = df, aes(x = date, y = height)) +
>
>        geom_bar(stat = "identity") +
>
>        geom_bar(aes(x = action, y = height), color = "red", stat =
>"identity") +
>
>        facet_wrap(~month, nrow = 3)
>
> 
>
>Jeff
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Keith.Jewell at campdenbri.co.uk  Wed May 10 12:46:38 2017
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Wed, 10 May 2017 11:46:38 +0100
Subject: [R] Problem with choose.files(default=..., multi=FALSE)
In-Reply-To: <b33b604f-4e5e-db2a-6c6e-4cc59bd0e27c@gmail.com>
References: <oespd8$okp$1@blaine.gmane.org>
 <b33b604f-4e5e-db2a-6c6e-4cc59bd0e27c@gmail.com>
Message-ID: <5912EF8E.5070507@campdenbri.co.uk>

Thanks for confirming that I wasn't being stupid :-}

When using default=pathlong I get the _correct_ starting directory...
(M:\test\Averyveryveryveryverylongfoldername\Averyveryveryveryverylongfoldername\Averyveryveryveryverylongfoldername) 

... both in the environment I indicated originally (Windows Server 2008 
R2 x64) and also in Windows 10 x64

Keith Jewell

On 09/05/2017 17:49, Duncan Murdoch wrote:
> On 09/05/2017 12:06 PM, Keith Jewell wrote:
>> I'm very hesitant to suggest that there's a bug in such a venerable R
>> function, but I can't see what I'm doing wrong. Any comments are welcome
>
> Yes, it looks like a bug.  One other thing I find a little strange: the
> starting directory seems wrong when I have the pathlong default.  Did
> you see that?  (I'm in Windows 10, not the same version as you.)
>
> Duncan Murdoch
>
>>
>> When using choose.files() where:
>>      default = something
>>      multi = FALSE
>>      selected file path is shorter than the default
>> ... then the returned value is at least as long as the default,
>> characters from default appearing (wrongly) at the end of the returned
>> value.
>>
>> Example, in which all but the first choose.files() select
>> "M:\\test\\target.dat". Note the last result.
>>
>>  > pathlong <- choose.files(caption = "long")
>>  > pathlong # long file name to use as default for short selection
>> [1]
>> "M:\\test\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\target.dat"
>>
>>  > choose.files(caption = "short")  # no default without multi works
>> [1] "M:\\test\\target.dat"
>>  > choose.files(default=pathlong, caption = "short") # default without
>> multi= works
>> [1] "M:\\test\\target.dat"
>>  > choose.files(caption = "short", multi = FALSE) # multi = FALSE
>> without default works
>> [1] "M:\\test\\target.dat"
>>  > choose.files(default=pathlong, caption = "short", multi = TRUE) #
>> multi = TRUE with default works
>> [1] "M:\\test\\target.dat"
>>  > choose.files(default=pathlong, caption = "short", multi = FALSE) #
>> multi = FALSE with default fails
>> [1]
>> "M:\\test\\target.dat\\ryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\target.dat"
>>
>>
>>  > # in case it's relevant
>>  > sessionInfo()
>> R version 3.4.0 (2017-04-21)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>> Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
>> Kingdom.1252
>> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=English_United Kingdom.1252
>>
>> attached base packages:
>> [1] graphics  grDevices datasets  stats     tcltk     utils     tools
>>    methods
>> [9] base
>>
>> other attached packages:
>>   [1] CBRIutils_1.0   stringr_1.2.0   svSocket_0.9-57 TinnR_1.0-5
>> R2HTML_2.3.2
>>   [6] Hmisc_4.0-3     ggplot2_2.2.1   Formula_1.2-1   survival_2.41-3
>> lattice_0.20-35
>>
>> loaded via a namespace (and not attached):
>>   [1] RColorBrewer_1.1-2  htmlTable_1.9       digest_0.6.12
>> htmltools_0.3.6
>>   [5] splines_3.4.0       scales_0.4.1        grid_3.4.0
>> checkmate_1.8.2
>>   [9] devtools_1.12.0     knitr_1.15.1        munsell_0.4.3
>> compiler_3.4.0
>> [13] tibble_1.3.0        nnet_7.3-12         acepack_1.4.1
>> Matrix_1.2-10
>> [17] svMisc_0.9-70       plyr_1.8.4          base64enc_0.1-3
>> data.table_1.10.4
>> [21] stringi_1.1.5       magrittr_1.5        gtable_0.2.0
>> colorspace_1.3-2
>> [25] foreign_0.8-68      cluster_2.0.6       gridExtra_2.2.1
>> htmlwidgets_0.8
>> [29] withr_1.0.2         lazyeval_0.2.0      backports_1.0.5
>> memoise_1.1.0
>> [33] rpart_4.1-11        Rcpp_0.12.10        latticeExtra_0.6-28
>>  >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From david.stevens at usu.edu  Wed May 10 17:43:15 2017
From: david.stevens at usu.edu (David Stevens)
Date: Wed, 10 May 2017 09:43:15 -0600
Subject: [R] Non-Linear Regression Help
In-Reply-To: <CANQ4g2Ur9UAHaDVJ_NcoqVvHk4RC68wVQA52=Tp_TJ71dhPa=A@mail.gmail.com>
References: <CANQ4g2Ur9UAHaDVJ_NcoqVvHk4RC68wVQA52=Tp_TJ71dhPa=A@mail.gmail.com>
Message-ID: <9985383c-eb3b-c7c1-c53a-437c51522c29@usu.edu>

I have a fair bit of experience with both nls and rating curves. This is 
not a nls() problem, this is a model problem. The power law rating curve 
favored by hydrologists would not apply to your data as it's based on 
the idea that a log-log plot of discharge vs. stage, or state+a in your 
case is a straight line, statistical assumptions notwithstanding. A 
log-log plot of your data,

plot(discharge~stage,data=yourdata,pch=19,log='xy')

clear is not a straight line. The very large discharge at stage=6.53 vs. 
stage=6.32 says one of two things: 1) there is an error in the data 
(perhaps the 2592.05 should be 592.05) or 2) the river channel geometry 
has changed dramatically, as in overtopping its banks or perhaps there's 
a smaller central channel set into a larger flood channel, similar to 
the LA river of the movies. The way forward is 1) recheck your data or 
2) recheck your data and use a two-piece model with one piece for stage 
<= 6.32 and a second piece for stage > 6.32. For this second approach to 
work, you'll need more data than you have given us here.

BTW, nls() should work fine if the model/data combination meet the 
requirements of 1) the model 'fits' the data, 2) the residuals are 
NIID(0,sigma^2), the parameters C, a, and n are identifiable from the 
data (should be if the last point is excluded). As always, you'll need 
good starting values for the parameters (get them from a log-log plot). 
You may find, based on the residuals, that linear regression (lm, glm) 
are most appropriate so that the errors meet the criteria of constant 
variance. If none of this makes sense, buy and study the book

Nonlinear regression analysis: Its applications, D. M. Bates and D. G. 
Watts, Wiley, New York, 1988. ISBN 0471-816434.

The nls() application is the easy part.


Good luck

David Stevens

On 5/4/2017 4:58 PM, Zachary Shadomy wrote:
> I am having some errors come up in my first section of code. I have no
> issue in plotting the points. Is there an easier method for creating a
> non-linear regression using C*(x+a)^n. The .txt file is named
> stage_discharge with the two variables being stage and discharge.
> The data is a relatively small file listed below:
>
> stage discharge
> 6.53 2592.05
> 6.32 559.5782
> 5.96 484.2151
> 4.99 494.7527
> 3.66 456.0778
> 0.51 291.13
>
>
>
>
>
>> power.nls<-nls(stage_dischargee$discharge~C*(stage_discharge$stage+a)^n,
> data=stage_discharge, start=list(C=4, a=0, n=1))
>> C<-coef(power.nls)["C"]
>> a<-coef(power.nls)["a"]
>> n<-coef(power.nls)["n"]
>> plot(stage_discharge$stage, stage_discharge$discharge, pch=17, cex=1.25,
> ylab='Discharge (cfs )', xlab='Stage (ft)', font.lab=2, main='Boone Creek\n
> St age-Discharge Curve')
>> curve(C*(x+a)^n, add=TRUE, col="red")
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu



	[[alternative HTML version deleted]]


From czarek230800 at gmail.com  Wed May 10 20:02:18 2017
From: czarek230800 at gmail.com (Czarek Kowalski)
Date: Wed, 10 May 2017 20:02:18 +0200
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
In-Reply-To: <DCA9924D-23C5-41B6-A4F3-79F30CC9DB0C@comcast.net>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
 <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>
 <CAEKZwC-_NJgFk8sD4+3D=bOGi1KDd0mUrKL+63yesNeOzC150w@mail.gmail.com>
 <A6EB7E1D-0D76-4EE7-8A35-9D620BCDD2D3@comcast.net>
 <CAEKZwC-0-XYH20bFCu1m-ooFDH3VuVjcw2mJcu08RYO-QrZz7A@mail.gmail.com>
 <13E94449-E676-44EE-96E1-106A2B915E5C@comcast.net>
 <DCA9924D-23C5-41B6-A4F3-79F30CC9DB0C@comcast.net>
Message-ID: <CAEKZwC8oE3doK_7F0CWNsC=5RBTBpXatsKEax+gSViz2s4FNDA@mail.gmail.com>

Previously I had used another language to make calculations based on
theory. I have calculated using R and I have received another results.
My theoretical calculation does not take into account the full
covariance matrix (only 6 elements from diagonal). Code based on
theory:

df = 4;   #degrees of freedom
sigmas = c(1, 4, 2, 5, 3, 6) # roots of diagonal elements of covariance matrix
meann = c(55, 40, 50, 35, 45, 30)
alfa1 = 20; # lower truncation
beta1 = 60; # upper truncation
a = (alfa1 - meann)/sigmas;
b = (beta1 - meann)/sigmas;
E = meann + sigmas * ((gamma(df - 1)/2)*((df + a^2)^(-(df-1)/2) - (df
+ b^2)^(-(df-1)/2))*df^(df/2))/(2*(pt(b,df)-pt(a,df))*gamma(df/2)*gamma(1/2))
E


Kind regards
Czarek

On 9 May 2017 at 23:50, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 9, 2017, at 2:33 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On May 9, 2017, at 2:05 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>
>>> I have already posted that in attachement - pdf file.
>>
>> I see that now. I failed to scroll to the 3rd page.
>>
>>> I am posting
>>> plain text here:
>>>
>>>> library(tmvtnorm)
>>>> meann = c(55, 40, 50, 35, 45, 30)
>>>> covv = matrix(c(  1, 1, 0, 2, -1, -1,
>>>                   1, 16, -6, -6, -2, 12,
>>>                   0, -6, 4, 2, -2, -5,
>>>                   2, -6, 2, 25, 0, -17,
>>>                  -1, -2, -2, 0, 9, -5,
>>>                  -1, 12, -5, -17, -5, 36), 6, 6)
>>> df = 4
>>> lower = c(20, 20, 20, 20, 20, 20)
>>> upper = c(60, 60, 60, 60, 60, 60)
>>> X1 <- rtmvt(n=100000, meann, covv, df, lower, upper)
>>>
>>>
>>>> sum(X1[,1]) / 100000
>>> [1] 54.98258
>>> sum(X1[,2]) / 100000
>>> [1] 40.36153
>>> sum(X1[,3]) / 100000
>>> [1] 49.83571
>>> sum(X1[,4]) / 100000
>>> [1] 34.69571      # "4th element of mean vector"
>>> sum(X1[,5]) / 100000
>>> [1] 44.81081
>>> sum(X1[,6]) / 100000
>>> [1] 31.10834
>>>
>>> And corresponding results received using equation (3) from pdf file:
>>> [54.97,
>>> 40,
>>> 49.95,
>>> 35.31, #  "4th element of mean vector"
>>> 44.94,
>>> 31.32]
>>>
>>
>> I get similar results for the output from your code,
>>
>> My 100-fold run of your calculations were:
>>
>> meansBig <- replicate(100, {Xbig <- rtmvt(n=100000, meann, covv, df, lower, upper)
>> colMeans(Xbig)} )
>>
>> describe(meansBig[4,])  # describe is from Hmisc package
>>
>> meansBig[4, ]
>>       n  missing distinct     Info     Mean      Gmd      .05      .10      .25
>>     100        0      100        1     34.7  0.01954    34.68    34.68    34.69
>>     .50      .75      .90      .95
>>   34.70    34.72    34.72    34.73
>>
>> lowest : 34.65222 34.66675 34.66703 34.66875 34.67566
>> highest: 34.72939 34.73012 34.73051 34.73742 34.74441
>>
>>
>> So agree, 35.31 is outside the plausible range of an RV formed with that package, but I don't have any code relating to your calculations from theory.
>
> Further investigation:
>
> covDiag <- covv*( row(covv)==col(covv) )  # just the diagonal means
>
> Repeat with all zero covariances:
>
>> meansDiag <- replicate(100, {Xbig <- rtmvt(n=100000, meann, covDiag, df, lower, upper)
> + colMeans(Xbig)} )
>> describe(meansDiag[4,])
> meansDiag[4, ]
>        n  missing distinct     Info     Mean      Gmd      .05      .10      .25
>      100        0      100        1    35.23  0.02074    35.21    35.21    35.22
>      .50      .75      .90      .95
>    35.23    35.25    35.26    35.26
>
> lowest : 35.18360 35.19756 35.20098 35.20179 35.20622
> highest: 35.26367 35.26635 35.26791 35.27251 35.27302
>
> So failing to account for the covariances in your theoretical calculations mostly explains the apparent discrepancy, although your value of 35.31 would be at the  far end of a statistical distribution and I wonder about some sort of error in your theoretical calculation, which didn't appear to take into account the covariance matrix.
>
> Best;
> David.
>
>
>
>>
>> Best;
>> David.
>>
>>
>>> On 9 May 2017 at 22:17, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>>> On May 9, 2017, at 1:11 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>>>
>>>>> Of course I have expected the difference between theory and a sample
>>>>> of realizations of RV's and result mean should still be a random
>>>>> variable. But, for example for 4th element of mean vector: 35.31 -
>>>>> 34.69571 = 0.61429. It is quite big difference, nieprawda?? I have
>>>>> expected that the difference would be smaller because of law of large
>>>>> numbers (for 10mln samples the difference is quite similar).
>>>>
>>>> I for one have no idea what is meant by a "4th element of mean vector". So I have now idea what to consider "big". I have found that my intuitions about multivariate distributions, especially those where the covariate structure is as complex as you have assumed, are often far from simulated results.
>>>>
>>>> I suggest you post some code and results.
>>>>
>>>> --
>>>> David.
>>>>
>>>>
>>>>>
>>>>> On 9 May 2017 at 21:40, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>>
>>>>>>> On May 9, 2017, at 10:09 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>>>>>
>>>>>>> Dear Members,
>>>>>>> I am working with 6-dimensional Student-t distribution with 4 degrees
>>>>>>> of freedom truncated to [20; 60]. I have generated 100 000 samples
>>>>>>> from truncated multivariate Student-t distribution using rtmvt
>>>>>>> function from package ?tmvtnorm?. I have also calculated  mean vector
>>>>>>> using equation (3) from attached pdf. The problem is, that after
>>>>>>> summing all elements in one column of rtmvt result (and dividing by
>>>>>>> 100 000) I do not receive the same result as using (3) equation. Could
>>>>>>> You tell me, what is incorrect, why there is a difference?
>>>>>>
>>>>>> I guess the question is why you would NOT expect a difference between theory and a sample of realizations of RV's? The result mean should still be a random variable, night wahr?
>>>>>>
>>>>>>
>>>>>>> Yours faithfully
>>>>>>> Czarek Kowalski
>>>>>>> <truncatedT.pdf>______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>>>
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From pdalgd at gmail.com  Wed May 10 21:09:30 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 10 May 2017 21:09:30 +0200
Subject: [R] Generating samples from truncated multivariate Student-t
 distribution
In-Reply-To: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
Message-ID: <E74BF9DD-7D06-45F6-9739-7C0BA0D10180@gmail.com>

It's not obvious to me that that marginal distribution of one component of a multivariate truncated t is the corresponding univariate truncated t.

In fact, I would expect it to differ because of tail-dependence effects, e.g.

> r <- rtmvt(1e5, c(30,0), diag(2), lower=c(29,-Inf), upper=c(31, +Inf), df=4)
> sd(r[,2])
[1] 1.191654
> r <- rtmvt(1e5, c(30,0), diag(2), lower=c(35,-Inf), upper=c(37, +Inf), df=4)
> sd(r[,2])
[1] 3.504233

-pd

> On 9 May 2017, at 19:09 , Czarek Kowalski <czarek230800 at gmail.com> wrote:
> 
> Dear Members,
> I am working with 6-dimensional Student-t distribution with 4 degrees
> of freedom truncated to [20; 60]. I have generated 100 000 samples
> from truncated multivariate Student-t distribution using rtmvt
> function from package ?tmvtnorm?. I have also calculated  mean vector
> using equation (3) from attached pdf. The problem is, that after
> summing all elements in one column of rtmvt result (and dividing by
> 100 000) I do not receive the same result as using (3) equation. Could
> You tell me, what is incorrect, why there is a difference?
> Yours faithfully
> Czarek Kowalski
> <truncatedT.pdf>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Wed May 10 21:25:42 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 May 2017 12:25:42 -0700
Subject: [R] Generating samples from truncated multivariate Student-t
	distribution
In-Reply-To: <CAEKZwC8oE3doK_7F0CWNsC=5RBTBpXatsKEax+gSViz2s4FNDA@mail.gmail.com>
References: <CAEKZwC-ms0txqaCoC6WgJtCk52oU1KtMR2mDYLLHTmQK=rqorA@mail.gmail.com>
 <668082F9-BBCB-46F6-BA13-62FFDCC76A02@comcast.net>
 <CAEKZwC-_NJgFk8sD4+3D=bOGi1KDd0mUrKL+63yesNeOzC150w@mail.gmail.com>
 <A6EB7E1D-0D76-4EE7-8A35-9D620BCDD2D3@comcast.net>
 <CAEKZwC-0-XYH20bFCu1m-ooFDH3VuVjcw2mJcu08RYO-QrZz7A@mail.gmail.com>
 <13E94449-E676-44EE-96E1-106A2B915E5C@comcast.net>
 <DCA9924D-23C5-41B6-A4F3-79F30CC9DB0C@comcast.net>
 <CAEKZwC8oE3doK_7F0CWNsC=5RBTBpXatsKEax+gSViz2s4FNDA@mail.gmail.com>
Message-ID: <A6165151-C564-4AFE-AD1E-1BB9D44BD340@comcast.net>


> On May 10, 2017, at 11:02 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
> 
> Previously I had used another language to make calculations based on
> theory. I have calculated using R and I have received another results.
> My theoretical calculation does not take into account the full
> covariance matrix (only 6 elements from diagonal). Code based on
> theory:
> 
> df = 4;   #degrees of freedom
> sigmas = c(1, 4, 2, 5, 3, 6) # roots of diagonal elements of covariance matrix
> meann = c(55, 40, 50, 35, 45, 30)
> alfa1 = 20; # lower truncation
> beta1 = 60; # upper truncation
> a = (alfa1 - meann)/sigmas;
> b = (beta1 - meann)/sigmas;
> E = meann + sigmas * ((gamma(df - 1)/2)*((df + a^2)^(-(df-1)/2) - (df
> + b^2)^(-(df-1)/2))*df^(df/2))/(2*(pt(b,df)-pt(a,df))*gamma(df/2)*gamma(1/2))

This looks wrong:

(gamma(df - 1)/2)

According to your "theory" (which you have not yet supported with references) in the attached pdf file, that should be:

gamma( (df - 1)/2 )

I'm not a statistician and checking your "theoretical" expression for the mean of a truncated PDF is not really on-topic for R help. When I look at http://www.tonyohagan.co.uk/academic/pdf/trunc_multi_t.PDF I see a lot of normalization factors that seem quite different than yours. Perhaps you should post any further difficulties to stats.stackexchange.com ?

You may also want to consult:

https://www.jstatsoft.org/article/view/v016c02


Authors:	Saralees Nadarajah, Samuel Kotz
Title:	R Programs for Truncated Distributions
Abstract:	Truncated distributions arise naturally in many practical situations. In this note, we provide programs for computing six quantities of interest (probability density function, mean, variance, cumulative distribution function, quantile function and random numbers) for any truncated distribution: whether it is left truncated, right truncated or doubly truncated. The programs are written in R: a freely downloadable statistical software.

Best;
David.


> E
> 
> 
> Kind regards
> Czarek
> 
> On 9 May 2017 at 23:50, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On May 9, 2017, at 2:33 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> 
>>>> On May 9, 2017, at 2:05 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>> 
>>>> I have already posted that in attachement - pdf file.
>>> 
>>> I see that now. I failed to scroll to the 3rd page.
>>> 
>>>> I am posting
>>>> plain text here:
>>>> 
>>>>> library(tmvtnorm)
>>>>> meann = c(55, 40, 50, 35, 45, 30)
>>>>> covv = matrix(c(  1, 1, 0, 2, -1, -1,
>>>>                  1, 16, -6, -6, -2, 12,
>>>>                  0, -6, 4, 2, -2, -5,
>>>>                  2, -6, 2, 25, 0, -17,
>>>>                 -1, -2, -2, 0, 9, -5,
>>>>                 -1, 12, -5, -17, -5, 36), 6, 6)
>>>> df = 4
>>>> lower = c(20, 20, 20, 20, 20, 20)
>>>> upper = c(60, 60, 60, 60, 60, 60)
>>>> X1 <- rtmvt(n=100000, meann, covv, df, lower, upper)
>>>> 
>>>> 
>>>>> sum(X1[,1]) / 100000
>>>> [1] 54.98258
>>>> sum(X1[,2]) / 100000
>>>> [1] 40.36153
>>>> sum(X1[,3]) / 100000
>>>> [1] 49.83571
>>>> sum(X1[,4]) / 100000
>>>> [1] 34.69571      # "4th element of mean vector"
>>>> sum(X1[,5]) / 100000
>>>> [1] 44.81081
>>>> sum(X1[,6]) / 100000
>>>> [1] 31.10834
>>>> 
>>>> And corresponding results received using equation (3) from pdf file:
>>>> [54.97,
>>>> 40,
>>>> 49.95,
>>>> 35.31, #  "4th element of mean vector"
>>>> 44.94,
>>>> 31.32]
>>>> 
>>> 
>>> I get similar results for the output from your code,
>>> 
>>> My 100-fold run of your calculations were:
>>> 
>>> meansBig <- replicate(100, {Xbig <- rtmvt(n=100000, meann, covv, df, lower, upper)
>>> colMeans(Xbig)} )
>>> 
>>> describe(meansBig[4,])  # describe is from Hmisc package
>>> 
>>> meansBig[4, ]
>>>      n  missing distinct     Info     Mean      Gmd      .05      .10      .25
>>>    100        0      100        1     34.7  0.01954    34.68    34.68    34.69
>>>    .50      .75      .90      .95
>>>  34.70    34.72    34.72    34.73
>>> 
>>> lowest : 34.65222 34.66675 34.66703 34.66875 34.67566
>>> highest: 34.72939 34.73012 34.73051 34.73742 34.74441
>>> 
>>> 
>>> So agree, 35.31 is outside the plausible range of an RV formed with that package, but I don't have any code relating to your calculations from theory.
>> 
>> Further investigation:
>> 
>> covDiag <- covv*( row(covv)==col(covv) )  # just the diagonal means
>> 
>> Repeat with all zero covariances:
>> 
>>> meansDiag <- replicate(100, {Xbig <- rtmvt(n=100000, meann, covDiag, df, lower, upper)
>> + colMeans(Xbig)} )
>>> describe(meansDiag[4,])
>> meansDiag[4, ]
>>       n  missing distinct     Info     Mean      Gmd      .05      .10      .25
>>     100        0      100        1    35.23  0.02074    35.21    35.21    35.22
>>     .50      .75      .90      .95
>>   35.23    35.25    35.26    35.26
>> 
>> lowest : 35.18360 35.19756 35.20098 35.20179 35.20622
>> highest: 35.26367 35.26635 35.26791 35.27251 35.27302
>> 
>> So failing to account for the covariances in your theoretical calculations mostly explains the apparent discrepancy, although your value of 35.31 would be at the  far end of a statistical distribution and I wonder about some sort of error in your theoretical calculation, which didn't appear to take into account the covariance matrix.
>> 
>> Best;
>> David.
>> 
>> 
>> 
>>> 
>>> Best;
>>> David.
>>> 
>>> 
>>>> On 9 May 2017 at 22:17, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>> 
>>>>>> On May 9, 2017, at 1:11 PM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>>>> 
>>>>>> Of course I have expected the difference between theory and a sample
>>>>>> of realizations of RV's and result mean should still be a random
>>>>>> variable. But, for example for 4th element of mean vector: 35.31 -
>>>>>> 34.69571 = 0.61429. It is quite big difference, nieprawda?? I have
>>>>>> expected that the difference would be smaller because of law of large
>>>>>> numbers (for 10mln samples the difference is quite similar).
>>>>> 
>>>>> I for one have no idea what is meant by a "4th element of mean vector". So I have now idea what to consider "big". I have found that my intuitions about multivariate distributions, especially those where the covariate structure is as complex as you have assumed, are often far from simulated results.
>>>>> 
>>>>> I suggest you post some code and results.
>>>>> 
>>>>> --
>>>>> David.
>>>>> 
>>>>> 
>>>>>> 
>>>>>> On 9 May 2017 at 21:40, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>>> 
>>>>>>>> On May 9, 2017, at 10:09 AM, Czarek Kowalski <czarek230800 at gmail.com> wrote:
>>>>>>>> 
>>>>>>>> Dear Members,
>>>>>>>> I am working with 6-dimensional Student-t distribution with 4 degrees
>>>>>>>> of freedom truncated to [20; 60]. I have generated 100 000 samples
>>>>>>>> from truncated multivariate Student-t distribution using rtmvt
>>>>>>>> function from package ?tmvtnorm?. I have also calculated  mean vector
>>>>>>>> using equation (3) from attached pdf. The problem is, that after
>>>>>>>> summing all elements in one column of rtmvt result (and dividing by
>>>>>>>> 100 000) I do not receive the same result as using (3) equation. Could
>>>>>>>> You tell me, what is incorrect, why there is a difference?
>>>>>>> 
>>>>>>> I guess the question is why you would NOT expect a difference between theory and a sample of realizations of RV's? The result mean should still be a random variable, night wahr?
>>>>>>> 
>>>>>>> 
>>>>>>>> Yours faithfully
>>>>>>>> Czarek Kowalski
>>>>>>>> <truncatedT.pdf>______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> David Winsemius
>>>>>>> Alameda, CA, USA
>>>>>>> 
>>>>> 
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>> 
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From kristi.glover at hotmail.com  Wed May 10 22:05:24 2017
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 10 May 2017 20:05:24 +0000
Subject: [R] creating a color gradient  in geom_ribbon
Message-ID: <DM3PR13MB0652666892E8CD7142840B6DFAEC0@DM3PR13MB0652.namprd13.prod.outlook.com>

Hi R Users,

I was trying to create a figure with geom_ribbon. There is a function "fill", but I want to make the shaded area with a gradient (increasing dark color towards a central line, inserted of having a color). Is there any possibility?


In the given example, I want the colour with "blue" but in a gradient (dark=central, light= as goes higher or lower)


pl = data.frame(Time = 0:10, menle = rnorm(11))

pl$menlelb = pl$menle -1

pl$menleub = pl$menle +1

ggplot(pl, aes(Time)) +

  geom_line(aes(y=menle), colour="blue") +

  geom_ribbon(aes(ymin=menlelb, ymax=menleub), fill="blue")


Thanks

	[[alternative HTML version deleted]]


From santiagoburone at icloud.com  Wed May 10 20:20:29 2017
From: santiagoburone at icloud.com (Santiago Burone)
Date: Wed, 10 May 2017 15:20:29 -0300
Subject: [R] Solve system of non linear equations using nasted loops
Message-ID: <50C38F17-A193-42DF-8A8D-612632417B35@icloud.com>

Hello, 

I'm new at R and I would like to use it in order to solve a system of non linear equations. I have the code that works but im not able to save the results. 

 

My system has three equations and i would like to solve this using three nested loops, becouse i need solutions for all the values combinations.

 

 

The code im using is this:

 

library(nleqslv)
#x3 es gamma
#x2 es alpha
#x1 es beta
MA <- c(50000, 43600, 40000, 38800, 37600, 34400, 31600, 27200, 24400, 20000)
MI <- c(10000, 21800, 20000, 19400, 18800, 17200, 15800, 13600, 12200, 10000)
ME <- c(30000, 32700, 30000, 29100, 28200, 25800, 23700, 20400, 18300, 15000)
DE <- c(0.384900179, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009)
for (i in 1:9) {
for (j in 1:9){
for (k in 1:9){
df.names <- paste("SociedadB",1:10,sep="")

fun <- function(x) { 
f <- numeric(length(x)) # read as:
f[1] <- 1*x[3] - (log(ME[1+i]/ME[1])+(1*x[1]+1*x[2])*(2)*(log((MA[1]-ME[1])/(MA[i+1]-ME[i+1]))))/(log(0.19245009/0.384900179))
f[2] <- 1*x[3] - (log(MI[1+j]/MI[1])-(1*x[2])*(2)*(log((MA[1+j]-MI[1+j])/(MA[1]-MI[1]))))/(log(0.19245009/0.384900179)) 
f[3] <- 1*x[3] - (log(MA[1+k]/MA[1])-(1*x[1])*(2)*(log((MI[1+k]-MA[1+k])/(MI[1]-MA[1]))))/(log(0.19245009/0.384900179)) 
f 
} 
startx <- c(1,1,1) 
answers<-as.data.frame(nleqslv(startx,fun)) 
d.frame <- (answers$x)
assign(df.names[k+20], d.frame)
despejes<- data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5, SociedadB6, SociedadB7, SociedadB8, SociedadB9, SociedadB10)

}
}
}

despejes<- data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5, SociedadB6, SociedadB7, SociedadB8, SociedadB9, SociedadB10)

 

If im not wrong i should have 1000 different solutions but the data frame only save 10 results. I tried copying the last part of the code between the last two brackets (changing the name of the data frame despejes for despejes 1, 2 and 3 but i only get three data frames with exactly the same results. I dont know how could i save all the results of every combination. I mean, i need to solve for i=1, j=1 and the 9 diferent values of k and save those results, then i=1, j=2 and the 9 values of k..

 

I know this might be a easy question but i have not been able to find a solution in the last days. 

 

Thanks in advance if you can help me.


Santiago. 
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed May 10 22:55:47 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 May 2017 13:55:47 -0700
Subject: [R] Solve system of non linear equations using nasted loops
In-Reply-To: <50C38F17-A193-42DF-8A8D-612632417B35@icloud.com>
References: <50C38F17-A193-42DF-8A8D-612632417B35@icloud.com>
Message-ID: <72293CD8-2D1D-4E1C-9A34-5D37C6FAFAA2@comcast.net>


> On May 10, 2017, at 11:20 AM, Santiago Burone <santiagoburone at icloud.com> wrote:
> 
> Hello, 
> 
> I'm new at R and I would like to use it in order to solve a system of non linear equations. I have the code that works but im not able to save the results. 
> 
> 
> 
> My system has three equations and i would like to solve this using three nested loops, becouse i need solutions for all the values combinations.
> 
> 
> 
> 
> 
> The code im using is this:
> 
> 
> 
> library(nleqslv)
> #x3 es gamma
> #x2 es alpha
> #x1 es beta
> MA <- c(50000, 43600, 40000, 38800, 37600, 34400, 31600, 27200, 24400, 20000)
> MI <- c(10000, 21800, 20000, 19400, 18800, 17200, 15800, 13600, 12200, 10000)
> ME <- c(30000, 32700, 30000, 29100, 28200, 25800, 23700, 20400, 18300, 15000)
> DE <- c(0.384900179, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009)
> for (i in 1:9) {
> for (j in 1:9){
> for (k in 1:9){

I got an error on the first pass through the loop.


> df.names <- paste("SociedadB",1:10,sep="")

# seems kind of excessive to repeat that process 9*9*9 times
# Maybe this should be done outside the loop?

> 
> fun <- function(x) { 
> f <- numeric(length(x)) # read as:
> f[1] <- 1*x[3] - (log(ME[1+i]/ME[1])+(1*x[1]+1*x[2])*(2)*(log((MA[1]-ME[1])/(MA[i+1]-ME[i+1]))))/(log(0.19245009/0.384900179))
> f[2] <- 1*x[3] - (log(MI[1+j]/MI[1])-(1*x[2])*(2)*(log((MA[1+j]-MI[1+j])/(MA[1]-MI[1]))))/(log(0.19245009/0.384900179)) 
> f[3] <- 1*x[3] - (log(MA[1+k]/MA[1])-(1*x[1])*(2)*(log((MI[1+k]-MA[1+k])/(MI[1]-MA[1]))))/(log(0.19245009/0.384900179)) 
> f 
> } 

# So you need 9*9*9 different functions? 


> startx <- c(1,1,1) 
> answers<-as.data.frame(nleqslv(startx,fun)) 

> d.frame <- (answers$x)
> assign(df.names[k+20], d.frame)

# I don't think that df.names[k+20] would be anything other than NA since it only has 10 elements

> despejes<- data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5, SociedadB6, SociedadB7, SociedadB8, SociedadB9, SociedadB10)
> 
> }
> }
> }
> 
> despejes<- data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5, SociedadB6, SociedadB7, SociedadB8, SociedadB9, SociedadB10)
> 

The error message is:

Error in data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5, SociedadB6,  : 
  object 'SociedadB2' not found

That's because column names are not first class data-objects in R.


> 
> 
> If im not wrong i should have 1000 different solutions but the data frame only save 10 results. I tried copying the last part of the code between the last two brackets (changing the name of the data frame despejes for despejes 1, 2 and 3 but i only get three data frames with exactly the same results. I dont know how could i save all the results of every combination. I mean, i need to solve for i=1, j=1 and the 9 diferent values of k and save those results, then i=1, j=2 and the 9 values of k..
> 

If you need to save separate results for each combination of i,j,k , then you need at a minimum an array (possibly with a further 4th dimension if you are storing numerical vectors)  or possibly a list if these items are more complicated than an atomic vector.
> 
> 
> I know this might be a easy question but i have not been able to find a solution in the last days. 
> 
> 
> 
> Thanks in advance if you can help me.
> 
> 
> Santiago. 
> 	[[alternative HTML version deleted]]

Rhelp is a plain text list although you don't seem to have run into trouble on that account. You should however determine how your mail client can be setup to just send pain text to this mailing list.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Thu May 11 00:51:56 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 10 May 2017 15:51:56 -0700
Subject: [R] Solve system of non linear equations using nasted loops
In-Reply-To: <50C38F17-A193-42DF-8A8D-612632417B35@icloud.com>
References: <50C38F17-A193-42DF-8A8D-612632417B35@icloud.com>
Message-ID: <CAGxFJbRf8jBBJcrLYbgKh+rhG4yU1r76XurCeWsSnVwN5T8X2A@mail.gmail.com>

I haven't gone through your code carefully, but I believe this can be done
in a tiny fraction of the time you are taking by eschewing loops. See
?expand.grid to get started. In general,nested loops should be avoided if
possible.

I  also suggest you spend some time with a good R tutorial to learn how to
write good R code instead of recapitulating C (or whatever) in R. All
languages have their own coding paradigms(R's is functional) and you will
do better in the long run if you spend the time to learn R's.

Cheers,
Bert



On May 10, 2017 1:20 PM, "Santiago Burone" <santiagoburone at icloud.com>
wrote:

Hello,

I'm new at R and I would like to use it in order to solve a system of non
linear equations. I have the code that works but im not able to save the
results.



My system has three equations and i would like to solve this using three
nested loops, becouse i need solutions for all the values combinations.





The code im using is this:



library(nleqslv)
#x3 es gamma
#x2 es alpha
#x1 es beta
MA <- c(50000, 43600, 40000, 38800, 37600, 34400, 31600, 27200, 24400,
20000)
MI <- c(10000, 21800, 20000, 19400, 18800, 17200, 15800, 13600, 12200,
10000)
ME <- c(30000, 32700, 30000, 29100, 28200, 25800, 23700, 20400, 18300,
15000)
DE <- c(0.384900179, 0.19245009, 0.19245009, 0.19245009, 0.19245009,
0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009)
for (i in 1:9) {
for (j in 1:9){
for (k in 1:9){
df.names <- paste("SociedadB",1:10,sep="")

fun <- function(x) {
f <- numeric(length(x)) # read as:
f[1] <- 1*x[3] - (log(ME[1+i]/ME[1])+(1*x[1]+1*
x[2])*(2)*(log((MA[1]-ME[1])/(MA[i+1]-ME[i+1]))))/(log(0.
19245009/0.384900179))
f[2] <- 1*x[3] - (log(MI[1+j]/MI[1])-(1*x[2])*(
2)*(log((MA[1+j]-MI[1+j])/(MA[1]-MI[1]))))/(log(0.19245009/0.384900179))
f[3] <- 1*x[3] - (log(MA[1+k]/MA[1])-(1*x[1])*(
2)*(log((MI[1+k]-MA[1+k])/(MI[1]-MA[1]))))/(log(0.19245009/0.384900179))
f
}
startx <- c(1,1,1)
answers<-as.data.frame(nleqslv(startx,fun))
d.frame <- (answers$x)
assign(df.names[k+20], d.frame)
despejes<- data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5,
SociedadB6, SociedadB7, SociedadB8, SociedadB9, SociedadB10)

}
}
}

despejes<- data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5,
SociedadB6, SociedadB7, SociedadB8, SociedadB9, SociedadB10)



If im not wrong i should have 1000 different solutions but the data frame
only save 10 results. I tried copying the last part of the code between the
last two brackets (changing the name of the data frame despejes for
despejes 1, 2 and 3 but i only get three data frames with exactly the same
results. I dont know how could i save all the results of every combination.
I mean, i need to solve for i=1, j=1 and the 9 diferent values of k and
save those results, then i=1, j=2 and the 9 values of k..



I know this might be a easy question but i have not been able to find a
solution in the last days.



Thanks in advance if you can help me.


Santiago.
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu May 11 07:22:41 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 11 May 2017 15:22:41 +1000
Subject: [R] creating a color gradient in geom_ribbon
In-Reply-To: <DM3PR13MB0652666892E8CD7142840B6DFAEC0@DM3PR13MB0652.namprd13.prod.outlook.com>
References: <DM3PR13MB0652666892E8CD7142840B6DFAEC0@DM3PR13MB0652.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fUN1XnpgwS7XTYcy=A-xXMo-beFmpMnA_27kZ4a-R=eWg@mail.gmail.com>

Hi Kristi,
It can be done, but it is messy:

pl = data.frame(Time = 0:10, menle = rnorm(11))
pl$menlelb = pl$menle -1
pl$menleub = pl$menle +1
rg<-0.95
blue<-1
plot(pl$Time,pl$menlelb,ylim=range(c(pl$menlelb,pl$menleub)),type="l",
 lwd=7,col=rgb(rg,rg,blue))
lines(pl$Time,pl$menlelb,lwd=7,col=rgb(rg,rg,blue))
rg<-seq(0.9,0.3,length.out=9)
offset<-seq(0.88,0.08,by=-0.1)
for(i in 1:9) {
 lines(pl$Time,pl$menle+offset[i],lwd=7,col=rgb(rg[i],rg[i],blue))
 lines(pl$Time,pl$menle-offset[i],lwd=7,col=rgb(rg[i],rg[i],blue))
}
lines(pl$Time,pl$menle,lwd=6,col=rgb(0,0,blue))

For the ggplot solution, this might work:

ggplot(pl, aes(Time)) +
  geom_line(aes(y=menle+1), colour=rgb(0.95,0.95,1), width=7) +
  geom_line(aes(y=menle-1), colour=rgb(0.95,0.95,1), width=7) +
  geom_line(aes(y=menle+0.88), colour=rgb(0.9,0.9,1), width=7) +
  geom_line(aes(y=menle-0.88), colour=rgb(0.9,0.9,1), width=7) +
  geom_line(aes(y=menle+0.78), colour=rgb(0.825,0.825,1), width=7) +
  geom_line(aes(y=menle-0.78), colour=rgb(0.825,0.825,1), width=7) +
  geom_line(aes(y=menle+68), colour=rgb(0.75,0.75,1), width=7) +
  geom_line(aes(y=menle-68), colour=rgb(0.75,0.75,1), width=7) +
  geom_line(aes(y=menle+0.58), colour=rgb(0.675,0.675,1), width=7) +
  geom_line(aes(y=menle-0.58), colour=rgb(0.675,0.675,1), width=7) +
  geom_line(aes(y=menle+0.48), colour=rgb(0.6,0.6,1), width=7) +
  geom_line(aes(y=menle-0.48), colour=rgb(0.6,0.6,1), width=7) +
  geom_line(aes(y=menle+0.38), colour=rgb(0.525,0.525,1), width=7) +
  geom_line(aes(y=menle-0.38), colour=rgb(0.525,0.525,1), width=7) +
  geom_line(aes(y=menle+0.28), colour=rgb(0.45,0.45,1), width=7) +
  geom_line(aes(y=menle-0.28), colour=rgb(0.45,0.45,1), width=7) +
  geom_line(aes(y=menle+0.18), colour=rgb(0.375,0.375,1), width=7) +
  geom_line(aes(y=menle-0.18), colour=rgb(0.375,0.375,1), width=7) +
  geom_line(aes(y=menle+0.08), colour=rgb(0.3,0.3,1), width=7) +
  geom_line(aes(y=menle-0.08), colour=rgb(0.3,0.3,1), width=7) +
  geom_line(aes(y=menle), colour="blue") )

but I can't test it.

Jim

On Thu, May 11, 2017 at 6:05 AM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi R Users,
>
> I was trying to create a figure with geom_ribbon. There is a function "fill", but I want to make the shaded area with a gradient (increasing dark color towards a central line, inserted of having a color). Is there any possibility?
>
>
> In the given example, I want the colour with "blue" but in a gradient (dark=central, light= as goes higher or lower)
>
>
> pl = data.frame(Time = 0:10, menle = rnorm(11))
>
> pl$menlelb = pl$menle -1
>
> pl$menleub = pl$menle +1
>
> ggplot(pl, aes(Time)) +
>
>   geom_line(aes(y=menle), colour="blue") +
>
>   geom_ribbon(aes(ymin=menlelb, ymax=menleub), fill="blue")
>
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Thu May 11 07:51:12 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 11 May 2017 05:51:12 +0000
Subject: [R] creating a color gradient in geom_ribbon
In-Reply-To: <CA+8X3fUN1XnpgwS7XTYcy=A-xXMo-beFmpMnA_27kZ4a-R=eWg@mail.gmail.com>
References: <DM3PR13MB0652666892E8CD7142840B6DFAEC0@DM3PR13MB0652.namprd13.prod.outlook.com>
 <CA+8X3fUN1XnpgwS7XTYcy=A-xXMo-beFmpMnA_27kZ4a-R=eWg@mail.gmail.com>
Message-ID: <CAKVAULMXf12L9PUStyBtVGPdf682Jjz0AVcyaKMqTJC6JX44-Q@mail.gmail.com>

I haven't tested it  but the first thing I'd look at is scale_fill_gradient.

HTH


Ulrik

Jim Lemon <drjimlemon at gmail.com> schrieb am Do., 11. Mai 2017, 07:22:

> Hi Kristi,
> It can be done, but it is messy:
>
> pl = data.frame(Time = 0:10, menle = rnorm(11))
> pl$menlelb = pl$menle -1
> pl$menleub = pl$menle +1
> rg<-0.95
> blue<-1
> plot(pl$Time,pl$menlelb,ylim=range(c(pl$menlelb,pl$menleub)),type="l",
>  lwd=7,col=rgb(rg,rg,blue))
> lines(pl$Time,pl$menlelb,lwd=7,col=rgb(rg,rg,blue))
> rg<-seq(0.9,0.3,length.out=9)
> offset<-seq(0.88,0.08,by=-0.1)
> for(i in 1:9) {
>  lines(pl$Time,pl$menle+offset[i],lwd=7,col=rgb(rg[i],rg[i],blue))
>  lines(pl$Time,pl$menle-offset[i],lwd=7,col=rgb(rg[i],rg[i],blue))
> }
> lines(pl$Time,pl$menle,lwd=6,col=rgb(0,0,blue))
>
> For the ggplot solution, this might work:
>
> ggplot(pl, aes(Time)) +
>   geom_line(aes(y=menle+1), colour=rgb(0.95,0.95,1), width=7) +
>   geom_line(aes(y=menle-1), colour=rgb(0.95,0.95,1), width=7) +
>   geom_line(aes(y=menle+0.88), colour=rgb(0.9,0.9,1), width=7) +
>   geom_line(aes(y=menle-0.88), colour=rgb(0.9,0.9,1), width=7) +
>   geom_line(aes(y=menle+0.78), colour=rgb(0.825,0.825,1), width=7) +
>   geom_line(aes(y=menle-0.78), colour=rgb(0.825,0.825,1), width=7) +
>   geom_line(aes(y=menle+68), colour=rgb(0.75,0.75,1), width=7) +
>   geom_line(aes(y=menle-68), colour=rgb(0.75,0.75,1), width=7) +
>   geom_line(aes(y=menle+0.58), colour=rgb(0.675,0.675,1), width=7) +
>   geom_line(aes(y=menle-0.58), colour=rgb(0.675,0.675,1), width=7) +
>   geom_line(aes(y=menle+0.48), colour=rgb(0.6,0.6,1), width=7) +
>   geom_line(aes(y=menle-0.48), colour=rgb(0.6,0.6,1), width=7) +
>   geom_line(aes(y=menle+0.38), colour=rgb(0.525,0.525,1), width=7) +
>   geom_line(aes(y=menle-0.38), colour=rgb(0.525,0.525,1), width=7) +
>   geom_line(aes(y=menle+0.28), colour=rgb(0.45,0.45,1), width=7) +
>   geom_line(aes(y=menle-0.28), colour=rgb(0.45,0.45,1), width=7) +
>   geom_line(aes(y=menle+0.18), colour=rgb(0.375,0.375,1), width=7) +
>   geom_line(aes(y=menle-0.18), colour=rgb(0.375,0.375,1), width=7) +
>   geom_line(aes(y=menle+0.08), colour=rgb(0.3,0.3,1), width=7) +
>   geom_line(aes(y=menle-0.08), colour=rgb(0.3,0.3,1), width=7) +
>   geom_line(aes(y=menle), colour="blue") )
>
> but I can't test it.
>
> Jim
>
> On Thu, May 11, 2017 at 6:05 AM, Kristi Glover
> <kristi.glover at hotmail.com> wrote:
> > Hi R Users,
> >
> > I was trying to create a figure with geom_ribbon. There is a function
> "fill", but I want to make the shaded area with a gradient (increasing dark
> color towards a central line, inserted of having a color). Is there any
> possibility?
> >
> >
> > In the given example, I want the colour with "blue" but in a gradient
> (dark=central, light= as goes higher or lower)
> >
> >
> > pl = data.frame(Time = 0:10, menle = rnorm(11))
> >
> > pl$menlelb = pl$menle -1
> >
> > pl$menleub = pl$menle +1
> >
> > ggplot(pl, aes(Time)) +
> >
> >   geom_line(aes(y=menle), colour="blue") +
> >
> >   geom_ribbon(aes(ymin=menlelb, ymax=menleub), fill="blue")
> >
> >
> > Thanks
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Thu May 11 10:12:42 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 11 May 2017 10:12:42 +0200
Subject: [R] Solve system of non linear equations using nasted loops
In-Reply-To: <50C38F17-A193-42DF-8A8D-612632417B35@icloud.com>
References: <50C38F17-A193-42DF-8A8D-612632417B35@icloud.com>
Message-ID: <3F9FFD1A-516D-4362-9D62-3EA07279CF21@xs4all.nl>


Your code looks needlessly complicated and inefficient in my view.
Even if you don't need or use nested for loops it can still be simplified.

1: First define  some new constants to avoid the  the M? stuff in your function

<code>
pME <- ME[2:9]/ME[1]
pMI <- MI[2:9]/MI[1]
pMA <- MA[2:9]/MA[1]
pMAE <- (MA[1]-ME[1])/(MA[2:9]-ME[2:9])
pMAI <- (MA[2:9]-MI[2:9])/(MA[1]-MI[1])
pMIA <- (MI[2:9]-MA[2:9])/(MI[1]-MA[1])
</code>

2. Redefine your function and avoid silly and unnecessary  use of 1* and 2* and use a constant for log(.../...)
The vector pXX is a vector consisting of elements from the vector pME etc.

<code>
fun <- function(x,pXX) {
    f <- numeric(length(x)) # read as:
    pME <- pXX[1]
    pMI <- pXX[2]
    pMA <- pXX[3]
    pMAE <- pXX[4]
    pMAI <- pXX[5]
    pMIA <- pXX[6]
    const <- log(0.19245009/0.384900179)
    f[1] <- x[3] - (log(pME)+(x[1]+x[2])*2*(log(pMAE)))/const
    f[2] <- x[3] - (log(pMI)-(x[2])*2*(log(pMAI)))/const
    f[3] <- x[3] - (log(pMA)-(x[1])*2*(log(pMIA)))/const
    f
}
</code>

This can be simplified further by doing the log(pXX) beforehand. 

3. I'm not going to have a go at using expand.grid. Too lazy and more involved to get everything correct.
So use a nested loop as follows:

- prepare a result matrix of correct dimensions with7 columns: one for nleaslv termination code, 3 for the result x-vales and another 3 to store i,j,k.
- storing the termination code is a must to see if convergence was obtained.
- and before invoking nleqslv test if fun(startx) contains NA values. If it does fill the appropriate row of Result with NA.
- use an index counter (indx) to store the results in the rows of Result

<code>
Result <- matrix(0,nrow=9*9*9,ncol=7)

indx <- 1
for (i in 1:9) {
    for (j in 1:9) {
        for (k in 1:9) {
            pXXijk <- c(pME[i],pMI[j],pMA[k],pMAE[i],pMAI[j],pMIA[k])
            f.startx <- fun(startx,pXXijk)
            if(anyNA(f.startx)) {
                Result[indx,1:4] <- NA
            } else {
                z <- nleqslv(startx,fun,pXX=pXXijk)
                Result[indx,1:4] <- c(z$termcd,z$x)
            }
            Result[indx,5:7] <- c(i,j,k)
            indx <- indx+1
        }
    }
}
</code>

And now you can inspect Result, which contains 729 rows (and not 1000) and continue to make  a data.frame with column names.
The rest is up to you.

Berend

On 10 May 2017, at 20:20, Santiago Burone <santiago
burone at icloud.com> wrote:
> 
> Hello, 
> 
> I'm new at R and I would like to use it in order to solve a system of non linear equations. I have the code that works but im not able to save the results. 
> 
> 
> 
> My system has three equations and i would like to solve this using three nested loops, becouse i need solutions for all the values combinations.
> 
> 
> 
> 
> 
> The code im using is this:
> 
> 
> 
> library(nleqslv)
> #x3 es gamma
> #x2 es alpha
> #x1 es beta
> MA <- c(50000, 43600, 40000, 38800, 37600, 34400, 31600, 27200, 24400, 20000)
> MI <- c(10000, 21800, 20000, 19400, 18800, 17200, 15800, 13600, 12200, 10000)
> ME <- c(30000, 32700, 30000, 29100, 28200, 25800, 23700, 20400, 18300, 15000)
> DE <- c(0.384900179, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009, 0.19245009)
> for (i in 1:9) {
> for (j in 1:9){
> for (k in 1:9){
> df.names <- paste("SociedadB",1:10,sep="")
> 
> fun <- function(x) { 
> f <- numeric(length(x)) # read as:
> f[1] <- 1*x[3] - (log(ME[1+i]/ME[1])+(1*x[1]+1*x[2])*(2)*(log((MA[1]-ME[1])/(MA[i+1]-ME[i+1]))))/(log(0.19245009/0.384900179))
> f[2] <- 1*x[3] - (log(MI[1+j]/MI[1])-(1*x[2])*(2)*(log((MA[1+j]-MI[1+j])/(MA[1]-MI[1]))))/(log(0.19245009/0.384900179)) 
> f[3] <- 1*x[3] - (log(MA[1+k]/MA[1])-(1*x[1])*(2)*(log((MI[1+k]-MA[1+k])/(MI[1]-MA[1]))))/(log(0.19245009/0.384900179)) 
> f 
> } 
> startx <- c(1,1,1) 
> answers<-as.data.frame(nleqslv(startx,fun)) 
> d.frame <- (answers$x)
> assign(df.names[k+20], d.frame)
> despejes<- data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5, SociedadB6, SociedadB7, SociedadB8, SociedadB9, SociedadB10)
> 
> }
> }
> }
> 
> despejes<- data.frame(SociedadB2, SociedadB3, SociedadB4, SociedadB5, SociedadB6, SociedadB7, SociedadB8, SociedadB9, SociedadB10)
> 
> 
> 
> If im not wrong i should have 1000 different solutions but the data frame only save 10 results. I tried copying the last part of the code between the last two brackets (changing the name of the data frame despejes for despejes 1, 2 and 3 but i only get three data frames with exactly the same results. I dont know how could i save all the results of every combination. I mean, i need to solve for i=1, j=1 and the 9 diferent values of k and save those results, then i=1, j=2 and the 9 values of k..
> 
> 
> 
> I know this might be a easy question but i have not been able to find a solution in the last days. 
> 
> 
> 
> Thanks in advance if you can help me.
> 
> 
> Santiago. 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Thu May 11 12:00:19 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Thu, 11 May 2017 15:30:19 +0530
Subject: [R] qqplot for binomial distribution
In-Reply-To: <CAC8=1er8tmxhHoFqvOrMBkwmSLbvkje8aS2dGK7C2d9vRG9Nog@mail.gmail.com>
References: <CAC8=1eos6eSC7=3XpVecjT2-jDs9w5GQ_m-6=t0EEhM1r3ObkQ@mail.gmail.com>
 <fa3e1bb3-46df-5356-3879-f3c78d02a45e@effectivedefense.org>
 <CAC8=1erWtM3s3cjFiHoHhMA1-8dTCi-QmyKX4WWGPLjiCGDjNg@mail.gmail.com>
 <F12FBBD4-03C5-4B22-9D66-28C2B260C764@utoronto.ca>
 <CAC8=1ep2=8+hgxqS3CCfCO2OTWq+iv=OtnS0JtWYJBxS62ZifQ@mail.gmail.com>
 <2575DB8F-9ACD-48D6-B6DD-5AEA9D709AEB@utoronto.ca>
 <CAC8=1er8tmxhHoFqvOrMBkwmSLbvkje8aS2dGK7C2d9vRG9Nog@mail.gmail.com>
Message-ID: <CAC8=1erGxOJZdw7mZv+7JdrkQ4M3WUcCk9VsqBa85YinwaHbQg@mail.gmail.com>

Dear All,

when I do :

set.seed(123)

expected_distribution<-rbinom(1000,100,.05)

#Without jitter

qqplot(jitter(expected_distribution),count1_vector, xlab="Expected
distribution",ylab="Observed values")
qqline(count1_vector,distribution = function(probs) { qbinom(probs,
size=100, prob=0.05) },col = "red",lwd = 2)

I get a line through the middle. Is this satisfactory ?

#With jitter
qqplot(jitter(expected_distribution),jitter(count1_vector),xlab="Expected
distribution",ylab="Observed values")
qqline(jitter(count1_vector),distribution = function(probs) { qbinom(probs,
size=100, prob=0.05) },col = "red",lwd = 2)

Now I can see the line is  not exactly through the middle. Can I think that
this is due to the way the data is discretized?

count1_vector <-
c(2, 6, 5, 8, 8, 6, 8, 3, 5, 8, 7, 6, 4, 7, 5, 2, 3, 3, 6, 3,
7, 3, 4, 8, 6, 6, 3, 5, 5, 3, 4, 5, 4, 2, 3, 6, 7, 7, 5, 4, 4,
7, 9, 4, 4, 4, 8, 9, 3, 5, 4, 7, 4, 3, 8, 6, 5, 5, 7, 3, 6, 7,
8, 7, 9, 3, 5, 5, 9, 8, 7, 7, 2, 3, 5, 2, 4, 14, 7, 7, 7, 3,
5, 4, 2, 12, 3, 6, 9, 4, 4, 3, 4, 4, 4, 6, 7, 4, 6, 10, 8, 5,
3, 3, 1, 3, 4, 3, 7, 3, 9, 7, 3, 3, 7, 5, 1, 2, 2, 3, 5, 4, 3,
8, 7, 0, 5, 3, 3, 4, 9, 2, 7, 5, 5, 5, 7, 7, 5, 4, 7, 2, 3, 5,
4, 5, 2, 10, 6, 3, 6, 2, 11, 2, 5, 5, 2, 5, 2, 10, 4, 5, 9, 1,
5, 6, 3, 4, 7, 7, 2, 2, 3, 6, 6, 6, 7, 3, 3, 6, 1, 4, 4, 4, 10,
4, 7, 4, 3, 4, 6, 5, 6, 7, 3, 7, 3, 5, 6, 6, 4, 5, 1, 7, 5, 7,
6, 7, 5, 3, 6, 7, 10, 5, 5, 4, 9, 6, 3, 9, 8, 4, 2, 8, 10, 4,
6, 7, 4, 4, 8, 4, 5, 4, 5, 6, 6, 5, 8, 2, 2, 6, 5, 3, 7, 7, 4,
9, 6, 5, 7, 8, 6, 1, 2, 3, 4, 4, 6, 8, 5, 8, 5, 7, 7, 4, 6, 3,
4, 5, 3, 4, 5, 3, 3, 4, 5, 5, 7, 8, 6, 5, 3, 3, 4, 3, 8, 6, 6,
3, 0, 4, 2, 7, 3, 5, 4, 6, 7, 4, 7, 6, 5, 8, 6, 7, 4, 5, 3, 6,
7, 6, 3, 5, 3, 3, 6, 3, 3, 2, 7, 5, 10, 2, 4, 5, 2, 4, 10, 5,
2, 7, 8, 5, 3, 7, 4, 2, 4, 3, 5, 6, 8, 10, 3, 7, 5, 8, 5, 2,
6, 8, 6, 7, 8, 2, 4, 2, 4, 3, 2, 4, 4, 2, 4, 3, 12, 2, 11, 5,
8, 8, 3, 6, 2, 6, 3, 5, 4, 8, 4, 5, 7, 2, 5, 3, 5, 3, 7, 6, 5,
2, 8, 6, 3, 3, 5, 3, 2, 6, 5, 8, 7, 4, 2, 3, 5, 2, 6, 4, 9, 5,
4, 4, 2, 1, 3, 3, 2, 5, 7, 6, 4, 4, 5, 6, 7, 4, 4, 4, 5, 9, 7,
5, 3, 5, 5, 2, 11, 9, 6, 8, 6, 6, 8, 6, 3, 6, 3, 7, 3, 3, 7,
4, 7, 4, 8, 3, 4, 8, 8, 8, 7, 4, 6, 1, 3, 7, 5, 13, 8, 1, 8,
5, 1, 3, 5, 4, 6, 5, 4, 3, 3, 7, 5, 5, 5, 3, 5, 5, 1, 8, 6, 4,
5, 9, 3, 8, 6, 4, 7, 6, 7, 5, 5, 6, 2, 7, 8, 11, 10, 4, 8, 5,
5, 4, 5, 4, 2, 8, 3, 3, 4, 5, 7, 12, 4, 7, 5, 4, 9, 8, 4, 5,
9, 4, 6, 5, 5, 2, 3, 4, 7, 7, 7, 7, 1, 6, 6, 6, 4, 8, 8, 5, 7,
3, 4, 6, 2, 6, 6, 4, 8, 4, 3, 7, 1, 4, 6, 2, 3, 5, 5, 9, 7, 1,
4, 1, 5, 3, 5, 4, 3, 5, 10, 4, 8, 6, 4, 3, 5, 6, 4, 6, 6, 4,
7, 7, 6, 5, 4, 4, 6, 10, 6, 5, 3, 8, 3, 4, 3, 5, 5, 2, 6, 6,
8, 2, 5, 9, 6, 5, 5, 4, 10, 7, 3, 5, 6, 8, 5, 3, 3, 7, 3, 4,
6, 2, 9, 2, 6, 5, 3, 6, 2, 4, 3, 4, 5, 5, 1, 5, 4, 11, 4, 1,
9, 5, 4, 7, 2, 11, 4, 9, 6, 5, 5, 6, 6, 7, 9, 4, 4, 4, 4, 3,
7, 3, 3, 4, 2, 6, 6, 6, 4, 6, 2, 5, 6, 5, 4, 3, 4, 7, 8, 7, 3,
5, 4, 4, 4, 4, 4, 4, 2, 7, 3, 5, 7, 1, 5, 5, 2, 7, 3, 3, 5, 3,
5, 4, 9, 5, 7, 8, 7, 7, 4, 5, 3, 5, 6, 5, 1, 6, 5, 5, 8, 7, 3,
6, 8, 1, 12, 1, 7, 6, 6, 3, 4, 4, 2, 2, 3, 2, 8, 4, 3, 7, 9,
10, 5, 5, 6, 7, 3, 7, 4, 7, 7, 3, 5, 9, 7, 3, 6, 6, 2, 5, 4,
3, 5, 8, 5, 6, 3, 4, 5, 2, 4, 3, 4, 5, 2, 7, 2, 7, 5, 5, 6, 8,
4, 8, 6, 5, 4, 5, 1, 6, 6, 2, 4, 8, 5, 7, 6, 10, 6, 4, 4, 4,
9, 5, 3, 1, 10, 7, 5, 6, 4, 7, 5, 6, 4, 2, 4, 6, 5, 3, 3, 6,
5, 9, 3, 7, 9, 4, 1, 4, 2, 4, 5, 4, 4, 2, 7, 11, 3, 3, 5, 8,
3, 5, 7, 9, 6, 11, 6, 5, 3, 7, 5, 3, 7, 4, 5, 4, 4, 8, 3, 3,
5, 4, 3, 7, 4, 2, 10, 2, 4, 3, 8, 4, 4, 5, 3, 3, 6, 2, 7, 2,
2, 11, 1, 6, 3, 6, 5, 7, 3, 3, 1, 7, 9, 8, 7, 2, 5, 4, 3, 7,
7, 2, 5, 4, 3, 3, 6, 10, 4, 9, 6, 5, 3, 4, 5, 5, 6, 6, 7, 3,
4, 8, 6, 4, 5, 1, 5, 9, 3, 6, 2, 4, 5, 5, 3, 3, 3, 3, 5, 4, 4,
5, 5, 1, 4, 5, 8, 7, 4, 3, 3, 5, 5, 4, 6, 5, 4, 7, 4, 4, 3, 3,
8, 4, 6, 7, 3, 4, 3, 5, 5, 7, 3, 6, 9, 7, 4, 3, 2, 6)








On Wed, Apr 19, 2017 at 12:32 PM, Ashim Kapoor <ashimkapoor at gmail.com>
wrote:

> Dear Boris,
>
> Many thanks,
> Ashim
>
> On Tue, Apr 18, 2017 at 7:56 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
>> As per the help pages, the data samples are expected in the second
>> argument, "y".
>>
>> So try
>>   qqplot(rbinom(n=100, size=100, p=0.05), count1_vector)
>>
>> ... and then plot your qqline()
>>
>> Alternatively, try
>>
>> qqline(count1_vector,
>>        distribution = function(probs) { qbinom(probs, size=100,
>> prob=0.05) },
>>        datax = TRUE, # <- logical. Should data values be on the x-axis?
>>        col = "red",
>>        lwd = 0.5)
>> ... and use your original qqplot()
>>
>>
>> B.
>>
>>
>> > On Apr 18, 2017, at 12:47 AM, Ashim Kapoor <ashimkapoor at gmail.com>
>> wrote:
>> >
>> > Dear Boris,
>> >
>> > Thank you for your reply.
>> >
>> > > dput(count1_vector)
>> > c(5, 6, 4, 4, 6, 5, 4, 5, 3, 7, 5, 5, 3, 4, 8, 6, 10, 2, 4, 6,
>> > 8, 4, 4, 6, 8, 5, 6, 3, 7, 9, 4, 7, 5, 7, 3, 4, 5, 2, 11, 7,
>> > 8, 5, 5, 6, 3, 2, 3, 5, 9, 6, 5, 6, 7, 3, 10, 7, 6, 4, 9, 5,
>> > 7, 3, 7, 3, 2, 3, 4, 5, 10, 4, 5, 5, 6, 7, 4, 8, 7, 5, 5, 4,
>> > 8, 7, 9, 4, 4, 4, 7, 5, 4, 10, 4, 5, 6, 1, 3, 5, 4, 7, 4, 6)
>> >
>> > set.seed(123)
>> > qqplot(count1_vector,rbinom(n=100,size=100,p=.05))
>> > qqline(count1_vector,distribution = function(probs) { qbinom(probs,
>> size=100, prob=0.05) },
>> >        col = "red",
>> >        lwd = 0.5)
>> >
>> > When I do this, the line does not pass through the center of my data.I
>> do expect count1_vector to be 100 samples of binomial with n=100 and p=.05.
>> >
>> > Any comments or suggestions for me ?
>> >
>> > Note : I built a 95% Confidence interval for my data and I counted how
>> often out of 100 times did the data fall outside the CI.This I expect to be
>> binomial with n=100,p=.05. I repeated this a 100 times and obtained
>> count1_vector.
>> >
>> > Best Regards,
>> > Ashim.
>> >
>> >
>> > On Mon, Apr 17, 2017 at 7:51 PM, Boris Steipe <boris.steipe at utoronto.ca>
>> wrote:
>> > That's not how qqline() works. The line is drawn with respect to a
>> _reference_distribution_ which is the normal distribution by default. For
>> the binomial distribution, you need to specify the distribution argument.
>> There is an example in the help page that shows you how this is done for
>> qchisq(). for qbinom() it is:
>> >
>> >
>> > set.seed(123)
>> > qqplot(rbinom(n=100, size=100, p=0.05),
>> >        rbinom(n=100, size=100, p=0.05) )
>> >
>> > qqline(rbinom(n=100,size=100,p=.05),
>> >        distribution = function(probs) { qbinom(probs, size=100,
>> prob=0.05) },
>> >        col = "red",
>> >        lwd = 0.5)
>> >
>> >
>> >
>> >
>> > B.
>> >
>> >
>> > > On Apr 17, 2017, at 9:15 AM, Ashim Kapoor <ashimkapoor at gmail.com>
>> wrote:
>> > >
>> > > Dear Spencer,
>> > >
>> > > Okay. Many thanks. My next query is how do I use qqline?
>> > >
>> > > When I try
>> > >
>> > >> qqline(rbinom(n=100,size=100,p=.05))
>> > >
>> > > I don't get the line in the right place.
>> > >
>> > > Best Regards,
>> > > Ashim
>> > >
>> > > On Mon, Apr 17, 2017 at 6:31 PM, Spencer Graves <
>> > > spencer.graves at effectivedefense.org> wrote:
>> > >
>> > >>
>> > >>
>> > >> On 2017-04-17 7:58 AM, Ashim Kapoor wrote:
>> > >>
>> > >>> Dear All,
>> > >>>
>> > >>> set.seed(123)
>> > >>> qqplot(rbinom(n=100,size=100,p=.05), rbinom(n=100,size=100,p=.05) )
>> > >>>
>> > >>> I expect to see 1 clear line,but I don't. What am I
>> misunderstanding?
>> > >>>
>> > >>
>> > >>
>> > >>      The distribution is discrete, and points are superimposed. Try
>> the
>> > >> following:
>> > >>
>> > >>
>> > >> set.seed(123)
>> > >> qqplot(jitter(rbinom(n=100,size=100,p=.05)),
>> > >>       jitter(rbinom(n=100,size=100,p=.05) ))
>> > >>
>> > >>
>> > >>      Spencer Graves
>> > >>
>> > >>>
>> > >>> Best Regards,
>> > >>> Ashim
>> > >>>
>> > >>>        [[alternative HTML version deleted]]
>> > >>>
>> > >>> ______________________________________________
>> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>> PLEASE do read the posting guide http://www.R-project.org/posti
>> > >>> ng-guide.html
>> > >>> and provide commented, minimal, self-contained, reproducible code.
>> > >>>
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide http://www.R-project.org/posti
>> > >> ng-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >>
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>>
>

	[[alternative HTML version deleted]]


From br at dmstat1.com  Thu May 11 13:15:38 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Thu, 11 May 2017 07:15:38 -0400
Subject: [R] functions similar to glm
Message-ID: <BE1A52A6-FED0-430A-A5AE-09C90D6396F8@dmstat1.com>

R-helpers:
In the "glmulti" package, it states parameter fitfunction assumes 
functions similar to glm, but doesn't list them. 
What are the functions similar to glm that can be used with glmulti?
Bruce


From paul at stat.auckland.ac.nz  Thu May 11 05:08:36 2017
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 11 May 2017 15:08:36 +1200
Subject: [R] [FORGED]  creating a color gradient in geom_ribbon
In-Reply-To: <DM3PR13MB0652666892E8CD7142840B6DFAEC0@DM3PR13MB0652.namprd13.prod.outlook.com>
References: <DM3PR13MB0652666892E8CD7142840B6DFAEC0@DM3PR13MB0652.namprd13.prod.outlook.com>
Message-ID: <7220f715-99b5-6445-e2d0-8462bef3b339@stat.auckland.ac.nz>

Hi

If the ribbon has constant "height" then this can be hacked by drawing a 
bunch of ribbons (polygons) with different heights and slowly changing 
colours.  If the height of the ribbon varies, then you could use the 
same approach and clip the result, with a little bit more work.  The 
attached code demonstrates the latter approach (the image files that it 
produces for me are also attached).

Hope that helps

Paul

On 11/05/17 08:05, Kristi Glover wrote:
> Hi R Users,
>
> I was trying to create a figure with geom_ribbon. There is a function
> "fill", but I want to make the shaded area with a gradient
> (increasing dark color towards a central line, inserted of having a
> color). Is there any possibility?
>
>
> In the given example, I want the colour with "blue" but in a gradient
> (dark=central, light= as goes higher or lower)
>
>
> pl = data.frame(Time = 0:10, menle = rnorm(11))
>
> pl$menlelb = pl$menle -1
>
> pl$menleub = pl$menle +1
>
> ggplot(pl, aes(Time)) +
>
> geom_line(aes(y=menle), colour="blue") +
>
> geom_ribbon(aes(ymin=menlelb, ymax=menleub), fill="blue")
>
>
> Thanks
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: gradient.pdf
Type: application/pdf
Size: 8834 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170511/59604882/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ggplot.pdf
Type: application/pdf
Size: 4761 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170511/59604882/attachment-0001.pdf>

From br at dmstat1.com  Thu May 11 14:22:46 2017
From: br at dmstat1.com (BR_email)
Date: Thu, 11 May 2017 08:22:46 -0400
Subject: [R] functions similar to glm
In-Reply-To: <CAGxFJbRhYaaxRPoUmV+-AsTyhxzXxtpm=bexyeCKTUF4Bxgotg@mail.gmail.com>
References: <BE1A52A6-FED0-430A-A5AE-09C90D6396F8@dmstat1.com>
 <CAGxFJbRhYaaxRPoUmV+-AsTyhxzXxtpm=bexyeCKTUF4Bxgotg@mail.gmail.com>
Message-ID: <34effa42-5db4-f687-013d-5bcfa64ad79e@dmstat1.com>

Thanks, Bert. I would expect the list to include, at least lm. The 
reference states, "See Examples section."
But, there is nothing in that section or elsewhere!!
Bruce

Bert Gunter wrote:
> Probably? :
>
> All functions for which a link function of the response is modeled as 
> a linear predictor of the covariates, but the response need not be in 
> the exponential family? Such a list of course cannot be "listed". I 
> would expect the package documentation, especially vignettes, explains 
> this in any case. Pls check.
>
> Hopefully, you'll get a more authoritative response if I'm wrong.
>
> Bert
>
>
>
>
>
>
>
> On May 11, 2017 4:15 AM, "Bruce Ratner PhD" <br at dmstat1.com 
> <mailto:br at dmstat1.com>> wrote:
>
>     R-helpers:
>     In the "glmulti" package, it states parameter fitfunction assumes
>     functions similar to glm, but doesn't list them.
>     What are the functions similar to glm that can be used with glmulti?
>     Bruce
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From bgunter.4567 at gmail.com  Thu May 11 14:39:07 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 11 May 2017 05:39:07 -0700
Subject: [R] functions similar to glm
In-Reply-To: <34effa42-5db4-f687-013d-5bcfa64ad79e@dmstat1.com>
References: <BE1A52A6-FED0-430A-A5AE-09C90D6396F8@dmstat1.com>
 <CAGxFJbRhYaaxRPoUmV+-AsTyhxzXxtpm=bexyeCKTUF4Bxgotg@mail.gmail.com>
 <34effa42-5db4-f687-013d-5bcfa64ad79e@dmstat1.com>
Message-ID: <CAGxFJbREaLY-dy3XTpXNczS9YMH4nVj3eQzPL7QXkb1zBbGBmQ@mail.gmail.com>

?glmulti seems clear enough to me. If not, pls check the reference given
therein.

Bert

On May 11, 2017 5:22 AM, "BR_email" <br at dmstat1.com> wrote:

> Thanks, Bert. I would expect the list to include, at least lm. The
> reference states, "See Examples section."
> But, there is nothing in that section or elsewhere!!
> Bruce
>
> Bert Gunter wrote:
>
>> Probably? :
>>
>> All functions for which a link function of the response is modeled as a
>> linear predictor of the covariates, but the response need not be in the
>> exponential family? Such a list of course cannot be "listed". I would
>> expect the package documentation, especially vignettes, explains this in
>> any case. Pls check.
>>
>> Hopefully, you'll get a more authoritative response if I'm wrong.
>>
>> Bert
>>
>>
>>
>>
>>
>>
>>
>> On May 11, 2017 4:15 AM, "Bruce Ratner PhD" <br at dmstat1.com <mailto:
>> br at dmstat1.com>> wrote:
>>
>>     R-helpers:
>>     In the "glmulti" package, it states parameter fitfunction assumes
>>     functions similar to glm, but doesn't list them.
>>     What are the functions similar to glm that can be used with glmulti?
>>     Bruce
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From br at dmstat1.com  Thu May 11 15:31:56 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Thu, 11 May 2017 09:31:56 -0400
Subject: [R] functions similar to glm
In-Reply-To: <CAGxFJbREaLY-dy3XTpXNczS9YMH4nVj3eQzPL7QXkb1zBbGBmQ@mail.gmail.com>
References: <BE1A52A6-FED0-430A-A5AE-09C90D6396F8@dmstat1.com>
 <CAGxFJbRhYaaxRPoUmV+-AsTyhxzXxtpm=bexyeCKTUF4Bxgotg@mail.gmail.com>
 <34effa42-5db4-f687-013d-5bcfa64ad79e@dmstat1.com>
 <CAGxFJbREaLY-dy3XTpXNczS9YMH4nVj3eQzPL7QXkb1zBbGBmQ@mail.gmail.com>
Message-ID: <9EAC9486-8D7B-47A7-B7B6-A16800B3885E@dmstat1.com>

Bert:
Not clear to me. 
Where mentioned are the functions similar to glm, if you please?
Bruce

______________




> On May 11, 2017, at 8:39 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ?glmulti seems clear enough to me. If not, pls check the reference given therein.
> 
> Bert
> 
>> On May 11, 2017 5:22 AM, "BR_email" <br at dmstat1.com> wrote:
>> Thanks, Bert. I would expect the list to include, at least lm. The reference states, "See Examples section."
>> But, there is nothing in that section or elsewhere!!
>> Bruce
>> 
>> Bert Gunter wrote:
>>> Probably? :
>>> 
>>> All functions for which a link function of the response is modeled as a linear predictor of the covariates, but the response need not be in the exponential family? Such a list of course cannot be "listed". I would expect the package documentation, especially vignettes, explains this in any case. Pls check.
>>> 
>>> Hopefully, you'll get a more authoritative response if I'm wrong.
>>> 
>>> Bert
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> On May 11, 2017 4:15 AM, "Bruce Ratner PhD" <br at dmstat1.com <mailto:br at dmstat1.com>> wrote:
>>> 
>>>     R-helpers:
>>>     In the "glmulti" package, it states parameter fitfunction assumes
>>>     functions similar to glm, but doesn't list them.
>>>     What are the functions similar to glm that can be used with glmulti?
>>>     Bruce
>>> 
>>>     ______________________________________________
>>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>>     To UNSUBSCRIBE and more, see
>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>     PLEASE do read the posting guide
>>>     http://www.R-project.org/posting-guide.html
>>>     <http://www.R-project.org/posting-guide.html>
>>>     and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu May 11 16:53:06 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 May 2017 07:53:06 -0700
Subject: [R] functions similar to glm
In-Reply-To: <9EAC9486-8D7B-47A7-B7B6-A16800B3885E@dmstat1.com>
References: <BE1A52A6-FED0-430A-A5AE-09C90D6396F8@dmstat1.com>
 <CAGxFJbRhYaaxRPoUmV+-AsTyhxzXxtpm=bexyeCKTUF4Bxgotg@mail.gmail.com>
 <34effa42-5db4-f687-013d-5bcfa64ad79e@dmstat1.com>
 <CAGxFJbREaLY-dy3XTpXNczS9YMH4nVj3eQzPL7QXkb1zBbGBmQ@mail.gmail.com>
 <9EAC9486-8D7B-47A7-B7B6-A16800B3885E@dmstat1.com>
Message-ID: <0A9BA1BB-E4DC-4988-ABEF-2A8A27C66F8B@comcast.net>


> On May 11, 2017, at 6:31 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
> 
> Bert:
> Not clear to me. 
> Where mentioned are the functions similar to glm, if you please?

The basis for the similarity was stated as having an available link function (and I suspected, an inverse as well.) I, for one, wouldn't have been surprised if `lm` were not in the list because `glm` with a 'gaussian' link would provide the same capabilities.   I read the basis as stating that a family-object be available (an object with the features described on the `?family` page. If I were correct, then running `methods(family)` would provide a list of the family objects that are available for loaded packages:

> methods("family")
[1] family.glm*    family.lm*     family.negbin*
see '?methods' for accessing help and source code

So lm would qualify as well.

> require(lme4)
Loading required package: lme4
Loading required package: Matrix
> methods("family")
[1] family.glm*     family.glmResp* family.lm*      family.lmResp*  family.merMod* 
[6] family.negbin*  family.nlsResp*
see '?methods' for accessing help and source code

Following Bert's advice (and so reading the manual for you), I find that Vincent Calcagno has stated the criterion somewhat differently in "Using glmulti with any type of statistical model, with examples."
#--------
glmulti works outof-the-box with several types of function (such as lm, glm or coxph), but it can in principle be used with any such function `myttingfunction`, as long as
 1. The function receives a model specication in the form of a formula; 
 2. The function ts the model by maximum likelihood, which can be accessed through the standard `LogLik` function; 

Even when the two conditions above are veried, complications arise because, unfortunately, dierent tting functions have dierent conventions regarding how characteristics of the t should be accessed. Indeed, most of them come from dierent packages with dierent authors and there is no common standard so far.
#--------



-- 
David
> Bruce
> 
> ______________
> 
> 
> 
> 
>> On May 11, 2017, at 8:39 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>> ?glmulti seems clear enough to me. If not, pls check the reference given therein.
>> 
>> Bert
>> 
>>> On May 11, 2017 5:22 AM, "BR_email" <br at dmstat1.com> wrote:
>>> Thanks, Bert. I would expect the list to include, at least lm. The reference states, "See Examples section."
>>> But, there is nothing in that section or elsewhere!!
>>> Bruce
>>> 
>>> Bert Gunter wrote:
>>>> Probably? :
>>>> 
>>>> All functions for which a link function of the response is modeled as a linear predictor of the covariates, but the response need not be in the exponential family? Such a list of course cannot be "listed". I would expect the package documentation, especially vignettes, explains this in any case. Pls check.
>>>> 
>>>> Hopefully, you'll get a more authoritative response if I'm wrong.
>>>> 
>>>> Bert
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> On May 11, 2017 4:15 AM, "Bruce Ratner PhD" <br at dmstat1.com <mailto:br at dmstat1.com>> wrote:
>>>> 
>>>>    R-helpers:
>>>>    In the "glmulti" package, it states parameter fitfunction assumes
>>>>    functions similar to glm, but doesn't list them.
>>>>    What are the functions similar to glm that can be used with glmulti?
>>>>    Bruce
>>>> 
>>>>    ______________________________________________
>>>>    R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>>>    To UNSUBSCRIBE and more, see
>>>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>>>    <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>    PLEASE do read the posting guide
>>>>    http://www.R-project.org/posting-guide.html
>>>>    <http://www.R-project.org/posting-guide.html>
>>>>    and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From br at dmstat1.com  Thu May 11 16:57:12 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Thu, 11 May 2017 10:57:12 -0400
Subject: [R] functions similar to glm
In-Reply-To: <0A9BA1BB-E4DC-4988-ABEF-2A8A27C66F8B@comcast.net>
References: <BE1A52A6-FED0-430A-A5AE-09C90D6396F8@dmstat1.com>
 <CAGxFJbRhYaaxRPoUmV+-AsTyhxzXxtpm=bexyeCKTUF4Bxgotg@mail.gmail.com>
 <34effa42-5db4-f687-013d-5bcfa64ad79e@dmstat1.com>
 <CAGxFJbREaLY-dy3XTpXNczS9YMH4nVj3eQzPL7QXkb1zBbGBmQ@mail.gmail.com>
 <9EAC9486-8D7B-47A7-B7B6-A16800B3885E@dmstat1.com>
 <0A9BA1BB-E4DC-4988-ABEF-2A8A27C66F8B@comcast.net>
Message-ID: <15E3FF70-57DA-4708-A0DA-A02C95369365@dmstat1.com>

Dear David:
Thank you for your excellent reply. 
Apparently, you are a in the know. 
Again, thanks. 
Bruce

______________
Bruce Ratner PhD
The Significant Statistician?
(516) 791-3544
Statistical Predictive Analytics -- www.DMSTAT1.com
Machine-Learning Data Mining -- www.GenIQ.net



> On May 11, 2017, at 10:53 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On May 11, 2017, at 6:31 AM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>> 
>> Bert:
>> Not clear to me. 
>> Where mentioned are the functions similar to glm, if you please?
> 
> The basis for the similarity was stated as having an available link function (and I suspected, an inverse as well.) I, for one, wouldn't have been surprised if `lm` were not in the list because `glm` with a 'gaussian' link would provide the same capabilities.   I read the basis as stating that a family-object be available (an object with the features described on the `?family` page. If I were correct, then running `methods(family)` would provide a list of the family objects that are available for loaded packages:
> 
>> methods("family")
> [1] family.glm*    family.lm*     family.negbin*
> see '?methods' for accessing help and source code
> 
> So lm would qualify as well.
> 
>> require(lme4)
> Loading required package: lme4
> Loading required package: Matrix
>> methods("family")
> [1] family.glm*     family.glmResp* family.lm*      family.lmResp*  family.merMod* 
> [6] family.negbin*  family.nlsResp*
> see '?methods' for accessing help and source code
> 
> Following Bert's advice (and so reading the manual for you), I find that Vincent Calcagno has stated the criterion somewhat differently in "Using glmulti with any type of statistical model, with examples."
> #--------
> glmulti works outof-the-box with several types of function (such as lm, glm or coxph), but it can in principle be used with any such function `my
ttingfunction`, as long as
> 1. The function receives a model speci
cation in the form of a formula; 
> 2. The function 
ts the model by maximum likelihood, which can be accessed through the standard `LogLik` function; 
> 
> Even when the two conditions above are veri
ed, complications arise because, unfortunately, dierent 
tting functions have dierent conventions regarding how characteristics of the 
t should be accessed. Indeed, most of them come from dierent packages with dierent authors and there is no common standard so far.
> #--------
> 
> 
> 
> -- 
> David
>> Bruce
>> 
>> ______________
>> 
>> 
>> 
>> 
>>> On May 11, 2017, at 8:39 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> ?glmulti seems clear enough to me. If not, pls check the reference given therein.
>>> 
>>> Bert
>>> 
>>>> On May 11, 2017 5:22 AM, "BR_email" <br at dmstat1.com> wrote:
>>>> Thanks, Bert. I would expect the list to include, at least lm. The reference states, "See Examples section."
>>>> But, there is nothing in that section or elsewhere!!
>>>> Bruce
>>>> 
>>>> Bert Gunter wrote:
>>>>> Probably? :
>>>>> 
>>>>> All functions for which a link function of the response is modeled as a linear predictor of the covariates, but the response need not be in the exponential family? Such a list of course cannot be "listed". I would expect the package documentation, especially vignettes, explains this in any case. Pls check.
>>>>> 
>>>>> Hopefully, you'll get a more authoritative response if I'm wrong.
>>>>> 
>>>>> Bert
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On May 11, 2017 4:15 AM, "Bruce Ratner PhD" <br at dmstat1.com <mailto:br at dmstat1.com>> wrote:
>>>>> 
>>>>>   R-helpers:
>>>>>   In the "glmulti" package, it states parameter fitfunction assumes
>>>>>   functions similar to glm, but doesn't list them.
>>>>>   What are the functions similar to glm that can be used with glmulti?
>>>>>   Bruce
>>>>> 
>>>>>   ______________________________________________
>>>>>   R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>>>>   To UNSUBSCRIBE and more, see
>>>>>   https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>   <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>   PLEASE do read the posting guide
>>>>>   http://www.R-project.org/posting-guide.html
>>>>>   <http://www.R-project.org/posting-guide.html>
>>>>>   and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>> 
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 


From br at dmstat1.com  Thu May 11 16:43:46 2017
From: br at dmstat1.com (BR_email)
Date: Thu, 11 May 2017 10:43:46 -0400
Subject: [R] functions similar to glm
In-Reply-To: <CAGxFJbQpOW64MRDQmvOAA_DygQUddmUc7p+jBPVpdV53yA9vVg@mail.gmail.com>
References: <BE1A52A6-FED0-430A-A5AE-09C90D6396F8@dmstat1.com>
 <CAGxFJbRhYaaxRPoUmV+-AsTyhxzXxtpm=bexyeCKTUF4Bxgotg@mail.gmail.com>
 <34effa42-5db4-f687-013d-5bcfa64ad79e@dmstat1.com>
 <CAGxFJbREaLY-dy3XTpXNczS9YMH4nVj3eQzPL7QXkb1zBbGBmQ@mail.gmail.com>
 <9EAC9486-8D7B-47A7-B7B6-A16800B3885E@dmstat1.com>
 <CAGxFJbQpOW64MRDQmvOAA_DygQUddmUc7p+jBPVpdV53yA9vVg@mail.gmail.com>
Message-ID: <09a93f6e-fc31-f0e0-e3b5-585a8415f0f4@dmstat1.com>

Bert:
My question implies that I read (consulted) the reference, as I cited 
actual wordings of the reference.
Apparently, you think I am lazy, and dumb, and like to waste R-helpers' 
time, as well as mine.
Thanks for your reply, quite helpful.
Bruce
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  

Bert Gunter wrote:
> CONSULT THE REFERENCE IN THE HELP PLS. AS I REQUESTED.
>
> Bert
>
>
>
> On May 11, 2017 7:32 AM, "Bruce Ratner PhD" <br at dmstat1.com 
> <mailto:br at dmstat1.com>> wrote:
>
>     Bert:
>     Not clear to me.
>     Where mentioned are the functions similar to glm, if you please?
>     Bruce
>
>     ______________
>
>
>
>
>     On May 11, 2017, at 8:39 AM, Bert Gunter <bgunter.4567 at gmail.com
>     <mailto:bgunter.4567 at gmail.com>> wrote:
>
>>     ?glmulti seems clear enough to me. If not, pls check the
>>     reference given therein.
>>
>>     Bert
>>
>>     On May 11, 2017 5:22 AM, "BR_email" <br at dmstat1.com
>>     <mailto:br at dmstat1.com>> wrote:
>>
>>         Thanks, Bert. I would expect the list to include, at least
>>         lm. The reference states, "See Examples section."
>>         But, there is nothing in that section or elsewhere!!
>>         Bruce
>>
>>         Bert Gunter wrote:
>>
>>             Probably? :
>>
>>             All functions for which a link function of the response
>>             is modeled as a linear predictor of the covariates, but
>>             the response need not be in the exponential family? Such
>>             a list of course cannot be "listed". I would expect the
>>             package documentation, especially vignettes, explains
>>             this in any case. Pls check.
>>
>>             Hopefully, you'll get a more authoritative response if
>>             I'm wrong.
>>
>>             Bert
>>
>>
>>
>>
>>
>>
>>
>>             On May 11, 2017 4:15 AM, "Bruce Ratner PhD"
>>             <br at dmstat1.com <mailto:br at dmstat1.com>
>>             <mailto:br at dmstat1.com <mailto:br at dmstat1.com>>> wrote:
>>
>>                 R-helpers:
>>                 In the "glmulti" package, it states parameter
>>             fitfunction assumes
>>                 functions similar to glm, but doesn't list them.
>>                 What are the functions similar to glm that can be
>>             used with glmulti?
>>                 Bruce
>>
>>                 ______________________________________________
>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>             <mailto:R-help at r-project.org
>>             <mailto:R-help at r-project.org>> mailing list --
>>                 To UNSUBSCRIBE and more, see
>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                 <https://stat.ethz.ch/mailman/listinfo/r-help
>>             <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>                 PLEASE do read the posting guide
>>             http://www.R-project.org/posting-guide.html
>>             <http://www.R-project.org/posting-guide.html>
>>                 <http://www.R-project.org/posting-guide.html
>>             <http://www.R-project.org/posting-guide.html>>
>>                 and provide commented, minimal, self-contained,
>>             reproducible code.
>>
>>
>>


From s3tochri at uni-bayreuth.de  Thu May 11 15:37:39 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Thu, 11 May 2017 15:37:39 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' - object
 specific trend
Message-ID: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>

Hey,

I just have trouble adding a object specific time trend with the 
plm-package. I recieve the following error:
*
**"Error in model.frame.default(terms(formula, lhs = lhs, rhs = rhs, 
data = data,  : invalid type for the variable 'time' "*

I used the formula:

/ FE_trend<- plm(log(revenue) ~ log(supply)+ city*time, 
data=R_Test_log_Neu, model="within", effect = "twoways") //
/
Do you have an idea how to fix it?

Toby

	[[alternative HTML version deleted]]


From margotneyret at gmail.com  Thu May 11 16:40:39 2017
From: margotneyret at gmail.com (Margot Neyret)
Date: Thu, 11 May 2017 16:40:39 +0200
Subject: [R] Design matrix for species mixture
Message-ID: <aebafc54-5235-4fd7-aff1-c4717c3b3362@Canary>

Hello,

I have fields with species mixtures (for instance, species a, b, c, a+b, a+c, b+c), and I look at the effect of each species on a response Y. More specifically, I would like to compare the effect of individual species, either alone or in mixture.

>Y = rnorm(18,0,1)
>mixture= rep(c('a','b', 'c', 'a+b', 'a+c', 'b+c'), each = 3)

Thus I create variables A, B and C with :
- A = 1 when the mixture contains a (ie mixture = a or a+b or a+c); and 0 otherwise.
- Idem for variables C and B.

>A = ifelse(mixture %in% c('a', 'a+b', 'a+c'), 1, 0)
>B = ifelse(mixture %in% c('b', 'a+b', 'b+c'), 1, 0)
>C = ifelse(mixture %in% c('c', 'a+c', 'b+c'), 1, 0)

My plan was to build a design matrix from these 3 variables, that would then allow me to compare the effects of each species.

> mm = model.matrix(~A+B+C+0)
> summary(lm(Y~mm))
Coefficients:
Estimate Std. Error t value Pr(>|t|)
(Intercept) -0.8301 0.6221 -1.334 0.203
mmA 1.1636 0.4819 2.415 0.030 *
mmB 0.8452 0.4819 1.754 0.101
mmC -0.1005 0.4819 -0.208 0.838
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.8347 on 14 degrees of freedom
Multiple R-squared: 0.4181, Adjusted R-squared: 0.2934
F-statistic: 3.353 on 3 and 14 DF, p-value: 0.04964

My questions :
1. Does this approach make any sense ? I have a feeling I am doing something strange but I cannot put my finger on it.
1. My ddl are wrong, I should not have an intercept here, or at least my intercept should be one of my species. Should I just remove one species form the design matrix ?
2. Is there any way to do post-hoc tests on my species now, as I would have done with Tukey test or lsmeans ?

My objective afterwards is to add other explanatory variables and interactions in the model.

Thanks in advance !

M. N.


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu May 11 17:23:37 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 11 May 2017 11:23:37 -0400
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
Message-ID: <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>

On 11/05/2017 9:37 AM, Tobias Christoph wrote:
> Hey,
>
> I just have trouble adding a object specific time trend with the
> plm-package. I recieve the following error:
> *
> **"Error in model.frame.default(terms(formula, lhs = lhs, rhs = rhs,
> data = data,  : invalid type for the variable 'time' "*
>
> I used the formula:
>
> / FE_trend<- plm(log(revenue) ~ log(supply)+ city*time,
> data=R_Test_log_Neu, model="within", effect = "twoways") //
> /
> Do you have an idea how to fix it?

I don't know that package and you didn't supply a reproducible example, 
so there are at least these two possibilities:

1.  Your dataframe R_Test_log_Neu contains no column named "time". 
(Remember that "Time" and "time" are different.)  Fix:  use the correct 
column name.

2.  The plm package isn't doing lookup of symbols from the formula first 
in your dataframe.  This would need to be fixed in the package.  A 
workaround might be to name the columns with unique names that won't be 
found anywhere else, e.g. name your column "NeuTime" instead of "time".

Duncan Murdoch


From G.Maubach at gmx.de  Thu May 11 18:33:35 2017
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Thu, 11 May 2017 18:33:35 +0200
Subject: [R] Off-Topic: Project Organisation
Message-ID: <trinity-828fb87e-81fb-47c6-8c8d-570c1c6d6634-1494520415424@3capp-gmx-bs28>

Hi All,

this post is somewhat off-topic cause it deals with a meta issue related to project organisation instead of real R code.

I have updated my blog concerning a possible directory and file structure for marketing research projects and data mining projects alike:

https://github.com/gmaubach/R-Know-How/wiki/R-Blog

There I condensed best practices already communicated in articels, books, packages and guidelines into a new universial structure. It shall serve as a template and construction kit which you can use to create a structure that suits your project best.

Comments and suggestions are welcome.

Kind regards

Georg


From dwinsemius at comcast.net  Thu May 11 19:59:37 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 May 2017 10:59:37 -0700
Subject: [R] Off-Topic: Project Organisation
In-Reply-To: <trinity-828fb87e-81fb-47c6-8c8d-570c1c6d6634-1494520415424@3capp-gmx-bs28>
References: <trinity-828fb87e-81fb-47c6-8c8d-570c1c6d6634-1494520415424@3capp-gmx-bs28>
Message-ID: <FA672F4E-92F1-486E-BB1A-9672A20C3DBD@comcast.net>


> On May 11, 2017, at 9:33 AM, G.Maubach at gmx.de wrote:
> 
> Hi All,
> 
> this post is somewhat off-topic cause it deals with a meta issue related to project organisation instead of real R code.
> 
> I have updated my blog concerning a possible directory and file structure for marketing research projects and data mining projects alike:
> 
> https://github.com/gmaubach/R-Know-How/wiki/R-Blog
> 
> There I condensed best practices already communicated in articels, books, packages and guidelines into a new universial structure. It shall serve as a template and construction kit which you can use to create a structure that suits your project best.
> 
> Comments and suggestions are welcome.

I wonder if you meant to write:

detach("package:xlsx", unload = TRUE)



Best;
David.
> 
> Kind regards
> 
> Georg
> 
David Winsemius
Alameda, CA, USA


From aolinto.lst at gmail.com  Thu May 11 20:36:14 2017
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Thu, 11 May 2017 15:36:14 -0300
Subject: [R] How to plot a legend centered only on the x axis
Message-ID: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>

Hello r-users

I want to plot some barplots inside a looping with the legend placed
outside the plotting area.

No matter the number of bars I want the legend to be placed centered on the
x-axis.

See the example below

for(i in 1:10) {
var_1 <- sample(1000:100000,sample(3:8,1))
ymax <- max(var_1)
b<-barplot(var_1,col="blue")
var_2 <- sample(1000:ymax,length(var_1))
lines(rowSums(b),var_2,type="o",col="red",pch=16)
par(xpd=TRUE)
legend(*1.1*
,ymax*-0.072,c("var_1","var_2"),horiz=T,cex=1.3,bty="n",pch=c(15,16),col=c("blue","red"),lty=c(0,1),lwd=c(0,2),pt.cex=2)
readline(prompt="Press [enter] to continue")
}

What I should use as x position in legend(x,y, ...), instead of *1.1*, to
have the legend centered on the x-axis?

I would love to use something like legend(x="center",y=ymax*-0.072, ... but
it did not worked.

I appreciate any suggestions. Best regards.

Antonio

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu May 11 21:19:12 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 11 May 2017 14:19:12 -0500
Subject: [R] How to plot a legend centered only on the x axis
In-Reply-To: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
References: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
Message-ID: <0DA903DA-A74A-4AAF-AD71-A15CA48B81C9@me.com>


> On May 11, 2017, at 1:36 PM, Antonio Silva <aolinto.lst at gmail.com> wrote:
> 
> Hello r-users
> 
> I want to plot some barplots inside a looping with the legend placed
> outside the plotting area.
> 
> No matter the number of bars I want the legend to be placed centered on the
> x-axis.
> 
> See the example below
> 
> for(i in 1:10) {
> var_1 <- sample(1000:100000,sample(3:8,1))
> ymax <- max(var_1)
> b<-barplot(var_1,col="blue")
> var_2 <- sample(1000:ymax,length(var_1))
> lines(rowSums(b),var_2,type="o",col="red",pch=16)
> par(xpd=TRUE)
> legend(*1.1*
> ,ymax*-0.072,c("var_1","var_2"),horiz=T,cex=1.3,bty="n",pch=c(15,16),col=c("blue","red"),lty=c(0,1),lwd=c(0,2),pt.cex=2)
> readline(prompt="Press [enter] to continue")
> }
> 
> What I should use as x position in legend(x,y, ...), instead of *1.1*, to
> have the legend centered on the x-axis?
> 
> I would love to use something like legend(x="center",y=ymax*-0.072, ... but
> it did not worked.co
> 
> I appreciate any suggestions. Best regards.
> 
> Antonio


Hi,

There is a level of magic that goes into the legend() code to determine the placement of the legend. You can take the time to review the code for the function, noting how, internally, the location of the box that contains the legend is determined.

Somebody may have an easier way to do this, but one approach is to first call legend() but set 'plot = FALSE' and obtain the return values of the function for use in a second call that will draw the legend in the position you desire.


Here is some basic information:

# Draw the initial barplot
barplot(1:5)

# Call legend() the first time, but don't draw it
# See ?legend for the Value section
# Use "bottom" to get the legend drawn in the center of the x axis, but it 
# will be within the plot region by default.
# Just save the 'rect' component of the returned value
BOX <- legend("bottom", legend = c("Label 1", "Label 2"), plot = FALSE)$rect

# This gives us the width and height of the box containing the legend
# as well as the x,y coordinates of the upper left hand corner
> BOX
$w
[1] 1.002451

$h
[1] 0.5872093

$left
[1] 2.598775

$top
[1] 0.5372093


Now, using BOX$left, which defines the x axis value for the left side of the legend box that is centered, we can call legend() a second time and adjust the y axis value of the legend to place it outside the plot region, below the plot. Just be sure that your second call to legend() is exactly the same as the first call, other than setting legend to FALSE in the first case. Any change in legend content between the two calls will alter the size and position of the enclosing box.

par(xpd = TRUE)
legend(BOX$left, y = -0.25, legend = c("Label 1", "Label 2"))


You can then adapt that basic approach to use in your code.

As an FYI, see ?par and note "usr", which defines the coordinates of the plot region. If desired, you can get the midpoint of the x axis using:

  mean(par("usr")[1:2])

Regards,

Marc Schwartz


From s3tochri at uni-bayreuth.de  Thu May 11 22:20:05 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Thu, 11 May 2017 22:20:05 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
Message-ID: <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>

Hey Duncan,

thank you very much for your quick reply.

_My data used:_

1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11

2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12

3rd column (revenue):

4th colum (supply):

I have now renamed my colums and did the regression again. Now there is 
a problem with R-squared, as it is the sum of 1 now with no given std. 
error and t-value. This is probably due to the fact, that I try to 
estimate more parameters than data.

To add a linear trend I found the following formular:*lm(y ~ x1 + 
factor(ccode)*time, data=df)*

I try to I decode it for and use it for my regression: *plm(log(revenue) 
~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*

When I do this regression I will get the original error: "invalid type 
(closure) for the variable 'time' - object specific trend"

With the notation"time" not my colum is meant, but probably the command 
"time" in R.

Can you follow my thoughts?

Tobi






Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
> Duncan Murdoch


From ruipbarradas at sapo.pt  Thu May 11 22:36:09 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 11 May 2017 21:36:09 +0100
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
Message-ID: <5914CB39.8050701@sapo.pt>

Hello,

A closure is, like you say, a function.
At an R prompt try:

 > typeof(time)
[1] "closure"

So like Duncan suggested rename 'time', for instance capitalize it 
'Time'. That should do it.

Hope this helps,

Rui Barradas



Em 11-05-2017 21:20, Tobias Christoph escreveu:
> Hey Duncan,
>
> thank you very much for your quick reply.
>
> _My data used:_
>
> 1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11
>
> 2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12
>
> 3rd column (revenue):
>
> 4th colum (supply):
>
> I have now renamed my colums and did the regression again. Now there is
> a problem with R-squared, as it is the sum of 1 now with no given std.
> error and t-value. This is probably due to the fact, that I try to
> estimate more parameters than data.
>
> To add a linear trend I found the following formular:*lm(y ~ x1 +
> factor(ccode)*time, data=df)*
>
> I try to I decode it for and use it for my regression: *plm(log(revenue)
> ~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*
>
> When I do this regression I will get the original error: "invalid type
> (closure) for the variable 'time' - object specific trend"
>
> With the notation"time" not my colum is meant, but probably the command
> "time" in R.
>
> Can you follow my thoughts?
>
> Tobi
>
>
>
>
>
>
> Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
>> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu May 11 23:17:18 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 11 May 2017 21:17:18 +0000
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <5914CB39.8050701@sapo.pt>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
Message-ID: <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>

What Rui said, but as important, you have four columns in your data called "town", "year", "revenue", and "supply". You do not have a column called "time". 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Thursday, May 11, 2017 3:36 PM
To: Tobias Christoph <s3tochri at uni-bayreuth.de>; Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
Subject: Re: [R] Error: invalid type (closure) for the variable 'time' - object specific trend

Hello,

A closure is, like you say, a function.
At an R prompt try:

 > typeof(time)
[1] "closure"

So like Duncan suggested rename 'time', for instance capitalize it 
'Time'. That should do it.

Hope this helps,

Rui Barradas



Em 11-05-2017 21:20, Tobias Christoph escreveu:
> Hey Duncan,
>
> thank you very much for your quick reply.
>
> _My data used:_
>
> 1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11
>
> 2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12
>
> 3rd column (revenue):
>
> 4th colum (supply):
>
> I have now renamed my colums and did the regression again. Now there is
> a problem with R-squared, as it is the sum of 1 now with no given std.
> error and t-value. This is probably due to the fact, that I try to
> estimate more parameters than data.
>
> To add a linear trend I found the following formular:*lm(y ~ x1 +
> factor(ccode)*time, data=df)*
>
> I try to I decode it for and use it for my regression: *plm(log(revenue)
> ~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*
>
> When I do this regression I will get the original error: "invalid type
> (closure) for the variable 'time' - object specific trend"
>
> With the notation"time" not my colum is meant, but probably the command
> "time" in R.
>
> Can you follow my thoughts?
>
> Tobi
>
>
>
>
>
>
> Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
>> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From abo_dlsh at hotmail.com  Fri May 12 01:16:34 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Thu, 11 May 2017 23:16:34 +0000
Subject: [R] Matched Items in rows + issue with writing a table
Message-ID: <CY4PR15MB1302882B8DED436735654C3FEFED0@CY4PR15MB1302.namprd15.prod.outlook.com>

Hi All ..,


I have a table called "x444" and I would like to create a new column contains the matched items in each row between column w & r . I used match()function as below but this does not return the results I want because of 2 issues. The 1st one is that this gives the row number of shared items while I want to see the item itself (e.g. in the table below, I want to see cyp2 instead of the row number 2). The 2nd issue is that I need to know matched items considering every item in the row instead of the entire row. For example, the item cyp3 is a matched item in the first row between columns w & r. The same applies for c6 in row 3. These don't appear in the results below.



>x444
               w         r
1 cyp3,cyp7     cyp2, cyp1,cyp3
2         cyp2      cyp2
3   c1,c3,c6       c6,c8,c5


> r = c(match(x444$w,X444$r))
> r
[1] NA  2 NA



The desired output should be like this :-

                w             r                             matched items
1 cyp3,cyp7     cyp2, cyp1,cyp3             cyp3
2         cyp2      cyp2                                  cyp2
3   c1,c3,c6       c6,c8,c5                          c6


The second issue is that when I write a table produced in R as follows :

write.table(MyTable,file="MyTable.txt", sep = "\t", quote = F, row.names = F)

and the read this txt. file in excel, some items from column B appears in Column A and some empty rows also appear?.

Could you please guide me about the mistakes I have done and suggest
some solutions?

Regards

	[[alternative HTML version deleted]]


From aolinto.lst at gmail.com  Fri May 12 01:29:13 2017
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Thu, 11 May 2017 20:29:13 -0300
Subject: [R] How to plot a legend centered only on the x axis
In-Reply-To: <0DA903DA-A74A-4AAF-AD71-A15CA48B81C9@me.com>
References: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
 <0DA903DA-A74A-4AAF-AD71-A15CA48B81C9@me.com>
Message-ID: <CAE8g1gMnA7L+A_Aud7gy969VrPf5so4XYA-7kJ7ttaWx4+BAXw@mail.gmail.com>

Thanks for you attention Mark. Your approach is really very interesting. I
will try to apply it in my code.

All the best

Antonio

2017-05-11 16:19 GMT-03:00 Marc Schwartz <marc_schwartz at me.com>:

>
> > On May 11, 2017, at 1:36 PM, Antonio Silva <aolinto.lst at gmail.com>
> wrote:
> >
> > Hello r-users
> >
> > I want to plot some barplots inside a looping with the legend placed
> > outside the plotting area.
> >
> > No matter the number of bars I want the legend to be placed centered on
> the
> > x-axis.
> >
> > See the example below
> >
> > for(i in 1:10) {
> > var_1 <- sample(1000:100000,sample(3:8,1))
> > ymax <- max(var_1)
> > b<-barplot(var_1,col="blue")
> > var_2 <- sample(1000:ymax,length(var_1))
> > lines(rowSums(b),var_2,type="o",col="red",pch=16)
> > par(xpd=TRUE)
> > legend(*1.1*
> > ,ymax*-0.072,c("var_1","var_2"),horiz=T,cex=1.3,bty="n",pch=
> c(15,16),col=c("blue","red"),lty=c(0,1),lwd=c(0,2),pt.cex=2)
> > readline(prompt="Press [enter] to continue")
> > }
> >
> > What I should use as x position in legend(x,y, ...), instead of *1.1*, to
> > have the legend centered on the x-axis?
> >
> > I would love to use something like legend(x="center",y=ymax*-0.072, ...
> but
> > it did not worked.co
> >
> > I appreciate any suggestions. Best regards.
> >
> > Antonio
>
>
> Hi,
>
> There is a level of magic that goes into the legend() code to determine
> the placement of the legend. You can take the time to review the code for
> the function, noting how, internally, the location of the box that contains
> the legend is determined.
>
> Somebody may have an easier way to do this, but one approach is to first
> call legend() but set 'plot = FALSE' and obtain the return values of the
> function for use in a second call that will draw the legend in the position
> you desire.
>
>
> Here is some basic information:
>
> # Draw the initial barplot
> barplot(1:5)
>
> # Call legend() the first time, but don't draw it
> # See ?legend for the Value section
> # Use "bottom" to get the legend drawn in the center of the x axis, but it
> # will be within the plot region by default.
> # Just save the 'rect' component of the returned value
> BOX <- legend("bottom", legend = c("Label 1", "Label 2"), plot =
> FALSE)$rect
>
> # This gives us the width and height of the box containing the legend
> # as well as the x,y coordinates of the upper left hand corner
> > BOX
> $w
> [1] 1.002451
>
> $h
> [1] 0.5872093
>
> $left
> [1] 2.598775
>
> $top
> [1] 0.5372093
>
>
> Now, using BOX$left, which defines the x axis value for the left side of
> the legend box that is centered, we can call legend() a second time and
> adjust the y axis value of the legend to place it outside the plot region,
> below the plot. Just be sure that your second call to legend() is exactly
> the same as the first call, other than setting legend to FALSE in the first
> case. Any change in legend content between the two calls will alter the
> size and position of the enclosing box.
>
> par(xpd = TRUE)
> legend(BOX$left, y = -0.25, legend = c("Label 1", "Label 2"))
>
>
> You can then adapt that basic approach to use in your code.
>
> As an FYI, see ?par and note "usr", which defines the coordinates of the
> plot region. If desired, you can get the midpoint of the x axis using:
>
>   mean(par("usr")[1:2])
>
> Regards,
>
> Marc Schwartz

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri May 12 01:30:45 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 12 May 2017 09:30:45 +1000
Subject: [R] How to plot a legend centered only on the x axis
In-Reply-To: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
References: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
Message-ID: <CA+8X3fUbgWEHh2kiFrewuvAU-VCXh2bAP9Ueg1T49jK9iyQFAw@mail.gmail.com>

Hi Antonio,
First you want the center of the plot:

xylim<-par("usr")
x_center<-sum(xylim[1:2])/2

Then as you want to have you legend above the plot:

# you will probably want to change the "20" to your preference
y_bottom<-xylim[4]+diff(xylim[3:4])/20

then:

legend(x_center,ybottom,...xjust=0.5,yjust=0)

Jim

On Fri, May 12, 2017 at 4:36 AM, Antonio Silva <aolinto.lst at gmail.com> wrote:
> Hello r-users
>
> I want to plot some barplots inside a looping with the legend placed
> outside the plotting area.
>
> No matter the number of bars I want the legend to be placed centered on the
> x-axis.
>
> See the example below
>
> for(i in 1:10) {
> var_1 <- sample(1000:100000,sample(3:8,1))
> ymax <- max(var_1)
> b<-barplot(var_1,col="blue")
> var_2 <- sample(1000:ymax,length(var_1))
> lines(rowSums(b),var_2,type="o",col="red",pch=16)
> par(xpd=TRUE)
> legend(*1.1*
> ,ymax*-0.072,c("var_1","var_2"),horiz=T,cex=1.3,bty="n",pch=c(15,16),col=c("blue","red"),lty=c(0,1),lwd=c(0,2),pt.cex=2)
> readline(prompt="Press [enter] to continue")
> }
>
> What I should use as x position in legend(x,y, ...), instead of *1.1*, to
> have the legend centered on the x-axis?
>
> I would love to use something like legend(x="center",y=ymax*-0.072, ... but
> it did not worked.
>
> I appreciate any suggestions. Best regards.
>
> Antonio
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri May 12 02:01:54 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 11 May 2017 20:01:54 -0400
Subject: [R] How to plot a legend centered only on the x axis
In-Reply-To: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
References: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
Message-ID: <2521b5b6-a841-0c10-7681-014a5305516d@gmail.com>

On 11/05/2017 2:36 PM, Antonio Silva wrote:
> Hello r-users
>
> I want to plot some barplots inside a looping with the legend placed
> outside the plotting area.
>
> No matter the number of bars I want the legend to be placed centered on the
> x-axis.
>
> See the example below
>
> for(i in 1:10) {
> var_1 <- sample(1000:100000,sample(3:8,1))
> ymax <- max(var_1)
> b<-barplot(var_1,col="blue")
> var_2 <- sample(1000:ymax,length(var_1))
> lines(rowSums(b),var_2,type="o",col="red",pch=16)
> par(xpd=TRUE)
> legend(*1.1*
> ,ymax*-0.072,c("var_1","var_2"),horiz=T,cex=1.3,bty="n",pch=c(15,16),col=c("blue","red"),lty=c(0,1),lwd=c(0,2),pt.cex=2)
> readline(prompt="Press [enter] to continue")
> }
>
> What I should use as x position in legend(x,y, ...), instead of *1.1*, to
> have the legend centered on the x-axis?
>
> I would love to use something like legend(x="center",y=ymax*-0.072, ... but
> it did not worked.
>
> I appreciate any suggestions. Best regards.

Instead of "center", use "top" or "bottom".  See the 2nd last example in 
examples(legend) for the possibilities.

If you want the legend outside the plotting area, set "inset" and "xpd" 
arguments.  For example,

plot(1,1)
legend("top", pch = 1, legend = "point", inset = -0.1, xpd = TRUE)


Duncan Murdoch


From drjimlemon at gmail.com  Fri May 12 02:53:44 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 12 May 2017 10:53:44 +1000
Subject: [R] Design matrix for species mixture
In-Reply-To: <aebafc54-5235-4fd7-aff1-c4717c3b3362@Canary>
References: <aebafc54-5235-4fd7-aff1-c4717c3b3362@Canary>
Message-ID: <CA+8X3fXRgQ=u7Yd22F0NahGUTVHPBYP6z-wkhhOMX3NtWTFnsw@mail.gmail.com>

Hi Margot,
I'm not sure I understand your model, but if I make up some data in
which the response variable is vegetation cover and the three species
are:

A - eats one type of plant
B - eats another type of plant
C - preys on herbivorous insects

df<-read.table(text="field,propveg,A,B,C
 1,1,0,0,1
 2,0.3,1,1,1
 3,0.6,0,1,1
 4,0.2,1,1,1
 5,0.7,1,0,1
 6,0.8,0,0,0
 7,0.3,1,0,0
 8,0.4,0,1,0
 9,0.1,1,1,0
 10,0.5,0,1,0
 11,0.5,1,0,1
 12,0.1,1,1,0
 13,0.6,0,1,1
 14,0,1,1,0",
 sep=",",header=TRUE)
print(summary(lm(propveg~A+B+C+A:B+A:C+B:C,df)))

Is that something like what you want?

Jim

On Fri, May 12, 2017 at 12:40 AM, Margot Neyret <margotneyret at gmail.com> wrote:
> Hello,
>
> I have fields with species mixtures (for instance, species a, b, c, a+b, a+c, b+c), and I look at the effect of each species on a response Y. More specifically, I would like to compare the effect of individual species, either alone or in mixture.
>
>>Y = rnorm(18,0,1)
>>mixture= rep(c('a','b', 'c', 'a+b', 'a+c', 'b+c'), each = 3)
>
> Thus I create variables A, B and C with :
> - A = 1 when the mixture contains a (ie mixture = a or a+b or a+c); and 0 otherwise.
> - Idem for variables C and B.
>
>>A = ifelse(mixture %in% c('a', 'a+b', 'a+c'), 1, 0)
>>B = ifelse(mixture %in% c('b', 'a+b', 'b+c'), 1, 0)
>>C = ifelse(mixture %in% c('c', 'a+c', 'b+c'), 1, 0)
>
> My plan was to build a design matrix from these 3 variables, that would then allow me to compare the effects of each species.
>
>> mm = model.matrix(~A+B+C+0)
>> summary(lm(Y~mm))
> Coefficients:
> Estimate Std. Error t value Pr(>|t|)
> (Intercept) -0.8301 0.6221 -1.334 0.203
> mmA 1.1636 0.4819 2.415 0.030 *
> mmB 0.8452 0.4819 1.754 0.101
> mmC -0.1005 0.4819 -0.208 0.838
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.8347 on 14 degrees of freedom
> Multiple R-squared: 0.4181, Adjusted R-squared: 0.2934
> F-statistic: 3.353 on 3 and 14 DF, p-value: 0.04964
>
> My questions :
> 1. Does this approach make any sense ? I have a feeling I am doing something strange but I cannot put my finger on it.
> 1. My ddl are wrong, I should not have an intercept here, or at least my intercept should be one of my species. Should I just remove one species form the design matrix ?
> 2. Is there any way to do post-hoc tests on my species now, as I would have done with Tukey test or lsmeans ?
>
> My objective afterwards is to add other explanatory variables and interactions in the model.
>
> Thanks in advance !
>
> M. N.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri May 12 02:53:44 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 12 May 2017 10:53:44 +1000
Subject: [R] Design matrix for species mixture
In-Reply-To: <aebafc54-5235-4fd7-aff1-c4717c3b3362@Canary>
References: <aebafc54-5235-4fd7-aff1-c4717c3b3362@Canary>
Message-ID: <CA+8X3fXRgQ=u7Yd22F0NahGUTVHPBYP6z-wkhhOMX3NtWTFnsw@mail.gmail.com>

Hi Margot,
I'm not sure I understand your model, but if I make up some data in
which the response variable is vegetation cover and the three species
are:

A - eats one type of plant
B - eats another type of plant
C - preys on herbivorous insects

df<-read.table(text="field,propveg,A,B,C
 1,1,0,0,1
 2,0.3,1,1,1
 3,0.6,0,1,1
 4,0.2,1,1,1
 5,0.7,1,0,1
 6,0.8,0,0,0
 7,0.3,1,0,0
 8,0.4,0,1,0
 9,0.1,1,1,0
 10,0.5,0,1,0
 11,0.5,1,0,1
 12,0.1,1,1,0
 13,0.6,0,1,1
 14,0,1,1,0",
 sep=",",header=TRUE)
print(summary(lm(propveg~A+B+C+A:B+A:C+B:C,df)))

Is that something like what you want?

Jim

On Fri, May 12, 2017 at 12:40 AM, Margot Neyret <margotneyret at gmail.com> wrote:
> Hello,
>
> I have fields with species mixtures (for instance, species a, b, c, a+b, a+c, b+c), and I look at the effect of each species on a response Y. More specifically, I would like to compare the effect of individual species, either alone or in mixture.
>
>>Y = rnorm(18,0,1)
>>mixture= rep(c('a','b', 'c', 'a+b', 'a+c', 'b+c'), each = 3)
>
> Thus I create variables A, B and C with :
> - A = 1 when the mixture contains a (ie mixture = a or a+b or a+c); and 0 otherwise.
> - Idem for variables C and B.
>
>>A = ifelse(mixture %in% c('a', 'a+b', 'a+c'), 1, 0)
>>B = ifelse(mixture %in% c('b', 'a+b', 'b+c'), 1, 0)
>>C = ifelse(mixture %in% c('c', 'a+c', 'b+c'), 1, 0)
>
> My plan was to build a design matrix from these 3 variables, that would then allow me to compare the effects of each species.
>
>> mm = model.matrix(~A+B+C+0)
>> summary(lm(Y~mm))
> Coefficients:
> Estimate Std. Error t value Pr(>|t|)
> (Intercept) -0.8301 0.6221 -1.334 0.203
> mmA 1.1636 0.4819 2.415 0.030 *
> mmB 0.8452 0.4819 1.754 0.101
> mmC -0.1005 0.4819 -0.208 0.838
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.8347 on 14 degrees of freedom
> Multiple R-squared: 0.4181, Adjusted R-squared: 0.2934
> F-statistic: 3.353 on 3 and 14 DF, p-value: 0.04964
>
> My questions :
> 1. Does this approach make any sense ? I have a feeling I am doing something strange but I cannot put my finger on it.
> 1. My ddl are wrong, I should not have an intercept here, or at least my intercept should be one of my species. Should I just remove one species form the design matrix ?
> 2. Is there any way to do post-hoc tests on my species now, as I would have done with Tukey test or lsmeans ?
>
> My objective afterwards is to add other explanatory variables and interactions in the model.
>
> Thanks in advance !
>
> M. N.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri May 12 03:14:54 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 12 May 2017 11:14:54 +1000
Subject: [R] Matched Items in rows + issue with writing a table
In-Reply-To: <CY4PR15MB1302882B8DED436735654C3FEFED0@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB1302882B8DED436735654C3FEFED0@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <CA+8X3fUKbA_nZQgUMAB5hjT6MQwBzBiVOwqBqjouYj7q1fqJQQ@mail.gmail.com>

Hi abo,
I think you want to split your strings and do your matching like this:

x444<-read.table(text="w r
 cyp3,cyp7 cyp2,cyp1,cyp3
 cyp2 cyp2
 c1,c3,c6 c6,c8,c5",
 header=TRUE,stringsAsFactors=FALSE)
findMatches<-function(x,sep=",") {
 matchval<-NA
 x1bits<-unlist(strsplit(x[1],sep))
 x2bits<-unlist(strsplit(x[2],sep))
 matches<-x1bits %in% x2bits
 if(any(matches)) matchval<-x1bits[which(matches)]
 return(matchval)
}
x444$matched_items<-apply(x444,1,findMatches)

Note that this will only work with character values, _not_ factors.

Jim

On Fri, May 12, 2017 at 9:16 AM, abo dalash <abo_dlsh at hotmail.com> wrote:
> Hi All ..,
>
>
> I have a table called "x444" and I would like to create a new column contains the matched items in each row between column w & r . I used match()function as below but this does not return the results I want because of 2 issues. The 1st one is that this gives the row number of shared items while I want to see the item itself (e.g. in the table below, I want to see cyp2 instead of the row number 2). The 2nd issue is that I need to know matched items considering every item in the row instead of the entire row. For example, the item cyp3 is a matched item in the first row between columns w & r. The same applies for c6 in row 3. These don't appear in the results below.
>
>
>
>>x444
>                w         r
> 1 cyp3,cyp7     cyp2, cyp1,cyp3
> 2         cyp2      cyp2
> 3   c1,c3,c6       c6,c8,c5
>
>
>> r = c(match(x444$w,X444$r))
>> r
> [1] NA  2 NA
>
>
>
> The desired output should be like this :-
>
>                 w             r                             matched items
> 1 cyp3,cyp7     cyp2, cyp1,cyp3             cyp3
> 2         cyp2      cyp2                                  cyp2
> 3   c1,c3,c6       c6,c8,c5                          c6
>
>
> The second issue is that when I write a table produced in R as follows :
>
> write.table(MyTable,file="MyTable.txt", sep = "\t", quote = F, row.names = F)
>
> and the read this txt. file in excel, some items from column B appears in Column A and some empty rows also appear?.
>
> Could you please guide me about the mistakes I have done and suggest
> some solutions?
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri May 12 03:59:29 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 11 May 2017 20:59:29 -0500
Subject: [R] How to plot a legend centered only on the x axis
In-Reply-To: <2521b5b6-a841-0c10-7681-014a5305516d@gmail.com>
References: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
 <2521b5b6-a841-0c10-7681-014a5305516d@gmail.com>
Message-ID: <49CF457C-6C7B-4262-BC92-AEEA722BB98F@me.com>


> On May 11, 2017, at 7:01 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 11/05/2017 2:36 PM, Antonio Silva wrote:
>> Hello r-users
>> 
>> I want to plot some barplots inside a looping with the legend placed
>> outside the plotting area.
>> 
>> No matter the number of bars I want the legend to be placed centered on the
>> x-axis.
>> 
>> See the example below
>> 
>> for(i in 1:10) {
>> var_1 <- sample(1000:100000,sample(3:8,1))
>> ymax <- max(var_1)
>> b<-barplot(var_1,col="blue")
>> var_2 <- sample(1000:ymax,length(var_1))
>> lines(rowSums(b),var_2,type="o",col="red",pch=16)
>> par(xpd=TRUE)
>> legend(*1.1*
>> ,ymax*-0.072,c("var_1","var_2"),horiz=T,cex=1.3,bty="n",pch=c(15,16),col=c("blue","red"),lty=c(0,1),lwd=c(0,2),pt.cex=2)
>> readline(prompt="Press [enter] to continue")
>> }
>> 
>> What I should use as x position in legend(x,y, ...), instead of *1.1*, to
>> have the legend centered on the x-axis?
>> 
>> I would love to use something like legend(x="center",y=ymax*-0.072, ... but
>> it did not worked.
>> 
>> I appreciate any suggestions. Best regards.
> 
> Instead of "center", use "top" or "bottom".  See the 2nd last example in examples(legend) for the possibilities.
> 
> If you want the legend outside the plotting area, set "inset" and "xpd" arguments.  For example,
> 
> plot(1,1)
> legend("top", pch = 1, legend = "point", inset = -0.1, xpd = TRUE)
> 
> 
> Duncan Murdoch


Bingo.

The 'inset' argument is what I was missing. That allows this to be done with one step, rather than the two that I had.

Thanks Duncan.

Marc


From tan_afreebird at yahoo.com  Fri May 12 04:10:57 2017
From: tan_afreebird at yahoo.com (M. Rajib Hassan Mozumder)
Date: Thu, 11 May 2017 22:10:57 -0400
Subject: [R] block kriging the entire area
Message-ID: <FE42CD00-7323-4E37-B83F-2CBB4ABB26FE@yahoo.com>

Hi Edzer-
Is it possible to block krige the entire area with "TransGaussian Kriging Using Box-Cox Transforms? (i.e. krigeTg)? Also, I have seen in the argument section: ?block: does not function correctly, afaik? for krigeTg. But when I used the ?block? argument it gave me reliable results for individual blocks (Because I matched it with a different method). Thanks for confirming. -Raj

From margotneyret at gmail.com  Fri May 12 10:20:47 2017
From: margotneyret at gmail.com (Margot Neyret)
Date: Fri, 12 May 2017 10:20:47 +0200
Subject: [R] Design matrix for species mixture
In-Reply-To: <CA+8X3fXRgQ=u7Yd22F0NahGUTVHPBYP6z-wkhhOMX3NtWTFnsw@mail.gmail.com>
References: <1771>
 <CA+8X3fXRgQ=u7Yd22F0NahGUTVHPBYP6z-wkhhOMX3NtWTFnsw@mail.gmail.com>
Message-ID: <f81bc8c0-7ee0-4347-b8e9-3b915be1c7bd@Canary>

Hi Jim,

Sorry if my question was not clear. I will try to explain again?

I have one response variable Y, let?s say vegetation cover. Then I have my explanatory variable, let?s call it Crop. In my field I can have either Maize (m), Bean (b), Pumpkin (p) or mixtures : m+b, m+p, b+p, m+b+p. I also have a second explanatory variable X (e.g. soil moisture content).

So for now my variable Crop has 7 levels [m, p, b, mp, mb, pb, mpb]. If I want to compare Y between these crops, I write :
summary(lm(Y~Crop))
TukeyHSD(aov(Y~Crop))

And with X :
summary(lm(Y~Crop*X))
? etc.

Then I want to compare the effect of each individual crop. I can do as you suggested Jim : 3 variables M, B, P with values 0 or 1 if the crop is present, 0 otherwise and add interactions.
summary(lm(Y~M+B+P+M*P+?))

But here come my questions. This model seems to have 2 drawbacks.
1. How can I do pairwise comparisons here as I would do with Turkey test ? How can test the hypothesis, for instance, ?Bean provides higher cover than Maize whatever the mixture is? ?
2. When it comes to interactions with other variables it gets quite complicated (also note that in real life I have 5 crops, not 3 and other explanatory variables) :
lm(Y~M*X+ B*X + P*X + M*B + M*P + P*B)

So, isn?t there a way to make it more concise ?

I hope it makes sens.

Thanks,
Margot

> On Friday, May 12, 2017 at 2:53 AM, Jim Lemon <drjimlemon at gmail.com (mailto:drjimlemon at gmail.com)> wrote:
> Hi Margot,
> I'm not sure I understand your model, but if I make up some data in
> which the response variable is vegetation cover and the three species
> are:
>
> A - eats one type of plant
> B - eats another type of plant
> C - preys on herbivorous insects
>
> df<-read.table(text="field,propveg,A,B,C
> 1,1,0,0,1
> 2,0.3,1,1,1
> 3,0.6,0,1,1
> 4,0.2,1,1,1
> 5,0.7,1,0,1
> 6,0.8,0,0,0
> 7,0.3,1,0,0
> 8,0.4,0,1,0
> 9,0.1,1,1,0
> 10,0.5,0,1,0
> 11,0.5,1,0,1
> 12,0.1,1,1,0
> 13,0.6,0,1,1
> 14,0,1,1,0",
> sep=",",header=TRUE)
> print(summary(lm(propveg~A+B+C+A:B+A:C+B:C,df)))
>
> Is that something like what you want?
>
> Jim
>
> On Fri, May 12, 2017 at 12:40 AM, Margot Neyret <margotneyret at gmail.com> wrote:
> > Hello,
> >
> > I have fields with species mixtures (for instance, species a, b, c, a+b, a+c, b+c), and I look at the effect of each species on a response Y. More specifically, I would like to compare the effect of individual species, either alone or in mixture.
> >
> > > Y = rnorm(18,0,1)
> > > mixture= rep(c('a','b', 'c', 'a+b', 'a+c', 'b+c'), each = 3)
> >
> > Thus I create variables A, B and C with :
> > - A = 1 when the mixture contains a (ie mixture = a or a+b or a+c); and 0 otherwise.
> > - Idem for variables C and B.
> >
> > > A = ifelse(mixture %in% c('a', 'a+b', 'a+c'), 1, 0)
> > > B = ifelse(mixture %in% c('b', 'a+b', 'b+c'), 1, 0)
> > > C = ifelse(mixture %in% c('c', 'a+c', 'b+c'), 1, 0)
> >
> > My plan was to build a design matrix from these 3 variables, that would then allow me to compare the effects of each species.
> >
> > > mm = model.matrix(~A+B+C+0)
> > > summary(lm(Y~mm))
> > Coefficients:
> > Estimate Std. Error t value Pr(>|t|)
> > (Intercept) -0.8301 0.6221 -1.334 0.203
> > mmA 1.1636 0.4819 2.415 0.030 *
> > mmB 0.8452 0.4819 1.754 0.101
> > mmC -0.1005 0.4819 -0.208 0.838
> > ---
> > Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Residual standard error: 0.8347 on 14 degrees of freedom
> > Multiple R-squared: 0.4181, Adjusted R-squared: 0.2934
> > F-statistic: 3.353 on 3 and 14 DF, p-value: 0.04964
> >
> > My questions :
> > 1. Does this approach make any sense ? I have a feeling I am doing something strange but I cannot put my finger on it.
> > 1. My ddl are wrong, I should not have an intercept here, or at least my intercept should be one of my species. Should I just remove one species form the design matrix ?
> > 2. Is there any way to do post-hoc tests on my species now, as I would have done with Tukey test or lsmeans ?
> >
> > My objective afterwards is to add other explanatory variables and interactions in the model.
> >
> > Thanks in advance !
> >
> > M. N.
> >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri May 12 11:18:35 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 12 May 2017 19:18:35 +1000
Subject: [R] Design matrix for species mixture
In-Reply-To: <f81bc8c0-7ee0-4347-b8e9-3b915be1c7bd@Canary>
References: <CA+8X3fXRgQ=u7Yd22F0NahGUTVHPBYP6z-wkhhOMX3NtWTFnsw@mail.gmail.com>
 <f81bc8c0-7ee0-4347-b8e9-3b915be1c7bd@Canary>
Message-ID: <CA+8X3fXUZDmbXNCxTYTRgEjKH1v_9XNo2n6Spo=ZdyTQXSDkjA@mail.gmail.com>

Hi Margot,
Very messy, like nature. One way is to do tests with dummy variables
that compare:

beans+anything vs anything without beans
maize+anything vs anything without maize
pumpkin+anything vs anything without pumpkin

Then if you find that the "beans" comparison has the strongest effect,
perhaps because beans are nitrogen fixers, you could do successive
comparisons of the bean +anything mixtures. It really depends upon
what your a priori hypothesis is. You'll need a bit of statistical
power to get reliable, or any, results.

Jim


On Fri, May 12, 2017 at 6:20 PM, Margot Neyret <margotneyret at gmail.com> wrote:
> Hi Jim,
>
> Sorry if my question was not clear. I will try to explain again?
>
> I have one response variable Y, let?s say vegetation cover. Then I have my
> explanatory variable, let?s call it Crop. In my field I can have either
> Maize (m), Bean (b), Pumpkin (p) or mixtures : m+b, m+p, b+p, m+b+p. I also
> have a second explanatory variable X (e.g. soil moisture content).
>
> So for now my variable Crop has 7 levels [m, p, b, mp, mb, pb, mpb]. If I
> want to compare Y between these crops, I write :
> summary(lm(Y~Crop))
> TukeyHSD(aov(Y~Crop))
>
> And with X :
> summary(lm(Y~Crop*X))
>         ? etc.
>
>
> Then I want to compare the effect of each individual crop. I can do as you
> suggested Jim : 3 variables M, B, P with values 0 or 1 if the crop is
> present, 0 otherwise and add interactions.
> summary(lm(Y~M+B+P+M*P+?))
>
> But here come my questions. This model seems to have 2 drawbacks.
> 1. How can I do pairwise comparisons here as I would do with Turkey test ?
> How can test the hypothesis, for instance, ?Bean provides higher cover than
> Maize whatever the mixture is? ?
> 2. When it comes to interactions with other variables it gets quite
> complicated (also note that in real life I have 5 crops, not 3 and other
> explanatory variables) :
> lm(Y~M*X+ B*X + P*X + M*B + M*P + P*B)
>
> So, isn?t there a way to make it more concise ?
>
> I hope it makes sens.
>
> Thanks,
> Margot
>
>
> On Friday, May 12, 2017 at 2:53 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Margot,
> I'm not sure I understand your model, but if I make up some data in
> which the response variable is vegetation cover and the three species
> are:
>
> A - eats one type of plant
> B - eats another type of plant
> C - preys on herbivorous insects
>
> df<-read.table(text="field,propveg,A,B,C
> 1,1,0,0,1
> 2,0.3,1,1,1
> 3,0.6,0,1,1
> 4,0.2,1,1,1
> 5,0.7,1,0,1
> 6,0.8,0,0,0
> 7,0.3,1,0,0
> 8,0.4,0,1,0
> 9,0.1,1,1,0
> 10,0.5,0,1,0
> 11,0.5,1,0,1
> 12,0.1,1,1,0
> 13,0.6,0,1,1
> 14,0,1,1,0",
> sep=",",header=TRUE)
> print(summary(lm(propveg~A+B+C+A:B+A:C+B:C,df)))
>
> Is that something like what you want?
>
> Jim
>
> On Fri, May 12, 2017 at 12:40 AM, Margot Neyret <margotneyret at gmail.com>
> wrote:
>
> Hello,
>
> I have fields with species mixtures (for instance, species a, b, c, a+b,
> a+c, b+c), and I look at the effect of each species on a response Y. More
> specifically, I would like to compare the effect of individual species,
> either alone or in mixture.
>
> Y = rnorm(18,0,1)
> mixture= rep(c('a','b', 'c', 'a+b', 'a+c', 'b+c'), each = 3)
>
>
> Thus I create variables A, B and C with :
> - A = 1 when the mixture contains a (ie mixture = a or a+b or a+c); and 0
> otherwise.
> - Idem for variables C and B.
>
> A = ifelse(mixture %in% c('a', 'a+b', 'a+c'), 1, 0)
> B = ifelse(mixture %in% c('b', 'a+b', 'b+c'), 1, 0)
> C = ifelse(mixture %in% c('c', 'a+c', 'b+c'), 1, 0)
>
>
> My plan was to build a design matrix from these 3 variables, that would then
> allow me to compare the effects of each species.
>
> mm = model.matrix(~A+B+C+0)
> summary(lm(Y~mm))
>
> Coefficients:
> Estimate Std. Error t value Pr(>|t|)
> (Intercept) -0.8301 0.6221 -1.334 0.203
> mmA 1.1636 0.4819 2.415 0.030 *
> mmB 0.8452 0.4819 1.754 0.101
> mmC -0.1005 0.4819 -0.208 0.838
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.8347 on 14 degrees of freedom
> Multiple R-squared: 0.4181, Adjusted R-squared: 0.2934
> F-statistic: 3.353 on 3 and 14 DF, p-value: 0.04964
>
> My questions :
> 1. Does this approach make any sense ? I have a feeling I am doing something
> strange but I cannot put my finger on it.
> 1. My ddl are wrong, I should not have an intercept here, or at least my
> intercept should be one of my species. Should I just remove one species form
> the design matrix ?
> 2. Is there any way to do post-hoc tests on my species now, as I would have
> done with Tukey test or lsmeans ?
>
> My objective afterwards is to add other explanatory variables and
> interactions in the model.
>
> Thanks in advance !
>
> M. N.
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri May 12 12:17:14 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 May 2017 03:17:14 -0700
Subject: [R] Design matrix for species mixture
In-Reply-To: <f81bc8c0-7ee0-4347-b8e9-3b915be1c7bd@Canary>
References: <CA+8X3fXRgQ=u7Yd22F0NahGUTVHPBYP6z-wkhhOMX3NtWTFnsw@mail.gmail.com>
 <f81bc8c0-7ee0-4347-b8e9-3b915be1c7bd@Canary>
Message-ID: <CAGxFJbQocGiyB6-WwLP4RoTukyJymbvJi3ro10FQPjjNr3mAyA@mail.gmail.com>

Please take this thread elsewhere(e.g. Stats.stackexchange.com) as it is
largely about statistics and is therefore offtopic here (this list is about
R programming).

Cheers,
Bert


On May 12, 2017 1:21 AM, "Margot Neyret" <margotneyret at gmail.com> wrote:

Hi Jim,

Sorry if my question was not clear. I will try to explain again?

I have one response variable Y, let?s say vegetation cover. Then I have my
explanatory variable, let?s call it Crop. In my field I can have either
Maize (m), Bean (b), Pumpkin (p) or mixtures : m+b, m+p, b+p, m+b+p. I also
have a second explanatory variable X (e.g. soil moisture content).

So for now my variable Crop has 7 levels [m, p, b, mp, mb, pb, mpb]. If I
want to compare Y between these crops, I write :
summary(lm(Y~Crop))
TukeyHSD(aov(Y~Crop))

And with X :
summary(lm(Y~Crop*X))
? etc.

Then I want to compare the effect of each individual crop. I can do as you
suggested Jim : 3 variables M, B, P with values 0 or 1 if the crop is
present, 0 otherwise and add interactions.
summary(lm(Y~M+B+P+M*P+?))

But here come my questions. This model seems to have 2 drawbacks.
1. How can I do pairwise comparisons here as I would do with Turkey test ?
How can test the hypothesis, for instance, ?Bean provides higher cover than
Maize whatever the mixture is? ?
2. When it comes to interactions with other variables it gets quite
complicated (also note that in real life I have 5 crops, not 3 and other
explanatory variables) :
lm(Y~M*X+ B*X + P*X + M*B + M*P + P*B)

So, isn?t there a way to make it more concise ?

I hope it makes sens.

Thanks,
Margot

> On Friday, May 12, 2017 at 2:53 AM, Jim Lemon <drjimlemon at gmail.com
(mailto:drjimlemon at gmail.com)> wrote:
> Hi Margot,
> I'm not sure I understand your model, but if I make up some data in
> which the response variable is vegetation cover and the three species
> are:
>
> A - eats one type of plant
> B - eats another type of plant
> C - preys on herbivorous insects
>
> df<-read.table(text="field,propveg,A,B,C
> 1,1,0,0,1
> 2,0.3,1,1,1
> 3,0.6,0,1,1
> 4,0.2,1,1,1
> 5,0.7,1,0,1
> 6,0.8,0,0,0
> 7,0.3,1,0,0
> 8,0.4,0,1,0
> 9,0.1,1,1,0
> 10,0.5,0,1,0
> 11,0.5,1,0,1
> 12,0.1,1,1,0
> 13,0.6,0,1,1
> 14,0,1,1,0",
> sep=",",header=TRUE)
> print(summary(lm(propveg~A+B+C+A:B+A:C+B:C,df)))
>
> Is that something like what you want?
>
> Jim
>
> On Fri, May 12, 2017 at 12:40 AM, Margot Neyret <margotneyret at gmail.com>
wrote:
> > Hello,
> >
> > I have fields with species mixtures (for instance, species a, b, c,
a+b, a+c, b+c), and I look at the effect of each species on a response Y.
More specifically, I would like to compare the effect of individual
species, either alone or in mixture.
> >
> > > Y = rnorm(18,0,1)
> > > mixture= rep(c('a','b', 'c', 'a+b', 'a+c', 'b+c'), each = 3)
> >
> > Thus I create variables A, B and C with :
> > - A = 1 when the mixture contains a (ie mixture = a or a+b or a+c); and
0 otherwise.
> > - Idem for variables C and B.
> >
> > > A = ifelse(mixture %in% c('a', 'a+b', 'a+c'), 1, 0)
> > > B = ifelse(mixture %in% c('b', 'a+b', 'b+c'), 1, 0)
> > > C = ifelse(mixture %in% c('c', 'a+c', 'b+c'), 1, 0)
> >
> > My plan was to build a design matrix from these 3 variables, that would
then allow me to compare the effects of each species.
> >
> > > mm = model.matrix(~A+B+C+0)
> > > summary(lm(Y~mm))
> > Coefficients:
> > Estimate Std. Error t value Pr(>|t|)
> > (Intercept) -0.8301 0.6221 -1.334 0.203
> > mmA 1.1636 0.4819 2.415 0.030 *
> > mmB 0.8452 0.4819 1.754 0.101
> > mmC -0.1005 0.4819 -0.208 0.838
> > ---
> > Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Residual standard error: 0.8347 on 14 degrees of freedom
> > Multiple R-squared: 0.4181, Adjusted R-squared: 0.2934
> > F-statistic: 3.353 on 3 and 14 DF, p-value: 0.04964
> >
> > My questions :
> > 1. Does this approach make any sense ? I have a feeling I am doing
something strange but I cannot put my finger on it.
> > 1. My ddl are wrong, I should not have an intercept here, or at least
my intercept should be one of my species. Should I just remove one species
form the design matrix ?
> > 2. Is there any way to do post-hoc tests on my species now, as I would
have done with Tukey test or lsmeans ?
> >
> > My objective afterwards is to add other explanatory variables and
interactions in the model.
> >
> > Thanks in advance !
> >
> > M. N.
> >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Fri May 12 15:35:00 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Fri, 12 May 2017 16:35:00 +0300
Subject: [R] visualization of KNN results in text classification
In-Reply-To: <985810624.2404408.1494592227590@mail.yahoo.com>
References: <985810624.2404408.1494592227590.ref@mail.yahoo.com>
 <985810624.2404408.1494592227590@mail.yahoo.com>
Message-ID: <67BCB909-F5EB-475F-8225-EDD49F988920@gmail.com>


> On 12 May 2017, at 15:30, Elahe chalabi <chalabi.elahe at yahoo.de> wrote:
> 
> 
> 
> Thanks for your reply. What I exactly have is a data frame with rows containing words which have been used in each speech and columns containing frequency of these words, I have an extra row showing the type of the speech whether it was from a control group or Alzheimer group. Then I create a training and test set for KNN from this data frame and by KNN I classify the speeches which assigns every speech (actually text of the speech!) to the correct type of group, if it's from control group or Alzheimer group. 
> Now my question is how can I visualize my KNN classifier or its results? cause now I only have an accuracy matrix from KNN!
> 
> Thanks for any help!
> Elahe 


It would be very helpful if you create a minimal example to understand your data and what you have done with. Yes, you explained your data by your words but it?s still unclear. So, I created a minimal example instead of you.

For simplicity, I have a data.frame with 3 columns. First 2 are numeric and last one is factor. Group column is my real classes. A and B columns are some kind a numeric representation of these classes. Let?s call them features. Because they have hidden information represent a class. I use 30% of data for training and 70% for test. 

This is the point you asked for. After classification, I have a test.guess.cluster (factor) variable and it contains predicted clusters by knn method (you said that accuracy matrix from KNN, I don?t know what it is). Now, I want to see the clusters on a plot. That?s why, I converted ?test.guess.cluster? variable to numeric, so I can use it to colorise the points on the plot. I plotted points in test.df data.frame (A versus B) and coloured them by predicted class.

At the end, I evaluated the overall performance of the knn model. Is it good or bad? Please note that you have to choose your own _k_ value and size of training dataset by trial and error.


library(class)
library(gmodels)
set.seed(6)
df <- data.frame(A = c(rnorm(30, 0), rnorm(30, 3)),
                 B = c(rnorm(30, 0), rnorm(30, 3)),
                 Group = factor(c(rep("G1", 30), rep("G2", 30))))
# use 33% of data for training and 67% is for test
i <- sample(2, nrow(df), replace = TRUE, prob = c(0.67, 0.33))
train.df <- df[i == 2, -3] # do not include last column
train.cl <- df[i == 2, 3] # training result cluters
test.df <- df[i == 1, -3] # test data.frame
test.real.cluster <- df[i == 1, 3] # real clusters for test
# predicted clusters by knn
test.guess.cluster <- knn(train = train.df, test = test.df, cl = train.cl, k = 3)
# convert them to muneric to colorize points on the plot
test.guess.cluster.num <- as.numeric(test.guess.cluster)
plot(test.df, col = test.guess.cluster.num, pch = test.guess.cluster.num)

# examine the result of CrossTable
# The model identified 2 G1 classes as G2 and 1 G2 class as G1.
# Hence, 3 elements are misclassified. (you can distinguish them on the plot)
gm <- gmodels::CrossTable(test.guess.cluster, test.real.cluster, prop.chisq = FALSE)
sum(diag(gm$prop.tbl)) # overall success of the model (34 - 3)/34




> 
> 
> On Monday, May 8, 2017 3:55 PM, Ismail SEZEN <sezenismail at gmail.com> wrote:
> 
> 
> 
> As far as I know, kNN groups by Eucledian distance. So, you need numerical data as input. You said your dataset has only ?speeches? and ?type of people?. Are these input? or one of them is input and the latter one is output? Type of people should be a factor variable (I guess). I don?t know how you represent ?speech? in your dataset. As character or numerical representation of a feature? If you send a minimal example of the problem, we can help you. Please, read posting guide.
> 
> 
> 
>> ______________________________________________
> 
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> 
>> https://stat.ethz.ch/mailman/listinfo/r-help
> 
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> 
>> and provide commented, minimal, self-contained, reproducible code.


From aolinto.lst at gmail.com  Fri May 12 16:14:54 2017
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Fri, 12 May 2017 11:14:54 -0300
Subject: [R] How to plot a legend centered only on the x axis
In-Reply-To: <49CF457C-6C7B-4262-BC92-AEEA722BB98F@me.com>
References: <CAE8g1gMQyQm1n992zR-amZgfn3YCjrsZcU=b9tPEgnA_UwZagg@mail.gmail.com>
 <2521b5b6-a841-0c10-7681-014a5305516d@gmail.com>
 <49CF457C-6C7B-4262-BC92-AEEA722BB98F@me.com>
Message-ID: <CAE8g1gPddHEVxktwsrvYhRZxywOyUumzywEQ_M2QtY_qA4XqDg@mail.gmail.com>

Thanks a lot Duncan, Jim and Marc!

2017-05-11 22:59 GMT-03:00 Marc Schwartz <marc_schwartz at me.com>:

>
> Bingo.
>
> The 'inset' argument is what I was missing. That allows this to be done
> with one step, rather than the two that I had.
>
> Thanks Duncan.
>
> Mar

	[[alternative HTML version deleted]]


From s3tochri at uni-bayreuth.de  Fri May 12 16:40:49 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Fri, 12 May 2017 16:40:49 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>

Hey guys,

thanks a lot for your tips. The regression is finally running. As you 
said, I had to integrate the column "year" in the function "time" in R.

So I used the following formula: *plm(log(revenue) ~ log(supply) + 
factor(town)*time(year), data=R_Test_log_Neu)*

So I have now sucessfully added a linear trend to my regression model? 
Another question that concernes me is how to add a quadratic trend 
instead of a linear trend. Can I just square the column "year"?

Enjoy your weekend,

Toby

_My results see below:_

Balanced Panel: n=11, T=12, N=132

Residuals :
     Min.  1st Qu.   Median  3rd Qu.     Max.
-0.09610 -0.02370 -0.00152  0.01980  0.14000

Coefficients :
                             Estimate Std. Error t-value  Pr(>|t|)
log(supply)               -0.0080702  0.0133675 -0.6037  0.547411
factor(town)2:time(year)  -0.0063245  0.0053744 -1.1768  0.242100
factor(town)3:time(year)   0.0295522  0.0056776  5.2050 1.053e-06 ***
factor(town)4:time(year)   0.0062191  0.0054152  1.1485  0.253549
factor(town)5:time(year)   0.0159028  0.0054954  2.8939  0.004681 **
factor(town)6:time(year)   0.0237112  0.0055395  4.2804 4.316e-05 ***
factor(town)7:time(year)   0.0410007  0.0055734  7.3565 5.576e-11 ***
factor(town)8:time(year)   0.0239085  0.0053751  4.4480 2.271e-05 ***
factor(town)9:time(year)   0.0242342  0.0056855  4.2625 4.619e-05 ***
factor(town)10:time(year)  0.0105890  0.0053302  1.9866  0.049733 *
factor(town)11:time(year)  0.0095270  0.0056354  1.6906  0.094065 .
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Total Sum of Squares:    0.46388
Residual Sum of Squares: 0.2001
R-Squared:      0.56863
Adj. R-Squared: 0.4292
F-statistic: 11.8637 on 11 and 99 DF, p-value: 7.3065e-14



Am 11.05.2017 um 23:17 schrieb David L Carlson:
> What Rui said, but as important, you have four columns in your data called "town", "year", "revenue", and "supply". You do not have a column called "time".
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
> Sent: Thursday, May 11, 2017 3:36 PM
> To: Tobias Christoph <s3tochri at uni-bayreuth.de>; Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
> Subject: Re: [R] Error: invalid type (closure) for the variable 'time' - object specific trend
>
> Hello,
>
> A closure is, like you say, a function.
> At an R prompt try:
>
>   > typeof(time)
> [1] "closure"
>
> So like Duncan suggested rename 'time', for instance capitalize it
> 'Time'. That should do it.
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Em 11-05-2017 21:20, Tobias Christoph escreveu:
>> Hey Duncan,
>>
>> thank you very much for your quick reply.
>>
>> _My data used:_
>>
>> 1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11
>>
>> 2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12
>>
>> 3rd column (revenue):
>>
>> 4th colum (supply):
>>
>> I have now renamed my colums and did the regression again. Now there is
>> a problem with R-squared, as it is the sum of 1 now with no given std.
>> error and t-value. This is probably due to the fact, that I try to
>> estimate more parameters than data.
>>
>> To add a linear trend I found the following formular:*lm(y ~ x1 +
>> factor(ccode)*time, data=df)*
>>
>> I try to I decode it for and use it for my regression: *plm(log(revenue)
>> ~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*
>>
>> When I do this regression I will get the original error: "invalid type
>> (closure) for the variable 'time' - object specific trend"
>>
>> With the notation"time" not my colum is meant, but probably the command
>> "time" in R.
>>
>> Can you follow my thoughts?
>>
>> Tobi
>>
>>
>>
>>
>>
>>
>> Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
>>> Duncan Murdoch
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From tsvibar at gmail.com  Fri May 12 16:57:34 2017
From: tsvibar at gmail.com (Micha Silver)
Date: Fri, 12 May 2017 17:57:34 +0300
Subject: [R] apply and cor()
Message-ID: <a783fa74-c1e6-8d74-eb79-f9e7bd434a9d@gmail.com>

I have two data.frames, one with a single row of 31 columns, and the 
second with 269 rows and the same 31 columns.
 > dim(compare_data)
[1] 269  31
 > dim(test_data)
[1]  1 31

I want to apply cor() between the one row of 'test_data', and each row 
of the 'compare_data' .
I tried 'apply' but I get this error:
 > apply(compare_data, 1, function(r) {cor(compare_data[r,], test_data)})
  Error in cor(compare_data[r, ], test_data) : incompatible dimensions


In order to try to understand I did:
 > dims <- apply(compare_data, 1, function(r) {dim(compare_data[r,])})
 > head(dims)
      20 73 103 118 130 142 151 154 191 205 217 222 227 232 240 275 282 
301 320 359 360 551 589 653 789 801 808 812
[1,]  9  8   8   9   5   9   8  11   6  15  12  13  10   7   9  14 8  
11   9  11  11  12   9  14   5   8   9  10
[2,] 31 31  31  31  31  31  31  31  31  31  31  31  31  31  31  31 31  
31  31  31  31  31  31  31  31  31  31  31
      840 856 857 867 885 970 983 985 1103 1107 1197 1207 1237 1262 1279 
1282 1332 1357 1358 1392 1411 1435 1458 1473
[1,]  14  11  12   8  10   2   7   9   10    8   10   13   11 7    9   
12   11   11   16   10   10   12   10   10
[2,]  31  31  31  31  31  31  31  31   31   31   31   31   31   31 31   
31   31   31   31   31   31   31   31   31

and indeed I am getting different row dimensions. I expected "1 31" for 
each. What are the values 9,8,8,9,5... in the [1,] dimension?

If I test the compare_data data.frame one row at a time:
 > dim(compare_data['20',])
[1]  1 31
 > dim(compare_data['1473',])
[1]  1 31

It looks as I expected.
What am I missing??

Thanks

-- 
Micha Silver
cell: +972-523-665918


From sezenismail at gmail.com  Fri May 12 17:10:32 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Fri, 12 May 2017 18:10:32 +0300
Subject: [R] apply and cor()
In-Reply-To: <a783fa74-c1e6-8d74-eb79-f9e7bd434a9d@gmail.com>
References: <a783fa74-c1e6-8d74-eb79-f9e7bd434a9d@gmail.com>
Message-ID: <8EF69165-86AE-4117-8932-4561582D2BEA@gmail.com>


> On 12 May 2017, at 17:57, Micha Silver <tsvibar at gmail.com> wrote:
> 
> I have two data.frames, one with a single row of 31 columns, and the second with 269 rows and the same 31 columns.
> > dim(compare_data)
> [1] 269  31
> > dim(test_data)
> [1]  1 31
> 
> I want to apply cor() between the one row of 'test_data', and each row of the 'compare_data' .
> I tried 'apply' but I get this error:
> > apply(compare_data, 1, function(r) {cor(compare_data[r,], test_data)})
> Error in cor(compare_data[r, ], test_data) : incompatible dimensions


apply(compare_data, 1, function(r) {cor(compare_data[r,], as.numeric(test_data))})

See ?cor. Explanation of y is "NULL (default) or a vector, matrix or data frame with compatible dimensions to x?.

> 
> 
> In order to try to understand I did:
> > dims <- apply(compare_data, 1, function(r) {dim(compare_data[r,])})
> > head(dims)
>     20 73 103 118 130 142 151 154 191 205 217 222 227 232 240 275 282 301 320 359 360 551 589 653 789 801 808 812
> [1,]  9  8   8   9   5   9   8  11   6  15  12  13  10   7   9  14 8  11   9  11  11  12   9  14   5   8   9  10
> [2,] 31 31  31  31  31  31  31  31  31  31  31  31  31  31  31  31 31  31  31  31  31  31  31  31  31  31  31  31
>     840 856 857 867 885 970 983 985 1103 1107 1197 1207 1237 1262 1279 1282 1332 1357 1358 1392 1411 1435 1458 1473
> [1,]  14  11  12   8  10   2   7   9   10    8   10   13   11 7    9   12   11   11   16   10   10   12   10   10
> [2,]  31  31  31  31  31  31  31  31   31   31   31   31   31   31 31   31   31   31   31   31   31   31   31   31
> 
> and indeed I am getting different row dimensions. I expected "1 31" for each. What are the values 9,8,8,9,5... in the [1,] dimension?
> 
> If I test the compare_data data.frame one row at a time:
> > dim(compare_data['20',])
> [1]  1 31
> > dim(compare_data['1473',])
> [1]  1 31
> 
> It looks as I expected.
> What am I missing??
> 
> Thanks
> 
> -- 
> Micha Silver
> cell: +972-523-665918
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri May 12 17:47:41 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 12 May 2017 15:47:41 +0000
Subject: [R] apply and cor()
In-Reply-To: <8EF69165-86AE-4117-8932-4561582D2BEA@gmail.com>
References: <a783fa74-c1e6-8d74-eb79-f9e7bd434a9d@gmail.com>
 <8EF69165-86AE-4117-8932-4561582D2BEA@gmail.com>
Message-ID: <d2597188ff0542c9913205d4070230cf@exch-2p-mbx-w2.ads.tamu.edu>

Actually, r is a vector, not an index value. You need

apply(compare_data, 1, function(r) cor(r, t(test_data)))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ismail SEZEN
Sent: Friday, May 12, 2017 10:11 AM
To: Micha Silver <tsvibar at gmail.com>
Cc: R-help at r-project.org
Subject: Re: [R] apply and cor()


> On 12 May 2017, at 17:57, Micha Silver <tsvibar at gmail.com> wrote:
> 
> I have two data.frames, one with a single row of 31 columns, and the second with 269 rows and the same 31 columns.
> > dim(compare_data)
> [1] 269  31
> > dim(test_data)
> [1]  1 31
> 
> I want to apply cor() between the one row of 'test_data', and each row of the 'compare_data' .
> I tried 'apply' but I get this error:
> > apply(compare_data, 1, function(r) {cor(compare_data[r,], test_data)})
> Error in cor(compare_data[r, ], test_data) : incompatible dimensions


apply(compare_data, 1, function(r) {cor(compare_data[r,], as.numeric(test_data))})

See ?cor. Explanation of y is "NULL (default) or a vector, matrix or data frame with compatible dimensions to x?.

> 
> 
> In order to try to understand I did:
> > dims <- apply(compare_data, 1, function(r) {dim(compare_data[r,])})
> > head(dims)
>     20 73 103 118 130 142 151 154 191 205 217 222 227 232 240 275 282 301 320 359 360 551 589 653 789 801 808 812
> [1,]  9  8   8   9   5   9   8  11   6  15  12  13  10   7   9  14 8  11   9  11  11  12   9  14   5   8   9  10
> [2,] 31 31  31  31  31  31  31  31  31  31  31  31  31  31  31  31 31  31  31  31  31  31  31  31  31  31  31  31
>     840 856 857 867 885 970 983 985 1103 1107 1197 1207 1237 1262 1279 1282 1332 1357 1358 1392 1411 1435 1458 1473
> [1,]  14  11  12   8  10   2   7   9   10    8   10   13   11 7    9   12   11   11   16   10   10   12   10   10
> [2,]  31  31  31  31  31  31  31  31   31   31   31   31   31   31 31   31   31   31   31   31   31   31   31   31
> 
> and indeed I am getting different row dimensions. I expected "1 31" for each. What are the values 9,8,8,9,5... in the [1,] dimension?
> 
> If I test the compare_data data.frame one row at a time:
> > dim(compare_data['20',])
> [1]  1 31
> > dim(compare_data['1473',])
> [1]  1 31
> 
> It looks as I expected.
> What am I missing??
> 
> Thanks
> 
> -- 
> Micha Silver
> cell: +972-523-665918
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dcarlson at tamu.edu  Fri May 12 17:53:23 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 12 May 2017 15:53:23 +0000
Subject: [R] apply and cor()
In-Reply-To: <d2597188ff0542c9913205d4070230cf@exch-2p-mbx-w2.ads.tamu.edu>
References: <a783fa74-c1e6-8d74-eb79-f9e7bd434a9d@gmail.com>
 <8EF69165-86AE-4117-8932-4561582D2BEA@gmail.com>
 <d2597188ff0542c9913205d4070230cf@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <50379a88ee4f47c09b296b9547656da1@exch-2p-mbx-w2.ads.tamu.edu>

Actually, not using apply() would be faster and simpler

cor(t(compare_data), t(test_data))

David C

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Friday, May 12, 2017 10:48 AM
To: Ismail SEZEN <sezenismail at gmail.com>; Micha Silver <tsvibar at gmail.com>
Cc: R-help at r-project.org
Subject: Re: [R] apply and cor()

Actually, r is a vector, not an index value. You need

apply(compare_data, 1, function(r) cor(r, t(test_data)))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ismail SEZEN
Sent: Friday, May 12, 2017 10:11 AM
To: Micha Silver <tsvibar at gmail.com>
Cc: R-help at r-project.org
Subject: Re: [R] apply and cor()


> On 12 May 2017, at 17:57, Micha Silver <tsvibar at gmail.com> wrote:
> 
> I have two data.frames, one with a single row of 31 columns, and the second with 269 rows and the same 31 columns.
> > dim(compare_data)
> [1] 269  31
> > dim(test_data)
> [1]  1 31
> 
> I want to apply cor() between the one row of 'test_data', and each row of the 'compare_data' .
> I tried 'apply' but I get this error:
> > apply(compare_data, 1, function(r) {cor(compare_data[r,], test_data)})
> Error in cor(compare_data[r, ], test_data) : incompatible dimensions


apply(compare_data, 1, function(r) {cor(compare_data[r,], as.numeric(test_data))})

See ?cor. Explanation of y is "NULL (default) or a vector, matrix or data frame with compatible dimensions to x?.

> 
> 
> In order to try to understand I did:
> > dims <- apply(compare_data, 1, function(r) {dim(compare_data[r,])})
> > head(dims)
>     20 73 103 118 130 142 151 154 191 205 217 222 227 232 240 275 282 301 320 359 360 551 589 653 789 801 808 812
> [1,]  9  8   8   9   5   9   8  11   6  15  12  13  10   7   9  14 8  11   9  11  11  12   9  14   5   8   9  10
> [2,] 31 31  31  31  31  31  31  31  31  31  31  31  31  31  31  31 31  31  31  31  31  31  31  31  31  31  31  31
>     840 856 857 867 885 970 983 985 1103 1107 1197 1207 1237 1262 1279 1282 1332 1357 1358 1392 1411 1435 1458 1473
> [1,]  14  11  12   8  10   2   7   9   10    8   10   13   11 7    9   12   11   11   16   10   10   12   10   10
> [2,]  31  31  31  31  31  31  31  31   31   31   31   31   31   31 31   31   31   31   31   31   31   31   31   31
> 
> and indeed I am getting different row dimensions. I expected "1 31" for each. What are the values 9,8,8,9,5... in the [1,] dimension?
> 
> If I test the compare_data data.frame one row at a time:
> > dim(compare_data['20',])
> [1]  1 31
> > dim(compare_data['1473',])
> [1]  1 31
> 
> It looks as I expected.
> What am I missing??
> 
> Thanks
> 
> -- 
> Micha Silver
> cell: +972-523-665918
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From chalabi.elahe at yahoo.de  Fri May 12 14:30:27 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Fri, 12 May 2017 12:30:27 +0000 (UTC)
Subject: [R] visualization of KNN results in text classification
References: <985810624.2404408.1494592227590.ref@mail.yahoo.com>
Message-ID: <985810624.2404408.1494592227590@mail.yahoo.com>



Thanks for your reply. What I exactly have is a data frame with rows containing words which have been used in each speech and columns containing frequency of these words, I have an extra row showing the type of the speech whether it was from a control group or Alzheimer group. Then I create a training and test set for KNN from this data frame and by KNN I classify the speeches which assigns every speech (actually text of the speech!) to the correct type of group, if it's from control group or Alzheimer group. 
Now my question is how can I visualize my KNN classifier or its results? cause now I only have an accuracy matrix from KNN!

Thanks for any help!
Elahe 

 
On Monday, May 8, 2017 3:55 PM, Ismail SEZEN <sezenismail at gmail.com> wrote:



As far as I know, kNN groups by Eucledian distance. So, you need numerical data as input. You said your dataset has only ?speeches? and ?type of people?. Are these input? or one of them is input and the latter one is output? Type of people should be a factor variable (I guess). I don?t know how you represent ?speech? in your dataset. As character or numerical representation of a feature? If you send a minimal example of the problem, we can help you. Please, read posting guide.



> ______________________________________________

> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

> https://stat.ethz.ch/mailman/listinfo/r-help

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Fri May 12 19:13:46 2017
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Fri, 12 May 2017 22:43:46 +0530
Subject: [R] Drawing World map divided into 6 economic regions
Message-ID: <CA+dpOJk-wB7_e44xBJFVfp+5MSVOJJH3i489=oNr0MjQQ1yB2Q@mail.gmail.com>

Hi again,

I am trying to draw a World map which is divided into 6 Economic
regions as available in below link

http://www.worldbank.org/en/about/annual-report/regions

I am aware of various R ways to draw World map based on Countries like
one available in

http://stackoverflow.com/questions/24136868/plot-map-with-values-for-countries-as-color-in-r

However I do not want to put any individual Country boundaries,
instead the individual boundaries of 6 Economic regions in the World.

Can you please suggest how can I achieve such a World map. Any pointer
will be highly appreciated.

Thanks for your time.


From ruipbarradas at sapo.pt  Fri May 12 19:15:43 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 12 May 2017 18:15:43 +0100
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
Message-ID: <5915EDBF.60009@sapo.pt>

Hello,

I have never used plm but the standard way of adding a quadratic term is

I(time(year)^2)

Hope this helps,

Rui Barradas

Em 12-05-2017 15:40, Tobias Christoph escreveu:
> Hey guys,
>
> thanks a lot for your tips. The regression is finally running. As you
> said, I had to integrate the column "year" in the function "time" in R.
>
> So I used the following formula: *plm(log(revenue) ~ log(supply) +
> factor(town)*time(year), data=R_Test_log_Neu)*
>
> So I have now sucessfully added a linear trend to my regression model?
> Another question that concernes me is how to add a quadratic trend
> instead of a linear trend. Can I just square the column "year"?
>
> Enjoy your weekend,
>
> Toby
>
> _My results see below:_
>
> Balanced Panel: n=11, T=12, N=132
>
> Residuals :
>      Min.  1st Qu.   Median  3rd Qu.     Max.
> -0.09610 -0.02370 -0.00152  0.01980  0.14000
>
> Coefficients :
>                              Estimate Std. Error t-value  Pr(>|t|)
> log(supply)               -0.0080702  0.0133675 -0.6037  0.547411
> factor(town)2:time(year)  -0.0063245  0.0053744 -1.1768  0.242100
> factor(town)3:time(year)   0.0295522  0.0056776  5.2050 1.053e-06 ***
> factor(town)4:time(year)   0.0062191  0.0054152  1.1485  0.253549
> factor(town)5:time(year)   0.0159028  0.0054954  2.8939  0.004681 **
> factor(town)6:time(year)   0.0237112  0.0055395  4.2804 4.316e-05 ***
> factor(town)7:time(year)   0.0410007  0.0055734  7.3565 5.576e-11 ***
> factor(town)8:time(year)   0.0239085  0.0053751  4.4480 2.271e-05 ***
> factor(town)9:time(year)   0.0242342  0.0056855  4.2625 4.619e-05 ***
> factor(town)10:time(year)  0.0105890  0.0053302  1.9866  0.049733 *
> factor(town)11:time(year)  0.0095270  0.0056354  1.6906  0.094065 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Total Sum of Squares:    0.46388
> Residual Sum of Squares: 0.2001
> R-Squared:      0.56863
> Adj. R-Squared: 0.4292
> F-statistic: 11.8637 on 11 and 99 DF, p-value: 7.3065e-14
>
>
>
> Am 11.05.2017 um 23:17 schrieb David L Carlson:
>> What Rui said, but as important, you have four columns in your data called "town", "year", "revenue", and "supply". You do not have a column called "time".
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>> Sent: Thursday, May 11, 2017 3:36 PM
>> To: Tobias Christoph<s3tochri at uni-bayreuth.de>; Duncan Murdoch<murdoch.duncan at gmail.com>;r-help at r-project.org
>> Subject: Re: [R] Error: invalid type (closure) for the variable 'time' - object specific trend
>>
>> Hello,
>>
>> A closure is, like you say, a function.
>> At an R prompt try:
>>
>>   > typeof(time)
>> [1] "closure"
>>
>> So like Duncan suggested rename 'time', for instance capitalize it
>> 'Time'. That should do it.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Em 11-05-2017 21:20, Tobias Christoph escreveu:
>>> Hey Duncan,
>>>
>>> thank you very much for your quick reply.
>>>
>>> _My data used:_
>>>
>>> 1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11
>>>
>>> 2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12
>>>
>>> 3rd column (revenue):
>>>
>>> 4th colum (supply):
>>>
>>> I have now renamed my colums and did the regression again. Now there is
>>> a problem with R-squared, as it is the sum of 1 now with no given std.
>>> error and t-value. This is probably due to the fact, that I try to
>>> estimate more parameters than data.
>>>
>>> To add a linear trend I found the following formular:*lm(y ~ x1 +
>>> factor(ccode)*time, data=df)*
>>>
>>> I try to I decode it for and use it for my regression: *plm(log(revenue)
>>> ~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*
>>>
>>> When I do this regression I will get the original error: "invalid type
>>> (closure) for the variable 'time' - object specific trend"
>>>
>>> With the notation"time" not my colum is meant, but probably the command
>>> "time" in R.
>>>
>>> Can you follow my thoughts?
>>>
>>> Tobi
>>>
>>>
>>>
>>>
>>>
>>>
>>> Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
>>>> Duncan Murdoch
>>> ______________________________________________
>>> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From macqueen1 at llnl.gov  Fri May 12 20:02:57 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 12 May 2017 18:02:57 +0000
Subject: [R] Drawing World map divided into 6 economic regions
In-Reply-To: <CA+dpOJk-wB7_e44xBJFVfp+5MSVOJJH3i489=oNr0MjQQ1yB2Q@mail.gmail.com>
References: <CA+dpOJk-wB7_e44xBJFVfp+5MSVOJJH3i489=oNr0MjQQ1yB2Q@mail.gmail.com>
Message-ID: <FEF787BB-04D6-471A-AD99-95F2F21F4257@llnl.gov>

Well, you'll have to find the boundaries in some electronic GIS format such as a shapefile (though there are other options).

I don't know where to find such a thing. Your chances of finding someone who does know are greater on the R-sig-geo mailing list, so I'd suggest asking there.

You may also need to transform your boundaries from whatever coordinate reference system they come in, to your desired projection.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 5/12/17, 10:13 AM, "R-help on behalf of Christofer Bogaso" <r-help-bounces at r-project.org on behalf of bogaso.christofer at gmail.com> wrote:

    Hi again,
    
    I am trying to draw a World map which is divided into 6 Economic
    regions as available in below link
    
    http://www.worldbank.org/en/about/annual-report/regions
    
    I am aware of various R ways to draw World map based on Countries like
    one available in
    
    http://stackoverflow.com/questions/24136868/plot-map-with-values-for-countries-as-color-in-r
    
    However I do not want to put any individual Country boundaries,
    instead the individual boundaries of 6 Economic regions in the World.
    
    Can you please suggest how can I achieve such a World map. Any pointer
    will be highly appreciated.
    
    Thanks for your time.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From abo_dlsh at hotmail.com  Fri May 12 20:08:50 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Fri, 12 May 2017 18:08:50 +0000
Subject: [R] Matched Items in rows + issue with writing a table
In-Reply-To: <CA+8X3fUKbA_nZQgUMAB5hjT6MQwBzBiVOwqBqjouYj7q1fqJQQ@mail.gmail.com>
References: <CY4PR15MB1302882B8DED436735654C3FEFED0@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <CA+8X3fUKbA_nZQgUMAB5hjT6MQwBzBiVOwqBqjouYj7q1fqJQQ@mail.gmail.com>
Message-ID: <CY4PR15MB130289D857990514F4C97F24EFE20@CY4PR15MB1302.namprd15.prod.outlook.com>

Dear Jim..,


Many thanks for your answer.


As I'm a new R user, could you please provide a short explanation

about what each line of the following does ?


findMatches<-function(x,sep=",") {
 matchval<-NA
 x1bits<-unlist(strsplit(x[1],sep))
 x2bits<-unlist(strsplit(x[2],sep))
 matches<-x1bits %in% x2bits
 if(any(matches)) matchval<-x1bits[which(matches)]
 return(matchval)
}
x444$matched_items<-apply(x444,1,findMatches)


I would like to understand so I can apply the same for any further analysis

I may need in the future.


Regards



________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: 12 May 2017 04:14 AM
To: abo dalash
Cc: r-help at R-project.org
Subject: Re: [R] Matched Items in rows + issue with writing a table

Hi abo,
I think you want to split your strings and do your matching like this:

x444<-read.table(text="w r
 cyp3,cyp7 cyp2,cyp1,cyp3
 cyp2 cyp2
 c1,c3,c6 c6,c8,c5",
 header=TRUE,stringsAsFactors=FALSE)
findMatches<-function(x,sep=",") {
 matchval<-NA
 x1bits<-unlist(strsplit(x[1],sep))
 x2bits<-unlist(strsplit(x[2],sep))
 matches<-x1bits %in% x2bits
 if(any(matches)) matchval<-x1bits[which(matches)]
 return(matchval)
}
x444$matched_items<-apply(x444,1,findMatches)

Note that this will only work with character values, _not_ factors.

Jim

On Fri, May 12, 2017 at 9:16 AM, abo dalash <abo_dlsh at hotmail.com> wrote:
> Hi All ..,
>
>
> I have a table called "x444" and I would like to create a new column contains the matched items in each row between column w & r . I used match()function as below but this does not return the results I want because of 2 issues. The 1st one is that this gives the row number of shared items while I want to see the item itself (e.g. in the table below, I want to see cyp2 instead of the row number 2). The 2nd issue is that I need to know matched items considering every item in the row instead of the entire row. For example, the item cyp3 is a matched item in the first row between columns w & r. The same applies for c6 in row 3. These don't appear in the results below.
>
>
>
>>x444
>                w         r
> 1 cyp3,cyp7     cyp2, cyp1,cyp3
> 2         cyp2      cyp2
> 3   c1,c3,c6       c6,c8,c5
>
>
>> r = c(match(x444$w,X444$r))
>> r
> [1] NA  2 NA
>
>
>
> The desired output should be like this :-
>
>                 w             r                             matched items
> 1 cyp3,cyp7     cyp2, cyp1,cyp3             cyp3
> 2         cyp2      cyp2                                  cyp2
> 3   c1,c3,c6       c6,c8,c5                          c6
>
>
> The second issue is that when I write a table produced in R as follows :
>
> write.table(MyTable,file="MyTable.txt", sep = "\t", quote = F, row.names = F)
>
> and the read this txt. file in excel, some items from column B appears in Column A and some empty rows also appear?.
>
> Could you please guide me about the mistakes I have done and suggest
> some solutions?
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help


thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From tsvibar at gmail.com  Fri May 12 20:58:04 2017
From: tsvibar at gmail.com (Micha Silver)
Date: Fri, 12 May 2017 21:58:04 +0300
Subject: [R] apply and cor()
In-Reply-To: <50379a88ee4f47c09b296b9547656da1@exch-2p-mbx-w2.ads.tamu.edu>
References: <a783fa74-c1e6-8d74-eb79-f9e7bd434a9d@gmail.com>
 <8EF69165-86AE-4117-8932-4561582D2BEA@gmail.com>
 <d2597188ff0542c9913205d4070230cf@exch-2p-mbx-w2.ads.tamu.edu>
 <50379a88ee4f47c09b296b9547656da1@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <773b6212-4641-54ba-d5e5-ac4474835707@gmail.com>



On 05/12/2017 06:53 PM, David L Carlson wrote:
> Actually, not using apply() would be faster and simpler
>
> cor(t(compare_data), t(test_data))
Worked just as I wanted, thanks!
I first reshaped the data frames, then I didn't even need the t()
>
> David C
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
> Sent: Friday, May 12, 2017 10:48 AM
> To: Ismail SEZEN <sezenismail at gmail.com>; Micha Silver <tsvibar at gmail.com>
> Cc: R-help at r-project.org
> Subject: Re: [R] apply and cor()
>
> Actually, r is a vector, not an index value. You need
>
> apply(compare_data, 1, function(r) cor(r, t(test_data)))
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ismail SEZEN
> Sent: Friday, May 12, 2017 10:11 AM
> To: Micha Silver <tsvibar at gmail.com>
> Cc: R-help at r-project.org
> Subject: Re: [R] apply and cor()
>
>
>> On 12 May 2017, at 17:57, Micha Silver <tsvibar at gmail.com> wrote:
>>
>> I have two data.frames, one with a single row of 31 columns, and the second with 269 rows and the same 31 columns.
>>> dim(compare_data)
>> [1] 269  31
>>> dim(test_data)
>> [1]  1 31
>>
>> I want to apply cor() between the one row of 'test_data', and each row of the 'compare_data' .
>> I tried 'apply' but I get this error:
>>> apply(compare_data, 1, function(r) {cor(compare_data[r,], test_data)})
>> Error in cor(compare_data[r, ], test_data) : incompatible dimensions
>
> apply(compare_data, 1, function(r) {cor(compare_data[r,], as.numeric(test_data))})
>
> See ?cor. Explanation of y is "NULL (default) or a vector, matrix or data frame with compatible dimensions to x?.
>
>>
>> In order to try to understand I did:
>>> dims <- apply(compare_data, 1, function(r) {dim(compare_data[r,])})
>>> head(dims)
>>      20 73 103 118 130 142 151 154 191 205 217 222 227 232 240 275 282 301 320 359 360 551 589 653 789 801 808 812
>> [1,]  9  8   8   9   5   9   8  11   6  15  12  13  10   7   9  14 8  11   9  11  11  12   9  14   5   8   9  10
>> [2,] 31 31  31  31  31  31  31  31  31  31  31  31  31  31  31  31 31  31  31  31  31  31  31  31  31  31  31  31
>>      840 856 857 867 885 970 983 985 1103 1107 1197 1207 1237 1262 1279 1282 1332 1357 1358 1392 1411 1435 1458 1473
>> [1,]  14  11  12   8  10   2   7   9   10    8   10   13   11 7    9   12   11   11   16   10   10   12   10   10
>> [2,]  31  31  31  31  31  31  31  31   31   31   31   31   31   31 31   31   31   31   31   31   31   31   31   31
>>
>> and indeed I am getting different row dimensions. I expected "1 31" for each. What are the values 9,8,8,9,5... in the [1,] dimension?
>>
>> If I test the compare_data data.frame one row at a time:
>>> dim(compare_data['20',])
>> [1]  1 31
>>> dim(compare_data['1473',])
>> [1]  1 31
>>
>> It looks as I expected.
>> What am I missing??
>>
>> Thanks
>>
>> -- 
>> Micha Silver
>> cell: +972-523-665918
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Micha Silver
cell: +972-523-665918


From jdnewmil at dcn.davis.ca.us  Fri May 12 21:43:14 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 12 May 2017 12:43:14 -0700
Subject: [R] Matched Items in rows + issue with writing a table
In-Reply-To: <CY4PR15MB130289D857990514F4C97F24EFE20@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB1302882B8DED436735654C3FEFED0@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <CA+8X3fUKbA_nZQgUMAB5hjT6MQwBzBiVOwqBqjouYj7q1fqJQQ@mail.gmail.com>
 <CY4PR15MB130289D857990514F4C97F24EFE20@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <AEC2E473-2451-44CB-83A6-EABD6F90E6A0@dcn.davis.ca.us>

Jim is generous enough that he might do this, but such assistance is not sustainable. Fortunately, you can type a ? in front of the name of a function and read about what goes in and what comes out. You can also type expressions like x[2] or which(matches) right before you execute the line of code, and you can use debug(findMatches) to cause R to let you step through the function one line at a time. These are all skills you should start developing soon, because in the long run they will teach you more than you can learn by asking questions here. 
-- 
Sent from my phone. Please excuse my brevity.

On May 12, 2017 11:08:50 AM PDT, abo dalash <abo_dlsh at hotmail.com> wrote:
>Dear Jim..,
>
>
>Many thanks for your answer.
>
>
>As I'm a new R user, could you please provide a short explanation
>
>about what each line of the following does ?
>
>
>findMatches<-function(x,sep=",") {
> matchval<-NA
> x1bits<-unlist(strsplit(x[1],sep))
> x2bits<-unlist(strsplit(x[2],sep))
> matches<-x1bits %in% x2bits
> if(any(matches)) matchval<-x1bits[which(matches)]
> return(matchval)
>}
>x444$matched_items<-apply(x444,1,findMatches)
>
>
>I would like to understand so I can apply the same for any further
>analysis
>
>I may need in the future.
>
>
>Regards
>
>
>
>________________________________
>From: Jim Lemon <drjimlemon at gmail.com>
>Sent: 12 May 2017 04:14 AM
>To: abo dalash
>Cc: r-help at R-project.org
>Subject: Re: [R] Matched Items in rows + issue with writing a table
>
>Hi abo,
>I think you want to split your strings and do your matching like this:
>
>x444<-read.table(text="w r
> cyp3,cyp7 cyp2,cyp1,cyp3
> cyp2 cyp2
> c1,c3,c6 c6,c8,c5",
> header=TRUE,stringsAsFactors=FALSE)
>findMatches<-function(x,sep=",") {
> matchval<-NA
> x1bits<-unlist(strsplit(x[1],sep))
> x2bits<-unlist(strsplit(x[2],sep))
> matches<-x1bits %in% x2bits
> if(any(matches)) matchval<-x1bits[which(matches)]
> return(matchval)
>}
>x444$matched_items<-apply(x444,1,findMatches)
>
>Note that this will only work with character values, _not_ factors.
>
>Jim
>
>On Fri, May 12, 2017 at 9:16 AM, abo dalash <abo_dlsh at hotmail.com>
>wrote:
>> Hi All ..,
>>
>>
>> I have a table called "x444" and I would like to create a new column
>contains the matched items in each row between column w & r . I used
>match()function as below but this does not return the results I want
>because of 2 issues. The 1st one is that this gives the row number of
>shared items while I want to see the item itself (e.g. in the table
>below, I want to see cyp2 instead of the row number 2). The 2nd issue
>is that I need to know matched items considering every item in the row
>instead of the entire row. For example, the item cyp3 is a matched item
>in the first row between columns w & r. The same applies for c6 in row
>3. These don't appear in the results below.
>>
>>
>>
>>>x444
>>                w         r
>> 1 cyp3,cyp7     cyp2, cyp1,cyp3
>> 2         cyp2      cyp2
>> 3   c1,c3,c6       c6,c8,c5
>>
>>
>>> r = c(match(x444$w,X444$r))
>>> r
>> [1] NA  2 NA
>>
>>
>>
>> The desired output should be like this :-
>>
>>                 w             r                             matched
>items
>> 1 cyp3,cyp7     cyp2, cyp1,cyp3             cyp3
>> 2         cyp2      cyp2                                  cyp2
>> 3   c1,c3,c6       c6,c8,c5                          c6
>>
>>
>> The second issue is that when I write a table produced in R as
>follows :
>>
>> write.table(MyTable,file="MyTable.txt", sep = "\t", quote = F,
>row.names = F)
>>
>> and the read this txt. file in excel, some items from column B
>appears in Column A and some empty rows also appear?.
>>
>> Could you please guide me about the mistakes I have done and suggest
>> some solutions?
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>
>
>thz.ch/mailman/listinfo/r-help>
>stat.ethz.ch
>The main R mailing list, for announcements about the development of R
>and the availability of new code, questions and answers about problems
>and solutions using R ...
>
>
>
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri May 12 22:12:05 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 May 2017 13:12:05 -0700
Subject: [R] Error: invalid type (closure) for the variable 'time' -
	object specific trend
In-Reply-To: <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
Message-ID: <D825D585-A11B-463F-9DA1-B4FBE66D10A1@comcast.net>


> On May 12, 2017, at 7:40 AM, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Hey guys,
> 
> thanks a lot for your tips. The regression is finally running. As you 
> said, I had to integrate the column "year" in the function "time" in R.
> 
> So I used the following formula: *plm(log(revenue) ~ log(supply) + 
> factor(town)*time(year), data=R_Test_log_Neu)*
> 
> So I have now sucessfully added a linear trend to my regression model? 
> Another question that concernes me is how to add a quadratic trend 
> instead of a linear trend. Can I just square the column "year"?

It's difficult to respond to these questions. It appears you have either created a function named `time` or loaded a package that contains such a named function. Several of the origianl responders thought it might be a misspelling of an existing column name.

One might guess from the output that `time` represents a linear value from a factor-variable across the values of the "year" column. You should probably NOT "just square column 'year'". That will probably construct non-orthogonal dependencies between "time" and "time"^2. The usual method in ordinary linear regression  is to use the "poly" function. In your case however the puzzle about what that `time` function looks like prevents much further comment.

To support informed discussion on this matter you MUST provide:

--- code that includes all the needed library() calls to load packages or to build a time function.
--- str(R_Test_log_Neu)


-- 
David
> 
> Enjoy your weekend,
> 
> Toby
> 
> _My results see below:_
> 
> Balanced Panel: n=11, T=12, N=132
> 
> Residuals :
>     Min.  1st Qu.   Median  3rd Qu.     Max.
> -0.09610 -0.02370 -0.00152  0.01980  0.14000
> 
> Coefficients :
>                             Estimate Std. Error t-value  Pr(>|t|)
> log(supply)               -0.0080702  0.0133675 -0.6037  0.547411
> factor(town)2:time(year)  -0.0063245  0.0053744 -1.1768  0.242100
> factor(town)3:time(year)   0.0295522  0.0056776  5.2050 1.053e-06 ***
> factor(town)4:time(year)   0.0062191  0.0054152  1.1485  0.253549
> factor(town)5:time(year)   0.0159028  0.0054954  2.8939  0.004681 **
> factor(town)6:time(year)   0.0237112  0.0055395  4.2804 4.316e-05 ***
> factor(town)7:time(year)   0.0410007  0.0055734  7.3565 5.576e-11 ***
> factor(town)8:time(year)   0.0239085  0.0053751  4.4480 2.271e-05 ***
> factor(town)9:time(year)   0.0242342  0.0056855  4.2625 4.619e-05 ***
> factor(town)10:time(year)  0.0105890  0.0053302  1.9866  0.049733 *
> factor(town)11:time(year)  0.0095270  0.0056354  1.6906  0.094065 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Total Sum of Squares:    0.46388
> Residual Sum of Squares: 0.2001
> R-Squared:      0.56863
> Adj. R-Squared: 0.4292
> F-statistic: 11.8637 on 11 and 99 DF, p-value: 7.3065e-14
> 
> 
> 
> Am 11.05.2017 um 23:17 schrieb David L Carlson:
>> What Rui said, but as important, you have four columns in your data called "town", "year", "revenue", and "supply". You do not have a column called "time".
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>> Sent: Thursday, May 11, 2017 3:36 PM
>> To: Tobias Christoph <s3tochri at uni-bayreuth.de>; Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
>> Subject: Re: [R] Error: invalid type (closure) for the variable 'time' - object specific trend
>> 
>> Hello,
>> 
>> A closure is, like you say, a function.
>> At an R prompt try:
>> 
>>> typeof(time)
>> [1] "closure"
>> 
>> So like Duncan suggested rename 'time', for instance capitalize it
>> 'Time'. That should do it.
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> 
>> Em 11-05-2017 21:20, Tobias Christoph escreveu:
>>> Hey Duncan,
>>> 
>>> thank you very much for your quick reply.
>>> 
>>> _My data used:_
>>> 
>>> 1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11
>>> 
>>> 2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12
>>> 
>>> 3rd column (revenue):
>>> 
>>> 4th colum (supply):
>>> 
>>> I have now renamed my colums and did the regression again. Now there is
>>> a problem with R-squared, as it is the sum of 1 now with no given std.
>>> error and t-value. This is probably due to the fact, that I try to
>>> estimate more parameters than data.
>>> 
>>> To add a linear trend I found the following formular:*lm(y ~ x1 +
>>> factor(ccode)*time, data=df)*
>>> 
>>> I try to I decode it for and use it for my regression: *plm(log(revenue)
>>> ~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*
>>> 
>>> When I do this regression I will get the original error: "invalid type
>>> (closure) for the variable 'time' - object specific trend"
>>> 
>>> With the notation"time" not my colum is meant, but probably the command
>>> "time" in R.
>>> 
>>> Can you follow my thoughts?
>>> 
>>> Tobi
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
>>>> Duncan Murdoch
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Fri May 12 23:23:37 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 May 2017 23:23:37 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
Message-ID: <90C874C2-BE0F-4959-B317-277D0291587D@gmail.com>


> On 12 May 2017, at 16:40 , Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Hey guys,
> 
> thanks a lot for your tips. The regression is finally running. As you 
> said, I had to integrate the column "year" in the function "time" in R.
> 
> So I used the following formula: *plm(log(revenue) ~ log(supply) + 
> factor(town)*time(year), data=R_Test_log_Neu)*

Um, that might not do what I think you think it does. time() gives you the "vector of times at which a time series was sampled". If you feed it any regular vector, it just gives the numbers 1:n, witness

> time(rnorm(20))
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
attr(,"tsp")
[1]  1 20  1

I suspect you just want "year" in the formula.

> 
> So I have now sucessfully added a linear trend to my regression model? 
> Another question that concernes me is how to add a quadratic trend 
> instead of a linear trend. Can I just square the column "year"?

In principle, yes, but as others have pointed out, centering the variable may be a good idea, for numerical stability.

-pd

> 
> Enjoy your weekend,
> 
> Toby
> 
> _My results see below:_
> 
> Balanced Panel: n=11, T=12, N=132
> 
> Residuals :
>     Min.  1st Qu.   Median  3rd Qu.     Max.
> -0.09610 -0.02370 -0.00152  0.01980  0.14000
> 
> Coefficients :
>                             Estimate Std. Error t-value  Pr(>|t|)
> log(supply)               -0.0080702  0.0133675 -0.6037  0.547411
> factor(town)2:time(year)  -0.0063245  0.0053744 -1.1768  0.242100
> factor(town)3:time(year)   0.0295522  0.0056776  5.2050 1.053e-06 ***
> factor(town)4:time(year)   0.0062191  0.0054152  1.1485  0.253549
> factor(town)5:time(year)   0.0159028  0.0054954  2.8939  0.004681 **
> factor(town)6:time(year)   0.0237112  0.0055395  4.2804 4.316e-05 ***
> factor(town)7:time(year)   0.0410007  0.0055734  7.3565 5.576e-11 ***
> factor(town)8:time(year)   0.0239085  0.0053751  4.4480 2.271e-05 ***
> factor(town)9:time(year)   0.0242342  0.0056855  4.2625 4.619e-05 ***
> factor(town)10:time(year)  0.0105890  0.0053302  1.9866  0.049733 *
> factor(town)11:time(year)  0.0095270  0.0056354  1.6906  0.094065 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Total Sum of Squares:    0.46388
> Residual Sum of Squares: 0.2001
> R-Squared:      0.56863
> Adj. R-Squared: 0.4292
> F-statistic: 11.8637 on 11 and 99 DF, p-value: 7.3065e-14
> 
> 
> 
> Am 11.05.2017 um 23:17 schrieb David L Carlson:
>> What Rui said, but as important, you have four columns in your data called "town", "year", "revenue", and "supply". You do not have a column called "time".
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>> Sent: Thursday, May 11, 2017 3:36 PM
>> To: Tobias Christoph <s3tochri at uni-bayreuth.de>; Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
>> Subject: Re: [R] Error: invalid type (closure) for the variable 'time' - object specific trend
>> 
>> Hello,
>> 
>> A closure is, like you say, a function.
>> At an R prompt try:
>> 
>>> typeof(time)
>> [1] "closure"
>> 
>> So like Duncan suggested rename 'time', for instance capitalize it
>> 'Time'. That should do it.
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> 
>> Em 11-05-2017 21:20, Tobias Christoph escreveu:
>>> Hey Duncan,
>>> 
>>> thank you very much for your quick reply.
>>> 
>>> _My data used:_
>>> 
>>> 1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11
>>> 
>>> 2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12
>>> 
>>> 3rd column (revenue):
>>> 
>>> 4th colum (supply):
>>> 
>>> I have now renamed my colums and did the regression again. Now there is
>>> a problem with R-squared, as it is the sum of 1 now with no given std.
>>> error and t-value. This is probably due to the fact, that I try to
>>> estimate more parameters than data.
>>> 
>>> To add a linear trend I found the following formular:*lm(y ~ x1 +
>>> factor(ccode)*time, data=df)*
>>> 
>>> I try to I decode it for and use it for my regression: *plm(log(revenue)
>>> ~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*
>>> 
>>> When I do this regression I will get the original error: "invalid type
>>> (closure) for the variable 'time' - object specific trend"
>>> 
>>> With the notation"time" not my colum is meant, but probably the command
>>> "time" in R.
>>> 
>>> Can you follow my thoughts?
>>> 
>>> Tobi
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
>>>> Duncan Murdoch
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chalabi.elahe at yahoo.de  Fri May 12 22:21:49 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Fri, 12 May 2017 20:21:49 +0000 (UTC)
Subject: [R] installing caret package
References: <2106096530.16245612.1494620509961.ref@mail.yahoo.com>
Message-ID: <2106096530.16245612.1494620509961@mail.yahoo.com>

Hi all,

I'm using Rstudio 64 bit version3.2.5 and I faced a problem installing caret package,the error is :

Loading required package: lattice
Loading required package: ggplot2
Error : object ?sigma? is not exported by 'namespace:stats'
Error: package or namespace load failed for ?caret?

how should I solve the problem with this sigma?!

Thanks for any help.
Elahe


From dwinsemius at comcast.net  Sat May 13 01:02:08 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 May 2017 16:02:08 -0700
Subject: [R] installing caret package
In-Reply-To: <2106096530.16245612.1494620509961@mail.yahoo.com>
References: <2106096530.16245612.1494620509961.ref@mail.yahoo.com>
 <2106096530.16245612.1494620509961@mail.yahoo.com>
Message-ID: <C1505688-5074-4AFD-B6FF-1B5AD11F0761@comcast.net>


> On May 12, 2017, at 1:21 PM, Elahe chalabi via R-help <r-help at r-project.org> wrote:
> 
> Hi all,
> 
> I'm using Rstudio 64 bit version3.2.5

I'm guessing that means using R 3.2.5, at least if RStudio is keeping its different os versions numering in sync. I'm on R studio 1.0.136 and I don't think I'm that out of date. So the stats package is part of the core load and to not have that function suggests that it was added and that you are using code from a later package version. You could try dropping back to a caret version from two years ago and see if you get better results ... or you could exit RStudio, and update R.

> and I faced a problem installing caret package,the error is :
> 
> Loading required package: lattice
> Loading required package: ggplot2
> Error : object ?sigma? is not exported by 'namespace:stats'
> Error: package or namespace load failed for ?caret?
> 
> how should I solve the problem with this sigma?!
> 
> Thanks for any help.
> Elahe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Sat May 13 02:16:45 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 May 2017 20:16:45 -0400
Subject: [R] installing caret package
In-Reply-To: <2106096530.16245612.1494620509961@mail.yahoo.com>
References: <2106096530.16245612.1494620509961.ref@mail.yahoo.com>
 <2106096530.16245612.1494620509961@mail.yahoo.com>
Message-ID: <7ce98211-45db-65a5-5ff7-530850612899@gmail.com>

On 12/05/2017 4:21 PM, Elahe chalabi via R-help wrote:
> Hi all,
>
> I'm using Rstudio 64 bit version3.2.5 and I faced a problem installing caret package,the error is :
>
> Loading required package: lattice
> Loading required package: ggplot2
> Error : object ?sigma? is not exported by 'namespace:stats'
> Error: package or namespace load failed for ?caret?

The caret function was introduced in R 3.3.0.  You need to update R to 
be at least as new as that.

You might also let the maintainer of caret know about this; they should 
have "Depends:  R (>= 3.3.0)" or something similar to prevent this kind 
of error.  (But I don't see "sigma" being used in the current source, so 
this may have been addressed already, or the error message may be 
tricking me into looking in the wrong place.)

Duncan Murdoch


From maitra at email.com  Sat May 13 01:55:06 2017
From: maitra at email.com (Ranjan Maitra)
Date: Fri, 12 May 2017 18:55:06 -0500
Subject: [R] display double dot over character in plotmath?
Message-ID: <20170512185506.d3423854090264785a15ef80@email.com>

Hi,

Is it possible to display double dot (umlaut) over a character such as would be possible using \ddot x in LaTeX? I can do this using tikzDevice but I wanted something simpler to point to. 

Here is an example of what I would like to do, but it is not quite there:

require(ggplot2)
data<-as.data.frame(c("a","b","c","a","b","c"))
colnames(data)<-"Y"
data$X<-c(1:6)
data$Z<-c(1,2,3,1,2,3)

ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab(expression(atop(top,bold(Age~"?"))))

I would like to put in a double dot over the "a" in the x-axis instead of "`".

Many thanks for any suggestions and best wishes,
Ranjan

-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From djnordlund at gmail.com  Sat May 13 08:39:14 2017
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Fri, 12 May 2017 23:39:14 -0700
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <20170512185506.d3423854090264785a15ef80@email.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
Message-ID: <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>

On 5/12/17 4:55 PM, Ranjan Maitra wrote:
> Hi,
> 
> Is it possible to display double dot (umlaut) over a character such as would be possible using \ddot x in LaTeX? I can do this using tikzDevice but I wanted something simpler to point to.
> 
> Here is an example of what I would like to do, but it is not quite there:
> 
> require(ggplot2)
> data<-as.data.frame(c("a","b","c","a","b","c"))
> colnames(data)<-"Y"
> data$X<-c(1:6)
> data$Z<-c(1,2,3,1,2,3)
> 
> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab(expression(atop(top,bold(Age~"?"))))
> 
> I would like to put in a double dot over the "a" in the x-axis instead of "`".
> 
> Many thanks for any suggestions and best wishes,
> Ranjan
> 

You haven't told what OS you are using, but with Windows OS, you can get 
the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
press 0228 on the numeric keypad.


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From s3tochri at uni-bayreuth.de  Sat May 13 12:51:30 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Sat, 13 May 2017 12:51:30 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <D825D585-A11B-463F-9DA1-B4FBE66D10A1@comcast.net>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
 <D825D585-A11B-463F-9DA1-B4FBE66D10A1@comcast.net>
Message-ID: <195e43cb-3e79-fbdd-2bd0-e732a32665ea@uni-bayreuth.de>

Hey David,

thanks for your reply.

Maybe the time -function is related to the plm-package. In R the 
function of time is declared as the following:


    Sampling Times of Time Series


      Description

|time|creates the vector of times at which a time series was sampled.

|cycle|gives the positions in the cycle of each observation.

|frequency|returns the number of samples per unit time and|deltat|the 
time interval between observations (see|ts 
<http://127.0.0.1:35865/help/library/stats/help/ts>|).


      Usage

time(x, ...)
## Default S3 method:
time(x, offset = 0, ...)

cycle(x, ...)
frequency(x, ...)
deltat(x, ...)

So the error was definitely not caused by a misspelling of an existing 
column-name.

Please see attached: _str(R_Test_log_Neu) & library()_

Hope it helps,

Toby

* > **str(R_Test_log_Neu)* Classes ?tbl_df?, ?tbl? and 'data.frame':	132 obs. of  4 variables:
  $ town   : num  1 1 1 1 1 1 1 1 1 1 ...
  $ year   : num  1 2 3 4 5 6 7 8 9 10 ...
  $ revenue: num  39.9 43.3 44 43.2 39.1 ...
  $ supply : num  1 1 1 1 1 1 35 101 181 323 ...



  *Pakete in Library*  ?C:/Users/Tobias Christoph/Documents/R/win-library/3.3?:

assertthat
          Easy pre and post
          assertions.
bdsmatrix
          Routines for
          Block Diagonal
          Symmetric
          matrices
BH       Boost C++ Header
          Files
car      Companion to
          Applied
          Regression
curl     A Modern and
          Flexible Web
          Client for R
Formula
          Extended Model
          Formulas
hms      Pretty Time of
          Day
lazyeval
          Lazy
          (Non-Standard)
          Evaluation
lme4     Linear
          Mixed-Effects
          Models using
          'Eigen' and S4
lmtest   Testing Linear
          Regression Models
MatrixModels
          Modelling with
          Sparse And Dense
          Matrices
minqa    Derivative-free
          optimization
          algorithms by
          quadratic
          approximation
nloptr   R interface to
          NLopt
Paneldata
          Linear models for
          panel data
pbkrtest
          Parametric
          Bootstrap and
          Kenward Roger
          Based Methods for
          Mixed Model
          Comparison
plm      Linear Models for
          Panel Data
plmDE    Additive
          partially linear
          models for
          differential gene
          expression
          analysis
quantreg
          Quantile
          Regression
R.methodsS3
          S3 Methods
          Simplified
R.oo     R Object-Oriented
          Programming with
          or without
          References
R6       Classes with
          Reference
          Semantics
Rcpp     Seamless R and
          C++ Integration
RcppEigen
          'Rcpp'
          Integration for
          the 'Eigen'
          Templated Linear
          Algebra Library
readr    Read Rectangular
          Text Data
readxl   Read Excel Files
sandwich
          Robust Covariance
          Matrix Estimators
SparseM
          Sparse Linear
          Algebra
tibble   Simple Data
          Frames
zoo      S3 Infrastructure
          for Regular and
          Irregular Time
          Series (Z's
          Ordered
          Observations)

  Pakete in Library ?C:/Program Files/R/R-3.3.3/library?:

base     The R Base
          Package
boot     Bootstrap
          Functions
          (Originally by
          Angelo Canty for
          S)
class    Functions for
          Classification
cluster
          "Finding Groups
          in Data": Cluster
          Analysis Extended
          Rousseeuw et al.
codetools
          Code Analysis
          Tools for R
compiler
          The R Compiler
          Package
datasets
          The R Datasets
          Package
foreign
          Read Data Stored
          by Minitab, S,
          SAS, SPSS, Stata,
          Systat, Weka,
          dBase, ...
graphics
          The R Graphics
          Package
grDevices
          The R Graphics
          Devices and
          Support for
          Colours and Fonts
grid     The Grid Graphics
          Package
KernSmooth
          Functions for
          Kernel Smoothing
          Supporting Wand &
          Jones (1995)
lattice
          Trellis Graphics
          for R
MASS     Support Functions
          and Datasets for
          Venables and
          Ripley's MASS
Matrix   Sparse and Dense
          Matrix Classes
          and Methods
methods
          Formal Methods
          and Classes
mgcv     Mixed GAM
          Computation
          Vehicle with
          GCV/AIC/REML
          Smoothness
          Estimation
nlme     Linear and
          Nonlinear Mixed
          Effects Models
nnet     Feed-Forward
          Neural Networks
          and Multinomial
          Log-Linear Models
parallel
          Support for
          Parallel
          computation in R
rpart    Recursive
          Partitioning and
          Regression Trees
spatial
          Functions for
          Kriging and Point
          Pattern Analysis
splines
          Regression Spline
          Functions and
          Classes
stats    The R Stats
          Package
stats4   Statistical
          Functions using
          S4 Classes
survival
          Survival Analysis
tcltk    Tcl/Tk Interface
tools    Tools for Package
          Development
translations
          The R
          Translations
          Package
utils    The R Utils
          Package


Am 12.05.2017 um 22:12 schrieb David Winsemius:
>> On May 12, 2017, at 7:40 AM, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
>>
>> Hey guys,
>>
>> thanks a lot for your tips. The regression is finally running. As you
>> said, I had to integrate the column "year" in the function "time" in R.
>>
>> So I used the following formula: *plm(log(revenue) ~ log(supply) +
>> factor(town)*time(year), data=R_Test_log_Neu)*
>>
>> So I have now sucessfully added a linear trend to my regression model?
>> Another question that concernes me is how to add a quadratic trend
>> instead of a linear trend. Can I just square the column "year"?
> It's difficult to respond to these questions. It appears you have either created a function named `time` or loaded a package that contains such a named function. Several of the origianl responders thought it might be a misspelling of an existing column name.
>
> One might guess from the output that `time` represents a linear value from a factor-variable across the values of the "year" column. You should probably NOT "just square column 'year'". That will probably construct non-orthogonal dependencies between "time" and "time"^2. The usual method in ordinary linear regression  is to use the "poly" function. In your case however the puzzle about what that `time` function looks like prevents much further comment.
>
> To support informed discussion on this matter you MUST provide:
>
> --- code that includes all the needed library() calls to load packages or to build a time function.
> --- str(R_Test_log_Neu)
>
>


	[[alternative HTML version deleted]]


From s3tochri at uni-bayreuth.de  Sat May 13 13:07:41 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Sat, 13 May 2017 13:07:41 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <90C874C2-BE0F-4959-B317-277D0291587D@gmail.com>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
 <90C874C2-BE0F-4959-B317-277D0291587D@gmail.com>
Message-ID: <001443c2-a544-d672-4de4-99cf542b594c@uni-bayreuth.de>

Hey Peter,

thank you. Yes, I want to have "year" in the varibale.
But if I use "*town*year*" as a furmula, R will create new factor 
variable with n levels, where n = (num of towns) x (num of years). What 
I'm trying to do is create 50 (town x year) variables such that 
town1xyear is 1,2,3... when town== 1 and zero otherwise, repeat for 
town2xyear, where state == 2, etc.

It is now clear? Sorry for my bad explanations.

Toby


Am 12.05.2017 um 23:23 schrieb peter dalgaard:
>> On 12 May 2017, at 16:40 , Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
>>
>> Hey guys,
>>
>> thanks a lot for your tips. The regression is finally running. As you
>> said, I had to integrate the column "year" in the function "time" in R.
>>
>> So I used the following formula: *plm(log(revenue) ~ log(supply) +
>> factor(town)*time(year), data=R_Test_log_Neu)*
> Um, that might not do what I think you think it does. time() gives you the "vector of times at which a time series was sampled". If you feed it any regular vector, it just gives the numbers 1:n, witness
>
>> time(rnorm(20))
>   [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
> attr(,"tsp")
> [1]  1 20  1
>
> I suspect you just want "year" in the formula.
>
>> So I have now sucessfully added a linear trend to my regression model?
>> Another question that concernes me is how to add a quadratic trend
>> instead of a linear trend. Can I just square the column "year"?
> In principle, yes, but as others have pointed out, centering the variable may be a good idea, for numerical stability.
>
> -pd
>
>> Enjoy your weekend,
>>
>> Toby
>>
>> _My results see below:_
>>
>> Balanced Panel: n=11, T=12, N=132
>>
>> Residuals :
>>      Min.  1st Qu.   Median  3rd Qu.     Max.
>> -0.09610 -0.02370 -0.00152  0.01980  0.14000
>>
>> Coefficients :
>>                              Estimate Std. Error t-value  Pr(>|t|)
>> log(supply)               -0.0080702  0.0133675 -0.6037  0.547411
>> factor(town)2:time(year)  -0.0063245  0.0053744 -1.1768  0.242100
>> factor(town)3:time(year)   0.0295522  0.0056776  5.2050 1.053e-06 ***
>> factor(town)4:time(year)   0.0062191  0.0054152  1.1485  0.253549
>> factor(town)5:time(year)   0.0159028  0.0054954  2.8939  0.004681 **
>> factor(town)6:time(year)   0.0237112  0.0055395  4.2804 4.316e-05 ***
>> factor(town)7:time(year)   0.0410007  0.0055734  7.3565 5.576e-11 ***
>> factor(town)8:time(year)   0.0239085  0.0053751  4.4480 2.271e-05 ***
>> factor(town)9:time(year)   0.0242342  0.0056855  4.2625 4.619e-05 ***
>> factor(town)10:time(year)  0.0105890  0.0053302  1.9866  0.049733 *
>> factor(town)11:time(year)  0.0095270  0.0056354  1.6906  0.094065 .
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Total Sum of Squares:    0.46388
>> Residual Sum of Squares: 0.2001
>> R-Squared:      0.56863
>> Adj. R-Squared: 0.4292
>> F-statistic: 11.8637 on 11 and 99 DF, p-value: 7.3065e-14
>>
>>
>>
>> Am 11.05.2017 um 23:17 schrieb David L Carlson:
>>> What Rui said, but as important, you have four columns in your data called "town", "year", "revenue", and "supply". You do not have a column called "time".
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>>> Sent: Thursday, May 11, 2017 3:36 PM
>>> To: Tobias Christoph <s3tochri at uni-bayreuth.de>; Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
>>> Subject: Re: [R] Error: invalid type (closure) for the variable 'time' - object specific trend
>>>
>>> Hello,
>>>
>>> A closure is, like you say, a function.
>>> At an R prompt try:
>>>
>>>> typeof(time)
>>> [1] "closure"
>>>
>>> So like Duncan suggested rename 'time', for instance capitalize it
>>> 'Time'. That should do it.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>>
>>> Em 11-05-2017 21:20, Tobias Christoph escreveu:
>>>> Hey Duncan,
>>>>
>>>> thank you very much for your quick reply.
>>>>
>>>> _My data used:_
>>>>
>>>> 1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11
>>>>
>>>> 2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12
>>>>
>>>> 3rd column (revenue):
>>>>
>>>> 4th colum (supply):
>>>>
>>>> I have now renamed my colums and did the regression again. Now there is
>>>> a problem with R-squared, as it is the sum of 1 now with no given std.
>>>> error and t-value. This is probably due to the fact, that I try to
>>>> estimate more parameters than data.
>>>>
>>>> To add a linear trend I found the following formular:*lm(y ~ x1 +
>>>> factor(ccode)*time, data=df)*
>>>>
>>>> I try to I decode it for and use it for my regression: *plm(log(revenue)
>>>> ~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*
>>>>
>>>> When I do this regression I will get the original error: "invalid type
>>>> (closure) for the variable 'time' - object specific trend"
>>>>
>>>> With the notation"time" not my colum is meant, but probably the command
>>>> "time" in R.
>>>>
>>>> Can you follow my thoughts?
>>>>
>>>> Tobi
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
>>>>> Duncan Murdoch
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From maitra at email.com  Sat May 13 14:47:45 2017
From: maitra at email.com (Ranjan Maitra)
Date: Sat, 13 May 2017 07:47:45 -0500
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
Message-ID: <20170513074745.a79bde205f3a272aabc4a260@email.com>

On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com> wrote:

> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
> > Hi,
> > 
> > Is it possible to display double dot (umlaut) over a character such as would be possible using \ddot x in LaTeX? I can do this using tikzDevice but I wanted something simpler to point to.
> > 
> > Here is an example of what I would like to do, but it is not quite there:
> > 
> > require(ggplot2)
> > data<-as.data.frame(c("a","b","c","a","b","c"))
> > colnames(data)<-"Y"
> > data$X<-c(1:6)
> > data$Z<-c(1,2,3,1,2,3)
> > 
> > ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab(expression(atop(top,bold(Age~"?"))))
> > 
> > I would like to put in a double dot over the "a" in the x-axis instead of "`".
> > 
> > Many thanks for any suggestions and best wishes,
> > Ranjan
> > 
> 
> You haven't told what OS you are using, but with Windows OS, you can get 
> the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
> press 0228 on the numeric keypad.
> 
> 

I am sorry, I use a linux operating system. I use Fedora 25 but the student I wanted to show this uses Ubuntu, though I don't know if the distribution matters.

Thanks again for your help, and best wishes,
Ranjan


From dwinsemius at comcast.net  Sat May 13 16:40:36 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 13 May 2017 07:40:36 -0700
Subject: [R] Error: invalid type (closure) for the variable 'time' -
	object specific trend
In-Reply-To: <001443c2-a544-d672-4de4-99cf542b594c@uni-bayreuth.de>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
 <90C874C2-BE0F-4959-B317-277D0291587D@gmail.com>
 <001443c2-a544-d672-4de4-99cf542b594c@uni-bayreuth.de>
Message-ID: <B3E8758D-8993-4BD5-8C61-4AD69E552EE3@comcast.net>


> On May 13, 2017, at 4:07 AM, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Hey Peter,
> 
> thank you. Yes, I want to have "year" in the varibale.
> But if I use "*town*year*" as a furmula, R will create new factor 
> variable with n levels, where n = (num of towns) x (num of years). What 
> I'm trying to do is create 50 (town x year) variables such that 
> town1xyear is 1,2,3... when town== 1 and zero otherwise, repeat for 
> town2xyear, where state == 2, etc.
> 
> It is now clear? Sorry for my bad explanations.

I had suggested that you must provide str(R_Test_log_Neu). I'm still suggesting this would be a good idea.

Since you have not done so, we can only guess at the right course to follow from your reports of problems and errors. Peter pointed out that the `time` function was in the 'stats' package (not from plm or elsewhere as I imagined). You are implying that 'year' is currently a factor value with levels that appears as the character versions of integers.

You may be able to get closer to what is possible by using:

plm( log(revenue) ~ log(supply) + factor(town) + as.numeric(as.character(year)), 
     data=R_Test_log_Neu)

This should fix the problem noted by Peter and avoid the potentially incorrect construction of the desired linear trend.

If you used the interaction operator "*" between 'town' and the numeric version of 'year' it will give you two sets of coefficients involving 'town'. The first set will be the mean deviations from the base factor level. The other set will be the differences in slopes for the time trends for each of the (factored) towns from the overall time trend/slope. And for your data you wouldbe constructing a saturated model ... as you observed in your first message (which remains in the copied thread below).

-- 
David.

> 
> Toby
> 
> 
> Am 12.05.2017 um 23:23 schrieb peter dalgaard:
>>> On 12 May 2017, at 16:40 , Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
>>> 
>>> Hey guys,
>>> 
>>> thanks a lot for your tips. The regression is finally running. As you
>>> said, I had to integrate the column "year" in the function "time" in R.
>>> 
>>> So I used the following formula: *plm(log(revenue) ~ log(supply) +
>>> factor(town)*time(year), data=R_Test_log_Neu)*
>> Um, that might not do what I think you think it does. time() gives you the "vector of times at which a time series was sampled". If you feed it any regular vector, it just gives the numbers 1:n, witness
>> 
>>> time(rnorm(20))
>>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
>> attr(,"tsp")
>> [1]  1 20  1
>> 
>> I suspect you just want "year" in the formula.
>> 
>>> So I have now sucessfully added a linear trend to my regression model?
>>> Another question that concernes me is how to add a quadratic trend
>>> instead of a linear trend. Can I just square the column "year"?
>> In principle, yes, but as others have pointed out, centering the variable may be a good idea, for numerical stability.
>> 
>> -pd
>> 
>>> Enjoy your weekend,
>>> 
>>> Toby
>>> 
>>> _My results see below:_
>>> 
>>> Balanced Panel: n=11, T=12, N=132
>>> 
>>> Residuals :
>>>     Min.  1st Qu.   Median  3rd Qu.     Max.
>>> -0.09610 -0.02370 -0.00152  0.01980  0.14000
>>> 
>>> Coefficients :
>>>                             Estimate Std. Error t-value  Pr(>|t|)
>>> log(supply)               -0.0080702  0.0133675 -0.6037  0.547411
>>> factor(town)2:time(year)  -0.0063245  0.0053744 -1.1768  0.242100
>>> factor(town)3:time(year)   0.0295522  0.0056776  5.2050 1.053e-06 ***
>>> factor(town)4:time(year)   0.0062191  0.0054152  1.1485  0.253549
>>> factor(town)5:time(year)   0.0159028  0.0054954  2.8939  0.004681 **
>>> factor(town)6:time(year)   0.0237112  0.0055395  4.2804 4.316e-05 ***
>>> factor(town)7:time(year)   0.0410007  0.0055734  7.3565 5.576e-11 ***
>>> factor(town)8:time(year)   0.0239085  0.0053751  4.4480 2.271e-05 ***
>>> factor(town)9:time(year)   0.0242342  0.0056855  4.2625 4.619e-05 ***
>>> factor(town)10:time(year)  0.0105890  0.0053302  1.9866  0.049733 *
>>> factor(town)11:time(year)  0.0095270  0.0056354  1.6906  0.094065 .
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Total Sum of Squares:    0.46388
>>> Residual Sum of Squares: 0.2001
>>> R-Squared:      0.56863
>>> Adj. R-Squared: 0.4292
>>> F-statistic: 11.8637 on 11 and 99 DF, p-value: 7.3065e-14
>>> 
>>> 
>>> 
>>> Am 11.05.2017 um 23:17 schrieb David L Carlson:
>>>> What Rui said, but as important, you have four columns in your data called "town", "year", "revenue", and "supply". You do not have a column called "time".
>>>> 
>>>> -------------------------------------
>>>> David L Carlson
>>>> Department of Anthropology
>>>> Texas A&M University
>>>> College Station, TX 77840-4352
>>>> 
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>>>> Sent: Thursday, May 11, 2017 3:36 PM
>>>> To: Tobias Christoph <s3tochri at uni-bayreuth.de>; Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
>>>> Subject: Re: [R] Error: invalid type (closure) for the variable 'time' - object specific trend
>>>> 
>>>> Hello,
>>>> 
>>>> A closure is, like you say, a function.
>>>> At an R prompt try:
>>>> 
>>>>> typeof(time)
>>>> [1] "closure"
>>>> 
>>>> So like Duncan suggested rename 'time', for instance capitalize it
>>>> 'Time'. That should do it.
>>>> 
>>>> Hope this helps,
>>>> 
>>>> Rui Barradas
>>>> 
>>>> 
>>>> 
>>>> Em 11-05-2017 21:20, Tobias Christoph escreveu:
>>>>> Hey Duncan,
>>>>> 
>>>>> thank you very much for your quick reply.
>>>>> 
>>>>> _My data used:_
>>>>> 
>>>>> 1st column(town):1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,...........,11
>>>>> 
>>>>> 2nd column(year):1,2,3,4,5,6,7,8,9,10,11,12,1,2,3.......,12
>>>>> 
>>>>> 3rd column (revenue):
>>>>> 
>>>>> 4th colum (supply):
>>>>> 
>>>>> I have now renamed my colums and did the regression again. Now there is
>>>>> a problem with R-squared, as it is the sum of 1 now with no given std.
>>>>> error and t-value. This is probably due to the fact, that I try to
>>>>> estimate more parameters than data.
>>>>> 
>>>>> To add a linear trend I found the following formular:*lm(y ~ x1 +
>>>>> factor(ccode)*time, data=df)*
>>>>> 
>>>>> I try to I decode it for and use it for my regression: *plm(log(revenue)
>>>>> ~ log(supply) + factor(town)*time, data=R_Test_log_Neu)*
>>>>> 
>>>>> When I do this regression I will get the original error: "invalid type
>>>>> (closure) for the variable 'time' - object specific trend"
>>>>> 
>>>>> With the notation"time" not my colum is meant, but probably the command
>>>>> "time" in R.
>>>>> 
>>>>> Can you follow my thoughts?
>>>>> 
>>>>> Tobi
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> Am 11.05.2017 um 17:23 schrieb Duncan Murdoch:
>>>>>> Duncan Murdoch
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jrkrideau at yahoo.ca  Sat May 13 16:34:56 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Sat, 13 May 2017 14:34:56 +0000 (UTC)
Subject: [R] Plotting bar charts by Month
In-Reply-To: <000e01d2c930$8062af90$81280eb0$@sbcglobal.net>
References: <000e01d2c930$8062af90$81280eb0$@sbcglobal.net>
Message-ID: <2055571118.390930.1494686096654@mail.yahoo.com>

Could we see some sample data? 
 

    On Tuesday, May 9, 2017 9:55 PM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
 

 r-help

 

Trying to figure out how to plot by month bar charts. The follow code plots
the monthly portion on a yearly x-scale.? So I either I create 12 individual
month plots or maybe there is some sort of "break" to tell R separate by
month and use the months dates as the x-scale; so that Jan's scale is 1 - 31
Jan , Feb scale is 1 - 28 Feb etc.? As it is now I get the Jan values ploted
with a 1-Jan to 31 Dec x-scale; Feb's value are ploted on a 1-Jan to 31 Dec
x-scale etc.

 

ggplot(data = df, aes(x = date, y = height)) +

? ? ? ? geom_bar(stat = "identity") +

? ? ? ? geom_bar(aes(x = action, y = height), color = "red", stat =
"identity") +

? ? ? ? facet_wrap(~month, nrow = 3)

 

Jeff


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat May 13 20:10:49 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 13 May 2017 11:10:49 -0700
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <20170513074745.a79bde205f3a272aabc4a260@email.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
Message-ID: <7B679810-883D-4588-8799-42EA60E45ED0@comcast.net>


> On May 13, 2017, at 5:47 AM, Ranjan Maitra <maitra at email.com> wrote:
> 
> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com> wrote:
> 
>> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
>>> Hi,
>>> 
>>> Is it possible to display double dot (umlaut) over a character such as would be possible using \ddot x in LaTeX? I can do this using tikzDevice but I wanted something simpler to point to.
>>> 
>>> Here is an example of what I would like to do, but it is not quite there:
>>> 
>>> require(ggplot2)
>>> data<-as.data.frame(c("a","b","c","a","b","c"))
>>> colnames(data)<-"Y"
>>> data$X<-c(1:6)
>>> data$Z<-c(1,2,3,1,2,3)
>>> 
>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab(expression(atop(top,bold(Age~"?"))))
>>> 
>>> I would like to put in a double dot over the "a" in the x-axis instead of "`".
>>> 
>>> Many thanks for any suggestions and best wishes,
>>> Ranjan
>>> 
>> 
>> You haven't told what OS you are using, but with Windows OS, you can get 
>> the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
>> press 0228 on the numeric keypad.
>> 
>> 
> 
> I am sorry, I use a linux operating system. I use Fedora 25 but the student I wanted to show this uses Ubuntu, though I don't know if the distribution matters.

On a Mac it is cmd-u followed by the vowel of your choice. Perhaps you should do a google search on the topic of getting umlauted characters for the distro of your choice?

David.


> 
> Thanks again for your help, and best wishes,
> Ranjan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bhh at xs4all.nl  Sat May 13 20:25:41 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 13 May 2017 20:25:41 +0200
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <7B679810-883D-4588-8799-42EA60E45ED0@comcast.net>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <7B679810-883D-4588-8799-42EA60E45ED0@comcast.net>
Message-ID: <E2AEE153-FECB-453B-9670-7023F0206BF7@xs4all.nl>


> On 13 May 2017, at 20:10, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On May 13, 2017, at 5:47 AM, Ranjan Maitra <maitra at email.com> wrote:
>> 
>> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com> wrote:
>> 
>>> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
>>>> Hi,
>>>> 
>>>> Is it possible to display double dot (umlaut) over a character such as would be possible using \ddot x in LaTeX? I can do this using tikzDevice but I wanted something simpler to point to.
>>>> 
>>>> Here is an example of what I would like to do, but it is not quite there:
>>>> 
>>>> require(ggplot2)
>>>> data<-as.data.frame(c("a","b","c","a","b","c"))
>>>> colnames(data)<-"Y"
>>>> data$X<-c(1:6)
>>>> data$Z<-c(1,2,3,1,2,3)
>>>> 
>>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab(expression(atop(top,bold(Age~"?"))))
>>>> 
>>>> I would like to put in a double dot over the "a" in the x-axis instead of "`".
>>>> 
>>>> Many thanks for any suggestions and best wishes,
>>>> Ranjan
>>>> 
>>> 
>>> You haven't told what OS you are using, but with Windows OS, you can get 
>>> the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
>>> press 0228 on the numeric keypad.
>>> 
>>> 
>> 
>> I am sorry, I use a linux operating system. I use Fedora 25 but the student I wanted to show this uses Ubuntu, though I don't know if the distribution matters.
> 
> On a Mac it is cmd-u followed by the vowel of your choice. Perhaps you should do a google search on the topic of getting umlauted characters for the distro of your choice?
> 

Option u followed by vowel! If you haven't changed Modifier Keys.

Berend


From ulrik.stervbo at gmail.com  Sat May 13 21:30:20 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 13 May 2017 19:30:20 +0000
Subject: [R] Plotting bar charts by Month
In-Reply-To: <2055571118.390930.1494686096654@mail.yahoo.com>
References: <000e01d2c930$8062af90$81280eb0$@sbcglobal.net>
 <2055571118.390930.1494686096654@mail.yahoo.com>
Message-ID: <CAKVAULPMGwW54ZFNzKvx+p8iubkicrPqmr7-K480g4pYMw61iQ@mail.gmail.com>

Does

scale_x_date(date_breaks = "1 month")

do what you want?

Ulrik

John Kane via R-help <r-help at r-project.org> schrieb am Sa., 13. Mai 2017,
17:12:

> Could we see some sample data?
>
>
>     On Tuesday, May 9, 2017 9:55 PM, Jeff Reichman <
> reichmanj at sbcglobal.net> wrote:
>
>
>  r-help
>
>
>
> Trying to figure out how to plot by month bar charts. The follow code plots
> the monthly portion on a yearly x-scale.  So I either I create 12
> individual
> month plots or maybe there is some sort of "break" to tell R separate by
> month and use the months dates as the x-scale; so that Jan's scale is 1 -
> 31
> Jan , Feb scale is 1 - 28 Feb etc.  As it is now I get the Jan values
> ploted
> with a 1-Jan to 31 Dec x-scale; Feb's value are ploted on a 1-Jan to 31 Dec
> x-scale etc.
>
>
>
> ggplot(data = df, aes(x = date, y = height)) +
>
>         geom_bar(stat = "identity") +
>
>         geom_bar(aes(x = action, y = height), color = "red", stat =
> "identity") +
>
>         facet_wrap(~month, nrow = 3)
>
>
>
> Jeff
>
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun May 14 02:54:35 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 14 May 2017 12:54:35 +1200
Subject: [R] [FORGED] Re: display double dot over character in plotmath?
In-Reply-To: <7B679810-883D-4588-8799-42EA60E45ED0@comcast.net>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <7B679810-883D-4588-8799-42EA60E45ED0@comcast.net>
Message-ID: <7e46d42c-05d4-9f9e-db06-72dee21322ef@auckland.ac.nz>

On 14/05/17 06:10, David Winsemius wrote:
>
>> On May 13, 2017, at 5:47 AM, Ranjan Maitra <maitra at email.com> wrote:
>>
>> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com> wrote:
>>
>>> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
>>>> Hi,
>>>>
>>>> Is it possible to display double dot (umlaut) over a character such as would be possible using \ddot x in LaTeX? I can do this using tikzDevice but I wanted something simpler to point to.
>>>>
>>>> Here is an example of what I would like to do, but it is not quite there:
>>>>
>>>> require(ggplot2)
>>>> data<-as.data.frame(c("a","b","c","a","b","c"))
>>>> colnames(data)<-"Y"
>>>> data$X<-c(1:6)
>>>> data$Z<-c(1,2,3,1,2,3)
>>>>
>>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab(expression(atop(top,bold(Age~"?"))))
>>>>
>>>> I would like to put in a double dot over the "a" in the x-axis instead of "`".
>>>>
>>>> Many thanks for any suggestions and best wishes,
>>>> Ranjan
>>>>
>>>
>>> You haven't told what OS you are using, but with Windows OS, you can get
>>> the '?' by making sure the NUMLOCK key is on, hold down the alt key and
>>> press 0228 on the numeric keypad.
>>>
>>>
>>
>> I am sorry, I use a linux operating system. I use Fedora 25 but the student I wanted to show this uses Ubuntu, though I don't know if the distribution matters.
>
> On a Mac it is cmd-u followed by the vowel of your choice. Perhaps you should do a google search on the topic of getting umlauted characters for the distro of your choice?
>

Well, Linux is not Mac.  For which I am everlastingly thankful.

I believe the following works on both Fedora and Ubuntu:

(1) First add/set a "compose" key:

In my current system (Ubuntu 16.04.2; Mate Desktop 1.12.1) the sequence 
of clicks is:

System -> Control Center -> Keyboard -> Layouts -> Options
        -> Position of Compose key -> [e.g.] Left Win

Clicking on "Left Win" inserts a tick mark in the little white box.  On 
my keyboard the "Left Win" key is to the left of the "Alt" key, which is 
to the left of the space bar.  It displays the (yeuchh!!!) Windoze 
symbol, a distorted window in black and white.  This key is totally 
useless for anything else, so one might as well use it for the compose key.

(2) Then do: <compose key> <letter> <accent>.  E.g

     ' <compose key> a " ' gives  ' ? '.

Note: Do *not* hold the compose key down while pressing the other
keys.  Press the compose key and release it; then press "a" (nothing
appears) then press ' " ' --- and bingo, ? appears.

HTH

cheers,

Rolf Turner

P. S.  Of course you just need to do the "set a compose key" bizzo 
*once* and then it is set and works forever more.  Until you change or 
bugger up your OS. :-)

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From maitra at email.com  Sat May 13 22:27:24 2017
From: maitra at email.com (Ranjan Maitra)
Date: Sat, 13 May 2017 15:27:24 -0500
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <E2AEE153-FECB-453B-9670-7023F0206BF7@xs4all.nl>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <7B679810-883D-4588-8799-42EA60E45ED0@comcast.net>
 <E2AEE153-FECB-453B-9670-7023F0206BF7@xs4all.nl>
Message-ID: <20170513152724.ae6802930eb3802ed57fe88c@email.com>

On Sat, 13 May 2017 20:25:41 +0200 Berend Hasselman <bhh at xs4all.nl> wrote:

> 
> > On 13 May 2017, at 20:10, David Winsemius <dwinsemius at comcast.net> wrote:
> > 
> >> 
> >> On May 13, 2017, at 5:47 AM, Ranjan Maitra <maitra at email.com> wrote:
> >> 
> >> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com> wrote:
> >> 
> >>> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
> >>>> Hi,
> >>>> 
> >>>> Is it possible to display double dot (umlaut) over a character such as would be possible using \ddot x in LaTeX? I can do this using tikzDevice but I wanted something simpler to point to.
> >>>> 
> >>>> Here is an example of what I would like to do, but it is not quite there:
> >>>> 
> >>>> require(ggplot2)
> >>>> data<-as.data.frame(c("a","b","c","a","b","c"))
> >>>> colnames(data)<-"Y"
> >>>> data$X<-c(1:6)
> >>>> data$Z<-c(1,2,3,1,2,3)
> >>>> 
> >>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab(expression(atop(top,bold(Age~"?"))))
> >>>> 
> >>>> I would like to put in a double dot over the "a" in the x-axis instead of "`".
> >>>> 
> >>>> Many thanks for any suggestions and best wishes,
> >>>> Ranjan
> >>>> 
> >>> 
> >>> You haven't told what OS you are using, but with Windows OS, you can get 
> >>> the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
> >>> press 0228 on the numeric keypad.
> >>> 
> >>> 
> >> 
> >> I am sorry, I use a linux operating system. I use Fedora 25 but the student I wanted to show this uses Ubuntu, though I don't know if the distribution matters.
> > 
> > On a Mac it is cmd-u followed by the vowel of your choice. Perhaps you should do a google search on the topic of getting umlauted characters for the distro of your choice?
> > 
> 
> Option u followed by vowel! If you haven't changed Modifier Keys.

Thanks! I could not figure this out yet, butI was thinking: can I not use the ascii key (I guess it would be 0228) then? But how would I do this? Btw, I really would like to use omega  in an example but I figured that the usual way of writing Greek characters would work there.

I tried the following:

require(ggplot2)
data<-as.data.frame(c("a","b","c","a","b","c"))
colnames(data)<-"Y"
data$X<-c(1:6)
data$Z<-c(1,2,3,1,2,3)

ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab(expression(atop(top,bold(Age~"\0228"(omega)))))

but I do not get what I want. Looking around, it is not clear to me that I can get this to work. The ASCII codes that I saw were all specific to a letter with umlaut. I want \omega with the double dots (umlaut).

Thanks again!
Best wishes,
Ranjan


From kdas.ujjwal at gmail.com  Sat May 13 23:00:24 2017
From: kdas.ujjwal at gmail.com (Ujjwal Kumar Das)
Date: Sat, 13 May 2017 22:00:24 +0100
Subject: [R] SEM with categorical variables
Message-ID: <CAM3YR6LL-1WYJ3U6ZS5LBwqDFZ3sOYSseba=an979cVFF1Fodg@mail.gmail.com>

Dear forum,

I am trying to run a SEM with three endogenous variables - one continuous,
one categorical and the other ordinal (1-5). As per my knowledge 'lavaan'
package can handle continuous and ordinal but not the categorical
endogenous variables.

Can any other R package handle categorical endogenous variables? Any
comments highly appreciated.

Regards,

Ujjwal Kumar Das
PhD Student, Economics
Leeds University Business School, UK
Email: bn13ukd at leeds.ac.uk; kdas.ujjwal at gmail.com
Mobile: +447417445195
Skype: ujjwal.kdasbb

	[[alternative HTML version deleted]]


From sharada.ramadass at gmail.com  Sun May 14 04:33:29 2017
From: sharada.ramadass at gmail.com (Sharada Ramadass)
Date: Sun, 14 May 2017 08:03:29 +0530
Subject: [R] variable scale and transform confusion with glmm
Message-ID: <CAG=Fgt-K_+E1KakdM09eFoojPWj42bH5geASdLE2yS2rL+eCNg@mail.gmail.com>

Hello,
  I am a complete newbie to GLMM and R. I do understand some bit of
statistics though I am in no-way a core statistician. So, here are my
doubts and I would really appreciate if someone can provide some
inputs.
I have looked up for prior responses on various lists and could not
come up with satisfactory results that clear my confusion.
1. My problem is an ecological problem and I am trying to model growth
rate in trees as a response to various predictors (fixed and random).
So far, so good.
2. Literature tells me that people use RGR (relative growth rate) to
look at growth to account for girth size classes.
3. My AGR or RGR are very small values (mathemetically in terms of
numbers) since my timeline for the data is very short. That is my
limitation.
4. Some predictors have large values (orders of magnitude,
mathematically) while some other others have smaller values.
5. So I have very small values for my growth rate, very large values
for some predictors and all the other predictors are in a similar
range of values, mathematically.

Here are my questions:
1. Does using AGR (absolute growth rate) introduce any bias or
inflation in the model if we use AGR instead of RGR? One paper (stoll
1990) did mention the use of AGR over RGR to avoid skewness.
2. I get 'large variance' errors when running lmer on the model with
the raw data (both response and predictors). Is that a problem?
3.If I had to transform the data, should I transform it for all
predictors and response (independent of which ones are extreme in
their values in orders of magnitude)?
4. If I did apply some kind of transformation, how do you interpret
the parameter estimates? Do you need to undo the transformation to get
correct values? Some posts seem to indicate you need to un-transform
the results.
5. For transformation/scaling, I am confused as to what should be
done. Some posts suggested simply scaling the variables up/down my
multiplicative factors. Again should this be done for all predictors?
If done for only select few, do we need to interpret their parameter
estimates differently?
6. The scale function in R has also been suggested as a way to do the
scaling. This seems to center the mean and not necessarily have just a
multiplicative effect? Is this the function to use for transform?
Again, only for some variables or for all?
7. Can the response alone be transformed (log or scale) and results
interpreted as-is?
8. Is there a certain log transform only that should be applied (to
which base)? Again, some posts indicate you can transform to base 10
or natural log while others indicate log transform is natural log
only.

Thanks and Regards,
Sharada


From bgunter.4567 at gmail.com  Sun May 14 06:19:46 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 13 May 2017 21:19:46 -0700
Subject: [R] variable scale and transform confusion with glmm
In-Reply-To: <CAG=Fgt-K_+E1KakdM09eFoojPWj42bH5geASdLE2yS2rL+eCNg@mail.gmail.com>
References: <CAG=Fgt-K_+E1KakdM09eFoojPWj42bH5geASdLE2yS2rL+eCNg@mail.gmail.com>
Message-ID: <CAGxFJbQ-uqHo-VvegKRzc72PHEaQ4oSJ70a-iU2HfXzP=NyPiQ@mail.gmail.com>

This list is about R programming not statistics, so your post is OT.
Try stats.stackexchange.com instead.

However, given your admitted statistical ignorance, I think you need a
local consultant to lead you through the statistical wilderness, not a
remote internet list. Note that, e.g. "which base" to use for logs,is
always irrelevant (other than as a matter of convention, possibly).

Cheers
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 13, 2017 at 7:33 PM, Sharada Ramadass
<sharada.ramadass at gmail.com> wrote:
> Hello,
>   I am a complete newbie to GLMM and R. I do understand some bit of
> statistics though I am in no-way a core statistician. So, here are my
> doubts and I would really appreciate if someone can provide some
> inputs.
> I have looked up for prior responses on various lists and could not
> come up with satisfactory results that clear my confusion.
> 1. My problem is an ecological problem and I am trying to model growth
> rate in trees as a response to various predictors (fixed and random).
> So far, so good.
> 2. Literature tells me that people use RGR (relative growth rate) to
> look at growth to account for girth size classes.
> 3. My AGR or RGR are very small values (mathemetically in terms of
> numbers) since my timeline for the data is very short. That is my
> limitation.
> 4. Some predictors have large values (orders of magnitude,
> mathematically) while some other others have smaller values.
> 5. So I have very small values for my growth rate, very large values
> for some predictors and all the other predictors are in a similar
> range of values, mathematically.
>
> Here are my questions:
> 1. Does using AGR (absolute growth rate) introduce any bias or
> inflation in the model if we use AGR instead of RGR? One paper (stoll
> 1990) did mention the use of AGR over RGR to avoid skewness.
> 2. I get 'large variance' errors when running lmer on the model with
> the raw data (both response and predictors). Is that a problem?
> 3.If I had to transform the data, should I transform it for all
> predictors and response (independent of which ones are extreme in
> their values in orders of magnitude)?
> 4. If I did apply some kind of transformation, how do you interpret
> the parameter estimates? Do you need to undo the transformation to get
> correct values? Some posts seem to indicate you need to un-transform
> the results.
> 5. For transformation/scaling, I am confused as to what should be
> done. Some posts suggested simply scaling the variables up/down my
> multiplicative factors. Again should this be done for all predictors?
> If done for only select few, do we need to interpret their parameter
> estimates differently?
> 6. The scale function in R has also been suggested as a way to do the
> scaling. This seems to center the mean and not necessarily have just a
> multiplicative effect? Is this the function to use for transform?
> Again, only for some variables or for all?
> 7. Can the response alone be transformed (log or scale) and results
> interpreted as-is?
> 8. Is there a certain log transform only that should be applied (to
> which base)? Again, some posts indicate you can transform to base 10
> or natural log while others indicate log transform is natural log
> only.
>
> Thanks and Regards,
> Sharada
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From s3tochri at uni-bayreuth.de  Sun May 14 10:22:03 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Sun, 14 May 2017 10:22:03 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <B3E8758D-8993-4BD5-8C61-4AD69E552EE3@comcast.net>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
 <90C874C2-BE0F-4959-B317-277D0291587D@gmail.com>
 <001443c2-a544-d672-4de4-99cf542b594c@uni-bayreuth.de>
 <B3E8758D-8993-4BD5-8C61-4AD69E552EE3@comcast.net>
Message-ID: <4c5686d6-e6d4-eacc-ee31-ee1323830529@uni-bayreuth.de>

Hey David,

when I used your suggested formula: *plm( log(revenue) ~ log(supply) + 
factor(town) + as.numeric(as.character(year)), data=R_Test_log_Neu) *I 
will get the same results as without considering town and year in the 
formula. So this might not the clue for taking into account a linear trend.

Please find attached the results of _str(R_Test_log_Neu):
_

Classes ?tbl_df?, ?tbl? and 'data.frame':	132 obs. of  4 variables:
  $ town   : num  1 1 1 1 1 1 1 1 1 1 ...
  $ year   : num  1 2 3 4 5 6 7 8 9 10 ...
  $ revenue: num  39.9 43.3 44 43.2 39.1 ...
  $ supply : num  1 1 1 1 1 1 35 101 181 323 ...


Hope this is helpful.

Toby



Am 13.05.2017 um 16:40 schrieb David Winsemius:
>> On May 13, 2017, at 4:07 AM, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
>>
>> Hey Peter,
>>
>> thank you. Yes, I want to have "year" in the varibale.
>> But if I use "*town*year*" as a furmula, R will create new factor
>> variable with n levels, where n = (num of towns) x (num of years). What
>> I'm trying to do is create 50 (town x year) variables such that
>> town1xyear is 1,2,3... when town== 1 and zero otherwise, repeat for
>> town2xyear, where state == 2, etc.
>>
>> It is now clear? Sorry for my bad explanations.
> I had suggested that you must provide str(R_Test_log_Neu). I'm still suggesting this would be a good idea.
>
> Since you have not done so, we can only guess at the right course to follow from your reports of problems and errors. Peter pointed out that the `time` function was in the 'stats' package (not from plm or elsewhere as I imagined). You are implying that 'year' is currently a factor value with levels that appears as the character versions of integers.
>
> You may be able to get closer to what is possible by using:
>
> plm( log(revenue) ~ log(supply) + factor(town) + as.numeric(as.character(year)),
>       data=R_Test_log_Neu)
>
> This should fix the problem noted by Peter and avoid the potentially incorrect construction of the desired linear trend.
>
> If you used the interaction operator "*" between 'town' and the numeric version of 'year' it will give you two sets of coefficients involving 'town'. The first set will be the mean deviations from the base factor level. The other set will be the differences in slopes for the time trends for each of the (factored) towns from the overall time trend/slope. And for your data you wouldbe constructing a saturated model ... as you observed in your first message (which remains in the copied thread below).
>


	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Sun May 14 15:57:50 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 14 May 2017 23:57:50 +1000
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <20170513074745.a79bde205f3a272aabc4a260@email.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
Message-ID: <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>

Hi

I just had to do something similar in windows with \"{u}. Try Unicode symbol
- see ?plotmath 

ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
xlab(expression(atop(top,bold(Age~"\u00e4"))))

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ranjan
Maitra
Sent: Saturday, 13 May 2017 22:48
To: r-help at stat.math.ethz.ch
Subject: Re: [R] display double dot over character in plotmath?

On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com>
wrote:

> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
> > Hi,
> > 
> > Is it possible to display double dot (umlaut) over a character such as
would be possible using \ddot x in LaTeX? I can do this using tikzDevice but
I wanted something simpler to point to.
> > 
> > Here is an example of what I would like to do, but it is not quite
there:
> > 
> > require(ggplot2)
> > data<-as.data.frame(c("a","b","c","a","b","c"))
> > colnames(data)<-"Y"
> > data$X<-c(1:6)
> > data$Z<-c(1,2,3,1,2,3)
> > 
> > ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
xlab(expression(atop(top,bold(Age~"?"))))
> > 
> > I would like to put in a double dot over the "a" in the x-axis instead
of "`".
> > 
> > Many thanks for any suggestions and best wishes,
> > Ranjan
> > 
> 
> You haven't told what OS you are using, but with Windows OS, you can get 
> the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
> press 0228 on the numeric keypad.
> 
> 

I am sorry, I use a linux operating system. I use Fedora 25 but the student
I wanted to show this uses Ubuntu, though I don't know if the distribution
matters.

Thanks again for your help, and best wishes,
Ranjan

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sun May 14 16:04:17 2017
From: jholtman at gmail.com (jim holtman)
Date: Sun, 14 May 2017 10:04:17 -0400
Subject: [R] Joining tables with different order and matched values
In-Reply-To: <CY4PR15MB130291337499E7A8300D926BEFEE0@CY4PR15MB1302.namprd15.prod.outlook.com>
References: <CY4PR15MB130291337499E7A8300D926BEFEE0@CY4PR15MB1302.namprd15.prod.outlook.com>
Message-ID: <CAAxdm-7OPMzsy7__T5zrspxRnjjvACBrTL3HBu_6cgKDzq+a7A@mail.gmail.com>

Here is a solution to the "shared values" question

> library(stringr)
> input <- read.table(text = "A             B
+
+ 1,2,5       3,8,7
+
+ 2,4,6       7,6,3  ",
+     header = TRUE,
+     as.is = TRUE
+     )
>
> input$'shared values' <- apply(input, 1, function(x){
+     toString(intersect(str_extract_all(x[1], "[^,]")[[1]],
+               str_extract_all(x[2], "[^,]")[[1]]
+               ))
+ })
>
> input
      A     B shared values
1 1,2,5 3,8,7
2 2,4,6 7,6,3             6



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, May 8, 2017 at 10:56 AM, abo dalash <abo_dlsh at hotmail.com> wrote:

> Hi All ..,
>
>
> I have 2 tables and I'm trying to have some information from the 1st table
> to appear in the second table with different order.
>
>
> For Example, let's say this is my 1st table :-
>
>
>
> Drug name           indications
>
>  Ibuprofen                Pain
>
>  Simvastatin            hyperlipidemia
>
> losartan                   hypertension
>
>
>
> my 2nd table is in different order for the 1st column :-
>
>
> Drug name       indications
>
>
> Simvastatin
>
> losartan
>
> Ibuprofen
>
> Metformin
>
>
> I wish to see the indication of each drug in my 2nd table subsisted from
> the information in my 1st table so the final table
>
> would be like this
>
>
> Drug name       indications
>
>
> Simvastatin     hyperlipidemia
>
> losartan           hypertension
>
> Ibuprofen       pain
>
> Metformin    N/A
>
>
> I have been trying to use Sqldf package and right join function but not
> able to formulate the correct syntax.
>
>
> I'm also trying to identify rows contain at least one shared value  in a
> dataset called 'Values":
>
>
> >Values
>
> A             B
>
> 1,2,5       3,8,7
>
> 2,4,6       7,6,3
>
>
>
> Columns A & B in the first row do not share any value while in the 2nd row
> they have a single shared value which is 6.
>
> The result I wish to see :-
>
>
> A             B             shared values
>
> 1,2,5       3,8,7             N/A
>
> 2,4,6       7,6,3               6
>
>
> I tried this syntax : SharedValues <- Values$A == Values$B but this
> returns logical results and what I wish to have
>
> is a new data frame including the new vector "shared values" showing the
> information exactly as above.
>
>
>
>
> Kind Regards
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maitra at email.com  Sun May 14 17:43:40 2017
From: maitra at email.com (Ranjan Maitra)
Date: Sun, 14 May 2017 10:43:40 -0500
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
Message-ID: <20170514104340.ff0e3a9b11a131f900282f89@email.com>

Thanks, Duncan!

This works for the particular case and is, to my mind, a great solution!

However, I was wondering: is it possible to use these double dots with another character, such as omega?  

I apologize for changing the question somewhat, but I did not realize earlier that there were separate codes for putting double dots over different letters and I thought that figuring out the simpler question would be enough for me to figure out the next step. 

Thanks again!

Best wishes,
Ranjan



On Sun, 14 May 2017 23:57:50 +1000 Duncan Mackay <dulcalma at bigpond.com> wrote:

> Hi
> 
> I just had to do something similar in windows with \"{u}. Try Unicode symbol
> - see ?plotmath 
> 
> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
> xlab(expression(atop(top,bold(Age~"\u00e4"))))
> 
> Regards
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ranjan
> Maitra
> Sent: Saturday, 13 May 2017 22:48
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] display double dot over character in plotmath?
> 
> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com>
> wrote:
> 
> > On 5/12/17 4:55 PM, Ranjan Maitra wrote:
> > > Hi,
> > > 
> > > Is it possible to display double dot (umlaut) over a character such as
> would be possible using \ddot x in LaTeX? I can do this using tikzDevice but
> I wanted something simpler to point to.
> > > 
> > > Here is an example of what I would like to do, but it is not quite
> there:
> > > 
> > > require(ggplot2)
> > > data<-as.data.frame(c("a","b","c","a","b","c"))
> > > colnames(data)<-"Y"
> > > data$X<-c(1:6)
> > > data$Z<-c(1,2,3,1,2,3)
> > > 
> > > ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
> xlab(expression(atop(top,bold(Age~"?"))))
> > > 
> > > I would like to put in a double dot over the "a" in the x-axis instead
> of "`".
> > > 
> > > Many thanks for any suggestions and best wishes,
> > > Ranjan
> > > 
> > 
> > You haven't told what OS you are using, but with Windows OS, you can get 
> > the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
> > press 0228 on the numeric keypad.
> > 
> > 
> 
> I am sorry, I use a linux operating system. I use Fedora 25 but the student
> I wanted to show this uses Ubuntu, though I don't know if the distribution
> matters.
> 
> Thanks again for your help, and best wishes,
> Ranjan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From dwinsemius at comcast.net  Sun May 14 18:08:46 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 May 2017 09:08:46 -0700
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <20170514104340.ff0e3a9b11a131f900282f89@email.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
 <20170514104340.ff0e3a9b11a131f900282f89@email.com>
Message-ID: <BF6BF362-0EB2-4B83-AFF9-9E7CA93BB427@comcast.net>


> On May 14, 2017, at 8:43 AM, Ranjan Maitra <maitra at email.com> wrote:
> 
> Thanks, Duncan!
> 
> This works for the particular case and is, to my mind, a great solution!
> 
> However, I was wondering: is it possible to use these double dots with another character, such as omega?  
> 
> I apologize for changing the question somewhat, but I did not realize earlier that there were separate codes for putting double dots over different letters and I thought that figuring out the simpler question would be enough for me to figure out the next step. 

I think you should be looking for a LaTeX solution. There is a tikzDevice-package.

This says you can assemble symbols with backspaces:

https://www.stat.berkeley.edu/~partha/symbols.pdf

For instance, LATEX defines \hbar (?~?) as a ??? character (\mathchar?26) followed by a backspace of 9 math units (\mkern-9mu), followed by the letter ?h?:

The second example in ?tikz, which could be a starting point for completing your task fails on my Mac by only displaying the names of the glyphs but not the glyphs themselves in the plot,  but it might have a better chance of succeeding on a Linux box.

Best;
David.


> 
> Thanks again!
> 
> Best wishes,
> Ranjan
> 
> 
> 
> On Sun, 14 May 2017 23:57:50 +1000 Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
>> Hi
>> 
>> I just had to do something similar in windows with \"{u}. Try Unicode symbol
>> - see ?plotmath 
>> 
>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
>> xlab(expression(atop(top,bold(Age~"\u00e4"))))
>> 
>> Regards
>> 
>> Duncan
>> 
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ranjan
>> Maitra
>> Sent: Saturday, 13 May 2017 22:48
>> To: r-help at stat.math.ethz.ch
>> Subject: Re: [R] display double dot over character in plotmath?
>> 
>> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com>
>> wrote:
>> 
>>> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
>>>> Hi,
>>>> 
>>>> Is it possible to display double dot (umlaut) over a character such as
>> would be possible using \ddot x in LaTeX? I can do this using tikzDevice but
>> I wanted something simpler to point to.
>>>> 
>>>> Here is an example of what I would like to do, but it is not quite
>> there:
>>>> 
>>>> require(ggplot2)
>>>> data<-as.data.frame(c("a","b","c","a","b","c"))
>>>> colnames(data)<-"Y"
>>>> data$X<-c(1:6)
>>>> data$Z<-c(1,2,3,1,2,3)
>>>> 
>>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
>> xlab(expression(atop(top,bold(Age~"?"))))
>>>> 
>>>> I would like to put in a double dot over the "a" in the x-axis instead
>> of "`".
>>>> 
>>>> Many thanks for any suggestions and best wishes,
>>>> Ranjan
>>>> 
>>> 
>>> You haven't told what OS you are using, but with Windows OS, you can get 
>>> the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
>>> press 0228 on the numeric keypad.
>>> 
>>> 
>> 
>> I am sorry, I use a linux operating system. I use Fedora 25 but the student
>> I wanted to show this uses Ubuntu, though I don't know if the distribution
>> matters.
>> 
>> Thanks again for your help, and best wishes,
>> Ranjan
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From abo_dlsh at hotmail.com  Sun May 14 18:36:08 2017
From: abo_dlsh at hotmail.com (abo dalash)
Date: Sun, 14 May 2017 16:36:08 +0000
Subject: [R] Matched Items in rows + issue with writing a table
In-Reply-To: <AEC2E473-2451-44CB-83A6-EABD6F90E6A0@dcn.davis.ca.us>
References: <CY4PR15MB1302882B8DED436735654C3FEFED0@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <CA+8X3fUKbA_nZQgUMAB5hjT6MQwBzBiVOwqBqjouYj7q1fqJQQ@mail.gmail.com>
 <CY4PR15MB130289D857990514F4C97F24EFE20@CY4PR15MB1302.namprd15.prod.outlook.com>,
 <AEC2E473-2451-44CB-83A6-EABD6F90E6A0@dcn.davis.ca.us>
Message-ID: <CY4PR15MB1302EA57DCC9F1F3AF886501EFE00@CY4PR15MB1302.namprd15.prod.outlook.com>

I would like to thank anyone here spending the time to help.


Jeff, I did not understand your recommendations regarding understanding the code. I tried to break the parts of the code but this does not make sense.




> x[1]
"1"
> x[2]

"2"

N <- strsplit(x[1],sep)
> N
[[1]]
[1] "1"

> strsplit(x444$w,sep)
[[1]]
[1] "cyp3" "cyp7"

[[2]]
[1] "cyp2"

[[3]]
[1] "c1" "c3" "c6"

> unlist(x444$w,sep)
[1] "cyp3,cyp7" "cyp2"      "c1,c3,c6"


Jim, thank you so much for writing the code which works but I will not complete my analysis until I understand what happens in each line. Otherwise, I will try to search for alternative solutions which I can understand.  If anyone can explain me what each part of the code has done, then please kindly replay . Please do not reply to just say try to teach yourself as I usually do not post any question here or ask for explanation until after I have already spent many hours or sometimes days of multiple tries. I also

have registered to an R course but many of what I have learnt until now was with just simple examples.  The blue lines bellows are the ones I did not understand.



findMatches<-function(x,sep=",") {
> matchval<-NA
> x1bits<-unlist(strsplit(x[1],sep))
> x2bits<-unlist(strsplit(x[2],sep))
> matches<-x1bits %in% x2bits
> if(any(matches)) matchval<-x1bits[which(matches)]
> return(matchval)
> }
> x444$matched_items<-apply(x444,1,findMatches)



________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: 12 May 2017 10:43 PM
To: r-help at r-project.org; abo dalash; Jim Lemon
Cc: r-help at R-project.org
Subject: Re: [R] Matched Items in rows + issue with writing a table

Jim is generous enough that he might do this, but such assistance is not sustainable. Fortunately, you can type a ? in front of the name of a function and read about what goes in and what comes out. You can also type expressions like x[2] or which(matches) right before you execute the line of code, and you can use debug(findMatches) to cause R to let you step through the function one line at a time. These are all skills you should start developing soon, because in the long run they will teach you more than you can learn by asking questions here.
--
Sent from my phone. Please excuse my brevity.

On May 12, 2017 11:08:50 AM PDT, abo dalash <abo_dlsh at hotmail.com> wrote:
>Dear Jim..,
>
>
>Many thanks for your answer.
>
>
>As I'm a new R user, could you please provide a short explanation
>
>about what each line of the following does ?
>
>
>findMatches<-function(x,sep=",") {
> matchval<-NA
> x1bits<-unlist(strsplit(x[1],sep))
> x2bits<-unlist(strsplit(x[2],sep))
> matches<-x1bits %in% x2bits
> if(any(matches)) matchval<-x1bits[which(matches)]
> return(matchval)
>}
>x444$matched_items<-apply(x444,1,findMatches)
>
>
>I would like to understand so I can apply the same for any further
>analysis
>
>I may need in the future.
>
>
>Regards
>
>
>
>________________________________
>From: Jim Lemon <drjimlemon at gmail.com>
>Sent: 12 May 2017 04:14 AM
>To: abo dalash
>Cc: r-help at R-project.org
>Subject: Re: [R] Matched Items in rows + issue with writing a table
>
>Hi abo,
>I think you want to split your strings and do your matching like this:
>
>x444<-read.table(text="w r
> cyp3,cyp7 cyp2,cyp1,cyp3
> cyp2 cyp2
> c1,c3,c6 c6,c8,c5",
> header=TRUE,stringsAsFactors=FALSE)
>findMatches<-function(x,sep=",") {
> matchval<-NA
> x1bits<-unlist(strsplit(x[1],sep))
> x2bits<-unlist(strsplit(x[2],sep))
> matches<-x1bits %in% x2bits
> if(any(matches)) matchval<-x1bits[which(matches)]
> return(matchval)
>}
>x444$matched_items<-apply(x444,1,findMatches)
>
>Note that this will only work with character values, _not_ factors.
>
>Jim
>
>On Fri, May 12, 2017 at 9:16 AM, abo dalash <abo_dlsh at hotmail.com>
>wrote:
>> Hi All ..,
>>
>>
>> I have a table called "x444" and I would like to create a new column
>contains the matched items in each row between column w & r . I used
>match()function as below but this does not return the results I want
>because of 2 issues. The 1st one is that this gives the row number of
>shared items while I want to see the item itself (e.g. in the table
>below, I want to see cyp2 instead of the row number 2). The 2nd issue
>is that I need to know matched items considering every item in the row
>instead of the entire row. For example, the item cyp3 is a matched item
>in the first row between columns w & r. The same applies for c6 in row
>3. These don't appear in the results below.
>>
>>
>>
>>>x444
>>                w         r
>> 1 cyp3,cyp7     cyp2, cyp1,cyp3
>> 2         cyp2      cyp2
>> 3   c1,c3,c6       c6,c8,c5
>>
>>
>>> r = c(match(x444$w,X444$r))
>>> r
>> [1] NA  2 NA
>>
>>
>>
>> The desired output should be like this :-
>>
>>                 w             r                             matched
>items
>> 1 cyp3,cyp7     cyp2, cyp1,cyp3             cyp3
>> 2         cyp2      cyp2                                  cyp2
>> 3   c1,c3,c6       c6,c8,c5                          c6
>>
>>
>> The second issue is that when I write a table produced in R as
>follows :
>>
>> write.table(MyTable,file="MyTable.txt", sep = "\t", quote = F,
>row.names = F)
>>
>> and the read this txt. file in excel, some items from column B
>appears in Column A and some empty rows also appear?.
>>
>> Could you please guide me about the mistakes I have done and suggest
>> some solutions?
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help


thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



>
>
>thz.ch/mailman/listinfo/r-help>
>stat.ethz.ch
>The main R mailing list, for announcements about the development of R
>and the availability of new code, questions and answers about problems
>and solutions using R ...
>
>
>
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help


thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun May 14 19:43:07 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 May 2017 10:43:07 -0700
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <BF6BF362-0EB2-4B83-AFF9-9E7CA93BB427@comcast.net>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
 <20170514104340.ff0e3a9b11a131f900282f89@email.com>
 <BF6BF362-0EB2-4B83-AFF9-9E7CA93BB427@comcast.net>
Message-ID: <4654F6D1-B302-4B47-90A0-8261397812C8@comcast.net>


> On May 14, 2017, at 9:08 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On May 14, 2017, at 8:43 AM, Ranjan Maitra <maitra at email.com> wrote:
>> 
>> Thanks, Duncan!
>> 
>> This works for the particular case and is, to my mind, a great solution!
>> 
>> However, I was wondering: is it possible to use these double dots with another character, such as omega?  
>> 
>> I apologize for changing the question somewhat, but I did not realize earlier that there were separate codes for putting double dots over different letters and I thought that figuring out the simpler question would be enough for me to figure out the next step. 
> 
> I think you should be looking for a LaTeX solution. There is a tikzDevice-package.
> 
> This says you can assemble symbols with backspaces:
> 
> https://www.stat.berkeley.edu/~partha/symbols.pdf
> 
> For instance, LATEX defines \hbar (?~?) as a ??? character (\mathchar?26) followed by a backspace of 9 math units (\mkern-9mu), followed by the letter ?h?:
> 
> The second example in ?tikz, which could be a starting point for completing your task fails on my Mac by only displaying the names of the glyphs but not the glyphs themselves in the plot,  but it might have a better chance of succeeding on a Linux box.

I'm not having a lot of success finding a "naked umlaut" with which I can backspace to put above a capital \Omega but I found and answer on how to use Newtonian differentiation notation in LateX:

https://tex.stackexchange.com/questions/152951/how-to-write-two-dot-above-a-letter

So this now produces the desire results, thanks to Kirill M?ller <krlmlr+r at mailbox.org>  tikzDevice package:

#-----------

library(tikzDevice)
options(tikzMetricPackages = c("\\usepackage[utf8]{inputenc}",
    "\\usepackage[T1]{fontenc}", "\\usetikzlibrary{calc}",
    "\\usepackage{amssymb}"))

tikz("formula.tex", width = 4, height = 4, standAlone = TRUE,
    packages = c("\\usepackage{tikz}",
                 "\\usepackage[active,tightpage,psfixbb]{preview}",
                 "\\PreviewEnvironment{pgfpicture}",
                 "\\setlength\\PreviewBorder{0pt}",
                 "\\usepackage{amssymb}"))
par(mar = c(4, 4, 1, 1))
plot(1, type = "n", xlab = "$x_1$", ylab = "$x_2$")
text(1, c(0.8), c("$\\ddot{\\Omega}$"), cex = 2.5)
dev.off()

tools::texi2pdf("formula.tex")
system(paste(getOption("pdfviewer"), "formula.pdf"))
#-----------


Best;
David.
> 
> Best;
> David.
> 
> 
>> 
>> Thanks again!
>> 
>> Best wishes,
>> Ranjan
>> 
>> 
>> 
>> On Sun, 14 May 2017 23:57:50 +1000 Duncan Mackay <dulcalma at bigpond.com> wrote:
>> 
>>> Hi
>>> 
>>> I just had to do something similar in windows with \"{u}. Try Unicode symbol
>>> - see ?plotmath 
>>> 
>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
>>> xlab(expression(atop(top,bold(Age~"\u00e4"))))
>>> 
>>> Regards
>>> 
>>> Duncan
>>> 
>>> Duncan Mackay
>>> Department of Agronomy and Soil Science
>>> University of New England
>>> Armidale NSW 2351
>>> Email: home: mackay at northnet.com.au
>>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ranjan
>>> Maitra
>>> Sent: Saturday, 13 May 2017 22:48
>>> To: r-help at stat.math.ethz.ch
>>> Subject: Re: [R] display double dot over character in plotmath?
>>> 
>>> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com>
>>> wrote:
>>> 
>>>> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
>>>>> Hi,
>>>>> 
>>>>> Is it possible to display double dot (umlaut) over a character such as
>>> would be possible using \ddot x in LaTeX? I can do this using tikzDevice but
>>> I wanted something simpler to point to.
>>>>> 
>>>>> Here is an example of what I would like to do, but it is not quite
>>> there:
>>>>> 
>>>>> require(ggplot2)
>>>>> data<-as.data.frame(c("a","b","c","a","b","c"))
>>>>> colnames(data)<-"Y"
>>>>> data$X<-c(1:6)
>>>>> data$Z<-c(1,2,3,1,2,3)
>>>>> 
>>>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
>>> xlab(expression(atop(top,bold(Age~"?"))))
>>>>> 
>>>>> I would like to put in a double dot over the "a" in the x-axis instead
>>> of "`".
>>>>> 
>>>>> Many thanks for any suggestions and best wishes,
>>>>> Ranjan
>>>>> 
>>>> 
>>>> You haven't told what OS you are using, but with Windows OS, you can get 
>>>> the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
>>>> press 0228 on the numeric keypad.
>>>> 
>>>> 
>>> 
>>> I am sorry, I use a linux operating system. I use Fedora 25 but the student
>>> I wanted to show this uses Ubuntu, though I don't know if the distribution
>>> matters.
>>> 
>>> Thanks again for your help, and best wishes,
>>> Ranjan
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> -- 
>> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun May 14 20:10:50 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 May 2017 11:10:50 -0700
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <4654F6D1-B302-4B47-90A0-8261397812C8@comcast.net>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
 <20170514104340.ff0e3a9b11a131f900282f89@email.com>
 <BF6BF362-0EB2-4B83-AFF9-9E7CA93BB427@comcast.net>
 <4654F6D1-B302-4B47-90A0-8261397812C8@comcast.net>
Message-ID: <B238E8B7-36C2-4806-B8F9-951901312CAA@comcast.net>


> On May 14, 2017, at 10:43 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On May 14, 2017, at 9:08 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> 
>>> On May 14, 2017, at 8:43 AM, Ranjan Maitra <maitra at email.com> wrote:
>>> 
>>> Thanks, Duncan!
>>> 
>>> This works for the particular case and is, to my mind, a great solution!
>>> 
>>> However, I was wondering: is it possible to use these double dots with another character, such as omega?  
>>> 
>>> I apologize for changing the question somewhat, but I did not realize earlier that there were separate codes for putting double dots over different letters and I thought that figuring out the simpler question would be enough for me to figure out the next step. 
>> 
>> I think you should be looking for a LaTeX solution. There is a tikzDevice-package.
>> 
>> This says you can assemble symbols with backspaces:
>> 
>> https://www.stat.berkeley.edu/~partha/symbols.pdf
>> 
>> For instance, LATEX defines \hbar (?~?) as a ??? character (\mathchar?26) followed by a backspace of 9 math units (\mkern-9mu), followed by the letter ?h?:
>> 
>> The second example in ?tikz, which could be a starting point for completing your task fails on my Mac

And I got Example2 on the ?tikz page working on a mac but removing hte \\Large that I could not seem to get recognized  and the extra backslashes:

library(tikzDevice)
td <- tempdir()
tf <- file.path(td,'example2.tex')
oldwd <- getwd()
setwd(td)
syms <-c('alpha','theta','tau','beta','vartheta','pi','upsilon',
         'gamma','gamma','varpi','phi','delta','kappa','rho',
         'varphi','epsilon','lambda','varrho','chi','varepsilon',
         'mu','sigma','psi','zeta','nu','varsigma','omega','eta',
         'xi','Gamma','Lambda','Sigma','Psi','Delta','Xi','Upsilon',
         'Omega','Theta','Pi','Phi')
x <- rnorm(length(syms))
y <- rnorm(length(syms))

tikz(tf,standAlone=TRUE)
  plot(-2:2, -2:2, type = "n", axes=F,
      xlab='', ylab='', main='TikZ Device Math Example')
    text(x,y,paste("$\\",syms, "$", sep=""), cex=3)
dev.off()
tools::texi2dvi(tf,pdf=TRUE)
system(paste(getOption('pdfviewer'),file.path(td,'example2.pdf')))
setwd(oldwd)


>> by only displaying the names of the glyphs but not the glyphs themselves in the plot,  but it might have a better chance of succeeding on a Linux box.
> 
> I'm not having a lot of success finding a "naked umlaut" with which I can backspace to put above a capital \Omega but I found and answer on how to use Newtonian differentiation notation in LateX:
> 
> https://tex.stackexchange.com/questions/152951/how-to-write-two-dot-above-a-letter



 Thanks (amended) to Kirill M?ller <krlmlr+r at mailbox.org> and Charlie Sharpsteen, Cameron Bracken, and Yihue Xie for the tikzDevice package:

-- 
David.

> 
> #-----------
> 
> library(tikzDevice)
> options(tikzMetricPackages = c("\\usepackage[utf8]{inputenc}",
>    "\\usepackage[T1]{fontenc}", "\\usetikzlibrary{calc}",
>    "\\usepackage{amssymb}"))
> 
> tikz("formula.tex", width = 4, height = 4, standAlone = TRUE,
>    packages = c("\\usepackage{tikz}",
>                 "\\usepackage[active,tightpage,psfixbb]{preview}",
>                 "\\PreviewEnvironment{pgfpicture}",
>                 "\\setlength\\PreviewBorder{0pt}",
>                 "\\usepackage{amssymb}"))
> par(mar = c(4, 4, 1, 1))
> plot(1, type = "n", xlab = "$x_1$", ylab = "$x_2$")
> text(1, c(0.8), c("$\\ddot{\\Omega}$"), cex = 2.5)
> dev.off()
> 
> tools::texi2pdf("formula.tex")
> system(paste(getOption("pdfviewer"), "formula.pdf"))
> #-----------
> 
> 
> Best;
> David.
>> 
>> Best;
>> David.
>> 
>> 
>>> 
>>> Thanks again!
>>> 
>>> Best wishes,
>>> Ranjan
>>> 
>>> 
>>> 
>>> On Sun, 14 May 2017 23:57:50 +1000 Duncan Mackay <dulcalma at bigpond.com> wrote:
>>> 
>>>> Hi
>>>> 
>>>> I just had to do something similar in windows with \"{u}. Try Unicode symbol
>>>> - see ?plotmath 
>>>> 
>>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
>>>> xlab(expression(atop(top,bold(Age~"\u00e4"))))
>>>> 
>>>> Regards
>>>> 
>>>> Duncan
>>>> 
>>>> Duncan Mackay
>>>> Department of Agronomy and Soil Science
>>>> University of New England
>>>> Armidale NSW 2351
>>>> Email: home: mackay at northnet.com.au
>>>> 
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ranjan
>>>> Maitra
>>>> Sent: Saturday, 13 May 2017 22:48
>>>> To: r-help at stat.math.ethz.ch
>>>> Subject: Re: [R] display double dot over character in plotmath?
>>>> 
>>>> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com>
>>>> wrote:
>>>> 
>>>>> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
>>>>>> Hi,
>>>>>> 
>>>>>> Is it possible to display double dot (umlaut) over a character such as
>>>> would be possible using \ddot x in LaTeX? I can do this using tikzDevice but
>>>> I wanted something simpler to point to.
>>>>>> 
>>>>>> Here is an example of what I would like to do, but it is not quite
>>>> there:
>>>>>> 
>>>>>> require(ggplot2)
>>>>>> data<-as.data.frame(c("a","b","c","a","b","c"))
>>>>>> colnames(data)<-"Y"
>>>>>> data$X<-c(1:6)
>>>>>> data$Z<-c(1,2,3,1,2,3)
>>>>>> 
>>>>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
>>>> xlab(expression(atop(top,bold(Age~"?"))))
>>>>>> 
>>>>>> I would like to put in a double dot over the "a" in the x-axis instead
>>>> of "`".
>>>>>> 
>>>>>> Many thanks for any suggestions and best wishes,
>>>>>> Ranjan
>>>>>> 
>>>>> 
>>>>> You haven't told what OS you are using, but with Windows OS, you can get 
>>>>> the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
>>>>> press 0228 on the numeric keypad.
>>>>> 
>>>>> 
>>>> 
>>>> I am sorry, I use a linux operating system. I use Fedora 25 but the student
>>>> I wanted to show this uses Ubuntu, though I don't know if the distribution
>>>> matters.
>>>> 
>>>> Thanks again for your help, and best wishes,
>>>> Ranjan
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>>> -- 
>>> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Sun May 14 20:24:36 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 14 May 2017 20:24:36 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <4c5686d6-e6d4-eacc-ee31-ee1323830529@uni-bayreuth.de>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
 <90C874C2-BE0F-4959-B317-277D0291587D@gmail.com>
 <001443c2-a544-d672-4de4-99cf542b594c@uni-bayreuth.de>
 <B3E8758D-8993-4BD5-8C61-4AD69E552EE3@comcast.net>
 <4c5686d6-e6d4-eacc-ee31-ee1323830529@uni-bayreuth.de>
Message-ID: <6034D452-2F97-4F2B-BB68-52E68978D6FE@gmail.com>


> On 14 May 2017, at 10:22 , Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Hey David,
> 
> when I used your suggested formula: plm( log(revenue) ~ log(supply) + factor(town) + as.numeric(as.character(year)), data=R_Test_log_Neu) I will get the same results as without considering town and year in the formula. So this might not the clue for taking into account a linear trend.

You probably still want a "*" in the model formula.

(It is not obvious to me why a plain factor(town)*year term does not work, something in the panel data frame setup auto-converts it to a factor? But why do you need to say factor(town) then?)

-pd 

> 
> Please find attached the results of str(R_Test_log_Neu): 
>  
> Classes ?tbl_df?, ?tbl? and 'data.frame':	132 obs. of  4 variables:
>  $ town   : num  1 1 1 1 1 1 1 1 1 1 ...
>  $ year   : num  1 2 3 4 5 6 7 8 9 10 ...
>  $ revenue: num  39.9 43.3 44 43.2 39.1 ...
>  $ supply : num  1 1 1 1 1 1 35 101 181 323 ...
> 
> 
> 
> Hope this is helpful.
> 
> Toby
> 
> 
> 
> Am 13.05.2017 um 16:40 schrieb David Winsemius:
>>> On May 13, 2017, at 4:07 AM, Tobias Christoph <s3tochri at uni-bayreuth.de>
>>>  wrote:
>>> 
>>> Hey Peter,
>>> 
>>> thank you. Yes, I want to have "year" in the varibale.
>>> But if I use "*town*year*" as a furmula, R will create new factor 
>>> variable with n levels, where n = (num of towns) x (num of years). What 
>>> I'm trying to do is create 50 (town x year) variables such that 
>>> town1xyear is 1,2,3... when town== 1 and zero otherwise, repeat for 
>>> town2xyear, where state == 2, etc.
>>> 
>>> It is now clear? Sorry for my bad explanations.
>>> 
>> I had suggested that you must provide str(R_Test_log_Neu). I'm still suggesting this would be a good idea.
>> 
>> Since you have not done so, we can only guess at the right course to follow from your reports of problems and errors. Peter pointed out that the `time` function was in the 'stats' package (not from plm or elsewhere as I imagined). You are implying that 'year' is currently a factor value with levels that appears as the character versions of integers.
>> 
>> You may be able to get closer to what is possible by using:
>> 
>> plm( log(revenue) ~ log(supply) + factor(town) + as.numeric(as.character(year)), 
>>      data=R_Test_log_Neu)
>> 
>> This should fix the problem noted by Peter and avoid the potentially incorrect construction of the desired linear trend.
>> 
>> If you used the interaction operator "*" between 'town' and the numeric version of 'year' it will give you two sets of coefficients involving 'town'. The first set will be the mean deviations from the base factor level. The other set will be the differences in slopes for the time trends for each of the (factored) towns from the overall time trend/slope. And for your data you wouldbe constructing a saturated model ... as you observed in your first message (which remains in the copied thread below).
>> 
>> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From yoursurrogategod at gmail.com  Sun May 14 20:35:45 2017
From: yoursurrogategod at gmail.com (Yves S. Garret)
Date: Sun, 14 May 2017 14:35:45 -0400
Subject: [R] Cannot generate a *.docx file
Message-ID: <CAJ=2b06vkXn=CKdqTka9cWwf_fF_CNLwny4Y2bL0MGa5f_06eA@mail.gmail.com>

Hello,

I have the following code example:

library(ReporteRs)

# Create a word document to contain R outputs
doc <- docx()

# Add a title to the document
doc <- addTitle(doc, "Simple Word document", level = 1)

# Add a paragraph of text into the Word document
cat("Output 1\n")
doc <- addParagraph(doc, "This.")
cat("Output 2\n")

# Write the Word document to a file
writeDoc(doc, file = "r-reporters-simple-word-document.docx")

When I run it, this is what I see:

source("writing_to_ms_word_new.R")
Output 1
Error in UseMethod("addParagraph") :
  no applicable method for 'addParagraph' applied to an object of class
"docx"

Why?  The library loads as it should.  So why am I getting the above error?

Thanks in advance.

	[[alternative HTML version deleted]]


From s3tochri at uni-bayreuth.de  Sun May 14 20:43:32 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Sun, 14 May 2017 20:43:32 +0200
Subject: [R] Error: invalid type (closure) for the variable 'time' -
 object specific trend
In-Reply-To: <6034D452-2F97-4F2B-BB68-52E68978D6FE@gmail.com>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
 <90C874C2-BE0F-4959-B317-277D0291587D@gmail.com>
 <001443c2-a544-d672-4de4-99cf542b594c@uni-bayreuth.de>
 <B3E8758D-8993-4BD5-8C61-4AD69E552EE3@comcast.net>
 <4c5686d6-e6d4-eacc-ee31-ee1323830529@uni-bayreuth.de>
 <6034D452-2F97-4F2B-BB68-52E68978D6FE@gmail.com>
Message-ID: <18fddf35-a436-6a8a-e14c-c0b8fa06d724@uni-bayreuth.de>

Hey Peter,

it is not necessary to use "factor(town)". I can just use  "town" as the 
name of the towns is already numeric.



Am 14.05.2017 um 20:24 schrieb peter dalgaard:
>> On 14 May 2017, at 10:22 , Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
>>
>> Hey David,
>>
>> when I used your suggested formula: plm( log(revenue) ~ log(supply) + factor(town) + as.numeric(as.character(year)), data=R_Test_log_Neu) I will get the same results as without considering town and year in the formula. So this might not the clue for taking into account a linear trend.
> You probably still want a "*" in the model formula.
>
> (It is not obvious to me why a plain factor(town)*year term does not work, something in the panel data frame setup auto-converts it to a factor? But why do you need to say factor(town) then?)
>
> -pd
>
>> Please find attached the results of str(R_Test_log_Neu):
>>   
>> Classes ?tbl_df?, ?tbl? and 'data.frame':	132 obs. of  4 variables:
>>   $ town   : num  1 1 1 1 1 1 1 1 1 1 ...
>>   $ year   : num  1 2 3 4 5 6 7 8 9 10 ...
>>   $ revenue: num  39.9 43.3 44 43.2 39.1 ...
>>   $ supply : num  1 1 1 1 1 1 35 101 181 323 ...
>>
>>
>>
>> Hope this is helpful.
>>
>> Toby
>>
>>
>>
>> Am 13.05.2017 um 16:40 schrieb David Winsemius:
>>>> On May 13, 2017, at 4:07 AM, Tobias Christoph <s3tochri at uni-bayreuth.de>
>>>>   wrote:
>>>>
>>>> Hey Peter,
>>>>
>>>> thank you. Yes, I want to have "year" in the varibale.
>>>> But if I use "*town*year*" as a furmula, R will create new factor
>>>> variable with n levels, where n = (num of towns) x (num of years). What
>>>> I'm trying to do is create 50 (town x year) variables such that
>>>> town1xyear is 1,2,3... when town== 1 and zero otherwise, repeat for
>>>> town2xyear, where state == 2, etc.
>>>>
>>>> It is now clear? Sorry for my bad explanations.
>>>>
>>> I had suggested that you must provide str(R_Test_log_Neu). I'm still suggesting this would be a good idea.
>>>
>>> Since you have not done so, we can only guess at the right course to follow from your reports of problems and errors. Peter pointed out that the `time` function was in the 'stats' package (not from plm or elsewhere as I imagined). You are implying that 'year' is currently a factor value with levels that appears as the character versions of integers.
>>>
>>> You may be able to get closer to what is possible by using:
>>>
>>> plm( log(revenue) ~ log(supply) + factor(town) + as.numeric(as.character(year)),
>>>       data=R_Test_log_Neu)
>>>
>>> This should fix the problem noted by Peter and avoid the potentially incorrect construction of the desired linear trend.
>>>
>>> If you used the interaction operator "*" between 'town' and the numeric version of 'year' it will give you two sets of coefficients involving 'town'. The first set will be the mean deviations from the base factor level. The other set will be the differences in slopes for the time trends for each of the (factored) towns from the overall time trend/slope. And for your data you wouldbe constructing a saturated model ... as you observed in your first message (which remains in the copied thread below).
>>>
>>>


From dwinsemius at comcast.net  Sun May 14 21:08:07 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 May 2017 12:08:07 -0700
Subject: [R] Error: invalid type (closure) for the variable 'time' -
	object specific trend
In-Reply-To: <18fddf35-a436-6a8a-e14c-c0b8fa06d724@uni-bayreuth.de>
References: <0c9ea81c-1c55-6a60-26a3-fb859c8b4867@uni-bayreuth.de>
 <ec064fa4-7f9b-c856-5a04-eef72e73125d@gmail.com>
 <05d174e1-97b7-26f1-0fd5-6c9e5dc6e4ea@uni-bayreuth.de>
 <5914CB39.8050701@sapo.pt>
 <7b97dba318bd42e291fb673adce57406@exch-2p-mbx-w2.ads.tamu.edu>
 <0d4c0905-4c64-d1a8-4b3e-89ef367e50f8@uni-bayreuth.de>
 <90C874C2-BE0F-4959-B317-277D0291587D@gmail.com>
 <001443c2-a544-d672-4de4-99cf542b594c@uni-bayreuth.de>
 <B3E8758D-8993-4BD5-8C61-4AD69E552EE3@comcast.net>
 <4c5686d6-e6d4-eacc-ee31-ee1323830529@uni-bayreuth.de>
 <6034D452-2F97-4F2B-BB68-52E68978D6FE@gmail.com>
 <18fddf35-a436-6a8a-e14c-c0b8fa06d724@uni-bayreuth.de>
Message-ID: <4E80E4C8-4DA6-4856-9E50-C138BD755C4A@comcast.net>


> On May 14, 2017, at 11:43 AM, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Hey Peter,
> 
> it is not necessary to use "factor(town)". I can just use  "town" as the name of the towns is already numeric.
> 

Isn't it a discrete variable? You most probably do want a different estimate for town.

-- 
David
> 
> 
> Am 14.05.2017 um 20:24 schrieb peter dalgaard:
>>> On 14 May 2017, at 10:22 , Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
>>> 
>>> Hey David,
>>> 
>>> when I used your suggested formula: plm( log(revenue) ~ log(supply) + factor(town) + as.numeric(as.character(year)), data=R_Test_log_Neu) I will get the same results as without considering town and year in the formula. So this might not the clue for taking into account a linear trend.
>> You probably still want a "*" in the model formula.
>> 
>> (It is not obvious to me why a plain factor(town)*year term does not work, something in the panel data frame setup auto-converts it to a factor? But why do you need to say factor(town) then?)
>> 
>> -pd
>> 
>>> Please find attached the results of str(R_Test_log_Neu):
>>>  Classes ?tbl_df?, ?tbl? and 'data.frame':	132 obs. of  4 variables:
>>>  $ town   : num  1 1 1 1 1 1 1 1 1 1 ...
>>>  $ year   : num  1 2 3 4 5 6 7 8 9 10 ...
>>>  $ revenue: num  39.9 43.3 44 43.2 39.1 ...
>>>  $ supply : num  1 1 1 1 1 1 35 101 181 323 ...
>>> 
>>> 
>>> 
>>> Hope this is helpful.
>>> 
>>> Toby
>>> 
>>> 
>>> 
>>> Am 13.05.2017 um 16:40 schrieb David Winsemius:
>>>>> On May 13, 2017, at 4:07 AM, Tobias Christoph <s3tochri at uni-bayreuth.de>
>>>>>  wrote:
>>>>> 
>>>>> Hey Peter,
>>>>> 
>>>>> thank you. Yes, I want to have "year" in the varibale.
>>>>> But if I use "*town*year*" as a furmula, R will create new factor
>>>>> variable with n levels, where n = (num of towns) x (num of years). What
>>>>> I'm trying to do is create 50 (town x year) variables such that
>>>>> town1xyear is 1,2,3... when town== 1 and zero otherwise, repeat for
>>>>> town2xyear, where state == 2, etc.
>>>>> 
>>>>> It is now clear? Sorry for my bad explanations.
>>>>> 
>>>> I had suggested that you must provide str(R_Test_log_Neu). I'm still suggesting this would be a good idea.
>>>> 
>>>> Since you have not done so, we can only guess at the right course to follow from your reports of problems and errors. Peter pointed out that the `time` function was in the 'stats' package (not from plm or elsewhere as I imagined). You are implying that 'year' is currently a factor value with levels that appears as the character versions of integers.
>>>> 
>>>> You may be able to get closer to what is possible by using:
>>>> 
>>>> plm( log(revenue) ~ log(supply) + factor(town) + as.numeric(as.character(year)),
>>>>      data=R_Test_log_Neu)
>>>> 
>>>> This should fix the problem noted by Peter and avoid the potentially incorrect construction of the desired linear trend.
>>>> 
>>>> If you used the interaction operator "*" between 'town' and the numeric version of 'year' it will give you two sets of coefficients involving 'town'. The first set will be the mean deviations from the base factor level. The other set will be the differences in slopes for the time trends for each of the (factored) towns from the overall time trend/slope. And for your data you wouldbe constructing a saturated model ... as you observed in your first message (which remains in the copied thread below).
>>>> 
>>>> 
> 

David Winsemius
Alameda, CA, USA


From yoursurrogategod at gmail.com  Sun May 14 21:30:33 2017
From: yoursurrogategod at gmail.com (Yves S. Garret)
Date: Sun, 14 May 2017 15:30:33 -0400
Subject: [R] Fwd: Cannot generate a *.docx file
In-Reply-To: <CAJ=2b06vkXn=CKdqTka9cWwf_fF_CNLwny4Y2bL0MGa5f_06eA@mail.gmail.com>
References: <CAJ=2b06vkXn=CKdqTka9cWwf_fF_CNLwny4Y2bL0MGa5f_06eA@mail.gmail.com>
Message-ID: <CAJ=2b06-u6RLDYDQq-sPkrgyRKkzjAEoZ0NH_Fazk-BykEUF=Q@mail.gmail.com>

I'm using R 3.4.0.

---------- Forwarded message ----------
From: Yves S. Garret <yoursurrogategod at gmail.com>
Date: Sun, May 14, 2017 at 2:35 PM
Subject: Cannot generate a *.docx file
To: r-help <r-help at r-project.org>


Hello,

I have the following code example:

library(ReporteRs)

# Create a word document to contain R outputs
doc <- docx()

# Add a title to the document
doc <- addTitle(doc, "Simple Word document", level = 1)

# Add a paragraph of text into the Word document
cat("Output 1\n")
doc <- addParagraph(doc, "This.")
cat("Output 2\n")

# Write the Word document to a file
writeDoc(doc, file = "r-reporters-simple-word-document.docx")

When I run it, this is what I see:

source("writing_to_ms_word_new.R")
Output 1
Error in UseMethod("addParagraph") :
  no applicable method for 'addParagraph' applied to an object of class
"docx"

Why?  The library loads as it should.  So why am I getting the above error?

Thanks in advance.

	[[alternative HTML version deleted]]


From maitra at email.com  Sun May 14 18:18:08 2017
From: maitra at email.com (Ranjan Maitra)
Date: Sun, 14 May 2017 11:18:08 -0500
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <BF6BF362-0EB2-4B83-AFF9-9E7CA93BB427@comcast.net>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
 <20170514104340.ff0e3a9b11a131f900282f89@email.com>
 <BF6BF362-0EB2-4B83-AFF9-9E7CA93BB427@comcast.net>
Message-ID: <20170514111808.87541f4cc9b73e195644f525@email.com>

On Sun, 14 May 2017 09:08:46 -0700 David Winsemius <dwinsemius at comcast.net> wrote:

> 
> > On May 14, 2017, at 8:43 AM, Ranjan Maitra <maitra at email.com> wrote:
> > 
> > Thanks, Duncan!
> > 
> > This works for the particular case and is, to my mind, a great solution!
> > 
> > However, I was wondering: is it possible to use these double dots with another character, such as omega?  
> > 
> > I apologize for changing the question somewhat, but I did not realize earlier that there were separate codes for putting double dots over different letters and I thought that figuring out the simpler question would be enough for me to figure out the next step. 
> 
> I think you should be looking for a LaTeX solution. There is a tikzDevice-package.
> 
> This says you can assemble symbols with backspaces:
> 
> https://www.stat.berkeley.edu/~partha/symbols.pdf
> 
> For instance, LATEX defines \hbar (?~?) as a ??? character (\mathchar?26) followed by a backspace of 9 math units (\mkern-9mu), followed by the letter ?h?:
> 
> The second example in ?tikz, which could be a starting point for completing your task fails on my Mac by only displaying the names of the glyphs but not the glyphs themselves in the plot,  but it might have a better chance of succeeding on a Linux box.


Thanks! I was trying to avoid using tikz but I guess that there may well be no other alternative.

Best wishes,
Ranjan


From bgunter.4567 at gmail.com  Sun May 14 22:26:23 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 14 May 2017 13:26:23 -0700
Subject: [R] Fwd: Cannot generate a *.docx file
In-Reply-To: <CAJ=2b06-u6RLDYDQq-sPkrgyRKkzjAEoZ0NH_Fazk-BykEUF=Q@mail.gmail.com>
References: <CAJ=2b06vkXn=CKdqTka9cWwf_fF_CNLwny4Y2bL0MGa5f_06eA@mail.gmail.com>
 <CAJ=2b06-u6RLDYDQq-sPkrgyRKkzjAEoZ0NH_Fazk-BykEUF=Q@mail.gmail.com>
Message-ID: <CAGxFJbRMsPi4iemowC6rRHJjZ9T7r944sTiBC4NmUQaNGgGUFA@mail.gmail.com>

Sorry, no clue.

If you don't get a satisfactory reply here, you should contact the
maintainer, David Gohel
<david.gohel at lysis-consultants.fr>  .


Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 14, 2017 at 12:30 PM, Yves S. Garret
<yoursurrogategod at gmail.com> wrote:
> I'm using R 3.4.0.
>
> ---------- Forwarded message ----------
> From: Yves S. Garret <yoursurrogategod at gmail.com>
> Date: Sun, May 14, 2017 at 2:35 PM
> Subject: Cannot generate a *.docx file
> To: r-help <r-help at r-project.org>
>
>
> Hello,
>
> I have the following code example:
>
> library(ReporteRs)
>
> # Create a word document to contain R outputs
> doc <- docx()
>
> # Add a title to the document
> doc <- addTitle(doc, "Simple Word document", level = 1)
>
> # Add a paragraph of text into the Word document
> cat("Output 1\n")
> doc <- addParagraph(doc, "This.")
> cat("Output 2\n")
>
> # Write the Word document to a file
> writeDoc(doc, file = "r-reporters-simple-word-document.docx")
>
> When I run it, this is what I see:
>
> source("writing_to_ms_word_new.R")
> Output 1
> Error in UseMethod("addParagraph") :
>   no applicable method for 'addParagraph' applied to an object of class
> "docx"
>
> Why?  The library loads as it should.  So why am I getting the above error?
>
> Thanks in advance.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rbaer at atsu.edu  Sun May 14 23:57:14 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Sun, 14 May 2017 16:57:14 -0500
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <20170514111808.87541f4cc9b73e195644f525@email.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
 <20170514104340.ff0e3a9b11a131f900282f89@email.com>
 <BF6BF362-0EB2-4B83-AFF9-9E7CA93BB427@comcast.net>
 <20170514111808.87541f4cc9b73e195644f525@email.com>
Message-ID: <e152769d-efe0-ec94-131c-b68e365dd154@atsu.edu>

I got this but the spacing is all wrong and plotmath() seems to have no 
way to do kernning or overprinting.  I'm surprised Paul didn't 
generalize the hat()-type functionality.

ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
   xlab(expression(atop("\U0308",Omega)))

ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
   xlab(expression(atop("\U0308",omega)))


On 5/14/2017 11:18 AM, Ranjan Maitra wrote:
> On Sun, 14 May 2017 09:08:46 -0700 David Winsemius <dwinsemius at comcast.net> wrote:
>
>>> On May 14, 2017, at 8:43 AM, Ranjan Maitra <maitra at email.com> wrote:
>>>
>>> Thanks, Duncan!
>>>
>>> This works for the particular case and is, to my mind, a great solution!
>>>
>>> However, I was wondering: is it possible to use these double dots with another character, such as omega?
>>>
>>> I apologize for changing the question somewhat, but I did not realize earlier that there were separate codes for putting double dots over different letters and I thought that figuring out the simpler question would be enough for me to figure out the next step.
>> I think you should be looking for a LaTeX solution. There is a tikzDevice-package.
>>
>> This says you can assemble symbols with backspaces:
>>
>> https://www.stat.berkeley.edu/~partha/symbols.pdf
>>
>> For instance, LATEX defines \hbar (?~?) as a ??? character (\mathchar?26) followed by a backspace of 9 math units (\mkern-9mu), followed by the letter ?h?:
>>
>> The second example in ?tikz, which could be a starting point for completing your task fails on my Mac by only displaying the names of the glyphs but not the glyphs themselves in the plot,  but it might have a better chance of succeeding on a Linux box.
>
> Thanks! I was trying to avoid using tikz but I guess that there may well be no other alternative.
>
> Best wishes,
> Ranjan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rbaer at atsu.edu  Mon May 15 00:40:59 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Sun, 14 May 2017 17:40:59 -0500
Subject: [R] Fwd: Cannot generate a *.docx file
In-Reply-To: <CAJ=2b06-u6RLDYDQq-sPkrgyRKkzjAEoZ0NH_Fazk-BykEUF=Q@mail.gmail.com>
References: <CAJ=2b06vkXn=CKdqTka9cWwf_fF_CNLwny4Y2bL0MGa5f_06eA@mail.gmail.com>
 <CAJ=2b06-u6RLDYDQq-sPkrgyRKkzjAEoZ0NH_Fazk-BykEUF=Q@mail.gmail.com>
Message-ID: <6f818d9e-ffe2-2838-9769-eaef1f22929e@atsu.edu>

I don't know what the error is, but your code snippet worked fine for me 
on Windows 10, R 3.4.0-patched.

I noticed that rJava is a dependency.   Don't know that the patch or 
Java updates I installed today could be a difference, but you might 
update packages, patched version,  Java, etc  and try again [since it 
worked here pasted right from your example].


On 5/14/2017 2:30 PM, Yves S. Garret wrote:
> I'm using R 3.4.0.
>
> ---------- Forwarded message ----------
> From: Yves S. Garret <yoursurrogategod at gmail.com>
> Date: Sun, May 14, 2017 at 2:35 PM
> Subject: Cannot generate a *.docx file
> To: r-help <r-help at r-project.org>
>
>
> Hello,
>
> I have the following code example:
>
> library(ReporteRs)
>
> # Create a word document to contain R outputs
> doc <- docx()
>
> # Add a title to the document
> doc <- addTitle(doc, "Simple Word document", level = 1)
>
> # Add a paragraph of text into the Word document
> cat("Output 1\n")
> doc <- addParagraph(doc, "This.")
> cat("Output 2\n")
>
> # Write the Word document to a file
> writeDoc(doc, file = "r-reporters-simple-word-document.docx")
>
> When I run it, this is what I see:
>
> source("writing_to_ms_word_new.R")
> Output 1
> Error in UseMethod("addParagraph") :
>    no applicable method for 'addParagraph' applied to an object of class
> "docx"
>
> Why?  The library loads as it should.  So why am I getting the above error?
>
> Thanks in advance.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Mon May 15 00:44:45 2017
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 15 May 2017 04:14:45 +0530
Subject: [R] How to calculate Rolling mean for a List object
Message-ID: <CA+dpOJm39A6cuSLDs9pGKQF0veW806GrcQN80hEZE1626GQYXg@mail.gmail.com>

Hi again,

I am looking to find a way on how to calculate Rolling average for the
elements of a list. For example consider below object 'Data'. This is
a list, where each elements are a Matrix. Basically, I am trying to
get Rolling average of those Matrices with rolling window as 5.

Data = structure(list(`2017-03-01` = structure(c(1.24915216491479e-06,
-2.0209685810767e-06, -6.64165527006046e-06, -2.0209685810767e-06,
3.26966891657893e-06, 1.07453495291747e-05, -6.64165527006046e-06,
1.07453495291747e-05, 3.53132196103035e-05), .Dim = c(3L, 3L)),
    `2017-03-02` = structure(c(0.00863066441403338, -7.25585852047094e-05,
    -0.000950715788640005, -7.25585852047094e-05, 6.10004981580403e-07,
    7.99273256915577e-06, -0.000950715788640005, 7.99273256915577e-06,
    0.000104726642980084), .Dim = c(3L, 3L)), `2017-03-03` =
structure(c(0.000785677680557358,
    0.000283148300122928, 0.000170319078518317, 0.000283148300122928,
    0.000102043066573597, 6.13808419844048e-05, 0.000170319078518317,
    6.13808419844048e-05, 3.6921741860797e-05), .Dim = c(3L,
    3L)), `2017-03-06` = structure(c(0.000100715163251975, 1.80035062425799e-06,
    -5.05489732985851e-07, 1.80035062425799e-06, 3.21824665284709e-08,
    -9.03596565752718e-09, -5.05489732985851e-07, -9.03596565752718e-09,
    2.53705461922188e-09), .Dim = c(3L, 3L)), `2017-03-07` =
structure(c(0.000640065014281149,
    -0.000110994847091752, -0.000231235438845606, -0.000110994847091752,
    1.92478198402357e-05, 4.00989612058198e-05, -0.000231235438845606,
    4.00989612058198e-05, 8.35381203238728e-05), .Dim = c(3L,
    3L)), `2017-03-08` = structure(c(7.72648041923266e-06,
-2.11571338014623e-05,
    7.82052544997182e-06, -2.11571338014623e-05, 5.79337921544145e-05,
    -2.14146538093767e-05, 7.82052544997182e-06, -2.14146538093767e-05,
    7.91571517626794e-06), .Dim = c(3L, 3L)), `2017-03-09` =
structure(c(4.43321118550061e-05,
    1.90242249279913e-05, 5.68672547310199e-05, 1.90242249279913e-05,
    8.16385953582618e-06, 2.44034267661023e-05, 5.68672547310199e-05,
    2.44034267661023e-05, 7.29467766214148e-05), .Dim = c(3L,
    3L)), `2017-03-10` = structure(c(0.000100081081692311, 1.39245218598852e-05,
    2.0935583168872e-05, 1.39245218598852e-05, 1.93735225227204e-06,
    2.91281809264057e-06, 2.0935583168872e-05, 2.91281809264057e-06,
    4.3794355057858e-06), .Dim = c(3L, 3L)), `2017-03-14` =
structure(c(7.82185299651879e-06,
    -3.05963602958646e-05, -4.65590052688468e-05, -3.05963602958646e-05,
    0.00011968228804236, 0.000182122586662866, -4.65590052688468e-05,
    0.000182122586662866, 0.000277139058045361), .Dim = c(3L,
    3L)), `2017-03-15` = structure(c(4.02156693772954e-05, -2.2362610665311e-05,
    -2.08706726432905e-05, -2.2362610665311e-05, 1.24351120722764e-05,
    1.16054944222453e-05, -2.08706726432905e-05, 1.16054944222453e-05,
    1.08312253240602e-05), .Dim = c(3L, 3L)), `2017-03-16` =
structure(c(2.64254966198469e-05,
    5.78730550194069e-06, 5.0445603894268e-05, 5.78730550194069e-06,
    1.26744656702641e-06, 1.10478196556107e-05, 5.0445603894268e-05,
    1.10478196556107e-05, 9.62993804379875e-05), .Dim = c(3L,
    3L)), `2017-03-17` = structure(c(0.000138433807049962, 8.72005344938308e-05,
    0.00014374477881467, 8.72005344938308e-05, 5.49282966209652e-05,
    9.05459570205481e-05, 0.00014374477881467, 9.05459570205481e-05,
    0.000149259504428865), .Dim = c(3L, 3L)), `2017-03-20` =
structure(c(3.92058275846982e-05,
    1.24332187386233e-05, -1.24235553811814e-05, 1.24332187386233e-05,
    3.94290690251335e-06, -3.93984239286701e-06, -1.24235553811814e-05,
    -3.93984239286701e-06, 3.93678026502162e-06), .Dim = c(3L,
    3L)), `2017-03-21` = structure(c(0.000407544227952838,
-6.22427018306449e-05,
    1.90596071859105e-05, -6.22427018306449e-05, 9.50609446890975e-06,
    -2.9109023406881e-06, 1.90596071859105e-05, -2.9109023406881e-06,
    8.91360007491622e-07), .Dim = c(3L, 3L)), `2017-03-22` =
structure(c(0.000220297355944482,
    0.000282600064158173, 8.26030839524992e-05, 0.000282600064158173,
    0.000362522718077154, 0.00010596421697645, 8.26030839524992e-05,
    0.00010596421697645, 3.09729976068491e-05), .Dim = c(3L,
    3L)), `2017-03-23` = structure(c(1.19559010537042e-05, 3.56054556562106e-05,
    5.51130473489473e-06, 3.56054556562106e-05, 0.000106035376739222,
    1.64130261253175e-05, 5.51130473489473e-06, 1.64130261253175e-05,
    2.54054292892148e-06), .Dim = c(3L, 3L)), `2017-03-24` =
structure(c(0.000573948692221572,
    -7.36566239512158e-05, 5.40736580500709e-05, -7.36566239512158e-05,
    9.45258404700116e-06, -6.93944101735685e-06, 5.40736580500709e-05,
    -6.93944101735685e-06, 5.0944632064554e-06), .Dim = c(3L,
    3L)), `2017-03-27` = structure(c(6.50931905856128e-06, -6.3937553506226e-07,
    3.58314387213273e-06, -6.3937553506226e-07, 6.28024331206322e-08,
    -3.51953024554351e-07, 3.58314387213273e-06, -3.51953024554351e-07,
    1.97239064376729e-06), .Dim = c(3L, 3L)), `2017-03-28` =
structure(c(3.59914960259327e-06,
    -2.75070253522731e-05, -2.11089438966147e-05, -2.75070253522731e-05,
    0.000210226449932902, 0.000161328179997165, -2.11089438966147e-05,
    0.000161328179997165, 0.000123803554069931), .Dim = c(3L,
    3L)), `2017-03-29` = structure(c(1.99662109539135e-05,
-1.93486727571024e-05,
    4.47577307389393e-05, -1.93486727571024e-05, 1.87502344999545e-05,
    -4.33734115810541e-05, 4.47577307389393e-05, -4.33734115810541e-05,
    0.0001003322295614), .Dim = c(3L, 3L)), `2017-03-30` =
structure(c(2.23173776734009e-06,
    4.62524439467561e-06, -2.71773191047607e-05, 4.62524439467561e-06,
    9.58575242286433e-06, -5.63246025994455e-05, -2.71773191047607e-05,
    -5.63246025994455e-05, 0.000330955851772093), .Dim = c(3L,
    3L)), `2017-03-31` = structure(c(4.71973793042384e-05, 0.000129971028444871,
    0.000195018983782496, 0.000129971028444871, 0.000357911148543379,
    0.000537038671683375, 0.000195018983782496, 0.000537038671683375,
    0.000805816013435771), .Dim = c(3L, 3L))), .Names = c("2017-03-01",
"2017-03-02", "2017-03-03", "2017-03-06", "2017-03-07", "2017-03-08",
"2017-03-09", "2017-03-10", "2017-03-14", "2017-03-15", "2017-03-16",
"2017-03-17", "2017-03-20", "2017-03-21", "2017-03-22", "2017-03-23",
"2017-03-24", "2017-03-27", "2017-03-28", "2017-03-29", "2017-03-30",
"2017-03-31"))

Normal rollmean() function works smoothly with a Zoo vector. However
in my case, that function is not working, throwing below error :

> rollmean(Data)
Error in zoo(x) : ?x? : attempt to define invalid zoo object

Appreciate if someone points to some solution.

Thanks for your time


From ggrothendieck at gmail.com  Mon May 15 01:07:04 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 14 May 2017 19:07:04 -0400
Subject: [R] How to calculate Rolling mean for a List object
In-Reply-To: <CA+dpOJm39A6cuSLDs9pGKQF0veW806GrcQN80hEZE1626GQYXg@mail.gmail.com>
References: <CA+dpOJm39A6cuSLDs9pGKQF0veW806GrcQN80hEZE1626GQYXg@mail.gmail.com>
Message-ID: <CAP01uRnXxcBfAsY7H0Q38EV=Ki8pkVCjqTV3b9Zk=Y-OrT+BPA@mail.gmail.com>

Try this code which does not use rollapply:

w <- 3
Mean <- function(L) Reduce("+", L) / length(L)
lapply(w:length(Data), function(i) Mean(Data[seq(to = i, length = w)]))

On Sun, May 14, 2017 at 6:44 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I am looking to find a way on how to calculate Rolling average for the
> elements of a list. For example consider below object 'Data'. This is
> a list, where each elements are a Matrix. Basically, I am trying to
> get Rolling average of those Matrices with rolling window as 5.
>
> Data = structure(list(`2017-03-01` = structure(c(1.24915216491479e-06,
> -2.0209685810767e-06, -6.64165527006046e-06, -2.0209685810767e-06,
> 3.26966891657893e-06, 1.07453495291747e-05, -6.64165527006046e-06,
> 1.07453495291747e-05, 3.53132196103035e-05), .Dim = c(3L, 3L)),
>     `2017-03-02` = structure(c(0.00863066441403338, -7.25585852047094e-05,
>     -0.000950715788640005, -7.25585852047094e-05, 6.10004981580403e-07,
>     7.99273256915577e-06, -0.000950715788640005, 7.99273256915577e-06,
>     0.000104726642980084), .Dim = c(3L, 3L)), `2017-03-03` =
> structure(c(0.000785677680557358,
>     0.000283148300122928, 0.000170319078518317, 0.000283148300122928,
>     0.000102043066573597, 6.13808419844048e-05, 0.000170319078518317,
>     6.13808419844048e-05, 3.6921741860797e-05), .Dim = c(3L,
>     3L)), `2017-03-06` = structure(c(0.000100715163251975, 1.80035062425799e-06,
>     -5.05489732985851e-07, 1.80035062425799e-06, 3.21824665284709e-08,
>     -9.03596565752718e-09, -5.05489732985851e-07, -9.03596565752718e-09,
>     2.53705461922188e-09), .Dim = c(3L, 3L)), `2017-03-07` =
> structure(c(0.000640065014281149,
>     -0.000110994847091752, -0.000231235438845606, -0.000110994847091752,
>     1.92478198402357e-05, 4.00989612058198e-05, -0.000231235438845606,
>     4.00989612058198e-05, 8.35381203238728e-05), .Dim = c(3L,
>     3L)), `2017-03-08` = structure(c(7.72648041923266e-06,
> -2.11571338014623e-05,
>     7.82052544997182e-06, -2.11571338014623e-05, 5.79337921544145e-05,
>     -2.14146538093767e-05, 7.82052544997182e-06, -2.14146538093767e-05,
>     7.91571517626794e-06), .Dim = c(3L, 3L)), `2017-03-09` =
> structure(c(4.43321118550061e-05,
>     1.90242249279913e-05, 5.68672547310199e-05, 1.90242249279913e-05,
>     8.16385953582618e-06, 2.44034267661023e-05, 5.68672547310199e-05,
>     2.44034267661023e-05, 7.29467766214148e-05), .Dim = c(3L,
>     3L)), `2017-03-10` = structure(c(0.000100081081692311, 1.39245218598852e-05,
>     2.0935583168872e-05, 1.39245218598852e-05, 1.93735225227204e-06,
>     2.91281809264057e-06, 2.0935583168872e-05, 2.91281809264057e-06,
>     4.3794355057858e-06), .Dim = c(3L, 3L)), `2017-03-14` =
> structure(c(7.82185299651879e-06,
>     -3.05963602958646e-05, -4.65590052688468e-05, -3.05963602958646e-05,
>     0.00011968228804236, 0.000182122586662866, -4.65590052688468e-05,
>     0.000182122586662866, 0.000277139058045361), .Dim = c(3L,
>     3L)), `2017-03-15` = structure(c(4.02156693772954e-05, -2.2362610665311e-05,
>     -2.08706726432905e-05, -2.2362610665311e-05, 1.24351120722764e-05,
>     1.16054944222453e-05, -2.08706726432905e-05, 1.16054944222453e-05,
>     1.08312253240602e-05), .Dim = c(3L, 3L)), `2017-03-16` =
> structure(c(2.64254966198469e-05,
>     5.78730550194069e-06, 5.0445603894268e-05, 5.78730550194069e-06,
>     1.26744656702641e-06, 1.10478196556107e-05, 5.0445603894268e-05,
>     1.10478196556107e-05, 9.62993804379875e-05), .Dim = c(3L,
>     3L)), `2017-03-17` = structure(c(0.000138433807049962, 8.72005344938308e-05,
>     0.00014374477881467, 8.72005344938308e-05, 5.49282966209652e-05,
>     9.05459570205481e-05, 0.00014374477881467, 9.05459570205481e-05,
>     0.000149259504428865), .Dim = c(3L, 3L)), `2017-03-20` =
> structure(c(3.92058275846982e-05,
>     1.24332187386233e-05, -1.24235553811814e-05, 1.24332187386233e-05,
>     3.94290690251335e-06, -3.93984239286701e-06, -1.24235553811814e-05,
>     -3.93984239286701e-06, 3.93678026502162e-06), .Dim = c(3L,
>     3L)), `2017-03-21` = structure(c(0.000407544227952838,
> -6.22427018306449e-05,
>     1.90596071859105e-05, -6.22427018306449e-05, 9.50609446890975e-06,
>     -2.9109023406881e-06, 1.90596071859105e-05, -2.9109023406881e-06,
>     8.91360007491622e-07), .Dim = c(3L, 3L)), `2017-03-22` =
> structure(c(0.000220297355944482,
>     0.000282600064158173, 8.26030839524992e-05, 0.000282600064158173,
>     0.000362522718077154, 0.00010596421697645, 8.26030839524992e-05,
>     0.00010596421697645, 3.09729976068491e-05), .Dim = c(3L,
>     3L)), `2017-03-23` = structure(c(1.19559010537042e-05, 3.56054556562106e-05,
>     5.51130473489473e-06, 3.56054556562106e-05, 0.000106035376739222,
>     1.64130261253175e-05, 5.51130473489473e-06, 1.64130261253175e-05,
>     2.54054292892148e-06), .Dim = c(3L, 3L)), `2017-03-24` =
> structure(c(0.000573948692221572,
>     -7.36566239512158e-05, 5.40736580500709e-05, -7.36566239512158e-05,
>     9.45258404700116e-06, -6.93944101735685e-06, 5.40736580500709e-05,
>     -6.93944101735685e-06, 5.0944632064554e-06), .Dim = c(3L,
>     3L)), `2017-03-27` = structure(c(6.50931905856128e-06, -6.3937553506226e-07,
>     3.58314387213273e-06, -6.3937553506226e-07, 6.28024331206322e-08,
>     -3.51953024554351e-07, 3.58314387213273e-06, -3.51953024554351e-07,
>     1.97239064376729e-06), .Dim = c(3L, 3L)), `2017-03-28` =
> structure(c(3.59914960259327e-06,
>     -2.75070253522731e-05, -2.11089438966147e-05, -2.75070253522731e-05,
>     0.000210226449932902, 0.000161328179997165, -2.11089438966147e-05,
>     0.000161328179997165, 0.000123803554069931), .Dim = c(3L,
>     3L)), `2017-03-29` = structure(c(1.99662109539135e-05,
> -1.93486727571024e-05,
>     4.47577307389393e-05, -1.93486727571024e-05, 1.87502344999545e-05,
>     -4.33734115810541e-05, 4.47577307389393e-05, -4.33734115810541e-05,
>     0.0001003322295614), .Dim = c(3L, 3L)), `2017-03-30` =
> structure(c(2.23173776734009e-06,
>     4.62524439467561e-06, -2.71773191047607e-05, 4.62524439467561e-06,
>     9.58575242286433e-06, -5.63246025994455e-05, -2.71773191047607e-05,
>     -5.63246025994455e-05, 0.000330955851772093), .Dim = c(3L,
>     3L)), `2017-03-31` = structure(c(4.71973793042384e-05, 0.000129971028444871,
>     0.000195018983782496, 0.000129971028444871, 0.000357911148543379,
>     0.000537038671683375, 0.000195018983782496, 0.000537038671683375,
>     0.000805816013435771), .Dim = c(3L, 3L))), .Names = c("2017-03-01",
> "2017-03-02", "2017-03-03", "2017-03-06", "2017-03-07", "2017-03-08",
> "2017-03-09", "2017-03-10", "2017-03-14", "2017-03-15", "2017-03-16",
> "2017-03-17", "2017-03-20", "2017-03-21", "2017-03-22", "2017-03-23",
> "2017-03-24", "2017-03-27", "2017-03-28", "2017-03-29", "2017-03-30",
> "2017-03-31"))
>
> Normal rollmean() function works smoothly with a Zoo vector. However
> in my case, that function is not working, throwing below error :
>
>> rollmean(Data)
> Error in zoo(x) : ?x? : attempt to define invalid zoo object
>
> Appreciate if someone points to some solution.
>
> Thanks for your time
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From J.C.marshall at massey.ac.nz  Mon May 15 04:25:33 2017
From: J.C.marshall at massey.ac.nz (Marshall, Jonathan)
Date: Mon, 15 May 2017 02:25:33 +0000
Subject: [R] Odd results from rpart classification tree
Message-ID: <AC08C77958DA1244A5CDBCD8011E86890EB0F6@tur-exch-node2.massey.ac.nz>

The following code produces a tree with only a root. However, clearly the tree with a split at x=0.5 is better. rpart doesn't seem to want to produce it.

Running the following produces a tree with only root.

y <- c(rep(0,65),rep(1,15),rep(0,20))
x <- c(rep(0,70),rep(1,30))
f <- rpart(y ~ x, method='class', minsplit=1, cp=0.0001, parms=list(split='gini'))

Computing the improvement for a split at x=0.5 manually:

obs_L <- y[x<.5]
obs_R <- y[x>.5]
n_L <- sum(x<.5)
n_R <- sum(x>.5)
gini <- function(p) {sum(p*(1-p))}
impurity_root <- gini(prop.table(table(y)))
impurity_L <- gini(prop.table(table(obs_L)))
impurity_R <- gini(prop.table(table(obs_R)))
impurity <- impurity_root * n - (n_L*impurity_L + n_R*impurity_R) # 2.880952

Thus, an improvement of 2.88 should result in a split. It does not.

Why?

Jonathan


From aurelien.chateigner at gmail.com  Mon May 15 09:03:57 2017
From: aurelien.chateigner at gmail.com (=?UTF-8?Q?Aur=C3=A9lien_Chateigner?=)
Date: Mon, 15 May 2017 07:03:57 -0000
Subject: [R] [R-pkgs] apercu
Message-ID: <CADgKAxs0pAa3EDBSdXS+uYhH+FWJXRaYF7HrBbO78eYoN+TYhw@mail.gmail.com>

Dear All,

I am pleased to announce the availability of my package called "apercu" on
CRAN. The goal is to make your development easier by showing you a quick
view (an "aper?u" in french) of any object you want (vector, matrix, data
frame, list, array...). I first developed it after being tired to write
matrix[1:5,1:5] all the time to check my data, and I am sure that I am not
the only one doing that all the time. Thus now you can replace it by
ap(matrix) !

If you find a bug, please don't hesitate to contact me.

Best,

Aur?lien Chateigner, PhD
Postdoctoral Fellow
UR0588 Am?lioration, G?n?tique et Physiologie Foresti?res
INRA Val-de-Loire
2163 avenue de la Pomme de Pin
CS 40001 - Ardon
45075 ORLEANS CEDEX 2
France

https://www6.val-de-loire.inra.fr/uragpf/

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From blake.seers at gmail.com  Tue May  2 01:24:41 2017
From: blake.seers at gmail.com (Blake Seers)
Date: Tue, 2 May 2017 11:24:41 +1200
Subject: [R] [R-pkgs] Calculate wind fetch using fetchR
Message-ID: <CAHayGv9FbsJ-FShx7VKd+UO73LTYqd=eP3kWX_xm0OFJVfqj0w@mail.gmail.com>

Dear R users,

I am pleased to announce that the fetchR package is now available on
CRAN, which automatically calculates wind fetch lengths, for any
location(s) around the world.

Wind fetch (or just fetch) is an important calculation in many coastal
and oceanographic applications that require a measure for wind and
wave exposure. The fetchR package exports the `fetch` function that
requires; a (projected) polygon shapefile representing the coastline
and other obstructions to wind; and a points shapefile representing
the location(s) at which the fetch is to be calculated. There are
arguments that allow you to change the maximum distance and number of
directions. Finally, there are plot and kml methods that allow you to
visualise the exposure and export the vectors to a KML file,
respectively. Refer to the vignette for a reproducible example
(https://cran.r-project.org/web/packages/fetchR/vignettes/introduction-to-fetchR.html).

Also, check out the shiny application for this R package
(http://windfetch.cer.auckland.ac.nz/). Refer to the 'help' tab to get
started with a reproducible example.

fetchR on CRAN: https://cran.r-project.org/package=fetchR
fetchR on GitHub: https://github.com/blasee/fetchR
bugs, suggestions: https://github.com/blasee/fetchR/issues

Feedback, comments and suggestions are welcomed!

All the best,
Blake

---
Blake Seers  |  PhD candidate
University of Auckland
Dept. of Statistics  |  Inst. of Marine Science
Building 303 Room 361

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From mail at dirk-schumacher.net  Sat May 13 15:00:14 2017
From: mail at dirk-schumacher.net (Dirk Schumacher)
Date: Sat, 13 May 2017 15:00:14 +0200
Subject: [R] [R-pkgs] New package: ompr
Message-ID: <c3552b8e-a141-2393-e282-380e52229ea1@dirk-schumacher.net>

Dear R users,

happy to announce that the first version of ompr is on CRAN now
(https://cran.r-project.org/web/packages/ompr/).

The package lets you model mixed integer linear programs algebraically
directly in R.
There is also another package ompr.roi that can be used to solve ompr
models with ROI.

Source code and extended examples are on GitHub:
https://github.com/dirkschumacher/ompr

While testing the package I also wrote a couple of vignettes describing
how to solve various combinatorial problems:
https://dirkschumacher.github.io/ompr/articles/index.html

Any feedback is most welcome!

Best
Dirk

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From neerajdhanraj at gmail.com  Mon May 15 09:07:50 2017
From: neerajdhanraj at gmail.com (Neeraj Dhanraj)
Date: Mon, 15 May 2017 07:07:50 -0000
Subject: [R] [R-pkgs] Updated Package PSF and Publication
Message-ID: <CAC58_YkuYnunbjV=xWKO0G3pV4x6=wpEFcX2RdV=VnQ2ShNCVg@mail.gmail.com>

Dear All,

Have a look at updated version of PSF package for time series forecasting.
I am glad to inform you, it gets published in R Journal, too.

Pattern Sequence Based Forecasting (PSF) takes univariate time series data
as input and assist in forecasting its future values. This algorithm
forecasts the behavior of time series based on similarity of pattern
sequences. Initially, clustering is done with the labelling of samples from
a database. The labels associated with samples are then used for
forecasting the future behaviour of time series data. The further technical
details and references regarding PSF are discussed in Vignette.

CRAN Link: https://cran.r-project.org/package=PSF

Publication Link: https://www.researchgate.net/publication/
304131481_PSF_Introduction_to_R_Package_for_Pattern_
Sequence_Based_Forecasting_Algorithm

Please feel free to contact me with suggestions, bug reports, criticisms,
etc.

-- 
Regards ,
*Neeraj Dhanraj Bokde  *
*Research Scholar (PhD)*

*Visvesvaraya National Institute of Technology ,* Nagpur

Maharashtra, India

Phone: *+91 9028415974*

Email: h2012105 at pilani.bits-pilani.ac.in; *neerajdhanraj at gmail.com
<neerajdhanraj at gmail.com>*

Website: http://www.neerajbokde.com

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dulcalma at bigpond.com  Mon May 15 10:05:24 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 15 May 2017 18:05:24 +1000
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <20170514104340.ff0e3a9b11a131f900282f89@email.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
 <20170514104340.ff0e3a9b11a131f900282f89@email.com>
Message-ID: <000801d2cd52$021a3510$064e9f30$@bigpond.com>

Hi

I looked up for the Unicode version at
http://www.utf8-chartable.de/unicode-utf8-table.pl
You might have to go to another page to find the Unicode equivalent.

You may not be able to get the right character showing  and get at square/s
instead - it all depends on the drivers and how many characters that make up
the Unicode character
I had a case of this recently and it did not make any difference using Cairo


Regards

Duncan

 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ranjan
Maitra
Sent: Monday, 15 May 2017 01:44
To: r-help at stat.math.ethz.ch
Subject: Re: [R] display double dot over character in plotmath?

Thanks, Duncan!

This works for the particular case and is, to my mind, a great solution!

However, I was wondering: is it possible to use these double dots with
another character, such as omega?  

I apologize for changing the question somewhat, but I did not realize
earlier that there were separate codes for putting double dots over
different letters and I thought that figuring out the simpler question would
be enough for me to figure out the next step. 

Thanks again!

Best wishes,
Ranjan



On Sun, 14 May 2017 23:57:50 +1000 Duncan Mackay <dulcalma at bigpond.com>
wrote:

> Hi
> 
> I just had to do something similar in windows with \"{u}. Try Unicode
symbol
> - see ?plotmath 
> 
> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
> xlab(expression(atop(top,bold(Age~"\u00e4"))))
> 
> Regards
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ranjan
> Maitra
> Sent: Saturday, 13 May 2017 22:48
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] display double dot over character in plotmath?
> 
> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund <djnordlund at gmail.com>
> wrote:
> 
> > On 5/12/17 4:55 PM, Ranjan Maitra wrote:
> > > Hi,
> > > 
> > > Is it possible to display double dot (umlaut) over a character such as
> would be possible using \ddot x in LaTeX? I can do this using tikzDevice
but
> I wanted something simpler to point to.
> > > 
> > > Here is an example of what I would like to do, but it is not quite
> there:
> > > 
> > > require(ggplot2)
> > > data<-as.data.frame(c("a","b","c","a","b","c"))
> > > colnames(data)<-"Y"
> > > data$X<-c(1:6)
> > > data$Z<-c(1,2,3,1,2,3)
> > > 
> > > ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
> xlab(expression(atop(top,bold(Age~"?"))))
> > > 
> > > I would like to put in a double dot over the "a" in the x-axis instead
> of "`".
> > > 
> > > Many thanks for any suggestions and best wishes,
> > > Ranjan
> > > 
> > 
> > You haven't told what OS you are using, but with Windows OS, you can get

> > the '?' by making sure the NUMLOCK key is on, hold down the alt key and 
> > press 0228 on the numeric keypad.
> > 
> > 
> 
> I am sorry, I use a linux operating system. I use Fedora 25 but the
student
> I wanted to show this uses Ubuntu, though I don't know if the distribution
> matters.
> 
> Thanks again for your help, and best wishes,
> Ranjan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on
receipt. Please respond to the mailing list if appropriate. For those
needing to send personal or professional e-mail, please use appropriate
addresses.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon May 15 11:30:19 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 15 May 2017 19:30:19 +1000
Subject: [R]  Joining tables with different order and matched values
Message-ID: <CA+8X3fWzRE=CgHmnrX9hgReMVLtOCASn6no9aWsn4L1eh-9DYw@mail.gmail.com>

Hi Abo,
This is essentially the same as your other problem. Notice that this
solution will only work if the values in dt1 and dt2 are character,
not factor and that I have replaced the space in "Drug name" with an
underscore. R will automatically substitute a period when such a name
is read in.

dt1<-read.table(text="Drug_name indications
 Ibuprofen Pain
 Simvastatin hyperlipidemia
 losartan hypertension",header=TRUE,stringsAsFactors=FALSE)
dt2<-read.table(text="Drug_name indications
 Simvastatin
 losartan
 Ibuprofen
 Metformin ",fill=TRUE,header=TRUE,stringsAsFactors=FALSE)
# this gets all the values you want, but not in the correct format
dt3<-merge(dt1,dt2,by="Drug_name",all=TRUE)
# set up a new "indications" field
dt3$indications<-NA
for(i in 1:length(unique(dt3$Drug_name))) {
 all_ind<-c(dt3$indications.x[i],dt3$indications.y[i])
 notNA<-which(!is.na(all_ind))
 if(any(notNA)) dt3$indications[i]<-all_ind[notNA][1]
}
dt3<-dt3[,c("Drug_name","indications")]
dt3

Jim

Hi All ..,

I have 2 tables and I'm trying to have some information from the 1st table
to appear in the second table with different order.

For Example, let's say this is my 1st table :-


Drug name           indications
 Ibuprofen                Pain
 Simvastatin            hyperlipidemia
losartan                   hypertension


my 2nd table is in different order for the 1st column :-

Drug name       indications

Simvastatin
losartan
Ibuprofen
Metformin

I wish to see the indication of each drug in my 2nd table subsisted from
the information in my 1st table so the final table
would be like this

Drug name       indications

Simvastatin     hyperlipidemia
losartan           hypertension
Ibuprofen       pain
Metformin    N/A


From patrcasi at nova.edu  Mon May 15 14:10:54 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Mon, 15 May 2017 12:10:54 +0000
Subject: [R] Uisng a Dictionary with tm Package
Message-ID: <CY4PR06MB3032B644DE239D754379584AB9E10@CY4PR06MB3032.namprd06.prod.outlook.com>

Hello Fellows,


I used the dictionary function to capture terms from a corpus of 102 docs but the dictionary only captures those terms in 10 documents. I need those terms from all 102 docs. Any idea why? How do I get the dictionary to return for all 102 docs? See my coding below.


> myTerms <- c("prostatic", "adenocarcinoma", "grade")
> inspect(DocumentTermMatrix(docs, list(dictionary = myTerms)))

<<DocumentTermMatrix (documents: 102, terms: 3)>>
Non-/sparse entries: 292/14
Sparsity           : 5%
Maximal term length: 14
Weighting          : term frequency (tf)
Sample             :
               Terms
Docs            adenocarcinoma grade prostatic
  Patient14.txt             11     6         3
  Patient15.txt              7    12         2
  Patient16.txt             13    16         4
  Patient19.txt              5    13         2
  Patient24.txt             11    12         4
  Patient25.txt              8     9         4
  Patient41.txt              8    10         4
  Patient46.txt              8    10         3
  Patient8.txt               9    12         2
  Patient9.txt               8    23         2


Pat



	[[alternative HTML version deleted]]


From olivier.crouzet at univ-nantes.fr  Mon May 15 14:18:44 2017
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Mon, 15 May 2017 14:18:44 +0200
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <20170514104340.ff0e3a9b11a131f900282f89@email.com>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
 <20170514104340.ff0e3a9b11a131f900282f89@email.com>
Message-ID: <20170515141844.bc9c11c0a68fa6776d0ceeb2@univ-nantes.fr>

Hi,

The following simple solution gives appropriate results in base R (and
should work with any base character):

plot(rnorm(100), rnorm(100), main = expression(paste(omega, "\u0308")))

In your ggplot example, something like:

ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab
(expression(atop(top, bold(Age~paste(omega,"\u0308")))))

seems to produce what you need (AFAICT).

Note that, contrary to Robert's examples, one has to put
the corresponding diacritic AFTER the base character in unicode
conventions. Also, one needs to put the omega and "\u0308" within a 
paste() function in order to concatenate them correctly and to reach a
state in which they "combine" together.

Inserting this into your own code, the characters are not bold though
and I'm not sure what the solution would be. This may be an issue with
the font that is used. Also note that in order to export the graph to
pdf, you'd need to use cairo_pdf() in order to get the character
displayed correctly.

Olivier.


On Sun, 14 May 2017 10:43:40 -0500
Ranjan Maitra <maitra at email.com> wrote:

> Thanks, Duncan!
> 
> This works for the particular case and is, to my mind, a great
> solution!
> 
> However, I was wondering: is it possible to use these double dots
> with another character, such as omega?  
> 
> I apologize for changing the question somewhat, but I did not realize
> earlier that there were separate codes for putting double dots over
> different letters and I thought that figuring out the simpler
> question would be enough for me to figure out the next step. 
> 
> Thanks again!
> 
> Best wishes,
> Ranjan
> 
> 
> 
> On Sun, 14 May 2017 23:57:50 +1000 Duncan Mackay
> <dulcalma at bigpond.com> wrote:
> 
> > Hi
> > 
> > I just had to do something similar in windows with \"{u}. Try
> > Unicode symbol
> > - see ?plotmath 
> > 
> > ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
> > xlab(expression(atop(top,bold(Age~"\u00e4"))))
> > 
> > Regards
> > 
> > Duncan
> > 
> > Duncan Mackay
> > Department of Agronomy and Soil Science
> > University of New England
> > Armidale NSW 2351
> > Email: home: mackay at northnet.com.au
> > 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Ranjan Maitra
> > Sent: Saturday, 13 May 2017 22:48
> > To: r-help at stat.math.ethz.ch
> > Subject: Re: [R] display double dot over character in plotmath?
> > 
> > On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund
> > <djnordlund at gmail.com> wrote:
> > 
> > > On 5/12/17 4:55 PM, Ranjan Maitra wrote:
> > > > Hi,
> > > > 
> > > > Is it possible to display double dot (umlaut) over a character
> > > > such as
> > would be possible using \ddot x in LaTeX? I can do this using
> > tikzDevice but I wanted something simpler to point to.
> > > > 
> > > > Here is an example of what I would like to do, but it is not
> > > > quite
> > there:
> > > > 
> > > > require(ggplot2)
> > > > data<-as.data.frame(c("a","b","c","a","b","c"))
> > > > colnames(data)<-"Y"
> > > > data$X<-c(1:6)
> > > > data$Z<-c(1,2,3,1,2,3)
> > > > 
> > > > ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
> > xlab(expression(atop(top,bold(Age~"?"))))
> > > > 
> > > > I would like to put in a double dot over the "a" in the x-axis
> > > > instead
> > of "`".
> > > > 
> > > > Many thanks for any suggestions and best wishes,
> > > > Ranjan
> > > > 
> > > 
> > > You haven't told what OS you are using, but with Windows OS, you
> > > can get the '?' by making sure the NUMLOCK key is on, hold down
> > > the alt key and press 0228 on the numeric keypad.
> > > 
> > > 
> > 
> > I am sorry, I use a linux operating system. I use Fedora 25 but the
> > student I wanted to show this uses Ubuntu, though I don't know if
> > the distribution matters.
> > 
> > Thanks again for your help, and best wishes,
> > Ranjan
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code.
> > 
> 
> 
> -- 
> Important Notice: This mailbox is ignored: e-mails are set to be
> deleted on receipt. Please respond to the mailing list if
> appropriate. For those needing to send personal or professional
> e-mail, please use appropriate addresses.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  /Assistant Professor/
  @LLING - Laboratoire de Linguistique de Nantes
    UMR6310 CNRS / Universit? de Nantes
  /Guest Researcher/
  @UMCG (University Medical Center Groningen)
    ENT department
    Reijksuniversiteit Groningen


From murdoch.duncan at gmail.com  Mon May 15 14:40:42 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 15 May 2017 08:40:42 -0400
Subject: [R] display double dot over character in plotmath?
In-Reply-To: <20170515141844.bc9c11c0a68fa6776d0ceeb2@univ-nantes.fr>
References: <20170512185506.d3423854090264785a15ef80@email.com>
 <a4d15598-ba6f-528f-d554-a5c9816efaf9@gmail.com>
 <20170513074745.a79bde205f3a272aabc4a260@email.com>
 <000001d2ccba$13a2deb0$3ae89c10$@bigpond.com>
 <20170514104340.ff0e3a9b11a131f900282f89@email.com>
 <20170515141844.bc9c11c0a68fa6776d0ceeb2@univ-nantes.fr>
Message-ID: <8cc223fa-16be-32cc-b595-9a41827f52df@gmail.com>

On 15/05/2017 8:18 AM, Olivier Crouzet wrote:
> Hi,
>
> The following simple solution gives appropriate results in base R (and
> should work with any base character):
>
> plot(rnorm(100), rnorm(100), main = expression(paste(omega, "\u0308")))

It doesn't work for me on Mac OS or Windows 10 in the default device or 
pdf().  The trouble with Unicode solutions is that R graphics devices 
aren't required to support it.

Duncan Murdoch

>
> In your ggplot example, something like:
>
> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) + xlab
> (expression(atop(top, bold(Age~paste(omega,"\u0308")))))
>
> seems to produce what you need (AFAICT).
>
> Note that, contrary to Robert's examples, one has to put
> the corresponding diacritic AFTER the base character in unicode
> conventions. Also, one needs to put the omega and "\u0308" within a
> paste() function in order to concatenate them correctly and to reach a
> state in which they "combine" together.
>
> Inserting this into your own code, the characters are not bold though
> and I'm not sure what the solution would be. This may be an issue with
> the font that is used. Also note that in order to export the graph to
> pdf, you'd need to use cairo_pdf() in order to get the character
> displayed correctly.
>
> Olivier.
>
>
> On Sun, 14 May 2017 10:43:40 -0500
> Ranjan Maitra <maitra at email.com> wrote:
>
>> Thanks, Duncan!
>>
>> This works for the particular case and is, to my mind, a great
>> solution!
>>
>> However, I was wondering: is it possible to use these double dots
>> with another character, such as omega?
>>
>> I apologize for changing the question somewhat, but I did not realize
>> earlier that there were separate codes for putting double dots over
>> different letters and I thought that figuring out the simpler
>> question would be enough for me to figure out the next step.
>>
>> Thanks again!
>>
>> Best wishes,
>> Ranjan
>>
>>
>>
>> On Sun, 14 May 2017 23:57:50 +1000 Duncan Mackay
>> <dulcalma at bigpond.com> wrote:
>>
>>> Hi
>>>
>>> I just had to do something similar in windows with \"{u}. Try
>>> Unicode symbol
>>> - see ?plotmath
>>>
>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
>>> xlab(expression(atop(top,bold(Age~"\u00e4"))))
>>>
>>> Regards
>>>
>>> Duncan
>>>
>>> Duncan Mackay
>>> Department of Agronomy and Soil Science
>>> University of New England
>>> Armidale NSW 2351
>>> Email: home: mackay at northnet.com.au
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> Ranjan Maitra
>>> Sent: Saturday, 13 May 2017 22:48
>>> To: r-help at stat.math.ethz.ch
>>> Subject: Re: [R] display double dot over character in plotmath?
>>>
>>> On Fri, 12 May 2017 23:39:14 -0700 Daniel Nordlund
>>> <djnordlund at gmail.com> wrote:
>>>
>>>> On 5/12/17 4:55 PM, Ranjan Maitra wrote:
>>>>> Hi,
>>>>>
>>>>> Is it possible to display double dot (umlaut) over a character
>>>>> such as
>>> would be possible using \ddot x in LaTeX? I can do this using
>>> tikzDevice but I wanted something simpler to point to.
>>>>>
>>>>> Here is an example of what I would like to do, but it is not
>>>>> quite
>>> there:
>>>>>
>>>>> require(ggplot2)
>>>>> data<-as.data.frame(c("a","b","c","a","b","c"))
>>>>> colnames(data)<-"Y"
>>>>> data$X<-c(1:6)
>>>>> data$Z<-c(1,2,3,1,2,3)
>>>>>
>>>>> ggplot(data, aes(x=X)) + geom_line(aes(y = Z), size=0.43) +
>>> xlab(expression(atop(top,bold(Age~"?"))))
>>>>>
>>>>> I would like to put in a double dot over the "a" in the x-axis
>>>>> instead
>>> of "`".
>>>>>
>>>>> Many thanks for any suggestions and best wishes,
>>>>> Ranjan
>>>>>
>>>>
>>>> You haven't told what OS you are using, but with Windows OS, you
>>>> can get the '?' by making sure the NUMLOCK key is on, hold down
>>>> the alt key and press 0228 on the numeric keypad.
>>>>
>>>>
>>>
>>> I am sorry, I use a linux operating system. I use Fedora 25 but the
>>> student I wanted to show this uses Ubuntu, though I don't know if
>>> the distribution matters.
>>>
>>> Thanks again for your help, and best wishes,
>>> Ranjan
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html and provide commented,
>>> minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html and provide commented,
>>> minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Important Notice: This mailbox is ignored: e-mails are set to be
>> deleted on receipt. Please respond to the mailing list if
>> appropriate. For those needing to send personal or professional
>> e-mail, please use appropriate addresses.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
>
>


From therneau at mayo.edu  Mon May 15 14:43:11 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 15 May 2017 07:43:11 -0500
Subject: [R] Odd results from rpart classification tree
In-Reply-To: <mailman.1.1494842401.27874.r-help@r-project.org>
References: <mailman.1.1494842401.27874.r-help@r-project.org>
Message-ID: <47cabe$6iteev@ironport10.mayo.edu>

You are mixing up two of the steps in rpart.  1: how to find the best candidate split and 
2: evaluation of that split.

With the "class" method we use the information or Gini criteria for step 1.  The code 
finds a worthwhile candidate split at 0.5 using exactly the calculations you outline.  For 
step 2 the criteria is the "decision theory" loss.  In your data the estimated rate is 0 
for the left node and 15/45 = .333 for the right node.  As a decision rule both predict 
y=0 (since both are < 1/2).  The split predicts 0 on the left and 0 on the right, so does 
nothing.

The CART book (Brieman, Freidman, Olshen and Stone) on which rpart is based highlights the 
difference between odds-regression (for which the final prediction is a percent, and error 
is Gini) and classification.  For the former treat y as continuous.

Terry T.


On 05/15/2017 05:00 AM, r-help-request at r-project.org wrote:
> The following code produces a tree with only a root. However, clearly the tree with a split at x=0.5 is better. rpart doesn't seem to want to produce it.
>
> Running the following produces a tree with only root.
>
> y <- c(rep(0,65),rep(1,15),rep(0,20))
> x <- c(rep(0,70),rep(1,30))
> f <- rpart(y ~ x, method='class', minsplit=1, cp=0.0001, parms=list(split='gini'))
>
> Computing the improvement for a split at x=0.5 manually:
>
> obs_L <- y[x<.5]
> obs_R <- y[x>.5]
> n_L <- sum(x<.5)
> n_R <- sum(x>.5)
> gini <- function(p) {sum(p*(1-p))}
> impurity_root <- gini(prop.table(table(y)))
> impurity_L <- gini(prop.table(table(obs_L)))
> impurity_R <- gini(prop.table(table(obs_R)))
> impurity <- impurity_root * n - (n_L*impurity_L + n_R*impurity_R) # 2.880952
>
> Thus, an improvement of 2.88 should result in a split. It does not.
>
> Why?
>
> Jonathan
>
>


From br at dmstat1.com  Mon May 15 19:15:44 2017
From: br at dmstat1.com (Bruce Ratner PhD)
Date: Mon, 15 May 2017 13:15:44 -0400
Subject: [R] Xtable with long column headings/names
Message-ID: <CB805CD7-E227-4061-8E81-661E20C44A27@dmstat1.com>

R-help:
I'm using xtable that produces a table in html with one-line for each of the
long column headings/names. 

I would like to word wrap the column headings to break into two-lines. 
Any suggestion as to which argument needs adjustment is appreciated. 
Bruce


From br at dmstat1.com  Mon May 15 19:32:48 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 15 May 2017 13:32:48 -0400
Subject: [R] Xtable with long column headings/names
In-Reply-To: <700479592.1833249.1494868927597@mail.yahoo.com>
References: <CB805CD7-E227-4061-8E81-661E20C44A27@dmstat1.com>
 <700479592.1833249.1494868927597@mail.yahoo.com>
Message-ID: <34d1802e-37d0-6d50-072b-e024112fbd11@dmstat1.com>

John:
After I generate the xtable table, I manually edited (by inserting 
<br/>) the html header, below.
Is there a way in xtable that I can set some setting to affect my xtable 
table?
Thanks for your reply.
Bruce

<table border=1>
<caption align="top"> Analysis </caption>
<tr> <th> DECILE </th>
<th> NUMBER OF <br /> INDIVIDUALS <br /> </th>
<th> NUMBER OF <br /> RESPONDERS <br /> </th>
<th> RESPONSE <br /> RATE (%) <br /> </th>
<th> CUM RESPONSE <br /> RATE (%) <br />
</th> <th> CUM LIFT </th>  </tr>

  

John Kane wrote:
> Can you give us an example. I am having a problem visualizing this.  
> It seems obvious just to put in a line break normally but in xtabs who 
> knows?
>
>
> On Monday, May 15, 2017 1:15 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
>
>
> R-help:
> I'm using xtable that produces a table in html with one-line for each 
> of the
> long column headings/names.
>
> I would like to word wrap the column headings to break into two-lines.
> Any suggestion as to which argument needs adjustment is appreciated.
> Bruce
>
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>


From br at dmstat1.com  Mon May 15 19:40:10 2017
From: br at dmstat1.com (BR_email)
Date: Mon, 15 May 2017 13:40:10 -0400
Subject: [R] Xtable with long column headings/names
In-Reply-To: <34d1802e-37d0-6d50-072b-e024112fbd11@dmstat1.com>
References: <CB805CD7-E227-4061-8E81-661E20C44A27@dmstat1.com>
 <700479592.1833249.1494868927597@mail.yahoo.com>
 <34d1802e-37d0-6d50-072b-e024112fbd11@dmstat1.com>
Message-ID: <69e3c7de-dc0a-4af5-266c-c3b0a5f68573@dmstat1.com>

John:
Here is the code of my xtable:
TABLE <-xtable(dec_analy, digits = c(0,0,0,0,2,2,0),
                       align = "ccccccc", latex.environments = "center",
                       caption = "Analysis ")
print.xtable(TABLE, type="html",file="C:/R_Data/Table.html",
              include.rownames = FALSE,
              caption.placement = "top",
              align = "p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}")

  

BR_email wrote:
> John:
> After I generate the xtable table, I manually edited (by inserting 
> <br/>) the html header, below.
> Is there a way in xtable that I can set some setting to affect my 
> xtable table?
> Thanks for your reply.
> Bruce
>
> <table border=1>
> <caption align="top"> Analysis </caption>
> <tr> <th> DECILE </th>
> <th> NUMBER OF <br /> INDIVIDUALS <br /> </th>
> <th> NUMBER OF <br /> RESPONDERS <br /> </th>
> <th> RESPONSE <br /> RATE (%) <br /> </th>
> <th> CUM RESPONSE <br /> RATE (%) <br />
> </th> <th> CUM LIFT </th>  </tr>
>
>
>
> John Kane wrote:
>> Can you give us an example. I am having a problem visualizing this.  
>> It seems obvious just to put in a line break normally but in xtabs 
>> who knows?
>>
>>
>> On Monday, May 15, 2017 1:15 PM, Bruce Ratner PhD <br at dmstat1.com> 
>> wrote:
>>
>>
>> R-help:
>> I'm using xtable that produces a table in html with one-line for each 
>> of the
>> long column headings/names.
>>
>> I would like to word wrap the column headings to break into two-lines.
>> Any suggestion as to which argument needs adjustment is appreciated.
>> Bruce
>>
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html 
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From jrkrideau at yahoo.ca  Mon May 15 19:22:07 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 15 May 2017 17:22:07 +0000 (UTC)
Subject: [R] Xtable with long column headings/names
In-Reply-To: <CB805CD7-E227-4061-8E81-661E20C44A27@dmstat1.com>
References: <CB805CD7-E227-4061-8E81-661E20C44A27@dmstat1.com>
Message-ID: <700479592.1833249.1494868927597@mail.yahoo.com>

Can you give us an example. I am having a problem visualizing this.? It seems obvious just to put in a line break normally but in xtabs who knows?
 

    On Monday, May 15, 2017 1:15 PM, Bruce Ratner PhD <br at dmstat1.com> wrote:
 

 R-help:
I'm using xtable that produces a table in html with one-line for each of the
long column headings/names. 

I would like to word wrap the column headings to break into two-lines. 
Any suggestion as to which argument needs adjustment is appreciated. 
Bruce

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From lucymcmahon004 at hotmail.co.uk  Mon May 15 19:40:29 2017
From: lucymcmahon004 at hotmail.co.uk (Lucy McMahon)
Date: Mon, 15 May 2017 17:40:29 +0000
Subject: [R] Tukey tests in two-way ANOVA
Message-ID: <DB6PR0202MB2776136CBE8EE0000718ECD8CEE10@DB6PR0202MB2776.eurprd02.prod.outlook.com>

R-help:

I'm looking into the abundance of an algal species over site and years using a two-way ANOVA:

> summary (aov (fserratus ~ site+year))
            Df     Sum Sq   Mean Sq   F value      Pr(>F)
site       1      1487       1486.6      6.094       0.0155 *
year      1      1173      1172.8      4.808       0.0309 *

But I'm receiving the following warning messages when I run the Tukey test.
> TukeyHSD(aov(fserratus ~ site+year))

$site
                    diff              lwr                      upr                 p adj
1-0         -8.039565     -14.51045     -1.568685    0.0154723

Warning messages:
1: In replications(paste("~", xx), data = mf) : non-factors ignored: year
2: In TukeyHSD.aov(aov(fserratus ~ site + year)) :
  'which' specified some non-factors which will be dropped


Any advice would be appreciated, thanks.




	[[alternative HTML version deleted]]


From sylvie.celerier at free.fr  Mon May 15 22:15:14 2017
From: sylvie.celerier at free.fr (sylvie.celerier at free.fr)
Date: Mon, 15 May 2017 22:15:14 +0200 (CEST)
Subject: [R] plot problems
In-Reply-To: <1292384328.208647554.1494879012576.JavaMail.root@spooler7-g27.priv.proxad.net>
Message-ID: <501065229.208665498.1494879314869.JavaMail.root@spooler7-g27.priv.proxad.net>

Hello all, 
I'm using RStudio Version 1.0.136 on wondow 7 (64 bite) and I can't understand why all my plots are displayed ouside of the Rstudio graphic pane. How can I make them go back to the graphic panes ?
thanks a lot for your help 
sylvie


From pdalgd at gmail.com  Tue May 16 01:02:05 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 16 May 2017 01:02:05 +0200
Subject: [R] Tukey tests in two-way ANOVA
In-Reply-To: <DB6PR0202MB2776136CBE8EE0000718ECD8CEE10@DB6PR0202MB2776.eurprd02.prod.outlook.com>
References: <DB6PR0202MB2776136CBE8EE0000718ECD8CEE10@DB6PR0202MB2776.eurprd02.prod.outlook.com>
Message-ID: <8D58EA3A-81AB-49DA-A38E-1861B5ADBAD7@gmail.com>

I think you forgot to turn site and year into factors. (The 1 Df is the giveaway).

-pd

> On 15 May 2017, at 19:40 , Lucy McMahon <lucymcmahon004 at hotmail.co.uk> wrote:
> 
> R-help:
> 
> I'm looking into the abundance of an algal species over site and years using a two-way ANOVA:
> 
>> summary (aov (fserratus ~ site+year))
>            Df     Sum Sq   Mean Sq   F value      Pr(>F)
> site       1      1487       1486.6      6.094       0.0155 *
> year      1      1173      1172.8      4.808       0.0309 *
> 
> But I'm receiving the following warning messages when I run the Tukey test.
>> TukeyHSD(aov(fserratus ~ site+year))
> 
> $site
>                    diff              lwr                      upr                 p adj
> 1-0         -8.039565     -14.51045     -1.568685    0.0154723
> 
> Warning messages:
> 1: In replications(paste("~", xx), data = mf) : non-factors ignored: year
> 2: In TukeyHSD.aov(aov(fserratus ~ site + year)) :
>  'which' specified some non-factors which will be dropped
> 
> 
> Any advice would be appreciated, thanks.
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rmh at temple.edu  Tue May 16 01:02:28 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 15 May 2017 19:02:28 -0400
Subject: [R] Tukey tests in two-way ANOVA
In-Reply-To: <DB6PR0202MB2776136CBE8EE0000718ECD8CEE10@DB6PR0202MB2776.eurprd02.prod.outlook.com>
References: <DB6PR0202MB2776136CBE8EE0000718ECD8CEE10@DB6PR0202MB2776.eurprd02.prod.outlook.com>
Message-ID: <CAGx1TMAjDproJA6ibGaPfEeW99WxYnBfQAXVuVtOvH+wxehR6g@mail.gmail.com>

you have only one df for site and one df for year.  most likely you
skipped the step of
telling R those are factors.

On Mon, May 15, 2017 at 1:40 PM, Lucy McMahon
<lucymcmahon004 at hotmail.co.uk> wrote:
> R-help:
>
> I'm looking into the abundance of an algal species over site and years using a two-way ANOVA:
>
>> summary (aov (fserratus ~ site+year))
>             Df     Sum Sq   Mean Sq   F value      Pr(>F)
> site       1      1487       1486.6      6.094       0.0155 *
> year      1      1173      1172.8      4.808       0.0309 *
>
> But I'm receiving the following warning messages when I run the Tukey test.
>> TukeyHSD(aov(fserratus ~ site+year))
>
> $site
>                     diff              lwr                      upr                 p adj
> 1-0         -8.039565     -14.51045     -1.568685    0.0154723
>
> Warning messages:
> 1: In replications(paste("~", xx), data = mf) : non-factors ignored: year
> 2: In TukeyHSD.aov(aov(fserratus ~ site + year)) :
>   'which' specified some non-factors which will be dropped
>
>
> Any advice would be appreciated, thanks.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue May 16 02:05:30 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 15 May 2017 20:05:30 -0400
Subject: [R] plot problems
In-Reply-To: <501065229.208665498.1494879314869.JavaMail.root@spooler7-g27.priv.proxad.net>
References: <501065229.208665498.1494879314869.JavaMail.root@spooler7-g27.priv.proxad.net>
Message-ID: <c4bb7ebd-3368-9fa5-486d-4dff970c0a98@gmail.com>

On 15/05/2017 4:15 PM, sylvie.celerier at free.fr wrote:
> Hello all,
> I'm using RStudio Version 1.0.136 on wondow 7 (64 bite) and I can't understand why all my plots are displayed ouside of the Rstudio graphic pane. How can I make them go back to the graphic panes ?

This is a question for RStudio, and should be asked in one of their help 
forums.  This mailing list is for R itself.

Duncan Murdoch


From J.C.marshall at massey.ac.nz  Tue May 16 02:20:48 2017
From: J.C.marshall at massey.ac.nz (Marshall, Jonathan)
Date: Tue, 16 May 2017 00:20:48 +0000
Subject: [R] Odd results from rpart classification tree
In-Reply-To: <47cabe$6iteeu@ironport10.mayo.edu>
References: <mailman.1.1494842401.27874.r-help@r-project.org>,
 <47cabe$6iteeu@ironport10.mayo.edu>
Message-ID: <AC08C77958DA1244A5CDBCD8011E86890EB21A@tur-exch-node2.massey.ac.nz>

Thanks Terry!

I managed to figure that out shortly after posting (as is the way!) Adding an additional covariate that splits below one of the x branches but not the other and means the class proportion to go over 0.5 means the x split is retained.

However, I now have another conundrum, this time with rpart in anova mode...

library(rpart)
test_split <- function(offset) {
  y <- c(rep(0,10),rep(0.5,2)) + offset
  x <- c(rep(0,10),rep(1,2))
  if (is.null(rpart(y ~ x, minsplit=1, cp=0, xval=0)$splits)) 0 else 1
}

sum(replicate(1000, test_split(0))) # 1000, i.e. always splits
sum(replicate(1000, test_split(0.5))) # 2-12, i.e. splits only sometimes...

Adding a constant to y and getting different trees is a bit strange, particularly stochastically.

Will see if I can track down a copy of the CART book.

Jonathan

________________________________________
From: Therneau, Terry M., Ph.D. [therneau at mayo.edu]
Sent: 16 May 2017 00:43
To: r-help at r-project.org; Marshall, Jonathan
Subject: Re: Odd results from rpart classification tree

You are mixing up two of the steps in rpart.  1: how to find the best candidate split and
2: evaluation of that split.

With the "class" method we use the information or Gini criteria for step 1.  The code
finds a worthwhile candidate split at 0.5 using exactly the calculations you outline.  For
step 2 the criteria is the "decision theory" loss.  In your data the estimated rate is 0
for the left node and 15/45 = .333 for the right node.  As a decision rule both predict
y=0 (since both are < 1/2).  The split predicts 0 on the left and 0 on the right, so does
nothing.

The CART book (Brieman, Freidman, Olshen and Stone) on which rpart is based highlights the
difference between odds-regression (for which the final prediction is a percent, and error
is Gini) and classification.  For the former treat y as continuous.

Terry T.


On 05/15/2017 05:00 AM, r-help-request at r-project.org wrote:
> The following code produces a tree with only a root. However, clearly the tree with a split at x=0.5 is better. rpart doesn't seem to want to produce it.
>
> Running the following produces a tree with only root.
>
> y <- c(rep(0,65),rep(1,15),rep(0,20))
> x <- c(rep(0,70),rep(1,30))
> f <- rpart(y ~ x, method='class', minsplit=1, cp=0.0001, parms=list(split='gini'))
>
> Computing the improvement for a split at x=0.5 manually:
>
> obs_L <- y[x<.5]
> obs_R <- y[x>.5]
> n_L <- sum(x<.5)
> n_R <- sum(x>.5)
> gini <- function(p) {sum(p*(1-p))}
> impurity_root <- gini(prop.table(table(y)))
> impurity_L <- gini(prop.table(table(obs_L)))
> impurity_R <- gini(prop.table(table(obs_R)))
> impurity <- impurity_root * n - (n_L*impurity_L + n_R*impurity_R) # 2.880952
>
> Thus, an improvement of 2.88 should result in a split. It does not.
>
> Why?
>
> Jonathan
>
>


From jmarkn at gmail.com  Tue May 16 06:48:45 2017
From: jmarkn at gmail.com (Mark Noworolski)
Date: Tue, 16 May 2017 00:48:45 -0400
Subject: [R] Aggregate counts of observations with times surrounding a time?
Message-ID: <CABfYR_9rVuwL8RQrTAO_G+j3TR0nkaiN60wtoozCs2LCVjWYPg@mail.gmail.com>

I have a data frame that has a set of observed dwell times at a set of
locations. The metadata for the locations includes things that have varying
degrees of specificity. I'm interested in tracking the number of people
present at a given time in a given store, type of store, or zip code.

Here's an example of some sample data (here st=start_time, and et=end_time):
data.frame(st=seq(1483360938,by=1700,length=10),et=seq(1483362938,by=1700,length=10),store=c(rep("gap",5),rep("starbucks",5)),zip=c(94000,94000,94100,94100,94200,94000,94000,94100,94100,94200),store_id=seq(50,59))
           st         et     store   zip store_id
1  1483360938 1483362938       gap 94000       50
2  1483362638 1483364638       gap 94000       51
3  1483364338 1483366338       gap 94100       52
4  1483366038 1483368038       gap 94100       53
5  1483367738 1483369738       gap 94200       54
6  1483369438 1483371438 starbucks 94000       55
7  1483371138 1483373138 starbucks 94000       56
8  1483372838 1483374838 starbucks 94100       57
9  1483374538 1483376538 starbucks 94100       58
10 1483376238 1483378238 starbucks 94200       59

I'd like to be able to:
a) create aggretages of the number of people present in each store_id at a
given time
b) create aggregates of the number of people present - grouped by zip or
store

I expect to be rolling up to hour or half hour buckets, but I don't think I
should have to decide this up front and be able to do something clever to
be able to use ggplot + some other library to plot the time evolution of
this information, rolled up the way I want.

Any clever solutions? I've trolled stackoverflow and this email list.. to
no avail - but I'm willing to acknowledge I may have missed something.

	[[alternative HTML version deleted]]


From sjtu at gap.cgu.edu.tw  Tue May 16 04:35:35 2017
From: sjtu at gap.cgu.edu.tw (Shu-Ju Tu)
Date: Tue, 16 May 2017 10:35:35 +0800
Subject: [R] Problem to install xgboost package
Message-ID: <CABaQXBviKVBQhsE0+MN0Yaj3zmmyvvQp=GU8srfYirQHU7VSVg@mail.gmail.com>

Hi

I planned to learn R and their machine learning algorithms such as xgboost.
I just installed R 3.3 in our CentOS linux system.
Linus system: centos-release-6-9.el6.12.3.x86_64
I used the command: yum install R.
I successfully install "rJava" and "mlr" packages.
Then I used the following command:
install.packages("xgboost")
Unfortunately, I cannot install xgboost successfully.
Can anyone out there help me when you can get a chance.

Thanks

--- begin error message
trying URL 'https://mirror.usertrust.info/cranmirror/src/contrib/xgboost_0.6-4.tar.gz'
Content type 'application/x-gzip' length 596158 bytes (582 KB)
==================================================
downloaded 582 KB

* installing *source* package ???xgboost??? ...
** package ???xgboost??? successfully unpacked and MD5 sums checked
configure: creating ./config.status
config.status: creating src/Makevars
** libs
g++ -m64 -std=c++0x -I/usr/include/R -DNDEBUG -I./include
-I./dmlc-core/include -I./rabit/include -I. -DXGBOOST_STRICT_R_MODE=1
-DDMLC_LOG_BEFORE_THROW=0 -DDMLC_ENABLE_STD_THREAD=0
-DDMLC_DISABLE_STDIN=1 -DDMLC_LOG_CUSTOMIZE=1
-DXGBOOST_CUSTOMIZE_LOGGER=1 -DRABIT_CUSTOMIZE_MSG_
-DRABIT_STRICT_CXX98_ -I/usr/local/include   -fopenmp  -fpic  -O2 -g
-pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c xgboost_R.cc -o
xgboost_R.o
In file included from ./dmlc-core/include/dmlc/logging.h:15,
                 from xgboost_R.cc:2:
./dmlc-core/include/dmlc/./base.h:71: note: #pragma message: Will need
g++-4.6 or higher to compile allthe features in dmlc-core, compile
without c++0x, some features may be disabled
xgboost_R.cc: In function ???SEXPREC* XGBoosterSetAttr_R(SEXPREC*,
SEXPREC*, SEXPREC*)???:
xgboost_R.cc:412: error: ???nullptr??? was not declared in this scope
make: *** [xgboost_R.o] Error 1
ERROR: compilation failed for package ???xgboost???
* removing ???/home/sjtu/R/x86_64-redhat-linux-gnu-library/3.3/xgboost???

The downloaded source packages are in
        ???/tmp/Rtmp8IwXn4/downloaded_packages???
Warning message:
In install.packages("xgboost") :
  installation of package ???xgboost??? had non-zero exit status


From pdalgd at gmail.com  Tue May 16 10:36:43 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 16 May 2017 10:36:43 +0200
Subject: [R] plot problems
In-Reply-To: <c4bb7ebd-3368-9fa5-486d-4dff970c0a98@gmail.com>
References: <501065229.208665498.1494879314869.JavaMail.root@spooler7-g27.priv.proxad.net>
 <c4bb7ebd-3368-9fa5-486d-4dff970c0a98@gmail.com>
Message-ID: <65B9ED68-D11C-4484-BBED-AF54DF353F2A@gmail.com>


> On 16 May 2017, at 02:05 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 15/05/2017 4:15 PM, sylvie.celerier at free.fr wrote:
>> Hello all,
>> I'm using RStudio Version 1.0.136 on wondow 7 (64 bite) and I can't understand why all my plots are displayed ouside of the Rstudio graphic pane. How can I make them go back to the graphic panes ?
> 
> This is a question for RStudio, and should be asked in one of their help forums.  This mailing list is for R itself.

Yes.

However, if you explicitly start a graphics window device (e.g. quartz() on Macs & I expect windows() on Windows), then that might behave completely ignorant of the fact that you are running RStudio.

Also check ?Devices for info on getOption("device").

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Tue May 16 11:43:24 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 16 May 2017 19:43:24 +1000
Subject: [R] Aggregate counts of observations with times surrounding a
	time?
In-Reply-To: <CABfYR_9rVuwL8RQrTAO_G+j3TR0nkaiN60wtoozCs2LCVjWYPg@mail.gmail.com>
References: <CABfYR_9rVuwL8RQrTAO_G+j3TR0nkaiN60wtoozCs2LCVjWYPg@mail.gmail.com>
Message-ID: <CA+8X3fXWMqn2mfCDq7F4x_nZgm7tSD8c8dEWmkhLny2Gf3=-dg@mail.gmail.com>

Hi Mark,
I think you might want something like this:

mndf<-data.frame(st=seq(1483360938,by=1700,length=10),
 et=seq(1483362938,by=1700,length=10),
 store=c(rep("gap",5),rep("starbucks",5)),
 zip=c(94000,94000,94100,94100,94200,94000,94000,94100,94100,94200),
 store_id=seq(50,59))
# orders the times and calculates number of simultaneous presences
count_simult<-function(x) {
 nrows<-dim(x)[1]
 timeorder<-order(unlist(mndf[1:nrows,c("st","et")]))
 interval_counts<-data.frame(time=c(x$st,x$et)[timeorder],
  startfin=rep(c("st","et"),each=5)[timeorder],count=rep(NA,10))
 interval_counts[1,"count"]<-1
 for(i in 2:(nrows*2)) {
  interval_counts[i,"count"]<-
   interval_counts[i-1,"count"]+
   ifelse(interval_counts[i,"startfin"]=="st",1,-1)
 }
 return(interval_counts)
}
gap_counts<-count_simult(mndf[1:5,])
plot(gap_counts$time,gap_counts$count,type="l")
starbucks_counts<-count_simult(mndf[6:10,])
plot(starbucks_counts$time,gap_counts$count,type="l")

There are a lot of ways to plot the counts by time. If you have any
preferences, let me know.

Jim


On Tue, May 16, 2017 at 2:48 PM, Mark Noworolski <jmarkn at gmail.com> wrote:
> I have a data frame that has a set of observed dwell times at a set of
> locations. The metadata for the locations includes things that have varying
> degrees of specificity. I'm interested in tracking the number of people
> present at a given time in a given store, type of store, or zip code.
>
> Here's an example of some sample data (here st=start_time, and et=end_time):
> data.frame(st=seq(1483360938,by=1700,length=10),et=seq(1483362938,by=1700,length=10),store=c(rep("gap",5),rep("starbucks",5)),zip=c(94000,94000,94100,94100,94200,94000,94000,94100,94100,94200),store_id=seq(50,59))
>            st         et     store   zip store_id
> 1  1483360938 1483362938       gap 94000       50
> 2  1483362638 1483364638       gap 94000       51
> 3  1483364338 1483366338       gap 94100       52
> 4  1483366038 1483368038       gap 94100       53
> 5  1483367738 1483369738       gap 94200       54
> 6  1483369438 1483371438 starbucks 94000       55
> 7  1483371138 1483373138 starbucks 94000       56
> 8  1483372838 1483374838 starbucks 94100       57
> 9  1483374538 1483376538 starbucks 94100       58
> 10 1483376238 1483378238 starbucks 94200       59
>
> I'd like to be able to:
> a) create aggretages of the number of people present in each store_id at a
> given time
> b) create aggregates of the number of people present - grouped by zip or
> store
>
> I expect to be rolling up to hour or half hour buckets, but I don't think I
> should have to decide this up front and be able to do something clever to
> be able to use ggplot + some other library to plot the time evolution of
> this information, rolled up the way I want.
>
> Any clever solutions? I've trolled stackoverflow and this email list.. to
> no avail - but I'm willing to acknowledge I may have missed something.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From br at dmstat1.com  Tue May 16 12:56:52 2017
From: br at dmstat1.com (BR_email)
Date: Tue, 16 May 2017 06:56:52 -0400
Subject: [R] Xtable with long column headings/names
In-Reply-To: <1349073197.345839.1494929594457@mail.yahoo.com>
References: <CB805CD7-E227-4061-8E81-661E20C44A27@dmstat1.com>
 <700479592.1833249.1494868927597@mail.yahoo.com>
 <34d1802e-37d0-6d50-072b-e024112fbd11@dmstat1.com>
 <69e3c7de-dc0a-4af5-266c-c3b0a5f68573@dmstat1.com>
 <1349073197.345839.1494929594457@mail.yahoo.com>
Message-ID: <27cb9780-a6e3-3462-b79c-4ac6e16998d6@dmstat1.com>

John:
Did not mean to take a short-cut, but I thought the code was not needed.
Your follow-up is appreciated. Here's the code. I want the column headings
  to wrap around into two lines, not one long heading.
Any help is greatly sought. Thanks. Bruce
~~

Response <- rbinom(50,1,0.2)
yhat     <- runif(50)
data     <- data.frame(Response,yhat)
data     <- data[order(data$yhat,decreasing=TRUE),]
cum_R    <- cumsum(data$Response)
sam_size <- nrow(data)
cum_n    <- seq(1:1,sam_size)
wt       <- rep(c(1), times=sam_size)
cum_wt   <- cumsum(wt)
dec      <- (cum_n/sam_size)
decc     <- floor((cum_n*10)/(sam_size+1))
dec_mean <- aggregate(data$Response, by=list(decc), mean)
dd_      <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
dd       <- data.frame(Response, dd_)
dec_mean <- aggregate(data$Response ~ decc, dd, mean)
wt       <- rep(c(1), times=sam_size)
cum_wt   <- aggregate(wt        ~ decc, dd, sum)
cum_R    <- aggregate(data$Response  ~ decc, dd, sum)
dec_mean_wt    <- cbind(dec_mean, cum_wt)
dec_mean_wt    <- dec_mean_wt[-3]
dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
dec_mean_wt_R  <- dec_mean_wt_R[-4]
colnames(dec_mean_wt_R) <- c("Decile", "Avg_Response", "No_Individuals",
                              "Total_Response")
dec_mean_wt_R <- dec_mean_wt_R[,c(1,2,3,4)]
cum_n         <- dec_mean_wt_R[3]
cum_n         <- cumsum(cum_n)
library(plyr)
Cum_Inds      <- rename(cum_n, c(No_Individuals="Cum_Inds"))
Cum_Response  <- dec_mean_wt_R[4]
Cum_Response  <- cumsum(Cum_Response)
library(plyr)
Cum_Total_Response  <- rename(Cum_Response, 
c(Total_Response="Cum_Total_Response"))
dec_mean_wt_R_nR    <- cbind(dec_mean_wt_R, Cum_Inds, Cum_Total_Response)
Cum_Decile_Response <- Cum_Total_Response/ Cum_Inds
library(plyr)
Cum_Decile_Response <-rename(Cum_Decile_Response, 
c(Cum_Total_Response="Cum_Decile_Response"))
dec_mean_wt_R_nRD   <- cbind(dec_mean_wt_R_nR, Cum_Decile_Response)
avg_RR              <- dec_mean_wt_R_nRD[10,7]
Cum_Lift            <- (Cum_Decile_Response/avg_RR)*100
library(plyr)
Cum_Lift <-rename(Cum_Lift, c(Cum_Decile_Response="Cum_Lift"))
DECILE              <- c("top","2","3","4","5","6","7","8","9","bot")
dec_mean_wt_R_nRDL  <- cbind(dec_mean_wt_R_nRD, Cum_Lift,DECILE)
options(digits=3)

dec_mean_wt_R_nRDL  <- dec_mean_wt_R_nRDL[,c(9,3,4,2,7,8)]
total_line<-cbind(DECILE="Total",
   as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA, 
3)),nrow=1)))

names(total_line)   <-names(dec_mean_wt_R_nRDL)
dec_mean_wt_R_nRDLT <-rbind(dec_mean_wt_R_nRDL,total_line)
decile_table        <- dec_mean_wt_R_nRDLT
library(plyr)
dec_analy           <- rename(decile_table,
        c(No_Individuals="NUMBER OF INDIVIDUALS",
          Total_Response="NUMBER OF RESPONDERS",
          Avg_Response="RESPONSE RATE (%)",
          Decile_RespRate="RESPONSE RATE (%)",
          Cum_Decile_Response="CUM RESPONSE RATE (%)" ,
          Cum_Lift="CUM LIFT"))
#Install the xtable package: install.packages("xtable")
#Load the xtable package:
library(xtable)
DECILE_TABLE <-xtable(dec_analy, digits = c(0,0,0,0,2,2,0),
                       align = "ccccccc", latex.environments = "center",
                       caption = "Decile Analysis based on Y (RESPONSE) 
regressed on X1 X2 X3")
DECILE_TABLE

print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html",
              include.rownames = FALSE,
              caption.placement = "top",
              align = "p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}")


John Kane wrote:
> Hi Bruce,
> I accidentally replied just to you and we should be replying to the 
> list especially since there are a lot of people there who know a lot 
> more about xtabs than I do. My bad.
>
> I use xtabs from time to time and love it but I occasionally feel that 
> I am groping in the dark when I try anything fancy.
>
> What we need is an actual working example so we would need not only 
> the table code but a sample of the data with some of the long titles 
> included.
>
> I'd suggest resubmitting the table information with some sampled data 
> to the list.  Have a look at Reproducibility ? Advanced R. 
> <http://adv-r.had.co.nz/Reproducibility.html> for some suggestions on 
> how to put one together.
>
> In particular, some sample data in dput form ( see ?dput) would be 
> best. Data in dput() format is essentially an exact copy of your data 
> and avoids confusion in reading in data. that is a factor remains a 
> factor, character data remains character and so on.
>
>
>
>
> 	
>
>
>     Reproducibility ? Advanced R.
>
> 	
>
> <http://adv-r.had.co.nz/Reproducibility.html>
>
>
>
>
>
>
> On Monday, May 15, 2017 1:40 PM, BR_email <br at dmstat1.com> wrote:
>
>
> John:
> Here is the code of my xtable:
> TABLE <-xtable(dec_analy, digits = c(0,0,0,0,2,2,0),
>                       align = "ccccccc", latex.environments = "center",
>                       caption = "Analysis ")
> print.xtable(TABLE, type="html",file="C:/R_Data/Table.html",
>               include.rownames = FALSE,
>               caption.placement = "top",
>               align = "p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}")
>
>
>
> BR_email wrote:
> > John:
> > After I generate the xtable table, I manually edited (by inserting
> > <br/>) the html header, below.
> > Is there a way in xtable that I can set some setting to affect my
> > xtable table?
> > Thanks for your reply.
> > Bruce
> >
> > <table border=1>
> > <caption align="top"> Analysis </caption>
> > <tr> <th> DECILE </th>
> > <th> NUMBER OF <br /> INDIVIDUALS <br /> </th>
> > <th> NUMBER OF <br /> RESPONDERS <br /> </th>
> > <th> RESPONSE <br /> RATE (%) <br /> </th>
> > <th> CUM RESPONSE <br /> RATE (%) <br />
> > </th> <th> CUM LIFT </th> </tr>
> >
> >
> >
> > John Kane wrote:
> >> Can you give us an example. I am having a problem visualizing this.
> >> It seems obvious just to put in a line break normally but in xtabs
> >> who knows?
> >>
> >>
> >> On Monday, May 15, 2017 1:15 PM, Bruce Ratner PhD <br at dmstat1.com 
> <mailto:br at dmstat1.com>>
> >> wrote:
> >>
> >>
> >> R-help:
> >> I'm using xtable that produces a table in html with one-line for each
> >> of the
> >> long column headings/names.
> >>
> >> I would like to word wrap the column headings to break into two-lines.
> >> Any suggestion as to which argument needs adjustment is appreciated.
> >> Bruce
> >>
> >> ______________________________________________
> >> R-help at r-project.org <mailto:R-help at r-project.org> 
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing 
> list -- To
> >> UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html 
> <http://www.r-project.org/posting-guide.html>
> >> <http://www.r-project.org/posting-guide.html>
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
>
>
>


From patrcasi at nova.edu  Tue May 16 14:54:49 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Tue, 16 May 2017 12:54:49 +0000
Subject: [R] Dictionary not showing full list of trems with tm Package
In-Reply-To: <CY4PR06MB3032321F3656ED0270844649B9E60@CY4PR06MB3032.namprd06.prod.outlook.com>
References: <CY4PR06MB3032B644DE239D754379584AB9E10@CY4PR06MB3032.namprd06.prod.outlook.com>,
 <CY4PR06MB30322285517463E781BA0EB8B9E10@CY4PR06MB3032.namprd06.prod.outlook.com>,
 <CY4PR06MB3032321F3656ED0270844649B9E60@CY4PR06MB3032.namprd06.prod.outlook.com>
Message-ID: <CY4PR06MB30321892D43680EE164B1D5DB9E60@CY4PR06MB3032.namprd06.prod.outlook.com>

Hello Fellows,


I want to use dictionary function to capture all specific terms from a corpus of 102 docs but the dictionary only captures those terms in 10 documents. I need those terms from all 102 docs.  Any idea why? How do I get the dictionary to return for all 102 docs? See my coding below. Can anyone help me capture any specific terms from all the documents in the DocumentTermMatrix? When I use the function Dictionary (), I got the error: Error: could not find function "Dictionary"


Million Thanks


> myTerms <- c("prostatic", "adenocarcinoma", "grade")
> inspect(DocumentTermMatrix(docs, list(dictionary = myTerms)))

<<DocumentTermMatrix (documents: 102, terms: 3)>>
Non-/sparse entries: 292/14
Sparsity           : 5%
Maximal term length: 14
Weighting          : term frequency (tf)
Sample             :
               Terms
Docs            adenocarcinoma grade prostatic
  Patient14.txt             11     6         3
  Patient15.txt              7    12         2
  Patient16.txt             13    16         4
  Patient19.txt              5    13         2
  Patient24.txt             11    12         4
  Patient25.txt              8     9         4
  Patient41.txt              8    10         4
  Patient46.txt              8    10         3
  Patient8.txt               9    12         2
  Patient9.txt               8    23         2


Pat



	[[alternative HTML version deleted]]


From nielsenrune at me.com  Tue May 16 11:30:30 2017
From: nielsenrune at me.com (=?utf-8?Q?Rune_Gr=C3=B8nseth?=)
Date: Tue, 16 May 2017 11:30:30 +0200
Subject: [R] Extracting metadata information to corresponding dissimilarity
	matrix
Message-ID: <690BC4CA-BCFD-49DF-BFCD-32CEF488991F@me.com>

Hi,
I am R beginner. I've tried googling and reading, but this might be too simple to be found in the documentation. 

I have a dissimilarity index (symmetric matrix) from which I have extracted the unique values using the exodist package command "lower". There are 14 observations, so there are 91 unique comparisons.

After this I'd like to extract corresponding metadata from a separate data frame (the 14 observations organized in rows identified by a samplenumber-vector, and other variables as gender, age, et cetera). The aim is to have a new data frame with 91 rows and metadata vectors giving me the value of the dissimilarity index,  gender each of the two observations that are compared by the dissimilarity metric. So if I'm looking for gender differences, I need 5 vectors in the data frame: samplenumber1, samplenumber2, gender1, gender2 and dissimilarity metric.

Does anyone have suggestions or experiences in reformatting data in this manner? This is just a test-dataset. My full data-set is for more than 100 observations, so I need a more general code, if that is possible.

With great appreciation of any help.

Rune Gr?nseth 

---

Rune Gr?nseth, MD, PhD, postdoctoral fellow
Department of Thoracic Medicine
Haukeland University Hospital
N-5021 Bergen
Norway

	[[alternative HTML version deleted]]


From Patrick.Casimir at moffitt.org  Tue May 16 15:19:15 2017
From: Patrick.Casimir at moffitt.org (Casimir, Patrick)
Date: Tue, 16 May 2017 13:19:15 +0000
Subject: [R] Alternative function for Dictionary ( )
Message-ID: <4806CBC3B113BC4A81D03138B29B88021C3D059C@EXMB04.hlm.ad.moffitt.usf.edu>

All,

Since the Dictionary () function is no longer available with the tm package. How do I use other functions to do the same as below? I want to capture a list of specific terms from a corpus. By example, if my corpus has 100 files. I want to see a list with
occurrences of price, crude, oil in all 100 files.

d <- Dictionary(c("prices", "crude", "oil"))
inspect(DocumentTermMatrix(reuters, list(dictionary = d)))

Thanks

Please consider the environment before printing this email.

This transmission may be confidential or protected from disclosure and is only for review and use by the intended recipient. Access by anyone else is unauthorized. Any unauthorized reader is hereby notified that any review, use, dissemination, disclosure or copying of this information, or any act or omission taken in reliance on it, is prohibited and may be unlawful. If you received this transmission in error, please notify the sender immediately. Thank you.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue May 16 15:47:51 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 16 May 2017 06:47:51 -0700
Subject: [R] Extracting metadata information to corresponding
	dissimilarity	matrix
In-Reply-To: <690BC4CA-BCFD-49DF-BFCD-32CEF488991F@me.com>
References: <690BC4CA-BCFD-49DF-BFCD-32CEF488991F@me.com>
Message-ID: <15111380-EDA7-4A35-8E95-742661A9E951@dcn.davis.ca.us>

Hello R Beginner...

It is good that you are articulate, but R code has subtleties that words miss, so you really need to provide sample code and sample data to convey where you are.  This is not necessarily easy, but it avoids a lot of us fixing the wrong problem and you might even solve your own problem in the course of making a simple example. Help with doing this is available on the Web [1] [2].

I suspect that the reshape function or one of the many alternative packages like reshape2 or tidyr are what you are looking for. 

You also need to read the Posting Guide, which among other things mentions that this is a plain text mailing list. It is up to you to figure out how to adjust your email program to send only plain text, but if you don't we may not be able to read your garbled code and may ignore you.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

-- 
Sent from my phone. Please excuse my brevity.

On May 16, 2017 2:30:30 AM PDT, "Rune Gr?nseth" <nielsenrune at me.com> wrote:
>Hi,
>I am R beginner. I've tried googling and reading, but this might be too
>simple to be found in the documentation. 
>
>I have a dissimilarity index (symmetric matrix) from which I have
>extracted the unique values using the exodist package command "lower".
>There are 14 observations, so there are 91 unique comparisons.
>
>After this I'd like to extract corresponding metadata from a separate
>data frame (the 14 observations organized in rows identified by a
>samplenumber-vector, and other variables as gender, age, et cetera).
>The aim is to have a new data frame with 91 rows and metadata vectors
>giving me the value of the dissimilarity index,  gender each of the two
>observations that are compared by the dissimilarity metric. So if I'm
>looking for gender differences, I need 5 vectors in the data frame:
>samplenumber1, samplenumber2, gender1, gender2 and dissimilarity
>metric.
>
>Does anyone have suggestions or experiences in reformatting data in
>this manner? This is just a test-dataset. My full data-set is for more
>than 100 observations, so I need a more general code, if that is
>possible.
>
>With great appreciation of any help.
>
>Rune Gr?nseth 
>
>---
>
>Rune Gr?nseth, MD, PhD, postdoctoral fellow
>Department of Thoracic Medicine
>Haukeland University Hospital
>N-5021 Bergen
>Norway
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Omar.Abdelrahman at miamidade.gov  Tue May 16 16:06:40 2017
From: Omar.Abdelrahman at miamidade.gov (Abdelrahman, Omar (RER))
Date: Tue, 16 May 2017 14:06:40 +0000
Subject: [R] violin plot help
Message-ID: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>

I am trying to produce multiple violin plots by 3 categorical variables, each violin representing 1 year worth of data. The variables are:

Watershed (7 levels: county canals)

Geography (5 levels: west; central; east; mouth; bay)

Parameter (8 levels: water quality chemical parameters)

Year (25 levels: 1992-2017)

I want to produce 1 plot for each Parameter-Watershed subdivided into Geography with a violin for each year. I used facets with the following code (not by year):

ggplot () +

facet_grid (PARAMETER ~Wshed, scales="free_y") +

geom_violin (data=merged, aes(x=Geo, y=RESULT))



I do not want facets, they crowd the information so it is unreadable. I just started with R this week and have not been able to figure out the foreach protocol, or any other loop protocol. I tried to subset the data to do it iteratively with the following code:



subdf<-subset (merged, Wshed = "AC")



but got an error: Error: unexpected input in "subdf=subset (merged, Wshed == ""

Any help would be greatly appreciated.

Thanks,

Omar Abdelrahman, Biologist II
Miami-Dade County, Department of Regulatory and Economic Resources
Division of Environmental Resources Management (DERM)
Overtown Transit Village
701 NW 1st Court, 5th Floor
Miami, FL 33136-3912
(305) 372-6872
abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
www.miamidade.gov/environment<http://www.miamidade.gov/environment/>


	[[alternative HTML version deleted]]


From br at dmstat1.com  Tue May 16 17:38:38 2017
From: br at dmstat1.com (BR_email)
Date: Tue, 16 May 2017 11:38:38 -0400
Subject: [R] Xtable with long column headings/names
In-Reply-To: <622573857.631358.1494947739181@mail.yahoo.com>
References: <CB805CD7-E227-4061-8E81-661E20C44A27@dmstat1.com>
 <700479592.1833249.1494868927597@mail.yahoo.com>
 <34d1802e-37d0-6d50-072b-e024112fbd11@dmstat1.com>
 <69e3c7de-dc0a-4af5-266c-c3b0a5f68573@dmstat1.com>
 <1349073197.345839.1494929594457@mail.yahoo.com>
 <27cb9780-a6e3-3462-b79c-4ac6e16998d6@dmstat1.com>
 <622573857.631358.1494947739181@mail.yahoo.com>
Message-ID: <c34868b9-3b45-bff2-b142-20b8b199d52d@dmstat1.com>

John:
Sorry, but I do not understand what you have done.
It seems like you hard coded the format I want, correct?
Bruce

  

John Kane wrote:
> Hi Bruce,
> We don't need all that code :)  All that is required is the data.fame 
> being used in the xtable command and the actual xtable commands. Below 
> is what I think is a complete "minimal working example" for your 
> problem. Note that in the print.xtable command I have removed the file 
> path as it will be meaningless to other users. It gave me an error as 
> I don't even have a C: drive--I use linux.
>
> I'd suggest posting it as a follow-up to your original question on 
> R-help and going from there. I have done a bit of Googling and it 
> looks, perhaps, possible to do what you want but it's beyond my 
> knowledge level at the moment. I "might" be able to figure it out but 
> in days whereas the real gurus on the R-help list may do it in 30 seconds.
>
> Shifting to another topic, you are using "data" as the name of a 
> data.frame which is not a good idea as there is a function in R called 
> "data".  It is possible to over-write functions in R with" 
> interesting" results. If you are feeling really adventurous try FALSE 
> <- TRUE and see what happens.
>
> You also have 4 calls to plyr in the code and there is what I think is 
> a duplication of code below one of the library(plyr) calls, probably a 
> duplicate paste..  I'd suggest putting all library() or require() 
> calls at the top of the code.
>
> And to be incredibly picky, you have a colnames () command at roughly 
> line 27:30 for a data.frame and names() is the usual (preferred?) way 
> to do this. colnames() is more used for a matrix. I "think" names() is 
> more more generic though you would have to ask someone who knows what 
> they are talking about it--not me-- to be sure.
>
> Sorry I cannot be of more help.
>
>
> ##===========================================================
> library(xtable)
> dec_analy <- structure(list(DECILE = structure(c(10L, 1L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 11L), .Label = c("2", "3", "4", "5", "6", "7",
> "8", "9", "bot", "top", "Total"), class = "factor"), `NUMBER OF 
> INDIVIDUALS` = c(5,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 50), `NUMBER OF RESPONDERS` = c(2,
> 1, 2, 0, 0, 0, 0, 1, 0, 1, 7), `RESPONSE RATE (%)` = c(0.4, 0.2,
> 0.4, 0, 0, 0, 0, 0.2, 0, 0.2, NA), `CUM RESPONSE RATE (%)` = c(0.4,
> 0.3, 0.333333333333333, 0.25, 0.2, 0.166666666666667, 0.142857142857143,
> 0.15, 0.133333333333333, 0.14, NA), Cum_Total_Response = c(NaN,
> 714.285714285714, 714.285714285714, 714.285714285714, 714.285714285714,
> 714.285714285714, 714.285714285714, 714.285714285714, 714.285714285714,
> 714.285714285714, NA)), .Names = c("DECILE", "NUMBER OF INDIVIDUALS",
> "NUMBER OF RESPONDERS", "RESPONSE RATE (%)", "CUM RESPONSE RATE (%)",
> "Cum_Total_Response"), row.names = c(NA, 11L), class = "data.frame")
>
> DECILE_TABLE <-xtable(dec_analy, digits = c(0,0,0,0,2,2,0),
>                       align = "ccccccc", latex.environments = "center",
>                       caption = "Decile Analysis based on Y (RESPONSE)
> regressed on X1 X2 X3")
> DECILE_TABLE
>
> print.xtable(DECILE_TABLE, type="html",
>              include.rownames = FALSE,
>              caption.placement = "top",
>              align = "p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}")
> #============================================================
>
>
> On Tuesday, May 16, 2017 6:56 AM, BR_email <br at dmstat1.com> wrote:
>
>
> John:
> Did not mean to take a short-cut, but I thought the code was not needed.
> Your follow-up is appreciated. Here's the code. I want the column headings
>   to wrap around into two lines, not one long heading.
> Any help is greatly sought. Thanks. Bruce
> ~~
>
> Response <- rbinom(50,1,0.2)
> yhat    <- runif(50)
> data    <- data.frame(Response,yhat)
> data    <- data[order(data$yhat,decreasing=TRUE),]
> cum_R    <- cumsum(data$Response)
> sam_size <- nrow(data)
> cum_n    <- seq(1:1,sam_size)
> wt      <- rep(c(1), times=sam_size)
> cum_wt  <- cumsum(wt)
> dec      <- (cum_n/sam_size)
> decc    <- floor((cum_n*10)/(sam_size+1))
> dec_mean <- aggregate(data$Response, by=list(decc), mean)
> dd_      <- data.frame(cum_R, sam_size, cum_wt, cum_n, decc)
> dd      <- data.frame(Response, dd_)
> dec_mean <- aggregate(data$Response ~ decc, dd, mean)
> wt      <- rep(c(1), times=sam_size)
> cum_wt  <- aggregate(wt        ~ decc, dd, sum)
> cum_R    <- aggregate(data$Response  ~ decc, dd, sum)
> dec_mean_wt    <- cbind(dec_mean, cum_wt)
> dec_mean_wt    <- dec_mean_wt[-3]
> dec_mean_wt_R  <- cbind(dec_mean_wt, cum_R)
> dec_mean_wt_R  <- dec_mean_wt_R[-4]
> colnames(dec_mean_wt_R) <- c("Decile", "Avg_Response", "No_Individuals",
>                               "Total_Response")
> dec_mean_wt_R <- dec_mean_wt_R[,c(1,2,3,4)]
> cum_n        <- dec_mean_wt_R[3]
> cum_n        <- cumsum(cum_n)
> library(plyr)
> Cum_Inds      <- rename(cum_n, c(No_Individuals="Cum_Inds"))
> Cum_Response  <- dec_mean_wt_R[4]
> Cum_Response  <- cumsum(Cum_Response)
> library(plyr)
> Cum_Total_Response  <- rename(Cum_Response,
> c(Total_Response="Cum_Total_Response"))
> dec_mean_wt_R_nR    <- cbind(dec_mean_wt_R, Cum_Inds, Cum_Total_Response)
> Cum_Decile_Response <- Cum_Total_Response/ Cum_Inds
> library(plyr)
> Cum_Decile_Response <-rename(Cum_Decile_Response,
> c(Cum_Total_Response="Cum_Decile_Response"))
> dec_mean_wt_R_nRD  <- cbind(dec_mean_wt_R_nR, Cum_Decile_Response)
> avg_RR              <- dec_mean_wt_R_nRD[10,7]
> Cum_Lift            <- (Cum_Decile_Response/avg_RR)*100
> library(plyr)
> Cum_Lift <-rename(Cum_Lift, c(Cum_Decile_Response="Cum_Lift"))
> DECILE              <- c("top","2","3","4","5","6","7","8","9","bot")
> dec_mean_wt_R_nRDL  <- cbind(dec_mean_wt_R_nRD, Cum_Lift,DECILE)
> options(digits=3)
>
> dec_mean_wt_R_nRDL  <- dec_mean_wt_R_nRDL[,c(9,3,4,2,7,8)]
> total_line<-cbind(DECILE="Total",
>   as.data.frame(matrix(c(colSums(dec_mean_wt_R_nRDL[ , 2:3]), rep(NA,
> 3)),nrow=1)))
>
> names(total_line)  <-names(dec_mean_wt_R_nRDL)
> dec_mean_wt_R_nRDLT <-rbind(dec_mean_wt_R_nRDL,total_line)
> decile_table        <- dec_mean_wt_R_nRDLT
> library(plyr)
> dec_analy          <- rename(decile_table,
>         c(No_Individuals="NUMBER OF INDIVIDUALS",
>           Total_Response="NUMBER OF RESPONDERS",
>           Avg_Response="RESPONSE RATE (%)",
>           Decile_RespRate="RESPONSE RATE (%)",
>           Cum_Decile_Response="CUM RESPONSE RATE (%)" ,
>           Cum_Lift="CUM LIFT"))
> #Install the xtable package: install.packages("xtable")
> #Load the xtable package:
> library(xtable)
> DECILE_TABLE <-xtable(dec_analy, digits = c(0,0,0,0,2,2,0),
>                       align = "ccccccc", latex.environments = "center",
>                       caption = "Decile Analysis based on Y (RESPONSE)
> regressed on X1 X2 X3")
> DECILE_TABLE
>
> print.xtable(DECILE_TABLE, type="html",file="C:/R_Data/DecileTable.html",
>               include.rownames = FALSE,
>               caption.placement = "top",
>               align = "p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}")
>
>
> John Kane wrote:
> > Hi Bruce,
> > I accidentally replied just to you and we should be replying to the
> > list especially since there are a lot of people there who know a lot
> > more about xtabs than I do. My bad.
> >
> > I use xtabs from time to time and love it but I occasionally feel that
> > I am groping in the dark when I try anything fancy.
> >
> > What we need is an actual working example so we would need not only
> > the table code but a sample of the data with some of the long titles
> > included.
> >
> > I'd suggest resubmitting the table information with some sampled data
> > to the list.  Have a look at Reproducibility ? Advanced R.
> > <http://adv-r.had.co.nz/Reproducibility.html> for some suggestions on
> > how to put one together.
> >
> > In particular, some sample data in dput form ( see ?dput) would be
> > best. Data in dput() format is essentially an exact copy of your data
> > and avoids confusion in reading in data. that is a factor remains a
> > factor, character data remains character and so on.
> >
> >
> >
> >
> >
> >
> >
> >    Reproducibility ? Advanced R.
> >
> >
> >
> > <http://adv-r.had.co.nz/Reproducibility.html>
> >
> >
> >
> >
> >
> >
> > On Monday, May 15, 2017 1:40 PM, BR_email <br at dmstat1.com 
> <mailto:br at dmstat1.com>> wrote:
> >
> >
> > John:
> > Here is the code of my xtable:
> > TABLE <-xtable(dec_analy, digits = c(0,0,0,0,2,2,0),
> >                      align = "ccccccc", latex.environments = "center",
> >                      caption = "Analysis ")
> > print.xtable(TABLE, type="html",file="C:/R_Data/Table.html",
> >              include.rownames = FALSE,
> >              caption.placement = "top",
> >              align = "p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}p{.5in}")
> >
> >
> >
> > BR_email wrote:
> > > John:
> > > After I generate the xtable table, I manually edited (by inserting
> > > <br/>) the html header, below.
> > > Is there a way in xtable that I can set some setting to affect my
> > > xtable table?
> > > Thanks for your reply.
> > > Bruce
> > >
> > > <table border=1>
> > > <caption align="top"> Analysis </caption>
> > > <tr> <th> DECILE </th>
> > > <th> NUMBER OF <br /> INDIVIDUALS <br /> </th>
> > > <th> NUMBER OF <br /> RESPONDERS <br /> </th>
> > > <th> RESPONSE <br /> RATE (%) <br /> </th>
> > > <th> CUM RESPONSE <br /> RATE (%) <br />
> > > </th> <th> CUM LIFT </th> </tr>
> > >
> > >
> > >
> > > John Kane wrote:
> > >> Can you give us an example. I am having a problem visualizing this.
> > >> It seems obvious just to put in a line break normally but in xtabs
> > >> who knows?
> > >>
> > >>
> > >> On Monday, May 15, 2017 1:15 PM, Bruce Ratner PhD <br at dmstat1.com 
> <mailto:br at dmstat1.com>
> > <mailto:br at dmstat1.com <mailto:br at dmstat1.com>>>
> > >> wrote:
> > >>
> > >>
> > >> R-help:
> > >> I'm using xtable that produces a table in html with one-line for each
> > >> of the
> > >> long column headings/names.
> > >>
> > >> I would like to word wrap the column headings to break into 
> two-lines.
> > >> Any suggestion as to which argument needs adjustment is appreciated.
> > >> Bruce
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org <mailto:R-help at r-project.org> 
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
> > <mailto:R-help at r-project.org <mailto:R-help at r-project.org> 
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>> mailing
>
> > list -- To
> > >> UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html 
> <http://www.r-project.org/posting-guide.html>
> > <http://www.r-project.org/posting-guide.html>
> > >> <http://www.r-project.org/posting-guide.html>
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >
> >
> >
> >
>
>
>


From jdnewmil at dcn.davis.ca.us  Tue May 16 17:43:09 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 16 May 2017 08:43:09 -0700
Subject: [R] violin plot help
In-Reply-To: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
References: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
Message-ID: <D5E780EE-3EAF-49C6-ACF6-5C2918A20E1A@dcn.davis.ca.us>

Read
A) the Posting Guide (re plain text only... your emails may be damaged by the mailing list if you send html-formatted email... only you can solve this by figuring out how to use your email software)
B) Help on assignment (?`=`)
C) Help on logical tests (?`==`)
-- 
Sent from my phone. Please excuse my brevity.

On May 16, 2017 7:06:40 AM PDT, "Abdelrahman, Omar (RER)" <Omar.Abdelrahman at miamidade.gov> wrote:
>I am trying to produce multiple violin plots by 3 categorical
>variables, each violin representing 1 year worth of data. The variables
>are:
>
>Watershed (7 levels: county canals)
>
>Geography (5 levels: west; central; east; mouth; bay)
>
>Parameter (8 levels: water quality chemical parameters)
>
>Year (25 levels: 1992-2017)
>
>I want to produce 1 plot for each Parameter-Watershed subdivided into
>Geography with a violin for each year. I used facets with the following
>code (not by year):
>
>ggplot () +
>
>facet_grid (PARAMETER ~Wshed, scales="free_y") +
>
>geom_violin (data=merged, aes(x=Geo, y=RESULT))
>
>
>
>I do not want facets, they crowd the information so it is unreadable. I
>just started with R this week and have not been able to figure out the
>foreach protocol, or any other loop protocol. I tried to subset the
>data to do it iteratively with the following code:
>
>
>
>subdf<-subset (merged, Wshed = "AC")
>
>
>
>but got an error: Error: unexpected input in "subdf=subset (merged,
>Wshed == ""
>
>Any help would be greatly appreciated.
>
>Thanks,
>
>Omar Abdelrahman, Biologist II
>Miami-Dade County, Department of Regulatory and Economic Resources
>Division of Environmental Resources Management (DERM)
>Overtown Transit Village
>701 NW 1st Court, 5th Floor
>Miami, FL 33136-3912
>(305) 372-6872
>abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
>www.miamidade.gov/environment<http://www.miamidade.gov/environment/>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue May 16 18:21:23 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 16 May 2017 16:21:23 +0000
Subject: [R] Extracting metadata information to corresponding
 dissimilarity	matrix
In-Reply-To: <690BC4CA-BCFD-49DF-BFCD-32CEF488991F@me.com>
References: <690BC4CA-BCFD-49DF-BFCD-32CEF488991F@me.com>
Message-ID: <29e4508222704dfb90c3abaf09e69880@exch-2p-mbx-w2.ads.tamu.edu>

I think this is what you are trying to do. I've created a data set with 7 rows and a similarity matrix based on age:

set.seed(42)
dta <- data.frame(ID=1:7, gender=sample(c("M", "F"), 7, replace=TRUE),
     age=sample.int(75, 7))
sim <- max(dist(dta$age)) - dist(dta$age) # already lower triangular
sim

#    1  2  3  4  5  6
# 2 24               
# 3 21 59            
# 4 40 46 43         
# 5  0 38 41 22      
# 6  7 45 48 29 55   
# 7 55 31 28 47  7 14

# Now duplicate dta:
dta1 <- dta
names(dta1) <- c("ID1", "gender1", "age1")
dta2 <- dta
names(dta2) <- c("ID2", "gender2", "age2")

# Now merge and eliminate unneeded rows
dta12 <- merge(dta2, dta1) # order is important
dta12 <- dta12[dta12$ID1 < dta12$ID2, ]

# Finally combine the similarities with the combined data and rearrange
# the variable names
dta12 <- data.frame(dta12mod, sim=as.vector(sim))
dta12 <- dta12[, c("ID1", "ID2", "gender1", "gender2", "age1", "age2", "sim")]
dta12

#    ID1 ID2 gender1 gender2 age1 age2 sim
# 2    1   2       F       F   11   49  24
# 3    1   3       F       M   11   52  21
# 4    1   4       F       F   11   33  40
# 5    1   5       F       F   11   73   0
# 6    1   6       F       F   11   66   7
# 7    1   7       F       F   11   18  55
# 10   2   3       F       M   49   52  59
# 11   2   4       F       F   49   33  46
# 12   2   5       F       F   49   73  38
# 13   2   6       F       F   49   66  45
# 14   2   7       F       F   49   18  31
# 18   3   4       M       F   52   33  43
# 19   3   5       M       F   52   73  41
# 20   3   6       M       F   52   66  48
# 21   3   7       M       F   52   18  28
# 26   4   5       F       F   33   73  22
# 27   4   6       F       F   33   66  29
# 28   4   7       F       F   33   18  47
# 34   5   6       F       F   73   66  55
# 35   5   7       F       F   73   18   7
# 42   6   7       F       F   66   18  14

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rune Gr?nseth
Sent: Tuesday, May 16, 2017 4:31 AM
To: r-help at r-project.org
Subject: [R] Extracting metadata information to corresponding dissimilarity matrix

Hi,
I am R beginner. I've tried googling and reading, but this might be too simple to be found in the documentation. 

I have a dissimilarity index (symmetric matrix) from which I have extracted the unique values using the exodist package command "lower". There are 14 observations, so there are 91 unique comparisons.

After this I'd like to extract corresponding metadata from a separate data frame (the 14 observations organized in rows identified by a samplenumber-vector, and other variables as gender, age, et cetera). The aim is to have a new data frame with 91 rows and metadata vectors giving me the value of the dissimilarity index,  gender each of the two observations that are compared by the dissimilarity metric. So if I'm looking for gender differences, I need 5 vectors in the data frame: samplenumber1, samplenumber2, gender1, gender2 and dissimilarity metric.

Does anyone have suggestions or experiences in reformatting data in this manner? This is just a test-dataset. My full data-set is for more than 100 observations, so I need a more general code, if that is possible.

With great appreciation of any help.

Rune Gr?nseth 

---

Rune Gr?nseth, MD, PhD, postdoctoral fellow
Department of Thoracic Medicine
Haukeland University Hospital
N-5021 Bergen
Norway

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.ca.us  Tue May 16 18:30:22 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 16 May 2017 09:30:22 -0700
Subject: [R] violin plot help
In-Reply-To: <161FBD7CDADFC2489F2D5A7441BEBFBF8F463436@S0020287.miamidade.gov>
References: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
 <D5E780EE-3EAF-49C6-ACF6-5C2918A20E1A@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463436@S0020287.miamidade.gov>
Message-ID: <571BEE09-8994-4FB6-B67C-8E2D909CFC09@dcn.davis.ca.us>

Please use reply-all or equivalent to keep the list in the conversation. I don't do private online consultation.

Your example suggested you did not know the difference, but your error suggests a completely different expression triggered the error, so all the more reason to give us an example that we can run to trigger the same error. 

Items B and C are recommendations to read the help pages for those syntax elements. You should already have read enough of an introduction to R to have encountered the use of the question mark to bring up the help pages. If not, please do. 
-- 
Sent from my phone. Please excuse my brevity.

On May 16, 2017 9:00:09 AM PDT, "Abdelrahman, Omar (RER)" <Omar.Abdelrahman at miamidade.gov> wrote:
>Thanks Jeff. I will send plain text from now on. I am not sure what B
>or C mean; is there a guide that I can reference? I know the difference
>between "=" and "==" , they work the same in Stata and SAS. 
>
>Omar
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
>Sent: Tuesday, May 16, 2017 11:43 AM
>To: r-help at r-project.org; Abdelrahman, Omar (RER)
><Omar.Abdelrahman at miamidade.gov>; 'r-help at r-project.org'
><r-help at r-project.org>
>Subject: Re: [R] violin plot help
>
>Read
>A) the Posting Guide (re plain text only... your emails may be damaged
>by the mailing list if you send html-formatted email... only you can
>solve this by figuring out how to use your email software)
>B) Help on assignment (?`=`)
>C) Help on logical tests (?`==`)
>--
>Sent from my phone. Please excuse my brevity.
>
>On May 16, 2017 7:06:40 AM PDT, "Abdelrahman, Omar (RER)"
><Omar.Abdelrahman at miamidade.gov> wrote:
>>I am trying to produce multiple violin plots by 3 categorical 
>>variables, each violin representing 1 year worth of data. The
>variables
>>are:
>>
>>Watershed (7 levels: county canals)
>>
>>Geography (5 levels: west; central; east; mouth; bay)
>>
>>Parameter (8 levels: water quality chemical parameters)
>>
>>Year (25 levels: 1992-2017)
>>
>>I want to produce 1 plot for each Parameter-Watershed subdivided into 
>>Geography with a violin for each year. I used facets with the
>following 
>>code (not by year):
>>
>>ggplot () +
>>
>>facet_grid (PARAMETER ~Wshed, scales="free_y") +
>>
>>geom_violin (data=merged, aes(x=Geo, y=RESULT))
>>
>>
>>
>>I do not want facets, they crowd the information so it is unreadable.
>I 
>>just started with R this week and have not been able to figure out the
>
>>foreach protocol, or any other loop protocol. I tried to subset the 
>>data to do it iteratively with the following code:
>>
>>
>>
>>subdf<-subset (merged, Wshed = "AC")
>>
>>
>>
>>but got an error: Error: unexpected input in "subdf=subset (merged, 
>>Wshed == ""
>>
>>Any help would be greatly appreciated.
>>
>>Thanks,
>>
>>Omar Abdelrahman, Biologist II
>>Miami-Dade County, Department of Regulatory and Economic Resources 
>>Division of Environmental Resources Management (DERM) Overtown Transit
>
>>Village
>>701 NW 1st Court, 5th Floor
>>Miami, FL 33136-3912
>>(305) 372-6872
>>abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
>>www.miamidade.gov/environment<http://www.miamidade.gov/environment/>
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue May 16 18:44:28 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 16 May 2017 16:44:28 +0000
Subject: [R] Extracting metadata information to corresponding
 dissimilarity	matrix
In-Reply-To: <29e4508222704dfb90c3abaf09e69880@exch-2p-mbx-w2.ads.tamu.edu>
References: <690BC4CA-BCFD-49DF-BFCD-32CEF488991F@me.com>
 <29e4508222704dfb90c3abaf09e69880@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <b45a70dbcf1a47e784a20c1f75348351@exch-2p-mbx-w2.ads.tamu.edu>

Fixing a typo in the original, adding a simplification, and using dissimilarity instead of similarity:

set.seed(42)
dta <- data.frame(ID=1:7, gender=sample(c("M", "F"), 7, replace=TRUE),
     age=sample.int(75, 7))
dsim <- dist(dta$age) # distance, already lower triangular
dsim

dta1 <- dta
names(dta1) <- paste0(names(dta), "1") # generalizes to more than 3 columns
dta2 <- dta
names(dta2) <- paste0(names(dta), "2")

dta12 <- merge(dta2, dta1) # order is important
dta12 <- dta12[dta12$ID1 < dta12$ID2, ] # get rid of duplicates

dta12 <- data.frame(dta12, dsim=as.vector(dsim)) # Typo was here
dta12 <- dta12[, c("ID1", "ID2", "gender1", "gender2", "age1", "age2", "dsim")]
dta12

David C


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Tuesday, May 16, 2017 11:21 AM
To: Rune Gr?nseth <nielsenrune at me.com>; r-help at r-project.org
Subject: Re: [R] Extracting metadata information to corresponding dissimilarity matrix

I think this is what you are trying to do. I've created a data set with 7 rows and a similarity matrix based on age:

set.seed(42)
dta <- data.frame(ID=1:7, gender=sample(c("M", "F"), 7, replace=TRUE),
     age=sample.int(75, 7))
sim <- max(dist(dta$age)) - dist(dta$age) # already lower triangular
sim

#    1  2  3  4  5  6
# 2 24               
# 3 21 59            
# 4 40 46 43         
# 5  0 38 41 22      
# 6  7 45 48 29 55   
# 7 55 31 28 47  7 14

# Now duplicate dta:
dta1 <- dta
names(dta1) <- c("ID1", "gender1", "age1")
dta2 <- dta
names(dta2) <- c("ID2", "gender2", "age2")

# Now merge and eliminate unneeded rows
dta12 <- merge(dta2, dta1) # order is important
dta12 <- dta12[dta12$ID1 < dta12$ID2, ]

# Finally combine the similarities with the combined data and rearrange
# the variable names
dta12 <- data.frame(dta12mod, sim=as.vector(sim))
dta12 <- dta12[, c("ID1", "ID2", "gender1", "gender2", "age1", "age2", "sim")]
dta12

#    ID1 ID2 gender1 gender2 age1 age2 sim
# 2    1   2       F       F   11   49  24
# 3    1   3       F       M   11   52  21
# 4    1   4       F       F   11   33  40
# 5    1   5       F       F   11   73   0
# 6    1   6       F       F   11   66   7
# 7    1   7       F       F   11   18  55
# 10   2   3       F       M   49   52  59
# 11   2   4       F       F   49   33  46
# 12   2   5       F       F   49   73  38
# 13   2   6       F       F   49   66  45
# 14   2   7       F       F   49   18  31
# 18   3   4       M       F   52   33  43
# 19   3   5       M       F   52   73  41
# 20   3   6       M       F   52   66  48
# 21   3   7       M       F   52   18  28
# 26   4   5       F       F   33   73  22
# 27   4   6       F       F   33   66  29
# 28   4   7       F       F   33   18  47
# 34   5   6       F       F   73   66  55
# 35   5   7       F       F   73   18   7
# 42   6   7       F       F   66   18  14

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rune Gr?nseth
Sent: Tuesday, May 16, 2017 4:31 AM
To: r-help at r-project.org
Subject: [R] Extracting metadata information to corresponding dissimilarity matrix

Hi,
I am R beginner. I've tried googling and reading, but this might be too simple to be found in the documentation. 

I have a dissimilarity index (symmetric matrix) from which I have extracted the unique values using the exodist package command "lower". There are 14 observations, so there are 91 unique comparisons.

After this I'd like to extract corresponding metadata from a separate data frame (the 14 observations organized in rows identified by a samplenumber-vector, and other variables as gender, age, et cetera). The aim is to have a new data frame with 91 rows and metadata vectors giving me the value of the dissimilarity index,  gender each of the two observations that are compared by the dissimilarity metric. So if I'm looking for gender differences, I need 5 vectors in the data frame: samplenumber1, samplenumber2, gender1, gender2 and dissimilarity metric.

Does anyone have suggestions or experiences in reformatting data in this manner? This is just a test-dataset. My full data-set is for more than 100 observations, so I need a more general code, if that is possible.

With great appreciation of any help.

Rune Gr?nseth 

---

Rune Gr?nseth, MD, PhD, postdoctoral fellow
Department of Thoracic Medicine
Haukeland University Hospital
N-5021 Bergen
Norway

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From arz at berkeley.edu  Tue May 16 21:49:43 2017
From: arz at berkeley.edu (Adam Ralph Zeilinger)
Date: Tue, 16 May 2017 12:49:43 -0700
Subject: [R] Long vectors error using lar function in selectiveInference
	package
Message-ID: <CAA1vyF4QQNsQYAiznyXF4RVvj=du-PKrn7ChbQrGpg5x69rXag@mail.gmail.com>

Hello,

I'm trying to use the lar() and larInf() functions in the
selectiveInference package to fit a least-angle regression model and
calculate sequential p-values for the coefficients. However, I am getting a
"long vectors error" when I run my data set through the lar() function:

Error in qr.qy(qr, D) :
  long vectors (argument 5) are not supported in .Fortran

>From reading on-line, this seems to be commonly encountered when a function
in C or Fortran tries to manipulate a matrix that is larger than 2^31-1
elements. My predictor matrix x is 56676 rows by 31 columns, producing a
matrix smaller than the 2^31-1 limit. I'm guessing that there are some
calculations within lar() that produce a larger matrix. While the lar()
function doesn't work, the lars() function in the lars package does.
However, I'd like to use lar() to be able to also use larInf() to get
sequential p-values.

Can anyone help me understand why I'm getting this error? Any thoughts on
ways that I could use lar() with my full data set? Or alternative
suggestions?

I'm running R 3.4.0, selectiveInference v. 1.2.2 and lars v. 1.2. I've
included example code below, modified from the lar() help page to reflect
the dimensions of my predictor matrix x:


library(selectiveInference)
library(lars)

set.seed(43)
n = 56676
p = 31
sigma = 0.95 # Estimated using original data set and the estimateSigma()
function
x = matrix(rnorm(n*p),n,p)
beta = c(3,2,rep(0,p-2))
y = x%*%beta + sigma*rnorm(n)

# run LAR, plot results
larfit = lar(x,y) # Returns 'long vector error'
plot(larfit)

# compute sequential p-values and confidence intervals
# (sigma estimated from full model)
out = larInf(larfit)
out

# But lars::lars() works fine
larsfit <- lars(x = x, y = y)


Thanks in advance for the help,
Adam

-- 
Adam Zeilinger

Postdoctoral Scholar
Department of Environmental Science, Policy, and Management
University of California Berkeley
arz at berkeley.edu

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed May 17 00:11:57 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 17 May 2017 08:11:57 +1000
Subject: [R] Aggregate counts of observations with times surrounding a
	time?
In-Reply-To: <CA+8X3fXWMqn2mfCDq7F4x_nZgm7tSD8c8dEWmkhLny2Gf3=-dg@mail.gmail.com>
References: <CABfYR_9rVuwL8RQrTAO_G+j3TR0nkaiN60wtoozCs2LCVjWYPg@mail.gmail.com>
 <CA+8X3fXWMqn2mfCDq7F4x_nZgm7tSD8c8dEWmkhLny2Gf3=-dg@mail.gmail.com>
Message-ID: <CA+8X3fWdZxLUKECA_FXJdXOtdsDeNW7G-GAuP6y6fyeiwkkrfg@mail.gmail.com>

Hi again,
Here is a version cleaned up a bit. Too tired to do it last night.

mndf<-data.frame(st=seq(1483360938,by=1700,length=10),
 et=seq(1483362938,by=1700,length=10),
 store=c(rep("gap",5),rep("starbucks",5)),
 zip=c(94000,94000,94100,94100,94200,94000,94000,94100,94100,94200),
 store_id=seq(50,59))
# orders the times and calculates number of simultaneous presences
count_simult<-function(x) {
 nrows<-dim(x)[1]
 timeorder<-order(unlist(mndf[1:nrows,c("st","et")]))
 # initialize result data frame - first time always has a value of 1
 interval_counts<-data.frame(time=c(x$st,x$et)[timeorder],
  startfin=rep(c("st","et"),each=5)[timeorder],
  count=c(1,rep(0,nrows-1)))
 for(i in 2:(nrows*2)) {
  interval_counts[i,"count"]<-
   interval_counts[i-1,"count"]+
   ifelse(interval_counts[i,"startfin"]=="st",1,-1)
 }
 return(interval_counts)
}
gap_counts<-count_simult(mndf[mndf$store=="gap",])
plot(gap_counts$time,gap_counts$count,type="l")
starbucks_counts<-count_simult(mndf[mndf$store=="starbucks",])
plot(starbucks_counts$time,gap_counts$count,type="l")

Jim


On Tue, May 16, 2017 at 7:43 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Mark,
> I think you might want something like this:
>
> mndf<-data.frame(st=seq(1483360938,by=1700,length=10),
>  et=seq(1483362938,by=1700,length=10),
>  store=c(rep("gap",5),rep("starbucks",5)),
>  zip=c(94000,94000,94100,94100,94200,94000,94000,94100,94100,94200),
>  store_id=seq(50,59))
> # orders the times and calculates number of simultaneous presences
> count_simult<-function(x) {
>  nrows<-dim(x)[1]
>  timeorder<-order(unlist(mndf[1:nrows,c("st","et")]))
>  interval_counts<-data.frame(time=c(x$st,x$et)[timeorder],
>   startfin=rep(c("st","et"),each=5)[timeorder],count=rep(NA,10))
>  interval_counts[1,"count"]<-1
>  for(i in 2:(nrows*2)) {
>   interval_counts[i,"count"]<-
>    interval_counts[i-1,"count"]+
>    ifelse(interval_counts[i,"startfin"]=="st",1,-1)
>  }
>  return(interval_counts)
> }
> gap_counts<-count_simult(mndf[1:5,])
> plot(gap_counts$time,gap_counts$count,type="l")
> starbucks_counts<-count_simult(mndf[6:10,])
> plot(starbucks_counts$time,gap_counts$count,type="l")
>
> There are a lot of ways to plot the counts by time. If you have any
> preferences, let me know.
>
> Jim
>
>
> On Tue, May 16, 2017 at 2:48 PM, Mark Noworolski <jmarkn at gmail.com> wrote:
>> I have a data frame that has a set of observed dwell times at a set of
>> locations. The metadata for the locations includes things that have varying
>> degrees of specificity. I'm interested in tracking the number of people
>> present at a given time in a given store, type of store, or zip code.
>>
>> Here's an example of some sample data (here st=start_time, and et=end_time):
>> data.frame(st=seq(1483360938,by=1700,length=10),et=seq(1483362938,by=1700,length=10),store=c(rep("gap",5),rep("starbucks",5)),zip=c(94000,94000,94100,94100,94200,94000,94000,94100,94100,94200),store_id=seq(50,59))
>>            st         et     store   zip store_id
>> 1  1483360938 1483362938       gap 94000       50
>> 2  1483362638 1483364638       gap 94000       51
>> 3  1483364338 1483366338       gap 94100       52
>> 4  1483366038 1483368038       gap 94100       53
>> 5  1483367738 1483369738       gap 94200       54
>> 6  1483369438 1483371438 starbucks 94000       55
>> 7  1483371138 1483373138 starbucks 94000       56
>> 8  1483372838 1483374838 starbucks 94100       57
>> 9  1483374538 1483376538 starbucks 94100       58
>> 10 1483376238 1483378238 starbucks 94200       59
>>
>> I'd like to be able to:
>> a) create aggretages of the number of people present in each store_id at a
>> given time
>> b) create aggregates of the number of people present - grouped by zip or
>> store
>>
>> I expect to be rolling up to hour or half hour buckets, but I don't think I
>> should have to decide this up front and be able to do something clever to
>> be able to use ggplot + some other library to plot the time evolution of
>> this information, rolled up the way I want.
>>
>> Any clever solutions? I've trolled stackoverflow and this email list.. to
>> no avail - but I'm willing to acknowledge I may have missed something.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From urs at kleinholdermann.de  Wed May 17 09:12:17 2017
From: urs at kleinholdermann.de (Urs Kleinholdermann)
Date: Wed, 17 May 2017 09:12:17 +0200
Subject: [R] adding predictor to linear model without changing existing
	coefficients
Message-ID: <87bmqsgdny.fsf@kleinholdermann.de>

Dear list members,

I want to add a predictor to a linear model without changing the
coefficients of the existing model. How is that done with R?

So if I have a response y and predictors x1, x2, x3 I want to make a model lm1 like

lm1 = lm(y~x1+x2)

After this model is computed I want to add x3 like

lm2 = lm(y~x1+x2+x3)

However, unlike it is done by the notation above or by update or add1
(as far as I understand) I don't want a new model with all predictors
estimated anew but I want a model lm2 where the coefficients for x1 and
x2 stay exactly as in lm1 and the coefficent for x3 is estimated
additionally. The reasons for this are theoretical. I guess what I want
is similar to calculating a new regression on the residuals of lm1.

lm2 = lm(residuals(lm1)~x3)

however, I would prefer to to that in the common framework of the lm
command in order to calculate statistics, perform anova on the models
and so on.

thanks for your help!
Urs


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed May 17 09:36:13 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Wed, 17 May 2017 07:36:13 +0000
Subject: [R] adding predictor to linear model without changing
	existing	coefficients
In-Reply-To: <87bmqsgdny.fsf@kleinholdermann.de>
References: <87bmqsgdny.fsf@kleinholdermann.de>
Message-ID: <5935a10ecd9a47f3986b81f5de65e71e@UM-MAIL3216.unimaas.nl>

You could use an offset term. An example:

n <- 100
x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
y <- 0 + .2 * x1 - .5 * x2 + .3 * x3 + rnorm(n)
res1 <- lm(y ~ x1 + x2)
summary(res1)
res2 <- lm(y ~ 1 + offset(coef(res1)[2] * x1 + coef(res1)[3] * x2))
summary(res2) ### identical intercept as in res1
res3 <- lm(y ~ offset(coef(res1)[2] * x1 + coef(res1)[3] * x2) + x3)
summary(res3)
 
You may need to consider whether you want to fix up the dfs, since the coefficients in the offset term are obviously not counted. Also, you did not say whether you want to reestimate the intercept; in res3 the intercept is reestimated.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Urs
>Kleinholdermann
>Sent: Wednesday, May 17, 2017 09:12
>To: r-help at r-project.org
>Subject: [R] adding predictor to linear model without changing existing
>coefficients
>
>Dear list members,
>
>I want to add a predictor to a linear model without changing the
>coefficients of the existing model. How is that done with R?
>
>So if I have a response y and predictors x1, x2, x3 I want to make a model
>lm1 like
>
>lm1 = lm(y~x1+x2)
>
>After this model is computed I want to add x3 like
>
>lm2 = lm(y~x1+x2+x3)
>
>However, unlike it is done by the notation above or by update or add1
>(as far as I understand) I don't want a new model with all predictors
>estimated anew but I want a model lm2 where the coefficients for x1 and
>x2 stay exactly as in lm1 and the coefficent for x3 is estimated
>additionally. The reasons for this are theoretical. I guess what I want
>is similar to calculating a new regression on the residuals of lm1.
>
>lm2 = lm(residuals(lm1)~x3)
>
>however, I would prefer to to that in the common framework of the lm
>command in order to calculate statistics, perform anova on the models
>and so on.
>
>thanks for your help!
>Urs
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-
>guide.html
>and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Wed May 17 09:42:16 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 17 May 2017 19:42:16 +1200
Subject: [R] R-3.4.0 fails test
Message-ID: <20170517074216.GA4553@slingshot.co.nz>

After installing R-3.4.0 I ran 'make check'  which halted here:

$ > tail reg-tests-1d.Rout.fail -n 16
> ## format()ing invalid hand-constructed  POSIXlt  objects
> d <- as.POSIXlt("2016-12-06"); d$zone <- 1
> tools::assertError(format(d))
> d$zone <- NULL
> stopifnot(identical(format(d),"2016-12-06"))
> d$zone <- "CET" # = previous, but 'zone' now is last
> tools::assertError(format(d))
> dlt <- structure(
+     list(sec = 52, min = 59L, hour = 18L, mday = 6L, mon = 11L, year = 116L,
+          wday = 2L, yday = 340L, isdst = 0L, zone = "CET", gmtoff = 3600L),
+     class = c("POSIXlt", "POSIXt"), tzone = c("", "CET", "CEST"))
> dlt$sec <- 10000 + 1:10 # almost three hours & uses re-cycling ..
> fd <- format(dlt)
> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXct(dlt))))
Error: identical(fd, format(dct <- as.POSIXct(dlt))) is not TRUE
Execution halted

... so, of course, the remaining tests aren't done.

AFAICT, that test will fail anywhere outside of tzone CET, but I could
be missing something.

What is the point of this test and is there a better way to move on to
the remaining tests besides editing the corresponding .R file?

Changing the line

> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXct(dlt))))
to
> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXlt(dlt))))
                                                                ^^^^
would pass.  But would that be any use?

TIA

(Linux Mint 17.3)

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From Gerrit.Eichner at math.uni-giessen.de  Wed May 17 10:12:13 2017
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 17 May 2017 10:12:13 +0200
Subject: [R] adding predictor to linear model without
	changingexistingcoefficients
In-Reply-To: <87bmqsgdny.fsf@kleinholdermann.de>
References: <87bmqsgdny.fsf@kleinholdermann.de>
Message-ID: <426f09c5-b000-04f7-b48c-67e144fc3fe8@math.uni-giessen.de>

Hello, Urs,

you may have seen Wolfgang Viechtbauer's answer already which offers
an R-technical solution, but this may leave the mathematical grounds
of linear models. See inline below for my concern and a hint.

Am 17.05.2017 um 09:12 schrieb Urs Kleinholdermann:
> Dear list members,
>
> I want to add a predictor to a linear model without changing the
> coefficients of the existing model. How is that done with R?
>
> So if I have a response y and predictors x1, x2, x3 I want to make a model lm1 like
>
> lm1 = lm(y~x1+x2)
>
> After this model is computed I want to add x3 like
>
> lm2 = lm(y~x1+x2+x3)
>
> However, unlike it is done by the notation above or by update or add1
> (as far as I understand) I don't want a new model with all predictors
> estimated anew but I want a model lm2 where the coefficients for x1 and
> x2 stay exactly as in lm1 and the coefficent for x3 is estimated
> additionally. The reasons for this are theoretical.

And the reasons why this is usually impossible (for a valid linear
model as a projection of the response vector onto a linear subspace
spanned by the columns of the design matrix) are also theoretical:
It is not an R problem, but a mathematical fact that unless the vector
of values of a new model term is orthogonal to the vectors of all model
terms already included in the model (i.e., to all columns of its design
matrix) the estimated coefficients of the "old" model are correlated
with the estimated coefficient of the "new" one, and hence the already
existing ones change. So, if you manage to obtain orthogonality you can
achieve what you desire. (You may want to consult with a (theoretical)
book on linear models ... or a local statistician.)

Hth  --  Gerrit


> I guess what I want is similar to calculating a new regression on
> the residuals of lm1.
>
> lm2 = lm(residuals(lm1)~x3)
>
> however, I would prefer to to that in the common framework of the lm
> command in order to calculate statistics, perform anova on the models
> and so on.
>
> thanks for your help!
> Urs
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nilsson.henric at gmail.com  Wed May 17 12:31:52 2017
From: nilsson.henric at gmail.com (Henric Winell)
Date: Wed, 17 May 2017 12:31:52 +0200
Subject: [R] R-3.4.0 fails test
In-Reply-To: <20170517074216.GA4553@slingshot.co.nz>
References: <20170517074216.GA4553@slingshot.co.nz>
Message-ID: <4a086fbb-61ed-d3a5-ce23-14bbaea5531f@gmail.com>

On 2017-05-17 09:42, Patrick Connolly wrote:

> After installing R-3.4.0 I ran 'make check'  which halted here:
> 
> $ > tail reg-tests-1d.Rout.fail -n 16

This problem was brought up on the R-devel list early this morning.  See 
https://stat.ethz.ch/pipermail/r-devel/2017-May/074275.html


Henric Winell




>> ## format()ing invalid hand-constructed  POSIXlt  objects
>> d <- as.POSIXlt("2016-12-06"); d$zone <- 1
>> tools::assertError(format(d))
>> d$zone <- NULL
>> stopifnot(identical(format(d),"2016-12-06"))
>> d$zone <- "CET" # = previous, but 'zone' now is last
>> tools::assertError(format(d))
>> dlt <- structure(
> +     list(sec = 52, min = 59L, hour = 18L, mday = 6L, mon = 11L, year = 116L,
> +          wday = 2L, yday = 340L, isdst = 0L, zone = "CET", gmtoff = 3600L),
> +     class = c("POSIXlt", "POSIXt"), tzone = c("", "CET", "CEST"))
>> dlt$sec <- 10000 + 1:10 # almost three hours & uses re-cycling ..
>> fd <- format(dlt)
>> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXct(dlt))))
> Error: identical(fd, format(dct <- as.POSIXct(dlt))) is not TRUE
> Execution halted
> 
> ... so, of course, the remaining tests aren't done.
> 
> AFAICT, that test will fail anywhere outside of tzone CET, but I could
> be missing something.
> 
> What is the point of this test and is there a better way to move on to
> the remaining tests besides editing the corresponding .R file?
> 
> Changing the line
> 
>> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXct(dlt))))
> to
>> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXlt(dlt))))
>                                                                  ^^^^
> would pass.  But would that be any use?
> 
> TIA
> 
> (Linux Mint 17.3)
>


From pdalgd at gmail.com  Wed May 17 13:21:43 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Wed, 17 May 2017 13:21:43 +0200
Subject: [R] R-3.4.0 fails test
In-Reply-To: <4a086fbb-61ed-d3a5-ce23-14bbaea5531f@gmail.com>
References: <20170517074216.GA4553@slingshot.co.nz>
 <4a086fbb-61ed-d3a5-ce23-14bbaea5531f@gmail.com>
Message-ID: <ACA47D66-F469-4C75-8521-CB0DD76572C7@gmail.com>


> On 17 May 2017, at 12:31 , Henric Winell <nilsson.henric at gmail.com> wrote:
> 
> On 2017-05-17 09:42, Patrick Connolly wrote:
> 
>> After installing R-3.4.0 I ran 'make check'  which halted here:
>> $ > tail reg-tests-1d.Rout.fail -n 16
> 
> This problem was brought up on the R-devel list early this morning.  See https://stat.ethz.ch/pipermail/r-devel/2017-May/074275.html

Looks like that one is not the same, occurring a handful of lines further up.

Anyways, you might want to 

a) move the discussion to R-devel
b) include your platform (hardware, OS) and time zone info
c) run the offending code lines "by hand" and show us the values of format(dlt) and format(dct) so we can see what the problem is, something like

dlt <- structure(
    list(sec = 52, min = 59L, hour = 18L, mday = 6L, mon = 11L, year = 116L,
       wday = 2L, yday = 340L, isdst = 0L, zone = "CET", gmtoff = 3600L),
       class = c("POSIXlt", "POSIXt"), tzone = c("", "CET", "CEST"))
dlt$sec <- 10000 + 1:10 
dct <- as.POSIXct(dlt)
cbind(format(dlt), format(dct))


-pd


> Henric Winell
> 
> 
> 
> 
>>> ## format()ing invalid hand-constructed  POSIXlt  objects
>>> d <- as.POSIXlt("2016-12-06"); d$zone <- 1
>>> tools::assertError(format(d))
>>> d$zone <- NULL
>>> stopifnot(identical(format(d),"2016-12-06"))
>>> d$zone <- "CET" # = previous, but 'zone' now is last
>>> tools::assertError(format(d))
>>> dlt <- structure(
>> +     list(sec = 52, min = 59L, hour = 18L, mday = 6L, mon = 11L, year = 116L,
>> +          wday = 2L, yday = 340L, isdst = 0L, zone = "CET", gmtoff = 3600L),
>> +     class = c("POSIXlt", "POSIXt"), tzone = c("", "CET", "CEST"))
>>> dlt$sec <- 10000 + 1:10 # almost three hours & uses re-cycling ..
>>> fd <- format(dlt)
>>> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXct(dlt))))
>> Error: identical(fd, format(dct <- as.POSIXct(dlt))) is not TRUE
>> Execution halted
>> ... so, of course, the remaining tests aren't done.
>> AFAICT, that test will fail anywhere outside of tzone CET, but I could
>> be missing something.
>> What is the point of this test and is there a better way to move on to
>> the remaining tests besides editing the corresponding .R file?
>> Changing the line
>>> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXct(dlt))))
>> to
>>> stopifnot(length(fd) == 10, identical(fd, format(dct <- as.POSIXlt(dlt))))
>>                                                                 ^^^^
>> would pass.  But would that be any use?
>> TIA
>> (Linux Mint 17.3)
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From patrcasi at nova.edu  Wed May 17 13:55:10 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Wed, 17 May 2017 11:55:10 +0000
Subject: [R] CREATE DICTIONARY WITH TM PACKAGE
Message-ID: <CY4PR06MB3032945BB7D2A0989FAF4ECCB9E70@CY4PR06MB3032.namprd06.prod.outlook.com>

Dear Members & Experts,


Since the Dictionary () function is no longer available with the tm package. How do I use other functions to do the same as below? I want to capture a list of specific terms from a corpus. By example, if my corpus has 102 files. I want to see a list with occurrences of price, crude, oil in all 102 files. When I use the function Dictionary (), I got the error: Error: could not find function "Dictionary"


> d <- Dictionary(c("prostatic", "adenocarcinoma", "grade"))
> inspect(DocumentTermMatrix(docs, list(dictionary = d)))


But if I use the codes below using inspect, the dictionary only returns the terms for 10 files instead of 102. I need a way to get my dictionary to capture and return those terms for all 102 files or whatever other terms I select. I know I am close but inspect () is not the right function.


> myTerms <- c("prostatic", "adenocarcinoma", "grade")
> inspect(DocumentTermMatrix(docs, list(dictionary = myTerms)))

 <<DocumentTermMatrix (documents: 102, terms: 3)>>
 Non-/sparse entries: 292/14
 Sparsity           : 5%
 Maximal term length: 14
 Weighting          : term frequency (tf)
 Sample             :
                Terms
 Docs            adenocarcinoma grade prostatic
   Patient14.txt             11     6         3
   Patient15.txt              7    12         2
   Patient16.txt             13    16         4
   Patient19.txt              5    13         2
   Patient24.txt             11    12         4
   Patient25.txt              8     9         4
   Patient41.txt              8    10         4
   Patient46.txt              8    10         3
   Patient8.txt               9    12         2
   Patient9.txt               8    23         2


Thanks


Patrick Casimir, PhD

Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed May 17 16:05:06 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 17 May 2017 07:05:06 -0700 (PDT)
Subject: [R] violin plot help
In-Reply-To: <161FBD7CDADFC2489F2D5A7441BEBFBF8F463597@S0020287.miamidade.gov>
References: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
 <D5E780EE-3EAF-49C6-ACF6-5C2918A20E1A@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463436@S0020287.miamidade.gov>
 <571BEE09-8994-4FB6-B67C-8E2D909CFC09@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463597@S0020287.miamidade.gov>
Message-ID: <alpine.BSF.2.00.1705170654410.49807@pedal.dcn.davis.ca.us>

Here is an example that works... a reproducible example always includes 
code AND enough sample data to exercise the code:

########
dta <- read.table( text=
"STATION        Geo     Wshed   DATE            PARAMETER                 RESULT
BB36            Bay     C-100   1/10/2013       'Phosphorus, Total (TP)'  0.004
BB36            Bay     C-100   1/10/2013       'Chlorophyll-A'           0.2
BB52            Bay     C-100   1/10/2013       'Phosphorus, Total (TP)'  0.003
BB52            Bay     C-100   1/10/2013       'Chlorophyll-A'           0.39
CD01A           Mouth   C-100   1/10/2013       'Phosphorus, Total (TP)'  0.017
CD01A           Mouth   C-100   1/10/2013       'Chlorophyll-A'           0.64
CD02            East    C-100   1/10/2013       'Phosphorus, Total (TP)'  0.01
CD05            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.005
CD06            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.01
CD09            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.007
BB36            Bay     C-100   2/7/2013        'Chlorophyll-A'           0.18
BB36            Bay     C-100   2/7/2013        'Phosphorus, Total (TP)'  0.002
BB52            Bay     C-100   2/7/2013        'Phosphorus, Total (TP)'  0.002
BB52            Bay     C-100   2/7/2013        'Chlorophyll-A'           0.31
CD01A           Mouth   C-100   2/7/2013        'Phosphorus, Total (TP)'  0.004
CD01A           Mouth   C-100   2/7/2013        'Chlorophyll-A'           0.4
CD02            East    C-100   2/7/2013        'Phosphorus, Total (TP)'  0.011
CD05            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.007
CD06            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.015
CD09            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.008
CD01A           Mouth   C-100   3/7/2013        'Phosphorus, Total (TP)'  0.007
", header=TRUE)
# prints result to console without assigning it to a new variable
subset( dta, Geo == "East" )
########

Note that [1] and [2] suggest the use of the dput function to help create 
R code that creates the object just as you have it before the troublesome 
line of code:

########
dta <- structure(list(STATION = structure(c(1L, 1L, 2L, 2L, 3L, 3L,
4L, 5L, 6L, 7L, 1L, 1L, 2L, 2L, 3L, 3L, 4L, 5L, 6L, 7L, 3L)
, .Label = c("BB36", "BB52", "CD01A", "CD02", "CD05", "CD06", "CD09")
      , class = "factor"),
     Geo = structure(c(1L, 1L, 1L, 1L, 4L, 4L, 3L, 2L, 2L, 2L,
     1L, 1L, 1L, 1L, 4L, 4L, 3L, 2L, 2L, 2L, 4L), .Label = c("Bay",
     "Central", "East", "Mouth"), class = "factor"),
     Wshed = structure(c(1L,
     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
     1L, 1L, 1L, 1L, 1L), .Label = "C-100", class = "factor"),
     DATE = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L), .Label = c("1/10/2013",
     "2/7/2013", "3/7/2013"), class = "factor"),
     PARAMETER = structure(c(2L,
     1L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L,
     2L, 2L, 2L, 2L, 2L), .Label = c("Chlorophyll-A",
     "Phosphorus, Total (TP)"
     ), class = "factor"), RESULT = c(0.004, 0.2, 0.003, 0.39,
     0.017, 0.64, 0.01, 0.005, 0.01, 0.007, 0.18, 0.002, 0.002,
     0.31, 0.004, 0.4, 0.011, 0.007, 0.015, 0.008, 0.007)),
     .Names = c("STATION", "Geo", "Wshed", "DATE", "PARAMETER", "RESULT"),
     class = "data.frame", row.names = c(NA, -21L))
subset( dta, Geo == "East" )
########

Note that the "structure" function created by dput is mostly insensitive
to extra newlines, except inside quotes.

So the above examples work for me. What doesn't work for you?

One thought: Are you editing your R code with a plain text editor or are 
you editing it with a word processor that might replace your plain quotes 
with curly quotes?

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

On Wed, 17 May 2017, Abdelrahman, Omar (RER) wrote:

> Thanks again
> RE: "so all the more reason to give us an example that we can run to trigger the same error." Are you asking for an example of the data? Below is a "small" example, but with so many levels of the different variables I am not sure it can be useful.
>
> STATION	Geo	Wshed	DATE		PARAMETER		RESULT
> BB36		Bay	C-100	1/10/2013	Phosphorus, Total (TP)	0.004
> BB36		Bay	C-100	1/10/2013	Chlorophyll-A		0.2
> BB52		Bay	C-100	1/10/2013	Phosphorus, Total (TP)	0.003
> BB52		Bay	C-100	1/10/2013	Chlorophyll-A		0.39
> CD01A		Mouth	C-100	1/10/2013	Phosphorus, Total (TP)	0.017
> CD01A		Mouth	C-100	1/10/2013	Chlorophyll-A	0.64
> CD02		East	C-100	1/10/2013	Phosphorus, Total (TP)	0.01
> CD05		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.005
> CD06		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.01
> CD09		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.007
> BB36		Bay	C-100	2/7/2013	Chlorophyll-A		0.18
> BB36		Bay	C-100	2/7/2013	Phosphorus, Total (TP)	0.002
> BB52		Bay	C-100	2/7/2013	Phosphorus, Total (TP)	0.002
> BB52		Bay	C-100	2/7/2013	Chlorophyll-A		0.31
> CD01A		Mouth	C-100	2/7/2013	Phosphorus, Total (TP)	0.004
> CD01A		Mouth	C-100	2/7/2013	Chlorophyll-A		0.4
> CD02		East	C-100	2/7/2013	Phosphorus, Total (TP)	0.011
> CD05		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.007
> CD06		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.015
> CD09		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.008
> CD01A		Mouth	C-100	3/7/2013	Phosphorus, Total (TP)	0.007
>
> Hope this is not too much
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, May 16, 2017 12:30 PM
> To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>; R-help <r-help at r-project.org>
> Subject: RE: [R] violin plot help
>
> Please use reply-all or equivalent to keep the list in the conversation. I don't do private online consultation.
>
> Your example suggested you did not know the difference, but your error suggests a completely different expression triggered the error, so all the more reason to give us an example that we can run to trigger the same error.
>
> Items B and C are recommendations to read the help pages for those syntax elements. You should already have read enough of an introduction to R to have encountered the use of the question mark to bring up the help pages. If not, please do.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 16, 2017 9:00:09 AM PDT, "Abdelrahman, Omar (RER)" <Omar.Abdelrahman at miamidade.gov> wrote:
>> Thanks Jeff. I will send plain text from now on. I am not sure what B
>> or C mean; is there a guide that I can reference? I know the difference
>> between "=" and "==" , they work the same in Stata and SAS.
>>
>> Omar
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, May 16, 2017 11:43 AM
>> To: r-help at r-project.org; Abdelrahman, Omar (RER)
>> <Omar.Abdelrahman at miamidade.gov>; 'r-help at r-project.org'
>> <r-help at r-project.org>
>> Subject: Re: [R] violin plot help
>>
>> Read
>> A) the Posting Guide (re plain text only... your emails may be damaged
>> by the mailing list if you send html-formatted email... only you can
>> solve this by figuring out how to use your email software)
>> B) Help on assignment (?`=`)
>> C) Help on logical tests (?`==`)
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 16, 2017 7:06:40 AM PDT, "Abdelrahman, Omar (RER)"
>> <Omar.Abdelrahman at miamidade.gov> wrote:
>>> I am trying to produce multiple violin plots by 3 categorical
>>> variables, each violin representing 1 year worth of data. The
>> variables
>>> are:
>>>
>>> Watershed (7 levels: county canals)
>>>
>>> Geography (5 levels: west; central; east; mouth; bay)
>>>
>>> Parameter (8 levels: water quality chemical parameters)
>>>
>>> Year (25 levels: 1992-2017)
>>>
>>> I want to produce 1 plot for each Parameter-Watershed subdivided into
>>> Geography with a violin for each year. I used facets with the
>> following
>>> code (not by year):
>>>
>>> ggplot () +
>>>
>>> facet_grid (PARAMETER ~Wshed, scales="free_y") +
>>>
>>> geom_violin (data=merged, aes(x=Geo, y=RESULT))
>>>
>>>
>>>
>>> I do not want facets, they crowd the information so it is unreadable.
>> I
>>> just started with R this week and have not been able to figure out the
>>
>>> foreach protocol, or any other loop protocol. I tried to subset the
>>> data to do it iteratively with the following code:
>>>
>>>
>>>
>>> subdf<-subset (merged, Wshed = "AC")
>>>
>>>
>>>
>>> but got an error: Error: unexpected input in "subdf=subset (merged,
>>> Wshed == ""
>>>
>>> Any help would be greatly appreciated.
>>>
>>> Thanks,
>>>
>>> Omar Abdelrahman, Biologist II
>>> Miami-Dade County, Department of Regulatory and Economic Resources
>>> Division of Environmental Resources Management (DERM) Overtown Transit
>>
>>> Village
>>> 701 NW 1st Court, 5th Floor
>>> Miami, FL 33136-3912
>>> (305) 372-6872
>>> abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
>>> www.miamidade.gov/environment<http://www.miamidade.gov/environment/>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From bgunter.4567 at gmail.com  Wed May 17 16:48:12 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 17 May 2017 07:48:12 -0700
Subject: [R] adding predictor to linear model without changing existing
	coefficients
In-Reply-To: <87bmqsgdny.fsf@kleinholdermann.de>
References: <87bmqsgdny.fsf@kleinholdermann.de>
Message-ID: <CAGxFJbSsVsRYf6hCRWaxXfu01gtR1gSh2SdTzy25ZMW8X-OOoQ@mail.gmail.com>

You should consult a linear models text, but, assuming I have
correctly understood your post, the procedure is this (the translation
to R code is trivial, and I leave it to you):

Let y be the response variable, P1 be the first set of predictors and
z be your new predictor to be added.

1. regress y on P1; let r1 be the residuals from this model, call it M1.

2. regress z on P1 and let r2 be the residuals from this model

3. regress r1 on r2, Call this model M2

Than the predictions obtained from the model y ~ P1 + z are the same
(within numerical error) as those obtained by adding the predictions
from M1 to the predictions of M2. As Gerrit mentioned, the
coefficients from the full fit model will be different than those
obtained from the seprate model fitting procedure.

Cheers,
Bert





Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, May 17, 2017 at 12:12 AM, Urs Kleinholdermann
<urs at kleinholdermann.de> wrote:
> Dear list members,
>
> I want to add a predictor to a linear model without changing the
> coefficients of the existing model. How is that done with R?
>
> So if I have a response y and predictors x1, x2, x3 I want to make a model lm1 like
>
> lm1 = lm(y~x1+x2)
>
> After this model is computed I want to add x3 like
>
> lm2 = lm(y~x1+x2+x3)
>
> However, unlike it is done by the notation above or by update or add1
> (as far as I understand) I don't want a new model with all predictors
> estimated anew but I want a model lm2 where the coefficients for x1 and
> x2 stay exactly as in lm1 and the coefficent for x3 is estimated
> additionally. The reasons for this are theoretical. I guess what I want
> is similar to calculating a new regression on the residuals of lm1.
>
> lm2 = lm(residuals(lm1)~x3)
>
> however, I would prefer to to that in the common framework of the lm
> command in order to calculate statistics, perform anova on the models
> and so on.
>
> thanks for your help!
> Urs
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Wed May 17 18:29:31 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 17 May 2017 18:29:31 +0200
Subject: [R] optimx and follow.on=TRUE... does not follow
Message-ID: <8d21d3a9-3ca6-1f60-6e32-6c4bd4bd8eba@yahoo.fr>

Hi,

I would like to know if some of you have a solution for this problem:

I use optimx (from package optimx) to fit the parameters of a model 
(complex model based on several imbricated exponential functions).

I use the two methods : method = c("Nelder-Mead", "BFGS") with the options:

control=list(dowarn=FALSE, follow.on=TRUE, kkt=FALSE, trace=1, 
REPORT=100, maxit=1000)

For some situations, it works as expected, but not for others.

The problem occurs at the transition between the two methods:

For example at the end of the Nelder-Mead method the value is 47.55839 
but at the beginning of the BFGS it drops again at 47.62xxx and at the 
end of the BFGS it is "only" 47.56198, so a local minimum (see below a 
result).

                  DHA      DHH     T12H    value fevals gevals niter 
convcode kkt1 kkt2  xtimes

Nelder-Mead 46.93154 39.94028 318.4949 47.55839    409     NA NA       
10   NA   NA 156.896
BFGS        45.29744 36.80026 321.5996 47.56198     54      5 NA        
0   NA   NA  32.604

After investigations, it seems that when parameters are transmitted from 
one method to the next, the values is truncated at the 5th digit. And as 
my model has several exponential functions imbricated, it is very 
sensitive to the precision of the parameters. It does not change the 
main conclusion, but I would prefer not have such a problem.

Does someone has a solution ?

I would prefer continue to use optimx.

Thanks a lot.

Marc


From profjcnash at gmail.com  Wed May 17 19:08:05 2017
From: profjcnash at gmail.com (J C Nash)
Date: Wed, 17 May 2017 13:08:05 -0400
Subject: [R] optimx and follow.on=TRUE... does not follow
In-Reply-To: <8d21d3a9-3ca6-1f60-6e32-6c4bd4bd8eba@yahoo.fr>
References: <8d21d3a9-3ca6-1f60-6e32-6c4bd4bd8eba@yahoo.fr>
Message-ID: <0733b83f-65c8-0a0a-573d-667773e832ce@gmail.com>

"follow-on" is one of the main reasons I stopped work on optimx and refactored to optimr/optimrx, where I
separated this functionality into the polyopt() function. optimr has just a few solvers, while optimrx is used to
add them as I get round to doing it, but it's on R-forge. Mainly a matter of avoiding "your package
fails" when some dependency goes sick.

I am grateful that this posting has come, as I noted the Rd function for polyopt() had not been
completed. It is now mostly fixed on R-forge. I will do CRAN version when more tests are completed on
polyopt(). I'd be grateful for any feedback from users.

Marc: Can you try the polyopt from optimrx? I'll be happy to help with it, as I feel much more confident
there aren't collisions with other parts of the code. I tried and failed to fix optimx for the
kind of issue you found because there were (as far as I could determine) options that were incompatible.
I believe Ravi and I tried to go a step too far to integrate all the features in one function.

I'm hoping that polyopt doesn't truncate as you experienced, and am also willing to help sort that out.
I made the example in the polyopt manual page dump the function value at each evaluation, and the "best"
NM solution was passed to Rvmmin OK. But that is, after all, just one test.

Perhaps we should go off-list to work this out, then report back.

Best, JN


On 2017-05-17 12:29 PM, Marc Girondot via R-help wrote:
> Hi,
> 
> I would like to know if some of you have a solution for this problem:
> 
> I use optimx (from package optimx) to fit the parameters of a model (complex model based on several imbricated 
> exponential functions).
> 
> I use the two methods : method = c("Nelder-Mead", "BFGS") with the options:
> 
> control=list(dowarn=FALSE, follow.on=TRUE, kkt=FALSE, trace=1, REPORT=100, maxit=1000)
> 
> For some situations, it works as expected, but not for others.
> 
> The problem occurs at the transition between the two methods:
> 
> For example at the end of the Nelder-Mead method the value is 47.55839 but at the beginning of the BFGS it drops again 
> at 47.62xxx and at the end of the BFGS it is "only" 47.56198, so a local minimum (see below a result).
> 
>                   DHA      DHH     T12H    value fevals gevals niter convcode kkt1 kkt2  xtimes
> 
> Nelder-Mead 46.93154 39.94028 318.4949 47.55839    409     NA NA 10   NA   NA 156.896
> BFGS        45.29744 36.80026 321.5996 47.56198     54      5 NA 0   NA   NA  32.604
> 
> After investigations, it seems that when parameters are transmitted from one method to the next, the values is truncated 
> at the 5th digit. And as my model has several exponential functions imbricated, it is very sensitive to the precision of 
> the parameters. It does not change the main conclusion, but I would prefer not have such a problem.
> 
> Does someone has a solution ?
> 
> I would prefer continue to use optimx.
> 
> Thanks a lot.
> 
> Marc
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pifferdavide at gmail.com  Wed May 17 21:18:07 2017
From: pifferdavide at gmail.com (Davide Piffer)
Date: Wed, 17 May 2017 22:18:07 +0300
Subject: [R] converting each column of a data frame into a matrix with n rows
Message-ID: <CAOq2dy7=rMemyBuLbitf1foqsrnXvYWUEQVnD7Qy9t6t5Pw1QQ@mail.gmail.com>

I need to convert each vector of a dataframe into a matrix with 2 rows
and 2 columns (i.e. contingency table).
Note I don't want to convert the entire df into a matrix! I want to
apply a function that converts each 4 elements vector of a df into a 2
x 2 matrix.

I wrote something like this, but it will not work:

f_matrix=function(x){ matrix (x)
  nrow=2}
matrix_y=apply(y,2,function(x) f_matrix (x))


From dwinsemius at comcast.net  Wed May 17 21:34:51 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 17 May 2017 12:34:51 -0700
Subject: [R] converting each column of a data frame into a matrix with n
	rows
In-Reply-To: <CAOq2dy7=rMemyBuLbitf1foqsrnXvYWUEQVnD7Qy9t6t5Pw1QQ@mail.gmail.com>
References: <CAOq2dy7=rMemyBuLbitf1foqsrnXvYWUEQVnD7Qy9t6t5Pw1QQ@mail.gmail.com>
Message-ID: <4141A2C6-C757-45DE-B80E-B38799DD4F90@comcast.net>


> On May 17, 2017, at 12:18 PM, Davide Piffer <pifferdavide at gmail.com> wrote:
> 
> I need to convert each vector of a dataframe into a matrix with 2 rows
> and 2 columns (i.e. contingency table).
> Note I don't want to convert the entire df into a matrix! I want to
> apply a function that converts each 4 elements vector of a df into a 2
> x 2 matrix.
> 
> I wrote something like this, but it will not work:
> 
> f_matrix=function(x){ matrix (x)
>  nrow=2}
> matrix_y=apply(y,2,function(x) f_matrix (x))

Maybe it shold be:

matrix_y_list = lapply(y, function(x) f_matrix (x) )


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Wed May 17 21:35:48 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 17 May 2017 19:35:48 +0000
Subject: [R] converting each column of a data frame into a matrix with n
 rows
In-Reply-To: <CAOq2dy7=rMemyBuLbitf1foqsrnXvYWUEQVnD7Qy9t6t5Pw1QQ@mail.gmail.com>
References: <CAOq2dy7=rMemyBuLbitf1foqsrnXvYWUEQVnD7Qy9t6t5Pw1QQ@mail.gmail.com>
Message-ID: <829fc4d7262e4caa9b32bdabbad9b17b@exch-2p-mbx-w2.ads.tamu.edu>

Not really enough info here since you don't specify much about the data frame or how the results should be provided, but maybe something like this:

y <- data.frame(matrix(1:100, 10, 10))
y.mat <- lapply(y, matrix, nrow=2)
str(y.mat)
List of 10
 $ X1 : int [1:2, 1:5] 1 2 3 4 5 6 7 8 9 10
 $ X2 : int [1:2, 1:5] 11 12 13 14 15 16 17 18 19 20
 $ X3 : int [1:2, 1:5] 21 22 23 24 25 26 27 28 29 30
 $ X4 : int [1:2, 1:5] 31 32 33 34 35 36 37 38 39 40
 $ X5 : int [1:2, 1:5] 41 42 43 44 45 46 47 48 49 50
 $ X6 : int [1:2, 1:5] 51 52 53 54 55 56 57 58 59 60
 $ X7 : int [1:2, 1:5] 61 62 63 64 65 66 67 68 69 70
 $ X8 : int [1:2, 1:5] 71 72 73 74 75 76 77 78 79 80
 $ X9 : int [1:2, 1:5] 81 82 83 84 85 86 87 88 89 90
 $ X10: int [1:2, 1:5] 91 92 93 94 95 96 97 98 99 100


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Davide Piffer
Sent: Wednesday, May 17, 2017 2:18 PM
To: r-help at r-project.org
Subject: [R] converting each column of a data frame into a matrix with n rows

I need to convert each vector of a dataframe into a matrix with 2 rows
and 2 columns (i.e. contingency table).
Note I don't want to convert the entire df into a matrix! I want to
apply a function that converts each 4 elements vector of a df into a 2
x 2 matrix.

I wrote something like this, but it will not work:

f_matrix=function(x){ matrix (x)
  nrow=2}
matrix_y=apply(y,2,function(x) f_matrix (x))

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pifferdavide at gmail.com  Wed May 17 22:01:08 2017
From: pifferdavide at gmail.com (Davide Piffer)
Date: Wed, 17 May 2017 23:01:08 +0300
Subject: [R] converting each column of a data frame into a matrix with n
	rows
In-Reply-To: <829fc4d7262e4caa9b32bdabbad9b17b@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAOq2dy7=rMemyBuLbitf1foqsrnXvYWUEQVnD7Qy9t6t5Pw1QQ@mail.gmail.com>
 <829fc4d7262e4caa9b32bdabbad9b17b@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAOq2dy47AnF=Oc_7L-6HR7DL3PK8RZe5_-1c3E3=Ar0NC8EGHw@mail.gmail.com>

Thanks! This gets closer to the solution but a small problem remains.
I get 2 rows and only one column, whereas I need a 2x2 matrix (like a
contingency table for Fisher's exact test).Also another issue is it
repeats the first number of the column, instead of using all 4.
For example, first vector of df is=c(564,3825,125, 377

I get:

         [,1]
[1,] 564.3112
[2,] 564.3112


But I should get

       [,1]   [.2]
[1,]564   125
[2,] 3825  377

On 17 May 2017 at 22:35, David L Carlson <dcarlson at tamu.edu> wrote:
> Not really enough info here since you don't specify much about the data frame or how the results should be provided, but maybe something like this:
>
> y <- data.frame(matrix(1:100, 10, 10))
> y.mat <- lapply(y, matrix, nrow=2)
> str(y.mat)
> List of 10
>  $ X1 : int [1:2, 1:5] 1 2 3 4 5 6 7 8 9 10
>  $ X2 : int [1:2, 1:5] 11 12 13 14 15 16 17 18 19 20
>  $ X3 : int [1:2, 1:5] 21 22 23 24 25 26 27 28 29 30
>  $ X4 : int [1:2, 1:5] 31 32 33 34 35 36 37 38 39 40
>  $ X5 : int [1:2, 1:5] 41 42 43 44 45 46 47 48 49 50
>  $ X6 : int [1:2, 1:5] 51 52 53 54 55 56 57 58 59 60
>  $ X7 : int [1:2, 1:5] 61 62 63 64 65 66 67 68 69 70
>  $ X8 : int [1:2, 1:5] 71 72 73 74 75 76 77 78 79 80
>  $ X9 : int [1:2, 1:5] 81 82 83 84 85 86 87 88 89 90
>  $ X10: int [1:2, 1:5] 91 92 93 94 95 96 97 98 99 100
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Davide Piffer
> Sent: Wednesday, May 17, 2017 2:18 PM
> To: r-help at r-project.org
> Subject: [R] converting each column of a data frame into a matrix with n rows
>
> I need to convert each vector of a dataframe into a matrix with 2 rows
> and 2 columns (i.e. contingency table).
> Note I don't want to convert the entire df into a matrix! I want to
> apply a function that converts each 4 elements vector of a df into a 2
> x 2 matrix.
>
> I wrote something like this, but it will not work:
>
> f_matrix=function(x){ matrix (x)
>   nrow=2}
> matrix_y=apply(y,2,function(x) f_matrix (x))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed May 17 22:39:22 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 17 May 2017 13:39:22 -0700
Subject: [R] converting each column of a data frame into a matrix with n
	rows
In-Reply-To: <CAOq2dy47AnF=Oc_7L-6HR7DL3PK8RZe5_-1c3E3=Ar0NC8EGHw@mail.gmail.com>
References: <CAOq2dy7=rMemyBuLbitf1foqsrnXvYWUEQVnD7Qy9t6t5Pw1QQ@mail.gmail.com>
 <829fc4d7262e4caa9b32bdabbad9b17b@exch-2p-mbx-w2.ads.tamu.edu>
 <CAOq2dy47AnF=Oc_7L-6HR7DL3PK8RZe5_-1c3E3=Ar0NC8EGHw@mail.gmail.com>
Message-ID: <94D94C3A-AD28-49B4-B381-CB4C1F46D748@comcast.net>


> On May 17, 2017, at 1:01 PM, Davide Piffer <pifferdavide at gmail.com> wrote:
> 
> Thanks! This gets closer to the solution but a small problem remains.
> I get 2 rows and only one column, whereas I need a 2x2 matrix (like a
> contingency table for Fisher's exact test).Also another issue is it
> repeats the first number of the column, instead of using all 4.
> For example, first vector of df is=c(564,3825,125, 377
> 
> I get:
> 
>         [,1]
> [1,] 564.3112
> [2,] 564.3112
> 
> 
> But I should get
> 
>       [,1]   [.2]
> [1,]564   125
> [2,] 3825  377

( y <- data.frame(matrix(1:40, 4, 10)) )
( y.mat <- lapply(y, matrix, nrow=2))

> head(y.mat, 3)
$X1
     [,1] [,2]
[1,]    1    3
[2,]    2    4

$X2
     [,1] [,2]
[1,]    5    7
[2,]    6    8

$X3
     [,1] [,2]
[1,]    9   11
[2,]   10   12

> 
> On 17 May 2017 at 22:35, David L Carlson <dcarlson at tamu.edu> wrote:
>> Not really enough info here since you don't specify much about the data frame or how the results should be provided, but maybe something like this:
>> 
>> y <- data.frame(matrix(1:100, 10, 10))
>> y.mat <- lapply(y, matrix, nrow=2)
>> str(y.mat)
>> List of 10
>> $ X1 : int [1:2, 1:5] 1 2 3 4 5 6 7 8 9 10
>> $ X2 : int [1:2, 1:5] 11 12 13 14 15 16 17 18 19 20
>> $ X3 : int [1:2, 1:5] 21 22 23 24 25 26 27 28 29 30
>> $ X4 : int [1:2, 1:5] 31 32 33 34 35 36 37 38 39 40
>> $ X5 : int [1:2, 1:5] 41 42 43 44 45 46 47 48 49 50
>> $ X6 : int [1:2, 1:5] 51 52 53 54 55 56 57 58 59 60
>> $ X7 : int [1:2, 1:5] 61 62 63 64 65 66 67 68 69 70
>> $ X8 : int [1:2, 1:5] 71 72 73 74 75 76 77 78 79 80
>> $ X9 : int [1:2, 1:5] 81 82 83 84 85 86 87 88 89 90
>> $ X10: int [1:2, 1:5] 91 92 93 94 95 96 97 98 99 100
>> 
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Davide Piffer
>> Sent: Wednesday, May 17, 2017 2:18 PM
>> To: r-help at r-project.org
>> Subject: [R] converting each column of a data frame into a matrix with n rows
>> 
>> I need to convert each vector of a dataframe into a matrix with 2 rows
>> and 2 columns (i.e. contingency table).
>> Note I don't want to convert the entire df into a matrix! I want to
>> apply a function that converts each 4 elements vector of a df into a 2
>> x 2 matrix.
>> 
>> I wrote something like this, but it will not work:
>> 
>> f_matrix=function(x){ matrix (x)
>>  nrow=2}
>> matrix_y=apply(y,2,function(x) f_matrix (x))
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Wed May 17 23:50:10 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 18 May 2017 07:50:10 +1000
Subject: [R] RCommander issue
In-Reply-To: <1029354536.1835670.1495024063011@mail.yahoo.com>
References: <1197692941.1996216.1493823349413.ref@mail.yahoo.com>
 <1197692941.1996216.1493823349413@mail.yahoo.com>
 <CA+8X3fV+mg8EGt0eCfz7pJ6=dbTTJJccDpatkZp3KD12GK2g2Q@mail.gmail.com>
 <1029354536.1835670.1495024063011@mail.yahoo.com>
Message-ID: <CA+8X3fUsy3RHWHmt7CvcrfRbE4380BEUHnjU33iL1OtLjrqFyQ@mail.gmail.com>

Hi Thambu,
You must have an internet connection, otherwise you couldn't access
CRAN. Have you tried using "install.packages" (see the help page) from
within R? Your message isn't clear whether you have used that function
or tried to download the package from a Web browser and then install
it from the local copy of the package.

There are a lot of things that can go wrong when accessing the
internet and the error message does not seem to implicate R.

Jim

On Wed, May 17, 2017 at 10:27 PM, thambu david <thambsup at yahoo.com> wrote:
> :-)
> I did try with the right spelling with no luck
> is there any simple ting i am making an error with?
>
>


From sumanta24 at gmail.com  Wed May 17 08:22:23 2017
From: sumanta24 at gmail.com (Sumanta Basak)
Date: Wed, 17 May 2017 11:52:23 +0530
Subject: [R] Help on reducing multiple loops
Message-ID: <CADiURWtphCtvNT09cx_7yy6EwGqs0Tp+HoMaajyV2Lm4_0yQdA@mail.gmail.com>

Hi All,

I've a data-set on product sub-product matrix on which I'm doing multiple
calculation, but unfortunately using nested loops, the programme is taking
long time to execute. Can anyone help me how to get rid of the following
jungle? Any direction would be helpful.

GA <- "India"
verticle <- "Prod1"

prod_data <- readRDS(paste0("/Prod_ladder_",GA,"_",verticle,".rds"))
setDF(prod_data)

Final_data <-
subset(prod_data[,c("P_KEY","Active_Prod_Id","Active_Prod_Nm")],!duplicated(prod_data[,c("P_KEY","Active_Prod_Id")]))

proximity_prod_mapping <- readRDS("Proximity_prod_mapping.rds")
dst_prod <- subset(prod_data[,c("P_KEY")],!duplicated(prod_data$P_KEY))


output_data <- c()
data_merge_final <- c()

system.time({
  for(i in 1 : length(dst_prod)){

    prod_data <- subset(prod_data,prod_data$P_KEY == dst_prod[i]) #
Subsetting data at prod level
    dst_prod <-
subset(prod_data[,c("Active_Prod_Id")],!duplicated(prod_data$Active_Prod_Id))
# Finding distinct prods of active prodloyee

    for(j in 1 : length(dst_prod)){
      # Subsetting data at prod level for active prod
      # Fetiching data for Anchor prod
      prod_data1 <-
subset(prod_data[,c("P_KEY","Active_Prod_Id","Active_Prod_Nm","Start_Date_1","End_Date_1")],prod_data$Active_Prod_Id
== dst_prod[j])
      prod_data1$Anchor_prod <- 1
      anc_max_End_Date_1 <- as.Date(max(prod_data1$End_Date_1),origin =
"1970-01-01")
      anc_prod_count <- sum(prod_data1$Anchor_prod)

      # Fetiching data for Proximate prod
      prox_prod_data <-
subset(proximity_prod_mapping[,c("Proximate_prod_ID")],proximity_prod_mapping$Anchor_prod_ID
== dst_prod[j])
      prod_data2 <-
subset(prod_data[,c("P_KEY","Active_Prod_Id","Active_Prod_Nm","Start_Date_1","End_Date_1")],prod_data$Active_Prod_Id
%in% c(prox_prod_data))
      prox_sill_count <- 0
      if(nrow(prod_data2) > 0){
        prod_data2$Proximity_prod <- 1
        prox_max_End_Date_1 <- as.Date(max(prod_data2$End_Date_1),origin =
"1970-01-01")
        prox_sill_count <- sum(prod_data2$Proximity_prod)
      }
      # library(plyr)
      prod_data <-rbind.fill(prod_data1,prod_data2)
      prod_data$exclude <- 0
      prod_data$Anchor_Active_Prod_Id <- dst_prod[j]

      prod_data$Start_Date_1 <- as.Date(prod_data$Start_Date_1,origin =
"1970-01-01")
      prod_data$End_Date_1 <- as.Date(prod_data$End_Date_1,origin =
"1970-01-01")

      if(prox_sill_count > 0){
        if(nrow(prod_data) > 1){
          # Trimming end date of proximity prods where end data of
proximity prod is greater that Anchor prod
          if((prox_max_End_Date_1 - anc_max_End_Date_1) > 0){
            prod_data$End_Date_1 <- ifelse(prod_data$Proximity_prod == 1 &
(prod_data$End_Date_1 - anc_max_End_Date_1) > 0,
anc_max_End_Date_1,prod_data$End_Date_1)
            prod_data$End_Date_1 <- as.Date(prod_data$End_Date_1,origin =
"1970-01-01")
          }
          prod_data$exclude <- ifelse(prod_data$Proximity_prod == 1 &
(as.Date(prod_data$Start_Date_1,origin = "1970-01-01") -
anc_max_End_Date_1) > 0,1,0)
          prod_data <- subset(prod_data,prod_data$exclude == 0)

          prod_data <-
arrange(prod_data,prod_data$Anchor_prod,desc(prod_data$End_Date_1),prod_data$Start_Date_1)

          prod_data$Anchor_prod <- ifelse(is.na
(prod_data$Anchor_prod),0,prod_data$Anchor_prod)
          prod_data$Proximity_prod <- ifelse(is.na
(prod_data$Proximity_prod),0,prod_data$Proximity_prod)
          prod_data$new_rec <- 0

          tot_loop <- nrow(prod_data)
          k=1
          # Looping to map start date and end date of each row with other
rows
          while(k <= tot_loop){
            excl_flag <- prod_data[k,c("exclude")]
            if(excl_flag == 0){
              st_dt1 <- as.Date(prod_data[k,c("Start_Date_1")])
              end_dt1 <- as.Date(prod_data[k,c("End_Date_1")])
              prod_flag1 <- prod_data[k,c("Anchor_prod")]

              if(k != nrow(prod_data)){
                tot_row <- nrow(prod_data)

                for(m in 1 : (tot_row -k)){
                  l = k+m
                  if(l != k){
                    st_dt2 <- as.Date(prod_data[l,c("Start_Date_1")])
                    end_dt2 <- as.Date(prod_data[l,c("End_Date_1")])
                    prod_flag2 <- prod_data[l,c("Anchor_prod")]

                    flag_excl <- prod_data[l,c("exclude")]
                    if(flag_excl ==0){
                      rec_check <- prod_data[l,c("new_rec")]
                      # if(rec_check == 0){
                      prod_data$Start_date2 <- NA
                      prod_data$End_date2 <- NA

                      new_start_date <- as.Date(ifelse(prod_flag1 == 1 &
prod_flag2 == 1,NA,
                                                       ifelse(prod_flag1 ==
1 & prod_flag2 == 0 & end_dt2 > end_dt1 & st_dt2 < end_dt1,end_dt1,

ifelse(prod_flag1 == 0 & prod_flag2 == 1 & end_dt1 > end_dt2 & st_dt1 <
end_dt2,end_dt2,NA))),origin = "1970-01-01")
                      message(paste0("new_start_date = ",new_start_date))
                      new_start_date <- as.Date(new_start_date,origin =
"1970-01-01")
                      message(paste0("new_start_date = ",new_start_date))
                      new_end_date <- as.Date(ifelse(prod_flag1 == 1 &
prod_flag2 == 1,NA,
                                                     ifelse(prod_flag1 == 1
& prod_flag2 == 0 & end_dt2 > end_dt1 & st_dt2 < end_dt1,end_dt2,

ifelse(prod_flag1 == 0 & prod_flag2 == 1 & end_dt1 > end_dt2 & st_dt1 <
end_dt2,end_dt1,NA))),origin = "1970-01-01")
                      message(paste0("new_end_date = ",new_end_date))
                      new_end_date <- as.Date(new_end_date,origin =
"1970-01-01")
                      message(paste0("new_end_date = ",new_end_date))
                      prod_data[l,c("Start_date2")] <-
as.Date(new_start_date,origin = "1970-01-01")
                      prod_data[l,c("End_date2")] <-
as.Date(new_end_date,origin = "1970-01-01")

                      tmp_data <- subset(prod_data,!is.na
(prod_data$Start_date2))
                      tmp_data$Start_Date_1 <-
as.Date(tmp_data$Start_date2,origin = "1970-01-01")
                      tmp_data$End_Date_1 <-
as.Date(tmp_data$End_date2,origin = "1970-01-01")
                      if(nrow(tmp_data)){
                        tmp_data$new_rec <- 1
                        prod_data[l,c("End_Date_1")] <-
as.Date(end_dt1,origin = "1970-01-01")
                      }
                      prod_data <- rbind(prod_data,tmp_data)
                      tot_row <- tot_row + nrow(tmp_data)
                      tot_loop <- tot_loop + nrow(tmp_data)
                      prod_data$Start_date2 <- NULL
                      prod_data$End_date2 <- NULL
                      # }
                    }
                    # Condition to identify true subset

                    # overlap <- ifelse((st_dt1 >= st_dt2 & st_dt1 <=
end_dt2) & (end_dt1 >= st_dt2 & end_dt1 <= end_dt2),1,
                    #            ifelse((st_dt2 >= st_dt1 & st_dt2 <=
end_dt1) & (end_dt2 >= st_dt1 & end_dt2 <= end_dt1),1,0))



                    if((end_dt1 - st_dt2) >= 0){
                      if((end_dt2 - st_dt1) >= 0){
                        if((st_dt2 - st_dt1) >=0){
                          prod_data[k,c("exclude")] <- ifelse(prod_flag1 ==
1 & prod_flag2 == 1,9999, #if Anchor prods have overlapping

 ifelse(prod_flag1 == 1 & prod_flag2 == 0,0,

ifelse(prod_flag1 == 0 & prod_flag2 == 1,1,

 ifelse(prod_flag1 == 0 & prod_flag2 == 0,0,1))))
                          prod_data[l,c("exclude")] <- ifelse(prod_flag1 ==
1 & prod_flag2 == 1,9999,

 ifelse(prod_flag1 == 0 & prod_flag2 == 1,0,

ifelse(prod_flag1 == 1 & prod_flag2 == 0,1,

 ifelse(prod_flag1 == 0 & prod_flag2 == 0,1,0))))
                        }
                      }
                    }
                    # Condition to trim the dates as to make dates in each
observation mutually exclusive to exch other
                    flag_excl <- prod_data[l,c("exclude")]
                    if(flag_excl == 0){
                      if(end_dt1 > st_dt2){
                        if(st_dt1 >= st_dt2){
                          new_date <- ifelse(end_dt2 >
st_dt1,as.Date(st_dt1,origin = "1970-01-01"),as.Date(end_dt2,origin =
"1970-01-01"))
                          new_date <- as.Date(new_date,origin =
"1970-01-01")
                          old_date <-
as.Date(prod_data[l,c("End_Date_1")],origin = "1970-01-01")
                          old_date <- as.Date(old_date,origin =
"1970-01-01")

                          # prod_data[j,c("End_Date_1")] <-
ifelse(prod_flag1 == 1 & prod_flag2 == 1,as.Date(old_date,origin =
"1970-01-01"),
                          #
ifelse(prod_flag1 == 0 & prod_flag2 == 1,as.date(old_date, origin =
"1970-01-01"),as.Date(new_date,origin = "1970-01-01")))

                          prod_data[l,c("End_Date_1")] <-
as.Date(ifelse(prod_flag1 == 1 & prod_flag2 == 1,old_date,ifelse(prod_flag1
== 0 & prod_flag2 == 1,old_date,new_date)),origin = "1970-01-01")

                        }
                      }
                    }
                  }
                }

              }
            }
            k=k+1
          }
        }
      }
      # excluding non required observations
      prod_data <- subset(prod_data,prod_data$exclude == 0)

      prod_data$multiply_factor <- ifelse(prod_data$Anchor_prod == 1,1,
                                           ifelse(prod_data$Proximity_prod
== 1,0.5,9999))

      prod_data$recency_in_months <- (as.Date("2017-01-31") -
prod_data$End_Date_1)/30

      prod_data$recency_factor <- ifelse(prod_data$recency_in_months <=
12,1,

ifelse(prod_data$recency_in_months > 12 & prod_data$recency_in_months <=
24,0.9,

 ifelse(prod_data$recency_in_months > 24 & prod_data$recency_in_months <=
36,0.8,

ifelse(prod_data$recency_in_months > 36 & prod_data$recency_in_months <=
48,0.7,

 ifelse(prod_data$recency_in_months > 48,0.6,9999)))))

      prod_data$duration_in_months <- (prod_data$End_Date_1 -
prod_data$Start_Date_1)/30

      prod_data$weight <-
prod_data$duration_in_months*prod_data$multiply_factor*prod_data$recency_factor

      prod <- prod_data[1,c("Anchor_Active_Prod_Id")]
      if(nrow(prod_data) > 1){
        data_merge <-with(prod_data,aggregate(weight ~ P_KEY, FUN =
function(x) c(Proficiency_Score = sum(x))))
      }else{
        data_merge <- prod_data[1,c("P_KEY","weight")]
      }


      data_merge$prod <- prod_data[1,c("Anchor_Active_Prod_Id")]

      data_merge_final <- rbind(data_merge_final,data_merge)


      # Recency and Duration calculation goes here and final score will be
added in final data
      output_data <- rbind.fill(output_data,prod_data)

    }
  }


  Final_data <- merge(Final_data,data_merge_final,by.x= c("P_KEY",
"Active_Prod_Id"),by.y = c("P_KEY", "prod"),all.x=TRUE)

  names(Final_data)[names(Final_data) == "weight"] <- "Proficiency_Score"

  emerging_prod_mapping <- readRDS("5.Emerging_prod_Lookup.rds")

  emerging_prod_list <-
subset(emerging_prod_mapping[,c("prod_ID")],!duplicated(emerging_prod_mapping$prod_ID))


  Final_data$Emerging_Traditional <- ifelse(Final_data$Active_Prod_Id %in%
c(emerging_prod_list),"Emerging","Traditional")

  Final_data$Final_Proficiency <- ifelse(Final_data$Emerging_Traditional ==
"Traditional",

 ifelse(Final_data$Proficiency_Score < 12, "P0",

ifelse(Final_data$Proficiency_Score >=12 & Final_data$Proficiency_Score <
24,"P1",

 ifelse(Final_data$Proficiency_Score >=24 & Final_data$Proficiency_Score <
48,"P2",

ifelse(Final_data$Proficiency_Score >=48 & Final_data$Proficiency_Score <
60,"P3",

 ifelse(Final_data$Proficiency_Score >=60,"P4",NA))))),

 ifelse(Final_data$Emerging_Traditional == "Emerging",

ifelse(Final_data$Proficiency_Score < 6, "P0",

 ifelse(Final_data$Proficiency_Score >=6 & Final_data$Proficiency_Score <
12,"P1",

ifelse(Final_data$Proficiency_Score >=12 & Final_data$Proficiency_Score <
24,"P2",

 ifelse(Final_data$Proficiency_Score >=24 & Final_data$Proficiency_Score <
30,"P3",

ifelse(Final_data$Proficiency_Score >=30,"P4",NA))))),NA))

  tst <- prod_data[,c("P_KEY", "Id")]
  tst <- subset(tst,!duplicated(tst))

  Final_data <-
merge(Final_data,tst[,c("P_KEY","Id")],by="P_KEY",all.x=TRUE)
})

*SUMANTA BASAK*

	[[alternative HTML version deleted]]


From Omar.Abdelrahman at miamidade.gov  Wed May 17 14:50:08 2017
From: Omar.Abdelrahman at miamidade.gov (Abdelrahman, Omar (RER))
Date: Wed, 17 May 2017 12:50:08 +0000
Subject: [R] violin plot help
In-Reply-To: <571BEE09-8994-4FB6-B67C-8E2D909CFC09@dcn.davis.ca.us>
References: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
 <D5E780EE-3EAF-49C6-ACF6-5C2918A20E1A@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463436@S0020287.miamidade.gov>
 <571BEE09-8994-4FB6-B67C-8E2D909CFC09@dcn.davis.ca.us>
Message-ID: <161FBD7CDADFC2489F2D5A7441BEBFBF8F463597@S0020287.miamidade.gov>

Thanks again
RE: "so all the more reason to give us an example that we can run to trigger the same error." Are you asking for an example of the data? Below is a "small" example, but with so many levels of the different variables I am not sure it can be useful.

STATION	Geo	Wshed	DATE		PARAMETER		RESULT
BB36		Bay	C-100	1/10/2013	Phosphorus, Total (TP)	0.004
BB36		Bay	C-100	1/10/2013	Chlorophyll-A		0.2
BB52		Bay	C-100	1/10/2013	Phosphorus, Total (TP)	0.003
BB52		Bay	C-100	1/10/2013	Chlorophyll-A		0.39
CD01A		Mouth	C-100	1/10/2013	Phosphorus, Total (TP)	0.017
CD01A		Mouth	C-100	1/10/2013	Chlorophyll-A	0.64
CD02		East	C-100	1/10/2013	Phosphorus, Total (TP)	0.01
CD05		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.005
CD06		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.01
CD09		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.007
BB36		Bay	C-100	2/7/2013	Chlorophyll-A		0.18
BB36		Bay	C-100	2/7/2013	Phosphorus, Total (TP)	0.002
BB52		Bay	C-100	2/7/2013	Phosphorus, Total (TP)	0.002
BB52		Bay	C-100	2/7/2013	Chlorophyll-A		0.31
CD01A		Mouth	C-100	2/7/2013	Phosphorus, Total (TP)	0.004
CD01A		Mouth	C-100	2/7/2013	Chlorophyll-A		0.4
CD02		East	C-100	2/7/2013	Phosphorus, Total (TP)	0.011
CD05		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.007
CD06		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.015
CD09		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.008
CD01A		Mouth	C-100	3/7/2013	Phosphorus, Total (TP)	0.007

Hope this is not too much

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Tuesday, May 16, 2017 12:30 PM
To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>; R-help <r-help at r-project.org>
Subject: RE: [R] violin plot help

Please use reply-all or equivalent to keep the list in the conversation. I don't do private online consultation.

Your example suggested you did not know the difference, but your error suggests a completely different expression triggered the error, so all the more reason to give us an example that we can run to trigger the same error. 

Items B and C are recommendations to read the help pages for those syntax elements. You should already have read enough of an introduction to R to have encountered the use of the question mark to bring up the help pages. If not, please do. 
--
Sent from my phone. Please excuse my brevity.

On May 16, 2017 9:00:09 AM PDT, "Abdelrahman, Omar (RER)" <Omar.Abdelrahman at miamidade.gov> wrote:
>Thanks Jeff. I will send plain text from now on. I am not sure what B 
>or C mean; is there a guide that I can reference? I know the difference 
>between "=" and "==" , they work the same in Stata and SAS.
>
>Omar
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>Sent: Tuesday, May 16, 2017 11:43 AM
>To: r-help at r-project.org; Abdelrahman, Omar (RER) 
><Omar.Abdelrahman at miamidade.gov>; 'r-help at r-project.org'
><r-help at r-project.org>
>Subject: Re: [R] violin plot help
>
>Read
>A) the Posting Guide (re plain text only... your emails may be damaged 
>by the mailing list if you send html-formatted email... only you can 
>solve this by figuring out how to use your email software)
>B) Help on assignment (?`=`)
>C) Help on logical tests (?`==`)
>--
>Sent from my phone. Please excuse my brevity.
>
>On May 16, 2017 7:06:40 AM PDT, "Abdelrahman, Omar (RER)"
><Omar.Abdelrahman at miamidade.gov> wrote:
>>I am trying to produce multiple violin plots by 3 categorical 
>>variables, each violin representing 1 year worth of data. The
>variables
>>are:
>>
>>Watershed (7 levels: county canals)
>>
>>Geography (5 levels: west; central; east; mouth; bay)
>>
>>Parameter (8 levels: water quality chemical parameters)
>>
>>Year (25 levels: 1992-2017)
>>
>>I want to produce 1 plot for each Parameter-Watershed subdivided into 
>>Geography with a violin for each year. I used facets with the
>following
>>code (not by year):
>>
>>ggplot () +
>>
>>facet_grid (PARAMETER ~Wshed, scales="free_y") +
>>
>>geom_violin (data=merged, aes(x=Geo, y=RESULT))
>>
>>
>>
>>I do not want facets, they crowd the information so it is unreadable.
>I
>>just started with R this week and have not been able to figure out the
>
>>foreach protocol, or any other loop protocol. I tried to subset the 
>>data to do it iteratively with the following code:
>>
>>
>>
>>subdf<-subset (merged, Wshed = "AC")
>>
>>
>>
>>but got an error: Error: unexpected input in "subdf=subset (merged, 
>>Wshed == ""
>>
>>Any help would be greatly appreciated.
>>
>>Thanks,
>>
>>Omar Abdelrahman, Biologist II
>>Miami-Dade County, Department of Regulatory and Economic Resources 
>>Division of Environmental Resources Management (DERM) Overtown Transit
>
>>Village
>>701 NW 1st Court, 5th Floor
>>Miami, FL 33136-3912
>>(305) 372-6872
>>abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
>>www.miamidade.gov/environment<http://www.miamidade.gov/environment/>
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.

From panjj1125 at outlook.com  Wed May 17 15:43:31 2017
From: panjj1125 at outlook.com (=?gb2312?B?xcsgvqe+pw==?=)
Date: Wed, 17 May 2017 13:43:31 +0000
Subject: [R]  Offset - usersplits function package RPART
Message-ID: <0D65EFCC-E1B0-4AE1-89B5-B75059938D28@outlook.com>

I have written a user written splitting function recently, but I do not know how to use my splitting criteria to predict the test data. If I use the function ?predict?, there will return an error message, please give me some helpful advice.

From Omar.Abdelrahman at miamidade.gov  Wed May 17 21:59:36 2017
From: Omar.Abdelrahman at miamidade.gov (Abdelrahman, Omar (RER))
Date: Wed, 17 May 2017 19:59:36 +0000
Subject: [R] violin plot help
In-Reply-To: <alpine.BSF.2.00.1705170654410.49807@pedal.dcn.davis.ca.us>
References: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
 <D5E780EE-3EAF-49C6-ACF6-5C2918A20E1A@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463436@S0020287.miamidade.gov>
 <571BEE09-8994-4FB6-B67C-8E2D909CFC09@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463597@S0020287.miamidade.gov>
 <alpine.BSF.2.00.1705170654410.49807@pedal.dcn.davis.ca.us>
Message-ID: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4636D9@S0020287.miamidade.gov>

Thank you, curly quotes got me! I was able to subset the data and produce the violin plot. Now, is there a way to generate multiple plots separately (no facets)? With so many levels of each variable, I am trying to avoid doing it iteratively. Neither ggplot2 books nor web searches have yielded anything (so far). 
Also I want a violin for each year within Geo. I did try to specify year with the following:
ggplot () +
facet_grid (PARAMETER ~Wshed~year, scales="free_y") +
geom_violin (data=subdf, aes(x=Geo, y=RESULT, fill=Geo))

which yielded
-Error in combine_vars(data, params$plot_env, cols, drop = params$drop) : 
  At least one layer must contain all variables used for faceting

Also tried:
ggplot () +
facet_grid (PARAMETER ~Wshed, scales="free_y") +
geom_violin (data=subdf, aes(x=Geo~year, y=RESULT, fill=Geo))

Do I need to specify "year(date)"; I loaded lubridate?


-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Wednesday, May 17, 2017 10:05 AM
To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>
Cc: R-help <r-help at r-project.org>
Subject: RE: [R] violin plot help

Here is an example that works... a reproducible example always includes code AND enough sample data to exercise the code:

########
dta <- read.table( text=
"STATION        Geo     Wshed   DATE            PARAMETER                 RESULT
BB36            Bay     C-100   1/10/2013       'Phosphorus, Total (TP)'  0.004
BB36            Bay     C-100   1/10/2013       'Chlorophyll-A'           0.2
BB52            Bay     C-100   1/10/2013       'Phosphorus, Total (TP)'  0.003
BB52            Bay     C-100   1/10/2013       'Chlorophyll-A'           0.39
CD01A           Mouth   C-100   1/10/2013       'Phosphorus, Total (TP)'  0.017
CD01A           Mouth   C-100   1/10/2013       'Chlorophyll-A'           0.64
CD02            East    C-100   1/10/2013       'Phosphorus, Total (TP)'  0.01
CD05            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.005
CD06            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.01
CD09            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.007
BB36            Bay     C-100   2/7/2013        'Chlorophyll-A'           0.18
BB36            Bay     C-100   2/7/2013        'Phosphorus, Total (TP)'  0.002
BB52            Bay     C-100   2/7/2013        'Phosphorus, Total (TP)'  0.002
BB52            Bay     C-100   2/7/2013        'Chlorophyll-A'           0.31
CD01A           Mouth   C-100   2/7/2013        'Phosphorus, Total (TP)'  0.004
CD01A           Mouth   C-100   2/7/2013        'Chlorophyll-A'           0.4
CD02            East    C-100   2/7/2013        'Phosphorus, Total (TP)'  0.011
CD05            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.007
CD06            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.015
CD09            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.008
CD01A           Mouth   C-100   3/7/2013        'Phosphorus, Total (TP)'  0.007
", header=TRUE)
# prints result to console without assigning it to a new variable subset( dta, Geo == "East" ) ########

Note that [1] and [2] suggest the use of the dput function to help create R code that creates the object just as you have it before the troublesome line of code:

########
dta <- structure(list(STATION = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 5L, 6L, 7L, 1L, 1L, 2L, 2L, 3L, 3L, 4L, 5L, 6L, 7L, 3L) , .Label = c("BB36", "BB52", "CD01A", "CD02", "CD05", "CD06", "CD09")
      , class = "factor"),
     Geo = structure(c(1L, 1L, 1L, 1L, 4L, 4L, 3L, 2L, 2L, 2L,
     1L, 1L, 1L, 1L, 4L, 4L, 3L, 2L, 2L, 2L, 4L), .Label = c("Bay",
     "Central", "East", "Mouth"), class = "factor"),
     Wshed = structure(c(1L,
     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
     1L, 1L, 1L, 1L, 1L), .Label = "C-100", class = "factor"),
     DATE = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L), .Label = c("1/10/2013",
     "2/7/2013", "3/7/2013"), class = "factor"),
     PARAMETER = structure(c(2L,
     1L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L,
     2L, 2L, 2L, 2L, 2L), .Label = c("Chlorophyll-A",
     "Phosphorus, Total (TP)"
     ), class = "factor"), RESULT = c(0.004, 0.2, 0.003, 0.39,
     0.017, 0.64, 0.01, 0.005, 0.01, 0.007, 0.18, 0.002, 0.002,
     0.31, 0.004, 0.4, 0.011, 0.007, 0.015, 0.008, 0.007)),
     .Names = c("STATION", "Geo", "Wshed", "DATE", "PARAMETER", "RESULT"),
     class = "data.frame", row.names = c(NA, -21L)) subset( dta, Geo == "East" ) ########

Note that the "structure" function created by dput is mostly insensitive to extra newlines, except inside quotes.

So the above examples work for me. What doesn't work for you?

One thought: Are you editing your R code with a plain text editor or are you editing it with a word processor that might replace your plain quotes with curly quotes?

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

On Wed, 17 May 2017, Abdelrahman, Omar (RER) wrote:

> Thanks again
> RE: "so all the more reason to give us an example that we can run to trigger the same error." Are you asking for an example of the data? Below is a "small" example, but with so many levels of the different variables I am not sure it can be useful.
>
> STATION	Geo	Wshed	DATE		PARAMETER		RESULT
> BB36		Bay	C-100	1/10/2013	Phosphorus, Total (TP)	0.004
> BB36		Bay	C-100	1/10/2013	Chlorophyll-A		0.2
> BB52		Bay	C-100	1/10/2013	Phosphorus, Total (TP)	0.003
> BB52		Bay	C-100	1/10/2013	Chlorophyll-A		0.39
> CD01A		Mouth	C-100	1/10/2013	Phosphorus, Total (TP)	0.017
> CD01A		Mouth	C-100	1/10/2013	Chlorophyll-A	0.64
> CD02		East	C-100	1/10/2013	Phosphorus, Total (TP)	0.01
> CD05		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.005
> CD06		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.01
> CD09		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.007
> BB36		Bay	C-100	2/7/2013	Chlorophyll-A		0.18
> BB36		Bay	C-100	2/7/2013	Phosphorus, Total (TP)	0.002
> BB52		Bay	C-100	2/7/2013	Phosphorus, Total (TP)	0.002
> BB52		Bay	C-100	2/7/2013	Chlorophyll-A		0.31
> CD01A		Mouth	C-100	2/7/2013	Phosphorus, Total (TP)	0.004
> CD01A		Mouth	C-100	2/7/2013	Chlorophyll-A		0.4
> CD02		East	C-100	2/7/2013	Phosphorus, Total (TP)	0.011
> CD05		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.007
> CD06		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.015
> CD09		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.008
> CD01A		Mouth	C-100	3/7/2013	Phosphorus, Total (TP)	0.007
>
> Hope this is not too much
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, May 16, 2017 12:30 PM
> To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>; R-help 
> <r-help at r-project.org>
> Subject: RE: [R] violin plot help
>
> Please use reply-all or equivalent to keep the list in the conversation. I don't do private online consultation.
>
> Your example suggested you did not know the difference, but your error suggests a completely different expression triggered the error, so all the more reason to give us an example that we can run to trigger the same error.
>
> Items B and C are recommendations to read the help pages for those syntax elements. You should already have read enough of an introduction to R to have encountered the use of the question mark to bring up the help pages. If not, please do.
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 16, 2017 9:00:09 AM PDT, "Abdelrahman, Omar (RER)" <Omar.Abdelrahman at miamidade.gov> wrote:
>> Thanks Jeff. I will send plain text from now on. I am not sure what B 
>> or C mean; is there a guide that I can reference? I know the 
>> difference between "=" and "==" , they work the same in Stata and SAS.
>>
>> Omar
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, May 16, 2017 11:43 AM
>> To: r-help at r-project.org; Abdelrahman, Omar (RER) 
>> <Omar.Abdelrahman at miamidade.gov>; 'r-help at r-project.org'
>> <r-help at r-project.org>
>> Subject: Re: [R] violin plot help
>>
>> Read
>> A) the Posting Guide (re plain text only... your emails may be 
>> damaged by the mailing list if you send html-formatted email... only 
>> you can solve this by figuring out how to use your email software)
>> B) Help on assignment (?`=`)
>> C) Help on logical tests (?`==`)
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 16, 2017 7:06:40 AM PDT, "Abdelrahman, Omar (RER)"
>> <Omar.Abdelrahman at miamidade.gov> wrote:
>>> I am trying to produce multiple violin plots by 3 categorical 
>>> variables, each violin representing 1 year worth of data. The
>> variables
>>> are:
>>>
>>> Watershed (7 levels: county canals)
>>>
>>> Geography (5 levels: west; central; east; mouth; bay)
>>>
>>> Parameter (8 levels: water quality chemical parameters)
>>>
>>> Year (25 levels: 1992-2017)
>>>
>>> I want to produce 1 plot for each Parameter-Watershed subdivided 
>>> into Geography with a violin for each year. I used facets with the
>> following
>>> code (not by year):
>>>
>>> ggplot () +
>>>
>>> facet_grid (PARAMETER ~Wshed, scales="free_y") +
>>>
>>> geom_violin (data=merged, aes(x=Geo, y=RESULT))
>>>
>>>
>>>
>>> I do not want facets, they crowd the information so it is unreadable.
>> I
>>> just started with R this week and have not been able to figure out 
>>> the
>>
>>> foreach protocol, or any other loop protocol. I tried to subset the 
>>> data to do it iteratively with the following code:
>>>
>>>
>>>
>>> subdf<-subset (merged, Wshed = "AC")
>>>
>>>
>>>
>>> but got an error: Error: unexpected input in "subdf=subset (merged, 
>>> Wshed == ""
>>>
>>> Any help would be greatly appreciated.
>>>
>>> Thanks,
>>>
>>> Omar Abdelrahman, Biologist II
>>> Miami-Dade County, Department of Regulatory and Economic Resources 
>>> Division of Environmental Resources Management (DERM) Overtown 
>>> Transit
>>
>>> Village
>>> 701 NW 1st Court, 5th Floor
>>> Miami, FL 33136-3912
>>> (305) 372-6872
>>> abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
>>> www.miamidade.gov/environment<http://www.miamidade.gov/environment/>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From drjimlemon at gmail.com  Thu May 18 00:25:04 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 18 May 2017 08:25:04 +1000
Subject: [R] violin plot help
In-Reply-To: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4636D9@S0020287.miamidade.gov>
References: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
 <D5E780EE-3EAF-49C6-ACF6-5C2918A20E1A@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463436@S0020287.miamidade.gov>
 <571BEE09-8994-4FB6-B67C-8E2D909CFC09@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463597@S0020287.miamidade.gov>
 <alpine.BSF.2.00.1705170654410.49807@pedal.dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F4636D9@S0020287.miamidade.gov>
Message-ID: <CA+8X3fVuO7q9EMUYRXM_-zaTOE0gq5LnWLG=mY-965W11b91ew@mail.gmail.com>

Hi Omar,
You may want to try subsetting your data and then passing each morsel
to be plotted as a violin plot, either as separate calls to ggplot or
directly to a violin plotting routine.

vioplot (vioplot)
violin_plot (plotrix)

Jim

On Thu, May 18, 2017 at 5:59 AM, Abdelrahman, Omar (RER)
<Omar.Abdelrahman at miamidade.gov> wrote:
> Thank you, curly quotes got me! I was able to subset the data and produce the violin plot. Now, is there a way to generate multiple plots separately (no facets)? With so many levels of each variable, I am trying to avoid doing it iteratively. Neither ggplot2 books nor web searches have yielded anything (so far).
> Also I want a violin for each year within Geo. I did try to specify year with the following:
> ggplot () +
> facet_grid (PARAMETER ~Wshed~year, scales="free_y") +
> geom_violin (data=subdf, aes(x=Geo, y=RESULT, fill=Geo))
>
> which yielded
> -Error in combine_vars(data, params$plot_env, cols, drop = params$drop) :
>   At least one layer must contain all variables used for faceting
>
> Also tried:
> ggplot () +
> facet_grid (PARAMETER ~Wshed, scales="free_y") +
> geom_violin (data=subdf, aes(x=Geo~year, y=RESULT, fill=Geo))
>
> Do I need to specify "year(date)"; I loaded lubridate?
>
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Wednesday, May 17, 2017 10:05 AM
> To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>
> Cc: R-help <r-help at r-project.org>
> Subject: RE: [R] violin plot help
>
> Here is an example that works... a reproducible example always includes code AND enough sample data to exercise the code:
>
> ########
> dta <- read.table( text=
> "STATION        Geo     Wshed   DATE            PARAMETER                 RESULT
> BB36            Bay     C-100   1/10/2013       'Phosphorus, Total (TP)'  0.004
> BB36            Bay     C-100   1/10/2013       'Chlorophyll-A'           0.2
> BB52            Bay     C-100   1/10/2013       'Phosphorus, Total (TP)'  0.003
> BB52            Bay     C-100   1/10/2013       'Chlorophyll-A'           0.39
> CD01A           Mouth   C-100   1/10/2013       'Phosphorus, Total (TP)'  0.017
> CD01A           Mouth   C-100   1/10/2013       'Chlorophyll-A'           0.64
> CD02            East    C-100   1/10/2013       'Phosphorus, Total (TP)'  0.01
> CD05            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.005
> CD06            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.01
> CD09            Central C-100   1/10/2013       'Phosphorus, Total (TP)'  0.007
> BB36            Bay     C-100   2/7/2013        'Chlorophyll-A'           0.18
> BB36            Bay     C-100   2/7/2013        'Phosphorus, Total (TP)'  0.002
> BB52            Bay     C-100   2/7/2013        'Phosphorus, Total (TP)'  0.002
> BB52            Bay     C-100   2/7/2013        'Chlorophyll-A'           0.31
> CD01A           Mouth   C-100   2/7/2013        'Phosphorus, Total (TP)'  0.004
> CD01A           Mouth   C-100   2/7/2013        'Chlorophyll-A'           0.4
> CD02            East    C-100   2/7/2013        'Phosphorus, Total (TP)'  0.011
> CD05            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.007
> CD06            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.015
> CD09            Central C-100   2/7/2013        'Phosphorus, Total (TP)'  0.008
> CD01A           Mouth   C-100   3/7/2013        'Phosphorus, Total (TP)'  0.007
> ", header=TRUE)
> # prints result to console without assigning it to a new variable subset( dta, Geo == "East" ) ########
>
> Note that [1] and [2] suggest the use of the dput function to help create R code that creates the object just as you have it before the troublesome line of code:
>
> ########
> dta <- structure(list(STATION = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 5L, 6L, 7L, 1L, 1L, 2L, 2L, 3L, 3L, 4L, 5L, 6L, 7L, 3L) , .Label = c("BB36", "BB52", "CD01A", "CD02", "CD05", "CD06", "CD09")
>       , class = "factor"),
>      Geo = structure(c(1L, 1L, 1L, 1L, 4L, 4L, 3L, 2L, 2L, 2L,
>      1L, 1L, 1L, 1L, 4L, 4L, 3L, 2L, 2L, 2L, 4L), .Label = c("Bay",
>      "Central", "East", "Mouth"), class = "factor"),
>      Wshed = structure(c(1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>      1L, 1L, 1L, 1L, 1L), .Label = "C-100", class = "factor"),
>      DATE = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L), .Label = c("1/10/2013",
>      "2/7/2013", "3/7/2013"), class = "factor"),
>      PARAMETER = structure(c(2L,
>      1L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L,
>      2L, 2L, 2L, 2L, 2L), .Label = c("Chlorophyll-A",
>      "Phosphorus, Total (TP)"
>      ), class = "factor"), RESULT = c(0.004, 0.2, 0.003, 0.39,
>      0.017, 0.64, 0.01, 0.005, 0.01, 0.007, 0.18, 0.002, 0.002,
>      0.31, 0.004, 0.4, 0.011, 0.007, 0.015, 0.008, 0.007)),
>      .Names = c("STATION", "Geo", "Wshed", "DATE", "PARAMETER", "RESULT"),
>      class = "data.frame", row.names = c(NA, -21L)) subset( dta, Geo == "East" ) ########
>
> Note that the "structure" function created by dput is mostly insensitive to extra newlines, except inside quotes.
>
> So the above examples work for me. What doesn't work for you?
>
> One thought: Are you editing your R code with a plain text editor or are you editing it with a word processor that might replace your plain quotes with curly quotes?
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> On Wed, 17 May 2017, Abdelrahman, Omar (RER) wrote:
>
>> Thanks again
>> RE: "so all the more reason to give us an example that we can run to trigger the same error." Are you asking for an example of the data? Below is a "small" example, but with so many levels of the different variables I am not sure it can be useful.
>>
>> STATION       Geo     Wshed   DATE            PARAMETER               RESULT
>> BB36          Bay     C-100   1/10/2013       Phosphorus, Total (TP)  0.004
>> BB36          Bay     C-100   1/10/2013       Chlorophyll-A           0.2
>> BB52          Bay     C-100   1/10/2013       Phosphorus, Total (TP)  0.003
>> BB52          Bay     C-100   1/10/2013       Chlorophyll-A           0.39
>> CD01A         Mouth   C-100   1/10/2013       Phosphorus, Total (TP)  0.017
>> CD01A         Mouth   C-100   1/10/2013       Chlorophyll-A   0.64
>> CD02          East    C-100   1/10/2013       Phosphorus, Total (TP)  0.01
>> CD05          Central C-100   1/10/2013       Phosphorus, Total (TP)  0.005
>> CD06          Central C-100   1/10/2013       Phosphorus, Total (TP)  0.01
>> CD09          Central C-100   1/10/2013       Phosphorus, Total (TP)  0.007
>> BB36          Bay     C-100   2/7/2013        Chlorophyll-A           0.18
>> BB36          Bay     C-100   2/7/2013        Phosphorus, Total (TP)  0.002
>> BB52          Bay     C-100   2/7/2013        Phosphorus, Total (TP)  0.002
>> BB52          Bay     C-100   2/7/2013        Chlorophyll-A           0.31
>> CD01A         Mouth   C-100   2/7/2013        Phosphorus, Total (TP)  0.004
>> CD01A         Mouth   C-100   2/7/2013        Chlorophyll-A           0.4
>> CD02          East    C-100   2/7/2013        Phosphorus, Total (TP)  0.011
>> CD05          Central C-100   2/7/2013        Phosphorus, Total (TP)  0.007
>> CD06          Central C-100   2/7/2013        Phosphorus, Total (TP)  0.015
>> CD09          Central C-100   2/7/2013        Phosphorus, Total (TP)  0.008
>> CD01A         Mouth   C-100   3/7/2013        Phosphorus, Total (TP)  0.007
>>
>> Hope this is not too much
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, May 16, 2017 12:30 PM
>> To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>; R-help
>> <r-help at r-project.org>
>> Subject: RE: [R] violin plot help
>>
>> Please use reply-all or equivalent to keep the list in the conversation. I don't do private online consultation.
>>
>> Your example suggested you did not know the difference, but your error suggests a completely different expression triggered the error, so all the more reason to give us an example that we can run to trigger the same error.
>>
>> Items B and C are recommendations to read the help pages for those syntax elements. You should already have read enough of an introduction to R to have encountered the use of the question mark to bring up the help pages. If not, please do.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 16, 2017 9:00:09 AM PDT, "Abdelrahman, Omar (RER)" <Omar.Abdelrahman at miamidade.gov> wrote:
>>> Thanks Jeff. I will send plain text from now on. I am not sure what B
>>> or C mean; is there a guide that I can reference? I know the
>>> difference between "=" and "==" , they work the same in Stata and SAS.
>>>
>>> Omar
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Tuesday, May 16, 2017 11:43 AM
>>> To: r-help at r-project.org; Abdelrahman, Omar (RER)
>>> <Omar.Abdelrahman at miamidade.gov>; 'r-help at r-project.org'
>>> <r-help at r-project.org>
>>> Subject: Re: [R] violin plot help
>>>
>>> Read
>>> A) the Posting Guide (re plain text only... your emails may be
>>> damaged by the mailing list if you send html-formatted email... only
>>> you can solve this by figuring out how to use your email software)
>>> B) Help on assignment (?`=`)
>>> C) Help on logical tests (?`==`)
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On May 16, 2017 7:06:40 AM PDT, "Abdelrahman, Omar (RER)"
>>> <Omar.Abdelrahman at miamidade.gov> wrote:
>>>> I am trying to produce multiple violin plots by 3 categorical
>>>> variables, each violin representing 1 year worth of data. The
>>> variables
>>>> are:
>>>>
>>>> Watershed (7 levels: county canals)
>>>>
>>>> Geography (5 levels: west; central; east; mouth; bay)
>>>>
>>>> Parameter (8 levels: water quality chemical parameters)
>>>>
>>>> Year (25 levels: 1992-2017)
>>>>
>>>> I want to produce 1 plot for each Parameter-Watershed subdivided
>>>> into Geography with a violin for each year. I used facets with the
>>> following
>>>> code (not by year):
>>>>
>>>> ggplot () +
>>>>
>>>> facet_grid (PARAMETER ~Wshed, scales="free_y") +
>>>>
>>>> geom_violin (data=merged, aes(x=Geo, y=RESULT))
>>>>
>>>>
>>>>
>>>> I do not want facets, they crowd the information so it is unreadable.
>>> I
>>>> just started with R this week and have not been able to figure out
>>>> the
>>>
>>>> foreach protocol, or any other loop protocol. I tried to subset the
>>>> data to do it iteratively with the following code:
>>>>
>>>>
>>>>
>>>> subdf<-subset (merged, Wshed = "AC")
>>>>
>>>>
>>>>
>>>> but got an error: Error: unexpected input in "subdf=subset (merged,
>>>> Wshed == ""
>>>>
>>>> Any help would be greatly appreciated.
>>>>
>>>> Thanks,
>>>>
>>>> Omar Abdelrahman, Biologist II
>>>> Miami-Dade County, Department of Regulatory and Economic Resources
>>>> Division of Environmental Resources Management (DERM) Overtown
>>>> Transit
>>>
>>>> Village
>>>> 701 NW 1st Court, 5th Floor
>>>> Miami, FL 33136-3912
>>>> (305) 372-6872
>>>> abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
>>>> www.miamidade.gov/environment<http://www.miamidade.gov/environment/>
>>>>
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu May 18 00:27:38 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 17 May 2017 15:27:38 -0700
Subject: [R] Offset - usersplits function package RPART
In-Reply-To: <0D65EFCC-E1B0-4AE1-89B5-B75059938D28@outlook.com>
References: <0D65EFCC-E1B0-4AE1-89B5-B75059938D28@outlook.com>
Message-ID: <6A24E5C1-138A-4592-9E60-F9966C21D002@comcast.net>


> On May 17, 2017, at 6:43 AM, ?? ???? <panjj1125 at outlook.com> wrote:
> 
> I have written a user written splitting function recently, but I do not know how to use my splitting criteria to predict the test data. If I use the function ?predict?, there will return an error message, please give me some helpful advice.

`predict`-methods are functions written to deliver results from a particular class. Look at:

 methods(predict)

Sometimes there is a func.default method for a generic function named `func`, but rather predictably I would say, there is no such default in the case of `predict`.

-- 
David Winsemius
Alameda, CA, USA


From pifferdavide at gmail.com  Thu May 18 12:19:21 2017
From: pifferdavide at gmail.com (Davide Piffer)
Date: Thu, 18 May 2017 13:19:21 +0300
Subject: [R] converting each column of a data frame into a matrix with n
	rows
In-Reply-To: <94D94C3A-AD28-49B4-B381-CB4C1F46D748@comcast.net>
References: <CAOq2dy7=rMemyBuLbitf1foqsrnXvYWUEQVnD7Qy9t6t5Pw1QQ@mail.gmail.com>
 <829fc4d7262e4caa9b32bdabbad9b17b@exch-2p-mbx-w2.ads.tamu.edu>
 <CAOq2dy47AnF=Oc_7L-6HR7DL3PK8RZe5_-1c3E3=Ar0NC8EGHw@mail.gmail.com>
 <94D94C3A-AD28-49B4-B381-CB4C1F46D748@comcast.net>
Message-ID: <CAOq2dy5kaASWRtiUCcp=AwxmkHwJ6=-5tcZzLdq9J83oxccjNg@mail.gmail.com>

Thanks David! It worked!

On 17 May 2017 at 23:39, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On May 17, 2017, at 1:01 PM, Davide Piffer <pifferdavide at gmail.com> wrote:
>>
>> Thanks! This gets closer to the solution but a small problem remains.
>> I get 2 rows and only one column, whereas I need a 2x2 matrix (like a
>> contingency table for Fisher's exact test).Also another issue is it
>> repeats the first number of the column, instead of using all 4.
>> For example, first vector of df is=c(564,3825,125, 377
>>
>> I get:
>>
>>         [,1]
>> [1,] 564.3112
>> [2,] 564.3112
>>
>>
>> But I should get
>>
>>       [,1]   [.2]
>> [1,]564   125
>> [2,] 3825  377
>
> ( y <- data.frame(matrix(1:40, 4, 10)) )
> ( y.mat <- lapply(y, matrix, nrow=2))
>
>> head(y.mat, 3)
> $X1
>      [,1] [,2]
> [1,]    1    3
> [2,]    2    4
>
> $X2
>      [,1] [,2]
> [1,]    5    7
> [2,]    6    8
>
> $X3
>      [,1] [,2]
> [1,]    9   11
> [2,]   10   12
>
>>
>> On 17 May 2017 at 22:35, David L Carlson <dcarlson at tamu.edu> wrote:
>>> Not really enough info here since you don't specify much about the data frame or how the results should be provided, but maybe something like this:
>>>
>>> y <- data.frame(matrix(1:100, 10, 10))
>>> y.mat <- lapply(y, matrix, nrow=2)
>>> str(y.mat)
>>> List of 10
>>> $ X1 : int [1:2, 1:5] 1 2 3 4 5 6 7 8 9 10
>>> $ X2 : int [1:2, 1:5] 11 12 13 14 15 16 17 18 19 20
>>> $ X3 : int [1:2, 1:5] 21 22 23 24 25 26 27 28 29 30
>>> $ X4 : int [1:2, 1:5] 31 32 33 34 35 36 37 38 39 40
>>> $ X5 : int [1:2, 1:5] 41 42 43 44 45 46 47 48 49 50
>>> $ X6 : int [1:2, 1:5] 51 52 53 54 55 56 57 58 59 60
>>> $ X7 : int [1:2, 1:5] 61 62 63 64 65 66 67 68 69 70
>>> $ X8 : int [1:2, 1:5] 71 72 73 74 75 76 77 78 79 80
>>> $ X9 : int [1:2, 1:5] 81 82 83 84 85 86 87 88 89 90
>>> $ X10: int [1:2, 1:5] 91 92 93 94 95 96 97 98 99 100
>>>
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Davide Piffer
>>> Sent: Wednesday, May 17, 2017 2:18 PM
>>> To: r-help at r-project.org
>>> Subject: [R] converting each column of a data frame into a matrix with n rows
>>>
>>> I need to convert each vector of a dataframe into a matrix with 2 rows
>>> and 2 columns (i.e. contingency table).
>>> Note I don't want to convert the entire df into a matrix! I want to
>>> apply a function that converts each 4 elements vector of a df into a 2
>>> x 2 matrix.
>>>
>>> I wrote something like this, but it will not work:
>>>
>>> f_matrix=function(x){ matrix (x)
>>>  nrow=2}
>>> matrix_y=apply(y,2,function(x) f_matrix (x))
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From jrkrideau at yahoo.ca  Thu May 18 11:55:39 2017
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 18 May 2017 09:55:39 +0000 (UTC)
Subject: [R] Help on reducing multiple loops
In-Reply-To: <CADiURWtphCtvNT09cx_7yy6EwGqs0Tp+HoMaajyV2Lm4_0yQdA@mail.gmail.com>
References: <CADiURWtphCtvNT09cx_7yy6EwGqs0Tp+HoMaajyV2Lm4_0yQdA@mail.gmail.com>
Message-ID: <114742165.533352.1495101339698@mail.yahoo.com>

Data? It's difficult to do anything without some test data.See How to make a great R reproducible example? or http://adv-r.had.co.nz/Reproducibility.html 
?with particular reference to the use of dput() as the best way to provide sample data.

  
|  
|   
|   
|   |    |

   |

  |
|  
|   |  
How to make a great R reproducible example?
 When discussing performance with colleagues, teaching, sending a bug report or searching for guidance on mailing...  |   |

  |

  |

 
 

    On Wednesday, May 17, 2017 6:10 PM, Sumanta Basak <sumanta24 at gmail.com> wrote:
 

 Hi All,

I've a data-set on product sub-product matrix on which I'm doing multiple
calculation, but unfortunately using nested loops, the programme is taking
long time to execute. Can anyone help me how to get rid of the following
jungle? Any direction would be helpful.

GA <- "India"
verticle <- "Prod1"

prod_data <- readRDS(paste0("/Prod_ladder_",GA,"_",verticle,".rds"))
setDF(prod_data)

Final_data <-
subset(prod_data[,c("P_KEY","Active_Prod_Id","Active_Prod_Nm")],!duplicated(prod_data[,c("P_KEY","Active_Prod_Id")]))

proximity_prod_mapping <- readRDS("Proximity_prod_mapping.rds")
dst_prod <- subset(prod_data[,c("P_KEY")],!duplicated(prod_data$P_KEY))


output_data <- c()
data_merge_final <- c()

system.time({
? for(i in 1 : length(dst_prod)){

? ? prod_data <- subset(prod_data,prod_data$P_KEY == dst_prod[i]) #
Subsetting data at prod level
? ? dst_prod <-
subset(prod_data[,c("Active_Prod_Id")],!duplicated(prod_data$Active_Prod_Id))
# Finding distinct prods of active prodloyee

? ? for(j in 1 : length(dst_prod)){
? ? ? # Subsetting data at prod level for active prod
? ? ? # Fetiching data for Anchor prod
? ? ? prod_data1 <-
subset(prod_data[,c("P_KEY","Active_Prod_Id","Active_Prod_Nm","Start_Date_1","End_Date_1")],prod_data$Active_Prod_Id
== dst_prod[j])
? ? ? prod_data1$Anchor_prod <- 1
? ? ? anc_max_End_Date_1 <- as.Date(max(prod_data1$End_Date_1),origin =
"1970-01-01")
? ? ? anc_prod_count <- sum(prod_data1$Anchor_prod)

? ? ? # Fetiching data for Proximate prod
? ? ? prox_prod_data <-
subset(proximity_prod_mapping[,c("Proximate_prod_ID")],proximity_prod_mapping$Anchor_prod_ID
== dst_prod[j])
? ? ? prod_data2 <-
subset(prod_data[,c("P_KEY","Active_Prod_Id","Active_Prod_Nm","Start_Date_1","End_Date_1")],prod_data$Active_Prod_Id
%in% c(prox_prod_data))
? ? ? prox_sill_count <- 0
? ? ? if(nrow(prod_data2) > 0){
? ? ? ? prod_data2$Proximity_prod <- 1
? ? ? ? prox_max_End_Date_1 <- as.Date(max(prod_data2$End_Date_1),origin =
"1970-01-01")
? ? ? ? prox_sill_count <- sum(prod_data2$Proximity_prod)
? ? ? }
? ? ? # library(plyr)
? ? ? prod_data <-rbind.fill(prod_data1,prod_data2)
? ? ? prod_data$exclude <- 0
? ? ? prod_data$Anchor_Active_Prod_Id <- dst_prod[j]

? ? ? prod_data$Start_Date_1 <- as.Date(prod_data$Start_Date_1,origin =
"1970-01-01")
? ? ? prod_data$End_Date_1 <- as.Date(prod_data$End_Date_1,origin =
"1970-01-01")

? ? ? if(prox_sill_count > 0){
? ? ? ? if(nrow(prod_data) > 1){
? ? ? ? ? # Trimming end date of proximity prods where end data of
proximity prod is greater that Anchor prod
? ? ? ? ? if((prox_max_End_Date_1 - anc_max_End_Date_1) > 0){
? ? ? ? ? ? prod_data$End_Date_1 <- ifelse(prod_data$Proximity_prod == 1 &
(prod_data$End_Date_1 - anc_max_End_Date_1) > 0,
anc_max_End_Date_1,prod_data$End_Date_1)
? ? ? ? ? ? prod_data$End_Date_1 <- as.Date(prod_data$End_Date_1,origin =
"1970-01-01")
? ? ? ? ? }
? ? ? ? ? prod_data$exclude <- ifelse(prod_data$Proximity_prod == 1 &
(as.Date(prod_data$Start_Date_1,origin = "1970-01-01") -
anc_max_End_Date_1) > 0,1,0)
? ? ? ? ? prod_data <- subset(prod_data,prod_data$exclude == 0)

? ? ? ? ? prod_data <-
arrange(prod_data,prod_data$Anchor_prod,desc(prod_data$End_Date_1),prod_data$Start_Date_1)

? ? ? ? ? prod_data$Anchor_prod <- ifelse(is.na
(prod_data$Anchor_prod),0,prod_data$Anchor_prod)
? ? ? ? ? prod_data$Proximity_prod <- ifelse(is.na
(prod_data$Proximity_prod),0,prod_data$Proximity_prod)
? ? ? ? ? prod_data$new_rec <- 0

? ? ? ? ? tot_loop <- nrow(prod_data)
? ? ? ? ? k=1
? ? ? ? ? # Looping to map start date and end date of each row with other
rows
? ? ? ? ? while(k <= tot_loop){
? ? ? ? ? ? excl_flag <- prod_data[k,c("exclude")]
? ? ? ? ? ? if(excl_flag == 0){
? ? ? ? ? ? ? st_dt1 <- as.Date(prod_data[k,c("Start_Date_1")])
? ? ? ? ? ? ? end_dt1 <- as.Date(prod_data[k,c("End_Date_1")])
? ? ? ? ? ? ? prod_flag1 <- prod_data[k,c("Anchor_prod")]

? ? ? ? ? ? ? if(k != nrow(prod_data)){
? ? ? ? ? ? ? ? tot_row <- nrow(prod_data)

? ? ? ? ? ? ? ? for(m in 1 : (tot_row -k)){
? ? ? ? ? ? ? ? ? l = k+m
? ? ? ? ? ? ? ? ? if(l != k){
? ? ? ? ? ? ? ? ? ? st_dt2 <- as.Date(prod_data[l,c("Start_Date_1")])
? ? ? ? ? ? ? ? ? ? end_dt2 <- as.Date(prod_data[l,c("End_Date_1")])
? ? ? ? ? ? ? ? ? ? prod_flag2 <- prod_data[l,c("Anchor_prod")]

? ? ? ? ? ? ? ? ? ? flag_excl <- prod_data[l,c("exclude")]
? ? ? ? ? ? ? ? ? ? if(flag_excl ==0){
? ? ? ? ? ? ? ? ? ? ? rec_check <- prod_data[l,c("new_rec")]
? ? ? ? ? ? ? ? ? ? ? # if(rec_check == 0){
? ? ? ? ? ? ? ? ? ? ? prod_data$Start_date2 <- NA
? ? ? ? ? ? ? ? ? ? ? prod_data$End_date2 <- NA

? ? ? ? ? ? ? ? ? ? ? new_start_date <- as.Date(ifelse(prod_flag1 == 1 &
prod_flag2 == 1,NA,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ifelse(prod_flag1 ==
1 & prod_flag2 == 0 & end_dt2 > end_dt1 & st_dt2 < end_dt1,end_dt1,

ifelse(prod_flag1 == 0 & prod_flag2 == 1 & end_dt1 > end_dt2 & st_dt1 <
end_dt2,end_dt2,NA))),origin = "1970-01-01")
? ? ? ? ? ? ? ? ? ? ? message(paste0("new_start_date = ",new_start_date))
? ? ? ? ? ? ? ? ? ? ? new_start_date <- as.Date(new_start_date,origin =
"1970-01-01")
? ? ? ? ? ? ? ? ? ? ? message(paste0("new_start_date = ",new_start_date))
? ? ? ? ? ? ? ? ? ? ? new_end_date <- as.Date(ifelse(prod_flag1 == 1 &
prod_flag2 == 1,NA,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ifelse(prod_flag1 == 1
& prod_flag2 == 0 & end_dt2 > end_dt1 & st_dt2 < end_dt1,end_dt2,

ifelse(prod_flag1 == 0 & prod_flag2 == 1 & end_dt1 > end_dt2 & st_dt1 <
end_dt2,end_dt1,NA))),origin = "1970-01-01")
? ? ? ? ? ? ? ? ? ? ? message(paste0("new_end_date = ",new_end_date))
? ? ? ? ? ? ? ? ? ? ? new_end_date <- as.Date(new_end_date,origin =
"1970-01-01")
? ? ? ? ? ? ? ? ? ? ? message(paste0("new_end_date = ",new_end_date))
? ? ? ? ? ? ? ? ? ? ? prod_data[l,c("Start_date2")] <-
as.Date(new_start_date,origin = "1970-01-01")
? ? ? ? ? ? ? ? ? ? ? prod_data[l,c("End_date2")] <-
as.Date(new_end_date,origin = "1970-01-01")

? ? ? ? ? ? ? ? ? ? ? tmp_data <- subset(prod_data,!is.na
(prod_data$Start_date2))
? ? ? ? ? ? ? ? ? ? ? tmp_data$Start_Date_1 <-
as.Date(tmp_data$Start_date2,origin = "1970-01-01")
? ? ? ? ? ? ? ? ? ? ? tmp_data$End_Date_1 <-
as.Date(tmp_data$End_date2,origin = "1970-01-01")
? ? ? ? ? ? ? ? ? ? ? if(nrow(tmp_data)){
? ? ? ? ? ? ? ? ? ? ? ? tmp_data$new_rec <- 1
? ? ? ? ? ? ? ? ? ? ? ? prod_data[l,c("End_Date_1")] <-
as.Date(end_dt1,origin = "1970-01-01")
? ? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? ? prod_data <- rbind(prod_data,tmp_data)
? ? ? ? ? ? ? ? ? ? ? tot_row <- tot_row + nrow(tmp_data)
? ? ? ? ? ? ? ? ? ? ? tot_loop <- tot_loop + nrow(tmp_data)
? ? ? ? ? ? ? ? ? ? ? prod_data$Start_date2 <- NULL
? ? ? ? ? ? ? ? ? ? ? prod_data$End_date2 <- NULL
? ? ? ? ? ? ? ? ? ? ? # }
? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? # Condition to identify true subset

? ? ? ? ? ? ? ? ? ? # overlap <- ifelse((st_dt1 >= st_dt2 & st_dt1 <=
end_dt2) & (end_dt1 >= st_dt2 & end_dt1 <= end_dt2),1,
? ? ? ? ? ? ? ? ? ? #? ? ? ? ? ? ifelse((st_dt2 >= st_dt1 & st_dt2 <=
end_dt1) & (end_dt2 >= st_dt1 & end_dt2 <= end_dt1),1,0))



? ? ? ? ? ? ? ? ? ? if((end_dt1 - st_dt2) >= 0){
? ? ? ? ? ? ? ? ? ? ? if((end_dt2 - st_dt1) >= 0){
? ? ? ? ? ? ? ? ? ? ? ? if((st_dt2 - st_dt1) >=0){
? ? ? ? ? ? ? ? ? ? ? ? ? prod_data[k,c("exclude")] <- ifelse(prod_flag1 ==
1 & prod_flag2 == 1,9999, #if Anchor prods have overlapping

 ifelse(prod_flag1 == 1 & prod_flag2 == 0,0,

ifelse(prod_flag1 == 0 & prod_flag2 == 1,1,

 ifelse(prod_flag1 == 0 & prod_flag2 == 0,0,1))))
? ? ? ? ? ? ? ? ? ? ? ? ? prod_data[l,c("exclude")] <- ifelse(prod_flag1 ==
1 & prod_flag2 == 1,9999,

 ifelse(prod_flag1 == 0 & prod_flag2 == 1,0,

ifelse(prod_flag1 == 1 & prod_flag2 == 0,1,

 ifelse(prod_flag1 == 0 & prod_flag2 == 0,1,0))))
? ? ? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? # Condition to trim the dates as to make dates in each
observation mutually exclusive to exch other
? ? ? ? ? ? ? ? ? ? flag_excl <- prod_data[l,c("exclude")]
? ? ? ? ? ? ? ? ? ? if(flag_excl == 0){
? ? ? ? ? ? ? ? ? ? ? if(end_dt1 > st_dt2){
? ? ? ? ? ? ? ? ? ? ? ? if(st_dt1 >= st_dt2){
? ? ? ? ? ? ? ? ? ? ? ? ? new_date <- ifelse(end_dt2 >
st_dt1,as.Date(st_dt1,origin = "1970-01-01"),as.Date(end_dt2,origin =
"1970-01-01"))
? ? ? ? ? ? ? ? ? ? ? ? ? new_date <- as.Date(new_date,origin =
"1970-01-01")
? ? ? ? ? ? ? ? ? ? ? ? ? old_date <-
as.Date(prod_data[l,c("End_Date_1")],origin = "1970-01-01")
? ? ? ? ? ? ? ? ? ? ? ? ? old_date <- as.Date(old_date,origin =
"1970-01-01")

? ? ? ? ? ? ? ? ? ? ? ? ? # prod_data[j,c("End_Date_1")] <-
ifelse(prod_flag1 == 1 & prod_flag2 == 1,as.Date(old_date,origin =
"1970-01-01"),
? ? ? ? ? ? ? ? ? ? ? ? ? #
ifelse(prod_flag1 == 0 & prod_flag2 == 1,as.date(old_date, origin =
"1970-01-01"),as.Date(new_date,origin = "1970-01-01")))

? ? ? ? ? ? ? ? ? ? ? ? ? prod_data[l,c("End_Date_1")] <-
as.Date(ifelse(prod_flag1 == 1 & prod_flag2 == 1,old_date,ifelse(prod_flag1
== 0 & prod_flag2 == 1,old_date,new_date)),origin = "1970-01-01")

? ? ? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? }

? ? ? ? ? ? ? }
? ? ? ? ? ? }
? ? ? ? ? ? k=k+1
? ? ? ? ? }
? ? ? ? }
? ? ? }
? ? ? # excluding non required observations
? ? ? prod_data <- subset(prod_data,prod_data$exclude == 0)

? ? ? prod_data$multiply_factor <- ifelse(prod_data$Anchor_prod == 1,1,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ifelse(prod_data$Proximity_prod
== 1,0.5,9999))

? ? ? prod_data$recency_in_months <- (as.Date("2017-01-31") -
prod_data$End_Date_1)/30

? ? ? prod_data$recency_factor <- ifelse(prod_data$recency_in_months <=
12,1,

ifelse(prod_data$recency_in_months > 12 & prod_data$recency_in_months <=
24,0.9,

 ifelse(prod_data$recency_in_months > 24 & prod_data$recency_in_months <=
36,0.8,

ifelse(prod_data$recency_in_months > 36 & prod_data$recency_in_months <=
48,0.7,

 ifelse(prod_data$recency_in_months > 48,0.6,9999)))))

? ? ? prod_data$duration_in_months <- (prod_data$End_Date_1 -
prod_data$Start_Date_1)/30

? ? ? prod_data$weight <-
prod_data$duration_in_months*prod_data$multiply_factor*prod_data$recency_factor

? ? ? prod <- prod_data[1,c("Anchor_Active_Prod_Id")]
? ? ? if(nrow(prod_data) > 1){
? ? ? ? data_merge <-with(prod_data,aggregate(weight ~ P_KEY, FUN =
function(x) c(Proficiency_Score = sum(x))))
? ? ? }else{
? ? ? ? data_merge <- prod_data[1,c("P_KEY","weight")]
? ? ? }


? ? ? data_merge$prod <- prod_data[1,c("Anchor_Active_Prod_Id")]

? ? ? data_merge_final <- rbind(data_merge_final,data_merge)


? ? ? # Recency and Duration calculation goes here and final score will be
added in final data
? ? ? output_data <- rbind.fill(output_data,prod_data)

? ? }
? }


? Final_data <- merge(Final_data,data_merge_final,by.x= c("P_KEY",
"Active_Prod_Id"),by.y = c("P_KEY", "prod"),all.x=TRUE)

? names(Final_data)[names(Final_data) == "weight"] <- "Proficiency_Score"

? emerging_prod_mapping <- readRDS("5.Emerging_prod_Lookup.rds")

? emerging_prod_list <-
subset(emerging_prod_mapping[,c("prod_ID")],!duplicated(emerging_prod_mapping$prod_ID))


? Final_data$Emerging_Traditional <- ifelse(Final_data$Active_Prod_Id %in%
c(emerging_prod_list),"Emerging","Traditional")

? Final_data$Final_Proficiency <- ifelse(Final_data$Emerging_Traditional ==
"Traditional",

 ifelse(Final_data$Proficiency_Score < 12, "P0",

ifelse(Final_data$Proficiency_Score >=12 & Final_data$Proficiency_Score <
24,"P1",

 ifelse(Final_data$Proficiency_Score >=24 & Final_data$Proficiency_Score <
48,"P2",

ifelse(Final_data$Proficiency_Score >=48 & Final_data$Proficiency_Score <
60,"P3",

 ifelse(Final_data$Proficiency_Score >=60,"P4",NA))))),

 ifelse(Final_data$Emerging_Traditional == "Emerging",

ifelse(Final_data$Proficiency_Score < 6, "P0",

 ifelse(Final_data$Proficiency_Score >=6 & Final_data$Proficiency_Score <
12,"P1",

ifelse(Final_data$Proficiency_Score >=12 & Final_data$Proficiency_Score <
24,"P2",

 ifelse(Final_data$Proficiency_Score >=24 & Final_data$Proficiency_Score <
30,"P3",

ifelse(Final_data$Proficiency_Score >=30,"P4",NA))))),NA))

? tst <- prod_data[,c("P_KEY", "Id")]
? tst <- subset(tst,!duplicated(tst))

? Final_data <-
merge(Final_data,tst[,c("P_KEY","Id")],by="P_KEY",all.x=TRUE)
})

*SUMANTA BASAK*

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From Omar.Abdelrahman at miamidade.gov  Thu May 18 14:31:03 2017
From: Omar.Abdelrahman at miamidade.gov (Abdelrahman, Omar (RER))
Date: Thu, 18 May 2017 12:31:03 +0000
Subject: [R] violin plot help
In-Reply-To: <37EAAC2D-8A13-45C2-BEC4-73981597CF0C@dcn.davis.ca.us>
References: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
 <D5E780EE-3EAF-49C6-ACF6-5C2918A20E1A@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463436@S0020287.miamidade.gov>
 <571BEE09-8994-4FB6-B67C-8E2D909CFC09@dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F463597@S0020287.miamidade.gov>
 <alpine.BSF.2.00.1705170654410.49807@pedal.dcn.davis.ca.us>
 <161FBD7CDADFC2489F2D5A7441BEBFBF8F4636D9@S0020287.miamidade.gov>
 <37EAAC2D-8A13-45C2-BEC4-73981597CF0C@dcn.davis.ca.us>
Message-ID: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4637AA@S0020287.miamidade.gov>

Many thanks Jeff! I knew it would require a loop approach, so I will now explore that with the code you suggested.

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Wednesday, May 17, 2017 5:19 PM
To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>; R-help <r-help at r-project.org>
Subject: RE: [R] violin plot help

Your request is outside of the scope of ggplot2. There are a variety of ways to achieve your ends, but they all involve loops of one sort or another... e.g.

wsheds <- unique( merged$Wshed )
for ( w in wsheds ) {
    print( ggplot( data=subset( merged, w == Wsheds ), ... ) ) }

I have become quite used to embedding my R code into rmarkdown files which allows me to mix multiple graphs, tables and text commentary in one place. RStudio makes this about as easy as it can be,  though support for that IDE is off topic here. 
--
Sent from my phone. Please excuse my brevity.

On May 17, 2017 12:59:36 PM PDT, "Abdelrahman, Omar (RER)" <Omar.Abdelrahman at miamidade.gov> wrote:
>Thank you, curly quotes got me! I was able to subset the data and 
>produce the violin plot. Now, is there a way to generate multiple plots 
>separately (no facets)? With so many levels of each variable, I am 
>trying to avoid doing it iteratively. Neither ggplot2 books nor web 
>searches have yielded anything (so far).
>Also I want a violin for each year within Geo. I did try to specify 
>year with the following:
>ggplot () +
>facet_grid (PARAMETER ~Wshed~year, scales="free_y") + geom_violin 
>(data=subdf, aes(x=Geo, y=RESULT, fill=Geo))
>
>which yielded
>-Error in combine_vars(data, params$plot_env, cols, drop = params$drop)
>: 
>  At least one layer must contain all variables used for faceting
>
>Also tried:
>ggplot () +
>facet_grid (PARAMETER ~Wshed, scales="free_y") + geom_violin 
>(data=subdf, aes(x=Geo~year, y=RESULT, fill=Geo))
>
>Do I need to specify "year(date)"; I loaded lubridate?
>
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>Sent: Wednesday, May 17, 2017 10:05 AM
>To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>
>Cc: R-help <r-help at r-project.org>
>Subject: RE: [R] violin plot help
>
>Here is an example that works... a reproducible example always includes 
>code AND enough sample data to exercise the code:
>
>########
>dta <- read.table( text=
>"STATION        Geo     Wshed   DATE            PARAMETER              
>  RESULT
>BB36            Bay     C-100   1/10/2013       'Phosphorus, Total
>(TP)'  0.004
>BB36            Bay     C-100   1/10/2013       'Chlorophyll-A'        
>  0.2
>BB52            Bay     C-100   1/10/2013       'Phosphorus, Total
>(TP)'  0.003
>BB52            Bay     C-100   1/10/2013       'Chlorophyll-A'        
>  0.39
>CD01A           Mouth   C-100   1/10/2013       'Phosphorus, Total
>(TP)'  0.017
>CD01A           Mouth   C-100   1/10/2013       'Chlorophyll-A'        
>  0.64
>CD02            East    C-100   1/10/2013       'Phosphorus, Total
>(TP)'  0.01
>CD05            Central C-100   1/10/2013       'Phosphorus, Total
>(TP)'  0.005
>CD06            Central C-100   1/10/2013       'Phosphorus, Total
>(TP)'  0.01
>CD09            Central C-100   1/10/2013       'Phosphorus, Total
>(TP)'  0.007
>BB36            Bay     C-100   2/7/2013        'Chlorophyll-A'        
>  0.18
>BB36            Bay     C-100   2/7/2013        'Phosphorus, Total
>(TP)'  0.002
>BB52            Bay     C-100   2/7/2013        'Phosphorus, Total
>(TP)'  0.002
>BB52            Bay     C-100   2/7/2013        'Chlorophyll-A'        
>  0.31
>CD01A           Mouth   C-100   2/7/2013        'Phosphorus, Total
>(TP)'  0.004
>CD01A           Mouth   C-100   2/7/2013        'Chlorophyll-A'        
>  0.4
>CD02            East    C-100   2/7/2013        'Phosphorus, Total
>(TP)'  0.011
>CD05            Central C-100   2/7/2013        'Phosphorus, Total
>(TP)'  0.007
>CD06            Central C-100   2/7/2013        'Phosphorus, Total
>(TP)'  0.015
>CD09            Central C-100   2/7/2013        'Phosphorus, Total
>(TP)'  0.008
>CD01A           Mouth   C-100   3/7/2013        'Phosphorus, Total
>(TP)'  0.007
>", header=TRUE)
># prints result to console without assigning it to a new variable 
>subset( dta, Geo == "East" ) ########
>
>Note that [1] and [2] suggest the use of the dput function to help 
>create R code that creates the object just as you have it before the 
>troublesome line of code:
>
>########
>dta <- structure(list(STATION = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 
>5L, 6L, 7L, 1L, 1L, 2L, 2L, 3L, 3L, 4L, 5L, 6L, 7L, 3L) , .Label = 
>c("BB36", "BB52", "CD01A", "CD02", "CD05", "CD06", "CD09")
>      , class = "factor"),
>     Geo = structure(c(1L, 1L, 1L, 1L, 4L, 4L, 3L, 2L, 2L, 2L,
>     1L, 1L, 1L, 1L, 4L, 4L, 3L, 2L, 2L, 2L, 4L), .Label = c("Bay",
>     "Central", "East", "Mouth"), class = "factor"),
>     Wshed = structure(c(1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L), .Label = "C-100", class = "factor"),
>     DATE = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>   2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L), .Label = c("1/10/2013",
>     "2/7/2013", "3/7/2013"), class = "factor"),
>     PARAMETER = structure(c(2L,
>     1L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L,
>     2L, 2L, 2L, 2L, 2L), .Label = c("Chlorophyll-A",
>     "Phosphorus, Total (TP)"
>     ), class = "factor"), RESULT = c(0.004, 0.2, 0.003, 0.39,
>     0.017, 0.64, 0.01, 0.005, 0.01, 0.007, 0.18, 0.002, 0.002,
>     0.31, 0.004, 0.4, 0.011, 0.007, 0.015, 0.008, 0.007)),
>  .Names = c("STATION", "Geo", "Wshed", "DATE", "PARAMETER", "RESULT"), 
>class = "data.frame", row.names = c(NA, -21L)) subset( dta, Geo == 
>"East" ) ########
>
>Note that the "structure" function created by dput is mostly 
>insensitive to extra newlines, except inside quotes.
>
>So the above examples work for me. What doesn't work for you?
>
>One thought: Are you editing your R code with a plain text editor or 
>are you editing it with a word processor that might replace your plain 
>quotes with curly quotes?
>
>[1]
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reprod
>ucible-example
>
>[2] http://adv-r.had.co.nz/Reproducibility.html
>
>On Wed, 17 May 2017, Abdelrahman, Omar (RER) wrote:
>
>> Thanks again
>> RE: "so all the more reason to give us an example that we can run to
>trigger the same error." Are you asking for an example of the data?
>Below is a "small" example, but with so many levels of the different 
>variables I am not sure it can be useful.
>>
>> STATION	Geo	Wshed	DATE		PARAMETER		RESULT
>> BB36		Bay	C-100	1/10/2013	Phosphorus, Total (TP)	0.004
>> BB36		Bay	C-100	1/10/2013	Chlorophyll-A		0.2
>> BB52		Bay	C-100	1/10/2013	Phosphorus, Total (TP)	0.003
>> BB52		Bay	C-100	1/10/2013	Chlorophyll-A		0.39
>> CD01A		Mouth	C-100	1/10/2013	Phosphorus, Total (TP)	0.017
>> CD01A		Mouth	C-100	1/10/2013	Chlorophyll-A	0.64
>> CD02		East	C-100	1/10/2013	Phosphorus, Total (TP)	0.01
>> CD05		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.005
>> CD06		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.01
>> CD09		Central	C-100	1/10/2013	Phosphorus, Total (TP)	0.007
>> BB36		Bay	C-100	2/7/2013	Chlorophyll-A		0.18
>> BB36		Bay	C-100	2/7/2013	Phosphorus, Total (TP)	0.002
>> BB52		Bay	C-100	2/7/2013	Phosphorus, Total (TP)	0.002
>> BB52		Bay	C-100	2/7/2013	Chlorophyll-A		0.31
>> CD01A		Mouth	C-100	2/7/2013	Phosphorus, Total (TP)	0.004
>> CD01A		Mouth	C-100	2/7/2013	Chlorophyll-A		0.4
>> CD02		East	C-100	2/7/2013	Phosphorus, Total (TP)	0.011
>> CD05		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.007
>> CD06		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.015
>> CD09		Central	C-100	2/7/2013	Phosphorus, Total (TP)	0.008
>> CD01A		Mouth	C-100	3/7/2013	Phosphorus, Total (TP)	0.007
>>
>> Hope this is not too much
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, May 16, 2017 12:30 PM
>> To: Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov>; R-help 
>> <r-help at r-project.org>
>> Subject: RE: [R] violin plot help
>>
>> Please use reply-all or equivalent to keep the list in the
>conversation. I don't do private online consultation.
>>
>> Your example suggested you did not know the difference, but your
>error suggests a completely different expression triggered the error, 
>so all the more reason to give us an example that we can run to trigger 
>the same error.
>>
>> Items B and C are recommendations to read the help pages for those
>syntax elements. You should already have read enough of an introduction 
>to R to have encountered the use of the question mark to bring up the 
>help pages. If not, please do.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 16, 2017 9:00:09 AM PDT, "Abdelrahman, Omar (RER)"
><Omar.Abdelrahman at miamidade.gov> wrote:
>>> Thanks Jeff. I will send plain text from now on. I am not sure what
>B
>>> or C mean; is there a guide that I can reference? I know the 
>>> difference between "=" and "==" , they work the same in Stata and
>SAS.
>>>
>>> Omar
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Tuesday, May 16, 2017 11:43 AM
>>> To: r-help at r-project.org; Abdelrahman, Omar (RER) 
>>> <Omar.Abdelrahman at miamidade.gov>; 'r-help at r-project.org'
>>> <r-help at r-project.org>
>>> Subject: Re: [R] violin plot help
>>>
>>> Read
>>> A) the Posting Guide (re plain text only... your emails may be 
>>> damaged by the mailing list if you send html-formatted email... only
>
>>> you can solve this by figuring out how to use your email software)
>>> B) Help on assignment (?`=`)
>>> C) Help on logical tests (?`==`)
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On May 16, 2017 7:06:40 AM PDT, "Abdelrahman, Omar (RER)"
>>> <Omar.Abdelrahman at miamidade.gov> wrote:
>>>> I am trying to produce multiple violin plots by 3 categorical 
>>>> variables, each violin representing 1 year worth of data. The
>>> variables
>>>> are:
>>>>
>>>> Watershed (7 levels: county canals)
>>>>
>>>> Geography (5 levels: west; central; east; mouth; bay)
>>>>
>>>> Parameter (8 levels: water quality chemical parameters)
>>>>
>>>> Year (25 levels: 1992-2017)
>>>>
>>>> I want to produce 1 plot for each Parameter-Watershed subdivided 
>>>> into Geography with a violin for each year. I used facets with the
>>> following
>>>> code (not by year):
>>>>
>>>> ggplot () +
>>>>
>>>> facet_grid (PARAMETER ~Wshed, scales="free_y") +
>>>>
>>>> geom_violin (data=merged, aes(x=Geo, y=RESULT))
>>>>
>>>>
>>>>
>>>> I do not want facets, they crowd the information so it is
>unreadable.
>>> I
>>>> just started with R this week and have not been able to figure out 
>>>> the
>>>
>>>> foreach protocol, or any other loop protocol. I tried to subset the
>
>>>> data to do it iteratively with the following code:
>>>>
>>>>
>>>>
>>>> subdf<-subset (merged, Wshed = "AC")
>>>>
>>>>
>>>>
>>>> but got an error: Error: unexpected input in "subdf=subset (merged,
>
>>>> Wshed == ""
>>>>
>>>> Any help would be greatly appreciated.
>>>>
>>>> Thanks,
>>>>
>>>> Omar Abdelrahman, Biologist II
>>>> Miami-Dade County, Department of Regulatory and Economic Resources 
>>>> Division of Environmental Resources Management (DERM) Overtown 
>>>> Transit
>>>
>>>> Village
>>>> 701 NW 1st Court, 5th Floor
>>>> Miami, FL 33136-3912
>>>> (305) 372-6872
>>>> abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
>>>>
>www.miamidade.gov/environment<http://www.miamidade.gov/environment/>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>-----------------------------------------------------------------------
>----

From sezenismail at gmail.com  Thu May 18 15:40:35 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Thu, 18 May 2017 16:40:35 +0300
Subject: [R] violin plot help
In-Reply-To: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
References: <161FBD7CDADFC2489F2D5A7441BEBFBF8F4633D2@S0020287.miamidade.gov>
Message-ID: <0503E82B-63C5-4A60-80D4-31CEAAC72700@gmail.com>


> On 16 May 2017, at 17:06, Abdelrahman, Omar (RER) <Omar.Abdelrahman at miamidade.gov> wrote:
> 
> I am trying to produce multiple violin plots by 3 categorical variables, each violin representing 1 year worth of data. The variables are:
> 
> Watershed (7 levels: county canals)
> 
> Geography (5 levels: west; central; east; mouth; bay)
> 
> Parameter (8 levels: water quality chemical parameters)
> 
> Year (25 levels: 1992-2017)
> 
> I want to produce 1 plot for each Parameter-Watershed subdivided into Geography with a violin for each year. I used facets with the following code (not by year):

Hello Omer,
If you want violin plots for different categories, I would suggest lattice solution. For start;

https://www.r-bloggers.com/violin-and-boxplots-with-lattice-and-r/

Search terms: lattice, bwplot, panel.violin will help you find more examples.

> 
> ggplot () +
> 
> facet_grid (PARAMETER ~Wshed, scales="free_y") +
> 
> geom_violin (data=merged, aes(x=Geo, y=RESULT))
> 
> 
> 
> I do not want facets, they crowd the information so it is unreadable. I just started with R this week and have not been able to figure out the foreach protocol, or any other loop protocol. I tried to subset the data to do it iteratively with the following code:
> 
> 
> 
> subdf<-subset (merged, Wshed = "AC")
> 
> 
> 
> but got an error: Error: unexpected input in "subdf=subset (merged, Wshed == ""
> 
> Any help would be greatly appreciated.
> 
> Thanks,
> 
> Omar Abdelrahman, Biologist II
> Miami-Dade County, Department of Regulatory and Economic Resources
> Division of Environmental Resources Management (DERM)
> Overtown Transit Village
> 701 NW 1st Court, 5th Floor
> Miami, FL 33136-3912
> (305) 372-6872
> abdelo at miamidade.gov<mailto:abdelo at miamidade.gov>
> www.miamidade.gov/environment<http://www.miamidade.gov/environment/>
> 


From marine.regis at hotmail.fr  Thu May 18 17:18:34 2017
From: marine.regis at hotmail.fr (Marine Regis)
Date: Thu, 18 May 2017 15:18:34 +0000
Subject: [R] Randomly select one row by group from a matrix
Message-ID: <AM3PR07MB11852BDAF5FD9E9866C50C8AE2E40@AM3PR07MB1185.eurprd07.prod.outlook.com>

Hello,
I would like to randomly select one row by group from a matrix. Here is an example where there is one row by group. The code gives an error message:
test <- matrix(c(4,4, 6,2, 1,2), nrow = 2, ncol = 3, dimnames = list(NULL, c("xcor", "ycor", "id")))
do.call(rbind, lapply(split(test, test[,c("id")]), function(x) x[sample(nrow(x), 1), ]))
 Show Traceback

 Rerun with Debug

Error in sample.int(length(x), size, replace, prob) :
  invalid first argument


How can I modify the code so that it works when there are several rows or one row for a given group?
Thanks very much for your time
Have a nice day
Marine


	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu May 18 17:45:05 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 18 May 2017 15:45:05 +0000
Subject: [R] Randomly select one row by group from a matrix
In-Reply-To: <AM3PR07MB11852BDAF5FD9E9866C50C8AE2E40@AM3PR07MB1185.eurprd07.prod.outlook.com>
References: <AM3PR07MB11852BDAF5FD9E9866C50C8AE2E40@AM3PR07MB1185.eurprd07.prod.outlook.com>
Message-ID: <CAKVAULOOpeijZYABoXherCnGihGVCGoZD4Ev52yiAdqwfqoKUg@mail.gmail.com>

Hi Marine,

your manipulation of the matrix is quite convoluted, and it helps to expand
a bit:

test_lst <- split(test, test[,c("id")])
test_lst$`1`

after splitting, your matrix has gone back to be a plain vector, which
makes the sampling fail.

The reason is that, a matrix - behind the scenes - is a vector with a
dimension and when splitting the matrix you lose the dimension information.

Do you really need to work with a matrix? I prefer data.frames because I
can mix different types. Also with data.frame you can use the functionality
of the dplyr library, which also makes things more readable:

library(dplyr)

test_df <- data.frame(xcor = rnorm(8), ycor = rnorm(8), id = c(1, 2))

grouped_test_df <- group_by(test_df, id)
sample_n(grouped_test_df, 1)

HTH
Ulrik



On Thu, 18 May 2017 at 17:18 Marine Regis <marine.regis at hotmail.fr> wrote:

> Hello,
> I would like to randomly select one row by group from a matrix. Here is an
> example where there is one row by group. The code gives an error message:
> test <- matrix(c(4,4, 6,2, 1,2), nrow = 2, ncol = 3, dimnames = list(NULL,
> c("xcor", "ycor", "id")))
> do.call(rbind, lapply(split(test, test[,c("id")]), function(x)
> x[sample(nrow(x), 1), ]))
>  Show Traceback
>
>  Rerun with Debug
>
> Error in sample.int(length(x), size, replace, prob) :
>   invalid first argument
>
>
> How can I modify the code so that it works when there are several rows or
> one row for a given group?
> Thanks very much for your time
> Have a nice day
> Marine
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu May 18 19:38:46 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 18 May 2017 10:38:46 -0700
Subject: [R] Randomly select one row by group from a matrix
In-Reply-To: <CAKVAULOOpeijZYABoXherCnGihGVCGoZD4Ev52yiAdqwfqoKUg@mail.gmail.com>
References: <AM3PR07MB11852BDAF5FD9E9866C50C8AE2E40@AM3PR07MB1185.eurprd07.prod.outlook.com>
 <CAKVAULOOpeijZYABoXherCnGihGVCGoZD4Ev52yiAdqwfqoKUg@mail.gmail.com>
Message-ID: <CAGxFJbREXYec5WSnLDO_NoNPEjXf0rzZPfzdC7-cO+9+pgqPDw@mail.gmail.com>

If I understand corrrectly, this is easily accomplished in base R via
?tapply and indexing.

e.g.

set.seed(1234) ## for reproducibility
grp <- sample.int(5,size = 30,rep = TRUE) ## a grouping vector
## Could be just a column of your matrix or frame

indx <- tapply(seq_along(grp),grp, sample,size =1)
> indx  ## just to show you what you get
 1  2  3  4  5
19 15 10  6 14

## now just use indx to extract rowd of your matrix or data frame,d:

selected <- d[indx,] ## one row per group


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 18, 2017 at 8:45 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> Hi Marine,
>
> your manipulation of the matrix is quite convoluted, and it helps to expand
> a bit:
>
> test_lst <- split(test, test[,c("id")])
> test_lst$`1`
>
> after splitting, your matrix has gone back to be a plain vector, which
> makes the sampling fail.
>
> The reason is that, a matrix - behind the scenes - is a vector with a
> dimension and when splitting the matrix you lose the dimension information.
>
> Do you really need to work with a matrix? I prefer data.frames because I
> can mix different types. Also with data.frame you can use the functionality
> of the dplyr library, which also makes things more readable:
>
> library(dplyr)
>
> test_df <- data.frame(xcor = rnorm(8), ycor = rnorm(8), id = c(1, 2))
>
> grouped_test_df <- group_by(test_df, id)
> sample_n(grouped_test_df, 1)
>
> HTH
> Ulrik
>
>
>
> On Thu, 18 May 2017 at 17:18 Marine Regis <marine.regis at hotmail.fr> wrote:
>
>> Hello,
>> I would like to randomly select one row by group from a matrix. Here is an
>> example where there is one row by group. The code gives an error message:
>> test <- matrix(c(4,4, 6,2, 1,2), nrow = 2, ncol = 3, dimnames = list(NULL,
>> c("xcor", "ycor", "id")))
>> do.call(rbind, lapply(split(test, test[,c("id")]), function(x)
>> x[sample(nrow(x), 1), ]))
>>  Show Traceback
>>
>>  Rerun with Debug
>>
>> Error in sample.int(length(x), size, replace, prob) :
>>   invalid first argument
>>
>>
>> How can I modify the code so that it works when there are several rows or
>> one row for a given group?
>> Thanks very much for your time
>> Have a nice day
>> Marine
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu May 18 20:56:35 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 18 May 2017 18:56:35 +0000
Subject: [R] Randomly select one row by group from a matrix
In-Reply-To: <CAGxFJbREXYec5WSnLDO_NoNPEjXf0rzZPfzdC7-cO+9+pgqPDw@mail.gmail.com>
References: <AM3PR07MB11852BDAF5FD9E9866C50C8AE2E40@AM3PR07MB1185.eurprd07.prod.outlook.com>
 <CAKVAULOOpeijZYABoXherCnGihGVCGoZD4Ev52yiAdqwfqoKUg@mail.gmail.com>
 <CAGxFJbREXYec5WSnLDO_NoNPEjXf0rzZPfzdC7-cO+9+pgqPDw@mail.gmail.com>
Message-ID: <57adf46051b045d794e92501abb6e8c1@exch-2p-mbx-w2.ads.tamu.edu>

You can modify your original code to get what you want:

do.call(rbind, lapply(split(data.frame(test), test[,c("id")]), function(x) as.matrix(x[sample(nrow(x), 1), ])))
#   xcor ycor id
# 1    4    6  1
# 2    4    2  2

But Bert's way is simpler:

indx <- tapply(seq_along(test[, "id"]), test[, "id"], sample, size=1)
test[indx, ]
#      xcor ycor id
# [1,]    4    6  1
# [2,]    4    2  2

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Thursday, May 18, 2017 12:39 PM
To: Ulrik Stervbo <ulrik.stervbo at gmail.com>
Cc: r-help at r-project.org; Marine Regis <marine.regis at hotmail.fr>
Subject: Re: [R] Randomly select one row by group from a matrix

If I understand corrrectly, this is easily accomplished in base R via
?tapply and indexing.

e.g.

set.seed(1234) ## for reproducibility
grp <- sample.int(5,size = 30,rep = TRUE) ## a grouping vector
## Could be just a column of your matrix or frame

indx <- tapply(seq_along(grp),grp, sample,size =1)
> indx  ## just to show you what you get
 1  2  3  4  5
19 15 10  6 14

## now just use indx to extract rowd of your matrix or data frame,d:

selected <- d[indx,] ## one row per group


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 18, 2017 at 8:45 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> Hi Marine,
>
> your manipulation of the matrix is quite convoluted, and it helps to expand
> a bit:
>
> test_lst <- split(test, test[,c("id")])
> test_lst$`1`
>
> after splitting, your matrix has gone back to be a plain vector, which
> makes the sampling fail.
>
> The reason is that, a matrix - behind the scenes - is a vector with a
> dimension and when splitting the matrix you lose the dimension information.
>
> Do you really need to work with a matrix? I prefer data.frames because I
> can mix different types. Also with data.frame you can use the functionality
> of the dplyr library, which also makes things more readable:
>
> library(dplyr)
>
> test_df <- data.frame(xcor = rnorm(8), ycor = rnorm(8), id = c(1, 2))
>
> grouped_test_df <- group_by(test_df, id)
> sample_n(grouped_test_df, 1)
>
> HTH
> Ulrik
>
>
>
> On Thu, 18 May 2017 at 17:18 Marine Regis <marine.regis at hotmail.fr> wrote:
>
>> Hello,
>> I would like to randomly select one row by group from a matrix. Here is an
>> example where there is one row by group. The code gives an error message:
>> test <- matrix(c(4,4, 6,2, 1,2), nrow = 2, ncol = 3, dimnames = list(NULL,
>> c("xcor", "ycor", "id")))
>> do.call(rbind, lapply(split(test, test[,c("id")]), function(x)
>> x[sample(nrow(x), 1), ]))
>>  Show Traceback
>>
>>  Rerun with Debug
>>
>> Error in sample.int(length(x), size, replace, prob) :
>>   invalid first argument
>>
>>
>> How can I modify the code so that it works when there are several rows or
>> one row for a given group?
>> Thanks very much for your time
>> Have a nice day
>> Marine
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From nielsenrune at me.com  Thu May 18 15:08:33 2017
From: nielsenrune at me.com (=?utf-8?Q?Rune_Gr=C3=B8nseth?=)
Date: Thu, 18 May 2017 15:08:33 +0200
Subject: [R] Extracting metadata information to corresponding
 dissimilarity matrix
In-Reply-To: <b45a70dbcf1a47e784a20c1f75348351@exch-2p-mbx-w2.ads.tamu.edu>
References: <690BC4CA-BCFD-49DF-BFCD-32CEF488991F@me.com>
 <29e4508222704dfb90c3abaf09e69880@exch-2p-mbx-w2.ads.tamu.edu>
 <b45a70dbcf1a47e784a20c1f75348351@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <2E7CAF88-068B-4790-8C63-108D1B1247A0@me.com>

Brilliant, David, thank you so much!

Cheers, 

Rune 

> 16. mai 2017 kl. 18.44 skrev David L Carlson <dcarlson at tamu.edu>:
> 
> Fixing a typo in the original, adding a simplification, and using dissimilarity instead of similarity:
> 
> set.seed(42)
> dta <- data.frame(ID=1:7, gender=sample(c("M", "F"), 7, replace=TRUE),
>     age=sample.int(75, 7))
> dsim <- dist(dta$age) # distance, already lower triangular
> dsim
> 
> dta1 <- dta
> names(dta1) <- paste0(names(dta), "1") # generalizes to more than 3 columns
> dta2 <- dta
> names(dta2) <- paste0(names(dta), "2")
> 
> dta12 <- merge(dta2, dta1) # order is important
> dta12 <- dta12[dta12$ID1 < dta12$ID2, ] # get rid of duplicates
> 
> dta12 <- data.frame(dta12, dsim=as.vector(dsim)) # Typo was here
> dta12 <- dta12[, c("ID1", "ID2", "gender1", "gender2", "age1", "age2", "dsim")]
> dta12
> 
> David C
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
> Sent: Tuesday, May 16, 2017 11:21 AM
> To: Rune Gr?nseth <nielsenrune at me.com>; r-help at r-project.org
> Subject: Re: [R] Extracting metadata information to corresponding dissimilarity matrix
> 
> I think this is what you are trying to do. I've created a data set with 7 rows and a similarity matrix based on age:
> 
> set.seed(42)
> dta <- data.frame(ID=1:7, gender=sample(c("M", "F"), 7, replace=TRUE),
>     age=sample.int(75, 7))
> sim <- max(dist(dta$age)) - dist(dta$age) # already lower triangular
> sim
> 
> #    1  2  3  4  5  6
> # 2 24               
> # 3 21 59            
> # 4 40 46 43         
> # 5  0 38 41 22      
> # 6  7 45 48 29 55   
> # 7 55 31 28 47  7 14
> 
> # Now duplicate dta:
> dta1 <- dta
> names(dta1) <- c("ID1", "gender1", "age1")
> dta2 <- dta
> names(dta2) <- c("ID2", "gender2", "age2")
> 
> # Now merge and eliminate unneeded rows
> dta12 <- merge(dta2, dta1) # order is important
> dta12 <- dta12[dta12$ID1 < dta12$ID2, ]
> 
> # Finally combine the similarities with the combined data and rearrange
> # the variable names
> dta12 <- data.frame(dta12mod, sim=as.vector(sim))
> dta12 <- dta12[, c("ID1", "ID2", "gender1", "gender2", "age1", "age2", "sim")]
> dta12
> 
> #    ID1 ID2 gender1 gender2 age1 age2 sim
> # 2    1   2       F       F   11   49  24
> # 3    1   3       F       M   11   52  21
> # 4    1   4       F       F   11   33  40
> # 5    1   5       F       F   11   73   0
> # 6    1   6       F       F   11   66   7
> # 7    1   7       F       F   11   18  55
> # 10   2   3       F       M   49   52  59
> # 11   2   4       F       F   49   33  46
> # 12   2   5       F       F   49   73  38
> # 13   2   6       F       F   49   66  45
> # 14   2   7       F       F   49   18  31
> # 18   3   4       M       F   52   33  43
> # 19   3   5       M       F   52   73  41
> # 20   3   6       M       F   52   66  48
> # 21   3   7       M       F   52   18  28
> # 26   4   5       F       F   33   73  22
> # 27   4   6       F       F   33   66  29
> # 28   4   7       F       F   33   18  47
> # 34   5   6       F       F   73   66  55
> # 35   5   7       F       F   73   18   7
> # 42   6   7       F       F   66   18  14
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rune Gr?nseth
> Sent: Tuesday, May 16, 2017 4:31 AM
> To: r-help at r-project.org
> Subject: [R] Extracting metadata information to corresponding dissimilarity matrix
> 
> Hi,
> I am R beginner. I've tried googling and reading, but this might be too simple to be found in the documentation. 
> 
> I have a dissimilarity index (symmetric matrix) from which I have extracted the unique values using the exodist package command "lower". There are 14 observations, so there are 91 unique comparisons.
> 
> After this I'd like to extract corresponding metadata from a separate data frame (the 14 observations organized in rows identified by a samplenumber-vector, and other variables as gender, age, et cetera). The aim is to have a new data frame with 91 rows and metadata vectors giving me the value of the dissimilarity index,  gender each of the two observations that are compared by the dissimilarity metric. So if I'm looking for gender differences, I need 5 vectors in the data frame: samplenumber1, samplenumber2, gender1, gender2 and dissimilarity metric.
> 
> Does anyone have suggestions or experiences in reformatting data in this manner? This is just a test-dataset. My full data-set is for more than 100 observations, so I need a more general code, if that is possible.
> 
> With great appreciation of any help.
> 
> Rune Gr?nseth 
> 
> ---
> 
> Rune Gr?nseth, MD, PhD, postdoctoral fellow
> Department of Thoracic Medicine
> Haukeland University Hospital
> N-5021 Bergen
> Norway
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ssefick at gmail.com  Thu May 18 22:17:50 2017
From: ssefick at gmail.com (stephen sefick)
Date: Thu, 18 May 2017 15:17:50 -0500
Subject: [R] S4 Question; show generic method
Message-ID: <CADKEMqi=L2JCGZo-wyeu50qnzKNsZED_Sxaz48SwHsJU=z_oiw@mail.gmail.com>

Hello,

I changed the name of a function, and updated my R packages with
update.packages(ask=FALSE), and I have had a curious (to me) change in show
method. I am developing a package, and a generic show method I defined for
my S4 class is not autocalled when I type the object name - object_name;
however, the show(object_name) works as expected. I have included the
output from sessionInfo():

R version 3.3.2 (2016-10-31)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] genotypeR_0.0.0.9000 ggplot2_2.2.1

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.10     lattice_0.20-35  zoo_1.8-0        MASS_7.3-47
 [5] grid_3.3.2       plyr_1.8.4       gtable_0.2.0     magrittr_1.5
 [9] scales_0.4.1     stringi_1.1.5    rlang_0.1.1      reshape2_1.4.2
[13] lazyeval_0.2.0   doBy_4.5-15      Matrix_1.2-10    tools_3.3.2
[17] stringr_1.2.0    munsell_0.4.3    colorspace_1.3-2 tibble_1.3.1

I appreciate any help with this problem.
kindest regards,

Stephen

-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri May 19 00:11:54 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 19 May 2017 08:11:54 +1000
Subject: [R] RCommander issue
In-Reply-To: <1178040662.759173.1495105902903@mail.yahoo.com>
References: <1197692941.1996216.1493823349413.ref@mail.yahoo.com>
 <1197692941.1996216.1493823349413@mail.yahoo.com>
 <CA+8X3fV+mg8EGt0eCfz7pJ6=dbTTJJccDpatkZp3KD12GK2g2Q@mail.gmail.com>
 <1029354536.1835670.1495024063011@mail.yahoo.com>
 <CA+8X3fUsy3RHWHmt7CvcrfRbE4380BEUHnjU33iL1OtLjrqFyQ@mail.gmail.com>
 <1178040662.759173.1495105902903@mail.yahoo.com>
Message-ID: <CA+8X3fWeBJ1+oTcCKo6shHXTeEiZR7M16PLDEkXm-JWufogysQ@mail.gmail.com>

Hi Thambu,
Try downloading the package from CRAN. For example, I just tried this
with the rgdal package as I need to use it.

The package (rgdal_1.2-7.zip) is saved on the local hard disk. Then
find out where your R executable is. For me it is:

E:\jim\R\R-3.3.3\bin\x64\R.exe

Now open a "Command Prompt" window. Change your directory to where the
package file is saved. Then using your path to the R executable and
the name of the package file you downloaded:

E:\jim\R\R-3.3.3\bin\x64\R CMD INSTALL rgdal_1.2-7.zip

This seems to work without invoking install.packages, which may be
failing to establish an internet connection for the download.

Jim


On Thu, May 18, 2017 at 9:11 PM, thambu david <thambsup at yahoo.com> wrote:
> thanks JIm, i do have internet connection and i was trying to set the CRAN
> mirror from R , before when i got the message
>
>
>
> On Thursday, 18 May 2017 3:20 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
> Hi Thambu,
> You must have an internet connection, otherwise you couldn't access
> CRAN. Have you tried using "install.packages" (see the help page) from
> within R? Your message isn't clear whether you have used that function
> or tried to download the package from a Web browser and then install
> it from the local copy of the package.
>
> There are a lot of things that can go wrong when accessing the
> internet and the error message does not seem to implicate R.
>
> Jim
>
> On Wed, May 17, 2017 at 10:27 PM, thambu david <thambsup at yahoo.com> wrote:
>> :-)
>> I did try with the right spelling with no luck
>> is there any simple ting i am making an error with?
>>
>>
>
>


From b88207001 at ntu.edu.tw  Fri May 19 05:57:51 2017
From: b88207001 at ntu.edu.tw (Yen Lee)
Date: Thu, 18 May 2017 22:57:51 -0500
Subject: [R] Question about change the length of a string.
Message-ID: <000001d2d054$18aac240$4a0046c0$@ntu.edu.tw>

Hello everyone,

 

I have a question and I need your precious kind help. 

 

I am working on matching two string. However, the length of the two strings
is different. For example, one is "example" (nchar=7), the other one is
"example   " (nchar=10). The R considers them as different strings but they
will be the same if I could make the first string has 10 characters,
"example" followed by 3 spaces. However, I could not find a way to do it. Is
there anyone able to provide some suggestions? 

 

I appreciate your precious time!!!!

 

Best,

Yen 

 


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri May 19 06:10:43 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 18 May 2017 21:10:43 -0700
Subject: [R] Question about change the length of a string.
In-Reply-To: <000001d2d054$18aac240$4a0046c0$@ntu.edu.tw>
References: <000001d2d054$18aac240$4a0046c0$@ntu.edu.tw>
Message-ID: <A42C7D86-BF74-4CD6-894F-62F3DF5B26F6@dcn.davis.ca.us>

http://stackoverflow.com/questions/2261079/how-to-trim-leading-and-trailing-whitespace-in-r
-- 
Sent from my phone. Please excuse my brevity.

On May 18, 2017 8:57:51 PM PDT, Yen Lee <b88207001 at ntu.edu.tw> wrote:
>Hello everyone,
>
> 
>
>I have a question and I need your precious kind help. 
>
> 
>
>I am working on matching two string. However, the length of the two
>strings
>is different. For example, one is "example" (nchar=7), the other one is
>"example   " (nchar=10). The R considers them as different strings but
>they
>will be the same if I could make the first string has 10 characters,
>"example" followed by 3 spaces. However, I could not find a way to do
>it. Is
>there anyone able to provide some suggestions? 
>
> 
>
>I appreciate your precious time!!!!
>
> 
>
>Best,
>
>Yen 
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From b88207001 at ntu.edu.tw  Fri May 19 06:14:40 2017
From: b88207001 at ntu.edu.tw (Yen Lee)
Date: Thu, 18 May 2017 23:14:40 -0500
Subject: [R] Question about change the length of a string.
In-Reply-To: <A42C7D86-BF74-4CD6-894F-62F3DF5B26F6@dcn.davis.ca.us>
References: <000001d2d054$18aac240$4a0046c0$@ntu.edu.tw>
 <A42C7D86-BF74-4CD6-894F-62F3DF5B26F6@dcn.davis.ca.us>
Message-ID: <000201d2d056$7230a080$5691e180$@ntu.edu.tw>

Hi Jeff,

Thank you a lot!!!!!

Best,
Yen

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Thursday, May 18, 2017 11:11 PM
To: r-help at r-project.org; Yen Lee <b88207001 at ntu.edu.tw>
Subject: Re: [R] Question about change the length of a string.

http://stackoverflow.com/questions/2261079/how-to-trim-leading-and-trailing-whitespace-in-r
--
Sent from my phone. Please excuse my brevity.

On May 18, 2017 8:57:51 PM PDT, Yen Lee <b88207001 at ntu.edu.tw> wrote:
>Hello everyone,
>
> 
>
>I have a question and I need your precious kind help. 
>
> 
>
>I am working on matching two string. However, the length of the two 
>strings is different. For example, one is "example" (nchar=7), the 
>other one is
>"example   " (nchar=10). The R considers them as different strings but
>they
>will be the same if I could make the first string has 10 characters, 
>"example" followed by 3 spaces. However, I could not find a way to do 
>it. Is there anyone able to provide some suggestions?
>
> 
>
>I appreciate your precious time!!!!
>
> 
>
>Best,
>
>Yen
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From annekarinmm at gmail.com  Fri May 19 02:48:19 2017
From: annekarinmm at gmail.com (Anne Karin da Mota Borges)
Date: Thu, 18 May 2017 21:48:19 -0300
Subject: [R] p-value=0 running log-rank test
Message-ID: <CAG5XtzV62K8P1bmHG+bWGW7CbmFzAkejXqJytHdeFrkeLyJpZA@mail.gmail.com>

Dear all,

I have a question concerning the p-value. When running log-rank test I get
a p-value = 0.
What is it mean? Can this be true? Why aren?t there decimal points? Is
there a way to find out the exact p-value?

Here is the output:

> survdiff(Surv(tempo2,status)~tphist, data=base,rho=0)
Call:
survdiff(formula = Surv(tempo2, status) ~ tphist, data = base,
    rho = 0)

           N Observed Expected (O-E)^2/E (O-E)^2/V
tphist=1 513       19   40.879    11.710  9.00e+01
tphist=2  49        4    3.892     0.003  3.27e-03
tphist=3  23        9    1.686    31.717  3.29e+01
tphist=4  18       15    0.543   385.172  3.91e+02

 Chisq= 430  on 3 degrees of freedom, p= 0

Thank you in advance.

Anne.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri May 19 07:14:15 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 19 May 2017 17:14:15 +1200
Subject: [R] [FORGED]  p-value=0 running log-rank test
In-Reply-To: <CAG5XtzV62K8P1bmHG+bWGW7CbmFzAkejXqJytHdeFrkeLyJpZA@mail.gmail.com>
References: <CAG5XtzV62K8P1bmHG+bWGW7CbmFzAkejXqJytHdeFrkeLyJpZA@mail.gmail.com>
Message-ID: <9e7a4a16-3692-323a-c33b-863c3f6b32a7@auckland.ac.nz>


This is not an R question.

Your question indicates that you really need to learn some statistics.

To answer the very last part:

 > pchisq(430,3,lower=FALSE)
[1] 7.020486e-93

And if that is not 0 to all intents and purposes, then God help us all.

cheers,

Rolf Turner

On 19/05/17 12:48, Anne Karin da Mota Borges wrote:
> Dear all,
>
> I have a question concerning the p-value. When running log-rank test I get
> a p-value = 0.
> What is it mean? Can this be true? Why aren?t there decimal points? Is
> there a way to find out the exact p-value?
>
> Here is the output:
>
>> survdiff(Surv(tempo2,status)~tphist, data=base,rho=0)
> Call:
> survdiff(formula = Surv(tempo2, status) ~ tphist, data = base,
>     rho = 0)
>
>            N Observed Expected (O-E)^2/E (O-E)^2/V
> tphist=1 513       19   40.879    11.710  9.00e+01
> tphist=2  49        4    3.892     0.003  3.27e-03
> tphist=3  23        9    1.686    31.717  3.29e+01
> tphist=4  18       15    0.543   385.172  3.91e+02
>
>  Chisq= 430  on 3 degrees of freedom, p= 0
>
> Thank you in advance.


From ramnik.bansal at gmail.com  Fri May 19 11:48:46 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Fri, 19 May 2017 15:18:46 +0530
Subject: [R] Logical Operators' inconsistent Behavior
Message-ID: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>

Hi,

I need to understand the inconsistent behaviour of & and I operators when
used with NA.

The code below explains this inconsistency

> TRUE & NA
[1] NA

> FALSE & NA
[1] FALSE

> TRUE & NA
[1] NA

> FALSE | NA
[1] NA

> TRUE | NA
[1] TRUE

> TRUE == NA
[1] NA

> FALSE == NA
[1] NA

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri May 19 11:58:00 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 19 May 2017 11:58:00 +0200
Subject: [R] Logical Operators' inconsistent Behavior
In-Reply-To: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
Message-ID: <CAJuCY5xbyQBogn68wkuy00K14R+iY4g6j1dgNPffVnAO=T8GJw@mail.gmail.com>

& -> AND -> results only TRUE if both inputs are TRUE. Hence: FALSE AND
unknown = FALSE, TRUE AND unknown = unknown
| -> OR -> results in TRUE as soon as one of the inputs is TRUE. Hence FASE
or unknown = unknown, TRUE or unknown = TRUE
TRUE == NA and FALSE == NA compares TRUE/FALSE against unknown hence the
output is unknown.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-05-19 11:48 GMT+02:00 Ramnik Bansal <ramnik.bansal at gmail.com>:

> Hi,
>
> I need to understand the inconsistent behaviour of & and I operators when
> used with NA.
>
> The code below explains this inconsistency
>
> > TRUE & NA
> [1] NA
>
> > FALSE & NA
> [1] FALSE
>
> > TRUE & NA
> [1] NA
>
> > FALSE | NA
> [1] NA
>
> > TRUE | NA
> [1] TRUE
>
> > TRUE == NA
> [1] NA
>
> > FALSE == NA
> [1] NA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri May 19 12:05:11 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 19 May 2017 22:05:11 +1200
Subject: [R] [FORGED]  Logical Operators' inconsistent Behavior
In-Reply-To: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
Message-ID: <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>


On 19/05/17 21:48, Ramnik Bansal wrote:

> Hi,
>
> I need to understand the inconsistent behaviour of & and I operators when
> used with NA.
>
> The code below explains this inconsistency
>
>> TRUE & NA
> [1] NA
>
>> FALSE & NA
> [1] FALSE
>
>> TRUE & NA
> [1] NA
>
>> FALSE | NA
> [1] NA
>
>> TRUE | NA
> [1] TRUE
>
>> TRUE == NA
> [1] NA
>
>> FALSE == NA
> [1] NA

What inconsistency?  It all makes complete sense.  Think about it.

TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
either TRUE or FALSE and consequently is NA.

OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.

Und so weiter.

As I said *think* about it; don't just go with your immediate knee-jerk 
(simplistic) reaction.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From S.Ellison at LGCGroup.com  Fri May 19 13:38:06 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 19 May 2017 12:38:06 +0100
Subject: [R] [FORGED]  Logical Operators' inconsistent Behavior
In-Reply-To: <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
Message-ID: <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>

> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
> either TRUE or FALSE and consequently is NA.
> 
> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>
> As I said *think* about it; don't just go with your immediate knee-jerk
> (simplistic) reaction.

Hmm... not sure that was quite fair to the OP. Yes,  FALSE & <anything> == FALSE. But 'NA' does not mean 'anything'; it means 'missing' (see ?'NA'). It is much less obvious that FALSE & <missing> should generate a non-missing value. SQL, for example, generally  takes the view that any expression involving 'missing' is 'missing'. 

And R's behaviour can look odd if the vagaries of real data intervene:
b1 <- c(A=TRUE, C=FALSE)
b2 <- c(A=FALSE, B=FALSE, C=TRUE)
b1['B'] & b2['B']
#Which returns
# <NA> 
# FALSE 

which - particularly since it appears without warning - is not an obviously sensible outcome. 

I am not suggesting a change to R's logical operations, which have clearly been thought through (that is evident from NA&FALSE == FALSE&NA == FALSE). But R's behaviour looks to me like a choice among difficult alternatives, rather than the only possible choice. I'd give the OP some credit for that.

S Ellison


S Ellison







*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jeremiejuste at gmail.com  Fri May 19 14:01:54 2017
From: jeremiejuste at gmail.com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Fri, 19 May 2017 14:01:54 +0200
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>

Hello,

Rolf said,

TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
either TRUE or FALSE and consequently is NA.

OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.


According to this logic why is

> FALSE & NA
>
[1] FALSE
?

Best regards,

Jeremie

On Fri, May 19, 2017 at 1:38 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
> > either TRUE or FALSE and consequently is NA.
> >
> > OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
> >
> > As I said *think* about it; don't just go with your immediate knee-jerk
> > (simplistic) reaction.
>
> Hmm... not sure that was quite fair to the OP. Yes,  FALSE & <anything> ==
> FALSE. But 'NA' does not mean 'anything'; it means 'missing' (see ?'NA').
> It is much less obvious that FALSE & <missing> should generate a
> non-missing value. SQL, for example, generally  takes the view that any
> expression involving 'missing' is 'missing'.
>
> And R's behaviour can look odd if the vagaries of real data intervene:
> b1 <- c(A=TRUE, C=FALSE)
> b2 <- c(A=FALSE, B=FALSE, C=TRUE)
> b1['B'] & b2['B']
> #Which returns
> # <NA>
> # FALSE
>
> which - particularly since it appears without warning - is not an
> obviously sensible outcome.
>
> I am not suggesting a change to R's logical operations, which have clearly
> been thought through (that is evident from NA&FALSE == FALSE&NA == FALSE).
> But R's behaviour looks to me like a choice among difficult alternatives,
> rather than the only possible choice. I'd give the OP some credit for that.
>
> S Ellison
>
>
> S Ellison
>
>
>
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:18}}


From r.turner at auckland.ac.nz  Fri May 19 14:12:58 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 20 May 2017 00:12:58 +1200
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <1640edb9-99d4-e80f-7eac-25e05b0cb645@auckland.ac.nz>

On 19/05/17 23:38, S Ellison wrote:
>> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
>> either TRUE or FALSE and consequently is NA.
>>
>> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>>
>> As I said *think* about it; don't just go with your immediate knee-jerk
>> (simplistic) reaction.
>
> Hmm... not sure that was quite fair to the OP.

The OP complained that the logical operators in R are inconsistent. 
This is an arrogant and presumptuous assertion that deserves a 
reprimand.  One should be very, very circumspect about presuming to know 
better than R.

> Yes, FALSE &
> <anything>== FALSE. But 'NA' does not mean 'anything'; it means 'missing' (see
> ?'NA').

Well, duh.  Yes, I know what NA means.  If it's missing, you don't know 
what it's value is.  But it doesn't *matter* what its value is; FALSE &
<anything> is FALSE.  So FALSE & NA is FALSE, irrespective of what NA
"really" is.

> It is much less obvious that FALSE & <missing> should generate a
> non-missing value. SQL, for example, generally takes the view that any
> expression involving 'missing' is 'missing'.

Well, then SQL gets it wrong.

> And R's behaviour can look odd if the vagaries of real data intervene:
> b1 <- c(A=TRUE, C=FALSE)
> b2 <- c(A=FALSE, B=FALSE, C=TRUE)
> b1['B'] & b2['B']
> #Which returns
> # <NA>
> # FALSE
>
> which - particularly since it appears without warning ....

Everything appears without warning.  Nobody expected the Spanish 
Inquisition.

> .... - is not an obviously sensible outcome.

Why not?  It's obviously sensible to me, and to anyone else who is 
thinking.  Since b1['B'] is NA (b1 doesn't have an entry named 'B') and 
b2['B'] is FALSE we get NA & FALSE which is FALSE.  Where's the problem?

The "<NA>" in the output that you show is the *name* of the 'B' entry of 
b1, and since there isn't one, it doesn't have a name.  So the name is 
missing whence it is rendered as "<NA>" (missing character).

> I am not suggesting a change to R's logical operations, which have
> clearly been thought through (that is evident from NA&FALSE ==
> FALSE&NA == FALSE). But R's behaviour looks to me like a choice among
> difficult alternatives, rather than the only possible choice. I'd
> give the OP some credit for that.

You seem to be arguing for the sake of arguing.  It's really quite 
straightforward *if* you *think* about it.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Fri May 19 14:13:56 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 20 May 2017 00:13:56 +1200
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
Message-ID: <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>

On 20/05/17 00:01, J?r?mie Juste wrote:
> Hello,
>
> Rolf said,
>
> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
> either TRUE or FALSE and consequently is NA.
>
> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>
>
> According to this logic why is
>
>     FALSE & NA
>
> [1] FALSE

Huh????

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jeremiejuste at gmail.com  Fri May 19 14:24:06 2017
From: jeremiejuste at gmail.com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Fri, 19 May 2017 14:24:06 +0200
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
Message-ID: <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>

My apologies if I was not clear enough,

TRUE & NA could be either TRUE or FALSE and consequently is NA.
why is   FALSE & NA = FALSE?  NA could be TRUE or FALSE, so FALSE & NA
should be NA?


On Fri, May 19, 2017 at 2:13 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 20/05/17 00:01, J?r?mie Juste wrote:
>
>> Hello,
>>
>> Rolf said,
>>
>> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
>> either TRUE or FALSE and consequently is NA.
>>
>> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>>
>>
>> According to this logic why is
>>
>>     FALSE & NA
>>
>> [1] FALSE
>>
>
> Huh????
>
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>



-- 
J?r?mie Juste

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Fri May 19 14:48:54 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 19 May 2017 13:48:54 +0100
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <1640edb9-99d4-e80f-7eac-25e05b0cb645@auckland.ac.nz>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <1640edb9-99d4-e80f-7eac-25e05b0cb645@auckland.ac.nz>
Message-ID: <1A8C1289955EF649A09086A153E267240B9597D61D@GBTEDVPEXCMB04.corp.lgc-group.com>

> > SQL, for example, generally takes the view that any 
> > expression involving 'missing' is 'missing'.
> 
> Well, then SQL gets it wrong.

Well, that's a view. But paraphrasing an  R Turner from a few lines away in the same email:

> One should be very, very circumspect about presuming to know better than
> SQL

It's a choice. I understand and respect R's. But I can also understand why someone might have expected something different.

S


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From pdalgd at gmail.com  Fri May 19 15:00:24 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 19 May 2017 15:00:24 +0200
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
Message-ID: <758C5241-9C2B-4C8C-89B6-844987BB2FB5@gmail.com>


> On 19 May 2017, at 14:24 , J?r?mie Juste <jeremiejuste at gmail.com> wrote:
> 
> My apologies if I was not clear enough,
> 
> TRUE & NA could be either TRUE or FALSE and consequently is NA.
> why is   FALSE & NA = FALSE?  NA could be TRUE or FALSE, so FALSE & NA
> should be NA?
> 

At the risk of flogging a dead horse:

FALSE & TRUE = FALSE
FALSE & FALSE = FALSE

FALSE & x = FALSE, whatever the value of x, hence 

FALSE & NA = FALSE

Get it?  

-pd


> 
> On Fri, May 19, 2017 at 2:13 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> 
>> On 20/05/17 00:01, J?r?mie Juste wrote:
>> 
>>> Hello,
>>> 
>>> Rolf said,
>>> 
>>> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
>>> either TRUE or FALSE and consequently is NA.
>>> 
>>> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>>> 
>>> 
>>> According to this logic why is
>>> 
>>>    FALSE & NA
>>> 
>>> [1] FALSE
>>> 
>> 
>> Huh????
>> 
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> 
> 
> 
> 
> -- 
> J?r?mie Juste
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Fri May 19 15:02:00 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 May 2017 09:02:00 -0400
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <1A8C1289955EF649A09086A153E267240B9597D61D@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <1640edb9-99d4-e80f-7eac-25e05b0cb645@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D61D@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <58e56fca-bb8e-7862-982e-621c9e4d8eb7@gmail.com>

On 19/05/2017 8:48 AM, S Ellison wrote:
>>> SQL, for example, generally takes the view that any
>>> expression involving 'missing' is 'missing'.
>>
>> Well, then SQL gets it wrong.
>
> Well, that's a view. But paraphrasing an  R Turner from a few lines away in the same email:
>
>> One should be very, very circumspect about presuming to know better than
>> SQL
>
> It's a choice. I understand and respect R's. But I can also understand why someone might have expected something different.

You're right about SQL.  But for R, it's pretty simple to read the help 
page on NA, and it is quite explicit about this:

"Logical computations treat NA as a missing TRUE/FALSE value, and so may 
return TRUE or FALSE if the expression does not depend on the NA operand."

I'm surprised nobody on this thread has quoted that before.

Duncan Murdoch


From jdnewmil at dcn.davis.ca.us  Fri May 19 15:06:49 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 19 May 2017 06:06:49 -0700
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
Message-ID: <3F58DEB0-D225-4F70-92B1-782266D54CAF@dcn.davis.ca.us>

FALSE & FALSE -> FALSE
FALSE & TRUE -> FALSE

Why do you need to know what the second value is? It doesn't matter what it is... the answer is FALSE. 
-- 
Sent from my phone. Please excuse my brevity.

On May 19, 2017 5:24:06 AM PDT, "J?r?mie Juste" <jeremiejuste at gmail.com> wrote:
>My apologies if I was not clear enough,
>
>TRUE & NA could be either TRUE or FALSE and consequently is NA.
>why is   FALSE & NA = FALSE?  NA could be TRUE or FALSE, so FALSE & NA
>should be NA?
>
>
>On Fri, May 19, 2017 at 2:13 PM, Rolf Turner <r.turner at auckland.ac.nz>
>wrote:
>
>> On 20/05/17 00:01, J?r?mie Juste wrote:
>>
>>> Hello,
>>>
>>> Rolf said,
>>>
>>> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
>>> either TRUE or FALSE and consequently is NA.
>>>
>>> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>>>
>>>
>>> According to this logic why is
>>>
>>>     FALSE & NA
>>>
>>> [1] FALSE
>>>
>>
>> Huh????
>>
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>
>
>
>-- 
>J?r?mie Juste
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ted.harding at wlandres.net  Fri May 19 15:27:01 2017
From: ted.harding at wlandres.net (Ted Harding)
Date: Fri, 19 May 2017 14:27:01 +0100
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
Message-ID: <1495200421.6068.11.camel@deb2.fort.knox.uk>

[I unadvertently sent my reply below to Jeremie, instead of R-help.
Also, I havve had an additional thought which may clarify things
for R users].
[Original reply]:
The point about this is that (as Rolf wrote) FALSE & (anything)
is FALSE, provided logical NA is either TRUE ot FALSE but,
because the "NA" says that it is not known which it is,
it could be "anything". And, indeed, if "NA" is given the
"missing" meaning and if we assume that a missing logical value
did indeed have a value (necessarily either TRUE or FALSE),
then it follows logically that FALSE & NA = FALS?.

On the other hand, if with the "missing" interpretation of "NA"
we don't even know that it is a logical, then it might be fair
enough to say FALSE & NA = NA.
Ted.

[Additional thought]:
Testing to see what would happen if the NA were not loigical,
I put myself (not being logical ... ) on the line, facing up to R:
   X <- "Ted"
   FALSE & X
   Error in FALSE & X : 
   operations are possible only for numeric, logical or complex types
So R will refuse to deal with any variable which cannot partake in
a logical expression.

Ted.

On Fri, 2017-05-19 at 14:24 +0200, J?r?mie Juste wrote:
> My apologies if I was not clear enough,
> 
> TRUE & NA could be either TRUE or FALSE and consequently is NA.
> why is   FALSE & NA = FALSE?  NA could be TRUE or FALSE, so FALSE & NA
> should be NA?
> 
> 
> On Fri, May 19, 2017 at 2:13 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> 
> > On 20/05/17 00:01, J?r?mie Juste wrote:
> >
> >> Hello,
> >>
> >> Rolf said,
> >>
> >> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
> >> either TRUE or FALSE and consequently is NA.
> >>
> >> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
> >>
> >>
> >> According to this logic why is
> >>
> >>     FALSE & NA
> >>
> >> [1] FALSE
> >>
> >
> > Huh????
> >
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> 
> 
> 
> -- 
> J?r?mie Juste
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From brigitte.mangin at inra.fr  Fri May 19 14:30:45 2017
From: brigitte.mangin at inra.fr (Brigitte Mangin)
Date: Fri, 19 May 2017 12:30:45 +0000
Subject: [R] mixed Model: asreml-r versus nmle,lme4 or coxme
Message-ID: <1495197045517.38712@inra.fr>




Hi,

Did somebody know why asreml does not provide the same REML loglikehood  as coxme, lme4 or lmne.
Here is a simple example showing the differences:


#######################################################################
library(lme4)
library(coxme)
library(asreml)
library(nlme)

data(ergoStool, package="nlme") # use a data set from nlme

fit1 <- lmekin(effort ~ Type+(1|Subject), data=ergoStool,method="REML")
fit1$loglik #-60.56539
fit2 <- lmer(effort ~ Type+(1|Subject), data=ergoStool,REML=TRUE)
logLik(fit2) #'log Lik.' -60.56539 (df=6)
fit3<-asreml(fixed=effort ~ Type,random=~Subject,data=ergoStool,
        na.method.X="omit",na.method.Y="omit")
fit3$loglik #-31.15936
fit4<-lme(effort ~ Type,random=~1|Subject, data = ergoStool,method="REML")
fit4$logLik  #-60.56539

fit1 <- lmekin(effort ~ (1|Subject), data=ergoStool,method="REML")
fit1$loglik #-78.91898
fit2 <- lmer(effort ~ (1|Subject), data=ergoStool,REML=TRUE)
logLik(fit2) #'log Lik.' -78.91898 (df=3)
fit3<-asreml(fixed=effort ~ 1,random=~Subject,data=ergoStool,
        na.method.X="omit",na.method.Y="omit")
fit3$loglik #-46.75614
fit4<-lme(effort ~ 1,random=~1|Subject, data = ergoStool,method="REML")
fit4$logLik #-78.91898


############################
If it was just a constant value between the two models (with or without the fixed effect) it would not be important. But it is not.
I checked that the variance component estimators were equal.

Thanks



	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Fri May 19 09:39:18 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Fri, 19 May 2017 07:39:18 +0000 (UTC)
Subject: [R] train function in caret package
References: <667543577.1989752.1495179558848.ref@mail.yahoo.com>
Message-ID: <667543577.1989752.1495179558848@mail.yahoo.com>

Hi all,

I'm running train function from caret package on my data set patientdata:

    model=train(type~., data=patientdata, method="lvq", preProcess="scale", trControl=control)
and I get this error:

    Error in comp(expr, env = envir, options = list(suppressUndefined = TRUE)) : 

     could not find function "mayCallBrowser"
Does anyone know how should I solve it?!

Thanks for any help!
Elahe


From murdoch.duncan at gmail.com  Fri May 19 15:57:21 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 May 2017 09:57:21 -0400
Subject: [R] Problem with choose.files(default=..., multi=FALSE)
In-Reply-To: <5912EF8E.5070507@campdenbri.co.uk>
References: <oespd8$okp$1@blaine.gmane.org>
 <b33b604f-4e5e-db2a-6c6e-4cc59bd0e27c@gmail.com>
 <5912EF8E.5070507@campdenbri.co.uk>
Message-ID: <33ec13ca-f2b5-a888-f882-97d780fc857f@gmail.com>

On 10/05/2017 6:46 AM, Keith Jewell wrote:
> Thanks for confirming that I wasn't being stupid :-}
>
> When using default=pathlong I get the _correct_ starting directory...
> (M:\test\Averyveryveryveryverylongfoldername\Averyveryveryveryverylongfoldername\Averyveryveryveryverylongfoldername)
>
> ... both in the environment I indicated originally (Windows Server 2008
> R2 x64) and also in Windows 10 x64

This should now be fixed in R-patched and R-devel, as of revision 72703. 
  The issue was that the Windows API function returned its results in a 
slightly different format when multi=FALSE.  When there was no default 
or a short one, the two formats happened to look identical so we didn't 
notice this, but they differed when the default was longer than the result.

Duncan Murdoch

>
> Keith Jewell
>
> On 09/05/2017 17:49, Duncan Murdoch wrote:
>> On 09/05/2017 12:06 PM, Keith Jewell wrote:
>>> I'm very hesitant to suggest that there's a bug in such a venerable R
>>> function, but I can't see what I'm doing wrong. Any comments are welcome
>>
>> Yes, it looks like a bug.  One other thing I find a little strange: the
>> starting directory seems wrong when I have the pathlong default.  Did
>> you see that?  (I'm in Windows 10, not the same version as you.)
>>
>> Duncan Murdoch
>>
>>>
>>> When using choose.files() where:
>>>      default = something
>>>      multi = FALSE
>>>      selected file path is shorter than the default
>>> ... then the returned value is at least as long as the default,
>>> characters from default appearing (wrongly) at the end of the returned
>>> value.
>>>
>>> Example, in which all but the first choose.files() select
>>> "M:\\test\\target.dat". Note the last result.
>>>
>>>  > pathlong <- choose.files(caption = "long")
>>>  > pathlong # long file name to use as default for short selection
>>> [1]
>>> "M:\\test\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\target.dat"
>>>
>>>  > choose.files(caption = "short")  # no default without multi works
>>> [1] "M:\\test\\target.dat"
>>>  > choose.files(default=pathlong, caption = "short") # default without
>>> multi= works
>>> [1] "M:\\test\\target.dat"
>>>  > choose.files(caption = "short", multi = FALSE) # multi = FALSE
>>> without default works
>>> [1] "M:\\test\\target.dat"
>>>  > choose.files(default=pathlong, caption = "short", multi = TRUE) #
>>> multi = TRUE with default works
>>> [1] "M:\\test\\target.dat"
>>>  > choose.files(default=pathlong, caption = "short", multi = FALSE) #
>>> multi = FALSE with default fails
>>> [1]
>>> "M:\\test\\target.dat\\ryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\Averyveryveryveryverylongfoldername\\target.dat"
>>>
>>>
>>>  > # in case it's relevant
>>>  > sessionInfo()
>>> R version 3.4.0 (2017-04-21)
>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>> Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
>>> Kingdom.1252
>>> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>>>
>>> [5] LC_TIME=English_United Kingdom.1252
>>>
>>> attached base packages:
>>> [1] graphics  grDevices datasets  stats     tcltk     utils     tools
>>>    methods
>>> [9] base
>>>
>>> other attached packages:
>>>   [1] CBRIutils_1.0   stringr_1.2.0   svSocket_0.9-57 TinnR_1.0-5
>>> R2HTML_2.3.2
>>>   [6] Hmisc_4.0-3     ggplot2_2.2.1   Formula_1.2-1   survival_2.41-3
>>> lattice_0.20-35
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] RColorBrewer_1.1-2  htmlTable_1.9       digest_0.6.12
>>> htmltools_0.3.6
>>>   [5] splines_3.4.0       scales_0.4.1        grid_3.4.0
>>> checkmate_1.8.2
>>>   [9] devtools_1.12.0     knitr_1.15.1        munsell_0.4.3
>>> compiler_3.4.0
>>> [13] tibble_1.3.0        nnet_7.3-12         acepack_1.4.1
>>> Matrix_1.2-10
>>> [17] svMisc_0.9-70       plyr_1.8.4          base64enc_0.1-3
>>> data.table_1.10.4
>>> [21] stringi_1.1.5       magrittr_1.5        gtable_0.2.0
>>> colorspace_1.3-2
>>> [25] foreign_0.8-68      cluster_2.0.6       gridExtra_2.2.1
>>> htmlwidgets_0.8
>>> [29] withr_1.0.2         lazyeval_0.2.0      backports_1.0.5
>>> memoise_1.1.0
>>> [33] rpart_4.1-11        Rcpp_0.12.10        latticeExtra_0.6-28
>>>  >
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From patrcasi at nova.edu  Fri May 19 16:12:45 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Fri, 19 May 2017 14:12:45 +0000
Subject: [R] PROBLEM USING DICTIONARY WITH TM PACKAGE
In-Reply-To: <CY4PR06MB3032945BB7D2A0989FAF4ECCB9E70@CY4PR06MB3032.namprd06.prod.outlook.com>
References: <CY4PR06MB3032945BB7D2A0989FAF4ECCB9E70@CY4PR06MB3032.namprd06.prod.outlook.com>
Message-ID: <CY4PR06MB3032476172CB14231F83B789B9E50@CY4PR06MB3032.namprd06.prod.outlook.com>

Dear Members & Experts,


Since the Dictionary () function is no longer available with the tm package. How do I use other functions to do the same as below? I want to capture a list of specific terms from a corpus. By example, if my corpus has 102 files. I want to see a list with occurrences of prostatic, adenocarcinoma, grade in all 102 files. When I use the function Dictionary (), I got the error: Error: could not find function "Dictionary"


> d <- Dictionary(c("prostatic", "adenocarcinoma", "grade"))
> inspect(DocumentTermMatrix(docs, list(dictionary = d)))


But if I use the codes below using inspect, the dictionary only returns the terms for 10 files instead of 102. I need a way to get my dictionary to capture and return those terms for all 102 files or whatever other terms I select. I know I am close but inspect () is not the right function.


> myTerms <- c("prostatic", "adenocarcinoma", "grade")
> inspect(DocumentTermMatrix(docs, list(dictionary = myTerms)))

 <<DocumentTermMatrix (documents: 102, terms: 3)>>
 Non-/sparse entries: 292/14
 Sparsity           : 5%
 Maximal term length: 14
 Weighting          : term frequency (tf)
 Sample             :
                Terms
 Docs            adenocarcinoma grade prostatic
   Patient14.txt             11     6         3
   Patient15.txt              7    12         2
   Patient16.txt             13    16         4
   Patient19.txt              5    13         2
   Patient24.txt             11    12         4
   Patient25.txt              8     9         4
   Patient41.txt              8    10         4
   Patient46.txt              8    10         3
   Patient8.txt               9    12         2
   Patient9.txt               8    23         2


Thanks



Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri May 19 17:04:22 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 19 May 2017 08:04:22 -0700
Subject: [R] PROBLEM USING DICTIONARY WITH TM PACKAGE
In-Reply-To: <CY4PR06MB3032476172CB14231F83B789B9E50@CY4PR06MB3032.namprd06.prod.outlook.com>
References: <CY4PR06MB3032945BB7D2A0989FAF4ECCB9E70@CY4PR06MB3032.namprd06.prod.outlook.com>
 <CY4PR06MB3032476172CB14231F83B789B9E50@CY4PR06MB3032.namprd06.prod.outlook.com>
Message-ID: <E7DC530B-508F-47EA-8024-C06BC567FA86@dcn.davis.ca.us>

Considering the deafening silence after three repeats, one explanation could be that you are asking the wrong group of people. It is also possible that your failure to follow the Posting Guide with regard to using plain text email and a reproducible example [1][2] means that readers who are not experts do not feel inclined to follow along with you and help you think of solutions. Keep in mind that supporting  contributed packages like tm is technically not on topic here, though people often do feel the urge to help solve problems with them anyway.

With regard to asking the wrong group of people I would suggest asking the maintainer of the tm package what they recommend. See the help for the maintainer function or read the CRAN Web page for that package. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On May 19, 2017 7:12:45 AM PDT, Patrick Casimir <patrcasi at nova.edu> wrote:
>Dear Members & Experts,
>
>
>Since the Dictionary () function is no longer available with the tm
>package. How do I use other functions to do the same as below? I want
>to capture a list of specific terms from a corpus. By example, if my
>corpus has 102 files. I want to see a list with occurrences of
>prostatic, adenocarcinoma, grade in all 102 files. When I use the
>function Dictionary (), I got the error: Error: could not find function
>"Dictionary"
>
>
>> d <- Dictionary(c("prostatic", "adenocarcinoma", "grade"))
>> inspect(DocumentTermMatrix(docs, list(dictionary = d)))
>
>
>But if I use the codes below using inspect, the dictionary only returns
>the terms for 10 files instead of 102. I need a way to get my
>dictionary to capture and return those terms for all 102 files or
>whatever other terms I select. I know I am close but inspect () is not
>the right function.
>
>
>> myTerms <- c("prostatic", "adenocarcinoma", "grade")
>> inspect(DocumentTermMatrix(docs, list(dictionary = myTerms)))
>
> <<DocumentTermMatrix (documents: 102, terms: 3)>>
> Non-/sparse entries: 292/14
> Sparsity           : 5%
> Maximal term length: 14
> Weighting          : term frequency (tf)
> Sample             :
>                Terms
> Docs            adenocarcinoma grade prostatic
>   Patient14.txt             11     6         3
>   Patient15.txt              7    12         2
>   Patient16.txt             13    16         4
>   Patient19.txt              5    13         2
>   Patient24.txt             11    12         4
>   Patient25.txt              8     9         4
>   Patient41.txt              8    10         4
>   Patient46.txt              8    10         3
>   Patient8.txt               9    12         2
>   Patient9.txt               8    23         2
>
>
>Thanks
>
>
>
>Patrick Casimir, PhD
>Health Analytics, Data Science, Big Data Expert & Independent
>Consultant
>C: 954.614.1178
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From brigitte.mangin at inra.fr  Fri May 19 17:08:53 2017
From: brigitte.mangin at inra.fr (Brigitte Mangin)
Date: Fri, 19 May 2017 15:08:53 +0000
Subject: [R] mixed Model: asreml-r versus nmle,lme4 or coxme
In-Reply-To: <CAJuCY5zEusUBC9NWaR-23e3tFR6V0j-ODvVDcJTZ8exiEJWHmw@mail.gmail.com>
References: <1495197045517.38712@inra.fr>,
 <CAJuCY5zEusUBC9NWaR-23e3tFR6V0j-ODvVDcJTZ8exiEJWHmw@mail.gmail.com>
Message-ID: <1495206533515.35503@inra.fr>

Thank's  Thierry, but as i mentioned, it is not a constant depending only of the data, since with the same observed trait:


the difference (between asreml and R packages) is equal to 29.40 in the model with a fixed effect (Type)

and the difference is equal to 32.16 in the model with only mu.


And that, it is a big concern.


________________________________
De : Thierry Onkelinx <thierry.onkelinx at inbo.be>
Envoy? : vendredi 19 mai 2017 16:40
? : Brigitte Mangin
Cc : R-help at lists.R-project.org
Objet : Re: [R] mixed Model: asreml-r versus nmle,lme4 or coxme

Dear Brigitte,

Maybe because the log likelihood is calculated differently. Note that the log likelihood contains a constant which only depends on the data. So one can safely omit that part for model comparison, assuming that use you the same formula to calculate the likelihood for all models.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2017-05-19 14:30 GMT+02:00 Brigitte Mangin <brigitte.mangin at inra.fr<mailto:brigitte.mangin at inra.fr>>:



Hi,

Did somebody know why asreml does not provide the same REML loglikehood  as coxme, lme4 or lmne.
Here is a simple example showing the differences:


#######################################################################
library(lme4)
library(coxme)
library(asreml)
library(nlme)

data(ergoStool, package="nlme") # use a data set from nlme

fit1 <- lmekin(effort ~ Type+(1|Subject), data=ergoStool,method="REML")
fit1$loglik #-60.56539
fit2 <- lmer(effort ~ Type+(1|Subject), data=ergoStool,REML=TRUE)
logLik(fit2) #'log Lik.' -60.56539 (df=6)
fit3<-asreml(fixed=effort ~ Type,random=~Subject,data=ergoStool,
        na.method.X="omit",na.method.Y="omit")
fit3$loglik #-31.15936
fit4<-lme(effort ~ Type,random=~1|Subject, data = ergoStool,method="REML")
fit4$logLik  #-60.56539

fit1 <- lmekin(effort ~ (1|Subject), data=ergoStool,method="REML")
fit1$loglik #-78.91898
fit2 <- lmer(effort ~ (1|Subject), data=ergoStool,REML=TRUE)
logLik(fit2) #'log Lik.' -78.91898 (df=3)
fit3<-asreml(fixed=effort ~ 1,random=~Subject,data=ergoStool,
        na.method.X="omit",na.method.Y="omit")
fit3$loglik #-46.75614
fit4<-lme(effort ~ 1,random=~1|Subject, data = ergoStool,method="REML")
fit4$logLik #-78.91898


############################
If it was just a constant value between the two models (with or without the fixed effect) it would not be important. But it is not.
I checked that the variance component estimators were equal.

Thanks



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From patrcasi at nova.edu  Fri May 19 17:55:03 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Fri, 19 May 2017 15:55:03 +0000
Subject: [R] PROBLEM USING DICTIONARY WITH TM PACKAGE
In-Reply-To: <E7DC530B-508F-47EA-8024-C06BC567FA86@dcn.davis.ca.us>
References: <CY4PR06MB3032945BB7D2A0989FAF4ECCB9E70@CY4PR06MB3032.namprd06.prod.outlook.com>
 <CY4PR06MB3032476172CB14231F83B789B9E50@CY4PR06MB3032.namprd06.prod.outlook.com>,
 <E7DC530B-508F-47EA-8024-C06BC567FA86@dcn.davis.ca.us>
Message-ID: <CY4PR06MB3032CDD8FF0B5ED06FC220C7B9E50@CY4PR06MB3032.namprd06.prod.outlook.com>

Thanks Jeff. I will try elsewhere.


Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Friday, May 19, 2017 11:04:22 AM
To: r-help at r-project.org; Patrick Casimir; r-help at r-project.org
Subject: Re: [R] PROBLEM USING DICTIONARY WITH TM PACKAGE

Considering the deafening silence after three repeats, one explanation could be that you are asking the wrong group of people. It is also possible that your failure to follow the Posting Guide with regard to using plain text email and a reproducible example [1][2] means that readers who are not experts do not feel inclined to follow along with you and help you think of solutions. Keep in mind that supporting  contributed packages like tm is technically not on topic here, though people often do feel the urge to help solve problems with them anyway.

With regard to asking the wrong group of people I would suggest asking the maintainer of the tm package what they recommend. See the help for the maintainer function or read the CRAN Web page for that package.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html
--
Sent from my phone. Please excuse my brevity.

On May 19, 2017 7:12:45 AM PDT, Patrick Casimir <patrcasi at nova.edu> wrote:
>Dear Members & Experts,
>
>
>Since the Dictionary () function is no longer available with the tm
>package. How do I use other functions to do the same as below? I want
>to capture a list of specific terms from a corpus. By example, if my
>corpus has 102 files. I want to see a list with occurrences of
>prostatic, adenocarcinoma, grade in all 102 files. When I use the
>function Dictionary (), I got the error: Error: could not find function
>"Dictionary"
>
>
>> d <- Dictionary(c("prostatic", "adenocarcinoma", "grade"))
>> inspect(DocumentTermMatrix(docs, list(dictionary = d)))
>
>
>But if I use the codes below using inspect, the dictionary only returns
>the terms for 10 files instead of 102. I need a way to get my
>dictionary to capture and return those terms for all 102 files or
>whatever other terms I select. I know I am close but inspect () is not
>the right function.
>
>
>> myTerms <- c("prostatic", "adenocarcinoma", "grade")
>> inspect(DocumentTermMatrix(docs, list(dictionary = myTerms)))
>
> <<DocumentTermMatrix (documents: 102, terms: 3)>>
> Non-/sparse entries: 292/14
> Sparsity           : 5%
> Maximal term length: 14
> Weighting          : term frequency (tf)
> Sample             :
>                Terms
> Docs            adenocarcinoma grade prostatic
>   Patient14.txt             11     6         3
>   Patient15.txt              7    12         2
>   Patient16.txt             13    16         4
>   Patient19.txt              5    13         2
>   Patient24.txt             11    12         4
>   Patient25.txt              8     9         4
>   Patient41.txt              8    10         4
>   Patient46.txt              8    10         3
>   Patient8.txt               9    12         2
>   Patient9.txt               8    23         2
>
>
>Thanks
>
>
>
>Patrick Casimir, PhD
>Health Analytics, Data Science, Big Data Expert & Independent
>Consultant
>C: 954.614.1178
>
>
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri May 19 21:04:46 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 19 May 2017 12:04:46 -0700
Subject: [R] [FORGED] p-value=0 running log-rank test
In-Reply-To: <9e7a4a16-3692-323a-c33b-863c3f6b32a7@auckland.ac.nz>
References: <CAG5XtzV62K8P1bmHG+bWGW7CbmFzAkejXqJytHdeFrkeLyJpZA@mail.gmail.com>
 <9e7a4a16-3692-323a-c33b-863c3f6b32a7@auckland.ac.nz>
Message-ID: <CAF8bMcZQuoqrdBRkZCVTd8Xi8kQbFFiGHVhTZY9H3a2QZk_RjA@mail.gmail.com>

This is a minor problem with the print method for "survdiff" objects.  It
acts like it computes the p-value with
   1 - pchisq( chisq, df)
instead of
    pchisq( chisq, df, lower.tail = FALSE)
The former will give zero when the latter gives a number less than about
10^-16.

Most people would accept 0 instead of 10^-16, but the 6-sigma folks worry
about probabilities of 10^-10 so perhaps it is worth making the easy change.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, May 18, 2017 at 10:14 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> This is not an R question.
>
> Your question indicates that you really need to learn some statistics.
>
> To answer the very last part:
>
> > pchisq(430,3,lower=FALSE)
> [1] 7.020486e-93
>
> And if that is not 0 to all intents and purposes, then God help us all.
>
> cheers,
>
> Rolf Turner
>
> On 19/05/17 12:48, Anne Karin da Mota Borges wrote:
>
>> Dear all,
>>
>> I have a question concerning the p-value. When running log-rank test I get
>> a p-value = 0.
>> What is it mean? Can this be true? Why aren?t there decimal points? Is
>> there a way to find out the exact p-value?
>>
>> Here is the output:
>>
>> survdiff(Surv(tempo2,status)~tphist, data=base,rho=0)
>>>
>> Call:
>> survdiff(formula = Surv(tempo2, status) ~ tphist, data = base,
>>     rho = 0)
>>
>>            N Observed Expected (O-E)^2/E (O-E)^2/V
>> tphist=1 513       19   40.879    11.710  9.00e+01
>> tphist=2  49        4    3.892     0.003  3.27e-03
>> tphist=3  23        9    1.686    31.717  3.29e+01
>> tphist=4  18       15    0.543   385.172  3.91e+02
>>
>>  Chisq= 430  on 3 degrees of freedom, p= 0
>>
>> Thank you in advance.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From panugu at umc.edu  Fri May 19 17:04:19 2017
From: panugu at umc.edu (Pramod Anugu)
Date: Fri, 19 May 2017 15:04:19 +0000
Subject: [R] had non-zero exit status
Message-ID: <8B839D95395DCB40ABA7FF3C2E6E7380E935B400@NTExMbx8.ntummc.umsmed.edu>

Hi , When installing  a tidyr package. I get an error message to install rlang package and I try to install rlang I get
"installation of package 'rlang' had non-zero exit status"
Please advise.

Ran
install.packages("tidyr", dependencies=TRUE)

getting below error message. Please advise. R version 3.1.0
pic  -g -O2  -c splice.c -o splice.o
In file included from splice.c:2:
vector.h: In function 'namespace_rlang_sym':
vector.h:94: error: 'R_DoubleColonSymbol' undeclared (first use in this
function)
vector.h:94: error: (Each undeclared identifier is reported only once
vector.h:94: error: for each function it appears in.)
make: *** [splice.o] Error 1
ERROR: compilation failed for package 'rlang'
* removing '/usr/local/lib64/R/library/rlang'
ERROR: dependency 'rlang' is not available for package 'tibble'
* removing '/usr/local/lib64/R/library/tibble'
ERROR: dependencies 'tibble', 'dplyr' are not available for package 'tidyr'
* removing '/usr/local/lib64/R/library/tidyr'


Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri May 19 23:27:00 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 19 May 2017 14:27:00 -0700
Subject: [R] had non-zero exit status
In-Reply-To: <8B839D95395DCB40ABA7FF3C2E6E7380E935B400@NTExMbx8.ntummc.umsmed.edu>
References: <8B839D95395DCB40ABA7FF3C2E6E7380E935B400@NTExMbx8.ntummc.umsmed.edu>
Message-ID: <CAF8bMcYTd08hpignKPD6iu4N9yvf=cz_kwk274_pzeCgL4MznA@mail.gmail.com>

Try using a more recent version of R - 3.4.0 is the current version and
3.1.0 is considered pretty old now.  'R_DoubleColonSymbol' is in
RHOME/include/Rinternals.h in R-3.3.0 but not in R-2.15.0.  I don't know
exactly when it was added.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, May 19, 2017 at 8:04 AM, Pramod Anugu <panugu at umc.edu> wrote:

> Hi , When installing  a tidyr package. I get an error message to install
> rlang package and I try to install rlang I get
> "installation of package 'rlang' had non-zero exit status"
> Please advise.
>
> Ran
> install.packages("tidyr", dependencies=TRUE)
>
> getting below error message. Please advise. R version 3.1.0
> pic  -g -O2  -c splice.c -o splice.o
> In file included from splice.c:2:
> vector.h: In function 'namespace_rlang_sym':
> vector.h:94: error: 'R_DoubleColonSymbol' undeclared (first use in this
> function)
> vector.h:94: error: (Each undeclared identifier is reported only once
> vector.h:94: error: for each function it appears in.)
> make: *** [splice.o] Error 1
> ERROR: compilation failed for package 'rlang'
> * removing '/usr/local/lib64/R/library/rlang'
> ERROR: dependency 'rlang' is not available for package 'tibble'
> * removing '/usr/local/lib64/R/library/tibble'
> ERROR: dependencies 'tibble', 'dplyr' are not available for package 'tidyr'
> * removing '/usr/local/lib64/R/library/tidyr'
>
>
> Individuals who have received this information in error or are not
> authorized to receive it must promptly return or dispose of the information
> and notify the sender. Those individuals are hereby notified that they are
> strictly prohibited from reviewing, forwarding, printing, copying,
> distributing or using this information in any way.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From panugu at umc.edu  Fri May 19 23:35:42 2017
From: panugu at umc.edu (Pramod Anugu)
Date: Fri, 19 May 2017 21:35:42 +0000
Subject: [R] [EXTERNAL] Re:  had non-zero exit status
In-Reply-To: <CAF8bMcYTd08hpignKPD6iu4N9yvf=cz_kwk274_pzeCgL4MznA@mail.gmail.com>
References: <8B839D95395DCB40ABA7FF3C2E6E7380E935B400@NTExMbx8.ntummc.umsmed.edu>
 <CAF8bMcYTd08hpignKPD6iu4N9yvf=cz_kwk274_pzeCgL4MznA@mail.gmail.com>
Message-ID: <8B839D95395DCB40ABA7FF3C2E6E7380E935B6F5@NTExMbx8.ntummc.umsmed.edu>

I tried using latest R-3-4.0. ./configure works but when I type make it does not work.

From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Friday, May 19, 2017 4:27 PM
To: Pramod Anugu <panugu at umc.edu>
Cc: r-help at R-project.org
Subject: [EXTERNAL] Re: [R] had non-zero exit status

Try using a more recent version of R - 3.4.0 is the current version and 3.1.0 is considered pretty old now.  'R_DoubleColonSymbol' is in RHOME/include/Rinternals.h in R-3.3.0 but not in R-2.15.0.  I don't know exactly when it was added.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<https://urldefense.proofpoint.com/v2/url?u=http-3A__tibco.com&d=DwMFaQ&c=lsRuZCBl6GuC9L6xVrEM6HFPHJkrlPlfLCjYs_lBYHk&r=RkX_7DVQKw_SdHQgHKW4xg&m=jdBKjUPvPl4OLs-0aOMw2PLfO4j_Bs04zdaFLxzGrhQ&s=GJP322e-U0soatwOliNzjC-jdEiVcSB2yp2nfYzwgdg&e=>

On Fri, May 19, 2017 at 8:04 AM, Pramod Anugu <panugu at umc.edu<mailto:panugu at umc.edu>> wrote:
Hi , When installing  a tidyr package. I get an error message to install rlang package and I try to install rlang I get
"installation of package 'rlang' had non-zero exit status"
Please advise.

Ran
install.packages("tidyr", dependencies=TRUE)

getting below error message. Please advise. R version 3.1.0
pic  -g -O2  -c splice.c -o splice.o
In file included from splice.c:2:
vector.h: In function 'namespace_rlang_sym':
vector.h:94: error: 'R_DoubleColonSymbol' undeclared (first use in this
function)
vector.h:94: error: (Each undeclared identifier is reported only once
vector.h:94: error: for each function it appears in.)
make: *** [splice.o] Error 1
ERROR: compilation failed for package 'rlang'
* removing '/usr/local/lib64/R/library/rlang'
ERROR: dependency 'rlang' is not available for package 'tibble'
* removing '/usr/local/lib64/R/library/tibble'
ERROR: dependencies 'tibble', 'dplyr' are not available for package 'tidyr'
* removing '/usr/local/lib64/R/library/tidyr'


Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=lsRuZCBl6GuC9L6xVrEM6HFPHJkrlPlfLCjYs_lBYHk&r=RkX_7DVQKw_SdHQgHKW4xg&m=jdBKjUPvPl4OLs-0aOMw2PLfO4j_Bs04zdaFLxzGrhQ&s=cb8NqG0f_gqytjWBftBanyXIl8kcqkgsmbn9XsFITCE&e=>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=lsRuZCBl6GuC9L6xVrEM6HFPHJkrlPlfLCjYs_lBYHk&r=RkX_7DVQKw_SdHQgHKW4xg&m=jdBKjUPvPl4OLs-0aOMw2PLfO4j_Bs04zdaFLxzGrhQ&s=uFLe9NLBOwarcpWK5orcEnnmwyYHDgfeGRMPOvVRY5E&e=>
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Sat May 20 01:56:18 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Fri, 19 May 2017 23:56:18 +0000 (UTC)
Subject: [R] train function in caret package
In-Reply-To: <667543577.1989752.1495179558848@mail.yahoo.com>
References: <667543577.1989752.1495179558848.ref@mail.yahoo.com>
 <667543577.1989752.1495179558848@mail.yahoo.com>
Message-ID: <1610360333.3180726.1495238178311@mail.yahoo.com>

Any answer?! 

    On Friday, May 19, 2017 6:33 AM, Elahe chalabi via R-help <r-help at r-project.org> wrote:
 

 Hi all,

I'm running train function from caret package on my data set patientdata:

? ? model=train(type~., data=patientdata, method="lvq", preProcess="scale", trControl=control)
and I get this error:

? ? Error in comp(expr, env = envir, options = list(suppressUndefined = TRUE)) : 

? ? could not find function "mayCallBrowser"
Does anyone know how should I solve it?!

Thanks for any help!
Elahe

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From ramnik.bansal at gmail.com  Sat May 20 05:22:55 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Sat, 20 May 2017 08:52:55 +0530
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <1495200421.6068.11.camel@deb2.fort.knox.uk>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
 <1495200421.6068.11.camel@deb2.fort.knox.uk>
Message-ID: <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>

Taking this question further.

If I use a complex number or a numeric as an operand in logical
operations, to me it APPEARS that these two types are first coerced to
LOGICAL internally and then THIS logical output is further used as the
operand.

For eg.
> x <- 4+5i; c(x & F, x & T, x | F, x | T)
[1] FALSE  TRUE  TRUE  TRUE

This output is consistent with
> x <- 4+5i; c(as.logical(x) & F, as.logical(x) & T, as.logical(x) | F, as.logical(x) | T)
[1] FALSE  TRUE  TRUE  TRUE

This consistency makes me draw an on-the-surface conclusion that in
the case of logical operations if the operand is not of type 'logical'
it is first coerced into 'logical'.

But this doesn't seem to be true because if that was the case it
should have worked with character operands as well, albeit following
the rules of NA in logical operations ( as per R help manual)

For e.g.
> x <- "abc"; c(as.logical(x) & F, as.logical(x) & T, as.logical(x) | F, as.logical(x) | T)
[1] FALSE    NA    NA  TRUE

Whereas
> x <- "abc"; c(x & F, x & T, x | F, x | T)
Error in x & F :
  operations are possible only for numeric, logical or complex types

So my question basically is :
What does R actually do in the case of complex numbers Vs characters
as operands in logical operations ?

And adding some more:

consistent with above behavior with character,
> NA_character_ & FALSE
Error in NA_character_ & FALSE :
  operations are possible only for numeric, logical or complex types

R documentation on the other hand mentions:
Logical computations treat NA as a missing TRUE/FALSE value and so may
return TRUE or FALSE if the expression does not depend on the NA
operand.

Isn't NA mentioned in the R documentation to be interpreted as NA
irrespective of the type? Else, shouldn't the R documentation mention
"Logical computations treat NA except NA_character_ as a missing..."


Thanks,
Ramnik

ps: I hope I have phrased my question well enough this time not to end
up inviting the wrath of some R-Gods around on a mere R-mortal that I
am at this stage :) The more am becoming familiar with R, the more am
loving it and definitely don't intend to offend R Gods!

On Fri, May 19, 2017 at 6:57 PM, Ted Harding <ted.harding at wlandres.net> wrote:
> [I unadvertently sent my reply below to Jeremie, instead of R-help.
> Also, I havve had an additional thought which may clarify things
> for R users].
> [Original reply]:
> The point about this is that (as Rolf wrote) FALSE & (anything)
> is FALSE, provided logical NA is either TRUE ot FALSE but,
> because the "NA" says that it is not known which it is,
> it could be "anything". And, indeed, if "NA" is given the
> "missing" meaning and if we assume that a missing logical value
> did indeed have a value (necessarily either TRUE or FALSE),
> then it follows logically that FALSE & NA = FALS?.
>
> On the other hand, if with the "missing" interpretation of "NA"
> we don't even know that it is a logical, then it might be fair
> enough to say FALSE & NA = NA.
> Ted.
>
> [Additional thought]:
> Testing to see what would happen if the NA were not loigical,
> I put myself (not being logical ... ) on the line, facing up to R:
>    X <- "Ted"
>    FALSE & X
>    Error in FALSE & X :
>    operations are possible only for numeric, logical or complex types
> So R will refuse to deal with any variable which cannot partake in
> a logical expression.
>
> Ted.
>
> On Fri, 2017-05-19 at 14:24 +0200, J?r?mie Juste wrote:
>> My apologies if I was not clear enough,
>>
>> TRUE & NA could be either TRUE or FALSE and consequently is NA.
>> why is   FALSE & NA = FALSE?  NA could be TRUE or FALSE, so FALSE & NA
>> should be NA?
>>
>>
>> On Fri, May 19, 2017 at 2:13 PM, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>
>> > On 20/05/17 00:01, J?r?mie Juste wrote:
>> >
>> >> Hello,
>> >>
>> >> Rolf said,
>> >>
>> >> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
>> >> either TRUE or FALSE and consequently is NA.
>> >>
>> >> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>> >>
>> >>
>> >> According to this logic why is
>> >>
>> >>     FALSE & NA
>> >>
>> >> [1] FALSE
>> >>
>> >
>> > Huh????
>> >
>> >
>> > cheers,
>> >
>> > Rolf Turner
>> >
>> > --
>> > Technical Editor ANZJS
>> > Department of Statistics
>> > University of Auckland
>> > Phone: +64-9-373-7599 ext. 88276
>> >
>>
>>
>>
>> --
>> J?r?mie Juste
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Sat May 20 11:53:26 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 20 May 2017 11:53:26 +0200
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
 <1495200421.6068.11.camel@deb2.fort.knox.uk>
 <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>
Message-ID: <22816.4630.997046.99474@stat.math.ethz.ch>

>>>>> Ramnik Bansal <ramnik.bansal at gmail.com>
>>>>>     on Sat, 20 May 2017 08:52:55 +0530 writes:

    > Taking this question further.
    > If I use a complex number or a numeric as an operand in logical
    > operations, to me it APPEARS that these two types are first coerced to
    > LOGICAL internally and then THIS logical output is further used as the
    > operand.

    > For eg.
    >> x <- 4+5i; c(x & F, x & T, x | F, x | T)
    > [1] FALSE  TRUE  TRUE  TRUE

    > This output is consistent with
    >> x <- 4+5i; c(as.logical(x) & F, as.logical(x) & T, as.logical(x) | F, as.logical(x) | T)
    > [1] FALSE  TRUE  TRUE  TRUE

    > This consistency makes me draw an on-the-surface conclusion that in
    > the case of logical operations if the operand is not of type 'logical'
    > it is first coerced into 'logical'.

That conclusion is wrong as you show below.
Rather, as the error message says,
logical
	"operations are possible only for numeric, logical or complex types"

Again:

1) Logical/Arithmetic  operations "work" with "numeric-like" types, namely
  numeric, logical or complex, (and numeric = {integer, double})

  ==> all other types give an error (the one you've cited twice)

2) For "numeric-like" types and *logical* operations (&, |, !; plus && and ||)
   the equivalent of as.logical() is applied before performing the Op.
   
Seems pretty consistent ...
and also according to the principle of "least surprise" (for me at least).


From murdoch.duncan at gmail.com  Sat May 20 12:18:53 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 20 May 2017 06:18:53 -0400
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <22816.4630.997046.99474@stat.math.ethz.ch>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
 <1495200421.6068.11.camel@deb2.fort.knox.uk>
 <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>
 <22816.4630.997046.99474@stat.math.ethz.ch>
Message-ID: <4a740d12-f643-8003-1c51-49fa452c26c8@gmail.com>

On 20/05/2017 5:53 AM, Martin Maechler wrote:
>>>>>> Ramnik Bansal <ramnik.bansal at gmail.com>
>>>>>>     on Sat, 20 May 2017 08:52:55 +0530 writes:
>
>     > Taking this question further.
>     > If I use a complex number or a numeric as an operand in logical
>     > operations, to me it APPEARS that these two types are first coerced to
>     > LOGICAL internally and then THIS logical output is further used as the
>     > operand.
>
>     > For eg.
>     >> x <- 4+5i; c(x & F, x & T, x | F, x | T)
>     > [1] FALSE  TRUE  TRUE  TRUE
>
>     > This output is consistent with
>     >> x <- 4+5i; c(as.logical(x) & F, as.logical(x) & T, as.logical(x) | F, as.logical(x) | T)
>     > [1] FALSE  TRUE  TRUE  TRUE
>
>     > This consistency makes me draw an on-the-surface conclusion that in
>     > the case of logical operations if the operand is not of type 'logical'
>     > it is first coerced into 'logical'.
>
> That conclusion is wrong as you show below.
> Rather, as the error message says,
> logical
> 	"operations are possible only for numeric, logical or complex types"
>
> Again:
>
> 1) Logical/Arithmetic  operations "work" with "numeric-like" types, namely
>   numeric, logical or complex, (and numeric = {integer, double})
>
>   ==> all other types give an error (the one you've cited twice)
>
> 2) For "numeric-like" types and *logical* operations (&, |, !; plus && and ||)
>    the equivalent of as.logical() is applied before performing the Op.
>
> Seems pretty consistent ...
> and also according to the principle of "least surprise" (for me at least).
>

The surprise is that as.logical("TRUE") returns TRUE, whereas automatic 
coercion doesn't apply to character strings.  I don't think we should 
change this, but it is an inconsistency.  (We could perhaps mention it 
in the ?logical help page.)

Duncan Murdoch

Duncan Murdoch


From r.turner at auckland.ac.nz  Sat May 20 12:39:10 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 20 May 2017 22:39:10 +1200
Subject: [R] [FORGED] Re: [FORGED] Logical Operators' inconsistent
 Behavior
In-Reply-To: <4a740d12-f643-8003-1c51-49fa452c26c8@gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
 <1495200421.6068.11.camel@deb2.fort.knox.uk>
 <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>
 <22816.4630.997046.99474@stat.math.ethz.ch>
 <4a740d12-f643-8003-1c51-49fa452c26c8@gmail.com>
Message-ID: <70e48256-6b44-093b-a834-a0fcb9150d50@auckland.ac.nz>

On 20/05/17 22:18, Duncan Murdoch wrote:
> On 20/05/2017 5:53 AM, Martin Maechler wrote:
>>>>>>> Ramnik Bansal <ramnik.bansal at gmail.com>
>>>>>>>     on Sat, 20 May 2017 08:52:55 +0530 writes:
>>
>>     > Taking this question further.
>>     > If I use a complex number or a numeric as an operand in logical
>>     > operations, to me it APPEARS that these two types are first
>> coerced to
>>     > LOGICAL internally and then THIS logical output is further used
>> as the
>>     > operand.
>>
>>     > For eg.
>>     >> x <- 4+5i; c(x & F, x & T, x | F, x | T)
>>     > [1] FALSE  TRUE  TRUE  TRUE
>>
>>     > This output is consistent with
>>     >> x <- 4+5i; c(as.logical(x) & F, as.logical(x) & T,
>> as.logical(x) | F, as.logical(x) | T)
>>     > [1] FALSE  TRUE  TRUE  TRUE
>>
>>     > This consistency makes me draw an on-the-surface conclusion that in
>>     > the case of logical operations if the operand is not of type
>> 'logical'
>>     > it is first coerced into 'logical'.
>>
>> That conclusion is wrong as you show below.
>> Rather, as the error message says,
>> logical
>>     "operations are possible only for numeric, logical or complex types"
>>
>> Again:
>>
>> 1) Logical/Arithmetic  operations "work" with "numeric-like" types,
>> namely
>>   numeric, logical or complex, (and numeric = {integer, double})
>>
>>   ==> all other types give an error (the one you've cited twice)
>>
>> 2) For "numeric-like" types and *logical* operations (&, |, !; plus &&
>> and ||)
>>    the equivalent of as.logical() is applied before performing the Op.
>>
>> Seems pretty consistent ...
>> and also according to the principle of "least surprise" (for me at
>> least).
>>
>
> The surprise is that as.logical("TRUE") returns TRUE, whereas automatic
> coercion doesn't apply to character strings.  I don't think we should
> change this, but it is an inconsistency.  (We could perhaps mention it
> in the ?logical help page.)


Actually it *is* mentioned.  From ?logical:

> Character strings c("T", "TRUE", "True", "true") are regarded as
> true,  c("F", "FALSE", "False", "false") as false, and all others as NA.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch.duncan at gmail.com  Sat May 20 12:42:36 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 20 May 2017 06:42:36 -0400
Subject: [R] [FORGED] Re: [FORGED] Logical Operators' inconsistent
 Behavior
In-Reply-To: <70e48256-6b44-093b-a834-a0fcb9150d50@auckland.ac.nz>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
 <1495200421.6068.11.camel@deb2.fort.knox.uk>
 <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>
 <22816.4630.997046.99474@stat.math.ethz.ch>
 <4a740d12-f643-8003-1c51-49fa452c26c8@gmail.com>
 <70e48256-6b44-093b-a834-a0fcb9150d50@auckland.ac.nz>
Message-ID: <043c4596-b097-4e78-79ae-ebbe3a4a6f4a@gmail.com>

On 20/05/2017 6:39 AM, Rolf Turner wrote:
> On 20/05/17 22:18, Duncan Murdoch wrote:
>> On 20/05/2017 5:53 AM, Martin Maechler wrote:
>>>>>>>> Ramnik Bansal <ramnik.bansal at gmail.com>
>>>>>>>>     on Sat, 20 May 2017 08:52:55 +0530 writes:
>>>
>>>     > Taking this question further.
>>>     > If I use a complex number or a numeric as an operand in logical
>>>     > operations, to me it APPEARS that these two types are first
>>> coerced to
>>>     > LOGICAL internally and then THIS logical output is further used
>>> as the
>>>     > operand.
>>>
>>>     > For eg.
>>>     >> x <- 4+5i; c(x & F, x & T, x | F, x | T)
>>>     > [1] FALSE  TRUE  TRUE  TRUE
>>>
>>>     > This output is consistent with
>>>     >> x <- 4+5i; c(as.logical(x) & F, as.logical(x) & T,
>>> as.logical(x) | F, as.logical(x) | T)
>>>     > [1] FALSE  TRUE  TRUE  TRUE
>>>
>>>     > This consistency makes me draw an on-the-surface conclusion that in
>>>     > the case of logical operations if the operand is not of type
>>> 'logical'
>>>     > it is first coerced into 'logical'.
>>>
>>> That conclusion is wrong as you show below.
>>> Rather, as the error message says,
>>> logical
>>>     "operations are possible only for numeric, logical or complex types"
>>>
>>> Again:
>>>
>>> 1) Logical/Arithmetic  operations "work" with "numeric-like" types,
>>> namely
>>>   numeric, logical or complex, (and numeric = {integer, double})
>>>
>>>   ==> all other types give an error (the one you've cited twice)
>>>
>>> 2) For "numeric-like" types and *logical* operations (&, |, !; plus &&
>>> and ||)
>>>    the equivalent of as.logical() is applied before performing the Op.
>>>
>>> Seems pretty consistent ...
>>> and also according to the principle of "least surprise" (for me at
>>> least).
>>>
>>
>> The surprise is that as.logical("TRUE") returns TRUE, whereas automatic
>> coercion doesn't apply to character strings.  I don't think we should
>> change this, but it is an inconsistency.  (We could perhaps mention it
>> in the ?logical help page.)
>
>
> Actually it *is* mentioned.  From ?logical:
>
>> Character strings c("T", "TRUE", "True", "true") are regarded as
>> true,  c("F", "FALSE", "False", "false") as false, and all others as NA.
>

I meant that the negative part should be mentioned:  this only works 
with an explicit as.logical(), not with implicit coercion.

Duncan Murdoch


From r.turner at auckland.ac.nz  Sat May 20 12:45:03 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 20 May 2017 22:45:03 +1200
Subject: [R] [FORGED] Re: [FORGED] Logical Operators' inconsistent
 Behavior
In-Reply-To: <043c4596-b097-4e78-79ae-ebbe3a4a6f4a@gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
 <1495200421.6068.11.camel@deb2.fort.knox.uk>
 <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>
 <22816.4630.997046.99474@stat.math.ethz.ch>
 <4a740d12-f643-8003-1c51-49fa452c26c8@gmail.com>
 <70e48256-6b44-093b-a834-a0fcb9150d50@auckland.ac.nz>
 <043c4596-b097-4e78-79ae-ebbe3a4a6f4a@gmail.com>
Message-ID: <2058867e-4229-4f12-e46a-7c807133a856@auckland.ac.nz>

On 20/05/17 22:42, Duncan Murdoch wrote:
> On 20/05/2017 6:39 AM, Rolf Turner wrote:
>> On 20/05/17 22:18, Duncan Murdoch wrote:
>>> On 20/05/2017 5:53 AM, Martin Maechler wrote:
>>>>>>>>> Ramnik Bansal <ramnik.bansal at gmail.com>
>>>>>>>>>     on Sat, 20 May 2017 08:52:55 +0530 writes:
>>>>
>>>>     > Taking this question further.
>>>>     > If I use a complex number or a numeric as an operand in logical
>>>>     > operations, to me it APPEARS that these two types are first
>>>> coerced to
>>>>     > LOGICAL internally and then THIS logical output is further used
>>>> as the
>>>>     > operand.
>>>>
>>>>     > For eg.
>>>>     >> x <- 4+5i; c(x & F, x & T, x | F, x | T)
>>>>     > [1] FALSE  TRUE  TRUE  TRUE
>>>>
>>>>     > This output is consistent with
>>>>     >> x <- 4+5i; c(as.logical(x) & F, as.logical(x) & T,
>>>> as.logical(x) | F, as.logical(x) | T)
>>>>     > [1] FALSE  TRUE  TRUE  TRUE
>>>>
>>>>     > This consistency makes me draw an on-the-surface conclusion
>>>> that in
>>>>     > the case of logical operations if the operand is not of type
>>>> 'logical'
>>>>     > it is first coerced into 'logical'.
>>>>
>>>> That conclusion is wrong as you show below.
>>>> Rather, as the error message says,
>>>> logical
>>>>     "operations are possible only for numeric, logical or complex
>>>> types"
>>>>
>>>> Again:
>>>>
>>>> 1) Logical/Arithmetic  operations "work" with "numeric-like" types,
>>>> namely
>>>>   numeric, logical or complex, (and numeric = {integer, double})
>>>>
>>>>   ==> all other types give an error (the one you've cited twice)
>>>>
>>>> 2) For "numeric-like" types and *logical* operations (&, |, !; plus &&
>>>> and ||)
>>>>    the equivalent of as.logical() is applied before performing the Op.
>>>>
>>>> Seems pretty consistent ...
>>>> and also according to the principle of "least surprise" (for me at
>>>> least).
>>>>
>>>
>>> The surprise is that as.logical("TRUE") returns TRUE, whereas automatic
>>> coercion doesn't apply to character strings.  I don't think we should
>>> change this, but it is an inconsistency.  (We could perhaps mention it
>>> in the ?logical help page.)
>>
>>
>> Actually it *is* mentioned.  From ?logical:
>>
>>> Character strings c("T", "TRUE", "True", "true") are regarded as
>>> true,  c("F", "FALSE", "False", "false") as false, and all others as NA.
>>
>
> I meant that the negative part should be mentioned:  this only works
> with an explicit as.logical(), not with implicit coercion.

Ah, I see.  I missed the point.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From patrcasi at nova.edu  Sat May 20 20:18:32 2017
From: patrcasi at nova.edu (Patrick Casimir)
Date: Sat, 20 May 2017 18:18:32 +0000
Subject: [R] PROBLEM USING DICTIONARY WITH TM PACKAGE
In-Reply-To: <E7DC530B-508F-47EA-8024-C06BC567FA86@dcn.davis.ca.us>
References: <CY4PR06MB3032945BB7D2A0989FAF4ECCB9E70@CY4PR06MB3032.namprd06.prod.outlook.com>
 <CY4PR06MB3032476172CB14231F83B789B9E50@CY4PR06MB3032.namprd06.prod.outlook.com>,
 <E7DC530B-508F-47EA-8024-C06BC567FA86@dcn.davis.ca.us>
Message-ID: <CY4PR06MB3032161A72A5E48D0677009EB9FA0@CY4PR06MB3032.namprd06.prod.outlook.com>

Jeff,


Here is the solution:


myTerms <- c("prostatic", "adenocarcinoma", "grade")
inspect(DocumentTermMatrix(docs, list(dictionary = myTerms)))  ## only returns from first 10 docs in DTM
as.matrix(DocumentTermMatrix(docs, list(dictionary = myTerms)))  ## returns from all docs in the DTM



Patrick Casimir, PhD
Health Analytics, Data Science, Big Data Expert & Independent Consultant
C: 954.614.1178

________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Friday, May 19, 2017 11:04:22 AM
To: r-help at r-project.org; Patrick Casimir; r-help at r-project.org
Subject: Re: [R] PROBLEM USING DICTIONARY WITH TM PACKAGE

Considering the deafening silence after three repeats, one explanation could be that you are asking the wrong group of people. It is also possible that your failure to follow the Posting Guide with regard to using plain text email and a reproducible example [1][2] means that readers who are not experts do not feel inclined to follow along with you and help you think of solutions. Keep in mind that supporting  contributed packages like tm is technically not on topic here, though people often do feel the urge to help solve problems with them anyway.

With regard to asking the wrong group of people I would suggest asking the maintainer of the tm package what they recommend. See the help for the maintainer function or read the CRAN Web page for that package.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html
--
Sent from my phone. Please excuse my brevity.

On May 19, 2017 7:12:45 AM PDT, Patrick Casimir <patrcasi at nova.edu> wrote:
>Dear Members & Experts,
>
>
>Since the Dictionary () function is no longer available with the tm
>package. How do I use other functions to do the same as below? I want
>to capture a list of specific terms from a corpus. By example, if my
>corpus has 102 files. I want to see a list with occurrences of
>prostatic, adenocarcinoma, grade in all 102 files. When I use the
>function Dictionary (), I got the error: Error: could not find function
>"Dictionary"
>
>
>> d <- Dictionary(c("prostatic", "adenocarcinoma", "grade"))
>> inspect(DocumentTermMatrix(docs, list(dictionary = d)))
>
>
>But if I use the codes below using inspect, the dictionary only returns
>the terms for 10 files instead of 102. I need a way to get my
>dictionary to capture and return those terms for all 102 files or
>whatever other terms I select. I know I am close but inspect () is not
>the right function.
>
>
>> myTerms <- c("prostatic", "adenocarcinoma", "grade")
>> inspect(DocumentTermMatrix(docs, list(dictionary = myTerms)))
>
> <<DocumentTermMatrix (documents: 102, terms: 3)>>
> Non-/sparse entries: 292/14
> Sparsity           : 5%
> Maximal term length: 14
> Weighting          : term frequency (tf)
> Sample             :
>                Terms
> Docs            adenocarcinoma grade prostatic
>   Patient14.txt             11     6         3
>   Patient15.txt              7    12         2
>   Patient16.txt             13    16         4
>   Patient19.txt              5    13         2
>   Patient24.txt             11    12         4
>   Patient25.txt              8     9         4
>   Patient41.txt              8    10         4
>   Patient46.txt              8    10         3
>   Patient8.txt               9    12         2
>   Patient9.txt               8    23         2
>
>
>Thanks
>
>
>
>Patrick Casimir, PhD
>Health Analytics, Data Science, Big Data Expert & Independent
>Consultant
>C: 954.614.1178
>
>
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sat May 20 20:23:07 2017
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sat, 20 May 2017 23:53:07 +0530
Subject: [R] Matching values between 2 data.frame.
Message-ID: <CA+dpOJ=TSjZE+cr9WikM9vd=FAg8P5YU2qmCbhLeWoQ0YqotcA@mail.gmail.com>

Hi again,

Let say I have below 2 data frames.

OriginalData = data.frame('Value1' = 1:12, 'Value2' = 11:22, 'AA1' =
c('AA4', 'AA3', 'AA4', 'AA1', 'AA2', 'AA1', 'AA6', 'AA6', 'AA3',
'AA3', 'AA4', 'AA3'), 'Value' = NA)

TargetValue = data.frame('AA' = c('AA1', 'AA2', 'AA3', 'AA4', 'AA5',
'AA6'), 'BB' = c('B', 'B', 'B', 'B', 'CC', 'CC'), 'Value' = c(5, 10,
25, 7, 35, 21))

OriginalData
TargetValue

Now I need to replace OriginalData's 'AA1' column with TargetValue's
'BB' column, based on matched values between 'AA1' & 'AA' columns of
OriginalData & TargetValue respectively. With this same law, I need to
update 'Value' column of  OriginalData with that of TargetValue.

As an example, after replacement by above rule, 1st row of
OriginalData should look like :

> OriginalData

   Value1 Value2 AA1 Value

1       1     11 B    7

Values of TargetValue's 'AA' column are unique i.e. no duplication

Previously I have implemented a 'for' loop to implement above, however
since both of my data.frames are quite big, it is taking long time to
execute. Is there any 'R' way to implement this quickly.

Appreciate for any pointer.

Thanks,


From dwinsemius at comcast.net  Sat May 20 20:53:45 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 20 May 2017 11:53:45 -0700
Subject: [R] Matching values between 2 data.frame.
In-Reply-To: <CA+dpOJ=TSjZE+cr9WikM9vd=FAg8P5YU2qmCbhLeWoQ0YqotcA@mail.gmail.com>
References: <CA+dpOJ=TSjZE+cr9WikM9vd=FAg8P5YU2qmCbhLeWoQ0YqotcA@mail.gmail.com>
Message-ID: <7FD21F33-DE89-437F-89C0-7A646755D790@comcast.net>


> On May 20, 2017, at 11:23 AM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 
> Hi again,
> 
> Let say I have below 2 data frames.
> 
> OriginalData = data.frame('Value1' = 1:12, 'Value2' = 11:22, 'AA1' =
> c('AA4', 'AA3', 'AA4', 'AA1', 'AA2', 'AA1', 'AA6', 'AA6', 'AA3',
> 'AA3', 'AA4', 'AA3'), 'Value' = NA)
> 
> TargetValue = data.frame('AA' = c('AA1', 'AA2', 'AA3', 'AA4', 'AA5',
> 'AA6'), 'BB' = c('B', 'B', 'B', 'B', 'CC', 'CC'), 'Value' = c(5, 10,
> 25, 7, 35, 21))
> 
> OriginalData
> TargetValue
> 
> Now I need to replace OriginalData's 'AA1' column with TargetValue's
> 'BB' column, based on matched values between 'AA1' & 'AA' columns of
> OriginalData & TargetValue respectively. With this same law, I need to
> update 'Value' column of  OriginalData with that of TargetValue.
> 
> As an example, after replacement by above rule, 1st row of
> OriginalData should look like :
> 
>> OriginalData
> 
>   Value1 Value2 AA1 Value
> 
> 1       1     11 B    7
> 
> Values of TargetValue's 'AA' column are unique i.e. no duplication
> 
> Previously I have implemented a 'for' loop to implement above, however
> since both of my data.frames are quite big, it is taking long time to
> execute. Is there any 'R' way to implement this quickly.
> 
> Appreciate for any pointer.

It's going to have a greater chance of delivering the desired result if you convert the factor columns into character.

> 
> Thanks,
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sat May 20 22:13:37 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 20 May 2017 13:13:37 -0700
Subject: [R] Matching values between 2 data.frame.
In-Reply-To: <7FD21F33-DE89-437F-89C0-7A646755D790@comcast.net>
References: <CA+dpOJ=TSjZE+cr9WikM9vd=FAg8P5YU2qmCbhLeWoQ0YqotcA@mail.gmail.com>
 <7FD21F33-DE89-437F-89C0-7A646755D790@comcast.net>
Message-ID: <CAGxFJbQPvx8REfOh8-UCJg2WzrXCaj8nVOdBYD0z7yToSpCrZw@mail.gmail.com>

Like this?  (use indexing to avoid explicit loops whenever possible):

## first convert factor columns to character, as David W. suggested
i <- sapply(od,is.factor)
od[i]<- lapply(od[i],as.character)
i <- sapply(tv, is.factor)
tv[i]<- lapply(tv[i],as.character)


## Now use ?match
wh  <-   match(od[,"AA1"], tv[,"AA"])
matched <- !is.na(wh)  ## only needed if not all AA1's match in AA
od[matched,c("AA1", "Value")] <- tv[wh[matched],c("BB","Value")]

> od
   Value1 Value2 AA1 Value
1       1     11   B     7
2       2     12   B    25
3       3     13   B     7
4       4     14   B     5
5       5     15   B    10
6       6     16   B     5
7       7     17  CC    21
8       8     18  CC    21
9       9     19   B    25
10     10     20   B    25
11     11     21   B     7
12     12     22   B    25


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 20, 2017 at 11:53 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
>> On May 20, 2017, at 11:23 AM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>
>> Hi again,
>>
>> Let say I have below 2 data frames.
>>
>> OriginalData = data.frame('Value1' = 1:12, 'Value2' = 11:22, 'AA1' =
>> c('AA4', 'AA3', 'AA4', 'AA1', 'AA2', 'AA1', 'AA6', 'AA6', 'AA3',
>> 'AA3', 'AA4', 'AA3'), 'Value' = NA)
>>
>> TargetValue = data.frame('AA' = c('AA1', 'AA2', 'AA3', 'AA4', 'AA5',
>> 'AA6'), 'BB' = c('B', 'B', 'B', 'B', 'CC', 'CC'), 'Value' = c(5, 10,
>> 25, 7, 35, 21))
>>
>> OriginalData
>> TargetValue
>>
>> Now I need to replace OriginalData's 'AA1' column with TargetValue's
>> 'BB' column, based on matched values between 'AA1' & 'AA' columns of
>> OriginalData & TargetValue respectively. With this same law, I need to
>> update 'Value' column of  OriginalData with that of TargetValue.
>>
>> As an example, after replacement by above rule, 1st row of
>> OriginalData should look like :
>>
>>> OriginalData
>>
>>   Value1 Value2 AA1 Value
>>
>> 1       1     11 B    7
>>
>> Values of TargetValue's 'AA' column are unique i.e. no duplication
>>
>> Previously I have implemented a 'for' loop to implement above, however
>> since both of my data.frames are quite big, it is taking long time to
>> execute. Is there any 'R' way to implement this quickly.
>>
>> Appreciate for any pointer.
>
> It's going to have a greater chance of delivering the desired result if you convert the factor columns into character.
>
>>
>> Thanks,
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat May 20 22:54:34 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 20 May 2017 13:54:34 -0700
Subject: [R] Matching values between 2 data.frame.
In-Reply-To: <CAGxFJbQPvx8REfOh8-UCJg2WzrXCaj8nVOdBYD0z7yToSpCrZw@mail.gmail.com>
References: <CA+dpOJ=TSjZE+cr9WikM9vd=FAg8P5YU2qmCbhLeWoQ0YqotcA@mail.gmail.com>
 <7FD21F33-DE89-437F-89C0-7A646755D790@comcast.net>
 <CAGxFJbQPvx8REfOh8-UCJg2WzrXCaj8nVOdBYD0z7yToSpCrZw@mail.gmail.com>
Message-ID: <CAF8bMcZmh3EBeUA-Sdub+br2ByMVn8aBPx3-y9S2oye20hVYJQ@mail.gmail.com>

merge() may be useful here:

> merge(OriginalData[1:3], TargetValue, by.x="AA1", by.y="AA",
sort=FALSE)[-1]
   Value1 Value2 BB Value
1       1     11  B     7
2       3     13  B     7
3      11     21  B     7
4       2     12  B    25
5      12     22  B    25
6       9     19  B    25
7      10     20  B    25
8       4     14  B     5
9       6     16  B     5
10      5     15  B    10
11      7     17 CC    21
12      8     18 CC    21

Rename the columns as desired.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, May 20, 2017 at 1:13 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Like this?  (use indexing to avoid explicit loops whenever possible):
>
> ## first convert factor columns to character, as David W. suggested
> i <- sapply(od,is.factor)
> od[i]<- lapply(od[i],as.character)
> i <- sapply(tv, is.factor)
> tv[i]<- lapply(tv[i],as.character)
>
>
> ## Now use ?match
> wh  <-   match(od[,"AA1"], tv[,"AA"])
> matched <- !is.na(wh)  ## only needed if not all AA1's match in AA
> od[matched,c("AA1", "Value")] <- tv[wh[matched],c("BB","Value")]
>
> > od
>    Value1 Value2 AA1 Value
> 1       1     11   B     7
> 2       2     12   B    25
> 3       3     13   B     7
> 4       4     14   B     5
> 5       5     15   B    10
> 6       6     16   B     5
> 7       7     17  CC    21
> 8       8     18  CC    21
> 9       9     19   B    25
> 10     10     20   B    25
> 11     11     21   B     7
> 12     12     22   B    25
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, May 20, 2017 at 11:53 AM, David Winsemius
> <dwinsemius at comcast.net> wrote:
> >
> >> On May 20, 2017, at 11:23 AM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
> >>
> >> Hi again,
> >>
> >> Let say I have below 2 data frames.
> >>
> >> OriginalData = data.frame('Value1' = 1:12, 'Value2' = 11:22, 'AA1' =
> >> c('AA4', 'AA3', 'AA4', 'AA1', 'AA2', 'AA1', 'AA6', 'AA6', 'AA3',
> >> 'AA3', 'AA4', 'AA3'), 'Value' = NA)
> >>
> >> TargetValue = data.frame('AA' = c('AA1', 'AA2', 'AA3', 'AA4', 'AA5',
> >> 'AA6'), 'BB' = c('B', 'B', 'B', 'B', 'CC', 'CC'), 'Value' = c(5, 10,
> >> 25, 7, 35, 21))
> >>
> >> OriginalData
> >> TargetValue
> >>
> >> Now I need to replace OriginalData's 'AA1' column with TargetValue's
> >> 'BB' column, based on matched values between 'AA1' & 'AA' columns of
> >> OriginalData & TargetValue respectively. With this same law, I need to
> >> update 'Value' column of  OriginalData with that of TargetValue.
> >>
> >> As an example, after replacement by above rule, 1st row of
> >> OriginalData should look like :
> >>
> >>> OriginalData
> >>
> >>   Value1 Value2 AA1 Value
> >>
> >> 1       1     11 B    7
> >>
> >> Values of TargetValue's 'AA' column are unique i.e. no duplication
> >>
> >> Previously I have implemented a 'for' loop to implement above, however
> >> since both of my data.frames are quite big, it is taking long time to
> >> execute. Is there any 'R' way to implement this quickly.
> >>
> >> Appreciate for any pointer.
> >
> > It's going to have a greater chance of delivering the desired result if
> you convert the factor columns into character.
> >
> >>
> >> Thanks,
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ramnik.bansal at gmail.com  Sun May 21 04:03:53 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Sun, 21 May 2017 07:33:53 +0530
Subject: [R] [FORGED] Re: [FORGED] Logical Operators' inconsistent
	Behavior
In-Reply-To: <2058867e-4229-4f12-e46a-7c807133a856@auckland.ac.nz>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
 <1495200421.6068.11.camel@deb2.fort.knox.uk>
 <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>
 <22816.4630.997046.99474@stat.math.ethz.ch>
 <4a740d12-f643-8003-1c51-49fa452c26c8@gmail.com>
 <70e48256-6b44-093b-a834-a0fcb9150d50@auckland.ac.nz>
 <043c4596-b097-4e78-79ae-ebbe3a4a6f4a@gmail.com>
 <2058867e-4229-4f12-e46a-7c807133a856@auckland.ac.nz>
Message-ID: <CAMLd9E7RZxAwy-R6nTeYsgA_saNNmL8jfc9bC6Lwf8=aC-hbtQ@mail.gmail.com>

In the case of logical operations performed with an operand being a
character type, the error is:
"operations are possible only for numeric, logical or complex types"

Now the display of this error message seems to be the OUTCOME of the
fact that implicit coercion is NOT BEING APPLIED INTERNALLY to
character operands in the case of logical operations but is applied to
all other "numeric" type operands. This error message is NOT the
CAUSE.

Well, why not:

F & "abc" return a FALSE because if F & NA can return  FALSE, the
logic being that once an operand is FALSE in case of AND operation
then the output should be False, IRRESPECTIVE of the second operand.
In that case how does it matter if the second operand  is "abc" or
4+5i or NA? The output is deterministically FALSE anyways.

Effectively the point that I want to make is: Treat the character
operand as NA ( except "F", "FALSE", "T", "TRUE" etc which can be
treated as FALSE/TRUE) and then apply the logical operations. Or in
short "Apply implicit coercion on character types as well in case of
logical operations."




On Sat, May 20, 2017 at 4:15 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 20/05/17 22:42, Duncan Murdoch wrote:
>>
>> On 20/05/2017 6:39 AM, Rolf Turner wrote:
>>>
>>> On 20/05/17 22:18, Duncan Murdoch wrote:
>>>>
>>>> On 20/05/2017 5:53 AM, Martin Maechler wrote:
>>>>>>>>>>
>>>>>>>>>> Ramnik Bansal <ramnik.bansal at gmail.com>
>>>>>>>>>>     on Sat, 20 May 2017 08:52:55 +0530 writes:
>>>>>
>>>>>
>>>>>     > Taking this question further.
>>>>>     > If I use a complex number or a numeric as an operand in logical
>>>>>     > operations, to me it APPEARS that these two types are first
>>>>> coerced to
>>>>>     > LOGICAL internally and then THIS logical output is further used
>>>>> as the
>>>>>     > operand.
>>>>>
>>>>>     > For eg.
>>>>>     >> x <- 4+5i; c(x & F, x & T, x | F, x | T)
>>>>>     > [1] FALSE  TRUE  TRUE  TRUE
>>>>>
>>>>>     > This output is consistent with
>>>>>     >> x <- 4+5i; c(as.logical(x) & F, as.logical(x) & T,
>>>>> as.logical(x) | F, as.logical(x) | T)
>>>>>     > [1] FALSE  TRUE  TRUE  TRUE
>>>>>
>>>>>     > This consistency makes me draw an on-the-surface conclusion
>>>>> that in
>>>>>     > the case of logical operations if the operand is not of type
>>>>> 'logical'
>>>>>     > it is first coerced into 'logical'.
>>>>>
>>>>> That conclusion is wrong as you show below.
>>>>> Rather, as the error message says,
>>>>> logical
>>>>>     "operations are possible only for numeric, logical or complex
>>>>> types"
>>>>>
>>>>> Again:
>>>>>
>>>>> 1) Logical/Arithmetic  operations "work" with "numeric-like" types,
>>>>> namely
>>>>>   numeric, logical or complex, (and numeric = {integer, double})
>>>>>
>>>>>   ==> all other types give an error (the one you've cited twice)
>>>>>
>>>>> 2) For "numeric-like" types and *logical* operations (&, |, !; plus &&
>>>>> and ||)
>>>>>    the equivalent of as.logical() is applied before performing the Op.
>>>>>
>>>>> Seems pretty consistent ...
>>>>> and also according to the principle of "least surprise" (for me at
>>>>> least).
>>>>>
>>>>
>>>> The surprise is that as.logical("TRUE") returns TRUE, whereas automatic
>>>> coercion doesn't apply to character strings.  I don't think we should
>>>> change this, but it is an inconsistency.  (We could perhaps mention it
>>>> in the ?logical help page.)
>>>
>>>
>>>
>>> Actually it *is* mentioned.  From ?logical:
>>>
>>>> Character strings c("T", "TRUE", "True", "true") are regarded as
>>>> true,  c("F", "FALSE", "False", "false") as false, and all others as NA.
>>>
>>>
>>
>> I meant that the negative part should be mentioned:  this only works
>> with an explicit as.logical(), not with implicit coercion.
>
>
> Ah, I see.  I missed the point.
>
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276


From hasan.diwan at gmail.com  Sun May 21 05:04:17 2017
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Sat, 20 May 2017 20:04:17 -0700
Subject: [R] train function in caret package
In-Reply-To: <1610360333.3180726.1495238178311@mail.yahoo.com>
References: <667543577.1989752.1495179558848.ref@mail.yahoo.com>
 <667543577.1989752.1495179558848@mail.yahoo.com>
 <1610360333.3180726.1495238178311@mail.yahoo.com>
Message-ID: <CAP+bYWBhaojQ4PeGUS+vDS_or15rSPcHk0grzdhBi0eGd5JkHg@mail.gmail.com>

A dput of your data may be helpful, Elahe? -- H[

On 19 May 2017 at 16:56, Elahe chalabi via R-help <r-help at r-project.org>
wrote:

> Any answer?!
>
>     On Friday, May 19, 2017 6:33 AM, Elahe chalabi via R-help <
> r-help at r-project.org> wrote:
>
>
>  Hi all,
>
> I'm running train function from caret package on my data set patientdata:
>
>     model=train(type~., data=patientdata, method="lvq",
> preProcess="scale", trControl=control)
> and I get this error:
>
>     Error in comp(expr, env = envir, options = list(suppressUndefined =
> TRUE)) :
>
>     could not find function "mayCallBrowser"
> Does anyone know how should I solve it?!
>
> Thanks for any help!
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
OpenPGP:
https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using
http://bit.ly/hd1ScheduleRequest.
Si vous voudrais faire connnaisance, allez a
http://bit.ly/hd1ScheduleRequest.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From heidi.mcgann at snhu.edu  Sun May 21 02:28:34 2017
From: heidi.mcgann at snhu.edu (McGann, Heidi)
Date: Sun, 21 May 2017 00:28:34 +0000
Subject: [R]  modulus operator?
Message-ID: <92282EA9-A9A1-4884-9701-C43B7D08496E@snhu.edu>


From dhiv.shreya at gmail.com  Sun May 21 07:05:03 2017
From: dhiv.shreya at gmail.com (Dhivya Narayanasamy)
Date: Sun, 21 May 2017 10:35:03 +0530
Subject: [R] Forecast using VAR model
Message-ID: <CACmggQvJb8pQPQ_eJBgPxAkfNT0ua4DrqGt-tEX6Hy9ODotq8Q@mail.gmail.com>

I am building a VAR model to forecast of bivariate timeseries. But it shows
flat forecast.

So I would like to use recursive window forecasting technique using VAR
model. Will it give what i expect (Avoid flat forecast) ? or should i have
to go with other package.

> datax.zoo <- read.zoo(datax)> datax.ts <- ts(datax.zoo)> v1b <- VARselect(datax.ts, lag.max = 10, type = "const")> v1b
$selection
AIC(n)  HQ(n)  SC(n) FPE(n)
     9      7      5      9

$criteria
                  1            2            3            4
5            6            7
AIC(n)     9.686513     9.657172     9.632444     9.625856
9.621148     9.619425     9.615396
HQ(n)      9.688951     9.661234     9.638131     9.633167
9.630085     9.629987     9.627583
SC(n)      9.693514     9.668839     9.648778     9.646856
9.646815     9.649759     9.650397
FPE(n) 16099.014774 15633.507506 15251.665643 15151.510512
15080.352425 15054.392389 14993.864861
                  8            9           10
AIC(n)     9.615430     9.615116     9.615990
HQ(n)      9.629241     9.630552     9.633051
SC(n)      9.655098     9.659451     9.664991
FPE(n) 14994.366572 14989.661383 15002.762011
> var7 = VAR(datax.ts, p=7)> serial.test(var7, lags.pt=10, type = "PT.asymptotic")

    Portmanteau Test (asymptotic)

data:  Residuals of VAR object var7Chi-squared = 22.745, df = 12,
p-value = 0.02997
> grangertest(datax.ts[,1] ~ datax.ts[,2], order = 7)Granger causality test
Model 1: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7) + Lags(datax.ts[,
2], 1:7)Model 2: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7)
  Res.Df Df      F    Pr(>F)    1   5686                        2
5693 -7 16.105 < 2.2e-16 ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01
?*? 0.05 ?.? 0.1 ? ? 1> grangertest(datax.ts[,2] ~  datax.ts[,1],
order = 7)Granger causality test
Model 1: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7) + Lags(datax.ts[,
1], 1:7)Model 2: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7)
  Res.Df Df      F Pr(>F)1   5686                 2   5693 -7 1.5618 0.1418
> g <- forecast(var7, h = 600)> plot(g)


Also the 'P' value  from portmanteau test shows auto correlation is present
is my VAR model. Here is my raw data you can find :
https://drive.google.com/file/d/0B7I0DT-PiG4RenVkdXV3OFJLYVk/view?usp=sharing


Thank you.

Regards
> Dhivya Narayanasamy

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun May 21 10:27:28 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 21 May 2017 18:27:28 +1000
Subject: [R] modulus operator?
In-Reply-To: <92282EA9-A9A1-4884-9701-C43B7D08496E@snhu.edu>
References: <92282EA9-A9A1-4884-9701-C43B7D08496E@snhu.edu>
Message-ID: <CA+8X3fX6VaHL2h5PO82ZrNejjkCdMnTjU=0GMpeSXSXsJpc84Q@mail.gmail.com>

Hi Heidi,
I think you are looking for the %% operator. See the Arithmetic help
page in the base package.

Jim

On Sun, May 21, 2017 at 10:28 AM, McGann, Heidi <heidi.mcgann at snhu.edu> wrote:
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun May 21 13:45:36 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Sun, 21 May 2017 13:45:36 +0200
Subject: [R] modulus operator?
In-Reply-To: <CA+8X3fX6VaHL2h5PO82ZrNejjkCdMnTjU=0GMpeSXSXsJpc84Q@mail.gmail.com>
References: <92282EA9-A9A1-4884-9701-C43B7D08496E@snhu.edu>
 <CA+8X3fX6VaHL2h5PO82ZrNejjkCdMnTjU=0GMpeSXSXsJpc84Q@mail.gmail.com>
Message-ID: <CC4CE298-ED34-451F-AD9F-1A88F5074DA5@gmail.com>

Or maybe Mod(), but please, Heidi, don't expect the rest of the world to guess your intentions like that...

-pd

> On 21 May 2017, at 10:27 , Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Heidi,
> I think you are looking for the %% operator. See the Arithmetic help
> page in the base package.
> 
> Jim
> 
> On Sun, May 21, 2017 at 10:28 AM, McGann, Heidi <heidi.mcgann at snhu.edu> wrote:
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Sun May 21 14:56:30 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 21 May 2017 08:56:30 -0400
Subject: [R] [FORGED] Re: [FORGED] Logical Operators' inconsistent
 Behavior
In-Reply-To: <CAMLd9E7RZxAwy-R6nTeYsgA_saNNmL8jfc9bC6Lwf8=aC-hbtQ@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CAPHJcdCzV-XMXQ=_1chJ6TpbsABVc=Yd=5MzrUKdxffJuQUHAA@mail.gmail.com>
 <d249a30b-5a5c-261c-07f9-43838ecf90c1@auckland.ac.nz>
 <CAPHJcdBedmhs0gC-S8E+-MyhJa0XP5_VtYZnou7GrqXY5wE4GQ@mail.gmail.com>
 <1495200421.6068.11.camel@deb2.fort.knox.uk>
 <CAMLd9E5eg18SbA0T5ZX2PqykM7-LMavFsTxbtKYt7EoJtpu7sQ@mail.gmail.com>
 <22816.4630.997046.99474@stat.math.ethz.ch>
 <4a740d12-f643-8003-1c51-49fa452c26c8@gmail.com>
 <70e48256-6b44-093b-a834-a0fcb9150d50@auckland.ac.nz>
 <043c4596-b097-4e78-79ae-ebbe3a4a6f4a@gmail.com>
 <2058867e-4229-4f12-e46a-7c807133a856@auckland.ac.nz>
 <CAMLd9E7RZxAwy-R6nTeYsgA_saNNmL8jfc9bC6Lwf8=aC-hbtQ@mail.gmail.com>
Message-ID: <04f5f6bd-20c3-2330-f5ca-88f835dd7767@gmail.com>

On 20/05/2017 10:03 PM, Ramnik Bansal wrote:
> In the case of logical operations performed with an operand being a
> character type, the error is:
> "operations are possible only for numeric, logical or complex types"
>
> Now the display of this error message seems to be the OUTCOME of the
> fact that implicit coercion is NOT BEING APPLIED INTERNALLY to
> character operands in the case of logical operations but is applied to
> all other "numeric" type operands. This error message is NOT the
> CAUSE.
>
> Well, why not:
>
> F & "abc" return a FALSE because if F & NA can return  FALSE, the
> logic being that once an operand is FALSE in case of AND operation
> then the output should be False, IRRESPECTIVE of the second operand.
> In that case how does it matter if the second operand  is "abc" or
> 4+5i or NA? The output is deterministically FALSE anyways.
>
> Effectively the point that I want to make is: Treat the character
> operand as NA ( except "F", "FALSE", "T", "TRUE" etc which can be
> treated as FALSE/TRUE) and then apply the logical operations. Or in
> short "Apply implicit coercion on character types as well in case of
> logical operations."

For consistency with that point of view, we'd also want

1 + "1"

to equal 2, as it does in some languages.  And maybe "1" + "1" should 
equal 2.

R doesn't do things like that.  It tries for consistency in the 
primitive operations:  you don't get auto-conversion of strings to 
logical/numeric values.  This forces some inconsistencies between the 
primitive operations and explicit coercions like as.logical(), but we 
think that's a good thing.

Duncan Murdoch

>
>
>
>
> On Sat, May 20, 2017 at 4:15 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 20/05/17 22:42, Duncan Murdoch wrote:
>>>
>>> On 20/05/2017 6:39 AM, Rolf Turner wrote:
>>>>
>>>> On 20/05/17 22:18, Duncan Murdoch wrote:
>>>>>
>>>>> On 20/05/2017 5:53 AM, Martin Maechler wrote:
>>>>>>>>>>>
>>>>>>>>>>> Ramnik Bansal <ramnik.bansal at gmail.com>
>>>>>>>>>>>     on Sat, 20 May 2017 08:52:55 +0530 writes:
>>>>>>
>>>>>>
>>>>>>     > Taking this question further.
>>>>>>     > If I use a complex number or a numeric as an operand in logical
>>>>>>     > operations, to me it APPEARS that these two types are first
>>>>>> coerced to
>>>>>>     > LOGICAL internally and then THIS logical output is further used
>>>>>> as the
>>>>>>     > operand.
>>>>>>
>>>>>>     > For eg.
>>>>>>     >> x <- 4+5i; c(x & F, x & T, x | F, x | T)
>>>>>>     > [1] FALSE  TRUE  TRUE  TRUE
>>>>>>
>>>>>>     > This output is consistent with
>>>>>>     >> x <- 4+5i; c(as.logical(x) & F, as.logical(x) & T,
>>>>>> as.logical(x) | F, as.logical(x) | T)
>>>>>>     > [1] FALSE  TRUE  TRUE  TRUE
>>>>>>
>>>>>>     > This consistency makes me draw an on-the-surface conclusion
>>>>>> that in
>>>>>>     > the case of logical operations if the operand is not of type
>>>>>> 'logical'
>>>>>>     > it is first coerced into 'logical'.
>>>>>>
>>>>>> That conclusion is wrong as you show below.
>>>>>> Rather, as the error message says,
>>>>>> logical
>>>>>>     "operations are possible only for numeric, logical or complex
>>>>>> types"
>>>>>>
>>>>>> Again:
>>>>>>
>>>>>> 1) Logical/Arithmetic  operations "work" with "numeric-like" types,
>>>>>> namely
>>>>>>   numeric, logical or complex, (and numeric = {integer, double})
>>>>>>
>>>>>>   ==> all other types give an error (the one you've cited twice)
>>>>>>
>>>>>> 2) For "numeric-like" types and *logical* operations (&, |, !; plus &&
>>>>>> and ||)
>>>>>>    the equivalent of as.logical() is applied before performing the Op.
>>>>>>
>>>>>> Seems pretty consistent ...
>>>>>> and also according to the principle of "least surprise" (for me at
>>>>>> least).
>>>>>>
>>>>>
>>>>> The surprise is that as.logical("TRUE") returns TRUE, whereas automatic
>>>>> coercion doesn't apply to character strings.  I don't think we should
>>>>> change this, but it is an inconsistency.  (We could perhaps mention it
>>>>> in the ?logical help page.)
>>>>
>>>>
>>>>
>>>> Actually it *is* mentioned.  From ?logical:
>>>>
>>>>> Character strings c("T", "TRUE", "True", "true") are regarded as
>>>>> true,  c("F", "FALSE", "False", "false") as false, and all others as NA.
>>>>
>>>>
>>>
>>> I meant that the negative part should be mentioned:  this only works
>>> with an explicit as.logical(), not with implicit coercion.
>>
>>
>> Ah, I see.  I missed the point.
>>
>>
>> cheers,
>>
>> Rolf
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276


From h.wickham at gmail.com  Sun May 21 16:00:42 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sun, 21 May 2017 09:00:42 -0500
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CABdHhvG3qziQEzL7gHCgN=6kXhqYK_288heA=ybta5OAmbidvw@mail.gmail.com>

On Fri, May 19, 2017 at 6:38 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
>> either TRUE or FALSE and consequently is NA.
>>
>> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>>
>> As I said *think* about it; don't just go with your immediate knee-jerk
>> (simplistic) reaction.
>
> Hmm... not sure that was quite fair to the OP. Yes,  FALSE & <anything> == FALSE. But 'NA' does not mean 'anything'; it means 'missing' (see ?'NA'). It is much less obvious that FALSE & <missing> should generate a non-missing value. SQL, for example, generally  takes the view that any expression involving 'missing' is 'missing'.

That's not TRUE ;)

sqlite> select (3 > 2) OR NULL;
1

sqlite> select (4 < 3) AND NULL;
0

Hadley


-- 
http://hadley.nz


From peter.carbonetto at gmail.com  Sun May 21 16:30:43 2017
From: peter.carbonetto at gmail.com (Peter Carbonetto)
Date: Sun, 21 May 2017 09:30:43 -0500
Subject: [R] Somewhat obscure bug in R 3.4.0 building from source
Message-ID: <CAPvCojJqJYiU4LN2XvxH7LMtzqeAghnkztXJ2YnjU4w6UrUFNw@mail.gmail.com>

Hi,

I uncovered a bug in installing R 3.4.0 from source in Linux, following the
standard procedure (configure; make; make install). Is this an appropriate
place to report this bug? If not, can you please direct me to the
appropriate place?

The error occurs only when I do "make clean" followed by "make" again; make
works the first time.

The error is a failure to build NEWS.pdf:

Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
  pdflatex is not available
Calls: <Anonymous> -> texi2pdf -> texi2dvi
Execution halted
make[1]: *** [NEWS.pdf] Error 1
make: [docs] Error 2 (ignored)

and can be reproduced wit the following sequence:

./configure
make
make clean
make

This suggests to me that perhaps "make clean" is not working.

I'm happy to provide more details so that you are able to reproduce the bug.

Thanks,

Peter Carbonetto, Ph.D.
Computational Staff Scientist, Statistics & Genetics
Research Computing Center
University of Chicago

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Sun May 21 22:14:02 2017
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sun, 21 May 2017 13:14:02 -0700 (PDT)
Subject: [R] Somewhat obscure bug in R 3.4.0 building from source
In-Reply-To: <CAPvCojJqJYiU4LN2XvxH7LMtzqeAghnkztXJ2YnjU4w6UrUFNw@mail.gmail.com>
References: <CAPvCojJqJYiU4LN2XvxH7LMtzqeAghnkztXJ2YnjU4w6UrUFNw@mail.gmail.com>
Message-ID: <alpine.LNX.2.11.1705211312350.32755@localhost>

On Sun, 21 May 2017, Peter Carbonetto wrote:

> The error occurs only when I do "make clean" followed by "make" again;
> make works the first time.

Peter,

   I suggest you use 'make distclean' rather than 'make clean.' There are
subtle differences between the two, yet the former is more complete. This
might resolve your missing file issue during a second build.

Rich


From bgunter.4567 at gmail.com  Sun May 21 22:19:35 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 21 May 2017 13:19:35 -0700
Subject: [R] Somewhat obscure bug in R 3.4.0 building from source
In-Reply-To: <CAPvCojJqJYiU4LN2XvxH7LMtzqeAghnkztXJ2YnjU4w6UrUFNw@mail.gmail.com>
References: <CAPvCojJqJYiU4LN2XvxH7LMtzqeAghnkztXJ2YnjU4w6UrUFNw@mail.gmail.com>
Message-ID: <CAGxFJbTbfbWAQgrnd+Pi0r3q7BAs4M51=zsz3r+C+3WhsUGWVw@mail.gmail.com>

... and whether or not Rich's suggestion resolves your difficulties,
please google such issues in future; e.g.

"report bugs R"

brought up all sorts of info on R bug reporting.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 21, 2017 at 7:30 AM, Peter Carbonetto
<peter.carbonetto at gmail.com> wrote:
> Hi,
>
> I uncovered a bug in installing R 3.4.0 from source in Linux, following the
> standard procedure (configure; make; make install). Is this an appropriate
> place to report this bug? If not, can you please direct me to the
> appropriate place?
>
> The error occurs only when I do "make clean" followed by "make" again; make
> works the first time.
>
> The error is a failure to build NEWS.pdf:
>
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>   pdflatex is not available
> Calls: <Anonymous> -> texi2pdf -> texi2dvi
> Execution halted
> make[1]: *** [NEWS.pdf] Error 1
> make: [docs] Error 2 (ignored)
>
> and can be reproduced wit the following sequence:
>
> ./configure
> make
> make clean
> make
>
> This suggests to me that perhaps "make clean" is not working.
>
> I'm happy to provide more details so that you are able to reproduce the bug.
>
> Thanks,
>
> Peter Carbonetto, Ph.D.
> Computational Staff Scientist, Statistics & Genetics
> Research Computing Center
> University of Chicago
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From allaisone1 at hotmail.com  Mon May 22 02:10:10 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Mon, 22 May 2017 00:10:10 +0000
Subject: [R] Identyfing rows with specific conditions
Message-ID: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>


Hi All..,

I have 2 tables. The first one contains 2 columns with the headers say "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each of which with a different combination of meals(unique combination per row).


>Meals

    meal A code      meal B code

1          34                   66

2           89                  39

3           25                   77

The second table(customers) shows customers ids in the first column with Meals codes(M) next to each customer. There are about 300,000 customers (300,000 rows).

> Customers
     1         2     3       4    ..30
     id       M1  M2   M3
1   15      77    34    25
2   11      25    34     39
3    85     89     25    77
.
.
300,000

I would like to identify all customers ids who have had each meal combination in the first table so the final output would be the first table with ids attached next to each meal combination in each row like this:

>IdsMeals


  MAcode  MBcode  ids

1     34        39            11

2     25       34              15   11

3      25     77                15   85

Would you please suggest any solutions to this problem?

Regards

	[[alternative HTML version deleted]]


From yarmi1224 at hotmail.com  Mon May 22 04:33:45 2017
From: yarmi1224 at hotmail.com (=?big5?B?o2Mgoag=?=)
Date: Mon, 22 May 2017 02:33:45 +0000
Subject: [R] How to extract text contexts after clustering.
Message-ID: <HK2PR0301MB1187F2C14787C61DD07279EAA4F80@HK2PR0301MB1187.apcprd03.prod.outlook.com>

hi:
I need to extract the text contexts of top 1 group after clustering.
But I have no idea how to sort the cluster size then extract the contexts of top 1 clusters.

here is my cluster code:

> file <- read.csv("SiC CMP.csv", header = TRUE)
> cluster_k<-length(unique(file$Main.IPC))
> cl <- kmeans(IPC_Dtm , cluster_k)


I have tried use??

> sort(cl$size, decreasing=T)
 [1] 341 107 104  80  51  22  15  11  10   8   8   5   5   5   4   4   4   3   3   2   2
[22]   2   2   2   2   2   2   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1
[43]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1

But I have no idea how to extract the contexts of top 1 cluster.


Eva

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Mon May 22 05:08:33 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Mon, 22 May 2017 06:08:33 +0300
Subject: [R] How to extract text contexts after clustering.
In-Reply-To: <HK2PR0301MB1187F2C14787C61DD07279EAA4F80@HK2PR0301MB1187.apcprd03.prod.outlook.com>
References: <HK2PR0301MB1187F2C14787C61DD07279EAA4F80@HK2PR0301MB1187.apcprd03.prod.outlook.com>
Message-ID: <A744EC35-9609-4135-A31E-7060DB17BD0F@gmail.com>

1- PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
2- PLEASE, first _read_ help for kmeans (?kmeans) function before using function.

> On 22 May 2017, at 05:33, ? ? <yarmi1224 at hotmail.com> wrote:
> 
> hi:
> I need to extract the text contexts of top 1 group after clustering.
> But I have no idea how to sort the cluster size then extract the contexts of top 1 clusters.

There isn?t a _top_ cluster for kmeans algorithm. There are _only_ clusters!

> 
> here is my cluster code:
> 
>> file <- read.csv("SiC CMP.csv", header = TRUE)

We don?t know what is in file$Main.IPC.

>> cluster_k<-length(unique(file$Main.IPC))
>> cl <- kmeans(IPC_Dtm , cluster_k)

What is IPC_Dtm?

> 
> 
> I have tried use??
> 
>> sort(cl$size, decreasing=T)

if you read the documentation, you would know cl$size means the number of points in each cluster. So, why do you sort them?

> [1] 341 107 104  80  51  22  15  11  10   8   8   5   5   5   4   4   4   3   3   2   2
> [22]   2   2   2   2   2   2   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1
> [43]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1
> 
> But I have no idea how to extract the contexts of top 1 cluster.

If you read the _Value_ section of kmeans documentation, you will have an idea how to extract context by using cl$cluster.

> 
> 
> Eva
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon May 22 05:11:11 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 21 May 2017 20:11:11 -0700
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQH55Lv47+46Xxs_prJ7+Ay-XQPKg2_bEwD-ieLtF3i2A@mail.gmail.com>

Clarification:

Does each customer have the same number of meals or do they differ
from customer to customer? If the latter, how are missing meals
notated? Do they always occur at the (right) end or can they occur
anywhere in the row?

Presumably each customer ID can have many different meal code
combinations, right ?(since they can have 30 different meals with
potentially 30 choose 2 = 435 combinations apiece)

Please make sure you reply to the list, not just to me, as I may not
pursue this further but am just trying to clarify for anyone else who
may wish to help.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>
> Hi All..,
>
> I have 2 tables. The first one contains 2 columns with the headers say "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each of which with a different combination of meals(unique combination per row).
>
>
>>Meals
>
>     meal A code      meal B code
>
> 1          34                   66
>
> 2           89                  39
>
> 3           25                   77
>
> The second table(customers) shows customers ids in the first column with Meals codes(M) next to each customer. There are about 300,000 customers (300,000 rows).
>
>> Customers
>      1         2     3       4    ..30
>      id       M1  M2   M3
> 1   15      77    34    25
> 2   11      25    34     39
> 3    85     89     25    77
> .
> .
> 300,000
>
> I would like to identify all customers ids who have had each meal combination in the first table so the final output would be the first table with ids attached next to each meal combination in each row like this:
>
>>IdsMeals
>
>
>   MAcode  MBcode  ids
>
> 1     34        39            11
>
> 2     25       34              15   11
>
> 3      25     77                15   85
>
> Would you please suggest any solutions to this problem?
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon May 22 05:19:57 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 21 May 2017 20:19:57 -0700
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbReXwWt7an7GMa4=RnP+=daZ0Si67a44Yq_F90rm-T2FA@mail.gmail.com>

More clarification:

Are your "tables" matrices or data frames? (If you don't know what
this means, you need to spend a little time with a e.g. web tutorial
to learn).

Also, does Meal A Meal B order count? -- i.e. is Meal A = 2, Meal B =
15 the same as Meal A = 15 and Meal B = 2?  This is important.

Cheers,

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>
> Hi All..,
>
> I have 2 tables. The first one contains 2 columns with the headers say "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each of which with a different combination of meals(unique combination per row).
>
>
>>Meals
>
>     meal A code      meal B code
>
> 1          34                   66
>
> 2           89                  39
>
> 3           25                   77
>
> The second table(customers) shows customers ids in the first column with Meals codes(M) next to each customer. There are about 300,000 customers (300,000 rows).
>
>> Customers
>      1         2     3       4    ..30
>      id       M1  M2   M3
> 1   15      77    34    25
> 2   11      25    34     39
> 3    85     89     25    77
> .
> .
> 300,000
>
> I would like to identify all customers ids who have had each meal combination in the first table so the final output would be the first table with ids attached next to each meal combination in each row like this:
>
>>IdsMeals
>
>
>   MAcode  MBcode  ids
>
> 1     34        39            11
>
> 2     25       34              15   11
>
> 3      25     77                15   85
>
> Would you please suggest any solutions to this problem?
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Mon May 22 06:35:57 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Sun, 21 May 2017 21:35:57 -0700
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <CABdHhvG3qziQEzL7gHCgN=6kXhqYK_288heA=ybta5OAmbidvw@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CABdHhvG3qziQEzL7gHCgN=6kXhqYK_288heA=ybta5OAmbidvw@mail.gmail.com>
Message-ID: <CAA99HCyeUfEa5b4Vk0f2+v_vfjLAxzGZChLzWDODNo+s7PeFrg@mail.gmail.com>

Looking below and online, R's truth tables for NOT, AND, OR are
identical to the NOT, AND, OR truth tables originating from Stephen
Cole Kleene's "strong logic of indeterminacy", as demonstrated on the
Wikipedia page entitled, "Three-Valued Logic"--specifically in the
section entitled "Kleene and Priest Logics":

https://en.wikipedia.org/wiki/Three-valued_logic#Kleene_and_Priest_logics

>
> ttNOT <- cbind(c(FALSE, NA, TRUE), !c(FALSE, NA, TRUE))
> rownames(ttNOT) <- c("False", "na", "True")
> colnames(ttNOT) <- c("A", "Not(A)")
> ttNOT
          A Not(A)
False FALSE   TRUE
na       NA     NA
True   TRUE  FALSE
>
> ttAND <- outer(c(FALSE, NA, TRUE), c(FALSE, NA, TRUE), "&" )
> rownames(ttAND) <- c("False", "na", "True")
> colnames(ttAND) <- c("False", "na", "True")
> ttAND
      False    na  True
False FALSE FALSE FALSE
na    FALSE    NA    NA
True  FALSE    NA  TRUE
>
> ttOR <- outer(c(FALSE, NA, TRUE), c(FALSE, NA, TRUE), "|" )
> rownames(ttOR) <- c("False", "na", "True")
> colnames(ttOR) <- c("False", "na", "True")
> ttOR
      False   na True
False FALSE   NA TRUE
na       NA   NA TRUE
True   TRUE TRUE TRUE
>
>

The bottom section of the same Wikipedia page (section entitled
"Application in SQL" ), and an additional Wikipedia page entitled
"Null (SQL)" discusses how the Kleene logic described above is
differentially implemented in SQL.

https://en.wikipedia.org/wiki/Null_(SQL)

HTH,

Bill

William Michels, Ph.D.




On Sun, May 21, 2017 at 7:00 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> On Fri, May 19, 2017 at 6:38 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>>> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
>>> either TRUE or FALSE and consequently is NA.
>>>
>>> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>>>
>>> As I said *think* about it; don't just go with your immediate knee-jerk
>>> (simplistic) reaction.
>>
>> Hmm... not sure that was quite fair to the OP. Yes,  FALSE & <anything> == FALSE. But 'NA' does not mean 'anything'; it means 'missing' (see ?'NA'). It is much less obvious that FALSE & <missing> should generate a non-missing value. SQL, for example, generally  takes the view that any expression involving 'missing' is 'missing'.
>
> That's not TRUE ;)
>
> sqlite> select (3 > 2) OR NULL;
> 1
>
> sqlite> select (4 < 3) AND NULL;
> 0
>
> Hadley
>
>
> --
> http://hadley.nz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Mon May 22 11:10:23 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Mon, 22 May 2017 21:10:23 +1200
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
 <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
Message-ID: <20170522091022.GC4553@slingshot.co.nz>

On Fri, 28-Apr-2017 at 07:04PM +0200, peter dalgaard wrote:

|> 
|> > On 28 Apr 2017, at 12:08 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
|> > 
|> > On 28/04/2017 4:45 AM, Thierry Onkelinx wrote:
|> >> Dear Peter,
|> >> 
|> >> It actually breaks install.packages(). So it is not that innocent.
|> > 
|> > I don't think he meant that it is harmless, he meant that the fix is easy, and is in place in R-patched and R-devel.  You should use R-patched and you won't have the problem.
|> 
|> Read more carefully: I said that the _fix_ is harmless for this case, but might not be so in general.
|> 
|> -pd


Apparently it isn't harmless.  

> install.packages("withr")
Error in readRDS(dest) : error reading from connection
>

> 
> sessionInfo()
R version 3.4.0 Patched (2017-05-19 r72713)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/hrapgc/local/R-patched/lib/libRblas.so
LAPACK: /home/hrapgc/local/R-patched/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
 [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grDevices utils     stats     graphics  methods   base     

other attached packages:
[1] lattice_0.20-35

loaded via a namespace (and not attached):
[1] compiler_3.4.0 tools_3.4.0    grid_3.4.0    
> 

Has anyone a workaround?

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From martin.morgan at roswellpark.org  Mon May 22 11:43:57 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Mon, 22 May 2017 05:43:57 -0400
Subject: [R] Error with installed.packages with R 3.4.0 on Windows
In-Reply-To: <20170522091022.GC4553@slingshot.co.nz>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
 <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
 <20170522091022.GC4553@slingshot.co.nz>
Message-ID: <7b8f4895-b41d-6634-367b-1754bc737c02@roswellpark.org>

On 05/22/2017 05:10 AM, Patrick Connolly wrote:
> On Fri, 28-Apr-2017 at 07:04PM +0200, peter dalgaard wrote:
>
> |>
> |> > On 28 Apr 2017, at 12:08 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> |> >
> |> > On 28/04/2017 4:45 AM, Thierry Onkelinx wrote:
> |> >> Dear Peter,
> |> >>
> |> >> It actually breaks install.packages(). So it is not that innocent.
> |> >
> |> > I don't think he meant that it is harmless, he meant that the fix is easy, and is in place in R-patched and R-devel.  You should use R-patched and you won't have the problem.
> |>
> |> Read more carefully: I said that the _fix_ is harmless for this case, but might not be so in general.
> |>
> |> -pd
>
>
> Apparently it isn't harmless.
>
>> install.packages("withr")
> Error in readRDS(dest) : error reading from connection

that seems like a plain-old network connectivity issue, or perhaps an 
issue with the CRAN mirror you're using. Can you debug on your end, e.g,.

   options(error=recover)
   install.packages("withr")
   ...

then select the 'frame' where the error occurs, look around

   ls()

find the value of 'dest', and e.g., try to open dest in your  browser.

Martin Morgan

>>
>
>>
>> sessionInfo()
> R version 3.4.0 Patched (2017-05-19 r72713)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
>
> Matrix products: default
> BLAS: /home/hrapgc/local/R-patched/lib/libRblas.so
> LAPACK: /home/hrapgc/local/R-patched/lib/libRlapack.so
>
> locale:
>  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] grDevices utils     stats     graphics  methods   base
>
> other attached packages:
> [1] lattice_0.20-35
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.0 tools_3.4.0    grid_3.4.0
>>
>
> Has anyone a workaround?
>


This email message may contain legally privileged and/or...{{dropped:2}}


From Mohan.Radhakrishnan at cognizant.com  Mon May 22 12:12:48 2017
From: Mohan.Radhakrishnan at cognizant.com (Mohan.Radhakrishnan at cognizant.com)
Date: Mon, 22 May 2017 10:12:48 +0000
Subject: [R] RC class composition
Message-ID: <E1B160F4999FD6449524E16C2CB94E031F908783@CTSINCHNSXMBE.cts.com>

Hi,

The last line should give me the value of 'amount'. Is the syntax wrong ?

Measurement <- setRefClass("Measurement",
              fields = list(subject = Subject,
                                 quantity = Quantity))

s <- Subject$new(id = 100)

u <- CompoundUnit$new(  micrograms = 100,
                                      cubicmeter = 1 )

q <- Quantity$new(amount = 100,
                             units = u )

m <- Measurement$new(subject = s,
                                  quantity = q)
print( m$quantity$amount )

Thanks,
Mohan
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

	[[alternative HTML version deleted]]


From allaisone1 at hotmail.com  Mon May 22 10:56:38 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Mon, 22 May 2017 08:56:38 +0000
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <CAGxFJbQH55Lv47+46Xxs_prJ7+Ay-XQPKg2_bEwD-ieLtF3i2A@mail.gmail.com>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <CAGxFJbQH55Lv47+46Xxs_prJ7+Ay-XQPKg2_bEwD-ieLtF3i2A@mail.gmail.com>
Message-ID: <AM5P195MB00205C73AAC9BB5DD9391C8380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>

Hi Bert ..,


The number of meals differ from one customer to other customer. You may find one customer with only one meal and another one with 2,3 or even rarely 30 meals. You may also

find no meal at all for some customers so the entire row takes the missing value "\N" . Any

row starts with the meals codes first, then all missing values are to the right end of the table.

________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 22 May 2017 03:11:11
To: Allaisone 1
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

Clarification:

Does each customer have the same number of meals or do they differ
from customer to customer? If the latter, how are missing meals
notated? Do they always occur at the (right) end or can they occur
anywhere in the row?

Presumably each customer ID can have many different meal code
combinations, right ?(since they can have 30 different meals with
potentially 30 choose 2 = 435 combinations apiece)

Please make sure you reply to the list, not just to me, as I may not
pursue this further but am just trying to clarify for anyone else who
may wish to help.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>
> Hi All..,
>
> I have 2 tables. The first one contains 2 columns with the headers say "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each of which with a different combination of meals(unique combination per row).
>
>
>>Meals
>
>     meal A code      meal B code
>
> 1          34                   66
>
> 2           89                  39
>
> 3           25                   77
>
> The second table(customers) shows customers ids in the first column with Meals codes(M) next to each customer. There are about 300,000 customers (300,000 rows).
>
>> Customers
>      1         2     3       4    ..30
>      id       M1  M2   M3
> 1   15      77    34    25
> 2   11      25    34     39
> 3    85     89     25    77
> .
> .
> 300,000
>
> I would like to identify all customers ids who have had each meal combination in the first table so the final output would be the first table with ids attached next to each meal combination in each row like this:
>
>>IdsMeals
>
>
>   MAcode  MBcode  ids
>
> 1     34        39            11
>
> 2     25       34              15   11
>
> 3      25     77                15   85
>
> Would you please suggest any solutions to this problem?
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From allaisone1 at hotmail.com  Mon May 22 11:11:05 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Mon, 22 May 2017 09:11:05 +0000
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <CAGxFJbReXwWt7an7GMa4=RnP+=daZ0Si67a44Yq_F90rm-T2FA@mail.gmail.com>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <CAGxFJbReXwWt7an7GMa4=RnP+=daZ0Si67a44Yq_F90rm-T2FA@mail.gmail.com>
Message-ID: <AM5P195MB0020AFBDFAF1304E997206B880F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>

Hi Again..,


All of my 2 tables are data.frames and the order of meals does not matter. Meal A =2 and Meal B= 15 is the same as Meal A=15 and Meal B= 2.

________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 22 May 2017 03:19:57
To: Allaisone 1
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

More clarification:

Are your "tables" matrices or data frames? (If you don't know what
this means, you need to spend a little time with a e.g. web tutorial
to learn).

Also, does Meal A Meal B order count? -- i.e. is Meal A = 2, Meal B =
15 the same as Meal A = 15 and Meal B = 2?  This is important.

Cheers,

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>
> Hi All..,
>
> I have 2 tables. The first one contains 2 columns with the headers say "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each of which with a different combination of meals(unique combination per row).
>
>
>>Meals
>
>     meal A code      meal B code
>
> 1          34                   66
>
> 2           89                  39
>
> 3           25                   77
>
> The second table(customers) shows customers ids in the first column with Meals codes(M) next to each customer. There are about 300,000 customers (300,000 rows).
>
>> Customers
>      1         2     3       4    ..30
>      id       M1  M2   M3
> 1   15      77    34    25
> 2   11      25    34     39
> 3    85     89     25    77
> .
> .
> 300,000
>
> I would like to identify all customers ids who have had each meal combination in the first table so the final output would be the first table with ids attached next to each meal combination in each row like this:
>
>>IdsMeals
>
>
>   MAcode  MBcode  ids
>
> 1     34        39            11
>
> 2     25       34              15   11
>
> 3      25     77                15   85
>
> Would you please suggest any solutions to this problem?
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bernardnorth at hotmail.com  Mon May 22 12:59:58 2017
From: bernardnorth at hotmail.com (Bernard North)
Date: Mon, 22 May 2017 10:59:58 +0000
Subject: [R] JMdesign package
Message-ID: <LOXP123MB0871C0536E1B3D966FD41D28CCF80@LOXP123MB0871.GBRP123.PROD.OUTLOOK.COM>


Dear R list


I wonder please if anyone has experience they can share of the JMdesign package that performs sample sized for (surviival/longitudinal) joint models and is based on the paper "Sample size and power determination in joint modeling of longitudinal and survival data " by Chen et al (Statistics  in Medicine 2011) .

If so I do have a few queries please.

  1.  the vignette states that JMdesign can work when ?the variance-covariance matrix Sigma_theta is unknown.? This is the the covariance matrix of the intercept, linear and quadratic effects of the longitudinal profiles of the longitudinal (time-dependent) variable thats affecting event time.

I wonder if that refers to the input SigmaTheta to the R function powerLongSurv in the package  ? Because it looks to me as though most of the examples in the vignette do supply a value for that matrix and it errors if its missing. I realise section 3.2 of the Liddy Chen paper does refer to the unknown covariance matrix situation

  2.  I?m also a little confused as to what is meant in the JMdesign vignette by ?Example 1? and "formula 4.6". Do these refer to the Chen paper ? I can?t see a formula denoted 4.6.

  3.  The original Chen paper refers on page 3 to two possible objectives: 1)  power for testing the effect of the longitudinal trajectory and 2) power for testing the effect of a fixed covariate, eg treatment, that affects the trajectory (and therefore indirectly survival) but also has a direct effect on survival.
Does the power calculation in the current JMdesign package only provide power of the first test ?  I think it does but from the paper both calculations are possible.

  4.  Can anyone help with how to estimate the covariance matrix of the intercept, linear and quadratic effects for the Sigma_theta input. I thought theVarCorr output from a lmer mixed model analysis of the profiles might provide the elements for that matrix

my apologies for so many questions - many thanks for any thoughts on any of them

best wishes
Bernard

	[[alternative HTML version deleted]]


From dhiv.shreya at gmail.com  Mon May 22 07:16:31 2017
From: dhiv.shreya at gmail.com (Dhivya Narayanasamy)
Date: Mon, 22 May 2017 10:46:31 +0530
Subject: [R] Forecast using VAR model
In-Reply-To: <CAHrK5172qwa+hYeVv1bLXWNQrpwv84xFWWgQ7rfSMNHEHC6M+Q@mail.gmail.com>
References: <CACmggQvJb8pQPQ_eJBgPxAkfNT0ua4DrqGt-tEX6Hy9ODotq8Q@mail.gmail.com>
 <CAHrK5172qwa+hYeVv1bLXWNQrpwv84xFWWgQ7rfSMNHEHC6M+Q@mail.gmail.com>
Message-ID: <CACmggQtnj9uoR7yEawYm7ZaYvcY=JtUbx34K0gKKK_1_iNGrcw@mail.gmail.com>

Hi Jon,

sorry for the inconvenience. I have done it in plain text now.

I am building a VAR model to forecast of bivariate time series. But it
shows flat forecast and i am in need of correcting  it. Is there any way to
correct this flat forecast?  or Do i have to go with other models?

Code:

> datax.zoo <- read.zoo(datax)
> datax.ts <- ts(datax.zoo)
> v1b <- VARselect(datax.ts, lag.max = 10, type = "const")
> v1b$selection
AIC(n)  HQ(n)  SC(n) FPE(n)
    10      7      3     10
> var7 = VAR(datax.ts, p=7)
> serial.test(var7, lags.pt=10, type = "PT.asymptotic")

Portmanteau Test (asymptotic)

data:  Residuals of VAR object var7
Chi-squared = 31.991, df = 12, p-value = 0.001388

> gf1 <- forecast(var7, h = 600)
> plot(gf1, main = "var7")
> grangertest(datax.ts[,1] ~ datax.ts[,2], order = 7)
Granger causality test

Model 1: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7) + Lags(datax.ts[, 2], 1:7)
Model 2: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7)
  Res.Df Df      F    Pr(>F)
1   9968
2   9975 -7 20.852 < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> grangertest(datax.ts[,2] ~  datax.ts[,1], order = 7)
Granger causality test

Model 1: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7) + Lags(datax.ts[, 1], 1:7)
Model 2: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7)
  Res.Df Df      F   Pr(>F)
1   9968
2   9975 -7 3.0918 0.002948 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



The P value from "Portmanteau Test" is very much less than << 0.05 for
lagged value 7. Is this correct?
I have added my plot and raw data in the attachment for your further
reference. Thank you.



Regards| Mit freundlichen Gr??en,
> Dhivya Narayanasamy


Regards| Mit freundlichen Gr??en,

Dhivya Narayanasamy

Contact No: +91-8438505020

On Sun, May 21, 2017 at 5:40 PM, John C Frain <frainj at gmail.com> wrote:

> It would be much easier to see what you are doing if you reposted in plain
> text.
>
> John C Frain
> 3 Aranleigh Park
> Rathfarnham
> Dublin 14
> Ireland
> www.tcd.ie/Economics/staff/frainj/home.html
> mailto:frainj at tcd.ie
> mailto:frainj at gmail.com
>
> On 21 May 2017 at 06:05, Dhivya Narayanasamy <dhiv.shreya at gmail.com>
> wrote:
>
>> I am building a VAR model to forecast of bivariate timeseries. But it
>> shows
>> flat forecast.
>>
>> So I would like to use recursive window forecasting technique using VAR
>> model. Will it give what i expect (Avoid flat forecast) ? or should i have
>> to go with other package.
>>
>> > datax.zoo <- read.zoo(datax)> datax.ts <- ts(datax.zoo)> v1b <-
>> VARselect(datax.ts, lag.max = 10, type = "const")> v1b
>> $selection
>> AIC(n)  HQ(n)  SC(n) FPE(n)
>>      9      7      5      9
>>
>> $criteria
>>                   1            2            3            4
>> 5            6            7
>> AIC(n)     9.686513     9.657172     9.632444     9.625856
>> 9.621148     9.619425     9.615396
>> HQ(n)      9.688951     9.661234     9.638131     9.633167
>> 9.630085     9.629987     9.627583
>> SC(n)      9.693514     9.668839     9.648778     9.646856
>> 9.646815     9.649759     9.650397
>> FPE(n) 16099.014774 15633.507506 15251.665643 15151.510512
>> 15080.352425 15054.392389 14993.864861
>>                   8            9           10
>> AIC(n)     9.615430     9.615116     9.615990
>> HQ(n)      9.629241     9.630552     9.633051
>> SC(n)      9.655098     9.659451     9.664991
>> FPE(n) 14994.366572 14989.661383 15002.762011
>> > var7 = VAR(datax.ts, p=7)> serial.test(var7, lags.pt=10, type =
>> "PT.asymptotic")
>>
>>     Portmanteau Test (asymptotic)
>>
>> data:  Residuals of VAR object var7Chi-squared = 22.745, df = 12,
>> p-value = 0.02997
>> > grangertest(datax.ts[,1] ~ datax.ts[,2], order = 7)Granger causality
>> test
>> Model 1: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7) + Lags(datax.ts[,
>> 2], 1:7)Model 2: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7)
>>   Res.Df Df      F    Pr(>F)    1   5686                        2
>> 5693 -7 16.105 < 2.2e-16 ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01
>> ?*? 0.05 ?.? 0.1 ? ? 1> grangertest(datax.ts[,2] ~  datax.ts[,1],
>> order = 7)Granger causality test
>> Model 1: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7) + Lags(datax.ts[,
>> 1], 1:7)Model 2: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7)
>>   Res.Df Df      F Pr(>F)1   5686                 2   5693 -7 1.5618
>> 0.1418
>> > g <- forecast(var7, h = 600)> plot(g)
>>
>>
>> Also the 'P' value  from portmanteau test shows auto correlation is
>> present
>> is my VAR model. Here is my raw data you can find :
>> https://drive.google.com/file/d/0B7I0DT-PiG4RenVkdXV3OFJLYVk
>> /view?usp=sharing
>>
>>
>> Thank you.
>>
>> Regards
>> > Dhivya Narayanasamy
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

From jeddite4 at gmail.com  Mon May 22 11:32:27 2017
From: jeddite4 at gmail.com (Krzysiek Gniady)
Date: Mon, 22 May 2017 11:32:27 +0200
Subject: [R] R - datatable formatting with javascript
Message-ID: <CAHyXxWPNd-VK6NC3ffPdP4B1kBObKxof-2S3T63ASk4jfhu0-g@mail.gmail.com>

I'm trying to format datatable in R using DT package. I have code like this:

library(data.table)
library(DT)
data<-data.table(rbind(c(1,2,3),c(4,5,6)))
colnames(data)<- c('A','B','c')

datatable(data, rownames=F,
      colnames=c('A','B','C'),
      class='stripe cell-border hover',
      options=list(
        pageLength=100,
        dom='ltp',
        initComplete = JS("
                          function(settings, json) {
                          $(this.api().table().body()).css({
                          'background-color': 'red',
                          'outline-color': 'red',
                          'margin':'100px',
                          'color': 'violet',
                          'text-align': 'center',
                          'font-family': 'Courier New',
                          'border-radius': '25px'
                          });
                          $(this.api().table().header()).css({
                          'background-color': '#000',
                          'color': '#fff',
                          'outline-color': 'red',
                          'margin':'100px',
                          'text-align': 'center',
                          'font-family': 'Courier New',
                          'border-radius': '25px'
                          });
                          }
                          ")
        ),
      caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: center; color:black;
        font-size:200% ;','Table'),
      filter=list(position = 'top')
      )

And I have problem with javascript in function JS(). It modifies background
color (but only in header), font color and style. But commands to align
text or round corners don't work.

Why does it work like that? And how can I modify code to format this other
things?


Regards,

Jeddite

	[[alternative HTML version deleted]]


From paumarc at gmail.com  Mon May 22 14:41:20 2017
From: paumarc at gmail.com (=?UTF-8?Q?Pau_Marc_Mu=C3=B1oz_Torres?=)
Date: Mon, 22 May 2017 14:41:20 +0200
Subject: [R] problem with
Message-ID: <CADFuJLjQkmKVtU5J6+np9d5AuhWUqkfP95qPLpe4ZNwddUtt9g@mail.gmail.com>

Hello everybody

 I am trying to use system.file but it returns not file found

what I have done is

> sample <- system.file("results.xlsx","estdata", package =
"readxl",mustWork = TRUE)
Error in system.file("results.xlsx", "estdata", package = "readxl",
mustWork = TRUE) :
  no file found

i have checked the path was correct and the file exists with

FILES <- file.path("results.xlsx")
present <- file.exists(FILES)

and it returned a true values. Anyone can tell me which can be the problem ?

thanks


Pau Marc Mu?oz Torres
skype: pau_marc
http://www.linkedin.com/in/paumarc
http://www.researchgate.net/profile/Pau_Marc_Torres3/info/

	[[alternative HTML version deleted]]


From paumarc at gmail.com  Mon May 22 14:43:14 2017
From: paumarc at gmail.com (=?UTF-8?Q?Pau_Marc_Mu=C3=B1oz_Torres?=)
Date: Mon, 22 May 2017 14:43:14 +0200
Subject: [R] problem with system.file
Message-ID: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>

Hello everybody

 I am trying to use system.file but it returns not file found

what I have done is

> sample <- system.file("results.xlsx","estdata", package =
"readxl",mustWork = TRUE)
Error in system.file("results.xlsx", "estdata", package = "readxl",
mustWork = TRUE) :
  no file found

i have checked the path was correct and the file exists with

FILES <- file.path("results.xlsx")
present <- file.exists(FILES)

and it returned a true values. Anyone can tell me which can be the problem ?

thanks

Pau Marc Mu?oz Torres
skype: pau_marc
http://www.linkedin.com/in/paumarc
http://www.researchgate.net/profile/Pau_Marc_Torres3/info/

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon May 22 14:53:16 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 22 May 2017 14:53:16 +0200
Subject: [R] problem with system.file
In-Reply-To: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>
References: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>
Message-ID: <8BB34943-84E4-414B-B517-008B42A902D1@gmail.com>


> On 22 May 2017, at 14:43 , Pau Marc Mu?oz Torres <paumarc at gmail.com> wrote:
> 
> Hello everybody
> 
> I am trying to use system.file but it returns not file found
> 
> what I have done is
> 
>> sample <- system.file("results.xlsx","estdata", package =
> "readxl",mustWork = TRUE)
> Error in system.file("results.xlsx", "estdata", package = "readxl",
> mustWork = TRUE) :
>  no file found
> 
> i have checked the path was correct and the file exists with
> 
> FILES <- file.path("results.xlsx")
> present <- file.exists(FILES)
> 
> and it returned a true values. Anyone can tell me which can be the problem ?

Not if you don't tell us WHERE you expect to find the file... 

Where is it located, and what is the value of FILES above?

It is not unlikely that you misunderstande what system.file() is supposed to do.

-pd


> 
> thanks
> 
> Pau Marc Mu?oz Torres
> skype: pau_marc
> http://www.linkedin.com/in/paumarc
> http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ulrik.stervbo at gmail.com  Mon May 22 14:55:59 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 22 May 2017 12:55:59 +0000
Subject: [R] problem with system.file
In-Reply-To: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>
References: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>
Message-ID: <CAKVAULM8Fmzt0Mb+mKpKYjTFtRm22dLgt5aL+cr+A8pDrCbbfQ@mail.gmail.com>

What is your version of readxl?

In my version 1.0, there is no directory called estdata, but there is one
called extdata. However, in that directory there is no file called
"results.xlsx"

Either it was there once and has now gone missing or "results.xlsx" your
own file? It looks like the latter - and in which case, there is no point
in using system.file. Rather you should use read_xlsx([path/file]).

HTH
Ulrik

On Mon, 22 May 2017 at 14:44 Pau Marc Mu?oz Torres <paumarc at gmail.com>
wrote:

> Hello everybody
>
>  I am trying to use system.file but it returns not file found
>
> what I have done is
>
> > sample <- system.file("results.xlsx","estdata", package =
> "readxl",mustWork = TRUE)
> Error in system.file("results.xlsx", "estdata", package = "readxl",
> mustWork = TRUE) :
>   no file found
>
> i have checked the path was correct and the file exists with
>
> FILES <- file.path("results.xlsx")
> present <- file.exists(FILES)
>
> and it returned a true values. Anyone can tell me which can be the problem
> ?
>
> thanks
>
> Pau Marc Mu?oz Torres
> skype: pau_marc
> http://www.linkedin.com/in/paumarc
> http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May 22 16:35:49 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 22 May 2017 07:35:49 -0700
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <AM5P195MB00205C73AAC9BB5DD9391C8380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQH55Lv47+46Xxs_prJ7+Ay-XQPKg2_bEwD-ieLtF3i2A@mail.gmail.com>
 <AM5P195MB00205C73AAC9BB5DD9391C8380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbRwQMvuFavCatxGtgoYwLGrmOkqbXzi04yTr0Z0yiRZTA@mail.gmail.com>

You haven't said whether your "table" is a matrix or data frame.
Presumably the latter.

Nor have you answered my question about whether order of your meal
code pairs matters.

Another question: can meals be replicated for an ID or are they all different?

Finally, is this a homework assignment or class project of some sort?
Or is it a real task -- i.e., what is the context?

Again, be sure to cc the list.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 22, 2017 at 1:56 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> Hi Bert ..,
>
>
> The number of meals differ from one customer to other customer. You may find
> one customer with only one meal and another one with 2,3 or even rarely 30
> meals. You may also
>
> find no meal at all for some customers so the entire row takes the missing
> value "\N" . Any
>
> row starts with the meals codes first, then all missing values are to the
> right end of the table.
>
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 22 May 2017 03:11:11
> To: Allaisone 1
> Cc: r-help at r-project.org
> Subject: Re: [R] Identyfing rows with specific conditions
>
> Clarification:
>
> Does each customer have the same number of meals or do they differ
> from customer to customer? If the latter, how are missing meals
> notated? Do they always occur at the (right) end or can they occur
> anywhere in the row?
>
> Presumably each customer ID can have many different meal code
> combinations, right ?(since they can have 30 different meals with
> potentially 30 choose 2 = 435 combinations apiece)
>
> Please make sure you reply to the list, not just to me, as I may not
> pursue this further but am just trying to clarify for anyone else who
> may wish to help.
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>
>> Hi All..,
>>
>> I have 2 tables. The first one contains 2 columns with the headers say
>> "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each
>> of which with a different combination of meals(unique combination per row).
>>
>>
>>>Meals
>>
>>     meal A code      meal B code
>>
>> 1          34                   66
>>
>> 2           89                  39
>>
>> 3           25                   77
>>
>> The second table(customers) shows customers ids in the first column with
>> Meals codes(M) next to each customer. There are about 300,000 customers
>> (300,000 rows).
>>
>>> Customers
>>      1         2     3       4    ..30
>>      id       M1  M2   M3
>> 1   15      77    34    25
>> 2   11      25    34     39
>> 3    85     89     25    77
>> .
>> .
>> 300,000
>>
>> I would like to identify all customers ids who have had each meal
>> combination in the first table so the final output would be the first table
>> with ids attached next to each meal combination in each row like this:
>>
>>>IdsMeals
>>
>>
>>   MAcode  MBcode  ids
>>
>> 1     34        39            11
>>
>> 2     25       34              15   11
>>
>> 3      25     77                15   85
>>
>> Would you please suggest any solutions to this problem?
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon May 22 17:04:25 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 22 May 2017 15:04:25 +0000
Subject: [R] How to extract text contexts after clustering.
In-Reply-To: <A744EC35-9609-4135-A31E-7060DB17BD0F@gmail.com>
References: <HK2PR0301MB1187F2C14787C61DD07279EAA4F80@HK2PR0301MB1187.apcprd03.prod.outlook.com>
 <A744EC35-9609-4135-A31E-7060DB17BD0F@gmail.com>
Message-ID: <626def1252144613bcb5a8afe0b93cdb@exch-2p-mbx-w2.ads.tamu.edu>

As Ismail notes, you did not give us your code, only a few disconnected bits of your code. Assuming that by "top 1 group" you mean the largest group, here is a reproducible example:

# First create a reproducible set of data
set.seed(42)
mydata <- matrix(rnorm(300, 50, 10), 100, 3)
# A matrix with 100 rows and 3 columns of random normal variates

# Run kmeans and look at the structure of the returned object
mydata.km <- kmeans(mydata, centers=10)
str(mydata.km)
List of 9
 $ cluster     : int [1:100] 5 9 3 6 1 1 10 1 10 8 ...
 $ centers     : num [1:10, 1:3] 53.8 31.8 54.5 40.1 61 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:10] "1" "2" "3" "4" ...
  .. ..$ : NULL
 $ totss       : num 29069
 $ withinss    : num [1:10] 601 868 443 1242 717 ...
 $ tot.withinss: num 6554
 $ betweenss   : num 22515
 $ size        : int [1:10] 13 10 9 11 10 5 7 14 13 8
 $ iter        : int 3
 $ ifault      : int 0
 - attr(*, "class")= chr "kmeans"

# "size" is the number of observation in each cluster
# "cluster" is the cluster membership for each observation

which.max(mydata.km$size)
[1] 8
table(mydata.km$cluster)

 1  2  3  4  5  6  7  8  9 10 
13 10  9 11 10  5  7 14 13  8 

# which.max() shows you which cluster is the 
# largest, cluster number 8
# By sorting "size" you lost the information
# about which cluster was the largest
# table() shows you the number of observations in each cluster
# You can see that cluster 8 has 14 observations
# Now print the 14 observations that belong to cluster 8

mydata[mydata.km$cluster == 8, ]
          [,1]     [,2]     [,3]
 [1,] 49.37286 51.19161 48.14622
 [2,] 47.21211 44.95783 49.15892
 [3,] 56.35950 46.17666 50.37415
 [4,] 47.15747 44.87350 48.67912
 [5,] 48.28083 51.24702 44.78204
 [6,] 45.69531 45.71741 48.25982
 [7,] 47.42731 43.86328 55.15668
 [8,] 54.55450 55.67621 47.28236
 [9,] 56.42899 47.26354 51.90019
[10,] 50.89833 41.99718 50.46564
[11,] 55.81824 51.63207 53.83847
[12,] 50.88440 53.68807 44.30694
[13,] 48.79103 52.94654 56.35514
[14,] 45.23826 46.54912 54.46041

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ismail SEZEN
Sent: Sunday, May 21, 2017 10:09 PM
To: ? ? <yarmi1224 at hotmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] How to extract text contexts after clustering.

1- PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
2- PLEASE, first _read_ help for kmeans (?kmeans) function before using function.

> On 22 May 2017, at 05:33, ? ? <yarmi1224 at hotmail.com> wrote:
> 
> hi:
> I need to extract the text contexts of top 1 group after clustering.
> But I have no idea how to sort the cluster size then extract the contexts of top 1 clusters.

There isn?t a _top_ cluster for kmeans algorithm. There are _only_ clusters!

> 
> here is my cluster code:
> 
>> file <- read.csv("SiC CMP.csv", header = TRUE)

We don?t know what is in file$Main.IPC.

>> cluster_k<-length(unique(file$Main.IPC))
>> cl <- kmeans(IPC_Dtm , cluster_k)

What is IPC_Dtm?

> 
> 
> I have tried use??
> 
>> sort(cl$size, decreasing=T)

if you read the documentation, you would know cl$size means the number of points in each cluster. So, why do you sort them?

> [1] 341 107 104  80  51  22  15  11  10   8   8   5   5   5   4   4   4   3   3   2   2
> [22]   2   2   2   2   2   2   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1
> [43]   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1
> 
> But I have no idea how to extract the contexts of top 1 cluster.

If you read the _Value_ section of kmeans documentation, you will have an idea how to extract context by using cl$cluster.

> 
> 
> Eva
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From paumarc at gmail.com  Mon May 22 15:38:10 2017
From: paumarc at gmail.com (=?UTF-8?Q?Pau_Marc_Mu=C3=B1oz_Torres?=)
Date: Mon, 22 May 2017 15:38:10 +0200
Subject: [R] problem with system.file
In-Reply-To: <8BB34943-84E4-414B-B517-008B42A902D1@gmail.com>
References: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>
 <8BB34943-84E4-414B-B517-008B42A902D1@gmail.com>
Message-ID: <CADFuJLgNPcGn2cpZLYJku_UHBgm751JSGgh0=i350nhPEdRUAA@mail.gmail.com>

hi to you both

 You are right peter, I probably miss understood the system.file function.
I was trying to use it with a package from bioconductor and when i saw that
it didn't work for me, I tested with readxl and still do not working, so I
am doing something wrong with system.file

the original script was


library(SICtools)

bam1 <- system.file(package='SICtools','extdata','example1.bam')

the example1.bam file is supposed to be at the working directory (i changed
the directory using setwd()), it was changed to /home/paumarc/Bam

 i tried to change extdata for my working directory but it did not work

thanks

Pau Marc Mu?oz Torres
skype: pau_marc
http://www.linkedin.com/in/paumarc
http://www.researchgate.net/profile/Pau_Marc_Torres3/info/


2017-05-22 14:53 GMT+02:00 peter dalgaard <pdalgd at gmail.com>:

>
> > On 22 May 2017, at 14:43 , Pau Marc Mu?oz Torres <paumarc at gmail.com>
> wrote:
> >
> > Hello everybody
> >
> > I am trying to use system.file but it returns not file found
> >
> > what I have done is
> >
> >> sample <- system.file("results.xlsx","estdata", package =
> > "readxl",mustWork = TRUE)
> > Error in system.file("results.xlsx", "estdata", package = "readxl",
> > mustWork = TRUE) :
> >  no file found
> >
> > i have checked the path was correct and the file exists with
> >
> > FILES <- file.path("results.xlsx")
> > present <- file.exists(FILES)
> >
> > and it returned a true values. Anyone can tell me which can be the
> problem ?
>
> Not if you don't tell us WHERE you expect to find the file...
>
> Where is it located, and what is the value of FILES above?
>
> It is not unlikely that you misunderstande what system.file() is supposed
> to do.
>
> -pd
>
>
> >
> > thanks
> >
> > Pau Marc Mu?oz Torres
> > skype: pau_marc
> > http://www.linkedin.com/in/paumarc
> > http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From paumarc at gmail.com  Mon May 22 15:59:11 2017
From: paumarc at gmail.com (=?UTF-8?Q?Pau_Marc_Mu=C3=B1oz_Torres?=)
Date: Mon, 22 May 2017 15:59:11 +0200
Subject: [R] problem with system.file
In-Reply-To: <CADFuJLgNPcGn2cpZLYJku_UHBgm751JSGgh0=i350nhPEdRUAA@mail.gmail.com>
References: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>
 <8BB34943-84E4-414B-B517-008B42A902D1@gmail.com>
 <CADFuJLgNPcGn2cpZLYJku_UHBgm751JSGgh0=i350nhPEdRUAA@mail.gmail.com>
Message-ID: <CADFuJLjMgRHadWZ_rZzr5RqjP_=2p4CqLQ8PdJObnu7bUh6_gA@mail.gmail.com>

i could make it worl, thanks for your help, it was usefull

Pau Marc Mu?oz Torres
skype: pau_marc
http://www.linkedin.com/in/paumarc
http://www.researchgate.net/profile/Pau_Marc_Torres3/info/


2017-05-22 15:38 GMT+02:00 Pau Marc Mu?oz Torres <paumarc at gmail.com>:

> hi to you both
>
>  You are right peter, I probably miss understood the system.file function.
> I was trying to use it with a package from bioconductor and when i saw that
> it didn't work for me, I tested with readxl and still do not working, so I
> am doing something wrong with system.file
>
> the original script was
>
>
> library(SICtools)
>
> bam1 <- system.file(package='SICtools','extdata','example1.bam')
>
> the example1.bam file is supposed to be at the working directory (i
> changed the directory using setwd()), it was changed to /home/paumarc/Bam
>
>  i tried to change extdata for my working directory but it did not work
>
> thanks
>
> Pau Marc Mu?oz Torres
> skype: pau_marc
> http://www.linkedin.com/in/paumarc
> http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>
>
> 2017-05-22 14:53 GMT+02:00 peter dalgaard <pdalgd at gmail.com>:
>
>>
>> > On 22 May 2017, at 14:43 , Pau Marc Mu?oz Torres <paumarc at gmail.com>
>> wrote:
>> >
>> > Hello everybody
>> >
>> > I am trying to use system.file but it returns not file found
>> >
>> > what I have done is
>> >
>> >> sample <- system.file("results.xlsx","estdata", package =
>> > "readxl",mustWork = TRUE)
>> > Error in system.file("results.xlsx", "estdata", package = "readxl",
>> > mustWork = TRUE) :
>> >  no file found
>> >
>> > i have checked the path was correct and the file exists with
>> >
>> > FILES <- file.path("results.xlsx")
>> > present <- file.exists(FILES)
>> >
>> > and it returned a true values. Anyone can tell me which can be the
>> problem ?
>>
>> Not if you don't tell us WHERE you expect to find the file...
>>
>> Where is it located, and what is the value of FILES above?
>>
>> It is not unlikely that you misunderstande what system.file() is supposed
>> to do.
>>
>> -pd
>>
>>
>> >
>> > thanks
>> >
>> > Pau Marc Mu?oz Torres
>> > skype: pau_marc
>> > http://www.linkedin.com/in/paumarc
>> > http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From wjm1 at caa.columbia.edu  Mon May 22 20:04:27 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Mon, 22 May 2017 11:04:27 -0700
Subject: [R] [FORGED] Logical Operators' inconsistent Behavior
In-Reply-To: <CABdHhvG3qziQEzL7gHCgN=6kXhqYK_288heA=ybta5OAmbidvw@mail.gmail.com>
References: <CAMLd9E4Nxq0WycSQ9CYgawzs-p9hC5GSbbpH2=7zpZXv-s6dxQ@mail.gmail.com>
 <ae4206d9-f182-9ed5-e1f9-9ffefbc2010c@auckland.ac.nz>
 <1A8C1289955EF649A09086A153E267240B9597D5EC@GBTEDVPEXCMB04.corp.lgc-group.com>
 <CABdHhvG3qziQEzL7gHCgN=6kXhqYK_288heA=ybta5OAmbidvw@mail.gmail.com>
Message-ID: <CAA99HCxZbuDBzoObAiqr-fBCUSDqxKOaXqQ-yOsMG39hAMVegQ@mail.gmail.com>

Evaluation of the NOT, AND, OR logical statements below in MySQL
5.5.30-log Community Server (GPL) replicate R's truth tables for NOT,
AND, OR. See MySQL queries (below), which are in agreement with R
truth table code posted in this thread:


bash-3.2$ mysql
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 346
Server version: 5.5.30-log MySQL Community Server (GPL)
Copyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.
Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> SELECT FALSE, NULL, TRUE;
+-------+------+------+
| FALSE | NULL | TRUE |
+-------+------+------+
|     0 | NULL |    1 |
+-------+------+------+
1 row in set (0.00 sec)

mysql> SELECT NOT FALSE, NOT NULL, NOT TRUE;
+-----------+----------+----------+
| NOT FALSE | NOT NULL | NOT TRUE |
+-----------+----------+----------+
|         1 |     NULL |        0 |
+-----------+----------+----------+
1 row in set (0.00 sec)

mysql> SELECT FALSE AND FALSE,
    -> FALSE AND NULL,
    -> FALSE AND TRUE;
+-----------------+----------------+----------------+
| FALSE AND FALSE | FALSE AND NULL | FALSE AND TRUE |
+-----------------+----------------+----------------+
|               0 |              0 |              0 |
+-----------------+----------------+----------------+
1 row in set (0.00 sec)

mysql> SELECT NULL AND NULL,
    -> NULL AND TRUE,
    -> TRUE AND TRUE;
+---------------+---------------+---------------+
| NULL AND NULL | NULL AND TRUE | TRUE AND TRUE |
+---------------+---------------+---------------+
|          NULL |          NULL |             1 |
+---------------+---------------+---------------+
1 row in set (0.00 sec)

mysql> SELECT TRUE OR TRUE,
    -> NULL OR TRUE,
    -> FALSE OR TRUE;
+--------------+--------------+---------------+
| TRUE OR TRUE | NULL OR TRUE | FALSE OR TRUE |
+--------------+--------------+---------------+
|            1 |            1 |             1 |
+--------------+--------------+---------------+
1 row in set (0.00 sec)

mysql> SELECT NULL OR NULL,
    -> FALSE OR NULL,
    -> FALSE OR FALSE;
+--------------+---------------+----------------+
| NULL OR NULL | FALSE OR NULL | FALSE OR FALSE |
+--------------+---------------+----------------+
|         NULL |          NULL |              0 |
+--------------+---------------+----------------+
1 row in set (0.00 sec)

mysql>


HTH,

Bill

William Michels, Ph.D.


On Sun, May 21, 2017 at 7:00 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> On Fri, May 19, 2017 at 6:38 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>>> TRUE & FALSE is FALSE but TRUE & TRUE is TRUE, so TRUE & NA could be
>>> either TRUE or FALSE and consequently is NA.
>>>
>>> OTOH FALSE & (anything) is FALSE so FALSE & NA is FALSE.
>>>
>>> As I said *think* about it; don't just go with your immediate knee-jerk
>>> (simplistic) reaction.
>>
>> Hmm... not sure that was quite fair to the OP. Yes,  FALSE & <anything> == FALSE. But 'NA' does not mean 'anything'; it means 'missing' (see ?'NA'). It is much less obvious that FALSE & <missing> should generate a non-missing value. SQL, for example, generally  takes the view that any expression involving 'missing' is 'missing'.
>
> That's not TRUE ;)
>
> sqlite> select (3 > 2) OR NULL;
> 1
>
> sqlite> select (4 < 3) AND NULL;
> 0
>
> Hadley
>
>
> --
> http://hadley.nz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From viiskola at yahoo.com  Mon May 22 21:02:46 2017
From: viiskola at yahoo.com (ville iiskola)
Date: Mon, 22 May 2017 19:02:46 +0000 (UTC)
Subject: [R] Duplicate row names are not allowed
References: <931132147.3122221.1495479766544.ref@mail.yahoo.com>
Message-ID: <931132147.3122221.1495479766544@mail.yahoo.com>

Hi
I read a book where was?shown an example how to?create a probability model with mlogit.?I tried to do like the instruction said but?i get error message that "duplicate row names are not allowed".?What could i do to fix it?

I had the data in excel and imported it to R using R commander. I attach the data file and print sqreen of my code to here if somebody could help the?novice.?Ville
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2017-05-21 (1).png
Type: image/png
Size: 98244 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170522/0a885163/attachment.png>

From andrea.goijman at gmail.com  Mon May 22 21:10:49 2017
From: andrea.goijman at gmail.com (Andrea Goijman)
Date: Mon, 22 May 2017 16:10:49 -0300
Subject: [R] R truncating decimal places
Message-ID: <CA+vCKnU5YXeTon8AYacqRksc0rWVNa15V5duw+82KuRdZw88rQ@mail.gmail.com>

Hello list,

I' trying to estimate a log likelihood function from my data.
I apply the mean to all my simulations, and I get something like this:

apply(likelihood, c(2, 3, 4), mean,na.rm=TRUE)
, , 1

             [,1]       [,2]       [,3]      [,4]      [,5]        [,6]
 [,7]
  [1,] 0.73162327 0.81197093 0.58216435 0.7295733 0.8930731 0.971775402
0.8882391
  [2,] 0.73162327 0.81197093 0.00000000 0.7295733 0.8930731 0.971775402
0.8882391

If you note, there is a 0.00000000 value, and it seems that R is truncating
it as a zero, because when I apply the log

apply(likelihood, c(2, 3, 4), mean,na.rm=TRUE)

I get a "-inf" at that position...


How do I avoid R truncating this value?

Thanks!

Andrea

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon May 22 23:15:56 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 22 May 2017 14:15:56 -0700
Subject: [R] R truncating decimal places
In-Reply-To: <CA+vCKnU5YXeTon8AYacqRksc0rWVNa15V5duw+82KuRdZw88rQ@mail.gmail.com>
References: <CA+vCKnU5YXeTon8AYacqRksc0rWVNa15V5duw+82KuRdZw88rQ@mail.gmail.com>
Message-ID: <CAF8bMcZvN3gKY4y4asqQ_NFxARX4MA-D2r8z=wey6xwxvwPvUw@mail.gmail.com>

Do not compute the log likelihood as the log of the product of
probabilities.  Instead compute it as the sum of logs of probabilities.
The latter is less likely to underflow (go below c. 0^-309).

Most (all?) of the built-in probability density functions have a 'log'
argument; when log=TRUE you get the log of the density.

E.g.,

> x <- 1:100
> log(prod(dnorm( (x-50)/2 )))
[1] -Inf
> sum(dnorm( (x-50)/2, log=TRUE ))
[1] -10510.64
>
> log(prod(dnorm( (x-50)/20 )))
[1] -196.0814
> sum(dnorm( (x-50)/20, log=TRUE ))
[1] -196.0814



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, May 22, 2017 at 12:10 PM, Andrea Goijman <andrea.goijman at gmail.com>
wrote:

> Hello list,
>
> I' trying to estimate a log likelihood function from my data.
> I apply the mean to all my simulations, and I get something like this:
>
> apply(likelihood, c(2, 3, 4), mean,na.rm=TRUE)
> , , 1
>
>              [,1]       [,2]       [,3]      [,4]      [,5]        [,6]
>  [,7]
>   [1,] 0.73162327 0.81197093 0.58216435 0.7295733 0.8930731 0.971775402
> 0.8882391
>   [2,] 0.73162327 0.81197093 0.00000000 0.7295733 0.8930731 0.971775402
> 0.8882391
>
> If you note, there is a 0.00000000 value, and it seems that R is truncating
> it as a zero, because when I apply the log
>
> apply(likelihood, c(2, 3, 4), mean,na.rm=TRUE)
>
> I get a "-inf" at that position...
>
>
> How do I avoid R truncating this value?
>
> Thanks!
>
> Andrea
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue May 23 00:00:00 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 22 May 2017 15:00:00 -0700
Subject: [R] Duplicate row names are not allowed
In-Reply-To: <931132147.3122221.1495479766544@mail.yahoo.com>
References: <931132147.3122221.1495479766544.ref@mail.yahoo.com>
 <931132147.3122221.1495479766544@mail.yahoo.com>
Message-ID: <86A8C533-4CFD-43F8-8B29-14C8F18F61A0@dcn.davis.ca.us>

Start with the Posting Guide mentioned at the bottom of this email.  Note that only a very few types of attachments are permitted on this list... yours apparently were not. We generally find that providing a reproducible example that includes the data in the R code and the statements that cause difficulty all together [1][2][3] conveys questions with as little room for misunderstanding as possible.

It does seem like there is something wrong with your data import code  that is confusing data that belongs inside the data frame with row names. Just what the problem is depends on what code you used to import your data and how that data is stored in the file. You need to learn how to use the str function to examine your data, and getting us a reprex will help us help you. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html
-- 
Sent from my phone. Please excuse my brevity.

On May 22, 2017 12:02:46 PM PDT, ville iiskola via R-help <r-help at r-project.org> wrote:
>Hi
>I read a book where was?shown an example how to?create a probability
>model with mlogit.?I tried to do like the instruction said but?i get
>error message that "duplicate row names are not allowed".?What could i
>do to fix it?
>
>I had the data in excel and imported it to R using R commander. I
>attach the data file and print sqreen of my code to here if somebody
>could help the?novice.?Ville


From drjimlemon at gmail.com  Tue May 23 00:22:06 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 23 May 2017 08:22:06 +1000
Subject: [R] problem with system.file
In-Reply-To: <CADFuJLjMgRHadWZ_rZzr5RqjP_=2p4CqLQ8PdJObnu7bUh6_gA@mail.gmail.com>
References: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>
 <8BB34943-84E4-414B-B517-008B42A902D1@gmail.com>
 <CADFuJLgNPcGn2cpZLYJku_UHBgm751JSGgh0=i350nhPEdRUAA@mail.gmail.com>
 <CADFuJLjMgRHadWZ_rZzr5RqjP_=2p4CqLQ8PdJObnu7bUh6_gA@mail.gmail.com>
Message-ID: <CA+8X3fW7Tqj=XdsBoKt-LnBTkOdo10+waFmnhaYu+ZznL0E+qA@mail.gmail.com>

Windows. A funny name for a operating system that doesn't let you see anything.

Jim

On Mon, May 22, 2017 at 11:59 PM, Pau Marc Mu?oz Torres
<paumarc at gmail.com> wrote:
> i could make it worl, thanks for your help, it was usefull
>
> Pau Marc Mu?oz Torres
> skype: pau_marc
> http://www.linkedin.com/in/paumarc
> http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>
>
> 2017-05-22 15:38 GMT+02:00 Pau Marc Mu?oz Torres <paumarc at gmail.com>:
>
>> hi to you both
>>
>>  You are right peter, I probably miss understood the system.file function.
>> I was trying to use it with a package from bioconductor and when i saw that
>> it didn't work for me, I tested with readxl and still do not working, so I
>> am doing something wrong with system.file
>>
>> the original script was
>>
>>
>> library(SICtools)
>>
>> bam1 <- system.file(package='SICtools','extdata','example1.bam')
>>
>> the example1.bam file is supposed to be at the working directory (i
>> changed the directory using setwd()), it was changed to /home/paumarc/Bam
>>
>>  i tried to change extdata for my working directory but it did not work
>>
>> thanks
>>
>> Pau Marc Mu?oz Torres
>> skype: pau_marc
>> http://www.linkedin.com/in/paumarc
>> http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>>
>>
>> 2017-05-22 14:53 GMT+02:00 peter dalgaard <pdalgd at gmail.com>:
>>
>>>
>>> > On 22 May 2017, at 14:43 , Pau Marc Mu?oz Torres <paumarc at gmail.com>
>>> wrote:
>>> >
>>> > Hello everybody
>>> >
>>> > I am trying to use system.file but it returns not file found
>>> >
>>> > what I have done is
>>> >
>>> >> sample <- system.file("results.xlsx","estdata", package =
>>> > "readxl",mustWork = TRUE)
>>> > Error in system.file("results.xlsx", "estdata", package = "readxl",
>>> > mustWork = TRUE) :
>>> >  no file found
>>> >
>>> > i have checked the path was correct and the file exists with
>>> >
>>> > FILES <- file.path("results.xlsx")
>>> > present <- file.exists(FILES)
>>> >
>>> > and it returned a true values. Anyone can tell me which can be the
>>> problem ?
>>>
>>> Not if you don't tell us WHERE you expect to find the file...
>>>
>>> Where is it located, and what is the value of FILES above?
>>>
>>> It is not unlikely that you misunderstande what system.file() is supposed
>>> to do.
>>>
>>> -pd
>>>
>>>
>>> >
>>> > thanks
>>> >
>>> > Pau Marc Mu?oz Torres
>>> > skype: pau_marc
>>> > http://www.linkedin.com/in/paumarc
>>> > http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue May 23 01:00:31 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 22 May 2017 16:00:31 -0700
Subject: [R] problem with system.file
In-Reply-To: <CA+8X3fW7Tqj=XdsBoKt-LnBTkOdo10+waFmnhaYu+ZznL0E+qA@mail.gmail.com>
References: <CADFuJLgRNnNk82zePz+PHM3kZ9dRUCrC6dABwniHFSax0nfSig@mail.gmail.com>
 <8BB34943-84E4-414B-B517-008B42A902D1@gmail.com>
 <CADFuJLgNPcGn2cpZLYJku_UHBgm751JSGgh0=i350nhPEdRUAA@mail.gmail.com>
 <CADFuJLjMgRHadWZ_rZzr5RqjP_=2p4CqLQ8PdJObnu7bUh6_gA@mail.gmail.com>
 <CA+8X3fW7Tqj=XdsBoKt-LnBTkOdo10+waFmnhaYu+ZznL0E+qA@mail.gmail.com>
Message-ID: <6E92BC46-39EF-4504-857E-0298EB43EBD7@dcn.davis.ca.us>

Did not look to me like Windows was a factor here... OP referred to /home/paumarc/Bam. I think the issue was trying to access his own data using an inappropriate function.
-- 
Sent from my phone. Please excuse my brevity.

On May 22, 2017 3:22:06 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Windows. A funny name for a operating system that doesn't let you see
>anything.
>
>Jim
>
>On Mon, May 22, 2017 at 11:59 PM, Pau Marc Mu?oz Torres
><paumarc at gmail.com> wrote:
>> i could make it worl, thanks for your help, it was usefull
>>
>> Pau Marc Mu?oz Torres
>> skype: pau_marc
>> http://www.linkedin.com/in/paumarc
>> http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>>
>>
>> 2017-05-22 15:38 GMT+02:00 Pau Marc Mu?oz Torres <paumarc at gmail.com>:
>>
>>> hi to you both
>>>
>>>  You are right peter, I probably miss understood the system.file
>function.
>>> I was trying to use it with a package from bioconductor and when i
>saw that
>>> it didn't work for me, I tested with readxl and still do not
>working, so I
>>> am doing something wrong with system.file
>>>
>>> the original script was
>>>
>>>
>>> library(SICtools)
>>>
>>> bam1 <- system.file(package='SICtools','extdata','example1.bam')
>>>
>>> the example1.bam file is supposed to be at the working directory (i
>>> changed the directory using setwd()), it was changed to
>/home/paumarc/Bam
>>>
>>>  i tried to change extdata for my working directory but it did not
>work
>>>
>>> thanks
>>>
>>> Pau Marc Mu?oz Torres
>>> skype: pau_marc
>>> http://www.linkedin.com/in/paumarc
>>> http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>>>
>>>
>>> 2017-05-22 14:53 GMT+02:00 peter dalgaard <pdalgd at gmail.com>:
>>>
>>>>
>>>> > On 22 May 2017, at 14:43 , Pau Marc Mu?oz Torres
><paumarc at gmail.com>
>>>> wrote:
>>>> >
>>>> > Hello everybody
>>>> >
>>>> > I am trying to use system.file but it returns not file found
>>>> >
>>>> > what I have done is
>>>> >
>>>> >> sample <- system.file("results.xlsx","estdata", package =
>>>> > "readxl",mustWork = TRUE)
>>>> > Error in system.file("results.xlsx", "estdata", package =
>"readxl",
>>>> > mustWork = TRUE) :
>>>> >  no file found
>>>> >
>>>> > i have checked the path was correct and the file exists with
>>>> >
>>>> > FILES <- file.path("results.xlsx")
>>>> > present <- file.exists(FILES)
>>>> >
>>>> > and it returned a true values. Anyone can tell me which can be
>the
>>>> problem ?
>>>>
>>>> Not if you don't tell us WHERE you expect to find the file...
>>>>
>>>> Where is it located, and what is the value of FILES above?
>>>>
>>>> It is not unlikely that you misunderstande what system.file() is
>supposed
>>>> to do.
>>>>
>>>> -pd
>>>>
>>>>
>>>> >
>>>> > thanks
>>>> >
>>>> > Pau Marc Mu?oz Torres
>>>> > skype: pau_marc
>>>> > http://www.linkedin.com/in/paumarc
>>>> > http://www.researchgate.net/profile/Pau_Marc_Torres3/info/
>>>> >
>>>> >       [[alternative HTML version deleted]]
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible
>code.
>>>>
>>>> --
>>>> Peter Dalgaard, Professor,
>>>> Center for Statistics, Copenhagen Business School
>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Office: A 4.23
>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Tue May 23 06:56:35 2017
From: chocold12 at gmail.com (lily li)
Date: Mon, 22 May 2017 22:56:35 -0600
Subject: [R] About change columns and specific rows in R
Message-ID: <CAN5afy-KJsLvXnmv3JLM3P=v1mqDSjcZKSajw_8GRM2m52G+Hw@mail.gmail.com>

Hi R users,

I have a question about manipulating the dataframe. I want to create a new
dataframe, and to multiply rows with different seasons for different
constants.

DF
year   month   day   product1   product2   product3
1981     1          1         18              56            20
1981     1          2         19              45            22
1981     1          3         16              48            28
1981     1          4         19              50            21
1981     2          1         17              49            25
1981     2          2         20              47            23
1981     2          3         21              52            27

For example, how to multiply product1 in month1 by 3.1, and to multiply
product3 in month2 by 2.0? I wrote the code like this but does not work.
Thanks for your help.

DF['month'==1, ]$product1_1 = DF['month'==1, ]$product1 * 3.1;
DF['month'==2, ]$product3_1 = DF['month'==1, ]$product3 * 2.0;

	[[alternative HTML version deleted]]


From wjm1 at caa.columbia.edu  Tue May 23 08:45:29 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Mon, 22 May 2017 23:45:29 -0700
Subject: [R] About change columns and specific rows in R
In-Reply-To: <CAN5afy-KJsLvXnmv3JLM3P=v1mqDSjcZKSajw_8GRM2m52G+Hw@mail.gmail.com>
References: <CAN5afy-KJsLvXnmv3JLM3P=v1mqDSjcZKSajw_8GRM2m52G+Hw@mail.gmail.com>
Message-ID: <CAA99HCyNFxTZSpGeeeP3ZiffXOJog44C_ioyR-BdEnSiJTy7gA@mail.gmail.com>

Hi Lily,

You're on the right track, but you should define a new column first
(filled with NA values), then specify the precise rows and columns on
both the left and right hand sides of the assignment operator that
will be altered. Luckily, this is pretty easy...just remember to use
which() on the right hand side of the assignment operator to get the
index of the rows you want. Example below for "product1":

> DF$product1_1 <- NA
> DF[DF$month == 1, "product1_1"] <- DF[which(DF$month == 1), "product1"]*3.1
>


HTH,

Bill.

William Michels, Ph.D.




On Mon, May 22, 2017 at 9:56 PM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I have a question about manipulating the dataframe. I want to create a new
> dataframe, and to multiply rows with different seasons for different
> constants.
>
> DF
> year   month   day   product1   product2   product3
> 1981     1          1         18              56            20
> 1981     1          2         19              45            22
> 1981     1          3         16              48            28
> 1981     1          4         19              50            21
> 1981     2          1         17              49            25
> 1981     2          2         20              47            23
> 1981     2          3         21              52            27
>
> For example, how to multiply product1 in month1 by 3.1, and to multiply
> product3 in month2 by 2.0? I wrote the code like this but does not work.
> Thanks for your help.
>
> DF['month'==1, ]$product1_1 = DF['month'==1, ]$product1 * 3.1;
> DF['month'==2, ]$product3_1 = DF['month'==1, ]$product3 * 2.0;
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From calandra at rgzm.de  Tue May 23 08:57:49 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Tue, 23 May 2017 08:57:49 +0200
Subject: [R] About change columns and specific rows in R
In-Reply-To: <CAA99HCyNFxTZSpGeeeP3ZiffXOJog44C_ioyR-BdEnSiJTy7gA@mail.gmail.com>
References: <CAN5afy-KJsLvXnmv3JLM3P=v1mqDSjcZKSajw_8GRM2m52G+Hw@mail.gmail.com>
 <CAA99HCyNFxTZSpGeeeP3ZiffXOJog44C_ioyR-BdEnSiJTy7gA@mail.gmail.com>
Message-ID: <83d3be54-34ce-3f09-b5a4-4bb65ea5f5d9@rgzm.de>

Hi,

Actually, you don't need to create the column first, nor to use which:
DF[DF$month==1, "product1_1"] = DF[DF$month==1, "product1"] * 3.1

The "[" is a great tool that you need to learn. In this case, you don't 
need to combine "[" and $: within the square brackets, the vector before 
the comma indexes the rows and the one after the comma indexes the columns.

The other thing you were missing correctly referencing the rows. You 
have to specify the data.frame you want to look into.

And last, learn to use dput() to provide a nice reproducible example.

HTH,
Ivan


--
Dr. Ivan Calandra
TraCEr, Laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 23/05/2017 08:45, William Michels via R-help wrote:
> Hi Lily,
>
> You're on the right track, but you should define a new column first
> (filled with NA values), then specify the precise rows and columns on
> both the left and right hand sides of the assignment operator that
> will be altered. Luckily, this is pretty easy...just remember to use
> which() on the right hand side of the assignment operator to get the
> index of the rows you want. Example below for "product1":
>
>> DF$product1_1 <- NA
>> DF[DF$month == 1, "product1_1"] <- DF[which(DF$month == 1), "product1"]*3.1
>>
>
> HTH,
>
> Bill.
>
> William Michels, Ph.D.
>
>
>
>
> On Mon, May 22, 2017 at 9:56 PM, lily li <chocold12 at gmail.com> wrote:
>> Hi R users,
>>
>> I have a question about manipulating the dataframe. I want to create a new
>> dataframe, and to multiply rows with different seasons for different
>> constants.
>>
>> DF
>> year   month   day   product1   product2   product3
>> 1981     1          1         18              56            20
>> 1981     1          2         19              45            22
>> 1981     1          3         16              48            28
>> 1981     1          4         19              50            21
>> 1981     2          1         17              49            25
>> 1981     2          2         20              47            23
>> 1981     2          3         21              52            27
>>
>> For example, how to multiply product1 in month1 by 3.1, and to multiply
>> product3 in month2 by 2.0? I wrote the code like this but does not work.
>> Thanks for your help.
>>
>> DF['month'==1, ]$product1_1 = DF['month'==1, ]$product1 * 3.1;
>> DF['month'==2, ]$product3_1 = DF['month'==1, ]$product3 * 2.0;
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wjm1 at caa.columbia.edu  Tue May 23 09:34:34 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Tue, 23 May 2017 00:34:34 -0700
Subject: [R] About change columns and specific rows in R
In-Reply-To: <83d3be54-34ce-3f09-b5a4-4bb65ea5f5d9@rgzm.de>
References: <CAN5afy-KJsLvXnmv3JLM3P=v1mqDSjcZKSajw_8GRM2m52G+Hw@mail.gmail.com>
 <CAA99HCyNFxTZSpGeeeP3ZiffXOJog44C_ioyR-BdEnSiJTy7gA@mail.gmail.com>
 <83d3be54-34ce-3f09-b5a4-4bb65ea5f5d9@rgzm.de>
Message-ID: <CAA99HCzigy66AFW9ziYkywiRFzQW0HXxHPGhZXbOc3suaFA+Hw@mail.gmail.com>

Hi Ivan,

I was just writing a follow-up note as your note came in. While the
code I posted previously works fine, using which() is unnecessary.

> DF <- read.csv("~/lily.csv")
> DF$product1_1 <- NA
> DF$product1_1 <- DF[DF$month == 1, "product1"]*3.1
Error in `$<-.data.frame`(`*tmp*`, "product1_1", value = c(55.8, 58.9,  :
  replacement has 4 rows, data has 7
> DF$product1_1 <- DF[which(DF$month == 1), "product1"]*3.1
Error in `$<-.data.frame`(`*tmp*`, "product1_1", value = c(55.8, 58.9,  :
  replacement has 4 rows, data has 7
> DF[DF$month == 1, "product1_1"] <- DF[DF$month == 1, "product1"]*3.1
> DF
  year month day product1 product2 product3 product1_1
1 1981     1   1       18       56       20       55.8
2 1981     1   2       19       45       22       58.9
3 1981     1   3       16       48       28       49.6
4 1981     1   4       19       50       21       58.9
5 1981     2   1       17       49       25         NA
6 1981     2   2       20       47       23         NA
7 1981     2   3       21       52       27         NA
>

The two errors above were caused because I failed to specify rows on
the left hand side of the assignment operator, not because I failed to
use which(). Once rows and columns are specified on both sides, the
assignment works fine.

(I do however, prefer to create an "NA" column first. Personal preference ;-).

Best Regards,

Bill.



On Mon, May 22, 2017 at 11:57 PM, Ivan Calandra <calandra at rgzm.de> wrote:
> Hi,
>
> Actually, you don't need to create the column first, nor to use which:
> DF[DF$month==1, "product1_1"] = DF[DF$month==1, "product1"] * 3.1
>
> The "[" is a great tool that you need to learn. In this case, you don't need
> to combine "[" and $: within the square brackets, the vector before the
> comma indexes the rows and the one after the comma indexes the columns.
>
> The other thing you were missing correctly referencing the rows. You have to
> specify the data.frame you want to look into.
>
> And last, learn to use dput() to provide a nice reproducible example.
>
> HTH,
> Ivan
>
>
> --
> Dr. Ivan Calandra
> TraCEr, Laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 23/05/2017 08:45, William Michels via R-help wrote:
>>
>> Hi Lily,
>>
>> You're on the right track, but you should define a new column first
>> (filled with NA values), then specify the precise rows and columns on
>> both the left and right hand sides of the assignment operator that
>> will be altered. Luckily, this is pretty easy...just remember to use
>> which() on the right hand side of the assignment operator to get the
>> index of the rows you want. Example below for "product1":
>>
>>> DF$product1_1 <- NA
>>> DF[DF$month == 1, "product1_1"] <- DF[which(DF$month == 1),
>>> "product1"]*3.1
>>>
>>
>> HTH,
>>
>> Bill.
>>
>> William Michels, Ph.D.
>>
>>
>>
>>
>> On Mon, May 22, 2017 at 9:56 PM, lily li <chocold12 at gmail.com> wrote:
>>>
>>> Hi R users,
>>>
>>> I have a question about manipulating the dataframe. I want to create a
>>> new
>>> dataframe, and to multiply rows with different seasons for different
>>> constants.
>>>
>>> DF
>>> year   month   day   product1   product2   product3
>>> 1981     1          1         18              56            20
>>> 1981     1          2         19              45            22
>>> 1981     1          3         16              48            28
>>> 1981     1          4         19              50            21
>>> 1981     2          1         17              49            25
>>> 1981     2          2         20              47            23
>>> 1981     2          3         21              52            27
>>>
>>> For example, how to multiply product1 in month1 by 3.1, and to multiply
>>> product3 in month2 by 2.0? I wrote the code like this but does not work.
>>> Thanks for your help.
>>>
>>> DF['month'==1, ]$product1_1 = DF['month'==1, ]$product1 * 3.1;
>>> DF['month'==2, ]$product3_1 = DF['month'==1, ]$product3 * 2.0;
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Tue May 23 10:47:22 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Tue, 23 May 2017 20:47:22 +1200
Subject: [R] Error in readRDS(dest) (was Re: Error with installed.packages
 with R 3.4.0 on Windows)
In-Reply-To: <7b8f4895-b41d-6634-367b-1754bc737c02@roswellpark.org>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
 <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
 <20170522091022.GC4553@slingshot.co.nz>
 <7b8f4895-b41d-6634-367b-1754bc737c02@roswellpark.org>
Message-ID: <20170523084722.GD4553@slingshot.co.nz>

On Mon, 22-May-2017 at 05:43AM -0400, Martin Morgan wrote:

|> On 05/22/2017 05:10 AM, Patrick Connolly wrote:

|> >Apparently it isn't harmless.
|> >
|> >>install.packages("withr")
|> >Error in readRDS(dest) : error reading from connection
|> 
|> that seems like a plain-old network connectivity issue, or perhaps
|> an issue with the CRAN mirror you're using. Can you debug on your
|> end, e.g,.
|> 
|>   options(error=recover)
|>   install.packages("withr")
|>   ...
|> 
|> then select the 'frame' where the error occurs, look around
|> 
|>   ls()
|> 
|> find the value of 'dest', and e.g., try to open dest in your  browser.

This is what I get

>   options(error=recover)
>   install.packages("withr")
^C

Enter a frame number, or 0 to exit   

1: install.packages("withr")
2: available.packages(contriburl = contriburl, method = method)
3: tryCatch({
    download.file(url = paste0(repos, "/PACKAGES.rds"), destfile
4: tryCatchList(expr, classes, parentenv, handlers)
5: tryCatchOne(expr, names, parentenv, handlers[[1]])
6: doTryCatch(return(expr), name, parentenv, handler)
7: download.file(url = paste0(repos, "/PACKAGES.rds"), destfile = dest, method

Selection: 7
Called from: eval(substitute(browser(skipCalls = skip), list(skip = 7 - which)), 
    envir = sys.frame(which))
Browse[1]> dest
Error during wrapup: object 'dest' not found

That indicates to me that the problem is further back but I have no
idea how make use of that information.


Browse[1]> ls()
[1] "cacheOK"  "destfile" "extra"    "method"   "mode"     "quiet"    "url"     
Browse[1]> url
[1] "http://cran.stat.auckland.ac.nz/src/contrib/PACKAGES.rds"
Browse[1]> destfile
[1] "/tmp/RtmpplJSrB/repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds"
Browse[1]> 

The destfile above is zero-length and I suppose is where dest is
intended to end up.

Where else should I be looking?  Earlier installations never had this
issue so I don't have anything to compare.

TIA
-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From pdalgd at gmail.com  Tue May 23 11:22:14 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 23 May 2017 11:22:14 +0200
Subject: [R] Duplicate row names are not allowed
In-Reply-To: <931132147.3122221.1495479766544@mail.yahoo.com>
References: <931132147.3122221.1495479766544.ref@mail.yahoo.com>
 <931132147.3122221.1495479766544@mail.yahoo.com>
Message-ID: <B55A9EC6-AA20-4187-96CE-877365003537@gmail.com>

Presumably, RCommander's readXL generates an invalid data frame (John?). To investigate, look at

row.names(Dataset)

and to fix 

row.names(Dataset) <- NULL

If the issue is that Dataset really isn't a data frame, maybe try Dataset <- as.data.frame(Dataset).

[Your screenshot made it through to here, but not the data. Notice, as a general matter, that it is preferable to give your code as part of the message text; it is hard to copy-paste from a .png]

-pd

> On 22 May 2017, at 21:02 , ville iiskola via R-help <r-help at r-project.org> wrote:
> 
> Hi
> I read a book where was shown an example how to create a probability model with mlogit. I tried to do like the instruction said but i get error message that "duplicate row names are not allowed". What could i do to fix it?
> 
> I had the data in excel and imported it to R using R commander. I attach the data file and print sqreen of my code to here if somebody could help the novice. Ville<2017-05-21 (1).png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Tue May 23 12:20:36 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 23 May 2017 12:20:36 +0200
Subject: [R] Error in readRDS(dest) (was Re: Error with installed.packages
 with R 3.4.0 on Windows)
In-Reply-To: <20170523084722.GD4553@slingshot.co.nz>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
 <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
 <20170522091022.GC4553@slingshot.co.nz>
 <7b8f4895-b41d-6634-367b-1754bc737c02@roswellpark.org>
 <20170523084722.GD4553@slingshot.co.nz>
Message-ID: <22820.3316.479418.85208@stat.math.ethz.ch>

>>>>> Patrick Connolly <p_connolly at slingshot.co.nz>
>>>>>     on Tue, 23 May 2017 20:47:22 +1200 writes:

    > On Mon, 22-May-2017 at 05:43AM -0400, Martin Morgan wrote:
    > |> On 05/22/2017 05:10 AM, Patrick Connolly wrote:

    > |> >Apparently it isn't harmless.
    > |> >
    > |> >>install.packages("withr")
    > |> >Error in readRDS(dest) : error reading from connection
    > |> 
    > |> that seems like a plain-old network connectivity issue, or perhaps
    > |> an issue with the CRAN mirror you're using. Can you debug on your
    > |> end, e.g,.
    > |> 
    > |>   options(error=recover)
    > |>   install.packages("withr")
    > |>   ...
    > |> 
    > |> then select the 'frame' where the error occurs, look around
    > |> 
    > |>   ls()
    > |> 
    > |> find the value of 'dest', and e.g., try to open dest in your  browser.

    > This is what I get

    >> options(error=recover)
    >> install.packages("withr")
    > ^C

    > Enter a frame number, or 0 to exit   

    > 1: install.packages("withr")
    > 2: available.packages(contriburl = contriburl, method = method)
    > 3: tryCatch({
    > download.file(url = paste0(repos, "/PACKAGES.rds"), destfile
    > 4: tryCatchList(expr, classes, parentenv, handlers)
    > 5: tryCatchOne(expr, names, parentenv, handlers[[1]])
    > 6: doTryCatch(return(expr), name, parentenv, handler)
    > 7: download.file(url = paste0(repos, "/PACKAGES.rds"), destfile = dest, method

    > Selection: 7

'7'  was the wrong choice:  'dest' exists in the frame that
     *calls* download.file, in this case, it is frame 2, i.e.,
     inside available.packages(.)  where the  tryCatch() call to
     download.file() happens.

Given the above stack trace. 
It may be easier to just do

    debugonce(available.packages)
    install.packages("withr")

and then inside available.packages, (using 'n') step to the
point _before_ the tryCatch(...) call happens; there, e.g. use

      ls.str()

which gives an str() of all your local objects, notably 'dest'
and 'method'.
but you can also try other things once inside
available.packages().

Martin


    > Called from: eval(substitute(browser(skipCalls = skip), list(skip = 7 - which)), 
    > envir = sys.frame(which))
    > Browse[1]> dest
    > Error during wrapup: object 'dest' not found

    > That indicates to me that the problem is further back but I have no
    > idea how make use of that information.


    > Browse[1]> ls()
    > [1] "cacheOK"  "destfile" "extra"    "method"   "mode"     "quiet"    "url"     
    > Browse[1]> url
    > [1] "http://cran.stat.auckland.ac.nz/src/contrib/PACKAGES.rds"
    > Browse[1]> destfile
    > [1] "/tmp/RtmpplJSrB/repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds"
    > Browse[1]> 

    > The destfile above is zero-length and I suppose is where dest is
    > intended to end up.

    > Where else should I be looking?  Earlier installations never had this
    > issue so I don't have anything to compare.

    > TIA
    > --


From dhiv.shreya at gmail.com  Tue May 23 14:08:49 2017
From: dhiv.shreya at gmail.com (Dhivya Narayanasamy)
Date: Tue, 23 May 2017 17:38:49 +0530
Subject: [R] P value of VAR model from Portmanteau Test
Message-ID: <CACmggQvrcPc9Ssr81Z2k788p1=0rzOCuh6DH3uCd8nAkFJccYw@mail.gmail.com>

Hi,

I am working with bivariate time series data. I used VAR model to fit and
forecast.
But the "*p*" value from seria.test (Portmanteau Test) gives values *p<<
0.05*. Is that okay?


> var1 = VAR(datax.ts, p= 8)
> serial.test(var1, lags.pt=10, type = "PT.asymptotic")

Portmanteau Test (asymptotic)

data:  Residuals of VAR object var1
Chi-squared = 23.724, df = 8, p-value = 0.002549

Am i doing it correct? or Is this wrong? Should the value of P supposed to
be greater than >> 0.05 ?  When i forecast this VAR model, it gives *flat
forecast* which is again wrong. Please help me.


Regards| Mit freundlichen Gr??en,
> Dhivya Narayanasamy
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue May 23 15:36:06 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 23 May 2017 14:36:06 +0100
Subject: [R] P value of VAR model from Portmanteau Test
In-Reply-To: <CACmggQvrcPc9Ssr81Z2k788p1=0rzOCuh6DH3uCd8nAkFJccYw@mail.gmail.com>
References: <CACmggQvrcPc9Ssr81Z2k788p1=0rzOCuh6DH3uCd8nAkFJccYw@mail.gmail.com>
Message-ID: <59243AC6.7090702@sapo.pt>

Hello,

It seems to be right.
You have Chi-squared = 23.724, df = 8, p-value = 0.002549. So try the R 
function ?pchisq:

pchisq(23.724, df = 8, lower = FALSE)
[1] 0.002549054

Hope this helps,

Rui Barradas

Em 23-05-2017 13:08, Dhivya Narayanasamy escreveu:
> Hi,
>
> I am working with bivariate time series data. I used VAR model to fit and
> forecast.
> But the "*p*" value from seria.test (Portmanteau Test) gives values *p<<
> 0.05*. Is that okay?
>
>
>> var1 = VAR(datax.ts, p= 8)
>> serial.test(var1, lags.pt=10, type = "PT.asymptotic")
>
> Portmanteau Test (asymptotic)
>
> data:  Residuals of VAR object var1
> Chi-squared = 23.724, df = 8, p-value = 0.002549
>
> Am i doing it correct? or Is this wrong? Should the value of P supposed to
> be greater than >> 0.05 ?  When i forecast this VAR model, it gives *flat
> forecast* which is again wrong. Please help me.
>
>
> Regards| Mit freundlichen Gr??en,
>> Dhivya Narayanasamy
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alcmeonida at hotmail.com  Mon May 22 23:35:33 2017
From: alcmeonida at hotmail.com (=?utf-8?B?SXbDoW4gQmxhbmNv?=)
Date: Mon, 22 May 2017 21:35:33 +0000
Subject: [R] Installing ranger package in Ubuntu 14
Message-ID: <VI1P194MB0079191B8DA652B826CBC4FDC4F80@VI1P194MB0079.EURP194.PROD.OUTLOOK.COM>

I'm trying to install ranger package (any version) in Ubuntu 14 from a tar.gz file already downloaded, but unsuccessfully. System admin has already installed gcc 5.4 and g++ 5.4 and I've created a ~/.R/Makevars file pointing to these compilers instead of gcc 4.8 that comes in Ubuntu 14 by default.  Ranger requires gcc 4.9 or higher. That Makevars file looks like this:

CC=/storage/home/user/bin/gcc-5
CCXX=/storage/home/user/bin/g++-5
FC=/storage/home/user/bin/gfortran-6
F77=/storage/home/user/bin/gfortran-6

I don?t have admin rights and system admin can't change gcc path for the whole server. Output error is this one:

=========================================
* installing *source* package ?ranger? ...
** package ?ranger? successfully unpacked and MD5 sums checked
** libs
g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG -DR_BUILD -I"/storage/home/user/R/x86_64-pc-linux-gnu-library/3.4/Rcpp/include"    -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g -c AAA_check_cpp11.cpp -o AAA_check_cpp11.o
g++: error: unrecognized command line option ?-fstack-protector-strong?
g++: error: unrecognized command line option ?-Wdate-time?
/usr/lib/R/etc/Makeconf:168: recipe for target 'AAA_check_cpp11.o' failed
make: *** [AAA_check_cpp11.o] Error 1
ERROR: compilation failed for package ?ranger?
* removing ?/storage/home/u382324/R/x86_64-pc-linux-gnu-library/3.4/ranger?

The downloaded source packages are in
        ?/tmp/RtmpXUQwl6/downloaded_packages?
Warning message:
In install.packages("ranger") :
  installation of package ?ranger? had non-zero exit status
==============================================

It seems I?m missing some flag defintion in my Makevars and R is using the default gcc 4.8 compiler, I don?t know. Any advice about how to procceed would be very helpful. Thanks.

Kind regards,

Ivan

	[[alternative HTML version deleted]]


From allaisone1 at hotmail.com  Mon May 22 23:40:37 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Mon, 22 May 2017 21:40:37 +0000
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <CAGxFJbRwQMvuFavCatxGtgoYwLGrmOkqbXzi04yTr0Z0yiRZTA@mail.gmail.com>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQH55Lv47+46Xxs_prJ7+Ay-XQPKg2_bEwD-ieLtF3i2A@mail.gmail.com>
 <AM5P195MB00205C73AAC9BB5DD9391C8380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <CAGxFJbRwQMvuFavCatxGtgoYwLGrmOkqbXzi04yTr0Z0yiRZTA@mail.gmail.com>
Message-ID: <AM5P195MB0020AF7DF2653A5A3E3F042380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>

Dear Bert

I have answered your questions in my last 2 messages. If you did not see them, I will answer again. The 2 tables are all data.frames and the order of the meals does not matter. The meal cannot be replicated for each person, they are all different. The missing values are to the right end of each row as each row starts with meal codes first. This task is just a small part of a long 2 years project.

Regards
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 22 May 2017 14:35:49
To: Allaisone 1
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

You haven't said whether your "table" is a matrix or data frame.
Presumably the latter.

Nor have you answered my question about whether order of your meal
code pairs matters.

Another question: can meals be replicated for an ID or are they all different?

Finally, is this a homework assignment or class project of some sort?
Or is it a real task -- i.e., what is the context?

Again, be sure to cc the list.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 22, 2017 at 1:56 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> Hi Bert ..,
>
>
> The number of meals differ from one customer to other customer. You may find
> one customer with only one meal and another one with 2,3 or even rarely 30
> meals. You may also
>
> find no meal at all for some customers so the entire row takes the missing
> value "\N" . Any
>
> row starts with the meals codes first, then all missing values are to the
> right end of the table.
>
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 22 May 2017 03:11:11
> To: Allaisone 1
> Cc: r-help at r-project.org
> Subject: Re: [R] Identyfing rows with specific conditions
>
> Clarification:
>
> Does each customer have the same number of meals or do they differ
> from customer to customer? If the latter, how are missing meals
> notated? Do they always occur at the (right) end or can they occur
> anywhere in the row?
>
> Presumably each customer ID can have many different meal code
> combinations, right ?(since they can have 30 different meals with
> potentially 30 choose 2 = 435 combinations apiece)
>
> Please make sure you reply to the list, not just to me, as I may not
> pursue this further but am just trying to clarify for anyone else who
> may wish to help.
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>
>> Hi All..,
>>
>> I have 2 tables. The first one contains 2 columns with the headers say
>> "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each
>> of which with a different combination of meals(unique combination per row).
>>
>>
>>>Meals
>>
>>     meal A code      meal B code
>>
>> 1          34                   66
>>
>> 2           89                  39
>>
>> 3           25                   77
>>
>> The second table(customers) shows customers ids in the first column with
>> Meals codes(M) next to each customer. There are about 300,000 customers
>> (300,000 rows).
>>
>>> Customers
>>      1         2     3       4    ..30
>>      id       M1  M2   M3
>> 1   15      77    34    25
>> 2   11      25    34     39
>> 3    85     89     25    77
>> .
>> .
>> 300,000
>>
>> I would like to identify all customers ids who have had each meal
>> combination in the first table so the final output would be the first table
>> with ids attached next to each meal combination in each row like this:
>>
>>>IdsMeals
>>
>>
>>   MAcode  MBcode  ids
>>
>> 1     34        39            11
>>
>> 2     25       34              15   11
>>
>> 3      25     77                15   85
>>
>> Would you please suggest any solutions to this problem?
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From R.E.Crump at warwick.ac.uk  Tue May 23 10:29:06 2017
From: R.E.Crump at warwick.ac.uk (Crump, Ron)
Date: Tue, 23 May 2017 08:29:06 +0000
Subject: [R] R-help Digest, Vol 171, Issue 20
In-Reply-To: <mailman.1.1495274401.24720.r-help@r-project.org>
References: <mailman.1.1495274401.24720.r-help@r-project.org>
Message-ID: <D549AD20.A170%lfslbx@live.warwick.ac.uk>

Hi Brigitte,

>Did somebody know why asreml does not provide the same REML loglikehood
>as coxme, lme4 or lmne.

I don't know the answer to this, but I'd guess it is either to do with the
use of the average information REML algorithm or asreml-r is for some
reason ending up with a different subset of the data.

>If it was just a constant value between the two models (with or without
>the fixed effect) it would not be important. But it is not.
>I checked that the variance component estimators were equal.

I'm still not clear that it is important (if the data subset analysed is
the same). You would only use the REML likelihoods to compare models with
different random effects and the same fixed effect structure (is there
another use for the REML likelihood other than that?), so then it is
really a question of whether for a given pair of random effect models and
the same data the likelihood ratio test statistic  changes across analysis
methods. Unless for some reason you are comparing two random effect models
fitted with different routines (one of which is asreml-r).

Ron.


From r-packages at r-project.org  Fri May 19 18:42:33 2017
From: r-packages at r-project.org (Malte Grosser via R-packages)
Date: Fri, 19 May 2017 18:42:33 +0200
Subject: [R] [R-pkgs] Announcing snakecase 0.4.0
Message-ID: <CAK8DnTmfSB8sV6XeNGG7zuNwCGP=7Eonk_Exg3rvD30wfiyz+Q@mail.gmail.com>

I am pleased to announce a fresh and simple approach on automatic
caseconversion with a concise design philosophy via the snakecase-pkg (
https://cran.r-project.org/package=snakecase).

Just use to_any_case(string, case) and (if the cases are too complex for
the default options) provide its most important arguments with further
information about:
- how a string should be parsed (regular expressions)
- how the result should be split (character).
On the way you can achieve things like special character handling and minor
customizations as also documented on github (
https://github.com/Tazinho/snakecase)

Examples:
- Easy case conversions:
"RStudio" to "R_Studio" (parsed) "r_studio", "R_STUDIO", "rStudio",
"RStudio"  or choose any other separator than the default "_" or "".
- More complex (different meanings of dots (separator or decimal) and
umlauts)
"R.St?dio: v.1.0.143" to "rst?dio_v_1_0_143" or "r_st?dio_v_1.0.143", "R
Stuedio v 1.0.143",...

Note that the usecases are not only formatting for naming conventions
itself, but also for automated pretty printing like "RStudio" to "R Studio".

Best,
Malte Grosser

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From jdnewmil at dcn.davis.ca.us  Tue May 23 17:28:18 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 23 May 2017 08:28:18 -0700
Subject: [R] Installing ranger package in Ubuntu 14
In-Reply-To: <VI1P194MB0079191B8DA652B826CBC4FDC4F80@VI1P194MB0079.EURP194.PROD.OUTLOOK.COM>
References: <VI1P194MB0079191B8DA652B826CBC4FDC4F80@VI1P194MB0079.EURP194.PROD.OUTLOOK.COM>
Message-ID: <F92D4EC1-0258-46E3-AA32-0C297B4AED67@dcn.davis.ca.us>

A) This should be asked on R-sig-debian or R-devel. This list is about the R language and basic installation issues... compiled installation debugging requires OS and C language skills that are OT here. 

B) You should read and follow the advice in the Posting Guide for all R mailing lists,  specifically about posting using plain text email. 

C) You need to use the same compiler setup for the package as you used to install R. If you are not using the system package manager then you should probably be clear in your question about what your original configure setup was for R when you ask for help elsewhere. Beyond that I have no experience to offer, as using the system package manager has been adequate for my needs.
-- 
Sent from my phone. Please excuse my brevity.

On May 22, 2017 2:35:33 PM PDT, "Iv?n Blanco" <alcmeonida at hotmail.com> wrote:
>I'm trying to install ranger package (any version) in Ubuntu 14 from a
>tar.gz file already downloaded, but unsuccessfully. System admin has
>already installed gcc 5.4 and g++ 5.4 and I've created a ~/.R/Makevars
>file pointing to these compilers instead of gcc 4.8 that comes in
>Ubuntu 14 by default.  Ranger requires gcc 4.9 or higher. That Makevars
>file looks like this:
>
>CC=/storage/home/user/bin/gcc-5
>CCXX=/storage/home/user/bin/g++-5
>FC=/storage/home/user/bin/gfortran-6
>F77=/storage/home/user/bin/gfortran-6
>
>I don?t have admin rights and system admin can't change gcc path for
>the whole server. Output error is this one:
>
>=========================================
>* installing *source* package ?ranger? ...
>** package ?ranger? successfully unpacked and MD5 sums checked
>** libs
>g++ -std=gnu++11 -I/usr/share/R/include -DNDEBUG -DR_BUILD
>-I"/storage/home/user/R/x86_64-pc-linux-gnu-library/3.4/Rcpp/include"  
>-fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security
>-Wdate-time -D_FORTIFY_SOURCE=2 -g -c AAA_check_cpp11.cpp -o
>AAA_check_cpp11.o
>g++: error: unrecognized command line option ?-fstack-protector-strong?
>g++: error: unrecognized command line option ?-Wdate-time?
>/usr/lib/R/etc/Makeconf:168: recipe for target 'AAA_check_cpp11.o'
>failed
>make: *** [AAA_check_cpp11.o] Error 1
>ERROR: compilation failed for package ?ranger?
>* removing
>?/storage/home/u382324/R/x86_64-pc-linux-gnu-library/3.4/ranger?
>
>The downloaded source packages are in
>        ?/tmp/RtmpXUQwl6/downloaded_packages?
>Warning message:
>In install.packages("ranger") :
>  installation of package ?ranger? had non-zero exit status
>==============================================
>
>It seems I?m missing some flag defintion in my Makevars and R is using
>the default gcc 4.8 compiler, I don?t know. Any advice about how to
>procceed would be very helpful. Thanks.
>
>Kind regards,
>
>Ivan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Tue May 23 17:55:12 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 23 May 2017 08:55:12 -0700
Subject: [R] Xtractomatic version 3.3.2 now available on CRAN
Message-ID: <DFB16F76-C0AD-41CC-BE79-116C8DAFB6FB@noaa.gov>

The xtractomatic package version 3.3.2 is now available on CRAN.  Besides the improvements listed below,  this release fixes a problem caused by an update to the Apache Tomcat used by the ERDDAP server,  that broke an important function in the package.

Many thanks to the CRAN maintainers for help in getting this on CRAN.

List of changes below,  as always the development version is available at https://github.com/rmendels/xtractomatic

-Roy

	? Fixes problem with newer versions of Apache Tomcat handling of special characters in URLS
	? dtype as number no longer allowed
	? searchData() now takes a list of objects of the form "searchType:searchString"
	? new datasets added
	? inactive or out of date datasets removed



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From lorenzo.isella at gmail.com  Tue May 23 18:22:00 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 23 May 2017 18:22:00 +0200
Subject: [R] Fitdistrplus and Parameter Constraints
Message-ID: <20170523162200.GE1275@chicca2>

Dear All,
In principle it is a simple question, but not idea about how to tackle
it.
Suppose you have a distribution depending on two parameters,
e.g. beta(a,b).
For some reasons, you want to impose
that the two parameters of the beta distribution are identical,
i.e. you want to fit your data to beta(a,a).
For instance

x<-rbeta(1000, 0.1, 0.1)
require(fitdistrplus)

mm<-fitdist(x, "beta",  method = "mge")


is how you would normally fit a sample, but I do not know how to
impose the constrain a=b before the fitting.
Any suggestion is appreciated.
Cheers

Lorenzo


From chocold12 at gmail.com  Tue May 23 18:31:51 2017
From: chocold12 at gmail.com (lily li)
Date: Tue, 23 May 2017 10:31:51 -0600
Subject: [R] About change columns and specific rows in R
In-Reply-To: <CAA99HCzigy66AFW9ziYkywiRFzQW0HXxHPGhZXbOc3suaFA+Hw@mail.gmail.com>
References: <CAN5afy-KJsLvXnmv3JLM3P=v1mqDSjcZKSajw_8GRM2m52G+Hw@mail.gmail.com>
 <CAA99HCyNFxTZSpGeeeP3ZiffXOJog44C_ioyR-BdEnSiJTy7gA@mail.gmail.com>
 <83d3be54-34ce-3f09-b5a4-4bb65ea5f5d9@rgzm.de>
 <CAA99HCzigy66AFW9ziYkywiRFzQW0HXxHPGhZXbOc3suaFA+Hw@mail.gmail.com>
Message-ID: <CAN5afy-dOpjQE_gtKAaFekhdAhmE_3iQwCTZthOL=kSVP0G_zg@mail.gmail.com>

Thanks for all your help. It works now.

On Tue, May 23, 2017 at 1:34 AM, William Michels via R-help <
r-help at r-project.org> wrote:

> Hi Ivan,
>
> I was just writing a follow-up note as your note came in. While the
> code I posted previously works fine, using which() is unnecessary.
>
> > DF <- read.csv("~/lily.csv")
> > DF$product1_1 <- NA
> > DF$product1_1 <- DF[DF$month == 1, "product1"]*3.1
> Error in `$<-.data.frame`(`*tmp*`, "product1_1", value = c(55.8, 58.9,  :
>   replacement has 4 rows, data has 7
> > DF$product1_1 <- DF[which(DF$month == 1), "product1"]*3.1
> Error in `$<-.data.frame`(`*tmp*`, "product1_1", value = c(55.8, 58.9,  :
>   replacement has 4 rows, data has 7
> > DF[DF$month == 1, "product1_1"] <- DF[DF$month == 1, "product1"]*3.1
> > DF
>   year month day product1 product2 product3 product1_1
> 1 1981     1   1       18       56       20       55.8
> 2 1981     1   2       19       45       22       58.9
> 3 1981     1   3       16       48       28       49.6
> 4 1981     1   4       19       50       21       58.9
> 5 1981     2   1       17       49       25         NA
> 6 1981     2   2       20       47       23         NA
> 7 1981     2   3       21       52       27         NA
> >
>
> The two errors above were caused because I failed to specify rows on
> the left hand side of the assignment operator, not because I failed to
> use which(). Once rows and columns are specified on both sides, the
> assignment works fine.
>
> (I do however, prefer to create an "NA" column first. Personal preference
> ;-).
>
> Best Regards,
>
> Bill.
>
>
>
> On Mon, May 22, 2017 at 11:57 PM, Ivan Calandra <calandra at rgzm.de> wrote:
> > Hi,
> >
> > Actually, you don't need to create the column first, nor to use which:
> > DF[DF$month==1, "product1_1"] = DF[DF$month==1, "product1"] * 3.1
> >
> > The "[" is a great tool that you need to learn. In this case, you don't
> need
> > to combine "[" and $: within the square brackets, the vector before the
> > comma indexes the rows and the one after the comma indexes the columns.
> >
> > The other thing you were missing correctly referencing the rows. You
> have to
> > specify the data.frame you want to look into.
> >
> > And last, learn to use dput() to provide a nice reproducible example.
> >
> > HTH,
> > Ivan
> >
> >
> > --
> > Dr. Ivan Calandra
> > TraCEr, Laboratory for Traceology and Controlled Experiments
> > MONREPOS Archaeological Research Centre and
> > Museum for Human Behavioural Evolution
> > Schloss Monrepos
> > 56567 Neuwied, Germany
> > +49 (0) 2631 9772-243
> > https://www.researchgate.net/profile/Ivan_Calandra
> >
> > On 23/05/2017 08:45, William Michels via R-help wrote:
> >>
> >> Hi Lily,
> >>
> >> You're on the right track, but you should define a new column first
> >> (filled with NA values), then specify the precise rows and columns on
> >> both the left and right hand sides of the assignment operator that
> >> will be altered. Luckily, this is pretty easy...just remember to use
> >> which() on the right hand side of the assignment operator to get the
> >> index of the rows you want. Example below for "product1":
> >>
> >>> DF$product1_1 <- NA
> >>> DF[DF$month == 1, "product1_1"] <- DF[which(DF$month == 1),
> >>> "product1"]*3.1
> >>>
> >>
> >> HTH,
> >>
> >> Bill.
> >>
> >> William Michels, Ph.D.
> >>
> >>
> >>
> >>
> >> On Mon, May 22, 2017 at 9:56 PM, lily li <chocold12 at gmail.com> wrote:
> >>>
> >>> Hi R users,
> >>>
> >>> I have a question about manipulating the dataframe. I want to create a
> >>> new
> >>> dataframe, and to multiply rows with different seasons for different
> >>> constants.
> >>>
> >>> DF
> >>> year   month   day   product1   product2   product3
> >>> 1981     1          1         18              56            20
> >>> 1981     1          2         19              45            22
> >>> 1981     1          3         16              48            28
> >>> 1981     1          4         19              50            21
> >>> 1981     2          1         17              49            25
> >>> 1981     2          2         20              47            23
> >>> 1981     2          3         21              52            27
> >>>
> >>> For example, how to multiply product1 in month1 by 3.1, and to multiply
> >>> product3 in month2 by 2.0? I wrote the code like this but does not
> work.
> >>> Thanks for your help.
> >>>
> >>> DF['month'==1, ]$product1_1 = DF['month'==1, ]$product1 * 3.1;
> >>> DF['month'==2, ]$product3_1 = DF['month'==1, ]$product3 * 2.0;
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From david.chin.work at gmail.com  Tue May 23 18:07:54 2017
From: david.chin.work at gmail.com (David Chin)
Date: Tue, 23 May 2017 12:07:54 -0400
Subject: [R] Compiling R with zlib in non-standard location
Message-ID: <CAP-4TpU5JN7CYEEFoiiX1en3A2onRu3vOkteraBL-a+u2qUtoQ@mail.gmail.com>

Hi all,

I am trying to compile R 3.4.0 on a RHEL 6.5 system. R requires a newer
version of zlib than is standard on RHEL 6.5. I do have a newer version
that satisfies R's requirement, but the configure script gives no way of
specifying a non-standard location of zlib.

Is there a way around this? Or should I try to make a feature request?

Thanks in advance,
    Dave

-- 
David Chin, Ph.D.
david.chin at drexel.edu    Sr. Systems Administrator, URCF, Drexel U.
http://www.drexel.edu/research/urcf/
https://linuxfollies.blogspot.com/
215.221.4747 (mobile)
https://github.com/prehensilecode

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue May 23 18:50:57 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 23 May 2017 11:50:57 -0500
Subject: [R] Compiling R with zlib in non-standard location
In-Reply-To: <CAP-4TpU5JN7CYEEFoiiX1en3A2onRu3vOkteraBL-a+u2qUtoQ@mail.gmail.com>
References: <CAP-4TpU5JN7CYEEFoiiX1en3A2onRu3vOkteraBL-a+u2qUtoQ@mail.gmail.com>
Message-ID: <52306A9F-A61B-4E5C-B788-367069FAD59F@me.com>


> On May 23, 2017, at 11:07 AM, David Chin <david.chin.work at gmail.com> wrote:
> 
> Hi all,
> 
> I am trying to compile R 3.4.0 on a RHEL 6.5 system. R requires a newer
> version of zlib than is standard on RHEL 6.5. I do have a newer version
> that satisfies R's requirement, but the configure script gives no way of
> specifying a non-standard location of zlib.
> 
> Is there a way around this? Or should I try to make a feature request?
> 
> Thanks in advance,
>    Dave


Hi,

This was recently asked here:

  https://stat.ethz.ch/pipermail/r-devel/2017-April/074157.html

Martyn provided a resolution in the follow up post, including a pointer to the EPEL, where there are pre-compiled RPMs for R.

For future reference, there is a dedicated e-mail list for queries pertaining to R on RH/Fedora based distributions:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Regards,

Marc Schwartz


From dutangc at gmail.com  Tue May 23 19:00:08 2017
From: dutangc at gmail.com (Christophe Dutang)
Date: Tue, 23 May 2017 19:00:08 +0200
Subject: [R] Fitdistrplus and Parameter Constraints
In-Reply-To: <20170523162200.GE1275@chicca2>
References: <20170523162200.GE1275@chicca2>
Message-ID: <F1B5725E-4041-4360-9DD5-AB3C9F8E3856@gmail.com>

Dear Lorenzo,

Please do read the posting guide (https://www.r-project.org/posting-guide.html) : The ?main? R mailing list, for discussion about problems and solutions using R, about the availability of new functionality for R and documentation of R, comparison and compatibility with S-plus, and for the posting of nice examples and benchmarks.


For your problem, you could do something like this

x <- rbeta(1000, 3, 3)

dbeta2 <- function(x, shape, ...)
	dbeta(x, shape, shape, ...)
pbeta2 <- function(q, shape, ...)
	pbeta(q, shape, shape, ...)	
	
library(fitdistrplus)
fitdist(x, "beta2", start=list(shape=1/2))

x <- rbeta(1000, .3, .3)
fitdist(x, "beta2", start=list(shape=1/2), optim.method="L-BFGS-B", lower=1e-2)	
 
Regards, Christophe
---------------------------------------
Christophe Dutang
LMM, UdM, Le Mans, France
web: http://dutangc.free.fr

> Le 23 mai 2017 ? 18:22, Lorenzo Isella <lorenzo.isella at gmail.com> a ?crit :
> 
> Dear All,
> In principle it is a simple question, but not idea about how to tackle
> it.
> Suppose you have a distribution depending on two parameters,
> e.g. beta(a,b).
> For some reasons, you want to impose
> that the two parameters of the beta distribution are identical,
> i.e. you want to fit your data to beta(a,a).
> For instance
> 
> x<-rbeta(1000, 0.1, 0.1)
> require(fitdistrplus)
> 
> mm<-fitdist(x, "beta",  method = "mge")
> 
> 
> is how you would normally fit a sample, but I do not know how to
> impose the constrain a=b before the fitting.
> Any suggestion is appreciated.
> Cheers
> 
> Lorenzo


From david.chin.work at gmail.com  Tue May 23 19:02:20 2017
From: david.chin.work at gmail.com (David Chin)
Date: Tue, 23 May 2017 13:02:20 -0400
Subject: [R] Compiling R with zlib in non-standard location
In-Reply-To: <52306A9F-A61B-4E5C-B788-367069FAD59F@me.com>
References: <CAP-4TpU5JN7CYEEFoiiX1en3A2onRu3vOkteraBL-a+u2qUtoQ@mail.gmail.com>
 <52306A9F-A61B-4E5C-B788-367069FAD59F@me.com>
Message-ID: <CAP-4TpWx19CJ70Txa1RegUdfeLBp=hkmYKYdZ=t0PwFBMr622A@mail.gmail.com>

Hi Marc,

Pre-compiled RPMs for R are up to 3x slower than "self-compiled" R using
Intel MKL.  Yes, I do know about Microsoft R Open, but it wants to
overwrite the default /usr/bin/R and I have AMD machines in my cluster,
which cannot run MRO. So, I want to do my own compilation and install R in
a non-standard location so that it can be used by loading a modulefile.  I
also have users who have varying requirements for versions of R (for
whatever reason), so I need to provide different versions.

I also tried the suggested solution
https://stat.ethz.ch/pipermail/r-devel/2017-April/074162.html  -- but it
did not work for me. The configure script still picked up zlib.h from
/usr/include and deduced that it was an older version and would quit with
error.

Apologies if this is a duplicate. I sent my first response with the wrong
email address.


On Tue, May 23, 2017 at 12:50 PM, Marc Schwartz <marc_schwartz at me.com>
wrote:

>
> > On May 23, 2017, at 11:07 AM, David Chin <david.chin.work at gmail.com>
> wrote:
> >
> > Hi all,
> >
> > I am trying to compile R 3.4.0 on a RHEL 6.5 system. R requires a newer
> > version of zlib than is standard on RHEL 6.5. I do have a newer version
> > that satisfies R's requirement, but the configure script gives no way of
> > specifying a non-standard location of zlib.
> >
> > Is there a way around this? Or should I try to make a feature request?
> >
> > Thanks in advance,
> >    Dave
>
>
> Hi,
>
> This was recently asked here:
>
>   https://stat.ethz.ch/pipermail/r-devel/2017-April/074157.html
>
> Martyn provided a resolution in the follow up post, including a pointer to
> the EPEL, where there are pre-compiled RPMs for R.
>
> For future reference, there is a dedicated e-mail list for queries
> pertaining to R on RH/Fedora based distributions:
>
>   https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>
> Regards,
>
> Marc Schwartz
>
>


-- 
David Chin, Ph.D.
david.chin at drexel.edu    Sr. Systems Administrator, URCF, Drexel U.
http://www.drexel.edu/research/urcf/
https://linuxfollies.blogspot.com/
215.221.4747 (mobile)
https://github.com/prehensilecode

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue May 23 19:41:36 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 23 May 2017 12:41:36 -0500
Subject: [R] Compiling R with zlib in non-standard location
In-Reply-To: <CAP-4TpWx19CJ70Txa1RegUdfeLBp=hkmYKYdZ=t0PwFBMr622A@mail.gmail.com>
References: <CAP-4TpU5JN7CYEEFoiiX1en3A2onRu3vOkteraBL-a+u2qUtoQ@mail.gmail.com>
 <52306A9F-A61B-4E5C-B788-367069FAD59F@me.com>
 <CAP-4TpWx19CJ70Txa1RegUdfeLBp=hkmYKYdZ=t0PwFBMr622A@mail.gmail.com>
Message-ID: <FDDC28E5-5CDB-455C-8A98-EEB5D64A8463@me.com>

Hi David,

It has been a while since I have worked on RH based systems, but looking at Martyn's reply, which includes:

CFLAGS="-g -O2 -I/path/to/my/headers" \
LDFLAGS="-L/path/to/my/libs" \
./configure

and references to the R Installation and Administration manual sections B3.3 and B7, if you used the lines verbatim as above, you will likely need to explicitly 'export' the two flag variables. Thus try:

export CFLAGS="-g -O2 -I/path/to/my/headers" \
export LDFLAGS="-L/path/to/my/libs" \
./configure


Using 'export' will ensure that the environment variables are also passed down to child processes started within the current shell session, which may be where it is failing.

See if that works. If not, subscribe to and post a new thread to R-SIG-Fedora, as there will be a focused audience there.

Regards,

Marc


> On May 23, 2017, at 12:02 PM, David Chin <david.chin.work at gmail.com> wrote:
> 
> Hi Marc,
> 
> Pre-compiled RPMs for R are up to 3x slower than "self-compiled" R using
> Intel MKL.  Yes, I do know about Microsoft R Open, but it wants to
> overwrite the default /usr/bin/R and I have AMD machines in my cluster,
> which cannot run MRO. So, I want to do my own compilation and install R in
> a non-standard location so that it can be used by loading a modulefile.  I
> also have users who have varying requirements for versions of R (for
> whatever reason), so I need to provide different versions.
> 
> I also tried the suggested solution
> https://stat.ethz.ch/pipermail/r-devel/2017-April/074162.html  -- but it
> did not work for me. The configure script still picked up zlib.h from
> /usr/include and deduced that it was an older version and would quit with
> error.
> 
> Apologies if this is a duplicate. I sent my first response with the wrong
> email address.
> 
> 
> On Tue, May 23, 2017 at 12:50 PM, Marc Schwartz <marc_schwartz at me.com>
> wrote:
> 
>> 
>>> On May 23, 2017, at 11:07 AM, David Chin <david.chin.work at gmail.com>
>> wrote:
>>> 
>>> Hi all,
>>> 
>>> I am trying to compile R 3.4.0 on a RHEL 6.5 system. R requires a newer
>>> version of zlib than is standard on RHEL 6.5. I do have a newer version
>>> that satisfies R's requirement, but the configure script gives no way of
>>> specifying a non-standard location of zlib.
>>> 
>>> Is there a way around this? Or should I try to make a feature request?
>>> 
>>> Thanks in advance,
>>>   Dave
>> 
>> 
>> Hi,
>> 
>> This was recently asked here:
>> 
>>  https://stat.ethz.ch/pipermail/r-devel/2017-April/074157.html
>> 
>> Martyn provided a resolution in the follow up post, including a pointer to
>> the EPEL, where there are pre-compiled RPMs for R.
>> 
>> For future reference, there is a dedicated e-mail list for queries
>> pertaining to R on RH/Fedora based distributions:
>> 
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>> 
>> Regards,
>> 
>> Marc Schwartz
>> 
>> 


From dcarlson at tamu.edu  Tue May 23 20:20:02 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 23 May 2017 18:20:02 +0000
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <AM5P195MB0020AF7DF2653A5A3E3F042380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQH55Lv47+46Xxs_prJ7+Ay-XQPKg2_bEwD-ieLtF3i2A@mail.gmail.com>
 <AM5P195MB00205C73AAC9BB5DD9391C8380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <CAGxFJbRwQMvuFavCatxGtgoYwLGrmOkqbXzi04yTr0Z0yiRZTA@mail.gmail.com>
 <AM5P195MB0020AF7DF2653A5A3E3F042380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <925d7124b8f74cc0827755161faa61ad@exch-2p-mbx-w2.ads.tamu.edu>

You will generally get a better response if you create a data set that we can test our ideas on. You sketched out the data but your final results include meal combinations that are not in your Meals data frame. Also using dput() to provide the data makes it easier to recreate the data since just printing it loses important information such as if the numbers are integer or decimal, or if the character variables are characters or factors. Also send your message as plain text, not html which messes up columns and other details. Here is a modification of your data with the beginnings of a solution:

Meals <- structure(list(mealAcode = c(34L, 89L, 25L, 34L, 25L), mealBcode = c(66L, 
39L, 77L, 39L, 34L)), .Names = c("mealAcode", "mealBcode"), row.names = c(NA, 
-5L), class = "data.frame")
Meals
#   mealAcode mealBcode
# 1        34        66
# 2        89        39
# 3        25        77
# 4        34        39
# 5        25        34

Customers <- structure(list(id = c(15L, 11L, 85L), M1 = c(77L, 25L, 89L), 
    M2 = c(34L, 34L, 25L), M3 = c(25L, 39L, 77L)), .Names = c("id", 
"M1", "M2", "M3"), class = "data.frame", row.names = c(NA, -3L
))
Customers
#   id M1 M2 M3
# 1 15 77 34 25
# 2 11 25 34 39
# 3 85 89 25 77

Results <- data.frame(mealAcode=NA, mealBcode=NA, id=NA)
k <- 0
for (i in seq_len(nrow(Meals))) {
    for (j in seq_len(nrow(Customers))) {
        if (any(Customers[j, -1] %in% Meals[i, 1]) & 
            any(Customers[j, -1] %in% Meals[i, 2])) {
               k <- k+1
               Results[k, ] <- cbind(Meals[i, ], id=Customers[j, 1])
        }
    }
rownames(Results) <- NULL
}
Results
#   mealAcode mealBcode id
# 1        25        77 15
# 2        25        77 85
# 3        34        39 11
# 4        25        34 15
# 5        25        34 11

Results is a data frame that can be modified to get various forms of output. You mention a data frame with ids in separate columns. That might be unwieldy for many types of analysis. The following list shows the ids for each meal combination,  the number of meals of each combination consumed, and a matrix similar to the one you provided.

Results.lst <- split(Results$id,  paste(Results[ , 1], Results[ , 2], sep=" - "))
Results.lst
# $`25 - 34`
# [1] 15 11
# 
# $`25 - 77`
# [1] 15 85
# 
# $`34 - 39`
# [1] 11
table(Results[, 1:2])
#          mealBcode
# mealAcode 34 39 77
#        25  2  0  2
#        34  0  1  0
maxid <- 5
t(sapply(Results.lst, function(x) c(sort(as.vector(x)), 
     rep(NA, maxid-length(as.vector(x))))))
#         [,1] [,2] [,3] [,4] [,5]
# 25 - 34   11   15   NA   NA   NA
# 25 - 77   15   85   NA   NA   NA
# 34 - 39   11   NA   NA   NA   NA

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Allaisone 1
Sent: Monday, May 22, 2017 4:41 PM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

Dear Bert

I have answered your questions in my last 2 messages. If you did not see them, I will answer again. The 2 tables are all data.frames and the order of the meals does not matter. The meal cannot be replicated for each person, they are all different. The missing values are to the right end of each row as each row starts with meal codes first. This task is just a small part of a long 2 years project.

Regards
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 22 May 2017 14:35:49
To: Allaisone 1
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

You haven't said whether your "table" is a matrix or data frame.
Presumably the latter.

Nor have you answered my question about whether order of your meal
code pairs matters.

Another question: can meals be replicated for an ID or are they all different?

Finally, is this a homework assignment or class project of some sort?
Or is it a real task -- i.e., what is the context?

Again, be sure to cc the list.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 22, 2017 at 1:56 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> Hi Bert ..,
>
>
> The number of meals differ from one customer to other customer. You may find
> one customer with only one meal and another one with 2,3 or even rarely 30
> meals. You may also
>
> find no meal at all for some customers so the entire row takes the missing
> value "\N" . Any
>
> row starts with the meals codes first, then all missing values are to the
> right end of the table.
>
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 22 May 2017 03:11:11
> To: Allaisone 1
> Cc: r-help at r-project.org
> Subject: Re: [R] Identyfing rows with specific conditions
>
> Clarification:
>
> Does each customer have the same number of meals or do they differ
> from customer to customer? If the latter, how are missing meals
> notated? Do they always occur at the (right) end or can they occur
> anywhere in the row?
>
> Presumably each customer ID can have many different meal code
> combinations, right ?(since they can have 30 different meals with
> potentially 30 choose 2 = 435 combinations apiece)
>
> Please make sure you reply to the list, not just to me, as I may not
> pursue this further but am just trying to clarify for anyone else who
> may wish to help.
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>
>> Hi All..,
>>
>> I have 2 tables. The first one contains 2 columns with the headers say
>> "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each
>> of which with a different combination of meals(unique combination per row).
>>
>>
>>>Meals
>>
>>     meal A code      meal B code
>>
>> 1          34                   66
>>
>> 2           89                  39
>>
>> 3           25                   77
>>
>> The second table(customers) shows customers ids in the first column with
>> Meals codes(M) next to each customer. There are about 300,000 customers
>> (300,000 rows).
>>
>>> Customers
>>      1         2     3       4    ..30
>>      id       M1  M2   M3
>> 1   15      77    34    25
>> 2   11      25    34     39
>> 3    85     89     25    77
>> .
>> .
>> 300,000
>>
>> I would like to identify all customers ids who have had each meal
>> combination in the first table so the final output would be the first table
>> with ids attached next to each meal combination in each row like this:
>>
>>>IdsMeals
>>
>>
>>   MAcode  MBcode  ids
>>
>> 1     34        39            11
>>
>> 2     25       34              15   11
>>
>> 3      25     77                15   85
>>
>> Would you please suggest any solutions to this problem?
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From david.chin at drexel.edu  Tue May 23 18:59:14 2017
From: david.chin at drexel.edu (David Chin)
Date: Tue, 23 May 2017 12:59:14 -0400
Subject: [R] Compiling R with zlib in non-standard location
In-Reply-To: <52306A9F-A61B-4E5C-B788-367069FAD59F@me.com>
References: <CAP-4TpU5JN7CYEEFoiiX1en3A2onRu3vOkteraBL-a+u2qUtoQ@mail.gmail.com>
 <52306A9F-A61B-4E5C-B788-367069FAD59F@me.com>
Message-ID: <CAP-4TpUpqfAWLtUHqZ0U_yiX_SQk3zx5fjLPJZVOt_pdzSLkLQ@mail.gmail.com>

Hi Marc,

Pre-compiled RPMs for R are up to 3x slower than "self-compiled" R using
Intel MKL.  Yes, I do know about Microsoft R Open, but it wants to
overwrite the default /usr/bin/R and I have AMD machines in my cluster,
which cannot run MRO. So, I want to do my own compilation and install R in
a non-standard location so that it can be used by loading a modulefile.  I
also have users who have varying requirements for versions of R (for
whatever reason), so I need to provide different versions.



On Tue, May 23, 2017 at 12:50 PM, Marc Schwartz <marc_schwartz at me.com>
wrote:

>
> > On May 23, 2017, at 11:07 AM, David Chin <david.chin.work at gmail.com>
> wrote:
> >
> > Hi all,
> >
> > I am trying to compile R 3.4.0 on a RHEL 6.5 system. R requires a newer
> > version of zlib than is standard on RHEL 6.5. I do have a newer version
> > that satisfies R's requirement, but the configure script gives no way of
> > specifying a non-standard location of zlib.
> >
> > Is there a way around this? Or should I try to make a feature request?
> >
> > Thanks in advance,
> >    Dave
>
>
> Hi,
>
> This was recently asked here:
>
>   https://stat.ethz.ch/pipermail/r-devel/2017-April/074157.html
>
> Martyn provided a resolution in the follow up post, including a pointer to
> the EPEL, where there are pre-compiled RPMs for R.
>
> For future reference, there is a dedicated e-mail list for queries
> pertaining to R on RH/Fedora based distributions:
>
>   https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>
> Regards,
>
> Marc Schwartz
>
>


-- 
David Chin, Ph.D.
david.chin at drexel.edu    Sr. Systems Administrator, URCF, Drexel U.
http://www.drexel.edu/research/urcf/
https://linuxfollies.blogspot.com/
+1.215.221.4747 (mobile)
https://github.com/prehensilecode

	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Tue May 23 19:27:45 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 23 May 2017 17:27:45 +0000 (UTC)
Subject: [R] prcomp: Error in La.svd(x, nu,
 nv): error code 1 from Lapack routine "dgesdd"
In-Reply-To: <CA+vqiLG_72uakzdS9RSpv1razuRs7-Xs5SYPTaPv4=zZ39xN8w@mail.gmail.com>
References: <mailman.2109.1481554377.3878.r-help@r-project.org>
 <1696757755.2866913.1482950990817@mail.yahoo.com>
 <1819010636.3252551.1483023558354@mail.yahoo.com>
 <CA+vqiLG_72uakzdS9RSpv1razuRs7-Xs5SYPTaPv4=zZ39xN8w@mail.gmail.com>
Message-ID: <321606284.556005.1495560465482@mail.yahoo.com>

Dear R community,
I have a data matrix (531X314), and would like to apply the prcomp. However, I got this error Lapack message. I am using R3.2.2.
I googled a bit and found that it might be related to converge issue. ?Just wonder if there is a way to get around it?
Thank you very much!
Ace 

    On Thursday, December 29, 2016 11:44 AM, Ista Zahn <istazahn at gmail.com> wrote:
 

 Use coord_fixed()

--Ista

On Thu, Dec 29, 2016 at 9:59 AM, Fix Ace via R-help
<r-help at r-project.org> wrote:
>
>
>
>? Hello, there,
> What exactly does "expand" do for this function?
> I followed the examples from the manual to get a plot:
>
> d <- ggplot(subset(diamonds, carat > 1), aes(cut, clarity)) +geom_jitter()
>
> I would like to have all the dots in a square instead of rectangular range. When I applied d + scale_x_discrete(expand=c(1,1)) and d + scale_x_discrete(expand=c(1,0)), I got the same plot (different from the original one though).
> Could anyone help me to figure out how to use this argument?
> Thank you very much!
> Ace
>
>
>
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From frainj at gmail.com  Tue May 23 22:25:29 2017
From: frainj at gmail.com (John C Frain)
Date: Tue, 23 May 2017 21:25:29 +0100
Subject: [R] Forecast using VAR model
In-Reply-To: <CACmggQtnj9uoR7yEawYm7ZaYvcY=JtUbx34K0gKKK_1_iNGrcw@mail.gmail.com>
References: <CACmggQvJb8pQPQ_eJBgPxAkfNT0ua4DrqGt-tEX6Hy9ODotq8Q@mail.gmail.com>
 <CAHrK5172qwa+hYeVv1bLXWNQrpwv84xFWWgQ7rfSMNHEHC6M+Q@mail.gmail.com>
 <CACmggQtnj9uoR7yEawYm7ZaYvcY=JtUbx34K0gKKK_1_iNGrcw@mail.gmail.com>
Message-ID: <CAHrK517xd_F0L_wkgdf8-7yN2EgcnP46iDcid+He9o6q2_wWMw@mail.gmail.com>

Dhivya

You have two variables speed and vibration. It strikes me that speed causes
vibration and vibration does not cause speed. Forgive me if I have
misunderstood. In such a case you would be better off using an ARMAX model
with vibration as dependent variable and speed as an explanatory variable.
The fact that you have autocorrelation problems is an indication that your
var model is not a correct specification.  I note that there are many zeros
in your data set. Are these missed measurements or actual zeros. If they
are missing observations your analysis becomes much more complicated.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 22 May 2017 at 06:16, Dhivya Narayanasamy <dhiv.shreya at gmail.com> wrote:

> Hi Jon,
>
> sorry for the inconvenience. I have done it in plain text now.
>
> I am building a VAR model to forecast of bivariate time series. But it
> shows flat forecast and i am in need of correcting  it. Is there any way
> to correct this flat forecast?  or Do i have to go with other models?
>
> Code:
>
> > datax.zoo <- read.zoo(datax)
> > datax.ts <- ts(datax.zoo)
> > v1b <- VARselect(datax.ts, lag.max = 10, type = "const")
> > v1b$selection
> AIC(n)  HQ(n)  SC(n) FPE(n)
>     10      7      3     10
> > var7 = VAR(datax.ts, p=7)
> > serial.test(var7, lags.pt=10, type = "PT.asymptotic")
>
> Portmanteau Test (asymptotic)
>
> data:  Residuals of VAR object var7
> Chi-squared = 31.991, df = 12, p-value = 0.001388
>
> > gf1 <- forecast(var7, h = 600)
> > plot(gf1, main = "var7")
> > grangertest(datax.ts[,1] ~ datax.ts[,2], order = 7)
> Granger causality test
>
> Model 1: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7) + Lags(datax.ts[, 2],
> 1:7)
> Model 2: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7)
>   Res.Df Df      F    Pr(>F)
> 1   9968
> 2   9975 -7 20.852 < 2.2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > grangertest(datax.ts[,2] ~  datax.ts[,1], order = 7)
> Granger causality test
>
> Model 1: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7) + Lags(datax.ts[, 1],
> 1:7)
> Model 2: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7)
>   Res.Df Df      F   Pr(>F)
> 1   9968
> 2   9975 -7 3.0918 0.002948 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>
> The P value from "Portmanteau Test" is very much less than << 0.05 for
> lagged value 7. Is this correct?
> I have added my plot and raw data in the attachment for your further
> reference. Thank you.
>
>
>
> Regards| Mit freundlichen Gr??en,
>> Dhivya Narayanasamy
>
>
> Regards| Mit freundlichen Gr??en,
>
> Dhivya Narayanasamy
>
> Contact No: +91-8438505020 <+91%2084385%2005020>
>
> On Sun, May 21, 2017 at 5:40 PM, John C Frain <frainj at gmail.com> wrote:
>
>> It would be much easier to see what you are doing if you reposted in
>> plain text.
>>
>> John C Frain
>> 3 Aranleigh Park
>> Rathfarnham
>> Dublin 14
>> Ireland
>> www.tcd.ie/Economics/staff/frainj/home.html
>> mailto:frainj at tcd.ie
>> mailto:frainj at gmail.com
>>
>> On 21 May 2017 at 06:05, Dhivya Narayanasamy <dhiv.shreya at gmail.com>
>> wrote:
>>
>>> I am building a VAR model to forecast of bivariate timeseries. But it
>>> shows
>>> flat forecast.
>>>
>>> So I would like to use recursive window forecasting technique using VAR
>>> model. Will it give what i expect (Avoid flat forecast) ? or should i
>>> have
>>> to go with other package.
>>>
>>> > datax.zoo <- read.zoo(datax)> datax.ts <- ts(datax.zoo)> v1b <-
>>> VARselect(datax.ts, lag.max = 10, type = "const")> v1b
>>> $selection
>>> AIC(n)  HQ(n)  SC(n) FPE(n)
>>>      9      7      5      9
>>>
>>> $criteria
>>>                   1            2            3            4
>>> 5            6            7
>>> AIC(n)     9.686513     9.657172     9.632444     9.625856
>>> 9.621148     9.619425     9.615396
>>> HQ(n)      9.688951     9.661234     9.638131     9.633167
>>> 9.630085     9.629987     9.627583
>>> SC(n)      9.693514     9.668839     9.648778     9.646856
>>> 9.646815     9.649759     9.650397
>>> FPE(n) 16099.014774 15633.507506 15251.665643 15151.510512
>>> 15080.352425 15054.392389 14993.864861
>>>                   8            9           10
>>> AIC(n)     9.615430     9.615116     9.615990
>>> HQ(n)      9.629241     9.630552     9.633051
>>> SC(n)      9.655098     9.659451     9.664991
>>> FPE(n) 14994.366572 14989.661383 15002.762011
>>> > var7 = VAR(datax.ts, p=7)> serial.test(var7, lags.pt=10, type =
>>> "PT.asymptotic")
>>>
>>>     Portmanteau Test (asymptotic)
>>>
>>> data:  Residuals of VAR object var7Chi-squared = 22.745, df = 12,
>>> p-value = 0.02997
>>> > grangertest(datax.ts[,1] ~ datax.ts[,2], order = 7)Granger causality
>>> test
>>> Model 1: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7) + Lags(datax.ts[,
>>> 2], 1:7)Model 2: datax.ts[, 1] ~ Lags(datax.ts[, 1], 1:7)
>>>   Res.Df Df      F    Pr(>F)    1   5686                        2
>>> 5693 -7 16.105 < 2.2e-16 ***---Signif. codes:  0 ?***? 0.001 ?**? 0.01
>>> ?*? 0.05 ?.? 0.1 ? ? 1> grangertest(datax.ts[,2] ~  datax.ts[,1],
>>> order = 7)Granger causality test
>>> Model 1: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7) + Lags(datax.ts[,
>>> 1], 1:7)Model 2: datax.ts[, 2] ~ Lags(datax.ts[, 2], 1:7)
>>>   Res.Df Df      F Pr(>F)1   5686                 2   5693 -7 1.5618
>>> 0.1418
>>> > g <- forecast(var7, h = 600)> plot(g)
>>>
>>>
>>> Also the 'P' value  from portmanteau test shows auto correlation is
>>> present
>>> is my VAR model. Here is my raw data you can find :
>>> https://drive.google.com/file/d/0B7I0DT-PiG4RenVkdXV3OFJLYVk
>>> /view?usp=sharing
>>>
>>>
>>> Thank you.
>>>
>>> Regards
>>> > Dhivya Narayanasamy
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Tue May 23 23:59:13 2017
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 23 May 2017 17:59:13 -0400
Subject: [R] ggplot problem
Message-ID: <CAM9Qe4h1k1sGFfkUgYgh5aGWciFdN3ChDpNC=K3B6OmQ+QjMDQ@mail.gmail.com>

Hi all;

When I run the following program substantially I have "Warning message:
position_dodge requires non-overlapping x intervals"

How I can overcome this problem.

Regards,

Greg

p <- ggplot() + geom_point(data=a, aes(x=Betas, y=Traits, color=
Super.Pathway), shape=15, size=4)

p <- p + guides(color=guide_legend(title=NULL))

p <- p + theme(legend.key = element_blank())

p <- p  + geom_boxplot(data=a,aes(x=Betas,fill=factor(Super.Pathway),y=Traits))
+ guides(fill=FALSE) +scale_x_continuous(breaks = seq(-50, 60, 5))

p

	[[alternative HTML version deleted]]


From raqueldourado at hotmail.com  Wed May 24 00:52:09 2017
From: raqueldourado at hotmail.com (Raquel D.)
Date: Tue, 23 May 2017 22:52:09 +0000
Subject: [R] Apriori Results- Same number to support an confidence
Message-ID: <BN6PR2001MB09775C34B1A79598D14A8D2AB7F90@BN6PR2001MB0977.namprd20.prod.outlook.com>

Hi!


Does anybody knows why it can be happening? Lift = 1




rule length distribution (lhs + rhs):sizes
 1
68

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      1       1       1       1       1       1

summary of quality measures:
    support           confidence            lift
 Min.   :0.002050   Min.   :0.002050   Min.   :1
 1st Qu.:0.002899   1st Qu.:0.002899   1st Qu.:1
 Median :0.004465   Median :0.004465   Median :1
 Mean   :0.008703   Mean   :0.008703   Mean   :1
 3rd Qu.:0.007605   3rd Qu.:0.007605   3rd Qu.:1
 Max.   :0.059593   Max.   :0.059593   Max.   :1

mining info:
 data ntransactions support confidence
  txn        438612   0.001      0.002



	[[alternative HTML version deleted]]


From wissmar.kristen at gmail.com  Wed May 24 03:45:50 2017
From: wissmar.kristen at gmail.com (kristen wissmar)
Date: Wed, 24 May 2017 11:45:50 +1000
Subject: [R] Fwd: Rpart help
In-Reply-To: <CALubmVMcm5FGUS5DHzPgcW562t1hFXRjwtwv1Nj+efGjqZ7buw@mail.gmail.com>
References: <CALubmVMcm5FGUS5DHzPgcW562t1hFXRjwtwv1Nj+efGjqZ7buw@mail.gmail.com>
Message-ID: <CALubmVP5TwSLv+J8Fz+X_xsMQ2SxXAOJHzjEew=y85Pk7af3-w@mail.gmail.com>

Hi R users!

I'm new to R, so I'm starting with a basic exercise in rpart.

I'm predicting if a user will churn based on past order history.  I've
calculated the probabilities in excel, and if user is a single order
customer (1), then their probability of churn is 90%, if there are multiple
orders(0) then the probability of churning is 70%. In the R model, the
probability looks like it's 100% and 53%. In excel I used the count of
shopper_key to calculate probabilities. So I'm wondering if R has needs a
shopper_key to count?

It would be helpful if someone could suggest where I'm going wrong.

Thank you!


Code -
m1 <- rpart( churn ~ single_order , data = data2, method="anova" )

Output-
n= 22041

node), split, n, deviance, yval
      * denotes terminal node

1) root 22041 3229.265 0.8216959
  2) single_order< 0.5 8407 2092.852 0.5325324 *
  3) single_order>=0.5 13634    0.000 1.0000000 *


shopper_key churn single_order
1 1 0
2 1 1
3 0 0
4 1 0
5 1 1
6 1 1
7 1 0
8 1 1
9 0 1
10 1 1

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed May 24 04:32:18 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 May 2017 19:32:18 -0700
Subject: [R] Apriori Results- Same number to support an confidence
In-Reply-To: <BN6PR2001MB09775C34B1A79598D14A8D2AB7F90@BN6PR2001MB0977.namprd20.prod.outlook.com>
References: <BN6PR2001MB09775C34B1A79598D14A8D2AB7F90@BN6PR2001MB0977.namprd20.prod.outlook.com>
Message-ID: <CAGxFJbTuJ6PMZ0A_dzMvAQO3LUN1E-JmFs1wY-n=WPg78vFPrQ@mail.gmail.com>

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 23, 2017 at 3:52 PM, Raquel D. <raqueldourado at hotmail.com> wrote:
> Hi!
>
>
> Does anybody knows why it can be happening? Lift = 1

Doubt it. Pretty incoherent, to me anyway.

But this is probaby the wrong place to post. This list is about R
programming; statistics is generally OT. Try posting on
stats.stackexchange.com for statistics issues. Being more coherent
might help, too

-- Bert


>
>
>
>
> rule length distribution (lhs + rhs):sizes
>  1
> 68
>
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       1       1       1       1       1       1
>
> summary of quality measures:
>     support           confidence            lift
>  Min.   :0.002050   Min.   :0.002050   Min.   :1
>  1st Qu.:0.002899   1st Qu.:0.002899   1st Qu.:1
>  Median :0.004465   Median :0.004465   Median :1
>  Mean   :0.008703   Mean   :0.008703   Mean   :1
>  3rd Qu.:0.007605   3rd Qu.:0.007605   3rd Qu.:1
>  Max.   :0.059593   Max.   :0.059593   Max.   :1
>
> mining info:
>  data ntransactions support confidence
>   txn        438612   0.001      0.002
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed May 24 04:38:53 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 May 2017 19:38:53 -0700
Subject: [R] Fwd: Rpart help
In-Reply-To: <CALubmVP5TwSLv+J8Fz+X_xsMQ2SxXAOJHzjEew=y85Pk7af3-w@mail.gmail.com>
References: <CALubmVMcm5FGUS5DHzPgcW562t1hFXRjwtwv1Nj+efGjqZ7buw@mail.gmail.com>
 <CALubmVP5TwSLv+J8Fz+X_xsMQ2SxXAOJHzjEew=y85Pk7af3-w@mail.gmail.com>
Message-ID: <CAGxFJbRMNj2QF3i-vEkk+3dg9p=LYeKui-k4Y5jN5HR3JzpnWA@mail.gmail.com>

1. Forget Excel. Erase it from your memory. banish its paradigms from
your practices. Faiing to do so will only bring misery as you explore
R. R is a rational programming language primarily for data analysis,
statistics, and graphics. Excel is, ummm, not.

2. Have you read the rpart documents and vignettes? That should be
your first port of call for questions about how it works.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 23, 2017 at 6:45 PM, kristen wissmar
<wissmar.kristen at gmail.com> wrote:
> Hi R users!
>
> I'm new to R, so I'm starting with a basic exercise in rpart.
>
> I'm predicting if a user will churn based on past order history.  I've
> calculated the probabilities in excel, and if user is a single order
> customer (1), then their probability of churn is 90%, if there are multiple
> orders(0) then the probability of churning is 70%. In the R model, the
> probability looks like it's 100% and 53%. In excel I used the count of
> shopper_key to calculate probabilities. So I'm wondering if R has needs a
> shopper_key to count?
>
> It would be helpful if someone could suggest where I'm going wrong.
>
> Thank you!
>
>
> Code -
> m1 <- rpart( churn ~ single_order , data = data2, method="anova" )
>
> Output-
> n= 22041
>
> node), split, n, deviance, yval
>       * denotes terminal node
>
> 1) root 22041 3229.265 0.8216959
>   2) single_order< 0.5 8407 2092.852 0.5325324 *
>   3) single_order>=0.5 13634    0.000 1.0000000 *
>
>
> shopper_key churn single_order
> 1 1 0
> 2 1 1
> 3 0 0
> 4 1 0
> 5 1 1
> 6 1 1
> 7 1 0
> 8 1 1
> 9 0 1
> 10 1 1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed May 24 06:05:37 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 May 2017 16:05:37 +1200
Subject: [R] [FORGED] Re:  Fwd: Rpart help
In-Reply-To: <CAGxFJbRMNj2QF3i-vEkk+3dg9p=LYeKui-k4Y5jN5HR3JzpnWA@mail.gmail.com>
References: <CALubmVMcm5FGUS5DHzPgcW562t1hFXRjwtwv1Nj+efGjqZ7buw@mail.gmail.com>
 <CALubmVP5TwSLv+J8Fz+X_xsMQ2SxXAOJHzjEew=y85Pk7af3-w@mail.gmail.com>
 <CAGxFJbRMNj2QF3i-vEkk+3dg9p=LYeKui-k4Y5jN5HR3JzpnWA@mail.gmail.com>
Message-ID: <de87010e-e03c-bd92-9fe3-53ba55ccbe3b@auckland.ac.nz>


On 24/05/17 14:38, Bert Gunter wrote:

> Forget Excel. Erase it from your memory. banish its paradigms from
> your practices. Faiing to do so will only bring misery as you explore
> R. R is a rational programming language primarily for data analysis,
> statistics, and graphics. Excel is, ummm, not.

Gotta be a fortune!!!

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From thierry.onkelinx at inbo.be  Wed May 24 09:51:46 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 24 May 2017 09:51:46 +0200
Subject: [R] ggplot problem
In-Reply-To: <CAM9Qe4h1k1sGFfkUgYgh5aGWciFdN3ChDpNC=K3B6OmQ+QjMDQ@mail.gmail.com>
References: <CAM9Qe4h1k1sGFfkUgYgh5aGWciFdN3ChDpNC=K3B6OmQ+QjMDQ@mail.gmail.com>
Message-ID: <CAJuCY5yiiSk+xC1rCKatNsHez48cCjBxhT=RcL+id05skEVJ4A@mail.gmail.com>

Dear Greg,

Make sure that your x variable (Betas) is categorical. That is required for
geom_boxplot().

And please do read the posting guide.

Best regards,



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-05-23 23:59 GMT+02:00 greg holly <mak.hholly at gmail.com>:

> Hi all;
>
> When I run the following program substantially I have "Warning message:
> position_dodge requires non-overlapping x intervals"
>
> How I can overcome this problem.
>
> Regards,
>
> Greg
>
> p <- ggplot() + geom_point(data=a, aes(x=Betas, y=Traits, color=
> Super.Pathway), shape=15, size=4)
>
> p <- p + guides(color=guide_legend(title=NULL))
>
> p <- p + theme(legend.key = element_blank())
>
> p <- p  + geom_boxplot(data=a,aes(x=Betas,fill=factor(Super.
> Pathway),y=Traits))
> + guides(fill=FALSE) +scale_x_continuous(breaks = seq(-50, 60, 5))
>
> p
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed May 24 10:30:16 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 24 May 2017 10:30:16 +0200
Subject: [R] Rpart help
In-Reply-To: <CAGxFJbRMNj2QF3i-vEkk+3dg9p=LYeKui-k4Y5jN5HR3JzpnWA@mail.gmail.com>
References: <CALubmVMcm5FGUS5DHzPgcW562t1hFXRjwtwv1Nj+efGjqZ7buw@mail.gmail.com>
 <CALubmVP5TwSLv+J8Fz+X_xsMQ2SxXAOJHzjEew=y85Pk7af3-w@mail.gmail.com>
 <CAGxFJbRMNj2QF3i-vEkk+3dg9p=LYeKui-k4Y5jN5HR3JzpnWA@mail.gmail.com>
Message-ID: <F15759A7-6ED0-47CC-807F-3321BD0482F1@gmail.com>


> On 24 May 2017, at 04:38 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> 1. Forget Excel. Erase it from your memory. banish its paradigms from
> your practices. Faiing to do so will only bring misery as you explore
> R. R is a rational programming language primarily for data analysis,
> statistics, and graphics. Excel is, ummm, not.

And, never mind Bert's rant, a simple table(single_order, churn) would give info similar to what you claim to have from Excel, minus the risk of finding that the data are not the same, or that Excel was doing something bizarre.

-pd


> 
> 2. Have you read the rpart documents and vignettes? That should be
> your first port of call for questions about how it works.
> 
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, May 23, 2017 at 6:45 PM, kristen wissmar
> <wissmar.kristen at gmail.com> wrote:
>> Hi R users!
>> 
>> I'm new to R, so I'm starting with a basic exercise in rpart.
>> 
>> I'm predicting if a user will churn based on past order history.  I've
>> calculated the probabilities in excel, and if user is a single order
>> customer (1), then their probability of churn is 90%, if there are multiple
>> orders(0) then the probability of churning is 70%. In the R model, the
>> probability looks like it's 100% and 53%. In excel I used the count of
>> shopper_key to calculate probabilities. So I'm wondering if R has needs a
>> shopper_key to count?
>> 
>> It would be helpful if someone could suggest where I'm going wrong.
>> 
>> Thank you!
>> 
>> 
>> Code -
>> m1 <- rpart( churn ~ single_order , data = data2, method="anova" )
>> 
>> Output-
>> n= 22041
>> 
>> node), split, n, deviance, yval
>>      * denotes terminal node
>> 
>> 1) root 22041 3229.265 0.8216959
>>  2) single_order< 0.5 8407 2092.852 0.5325324 *
>>  3) single_order>=0.5 13634    0.000 1.0000000 *
>> 
>> 
>> shopper_key churn single_order
>> 1 1 0
>> 2 1 1
>> 3 0 0
>> 4 1 0
>> 5 1 1
>> 6 1 1
>> 7 1 0
>> 8 1 1
>> 9 0 1
>> 10 1 1
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.turner at auckland.ac.nz  Wed May 24 10:47:32 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 May 2017 20:47:32 +1200
Subject: [R] [FORGED] Re:  Rpart help
In-Reply-To: <F15759A7-6ED0-47CC-807F-3321BD0482F1@gmail.com>
References: <CALubmVMcm5FGUS5DHzPgcW562t1hFXRjwtwv1Nj+efGjqZ7buw@mail.gmail.com>
 <CALubmVP5TwSLv+J8Fz+X_xsMQ2SxXAOJHzjEew=y85Pk7af3-w@mail.gmail.com>
 <CAGxFJbRMNj2QF3i-vEkk+3dg9p=LYeKui-k4Y5jN5HR3JzpnWA@mail.gmail.com>
 <F15759A7-6ED0-47CC-807F-3321BD0482F1@gmail.com>
Message-ID: <4252f64e-b881-5625-0d60-2ff2b8ad9efb@auckland.ac.nz>

On 24/05/17 20:30, peter dalgaard wrote:

<SNIP>

> And, never mind Bert's rant, a simple table(single_order, churn)
> would give info similar to what you claim to have from Excel, minus
> the risk of finding that the data are not the same, or that Excel was
> doing something bizarre.

<SNIP>

Bert?  Rant?  Perish the thought!!! :-)

cheers,

Rolf

P. S.  My thunderbird spell-checker suggests "laggard" as an alternative 
for the unrecognised "dalgaard".  :-)

R.


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From p_connolly at slingshot.co.nz  Wed May 24 11:07:59 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 24 May 2017 21:07:59 +1200
Subject: [R] Error in readRDS(dest) (was Re: Error with
 installed.packages with R 3.4.0 on Windows)
In-Reply-To: <22820.3316.479418.85208@stat.math.ethz.ch>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
 <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
 <20170522091022.GC4553@slingshot.co.nz>
 <7b8f4895-b41d-6634-367b-1754bc737c02@roswellpark.org>
 <20170523084722.GD4553@slingshot.co.nz>
 <22820.3316.479418.85208@stat.math.ethz.ch>
Message-ID: <20170524090759.GE4553@slingshot.co.nz>

On Tue, 23-May-2017 at 12:20PM +0200, Martin Maechler wrote:

[...]

|> 
|> Given the above stack trace. 
|> It may be easier to just do
|> 
|>     debugonce(available.packages)
|>     install.packages("withr")
|> 
|> and then inside available.packages, (using 'n') step to the
|> point _before_ the tryCatch(...) call happens; there, e.g. use
|> 
|>       ls.str()

I got:

contriburl :  chr [1:2] "http://cran.stat.auckland.ac.nz/src/contrib" ...
dest :  chr "/tmp/Rtmp6D0KNY/repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds"
fields :  chr [1:16] "Package" "Version" "Priority" "Depends" "Imports" "LinkingTo" ...
filters :  NULL
localcran :  logi FALSE
method : <missing>
repos :  chr "http://cran.stat.auckland.ac.nz/src/contrib"
requiredFields :  chr [1:16] "Package" "Version" "Priority" "Depends" "Imports" "LinkingTo" ...
res :  chr[0 , 1:17] 
type :  chr "source"


So I thought the missing method was the problem.  However, it's
exactly the same with R-3.3.3.  So still no answwer.

Then I tried:

debugonce(readRDS)
install.packages("withr")

Browse[2]> con
A connection with    
description "/tmp/RtmpqzKzzK/repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds"
class       "gzfile"               
mode        "rb"                   
text        "binary"               
opened      "opened"               
can read    "yes"                  
can write   "no"

## With R-3.3.3

Browse[2]> con       
                                                description 
"/home/hrapgc/local/R-3.3.3/library/abind/Meta/package.rds" 
                                                      class 
                                                   "gzfile" 
                                                       mode 
                                                       "rb" 
                                                       text 
                                                   "binary" 
                                                     opened 
                                                   "opened" 
                                                   can read 
                                                      "yes" 
                                                  can write 
                                                       "no" 

So, in 3.4.0, con refers to a repo and is zero length whereas 3.3.3
refers to a library.  To me that would appear to be a major
difference.  That must have something to do with it.  But what?

Since the latter works and the former doesn't, it seems as though the
problem is with 3.4.0's readRDS().  But others seem not to have the
same problem.  I'm no closer to understanding what's happenning.


-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From allaisone1 at hotmail.com  Wed May 24 14:54:07 2017
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Wed, 24 May 2017 12:54:07 +0000
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <925d7124b8f74cc0827755161faa61ad@exch-2p-mbx-w2.ads.tamu.edu>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQH55Lv47+46Xxs_prJ7+Ay-XQPKg2_bEwD-ieLtF3i2A@mail.gmail.com>
 <AM5P195MB00205C73AAC9BB5DD9391C8380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <CAGxFJbRwQMvuFavCatxGtgoYwLGrmOkqbXzi04yTr0Z0yiRZTA@mail.gmail.com>
 <AM5P195MB0020AF7DF2653A5A3E3F042380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <925d7124b8f74cc0827755161faa61ad@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <AM5P195MB00205A284E34B37CDB70BCBC80FE0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>

Dear David ..,


Many thanks for spending the time and effort solving this problem.


I liked your suggestion to generate the results with the first format

as this will be very helpful for further analysis :

 #   mealAcode mealBcode id
# 1        25        77             15
# 2        25        77             85
# 3        34        39             11
# 4        25        34             15
# 5        25        34             11


I wonder if if there is any method to process the analysis faster. The end output will be a very large table as I already know from my previous analysis that for example I have around 20,000 customers taking one of these combinations and there are about 17,000 customers taking another combination of meals and so on. Considering that I have 2000 rows (2000 combinations) and that number of customers per combination is very high

(20,000 or lower), this will generate a huge table with millions of rows which is very complex.  I have tested the code just to see and as expected it takes a long time(hours) before I stopped the analysis.

________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 23 May 2017 18:20:02
To: Allaisone 1; Bert Gunter
Cc: r-help at r-project.org
Subject: RE: [R] Identyfing rows with specific conditions

You will generally get a better response if you create a data set that we can test our ideas on. You sketched out the data but your final results include meal combinations that are not in your Meals data frame. Also using dput() to provide the data makes it easier to recreate the data since just printing it loses important information such as if the numbers are integer or decimal, or if the character variables are characters or factors. Also send your message as plain text, not html which messes up columns and other details. Here is a modification of your data with the beginnings of a solution:

Meals <- structure(list(mealAcode = c(34L, 89L, 25L, 34L, 25L), mealBcode = c(66L,
39L, 77L, 39L, 34L)), .Names = c("mealAcode", "mealBcode"), row.names = c(NA,
-5L), class = "data.frame")
Meals
#   mealAcode mealBcode
# 1        34        66
# 2        89        39
# 3        25        77
# 4        34        39
# 5        25        34

Customers <- structure(list(id = c(15L, 11L, 85L), M1 = c(77L, 25L, 89L),
    M2 = c(34L, 34L, 25L), M3 = c(25L, 39L, 77L)), .Names = c("id",
"M1", "M2", "M3"), class = "data.frame", row.names = c(NA, -3L
))
Customers
#   id M1 M2 M3
# 1 15 77 34 25
# 2 11 25 34 39
# 3 85 89 25 77

Results <- data.frame(mealAcode=NA, mealBcode=NA, id=NA)
k <- 0
for (i in seq_len(nrow(Meals))) {
    for (j in seq_len(nrow(Customers))) {
        if (any(Customers[j, -1] %in% Meals[i, 1]) &
            any(Customers[j, -1] %in% Meals[i, 2])) {
               k <- k+1
               Results[k, ] <- cbind(Meals[i, ], id=Customers[j, 1])
        }
    }
rownames(Results) <- NULL
}
Results
#   mealAcode mealBcode id
# 1        25        77 15
# 2        25        77 85
# 3        34        39 11
# 4        25        34 15
# 5        25        34 11

Results is a data frame that can be modified to get various forms of output. You mention a data frame with ids in separate columns. That might be unwieldy for many types of analysis. The following list shows the ids for each meal combination,  the number of meals of each combination consumed, and a matrix similar to the one you provided.

Results.lst <- split(Results$id,  paste(Results[ , 1], Results[ , 2], sep=" - "))
Results.lst
# $`25 - 34`
# [1] 15 11
#
# $`25 - 77`
# [1] 15 85
#
# $`34 - 39`
# [1] 11
table(Results[, 1:2])
#          mealBcode
# mealAcode 34 39 77
#        25  2  0  2
#        34  0  1  0
maxid <- 5
t(sapply(Results.lst, function(x) c(sort(as.vector(x)),
     rep(NA, maxid-length(as.vector(x))))))
#         [,1] [,2] [,3] [,4] [,5]
# 25 - 34   11   15   NA   NA   NA
# 25 - 77   15   85   NA   NA   NA
# 34 - 39   11   NA   NA   NA   NA

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Allaisone 1
Sent: Monday, May 22, 2017 4:41 PM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

Dear Bert

I have answered your questions in my last 2 messages. If you did not see them, I will answer again. The 2 tables are all data.frames and the order of the meals does not matter. The meal cannot be replicated for each person, they are all different. The missing values are to the right end of each row as each row starts with meal codes first. This task is just a small part of a long 2 years project.

Regards
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 22 May 2017 14:35:49
To: Allaisone 1
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

You haven't said whether your "table" is a matrix or data frame.
Presumably the latter.

Nor have you answered my question about whether order of your meal
code pairs matters.

Another question: can meals be replicated for an ID or are they all different?

Finally, is this a homework assignment or class project of some sort?
Or is it a real task -- i.e., what is the context?

Again, be sure to cc the list.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 22, 2017 at 1:56 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> Hi Bert ..,
>
>
> The number of meals differ from one customer to other customer. You may find
> one customer with only one meal and another one with 2,3 or even rarely 30
> meals. You may also
>
> find no meal at all for some customers so the entire row takes the missing
> value "\N" . Any
>
> row starts with the meals codes first, then all missing values are to the
> right end of the table.
>
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 22 May 2017 03:11:11
> To: Allaisone 1
> Cc: r-help at r-project.org
> Subject: Re: [R] Identyfing rows with specific conditions
>
> Clarification:
>
> Does each customer have the same number of meals or do they differ
> from customer to customer? If the latter, how are missing meals
> notated? Do they always occur at the (right) end or can they occur
> anywhere in the row?
>
> Presumably each customer ID can have many different meal code
> combinations, right ?(since they can have 30 different meals with
> potentially 30 choose 2 = 435 combinations apiece)
>
> Please make sure you reply to the list, not just to me, as I may not
> pursue this further but am just trying to clarify for anyone else who
> may wish to help.
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>
>> Hi All..,
>>
>> I have 2 tables. The first one contains 2 columns with the headers say
>> "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each
>> of which with a different combination of meals(unique combination per row).
>>
>>
>>>Meals
>>
>>     meal A code      meal B code
>>
>> 1          34                   66
>>
>> 2           89                  39
>>
>> 3           25                   77
>>
>> The second table(customers) shows customers ids in the first column with
>> Meals codes(M) next to each customer. There are about 300,000 customers
>> (300,000 rows).
>>
>>> Customers
>>      1         2     3       4    ..30
>>      id       M1  M2   M3
>> 1   15      77    34    25
>> 2   11      25    34     39
>> 3    85     89     25    77
>> .
>> .
>> 300,000
>>
>> I would like to identify all customers ids who have had each meal
>> combination in the first table so the final output would be the first table
>> with ids attached next to each meal combination in each row like this:
>>
>>>IdsMeals
>>
>>
>>   MAcode  MBcode  ids
>>
>> 1     34        39            11
>>
>> 2     25       34              15   11
>>
>> 3      25     77                15   85
>>
>> Would you please suggest any solutions to this problem?
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed May 24 19:23:20 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 May 2017 17:23:20 +0000
Subject: [R] Identyfing rows with specific conditions
In-Reply-To: <AM5P195MB00205A284E34B37CDB70BCBC80FE0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
References: <AM5P195MB0020AB0490A484595E38C68780F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbQH55Lv47+46Xxs_prJ7+Ay-XQPKg2_bEwD-ieLtF3i2A@mail.gmail.com>
 <AM5P195MB00205C73AAC9BB5DD9391C8380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <CAGxFJbRwQMvuFavCatxGtgoYwLGrmOkqbXzi04yTr0Z0yiRZTA@mail.gmail.com>
 <AM5P195MB0020AF7DF2653A5A3E3F042380F80@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>,
 <925d7124b8f74cc0827755161faa61ad@exch-2p-mbx-w2.ads.tamu.edu>
 <AM5P195MB00205A284E34B37CDB70BCBC80FE0@AM5P195MB0020.EURP195.PROD.OUTLOOK.COM>
Message-ID: <9b00873fd18d48f5b7ce9fb6adaf9e56@exch-2p-mbx-w2.ads.tamu.edu>

You may run into memory issues if the table is that large in which case you may need to break your customers into subsets and process each subset separately. Then combine the results of the subsets into a single file. 

There are a couple of relatively easy ways to speed things up, but I don't know if it will be enough. The simplest is to change from data.frames to matrices:

Meals <- structure(list(mealAcode = c(34L, 89L, 25L, 34L, 25L), mealBcode = c(66L, 
39L, 77L, 39L, 34L)), .Names = c("mealAcode", "mealBcode"), row.names = c(NA, 
-5L), class = "data.frame")

Customers <- structure(list(id = c(15L, 11L, 85L), M1 = c(77L, 25L, 89L), 
    M2 = c(34L, 34L, 25L), M3 = c(25L, 39L, 77L)), .Names = c("id", 
"M1", "M2", "M3"), class = "data.frame", row.names = c(NA, -3L
))

Meals <- as.matrix(Meals)
Meals <- unname(Meals)
Customers <- as.matrix(Customers)
Customers <- unname(Customers)

Results <- matrix(nrow=0, ncol=3)
k <- 0
for (i in seq_len(nrow(Meals))) {
    for (j in seq_len(nrow(Customers))) {
        if (any(Customers[j, -1] %in% Meals[i, 1]) & 
            any(Customers[j, -1] %in% Meals[i, 2])) {
               k <- k+1
               Results <- rbind(Results, c(Meals[i, ], Customers[j, 1]))
        }
    }
}
colnames(Results) <- c("mealAcode", "mealBcode", "id")
Results

This should process quite a bit faster, but is still slowed down by the fact that we are allocating memory for each match. If we pre-allocate the memory, it is faster, but you have to know how much to allocate:

Customers <- unname(Customers)
Meals <- unname(Meals)
Results <- matrix(nrow=1000000, ncol=3)
k <- 0
for (i in seq_len(nrow(Meals))) {
    for (j in seq_len(nrow(Customers))) {
        if (any(Customers[j, -1] %in% Meals[i, 1]) & 
            any(Customers[j, -1] %in% Meals[i, 2])) {
               k <- k+1
               Results[k, ] <- c(Meals[i, ], Customers[j, 1])
        }
    }
}
colnames(Results) <- c("mealAcode", "mealBcode", "id")
Results

This pre-allocates space for a million rows so it should be even faster, but it will fail if there are more rows, so guess high. 

There are some specialized packages such as data.table and dplyr in R that might be even faster. Also package parallel could use parallel processing to speed things up.


David C

From: Allaisone 1 [mailto:allaisone1 at hotmail.com] 
Sent: Wednesday, May 24, 2017 7:54 AM
To: David L Carlson <dcarlson at tamu.edu>; Bert Gunter <bgunter.4567 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

Dear David ..,

Many thanks for spending the time and effort solving this problem.

I liked your suggestion to generate the results with the first format
as this will be very helpful for further analysis :
?#?? mealAcode mealBcode id
# 1??????? 25??????? 77 ? ? ? ? ? ? 15
# 2??????? 25??????? 77 ? ? ? ? ? ? 85
# 3??????? 34??????? 39 ? ? ? ? ? ? 11
# 4??????? 25??????? 34 ? ? ? ? ? ? 15
# 5??????? 25??????? 34 ? ? ? ? ? ? 11

I wonder if if there is any method to process the analysis faster. The end output will be a very large table as I already know from my previous analysis that for example I have around 20,000 customers taking one of these combinations and there are about 17,000 customers taking another combination of meals and so on. Considering that I have 2000 rows (2000 combinations) and that number of customers per combination is very high?
(20,000 or lower), this will generate a huge table with millions of rows which is very?complex. ?I have tested the code just to see and as expected it takes a long time(hours) before I stopped the analysis.?
________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 23 May 2017 18:20:02
To: Allaisone 1; Bert Gunter
Cc: r-help at r-project.org
Subject: RE: [R] Identyfing rows with specific conditions 
?
You will generally get a better response if you create a data set that we can test our ideas on. You sketched out the data but your final results include meal combinations that are not in your Meals data frame. Also using dput() to provide the data makes it easier to recreate the data since just printing it loses important information such as if the numbers are integer or decimal, or if the character variables are characters or factors. Also send your message as plain text, not html which messes up columns and other details. Here is a modification of your data with the beginnings of a solution:

Meals <- structure(list(mealAcode = c(34L, 89L, 25L, 34L, 25L), mealBcode = c(66L, 
39L, 77L, 39L, 34L)), .Names = c("mealAcode", "mealBcode"), row.names = c(NA, 
-5L), class = "data.frame")
Meals
#?? mealAcode mealBcode
# 1??????? 34??????? 66
# 2??????? 89??????? 39
# 3??????? 25??????? 77
# 4??????? 34??????? 39
# 5??????? 25??????? 34

Customers <- structure(list(id = c(15L, 11L, 85L), M1 = c(77L, 25L, 89L), 
??? M2 = c(34L, 34L, 25L), M3 = c(25L, 39L, 77L)), .Names = c("id", 
"M1", "M2", "M3"), class = "data.frame", row.names = c(NA, -3L
))
Customers
#?? id M1 M2 M3
# 1 15 77 34 25
# 2 11 25 34 39
# 3 85 89 25 77

Results <- data.frame(mealAcode=NA, mealBcode=NA, id=NA)
k <- 0
for (i in seq_len(nrow(Meals))) {
??? for (j in seq_len(nrow(Customers))) {
??????? if (any(Customers[j, -1] %in% Meals[i, 1]) & 
??????????? any(Customers[j, -1] %in% Meals[i, 2])) {
?????????????? k <- k+1
?????????????? Results[k, ] <- cbind(Meals[i, ], id=Customers[j, 1])
??????? }
??? }
rownames(Results) <- NULL
}
Results
#?? mealAcode mealBcode id
# 1??????? 25??????? 77 15
# 2??????? 25??????? 77 85
# 3??????? 34??????? 39 11
# 4??????? 25??????? 34 15
# 5??????? 25??????? 34 11

Results is a data frame that can be modified to get various forms of output. You mention a data frame with ids in separate columns. That might be unwieldy for many types of analysis. The following list shows the ids for each meal combination,? the number of meals of each combination consumed, and a matrix similar to the one you provided.

Results.lst <- split(Results$id,? paste(Results[ , 1], Results[ , 2], sep=" - "))
Results.lst
# $`25 - 34`
# [1] 15 11
# 
# $`25 - 77`
# [1] 15 85
# 
# $`34 - 39`
# [1] 11
table(Results[, 1:2])
#????????? mealBcode
# mealAcode 34 39 77
#??????? 25? 2? 0? 2
#??????? 34? 0? 1? 0
maxid <- 5
t(sapply(Results.lst, function(x) c(sort(as.vector(x)), 
???? rep(NA, maxid-length(as.vector(x))))))
#???????? [,1] [,2] [,3] [,4] [,5]
# 25 - 34?? 11?? 15?? NA?? NA?? NA
# 25 - 77?? 15?? 85?? NA?? NA?? NA
# 34 - 39?? 11?? NA?? NA?? NA?? NA

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Allaisone 1
Sent: Monday, May 22, 2017 4:41 PM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

Dear Bert

I have answered your questions in my last 2 messages. If you did not see them, I will answer again. The 2 tables are all data.frames and the order of the meals does not matter. The meal cannot be replicated for each person, they are all different. The missing values are to the right end of each row as each row starts with meal codes first. This task is just a small part of a long 2 years project.

Regards
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: 22 May 2017 14:35:49
To: Allaisone 1
Cc: r-help at r-project.org
Subject: Re: [R] Identyfing rows with specific conditions

You haven't said whether your "table" is a matrix or data frame.
Presumably the latter.

Nor have you answered my question about whether order of your meal
code pairs matters.

Another question: can meals be replicated for an ID or are they all different?

Finally, is this a homework assignment or class project of some sort?
Or is it a real task -- i.e., what is the context?

Again, be sure to cc the list.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 22, 2017 at 1:56 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> Hi Bert ..,
>
>
> The number of meals differ from one customer to other customer. You may find
> one customer with only one meal and another one with 2,3 or even rarely 30
> meals. You may also
>
> find no meal at all for some customers so the entire row takes the missing
> value "\N" . Any
>
> row starts with the meals codes first, then all missing values are to the
> right end of the table.
>
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: 22 May 2017 03:11:11
> To: Allaisone 1
> Cc: r-help at r-project.org
> Subject: Re: [R] Identyfing rows with specific conditions
>
> Clarification:
>
> Does each customer have the same number of meals or do they differ
> from customer to customer? If the latter, how are missing meals
> notated? Do they always occur at the (right) end or can they occur
> anywhere in the row?
>
> Presumably each customer ID can have many different meal code
> combinations, right ?(since they can have 30 different meals with
> potentially 30 choose 2 = 435 combinations apiece)
>
> Please make sure you reply to the list, not just to me, as I may not
> pursue this further but am just trying to clarify for anyone else who
> may wish to help.
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, May 21, 2017 at 5:10 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
>>
>> Hi All..,
>>
>> I have 2 tables. The first one contains 2 columns with the headers say
>> "meal A code" & "meal B code " in a table called "Meals" with 2000 rows each
>> of which with a different combination of meals(unique combination per row).
>>
>>
>>>Meals
>>
>>???? meal A code????? meal B code
>>
>> 1????????? 34?????????????????? 66
>>
>> 2?????????? 89????????????????? 39
>>
>> 3?????????? 25?????????????????? 77
>>
>> The second table(customers) shows customers ids in the first column with
>> Meals codes(M) next to each customer. There are about 300,000 customers
>> (300,000 rows).
>>
>>> Customers
>>????? 1???????? 2???? 3?????? 4??? ..30
>>????? id?????? M1? M2?? M3
>> 1?? 15????? 77??? 34??? 25
>> 2?? 11????? 25??? 34???? 39
>> 3??? 85???? 89???? 25??? 77
>> .
>> .
>> 300,000
>>
>> I would like to identify all customers ids who have had each meal
>> combination in the first table so the final output would be the first table
>> with ids attached next to each meal combination in each row like this:
>>
>>>IdsMeals
>>
>>
>>?? MAcode? MBcode? ids
>>
>> 1???? 34??????? 39??????????? 11
>>
>> 2???? 25?????? 34????????????? 15?? 11
>>
>> 3????? 25???? 77??????????????? 15?? 85
>>
>> Would you please suggest any solutions to this problem?
>>
>> Regards
>>
>>???????? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Wed May 24 19:29:46 2017
From: chocold12 at gmail.com (lily li)
Date: Wed, 24 May 2017 11:29:46 -0600
Subject: [R] about combining two dataframes
Message-ID: <CAN5afy_7C6mdbkmfdCKE7Lze=GGxA6tq8dZ4XOkRNZL_gRNJ=g@mail.gmail.com>

Hi all,

I have a question about combining two data frames. For example, there are
the two dataframes below, with the same structure but different column
names and column lengths. How to add the values in DF2 to the end of DF1,
though the column names do not match? How to add more than two? Thanks.

DF1
year   month   day   product1   product2   product3
1981     1          1         18              56            20
1981     1          2         19              45            22
1981     1          3         16              48            28
1981     1          4         19              50            21

DF2
yr         mon      d         prod        prod2       prod3
1981     2          1         17              49            25
1981     2          2         20              47            23
1981     2          3         21              52            27

I use the code below but it does not work.
require(dplyr)
bind_rows(DF1, DF2) or bind_cols(DF1, DF2)

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed May 24 19:41:57 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 May 2017 17:41:57 +0000
Subject: [R] about combining two dataframes
In-Reply-To: <CAN5afy_7C6mdbkmfdCKE7Lze=GGxA6tq8dZ4XOkRNZL_gRNJ=g@mail.gmail.com>
References: <CAN5afy_7C6mdbkmfdCKE7Lze=GGxA6tq8dZ4XOkRNZL_gRNJ=g@mail.gmail.com>
Message-ID: <3e26df1d6a324a1dbe234ca6b83a1775@exch-2p-mbx-w2.ads.tamu.edu>

Is there a reason not to just rename the columns?

First, you should use dput(DF1) and dput(DF2) to send your example tables to the list:

DF1 <- structure(list(year = c(1981L, 1981L, 1981L, 1981L), month = c(1L, 
1L, 1L, 1L), day = 1:4, product1 = c(18L, 19L, 16L, 19L), product2 = c(56L, 
45L, 48L, 50L), product3 = c(20L, 22L, 28L, 21L)), .Names = c("year", 
"month", "day", "product1", "product2", "product3"), class = "data.frame", 
row.names = c(NA, -4L))

DF2 <- structure(list(yr = c(1981L, 1981L, 1981L), mon = c(2L, 2L, 2L
), d = 1:3, prod = c(17L, 20L, 21L), prod2 = c(49L, 47L, 52L), 
    prod3 = c(25L, 23L, 27L)), .Names = c("yr", "mon", "d", "prod", 
"prod2", "prod3"), class = "data.frame", row.names = c(NA, -3L
))

Assuming they are the same structure as you said:

colnames(DF2) <- colnames(DF1)
rbind(DF1, DF2)
#   year month day product1 product2 product3
# 1 1981     1   1       18       56       20
# 2 1981     1   2       19       45       22
# 3 1981     1   3       16       48       28
# 4 1981     1   4       19       50       21
# 5 1981     2   1       17       49       25
# 6 1981     2   2       20       47       23
# 7 1981     2   3       21       52       27

The attached .png image file shows you how to send plain text emails to r-help using gmail.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
Sent: Wednesday, May 24, 2017 12:30 PM
To: R mailing list <r-help at r-project.org>
Subject: [R] about combining two dataframes

Hi all,

I have a question about combining two data frames. For example, there are
the two dataframes below, with the same structure but different column
names and column lengths. How to add the values in DF2 to the end of DF1,
though the column names do not match? How to add more than two? Thanks.

DF1
year   month   day   product1   product2   product3
1981     1          1         18              56            20
1981     1          2         19              45            22
1981     1          3         16              48            28
1981     1          4         19              50            21

DF2
yr         mon      d         prod        prod2       prod3
1981     2          1         17              49            25
1981     2          2         20              47            23
1981     2          3         21              52            27

I use the code below but it does not work.
require(dplyr)
bind_rows(DF1, DF2) or bind_cols(DF1, DF2)

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GmailPlainText.png
Type: image/png
Size: 15966 bytes
Desc: GmailPlainText.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170524/e353db6c/attachment.png>

From ulrik.stervbo at gmail.com  Wed May 24 19:42:52 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 24 May 2017 17:42:52 +0000
Subject: [R] about combining two dataframes
In-Reply-To: <CAN5afy_7C6mdbkmfdCKE7Lze=GGxA6tq8dZ4XOkRNZL_gRNJ=g@mail.gmail.com>
References: <CAN5afy_7C6mdbkmfdCKE7Lze=GGxA6tq8dZ4XOkRNZL_gRNJ=g@mail.gmail.com>
Message-ID: <CAKVAULNgmeDobwVwOHVo4trVLd-zjWamVX-MjgHuqQ-4HRt1Lw@mail.gmail.com>

Hi Lily,

maybe you should read up on what bind_rows/bind_cols (or the base functions
rbind and cbind) do.

bind_cols and cbind will fail in this case because of the different number
of rows.

bind_rows and rbind will fail because the column names are different - how
can R know that month and mon really is the same.

Depending on what you want, you should unify the column names (I have a
hunch that this is what you want), or make sure the data.frames have the
same number of rows.

HTH
Ulrik



On Wed, 24 May 2017 at 19:30 lily li <chocold12 at gmail.com> wrote:

> Hi all,
>
> I have a question about combining two data frames. For example, there are
> the two dataframes below, with the same structure but different column
> names and column lengths. How to add the values in DF2 to the end of DF1,
> though the column names do not match? How to add more than two? Thanks.
>
> DF1
> year   month   day   product1   product2   product3
> 1981     1          1         18              56            20
> 1981     1          2         19              45            22
> 1981     1          3         16              48            28
> 1981     1          4         19              50            21
>
> DF2
> yr         mon      d         prod        prod2       prod3
> 1981     2          1         17              49            25
> 1981     2          2         20              47            23
> 1981     2          3         21              52            27
>
> I use the code below but it does not work.
> require(dplyr)
> bind_rows(DF1, DF2) or bind_cols(DF1, DF2)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Wed May 24 19:46:09 2017
From: chocold12 at gmail.com (lily li)
Date: Wed, 24 May 2017 11:46:09 -0600
Subject: [R] about combining two dataframes
In-Reply-To: <CAKVAULNgmeDobwVwOHVo4trVLd-zjWamVX-MjgHuqQ-4HRt1Lw@mail.gmail.com>
References: <CAN5afy_7C6mdbkmfdCKE7Lze=GGxA6tq8dZ4XOkRNZL_gRNJ=g@mail.gmail.com>
 <CAKVAULNgmeDobwVwOHVo4trVLd-zjWamVX-MjgHuqQ-4HRt1Lw@mail.gmail.com>
Message-ID: <CAN5afy8zuDPLEs0Yo9HeygZ+ypcMrTyVerX7OZ=b6kr7TjVUEQ@mail.gmail.com>

Thanks for your reply. I created the two dataframes (just numbers from txt
files) in one for loop, so that it is confused to give them the same column
names. That is the reason that I give them different column names to
differentiate them, but it causes difficulty in later combining them.


On Wed, May 24, 2017 at 11:42 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Hi Lily,
>
> maybe you should read up on what bind_rows/bind_cols (or the base
> functions rbind and cbind) do.
>
> bind_cols and cbind will fail in this case because of the different number
> of rows.
>
> bind_rows and rbind will fail because the column names are different - how
> can R know that month and mon really is the same.
>
> Depending on what you want, you should unify the column names (I have a
> hunch that this is what you want), or make sure the data.frames have the
> same number of rows.
>
> HTH
> Ulrik
>
>
>
> On Wed, 24 May 2017 at 19:30 lily li <chocold12 at gmail.com> wrote:
>
>> Hi all,
>>
>> I have a question about combining two data frames. For example, there are
>> the two dataframes below, with the same structure but different column
>> names and column lengths. How to add the values in DF2 to the end of DF1,
>> though the column names do not match? How to add more than two? Thanks.
>>
>> DF1
>> year   month   day   product1   product2   product3
>> 1981     1          1         18              56            20
>> 1981     1          2         19              45            22
>> 1981     1          3         16              48            28
>> 1981     1          4         19              50            21
>>
>> DF2
>> yr         mon      d         prod        prod2       prod3
>> 1981     2          1         17              49            25
>> 1981     2          2         20              47            23
>> 1981     2          3         21              52            27
>>
>> I use the code below but it does not work.
>> require(dplyr)
>> bind_rows(DF1, DF2) or bind_cols(DF1, DF2)
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Wed May 24 19:50:04 2017
From: chocold12 at gmail.com (lily li)
Date: Wed, 24 May 2017 11:50:04 -0600
Subject: [R] about combining two dataframes
In-Reply-To: <3e26df1d6a324a1dbe234ca6b83a1775@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAN5afy_7C6mdbkmfdCKE7Lze=GGxA6tq8dZ4XOkRNZL_gRNJ=g@mail.gmail.com>
 <3e26df1d6a324a1dbe234ca6b83a1775@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAN5afy9MfMF6pc+x7KTR0c3TZ09Z7tTLX5DSCB2b1+4CHywfQA@mail.gmail.com>

Thanks, I didn't know the email function before.
The code works. I found that using "=" is different from using "<-".


On Wed, May 24, 2017 at 11:41 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Is there a reason not to just rename the columns?
>
> First, you should use dput(DF1) and dput(DF2) to send your example tables
> to the list:
>
> DF1 <- structure(list(year = c(1981L, 1981L, 1981L, 1981L), month = c(1L,
> 1L, 1L, 1L), day = 1:4, product1 = c(18L, 19L, 16L, 19L), product2 = c(56L,
> 45L, 48L, 50L), product3 = c(20L, 22L, 28L, 21L)), .Names = c("year",
> "month", "day", "product1", "product2", "product3"), class = "data.frame",
> row.names = c(NA, -4L))
>
> DF2 <- structure(list(yr = c(1981L, 1981L, 1981L), mon = c(2L, 2L, 2L
> ), d = 1:3, prod = c(17L, 20L, 21L), prod2 = c(49L, 47L, 52L),
>     prod3 = c(25L, 23L, 27L)), .Names = c("yr", "mon", "d", "prod",
> "prod2", "prod3"), class = "data.frame", row.names = c(NA, -3L
> ))
>
> Assuming they are the same structure as you said:
>
> colnames(DF2) <- colnames(DF1)
> rbind(DF1, DF2)
> #   year month day product1 product2 product3
> # 1 1981     1   1       18       56       20
> # 2 1981     1   2       19       45       22
> # 3 1981     1   3       16       48       28
> # 4 1981     1   4       19       50       21
> # 5 1981     2   1       17       49       25
> # 6 1981     2   2       20       47       23
> # 7 1981     2   3       21       52       27
>
> The attached .png image file shows you how to send plain text emails to
> r-help using gmail.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> Sent: Wednesday, May 24, 2017 12:30 PM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] about combining two dataframes
>
> Hi all,
>
> I have a question about combining two data frames. For example, there are
> the two dataframes below, with the same structure but different column
> names and column lengths. How to add the values in DF2 to the end of DF1,
> though the column names do not match? How to add more than two? Thanks.
>
> DF1
> year   month   day   product1   product2   product3
> 1981     1          1         18              56            20
> 1981     1          2         19              45            22
> 1981     1          3         16              48            28
> 1981     1          4         19              50            21
>
> DF2
> yr         mon      d         prod        prod2       prod3
> 1981     2          1         17              49            25
> 1981     2          2         20              47            23
> 1981     2          3         21              52            27
>
> I use the code below but it does not work.
> require(dplyr)
> bind_rows(DF1, DF2) or bind_cols(DF1, DF2)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed May 24 19:59:37 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 May 2017 10:59:37 -0700
Subject: [R] about combining two dataframes
In-Reply-To: <CAN5afy9MfMF6pc+x7KTR0c3TZ09Z7tTLX5DSCB2b1+4CHywfQA@mail.gmail.com>
References: <CAN5afy_7C6mdbkmfdCKE7Lze=GGxA6tq8dZ4XOkRNZL_gRNJ=g@mail.gmail.com>
 <3e26df1d6a324a1dbe234ca6b83a1775@exch-2p-mbx-w2.ads.tamu.edu>
 <CAN5afy9MfMF6pc+x7KTR0c3TZ09Z7tTLX5DSCB2b1+4CHywfQA@mail.gmail.com>
Message-ID: <CAGxFJbSxyZObvdxb6nenuHKpaQzLP4V8sNx7_mUctkvk+Xm0Pg@mail.gmail.com>

On Wed, May 24, 2017 at 10:50 AM, lily li <chocold12 at gmail.com> wrote:
> Thanks, I didn't know the email function before.
> The code works. I found that using "=" is different from using "<-".
>
 If you are referring to assignment in the evaluation environment
(instead of e.g. to values of function arguments), then what you have
stated is wrong. See ?"<-"

-- Bert



> On Wed, May 24, 2017 at 11:41 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>
>> Is there a reason not to just rename the columns?
>>
>> First, you should use dput(DF1) and dput(DF2) to send your example tables
>> to the list:
>>
>> DF1 <- structure(list(year = c(1981L, 1981L, 1981L, 1981L), month = c(1L,
>> 1L, 1L, 1L), day = 1:4, product1 = c(18L, 19L, 16L, 19L), product2 = c(56L,
>> 45L, 48L, 50L), product3 = c(20L, 22L, 28L, 21L)), .Names = c("year",
>> "month", "day", "product1", "product2", "product3"), class = "data.frame",
>> row.names = c(NA, -4L))
>>
>> DF2 <- structure(list(yr = c(1981L, 1981L, 1981L), mon = c(2L, 2L, 2L
>> ), d = 1:3, prod = c(17L, 20L, 21L), prod2 = c(49L, 47L, 52L),
>>     prod3 = c(25L, 23L, 27L)), .Names = c("yr", "mon", "d", "prod",
>> "prod2", "prod3"), class = "data.frame", row.names = c(NA, -3L
>> ))
>>
>> Assuming they are the same structure as you said:
>>
>> colnames(DF2) <- colnames(DF1)
>> rbind(DF1, DF2)
>> #   year month day product1 product2 product3
>> # 1 1981     1   1       18       56       20
>> # 2 1981     1   2       19       45       22
>> # 3 1981     1   3       16       48       28
>> # 4 1981     1   4       19       50       21
>> # 5 1981     2   1       17       49       25
>> # 6 1981     2   2       20       47       23
>> # 7 1981     2   3       21       52       27
>>
>> The attached .png image file shows you how to send plain text emails to
>> r-help using gmail.
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
>> Sent: Wednesday, May 24, 2017 12:30 PM
>> To: R mailing list <r-help at r-project.org>
>> Subject: [R] about combining two dataframes
>>
>> Hi all,
>>
>> I have a question about combining two data frames. For example, there are
>> the two dataframes below, with the same structure but different column
>> names and column lengths. How to add the values in DF2 to the end of DF1,
>> though the column names do not match? How to add more than two? Thanks.
>>
>> DF1
>> year   month   day   product1   product2   product3
>> 1981     1          1         18              56            20
>> 1981     1          2         19              45            22
>> 1981     1          3         16              48            28
>> 1981     1          4         19              50            21
>>
>> DF2
>> yr         mon      d         prod        prod2       prod3
>> 1981     2          1         17              49            25
>> 1981     2          2         20              47            23
>> 1981     2          3         21              52            27
>>
>> I use the code below but it does not work.
>> require(dplyr)
>> bind_rows(DF1, DF2) or bind_cols(DF1, DF2)
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ramnik.bansal at gmail.com  Wed May 24 20:30:49 2017
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Thu, 25 May 2017 00:00:49 +0530
Subject: [R] Cause of error assigning NULL to element of a vector
Message-ID: <CAMLd9E6vCbmnxv_+gcDEbpgKRHqWfZBE-Q8qmaH1FstVcdCmuw@mail.gmail.com>

What is the cause of the error below ?

> y <- 1
> y[1] <- NULL
Error in y[1] <- NULL : replacement has length zero

Thanks,
Ramnik

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Wed May 24 20:51:41 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 24 May 2017 13:51:41 -0500
Subject: [R] Cause of error assigning NULL to element of a vector
In-Reply-To: <CAMLd9E6vCbmnxv_+gcDEbpgKRHqWfZBE-Q8qmaH1FstVcdCmuw@mail.gmail.com>
References: <CAMLd9E6vCbmnxv_+gcDEbpgKRHqWfZBE-Q8qmaH1FstVcdCmuw@mail.gmail.com>
Message-ID: <86632241-5387-4C0D-85E1-246EA2E3E307@me.com>


> On May 24, 2017, at 1:30 PM, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> 
> What is the cause of the error below ?
> 
>> y <- 1
>> y[1] <- NULL
> Error in y[1] <- NULL : replacement has length zero
> 
> Thanks,
> Ramnik

Hi,

> length(NULL)
[1] 0

You are attempting to assign NULL, which is a zero length special object of its own kind, to a specific element in the vector object 'y' and that cannot be done.

You can assign NULL to 'y':

y <- NULL

> y
NULL

> length(y)
[1] 0


BUT, 'y' is not a vector in that case:

> is.vector(y)
[1] FALSE



Nor can a vector contain multiple NULLs:

y <- c(NULL, NULL, NULL)

> y
NULL

> length(y)
[1] 0



Similarly:

y <- c(1, NULL, 1)

> y
[1] 1 1

> length(y)
[1] 2


Perhaps reviewing ?NULL as well as:

  https://cran.r-project.org/doc/manuals/r-release/R-lang.html#NULL-object

might also provide some insights.

Regards,

Marc Schwartz


From jdnewmil at dcn.davis.ca.us  Wed May 24 21:38:23 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 May 2017 12:38:23 -0700
Subject: [R] Cause of error assigning NULL to element of a vector
In-Reply-To: <86632241-5387-4C0D-85E1-246EA2E3E307@me.com>
References: <CAMLd9E6vCbmnxv_+gcDEbpgKRHqWfZBE-Q8qmaH1FstVcdCmuw@mail.gmail.com>
 <86632241-5387-4C0D-85E1-246EA2E3E307@me.com>
Message-ID: <4C4A6E3E-0E9B-4F4F-A25E-45D6F6A2CE9B@dcn.davis.ca.us>

Perhaps it is worth pointing out (in case the OP thinks this is SQL) that the special value NA is used for "missing" in R.

y[1] <- NA

works just fine. 
-- 
Sent from my phone. Please excuse my brevity.

On May 24, 2017 11:51:41 AM PDT, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> On May 24, 2017, at 1:30 PM, Ramnik Bansal <ramnik.bansal at gmail.com>
>wrote:
>> 
>> What is the cause of the error below ?
>> 
>>> y <- 1
>>> y[1] <- NULL
>> Error in y[1] <- NULL : replacement has length zero
>> 
>> Thanks,
>> Ramnik
>
>Hi,
>
>> length(NULL)
>[1] 0
>
>You are attempting to assign NULL, which is a zero length special
>object of its own kind, to a specific element in the vector object 'y'
>and that cannot be done.
>
>You can assign NULL to 'y':
>
>y <- NULL
>
>> y
>NULL
>
>> length(y)
>[1] 0
>
>
>BUT, 'y' is not a vector in that case:
>
>> is.vector(y)
>[1] FALSE
>
>
>
>Nor can a vector contain multiple NULLs:
>
>y <- c(NULL, NULL, NULL)
>
>> y
>NULL
>
>> length(y)
>[1] 0
>
>
>
>Similarly:
>
>y <- c(1, NULL, 1)
>
>> y
>[1] 1 1
>
>> length(y)
>[1] 2
>
>
>Perhaps reviewing ?NULL as well as:
>
>https://cran.r-project.org/doc/manuals/r-release/R-lang.html#NULL-object
>
>might also provide some insights.
>
>Regards,
>
>Marc Schwartz
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From akumar at stat.tamu.edu  Wed May 24 23:11:27 2017
From: akumar at stat.tamu.edu (Maity, Arnab K)
Date: Wed, 24 May 2017 21:11:27 +0000
Subject: [R] Error: could not find function of a packge
Message-ID: <1495660287678.55607@stat.tamu.edu>

Dear R helpers,


I created a package on github. It is located at "arnabkrmaity/brlrmr". Then I submitted this on CRAN and it is now available on CRAN.


When I install this package from github using install.github("arnabkrmaity\brlrmr"), everything works fine. However, when I install directly from R CRAN by install.packages("brlrmr"), and then try to examine the functions, I receive an error, ?


Error: could not find function "fil"


fil() is a function of this package. The data with this package is getting attached fine.


Any idea what is going wrong with the submission? Your help is much appreciated.


Thank you.




Arnab Kumar Maity
Department of Statistics
Texas A&M University
3143 TAMU, Room 401A
College Station, TX 77843
akumar at stat.tamu.edu<mailto:arnabkrmaity at stat.tamu.edu>
arnabkrmaity at tamu.edu
+1 779 777 3428<tel:%2B1%20779%20777%203428>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu May 25 00:07:49 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 May 2017 18:07:49 -0400
Subject: [R] Error: could not find function of a packge
In-Reply-To: <1495660287678.55607@stat.tamu.edu>
References: <1495660287678.55607@stat.tamu.edu>
Message-ID: <f290b2fe-c1cc-152b-7eb3-77aa53100b49@gmail.com>

On 24/05/2017 5:11 PM, Maity, Arnab K wrote:
> Dear R helpers,
>
>
> I created a package on github. It is located at "arnabkrmaity/brlrmr". Then I submitted this on CRAN and it is now available on CRAN.
>
>
> When I install this package from github using install.github("arnabkrmaity\brlrmr"), everything works fine. However, when I install directly from R CRAN by install.packages("brlrmr"), and then try to examine the functions, I receive an error, ?
>
>
> Error: could not find function "fil"
>
>
> fil() is a function of this package. The data with this package is getting attached fine.
>
>
> Any idea what is going wrong with the submission? Your help is much appreciated.

Your NAMESPACE file doesn't export anything.

For future reference, this is an R-devel or R-package-devel question 
rather than an R-help question.  Please post followups to one of those 
lists.

Duncan Murdoch


From anix1 at kent.edu  Wed May 24 18:15:03 2017
From: anix1 at kent.edu (Alice Nix)
Date: Wed, 24 May 2017 12:15:03 -0400
Subject: [R] Did not complete an assignment in time for students to grade
Message-ID: <CABe+Oc2t=C0iusTNW6g_KLkpSv0EuHjO0i2N-1rdygpHSK0Dzw@mail.gmail.com>

Hello,

I am wondering if I can re-subscribe to the R Programming course on
Coursera at a later point in time and pick up where I left off.

I completed everything except for one assignment in Week 3 which required
peer review of the assignment for a grade.

Thanks!

- Alice

	[[alternative HTML version deleted]]


From poorbagher at ut.ac.ir  Wed May 24 18:06:52 2017
From: poorbagher at ut.ac.ir (Hadi Poorbagher)
Date: Wed, 24 May 2017 20:36:52 +0430
Subject: [R] problem with vegan function rda()
Message-ID: <000001d2d4a7$c2110d10$46332730$@ut.ac.ir>

Hi

The problem with rda() and getting some result like:

 

Regularization parameters:

> NULL

 

may be related to the package ?agricolae? as when I load it, rda() fails to
produce a plot. To solve, quit R and re-start it. This time, do not load
?agricolae?. 

 

Regards

Hadi

 

 

?? ?????? 

??????? 

 

Department of Fisheries

Faculty of Natural Resources

University of Tehran 

Postal code 31587-77871

Karaj 

Iran 

 


	[[alternative HTML version deleted]]


From peter.carbonetto at gmail.com  Wed May 24 18:35:04 2017
From: peter.carbonetto at gmail.com (Peter Carbonetto)
Date: Wed, 24 May 2017 11:35:04 -0500
Subject: [R] Compiling R with zlib in non-standard location
Message-ID: <CAPvCojLT-xf2jb1cQrBdnfn5t4wyTb1gE2aEiWvJTB8_uQJ0YA@mail.gmail.com>

Hi David,

I found this blog post helpful. I had a similar situation where I was
installing R 3.3 on CentOS 6, and I found these instructinos worked well:

http://pj.freefaculty.org/blog/?p=315

The only problem I had is that the instructions as written do not allow for
using the R installation with RStudio or RStudio Server. For this, I
believe you need the -fPIC option when installing R (and maybe the
libraries as well), but not certain about this.

Peter Carbonetto, Ph.D.
Research Computing Center
University of Chicago

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu May 25 10:52:02 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 25 May 2017 18:52:02 +1000
Subject: [R] Did not complete an assignment in time for students to grade
In-Reply-To: <CABe+Oc2t=C0iusTNW6g_KLkpSv0EuHjO0i2N-1rdygpHSK0Dzw@mail.gmail.com>
References: <CABe+Oc2t=C0iusTNW6g_KLkpSv0EuHjO0i2N-1rdygpHSK0Dzw@mail.gmail.com>
Message-ID: <CA+8X3fUXH08f_UeKjODjQ1fYBKNWS2kmbXUdNgo2FfgcFzPSdg@mail.gmail.com>

Hi Alice,
This is the R help list, not Coursera. Try:

https://www.coursera.org/learn/r-programming

Jim

On Thu, May 25, 2017 at 2:15 AM, Alice Nix <anix1 at kent.edu> wrote:
> Hello,
>
> I am wondering if I can re-subscribe to the R Programming course on
> Coursera at a later point in time and pick up where I left off.
>
> I completed everything except for one assignment in Week 3 which required
> peer review of the assignment for a grade.
>
> Thanks!
>
> - Alice
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From johanna.vonbahr at gmail.com  Thu May 25 12:11:21 2017
From: johanna.vonbahr at gmail.com (Johanna von Bahr)
Date: Thu, 25 May 2017 12:11:21 +0200
Subject: [R] =?utf-8?q?Harris=E2=80=93Tzavalis?=
Message-ID: <0E7CD5E7-26A1-4601-9346-094A5996BEB2@gmail.com>

Hi!

I would like to know how to do a Harris?Tzavalis test in R?


Best,
Johanna
 

	[[alternative HTML version deleted]]


From peter.hanninen at gmail.com  Thu May 25 14:55:41 2017
From: peter.hanninen at gmail.com (=?UTF-8?Q?Peter_H=C3=A4nninen?=)
Date: Thu, 25 May 2017 15:55:41 +0300
Subject: [R] Help in R code
In-Reply-To: <CAGC-v+E72ggrJPEEAHeKv=g7d5nXa6HKV1A0WPMdFYimfqFYxQ@mail.gmail.com>
References: <CAGC-v+E72ggrJPEEAHeKv=g7d5nXa6HKV1A0WPMdFYimfqFYxQ@mail.gmail.com>
Message-ID: <CAGC-v+HMd48BZSMii1gTOCC+ZvgU38XOXZTgaP3AfXw7dcG2pA@mail.gmail.com>

Hi! Is this the correct place to ask for some help with R code? I have some
minor questions I would need to ask.

Best regards,
Peter

	[[alternative HTML version deleted]]


From sebastian.kraus.jena at gmail.com  Thu May 25 08:27:02 2017
From: sebastian.kraus.jena at gmail.com (Sebastian Kraus)
Date: Thu, 25 May 2017 08:27:02 +0200
Subject: [R] Did not complete an assignment in time for students to grade
In-Reply-To: <CABe+Oc2t=C0iusTNW6g_KLkpSv0EuHjO0i2N-1rdygpHSK0Dzw@mail.gmail.com>
References: <CABe+Oc2t=C0iusTNW6g_KLkpSv0EuHjO0i2N-1rdygpHSK0Dzw@mail.gmail.com>
Message-ID: <584ac90e-e056-a618-3872-2c9cf633bbc0@gmail.com>

Dear Alice,

yes, you can continue later. The given schedule is totally optional. It 
should just keep you on track.

Best regards,

Sebastian


On 24-May-17 18:15, Alice Nix wrote:
> Hello,
>
> I am wondering if I can re-subscribe to the R Programming course on
> Coursera at a later point in time and pick up where I left off.
>
> I completed everything except for one assignment in Week 3 which required
> peer review of the assignment for a grade.
>
> Thanks!
>
> - Alice
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu May 25 15:53:44 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 25 May 2017 06:53:44 -0700
Subject: [R] Help in R code
In-Reply-To: <CAGC-v+HMd48BZSMii1gTOCC+ZvgU38XOXZTgaP3AfXw7dcG2pA@mail.gmail.com>
References: <CAGC-v+E72ggrJPEEAHeKv=g7d5nXa6HKV1A0WPMdFYimfqFYxQ@mail.gmail.com>
 <CAGC-v+HMd48BZSMii1gTOCC+ZvgU38XOXZTgaP3AfXw7dcG2pA@mail.gmail.com>
Message-ID: <CC8FDB99-A2B7-41D0-87C4-A3EF2E052802@dcn.davis.ca.us>

Read the Posting Guide. Assuming your question is not about homework or statistics, the answer is probably yes. After reading the the Posting Guide you will also know that this is a plain text email list so you will need to set your email program appropriately. You will also know that a minimal example including data is (almost always) needed, but you might want to read some help about what that actually looks like [1][2][3], since many attachment types are also not allowed on the list.

If this seems like a lot of work, keep in mind that we can't read your mind and you will eventually have to break your problem down this way anyway, and you might just figure out the answer yourself if you are thorough in writing your minimal example. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html
-- 
Sent from my phone. Please excuse my brevity.

On May 25, 2017 5:55:41 AM PDT, "Peter H?nninen" <peter.hanninen at gmail.com> wrote:
>Hi! Is this the correct place to ask for some help with R code? I have
>some
>minor questions I would need to ask.
>
>Best regards,
>Peter
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu May 25 16:19:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 25 May 2017 07:19:36 -0700
Subject: [R] =?utf-8?q?Harris=E2=80=93Tzavalis?=
In-Reply-To: <0E7CD5E7-26A1-4601-9346-094A5996BEB2@gmail.com>
References: <0E7CD5E7-26A1-4601-9346-094A5996BEB2@gmail.com>
Message-ID: <CAGxFJbTm0mDbbtSqQf_6xj0JLR8ghmSb+ed02QdBmrwhTzC2Hg@mail.gmail.com>

Google it!

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, May 25, 2017 at 3:11 AM, Johanna von Bahr
<johanna.vonbahr at gmail.com> wrote:
> Hi!
>
> I would like to know how to do a Harris?Tzavalis test in R?
>
>
> Best,
> Johanna
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Thu May 25 17:15:11 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Thu, 25 May 2017 15:15:11 +0000 (UTC)
Subject: [R] MDS plot in Random Forest
References: <2024387461.3898717.1495725311319.ref@mail.yahoo.com>
Message-ID: <2024387461.3898717.1495725311319@mail.yahoo.com>

Hi all,
I have applied Random Forest on my data and divided data into test and rain set to see the prediction results and it seems good cause the accuracy is 82%. Now my question is how can I plot MDS on predicted data? here is my code: 


    
  spl=sample.split(df$PatientType,SplitRatio = 0.7)
  Train=subset(df,spl==TRUE)
  Test=subset(df,spl==FALSE)
  SecondTree=randomForest(PatientType~ cookie + curtains + get + mother + overflowing + sink +thats + window + stool + heres + drying + chair + okay +outside +  standing + tipping + windows + blowing + breeze +counter + finger + onto + open + reaching + didnt + spilled +action + quiet + summer + mouth + puddle + good +     wind +whos + sort,data = Train,nodesize=25,ntree=200,proximity=TRUE)
  PredictForest=predict(SecondTree,newdata =Test)
Is MDS plot a way to find out if the classification are easy to be separated?

thanks for any help.
Elahe


From bgunter.4567 at gmail.com  Thu May 25 18:37:11 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 25 May 2017 09:37:11 -0700
Subject: [R] MDS plot in Random Forest
In-Reply-To: <2024387461.3898717.1495725311319@mail.yahoo.com>
References: <2024387461.3898717.1495725311319.ref@mail.yahoo.com>
 <2024387461.3898717.1495725311319@mail.yahoo.com>
Message-ID: <CAGxFJbQcdvnU7XzumT8zA=MUAeFj7KgemMY2QHVy86CEZX9bgw@mail.gmail.com>

Elahe:


On Thu, May 25, 2017 at 8:15 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
> I have applied Random Forest on my data and divided data into test and rain set to see the prediction results and it seems good cause the accuracy is 82%. Now my question is how can I plot MDS on predicted data? here is my code:
>
>
>
>   spl=sample.split(df$PatientType,SplitRatio = 0.7)
>   Train=subset(df,spl==TRUE)
>   Test=subset(df,spl==FALSE)
>   SecondTree=randomForest(PatientType~ cookie + curtains + get + mother + overflowing + sink +thats + window + stool + heres + drying + chair + okay +outside +  standing + tipping + windows + blowing + breeze +counter + finger + onto + open + reaching + didnt + spilled +action + quiet + summer + mouth + puddle + good +     wind +whos + sort,data = Train,nodesize=25,ntree=200,proximity=TRUE)
>   PredictForest=predict(SecondTree,newdata =Test)


> Is MDS plot a way to find out if the classification are easy to be separated?

This seems to be largely a statistics question and, if so, is OT here
(this list is about R programming) I suggest you post this on
stats.stackexchange.com instead.

Cheers,
Bert


>
> thanks for any help.
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Thu May 25 19:35:45 2017
From: chalabi.elahe at yahoo.de (Elahe chalabi)
Date: Thu, 25 May 2017 17:35:45 +0000 (UTC)
Subject: [R] MDS plot in Random Forest
In-Reply-To: <CAGxFJbQcdvnU7XzumT8zA=MUAeFj7KgemMY2QHVy86CEZX9bgw@mail.gmail.com>
References: <2024387461.3898717.1495725311319.ref@mail.yahoo.com>
 <2024387461.3898717.1495725311319@mail.yahoo.com>
 <CAGxFJbQcdvnU7XzumT8zA=MUAeFj7KgemMY2QHVy86CEZX9bgw@mail.gmail.com>
Message-ID: <1710879912.3992353.1495733745913@mail.yahoo.com>

Thanks for your reply Bert. But the question on how to plot MDS on predicted data I guess belong to here!




On Thursday, May 25, 2017 9:43 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:



Elahe:


On Thu, May 25, 2017 at 8:15 AM, Elahe chalabi via R-help
<r-help at r-project.org> wrote:
> Hi all,
> I have applied Random Forest on my data and divided data into test and rain set to see the prediction results and it seems good cause the accuracy is 82%. Now my question is how can I plot MDS on predicted data? here is my code:
>
>
>
>   spl=sample.split(df$PatientType,SplitRatio = 0.7)
>   Train=subset(df,spl==TRUE)
>   Test=subset(df,spl==FALSE)
>   SecondTree=randomForest(PatientType~ cookie + curtains + get + mother + overflowing + sink +thats + window + stool + heres + drying + chair + okay +outside +  standing + tipping + windows + blowing + breeze +counter + finger + onto + open + reaching + didnt + spilled +action + quiet + summer + mouth + puddle + good +     wind +whos + sort,data = Train,nodesize=25,ntree=200,proximity=TRUE)
>   PredictForest=predict(SecondTree,newdata =Test)


> Is MDS plot a way to find out if the classification are easy to be separated?

This seems to be largely a statistics question and, if so, is OT here
(this list is about R programming) I suggest you post this on
stats.stackexchange.com instead.

Cheers,
Bert



>
> thanks for any help.
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Fri May 26 09:54:00 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Fri, 26 May 2017 10:54:00 +0300
Subject: [R] MDS plot in Random Forest
In-Reply-To: <1710879912.3992353.1495733745913@mail.yahoo.com>
References: <2024387461.3898717.1495725311319.ref@mail.yahoo.com>
 <2024387461.3898717.1495725311319@mail.yahoo.com>
 <CAGxFJbQcdvnU7XzumT8zA=MUAeFj7KgemMY2QHVy86CEZX9bgw@mail.gmail.com>
 <1710879912.3992353.1495733745913@mail.yahoo.com>
Message-ID: <8E0293A0-404B-46F3-B7D7-CC8490BE4488@gmail.com>


> On 25 May 2017, at 20:35, Elahe chalabi via R-help <r-help at r-project.org> wrote:
> 
> Thanks for your reply Bert. But the question on how to plot MDS on predicted data I guess belong to here!

Actually, You have 2 questions in conflict.

1- how can I plot MDS on predicted data?
2- Is MDS plot a way to find out if the classification are easy to be separated?

In first, You know what MDS is and asking only how to plot. In second, you ask how to interpret it. So, I suspect, too (as Bert did) that you actually want to learn how to interpret a MDS plot.

For the first question, I think you are looking for MDSplot function already comes with randomForest package. (type ?MDSplot in R)
For the second one, see the links below. If they are not enough, then ask your question again in stats.stackexchange.com <http://stats.stackexchange.com/>.

a) http://www.statmethods.net/advstats/mds.html <http://www.statmethods.net/advstats/mds.html>
b) https://stats.stackexchange.com/questions/40737/randomforest-mds-plot-interpretation <https://stats.stackexchange.com/questions/40737/randomforest-mds-plot-interpretation>
c) http://r.789695.n4.nabble.com/interpretation-of-MDS-plot-in-random-forest-td4681459.html <http://r.789695.n4.nabble.com/interpretation-of-MDS-plot-in-random-forest-td4681459.html>


> 
> 
> 
> 
> On Thursday, May 25, 2017 9:43 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> 
> 
> Elahe:
> 
> 
> On Thu, May 25, 2017 at 8:15 AM, Elahe chalabi via R-help
> <r-help at r-project.org> wrote:
>> Hi all,
>> I have applied Random Forest on my data and divided data into test and rain set to see the prediction results and it seems good cause the accuracy is 82%. Now my question is how can I plot MDS on predicted data? here is my code:
>> 
>> 
>> 
>>  spl=sample.split(df$PatientType,SplitRatio = 0.7)
>>  Train=subset(df,spl==TRUE)
>>  Test=subset(df,spl==FALSE)
>>  SecondTree=randomForest(PatientType~ cookie + curtains + get + mother + overflowing + sink +thats + window + stool + heres + drying + chair + okay +outside +  standing + tipping + windows + blowing + breeze +counter + finger + onto + open + reaching + didnt + spilled +action + quiet + summer + mouth + puddle + good +     wind +whos + sort,data = Train,nodesize=25,ntree=200,proximity=TRUE)
>>  PredictForest=predict(SecondTree,newdata =Test)
> 
> 
>> Is MDS plot a way to find out if the classification are easy to be separated?
> 
> This seems to be largely a statistics question and, if so, is OT here
> (this list is about R programming) I suggest you post this on
> stats.stackexchange.com instead.
> 
> Cheers,
> Bert
> 
> 
> 
>> 
>> thanks for any help.
>> Elahe
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From tanasa at gmail.com  Fri May 26 11:25:53 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 26 May 2017 02:25:53 -0700
Subject: [R] using "dcast" function ?
Message-ID: <CA+JEM00U2v_GQ4gphzKe=+BgFNdB93dQY2D5ugDpDi3Oy5kwtQ@mail.gmail.com>

Dear all, I would like to double-check with you please the use of "acast"
or "dcast" function from "reshape2"package.

I am starting with a data frame Y of GENES and SAMPLES,eg :

  Cancer_Gene     Sample
1        ABL2  WT_10T
2        ABL2   WT_6T
3      ADGRA2   HB_8R
4        AFF4 EWS_13R

and I would like to have a dataframe/matrix of CANCER_GENES * SAMPLES.

Shall I do " dcast(Y, Cancer_Gene ~ Sample)", would it be correct ? thank
you !

-- bogdan

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri May 26 12:45:05 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 26 May 2017 10:45:05 +0000
Subject: [R] using "dcast" function ?
In-Reply-To: <CA+JEM00U2v_GQ4gphzKe=+BgFNdB93dQY2D5ugDpDi3Oy5kwtQ@mail.gmail.com>
References: <CA+JEM00U2v_GQ4gphzKe=+BgFNdB93dQY2D5ugDpDi3Oy5kwtQ@mail.gmail.com>
Message-ID: <CAKVAULN4S1YLznYp0ja1Bd3HDLgizwgjdM2xvpxU8N3n=Z_StQ@mail.gmail.com>

It is correct and will produce a data.frame. But I guess the result is not
what you intend since the resulting data.frame nothing but NA and Samples
in the diagonal:

df1 <- data.frame(x = letters[1:5], y = letters[6:10])
reshape2::dcast(df1, x ~ y)

You are missing values somewhere. If you want all possible combinations of
Cancer_Gene and Sample, look at expand.grid:

expand.grid(df1)

HTH
Ulrik

On Fri, 26 May 2017 at 11:26 Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all, I would like to double-check with you please the use of "acast"
> or "dcast" function from "reshape2"package.
>
> I am starting with a data frame Y of GENES and SAMPLES,eg :
>
>   Cancer_Gene     Sample
> 1        ABL2  WT_10T
> 2        ABL2   WT_6T
> 3      ADGRA2   HB_8R
> 4        AFF4 EWS_13R
>
> and I would like to have a dataframe/matrix of CANCER_GENES * SAMPLES.
>
> Shall I do " dcast(Y, Cancer_Gene ~ Sample)", would it be correct ? thank
> you !
>
> -- bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mario.lavezzi at unipa.it  Fri May 26 13:46:52 2017
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 26 May 2017 13:46:52 +0200
Subject: [R] organizing data in a matrix avoiding loop
Message-ID: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>

Dear R-Users

I have data on bilateral trade flows among countries in the following form:

> head(dataTrade)

      iso_o iso_d year FLOW
1   ABW   AFG 1985   NA
2   ABW   AFG 1986   NA
3   ABW   AFG 1987   NA
4   ABW   AFG 1988   NA
5   ABW   AFG 1989   NA
6   ABW   AFG 1990   NA

where:
iso_o: code of country of origin
iso_d: code of country of destination
year: 1985:2015
FLOW: amount of trade (values are "NA", 0s, or positive numbers)

I have 215 countries. I would like to create a 215x215 matrix , say M, in
which element M(i,j) is the total trade between countries i and j between
1985 and 2015 (i.e. the sum of annual amounts of trade).

After collecting the country codes in a variable named "my_iso", I can
obtain M in a straightforward way using a loop such as:

for (i in my_iso){
  for(j in my_iso)
    if(i!=j){
      M[seq(1:length(my_iso))[my_iso==i],seq(1:length(my_iso))[my_iso==j]]
<-
        sum(dataTrade[dataTrade$iso_o==i &
dataTrade$iso_d==j,"FLOW"],na.rm=TRUE)
    }
}

However, it takes ages.

Is there a way to avoid these loops?

Thanks for your help
Mario


-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri May 26 14:15:57 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 26 May 2017 12:15:57 +0000
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
Message-ID: <CAM_vjum3ygA+Zpmmoj7S1ZhQt-fTXJmLmVxeOgTSC05VS55OBA@mail.gmail.com>

There are various ways to do this. It shouldn't take forever as a loop,
with only 215 entries.

I find crosstab() from the ecodist package helpful. The current version is
on GitHub, but not yet CRAN (soon!).

Sarah

On Fri, May 26, 2017 at 7:47 AM A M Lavezzi <mario.lavezzi at unipa.it> wrote:

> Dear R-Users
>
> I have data on bilateral trade flows among countries in the following form:
>
> > head(dataTrade)
>
>       iso_o iso_d year FLOW
> 1   ABW   AFG 1985   NA
> 2   ABW   AFG 1986   NA
> 3   ABW   AFG 1987   NA
> 4   ABW   AFG 1988   NA
> 5   ABW   AFG 1989   NA
> 6   ABW   AFG 1990   NA
>
> where:
> iso_o: code of country of origin
> iso_d: code of country of destination
> year: 1985:2015
> FLOW: amount of trade (values are "NA", 0s, or positive numbers)



> I have 215 countries. I would like to create a 215x215 matrix , say M, in
> which element M(i,j) is the total trade between countries i and j between
> 1985 and 2015 (i.e. the sum of annual amounts of trade).
>
> After collecting the country codes in a variable named "my_iso", I can
> obtain M in a straightforward way using a loop such as:
>
> for (i in my_iso){
>   for(j in my_iso)
>     if(i!=j){
>       M[seq(1:length(my_iso))[my_iso==i],seq(1:length(my_iso))[my_iso==j]]
> <-
>         sum(dataTrade[dataTrade$iso_o==i &
> dataTrade$iso_d==j,"FLOW"],na.rm=TRUE)
>     }
> }
>
> However, it takes ages.
>
> Is there a way to avoid these loops?
>
> Thanks for your help
> Mario
>
>
> --
> Andrea Mario Lavezzi
> DiGi,Sezione Diritto e Societ?
> Universit? di Palermo
> Piazza Bologni 8
> 90134 Palermo, Italy
> tel. ++39 091 23892208
> fax ++39 091 6111268
> skype: lavezzimario
> email: mario.lavezzi (at) unipa.it
> web: http://www.unipa.it/~mario.lavezzi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri May 26 14:17:56 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 26 May 2017 12:17:56 +0000
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
Message-ID: <CAKVAULNW=hWigzE4_b5PrPnuFgp=wmy4LPo=hd2BE4AKXyLpbw@mail.gmail.com>

Hi Mario,

does acast from the reshape2 package help?

dfa<- data.frame(iso_o = letters[c(1, 1:4)], iso_d = letters[6:10], year =
c(1985, 1985, 1986, 1987, 1988), flow = c(1,2,3,4, NA))
reshape2::acast(dfa, iso_o ~ iso_d, fun.aggregate = sum, value.var = "flow")

HTH
Ulrik

On Fri, 26 May 2017 at 13:47 A M Lavezzi <mario.lavezzi at unipa.it> wrote:

> Dear R-Users
>
> I have data on bilateral trade flows among countries in the following form:
>
> > head(dataTrade)
>
>       iso_o iso_d year FLOW
> 1   ABW   AFG 1985   NA
> 2   ABW   AFG 1986   NA
> 3   ABW   AFG 1987   NA
> 4   ABW   AFG 1988   NA
> 5   ABW   AFG 1989   NA
> 6   ABW   AFG 1990   NA
>
> where:
> iso_o: code of country of origin
> iso_d: code of country of destination
> year: 1985:2015
> FLOW: amount of trade (values are "NA", 0s, or positive numbers)
>
> I have 215 countries. I would like to create a 215x215 matrix , say M, in
> which element M(i,j) is the total trade between countries i and j between
> 1985 and 2015 (i.e. the sum of annual amounts of trade).
>
> After collecting the country codes in a variable named "my_iso", I can
> obtain M in a straightforward way using a loop such as:
>
> for (i in my_iso){
>   for(j in my_iso)
>     if(i!=j){
>       M[seq(1:length(my_iso))[my_iso==i],seq(1:length(my_iso))[my_iso==j]]
> <-
>         sum(dataTrade[dataTrade$iso_o==i &
> dataTrade$iso_d==j,"FLOW"],na.rm=TRUE)
>     }
> }
>
> However, it takes ages.
>
> Is there a way to avoid these loops?
>
> Thanks for your help
> Mario
>
>
> --
> Andrea Mario Lavezzi
> DiGi,Sezione Diritto e Societ?
> Universit? di Palermo
> Piazza Bologni 8
> 90134 Palermo, Italy
> tel. ++39 091 23892208 <+39%20091%202389%202208>
> fax ++39 091 6111268 <+39%20091%20611%201268>
> skype: lavezzimario
> email: mario.lavezzi (at) unipa.it
> web: http://www.unipa.it/~mario.lavezzi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri May 26 14:20:16 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 May 2017 08:20:16 -0400
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
Message-ID: <48796b45-c14a-cd69-f853-2a7f73f1ab3f@gmail.com>

On 26/05/2017 7:46 AM, A M Lavezzi wrote:
> Dear R-Users
>
> I have data on bilateral trade flows among countries in the following form:
>
>> head(dataTrade)
>
>       iso_o iso_d year FLOW
> 1   ABW   AFG 1985   NA
> 2   ABW   AFG 1986   NA
> 3   ABW   AFG 1987   NA
> 4   ABW   AFG 1988   NA
> 5   ABW   AFG 1989   NA
> 6   ABW   AFG 1990   NA
>
> where:
> iso_o: code of country of origin
> iso_d: code of country of destination
> year: 1985:2015
> FLOW: amount of trade (values are "NA", 0s, or positive numbers)
>
> I have 215 countries. I would like to create a 215x215 matrix , say M, in
> which element M(i,j) is the total trade between countries i and j between
> 1985 and 2015 (i.e. the sum of annual amounts of trade).
>
> After collecting the country codes in a variable named "my_iso", I can
> obtain M in a straightforward way using a loop such as:
>
> for (i in my_iso){
>   for(j in my_iso)
>     if(i!=j){
>       M[seq(1:length(my_iso))[my_iso==i],seq(1:length(my_iso))[my_iso==j]]
> <-
>         sum(dataTrade[dataTrade$iso_o==i &
> dataTrade$iso_d==j,"FLOW"],na.rm=TRUE)
>     }
> }
>
> However, it takes ages.
>
> Is there a way to avoid these loops?

Assuming that you have unique entries for each of the first 3 columns, 
you could so something like this:

# Put all the data into an array, indexed by origin, destination, year:

dataMatrix <- as.matrix(dataTrade)  # Converts everything to character

dataArray <- array(0, c(215, 215, 31))
dimnames(dataArray) <- list(unique(dataMatrix[,1]), 
unique(dataMatrix[,2]), unique(dataMatrix[,3]))

dataArray[dataMatrix[,1:3]] <- dataTrade$FLOW

# Sum across years

apply(dataArray, 3, sum)

I haven't tried this (you didn't give a reproducible example...), so you 
may need to tweak it a bit.

Duncan Murdoch


From S.Ellison at LGCGroup.com  Fri May 26 15:28:07 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 26 May 2017 14:28:07 +0100
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E267240B98A39EB7@GBTEDVPEXCMB04.corp.lgc-group.com>

> -----Original Message-----
> From: A M > Lavezzi
> 
> I have data on bilateral trade flows among countries in the following form:
> 
>       iso_o iso_d year FLOW
> 1   ABW   AFG 1985   NA
> 2   ABW   AFG 1986   NA
> 3   ABW   AFG 1987   NA
> 4   ABW   AFG 1988   NA
> 5   ABW   AFG 1989   NA
> 6   ABW   AFG 1990   NA
> 
>...
>
> I have 215 countries. I would like to create a 215x215 matrix , say M, in which
> element M(i,j) is the total trade between countries i and j between
> 1985 and 2015 (i.e. the sum of annual amounts of trade).
> 
> After collecting the country codes in a variable named "my_iso", I can obtain
> M in a straightforward way using a loop 
> 
> Is there a way to avoid these loops?

Using core R:
#Use aggregate() to aggregate across years:

dataTrade.ag <- aggregate (dataTrade[,'Flow',drop=FALSE], by=dataTrade[, c('iso_o', 'iso_d')], FUN=sum, na.rm=TRUE)

#where na.rm=TRUE (passed to sum()) essentially treats NAs as 0. If you really want NA leave it out or set it to FALSE
#This gives you one row per origin/destination pair that contains the total trade in Flow.
#If the years you want are a subset, subset the data frame first.

#Form an empty matrix with suitable dimnames:
N_iso <- length(my_iso)
dT.m <- matrix(rep(NA, N_iso*N_iso), ncol=N_iso, dimnames=list(my_iso, my_iso))

#Then use matrix indexing by name to populate your matrix with the available flow data
dT.m[as.matrix(dataTrade.ag[1:2]) ] <- dataTrade.ag$Flow	
	#This relies on a default conversion from data frame factors to a character matrix, together
	#with R's facility for matrix indexing by 2-column matrix

#Then
dataTrade.ag[1:10, 1:10]

#should have what you seem to want


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From dcarlson at tamu.edu  Fri May 26 16:51:02 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 26 May 2017 14:51:02 +0000
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <1A8C1289955EF649A09086A153E267240B98A39EB7@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
 <1A8C1289955EF649A09086A153E267240B98A39EB7@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <cdcabe55ca244a3caad4d0593507fb4d@exch-2p-mbx-w2.ads.tamu.edu>

How about?

Trade <- xtabs(FLOW ~ iso_o + iso_d + year, dta)

Gives you a 3d table with FLOW as the cell entry. Then

apply(Trade, 1:2, sum, na.rm=TRUE)

Gives you a 2d table with the total flow


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of S Ellison
Sent: Friday, May 26, 2017 8:28 AM
To: A M Lavezzi <mario.lavezzi at unipa.it>; r-help <r-help at r-project.org>
Subject: Re: [R] organizing data in a matrix avoiding loop

> -----Original Message-----
> From: A M > Lavezzi
> 
> I have data on bilateral trade flows among countries in the following form:
> 
>       iso_o iso_d year FLOW
> 1   ABW   AFG 1985   NA
> 2   ABW   AFG 1986   NA
> 3   ABW   AFG 1987   NA
> 4   ABW   AFG 1988   NA
> 5   ABW   AFG 1989   NA
> 6   ABW   AFG 1990   NA
> 
>...
>
> I have 215 countries. I would like to create a 215x215 matrix , say M, in which
> element M(i,j) is the total trade between countries i and j between
> 1985 and 2015 (i.e. the sum of annual amounts of trade).
> 
> After collecting the country codes in a variable named "my_iso", I can obtain
> M in a straightforward way using a loop 
> 
> Is there a way to avoid these loops?

Using core R:
#Use aggregate() to aggregate across years:

dataTrade.ag <- aggregate (dataTrade[,'Flow',drop=FALSE], by=dataTrade[, c('iso_o', 'iso_d')], FUN=sum, na.rm=TRUE)

#where na.rm=TRUE (passed to sum()) essentially treats NAs as 0. If you really want NA leave it out or set it to FALSE
#This gives you one row per origin/destination pair that contains the total trade in Flow.
#If the years you want are a subset, subset the data frame first.

#Form an empty matrix with suitable dimnames:
N_iso <- length(my_iso)
dT.m <- matrix(rep(NA, N_iso*N_iso), ncol=N_iso, dimnames=list(my_iso, my_iso))

#Then use matrix indexing by name to populate your matrix with the available flow data
dT.m[as.matrix(dataTrade.ag[1:2]) ] <- dataTrade.ag$Flow	
	#This relies on a default conversion from data frame factors to a character matrix, together
	#with R's facility for matrix indexing by 2-column matrix

#Then
dataTrade.ag[1:10, 1:10]

#should have what you seem to want


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:14}}


From nell.redu at hotmail.fr  Fri May 26 17:55:28 2017
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Fri, 26 May 2017 15:55:28 +0000
Subject: [R] Latin Hypercube Sampling when parameters are defined according
 to specific probability distributions
Message-ID: <CY1PR05MB2730059A11D144822D8A10B199FC0@CY1PR05MB2730.namprd05.prod.outlook.com>

Hello,

 I would like to perform a sensitivity analysis using a Latin Hypercube Sampling (LHS).

Among the input parameters in the model, I have a parameter ?dispersal distance? which is defined according to an exponential probability distribution.

In the model, the user thus sets a default probability value for each distance class.

For example, for distances ([0 ? 2]; ]2 ? 4]; ]4 ? 6]; ]6 ? 8]; ]8 ? 10];??; ]48 ? 50],

respective probabilities are 0.055; 0.090; 0.065; 0.035; 0.045;???; 0.005.

 Here is the code to represent an exponential probability distribution for the parameter ?dispersal distance?:

set.seed(0)
foo <- rexp(100, rate = 1/10)
hist(foo, prob=TRUE, breaks=20, ylim=c(0,0.1), xlab ="Distance (km)")
lines(dexp(seq(1, 100, by = 1), rate = 1/mean(foo)),col="red")
1/mean(foo)

When a parameter is defined according to a specific probability distribution, how can I perform a LHS ?
For example, should I sample N values from a uniform distribution for each distance class (i.e., [0 ? 2]; ]2 ? 4]; ]4 ? 6]; ]6 ? 8]; ]8 ? 10];??; ]48 ? 50])
or sample N values from exponential distributions with different rates ?

Here is the code used to perform a LHS when the parameter ?dispersal distance? is defined by  one default value in the model:

 library(pse)

factors <- c("distance")

q <- c("qexp")

q.arg <- list( list(rate=1/30) )

uncoupledLHS <- LHS(model=NULL, factors, 50, q, q.arg)

head(uncoupledLHS)

Thanks a lot for your time.
Have a nice day
Nell



	[[alternative HTML version deleted]]


From mario.lavezzi at unipa.it  Fri May 26 18:40:06 2017
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 26 May 2017 18:40:06 +0200
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <CAM_vjum3ygA+Zpmmoj7S1ZhQt-fTXJmLmVxeOgTSC05VS55OBA@mail.gmail.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
 <CAM_vjum3ygA+Zpmmoj7S1ZhQt-fTXJmLmVxeOgTSC05VS55OBA@mail.gmail.com>
Message-ID: <CAOZPQW5+RoNLq5q8SO-BqVbDNuHwZNVXCGjCQD=dKzj6wNrmmQ@mail.gmail.com>

Dear Sarah
thank you very much. I used "crosstab" and it worked,

xxx<-crosstab(dataTrade$iso_o,dataTrade$iso_d,dataTrade$FLOW,type="sum",na.rm=TRUE)

All the best
Mario

On Fri, May 26, 2017 at 2:15 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> There are various ways to do this. It shouldn't take forever as a loop,
> with only 215 entries.
>
> I find crosstab() from the ecodist package helpful. The current version is
> on GitHub, but not yet CRAN (soon!).
>
> Sarah
>
> On Fri, May 26, 2017 at 7:47 AM A M Lavezzi <mario.lavezzi at unipa.it>
> wrote:
>
>> Dear R-Users
>>
>> I have data on bilateral trade flows among countries in the following
>> form:
>>
>> > head(dataTrade)
>>
>>       iso_o iso_d year FLOW
>> 1   ABW   AFG 1985   NA
>> 2   ABW   AFG 1986   NA
>> 3   ABW   AFG 1987   NA
>> 4   ABW   AFG 1988   NA
>> 5   ABW   AFG 1989   NA
>> 6   ABW   AFG 1990   NA
>>
>> where:
>> iso_o: code of country of origin
>> iso_d: code of country of destination
>> year: 1985:2015
>> FLOW: amount of trade (values are "NA", 0s, or positive numbers)
>
>
>
>> I have 215 countries. I would like to create a 215x215 matrix , say M, in
>> which element M(i,j) is the total trade between countries i and j between
>> 1985 and 2015 (i.e. the sum of annual amounts of trade).
>>
>> After collecting the country codes in a variable named "my_iso", I can
>> obtain M in a straightforward way using a loop such as:
>>
>> for (i in my_iso){
>>   for(j in my_iso)
>>     if(i!=j){
>>       M[seq(1:length(my_iso))[my_iso==i],seq(1:length(my_iso))[
>> my_iso==j]]
>> <-
>>         sum(dataTrade[dataTrade$iso_o==i &
>> dataTrade$iso_d==j,"FLOW"],na.rm=TRUE)
>>     }
>> }
>>
>> However, it takes ages.
>>
>> Is there a way to avoid these loops?
>>
>> Thanks for your help
>> Mario
>>
>>
>> --
>> Andrea Mario Lavezzi
>> DiGi,Sezione Diritto e Societ?
>> Universit? di Palermo
>> Piazza Bologni 8
>> 90134 Palermo, Italy
>> tel. ++39 091 23892208 <+39%20091%202389%202208>
>> fax ++39 091 6111268 <+39%20091%20611%201268>
>> skype: lavezzimario
>> email: mario.lavezzi (at) unipa.it
>> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Funipa.it&e=ae0ec65b&h=e13e0f75&f=y>
>> web: http://www.unipa.it/~mario.lavezzi
>> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.unipa.it%2F~mario.lavezzi&e=ae0ec65b&h=f8f16f65&f=y>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> <https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=ae0ec65b&h=8af6ace6&f=y>
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=ae0ec65b&h=ea1999c9&f=y>
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sarah Goslee
> http://www.stringpage.com
> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.stringpage.com&e=ae0ec65b&h=19bbc433&f=y>
> http://www.sarahgoslee.com
> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.sarahgoslee.com&e=ae0ec65b&h=5b5cfa0d&f=y>
> http://www.functionaldiversity.org
> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.functionaldiversity.org&e=ae0ec65b&h=f81071c1&f=y>
>



-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

	[[alternative HTML version deleted]]


From mario.lavezzi at unipa.it  Fri May 26 18:41:03 2017
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 26 May 2017 18:41:03 +0200
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <CAKVAULNW=hWigzE4_b5PrPnuFgp=wmy4LPo=hd2BE4AKXyLpbw@mail.gmail.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
 <CAKVAULNW=hWigzE4_b5PrPnuFgp=wmy4LPo=hd2BE4AKXyLpbw@mail.gmail.com>
Message-ID: <CAOZPQW7ykYpZEgN7HJ9VP-dwb7W8TyUVEvrgyN0tkZwQG3yJaA@mail.gmail.com>

Hi Ulrik
thanks a lot for your suggestion. I followed the suggestion of Sarah (the
first on the thread) and solved my problem

I will keep into account you suggestion anyway
Mario

On Fri, May 26, 2017 at 2:17 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Hi Mario,
>
> does acast from the reshape2 package help?
>
> dfa<- data.frame(iso_o = letters[c(1, 1:4)], iso_d = letters[6:10], year =
> c(1985, 1985, 1986, 1987, 1988), flow = c(1,2,3,4, NA))
> reshape2::acast(dfa, iso_o ~ iso_d, fun.aggregate = sum, value.var =
> "flow")
>
> HTH
> Ulrik
>
> On Fri, 26 May 2017 at 13:47 A M Lavezzi <mario.lavezzi at unipa.it> wrote:
>
>> Dear R-Users
>>
>> I have data on bilateral trade flows among countries in the following
>> form:
>>
>> > head(dataTrade)
>>
>>       iso_o iso_d year FLOW
>> 1   ABW   AFG 1985   NA
>> 2   ABW   AFG 1986   NA
>> 3   ABW   AFG 1987   NA
>> 4   ABW   AFG 1988   NA
>> 5   ABW   AFG 1989   NA
>> 6   ABW   AFG 1990   NA
>>
>> where:
>> iso_o: code of country of origin
>> iso_d: code of country of destination
>> year: 1985:2015
>> FLOW: amount of trade (values are "NA", 0s, or positive numbers)
>>
>> I have 215 countries. I would like to create a 215x215 matrix , say M, in
>> which element M(i,j) is the total trade between countries i and j between
>> 1985 and 2015 (i.e. the sum of annual amounts of trade).
>>
>> After collecting the country codes in a variable named "my_iso", I can
>> obtain M in a straightforward way using a loop such as:
>>
>> for (i in my_iso){
>>   for(j in my_iso)
>>     if(i!=j){
>>       M[seq(1:length(my_iso))[my_iso==i],seq(1:length(my_iso))[
>> my_iso==j]]
>> <-
>>         sum(dataTrade[dataTrade$iso_o==i &
>> dataTrade$iso_d==j,"FLOW"],na.rm=TRUE)
>>     }
>> }
>>
>> However, it takes ages.
>>
>> Is there a way to avoid these loops?
>>
>> Thanks for your help
>> Mario
>>
>>
>> --
>> Andrea Mario Lavezzi
>> DiGi,Sezione Diritto e Societ?
>> Universit? di Palermo
>> Piazza Bologni 8
>> 90134 Palermo, Italy
>> tel. ++39 091 23892208 <+39%20091%202389%202208>
>> fax ++39 091 6111268 <+39%20091%20611%201268>
>> skype: lavezzimario
>> email: mario.lavezzi (at) unipa.it
>> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Funipa.it&e=ae0ec65b&h=e13e0f75&f=y>
>> web: http://www.unipa.it/~mario.lavezzi
>> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.unipa.it%2F~mario.lavezzi&e=ae0ec65b&h=f8f16f65&f=y>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> <https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=ae0ec65b&h=8af6ace6&f=y>
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> <https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=ae0ec65b&h=ea1999c9&f=y>
>> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

	[[alternative HTML version deleted]]


From mario.lavezzi at unipa.it  Fri May 26 18:41:20 2017
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 26 May 2017 18:41:20 +0200
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <48796b45-c14a-cd69-f853-2a7f73f1ab3f@gmail.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
 <48796b45-c14a-cd69-f853-2a7f73f1ab3f@gmail.com>
Message-ID: <CAOZPQW4gFveFKpADuC1+4-NrqA6wprpA1HQJB81nOzz4NHqVaQ@mail.gmail.com>

Hi Duncan
thanks a lot for your suggestion. I followed the suggestion of Sarah (the
first on the thread) and solved my problem

I will keep into account you suggestion anyway
Mario

On Fri, May 26, 2017 at 2:20 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 26/05/2017 7:46 AM, A M Lavezzi wrote:
>
>> Dear R-Users
>>
>> I have data on bilateral trade flows among countries in the following
>> form:
>>
>> head(dataTrade)
>>>
>>
>>       iso_o iso_d year FLOW
>> 1   ABW   AFG 1985   NA
>> 2   ABW   AFG 1986   NA
>> 3   ABW   AFG 1987   NA
>> 4   ABW   AFG 1988   NA
>> 5   ABW   AFG 1989   NA
>> 6   ABW   AFG 1990   NA
>>
>> where:
>> iso_o: code of country of origin
>> iso_d: code of country of destination
>> year: 1985:2015
>> FLOW: amount of trade (values are "NA", 0s, or positive numbers)
>>
>> I have 215 countries. I would like to create a 215x215 matrix , say M, in
>> which element M(i,j) is the total trade between countries i and j between
>> 1985 and 2015 (i.e. the sum of annual amounts of trade).
>>
>> After collecting the country codes in a variable named "my_iso", I can
>> obtain M in a straightforward way using a loop such as:
>>
>> for (i in my_iso){
>>   for(j in my_iso)
>>     if(i!=j){
>>       M[seq(1:length(my_iso))[my_iso==i],seq(1:length(my_iso))[my_
>> iso==j]]
>> <-
>>         sum(dataTrade[dataTrade$iso_o==i &
>> dataTrade$iso_d==j,"FLOW"],na.rm=TRUE)
>>     }
>> }
>>
>> However, it takes ages.
>>
>> Is there a way to avoid these loops?
>>
>
> Assuming that you have unique entries for each of the first 3 columns, you
> could so something like this:
>
> # Put all the data into an array, indexed by origin, destination, year:
>
> dataMatrix <- as.matrix(dataTrade)  # Converts everything to character
>
> dataArray <- array(0, c(215, 215, 31))
> dimnames(dataArray) <- list(unique(dataMatrix[,1]),
> unique(dataMatrix[,2]), unique(dataMatrix[,3]))
>
> dataArray[dataMatrix[,1:3]] <- dataTrade$FLOW
>
> # Sum across years
>
> apply(dataArray, 3, sum)
>
> I haven't tried this (you didn't give a reproducible example...), so you
> may need to tweak it a bit.
>
> Duncan Murdoch
>



-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

	[[alternative HTML version deleted]]


From mario.lavezzi at unipa.it  Fri May 26 18:41:41 2017
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 26 May 2017 18:41:41 +0200
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <1A8C1289955EF649A09086A153E267240B98A39EB7@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
 <1A8C1289955EF649A09086A153E267240B98A39EB7@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAOZPQW6mg5SunrOOUzqioqY8NaUSyhhZk1W966quimGf50B7yQ@mail.gmail.com>

Thanks a lot for your suggestion. I followed the suggestion of Sarah (the
first on the thread) and solved my problem

I will keep into account you suggestion anyway
Mario

On Fri, May 26, 2017 at 3:28 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > -----Original Message-----
> > From: A M > Lavezzi
> >
> > I have data on bilateral trade flows among countries in the following
> form:
> >
> >       iso_o iso_d year FLOW
> > 1   ABW   AFG 1985   NA
> > 2   ABW   AFG 1986   NA
> > 3   ABW   AFG 1987   NA
> > 4   ABW   AFG 1988   NA
> > 5   ABW   AFG 1989   NA
> > 6   ABW   AFG 1990   NA
> >
> >...
> >
> > I have 215 countries. I would like to create a 215x215 matrix , say M,
> in which
> > element M(i,j) is the total trade between countries i and j between
> > 1985 and 2015 (i.e. the sum of annual amounts of trade).
> >
> > After collecting the country codes in a variable named "my_iso", I can
> obtain
> > M in a straightforward way using a loop
> >
> > Is there a way to avoid these loops?
>
> Using core R:
> #Use aggregate() to aggregate across years:
>
> https://urlsand.esvalabs.com/?u=http%3A%2F%2FdataTrade.ag&e=
> ae0ec65b&h=cb58f304&f=y <- aggregate (dataTrade[,'Flow',drop=FALSE],
> by=dataTrade[, c('iso_o', 'iso_d')], FUN=sum, na.rm=TRUE)
>
> #where na.rm=TRUE (passed to sum()) essentially treats NAs as 0. If you
> really want NA leave it out or set it to FALSE
> #This gives you one row per origin/destination pair that contains the
> total trade in Flow.
> #If the years you want are a subset, subset the data frame first.
>
> #Form an empty matrix with suitable dimnames:
> N_iso <- length(my_iso)
> dT.m <- matrix(rep(NA, N_iso*N_iso), ncol=N_iso, dimnames=list(my_iso,
> my_iso))
>
> #Then use matrix indexing by name to populate your matrix with the
> available flow data
> dT.m[as.matrix(dataTrade.ag[1:2]) ] <- dataTrade.ag$Flow
>         #This relies on a default conversion from data frame factors to a
> character matrix, together
>         #with R's facility for matrix indexing by 2-column matrix
>
> #Then
> dataTrade.ag[1:10, 1:10]
>
> #should have what you seem to want
>
>
> S Ellison
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:26}}


From mario.lavezzi at unipa.it  Fri May 26 18:42:00 2017
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 26 May 2017 18:42:00 +0200
Subject: [R] organizing data in a matrix avoiding loop
In-Reply-To: <cdcabe55ca244a3caad4d0593507fb4d@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAOZPQW7h9ztK5m4Abw_NM0S3SZ7yLn3OtHXaLDnQ_b2rviDcnw@mail.gmail.com>
 <1A8C1289955EF649A09086A153E267240B98A39EB7@GBTEDVPEXCMB04.corp.lgc-group.com>
 <cdcabe55ca244a3caad4d0593507fb4d@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAOZPQW5YL6wr5r0e6czF=_fJX=mVuEEcw=ojfpymrU8JJoax-w@mail.gmail.com>

Hi David
thanks a lot for your suggestion. I followed the suggestion of Sarah (the
first on the thread) and solved my problem

I will keep into account you suggestion anyway
Mario

On Fri, May 26, 2017 at 4:51 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> How about?
>
> Trade <- xtabs(FLOW ~ iso_o + iso_d + year, dta)
>
> Gives you a 3d table with FLOW as the cell entry. Then
>
> apply(Trade, 1:2, sum, na.rm=TRUE)
>
> Gives you a 2d table with the total flow
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of S Ellison
> Sent: Friday, May 26, 2017 8:28 AM
> To: A M Lavezzi <mario.lavezzi at unipa.it>; r-help <r-help at r-project.org>
> Subject: Re: [R] organizing data in a matrix avoiding loop
>
> > -----Original Message-----
> > From: A M > Lavezzi
> >
> > I have data on bilateral trade flows among countries in the following
> form:
> >
> >       iso_o iso_d year FLOW
> > 1   ABW   AFG 1985   NA
> > 2   ABW   AFG 1986   NA
> > 3   ABW   AFG 1987   NA
> > 4   ABW   AFG 1988   NA
> > 5   ABW   AFG 1989   NA
> > 6   ABW   AFG 1990   NA
> >
> >...
> >
> > I have 215 countries. I would like to create a 215x215 matrix , say M,
> in which
> > element M(i,j) is the total trade between countries i and j between
> > 1985 and 2015 (i.e. the sum of annual amounts of trade).
> >
> > After collecting the country codes in a variable named "my_iso", I can
> obtain
> > M in a straightforward way using a loop
> >
> > Is there a way to avoid these loops?
>
> Using core R:
> #Use aggregate() to aggregate across years:
>
> https://urlsand.esvalabs.com/?u=http%3A%2F%2FdataTrade.ag&e=
> ae0ec65b&h=cb58f304&f=y <- aggregate (dataTrade[,'Flow',drop=FALSE],
> by=dataTrade[, c('iso_o', 'iso_d')], FUN=sum, na.rm=TRUE)
>
> #where na.rm=TRUE (passed to sum()) essentially treats NAs as 0. If you
> really want NA leave it out or set it to FALSE
> #This gives you one row per origin/destination pair that contains the
> total trade in Flow.
> #If the years you want are a subset, subset the data frame first.
>
> #Form an empty matrix with suitable dimnames:
> N_iso <- length(my_iso)
> dT.m <- matrix(rep(NA, N_iso*N_iso), ncol=N_iso, dimnames=list(my_iso,
> my_iso))
>
> #Then use matrix indexing by name to populate your matrix with the
> available flow data
> dT.m[as.matrix(dataTrade.ag[1:2]) ] <- dataTrade.ag$Flow
>         #This relies on a default conversion from data frame factors to a
> character matrix, together
>         #with R's facility for matrix indexing by 2-column matrix
>
> #Then
> dataTrade.ag[1:10, 1:10]
>
> #should have what you seem to want
>
>
> S Ellison
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use, copying or
> disclosure other than by the intended recipient is unauthorised. If
> you have received this message in error, please notify the sender
> immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com
> and delete this message and any copies from your computer and network.
> LGC Limited. Registered in England 2991879.
> Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%
> 2Fmailman%2Flistinfo%2Fr-help&e=ae0ec65b&h=8af6ace6&f=y
> PLEASE do read the posting guide https://urlsand.esvalabs.com/?
> u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=
> ae0ec65b&h=ea1999c9&f=y
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Andrea Mario Lavezzi
DiGi,Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

	[[alternative HTML version deleted]]


From m.ashton at enduringinvestments.com  Fri May 26 22:58:12 2017
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 26 May 2017 20:58:12 +0000
Subject: [R] getting a subset corresponding to a list element
Message-ID: <1e0317aa53bb45899d7fa96b920c59b3@MBX084-W1-CA-3.exch084.serverpod.net>

I'm not sure how to ask this with the proper terminology, but here goes:

The BDH() function in RBLPAPI returns, for a list of symbols (e.g., 'SPX Index','RIY Index','IBM Equity') a list of closing prices. The problem is that the result is not a matrix or a dataframe, but a list.

So, if I run the query with 3 symbols, I get a list with 3 elements. For example, in this case, if

symbolist <-c("SPX Index","MXWO Index","MXEA Index")
resultlist <- bdh(symbollist, "PX_LAST", options=opt,start.date=as.Date(begdate))

then resultlist is a list with 3 elements, and as many rows as there are dates between "begdate" and today (or as many month-ends, if "opt" declares monthly periodicity). Suppose in this case I've set this up to retrieve 60 dates.

But I don't WANT a list. I want a zoo object containing each of these as an element. I thought about starting by trying to put each element in a matrix by

data<-matrix(nrow=60,ncol=length(symbollist))

and then looping through from 1 to length(symbolist), letting

data[,i] <- resultlist$symbollist[i][,2]

but this clearly doesn't work since what I really want is

data[,1] <-resultlist$'SPX Index'[,2]
data[,2] <-resultlist$'MXWO Index'[,2]
etc

But there's probably a much easier way to do this.

I am sending this to both the general help list and the r-sig-finance list since there is probably both a general way to stuff a list into a zoo object and a way to do it cleanly with the BDH() command. Thanks in advance for help.

Mike


	[[alternative HTML version deleted]]


From rharlow86 at gmail.com  Fri May 26 23:12:55 2017
From: rharlow86 at gmail.com (Robert Harlow)
Date: Fri, 26 May 2017 17:12:55 -0400
Subject: [R] [R-SIG-Finance] getting a subset corresponding to a list
	element
In-Reply-To: <1e0317aa53bb45899d7fa96b920c59b3@MBX084-W1-CA-3.exch084.serverpod.net>
References: <1e0317aa53bb45899d7fa96b920c59b3@MBX084-W1-CA-3.exch084.serverpod.net>
Message-ID: <CAHdfS94zPRZSH1wDwLectytCKZxXdmfWvW3xknXPPFciBi1wtg@mail.gmail.com>

Hi Michael,
  Try not to post twice - this is really more of a general R question.  To
answer the question, however, turn each element of your resultlist into an
xts (or zoo)  object so that you have a list of xts objects (called xtsList
for example.)  Then call do.call("merge", xtsList).  Also, your example is
tough because it requires access to bloomberg, which isn't necessarily the
case for the vast majority of R users.
Bob

On Fri, May 26, 2017 at 4:58 PM, Michael Ashton <
m.ashton at enduringinvestments.com> wrote:

> I'm not sure how to ask this with the proper terminology, but here goes:
>
> The BDH() function in RBLPAPI returns, for a list of symbols (e.g., 'SPX
> Index','RIY Index','IBM Equity') a list of closing prices. The problem is
> that the result is not a matrix or a dataframe, but a list.
>
> So, if I run the query with 3 symbols, I get a list with 3 elements. For
> example, in this case, if
>
> symbolist <-c("SPX Index","MXWO Index","MXEA Index")
> resultlist <- bdh(symbollist, "PX_LAST", options=opt,start.date=as.
> Date(begdate))
>
> then resultlist is a list with 3 elements, and as many rows as there are
> dates between "begdate" and today (or as many month-ends, if "opt" declares
> monthly periodicity). Suppose in this case I've set this up to retrieve 60
> dates.
>
> But I don't WANT a list. I want a zoo object containing each of these as
> an element. I thought about starting by trying to put each element in a
> matrix by
>
> data<-matrix(nrow=60,ncol=length(symbollist))
>
> and then looping through from 1 to length(symbolist), letting
>
> data[,i] <- resultlist$symbollist[i][,2]
>
> but this clearly doesn't work since what I really want is
>
> data[,1] <-resultlist$'SPX Index'[,2]
> data[,2] <-resultlist$'MXWO Index'[,2]
> etc
>
> But there's probably a much easier way to do this.
>
> I am sending this to both the general help list and the r-sig-finance list
> since there is probably both a general way to stuff a list into a zoo
> object and a way to do it cleanly with the BDH() command. Thanks in advance
> for help.
>
> Mike
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions
> should go.
>

	[[alternative HTML version deleted]]


From yarmi1224 at hotmail.com  Sat May 27 04:18:38 2017
From: yarmi1224 at hotmail.com (=?big5?B?o2Mgoag=?=)
Date: Sat, 27 May 2017 02:18:38 +0000
Subject: [R] Using  associate words to search text .
Message-ID: <HK2PR0301MB11872776B0FF29B8B3CDFF81A4FD0@HK2PR0301MB1187.apcprd03.prod.outlook.com>

Hi:
I am using the package "tm" for text-mining of CMP patents.
I use findAssocs() function to find the words which associated my dictionary (technical names).
Now, I want to use these associate words to search for which documents are contain.

For example:
From the result of findAssocs(gram_dtm, dictionary_word, 0.5).

$apparatus
 apparatus polishing             glycerin          method high apparatus comprising
                0.66                 0.54                 0.54                 0.53

It shows "apparatus" is associate with "apparatus polishing", "glycerin", " method high" and "apparatus comprising".
How do I use the set of words to do the following works?
1. Search which documents have appear?
2. The words frequency in each documents ?
3. How to save these documents?



My code:?@
#Load the text mining package(s)
library("tm")
library("wordcloud")
library(ggplot2)

#Build Corpus
cluster1_df<- read.csv("cluster_1.csv",stringsAsFactors = F)
cluster1_combined <- cluster1_df[,c(3,4,5)]
corpus <- Corpus(DataframeSource(cluster1_combined))
inspect(corpus)


#Pre-processing and tranforming the Corpus
myStopwords <- c(stopwords("english"), stopwords("SMART"),"claim")
corpus_tm <- tm_map(corpus, content_transformer(tolower))
corpus_tm <- tm_map(corpus_tm, removeWords, myStopwords)
corpus_tm <- tm_map(corpus_tm, removeNumbers)
corpus_tm <- tm_map(corpus_tm, removePunctuation)
corpus_tm <- tm_map(corpus_tm, stripWhitespace)
corpus_tm <- tm_map(corpus_tm, stemDocument)
inspect(corpus_tm)

library(RWeka)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 3))
gram_dtm <- DocumentTermMatrix(corpus_tm, control = list(tokenize = BigramTokenizer,
                                                         weighting = function(x) weightTfIdf(x, normalize = TRUE)))
gram_dtm <- removeSparseTerms(gram_dtm, 1-(5/length(corpus_tm)))
inspect(gram_dtm)

dictionary_word <- c("neutral", "abras", "particl", "acid", "apparatus", "back film", "basic", "carrier",
                     "chemic", "chromat","confoc", "clean", "cmp", "compens type", "compress",
                     "comsum", "control", "pressur", "dresser", "condition", "detect",
                     "flow","rate", "fractal", "groov", "hard", "improv type", "infrar",
                     "laser", "layer", "measur", "micro stuctur", "monitor",
                     "multi layer", "none-por", "nonwoven", "pad", "pad applic", "pad condit",
                     "pad materi", "pad properti", "pad structur", "ph","planet", "plate",
                     "plat", "ratio", "polish head", "polish system", "polym", "polyurethan",
                     "porous", "process"," paramet", "path", "time", "recoveri", "speed",
                     "rough", "scatter", "semiconductor", "sensor", "signal", "singl layer",
                     "slurri", "flow rate",  "stirrer", "slurri suppli",
                     "temperatur", "weight percentag","wt", "storag cmp", "stylus profil", "substrat cmp",
                     "thick", "transfer robot", "ultrason", "urethan", "wafer cassett", "wafer transfer",
                     "white light interferomet", "youngs modulus")

onto_assocs<- findAssocs(gram_dtm, dictionary_word, 0.5)




	[[alternative HTML version deleted]]


From ddkssk909c at gmail.com  Sat May 27 05:54:56 2017
From: ddkssk909c at gmail.com (ddkssk 909)
Date: Sat, 27 May 2017 07:54:56 +0400
Subject: [R] Error in y - ymean : non-numeric argument to binary operator
Message-ID: <CAP8z1gzjDosY8spq1wLgn8GAuq16wJJOkEp_=7_7gMYq3VihNQ@mail.gmail.com>

I am trying to do classification with Randomforest() . the class variable
is nominal.

But I get this error
model1 <-randomForest(Cath~.,data=trainrf)
Error in y - ymean : non-numeric argument to binary operator
In addition: There were 26 warnings (use warnings() to see them)
>  model1
Error: object 'model1' not found

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Sat May 27 07:21:53 2017
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 26 May 2017 22:21:53 -0700
Subject: [R] Error in y - ymean : non-numeric argument to binary operator
In-Reply-To: <CAP8z1gzjDosY8spq1wLgn8GAuq16wJJOkEp_=7_7gMYq3VihNQ@mail.gmail.com>
References: <CAP8z1gzjDosY8spq1wLgn8GAuq16wJJOkEp_=7_7gMYq3VihNQ@mail.gmail.com>
Message-ID: <CA+hbrhUue4GToVHaj=mxp+B9faVAFRMKkOsu9xjMLVDdpwhUkQ@mail.gmail.com>

This is a bit of a shot in the dark since I haven't used randomForest
in several years, but I seem to recall that running randomForest
through the formula interface was asking for trouble... Try not using
the formula interface and specify the x, y, xtest arguments directly.

Peter

On Fri, May 26, 2017 at 8:54 PM, ddkssk 909 <ddkssk909c at gmail.com> wrote:
> I am trying to do classification with Randomforest() . the class variable
> is nominal.
>
> But I get this error
> model1 <-randomForest(Cath~.,data=trainrf)
> Error in y - ymean : non-numeric argument to binary operator
> In addition: There were 26 warnings (use warnings() to see them)
>>  model1
> Error: object 'model1' not found
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Sat May 27 15:03:05 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sat, 27 May 2017 15:03:05 +0200
Subject: [R] Problem with Example with Lattice
Message-ID: <20170527130305.GB2291@chicca>

Dear All,
I am making my baby steps with the lattice graphic system.
I am going through the great book by Sarkar which provides plenty of
examples.
However, I notice that some of them appear to give a different result
on my system.
For instance, consider the following


library(lattice)
library(latticeExtra)

dotplot(VADeaths, type = "o",
auto.key = list(lines = TRUE, space = "right"),
main = "Death Rates in Virginia - 1940",
xlab = "Rate (per 1000)")


This should produce a plot where I have different point shapes
connected by different line shapes, but I only one point shape
connected by solid segments.
Am I misunderstanding something basic?
Many thanks

Lorenzodeepayan.sarkar at r



sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 8 (jessie)

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.0
LAPACK: /usr/lib/lapack/liblapack.so.3.0

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
     [9] LC_ADDRESS=C              LC_TELEPHONE=C
     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] latticeExtra_0.6-28 RColorBrewer_1.1-2  lattice_0.20-35

loaded via a namespace (and not attached):
[1] compiler_3.4.0 tools_3.4.0    grid_3.4.0


From johanna.vonbahr at gmail.com  Sat May 27 14:15:38 2017
From: johanna.vonbahr at gmail.com (Johanna von Bahr)
Date: Sat, 27 May 2017 14:15:38 +0200
Subject: [R] Amelia
Message-ID: <3EA598BD-0676-40F7-BDC7-FCBD7F07275B@gmail.com>

Hi,

I have some trouble with Amelia.

I run the following:


all.data<-read.csv2("jldata2.csv", header = TRUE)
summary(all.data)
corp<-plm.data(all.data, cbind("country", "year"))
data.mi <- Amelia::amelia(corp, idvars=1, ts=2, cs=3,intercs=FALSE,nom=4,5,6, 7, 8, 13, 14,19:27, 61 , bounds=bounds,log=c(15, 16,17))

And get the result:
Amelia Error Code:  24 
 The number of polynomial terms to include must be between 1 and 3. 

Does anyone have a suggestion for next steps?

Best,
Johanna

From bgunter.4567 at gmail.com  Sat May 27 17:08:07 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 27 May 2017 08:08:07 -0700
Subject: [R] Problem with Example with Lattice
In-Reply-To: <20170527130305.GB2291@chicca>
References: <20170527130305.GB2291@chicca>
Message-ID: <CAGxFJbQHF0o+eb5zu___QznxLbZjDLrvyqLWBBVQai0EMRarTg@mail.gmail.com>

I was surprised this worked at all, as I usually use the formula interface.

Anyway, you need to explicitly specify the point types via the pch
argument.  The default uses trellis.par.get("dot.symbol"), which is
just a single value.


-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 27, 2017 at 6:03 AM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> I am making my baby steps with the lattice graphic system.
> I am going through the great book by Sarkar which provides plenty of
> examples.
> However, I notice that some of them appear to give a different result
> on my system.
> For instance, consider the following
>
>
> library(lattice)
> library(latticeExtra)
>
> dotplot(VADeaths, type = "o",
> auto.key = list(lines = TRUE, space = "right"),
> main = "Death Rates in Virginia - 1940",
> xlab = "Rate (per 1000)")
>
>
> This should produce a plot where I have different point shapes
> connected by different line shapes, but I only one point shape
> connected by solid segments.
> Am I misunderstanding something basic?
> Many thanks
>
> Lorenzodeepayan.sarkar at r
>
>
>
> sessionInfo()
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux 8 (jessie)
>
> Matrix products: default
> BLAS: /usr/lib/libblas/libblas.so.3.0
> LAPACK: /usr/lib/lapack/liblapack.so.3.0
>
> locale:
> [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
>   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
>    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
>     [9] LC_ADDRESS=C              LC_TELEPHONE=C
>     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] latticeExtra_0.6-28 RColorBrewer_1.1-2  lattice_0.20-35
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.0 tools_3.4.0    grid_3.4.0
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nshah.0452 at gmail.com  Sat May 27 18:16:29 2017
From: nshah.0452 at gmail.com (Neetu Shah)
Date: Sat, 27 May 2017 21:46:29 +0530
Subject: [R] Need Help To Solve An Equation In R
Message-ID: <CACnkotqnfDeL0BpmZ7R_oMehF4VjV-KBtqbK-rzbZsqw_NUQjw@mail.gmail.com>

Dear Sir/Ma'am,

I am trying to make a function to solve an equation that is given below:
findH <- function(p_star, k){
fun <- function(y){
(pnorm(y+h))^(k-1)*dnorm(y)
}
lhs <- integrate(fun, -Inf, Inf)$value
return(uniroot(lhs, lower = -10, upper = 10,
tol = p_star)$root)
}
In lhs, I integrated a function with respect to y and there would be an
unknown h that I need to find.
I need to equate this lhs to p_star value in order to find h. Which
function should I use to solve this equation?
Please guide me regarding this.
Thank you.

-- 
With Regards,
Neetu Shah,
B.Tech.(CS),
3rd Year,
IIIT Vadodara.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat May 27 21:31:58 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 27 May 2017 12:31:58 -0700
Subject: [R] Need Help To Solve An Equation In R
In-Reply-To: <CACnkotqnfDeL0BpmZ7R_oMehF4VjV-KBtqbK-rzbZsqw_NUQjw@mail.gmail.com>
References: <CACnkotqnfDeL0BpmZ7R_oMehF4VjV-KBtqbK-rzbZsqw_NUQjw@mail.gmail.com>
Message-ID: <3C664446-B1A1-4EE9-A5B1-0884F872A9D1@comcast.net>


> On May 27, 2017, at 9:16 AM, Neetu Shah <nshah.0452 at gmail.com> wrote:
> 
> Dear Sir/Ma'am,
> 
> I am trying to make a function to solve an equation that is given below:
> findH <- function(p_star, k){
> fun <- function(y){
> (pnorm(y+h))^(k-1)*dnorm(y)
> }
> lhs <- integrate(fun, -Inf, Inf)$value
> return(uniroot(lhs, lower = -10, upper = 10,
> tol = p_star)$root)
> }
> In lhs, I integrated a function with respect to y and there would be an
> unknown h that I need to find.

uniroot needs a function as its first argument. `integrate(fun, -Inf, Inf)$value` does not return a function. it will return a numeric value (if it succeeds). 

I have no idea whether this makes any mathematical sense because you have not described the background for this effort and have not shown how you expect to call `findH`. Is `h` supposed to be some sort of non-centrality parameter with `k` representing degrees of freedom?

I tried this code that does run, although it fails gracefully at runtime:

findH <- function(p_star= 0.004, k=2){
   fun <- function(y,h){
    (pnorm(y+h))^(k-1)*dnorm(y)
       }
    lhs <- function(x) { integrate(fun, lower=-Inf, upper=Inf, h=x)$value }
    return(uniroot(lhs, lower = -10, upper = 10, tol = p_star)$root)
}
#-------
> findH(k=6)
Error in uniroot(lhs, lower = -10, upper = 10, tol = p_star) : 
  f() values at end points not of opposite sign



> I need to equate this lhs to p_star value in order to find h.

> Which
> function should I use to solve this equation?
> Please guide me regarding this.
> Thank you.
> 
> -- 
> With Regards,
> Neetu Shah,
> B.Tech.(CS),
> 3rd Year,
> IIIT Vadodara.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From hannah.hlx at gmail.com  Sat May 27 21:49:08 2017
From: hannah.hlx at gmail.com (li li)
Date: Sat, 27 May 2017 15:49:08 -0400
Subject: [R] creat contingency tables with fixed row and column margins
Message-ID: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>

Hi all,
  Is there an R function that can be used to enumerate all the contingency
tables with fixed row and column margins. For example, can we list all 3 by
3 tables with row margins 3,6,6 and column margins 5,5,5.
   Thanks very much!
   Hanna

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat May 27 22:04:44 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 27 May 2017 13:04:44 -0700
Subject: [R] creat contingency tables with fixed row and column margins
In-Reply-To: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>
References: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>
Message-ID: <14B9A2C6-1D2E-4E10-9A75-C76D6EADA211@comcast.net>


> On May 27, 2017, at 12:49 PM, li li <hannah.hlx at gmail.com> wrote:
> 
> Hi all,
>  Is there an R function that can be used to enumerate all the contingency
> tables with fixed row and column margins. For example, can we list all 3 by
> 3 tables with row margins 3,6,6 and column margins 5,5,5.

The Posting Guide suggests that you describe the results of your efforts at searching:

https://www.google.com/search?q=use+r%3Alang+to+enumerate+contingency+tables+with+fixed+margins&oq=use+r%3Alang+to+enumerate+contingency+tables+with+fixed+margins&aqs=chrome..69i57.35014j0j4&sourceid=chrome&ie=UTF-8

>   Thanks very much!
>   Hanna
> 
> 	[[alternative HTML version deleted]]

And (yet again) you are asked to post in plain text.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bertcarnell at gmail.com  Sat May 27 22:32:23 2017
From: bertcarnell at gmail.com (Rob C)
Date: Sat, 27 May 2017 16:32:23 -0400
Subject: [R] Latin Hypercube Sampling when parameters are defined
 according to specific probability distributions
Message-ID: <CAPtunJZJ0HpZGGaNjpfbHL_bMxHeACJ21kzpP2Zv1+qtcnTMhg@mail.gmail.com>

>May 26, 2017; 11:41am  Nelly Reduan Latin Hypercube Sampling when parameters are >defined according to specific probability distributions
>Hello,
> I would like to perform a sensitivity analysis using a Latin Hypercube Sampling (LHS).
>Among the input parameters in the model, I have a parameter dispersal distance which is defined according to an exponential probability distribution.

>In the model, the user thus sets a default probability value for each distance class.

>For example, for distances ([0  2]; ]2  4]; ]4  6]; ]6  8]; ]8  10];; ]48  50],

>respective probabilities are 0.055; 0.090; 0.065; 0.035; 0.045;; 0.005.

 >Here is the code to represent an exponential probability
distribution for the parameter dispersal distance:

>set.seed(0)
>foo <- rexp(100, rate = 1/10)
>hist(foo, prob=TRUE, breaks=20, ylim=c(0,0.1), xlab ="Distance (km)")
>lines(dexp(seq(1, 100, by = 1), rate = 1/mean(foo)),col="red")
>1/mean(foo)

>When a parameter is defined according to a specific probability distribution, how can I perform a LHS ?
>For example, should I sample N values from a uniform distribution for each distance class (i.e., [0 ? 2]; ]2 ? 4]; ]4 ? 6]; ]6 ? 8]; ]8 ? 10];??; ]48 ? 50])
>or sample N values from exponential distributions with different rates ?

>Here is the code used to perform a LHS when the parameter ?dispersal distance? is defined by one default value in the model:

>library(pse)
>factors <- c("distance")
>q <- c("qexp")
>q.arg <- list( list(rate=1/30) )
>uncoupledLHS <- LHS(model=NULL, factors, 50, q, q.arg)
>head(uncoupledLHS)

>Thanks a lot for your time.
>Have a nice day
>Nell

Nell,

I would like to suggest a slightly different method for generating the
sample using the lhs library,  then I will try using the pse library.
Generally when you have a package specific
question, you should try to contact the package maintainer first.

set.seed(1)
# I don't think your model has only one parameter, so I will include multiple
input_parameters <- c("dispersal_distance", "temperature", "pressure")
N <- 50
exponential_rate <- 1/30

library(lhs)
X <- randomLHS(N, length(input_parameters))
dimnames(X) <- list(NULL, input_parameters)
# X is now a uniformly distributed Latin hypercube
head(X)
hist(X[,1], breaks=5)
hist(X[,2], breaks=5)
hist(X[,3], breaks=5)
# now, transform the dispersal_distance paramter to an exponential sample
Y <- X
Y[,"dispersal_distance"] <- qexp(X[,"dispersal_distance"],
rate=exponential_rate)
hist(Y[,1], breaks=10)
# you can transform the other marginals as required and then assess
function sensitivity
model_function <- function(z) z[1]*z[2] + z[3]
apply(Y, 1, model_function)

# now, trying to use pse
library(pse)
q <- list("qexp", "qunif", "qunif")
q.arg <- list(list(rate=exponential_rate), list(min=0, max=1),
list(min=0, max=1))
uncoupledLHS <- LHS(model=model_function, input_parameters, N, q, q.arg)
hist(uncoupledLHS$data$dispersal_distance, breaks=10)

Rob


From hannah.hlx at gmail.com  Sat May 27 22:53:18 2017
From: hannah.hlx at gmail.com (li li)
Date: Sat, 27 May 2017 16:53:18 -0400
Subject: [R] creat contingency tables with fixed row and column margins
In-Reply-To: <14B9A2C6-1D2E-4E10-9A75-C76D6EADA211@comcast.net>
References: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>
 <14B9A2C6-1D2E-4E10-9A75-C76D6EADA211@comcast.net>
Message-ID: <CAHLnndYAG58Lrg-SQsMT-BA89A8tf230koLjnWDh3xyPHZto2w@mail.gmail.com>

Hi Dave,
  Thanks for your reply but the post in your link above was certainly asked
by me.
   Hanna

2017-05-27 16:04 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On May 27, 2017, at 12:49 PM, li li <hannah.hlx at gmail.com> wrote:
> >
> > Hi all,
> >  Is there an R function that can be used to enumerate all the contingency
> > tables with fixed row and column margins. For example, can we list all 3
> by
> > 3 tables with row margins 3,6,6 and column margins 5,5,5.
>
> The Posting Guide suggests that you describe the results of your efforts
> at searching:
>
> https://www.google.com/search?q=use+r%3Alang+to+enumerate+
> contingency+tables+with+fixed+margins&oq=use+r%3Alang+to+
> enumerate+contingency+tables+with+fixed+margins&aqs=chrome.
> .69i57.35014j0j4&sourceid=chrome&ie=UTF-8
>
> >   Thanks very much!
> >   Hanna
> >
> >       [[alternative HTML version deleted]]
>
> And (yet again) you are asked to post in plain text.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sat May 27 22:54:18 2017
From: hannah.hlx at gmail.com (li li)
Date: Sat, 27 May 2017 16:54:18 -0400
Subject: [R] creat contingency tables with fixed row and column margins
In-Reply-To: <CAHLnndYAG58Lrg-SQsMT-BA89A8tf230koLjnWDh3xyPHZto2w@mail.gmail.com>
References: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>
 <14B9A2C6-1D2E-4E10-9A75-C76D6EADA211@comcast.net>
 <CAHLnndYAG58Lrg-SQsMT-BA89A8tf230koLjnWDh3xyPHZto2w@mail.gmail.com>
Message-ID: <CAHLnndbP-=B6C6t0boBc9pSCmva7ka9Ok2V1TBjD9pFOs_2GuQ@mail.gmail.com>

I meant that the post in your link above was NOT asked by me.

2017-05-27 16:53 GMT-04:00 li li <hannah.hlx at gmail.com>:

> Hi Dave,
>   Thanks for your reply but the post in your link above was certainly
> asked by me.
>    Hanna
>
> 2017-05-27 16:04 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:
>
>>
>> > On May 27, 2017, at 12:49 PM, li li <hannah.hlx at gmail.com> wrote:
>> >
>> > Hi all,
>> >  Is there an R function that can be used to enumerate all the
>> contingency
>> > tables with fixed row and column margins. For example, can we list all
>> 3 by
>> > 3 tables with row margins 3,6,6 and column margins 5,5,5.
>>
>> The Posting Guide suggests that you describe the results of your efforts
>> at searching:
>>
>> https://www.google.com/search?q=use+r%3Alang+to+enumerate+co
>> ntingency+tables+with+fixed+margins&oq=use+r%3Alang+to+enume
>> rate+contingency+tables+with+fixed+margins&aqs=chrome..
>> 69i57.35014j0j4&sourceid=chrome&ie=UTF-8
>>
>> >   Thanks very much!
>> >   Hanna
>> >
>> >       [[alternative HTML version deleted]]
>>
>> And (yet again) you are asked to post in plain text.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun May 28 04:25:54 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 27 May 2017 19:25:54 -0700
Subject: [R] creat contingency tables with fixed row and column margins
In-Reply-To: <CAHLnndbP-=B6C6t0boBc9pSCmva7ka9Ok2V1TBjD9pFOs_2GuQ@mail.gmail.com>
References: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>
 <14B9A2C6-1D2E-4E10-9A75-C76D6EADA211@comcast.net>
 <CAHLnndYAG58Lrg-SQsMT-BA89A8tf230koLjnWDh3xyPHZto2w@mail.gmail.com>
 <CAHLnndbP-=B6C6t0boBc9pSCmva7ka9Ok2V1TBjD9pFOs_2GuQ@mail.gmail.com>
Message-ID: <1BCF68CA-1E8A-4DCC-87D9-2EA7EA88A35B@dcn.davis.ca.us>

Ah, but the point is that you did not say why  those search results did not address your question, since if they DID answer your question then why should we have to be doing your searching for you? 
-- 
Sent from my phone. Please excuse my brevity.

On May 27, 2017 1:54:18 PM PDT, li li <hannah.hlx at gmail.com> wrote:
>I meant that the post in your link above was NOT asked by me.
>
>2017-05-27 16:53 GMT-04:00 li li <hannah.hlx at gmail.com>:
>
>> Hi Dave,
>>   Thanks for your reply but the post in your link above was certainly
>> asked by me.
>>    Hanna
>>
>> 2017-05-27 16:04 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:
>>
>>>
>>> > On May 27, 2017, at 12:49 PM, li li <hannah.hlx at gmail.com> wrote:
>>> >
>>> > Hi all,
>>> >  Is there an R function that can be used to enumerate all the
>>> contingency
>>> > tables with fixed row and column margins. For example, can we list
>all
>>> 3 by
>>> > 3 tables with row margins 3,6,6 and column margins 5,5,5.
>>>
>>> The Posting Guide suggests that you describe the results of your
>efforts
>>> at searching:
>>>
>>> https://www.google.com/search?q=use+r%3Alang+to+enumerate+co
>>> ntingency+tables+with+fixed+margins&oq=use+r%3Alang+to+enume
>>> rate+contingency+tables+with+fixed+margins&aqs=chrome..
>>> 69i57.35014j0j4&sourceid=chrome&ie=UTF-8
>>>
>>> >   Thanks very much!
>>> >   Hanna
>>> >
>>> >       [[alternative HTML version deleted]]
>>>
>>> And (yet again) you are asked to post in plain text.
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat May 27 19:41:24 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 27 May 2017 10:41:24 -0700
Subject: [R] Need Help To Solve An Equation In R
In-Reply-To: <CACnkotqnfDeL0BpmZ7R_oMehF4VjV-KBtqbK-rzbZsqw_NUQjw@mail.gmail.com>
References: <CACnkotqnfDeL0BpmZ7R_oMehF4VjV-KBtqbK-rzbZsqw_NUQjw@mail.gmail.com>
Message-ID: <CAGxFJbQ1odFQmnXP7fUX947sSkdDBXi8Z56jD-dpzEn5VCfSHw@mail.gmail.com>

Homework? We generally don't do homework here.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 27, 2017 at 9:16 AM, Neetu Shah <nshah.0452 at gmail.com> wrote:
> Dear Sir/Ma'am,
>
> I am trying to make a function to solve an equation that is given below:
> findH <- function(p_star, k){
> fun <- function(y){
> (pnorm(y+h))^(k-1)*dnorm(y)
> }
> lhs <- integrate(fun, -Inf, Inf)$value
> return(uniroot(lhs, lower = -10, upper = 10,
> tol = p_star)$root)
> }
> In lhs, I integrated a function with respect to y and there would be an
> unknown h that I need to find.
> I need to equate this lhs to p_star value in order to find h. Which
> function should I use to solve this equation?
> Please guide me regarding this.
> Thank you.
>
> --
> With Regards,
> Neetu Shah,
> B.Tech.(CS),
> 3rd Year,
> IIIT Vadodara.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat May 27 20:54:50 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 27 May 2017 11:54:50 -0700
Subject: [R] Need Help To Solve An Equation In R
In-Reply-To: <CACnkotqvJDzQcAjYP567BrPCot6WTOYYGz1tFH=XHtf7FX7r2A@mail.gmail.com>
References: <CACnkotqnfDeL0BpmZ7R_oMehF4VjV-KBtqbK-rzbZsqw_NUQjw@mail.gmail.com>
 <CAGxFJbQ1odFQmnXP7fUX947sSkdDBXi8Z56jD-dpzEn5VCfSHw@mail.gmail.com>
 <CACnkotqvJDzQcAjYP567BrPCot6WTOYYGz1tFH=XHtf7FX7r2A@mail.gmail.com>
Message-ID: <CAGxFJbRJ1qBY-s5TjCoo5UHa59_urnG-DDDy2KzUUEwfSg0xyw@mail.gmail.com>

Then:

1. Always cc the list;

2. Read and follow the posting guide: no HTML, plain text only.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, May 27, 2017 at 11:05 AM, Neetu Shah <nshah.0452 at gmail.com> wrote:
> Dear Sir,
>
> It is not homework. I am trying to develop a library in R as my project. My
> mentor said to ask this doubt on R forum. As I am not able to solve that
> equation in R. I need to know the alternative for uniroot function. Please
> help me regarding this.
>
>
> --
> With Regards,
> Neetu Shah,
> B.Tech.(CS),
> 3rd Year,
> IIIT Vadodara.
>
>
> On Sat, May 27, 2017 at 11:11 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>>
>> Homework? We generally don't do homework here.
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, May 27, 2017 at 9:16 AM, Neetu Shah <nshah.0452 at gmail.com> wrote:
>> > Dear Sir/Ma'am,
>> >
>> > I am trying to make a function to solve an equation that is given below:
>> > findH <- function(p_star, k){
>> > fun <- function(y){
>> > (pnorm(y+h))^(k-1)*dnorm(y)
>> > }
>> > lhs <- integrate(fun, -Inf, Inf)$value
>> > return(uniroot(lhs, lower = -10, upper = 10,
>> > tol = p_star)$root)
>> > }
>> > In lhs, I integrated a function with respect to y and there would be an
>> > unknown h that I need to find.
>> > I need to equate this lhs to p_star value in order to find h. Which
>> > function should I use to solve this equation?
>> > Please guide me regarding this.
>> > Thank you.
>> >
>> > --
>> > With Regards,
>> > Neetu Shah,
>> > B.Tech.(CS),
>> > 3rd Year,
>> > IIIT Vadodara.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>


From sepp9000 at yahoo.de  Sat May 27 23:29:53 2017
From: sepp9000 at yahoo.de (Sepp)
Date: Sat, 27 May 2017 21:29:53 +0000 (UTC)
Subject: [R] rollapply() produces NAs
References: <2052121563.2007006.1495920593348.ref@mail.yahoo.com>
Message-ID: <2052121563.2007006.1495920593348@mail.yahoo.com>

Hello,
I am fairly new to R and trying to calculate value at risk with exponentially decreasing weights.My function works for a single vector of returns but does not work with rollapply(), which is what I want to use. The function I am working on should assig exponentially decreasing weights to the K most recent returns and then order the returns in an ascending order. Subsequently it should pick the last return for which the cumulative sum of the weights is smaller or equal to a significance level. Thus, I am trying to construct a cumulative distribution function and find a quantile.
This is the function I wrote:
VaRfun <- function(x, lambda = 0.94) {
#create data.frame and order returns such that the lates return is the first? df <- data.frame(weight = c(1:length(x)), return = rev(x))? K <- nrow(df)? constant <- (1-lambda)/(1-lambda^(K))#assign weights to the returns ?? for(i in 1:nrow(df)) {? ? df$weight[i] <- lambda^(i-1) * constant? ? }#order returns in an ascending order? df <- df[order(df$return),]
#add the cumulative sum of the weights? df$cum.weight <- cumsum(df$weight)
#calculate value at risk? VaR <- -tail((df$return[df$cum.weight <= .05]), 1)? signif(VaR, digits = 3)}
It works for a single vector of returns but if I try to use it with rollapply(), such as
rollapply(r, width = list(-500, -1), FUN = VaRfun),
it outputs a vector of NAs and I don't know why.
Thank you for your help!
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun May 28 08:07:29 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 27 May 2017 23:07:29 -0700
Subject: [R] creat contingency tables with fixed row and column margins
In-Reply-To: <CAHLnndbP-=B6C6t0boBc9pSCmva7ka9Ok2V1TBjD9pFOs_2GuQ@mail.gmail.com>
References: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>
 <14B9A2C6-1D2E-4E10-9A75-C76D6EADA211@comcast.net>
 <CAHLnndYAG58Lrg-SQsMT-BA89A8tf230koLjnWDh3xyPHZto2w@mail.gmail.com>
 <CAHLnndbP-=B6C6t0boBc9pSCmva7ka9Ok2V1TBjD9pFOs_2GuQ@mail.gmail.com>
Message-ID: <A06722C6-7685-4311-B832-A894AB11525C@comcast.net>


> On May 27, 2017, at 1:54 PM, li li <hannah.hlx at gmail.com> wrote:
> 
> I meant that the post in your link above was NOT asked by me.
> 
> 2017-05-27 16:53 GMT-04:00 li li <hannah.hlx at gmail.com>:
> Hi Dave,
>   Thanks for your reply but the post in your link above was certainly asked by me.
>    Hanna
> 

I really have no idea what either of those sentences above might mean. I offered what I thought was one obvious effort at searching for a method to accomplish the task set forth in you subject line, but was leaving it up to you to take steps forward to advance the process. It might also help to explain the purpose of this effort.

-- 
David.

> 2017-05-27 16:04 GMT-04:00 David Winsemius <dwinsemius at comcast.net>:
> 
> > On May 27, 2017, at 12:49 PM, li li <hannah.hlx at gmail.com> wrote:
> >
> > Hi all,
> >  Is there an R function that can be used to enumerate all the contingency
> > tables with fixed row and column margins. For example, can we list all 3 by
> > 3 tables with row margins 3,6,6 and column margins 5,5,5.
> 
> The Posting Guide suggests that you describe the results of your efforts at searching:
> 
> https://www.google.com/search?q=use+r%3Alang+to+enumerate+contingency+tables+with+fixed+margins&oq=use+r%3Alang+to+enumerate+contingency+tables+with+fixed+margins&aqs=chrome..69i57.35014j0j4&sourceid=chrome&ie=UTF-8
> 
> >   Thanks very much!
> >   Hanna
> >
> >       [[alternative HTML version deleted]]
> 
> And (yet again) you are asked to post in plain text.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 

David Winsemius
Alameda, CA, USA


From ken.knoblauch at inserm.fr  Sun May 28 09:38:09 2017
From: ken.knoblauch at inserm.fr (Kenneth Knoblauch)
Date: Sun, 28 May 2017 09:38:09 +0200
Subject: [R]  Need Help To Solve An Equation In R
Message-ID: <80694eaf0536833c98b7fdb09404695e@inserm.fr>

This looks an awful lot like you are trying to solve for d' in an 
m-alternative forced choice experiment for an unbiased observer.  Try 
the function dprime.mAFC from the psyphy package.  For comparison with 
your example, it's code is:

  psyphy:::dprime.mAFC
function (Pc, m)
{
     m <- as.integer(m)
     if (m < 2)
         stop("m must be an integer greater than 1")
     if (!is.integer(m))
         stop("m must be an integer")
     if (Pc <= 0 || Pc >= 1)
         stop("Pc must be in (0,1)")
     est.dp <- function(dp) {
         pr <- function(x) dnorm(x - dp) * pnorm(x)^(m - 1)
         Pc - integrate(pr, lower = -Inf, upper = Inf)$value
     }
     dp.res <- uniroot(est.dp, interval = c(-10, 10))
     dp.res$root
}
<environment: namespace:psyphy>

Hope that helps,

best,

Ken


On Sat, May 27, 2017 at 9:16 AM, Neetu Shah <nshah.0452 at gmail.com> 
wrote:
> Dear Sir/Ma'am,
> 
> I am trying to make a function to solve an equation that is given 
> below:
> findH <- function(p_star, k){
> fun <- function(y){
> (pnorm(y+h))^(k-1)*dnorm(y)
> }
> lhs <- integrate(fun, -Inf, Inf)$value
> return(uniroot(lhs, lower = -10, upper = 10,
> tol = p_star)$root)
> }
> In lhs, I integrated a function with respect to y and there would be an
> unknown h that I need to find.
> I need to equate this lhs to p_star value in order to find h. Which
> function should I use to solve this equation?
> Please guide me regarding this.
> Thank you.
> 
> --
> With Regards,
> Neetu Shah,
> B.Tech.(CS),
> 3rd Year,
> IIIT Vadodara.
-- 
Kenneth Knoblauch
Inserm U1208
Stem-cell and Brain Research Institute
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From ashimkapoor at gmail.com  Sun May 28 09:55:09 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 28 May 2017 13:25:09 +0530
Subject: [R] Analysing the output from skmeans/clustering
Message-ID: <CAC8=1epP1gmWGy+scY7a_yNOKgE_0CuJWpe9nEZRyvyQNomZnA@mail.gmail.com>

Dear All,

Here is a small example:

library(skmeans)
library(tm)
data("crude")
#Examine the first document
inspect(crude[[1]])

dtm <- DocumentTermMatrix(crude, control =
                           list(removePunctuation = TRUE,
                               removeNumbers = TRUE,
                                stopwords = TRUE))
clus <- skmeans(dtm,3)
names(clus)

Is there any way I can get the document number of the  prototypes ? Also
can I get the 3 closest documents to each prototype ? By prototype I mean
the cluster centers.

I know can compare each row of the DocumentTermMatrix with the prototypes
to test for equality and I can manually compute the distance of each
Document from a prototypes,but I was wondering if such a tool already
exists.

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Sun May 28 16:15:28 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 28 May 2017 10:15:28 -0400
Subject: [R] rollapply() produces NAs
In-Reply-To: <2052121563.2007006.1495920593348@mail.yahoo.com>
References: <2052121563.2007006.1495920593348.ref@mail.yahoo.com>
 <2052121563.2007006.1495920593348@mail.yahoo.com>
Message-ID: <CAP01uRkLwAtO_zzQ15eW1BQ3Ru9GJp+vrt7Qo4gL9NRw7wQRnw@mail.gmail.com>

Maybe you want this.It computes VaRfun(r[c(i-500, i-1)] for each i for
which the argument to r makes sense.

rollapply(r, width = list(c(-500, -1)), FUN = VaRfun),

On Sat, May 27, 2017 at 5:29 PM, Sepp via R-help <r-help at r-project.org> wrote:
> Hello,
> I am fairly new to R and trying to calculate value at risk with exponentially decreasing weights.My function works for a single vector of returns but does not work with rollapply(), which is what I want to use. The function I am working on should assig exponentially decreasing weights to the K most recent returns and then order the returns in an ascending order. Subsequently it should pick the last return for which the cumulative sum of the weights is smaller or equal to a significance level. Thus, I am trying to construct a cumulative distribution function and find a quantile.
> This is the function I wrote:
> VaRfun <- function(x, lambda = 0.94) {
> #create data.frame and order returns such that the lates return is the first  df <- data.frame(weight = c(1:length(x)), return = rev(x))  K <- nrow(df)  constant <- (1-lambda)/(1-lambda^(K))#assign weights to the returns    for(i in 1:nrow(df)) {    df$weight[i] <- lambda^(i-1) * constant    }#order returns in an ascending order  df <- df[order(df$return),]
> #add the cumulative sum of the weights  df$cum.weight <- cumsum(df$weight)
> #calculate value at risk  VaR <- -tail((df$return[df$cum.weight <= .05]), 1)  signif(VaR, digits = 3)}
> It works for a single vector of returns but if I try to use it with rollapply(), such as
> rollapply(r, width = list(-500, -1), FUN = VaRfun),
> it outputs a vector of NAs and I don't know why.
> Thank you for your help!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From lorenzo.isella at gmail.com  Sun May 28 17:26:22 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sun, 28 May 2017 17:26:22 +0200
Subject: [R] Spacing Between Elements in Lattice Legend
Message-ID: <20170528152622.GA1872@chicca>

Dear All,
Please consider the short code at the end of the email.
It generates a barchart where everything is as I want, apart from some
minor tuning of the legend.
I can control the spacing between the text in the two rows of the
legend, but how do I force some separation between the red and the
blue rectangles in the legend?
Any suggestion is welcome.
Cheers

Lorenzo

###############################################

library(lattice)
library(latticeExtra)


df_tot<-structure(list(country = structure(c(13L, 1L, 3L, 21L, 12L, 6L,
22L, 14L, 19L, 20L, 4L, 16L, 9L, 11L, 18L, 17L, 7L, 8L, 2L, 15L,
10L, 5L, 13L, 1L, 23L, 21L, 12L, 6L, 22L, 14L, 19L, 20L, 4L,
16L, 9L, 11L, 24L, 18L, 25L, 28L, 26L, 17L, 7L, 8L, 2L, 27L,
15L, 10L), .Label = c("BE", "PT", "CZ", "EL", "TR", "EE", "NO",
"PL", "IE", "SI", "IL", "DK", "AT", "FI", "SE", "HU", "NL", "IT",
"FR", "UK", "DE", "ES", "CY", "IS", "LT", "MT", "RS", "LV"), class =
"factor"),
    number = c(12L, 1L, 2L, 42L, 11L, 4L, 78L, 12L, 35L, 41L,
        2L, 21L, 8L, 9L, 25L, 24L, 4L, 4L, 1L, 12L, 8L, 3L, 5L, 1L,
	    1L, 32L, 16L, 3L, 75L, 20L, 16L, 29L, 3L, 9L, 10L, 5L, 1L,
	        33L, 1L, 2L, 1L, 6L, 7L, 2L, 3L, 1L, 11L, 3L), year =
		c(2015,
		    2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015,
		    2015, 2015,
		        2015, 2015, 2015, 2015, 2015, 2015, 2015,
			2015, 2015, 2015,
			    2015, 2016, 2016, 2016, 2016, 2016, 2016,
			    2016, 2016, 2016,
			        2016, 2016, 2016, 2016, 2016, 2016,
				2016, 2016, 2016, 2016,
				    2016, 2016, 2016, 2016, 2016,
				    2016, 2016)), .Names =
				    c("country",
				    "number", "year"), row.names =
				    c(NA, -48L), class = "data.frame")
				    


p1 <- barchart(number ~ country ,
              groups= as.factor(year),
	                     data = df_tot## ,
			                    , origin=0, spect="fill",

             par.settings = c(ggplot2like(col=c("blue", "red"))),
	                    axis = axis.grid, xlab=list("Number of
	                    Beneficiaries", cex=1.2),
	                    ylab=list("Country", cex=1.2),##
	                    main=NULL,
			                   main=list(NULL),between =
	                    list(x = 1),
			      scales=list(cex=1), auto.key =
	                    list(title = "Year",
	                    columns=1,space="right",padding.text=3)
			                   )
					   pdf("beneficiaries_all2.pdf",
	                    width=15, height=5)
			    print(p1)
			    dev.off()


From glennmschultz at me.com  Sun May 28 16:51:42 2017
From: glennmschultz at me.com (Glenn Schultz)
Date: Sun, 28 May 2017 14:51:42 +0000 (GMT)
Subject: [R] get the value of a biplane
Message-ID: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>

If is specify a spline basis as follows

knots <- c(6, 12, 22, 30, 35)
x <- c(0.0, .25, 1.0, 2.0, 3.0)
SCurve <- bs(x = x, knots = knots, intercept = FALSE, Boundary.knots = c(0,3.5))

I would like to now get the spline value for new values of x. ?However, when I use predict the new basis is returned and I would like to get the value. ?Nothing has worked so far and ?predict plus examples only show prediction from linear models. ?Is there a way to extract the value from a defined spline?

Best Regards,
Glenn

From sepp9000 at yahoo.de  Sun May 28 16:58:59 2017
From: sepp9000 at yahoo.de (Sepp)
Date: Sun, 28 May 2017 14:58:59 +0000 (UTC)
Subject: [R] rollapply() produces NAs
In-Reply-To: <CAP01uRkLwAtO_zzQ15eW1BQ3Ru9GJp+vrt7Qo4gL9NRw7wQRnw@mail.gmail.com>
References: <2052121563.2007006.1495920593348.ref@mail.yahoo.com>
 <2052121563.2007006.1495920593348@mail.yahoo.com>
 <CAP01uRkLwAtO_zzQ15eW1BQ3Ru9GJp+vrt7Qo4gL9NRw7wQRnw@mail.gmail.com>
Message-ID: <793299582.2553166.1495983539982@mail.yahoo.com>

This is exactly what I want. However, with my function it produces a vector of NAs ...


Gabor Grothendieck <ggrothendieck at gmail.com> schrieb am 16:23 Sonntag, 28.Mai 2017:



Maybe you want this.It computes VaRfun(r[c(i-500, i-1)] for each i for
which the argument to r makes sense.

rollapply(r, width = list(c(-500, -1)), FUN = VaRfun),


On Sat, May 27, 2017 at 5:29 PM, Sepp via R-help <r-help at r-project.org> wrote:
> Hello,
> I am fairly new to R and trying to calculate value at risk with exponentially decreasing weights.My function works for a single vector of returns but does not work with rollapply(), which is what I want to use. The function I am working on should assig exponentially decreasing weights to the K most recent returns and then order the returns in an ascending order. Subsequently it should pick the last return for which the cumulative sum of the weights is smaller or equal to a significance level. Thus, I am trying to construct a cumulative distribution function and find a quantile.
> This is the function I wrote:
> VaRfun <- function(x, lambda = 0.94) {
> #create data.frame and order returns such that the lates return is the first  df <- data.frame(weight = c(1:length(x)), return = rev(x))  K <- nrow(df)  constant <- (1-lambda)/(1-lambda^(K))#assign weights to the returns    for(i in 1:nrow(df)) {    df$weight[i] <- lambda^(i-1) * constant    }#order returns in an ascending order  df <- df[order(df$return),]
> #add the cumulative sum of the weights  df$cum.weight <- cumsum(df$weight)
> #calculate value at risk  VaR <- -tail((df$return[df$cum.weight <= .05]), 1)  signif(VaR, digits = 3)}
> It works for a single vector of returns but if I try to use it with rollapply(), such as
> rollapply(r, width = list(-500, -1), FUN = VaRfun),
> it outputs a vector of NAs and I don't know why.
> Thank you for your help!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ruipbarradas at sapo.pt  Sun May 28 18:37:07 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 28 May 2017 17:37:07 +0100
Subject: [R] get the value of a biplane
In-Reply-To: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
References: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
Message-ID: <592AFCB3.9020108@sapo.pt>

Hello,

Since function splines::bs returns an object of class bs in order to 
read the help page for function predict you need

?predict.bs

The syntax would be

## S3 method for class 'bs'
predict(object, newx, ...)

Please read that help page and maybe you'll get the answer you need.

Hope this helps,

Rui Barradas

Em 28-05-2017 15:51, Glenn Schultz escreveu:
> If is specify a spline basis as follows
>
> knots <- c(6, 12, 22, 30, 35)
> x <- c(0.0, .25, 1.0, 2.0, 3.0)
> SCurve <- bs(x = x, knots = knots, intercept = FALSE, Boundary.knots =
> c(0,3.5))
>
> I would like to now get the spline value for new values of x.  However,
> when I use predict the new basis is returned and I would like to get the
> value.  Nothing has worked so far and ?predict plus examples only show
> prediction from linear models.  Is there a way to extract the value from
> a defined spline?
>
> Best Regards,
> Glenn
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun May 28 18:41:57 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 28 May 2017 09:41:57 -0700
Subject: [R] Fwd:  Spacing Between Elements in Lattice Legend
In-Reply-To: <CAGxFJbSTv_SebvA-mZdJ_Smm9dDebc4VViQ7C9183rrVvFXypg@mail.gmail.com>
References: <20170528152622.GA1872@chicca>
 <CAGxFJbSTv_SebvA-mZdJ_Smm9dDebc4VViQ7C9183rrVvFXypg@mail.gmail.com>
Message-ID: <CAGxFJbTt5Amm6R+3+R8VBpXkxdmNjs5shoioEGNd_2aW_3QGHg@mail.gmail.com>

(forgot to cc the list!)

-- Bert



---------- Forwarded message ----------
From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Sun, May 28, 2017 at 9:41 AM
Subject: Re: [R] Spacing Between Elements in Lattice Legend
To: Lorenzo Isella <lorenzo.isella at gmail.com>


See the "border" and "lwd" arguments in ?panel.barchart (checking the
panel function help for your display is always a good idea for such
questions).

Adding:

border = "lightgray", lwd=1,

to your call would seem to give what you want. (modify appropriately
to meet your aesthetic preferences).

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 28, 2017 at 8:26 AM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> Please consider the short code at the end of the email.
> It generates a barchart where everything is as I want, apart from some
> minor tuning of the legend.
> I can control the spacing between the text in the two rows of the
> legend, but how do I force some separation between the red and the
> blue rectangles in the legend?
> Any suggestion is welcome.
> Cheers
>
> Lorenzo
>
> ###############################################
>
> library(lattice)
> library(latticeExtra)
>
>
> df_tot<-structure(list(country = structure(c(13L, 1L, 3L, 21L, 12L, 6L,
> 22L, 14L, 19L, 20L, 4L, 16L, 9L, 11L, 18L, 17L, 7L, 8L, 2L, 15L,
> 10L, 5L, 13L, 1L, 23L, 21L, 12L, 6L, 22L, 14L, 19L, 20L, 4L,
> 16L, 9L, 11L, 24L, 18L, 25L, 28L, 26L, 17L, 7L, 8L, 2L, 27L,
> 15L, 10L), .Label = c("BE", "PT", "CZ", "EL", "TR", "EE", "NO",
> "PL", "IE", "SI", "IL", "DK", "AT", "FI", "SE", "HU", "NL", "IT",
> "FR", "UK", "DE", "ES", "CY", "IS", "LT", "MT", "RS", "LV"), class =
> "factor"),
>    number = c(12L, 1L, 2L, 42L, 11L, 4L, 78L, 12L, 35L, 41L,
>        2L, 21L, 8L, 9L, 25L, 24L, 4L, 4L, 1L, 12L, 8L, 3L, 5L, 1L,
>             1L, 32L, 16L, 3L, 75L, 20L, 16L, 29L, 3L, 9L, 10L, 5L, 1L,
>                 33L, 1L, 2L, 1L, 6L, 7L, 2L, 3L, 1L, 11L, 3L), year =
>                 c(2015,
>                     2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015,
>                     2015, 2015,
>                         2015, 2015, 2015, 2015, 2015, 2015, 2015,
>                         2015, 2015, 2015,
>                             2015, 2016, 2016, 2016, 2016, 2016, 2016,
>                             2016, 2016, 2016,
>                                 2016, 2016, 2016, 2016, 2016, 2016,
>                                 2016, 2016, 2016, 2016,
>                                     2016, 2016, 2016, 2016, 2016,
>                                     2016, 2016)), .Names =
>                                     c("country",
>                                     "number", "year"), row.names =
>                                     c(NA, -48L), class = "data.frame")
>
>
> p1 <- barchart(number ~ country ,
>              groups= as.factor(year),
>                              data = df_tot## ,
>                                             , origin=0, spect="fill",
>
>             par.settings = c(ggplot2like(col=c("blue", "red"))),
>                             axis = axis.grid, xlab=list("Number of
>                             Beneficiaries", cex=1.2),
>                             ylab=list("Country", cex=1.2),##
>                             main=NULL,
>                                            main=list(NULL),between =
>                             list(x = 1),
>                               scales=list(cex=1), auto.key =
>                             list(title = "Year",
>                             columns=1,space="right",padding.text=3)
>                                            )
>                                            pdf("beneficiaries_all2.pdf",
>                             width=15, height=5)
>                             print(p1)
>                             dev.off()
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun May 28 19:45:33 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 28 May 2017 10:45:33 -0700
Subject: [R] rollapply() produces NAs
In-Reply-To: <793299582.2553166.1495983539982@mail.yahoo.com>
References: <2052121563.2007006.1495920593348.ref@mail.yahoo.com>
 <2052121563.2007006.1495920593348@mail.yahoo.com>
 <CAP01uRkLwAtO_zzQ15eW1BQ3Ru9GJp+vrt7Qo4gL9NRw7wQRnw@mail.gmail.com>
 <793299582.2553166.1495983539982@mail.yahoo.com>
Message-ID: <D228A419-B06C-4F06-BC77-4FE815D731BB@dcn.davis.ca.us>

You will get better help if you read the Posting Guide mentioned at the foot if every posting including this one carefully and pay attention. 

A) You need to post in plain text, as your code came through the mailing list damaged.

B) You need to include sample data and make your code run from a clean R environment. See [1][2][3].

C) You need to make sure your function returns sensible results for short input vectors or input vectors with NA in them, as rollapply/embed need to be told how to handle the beginning/end of the series. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html
-- 
Sent from my phone. Please excuse my brevity.

On May 28, 2017 7:58:59 AM PDT, Sepp via R-help <r-help at r-project.org> wrote:
>This is exactly what I want. However, with my function it produces a
>vector of NAs ...
>
>
>Gabor Grothendieck <ggrothendieck at gmail.com> schrieb am 16:23 Sonntag,
>28.Mai 2017:
>
>
>
>Maybe you want this.It computes VaRfun(r[c(i-500, i-1)] for each i for
>which the argument to r makes sense.
>
>rollapply(r, width = list(c(-500, -1)), FUN = VaRfun),
>
>
>On Sat, May 27, 2017 at 5:29 PM, Sepp via R-help <r-help at r-project.org>
>wrote:
>> Hello,
>> I am fairly new to R and trying to calculate value at risk with
>exponentially decreasing weights.My function works for a single vector
>of returns but does not work with rollapply(), which is what I want to
>use. The function I am working on should assig exponentially decreasing
>weights to the K most recent returns and then order the returns in an
>ascending order. Subsequently it should pick the last return for which
>the cumulative sum of the weights is smaller or equal to a significance
>level. Thus, I am trying to construct a cumulative distribution
>function and find a quantile.
>> This is the function I wrote:
>> VaRfun <- function(x, lambda = 0.94) {
>> #create data.frame and order returns such that the lates return is
>the first  df <- data.frame(weight = c(1:length(x)), return = rev(x)) 
>K <- nrow(df)  constant <- (1-lambda)/(1-lambda^(K))#assign weights to
>the returns    for(i in 1:nrow(df)) {    df$weight[i] <- lambda^(i-1) *
>constant    }#order returns in an ascending order  df <-
>df[order(df$return),]
>> #add the cumulative sum of the weights  df$cum.weight <-
>cumsum(df$weight)
>> #calculate value at risk  VaR <- -tail((df$return[df$cum.weight <=
>.05]), 1)  signif(VaR, digits = 3)}
>> It works for a single vector of returns but if I try to use it with
>rollapply(), such as
>> rollapply(r, width = list(-500, -1), FUN = VaRfun),
>> it outputs a vector of NAs and I don't know why.
>> Thank you for your help!
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gdraisma at xs4all.nl  Sun May 28 20:44:51 2017
From: gdraisma at xs4all.nl (Gerrit Draisma)
Date: Sun, 28 May 2017 20:44:51 +0200
Subject: [R] Problem with Example with Lattice
In-Reply-To: <mailman.1.1495965601.20575.r-help@r-project.org>
References: <mailman.1.1495965601.20575.r-help@r-project.org>
Message-ID: <7df217f4-eac2-0a72-4c28-f9cefa97f7b8@xs4all.nl>

Hallo Lorenzo,
In addition to Berts advice
try
 > trellis.par.get("superpose.symbol")
which shows the default for superposed graphics
and set them with the par.settings parameter
 > dotplot(VADeaths, type = "o",
+ auto.key = list(lines = TRUE, space = "right"),
+ main = "Death Rates in Virginia - 1940",
+ par.settings=list(superpose.symbol=list(pch=1:4)),
+ xlab = "Rate (per 1000)")

Gerrit

On 05/28/2017 12:00 PM, r-help-request at r-project.org wrote:
> Re: Problem with Example with Lattice


From erinm.hodgess at gmail.com  Sun May 28 20:48:42 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 28 May 2017 13:48:42 -0500
Subject: [R] finding components of an API
Message-ID: <CACxE24nHJ-xq3H8W=zdQLmFdAvGxxp840S1q8=9P-1fnAqEaNA@mail.gmail.com>

Hello!

I would like to use a particular API for crimes (spot crimes) but I can't
find what components go into the API.  I have gone into the website,but to
no avail

Has anyone used it please?

Thank you,
Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun May 28 21:19:06 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 28 May 2017 12:19:06 -0700
Subject: [R] finding components of an API
In-Reply-To: <CACxE24nHJ-xq3H8W=zdQLmFdAvGxxp840S1q8=9P-1fnAqEaNA@mail.gmail.com>
References: <CACxE24nHJ-xq3H8W=zdQLmFdAvGxxp840S1q8=9P-1fnAqEaNA@mail.gmail.com>
Message-ID: <3C779009-EEC2-41AF-80F9-23E068A17DC1@dcn.davis.ca.us>

Can you please be just a little less vague? What API are you talking about, and how is this related to R?
-- 
Sent from my phone. Please excuse my brevity.

On May 28, 2017 11:48:42 AM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello!
>
>I would like to use a particular API for crimes (spot crimes) but I
>can't
>find what components go into the API.  I have gone into the website,but
>to
>no avail
>
>Has anyone used it please?
>
>Thank you,
>Sincerely,
>Erin


From erinm.hodgess at gmail.com  Sun May 28 22:45:18 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 28 May 2017 15:45:18 -0500
Subject: [R] finding components of an API
In-Reply-To: <3C779009-EEC2-41AF-80F9-23E068A17DC1@dcn.davis.ca.us>
References: <CACxE24nHJ-xq3H8W=zdQLmFdAvGxxp840S1q8=9P-1fnAqEaNA@mail.gmail.com>
 <3C779009-EEC2-41AF-80F9-23E068A17DC1@dcn.davis.ca.us>
Message-ID: <CACxE24m=_GrcHEdKCvRcVXr_W8DHYV9x9NrPG7ipLC+LLzaKmg@mail.gmail.com>

Sorry!!!

It's spotcrime.com, and I would like to use it via R for crimes.



On Sun, May 28, 2017 at 2:19 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Can you please be just a little less vague? What API are you talking
> about, and how is this related to R?
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 28, 2017 11:48:42 AM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >Hello!
> >
> >I would like to use a particular API for crimes (spot crimes) but I
> >can't
> >find what components go into the API.  I have gone into the website,but
> >to
> >no avail
> >
> >Has anyone used it please?
> >
> >Thank you,
> >Sincerely,
> >Erin
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May 29 00:11:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 28 May 2017 15:11:36 -0700
Subject: [R] Spacing Between Elements in Lattice Legend
In-Reply-To: <20170528200636.GB1872@chicca>
References: <20170528152622.GA1872@chicca>
 <CAGxFJbSTv_SebvA-mZdJ_Smm9dDebc4VViQ7C9183rrVvFXypg@mail.gmail.com>
 <20170528200636.GB1872@chicca>
Message-ID: <CAGxFJbQL2qshCjMnqFtfiOLUOW=RMPzbFPrCLSTHK4hg8YSoDQ@mail.gmail.com>

1. Always cc the list, which I have done here (unless you want to say
something that truly should be private).

2. Ahh... I see. I don't believe you can do it using auto.key, which
feeds it's list to the simpleKey() function: the price you pay for
keeping it simple is that you lack fine control over details such as
the rectangle height, which is (I believe) what you want. If you
replace the auto.key=  list via the following key= list, I think you
get what you want by controlling rectangle height to your taste: e.g.

key =               list(title = "Year",
                       text = list(c("2015","2016")),
                       rectangles = list(height=.5,
                           col= c("blue","red")),
                       columns=1,space="right",padding.text=3)


If this is *NOT* what you want, do cc the list in any reply.


Oh, and incidentally, your code mistakenly had the "main" argument replicated.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, May 28, 2017 at 1:06 PM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Thanks for the suggestion, but it is not what I want.
> I do not want to have a separation of the rectangles in the main plot,
> but only in the legend generated by my example.
> Any idea about how to achieve that?
>
> Lorenzo
>
>
> On Sun, May 28, 2017 at 09:41:10AM -0700, Bert Gunter wrote:
>>
>> See the "border" and "lwd" arguments in ?panel.barchart (checking the
>> panel function help for your display is always a good idea for such
>> questions).
>>
>> Adding:
>>
>> border = "lightgray", lwd=1,
>>
>> to your call would seem to give what you want. (modify appropriately
>> to meet your aesthetic preferences).
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, May 28, 2017 at 8:26 AM, Lorenzo Isella
>> <lorenzo.isella at gmail.com> wrote:
>>>
>>> Dear All,
>>> Please consider the short code at the end of the email.
>>> It generates a barchart where everything is as I want, apart from some
>>> minor tuning of the legend.
>>> I can control the spacing between the text in the two rows of the
>>> legend, but how do I force some separation between the red and the
>>> blue rectangles in the legend?
>>> Any suggestion is welcome.
>>> Cheers
>>>
>>> Lorenzo
>>>
>>> ###############################################
>>>
>>> library(lattice)
>>> library(latticeExtra)
>>>
>>>
>>> df_tot<-structure(list(country = structure(c(13L, 1L, 3L, 21L, 12L, 6L,
>>> 22L, 14L, 19L, 20L, 4L, 16L, 9L, 11L, 18L, 17L, 7L, 8L, 2L, 15L,
>>> 10L, 5L, 13L, 1L, 23L, 21L, 12L, 6L, 22L, 14L, 19L, 20L, 4L,
>>> 16L, 9L, 11L, 24L, 18L, 25L, 28L, 26L, 17L, 7L, 8L, 2L, 27L,
>>> 15L, 10L), .Label = c("BE", "PT", "CZ", "EL", "TR", "EE", "NO",
>>> "PL", "IE", "SI", "IL", "DK", "AT", "FI", "SE", "HU", "NL", "IT",
>>> "FR", "UK", "DE", "ES", "CY", "IS", "LT", "MT", "RS", "LV"), class =
>>> "factor"),
>>>    number = c(12L, 1L, 2L, 42L, 11L, 4L, 78L, 12L, 35L, 41L,
>>>        2L, 21L, 8L, 9L, 25L, 24L, 4L, 4L, 1L, 12L, 8L, 3L, 5L, 1L,
>>>             1L, 32L, 16L, 3L, 75L, 20L, 16L, 29L, 3L, 9L, 10L, 5L, 1L,
>>>                 33L, 1L, 2L, 1L, 6L, 7L, 2L, 3L, 1L, 11L, 3L), year =
>>>                 c(2015,
>>>                     2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015,
>>>                     2015, 2015,
>>>                         2015, 2015, 2015, 2015, 2015, 2015, 2015,
>>>                         2015, 2015, 2015,
>>>                             2015, 2016, 2016, 2016, 2016, 2016, 2016,
>>>                             2016, 2016, 2016,
>>>                                 2016, 2016, 2016, 2016, 2016, 2016,
>>>                                 2016, 2016, 2016, 2016,
>>>                                     2016, 2016, 2016, 2016, 2016,
>>>                                     2016, 2016)), .Names =
>>>                                     c("country",
>>>                                     "number", "year"), row.names =
>>>                                     c(NA, -48L), class = "data.frame")
>>>
>>>
>>> p1 <- barchart(number ~ country ,
>>>              groups= as.factor(year),
>>>                              data = df_tot## ,
>>>                                             , origin=0, spect="fill",
>>>
>>>             par.settings = c(ggplot2like(col=c("blue", "red"))),
>>>                             axis = axis.grid, xlab=list("Number of
>>>                             Beneficiaries", cex=1.2),
>>>                             ylab=list("Country", cex=1.2),##
>>>                             main=NULL,
>>>                                            main=list(NULL),between =
>>>                             list(x = 1),
>>>                               scales=list(cex=1), auto.key =
>>>                             list(title = "Year",
>>>                             columns=1,space="right",padding.text=3)
>>>                                            )
>>>                                            pdf("beneficiaries_all2.pdf",
>>>                             width=15, height=5)
>>>                             print(p1)
>>>                             dev.off()
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From rsherry8 at comcast.net  Mon May 29 02:51:20 2017
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sun, 28 May 2017 20:51:20 -0400
Subject: [R] finding components of an API
In-Reply-To: <CACxE24m=_GrcHEdKCvRcVXr_W8DHYV9x9NrPG7ipLC+LLzaKmg@mail.gmail.com>
References: <CACxE24nHJ-xq3H8W=zdQLmFdAvGxxp840S1q8=9P-1fnAqEaNA@mail.gmail.com>
 <3C779009-EEC2-41AF-80F9-23E068A17DC1@dcn.davis.ca.us>
 <CACxE24m=_GrcHEdKCvRcVXr_W8DHYV9x9NrPG7ipLC+LLzaKmg@mail.gmail.com>
Message-ID: <a8348de4-c938-6342-869a-c705cc54f64f@comcast.net>

Erin,

I do not think there is an R package that will enable you to get the 
data you would like from spotcrime.com.

You could write code, in R, or some other language, to extract the data 
you want but that is going to be a changeling  task and if
the website changes its format then your code may suddenly stop working. 
Also, the people who run spotcrime.com may not be happy if you do so.

Bob

On 5/28/2017 4:45 PM, Erin Hodgess wrote:
> Sorry!!!
>
> It's spotcrime.com, and I would like to use it via R for crimes.
>
>
>
> On Sun, May 28, 2017 at 2:19 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> Can you please be just a little less vague? What API are you talking
>> about, and how is this related to R?
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On May 28, 2017 11:48:42 AM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
>> wrote:
>>> Hello!
>>>
>>> I would like to use a particular API for crimes (spot crimes) but I
>>> can't
>>> find what components go into the API.  I have gone into the website,but
>>> to
>>> no avail
>>>
>>> Has anyone used it please?
>>>
>>> Thank you,
>>> Sincerely,
>>> Erin
>
>


From erinm.hodgess at gmail.com  Mon May 29 03:16:35 2017
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 28 May 2017 20:16:35 -0500
Subject: [R] finding components of an API
In-Reply-To: <a8348de4-c938-6342-869a-c705cc54f64f@comcast.net>
References: <CACxE24nHJ-xq3H8W=zdQLmFdAvGxxp840S1q8=9P-1fnAqEaNA@mail.gmail.com>
 <3C779009-EEC2-41AF-80F9-23E068A17DC1@dcn.davis.ca.us>
 <CACxE24m=_GrcHEdKCvRcVXr_W8DHYV9x9NrPG7ipLC+LLzaKmg@mail.gmail.com>
 <a8348de4-c938-6342-869a-c705cc54f64f@comcast.net>
Message-ID: <A68E7C4D-47B0-4E84-B262-FCFDD56A733F@gmail.com>

I have actually just figured it out with some help from a JS website . Was going to post the solution but maybe I shouldn't ? 


Sent from my iPhone

> On May 28, 2017, at 7:51 PM, Robert Sherry <rsherry8 at comcast.net> wrote:
> 
> Erin,
> 
> I do not think there is an R package that will enable you to get the data you would like from spotcrime.com.
> 
> You could write code, in R, or some other language, to extract the data you want but that is going to be a changeling  task and if
> the website changes its format then your code may suddenly stop working. Also, the people who run spotcrime.com may not be happy if you do so.
> 
> Bob
> 
>> On 5/28/2017 4:45 PM, Erin Hodgess wrote:
>> Sorry!!!
>> 
>> It's spotcrime.com, and I would like to use it via R for crimes.
>> 
>> 
>> 
>> On Sun, May 28, 2017 at 2:19 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> 
>>> Can you please be just a little less vague? What API are you talking
>>> about, and how is this related to R?
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On May 28, 2017 11:48:42 AM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
>>> wrote:
>>>> Hello!
>>>> 
>>>> I would like to use a particular API for crimes (spot crimes) but I
>>>> can't
>>>> find what components go into the API.  I have gone into the website,but
>>>> to
>>>> no avail
>>>> 
>>>> Has anyone used it please?
>>>> 
>>>> Thank you,
>>>> Sincerely,
>>>> Erin
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at effectivedefense.org  Mon May 29 03:51:43 2017
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sun, 28 May 2017 20:51:43 -0500
Subject: [R] finding components of an API
In-Reply-To: <A68E7C4D-47B0-4E84-B262-FCFDD56A733F@gmail.com>
References: <CACxE24nHJ-xq3H8W=zdQLmFdAvGxxp840S1q8=9P-1fnAqEaNA@mail.gmail.com>
 <3C779009-EEC2-41AF-80F9-23E068A17DC1@dcn.davis.ca.us>
 <CACxE24m=_GrcHEdKCvRcVXr_W8DHYV9x9NrPG7ipLC+LLzaKmg@mail.gmail.com>
 <a8348de4-c938-6342-869a-c705cc54f64f@comcast.net>
 <A68E7C4D-47B0-4E84-B262-FCFDD56A733F@gmail.com>
Message-ID: <90a29d72-be25-79a0-871d-2de26e69fcac@effectivedefense.org>



On 2017-05-28 8:16 PM, Erin Hodgess wrote:
> I have actually just figured it out with some help from a JS website . Was going to post the solution but maybe I shouldn't ?


       Have you considered contacting them and asking at 
"https://spotcrime.com/contact.php"?


       The web site does not contain copyright information that I can 
find.  Their "Terms of Use" (https://spotcrime.com/tos) says, "You will 
not ... distribute any files ... where it is possible that ... any of 
the Website may be used to distribute copyrighted materials to or from 
persons who are not authorized to receive, copy, distribute or use 
them."  I suggest you contact them.  Explain this could make it easier 
for people to use their data and promote their web site.


       The "Ecfun" package contains various "read*" functions that 
scrape data from different web sites. If spotcrime.com says it's OK to 
access their web site as you have AND you'd like to add a function to do 
this to the "Ecfun" package, please go to R-Forge, find the "Ecdat" 
project, and "request to join"  I will approve.


       Spencer Graves
>
> Sent from my iPhone
>
>> On May 28, 2017, at 7:51 PM, Robert Sherry <rsherry8 at comcast.net> wrote:
>>
>> Erin,
>>
>> I do not think there is an R package that will enable you to get the data you would like from spotcrime.com.
>>
>> You could write code, in R, or some other language, to extract the data you want but that is going to be a changeling  task and if
>> the website changes its format then your code may suddenly stop working. Also, the people who run spotcrime.com may not be happy if you do so.
>>
>> Bob
>>
>>> On 5/28/2017 4:45 PM, Erin Hodgess wrote:
>>> Sorry!!!
>>>
>>> It's spotcrime.com, and I would like to use it via R for crimes.
>>>
>>>
>>>
>>> On Sun, May 28, 2017 at 2:19 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>>> Can you please be just a little less vague? What API are you talking
>>>> about, and how is this related to R?
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On May 28, 2017 11:48:42 AM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
>>>> wrote:
>>>>> Hello!
>>>>>
>>>>> I would like to use a particular API for crimes (spot crimes) but I
>>>>> can't
>>>>> find what components go into the API.  I have gone into the website,but
>>>>> to
>>>>> no avail
>>>>>
>>>>> Has anyone used it please?
>>>>>
>>>>> Thank you,
>>>>> Sincerely,
>>>>> Erin
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sepp9000 at yahoo.de  Sun May 28 17:57:03 2017
From: sepp9000 at yahoo.de (Sepp)
Date: Sun, 28 May 2017 15:57:03 +0000 (UTC)
Subject: [R] rollapply() produces NAs
In-Reply-To: <793299582.2553166.1495983539982@mail.yahoo.com>
References: <2052121563.2007006.1495920593348.ref@mail.yahoo.com>
 <2052121563.2007006.1495920593348@mail.yahoo.com>
 <CAP01uRkLwAtO_zzQ15eW1BQ3Ru9GJp+vrt7Qo4gL9NRw7wQRnw@mail.gmail.com>
 <793299582.2553166.1495983539982@mail.yahoo.com>
Message-ID: <1614151048.2548235.1495987023114@mail.yahoo.com>

This is the function in plain text because it looked messy before:

VaRfun <- function(x, lambda = 0.94) {

#create data.frame and order returns such that the lates return is the first
  df <- data.frame(weight = c(1:length(x)), return = rev(x))
  K <- nrow(df)
  constant <- (1-lambda)/(1-lambda^(K))
#assign weights to the returns  
  for(i in 1:nrow(df)) {
    df$weight[i] <- lambda^(i-1) * constant
    }
#order returns in an ascending order
  df <- df[order(df$return),]

#add the cumulative sum of the weights
  df$cum.weight <- cumsum(df$weight)

#calculate value at risk
  VaR <- -tail((df$return[df$cum.weight <= .05]), 1)
  signif(VaR, digits = 3)
}

It works for a single vector of returns but if I try to use it with rollapply(), such as

rollapply(r, width = list(-500, -1), FUN = VaRfun),

it outputs a vector of NAs and I don't know why.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mcheung63 at hotmail.com  Sun May 28 20:12:45 2017
From: mcheung63 at hotmail.com (Peter Cheung)
Date: Sun, 28 May 2017 18:12:45 +0000
Subject: [R] Need help for Netbeans R plugin development
Message-ID: <HK2PR0401MB14273418E183E38F23DBF5ABB5F20@HK2PR0401MB1427.apcprd04.prod.outlook.com>

Hi
   My name is Peter, developing R plugin for netbeans, it is entirely in Java. What is the best way to interact Java with R and how can I hook some R functions such as plot()? so everytime plot() is called and i can capture the generated graph.
thanks
from Peter

From ruipbarradas at sapo.pt  Sun May 28 22:53:29 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 28 May 2017 21:53:29 +0100
Subject: [R] get the value of a biplane
In-Reply-To: <592AFCB3.9020108@sapo.pt>
References: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
 <592AFCB3.9020108@sapo.pt>
Message-ID: <592B38C9.5080701@sapo.pt>

Hello,

Can anyone explain why this error?

 > library(splines)
 >
 > knots <- c(6, 12, 22, 30, 35)
 > x <- c(0.0, .25, 1.0, 2.0, 3.0)
 > SCurve <- bs(x = x, knots = knots, intercept = FALSE, Boundary.knots 
= c(0,3.5))
 > class(SCurve)
[1] "bs"     "basis"  "matrix"
 >
 > ?predict.bs
 > predict.bs(SCurve, xnew = 40:45)
Error in predict.bs(SCurve, xnew = 40:45) :
   could not find function "predict.bs"

Note that splines:::predict.bs(SCurve, xnew = 40:45) works.

 > sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

loaded via a namespace (and not attached):
[1] compiler_3.4.0 tools_3.4.0


Rui Barradas


Em 28-05-2017 17:37, Rui Barradas escreveu:
> Hello,
>
> Since function splines::bs returns an object of class bs in order to
> read the help page for function predict you need
>
> ?predict.bs
>
> The syntax would be
>
> ## S3 method for class 'bs'
> predict(object, newx, ...)
>
> Please read that help page and maybe you'll get the answer you need.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 28-05-2017 15:51, Glenn Schultz escreveu:
>> If is specify a spline basis as follows
>>
>> knots <- c(6, 12, 22, 30, 35)
>> x <- c(0.0, .25, 1.0, 2.0, 3.0)
>> SCurve <- bs(x = x, knots = knots, intercept = FALSE, Boundary.knots =
>> c(0,3.5))
>>
>> I would like to now get the spline value for new values of x.  However,
>> when I use predict the new basis is returned and I would like to get the
>> value.  Nothing has worked so far and ?predict plus examples only show
>> prediction from linear models.  Is there a way to extract the value from
>> a defined spline?
>>
>> Best Regards,
>> Glenn
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon May 29 08:35:55 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 28 May 2017 23:35:55 -0700
Subject: [R] get the value of a biplane
In-Reply-To: <592B38C9.5080701@sapo.pt>
References: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
 <592AFCB3.9020108@sapo.pt> <592B38C9.5080701@sapo.pt>
Message-ID: <5A090C49-35A5-4195-AF29-31D24AF2C7F6@dcn.davis.ca.us>

Looks like it is not exported from the package namespace... a packaging error. 
-- 
Sent from my phone. Please excuse my brevity.

On May 28, 2017 1:53:29 PM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>Can anyone explain why this error?
>
> > library(splines)
> >
> > knots <- c(6, 12, 22, 30, 35)
> > x <- c(0.0, .25, 1.0, 2.0, 3.0)
>> SCurve <- bs(x = x, knots = knots, intercept = FALSE, Boundary.knots 
>= c(0,3.5))
> > class(SCurve)
>[1] "bs"     "basis"  "matrix"
> >
> > ?predict.bs
> > predict.bs(SCurve, xnew = 40:45)
>Error in predict.bs(SCurve, xnew = 40:45) :
>   could not find function "predict.bs"
>
>Note that splines:::predict.bs(SCurve, xnew = 40:45) works.
>
> > sessionInfo()
>R version 3.4.0 (2017-04-21)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>Matrix products: default
>
>locale:
>[1] LC_COLLATE=Portuguese_Portugal.1252 
>LC_CTYPE=Portuguese_Portugal.1252
>[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 
>
>[5] LC_TIME=Portuguese_Portugal.1252
>
>attached base packages:
>[1] splines   stats     graphics  grDevices utils     datasets  methods
>[8] base
>
>loaded via a namespace (and not attached):
>[1] compiler_3.4.0 tools_3.4.0
>
>
>Rui Barradas
>
>
>Em 28-05-2017 17:37, Rui Barradas escreveu:
>> Hello,
>>
>> Since function splines::bs returns an object of class bs in order to
>> read the help page for function predict you need
>>
>> ?predict.bs
>>
>> The syntax would be
>>
>> ## S3 method for class 'bs'
>> predict(object, newx, ...)
>>
>> Please read that help page and maybe you'll get the answer you need.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 28-05-2017 15:51, Glenn Schultz escreveu:
>>> If is specify a spline basis as follows
>>>
>>> knots <- c(6, 12, 22, 30, 35)
>>> x <- c(0.0, .25, 1.0, 2.0, 3.0)
>>> SCurve <- bs(x = x, knots = knots, intercept = FALSE, Boundary.knots
>=
>>> c(0,3.5))
>>>
>>> I would like to now get the spline value for new values of x. 
>However,
>>> when I use predict the new basis is returned and I would like to get
>the
>>> value.  Nothing has worked so far and ?predict plus examples only
>show
>>> prediction from linear models.  Is there a way to extract the value
>from
>>> a defined spline?
>>>
>>> Best Regards,
>>> Glenn
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Mon May 29 10:22:25 2017
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 29 May 2017 10:22:25 +0200
Subject: [R] Spacing Between Elements in Lattice Legend
In-Reply-To: <CAGxFJbQL2qshCjMnqFtfiOLUOW=RMPzbFPrCLSTHK4hg8YSoDQ@mail.gmail.com>
References: <20170528152622.GA1872@chicca>
 <CAGxFJbSTv_SebvA-mZdJ_Smm9dDebc4VViQ7C9183rrVvFXypg@mail.gmail.com>
 <20170528200636.GB1872@chicca>
 <CAGxFJbQL2qshCjMnqFtfiOLUOW=RMPzbFPrCLSTHK4hg8YSoDQ@mail.gmail.com>
Message-ID: <20170529082225.GA5921@chicca2>




Hello,
It was a matter of introducing a height parameter.
This code at the end provides me exactly with what I need.
Cheers

Lorenzo

#############################################################?

barchart(
  number ~ country ,
    	   groups = as.factor(year),
      	   data = df_tot,
           origin = 0,
	   aspect = "fill",
	   par.settings = c(ggplot2like(col = c("blue", "red"))),
	   axis = axis.grid,
	   xlab = list("Number of Beneficiaries", cex = 1.2),
	   ylab = list("Country", cex = 1.2),
	   main = list(NULL),
	   between = list(x = 1),
           scales = list(cex = 1),
	   auto.key = list(
	   title = "Year",
	   height = 0.8,
	   columns = 1,
	   space = "right",
	   padding.text =3
      )
      )
      




On Sun, May 28, 2017 at 03:11:36PM -0700, Bert Gunter wrote:
>1. Always cc the list, which I have done here (unless you want to say
>something that truly should be private).
>
>2. Ahh... I see. I don't believe you can do it using auto.key, which
>feeds it's list to the simpleKey() function: the price you pay for
>keeping it simple is that you lack fine control over details such as
>the rectangle height, which is (I believe) what you want. If you
>replace the auto.key=  list via the following key= list, I think you
>get what you want by controlling rectangle height to your taste: e.g.
>
>key =               list(title = "Year",
>                       text = list(c("2015","2016")),
>                       rectangles = list(height=.5,
>                           col= c("blue","red")),
>                       columns=1,space="right",padding.text=3)
>
>
>If this is *NOT* what you want, do cc the list in any reply.
>
>
>Oh, and incidentally, your code mistakenly had the "main" argument replicated.
>
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, May 28, 2017 at 1:06 PM, Lorenzo Isella
><lorenzo.isella at gmail.com> wrote:
>> Thanks for the suggestion, but it is not what I want.
>> I do not want to have a separation of the rectangles in the main plot,
>> but only in the legend generated by my example.
>> Any idea about how to achieve that?
>>
>> Lorenzo
>>
>>
>> On Sun, May 28, 2017 at 09:41:10AM -0700, Bert Gunter wrote:
>>>
>>> See the "border" and "lwd" arguments in ?panel.barchart (checking the
>>> panel function help for your display is always a good idea for such
>>> questions).
>>>
>>> Adding:
>>>
>>> border = "lightgray", lwd=1,
>>>
>>> to your call would seem to give what you want. (modify appropriately
>>> to meet your aesthetic preferences).
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sun, May 28, 2017 at 8:26 AM, Lorenzo Isella
>>> <lorenzo.isella at gmail.com> wrote:
>>>>
>>>> Dear All,
>>>> Please consider the short code at the end of the email.
>>>> It generates a barchart where everything is as I want, apart from some
>>>> minor tuning of the legend.
>>>> I can control the spacing between the text in the two rows of the
>>>> legend, but how do I force some separation between the red and the
>>>> blue rectangles in the legend?
>>>> Any suggestion is welcome.
>>>> Cheers
>>>>
>>>> Lorenzo
>>>>
>>>> ###############################################
>>>>
>>>> library(lattice)
>>>> library(latticeExtra)
>>>>
>>>>
>>>> df_tot<-structure(list(country = structure(c(13L, 1L, 3L, 21L, 12L, 6L,
>>>> 22L, 14L, 19L, 20L, 4L, 16L, 9L, 11L, 18L, 17L, 7L, 8L, 2L, 15L,
>>>> 10L, 5L, 13L, 1L, 23L, 21L, 12L, 6L, 22L, 14L, 19L, 20L, 4L,
>>>> 16L, 9L, 11L, 24L, 18L, 25L, 28L, 26L, 17L, 7L, 8L, 2L, 27L,
>>>> 15L, 10L), .Label = c("BE", "PT", "CZ", "EL", "TR", "EE", "NO",
>>>> "PL", "IE", "SI", "IL", "DK", "AT", "FI", "SE", "HU", "NL", "IT",
>>>> "FR", "UK", "DE", "ES", "CY", "IS", "LT", "MT", "RS", "LV"), class =
>>>> "factor"),
>>>>    number = c(12L, 1L, 2L, 42L, 11L, 4L, 78L, 12L, 35L, 41L,
>>>>        2L, 21L, 8L, 9L, 25L, 24L, 4L, 4L, 1L, 12L, 8L, 3L, 5L, 1L,
>>>>             1L, 32L, 16L, 3L, 75L, 20L, 16L, 29L, 3L, 9L, 10L, 5L, 1L,
>>>>                 33L, 1L, 2L, 1L, 6L, 7L, 2L, 3L, 1L, 11L, 3L), year =
>>>>                 c(2015,
>>>>                     2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015,
>>>>                     2015, 2015,
>>>>                         2015, 2015, 2015, 2015, 2015, 2015, 2015,
>>>>                         2015, 2015, 2015,
>>>>                             2015, 2016, 2016, 2016, 2016, 2016, 2016,
>>>>                             2016, 2016, 2016,
>>>>                                 2016, 2016, 2016, 2016, 2016, 2016,
>>>>                                 2016, 2016, 2016, 2016,
>>>>                                     2016, 2016, 2016, 2016, 2016,
>>>>                                     2016, 2016)), .Names =
>>>>                                     c("country",
>>>>                                     "number", "year"), row.names =
>>>>                                     c(NA, -48L), class = "data.frame")
>>>>
>>>>
>>>> p1 <- barchart(number ~ country ,
>>>>              groups= as.factor(year),
>>>>                              data = df_tot## ,
>>>>                                             , origin=0, spect="fill",
>>>>
>>>>             par.settings = c(ggplot2like(col=c("blue", "red"))),
>>>>                             axis = axis.grid, xlab=list("Number of
>>>>                             Beneficiaries", cex=1.2),
>>>>                             ylab=list("Country", cex=1.2),##
>>>>                             main=NULL,
>>>>                                            main=list(NULL),between =
>>>>                             list(x = 1),
>>>>                               scales=list(cex=1), auto.key =
>>>>                             list(title = "Year",
>>>>                             columns=1,space="right",padding.text=3)
>>>>                                            )
>>>>                                            pdf("beneficiaries_all2.pdf",
>>>>                             width=15, height=5)
>>>>                             print(p1)
>>>>                             dev.off()
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon May 29 11:43:22 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 May 2017 05:43:22 -0400
Subject: [R] get the value of a biplane
In-Reply-To: <5A090C49-35A5-4195-AF29-31D24AF2C7F6@dcn.davis.ca.us>
References: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
 <592AFCB3.9020108@sapo.pt> <592B38C9.5080701@sapo.pt>
 <5A090C49-35A5-4195-AF29-31D24AF2C7F6@dcn.davis.ca.us>
Message-ID: <6ecfb1b5-585d-d2ef-d707-7019f2e06dc1@gmail.com>


On May 28, 2017 1:53:29 PM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>  > predict.bs(SCurve, xnew = 40:45)
> Error in predict.bs(SCurve, xnew = 40:45) :
>    could not find function "predict.bs"

You should call it using the generic, i.e.

predict(SCurve, xnew = 40:45)


On 29/05/2017 2:35 AM, Jeff Newmiller wrote:
> Looks like it is not exported from the package namespace... a packaging error.
>

It's not an error to rely on the generic to get to a method.

Duncan Murdoch


From ruipbarradas at sapo.pt  Mon May 29 11:58:21 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 29 May 2017 10:58:21 +0100
Subject: [R] get the value of a biplane
In-Reply-To: <6ecfb1b5-585d-d2ef-d707-7019f2e06dc1@gmail.com>
References: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
 <592AFCB3.9020108@sapo.pt> <592B38C9.5080701@sapo.pt>
 <5A090C49-35A5-4195-AF29-31D24AF2C7F6@dcn.davis.ca.us>
 <6ecfb1b5-585d-d2ef-d707-7019f2e06dc1@gmail.com>
Message-ID: <592BF0BD.70805@sapo.pt>

Hello,

Em 29-05-2017 10:43, Duncan Murdoch escreveu:
>
> On May 28, 2017 1:53:29 PM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>  > predict.bs(SCurve, xnew = 40:45)
>> Error in predict.bs(SCurve, xnew = 40:45) :
>>    could not find function "predict.bs"
>
> You should call it using the generic, i.e.
>
> predict(SCurve, xnew = 40:45)

Thanks, I should have tested that. Just did and it (obviously) worked, 
giving the same result as splines:::predict.bs(...).

Rui Barradas
>
>
> On 29/05/2017 2:35 AM, Jeff Newmiller wrote:
>> Looks like it is not exported from the package namespace... a
>> packaging error.
>>
>
> It's not an error to rely on the generic to get to a method.
>
> Duncan Murdoch


From jeddite4 at gmail.com  Mon May 29 12:23:52 2017
From: jeddite4 at gmail.com (Krzysiek Gniady)
Date: Mon, 29 May 2017 12:23:52 +0200
Subject: [R] R - datatable formatting with javascript
In-Reply-To: <CAHyXxWPNd-VK6NC3ffPdP4B1kBObKxof-2S3T63ASk4jfhu0-g@mail.gmail.com>
References: <CAHyXxWPNd-VK6NC3ffPdP4B1kBObKxof-2S3T63ASk4jfhu0-g@mail.gmail.com>
Message-ID: <CAHyXxWN491ivkMh38F6k9qOj2H5P3hG1YRGRKpbfh1xVgqZW3w@mail.gmail.com>

Can anybody help with this problem?

2017-05-22 11:32 GMT+02:00 Krzysiek Gniady <jeddite4 at gmail.com>:

> I'm trying to format datatable in R using DT package. I have code like
> this:
>
> library(data.table)
> library(DT)
> data<-data.table(rbind(c(1,2,3),c(4,5,6)))
> colnames(data)<- c('A','B','c')
>
> datatable(data, rownames=F,
>       colnames=c('A','B','C'),
>       class='stripe cell-border hover',
>       options=list(
>         pageLength=100,
>         dom='ltp',
>         initComplete = JS("
>                           function(settings, json) {
>                           $(this.api().table().body()).css({
>                           'background-color': 'red',
>                           'outline-color': 'red',
>                           'margin':'100px',
>                           'color': 'violet',
>                           'text-align': 'center',
>                           'font-family': 'Courier New',
>                           'border-radius': '25px'
>                           });
>                           $(this.api().table().header()).css({
>                           'background-color': '#000',
>                           'color': '#fff',
>                           'outline-color': 'red',
>                           'margin':'100px',
>                           'text-align': 'center',
>                           'font-family': 'Courier New',
>                           'border-radius': '25px'
>                           });
>                           }
>                           ")
>         ),
>       caption = htmltools::tags$caption(
>         style = 'caption-side: top; text-align: center; color:black;
>         font-size:200% ;','Table'),
>       filter=list(position = 'top')
>       )
>
> And I have problem with javascript in function JS(). It modifies
> background color (but only in header), font color and style. But commands
> to align text or round corners don't work.
>
> Why does it work like that? And how can I modify code to format this other
> things?
>
>
> Regards,
>
> Jeddite
>

	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Mon May 29 13:41:49 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Mon, 29 May 2017 06:41:49 -0500
Subject: [R] Need help for Netbeans R plugin development
In-Reply-To: <HK2PR0401MB14273418E183E38F23DBF5ABB5F20@HK2PR0401MB1427.apcprd04.prod.outlook.com>
References: <HK2PR0401MB14273418E183E38F23DBF5ABB5F20@HK2PR0401MB1427.apcprd04.prod.outlook.com>
Message-ID: <b5ccc64a-3f2c-ba19-53e7-1864d925f069@atsu.edu>

rJava and Rserve might be architectures of interest.


On 5/28/2017 1:12 PM, Peter Cheung wrote:
> Hi
>     My name is Peter, developing R plugin for netbeans, it is entirely in Java. What is the best way to interact Java with R and how can I hook some R functions such as plot()? so everytime plot() is called and i can capture the generated graph.
> thanks
> from Peter
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From brigitte.mangin at inra.fr  Mon May 29 08:53:18 2017
From: brigitte.mangin at inra.fr (Brigitte Mangin)
Date: Mon, 29 May 2017 06:53:18 +0000
Subject: [R] R-help Digest, Vol 171, Issue 20
In-Reply-To: <D549AD20.A170%lfslbx@live.warwick.ac.uk>
References: <mailman.1.1495274401.24720.r-help@r-project.org>,
 <D549AD20.A170%lfslbx@live.warwick.ac.uk>
Message-ID: <1496040798457.90001@inra.fr>

Thanks Ron,

In fact, I want to make a model choice using different fixed structures and using the results of:
Gurka MJ (2006) Selecting the best linear mixed model under reml. The American Statistician 60(1):19{26,
the best criterium uses the reml likelihood.

I asked the ASREML-r developpers and they answered that their results were checked against GENSTAT.

I think it is not really a good think for the R community to compute a REML likelihood that is probably not the REML likelihood.

Brigitte



Brigitte Mangin, INRA, LIPM, CS 52627, 31326 CASTANET-TOLOSAN
tel: 33 + (0)5 61 28 54 58

________________________________________
De : Crump, Ron <R.E.Crump at warwick.ac.uk>
Envoy? : mardi 23 mai 2017 10:29
? : r-help at r-project.org; Brigitte Mangin
Objet : Re: R-help Digest, Vol 171, Issue 20

Hi Brigitte,

>Did somebody know why asreml does not provide the same REML loglikehood
>as coxme, lme4 or lmne.

I don't know the answer to this, but I'd guess it is either to do with the
use of the average information REML algorithm or asreml-r is for some
reason ending up with a different subset of the data.

>If it was just a constant value between the two models (with or without
>the fixed effect) it would not be important. But it is not.
>I checked that the variance component estimators were equal.

I'm still not clear that it is important (if the data subset analysed is
the same). You would only use the REML likelihoods to compare models with
different random effects and the same fixed effect structure (is there
another use for the REML likelihood other than that?), so then it is
really a question of whether for a given pair of random effect models and
the same data the likelihood ratio test statistic  changes across analysis
methods. Unless for some reason you are comparing two random effect models
fitted with different routines (one of which is asreml-r).

Ron.



From jdnewmil at dcn.davis.ca.us  Mon May 29 21:15:55 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 29 May 2017 12:15:55 -0700
Subject: [R] get the value of a biplane
In-Reply-To: <6ecfb1b5-585d-d2ef-d707-7019f2e06dc1@gmail.com>
References: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
 <592AFCB3.9020108@sapo.pt> <592B38C9.5080701@sapo.pt>
 <5A090C49-35A5-4195-AF29-31D24AF2C7F6@dcn.davis.ca.us>
 <6ecfb1b5-585d-d2ef-d707-7019f2e06dc1@gmail.com>
Message-ID: <8AB0D79D-8D83-4367-9BD0-ABFB73D61A9E@dcn.davis.ca.us>

Well, then I will hedge by saying that IN MY OPINION it is an error, because when it isn't exported the arguments not specified in the generic cannot be visible for argument completion in editors.  The predict.lm function specifies new data with the newdata argument, while the predict.bs function specifies it with the newx argument. Invoking with the generic is supposed be useful when trying out a variety of models, but being unable to generically specify a data frame (due to the inconsistent naming) blows that strategy to pieces anyway so you might as well be able to call the functions explicitly.
-- 
Sent from my phone. Please excuse my brevity.

On May 29, 2017 2:43:22 AM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>On May 28, 2017 1:53:29 PM PDT, Rui Barradas <ruipbarradas at sapo.pt>
>wrote:
>>  > predict.bs(SCurve, xnew = 40:45)
>> Error in predict.bs(SCurve, xnew = 40:45) :
>>    could not find function "predict.bs"
>
>You should call it using the generic, i.e.
>
>predict(SCurve, xnew = 40:45)
>
>
>On 29/05/2017 2:35 AM, Jeff Newmiller wrote:
>> Looks like it is not exported from the package namespace... a
>packaging error.
>>
>
>It's not an error to rely on the generic to get to a method.
>
>Duncan Murdoch


From murdoch.duncan at gmail.com  Mon May 29 22:16:53 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 May 2017 16:16:53 -0400
Subject: [R] get the value of a biplane
In-Reply-To: <8AB0D79D-8D83-4367-9BD0-ABFB73D61A9E@dcn.davis.ca.us>
References: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
 <592AFCB3.9020108@sapo.pt> <592B38C9.5080701@sapo.pt>
 <5A090C49-35A5-4195-AF29-31D24AF2C7F6@dcn.davis.ca.us>
 <6ecfb1b5-585d-d2ef-d707-7019f2e06dc1@gmail.com>
 <8AB0D79D-8D83-4367-9BD0-ABFB73D61A9E@dcn.davis.ca.us>
Message-ID: <7f534939-aa77-4855-3e11-1f4cf37f2fce@gmail.com>

On 29/05/2017 3:15 PM, Jeff Newmiller wrote:
> Well, then I will hedge by saying that IN MY OPINION it is an error, because when it isn't exported the arguments not specified in the generic cannot be visible for argument completion in editors.

But that's not true.  If you want the arguments , use

args(getS3method("predict", class(x)))

where x is your bs() object.  RStudio appears to make use of something 
like this.  R.app on MacOS and Rgui on Windows does something different, 
I think not as effectively. I don't know about other editors.

(BTW, I think the getS3method function has a bug:  if you change the x 
object to have class c("foobar", class(x)), it *does* fail, even though 
predict(x, ...)  will still work.)

  The predict.lm function specifies new data with the newdata argument, 
while the predict.bs function specifies it with the newx argument. 
Invoking with the generic is supposed be useful when trying out a 
variety of models, but being unable to generically specify a data frame 
(due to the inconsistent naming) blows that strategy to pieces anyway so 
you might as well be able to call the functions explicitly.
>

In RStudio, if you set x <- bs(1:10), then type

predict(x,

and hit TAB, you are offered "object", "newx" and "..." as choices.  On 
the other editors I mentioned you appear to get a list of argument names 
for all possible methods regardless of the class of x.

Duncan murdoch


From dwinsemius at comcast.net  Mon May 29 21:42:30 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 29 May 2017 12:42:30 -0700
Subject: [R] R-help Digest, Vol 171, Issue 20
In-Reply-To: <1496040798457.90001@inra.fr>
References: <mailman.1.1495274401.24720.r-help@r-project.org>
 <D549AD20.A170%lfslbx@live.warwick.ac.uk> <1496040798457.90001@inra.fr>
Message-ID: <4C4720B0-FA1C-42B9-8CC2-66720F9DDF7C@comcast.net>


> On May 28, 2017, at 11:53 PM, Brigitte Mangin <brigitte.mangin at inra.fr> wrote:
> 
> Thanks Ron,
> 
> In fact, I want to make a model choice using different fixed structures and using the results of:
> Gurka MJ (2006) Selecting the best linear mixed model under reml. The American Statistician 60(1):19{26,
> the best criterium uses the reml likelihood.
> 
> I asked the ASREML-r developpers and they answered that their results were checked against GENSTAT.
> 
> I think it is not really a good think for the R community to compute a REML likelihood that is probably not the REML likelihood.

Is it your understanding that REML values should be different somehow than other likelihoods with respect to the fact that you should only be comparing _differences_ in model likelihoods calculated on the same data? The value of a likelihood is only specified up to a constant (as Thierry Onkelinx already pointed out.)

I can get different deviances (-2*log(likelihood) in glm poisson models by just grouping data elements and modeling counts. But varying models will have the same differences in deviance regardless of grouping or not.

Looking at this copy of that citation It appears to me that differences (comparing full to reduced) in various criteria for models is what is under discussion:

http://users.jyu.fi/~hemipu/itms/Gurka%202006,%20TAS,%20REML.pdf

You should show some results rather than letting this discussion remain so vague.

-- 
David.


> 
> Brigitte
> 
> 
> 
> Brigitte Mangin, INRA, LIPM, CS 52627, 31326 CASTANET-TOLOSAN
> tel: 33 + (0)5 61 28 54 58
> 
> ________________________________________
> De : Crump, Ron <R.E.Crump at warwick.ac.uk>
> Envoy? : mardi 23 mai 2017 10:29
> ? : r-help at r-project.org; Brigitte Mangin
> Objet : Re: R-help Digest, Vol 171, Issue 20
> 
> Hi Brigitte,
> 
>> Did somebody know why asreml does not provide the same REML loglikehood
>> as coxme, lme4 or lmne.
> 
> I don't know the answer to this, but I'd guess it is either to do with the
> use of the average information REML algorithm or asreml-r is for some
> reason ending up with a different subset of the data.
> 
>> If it was just a constant value between the two models (with or without
>> the fixed effect) it would not be important. But it is not.
>> I checked that the variance component estimators were equal.
> 
> I'm still not clear that it is important (if the data subset analysed is
> the same). You would only use the REML likelihoods to compare models with
> different random effects and the same fixed effect structure (is there
> another use for the REML likelihood other than that?), so then it is
> really a question of whether for a given pair of random effect models and
> the same data the likelihood ratio test statistic  changes across analysis
> methods. Unless for some reason you are comparing two random effect models
> fitted with different routines (one of which is asreml-r).
> 
> Ron.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From maggieymakar at gmail.com  Mon May 29 22:14:26 2017
From: maggieymakar at gmail.com (Maggie Makar)
Date: Mon, 29 May 2017 16:14:26 -0400
Subject: [R] Disable weight re-scaling in GLMNET
Message-ID: <D551F962.1C76C%maggieymakar@gmail.com>

Hi all, 
Wondering if there is a way to disable observation weight re-scaling (such
that it adds to N of observations) in glmnet without having to delve into
the fortran code/ minimal edits to fortran code?
Thanks 
Maggie 






	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon May 29 22:51:22 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 29 May 2017 13:51:22 -0700
Subject: [R] get the value of a biplane
In-Reply-To: <7f534939-aa77-4855-3e11-1f4cf37f2fce@gmail.com>
References: <db6d1b76-2d69-4c81-928a-6908ad00d85b@me.com>
 <592AFCB3.9020108@sapo.pt> <592B38C9.5080701@sapo.pt>
 <5A090C49-35A5-4195-AF29-31D24AF2C7F6@dcn.davis.ca.us>
 <6ecfb1b5-585d-d2ef-d707-7019f2e06dc1@gmail.com>
 <8AB0D79D-8D83-4367-9BD0-ABFB73D61A9E@dcn.davis.ca.us>
 <7f534939-aa77-4855-3e11-1f4cf37f2fce@gmail.com>
Message-ID: <778CDE1F-2000-4301-91CE-FBA14825DDB1@comcast.net>


> On May 29, 2017, at 1:16 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 29/05/2017 3:15 PM, Jeff Newmiller wrote:
>> Well, then I will hedge by saying that IN MY OPINION it is an error, because when it isn't exported the arguments not specified in the generic cannot be visible for argument completion in editors.
> 
> But that's not true.  If you want the arguments , use
> 
> args(getS3method("predict", class(x)))
> 
> where x is your bs() object.  RStudio appears to make use of something like this.  R.app on MacOS and Rgui on Windows does something different, I think not as effectively.

I think R.app uses rcompgen {utils}. Fortunately a deficit in my aging memory was filled in because typing `?completion` brought up the correct help page. I was not so lucky in trying to find reference to that function in the R for MacOS FAQ.

-- 
David.
> I don't know about other editors.
> 
> (BTW, I think the getS3method function has a bug:  if you change the x object to have class c("foobar", class(x)), it *does* fail, even though predict(x, ...)  will still work.)
> 
> The predict.lm function specifies new data with the newdata argument, while the predict.bs function specifies it with the newx argument. Invoking with the generic is supposed be useful when trying out a variety of models, but being unable to generically specify a data frame (due to the inconsistent naming) blows that strategy to pieces anyway so you might as well be able to call the functions explicitly.
>> 
> 
> In RStudio, if you set x <- bs(1:10), then type
> 
> predict(x,
> 
> and hit TAB, you are offered "object", "newx" and "..." as choices.  On the other editors I mentioned you appear to get a list of argument names for all possible methods regardless of the class of x.
> 
> Duncan murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tanasa at gmail.com  Mon May 29 22:53:33 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Mon, 29 May 2017 13:53:33 -0700
Subject: [R] about Rstudio
Message-ID: <CA+JEM00s=nk5SZLWtGxvJJG-AiAgu=nEy51Sc=Zy3v4gFxDM-w@mail.gmail.com>

Dear all,

please could you help with an advice : I have installed Rstudio on my
Ubuntu PC, and when I initiate the application, it says :

 "R lib path(/usr/local/lib/R/lib) not found"

on my computer, at the path "/usr/local/lib/R/lib" there are the folders :
bin
etc
site-library

R is installed in another folder that is "/home/bogdan/R".

how could I fix the error please ? many thanks,

--bogdan

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon May 29 23:04:23 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 May 2017 14:04:23 -0700
Subject: [R] about Rstudio
In-Reply-To: <CA+JEM00s=nk5SZLWtGxvJJG-AiAgu=nEy51Sc=Zy3v4gFxDM-w@mail.gmail.com>
References: <CA+JEM00s=nk5SZLWtGxvJJG-AiAgu=nEy51Sc=Zy3v4gFxDM-w@mail.gmail.com>
Message-ID: <CAGxFJbQOw6ySL27uwShYh7QB4LXpAh9xfCE5U8O2Bf=31y3JGA@mail.gmail.com>

1, SHouldn't you be posting this on the R Studio support site, not here?

2. I googled on :

 "R lib path(/usr/local/lib/R/lib) not found" Ubuntu

and got what looked like relevant hits.

So I'd say it's time for you to do some homework...

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, May 29, 2017 at 1:53 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear all,
>
> please could you help with an advice : I have installed Rstudio on my
> Ubuntu PC, and when I initiate the application, it says :
>
>  "R lib path(/usr/local/lib/R/lib) not found"
>
> on my computer, at the path "/usr/local/lib/R/lib" there are the folders :
> bin
> etc
> site-library
>
> R is installed in another folder that is "/home/bogdan/R".
>
> how could I fix the error please ? many thanks,
>
> --bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tanasa at gmail.com  Mon May 29 23:07:27 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Mon, 29 May 2017 14:07:27 -0700
Subject: [R] about Rstudio
In-Reply-To: <CAGxFJbQOw6ySL27uwShYh7QB4LXpAh9xfCE5U8O2Bf=31y3JGA@mail.gmail.com>
References: <CA+JEM00s=nk5SZLWtGxvJJG-AiAgu=nEy51Sc=Zy3v4gFxDM-w@mail.gmail.com>
 <CAGxFJbQOw6ySL27uwShYh7QB4LXpAh9xfCE5U8O2Bf=31y3JGA@mail.gmail.com>
Message-ID: <CA+JEM022hSuPGHu3LSz+797hUE5RV=f4JZjM_mg9jd+EghS0-Q@mail.gmail.com>

Hi Bert, thank you for your email. yes, of course, i did the google
searches before posting, although the results did not help too much. At the
end, I've copied the R executable from the installation folder to
/usr/local/lib/R/lib, and apparently it worked ...

On Mon, May 29, 2017 at 2:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 1, SHouldn't you be posting this on the R Studio support site, not here?
>
> 2. I googled on :
>
>  "R lib path(/usr/local/lib/R/lib) not found" Ubuntu
>
> and got what looked like relevant hits.
>
> So I'd say it's time for you to do some homework...
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, May 29, 2017 at 1:53 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Dear all,
> >
> > please could you help with an advice : I have installed Rstudio on my
> > Ubuntu PC, and when I initiate the application, it says :
> >
> >  "R lib path(/usr/local/lib/R/lib) not found"
> >
> > on my computer, at the path "/usr/local/lib/R/lib" there are the folders
> :
> > bin
> > etc
> > site-library
> >
> > R is installed in another folder that is "/home/bogdan/R".
> >
> > how could I fix the error please ? many thanks,
> >
> > --bogdan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Mon May 29 23:29:27 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Mon, 29 May 2017 16:29:27 -0500
Subject: [R] creat contingency tables with fixed row and column margins
In-Reply-To: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>
References: <CAHLnndb2H5x7KRpe6pW8aGmc7KNMWLSzwq+0QcDJJ+6rH1+Qow@mail.gmail.com>
Message-ID: <334c6d91-9cb3-908a-886f-9e338bcca4fa@atsu.edu>

getAnywhere(fisher.test) probably has some clues


On 5/27/2017 2:49 PM, li li wrote:
> Hi all,
>    Is there an R function that can be used to enumerate all the contingency
> tables with fixed row and column margins. For example, can we list all 3 by
> 3 tables with row margins 3,6,6 and column margins 5,5,5.
>     Thanks very much!
>     Hanna
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Mon May 29 23:36:09 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 30 May 2017 00:36:09 +0300
Subject: [R] about Rstudio
In-Reply-To: <CA+JEM022hSuPGHu3LSz+797hUE5RV=f4JZjM_mg9jd+EghS0-Q@mail.gmail.com>
References: <CA+JEM00s=nk5SZLWtGxvJJG-AiAgu=nEy51Sc=Zy3v4gFxDM-w@mail.gmail.com>
 <CAGxFJbQOw6ySL27uwShYh7QB4LXpAh9xfCE5U8O2Bf=31y3JGA@mail.gmail.com>
 <CA+JEM022hSuPGHu3LSz+797hUE5RV=f4JZjM_mg9jd+EghS0-Q@mail.gmail.com>
Message-ID: <923051FB-E087-4E24-8BED-B063B89FC990@gmail.com>

You need to search a bit harder. At least give 60 minutes yourself. Check date of resultant pages hence be sure that you don?t follow an outdated instruction.  Hence, you can learn how to search in time.

Please, read;
https://support.rstudio.com/hc/en-us/articles/200486138-Using-Different-Versions-of-R

I strictly suggest you install R from Ubuntu repo. Do not try to compile/install to another custom location unless if you have very good reason. Try to follow generic installation steps at first.

> On 30 May 2017, at 00:07, Bogdan Tanasa <tanasa at gmail.com> wrote:
> 
> Hi Bert, thank you for your email. yes, of course, i did the google
> searches before posting, although the results did not help too much. At the
> end, I've copied the R executable from the installation folder to
> /usr/local/lib/R/lib, and apparently it worked ?

Copying an executable might not be a elegant solution. You might have issues in the future.


> 
> On Mon, May 29, 2017 at 2:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> 1, SHouldn't you be posting this on the R Studio support site, not here?
>> 
>> 2. I googled on :
>> 
>> "R lib path(/usr/local/lib/R/lib) not found" Ubuntu
>> 
>> and got what looked like relevant hits.
>> 
>> So I'd say it's time for you to do some homework...
>> 
>> -- Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Mon, May 29, 2017 at 1:53 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>>> Dear all,
>>> 
>>> please could you help with an advice : I have installed Rstudio on my
>>> Ubuntu PC, and when I initiate the application, it says :
>>> 
>>> "R lib path(/usr/local/lib/R/lib) not found"
>>> 
>>> on my computer, at the path "/usr/local/lib/R/lib" there are the folders
>> :
>>> bin
>>> etc
>>> site-library
>>> 
>>> R is installed in another folder that is "/home/bogdan/R".
>>> 
>>> how could I fix the error please ? many thanks,
>>> 
>>> --bogdan
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue May 30 02:52:11 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 May 2017 17:52:11 -0700
Subject: [R] about Rstudio
In-Reply-To: <CA+JEM022hSuPGHu3LSz+797hUE5RV=f4JZjM_mg9jd+EghS0-Q@mail.gmail.com>
References: <CA+JEM00s=nk5SZLWtGxvJJG-AiAgu=nEy51Sc=Zy3v4gFxDM-w@mail.gmail.com>
 <CAGxFJbQOw6ySL27uwShYh7QB4LXpAh9xfCE5U8O2Bf=31y3JGA@mail.gmail.com>
 <CA+JEM022hSuPGHu3LSz+797hUE5RV=f4JZjM_mg9jd+EghS0-Q@mail.gmail.com>
Message-ID: <CAGxFJbRrsv3jf0mHV+hZ-BAd136+0QjWXqKq9cLDN9gbEBuu2g@mail.gmail.com>

On Mon, May 29, 2017 at 2:07 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Hi Bert, thank you for your email. yes, of course, i did the google searches
> before posting, although the results did not help too much.

Then you should have said this in your post as well as **why** "the
results did not help too much."

-- Bert



At the end, I've
> copied the R executable from the installation folder to
> /usr/local/lib/R/lib, and apparently it worked ...
>
> On Mon, May 29, 2017 at 2:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> 1, SHouldn't you be posting this on the R Studio support site, not here?
>>
>> 2. I googled on :
>>
>>  "R lib path(/usr/local/lib/R/lib) not found" Ubuntu
>>
>> and got what looked like relevant hits.
>>
>> So I'd say it's time for you to do some homework...
>>
>> -- Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, May 29, 2017 at 1:53 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> > Dear all,
>> >
>> > please could you help with an advice : I have installed Rstudio on my
>> > Ubuntu PC, and when I initiate the application, it says :
>> >
>> >  "R lib path(/usr/local/lib/R/lib) not found"
>> >
>> > on my computer, at the path "/usr/local/lib/R/lib" there are the folders
>> > :
>> > bin
>> > etc
>> > site-library
>> >
>> > R is installed in another folder that is "/home/bogdan/R".
>> >
>> > how could I fix the error please ? many thanks,
>> >
>> > --bogdan
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.ca.us  Tue May 30 03:04:54 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 29 May 2017 18:04:54 -0700
Subject: [R] about Rstudio
In-Reply-To: <CA+JEM022hSuPGHu3LSz+797hUE5RV=f4JZjM_mg9jd+EghS0-Q@mail.gmail.com>
References: <CA+JEM00s=nk5SZLWtGxvJJG-AiAgu=nEy51Sc=Zy3v4gFxDM-w@mail.gmail.com>
 <CAGxFJbQOw6ySL27uwShYh7QB4LXpAh9xfCE5U8O2Bf=31y3JGA@mail.gmail.com>
 <CA+JEM022hSuPGHu3LSz+797hUE5RV=f4JZjM_mg9jd+EghS0-Q@mail.gmail.com>
Message-ID: <FC388FB0-94B5-4B21-A2FA-18A530B63595@dcn.davis.ca.us>

Did you follow the instructions at https://cran.r-project.org/bin/linux/ubuntu/README.html?
-- 
Sent from my phone. Please excuse my brevity.

On May 29, 2017 2:07:27 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Hi Bert, thank you for your email. yes, of course, i did the google
>searches before posting, although the results did not help too much. At
>the
>end, I've copied the R executable from the installation folder to
>/usr/local/lib/R/lib, and apparently it worked ...
>
>On Mon, May 29, 2017 at 2:04 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>
>> 1, SHouldn't you be posting this on the R Studio support site, not
>here?
>>
>> 2. I googled on :
>>
>>  "R lib path(/usr/local/lib/R/lib) not found" Ubuntu
>>
>> and got what looked like relevant hits.
>>
>> So I'd say it's time for you to do some homework...
>>
>> -- Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, May 29, 2017 at 1:53 PM, Bogdan Tanasa <tanasa at gmail.com>
>wrote:
>> > Dear all,
>> >
>> > please could you help with an advice : I have installed Rstudio on
>my
>> > Ubuntu PC, and when I initiate the application, it says :
>> >
>> >  "R lib path(/usr/local/lib/R/lib) not found"
>> >
>> > on my computer, at the path "/usr/local/lib/R/lib" there are the
>folders
>> :
>> > bin
>> > etc
>> > site-library
>> >
>> > R is installed in another folder that is "/home/bogdan/R".
>> >
>> > how could I fix the error please ? many thanks,
>> >
>> > --bogdan
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tanasa at gmail.com  Tue May 30 04:59:38 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Mon, 29 May 2017 19:59:38 -0700
Subject: [R] about Rstudio
In-Reply-To: <FC388FB0-94B5-4B21-A2FA-18A530B63595@dcn.davis.ca.us>
References: <CA+JEM00s=nk5SZLWtGxvJJG-AiAgu=nEy51Sc=Zy3v4gFxDM-w@mail.gmail.com>
 <CAGxFJbQOw6ySL27uwShYh7QB4LXpAh9xfCE5U8O2Bf=31y3JGA@mail.gmail.com>
 <CA+JEM022hSuPGHu3LSz+797hUE5RV=f4JZjM_mg9jd+EghS0-Q@mail.gmail.com>
 <FC388FB0-94B5-4B21-A2FA-18A530B63595@dcn.davis.ca.us>
Message-ID: <CA+JEM00e6GjU+4-W37qTG=H-k0vcp_A-x-fT5nXxAB=+Vd1gPA@mail.gmail.com>

thank you Jeff. I shall re-install R using the recommendations from the
page you've sent.

initially, I wanted to set up the ./configure manually, in the following
way :

./configure --enable-R-shlib --prefix=/home/bogdan/R

On Mon, May 29, 2017 at 6:04 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Did you follow the instructions at https://cran.r-project.org/
> bin/linux/ubuntu/README.html?
> --
> Sent from my phone. Please excuse my brevity.
>
> On May 29, 2017 2:07:27 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >Hi Bert, thank you for your email. yes, of course, i did the google
> >searches before posting, although the results did not help too much. At
> >the
> >end, I've copied the R executable from the installation folder to
> >/usr/local/lib/R/lib, and apparently it worked ...
> >
> >On Mon, May 29, 2017 at 2:04 PM, Bert Gunter <bgunter.4567 at gmail.com>
> >wrote:
> >
> >> 1, SHouldn't you be posting this on the R Studio support site, not
> >here?
> >>
> >> 2. I googled on :
> >>
> >>  "R lib path(/usr/local/lib/R/lib) not found" Ubuntu
> >>
> >> and got what looked like relevant hits.
> >>
> >> So I'd say it's time for you to do some homework...
> >>
> >> -- Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming
> >along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Mon, May 29, 2017 at 1:53 PM, Bogdan Tanasa <tanasa at gmail.com>
> >wrote:
> >> > Dear all,
> >> >
> >> > please could you help with an advice : I have installed Rstudio on
> >my
> >> > Ubuntu PC, and when I initiate the application, it says :
> >> >
> >> >  "R lib path(/usr/local/lib/R/lib) not found"
> >> >
> >> > on my computer, at the path "/usr/local/lib/R/lib" there are the
> >folders
> >> :
> >> > bin
> >> > etc
> >> > site-library
> >> >
> >> > R is installed in another folder that is "/home/bogdan/R".
> >> >
> >> > how could I fix the error please ? many thanks,
> >> >
> >> > --bogdan
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From VijayaKumar.Regati at m3bi.com  Tue May 30 09:02:52 2017
From: VijayaKumar.Regati at m3bi.com (Vijaya Kumar Regati)
Date: Tue, 30 May 2017 07:02:52 +0000
Subject: [R] Need Help - R Programming - Using iteration value to change
 field names for processing for every iteraion
Message-ID: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>

Hi,

I am new to R programming, I am trying to work on below requirement. But could not achieve desired result.
Appreciate if someone can help me on this :

test dataframe :
  Day1.balc Day2.balc Day3.balc Day4.balc
x       100        20        30        40
y       100        10        10        10
> class(test)
[1] "data.frame"

My Goal is to accomplish :
Day2.balc <- Day2.balc + Day1.balc
Day3.balc <- Day3.balc + Day2.balc
.
.
.
Day30.balc <- Day30.balc + Day29.balc

    # Testing for first 4 days
    for (i in 1:4 ) {
    test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
    }

I identified the line I have written inside the loop is not the correct one, can someone help me how I can use iteration value(i), for every iteration, as a basis for changing field names since field consists of 1,2,3... for each different day( Day1.balc Day2.balc Day3.balc Day4.balc etc.,).


Thanks,

Vijay



Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue May 30 10:44:02 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 30 May 2017 20:44:02 +1200
Subject: [R] [FORGED] Need Help - R Programming - Using iteration value
 to change field names for processing for every iteraion
In-Reply-To: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
References: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
Message-ID: <cd6b49cd-7e0d-b5ca-49c8-b2a9d1302046@auckland.ac.nz>

On 30/05/17 19:02, Vijaya Kumar Regati wrote:
> Hi,
> 
> I am new to R programming, I am trying to work on below requirement. But could not achieve desired result.
> Appreciate if someone can help me on this :
> 
> test dataframe :
>    Day1.balc Day2.balc Day3.balc Day4.balc
> x       100        20        30        40
> y       100        10        10        10
>> class(test)
> [1] "data.frame"
> 
> My Goal is to accomplish :
> Day2.balc <- Day2.balc + Day1.balc
> Day3.balc <- Day3.balc + Day2.balc
> .
> .
> .
> Day30.balc <- Day30.balc + Day29.balc
> 
>      # Testing for first 4 days
>      for (i in 1:4 ) {
>      test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
>      }
> 
> I identified the line I have written inside the loop is not the correct one, can someone help me how I can use iteration value(i), for every iteration, as a basis for changing field names since field consists of 1,2,3... for each different day( Day1.balc Day2.balc Day3.balc Day4.balc etc.,).

(1) Learn some R (read "An Introduction to R" from the R web page; 
manuals).  Don't use iteration when you don't need to; i.e. use 
vectorised operations whenever possible.  (Much faster and clearer.)

(2) Distinguish between data frames and matrices; they are *NOT* the 
same thing!  What you need here are matrices.

(3) I think this will work for you:

     M <- as.matrix(test)
     Mnew <- cbind(0,M[,-ncol(M)]) + M

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From manjusha.joshi at gmail.com  Tue May 30 10:12:10 2017
From: manjusha.joshi at gmail.com (Manjusha Joshi)
Date: Tue, 30 May 2017 13:42:10 +0530
Subject: [R] Need Help - R Programming - Using iteration value to change
 field names for processing for every iteraion
In-Reply-To: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
References: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
Message-ID: <CAKGzMdbFP5wfYBg5vgKNn=8TuqUehaM4-AdfhbCbTJj6AMHCMg@mail.gmail.com>

Hello Vijaya,

On Tue, May 30, 2017 at 12:32 PM, Vijaya Kumar Regati <
VijayaKumar.Regati at m3bi.com> wrote:

> Hi,
>
> I am new to R programming, I am trying to work on below requirement. But
> could not achieve desired result.
> Appreciate if someone can help me on this :
>
> test dataframe :
>   Day1.balc Day2.balc Day3.balc Day4.balc
> x       100        20        30        40
> y       100        10        10        10
> > class(test)
> [1] "data.frame"
>
> My Goal is to accomplish :
> Day2.balc <- Day2.balc + Day1.balc
> Day3.balc <- Day3.balc + Day2.balc
> .
> .
> .
> Day30.balc <- Day30.balc + Day29.balc
>
>     # Testing for first 4 days
>     for (i in 1:4 ) {
>     test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
>     }
>
> I identified the line I have written inside the loop is not the correct
> one, can someone help me how I can use iteration value(i), for every
> iteration, as a basis for changing field names since field consists of
> 1,2,3... for each different day( Day1.balc Day2.balc Day3.balc Day4.balc
> etc.,).
>
> ?
>
?There are many built in functions in R which will help to avoid loops.
Try 'cumsum' to add entries in a row to get cumulative sum. Use 'apply' to
avoid loops.

df is the dataframe in which your data has been stored.

t(apply,df,1,cumsum)

will give you the required results.
Please check help of  'apply' for more details.
Best wishes,



?
>
> ?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Manjusha S. Joshi
Mobile:  09822 319328
Pune, India
blog:http://manjushajoshi.wordpress.com/

	[[alternative HTML version deleted]]


From r.gayler at gmail.com  Tue May 30 13:51:23 2017
From: r.gayler at gmail.com (Ross Gayler)
Date: Tue, 30 May 2017 21:51:23 +1000
Subject: [R] R package recommendation - recursively partition data frame,
 calculate summaries of node data frames, plot and print summaries
Message-ID: <CABMcBh_X0mD-C6XYUBxQqi96f0-u62FnPtvuhs1rfMwqyJt2dw@mail.gmail.com>

I am after R package recommendations.

I have a data frame with ~5 million rows and ~50 columns. (I could do what
I want with a sample of the rows, but ideally i would use all the rows.)

(1) I want to recursively partition the rows of the data frame in a way
that I manually specify. That is, I want to generate a tree structure such
that each node of the tree represents a subset of the rows of the data
frame and the child nodes of any parent node represent a partition of the
rows represented by the parent node. This is the sort of thing that tree
induction algorithms like CART and ID3 do, but I want to manually specify
the tree structure rather than have some algorithm decide it for me.

(2) I want the means for specifying the tree structure to be as simple as
possible, because the users will be trying out different tree structures.

(3) Each node (internal or terminal) of the tree represents a row subset of
the root data frame. I want to be able to specify a function to be applied
to each node that takes the node data frame as input and calculates a set
of summary statistics. I will probably write this node summary function as
a dplyr pipeline. I will want to be able to associate the summaries with
the nodes so that I keep track of the summaries in terms of the tree
structure.

(4) I want to be able to print and plot the tree of summaries in a way that
shows the summaries in the context of the tree structure. Inevitably, there
will be fiddling with the formatting of the prints and plots, so I expect i
will need user definable print/plot formatting functions that are applied
to each node of the tree.

What I am looking for is an R package that provides the best starting point
for me to implement this. I am not a particularly good programmer, so
getting a package that minimises what I have to write is important to me.

So far, the most likely packages appear to be:

   - partykit <http://partykit.r-forge.r-project.org/partykit/>
   - data.tree <https://github.com/gluc/data.tree>

I would appreciate any recommendations for R packages that would serve as a
good base; any comments on the relative merits of the packages for my
purposes; and any pointers to example code of people doing similar things.

Thanks

Ross

	[[alternative HTML version deleted]]


From VijayaKumar.Regati at m3bi.com  Tue May 30 10:44:29 2017
From: VijayaKumar.Regati at m3bi.com (Vijaya Kumar Regati)
Date: Tue, 30 May 2017 08:44:29 +0000
Subject: [R] Need Help - R Programming - Using iteration value to change
 field names for processing for every iteraion
In-Reply-To: <CAKGzMdbFP5wfYBg5vgKNn=8TuqUehaM4-AdfhbCbTJj6AMHCMg@mail.gmail.com>
References: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>,
 <CAKGzMdbFP5wfYBg5vgKNn=8TuqUehaM4-AdfhbCbTJj6AMHCMg@mail.gmail.com>
Message-ID: <SIXPR02MB086133829664481794452BC2AEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>

Hi Manjusha,


Thank you for the response. That surely helps.


But the major issue in my case is not how we can apply sum fn, but how we can  change field names based on iteration number.

I cant skip loop in my case, because in real situation I have to deal with say around 100 fields, the only thing that changes is Day number in field name and the iteration number should be able to handle that.


With Regards,
Vijaya Kumar Regati
Technical Lead, M3bi India Private Ltd
Work: 040-67064732

________________________________
From: Manjusha Joshi <manjusha.joshi at gmail.com>
Sent: Tuesday, May 30, 2017 1:42:10 PM
To: Vijaya Kumar Regati
Cc: r-help at R-project.org; vijaykr.sas at gmail.com
Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion

Hello Vijaya,

On Tue, May 30, 2017 at 12:32 PM, Vijaya Kumar Regati <VijayaKumar.Regati at m3bi.com<mailto:VijayaKumar.Regati at m3bi.com>> wrote:
Hi,

I am new to R programming, I am trying to work on below requirement. But could not achieve desired result.
Appreciate if someone can help me on this :

test dataframe :
  Day1.balc Day2.balc Day3.balc Day4.balc
x       100        20        30        40
y       100        10        10        10
> class(test)
[1] "data.frame"

My Goal is to accomplish :
Day2.balc <- Day2.balc + Day1.balc
Day3.balc <- Day3.balc + Day2.balc
.
.
.
Day30.balc <- Day30.balc + Day29.balc

    # Testing for first 4 days
    for (i in 1:4 ) {
    test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
    }

I identified the line I have written inside the loop is not the correct one, can someone help me how I can use iteration value(i), for every iteration, as a basis for changing field names since field consists of 1,2,3... for each different day( Day1.balc Day2.balc Day3.balc Day4.balc etc.,).

?
?There are many built in functions in R which will help to avoid loops.
Try 'cumsum' to add entries in a row to get cumulative sum. Use 'apply' to avoid loops.

df is the dataframe in which your data has been stored.

t(apply,df,1,cumsum)

will give you the required results.
Please check help of  'apply' for more details.
Best wishes,



?

?

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Manjusha S. Joshi
Mobile:  09822 319328
Pune, India
blog:http://manjushajoshi.wordpress.com/


Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.

	[[alternative HTML version deleted]]


From VijayaKumar.Regati at m3bi.com  Tue May 30 12:07:52 2017
From: VijayaKumar.Regati at m3bi.com (Vijaya Kumar Regati)
Date: Tue, 30 May 2017 10:07:52 +0000
Subject: [R] Fw: Need Help - R Programming - Using iteration value to change
 field names for processing for every iteraion
In-Reply-To: <SIXPR02MB08618B54308DB77A39CFF39EAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
References: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>,
 <CA+8X3fV0hkvAJqXxT_qab=sg+8OmqHWkVLD_RVcxxNOAvUZ0zg@mail.gmail.com>,
 <SIXPR02MB08618B54308DB77A39CFF39EAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
Message-ID: <SIXPR02MB0861DDFC2F9F8280C95EFD1FAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>

Hi All,


I have tried in different ways.

Finally I got the solution this way :


for(i in 2:4) {
   test[,paste0("Day",i,".Prod.balc")] <- test[,paste0("Day",i,".Prod.balc")] + test[,paste0("Day",i-1,".Prod.balc")]
}


Please save it for references, if needed in future.
Thanks all for your references.


List Moderator,

You can mark the question as closed now.



With Regards,
Vijaya Kumar Regati
Technical Lead, M3bi India Private Ltd
Work: 040-67064732


________________________________
From: Vijaya Kumar Regati
Sent: Tuesday, May 30, 2017 3:35 PM
To: Jim Lemon
Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion


Thank you for the response.

That did not give me desired output when ran.


But I was able to find 1 solution :


for(i in 2:4) {
   test[,paste0("Day",i,".Prod.balc")] <- test[,paste0("Day",i,".Prod.balc")] + test[,paste0("Day",i-1,".Prod.balc")]
}

Its working now.


With Regards,
Vijaya Kumar Regati
Technical Lead, M3bi India Private Ltd
Work: 040-67064732

________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, May 30, 2017 3:00:39 PM
To: Vijaya Kumar Regati
Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion

Hi Vijaya,
How about:

test_dataframe<-read.table(
 text="Day1.balc Day2.balc Day3.balc Day4.balc
 100        20        30        40
 100        10        10        10",
 header=TRUE)
t(apply(test_dataframe,1,cumsum))

Jim

On Tue, May 30, 2017 at 5:02 PM, Vijaya Kumar Regati
<VijayaKumar.Regati at m3bi.com> wrote:
> Hi,
>
> I am new to R programming, I am trying to work on below requirement. But could not achieve desired result.
> Appreciate if someone can help me on this :
>
> test dataframe :
>   Day1.balc Day2.balc Day3.balc Day4.balc
> x       100        20        30        40
> y       100        10        10        10
>> class(test)
> [1] "data.frame"
>
> My Goal is to accomplish :
> Day2.balc <- Day2.balc + Day1.balc
> Day3.balc <- Day3.balc + Day2.balc
> .
> .
> .
> Day30.balc <- Day30.balc + Day29.balc
>
>     # Testing for first 4 days
>     for (i in 1:4 ) {
>     test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
>     }
>
> I identified the line I have written inside the loop is not the correct one, can someone help me how I can use iteration value(i), for every iteration, as a basis for changing field names since field consists of 1,2,3... for each different day( Day1.balc Day2.balc Day3.balc Day4.balc etc.,).
>
>
> Thanks,
>
> Vijay
>
>
>
> Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
R-help Info Page - Homepage - SfS ? Seminar for Statistics<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...


> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue May 30 15:30:00 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 30 May 2017 15:30:00 +0200
Subject: [R] ggplot: Pie Chart with correct labels
Message-ID: <OFFAE26995.966B52AD-ONC1258130.00499C42-C1258130.004A28B8@lotus.hawesko.de>

Hi All,

I would like to do the following pie chart using ggplot from an official 
data source (
http://www.deutscheweine.de/fileadmin/user_upload/Website/Service/Downloads/Statistik_2016-2017-neu.pdf
, Tab 8, Page 14):

-- cut --

cat("# weinimport_piechart.R\n")


# -- Input --------------------------------------------

d_wine_import_DE <- structure(list(Land = structure(1:24, .Label = 
c("Italien", "Frankreich", 
                                                 "Spanien", "USA", 
"S?dafrika", "Chile", "?sterreich", "Australien", 
                                                 "Portugal", 
"Griechenland", "Argentinien", "Neuseeland", "Ungarn", 
                                                 "Mazedonien", "Schweiz", 
"D?nemark", "Moldawien", "T?rkei", "Belgien/Luxemburg", 
                                                 "Rum?nien", "Ukraine", 
"Kroatien", "Israel", "Georgien"), class = "factor"), 
               Menge_hl_2015 = c(5481000, 2248000, 3824000, 493000, 
845000, 
                                 539000, 308000, 446000, 153000, 99000, 
64000, 43000, 123000, 
                                 186000, 5000, 9000, 28000, 7000, 10000, 
15000, 4000, 4000, 
                                 2000, 2000)), .Names = c("Land", 
"Menge_hl_2015"), class = "data.frame", row.names = c(NA, 
                                              -24L))
names(d_wine_import_DE)

# -- Data ---------------------------------------------

d_result <- data.frame(
  country = d_wine_import_DE$Land,
  abs = d_wine_import_DE$Menge_hl_2015) %>%
  mutate(rel = round(abs / sum(abs) * 100, 1)) %>%
  dplyr::arrange(desc(abs)) %>%
  dplyr::mutate(rel_labs = paste(rel, "%")) %>%  # rev() does not work
  dplyr::mutate(breaks = cumsum(abs) - (abs / 2))  # rev() does not work

# -- Plot ---------------------------------------------

d_result %>%
   ggplot() +
   geom_bar(
     aes(x = "", y = abs, fill = country),
     stat = "identity") +
   # %SOURCE%
   # coord_polar(): Wickham: ggplot2, Springer, 2nd Ed., p. 166
   coord_polar(theta = "y", start = 0) +
   guides(
     fill = guide_legend(
       title = "L?nder",
       reverse = FALSE)
   ) +
   scale_y_continuous(
     breaks = d_result$breaks,  # simply "breaks" does not work
     labels = d_result$rel_labs,  # simply "breaks" does not work
     trans = "reverse"
   ) +
   # %SOURCE%
   # Kassambra: Guide to Create Beautiful Graphics
   # in R, sthda.com, 2nd Ed., 2013, p. 136ff
   theme_minimal() +
   theme(
     panel.border = element_blank(),
     panel.grid = element_blank(),
     axis.title.x = element_blank(),
     axis.title.y = element_blank()
     # axis.text.x = element_text(size = 15)
   ) +
   labs(
     title = paste0("Weinimport nach Deutschland 2015"))

-- cut --

I can not figure out how to align the labels (values in %) with the 
reverse printed countries. Also the breaks and labels do need the dataset 
name although I thought "breaks" and "rel_labs" is sufficient due to the 
piping operator.

Can you help me by telling how to

1. get the order of the labels right
2. Why I need to reference "breaks" and "labels" completely?

Kind regards

Georg


From jdnewmil at dcn.davis.ca.us  Tue May 30 16:16:47 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 30 May 2017 07:16:47 -0700
Subject: [R] ggplot: Pie Chart with correct labels
In-Reply-To: <OFFAE26995.966B52AD-ONC1258130.00499C42-C1258130.004A28B8@lotus.hawesko.de>
References: <OFFAE26995.966B52AD-ONC1258130.00499C42-C1258130.004A28B8@lotus.hawesko.de>
Message-ID: <D45BA024-25D8-437C-9390-E929125AB675@dcn.davis.ca.us>

>1. get the order of the labels right

You need to order your labels in the Land factor correctly when you create it with the factor function, which was (not) done here but rather before you used dput to generate this code. 

>2. Why I need to reference "breaks" and "labels" completely?

Read the documentation for the magrittr package. Non-standard evaluation (that allows one to use a data frame as an implied variable evaluation context) is not handled by the %>% operator, but by the functions you are typically using in your pipeline. (scale_y_continuous does not do so.) The %>% operator supports the implicit passing of the first argument to the function, as well as use of the dot  (.) for referencing that hidden argument in other arguments to the function (which is why you have to use the dot when you call the dplyr::do function).
-- 
Sent from my phone. Please excuse my brevity.

On May 30, 2017 6:30:00 AM PDT, G.Maubach at weinwolf.de wrote:
>Hi All,
>
>I would like to do the following pie chart using ggplot from an
>official 
>data source (
>http://www.deutscheweine.de/fileadmin/user_upload/Website/Service/Downloads/Statistik_2016-2017-neu.pdf
>, Tab 8, Page 14):
>
>-- cut --
>
>cat("# weinimport_piechart.R\n")
>
>
># -- Input --------------------------------------------
>
>d_wine_import_DE <- structure(list(Land = structure(1:24, .Label = 
>c("Italien", "Frankreich", 
>                                                 "Spanien", "USA", 
>"S?dafrika", "Chile", "?sterreich", "Australien", 
>                                                 "Portugal", 
>"Griechenland", "Argentinien", "Neuseeland", "Ungarn", 
>                                              "Mazedonien", "Schweiz", 
>"D?nemark", "Moldawien", "T?rkei", "Belgien/Luxemburg", 
>                                                "Rum?nien", "Ukraine", 
>"Kroatien", "Israel", "Georgien"), class = "factor"), 
>               Menge_hl_2015 = c(5481000, 2248000, 3824000, 493000, 
>845000, 
>                                539000, 308000, 446000, 153000, 99000, 
>64000, 43000, 123000, 
>                               186000, 5000, 9000, 28000, 7000, 10000, 
>15000, 4000, 4000, 
>                                 2000, 2000)), .Names = c("Land", 
>"Menge_hl_2015"), class = "data.frame", row.names = c(NA, 
>                                              -24L))
>names(d_wine_import_DE)
>
># -- Data ---------------------------------------------
>
>d_result <- data.frame(
>  country = d_wine_import_DE$Land,
>  abs = d_wine_import_DE$Menge_hl_2015) %>%
>  mutate(rel = round(abs / sum(abs) * 100, 1)) %>%
>  dplyr::arrange(desc(abs)) %>%
>  dplyr::mutate(rel_labs = paste(rel, "%")) %>%  # rev() does not work
> dplyr::mutate(breaks = cumsum(abs) - (abs / 2))  # rev() does not work
>
># -- Plot ---------------------------------------------
>
>d_result %>%
>   ggplot() +
>   geom_bar(
>     aes(x = "", y = abs, fill = country),
>     stat = "identity") +
>   # %SOURCE%
>   # coord_polar(): Wickham: ggplot2, Springer, 2nd Ed., p. 166
>   coord_polar(theta = "y", start = 0) +
>   guides(
>     fill = guide_legend(
>       title = "L?nder",
>       reverse = FALSE)
>   ) +
>   scale_y_continuous(
>     breaks = d_result$breaks,  # simply "breaks" does not work
>     labels = d_result$rel_labs,  # simply "breaks" does not work
>     trans = "reverse"
>   ) +
>   # %SOURCE%
>   # Kassambra: Guide to Create Beautiful Graphics
>   # in R, sthda.com, 2nd Ed., 2013, p. 136ff
>   theme_minimal() +
>   theme(
>     panel.border = element_blank(),
>     panel.grid = element_blank(),
>     axis.title.x = element_blank(),
>     axis.title.y = element_blank()
>     # axis.text.x = element_text(size = 15)
>   ) +
>   labs(
>     title = paste0("Weinimport nach Deutschland 2015"))
>
>-- cut --
>
>I can not figure out how to align the labels (values in %) with the 
>reverse printed countries. Also the breaks and labels do need the
>dataset 
>name although I thought "breaks" and "rel_labs" is sufficient due to
>the 
>piping operator.
>
>Can you help me by telling how to
>
>1. get the order of the labels right
>2. Why I need to reference "breaks" and "labels" completely?
>
>Kind regards
>
>Georg
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From nell.redu at hotmail.fr  Tue May 30 16:59:49 2017
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Tue, 30 May 2017 14:59:49 +0000
Subject: [R] Latin Hypercube Sampling when parameters are defined
 according to specific probability distributions
In-Reply-To: <CAPtunJZJ0HpZGGaNjpfbHL_bMxHeACJ21kzpP2Zv1+qtcnTMhg@mail.gmail.com>
References: <CAPtunJZJ0HpZGGaNjpfbHL_bMxHeACJ21kzpP2Zv1+qtcnTMhg@mail.gmail.com>
Message-ID: <CY1PR05MB2730F1E421CF600D3A9890E799F00@CY1PR05MB2730.namprd05.prod.outlook.com>

Thanks a lot Rob for your answer. I need to add a condition for the parameter ?dispersal distance?. The sum of the probabilities of all distance classes must be equal to 1:

y <- c(9, 11, 10, 8.9, 8, 7, 6, 5.8, 5.1, 4, 3.9, 3.7, 3.4, 3.1, 2, 1.9, 1.6, 1.4, 1, 0.9, 0.8, 0.7, 0.4, 0.3, 0.1)

x <- seq(1, 25, by = 1)

barplot(y/100, names.arg=x, ylab="Probability", xlab="Distance (km)")



With this condition, is it possible to perform a LHS?

Thanks a lot for your time.

Nell


________________________________
De : R-help <r-help-bounces at r-project.org> de la part de Rob C <bertcarnell at gmail.com>
Envoy? : samedi 27 mai 2017 13:32:23
? : r-help at r-project.org
Objet : Re: [R] Latin Hypercube Sampling when parameters are defined according to specific probability distributions

>May 26, 2017; 11:41am  Nelly Reduan Latin Hypercube Sampling when parameters are >defined according to specific probability distributions
>Hello,
> I would like to perform a sensitivity analysis using a Latin Hypercube Sampling (LHS).
>Among the input parameters in the model, I have a parameter dispersal distance which is defined according to an exponential probability distribution.

>In the model, the user thus sets a default probability value for each distance class.

>For example, for distances ([0  2]; ]2  4]; ]4  6]; ]6  8]; ]8  10];; ]48  50],

>respective probabilities are 0.055; 0.090; 0.065; 0.035; 0.045;; 0.005.

 >Here is the code to represent an exponential probability
distribution for the parameter dispersal distance:

>set.seed(0)
>foo <- rexp(100, rate = 1/10)
>hist(foo, prob=TRUE, breaks=20, ylim=c(0,0.1), xlab ="Distance (km)")
>lines(dexp(seq(1, 100, by = 1), rate = 1/mean(foo)),col="red")
>1/mean(foo)

>When a parameter is defined according to a specific probability distribution, how can I perform a LHS ?
>For example, should I sample N values from a uniform distribution for each distance class (i.e., [0 ? 2]; ]2 ? 4]; ]4 ? 6]; ]6 ? 8]; ]8 ? 10];??; ]48 ? 50])
>or sample N values from exponential distributions with different rates ?

>Here is the code used to perform a LHS when the parameter ?dispersal distance? is defined by one default value in the model:

>library(pse)
>factors <- c("distance")
>q <- c("qexp")
>q.arg <- list( list(rate=1/30) )
>uncoupledLHS <- LHS(model=NULL, factors, 50, q, q.arg)
>head(uncoupledLHS)

>Thanks a lot for your time.
>Have a nice day
>Nell

Nell,

I would like to suggest a slightly different method for generating the
sample using the lhs library,  then I will try using the pse library.
Generally when you have a package specific
question, you should try to contact the package maintainer first.

set.seed(1)
# I don't think your model has only one parameter, so I will include multiple
input_parameters <- c("dispersal_distance", "temperature", "pressure")
N <- 50
exponential_rate <- 1/30

library(lhs)
X <- randomLHS(N, length(input_parameters))
dimnames(X) <- list(NULL, input_parameters)
# X is now a uniformly distributed Latin hypercube
head(X)
hist(X[,1], breaks=5)
hist(X[,2], breaks=5)
hist(X[,3], breaks=5)
# now, transform the dispersal_distance paramter to an exponential sample
Y <- X
Y[,"dispersal_distance"] <- qexp(X[,"dispersal_distance"],
rate=exponential_rate)
hist(Y[,1], breaks=10)
# you can transform the other marginals as required and then assess
function sensitivity
model_function <- function(z) z[1]*z[2] + z[3]
apply(Y, 1, model_function)

# now, trying to use pse
library(pse)
q <- list("qexp", "qunif", "qunif")
q.arg <- list(list(rate=exponential_rate), list(min=0, max=1),
list(min=0, max=1))
uncoupledLHS <- LHS(model=model_function, input_parameters, N, q, q.arg)
hist(uncoupledLHS$data$dispersal_distance, breaks=10)

Rob

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue May 30 17:08:38 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 30 May 2017 08:08:38 -0700
Subject: [R] R package recommendation - recursively partition data frame,
 calculate summaries of node data frames, plot and print summaries
In-Reply-To: <CABMcBh_X0mD-C6XYUBxQqi96f0-u62FnPtvuhs1rfMwqyJt2dw@mail.gmail.com>
References: <CABMcBh_X0mD-C6XYUBxQqi96f0-u62FnPtvuhs1rfMwqyJt2dw@mail.gmail.com>
Message-ID: <CAGxFJbR3eAFrCQWoUkxDQ9+bhb4occTO9V4EwBNLhGGdTgAYgA@mail.gmail.com>

1. Generally this sort of thing (statistical issues) is OT here.

2. Have you tried googling? "recursive partitioning R" .

3. Have you looked at the CRAN "Machine Laearning" Task View?
https://cran.r-project.org/web/views/MachineLearning.html

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 30, 2017 at 4:51 AM, Ross Gayler <r.gayler at gmail.com> wrote:
> I am after R package recommendations.
>
> I have a data frame with ~5 million rows and ~50 columns. (I could do what
> I want with a sample of the rows, but ideally i would use all the rows.)
>
> (1) I want to recursively partition the rows of the data frame in a way
> that I manually specify. That is, I want to generate a tree structure such
> that each node of the tree represents a subset of the rows of the data
> frame and the child nodes of any parent node represent a partition of the
> rows represented by the parent node. This is the sort of thing that tree
> induction algorithms like CART and ID3 do, but I want to manually specify
> the tree structure rather than have some algorithm decide it for me.
>
> (2) I want the means for specifying the tree structure to be as simple as
> possible, because the users will be trying out different tree structures.
>
> (3) Each node (internal or terminal) of the tree represents a row subset of
> the root data frame. I want to be able to specify a function to be applied
> to each node that takes the node data frame as input and calculates a set
> of summary statistics. I will probably write this node summary function as
> a dplyr pipeline. I will want to be able to associate the summaries with
> the nodes so that I keep track of the summaries in terms of the tree
> structure.
>
> (4) I want to be able to print and plot the tree of summaries in a way that
> shows the summaries in the context of the tree structure. Inevitably, there
> will be fiddling with the formatting of the prints and plots, so I expect i
> will need user definable print/plot formatting functions that are applied
> to each node of the tree.
>
> What I am looking for is an R package that provides the best starting point
> for me to implement this. I am not a particularly good programmer, so
> getting a package that minimises what I have to write is important to me.
>
> So far, the most likely packages appear to be:
>
>    - partykit <http://partykit.r-forge.r-project.org/partykit/>
>    - data.tree <https://github.com/gluc/data.tree>
>
> I would appreciate any recommendations for R packages that would serve as a
> good base; any comments on the relative merits of the packages for my
> purposes; and any pointers to example code of people doing similar things.
>
> Thanks
>
> Ross
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue May 30 17:17:35 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 30 May 2017 08:17:35 -0700
Subject: [R] Fw: Need Help - R Programming - Using iteration value to
 change field names for processing for every iteraion
In-Reply-To: <SIXPR02MB0861DDFC2F9F8280C95EFD1FAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
References: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
 <CA+8X3fV0hkvAJqXxT_qab=sg+8OmqHWkVLD_RVcxxNOAvUZ0zg@mail.gmail.com>
 <SIXPR02MB08618B54308DB77A39CFF39EAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
 <SIXPR02MB0861DDFC2F9F8280C95EFD1FAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
Message-ID: <CAGxFJbT6erpspRuts_2XCTEAQYSG4Xr=2tU45OTr0gwr4uxE_w@mail.gmail.com>

Your fields are adjacent, right?

If so, you do not need to refer to them by name to accomplish this.
Please spend some (more) time with an R tutorial or two as Rolf
suggested, especially with "indexing".

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 30, 2017 at 3:07 AM, Vijaya Kumar Regati
<VijayaKumar.Regati at m3bi.com> wrote:
> Hi All,
>
>
> I have tried in different ways.
>
> Finally I got the solution this way :
>
>
> for(i in 2:4) {
>    test[,paste0("Day",i,".Prod.balc")] <- test[,paste0("Day",i,".Prod.balc")] + test[,paste0("Day",i-1,".Prod.balc")]
> }
>
>
> Please save it for references, if needed in future.
> Thanks all for your references.
>
>
> List Moderator,
>
> You can mark the question as closed now.
>
>
>
> With Regards,
> Vijaya Kumar Regati
> Technical Lead, M3bi India Private Ltd
> Work: 040-67064732
>
>
> ________________________________
> From: Vijaya Kumar Regati
> Sent: Tuesday, May 30, 2017 3:35 PM
> To: Jim Lemon
> Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion
>
>
> Thank you for the response.
>
> That did not give me desired output when ran.
>
>
> But I was able to find 1 solution :
>
>
> for(i in 2:4) {
>    test[,paste0("Day",i,".Prod.balc")] <- test[,paste0("Day",i,".Prod.balc")] + test[,paste0("Day",i-1,".Prod.balc")]
> }
>
> Its working now.
>
>
> With Regards,
> Vijaya Kumar Regati
> Technical Lead, M3bi India Private Ltd
> Work: 040-67064732
>
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, May 30, 2017 3:00:39 PM
> To: Vijaya Kumar Regati
> Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion
>
> Hi Vijaya,
> How about:
>
> test_dataframe<-read.table(
>  text="Day1.balc Day2.balc Day3.balc Day4.balc
>  100        20        30        40
>  100        10        10        10",
>  header=TRUE)
> t(apply(test_dataframe,1,cumsum))
>
> Jim
>
> On Tue, May 30, 2017 at 5:02 PM, Vijaya Kumar Regati
> <VijayaKumar.Regati at m3bi.com> wrote:
>> Hi,
>>
>> I am new to R programming, I am trying to work on below requirement. But could not achieve desired result.
>> Appreciate if someone can help me on this :
>>
>> test dataframe :
>>   Day1.balc Day2.balc Day3.balc Day4.balc
>> x       100        20        30        40
>> y       100        10        10        10
>>> class(test)
>> [1] "data.frame"
>>
>> My Goal is to accomplish :
>> Day2.balc <- Day2.balc + Day1.balc
>> Day3.balc <- Day3.balc + Day2.balc
>> .
>> .
>> .
>> Day30.balc <- Day30.balc + Day29.balc
>>
>>     # Testing for first 4 days
>>     for (i in 1:4 ) {
>>     test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
>>     }
>>
>> I identified the line I have written inside the loop is not the correct one, can someone help me how I can use iteration value(i), for every iteration, as a basis for changing field names since field consists of 1,2,3... for each different day( Day1.balc Day2.balc Day3.balc Day4.balc etc.,).
>>
>>
>> Thanks,
>>
>> Vijay
>>
>>
>>
>> Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
> R-help Info Page - Homepage - SfS ? Seminar for Statistics<https://stat.ethz.ch/mailman/listinfo/r-help>
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...
>
>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Tue May 30 17:38:07 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 30 May 2017 18:38:07 +0300
Subject: [R] R package recommendation - recursively partition data frame,
 calculate summaries of node data frames, plot and print summaries
In-Reply-To: <CABMcBh_X0mD-C6XYUBxQqi96f0-u62FnPtvuhs1rfMwqyJt2dw@mail.gmail.com>
References: <CABMcBh_X0mD-C6XYUBxQqi96f0-u62FnPtvuhs1rfMwqyJt2dw@mail.gmail.com>
Message-ID: <2E255147-D7F0-4BCE-ABA1-713191D2DE52@gmail.com>

Hello Ross,

> On 30 May 2017, at 14:51, Ross Gayler <r.gayler at gmail.com> wrote:
> 
> I am after R package recommendations.
> 
> I have a data frame with ~5 million rows and ~50 columns. (I could do what
> I want with a sample of the rows, but ideally i would use all the rows.)

Very nice question for a mental gymnastics. First thing that comes in my mind is SPEED/PERFORMANCE when you mention ~5 million and _recursive_ words as you did. That?s why, the functions that have heavy work load are written in C/FORTRAN (i.e. partykit[1]). Most of the time, You are only limited to function arguments in R if you don?t want speed lost. For instance, lmtree function in partykit package decides the tree structure by its own partitioning model. So, you don?t have any authority (based on you are not a good programmer) to change the basic decision algorithm but only function arguments. Hence, the ready-to-go R functions only let you change function arguments but not the basic internal decision algorithm written in C/FORTRAN in backstage.

> 
> (1) I want to recursively partition the rows of the data frame in a way
> that I manually specify. That is, I want to generate a tree structure such
> that each node of the tree represents a subset of the rows of the data
> frame and the child nodes of any parent node represent a partition of the
> rows represented by the parent node. This is the sort of thing that tree
> induction algorithms like CART and ID3 do, but I want to manually specify
> the tree structure rather than have some algorithm decide it for me.

At this point, ?manually specify? requires you write your own decision mechanism (seems as your only chance). Scaring part here is a matrix with ~5milx50 cells and _recursive_ part. These are the first two of the things that R is not very good. Let?s create a very simple partitioning algorithm to see what we will encounter in the future.

part <- function(x, stop_rule = 1000) {
  set.seed(1)
  n <- round(runif(1, 1, nrow(x)))
  n1 <- 1:n; n2 <- (n + 1):nrow(x)
  part1 <- if (length(n1) < stop_rule)
    x[n1,] else part(x[n1,], stop_rule)
  part2 <- if (length(n2) < stop_rule)
    x[n2,] else part(x[n2,], stop_rule)
  return(list(p1 = part1, p2 = part2))
}

The _part_ function is a very simple partitioning algorithm by recursive function calling. It randomly parts a matrix till number of rows is less than 1000. Only 10 lines of code. Very nice huh? 
Now let?s create a data to play.

x <- matrix(runif(5e6), nrow = 5e6, ncol = 50)

Wow. please check the size of x. 1.9 GB! (Anyway, I have 8 core + 16 GB huge 27 inch desktop, I can handle it, I hope?) Now let?s apply the part function over x.

p <- part(x)

Please, note the execution time and watch the system memory! I used more than 16GB RAM and elapsed time is 46 sec for a very simple partitioning. And check the size of _p_ (1.9 GB). This is not good, mate. _p_ is a list of parts containing other subnodes. Terminal node contains partitioned rows of x matrix. also note that I didn?t use any information hidden in x matrix in calculations. only random length. So, in real life, if you use pure R to part things, you will end up with very long running functions (I mean days).

I think I can increase the performance a bit. Let?s try!

node <- 0
partf <- function(x, stop_rule = 1000) {
  set.seed(1)
  n <- round(runif(1, 1, nrow(x)))
  n1 <- 1:n; n2 <- (n + 1):nrow(x)
  part1 <- if (length(n1) < stop_rule) {
    node <<- node + 1
    rep(node, length(n1))
  } else partf(x[n1,], stop_rule)
  part2 <- if (length(n2) < stop_rule) {
    node <<- node + 1
    rep(node, length(n2))
  } else partf(x[n2,], stop_rule)
  return(c(part1, part2))
}

_partf_ function is the same as _part_ except it returns only an index of partitions. So, I can get rid of 1.9 GB _p_ variable.  Run the code below:

pf <- partf(x)

> 
> (2) I want the means for specifying the tree structure to be as simple as
> possible, because the users will be trying out different tree structures.

Now, excecution was completed in 32 sec and size of _pf_ is only 38 Mb. I can use _pf_ to index x matrix and calculate required summary statistics that you mention in (2). But monitor your memory pressure at this stage. _partf_function use still huge amount of RAM to complete a simple calculation. Accept these examples as a start point and decide the future of the project in your mind. 

> 
> (3) Each node (internal or terminal) of the tree represents a row subset of
> the root data frame. I want to be able to specify a function to be applied
> to each node that takes the node data frame as input and calculates a set
> of summary statistics. I will probably write this node summary function as
> a dplyr pipeline. I will want to be able to associate the summaries with
> the nodes so that I keep track of the summaries in terms of the tree
> structure.
> 
> (4) I want to be able to print and plot the tree of summaries in a way that
> shows the summaries in the context of the tree structure. Inevitably, there
> will be fiddling with the formatting of the prints and plots, so I expect i
> will need user definable print/plot formatting functions that are applied
> to each node of the tree.


Item 3 and 4 will be up to your R programming skills. Because a ready-to-go package won?t help you much as you want to construct your own partitioning rule.

> 
> What I am looking for is an R package that provides the best starting point
> for me to implement this. I am not a particularly good programmer, so
> getting a package that minimises what I have to write is important to me.

If you still insist on, I suggest you start to learn C/C++ and Rcpp and friends. So, you can write your own partitioning algorithm, your own decision mechanism. And your functions will work super duper fast and will use incredibly less RAM. Also Rcpp has parallel support. So, you can run your code faster on multicore machines. I hope my explanations make things clear in your mind.

> 
> So far, the most likely packages appear to be:
> 
>   - partykit <http://partykit.r-forge.r-project.org/partykit/>
>   - data.tree <https://github.com/gluc/data.tree>
> 
> I would appreciate any recommendations for R packages that would serve as a
> good base; any comments on the relative merits of the packages for my
> purposes; and any pointers to example code of people doing similar things.
> 
> Thanks
> 
> Ross

1- https://r-forge.r-project.org/scm/viewvc.php/pkg/partykit/src/?root=partykit <https://r-forge.r-project.org/scm/viewvc.php/pkg/partykit/src/?root=partykit>



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue May 30 17:43:59 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 30 May 2017 08:43:59 -0700
Subject: [R] (Somewhat?) Off topic: Containerization software
Message-ID: <CAGxFJbRr3B8F7B0Gs6VcRpO_EA_8h91SV96SJ+2jEHZ2CEje3w@mail.gmail.com>

Folks:

This is **off topic**, but I thought it might be informative to this
community. Consequently: please **no on list public comments or
discussion**. Feel free to respond to me privately, if you like; but I
have neither knowledge nor opinions, so why bother? This is just FYI.
My apology if it is deemed inappropriate.

http://www.nature.com/news/software-simplified-1.22059

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


From s3tochri at uni-bayreuth.de  Tue May 30 18:02:28 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Tue, 30 May 2017 18:02:28 +0200
Subject: [R] Differentiate values in a plot by colour or symbol
Message-ID: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>

Hey Guys,

I just try to differentiate certain values in my plot by colour or symbol.

I have panel data with three dimensions (number of stations, revenue, 
years). To integrate the third dimension (years) in the plot, I want to 
differentiate the values(number of stations, revenue) by a certain range 
of years.

e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots

For the normal plot I used the following formula:

*plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*

I only found a way to mark every single year. So hopefully you can help?

Cheers,

Toby



	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Tue May 30 18:26:10 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 30 May 2017 19:26:10 +0300
Subject: [R] Differentiate values in a plot by colour or symbol
In-Reply-To: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
References: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
Message-ID: <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>


> On 30 May 2017, at 19:02, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Hey Guys,
> 
> I just try to differentiate certain values in my plot by colour or symbol.
> 
> I have panel data with three dimensions (number of stations, revenue, 
> years). To integrate the third dimension (years) in the plot, I want to 
> differentiate the values(number of stations, revenue) by a certain range 
> of years.
> 
> e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots
> 
> For the normal plot I used the following formula:
> 
> *plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*
> 
> I only found a way to mark every single year. So hopefully you can help?
> 
> Cheers,
> 
> Toby
> 


See ?findInterval. Especially, first 3 lines in _Examples_ section. Use result of findInterval as argument to _col_ or _pch_ in plot function.


From s3tochri at uni-bayreuth.de  Tue May 30 19:48:33 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Tue, 30 May 2017 19:48:33 +0200
Subject: [R] Differentiate values in a plot by colour or symbol
In-Reply-To: <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>
References: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
 <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>
Message-ID: <798b7584-9543-d93d-11a6-e428a9694024@uni-bayreuth.de>

Hi Ismael,

thanks for your quick reply.

I was now able to esmitate two intervals with the "findInterval"-Function.

   x
  [1,] 2005 1
  [2,] 2006 1
  [3,] 2007 1
  [4,] 2008 1
  [5,] 2009 1
  [6,] 2010 1
  [7,] 2011 2
  [8,] 2012 2
  [9,] 2013 2
[10,] 2014 2
[11,] 2015 2
[12,] 2016 2

But I was not able to connect the intervals with the plot-function. I 
used the following formular.

"plot(data$stations, data$revenue, xlab="stations", ylab="revenue", 
col(findInterval())"

How can I proceed and get the plot-funktion running?

Maybe it is not running because the years as single numbers are already 
contained in my data-frame?

Cheers,

Toby



Am 30.05.2017 um 18:26 schrieb Ismail SEZEN:
>> On 30 May 2017, at 19:02, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
>>
>> Hey Guys,
>>
>> I just try to differentiate certain values in my plot by colour or symbol.
>>
>> I have panel data with three dimensions (number of stations, revenue,
>> years). To integrate the third dimension (years) in the plot, I want to
>> differentiate the values(number of stations, revenue) by a certain range
>> of years.
>>
>> e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots
>>
>> For the normal plot I used the following formula:
>>
>> *plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*
>>
>> I only found a way to mark every single year. So hopefully you can help?
>>
>> Cheers,
>>
>> Toby
>>
>
> See ?findInterval. Especially, first 3 lines in _Examples_ section. Use result of findInterval as argument to _col_ or _pch_ in plot function.
>
>


	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Tue May 30 19:57:46 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 30 May 2017 20:57:46 +0300
Subject: [R] Differentiate values in a plot by colour or symbol
In-Reply-To: <798b7584-9543-d93d-11a6-e428a9694024@uni-bayreuth.de>
References: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
 <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>
 <798b7584-9543-d93d-11a6-e428a9694024@uni-bayreuth.de>
Message-ID: <238165CC-17AE-4F64-80F3-F68D7B9C4F98@gmail.com>


> On 30 May 2017, at 20:48, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Hi Ismael,
> 
> thanks for your quick reply.
> 
> I was now able to esmitate two intervals with the "findInterval"-Function.
> 
>   x  
>  [1,] 2005 1
>  [2,] 2006 1
>  [3,] 2007 1
>  [4,] 2008 1
>  [5,] 2009 1
>  [6,] 2010 1
>  [7,] 2011 2
>  [8,] 2012 2
>  [9,] 2013 2
> [10,] 2014 2
> [11,] 2015 2
> [12,] 2016 2
> But I was not able to connect the intervals with the plot-function. I used the following formular.
> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col(findInterval())"
> 
In fact I should say ?feed _col_ or _pch_ argument with the result of findInterval? as below:

plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col = findInterval(x$year, c(2005, 2010, 2015))

Please note that If you have many (20-30) intervals, colour handling will be more complex. But I assume you have maximum 5-10 intervals. So, the piece of code above will work for you.

> How can I proceed and get the plot-funktion running?
> Maybe it is not running because the years as single numbers are already contained in my data-frame?
> Cheers,
> 
> Toby
> 
> 
> Am 30.05.2017 um 18:26 schrieb Ismail SEZEN:
>>> On 30 May 2017, at 19:02, Tobias Christoph <s3tochri at uni-bayreuth.de> <mailto:s3tochri at uni-bayreuth.de> wrote:
>>> 
>>> Hey Guys,
>>> 
>>> I just try to differentiate certain values in my plot by colour or symbol.
>>> 
>>> I have panel data with three dimensions (number of stations, revenue, 
>>> years). To integrate the third dimension (years) in the plot, I want to 
>>> differentiate the values(number of stations, revenue) by a certain range 
>>> of years.
>>> 
>>> e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots
>>> 
>>> For the normal plot I used the following formula:
>>> 
>>> *plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*
>>> 
>>> I only found a way to mark every single year. So hopefully you can help?
>>> 
>>> Cheers,
>>> 
>>> Toby
>>> 
>> 
>> See ?findInterval. Especially, first 3 lines in _Examples_ section. Use result of findInterval as argument to _col_ or _pch_ in plot function.
>> 
>> 
> 


	[[alternative HTML version deleted]]


From s3tochri at uni-bayreuth.de  Tue May 30 20:23:22 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Tue, 30 May 2017 20:23:22 +0200
Subject: [R] Differentiate values in a plot by colour or symbol
In-Reply-To: <238165CC-17AE-4F64-80F3-F68D7B9C4F98@gmail.com>
References: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
 <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>
 <798b7584-9543-d93d-11a6-e428a9694024@uni-bayreuth.de>
 <238165CC-17AE-4F64-80F3-F68D7B9C4F98@gmail.com>
Message-ID: <a5c2f116-cd2c-d616-bdcc-662142215d9d@uni-bayreuth.de>

Ahh, okay.

I think now I understand what you exactly mean. But the plot is stil not 
working /differentiate the dots by color. I used the following formula.

"plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col 
= findInterval(data$year, c(2005, 2010, 2015))"

I think the problem is stil related to the term "col = 
findInterval(data$year, c(2005, 2010, 2015))" and its notation.

Just to make sure: "data" is the name of the data-table imported in R. 
"year" is the lable of the column where the years are listed in the 
data-table?

Cheers



Am 30.05.2017 um 19:57 schrieb Ismail SEZEN:
>
>> On 30 May 2017, at 20:48, Tobias Christoph <s3tochri at uni-bayreuth.de 
>> <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>
>> Hi Ismael,
>>
>> thanks for your quick reply.
>>
>> I was now able to esmitate two intervals with the 
>> "findInterval"-Function.
>>
>>    x
>>   [1,] 2005 1
>>   [2,] 2006 1
>>   [3,] 2007 1
>>   [4,] 2008 1
>>   [5,] 2009 1
>>   [6,] 2010 1
>>   [7,] 2011 2
>>   [8,] 2012 2
>>   [9,] 2013 2
>> [10,] 2014 2
>> [11,] 2015 2
>> [12,] 2016 2
>>
>> But I was not able to connect the intervals with the plot-function. I 
>> used the following formular.
>>
>> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", 
>> col(findInterval())"
>>
> In fact I should say ?feed _col_ or _pch_ argument with the result of 
> findInterval? as below:
>
> plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col 
> = findInterval(x$year, c(2005, 2010, 2015))
>
> Please note that If you have many (20-30) intervals, colour handling 
> will be more complex. But I assume you have maximum 5-10 intervals. 
> So, the piece of code above will work for you.
>
>> How can I proceed and get the plot-funktion running?
>>
>> Maybe it is not running because the years as single numbers are 
>> already contained in my data-frame?
>>
>> Cheers,
>>
>> Toby
>>
>>
>>
>> Am 30.05.2017 um 18:26 schrieb Ismail SEZEN:
>>>> On 30 May 2017, at 19:02, Tobias Christoph<s3tochri at uni-bayreuth.de>  wrote:
>>>>
>>>> Hey Guys,
>>>>
>>>> I just try to differentiate certain values in my plot by colour or symbol.
>>>>
>>>> I have panel data with three dimensions (number of stations, revenue,
>>>> years). To integrate the third dimension (years) in the plot, I want to
>>>> differentiate the values(number of stations, revenue) by a certain range
>>>> of years.
>>>>
>>>> e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots
>>>>
>>>> For the normal plot I used the following formula:
>>>>
>>>> *plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*
>>>>
>>>> I only found a way to mark every single year. So hopefully you can help?
>>>>
>>>> Cheers,
>>>>
>>>> Toby
>>>>
>>> See ?findInterval. Especially, first 3 lines in _Examples_ section. Use result of findInterval as argument to _col_ or _pch_ in plot function.
>>>
>>>
>>
>


	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Tue May 30 20:30:04 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 30 May 2017 21:30:04 +0300
Subject: [R] Differentiate values in a plot by colour or symbol
In-Reply-To: <a5c2f116-cd2c-d616-bdcc-662142215d9d@uni-bayreuth.de>
References: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
 <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>
 <798b7584-9543-d93d-11a6-e428a9694024@uni-bayreuth.de>
 <238165CC-17AE-4F64-80F3-F68D7B9C4F98@gmail.com>
 <a5c2f116-cd2c-d616-bdcc-662142215d9d@uni-bayreuth.de>
Message-ID: <F5DD6376-AE75-4904-BD02-F29F321BF414@gmail.com>


> On 30 May 2017, at 21:23, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Ahh, okay.
> 
> I think now I understand what you exactly mean. But the plot is stil not working /differentiate the dots by color. I used the following formula.
> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col = findInterval(data$year, c(2005, 2010, 2015))"
> 
> I think the problem is stil related to the term "col = findInterval(data$year, c(2005, 2010, 2015))" and its notation.
> 
> Just to make sure: "data" is the name of the data-table imported in R. "year" is the lable of the column where the years are listed in the data-table?
> 
Exactly. Make sure all the columns in data.frame are numeric. Also I don?t know the range of years. You should arrange arguments to findInterval according your data. If you would send a minimal example as stated in posting guide [1], you will have your answer in second email :).

1- http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>

> Cheers
> 
> 
> 
> Am 30.05.2017 um 19:57 schrieb Ismail SEZEN:
>> 
>>> On 30 May 2017, at 20:48, Tobias Christoph <s3tochri at uni-bayreuth.de <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>> 
>>> Hi Ismael,
>>> 
>>> thanks for your quick reply.
>>> 
>>> I was now able to esmitate two intervals with the "findInterval"-Function.
>>> 
>>>   x  
>>>  [1,] 2005 1
>>>  [2,] 2006 1
>>>  [3,] 2007 1
>>>  [4,] 2008 1
>>>  [5,] 2009 1
>>>  [6,] 2010 1
>>>  [7,] 2011 2
>>>  [8,] 2012 2
>>>  [9,] 2013 2
>>> [10,] 2014 2
>>> [11,] 2015 2
>>> [12,] 2016 2
>>> But I was not able to connect the intervals with the plot-function. I used the following formular.
>>> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col(findInterval())"
>>> 
>> In fact I should say ?feed _col_ or _pch_ argument with the result of findInterval? as below:
>> 
>> plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col = findInterval(x$year, c(2005, 2010, 2015))
>> 
>> Please note that If you have many (20-30) intervals, colour handling will be more complex. But I assume you have maximum 5-10 intervals. So, the piece of code above will work for you.
>> 
>>> How can I proceed and get the plot-funktion running?
>>> Maybe it is not running because the years as single numbers are already contained in my data-frame?
>>> Cheers,
>>> 
>>> Toby
>>> 
>>> 
>>> Am 30.05.2017 um 18:26 schrieb Ismail SEZEN:
>>>>> On 30 May 2017, at 19:02, Tobias Christoph <s3tochri at uni-bayreuth.de> <mailto:s3tochri at uni-bayreuth.de> wrote:
>>>>> 
>>>>> Hey Guys,
>>>>> 
>>>>> I just try to differentiate certain values in my plot by colour or symbol.
>>>>> 
>>>>> I have panel data with three dimensions (number of stations, revenue, 
>>>>> years). To integrate the third dimension (years) in the plot, I want to 
>>>>> differentiate the values(number of stations, revenue) by a certain range 
>>>>> of years.
>>>>> 
>>>>> e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots
>>>>> 
>>>>> For the normal plot I used the following formula:
>>>>> 
>>>>> *plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*
>>>>> 
>>>>> I only found a way to mark every single year. So hopefully you can help?
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>> Toby
>>>>> 
>>>> See ?findInterval. Especially, first 3 lines in _Examples_ section. Use result of findInterval as argument to _col_ or _pch_ in plot function.
>>>> 
>>>> 
>>> 
>> 
> 


	[[alternative HTML version deleted]]


From s3tochri at uni-bayreuth.de  Tue May 30 20:44:47 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Tue, 30 May 2017 20:44:47 +0200
Subject: [R] Differentiate values in a plot by colour or symbol
In-Reply-To: <F5DD6376-AE75-4904-BD02-F29F321BF414@gmail.com>
References: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
 <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>
 <798b7584-9543-d93d-11a6-e428a9694024@uni-bayreuth.de>
 <238165CC-17AE-4F64-80F3-F68D7B9C4F98@gmail.com>
 <a5c2f116-cd2c-d616-bdcc-662142215d9d@uni-bayreuth.de>
 <F5DD6376-AE75-4904-BD02-F29F321BF414@gmail.com>
Message-ID: <ad924fab-6bb0-3c75-c72f-297fc08447bc@uni-bayreuth.de>

Okay;)

First of all many thanks to you, Ismail, that you really try to help me. 
I am really not an expert with R and try to learn.

I just checked: All columns in my data frame are numeric. The range of 
years is from 2005 to 2016.

Please find attached the result of "data.frame(data)". I also attached 
it as Excel-file

>data.frame(data)            town year  revenue stations
1       Bremen 2005 39.91036        1
2       Bremen 2006 43.34265        1
3       Bremen 2007 44.03614        1
4       Bremen 2008 43.19945        1
5       Bremen 2009 39.05230        1
6       Bremen 2010 44.24626        1
7       Bremen 2011 46.19309       35
8       Bremen 2012 48.59513      101
9       Bremen 2013 48.15778      181
10      Bremen 2014 48.83199      323
11      Bremen 2015 48.68549      463
12      Bremen 2016 50.00000      614
13     Dresden 2005 42.27858        1
14     Dresden 2006 50.39606        1
15     Dresden 2007 48.73299        1
16     Dresden 2008 42.69010        1
17     Dresden 2009 40.81174        1
18     Dresden 2010 47.09675        2
19     Dresden 2011 49.16900       43
20     Dresden 2012 48.13645      151
21     Dresden 2013 48.13645      284
22     Dresden 2014 49.77309      511
23     Dresden 2015 51.51515      773
24     Dresden 2016 51.00000     1057
25  D?sseldorf 2005 44.23227        1
26  D?sseldorf 2006 46.70928        1
27  D?sseldorf 2007 51.24008        1
28  D?sseldorf 2008 61.59058        1
29  D?sseldorf 2009 45.70021        1
30  D?sseldorf 2010 57.17096        8
31  D?sseldorf 2011 60.60122      115
32  D?sseldorf 2012 65.50992      339
33  D?sseldorf 2013 64.06870      636
34  D?sseldorf 2014 71.56474     1117
35  D?sseldorf 2015 68.20119     1622
36  D?sseldorf 2016 80.00000     2117
37       Essen 2005 37.71029        1
38       Essen 2006 44.61127        1
39       Essen 2007 41.39926        1
40       Essen 2008 49.34792        1
41       Essen 2009 38.49137        1
42       Essen 2010 51.57844        1
43       Essen 2011 48.38058       29
44       Essen 2012 50.17066       42
45       Essen 2013 49.26759       90
46       Essen 2014 50.20367      162
47       Essen 2015 47.89430      258
48       Essen 2016 58.00000      370
49   Frankfurt 2005 47.97355        1
50   Frankfurt 2006 50.37223        1
51   Frankfurt 2007 49.11292        1
52   Frankfurt 2008 49.65316        1
53   Frankfurt 2009 44.53889        3
54   Frankfurt 2010 54.02567       15
55   Frankfurt 2011 56.29475       80
56   Frankfurt 2012 59.10949      223
57   Frankfurt 2013 62.30140      488
58   Frankfurt 2014 62.67521      836
59   Frankfurt 2015 66.93712     1319
60   Frankfurt 2016 66.00000     1744
61    Hannover 2005 39.82472        1
62    Hannover 2006 41.25841        1
63    Hannover 2007 40.80456        1
64    Hannover 2008 42.19192        1
65    Hannover 2009 36.96012        1
66    Hannover 2010 45.83055        5
67    Hannover 2011 49.86364       35
68    Hannover 2012 51.11023      167
69    Hannover 2013 52.69465      351
70    Hannover 2014 56.22519      983
71    Hannover 2015 56.95612     1413
72    Hannover 2016 61.00000     1864
73     Leipzig 2005 29.05982        1
74     Leipzig 2006 34.52306        1
75     Leipzig 2007 35.97303        1
76     Leipzig 2008 40.03798        1
77     Leipzig 2009 37.67574        2
78     Leipzig 2010 44.19365        3
79     Leipzig 2011 44.72397       53
80     Leipzig 2012 49.55416      223
81     Leipzig 2013 52.92384      488
82     Leipzig 2014 53.50600      918
83     Leipzig 2015 54.62963     1517
84     Leipzig 2016 59.00000     2037
85    N?rnberg 2005 43.51885        1
86    N?rnberg 2006 49.13278        1
87    N?rnberg 2007 46.92181        1
88    N?rnberg 2008 52.03628        1
89    N?rnberg 2009 43.45030        1
90    N?rnberg 2010 55.44258        5
91    N?rnberg 2011 57.21674       48
92    N?rnberg 2012 62.36625      145
93    N?rnberg 2013 61.49312      297
94    N?rnberg 2014 66.22809      505
95    N?rnberg 2015 63.38028      813
96    N?rnberg 2016 72.00000     1101
97     Rostock 2005 32.56640        1
98     Rostock 2006 30.71011        1
99     Rostock 2007 33.71970        1
100    Rostock 2008 34.25922        1
101    Rostock 2009 34.60181        1
102    Rostock 2010 40.17270        1
103    Rostock 2011 42.06082        3
104    Rostock 2012 42.43937       15
105    Rostock 2013 43.67011       43
106    Rostock 2014 43.93213       93
107    Rostock 2015 47.35883      174
108    Rostock 2016 52.00000      243
109  Stuttgart 2005 50.72972        1
110  Stuttgart 2006 58.74502        1
111  Stuttgart 2007 53.45797        1
112  Stuttgart 2008 56.18432        1
113  Stuttgart 2009 46.29588        1
114  Stuttgart 2010 56.38839        2
115  Stuttgart 2011 58.92586       33
116  Stuttgart 2012 61.16505       96
117  Stuttgart 2013 60.12524      200
118  Stuttgart 2014 65.89726      409
119  Stuttgart 2015 71.49853      661
120  Stuttgart 2016 73.00000      853
121   Wiebaden 2005 37.40724        1
122   Wiebaden 2006 38.94093        1
123   Wiebaden 2007 38.08423        1
124   Wiebaden 2008 38.23657        1
125   Wiebaden 2009 34.98646        1
126   Wiebaden 2010 40.72424        2
127   Wiebaden 2011 44.59304        8
128   Wiebaden 2012 47.58078       27
129   Wiebaden 2013 46.86706       59
130   Wiebaden 2014 46.58586      110
131   Wiebaden 2015 48.12320      163
132   Wiebaden 2016 50.00000      220




Am 30.05.2017 um 20:30 schrieb Ismail SEZEN:
>
>> On 30 May 2017, at 21:23, Tobias Christoph <s3tochri at uni-bayreuth.de 
>> <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>
>> Ahh, okay.
>>
>> I think now I understand what you exactly mean. But the plot is stil 
>> not working /differentiate the dots by color. I used the following 
>> formula.
>>
>> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", 
>> col = findInterval(data$year, c(2005, 2010, 2015))"
>>
>> I think the problem is stil related to the term "col = 
>> findInterval(data$year, c(2005, 2010, 2015))" and its notation.
>>
>> Just to make sure: "data" is the name of the data-table imported in 
>> R. "year" is the lable of the column where the years are listed in 
>> the data-table?
>>
> Exactly. Make sure all the columns in data.frame are numeric. Also I 
> don?t know the range of years. You should arrange arguments to 
> findInterval according your data. If you would send a minimal example 
> as stated in posting guide [1], you will have your answer in second 
> email :).
>
> 1- http://www.R-project.org/posting-guide.html
>
>> Cheers
>>
>>
>>
>> Am 30.05.2017 um 19:57 schrieb Ismail SEZEN:
>>>
>>>> On 30 May 2017, at 20:48, Tobias Christoph 
>>>> <s3tochri at uni-bayreuth.de <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>>>
>>>> Hi Ismael,
>>>>
>>>> thanks for your quick reply.
>>>>
>>>> I was now able to esmitate two intervals with the 
>>>> "findInterval"-Function.
>>>>
>>>>    x
>>>>   [1,] 2005 1
>>>>   [2,] 2006 1
>>>>   [3,] 2007 1
>>>>   [4,] 2008 1
>>>>   [5,] 2009 1
>>>>   [6,] 2010 1
>>>>   [7,] 2011 2
>>>>   [8,] 2012 2
>>>>   [9,] 2013 2
>>>> [10,] 2014 2
>>>> [11,] 2015 2
>>>> [12,] 2016 2
>>>>
>>>> But I was not able to connect the intervals with the plot-function. 
>>>> I used the following formular.
>>>>
>>>> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", 
>>>> col(findInterval())"
>>>>
>>> In fact I should say ?feed _col_ or _pch_ argument with the result 
>>> of findInterval? as below:
>>>
>>> plot(data$stations, data$revenue, xlab="stations", ylab="revenue", 
>>> col = findInterval(x$year, c(2005, 2010, 2015))
>>>
>>> Please note that If you have many (20-30) intervals, colour handling 
>>> will be more complex. But I assume you have maximum 5-10 intervals. 
>>> So, the piece of code above will work for you.
>>>
>>>> How can I proceed and get the plot-funktion running?
>>>>
>>>> Maybe it is not running because the years as single numbers are 
>>>> already contained in my data-frame?
>>>>
>>>> Cheers,
>>>>
>>>> Toby
>>>>
>>>>
>>>>
>>>> Am 30.05.2017 um 18:26 schrieb Ismail SEZEN:
>>>>>> On 30 May 2017, at 19:02, Tobias Christoph<s3tochri at uni-bayreuth.de>  wrote:
>>>>>>
>>>>>> Hey Guys,
>>>>>>
>>>>>> I just try to differentiate certain values in my plot by colour or symbol.
>>>>>>
>>>>>> I have panel data with three dimensions (number of stations, revenue,
>>>>>> years). To integrate the third dimension (years) in the plot, I want to
>>>>>> differentiate the values(number of stations, revenue) by a certain range
>>>>>> of years.
>>>>>>
>>>>>> e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots
>>>>>>
>>>>>> For the normal plot I used the following formula:
>>>>>>
>>>>>> *plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*
>>>>>>
>>>>>> I only found a way to mark every single year. So hopefully you can help?
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Toby
>>>>>>
>>>>> See ?findInterval. Especially, first 3 lines in _Examples_ section. Use result of findInterval as argument to _col_ or _pch_ in plot function.
>>>>>
>>>>>
>>>>
>>>
>>
>


From barry.king at qlx.com  Tue May 30 20:54:38 2017
From: barry.king at qlx.com (Barry King)
Date: Tue, 30 May 2017 14:54:38 -0400
Subject: [R] seek non-black box alternative to randomForest
Message-ID: <CAP8WkrxiAhUBVTXAuPLG9qphR9iPpV_Rxmeuis1BBtZsFLQxug@mail.gmail.com>

I've recently had a research manuscript rejected by an editor. The
manuscript showed
that for a real life data set, random forest outperformed multiple linear
regression
with respect to predicting the target variable. The editor's objection was
that
random forest is a black box where the random assignment of features to
trees was
intractable. I need to find an alternative method to random forest that
does not
suffer from the black box label. Any suggestions? Would caret::treebag be
free of
random assignment of features? Your assistance is appreciated.

--

	[[alternative HTML version deleted]]


From percentil101 at gmail.com  Tue May 30 19:41:03 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Tue, 30 May 2017 19:41:03 +0200
Subject: [R] (no subject)
Message-ID: <CAB-TgNu=ZX6d=NjRby5Twmybzd_miaXHMyH7kFYj_nbjMbZsug@mail.gmail.com>

Hi all,

I get started with R till many time ago.

I want to make a function that makes a plot with several inputs.

First of all, the first input is a date 01/01/2014.

I make a plot of a calculated series from 01/01/2014 till TODAY.

How can I make this vector authomatically without calculating in Excel?

Then I have a value for instance 6 and then a value 30.000

So each day the associated vector minorates 6.

the final matrix will be somenting like this

result

01/01/2014 30000
02/01/2014  29994
03/01/2014 29988
...
....
30/05/2017 (today)

Finally I want to plot the series but with left and right axis on de Y (the
horizontal axes is time)

Can you guide me?

I?m reading manual but I need it urgently so please receive my apologuises
if it is not very clever to ask help for you.

I?m sure I will achive but if you can guide me I will earn time to learn
what I need.

Many thanks in advance

	[[alternative HTML version deleted]]


From percentil101 at gmail.com  Tue May 30 20:18:28 2017
From: percentil101 at gmail.com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Tue, 30 May 2017 20:18:28 +0200
Subject: [R] (no subject)
In-Reply-To: <CAB-TgNu=ZX6d=NjRby5Twmybzd_miaXHMyH7kFYj_nbjMbZsug@mail.gmail.com>
References: <CAB-TgNu=ZX6d=NjRby5Twmybzd_miaXHMyH7kFYj_nbjMbZsug@mail.gmail.com>
Message-ID: <CAB-TgNtp=U49xgpNWxvT1Evuq4SBYGH1MxfFUvhTz9tAX=NyZg@mail.gmail.com>

I have seen that the vector of dates could be:

itemizeDates(startDate="12-30-11", endDate="1-4-12")

How can I say "today" without having to declare the endDate?

Finally, if you can help mi with the plot would be very helpfull



2017-05-30 19:41 GMT+02:00 Pedro p?ramo <percentil101 at gmail.com>:

> Hi all,
>
> I get started with R till many time ago.
>
> I want to make a function that makes a plot with several inputs.
>
> First of all, the first input is a date 01/01/2014.
>
> I make a plot of a calculated series from 01/01/2014 till TODAY.
>
> How can I make this vector authomatically without calculating in Excel?
>
> Then I have a value for instance 6 and then a value 30.000
>
> So each day the associated vector minorates 6.
>
> the final matrix will be somenting like this
>
> result
>
> 01/01/2014 30000
> 02/01/2014  29994
> 03/01/2014 29988
> ...
> ....
> 30/05/2017 (today)
>
> Finally I want to plot the series but with left and right axis on de Y
> (the horizontal axes is time)
>
> Can you guide me?
>
> I?m reading manual but I need it urgently so please receive my apologuises
> if it is not very clever to ask help for you.
>
> I?m sure I will achive but if you can guide me I will earn time to learn
> what I need.
>
> Many thanks in advance
>
>
>

	[[alternative HTML version deleted]]


From jacob-simmering at uiowa.edu  Tue May 30 21:27:42 2017
From: jacob-simmering at uiowa.edu (Simmering, Jacob E)
Date: Tue, 30 May 2017 19:27:42 +0000
Subject: [R] seek non-black box alternative to randomForest
In-Reply-To: <CAP8WkrxiAhUBVTXAuPLG9qphR9iPpV_Rxmeuis1BBtZsFLQxug@mail.gmail.com>
References: <CAP8WkrxiAhUBVTXAuPLG9qphR9iPpV_Rxmeuis1BBtZsFLQxug@mail.gmail.com>
Message-ID: <34FA83BB-2FFA-4CAA-92D2-75C77286765B@uiowa.edu>

Barry, 

This is mostly a mailing list about R - you have have more luck with statistical questions on www.stat.stackexchange.com. 

That said - the editor is wrong. The limitations of trees that random forests ?solves? is overfitting. The mechanism by which a random forest classifier is built is not a black box - some number of features and some number of rows are selected to produce a split. The reasons why this approach avoids the issues associated with trees is also clear. These are theory based claims. The random selection is critical to the function of the process. I?d suggest resubmitting the paper to a different journal instead of trying to find some way to fit a random forest without the random part.  


> On May 30, 2017, at 1:54 PM, Barry King <barry.king at qlx.com> wrote:
> 
> I've recently had a research manuscript rejected by an editor. The
> manuscript showed
> that for a real life data set, random forest outperformed multiple linear
> regression
> with respect to predicting the target variable. The editor's objection was
> that
> random forest is a black box where the random assignment of features to
> trees was
> intractable. I need to find an alternative method to random forest that
> does not
> suffer from the black box label. Any suggestions? Would caret::treebag be
> free of
> random assignment of features? Your assistance is appreciated.
> 
> --
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Tue May 30 21:29:46 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 30 May 2017 22:29:46 +0300
Subject: [R] Differentiate values in a plot by colour or symbol
In-Reply-To: <ad924fab-6bb0-3c75-c72f-297fc08447bc@uni-bayreuth.de>
References: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
 <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>
 <798b7584-9543-d93d-11a6-e428a9694024@uni-bayreuth.de>
 <238165CC-17AE-4F64-80F3-F68D7B9C4F98@gmail.com>
 <a5c2f116-cd2c-d616-bdcc-662142215d9d@uni-bayreuth.de>
 <F5DD6376-AE75-4904-BD02-F29F321BF414@gmail.com>
 <ad924fab-6bb0-3c75-c72f-297fc08447bc@uni-bayreuth.de>
Message-ID: <EF9E4056-17D6-434A-83B6-24CD09C57360@gmail.com>


> On 30 May 2017, at 21:44, Tobias Christoph <s3tochri at uni-bayreuth.de> wrote:
> 
> Okay;)
> 
> First of all many thanks to you, Ismail, that you really try to help me. I am really not an expert with R and try to learn.
> 
You?re welcome.

> I just checked: All columns in my data frame are numeric. The range of years is from 2005 to 2016.
> 
> Please find attached the result of "data.frame(data)". I also attached it as Excel-file
> > data.frame(data)
>           town year  revenue stations
> 1       Bremen 2005 39.91036        1
> 2       Bremen 2006 43.34265        1
> 3       Bremen 2007 44.03614        1
> 4       Bremen 2008 43.19945        1
> 5       Bremen 2009 39.05230        1
> 6       Bremen 2010 44.24626        1
> 7       Bremen 2011 46.19309       35
> 8       Bremen 2012 48.59513      101
> 9       Bremen 2013 48.15778      181
> 10      Bremen 2014 48.83199      323
> 11      Bremen 2015 48.68549      463
> 12      Bremen 2016 50.00000      614
> 13     Dresden 2005 42.27858        1
> 14     Dresden 2006 50.39606        1
> 15     Dresden 2007 48.73299        1
> 16     Dresden 2008 42.69010        1
> 17     Dresden 2009 40.81174        1
> 18     Dresden 2010 47.09675        2
> 19     Dresden 2011 49.16900       43
> 20     Dresden 2012 48.13645      151
> 21     Dresden 2013 48.13645      284
> 22     Dresden 2014 49.77309      511
> 23     Dresden 2015 51.51515      773
> 24     Dresden 2016 51.00000     1057
> 25  D?sseldorf 2005 44.23227        1
> 26  D?sseldorf 2006 46.70928        1
> 27  D?sseldorf 2007 51.24008        1
> 28  D?sseldorf 2008 61.59058        1
> 29  D?sseldorf 2009 45.70021        1
> 30  D?sseldorf 2010 57.17096        8
> 31  D?sseldorf 2011 60.60122      115
> 32  D?sseldorf 2012 65.50992      339
> 33  D?sseldorf 2013 64.06870      636
> 34  D?sseldorf 2014 71.56474     1117
> 35  D?sseldorf 2015 68.20119     1622
> 36  D?sseldorf 2016 80.00000     2117
> 37       Essen 2005 37.71029        1
> 38       Essen 2006 44.61127        1
> 39       Essen 2007 41.39926        1
> 40       Essen 2008 49.34792        1
> 41       Essen 2009 38.49137        1
> 42       Essen 2010 51.57844        1
> 43       Essen 2011 48.38058       29
> 44       Essen 2012 50.17066       42
> 45       Essen 2013 49.26759       90
> 46       Essen 2014 50.20367      162
> 47       Essen 2015 47.89430      258
> 48       Essen 2016 58.00000      370
> 49   Frankfurt 2005 47.97355        1
> 50   Frankfurt 2006 50.37223        1
> 51   Frankfurt 2007 49.11292        1
> 52   Frankfurt 2008 49.65316        1
> 53   Frankfurt 2009 44.53889        3
> 54   Frankfurt 2010 54.02567       15
> 55   Frankfurt 2011 56.29475       80
> 56   Frankfurt 2012 59.10949      223
> 57   Frankfurt 2013 62.30140      488
> 58   Frankfurt 2014 62.67521      836
> 59   Frankfurt 2015 66.93712     1319
> 60   Frankfurt 2016 66.00000     1744
> 61    Hannover 2005 39.82472        1
> 62    Hannover 2006 41.25841        1
> 63    Hannover 2007 40.80456        1
> 64    Hannover 2008 42.19192        1
> 65    Hannover 2009 36.96012        1
> 66    Hannover 2010 45.83055        5
> 67    Hannover 2011 49.86364       35
> 68    Hannover 2012 51.11023      167
> 69    Hannover 2013 52.69465      351
> 70    Hannover 2014 56.22519      983
> 71    Hannover 2015 56.95612     1413
> 72    Hannover 2016 61.00000     1864
> 73     Leipzig 2005 29.05982        1
> 74     Leipzig 2006 34.52306        1
> 75     Leipzig 2007 35.97303        1
> 76     Leipzig 2008 40.03798        1
> 77     Leipzig 2009 37.67574        2
> 78     Leipzig 2010 44.19365        3
> 79     Leipzig 2011 44.72397       53
> 80     Leipzig 2012 49.55416      223
> 81     Leipzig 2013 52.92384      488
> 82     Leipzig 2014 53.50600      918
> 83     Leipzig 2015 54.62963     1517
> 84     Leipzig 2016 59.00000     2037
> 85    N?rnberg 2005 43.51885        1
> 86    N?rnberg 2006 49.13278        1
> 87    N?rnberg 2007 46.92181        1
> 88    N?rnberg 2008 52.03628        1
> 89    N?rnberg 2009 43.45030        1
> 90    N?rnberg 2010 55.44258        5
> 91    N?rnberg 2011 57.21674       48
> 92    N?rnberg 2012 62.36625      145
> 93    N?rnberg 2013 61.49312      297
> 94    N?rnberg 2014 66.22809      505
> 95    N?rnberg 2015 63.38028      813
> 96    N?rnberg 2016 72.00000     1101
> 97     Rostock 2005 32.56640        1
> 98     Rostock 2006 30.71011        1
> 99     Rostock 2007 33.71970        1
> 100    Rostock 2008 34.25922        1
> 101    Rostock 2009 34.60181        1
> 102    Rostock 2010 40.17270        1
> 103    Rostock 2011 42.06082        3
> 104    Rostock 2012 42.43937       15
> 105    Rostock 2013 43.67011       43
> 106    Rostock 2014 43.93213       93
> 107    Rostock 2015 47.35883      174
> 108    Rostock 2016 52.00000      243
> 109  Stuttgart 2005 50.72972        1
> 110  Stuttgart 2006 58.74502        1
> 111  Stuttgart 2007 53.45797        1
> 112  Stuttgart 2008 56.18432        1
> 113  Stuttgart 2009 46.29588        1
> 114  Stuttgart 2010 56.38839        2
> 115  Stuttgart 2011 58.92586       33
> 116  Stuttgart 2012 61.16505       96
> 117  Stuttgart 2013 60.12524      200
> 118  Stuttgart 2014 65.89726      409
> 119  Stuttgart 2015 71.49853      661
> 120  Stuttgart 2016 73.00000      853
> 121   Wiebaden 2005 37.40724        1
> 122   Wiebaden 2006 38.94093        1
> 123   Wiebaden 2007 38.08423        1
> 124   Wiebaden 2008 38.23657        1
> 125   Wiebaden 2009 34.98646        1
> 126   Wiebaden 2010 40.72424        2
> 127   Wiebaden 2011 44.59304        8
> 128   Wiebaden 2012 47.58078       27
> 129   Wiebaden 2013 46.86706       59
> 130   Wiebaden 2014 46.58586      110
> 131   Wiebaden 2015 48.12320      163
> 132   Wiebaden 2016 50.00000      220
> 
> 


Insead of copy and paste data.frame or attach an excel file, learn how to create a minimal example as below:

set.seed(6)
data <- data.frame(
  town = rep(LETTERS, each = 5, times = 5)[1:60],
  year = rep(2005:2016, times = 5),
  revenue = rnorm(60, 35),
  stations = round(rnorm(60, 250, 100)))

plot(data$stations, data$revenue, xlab="stations", ylab="revenue", pch = 16, col = findInterval(data$year, c(2005, 2010, 2016)))

I created a fake data.frame similar your original one and used it to plot. See the result of plot. It works as intended. 

let?s check result of findInterval function.

findInterval(data$year, c(2005, 2010, 2016))
[1] 1 1 1 1 1 2 2 2 2 2 2 3 1 1 1 1 1 2 2 2 2 2 2 3 1 1 1 1 1 2 2 2 2 2 2 3 1 1 1 1 1 2 2 2 2 2 2 3 1 1 1 1 1 2 2 2 2 2 2 3

and see the result of palette function.

palette()
"black"   "red"     "green3"  "blue"    "cyan"    "magenta" "yellow"  "gray"

as you noticed, black dots in the plot will be belong to years between 2005-2009, red dots will be belong to 2010-2015 and green dots will be belong to only 2016. 

I hope your next questions follow this guide and make things easier for you and us :)


> 
> 
> Am 30.05.2017 um 20:30 schrieb Ismail SEZEN:
>> 
>>> On 30 May 2017, at 21:23, Tobias Christoph <s3tochri at uni-bayreuth.de <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>> 
>>> Ahh, okay.
>>> 
>>> I think now I understand what you exactly mean. But the plot is stil not working /differentiate the dots by color. I used the following formula.
>>> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col = findInterval(data$year, c(2005, 2010, 2015))"
>>> 
>>> I think the problem is stil related to the term "col = findInterval(data$year, c(2005, 2010, 2015))" and its notation.
>>> 
>>> Just to make sure: "data" is the name of the data-table imported in R. "year" is the lable of the column where the years are listed in the data-table?
>>> 
>> Exactly. Make sure all the columns in data.frame are numeric. Also I don?t know the range of years. You should arrange arguments to findInterval according your data. If you would send a minimal example as stated in posting guide [1], you will have your answer in second email :).
>> 
>> 1- http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> 
>>> Cheers
>>> 
>>> 
>>> 
>>> Am 30.05.2017 um 19:57 schrieb Ismail SEZEN:
>>>> 
>>>>> On 30 May 2017, at 20:48, Tobias Christoph <s3tochri at uni-bayreuth.de <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>>>> 
>>>>> Hi Ismael,
>>>>> 
>>>>> thanks for your quick reply.
>>>>> 
>>>>> I was now able to esmitate two intervals with the "findInterval"-Function.
>>>>> 
>>>>>   x  
>>>>>  [1,] 2005 1
>>>>>  [2,] 2006 1
>>>>>  [3,] 2007 1
>>>>>  [4,] 2008 1
>>>>>  [5,] 2009 1
>>>>>  [6,] 2010 1
>>>>>  [7,] 2011 2
>>>>>  [8,] 2012 2
>>>>>  [9,] 2013 2
>>>>> [10,] 2014 2
>>>>> [11,] 2015 2
>>>>> [12,] 2016 2
>>>>> But I was not able to connect the intervals with the plot-function. I used the following formular.
>>>>> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col(findInterval())"
>>>>> 
>>>> In fact I should say ?feed _col_ or _pch_ argument with the result of findInterval? as below:
>>>> 
>>>> plot(data$stations, data$revenue, xlab="stations", ylab="revenue", col = findInterval(x$year, c(2005, 2010, 2015))
>>>> 
>>>> Please note that If you have many (20-30) intervals, colour handling will be more complex. But I assume you have maximum 5-10 intervals. So, the piece of code above will work for you.
>>>> 
>>>>> How can I proceed and get the plot-funktion running?
>>>>> Maybe it is not running because the years as single numbers are already contained in my data-frame?
>>>>> Cheers,
>>>>> 
>>>>> Toby
>>>>> 
>>>>> 
>>>>> Am 30.05.2017 um 18:26 schrieb Ismail SEZEN:
>>>>>>> On 30 May 2017, at 19:02, Tobias Christoph <s3tochri at uni-bayreuth.de> <mailto:s3tochri at uni-bayreuth.de> wrote:
>>>>>>> 
>>>>>>> Hey Guys,
>>>>>>> 
>>>>>>> I just try to differentiate certain values in my plot by colour or symbol.
>>>>>>> 
>>>>>>> I have panel data with three dimensions (number of stations, revenue, 
>>>>>>> years). To integrate the third dimension (years) in the plot, I want to 
>>>>>>> differentiate the values(number of stations, revenue) by a certain range 
>>>>>>> of years.
>>>>>>> 
>>>>>>> e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots
>>>>>>> 
>>>>>>> For the normal plot I used the following formula:
>>>>>>> 
>>>>>>> *plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*
>>>>>>> 
>>>>>>> I only found a way to mark every single year. So hopefully you can help?
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> 
>>>>>>> Toby
>>>>>>> 
>>>>>> See ?findInterval. Especially, first 3 lines in _Examples_ section. Use result of findInterval as argument to _col_ or _pch_ in plot function.
>>>>>> 
>>>>>> 
>>>>> 
>>>> 
>>> 
>> 
> 
> <data.xlsx>


	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Tue May 30 21:47:51 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Tue, 30 May 2017 22:47:51 +0300
Subject: [R] seek non-black box alternative to randomForest
In-Reply-To: <34FA83BB-2FFA-4CAA-92D2-75C77286765B@uiowa.edu>
References: <CAP8WkrxiAhUBVTXAuPLG9qphR9iPpV_Rxmeuis1BBtZsFLQxug@mail.gmail.com>
 <34FA83BB-2FFA-4CAA-92D2-75C77286765B@uiowa.edu>
Message-ID: <DC5FE6E4-85EB-4770-9EA2-D8D0042F8E37@gmail.com>

I?m interested in the subject. If you send the question to another platform, please share the link here to follow up. Also, I wish to see the manuscript and rejected parts and detailed reasons. Most of the time, scientists want to reveal/discuss underlying physical process in an event and it?s not enough to show that method A is better than method B. Perhaps, discussions and why the randomforest is better than multiple linear regression is not enough for him. This also may mean black box.

> On 30 May 2017, at 22:27, Simmering, Jacob E <jacob-simmering at uiowa.edu> wrote:
> 
> Barry, 
> 
> This is mostly a mailing list about R - you have have more luck with statistical questions on www.stat.stackexchange.com. 
> 
> That said - the editor is wrong. The limitations of trees that random forests ?solves? is overfitting. The mechanism by which a random forest classifier is built is not a black box - some number of features and some number of rows are selected to produce a split. The reasons why this approach avoids the issues associated with trees is also clear. These are theory based claims. The random selection is critical to the function of the process. I?d suggest resubmitting the paper to a different journal instead of trying to find some way to fit a random forest without the random part.  
> 
> 
>> On May 30, 2017, at 1:54 PM, Barry King <barry.king at qlx.com> wrote:
>> 
>> I've recently had a research manuscript rejected by an editor. The
>> manuscript showed
>> that for a real life data set, random forest outperformed multiple linear
>> regression
>> with respect to predicting the target variable. The editor's objection was
>> that
>> random forest is a black box where the random assignment of features to
>> trees was
>> intractable. I need to find an alternative method to random forest that
>> does not
>> suffer from the black box label. Any suggestions? Would caret::treebag be
>> free of
>> random assignment of features? Your assistance is appreciated.
>> 
>> --
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue May 30 22:05:43 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 30 May 2017 13:05:43 -0700
Subject: [R] (no subject)
In-Reply-To: <CAB-TgNtp=U49xgpNWxvT1Evuq4SBYGH1MxfFUvhTz9tAX=NyZg@mail.gmail.com>
References: <CAB-TgNu=ZX6d=NjRby5Twmybzd_miaXHMyH7kFYj_nbjMbZsug@mail.gmail.com>
 <CAB-TgNtp=U49xgpNWxvT1Evuq4SBYGH1MxfFUvhTz9tAX=NyZg@mail.gmail.com>
Message-ID: <D74B940B-6C9E-428D-B3FB-8F09FA163D42@comcast.net>


> On May 30, 2017, at 11:18 AM, Pedro p?ramo <percentil101 at gmail.com> wrote:
> 
> I have seen that the vector of dates could be:
> 
> itemizeDates(startDate="12-30-11", endDate="1-4-12")
> 
> How can I say "today" without having to declare the endDate?
> 
> Finally, if you can help mi with the plot would be very helpfull

Look at:

?Sys.Date
# And
?axis

--

David.

> 
> 
> 
> 2017-05-30 19:41 GMT+02:00 Pedro p?ramo <percentil101 at gmail.com>:
> 
>> Hi all,
>> 
>> I get started with R till many time ago.
>> 
>> I want to make a function that makes a plot with several inputs.
>> 
>> First of all, the first input is a date 01/01/2014.
>> 
>> I make a plot of a calculated series from 01/01/2014 till TODAY.
>> 
>> How can I make this vector authomatically without calculating in Excel?
>> 
>> Then I have a value for instance 6 and then a value 30.000
>> 
>> So each day the associated vector minorates 6.
>> 
>> the final matrix will be somenting like this
>> 
>> result
>> 
>> 01/01/2014 30000
>> 02/01/2014  29994
>> 03/01/2014 29988
>> ...
>> ....
>> 30/05/2017 (today)
>> 
>> Finally I want to plot the series but with left and right axis on de Y
>> (the horizontal axes is time)
>> 
>> Can you guide me?
>> 
>> I?m reading manual but I need it urgently so please receive my apologuises
>> if it is not very clever to ask help for you.
>> 
>> I?m sure I will achive but if you can guide me I will earn time to learn
>> what I need.
>> 
>> Many thanks in advance
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Wed May 31 00:05:19 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 30 May 2017 22:05:19 +0000
Subject: [R] Need Help - R Programming - Using iteration value to change
 field names for processing for every iteraion
In-Reply-To: <SIXPR02MB086133829664481794452BC2AEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
References: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>,
 <CAKGzMdbFP5wfYBg5vgKNn=8TuqUehaM4-AdfhbCbTJj6AMHCMg@mail.gmail.com>
 <SIXPR02MB086133829664481794452BC2AEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>
Message-ID: <f4018160ec7042af8cc4eaa82bf0c5b7@exch-2p-mbx-w2.ads.tamu.edu>

Refer to columns by position rather than name and everything is simpler:

for (i in 2:4 ) {
    test[, i] <- test[, i] + test[, i-1]
}

Note your approach fails on the first line since you start with i=1 and there is no Day0. Another approach that is simpler:

t(apply(test, 1, cumsum))


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vijaya Kumar Regati
Sent: Tuesday, May 30, 2017 3:44 AM
To: Manjusha Joshi <manjusha.joshi at gmail.com>
Cc: r-help at R-project.org; vijaykr.sas at gmail.com
Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion

Hi Manjusha,


Thank you for the response. That surely helps.


But the major issue in my case is not how we can apply sum fn, but how we can  change field names based on iteration number.

I cant skip loop in my case, because in real situation I have to deal with say around 100 fields, the only thing that changes is Day number in field name and the iteration number should be able to handle that.


With Regards,
Vijaya Kumar Regati
Technical Lead, M3bi India Private Ltd
Work: 040-67064732

________________________________
From: Manjusha Joshi <manjusha.joshi at gmail.com>
Sent: Tuesday, May 30, 2017 1:42:10 PM
To: Vijaya Kumar Regati
Cc: r-help at R-project.org; vijaykr.sas at gmail.com
Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion

Hello Vijaya,

On Tue, May 30, 2017 at 12:32 PM, Vijaya Kumar Regati <VijayaKumar.Regati at m3bi.com<mailto:VijayaKumar.Regati at m3bi.com>> wrote:
Hi,

I am new to R programming, I am trying to work on below requirement. But could not achieve desired result.
Appreciate if someone can help me on this :

test dataframe :
  Day1.balc Day2.balc Day3.balc Day4.balc
x       100        20        30        40
y       100        10        10        10
> class(test)
[1] "data.frame"

My Goal is to accomplish :
Day2.balc <- Day2.balc + Day1.balc
Day3.balc <- Day3.balc + Day2.balc
.
.
.
Day30.balc <- Day30.balc + Day29.balc

    # Testing for first 4 days
    for (i in 1:4 ) {
    test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
    }

I identified the line I have written inside the loop is not the correct one, can someone help me how I can use iteration value(i), for every iteration, as a basis for changing field names since field consists of 1,2,3... for each different day( Day1.balc Day2.balc Day3.balc Day4.balc etc.,).

?
?There are many built in functions in R which will help to avoid loops.
Try 'cumsum' to add entries in a row to get cumulative sum. Use 'apply' to avoid loops.

df is the dataframe in which your data has been stored.

t(apply,df,1,cumsum)

will give you the required results.
Please check help of  'apply' for more details.
Best wishes,



?

?

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Manjusha S. Joshi
Mobile:  09822 319328
Pune, India
blog:http://manjushajoshi.wordpress.com/


Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bertcarnell at gmail.com  Wed May 31 01:26:08 2017
From: bertcarnell at gmail.com (Rob C)
Date: Tue, 30 May 2017 19:26:08 -0400
Subject: [R] Latin Hypercube Sampling when parameters are defined
 according to specific probability distributions
In-Reply-To: <CY1PR05MB2730F1E421CF600D3A9890E799F00@CY1PR05MB2730.namprd05.prod.outlook.com>
References: <CAPtunJZJ0HpZGGaNjpfbHL_bMxHeACJ21kzpP2Zv1+qtcnTMhg@mail.gmail.com>
 <CY1PR05MB2730F1E421CF600D3A9890E799F00@CY1PR05MB2730.namprd05.prod.outlook.com>
Message-ID: <CAPtunJae1UcgrsOyS8+98BHT0E5ysnbmKumWj0zX8jOts+TsAg@mail.gmail.com>

Nell,

I still might not be interpreting your question correctly, but I will try.

When you say that the sum of the probabilities of all distance classes
must equal one, I am going to treat distance as a class, instead of as a
continuous variable.

distance_class_probabilities <- c(9, 11, 10, 8.9, 8, 7, 6, 5.8, 5.1,
4, 3.9, 3.7, 3.4, 3.1, 2, 1.9, 1.6, 1.4, 1, 0.9, 0.8, 0.7, 0.4, 0.3,
0.1)/100
sum(distance_class_probabilities)
distance_classes <- factor(paste0("d", 1:25), ordered = TRUE,
levels=paste0("d", 1:25))
input_parameters <- c("dispersal_distance", "temperature", "pressure")
N <- 1000

plot(1:25, distance_class_probabilities, type="h", lwd=5)

set.seed(1)
require(lhs)
X <- randomLHS(N, length(input_parameters))
dimnames(X) <- list(NULL, input_parameters)
Y <- X
Y[,"dispersal_distance"] <-
approx(x=cumsum(distance_class_probabilities), y=1:25,
xout=X[,"dispersal_distance"], method="constant", yleft=0)$y + 1

hist(Y[,"dispersal_distance"], breaks=c(seq(0.5, 25.5, by=1)))
plot(table(distance_classes[Y[,"dispersal_distance"]]))


Is it still a Latin hypercube?

This is a more difficult question.  In some ways, the sample is still a Latin
hypercube since it was drawn that way.  But once the sample has been discretized
into the distance classes, then it loses the latin property of having only one
sample per "row".  It might be close enough for your purposes though.

Rob



On Tue, May 30, 2017 at 10:59 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Thanks a lot Rob for your answer. I need to add a condition for the
> parameter ?dispersal distance?. The sum of the probabilities of all distance
> classes must be equal to 1:
>
> y <- c(9, 11, 10, 8.9, 8, 7, 6, 5.8, 5.1, 4, 3.9, 3.7, 3.4, 3.1, 2, 1.9,
> 1.6, 1.4, 1, 0.9, 0.8, 0.7, 0.4, 0.3, 0.1)
>
> x <- seq(1, 25, by = 1)
>
> barplot(y/100, names.arg=x, ylab="Probability", xlab="Distance (km)")
>
>
>
> With this condition, is it possible to perform a LHS?
>
> Thanks a lot for your time.
>
> Nell
>
>
> ________________________________
> De : R-help <r-help-bounces at r-project.org> de la part de Rob C
> <bertcarnell at gmail.com>
> Envoy? : samedi 27 mai 2017 13:32:23
> ? : r-help at r-project.org
> Objet : Re: [R] Latin Hypercube Sampling when parameters are defined
> according to specific probability distributions
>
>>May 26, 2017; 11:41am  Nelly Reduan Latin Hypercube Sampling when
>> parameters are >defined according to specific probability distributions
>>Hello,
>> I would like to perform a sensitivity analysis using a Latin Hypercube
>> Sampling (LHS).
>>Among the input parameters in the model, I have a parameter dispersal
>> distance which is defined according to an exponential probability
>> distribution.
>
>>In the model, the user thus sets a default probability value for each
>> distance class.
>
>>For example, for distances ([0  2]; ]2  4]; ]4  6]; ]6  8]; ]8  10];; ]48
>> 50],
>
>>respective probabilities are 0.055; 0.090; 0.065; 0.035; 0.045;; 0.005.
>
>  >Here is the code to represent an exponential probability
> distribution for the parameter dispersal distance:
>
>>set.seed(0)
>>foo <- rexp(100, rate = 1/10)
>>hist(foo, prob=TRUE, breaks=20, ylim=c(0,0.1), xlab ="Distance (km)")
>>lines(dexp(seq(1, 100, by = 1), rate = 1/mean(foo)),col="red")
>>1/mean(foo)
>
>>When a parameter is defined according to a specific probability
>> distribution, how can I perform a LHS ?
>>For example, should I sample N values from a uniform distribution for each
>> distance class (i.e., [0 ? 2]; ]2 ? 4]; ]4 ? 6]; ]6 ? 8]; ]8 ? 10];??; ]48 ?
>> 50])
>>or sample N values from exponential distributions with different rates ?
>
>>Here is the code used to perform a LHS when the parameter ?dispersal
>> distance? is defined by one default value in the model:
>
>>library(pse)
>>factors <- c("distance")
>>q <- c("qexp")
>>q.arg <- list( list(rate=1/30) )
>>uncoupledLHS <- LHS(model=NULL, factors, 50, q, q.arg)
>>head(uncoupledLHS)
>
>>Thanks a lot for your time.
>>Have a nice day
>>Nell
>
> Nell,
>
> I would like to suggest a slightly different method for generating the
> sample using the lhs library,  then I will try using the pse library.
> Generally when you have a package specific
> question, you should try to contact the package maintainer first.
>
> set.seed(1)
> # I don't think your model has only one parameter, so I will include
> multiple
> input_parameters <- c("dispersal_distance", "temperature", "pressure")
> N <- 50
> exponential_rate <- 1/30
>
> library(lhs)
> X <- randomLHS(N, length(input_parameters))
> dimnames(X) <- list(NULL, input_parameters)
> # X is now a uniformly distributed Latin hypercube
> head(X)
> hist(X[,1], breaks=5)
> hist(X[,2], breaks=5)
> hist(X[,3], breaks=5)
> # now, transform the dispersal_distance paramter to an exponential sample
> Y <- X
> Y[,"dispersal_distance"] <- qexp(X[,"dispersal_distance"],
> rate=exponential_rate)
> hist(Y[,1], breaks=10)
> # you can transform the other marginals as required and then assess
> function sensitivity
> model_function <- function(z) z[1]*z[2] + z[3]
> apply(Y, 1, model_function)
>
> # now, trying to use pse
> library(pse)
> q <- list("qexp", "qunif", "qunif")
> q.arg <- list(list(rate=exponential_rate), list(min=0, max=1),
> list(min=0, max=1))
> uncoupledLHS <- LHS(model=model_function, input_parameters, N, q, q.arg)
> hist(uncoupledLHS$data$dispersal_distance, breaks=10)
>
> Rob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dmck at u.washington.edu  Tue May 30 21:11:19 2017
From: dmck at u.washington.edu (Don McKenzie)
Date: Tue, 30 May 2017 12:11:19 -0700
Subject: [R] seek non-black box alternative to randomForest
In-Reply-To: <CAP8WkrxiAhUBVTXAuPLG9qphR9iPpV_Rxmeuis1BBtZsFLQxug@mail.gmail.com>
References: <CAP8WkrxiAhUBVTXAuPLG9qphR9iPpV_Rxmeuis1BBtZsFLQxug@mail.gmail.com>
Message-ID: <EA497BBA-EDE2-4322-9F57-0566058A4212@u.washington.edu>

Though off-topic for this list, your question (complaint?) comes up a lot in discussions of analytical methods, and has generated hundreds of papers (Google is your friend here).
You can start with

https://www.quora.com/What-are-the-pros-and-cons-of-GLM-vs-Random-forest-vs-SVM <https://www.quora.com/What-are-the-pros-and-cons-of-GLM-vs-Random-forest-vs-SVM>

for some of the controversies.  It looks to me as if your editor stated (poorly) the problem that some models that are good at pattern-matching (RF) are less useful for predicting new observations.

Others n the list who are more erudite than I may choose to comment, amplify, or refute...


> On May 30, 2017, at 11:54 AM, Barry King <barry.king at qlx.com> wrote:
> 
> I've recently had a research manuscript rejected by an editor. The
> manuscript showed
> that for a real life data set, random forest outperformed multiple linear
> regression
> with respect to predicting the target variable. The editor's objection was
> that
> random forest is a black box where the random assignment of features to
> trees was
> intractable. I need to find an alternative method to random forest that
> does not
> suffer from the black box label. Any suggestions? Would caret::treebag be
> free of
> random assignment of features? Your assistance is appreciated.
> 
> --
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




From VijayaKumar.Regati at m3bi.com  Wed May 31 06:24:45 2017
From: VijayaKumar.Regati at m3bi.com (Vijaya Kumar Regati)
Date: Wed, 31 May 2017 04:24:45 +0000
Subject: [R] Need Help - R Programming - Using iteration value to change
 field names for processing for every iteraion
In-Reply-To: <f4018160ec7042af8cc4eaa82bf0c5b7@exch-2p-mbx-w2.ads.tamu.edu>
References: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>,
 <CAKGzMdbFP5wfYBg5vgKNn=8TuqUehaM4-AdfhbCbTJj6AMHCMg@mail.gmail.com>
 <SIXPR02MB086133829664481794452BC2AEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>,
 <f4018160ec7042af8cc4eaa82bf0c5b7@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <SIXPR02MB0861B6DCAE8E57401344150EAEF10@SIXPR02MB0861.apcprd02.prod.outlook.com>

Thanks very much.

Can someone suggest me how I can close this qn, since I have the solution now ?


With Regards,
Vijaya Kumar Regati
Technical Lead, M3bi India Private Ltd
Work: 040-67064732

________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: Wednesday, May 31, 2017 3:35:19 AM
To: Vijaya Kumar Regati; Manjusha Joshi
Cc: r-help at R-project.org; vijaykr.sas at gmail.com
Subject: RE: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion

Refer to columns by position rather than name and everything is simpler:

for (i in 2:4 ) {
    test[, i] <- test[, i] + test[, i-1]
}

Note your approach fails on the first line since you start with i=1 and there is no Day0. Another approach that is simpler:

t(apply(test, 1, cumsum))


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vijaya Kumar Regati
Sent: Tuesday, May 30, 2017 3:44 AM
To: Manjusha Joshi <manjusha.joshi at gmail.com>
Cc: r-help at R-project.org; vijaykr.sas at gmail.com
Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion

Hi Manjusha,


Thank you for the response. That surely helps.


But the major issue in my case is not how we can apply sum fn, but how we can  change field names based on iteration number.

I cant skip loop in my case, because in real situation I have to deal with say around 100 fields, the only thing that changes is Day number in field name and the iteration number should be able to handle that.


With Regards,
Vijaya Kumar Regati
Technical Lead, M3bi India Private Ltd
Work: 040-67064732

________________________________
From: Manjusha Joshi <manjusha.joshi at gmail.com>
Sent: Tuesday, May 30, 2017 1:42:10 PM
To: Vijaya Kumar Regati
Cc: r-help at R-project.org; vijaykr.sas at gmail.com
Subject: Re: [R] Need Help - R Programming - Using iteration value to change field names for processing for every iteraion

Hello Vijaya,

On Tue, May 30, 2017 at 12:32 PM, Vijaya Kumar Regati <VijayaKumar.Regati at m3bi.com<mailto:VijayaKumar.Regati at m3bi.com>> wrote:
Hi,

I am new to R programming, I am trying to work on below requirement. But could not achieve desired result.
Appreciate if someone can help me on this :

test dataframe :
  Day1.balc Day2.balc Day3.balc Day4.balc
x       100        20        30        40
y       100        10        10        10
> class(test)
[1] "data.frame"

My Goal is to accomplish :
Day2.balc <- Day2.balc + Day1.balc
Day3.balc <- Day3.balc + Day2.balc
.
.
.
Day30.balc <- Day30.balc + Day29.balc

    # Testing for first 4 days
    for (i in 1:4 ) {
    test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
    }

I identified the line I have written inside the loop is not the correct one, can someone help me how I can use iteration value(i), for every iteration, as a basis for changing field names since field consists of 1,2,3... for each different day( Day1.balc Day2.balc Day3.balc Day4.balc etc.,).

?
?There are many built in functions in R which will help to avoid loops.
Try 'cumsum' to add entries in a row to get cumulative sum. Use 'apply' to avoid loops.

df is the dataframe in which your data has been stored.

t(apply,df,1,cumsum)

will give you the required results.
Please check help of  'apply' for more details.
Best wishes,



?

?

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Manjusha S. Joshi
Mobile:  09822 319328
Pune, India
blog:http://manjushajoshi.wordpress.com/


Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments) are confidential, may contain proprietary or privileged information and is intended for the named recipient(s) only. If you are not the intended recipient, any disclosures, use, review, distribution, printing or copying of the information contained in this e-mail message and/or attachments to it are strictly prohibited. If you have received this email in error, please notify the sender by return e-mail or telephone immediately and permanently delete the message and any attachments.

	[[alternative HTML version deleted]]


From arrayprofile at yahoo.com  Wed May 31 06:53:25 2017
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 31 May 2017 04:53:25 +0000 (UTC)
Subject: [R] deviance in GLM vs. summary.glm
References: <450505071.3919623.1496206405764.ref@mail.yahoo.com>
Message-ID: <450505071.3919623.1496206405764@mail.yahoo.com>

Hi, I am running a logistic regression on a simple dataset (attached) using glm:
> dat<-read.table("dat.txt",sep='\t',header=T)
If I use summary() on a logistic model:
> summary(glm(y~x1*x2,dat,family='binomial'))
Coefficients:? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)(Intercept) ? ?19.57 ? ?5377.01 ? 0.004 ? ?0.997x1 ? ? ? ? ? ?-18.59 ? ?5377.01 ?-0.003 ? ?0.997x2B ? ? ? ? ? -19.57 ? ?5377.01 ?-0.004 ? ?0.997x1:x2B ? ? ? ? 38.15 ? ?7604.24 ? 0.005 ? ?0.996
As you can see, the interaction term is very insignificant (p = 0.996)!
But if I use a anova() to compare a full vs reduced model to evaluate the interaction term:
> anova(glm(y~x1+x2,dat,family='binomial'), glm(y~x1*x2,dat,family='binomial'))Analysis of Deviance Table
Model 1: y ~ x1 + x2Model 2: y ~ x1 * x2? Resid. Df Resid. Dev Df Deviance1 ? ? ? ?22 ? ? 27.067 ? ? ? ? ? ?2 ? ? ? ?21 ? ? 21.209 ?1 ? 5.8579
This follows a chi-square distribution with 1 df, so the corresponding p value is:
> 1-pchisq(5.8679,1)[1] 0.01541944
So I get very different p value on the interaction term, can someone share what's going wrong here?
Thanks!
Yi

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dat.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170531/7d302080/attachment.txt>

From jdnewmil at dcn.davis.ca.us  Wed May 31 08:45:56 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 30 May 2017 23:45:56 -0700
Subject: [R] Need Help - R Programming - Using iteration value to change
	field names for processing for every iteraion
In-Reply-To: <SIXPR02MB0861B6DCAE8E57401344150EAEF10@SIXPR02MB0861.apcprd02.prod.outlook.com>
References: <SIXPR02MB0861218D2DF08FBC3C3E54BAAEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>,
 <CAKGzMdbFP5wfYBg5vgKNn=8TuqUehaM4-AdfhbCbTJj6AMHCMg@mail.gmail.com>
 <SIXPR02MB086133829664481794452BC2AEF00@SIXPR02MB0861.apcprd02.prod.outlook.com>,
 <f4018160ec7042af8cc4eaa82bf0c5b7@exch-2p-mbx-w2.ads.tamu.edu>
 <SIXPR02MB0861B6DCAE8E57401344150EAEF10@SIXPR02MB0861.apcprd02.prod.outlook.com>
Message-ID: <B3242B07-721A-4B75-A487-BD0DA9354DFA@dcn.davis.ca.us>

That is not possible... this is just a thread of emails. The closest you can get is to clearly indicate what solution worked for you so that people following along now it in the archives later know how your question was answered. 
-- 
Sent from my phone. Please excuse my brevity.

On May 30, 2017 9:24:45 PM PDT, Vijaya Kumar Regati <VijayaKumar.Regati at m3bi.com> wrote:
>Thanks very much.
>
>Can someone suggest me how I can close this qn, since I have the
>solution now ?
>
>
>With Regards,
>Vijaya Kumar Regati
>Technical Lead, M3bi India Private Ltd
>Work: 040-67064732
>
>________________________________
>From: David L Carlson <dcarlson at tamu.edu>
>Sent: Wednesday, May 31, 2017 3:35:19 AM
>To: Vijaya Kumar Regati; Manjusha Joshi
>Cc: r-help at R-project.org; vijaykr.sas at gmail.com
>Subject: RE: [R] Need Help - R Programming - Using iteration value to
>change field names for processing for every iteraion
>
>Refer to columns by position rather than name and everything is
>simpler:
>
>for (i in 2:4 ) {
>    test[, i] <- test[, i] + test[, i-1]
>}
>
>Note your approach fails on the first line since you start with i=1 and
>there is no Day0. Another approach that is simpler:
>
>t(apply(test, 1, cumsum))
>
>
>David L. Carlson
>Department of Anthropology
>Texas A&M University
>
>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Vijaya
>Kumar Regati
>Sent: Tuesday, May 30, 2017 3:44 AM
>To: Manjusha Joshi <manjusha.joshi at gmail.com>
>Cc: r-help at R-project.org; vijaykr.sas at gmail.com
>Subject: Re: [R] Need Help - R Programming - Using iteration value to
>change field names for processing for every iteraion
>
>Hi Manjusha,
>
>
>Thank you for the response. That surely helps.
>
>
>But the major issue in my case is not how we can apply sum fn, but how
>we can  change field names based on iteration number.
>
>I cant skip loop in my case, because in real situation I have to deal
>with say around 100 fields, the only thing that changes is Day number
>in field name and the iteration number should be able to handle that.
>
>
>With Regards,
>Vijaya Kumar Regati
>Technical Lead, M3bi India Private Ltd
>Work: 040-67064732
>
>________________________________
>From: Manjusha Joshi <manjusha.joshi at gmail.com>
>Sent: Tuesday, May 30, 2017 1:42:10 PM
>To: Vijaya Kumar Regati
>Cc: r-help at R-project.org; vijaykr.sas at gmail.com
>Subject: Re: [R] Need Help - R Programming - Using iteration value to
>change field names for processing for every iteraion
>
>Hello Vijaya,
>
>On Tue, May 30, 2017 at 12:32 PM, Vijaya Kumar Regati
><VijayaKumar.Regati at m3bi.com<mailto:VijayaKumar.Regati at m3bi.com>>
>wrote:
>Hi,
>
>I am new to R programming, I am trying to work on below requirement.
>But could not achieve desired result.
>Appreciate if someone can help me on this :
>
>test dataframe :
>  Day1.balc Day2.balc Day3.balc Day4.balc
>x       100        20        30        40
>y       100        10        10        10
>> class(test)
>[1] "data.frame"
>
>My Goal is to accomplish :
>Day2.balc <- Day2.balc + Day1.balc
>Day3.balc <- Day3.balc + Day2.balc
>.
>.
>.
>Day30.balc <- Day30.balc + Day29.balc
>
>    # Testing for first 4 days
>    for (i in 1:4 ) {
>    test$Day[i].balc <- test$Day[i].balc + test$Day[i-1].balc
>    }
>
>I identified the line I have written inside the loop is not the correct
>one, can someone help me how I can use iteration value(i), for every
>iteration, as a basis for changing field names since field consists of
>1,2,3... for each different day( Day1.balc Day2.balc Day3.balc
>Day4.balc etc.,).
>
>?
>?There are many built in functions in R which will help to avoid loops.
>Try 'cumsum' to add entries in a row to get cumulative sum. Use 'apply'
>to avoid loops.
>
>df is the dataframe in which your data has been stored.
>
>t(apply,df,1,cumsum)
>
>will give you the required results.
>Please check help of  'apply' for more details.
>Best wishes,
>
>
>
>?
>
>?
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>
>--
>Manjusha S. Joshi
>Mobile:  09822 319328
>Pune, India
>blog:http://manjushajoshi.wordpress.com/
>
>
>Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments)
>are confidential, may contain proprietary or privileged information and
>is intended for the named recipient(s) only. If you are not the
>intended recipient, any disclosures, use, review, distribution,
>printing or copying of the information contained in this e-mail message
>and/or attachments to it are strictly prohibited. If you have received
>this email in error, please notify the sender by return e-mail or
>telephone immediately and permanently delete the message and any
>attachments.
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>Disclaimer: IMPORTANT NOTICE: This e-mail (including any attachments)
>are confidential, may contain proprietary or privileged information and
>is intended for the named recipient(s) only. If you are not the
>intended recipient, any disclosures, use, review, distribution,
>printing or copying of the information contained in this e-mail message
>and/or attachments to it are strictly prohibited. If you have received
>this email in error, please notify the sender by return e-mail or
>telephone immediately and permanently delete the message and any
>attachments.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From s3tochri at uni-bayreuth.de  Wed May 31 09:56:51 2017
From: s3tochri at uni-bayreuth.de (Tobias Christoph)
Date: Wed, 31 May 2017 09:56:51 +0200
Subject: [R] Differentiate values in a plot by colour or symbol
In-Reply-To: <EF9E4056-17D6-434A-83B6-24CD09C57360@gmail.com>
References: <b207c515-4d21-87fb-03d4-1a8447bcf85f@uni-bayreuth.de>
 <032E6927-5D89-4E21-BE1F-7DB3B43D4F26@gmail.com>
 <798b7584-9543-d93d-11a6-e428a9694024@uni-bayreuth.de>
 <238165CC-17AE-4F64-80F3-F68D7B9C4F98@gmail.com>
 <a5c2f116-cd2c-d616-bdcc-662142215d9d@uni-bayreuth.de>
 <F5DD6376-AE75-4904-BD02-F29F321BF414@gmail.com>
 <ad924fab-6bb0-3c75-c72f-297fc08447bc@uni-bayreuth.de>
 <EF9E4056-17D6-434A-83B6-24CD09C57360@gmail.com>
Message-ID: <e9fe802c-5d76-66a5-d9d9-4827f23ec424@uni-bayreuth.de>

wuhu, the plot is running now;)

I had to put three brackets instead of two at the end of the formula.

Thank you!




Am 30.05.2017 um 21:29 schrieb Ismail SEZEN:
>
>> On 30 May 2017, at 21:44, Tobias Christoph <s3tochri at uni-bayreuth.de 
>> <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>
>> Okay;)
>>
>> First of all many thanks to you, Ismail, that you really try to help 
>> me. I am really not an expert with R and try to learn.
>>
> You?re welcome.
>
>> I just checked: All columns in my data frame are numeric. The range 
>> of years is from 2005 to 2016.
>>
>> Please find attached the result of "data.frame(data)". I also 
>> attached it as Excel-file
>>
>> >data.frame(data)            town year  revenue stations
>> 1       Bremen 2005 39.91036        1
>> 2       Bremen 2006 43.34265        1
>> 3       Bremen 2007 44.03614        1
>> 4       Bremen 2008 43.19945        1
>> 5       Bremen 2009 39.05230        1
>> 6       Bremen 2010 44.24626        1
>> 7       Bremen 2011 46.19309       35
>> 8       Bremen 2012 48.59513      101
>> 9       Bremen 2013 48.15778      181
>> 10      Bremen 2014 48.83199      323
>> 11      Bremen 2015 48.68549      463
>> 12      Bremen 2016 50.00000      614
>> 13     Dresden 2005 42.27858        1
>> 14     Dresden 2006 50.39606        1
>> 15     Dresden 2007 48.73299        1
>> 16     Dresden 2008 42.69010        1
>> 17     Dresden 2009 40.81174        1
>> 18     Dresden 2010 47.09675        2
>> 19     Dresden 2011 49.16900       43
>> 20     Dresden 2012 48.13645      151
>> 21     Dresden 2013 48.13645      284
>> 22     Dresden 2014 49.77309      511
>> 23     Dresden 2015 51.51515      773
>> 24     Dresden 2016 51.00000     1057
>> 25  D?sseldorf 2005 44.23227        1
>> 26  D?sseldorf 2006 46.70928        1
>> 27  D?sseldorf 2007 51.24008        1
>> 28  D?sseldorf 2008 61.59058        1
>> 29  D?sseldorf 2009 45.70021        1
>> 30  D?sseldorf 2010 57.17096        8
>> 31  D?sseldorf 2011 60.60122      115
>> 32  D?sseldorf 2012 65.50992      339
>> 33  D?sseldorf 2013 64.06870      636
>> 34  D?sseldorf 2014 71.56474     1117
>> 35  D?sseldorf 2015 68.20119     1622
>> 36  D?sseldorf 2016 80.00000     2117
>> 37       Essen 2005 37.71029        1
>> 38       Essen 2006 44.61127        1
>> 39       Essen 2007 41.39926        1
>> 40       Essen 2008 49.34792        1
>> 41       Essen 2009 38.49137        1
>> 42       Essen 2010 51.57844        1
>> 43       Essen 2011 48.38058       29
>> 44       Essen 2012 50.17066       42
>> 45       Essen 2013 49.26759       90
>> 46       Essen 2014 50.20367      162
>> 47       Essen 2015 47.89430      258
>> 48       Essen 2016 58.00000      370
>> 49   Frankfurt 2005 47.97355        1
>> 50   Frankfurt 2006 50.37223        1
>> 51   Frankfurt 2007 49.11292        1
>> 52   Frankfurt 2008 49.65316        1
>> 53   Frankfurt 2009 44.53889        3
>> 54   Frankfurt 2010 54.02567       15
>> 55   Frankfurt 2011 56.29475       80
>> 56   Frankfurt 2012 59.10949      223
>> 57   Frankfurt 2013 62.30140      488
>> 58   Frankfurt 2014 62.67521      836
>> 59   Frankfurt 2015 66.93712     1319
>> 60   Frankfurt 2016 66.00000     1744
>> 61    Hannover 2005 39.82472        1
>> 62    Hannover 2006 41.25841        1
>> 63    Hannover 2007 40.80456        1
>> 64    Hannover 2008 42.19192        1
>> 65    Hannover 2009 36.96012        1
>> 66    Hannover 2010 45.83055        5
>> 67    Hannover 2011 49.86364       35
>> 68    Hannover 2012 51.11023      167
>> 69    Hannover 2013 52.69465      351
>> 70    Hannover 2014 56.22519      983
>> 71    Hannover 2015 56.95612     1413
>> 72    Hannover 2016 61.00000     1864
>> 73     Leipzig 2005 29.05982        1
>> 74     Leipzig 2006 34.52306        1
>> 75     Leipzig 2007 35.97303        1
>> 76     Leipzig 2008 40.03798        1
>> 77     Leipzig 2009 37.67574        2
>> 78     Leipzig 2010 44.19365        3
>> 79     Leipzig 2011 44.72397       53
>> 80     Leipzig 2012 49.55416      223
>> 81     Leipzig 2013 52.92384      488
>> 82     Leipzig 2014 53.50600      918
>> 83     Leipzig 2015 54.62963     1517
>> 84     Leipzig 2016 59.00000     2037
>> 85    N?rnberg 2005 43.51885        1
>> 86    N?rnberg 2006 49.13278        1
>> 87    N?rnberg 2007 46.92181        1
>> 88    N?rnberg 2008 52.03628        1
>> 89    N?rnberg 2009 43.45030        1
>> 90    N?rnberg 2010 55.44258        5
>> 91    N?rnberg 2011 57.21674       48
>> 92    N?rnberg 2012 62.36625      145
>> 93    N?rnberg 2013 61.49312      297
>> 94    N?rnberg 2014 66.22809      505
>> 95    N?rnberg 2015 63.38028      813
>> 96    N?rnberg 2016 72.00000     1101
>> 97     Rostock 2005 32.56640        1
>> 98     Rostock 2006 30.71011        1
>> 99     Rostock 2007 33.71970        1
>> 100    Rostock 2008 34.25922        1
>> 101    Rostock 2009 34.60181        1
>> 102    Rostock 2010 40.17270        1
>> 103    Rostock 2011 42.06082        3
>> 104    Rostock 2012 42.43937       15
>> 105    Rostock 2013 43.67011       43
>> 106    Rostock 2014 43.93213       93
>> 107    Rostock 2015 47.35883      174
>> 108    Rostock 2016 52.00000      243
>> 109  Stuttgart 2005 50.72972        1
>> 110  Stuttgart 2006 58.74502        1
>> 111  Stuttgart 2007 53.45797        1
>> 112  Stuttgart 2008 56.18432        1
>> 113  Stuttgart 2009 46.29588        1
>> 114  Stuttgart 2010 56.38839        2
>> 115  Stuttgart 2011 58.92586       33
>> 116  Stuttgart 2012 61.16505       96
>> 117  Stuttgart 2013 60.12524      200
>> 118  Stuttgart 2014 65.89726      409
>> 119  Stuttgart 2015 71.49853      661
>> 120  Stuttgart 2016 73.00000      853
>> 121   Wiebaden 2005 37.40724        1
>> 122   Wiebaden 2006 38.94093        1
>> 123   Wiebaden 2007 38.08423        1
>> 124   Wiebaden 2008 38.23657        1
>> 125   Wiebaden 2009 34.98646        1
>> 126   Wiebaden 2010 40.72424        2
>> 127   Wiebaden 2011 44.59304        8
>> 128   Wiebaden 2012 47.58078       27
>> 129   Wiebaden 2013 46.86706       59
>> 130   Wiebaden 2014 46.58586      110
>> 131   Wiebaden 2015 48.12320      163
>> 132   Wiebaden 2016 50.00000      220
>>
>>
>
>
> Insead of copy and paste data.frame or attach an excel file, learn how 
> to create a minimal example as below:
>
> set.seed(6)
> data <- data.frame(
>   town = rep(LETTERS, each = 5, times = 5)[1:60],
>   year = rep(2005:2016, times = 5),
>   revenue = rnorm(60, 35),
>   stations = round(rnorm(60, 250, 100)))
>
> plot(data$stations, data$revenue, xlab="stations", ylab="revenue", pch 
> = 16, col = findInterval(data$year, c(2005, 2010, 2016)))
>
> I created a fake data.frame similar your original one and used it to 
> plot. See the result of plot. It works as intended.
>
> let?s check result of findInterval function.
>
> findInterval(data$year, c(2005, 2010, 2016))
> [1] 1 1 1 1 1 2 2 2 2 2 2 3 1 1 1 1 1 2 2 2 2 2 2 3 1 1 1 1 1 2 2 2 2 
> 2 2 3 1 1 1 1 1 2 2 2 2 2 2 3 1 1 1 1 1 2 2 2 2 2 2 3
>
> and see the result of palette function.
>
> palette()
> "black"   "red"     "green3"  "blue"    "cyan"    "magenta" "yellow" 
>  "gray"
>
> as you noticed, black dots in the plot will be belong to years between 
> 2005-2009, red dots will be belong to 2010-2015 and green dots will be 
> belong to only 2016.
>
> I hope your next questions follow this guide and make things easier 
> for you and us :)
>
>
>>
>>
>> Am 30.05.2017 um 20:30 schrieb Ismail SEZEN:
>>>
>>>> On 30 May 2017, at 21:23, Tobias Christoph 
>>>> <s3tochri at uni-bayreuth.de <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>>>
>>>> Ahh, okay.
>>>>
>>>> I think now I understand what you exactly mean. But the plot is 
>>>> stil not working /differentiate the dots by color. I used the 
>>>> following formula.
>>>>
>>>> "plot(data$stations, data$revenue, xlab="stations", ylab="revenue", 
>>>> col = findInterval(data$year, c(2005, 2010, 2015))"
>>>>
>>>> I think the problem is stil related to the term "col = 
>>>> findInterval(data$year, c(2005, 2010, 2015))" and its notation.
>>>>
>>>> Just to make sure: "data" is the name of the data-table imported in 
>>>> R. "year" is the lable of the column where the years are listed in 
>>>> the data-table?
>>>>
>>> Exactly. Make sure all the columns in data.frame are numeric. Also I 
>>> don?t know the range of years. You should arrange arguments to 
>>> findInterval according your data. If you would send a minimal 
>>> example as stated in posting guide [1], you will have your answer in 
>>> second email :).
>>>
>>> 1- http://www.R-project.org/posting-guide.html 
>>> <http://www.r-project.org/posting-guide.html>
>>>
>>>> Cheers
>>>>
>>>>
>>>>
>>>> Am 30.05.2017 um 19:57 schrieb Ismail SEZEN:
>>>>>
>>>>>> On 30 May 2017, at 20:48, Tobias Christoph 
>>>>>> <s3tochri at uni-bayreuth.de <mailto:s3tochri at uni-bayreuth.de>> wrote:
>>>>>>
>>>>>> Hi Ismael,
>>>>>>
>>>>>> thanks for your quick reply.
>>>>>>
>>>>>> I was now able to esmitate two intervals with the 
>>>>>> "findInterval"-Function.
>>>>>>
>>>>>>    x
>>>>>>   [1,] 2005 1
>>>>>>   [2,] 2006 1
>>>>>>   [3,] 2007 1
>>>>>>   [4,] 2008 1
>>>>>>   [5,] 2009 1
>>>>>>   [6,] 2010 1
>>>>>>   [7,] 2011 2
>>>>>>   [8,] 2012 2
>>>>>>   [9,] 2013 2
>>>>>> [10,] 2014 2
>>>>>> [11,] 2015 2
>>>>>> [12,] 2016 2
>>>>>>
>>>>>> But I was not able to connect the intervals with the 
>>>>>> plot-function. I used the following formular.
>>>>>>
>>>>>> "plot(data$stations, data$revenue, xlab="stations", 
>>>>>> ylab="revenue", col(findInterval())"
>>>>>>
>>>>> In fact I should say ?feed _col_ or _pch_ argument with the result 
>>>>> of findInterval? as below:
>>>>>
>>>>> plot(data$stations, data$revenue, xlab="stations", ylab="revenue", 
>>>>> col = findInterval(x$year, c(2005, 2010, 2015))
>>>>>
>>>>> Please note that If you have many (20-30) intervals, colour 
>>>>> handling will be more complex. But I assume you have maximum 5-10 
>>>>> intervals. So, the piece of code above will work for you.
>>>>>
>>>>>> How can I proceed and get the plot-funktion running?
>>>>>>
>>>>>> Maybe it is not running because the years as single numbers are 
>>>>>> already contained in my data-frame?
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Toby
>>>>>>
>>>>>>
>>>>>>
>>>>>> Am 30.05.2017 um 18:26 schrieb Ismail SEZEN:
>>>>>>>> On 30 May 2017, at 19:02, Tobias Christoph<s3tochri at uni-bayreuth.de>  wrote:
>>>>>>>>
>>>>>>>> Hey Guys,
>>>>>>>>
>>>>>>>> I just try to differentiate certain values in my plot by colour or symbol.
>>>>>>>>
>>>>>>>> I have panel data with three dimensions (number of stations, revenue,
>>>>>>>> years). To integrate the third dimension (years) in the plot, I want to
>>>>>>>> differentiate the values(number of stations, revenue) by a certain range
>>>>>>>> of years.
>>>>>>>>
>>>>>>>> e.g.: 2005-2010: red coloured dots, 2011-2016, blue coloured dots
>>>>>>>>
>>>>>>>> For the normal plot I used the following formula:
>>>>>>>>
>>>>>>>> *plot(data$stations, data$revenue, xlab="stations", ylab="revenue")*
>>>>>>>>
>>>>>>>> I only found a way to mark every single year. So hopefully you can help?
>>>>>>>>
>>>>>>>> Cheers,
>>>>>>>>
>>>>>>>> Toby
>>>>>>>>
>>>>>>> See ?findInterval. Especially, first 3 lines in _Examples_ section. Use result of findInterval as argument to _col_ or _pch_ in plot function.
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>> <data.xlsx>
>


	[[alternative HTML version deleted]]


From berwin.turlach at gmail.com  Wed May 31 09:54:44 2017
From: berwin.turlach at gmail.com (Berwin A Turlach)
Date: Wed, 31 May 2017 15:54:44 +0800
Subject: [R] deviance in GLM vs. summary.glm
In-Reply-To: <450505071.3919623.1496206405764@mail.yahoo.com>
References: <450505071.3919623.1496206405764.ref@mail.yahoo.com>
 <450505071.3919623.1496206405764@mail.yahoo.com>
Message-ID: <20170531155444.46d9ba05@ECM-DTC-716.uniwa.uwa.edu.au>

Dear Yi,

On Wed, 31 May 2017 04:53:25 +0000 (UTC)
array chip via R-help <r-help at r-project.org> wrote:

> Hi, I am running a logistic regression on a simple dataset (attached)
> using glm: [...] As you can see, the interaction term is very
> insignificant (p = 0.996)! 

Well, all terms are not significant (actually, AFAIK, the phrase "very
insignificant" does not exist; and if it does, than it ought not).  

But look at the estimates and the standard errors too (might be easier
if you had formatted your e-mail in a way that was readable)!  What
does an estimate for the intercept of 19.57 on the linear predictor
scale mean?  What it the estimated probability if you transform back?

Perhaps the following command

R> xtabs(~x1+x2+y,dat)

will shed some more light on what is going on in your data set, and why
the interaction term is highly significant.

> But if I use a anova() to compare a full
> vs reduced model to evaluate the interaction term:
> > anova(glm(y~x1+x2,dat,family='binomial'),
> > glm(y~x1*x2,dat,family='binomial'))

To you know about the (optional) argument 'test="ChiSq"' for the
anova() command if you use it to compare models fitted by glm()? (see
help(anova.glm))

> So I get very different p value on the interaction term, can someone
> share what's going wrong here?

Data separation, aka Hauck-Donner phenomenon, discussed in any good
book on logistic regression.

Best wishes,

	Berwin

========================== Full address ============================
A/Prof Berwin A Turlach, Director     Tel.: +61 (8) 6488 3338 (secr)
Centre for Applied Statistics               +61 (8) 6488 3383 (self)
School of Maths and Stats (M019)      FAX : +61 (8) 6488 1028
The University of Western Australia                 
35 Stirling Highway                 e-mail: Berwin.Turlach at gmail.com
Crawley WA 6009          http://staffhome.ecm.uwa.edu.au/~00043886/
Australia                http://www.researcherid.com/rid/A-4995-2008


From p_connolly at slingshot.co.nz  Wed May 31 10:38:10 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 31 May 2017 20:38:10 +1200
Subject: [R] Error in readRDS(dest) (was Re: Error with
 installed.packages with R 3.4.0 on Windows)
In-Reply-To: <22820.3316.479418.85208@stat.math.ethz.ch>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
 <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
 <20170522091022.GC4553@slingshot.co.nz>
 <7b8f4895-b41d-6634-367b-1754bc737c02@roswellpark.org>
 <20170523084722.GD4553@slingshot.co.nz>
 <22820.3316.479418.85208@stat.math.ethz.ch>
Message-ID: <20170531083810.GF4553@slingshot.co.nz>

On Tue, 23-May-2017 at 12:20PM +0200, Martin Maechler wrote:

[...]

|> 
|> Given the above stack trace. 
|> It may be easier to just do
|> 
|>     debugonce(available.packages)
|>     install.packages("withr")
|> 
|> and then inside available.packages, (using 'n') step to the
|> point _before_ the tryCatch(...) call happens; there, e.g. use
|> 
|>       ls.str()
|> 
|> which gives an str() of all your local objects, notably 'dest'
|> and 'method'.
|> but you can also try other things once inside
|> available.packages().

I couldn't see any differences between R-3.3.3 (which works) and
R-3.4.0 (which doesn't) until I got to here, a few lines before the
download.file line:

Browse[2]> 
debug: dest <- file.path(tempdir(), paste0("repos_", URLencode(repos, 
    TRUE), ".rds"))
Browse[2]> 

When I check out those directories in a terminal, there's a big diffrence:

With R-3.4.0
~ > ll /tmp/RtmpFUhtpY
total 4
drwxr-xr-x 2 hrapgc hrapgc 4096 May 31 10:45 downloaded_packages/
-rw-r--r-- 1 hrapgc hrapgc    0 May 31 10:56 repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds


With R-3.3.3
~ > ll /tmp/RtmpkPgL3A
total 380
drwxr-xr-x 2 hrapgc hrapgc   4096 May 31 11:01 downloaded_packages/
-rw-r--r-- 1 hrapgc hrapgc   8214 May 31 11:01 libloc_185_3165c7f52d5fdf96.rds
-rw-r--r-- 1 hrapgc hrapgc 372263 May 31 11:01 repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds

So, if I could figure out what makes *that* difference I could get
somewhere.  I see there's considerably extra code in the newer of the
two versions of available.packages() but being a bear with a small
brain, I can't figure out what differences should be expected.  I have
no idea what populates those 'dest' directories.

TIA
-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From francois.morneau at ign.fr  Wed May 31 11:21:17 2017
From: francois.morneau at ign.fr (=?UTF-8?Q?Fran=c3=a7ois_Morneau?=)
Date: Wed, 31 May 2017 11:21:17 +0200
Subject: [R] Locale changed after an RODBC connection on Linux
Message-ID: <84b98a0a-c43f-2a2b-7fa9-7ebb7ad09db8@ign.fr>

Dear helpeRs,

When connecting to a PostgreSQL database (via the RODBC functions 
odbcConnect or odbcDriverConnect), my locale are redefined from:
  [1] LC_CTYPE=fr_FR.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=fr_FR.UTF-8        LC_COLLATE=fr_FR.UTF-8
  [5] LC_MONETARY=fr_FR.UTF-8    LC_MESSAGES=fr_FR.UTF-8
  [7] LC_PAPER=fr_FR.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C

to:
[1] fr_FR.UTF-8

Loading RODBC does not affect the locale. It happens only after opening 
a first connection:

 > ch <- odbcConnect(dsn = "Inv_Exp")

After that the Sys.localeconv() is changed and among others, the 
"decimal_point" is modified from "." to ",", which as an impact on my R 
script which was previously running.

I am running an Linux Mint computer. The rest of my sessionInfo() is:

R version 3.4.0 (2017-04-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.0
LAPACK: /usr/lib/lapack/liblapack.so.3.0

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] RODBC_1.3-15

loaded via a namespace (and not attached):
[1] compiler_3.4.0

We observed the same behaviour on my colleague's computer (also on the 
same Linux Mint version) but not on Windows (7) or on a more recent 
Ubuntu 16 with sessionInfo() :

R version 3.4.0 (2017-04-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.2 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
  [1] LC_CTYPE=fr_FR.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=fr_FR.UTF-8        LC_COLLATE=fr_FR.UTF-8
  [5] LC_MONETARY=fr_FR.UTF-8    LC_MESSAGES=fr_FR.UTF-8
  [7] LC_PAPER=fr_FR.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] RODBC_1.3-15

loaded via a namespace (and not attached):
[1] compiler_3.4.0

Going back to previous versions (even old ones) of RODBC does not solve 
the issue. I certainely miss something obvious but can not find out what.

Regards,

Fran?ois Morneau


From r.turner at auckland.ac.nz  Wed May 31 11:31:02 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 31 May 2017 21:31:02 +1200
Subject: [R] [FORGED]  deviance in GLM vs. summary.glm
In-Reply-To: <450505071.3919623.1496206405764@mail.yahoo.com>
References: <450505071.3919623.1496206405764.ref@mail.yahoo.com>
 <450505071.3919623.1496206405764@mail.yahoo.com>
Message-ID: <b8dde9d4-54e1-f115-7375-7ea1e4aecc3c@auckland.ac.nz>

On 31/05/17 16:53, array chip via R-help wrote:
> Hi, I am running a logistic regression on a simple dataset (attached) using glm:
>> dat<-read.table("dat.txt",sep='\t',header=T)
> If I use summary() on a logistic model:
>> summary(glm(y~x1*x2,dat,family='binomial'))
> Coefficients:            Estimate Std. Error z value Pr(>|z|)(Intercept)    19.57    5377.01   0.004    0.997x1            -18.59    5377.01  -0.003    0.997x2B           -19.57    5377.01  -0.004    0.997x1:x2B         38.15    7604.24   0.005    0.996
> As you can see, the interaction term is very insignificant (p = 0.996)!
> But if I use a anova() to compare a full vs reduced model to evaluate the interaction term:
>> anova(glm(y~x1+x2,dat,family='binomial'), glm(y~x1*x2,dat,family='binomial'))Analysis of Deviance Table
> Model 1: y ~ x1 + x2Model 2: y ~ x1 * x2  Resid. Df Resid. Dev Df Deviance1        22     27.067            2        21     21.209  1   5.8579
> This follows a chi-square distribution with 1 df, so the corresponding p value is:
>> 1-pchisq(5.8679,1)[1] 0.01541944
> So I get very different p value on the interaction term, can someone share what's going wrong here?

(1) To re-emphasize Berwin Turlach's exhortation, ***PLEASE*** do not 
post in html; your results are nearly impossible to read.

(2) To add a tiny bit to Berwin's comments:

There is something a bit weird about your data; note that if you look at 
the fitted values from your fit, you get only *three* distinct values 
--- whereas there should be four, since there are four distinct
treatment combinations, (0,A), (0,B), (1,A) and (1,B).  And all possible 
treatment combinations do indeed occur.

The deficiency occurs because the last three of your coefficients (the 
non-intercept terms) sum to (effectively) 0.  Thus you get the same 
fitted value from the (1,B) combination as from the (0,A) combination.

It is not clear to me what the implications of all this are --- 
particularly since it's getting on for my bed time :-) --- but it seems 
clear that this sort of "degeneracy" is going to mess things up.
And perhaps contribute to the Hauck-Donner effect that Berwin told you 
about.

I would also advise you to try experimenting with simulated data.  (When 
in doubt, simulate.  Even when not in doubt, simulate.  That is my 
guiding principle.)  I.e. try to simulate y-values from a coefficient 
vector that does not suffer from the "degeneracy", fit a model to the 
simulated y-values, and compare the two tests.  They still won't agree, 
but they will (surely?) be less wildly discrepant.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From martin.morgan at roswellpark.org  Wed May 31 16:05:37 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Wed, 31 May 2017 10:05:37 -0400
Subject: [R] Error in readRDS(dest) (was Re: Error with
 installed.packages with R 3.4.0 on Windows)
In-Reply-To: <20170531083810.GF4553@slingshot.co.nz>
References: <CANufCk7ev+V-mhYse0aXsB2JvEPD53LM2Vj_a7vzfjJtf=oq6A@mail.gmail.com>
 <CAJuCY5x43qHnVfdjA4pt3XV9pWPi+h=Xwsb1nhRx6hGf_GvmnA@mail.gmail.com>
 <197DB706-D82D-4F63-A099-D3A431F10E29@gmail.com>
 <CAJuCY5wytBCWO8R6hFuxhNdRTh07KOq51M6Zr3gt4ByG=x7XaQ@mail.gmail.com>
 <b32387cd-79ac-84b8-40c0-fb202f1b14f0@gmail.com>
 <3A3EC3DC-6AE0-4292-A628-F68398154CA2@gmail.com>
 <20170522091022.GC4553@slingshot.co.nz>
 <7b8f4895-b41d-6634-367b-1754bc737c02@roswellpark.org>
 <20170523084722.GD4553@slingshot.co.nz>
 <22820.3316.479418.85208@stat.math.ethz.ch>
 <20170531083810.GF4553@slingshot.co.nz>
Message-ID: <72e983a8-06e8-2504-0e70-3614de672b83@roswellpark.org>

On 05/31/2017 04:38 AM, Patrick Connolly wrote:
> On Tue, 23-May-2017 at 12:20PM +0200, Martin Maechler wrote:
> 
> [...]
> 
> |>
> |> Given the above stack trace.
> |> It may be easier to just do
> |>
> |>     debugonce(available.packages)
> |>     install.packages("withr")
> |>
> |> and then inside available.packages, (using 'n') step to the
> |> point _before_ the tryCatch(...) call happens; there, e.g. use
> |>
> |>       ls.str()
> |>
> |> which gives an str() of all your local objects, notably 'dest'
> |> and 'method'.
> |> but you can also try other things once inside
> |> available.packages().
> 
> I couldn't see any differences between R-3.3.3 (which works) and
> R-3.4.0 (which doesn't) until I got to here, a few lines before the
> download.file line:
> 
> Browse[2]>
> debug: dest <- file.path(tempdir(), paste0("repos_", URLencode(repos,
>      TRUE), ".rds"))
> Browse[2]>
> 
> When I check out those directories in a terminal, there's a big diffrence:
> 
> With R-3.4.0
> ~ > ll /tmp/RtmpFUhtpY
> total 4
> drwxr-xr-x 2 hrapgc hrapgc 4096 May 31 10:45 downloaded_packages/
> -rw-r--r-- 1 hrapgc hrapgc    0 May 31 10:56 repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds
> 
> 

The file repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds 
was likely created earlier in your R session. Likely the download a few 
lines down

                     download.file(url = paste0(repos, "/PACKAGES.rds"),
                                   destfile = dest, method = method,
                                   cacheOK = FALSE, quiet = TRUE, mode = 
"wb")

'succeeded' but created a zero-length file.

You could try to troubleshoot this with something like the following, 
downloading to a temporary location

   dest = tempfile()
   url = "http://cran.stat.auckland.ac.nz/src/contrib/PACKAGES.rds"
   download.file(url, dest)
   file.size(dest)

If this succeeds (it should download a file of several hundred KB), then 
try adding the options method, cacheOK, quiet, mode to the 
download.file() call. 'method' can be determined when you are in 
available.packages while debugging; if R says that it is missing, then 
it will be assigned, in download.file, to either 
getOption("download.file.method") or (if the option is NULL or "auto") 
"libcurl".

If the download 'succeeds' but the temporary file created is 0 bytes, 
then it would be good to share the problematic command with us.

Martin Morgan

> With R-3.3.3
> ~ > ll /tmp/RtmpkPgL3A
> total 380
> drwxr-xr-x 2 hrapgc hrapgc   4096 May 31 11:01 downloaded_packages/
> -rw-r--r-- 1 hrapgc hrapgc   8214 May 31 11:01 libloc_185_3165c7f52d5fdf96.rds
> -rw-r--r-- 1 hrapgc hrapgc 372263 May 31 11:01 repos_http%3A%2F%2Fcran.stat.auckland.ac.nz%2Fsrc%2Fcontrib.rds
> 
> So, if I could figure out what makes *that* difference I could get
> somewhere.  I see there's considerably extra code in the newer of the
> two versions of available.packages() but being a bear with a small
> brain, I can't figure out what differences should be expected.  I have
> no idea what populates those 'dest' directories.
> 
> TIA
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From bgunter.4567 at gmail.com  Wed May 31 16:58:16 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 31 May 2017 07:58:16 -0700
Subject: [R] seek non-black box alternative to randomForest
In-Reply-To: <EA497BBA-EDE2-4322-9F57-0566058A4212@u.washington.edu>
References: <CAP8WkrxiAhUBVTXAuPLG9qphR9iPpV_Rxmeuis1BBtZsFLQxug@mail.gmail.com>
 <EA497BBA-EDE2-4322-9F57-0566058A4212@u.washington.edu>
Message-ID: <CAGxFJbQJVuFXDYexYS9S8Ot20L-7jDhmkyjp-_44+jsCUHDzMg@mail.gmail.com>

On Tue, May 30, 2017 at 12:11 PM, Don McKenzie <dmck at u.washington.edu> wrote:
> Though off-topic for this list, your question (complaint?) comes up a lot in discussions of analytical methods, and has generated hundreds of papers (Google is your friend here).
> You can start with
>
> https://www.quora.com/What-are-the-pros-and-cons-of-GLM-vs-Random-forest-vs-SVM <https://www.quora.com/What-are-the-pros-and-cons-of-GLM-vs-Random-forest-vs-SVM>
>
> for some of the controversies.  It looks to me as if your editor stated (poorly) the problem that some models that are good at pattern-matching (RF) are less useful for predicting new observations.
>
> Others n the list who are more erudite than I may choose to comment, amplify, or refute...

... But hopefully will not, as this could quickly devolve into endless
opining that would clog up this list, as you have yourself noted.

-- Bert


>
>
>> On May 30, 2017, at 11:54 AM, Barry King <barry.king at qlx.com> wrote:
>>
>> I've recently had a research manuscript rejected by an editor. The
>> manuscript showed
>> that for a real life data set, random forest outperformed multiple linear
>> regression
>> with respect to predicting the target variable. The editor's objection was
>> that
>> random forest is a black box where the random assignment of features to
>> trees was
>> intractable. I need to find an alternative method to random forest that
>> does not
>> suffer from the black box label. Any suggestions? Would caret::treebag be
>> free of
>> random assignment of features? Your assistance is appreciated.
>>
>> --
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mcheung63 at hotmail.com  Wed May 31 20:26:48 2017
From: mcheung63 at hotmail.com (Peter Cheung)
Date: Wed, 31 May 2017 18:26:48 +0000
Subject: [R] Need help for Netbeans R plugin development
In-Reply-To: <b5ccc64a-3f2c-ba19-53e7-1864d925f069@atsu.edu>
References: <HK2PR0401MB14273418E183E38F23DBF5ABB5F20@HK2PR0401MB1427.apcprd04.prod.outlook.com>,
 <b5ccc64a-3f2c-ba19-53e7-1864d925f069@atsu.edu>
Message-ID: <HK2PR0401MB142786240BA2193ADAD5E609B5F10@HK2PR0401MB1427.apcprd04.prod.outlook.com>

Perfect, i am using RServe now. Thanks for telling me


________________________________
From: Robert Baer <rbaer at atsu.edu>
Sent: Monday, May 29, 2017 7:41 PM
To: Peter Cheung; r-help at R-project.org
Subject: Re: [R] Need help for Netbeans R plugin development

rJava and Rserve might be architectures of interest.


On 5/28/2017 1:12 PM, Peter Cheung wrote:
> Hi
>     My name is Peter, developing R plugin for netbeans, it is entirely in Java. What is the best way to interact Java with R and how can I hook some R functions such as plot()? so everytime plot() is called and i can capture the generated graph.
> thanks
> from Peter
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From mcheung63 at hotmail.com  Wed May 31 21:09:05 2017
From: mcheung63 at hotmail.com (Peter Cheung)
Date: Wed, 31 May 2017 19:09:05 +0000
Subject: [R] How to create my own grDevices using java
Message-ID: <HK2PR0401MB1427F8D4433C522AE1D22107B5F10@HK2PR0401MB1427.apcprd04.prod.outlook.com>

Hi All

   How to create my own grDevices using java, so that i can display the graphic from plot() in my java software?

thanks

from Peter

	[[alternative HTML version deleted]]


