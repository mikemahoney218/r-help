From yugoh|@v @end|ng |rom gm@||@com  Tue Feb  1 04:50:57 2022
From: yugoh|@v @end|ng |rom gm@||@com (Love Umesi)
Date: Tue, 1 Feb 2022 16:50:57 +1300
Subject: [R] Survey design for multilevel analysis
Message-ID: <CAOTqx+KtV1_WOtffzuZJetE=JFKqVDqV8O15aUs0vBFZa1yyeQ@mail.gmail.com>

I am new in using R, and I need to run a multilevel analysis (two-phase
design on two levels) using Cox frailty survival model on a survey data
(Nigeria Demographic and Health Survey Data).

My problem is how to write the design weight using the two weights needed
and apply them to the analysis.

I have identified the needed variables for the survey design, which
are : psu/cluster=
v021 individual-level weight= wt1_1 cluster-level weigh= wt2_1 strata/stratum=
v022

Please can someone help me with the survey design (svydesign) code and how
to include it and the weights in a model.

I understand I have to use svycoxph in the model. Please how do I include
survey design and account for the 2 weights (individual-level and
cluster-level weights) in the gamma frailty model below?

Frailty1 <- coxph (Surv(study_time, died) ~ factor(v024) + factor(mat_edu)
+ v025 + frailty(v021,distribution="gamma"), data=rcom2018)

Really looking forward to your help as my project is hanging on this.

Many thanks.


library(survival)#> Warning: package 'survival' was built under R version 4.0.5
library(frailtypack)#> Warning: package 'frailtypack' was built under
R version 4.0.5#> Loading required package: boot#> #> Attaching
package: 'boot'#> The following object is masked from
'package:survival':#> #>     aml#> Loading required package: MASS#>
Loading required package: survC1#> Warning: package 'survC1' was built
under R version 4.0.5#> Loading required package: doBy#> Warning:
package 'doBy' was built under R version 4.0.5#> #> Attaching package:
'frailtypack'#> The following object is masked from
'package:survival':#> #>     cluster


rcom1 <- data.frame(
  data.frame(
    pid = c(
      1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,
      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
      30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
      46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,
      61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,
      77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92,
      93, 94, 95, 96, 97, 98, 99, 100
    ),
    study_time = c(
      13, 9, 17, 31, 39, 22, 24, 0, 23, 12, 9, 35,
      18, 20, 60, 18, 5, 46, 26, 54, 37, 51, 31, 55, 27, 15, 39, 6,
      29, 0, 9, 40, 23, 12, 35, 56, 14, 40, 57, 42, 5, 42, 39, 39,
      54, 19, 52, 42, 7, 28, 53, 5, 28, 13, 37, 0, 23, 33, 27, 36, 20,
      24, 58, 34, 12, 44, 3, 34, 14, 5, 10, 40, 12, 36, 19, 58, 17,
      40, 39, 58, 53, 53, 1, 50, 2, 28, 24, 13, 13, 50, 46, 46, 19, 6,
      32, 59, 9, 30, 30, 43
    ),
    died = c(
      0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
      0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
      0
    ),
    v021 = c(
      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
      2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,
      3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,
      4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
      5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,
      6
    ),
    v022 = c(
      "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "2", "2", "2", "2", "2", "2", "2",
      "2", "2", "2"
    ),
    v012 = c(
      40, 37, 27, 27, 24, 32, 35, 35, 34, 20, 28,
      28, 26, 24, 24, 25, 26, 26, 26, 26, 28, 27, 25, 25, 27, 26, 26,
      21, 21, 31, 36, 36, 27, 23, 32, 32, 33, 33, 33, 28, 25, 37,
      33, 34, 33, 28, 28, 29, 33, 33, 33, 39, 38, 38, 38, 38, 24, 27,
      35, 40, 22, 38, 38, 21, 30, 30, 30, 39, 43, 18, 23, 23, 25, 25,
      30, 45, 26, 26, 35, 35, 35, 35, 32, 32, 40, 25, 27, 30, 30, 30,
      28, 28, 18, 27, 30, 30, 27, 21, 21, 30
    ),
    wt2_1 = c(
      401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031,
      401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
      631.818176269531, 631.818176269531, 631.818176269531,
      631.818176269531, 631.818176269531, 631.818176269531, 631.818176269531,
      631.818176269531, 631.818176269531, 631.818176269531
    ),
    wt1_1 = c(
      2.5074667930603, 2.5074667930603,
      2.5074667930603, 2.5074667930603, 2.5074667930603, 2.5074667930603,
      2.5074667930603, 2.5074667930603, 2.5074667930603, 2.5074667930603,
      2.5074667930603, 2.5074667930603, 2.5074667930603,
      2.5074667930603, 2.5074667930603, 5.1194109916687, 5.1194109916687,
      5.1194109916687, 5.1194109916687, 5.1194109916687, 5.1194109916687,
      5.1194109916687, 5.1194109916687, 5.1194109916687,
      5.1194109916687, 5.1194109916687, 5.1194109916687, 5.1194109916687,
      5.1194109916687, 5.1194109916687, 5.1194109916687, 5.1194109916687,
      5.1194109916687, 5.1194109916687, 2.40910983085632,
      2.40910983085632, 2.40910983085632, 2.40910983085632, 2.40910983085632,
      2.40910983085632, 2.40910983085632, 2.40910983085632,
      2.40910983085632, 2.40910983085632, 2.40910983085632, 2.40910983085632,
      2.40910983085632, 2.40910983085632, 1.06203985214233,
      1.06203985214233, 1.06203985214233, 1.06203985214233, 1.06203985214233,
      1.06203985214233, 1.06203985214233, 1.06203985214233,
      1.06203985214233, 1.06203985214233, 1.06203985214233, 1.06203985214233,
      1.06203985214233, 1.06203985214233, 1.06203985214233,
      1.06203985214233, 1.06203985214233, 1.06203985214233, 1.06203985214233,
      2.80098295211792, 2.80098295211792, 2.80098295211792,
      2.80098295211792, 2.80098295211792, 2.80098295211792, 2.80098295211792,
      2.80098295211792, 2.80098295211792, 2.80098295211792,
      2.80098295211792, 2.80098295211792, 2.80098295211792, 2.80098295211792,
      2.80098295211792, 2.80098295211792, 2.80098295211792,
      2.80098295211792, 2.80098295211792, 2.80098295211792, 2.80098295211792,
      2.80098295211792, 2.80098295211792, 1.24210178852081,
      1.24210178852081, 1.24210178852081, 1.24210178852081, 1.24210178852081,
      1.24210178852081, 1.24210178852081, 1.24210178852081,
      1.24210178852081, 1.24210178852081
    ),
    v024 = c(
      "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1"
    ),
    v025 = c(
      "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
      "1", "1", "1", "1", "1", "1", "2", "2", "2", "2", "2", "2", "2",
      "2", "2", "2"
    ),
    mat_edu = c(
      "5", "5", "5", "4", "4", "5", "4", "4", "4",
      "4", "4", "4", "5", "5", "5", "5", "5", "5", "4", "4", "5",
      "4", "4", "4", "5", "3", "3", "4", "4", "5", "5", "5", "5", "4",
      "2", "2", "0", "0", "0", "5", "5", "0", "1", "5", "5", "3",
      "3", "5", "5", "5", "5", "5", "5", "5", "5", "5", "5", "4", "5",
      "5", "4", "5", "5", "3", "4", "4", "5", "3", "1", "3", "3", "3",
      "1", "3", "2", "1", "3", "3", "4", "4", "0", "0", "2", "2",
      "1", "0", "4", "4", "4", "4", "0", "0", "3", "4", "2", "2", "3",
      "3", "3", "0"
    )
  ))

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb  1 16:34:24 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 1 Feb 2022 07:34:24 -0800
Subject: [R] Repeatability Analysis of Ordinal Data
In-Reply-To: <DM6PR01MB4314D3686B97D43F15DF3096EA259@DM6PR01MB4314.prod.exchangelabs.com>
References: <DM6PR01MB4314D3686B97D43F15DF3096EA259@DM6PR01MB4314.prod.exchangelabs.com>
Message-ID: <CAGxFJbTqwHWJnBtX92T+bBH58C2tA4cT613nnv6g=8mO38VYJA@mail.gmail.com>

Package-specific questions for non-standard packages (see
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R for
the list of current standard packages) are generally off topic here
per the posting guide (linked below). It is suggested there that you
contact the package maintainer (?maintainer) for such questions.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 1, 2022 at 2:02 AM Sidoti, Salvatore <sidoti.23 at osu.edu> wrote:
>
> Greetings, Colleagues:
>
> I have several Likert-type ordinal data sets consisting of animal responses with repeated measures. I was able to implement a CLMM model easily enough with the package `ordinal`. However, the package does not support repeatability analyses.
>
> Assuming that I subset my data according to treatment and/or sex, I am keen to try the `ordinalRR` package. According to the package documentation (https://cran.r-project.org/web/packages/ordinalRR/ordinalRR.pdf), performing `summary()` on the output from the function `ordinalRR()` returns the point estimates for each rater and for each pairwise combination of raters. However, is it possible to return an overall repeatability value and a 95% credible interval across all raters?
>
> What follows is a stock procedure from the package reference document:
>
> #-------------------------------------------------------------------------------
> library(ordinalRR)
>
> # load the dataset that comes with the package
> data(followup)
>
> # preprocess data to accommodate the package functions
> followup.pre <- preprocess(followup)
>
> # perform the analysis
> followup.random <- ordinalRR(followup.pre)
>
> summary(followup.random)
>
> Call:
>   ordinalRR(followup.pre)
>
> Data: 30 parts, 3 operators, 2 repetitions with 4 ordinal categories.
> Random-effects model MCMC chain: 1000 burn-in and 10000 retained.
>
> Simple repeatability and model parameter estimates by rater:
>   Rater j Repeatability  a_j d_{j,1} d_{j,2} d_{j,3}
> 1         0.900 12.0    -1.5    -0.1     0.6
> 2         0.900 10.9    -1.6    -0.3     0.5
> 3         0.933 12.7    -1.5    -0.2     0.5
>
> Simple repeatability and reproducibility (R&R) point estimates for pairs of raters:
>   Rater j Rater j' (R&R)_{j,j'}
> 1        2        0.808
> 1        3        0.900
> 2        3        0.850
> #-------------------------------------------------------------------------------
>
> Kind Regards,
> Salvatore Sidoti
> PhD Candidate
> The Ohio State University
> Columbus, Ohio USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nboeger @end|ng |rom gm@||@com  Tue Feb  1 14:45:40 2022
From: nboeger @end|ng |rom gm@||@com (Nathan Boeger)
Date: Tue, 1 Feb 2022 20:45:40 +0700
Subject: [R] Funky calculations
Message-ID: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>

Hello,

I found something strange and maybe I am going nuts but this does not make
sense:

>  (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1
[1] TRUE

I tried it on my mac M1 (R v4.1.2) and my Linux box (R v4.0.4). If I use
other values, it does not work (see below). It seems only that combination,
granted I did not try them all.

>  (0.4 + 0.2 + 0 + 0.2 + 0 + 0.2) > 1
[1] FALSE

Am I missing something?

Cheers

-nb

	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Tue Feb  1 17:34:13 2022
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Tue, 1 Feb 2022 16:34:13 +0000
Subject: [R] Funky calculations
In-Reply-To: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
Message-ID: <B55BEB40-523F-4362-905A-98AB3BF1ED48@utoronto.ca>

This looks like a version of FAQ 7.31.

> On Feb 1, 2022, at 8:45 AM, Nathan Boeger <nboeger at gmail.com> wrote:
> 
> [You don't often get email from nboeger at gmail.com. Learn why this is important at http://aka.ms/LearnAboutSenderIdentification.]
> 
> Hello,
> 
> I found something strange and maybe I am going nuts but this does not make
> sense:
> 
>> (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1
> [1] TRUE
> 
> I tried it on my mac M1 (R v4.1.2) and my Linux box (R v4.0.4). If I use
> other values, it does not work (see below). It seems only that combination,
> granted I did not try them all.
> 
>> (0.4 + 0.2 + 0 + 0.2 + 0 + 0.2) > 1
> [1] FALSE
> 
> Am I missing something?
> 
> Cheers
> 
> -nb
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael?s Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From gm@rk@|ow|er @end|ng |rom out|ook@com  Tue Feb  1 17:34:21 2022
From: gm@rk@|ow|er @end|ng |rom out|ook@com (Mark Fowler)
Date: Tue, 1 Feb 2022 16:34:21 +0000
Subject: [R] Funky calculations
In-Reply-To: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
Message-ID: <MN2PR07MB7213D0DFE6763C37A38C8A9985269@MN2PR07MB7213.namprd07.prod.outlook.com>

This a joke? The values differ between the TRUE and FALSE syntaxes. The FALSE computes to 1.0, which is not greater than 0.

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows

From: Nathan Boeger<mailto:nboeger at gmail.com>
Sent: Tuesday, February 1, 2022 12:28 PM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] Funky calculations

Hello,

I found something strange and maybe I am going nuts but this does not make
sense:

>  (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1
[1] TRUE

I tried it on my mac M1 (R v4.1.2) and my Linux box (R v4.0.4). If I use
other values, it does not work (see below). It seems only that combination,
granted I did not try them all.

>  (0.4 + 0.2 + 0 + 0.2 + 0 + 0.2) > 1
[1] FALSE

Am I missing something?

Cheers

-nb

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Feb  1 17:35:57 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 1 Feb 2022 19:35:57 +0300
Subject: [R] Funky calculations
In-Reply-To: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
Message-ID: <20220201193557.308209e8@Tarkus>

On Tue, 1 Feb 2022 20:45:40 +0700
Nathan Boeger <nboeger at gmail.com> wrote:

> I found something strange and maybe I am going nuts but this does not
> make sense:
> 
> >  (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1  
> [1] TRUE

Unfortunately, this always happens when computers approximate real
numbers with fractions in binary. See R FAQ 7.31 (RShowDoc('FAQ') or
<https://cran.r-project.org/doc/FAQ/R-FAQ.html>).

-- 
Best regards,
Ivan


From gm@rk@|ow|er @end|ng |rom out|ook@com  Tue Feb  1 17:37:03 2022
From: gm@rk@|ow|er @end|ng |rom out|ook@com (Mark Fowler)
Date: Tue, 1 Feb 2022 16:37:03 +0000
Subject: [R] Funky calculations
In-Reply-To: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
Message-ID: <MN2PR07MB7213E5C0FC4BD36A4034C16985269@MN2PR07MB7213.namprd07.prod.outlook.com>

Sorry, last post I meant not > 1

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows

From: Nathan Boeger<mailto:nboeger at gmail.com>
Sent: Tuesday, February 1, 2022 12:28 PM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] Funky calculations

Hello,

I found something strange and maybe I am going nuts but this does not make
sense:

>  (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1
[1] TRUE

I tried it on my mac M1 (R v4.1.2) and my Linux box (R v4.0.4). If I use
other values, it does not work (see below). It seems only that combination,
granted I did not try them all.

>  (0.4 + 0.2 + 0 + 0.2 + 0 + 0.2) > 1
[1] FALSE

Am I missing something?

Cheers

-nb

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Feb  1 17:52:56 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 1 Feb 2022 16:52:56 +0000 (UTC)
Subject: [R] Funky calculations
In-Reply-To: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
Message-ID: <542510676.2533919.1643734376267@mail.yahoo.com>

Yes, Nathan, you are missing something.

You are missing a computer language that does infinite precision arithmetic.

0.1 cannot be stored in binary exactly just as numbers like pi and e cannot be stored exactly as they keep needing more digits. The last digit of the allowed number of digits in floating point may have to be chosen as either a 0 or 1 even though the value is sort of in between. 

Think of what happens if you add in decimal

1/3 + 1/3 + 1/3

You could add

.333
.333
.333

And your handwritten calculation would be .999

And no matter how many more 3's you add, you never get beyond .999999999999999999999999999999999

And obviously the right answer is 1.0000000000000000000000000000

The order the numbers are added can matter. You interspersed a combination of floating point and integers so conversions are happening too. 

R has the ability to test for very near equality like this:

> all.equal(1, (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1))
[1] TRUE

There are some built-in and sort of hidden variables stored in .Machine that provide some tolerances for the data storage on that machine. 

> str(.Machine)
List of 28
 $ double.eps               : num 2.22e-16
 $ double.neg.eps           : num 1.11e-16
 $ double.xmin              : num 2.23e-308
 $ double.xmax              : num 1.8e+308
 $ double.base              : int 2
 $ double.digits            : int 53
 $ double.rounding          : int 5
 $ double.guard             : int 0
 $ double.ulp.digits        : int -52
 $ double.neg.ulp.digits    : int -53
 $ double.exponent          : int 11
 $ double.min.exp           : int -1022
 $ double.max.exp           : int 1024
 $ integer.max              : int 2147483647
 $ sizeof.long              : int 4
 $ sizeof.longlong          : int 8
 $ sizeof.longdouble        : int 16
 $ sizeof.pointer           : int 8
 $ longdouble.eps           : num 1.08e-19
 $ longdouble.neg.eps       : num 5.42e-20
 $ longdouble.digits        : int 64
 $ longdouble.rounding      : int 5
 $ longdouble.guard         : int 0
 $ longdouble.ulp.digits    : int -63
 $ longdouble.neg.ulp.digits: int -64
 $ longdouble.exponent      : int 15
 $ longdouble.min.exp       : int -16382
 $ longdouble.max.exp       : int 16384

Functions like all.equal() can use these to determine a way to compare while ignoring the last.

So yes, R shares this glitch with other programming languages and it is not really safe to compare floating point numbers at times. Here is just a suggestion on say rounding your sum to twelve digits to see how it compares to 1.0:

> round((0.4 + 0.2 + 0 + 0.3 + 0 + 0.1),12) > 1.0
[1] FALSE





-----Original Message-----
From: Nathan Boeger <nboeger at gmail.com>
To: r-help at r-project.org
Sent: Tue, Feb 1, 2022 8:45 am
Subject: [R] Funky calculations

Hello,

I found something strange and maybe I am going nuts but this does not make
sense:

>? (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1
[1] TRUE

I tried it on my mac M1 (R v4.1.2) and my Linux box (R v4.0.4). If I use
other values, it does not work (see below). It seems only that combination,
granted I did not try them all.

>? (0.4 + 0.2 + 0 + 0.2 + 0 + 0.2) > 1
[1] FALSE

Am I missing something?

Cheers

-nb

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Feb  1 18:07:51 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 1 Feb 2022 17:07:51 +0000
Subject: [R] Funky calculations
In-Reply-To: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
Message-ID: <e414e0f2-129f-e81e-7fa1-ca1f610c6176@sapo.pt>

Hello,

Like others have said, this is FAQ 7.31. Try

(0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) - 1


on both systems, on one of them it's not zero.

Hope this helps,

Rui Barradas

?s 13:45 de 01/02/2022, Nathan Boeger escreveu:
> Hello,
> 
> I found something strange and maybe I am going nuts but this does not make
> sense:
> 
>>   (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1
> [1] TRUE
> 
> I tried it on my mac M1 (R v4.1.2) and my Linux box (R v4.0.4). If I use
> other values, it does not work (see below). It seems only that combination,
> granted I did not try them all.
> 
>>   (0.4 + 0.2 + 0 + 0.2 + 0 + 0.2) > 1
> [1] FALSE
> 
> Am I missing something?
> 
> Cheers
> 
> -nb
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Feb  1 18:19:47 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 1 Feb 2022 17:19:47 +0000 (UTC)
Subject: [R] 
 [External] Weird behaviour of order() when having multiple ties
In-Reply-To: <CAFVVV-i83ad8OWs-8veC3dpnFNmaOenuNLWHpksuEH1za=Gr3w@mail.gmail.com>
References: <CAFVVV-gzoE2UDGMga_Pgbix=BmZj5WN2nA1wqY9s75_tcKQiWA@mail.gmail.com>
 <BL1PR11MB5239432B2669D24516983141D2249@BL1PR11MB5239.namprd11.prod.outlook.com>
 <CAFVVV-i83ad8OWs-8veC3dpnFNmaOenuNLWHpksuEH1za=Gr3w@mail.gmail.com>
Message-ID: <1765395989.2546954.1643735987443@mail.yahoo.com>

Stefan,

You are thinking of sorting and indeed if you sort, you get what you think:

> sort(c(2,3,4,1,1,1,1,1))
[1] 1 1 1 1 1 2 3 4

BUT order() does not return any of its values. NONE. It returns the indexes of sorted values and you can, if you choose, use the index to sort one or more values.

Imagine you have two independent vectors (not a data.frame) containing names and ages. You want to rearrange the names in alphabetical order but do not want to lose the ages. When done you want the correspondence to remain.

> Names <- c("Marie", "Jacques", "Zelda", "Jean")
> Ages <- c(12, 32, 3, 102)
> (index <- order(Names))
[1] 2 4 1 3
> (sortedNames <- Names[index])
[1] "Jacques" "Jean"    "Marie"   "Zelda"  
> (sortedAges <- Ages[index])
[1]  32 102  12   3

By getting the order you should take entries from the original, you can apply that order to both of the vectors, or anything else linked such as their birthday. Yes, many people avoid this by simply connecting all the vectors in a data.frame, but under the sheets, the code you use to manipulate things will often do something similar to actually make what you want happen.

In your example, you can get the sorted version like this:

> # Get vector of indices and print
> (index <- order(c(2,3,4,1,1,1,1,1)))
[1] 4 5 6 7 8 1 2 3
> 
> # Use the index on the vector to reaarange the order and print
> (c(2,3,4,1,1,1,1,1)[index])
[1] 1 1 1 1 1 2 3 4
> 
> # Use the index reversed to print in descending order.
> (c(2,3,4,1,1,1,1,1)[rev(index)])
[1] 4 3 2 1 1 1 1 1

And note you can print it forward and backward without calling sort() twice, not that this is important!

I hope that clarifies why the name is "order" and not "sort". 


-----Original Message-----
From: Stefan Fleck <stefan.b.fleck at gmail.com>
To: Richard M. Heiberger <rmh at temple.edu>
Cc: r-help at r-project.org <r-help at r-project.org>
Sent: Sun, Jan 30, 2022 3:07 pm
Subject: Re: [R]  [External] Weird behaviour of order() when having multiple ties

it's not about the sort order of the ties, shouldn't all the 1s in
order(c(2,3,4,1,1,1,1,1)) come before 2,3,4? because that's not what
happening

On Sun, Jan 30, 2022 at 9:00 PM Richard M. Heiberger <rmh at temple.edu> wrote:

> when there are ties it doesn't matter which is first.
> in a situation where it does matter, you will need a tiebreaker column.
> ------------------------------
> *From:* R-help <r-help-bounces at r-project.org> on behalf of Stefan Fleck <
> stefan.b.fleck at gmail.com>
> *Sent:* Sunday, January 30, 2022 4:16:44 AM
> *To:* r-help at r-project.org <r-help at r-project.org>
> *Subject:* [External] [R] Weird behaviour of order() when having multiple
> ties
>
> I am experiencing a weird behavior of `order()` for numeric vectors. I
> tested on 3.6.2 and 4.1.2 for windows and R 4.0.2 on ubuntu. Can anyone
> confirm?
>
> order(
>?  c(
>? ?  0.6,
>? ?  0.5,
>? ?  0.3,
>? ?  0.2,
>? ?  0.1,
>? ?  0.1
>?  )
> )
> ## Result [should be in order]
> [1] 5 6 4 3 2 1
>
> The sort order is obviously wrong. This only occurs if i have multiple
> ties. The problem does _not_ occur for decreasing = TRUE.
>
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=04%7C01%7Crmh%40temple.edu%7Cbae20314c2314a5cc7cd08d9e429e33f%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637791692024451993%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=O6R%2FNM6IdPzP8RY3JIWfLgmkE%2B0KcVyYBxoRMo8v2dk%3D&reserved=0
> PLEASE do read the posting guide
> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&data=04%7C01%7Crmh%40temple.edu%7Cbae20314c2314a5cc7cd08d9e429e33f%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637791692024451993%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=6hlfMjZLzopVzGnFVWlGnoEqvZBQwXPlxMuZ2sglEUk%3D&reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Feb  1 20:07:50 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 1 Feb 2022 19:07:50 +0000 (UTC)
Subject: [R] Funky calculations
In-Reply-To: <e414e0f2-129f-e81e-7fa1-ca1f610c6176@sapo.pt>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <e414e0f2-129f-e81e-7fa1-ca1f610c6176@sapo.pt>
Message-ID: <302884631.2576868.1643742470880@mail.yahoo.com>

I suspect there are examples, RUI, where the same code can produce different results based on the underlying representation or manipulation of floating point. There are two main versions I typically see using what some call a "float" and a "double" and I suspect at some future point someone will take 256 bits or so to make a "superdouble" that allots so many more bits to the mantissa and exponent components that you can use much larger numbers with many more significant digits. But it is the final digits where imprecision enters and also a number can vary whether you do rounding or truncating at that point. I think in binary, you generally truncate. So if you consider a number like 1/7 that has an infinitely long decimal representation in bases like decimal, but does have repeats, compared to a transcendental number like pi that does not really repeat, you can round it in decimal representation depending on where you are in the sequence when you stop.

.142857142857142857...

If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone.

.1
.14
.143
.1429
etc.

I actually wrote a much longer explanation about a similar concern someone had in another language, Python, that was picked up and published in a new daily and can be found as the second article at the following URL if interested.

https://pyherald.com/articles/02_01_2022/

It starts like this:

Representing Numbers: The Complexity Behind
Mail by Avi Gross , src

Note I did not choose that title nor did I choose the original Subject line I was replying to here: https://mail.python.org/pipermail/python-list/2021-November/904404.html

And, no, I was not asked nor given any opportunity to polish it or fix a spelling error. It was just my fairly usual free-floating posting style like I use here. It doe illustrate that we are not talking about a bug in R and that the proper way to avoid it may include being aware that sometimes a test for near-equality may be needed.

Think of how many people write an endless loop by waiting for an asymptotic sum like adding 1/2 + 1/4 + 1/8 ... and breaking out of the loop only when the sum is exactly equal to 1.0. Not only will it mathematically never happen, unless you consider happening AT infinity to qualify, but the addition using floating point numbers may end at 0.9999999999999999999999 or so and anything added to it will underflow and always be shown as adding 0 thereafter. But looked at properly, this is pretty much the same problem being reported here. So some people create a small epsilon such as 1E-15 ad write code like:

if (abs(myval - expected) < epsilon) ...

This is another way of saying, if I am close enough, we are there.

All computer languages are alike; except where they aren't.


-----Original Message-----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Nathan Boeger <nboeger at gmail.com>; r-help at r-project.org
Sent: Tue, Feb 1, 2022 12:07 pm
Subject: Re: [R] Funky calculations


Hello,

Like others have said, this is FAQ 7.31. Try

(0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) - 1


on both systems, on one of them it's not zero.

Hope this helps,

Rui Barradas

?s 13:45 de 01/02/2022, Nathan Boeger escreveu:
> Hello,
> 
> I found something strange and maybe I am going nuts but this does not make
> sense:
> 
>>?  (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1
> [1] TRUE
> 
> I tried it on my mac M1 (R v4.1.2) and my Linux box (R v4.0.4). If I use
> other values, it does not work (see below). It seems only that combination,
> granted I did not try them all.
> 
>>?  (0.4 + 0.2 + 0 + 0.2 + 0 + 0.2) > 1
> [1] FALSE
> 
> Am I missing something?
> 
> Cheers
> 
> -nb


 


From rmh @end|ng |rom temp|e@edu  Tue Feb  1 20:44:02 2022
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 1 Feb 2022 19:44:02 +0000
Subject: [R] [External]  Funky calculations
In-Reply-To: <20220201193557.308209e8@Tarkus>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
Message-ID: <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>

RShowDoc('FAQ') 

then search for 7.31


This statement
"If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone."
is not quite right.  The recommendation in IEEE 754, and this is how R does arithmetic, is to Round Even.

I ilustrate here with decimal, even though R and other programs use binary.

> x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
> r <- round(x)
> cbind(x, r)
        x r
 [1,] 1.4 1
 [2,] 1.5 2
 [3,] 1.6 2
 [4,] 2.4 2
 [5,] 2.5 2
 [6,] 2.6 3
 [7,] 3.4 3
 [8,] 3.5 4
 [9,] 3.6 4
[10,] 4.4 4
[11,] 4.5 4
[12,] 4.6 5
> 

Numbers whose last digit is not 5 (when in decimal) round to the nearest integer.
Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above) 
round to the nearest EVEN integer.
Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
2.5 and 4.5 round down do the even numbers 2 and 4.

This way the round ups and downs average out to 0.  If we always went up from .5 we would have
an updrift over time.

For even more detail click on the link in FAQ 7.31 to my appendix
https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
and search for "Appendix G".

Section G.5 explains Round to Even.
Sections G.6 onward illustrate specific examples, such as the one that started this email thread.

Rich

From drj|m|emon @end|ng |rom gm@||@com  Tue Feb  1 23:19:35 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 2 Feb 2022 09:19:35 +1100
Subject: [R] Survey design for multilevel analysis
In-Reply-To: <CAOTqx+KtV1_WOtffzuZJetE=JFKqVDqV8O15aUs0vBFZa1yyeQ@mail.gmail.com>
References: <CAOTqx+KtV1_WOtffzuZJetE=JFKqVDqV8O15aUs0vBFZa1yyeQ@mail.gmail.com>
Message-ID: <CA+8X3fUCk5FYbXOpTWLnFS3tzf7pSx4DvQrGHa0RcCRgTKJ4Tw@mail.gmail.com>

Hi Love,
I have finally had a chance to look at this more closely. I think that
the following link:

https://cran.r-project.org/web/packages/survival/vignettes/adjcurve.pdf

may be useful. See section 4.2.
This is not my area of expertise, but it seems to be a known problem.
Perhaps by posting to the:

R-SGI-Epi

mailing list you will get responses from specialists in the field.

Jim

On Tue, Feb 1, 2022 at 9:02 PM Love Umesi <yugohlav at gmail.com> wrote:
>
> I am new in using R, and I need to run a multilevel analysis (two-phase
> design on two levels) using Cox frailty survival model on a survey data
> (Nigeria Demographic and Health Survey Data).
>
> My problem is how to write the design weight using the two weights needed
> and apply them to the analysis.
>
> I have identified the needed variables for the survey design, which
> are : psu/cluster=
> v021 individual-level weight= wt1_1 cluster-level weigh= wt2_1 strata/stratum=
> v022
>
> Please can someone help me with the survey design (svydesign) code and how
> to include it and the weights in a model.
>
> I understand I have to use svycoxph in the model. Please how do I include
> survey design and account for the 2 weights (individual-level and
> cluster-level weights) in the gamma frailty model below?
>
> Frailty1 <- coxph (Surv(study_time, died) ~ factor(v024) + factor(mat_edu)
> + v025 + frailty(v021,distribution="gamma"), data=rcom2018)
>
> Really looking forward to your help as my project is hanging on this.
>
> Many thanks.
>
>
> library(survival)#> Warning: package 'survival' was built under R version 4.0.5
> library(frailtypack)#> Warning: package 'frailtypack' was built under
> R version 4.0.5#> Loading required package: boot#> #> Attaching
> package: 'boot'#> The following object is masked from
> 'package:survival':#> #>     aml#> Loading required package: MASS#>
> Loading required package: survC1#> Warning: package 'survC1' was built
> under R version 4.0.5#> Loading required package: doBy#> Warning:
> package 'doBy' was built under R version 4.0.5#> #> Attaching package:
> 'frailtypack'#> The following object is masked from
> 'package:survival':#> #>     cluster
>
>
> rcom1 <- data.frame(
>   data.frame(
>     pid = c(
>       1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,
>       14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,
>       30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
>       46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,
>       61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,
>       77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92,
>       93, 94, 95, 96, 97, 98, 99, 100
>     ),
>     study_time = c(
>       13, 9, 17, 31, 39, 22, 24, 0, 23, 12, 9, 35,
>       18, 20, 60, 18, 5, 46, 26, 54, 37, 51, 31, 55, 27, 15, 39, 6,
>       29, 0, 9, 40, 23, 12, 35, 56, 14, 40, 57, 42, 5, 42, 39, 39,
>       54, 19, 52, 42, 7, 28, 53, 5, 28, 13, 37, 0, 23, 33, 27, 36, 20,
>       24, 58, 34, 12, 44, 3, 34, 14, 5, 10, 40, 12, 36, 19, 58, 17,
>       40, 39, 58, 53, 53, 1, 50, 2, 28, 24, 13, 13, 50, 46, 46, 19, 6,
>       32, 59, 9, 30, 30, 43
>     ),
>     died = c(
>       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
>       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
>       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,
>       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>       0
>     ),
>     v021 = c(
>       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,
>       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,
>       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
>       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,
>       6
>     ),
>     v022 = c(
>       "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "2", "2", "2", "2", "2", "2", "2",
>       "2", "2", "2"
>     ),
>     v012 = c(
>       40, 37, 27, 27, 24, 32, 35, 35, 34, 20, 28,
>       28, 26, 24, 24, 25, 26, 26, 26, 26, 28, 27, 25, 25, 27, 26, 26,
>       21, 21, 31, 36, 36, 27, 23, 32, 32, 33, 33, 33, 28, 25, 37,
>       33, 34, 33, 28, 28, 29, 33, 33, 33, 39, 38, 38, 38, 38, 24, 27,
>       35, 40, 22, 38, 38, 21, 30, 30, 30, 39, 43, 18, 23, 23, 25, 25,
>       30, 45, 26, 26, 35, 35, 35, 35, 32, 32, 40, 25, 27, 30, 30, 30,
>       28, 28, 18, 27, 30, 30, 27, 21, 21, 30
>     ),
>     wt2_1 = c(
>       401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031,
>       401.200012207031, 401.200012207031, 401.200012207031, 401.200012207031,
>       631.818176269531, 631.818176269531, 631.818176269531,
>       631.818176269531, 631.818176269531, 631.818176269531, 631.818176269531,
>       631.818176269531, 631.818176269531, 631.818176269531
>     ),
>     wt1_1 = c(
>       2.5074667930603, 2.5074667930603,
>       2.5074667930603, 2.5074667930603, 2.5074667930603, 2.5074667930603,
>       2.5074667930603, 2.5074667930603, 2.5074667930603, 2.5074667930603,
>       2.5074667930603, 2.5074667930603, 2.5074667930603,
>       2.5074667930603, 2.5074667930603, 5.1194109916687, 5.1194109916687,
>       5.1194109916687, 5.1194109916687, 5.1194109916687, 5.1194109916687,
>       5.1194109916687, 5.1194109916687, 5.1194109916687,
>       5.1194109916687, 5.1194109916687, 5.1194109916687, 5.1194109916687,
>       5.1194109916687, 5.1194109916687, 5.1194109916687, 5.1194109916687,
>       5.1194109916687, 5.1194109916687, 2.40910983085632,
>       2.40910983085632, 2.40910983085632, 2.40910983085632, 2.40910983085632,
>       2.40910983085632, 2.40910983085632, 2.40910983085632,
>       2.40910983085632, 2.40910983085632, 2.40910983085632, 2.40910983085632,
>       2.40910983085632, 2.40910983085632, 1.06203985214233,
>       1.06203985214233, 1.06203985214233, 1.06203985214233, 1.06203985214233,
>       1.06203985214233, 1.06203985214233, 1.06203985214233,
>       1.06203985214233, 1.06203985214233, 1.06203985214233, 1.06203985214233,
>       1.06203985214233, 1.06203985214233, 1.06203985214233,
>       1.06203985214233, 1.06203985214233, 1.06203985214233, 1.06203985214233,
>       2.80098295211792, 2.80098295211792, 2.80098295211792,
>       2.80098295211792, 2.80098295211792, 2.80098295211792, 2.80098295211792,
>       2.80098295211792, 2.80098295211792, 2.80098295211792,
>       2.80098295211792, 2.80098295211792, 2.80098295211792, 2.80098295211792,
>       2.80098295211792, 2.80098295211792, 2.80098295211792,
>       2.80098295211792, 2.80098295211792, 2.80098295211792, 2.80098295211792,
>       2.80098295211792, 2.80098295211792, 1.24210178852081,
>       1.24210178852081, 1.24210178852081, 1.24210178852081, 1.24210178852081,
>       1.24210178852081, 1.24210178852081, 1.24210178852081,
>       1.24210178852081, 1.24210178852081
>     ),
>     v024 = c(
>       "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1"
>     ),
>     v025 = c(
>       "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1", "1",
>       "1", "1", "1", "1", "1", "1", "2", "2", "2", "2", "2", "2", "2",
>       "2", "2", "2"
>     ),
>     mat_edu = c(
>       "5", "5", "5", "4", "4", "5", "4", "4", "4",
>       "4", "4", "4", "5", "5", "5", "5", "5", "5", "4", "4", "5",
>       "4", "4", "4", "5", "3", "3", "4", "4", "5", "5", "5", "5", "4",
>       "2", "2", "0", "0", "0", "5", "5", "0", "1", "5", "5", "3",
>       "3", "5", "5", "5", "5", "5", "5", "5", "5", "5", "5", "4", "5",
>       "5", "4", "5", "5", "3", "4", "4", "5", "3", "1", "3", "3", "3",
>       "1", "3", "2", "1", "3", "3", "4", "4", "0", "0", "2", "2",
>       "1", "0", "4", "4", "4", "4", "0", "0", "3", "4", "2", "2", "3",
>       "3", "3", "0"
>     )
>   ))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Feb  2 02:42:12 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 2 Feb 2022 01:42:12 +0000 (UTC)
Subject: [R] [External]  Funky calculations
In-Reply-To: <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
Message-ID: <1240726547.2663210.1643766132419@mail.yahoo.com>

Richard,

I think it was fairly clear I was explaining how people do arithmetic manually and often truncate or round to some number of decimal places. I said nothing about what R does or what the IEEE standards say and I do not particularly care when making MY point.

My point is that humans before computers also had trouble writing down any decimals that continue indefinitely. It cannot be expected computer versions of arithmetic can do much better. Different people can opt to do the calculation with the same or different numbers of digits ad when compared to each other they may not match.

I do care what it does in my programs, of course. My goal here was to explain to someone that the anomaly found was not really an anomaly and that careful coding may be required in these situations.


-----Original Message-----
From: Richard M. Heiberger <rmh at temple.edu>
To: Avi Gross <avigross at verizon.net>
Cc: Nathan Boeger <nboeger at gmail.com>; r-help at r-project.org <r-help at r-project.org>
Sent: Tue, Feb 1, 2022 2:44 pm
Subject: Re: [External] [R] Funky calculations


RShowDoc('FAQ') 


then search for 7.31


This statement
"If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone."
is not quite right.? The recommendation in IEEE 754, and this is how R does arithmetic, is to Round Even.

I ilustrate here with decimal, even though R and other programs use binary.

> x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
> r <- round(x)
> cbind(x, r)
? ? ? ? x r
 [1,] 1.4 1
 [2,] 1.5 2
 [3,] 1.6 2
 [4,] 2.4 2
 [5,] 2.5 2
 [6,] 2.6 3
 [7,] 3.4 3
 [8,] 3.5 4
 [9,] 3.6 4
[10,] 4.4 4
[11,] 4.5 4
[12,] 4.6 5
> 

Numbers whose last digit is not 5 (when in decimal) round to the nearest integer.
Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above) 
round to the nearest EVEN integer.
Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
2.5 and 4.5 round down do the even numbers 2 and 4.

This way the round ups and downs average out to 0.? If we always went up from .5 we would have
an updrift over time.

For even more detail click on the link in FAQ 7.31 to my appendix
https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
and search for "Appendix G".

Section G.5 explains Round to Even.
Sections G.6 onward illustrate specific examples, such as the one that started this email thread.

Rich
 


From rmh @end|ng |rom temp|e@edu  Wed Feb  2 03:04:45 2022
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 2 Feb 2022 02:04:45 +0000
Subject: [R] [External]  Funky calculations
In-Reply-To: <1240726547.2663210.1643766132419@mail.yahoo.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <1240726547.2663210.1643766132419@mail.yahoo.com>
Message-ID: <1A13EFE0-C500-40D0-9BD0-8546E4EECBEA@temple.edu>

I apologize if my tone came across wrong.  I enjoy reading your comments on this list.

My goal was to describe what the IEEE and R interpret "careful coding" to be.

> On Feb 01, 2022, at 20:42, Avi Gross <avigross at verizon.net> wrote:
> 
> Richard,
> 
> I think it was fairly clear I was explaining how people do arithmetic manually and often truncate or round to some number of decimal places. I said nothing about what R does or what the IEEE standards say and I do not particularly care when making MY point.
> 
> My point is that humans before computers also had trouble writing down any decimals that continue indefinitely. It cannot be expected computer versions of arithmetic can do much better. Different people can opt to do the calculation with the same or different numbers of digits ad when compared to each other they may not match.
> 
> I do care what it does in my programs, of course. My goal here was to explain to someone that the anomaly found was not really an anomaly and that careful coding may be required in these situations.
> 
> 
> -----Original Message-----
> From: Richard M. Heiberger <rmh at temple.edu>
> To: Avi Gross <avigross at verizon.net>
> Cc: Nathan Boeger <nboeger at gmail.com>; r-help at r-project.org <r-help at r-project.org>
> Sent: Tue, Feb 1, 2022 2:44 pm
> Subject: Re: [External] [R] Funky calculations
> 
> 
> RShowDoc('FAQ') 
> 
> 
> then search for 7.31
> 
> 
> This statement
> "If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone."
> is not quite right.  The recommendation in IEEE 754, and this is how R does arithmetic, is to Round Even.
> 
> I ilustrate here with decimal, even though R and other programs use binary.
> 
>> x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
>> r <- round(x)
>> cbind(x, r)
>         x r
> [1,] 1.4 1
> [2,] 1.5 2
> [3,] 1.6 2
> [4,] 2.4 2
> [5,] 2.5 2
> [6,] 2.6 3
> [7,] 3.4 3
> [8,] 3.5 4
> [9,] 3.6 4
> [10,] 4.4 4
> [11,] 4.5 4
> [12,] 4.6 5
>> 
> 
> Numbers whose last digit is not 5 (when in decimal) round to the nearest integer.
> Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above) 
> round to the nearest EVEN integer.
> Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
> 2.5 and 4.5 round down do the even numbers 2 and 4.
> 
> This way the round ups and downs average out to 0.  If we always went up from .5 we would have
> an updrift over time.
> 
> For even more detail click on the link in FAQ 7.31 to my appendix
> https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
> and search for "Appendix G".
> 
> Section G.5 explains Round to Even.
> Sections G.6 onward illustrate specific examples, such as the one that started this email thread.
> 
> Rich
> 


From nboeger @end|ng |rom gm@||@com  Wed Feb  2 04:00:44 2022
From: nboeger @end|ng |rom gm@||@com (Nathan Boeger)
Date: Wed, 2 Feb 2022 10:00:44 +0700
Subject: [R] [External]  Funky calculations
In-Reply-To: <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
Message-ID: <CAFxA6Qq1sGwh9ZwEaV6zvtfd0yq6A1W6U4oDMuy1KXs_CV9ryQ@mail.gmail.com>

Thank you for this explanation!

I have a long background in C/C++ and never realized this was such an issue
with some languages. At least, with trivial single digit decimals. I
understand accuracy issues with very large decimals, repeating or
non-terminating rationals and I have handled them in the past. It makes me
worried about all the R scripts I have written before (yikes!).

Cheers

-nb

On Wed, 2 Feb 2022 at 02:44, Richard M. Heiberger <rmh at temple.edu> wrote:

> RShowDoc('FAQ')
>
> then search for 7.31
>
>
> This statement
> "If you stop at a 5 or 7 or 8 and back up to the previous digit, you round
> up. Else you leave the previous result alone."
> is not quite right.  The recommendation in IEEE 754, and this is how R
> does arithmetic, is to Round Even.
>
> I ilustrate here with decimal, even though R and other programs use binary.
>
> > x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
> > r <- round(x)
> > cbind(x, r)
>         x r
>  [1,] 1.4 1
>  [2,] 1.5 2
>  [3,] 1.6 2
>  [4,] 2.4 2
>  [5,] 2.5 2
>  [6,] 2.6 3
>  [7,] 3.4 3
>  [8,] 3.5 4
>  [9,] 3.6 4
> [10,] 4.4 4
> [11,] 4.5 4
> [12,] 4.6 5
> >
>
> Numbers whose last digit is not 5 (when in decimal) round to the nearest
> integer.
> Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above)
> round to the nearest EVEN integer.
> Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
> 2.5 and 4.5 round down do the even numbers 2 and 4.
>
> This way the round ups and downs average out to 0.  If we always went up
> from .5 we would have
> an updrift over time.
>
> For even more detail click on the link in FAQ 7.31 to my appendix
> https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
> and search for "Appendix G".
>
> Section G.5 explains Round to Even.
> Sections G.6 onward illustrate specific examples, such as the one that
> started this email thread.
>
> Rich

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Feb  2 04:30:19 2022
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 1 Feb 2022 19:30:19 -0800
Subject: [R] [External] Funky calculations
In-Reply-To: <CAFxA6Qq1sGwh9ZwEaV6zvtfd0yq6A1W6U4oDMuy1KXs_CV9ryQ@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <CAFxA6Qq1sGwh9ZwEaV6zvtfd0yq6A1W6U4oDMuy1KXs_CV9ryQ@mail.gmail.com>
Message-ID: <CAHqSRuT7KsOnUEKQRz2+Y_Z0ZoE+y3LHm4q9JLzqsSATe-85iA@mail.gmail.com>

The base 2 representation of 0.4 repeats the digit sequence 1001
infinitely, hence must be rounded.  The problem occurs in C the same as it
does in R.

bill at Bill-T490:~$ cat a.c
#include <stdio.h>

int main(int argc, char* argv[])
{
    double d = 0.4 + 0.3 + 0.2 + 0.1;
    printf("0.4+0.3+0.2+0.1 -> %24.17g\n", d);
    printf("0.4+0.3+0.2+0.1 == 1.0 -> %s\n", d == 1.0 ? "true" : "false");
    return 0;
}
bill at Bill-T490:~$ gcc a.c
bill at Bill-T490:~$ ./a.out
0.4+0.3+0.2+0.1 ->      0.99999999999999989
0.4+0.3+0.2+0.1 == 1.0 -> false

-Bill

On Tue, Feb 1, 2022 at 7:01 PM Nathan Boeger <nboeger at gmail.com> wrote:

> Thank you for this explanation!
>
> I have a long background in C/C++ and never realized this was such an issue
> with some languages. At least, with trivial single digit decimals. I
> understand accuracy issues with very large decimals, repeating or
> non-terminating rationals and I have handled them in the past. It makes me
> worried about all the R scripts I have written before (yikes!).
>
> Cheers
>
> -nb
>
> On Wed, 2 Feb 2022 at 02:44, Richard M. Heiberger <rmh at temple.edu> wrote:
>
> > RShowDoc('FAQ')
> >
> > then search for 7.31
> >
> >
> > This statement
> > "If you stop at a 5 or 7 or 8 and back up to the previous digit, you
> round
> > up. Else you leave the previous result alone."
> > is not quite right.  The recommendation in IEEE 754, and this is how R
> > does arithmetic, is to Round Even.
> >
> > I ilustrate here with decimal, even though R and other programs use
> binary.
> >
> > > x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
> > > r <- round(x)
> > > cbind(x, r)
> >         x r
> >  [1,] 1.4 1
> >  [2,] 1.5 2
> >  [3,] 1.6 2
> >  [4,] 2.4 2
> >  [5,] 2.5 2
> >  [6,] 2.6 3
> >  [7,] 3.4 3
> >  [8,] 3.5 4
> >  [9,] 3.6 4
> > [10,] 4.4 4
> > [11,] 4.5 4
> > [12,] 4.6 5
> > >
> >
> > Numbers whose last digit is not 5 (when in decimal) round to the nearest
> > integer.
> > Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above)
> > round to the nearest EVEN integer.
> > Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
> > 2.5 and 4.5 round down do the even numbers 2 and 4.
> >
> > This way the round ups and downs average out to 0.  If we always went up
> > from .5 we would have
> > an updrift over time.
> >
> > For even more detail click on the link in FAQ 7.31 to my appendix
> > https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
> > and search for "Appendix G".
> >
> > Section G.5 explains Round to Even.
> > Sections G.6 onward illustrate specific examples, such as the one that
> > started this email thread.
> >
> > Rich
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Feb  2 04:35:56 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 01 Feb 2022 19:35:56 -0800
Subject: [R] [External]  Funky calculations
In-Reply-To: <CAFxA6Qq1sGwh9ZwEaV6zvtfd0yq6A1W6U4oDMuy1KXs_CV9ryQ@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <CAFxA6Qq1sGwh9ZwEaV6zvtfd0yq6A1W6U4oDMuy1KXs_CV9ryQ@mail.gmail.com>
Message-ID: <2B4B92D0-499B-4A18-83E7-8F0067E91E50@dcn.davis.ca.us>

Please don't be dense. Not "some languages"... the discussion here has tried very hard to explain why this affects all of them. Including C/C++ (R is written in C). Look at [1] if you don't believe us.

[1] https://0.30000000000000004.com/


On February 1, 2022 7:00:44 PM PST, Nathan Boeger <nboeger at gmail.com> wrote:
>Thank you for this explanation!
>
>I have a long background in C/C++ and never realized this was such an issue
>with some languages. At least, with trivial single digit decimals. I
>understand accuracy issues with very large decimals, repeating or
>non-terminating rationals and I have handled them in the past. It makes me
>worried about all the R scripts I have written before (yikes!).
>
>Cheers
>
>-nb
>
>On Wed, 2 Feb 2022 at 02:44, Richard M. Heiberger <rmh at temple.edu> wrote:
>
>> RShowDoc('FAQ')
>>
>> then search for 7.31
>>
>>
>> This statement
>> "If you stop at a 5 or 7 or 8 and back up to the previous digit, you round
>> up. Else you leave the previous result alone."
>> is not quite right.  The recommendation in IEEE 754, and this is how R
>> does arithmetic, is to Round Even.
>>
>> I ilustrate here with decimal, even though R and other programs use binary.
>>
>> > x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
>> > r <- round(x)
>> > cbind(x, r)
>>         x r
>>  [1,] 1.4 1
>>  [2,] 1.5 2
>>  [3,] 1.6 2
>>  [4,] 2.4 2
>>  [5,] 2.5 2
>>  [6,] 2.6 3
>>  [7,] 3.4 3
>>  [8,] 3.5 4
>>  [9,] 3.6 4
>> [10,] 4.4 4
>> [11,] 4.5 4
>> [12,] 4.6 5
>> >
>>
>> Numbers whose last digit is not 5 (when in decimal) round to the nearest
>> integer.
>> Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above)
>> round to the nearest EVEN integer.
>> Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
>> 2.5 and 4.5 round down do the even numbers 2 and 4.
>>
>> This way the round ups and downs average out to 0.  If we always went up
>> from .5 we would have
>> an updrift over time.
>>
>> For even more detail click on the link in FAQ 7.31 to my appendix
>> https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
>> and search for "Appendix G".
>>
>> Section G.5 explains Round to Even.
>> Sections G.6 onward illustrate specific examples, such as the one that
>> started this email thread.
>>
>> Rich
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Feb  2 04:45:08 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 2 Feb 2022 03:45:08 +0000 (UTC)
Subject: [R] [External]  Funky calculations
In-Reply-To: <1A13EFE0-C500-40D0-9BD0-8546E4EECBEA@temple.edu>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <1240726547.2663210.1643766132419@mail.yahoo.com>
 <1A13EFE0-C500-40D0-9BD0-8546E4EECBEA@temple.edu>
Message-ID: <801628629.2676628.1643773508952@mail.yahoo.com>

This is a discussion forum, Richard, and I welcome requests to clarify what I wrote or to be corrected, especially when my words have been read with an attempt to understand. I do get private responses too and some days i wonder if I am not communicating the way people like!

But let me repeat. The question we started with asked about R. My answer applies to quite a few languages besides R and maybe just about all of them.

I got private email insisting the numbers being added were not irrational so why would they not be represented easily as a sum. I know my answers included parts at various levels of abstraction as well as examples of cases when Decimals notation for a number like 1/7 results in an infinite repeating sequence. So, I think it wise to follow up with what binary looks like and why hardly ANYTHING that looks reasonable is hard to represent exactly.

Consider that binary means POWERS OF TWO. The sequence 1101 before a decimal point means (starting from the right and heading left) that you have one ONES and no TWOS and one FOURS and one EIGHTS. Powers of two ranging from 2 to the zero power to two cubed. You can make any integer whatsoever using as long a sequence of zeros and ones as you like. Compare this to decimal notation where you use powers of ten and of course can use any of 0-9.

But looking at fractional numbers, like 1/7 and 1/10, it gets hard and inexact.

Remember now we are in BINARY. Here are some fractions with everything not shown to the right being zeros and thus not needed to be shown explicitly. Starting with the decimal point, read this from left to right to see the powers in the denominator rising so 1/2 then 1/4 then 1/8 ...:

0.0 would be 0.
0.1 would be 1/2
0.101 would be 1/2 + 1/8 or 5/8
0.11 would be 1/2 + 1/4 or 3/4
0.111 would be 1/2 + 1/4 + 1/8 or 7/8

We are now using negative powers where 2 raised to the minus one power is one over two raised to the plus one power, or 1/2 and so on. As you head to the right you get to fairly small numbers like 1/2048 ...

Every single binary fraction is thus a possibly infinite sum of negative powers of two, or rather the reciprocals of those in positive terms.

If you want to make 1/7, to some number of decimal places, it looks like this up to some point where I stop:

0.00100100100100100101

So no halves, no quarters, 1/8, no sixteenths, no thirty-seconds, 1/64, and so on. But if you add all that up, and note the sequence was STOPPED before it could continue further, you get this translated into decimal:

0.142857 55157470703125

Recall 1/7 in decimal notation is
0.142857 142857142857142857...

Note the divergence at the seventh digit after the decimal point. I left a space to show where they diverge. If I used more binary digits, I can get as close as I want but computers these days do not allow too many more digits unless you use highly specialized programs. There are packages that give you access such as "mpfr" but generally nothing can give you infinite precision. R will not handle an infinite number of infinitesimals.

The original problem that began our thread was about numbers like 0.1 and 0.2 and so on. In base ten, they look nice but I repeat in base 2 only powers of TWO reign.

0.1 in base two is about 0.0001100110011001101

that reads as 1/16 + 1/32 + 1/256 + 1/512 + ...

If I convert the above segment, which I repeat was stopped short, I get 0.1000003814697265625 which is a tad over and had I taken the last 1 and changed it to a zero as in 0.0001100110011001100 then we would have a bit under at 0.09999847412109375 

So the only way to write 0.1 exactly is to continue infinitely, again. Do the analysis and understand why most rational numbers will not easily convert to a small number of bits. But the advantages of computers doing operations in binary are huge and need not be explained. You may THINK you are entering numbers in decimal form but they rarely remain that way for long before they simply become binary and often remain binary unless and until you ask to print them out, usually in decimal.

BTW, I used a random web site to do the above conversion calculations:

https://www.rapidtables.com/convert/number/binary-to-decimal.html

Since I am writing in plain text, I cannot show what it says in the box on that page further down under Decimal Calculation Steps so I wonder what the rest of this message looks like:

(0.0001100110011001100)? = (0 ? 2?) + (0 ? 2??) + (0 ? 2??) + (0 ? 2??) + (1 ? 2??) + (1 ? 2??) + (0 ? 2??) + (0 ? 2??) + (1 ? 2??) + (1 ? 2??) + (0 ? 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 2???) + (0 ? 2???) = (0.09999847412109375)??

I think my part in this particular discussion can now finally come to an end. R and everything else can be incomplete. Deal with it!

-----Original Message-----
From: Richard M. Heiberger <rmh at temple.edu>
To: Avi Gross <avigross at verizon.net>
Cc: nboeger at gmail.com <nboeger at gmail.com>; r-help at r-project.org <r-help at r-project.org>
Sent: Tue, Feb 1, 2022 9:04 pm
Subject: Re: [External] [R] Funky calculations


I apologize if my tone came across wrong.? I enjoy reading your comments on this list.

My goal was to describe what the IEEE and R interpret "careful coding" to be.


> On Feb 01, 2022, at 20:42, Avi Gross <avigross at verizon.net> wrote:
> 
> Richard,
> 
> I think it was fairly clear I was explaining how people do arithmetic manually and often truncate or round to some number of decimal places. I said nothing about what R does or what the IEEE standards say and I do not particularly care when making MY point.
> 
> My point is that humans before computers also had trouble writing down any decimals that continue indefinitely. It cannot be expected computer versions of arithmetic can do much better. Different people can opt to do the calculation with the same or different numbers of digits ad when compared to each other they may not match.
> 
> I do care what it does in my programs, of course. My goal here was to explain to someone that the anomaly found was not really an anomaly and that careful coding may be required in these situations.
> 
> 
> -----Original Message-----
> From: Richard M. Heiberger <rmh at temple.edu>
> To: Avi Gross <avigross at verizon.net>
> Cc: Nathan Boeger <nboeger at gmail.com>; r-help at r-project.org <r-help at r-project.org>
> Sent: Tue, Feb 1, 2022 2:44 pm
> Subject: Re: [External] [R] Funky calculations
> 
> 
> RShowDoc('FAQ') 
> 
> 
> then search for 7.31
> 
> 
> This statement
> "If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone."
> is not quite right.? The recommendation in IEEE 754, and this is how R does arithmetic, is to Round Even.
> 
> I ilustrate here with decimal, even though R and other programs use binary.
> 
>> x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
>> r <- round(x)
>> cbind(x, r)
>? ? ? ?  x r
> [1,] 1.4 1
> [2,] 1.5 2
> [3,] 1.6 2
> [4,] 2.4 2
> [5,] 2.5 2
> [6,] 2.6 3
> [7,] 3.4 3
> [8,] 3.5 4
> [9,] 3.6 4
> [10,] 4.4 4
> [11,] 4.5 4
> [12,] 4.6 5
>> 
> 
> Numbers whose last digit is not 5 (when in decimal) round to the nearest integer.
> Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above) 
> round to the nearest EVEN integer.
> Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
> 2.5 and 4.5 round down do the even numbers 2 and 4.
> 
> This way the round ups and downs average out to 0.? If we always went up from .5 we would have
> an updrift over time.
> 
> For even more detail click on the link in FAQ 7.31 to my appendix
> https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
> and search for "Appendix G".
> 
> Section G.5 explains Round to Even.
> Sections G.6 onward illustrate specific examples, such as the one that started this email thread.
> 
> Rich
> 


 


From nboeger @end|ng |rom gm@||@com  Wed Feb  2 06:06:10 2022
From: nboeger @end|ng |rom gm@||@com (Nathan Boeger)
Date: Wed, 2 Feb 2022 12:06:10 +0700
Subject: [R] [External] Funky calculations
In-Reply-To: <CAHqSRuT7KsOnUEKQRz2+Y_Z0ZoE+y3LHm4q9JLzqsSATe-85iA@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <CAFxA6Qq1sGwh9ZwEaV6zvtfd0yq6A1W6U4oDMuy1KXs_CV9ryQ@mail.gmail.com>
 <CAHqSRuT7KsOnUEKQRz2+Y_Z0ZoE+y3LHm4q9JLzqsSATe-85iA@mail.gmail.com>
Message-ID: <CAFxA6Qr93D4VYjrZDvvrQgnTnToNQj3RQ21pLYrm8tJFHpA=1Q@mail.gmail.com>

I understand this and with C the data type used is important. For this type
of calculation, I would normally use a float (basic single precision is all
I require).

#include <stdio.h>

void main() {
  float foo = (0.4 + 0.2 + 0.30 + 0.1) ;
  printf("foo: %f , foo > 1: %s \n", foo, (foo > 1.0 ? "true" : "false"));
  double bar = (0.4 + 0.2 + 0.30 + 0.1) ;
  printf("bar: %lf , bar > 1: %s \n", bar, (bar > 1.0 ? "true" : "false"));
}

gcc  c-check.c -o c-check
./c-check
foo: 1.000000 , foo > 1: false
bar: 1.000000 , bar > 1: true

Again, it was my mistake for not reading the R-FAQ. I had no idea it would
spark such a long thread.

Cheers

-nb

On Wed, 2 Feb 2022 at 10:30, Bill Dunlap <williamwdunlap at gmail.com> wrote:

> The base 2 representation of 0.4 repeats the digit sequence 1001
> infinitely, hence must be rounded.  The problem occurs in C the same as it
> does in R.
>
> bill at Bill-T490:~$ cat a.c
> #include <stdio.h>
>
> int main(int argc, char* argv[])
> {
>     double d = 0.4 + 0.3 + 0.2 + 0.1;
>     printf("0.4+0.3+0.2+0.1 -> %24.17g\n", d);
>     printf("0.4+0.3+0.2+0.1 == 1.0 -> %s\n", d == 1.0 ? "true" : "false");
>     return 0;
> }
> bill at Bill-T490:~$ gcc a.c
> bill at Bill-T490:~$ ./a.out
> 0.4+0.3+0.2+0.1 ->      0.99999999999999989
> 0.4+0.3+0.2+0.1 == 1.0 -> false
>
> -Bill
>
> On Tue, Feb 1, 2022 at 7:01 PM Nathan Boeger <nboeger at gmail.com> wrote:
>
>> Thank you for this explanation!
>>
>> I have a long background in C/C++ and never realized this was such an
>> issue
>> with some languages. At least, with trivial single digit decimals. I
>> understand accuracy issues with very large decimals, repeating or
>> non-terminating rationals and I have handled them in the past. It makes me
>> worried about all the R scripts I have written before (yikes!).
>>
>> Cheers
>>
>> -nb
>>
>> On Wed, 2 Feb 2022 at 02:44, Richard M. Heiberger <rmh at temple.edu> wrote:
>>
>> > RShowDoc('FAQ')
>> >
>> > then search for 7.31
>> >
>> >
>> > This statement
>> > "If you stop at a 5 or 7 or 8 and back up to the previous digit, you
>> round
>> > up. Else you leave the previous result alone."
>> > is not quite right.  The recommendation in IEEE 754, and this is how R
>> > does arithmetic, is to Round Even.
>> >
>> > I ilustrate here with decimal, even though R and other programs use
>> binary.
>> >
>> > > x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
>> > > r <- round(x)
>> > > cbind(x, r)
>> >         x r
>> >  [1,] 1.4 1
>> >  [2,] 1.5 2
>> >  [3,] 1.6 2
>> >  [4,] 2.4 2
>> >  [5,] 2.5 2
>> >  [6,] 2.6 3
>> >  [7,] 3.4 3
>> >  [8,] 3.5 4
>> >  [9,] 3.6 4
>> > [10,] 4.4 4
>> > [11,] 4.5 4
>> > [12,] 4.6 5
>> > >
>> >
>> > Numbers whose last digit is not 5 (when in decimal) round to the nearest
>> > integer.
>> > Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above)
>> > round to the nearest EVEN integer.
>> > Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
>> > 2.5 and 4.5 round down do the even numbers 2 and 4.
>> >
>> > This way the round ups and downs average out to 0.  If we always went up
>> > from .5 we would have
>> > an updrift over time.
>> >
>> > For even more detail click on the link in FAQ 7.31 to my appendix
>> > https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
>> > and search for "Appendix G".
>> >
>> > Section G.5 explains Round to Even.
>> > Sections G.6 onward illustrate specific examples, such as the one that
>> > started this email thread.
>> >
>> > Rich
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Wed Feb  2 14:35:54 2022
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Wed, 2 Feb 2022 08:35:54 -0500
Subject: [R] [External] Funky calculations
In-Reply-To: <801628629.2676628.1643773508952@mail.yahoo.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <1240726547.2663210.1643766132419@mail.yahoo.com>
 <1A13EFE0-C500-40D0-9BD0-8546E4EECBEA@temple.edu>
 <801628629.2676628.1643773508952@mail.yahoo.com>
Message-ID: <f7f69f1b-e19c-42e3-863f-27681a8fb618@gmail.com>

I was one of the 31 names on the 1985 IEEE standard. If anyone thinks things are awkward now,
try looking at the swamp we had beforehand.

What I believe IS useful is to provide examples and to explain them in tutorial fashion.
We need to recognize that our computations have limitations. Most common computing platforms
use IEEE binary arithmetic, but not all.

This was much more "in our face" when we used slide rules or hand-crank calculators. I still
have slide rules and a Monroe "Portable" calculator -- 5 kg! It's worth bringing them out every
so often and being thankful for the power and speed of modern computing, while remembering to
watch for the cowpads of REAL and REAL*8 arithmetic.

JN

On 2022-02-01 22:45, Avi Gross via R-help wrote:
> This is a discussion forum, Richard, and I welcome requests to clarify what I wrote or to be corrected, especially when my words have been read with an attempt to understand. I do get private responses too and some days i wonder if I am not communicating the way people like!
> 
> But let me repeat. The question we started with asked about R. My answer applies to quite a few languages besides R and maybe just about all of them.
> 
> I got private email insisting the numbers being added were not irrational so why would they not be represented easily as a sum. I know my answers included parts at various levels of abstraction as well as examples of cases when Decimals notation for a number like 1/7 results in an infinite repeating sequence. So, I think it wise to follow up with what binary looks like and why hardly ANYTHING that looks reasonable is hard to represent exactly.
> 
> Consider that binary means POWERS OF TWO. The sequence 1101 before a decimal point means (starting from the right and heading left) that you have one ONES and no TWOS and one FOURS and one EIGHTS. Powers of two ranging from 2 to the zero power to two cubed. You can make any integer whatsoever using as long a sequence of zeros and ones as you like. Compare this to decimal notation where you use powers of ten and of course can use any of 0-9.
> 
> But looking at fractional numbers, like 1/7 and 1/10, it gets hard and inexact.
> 
> Remember now we are in BINARY. Here are some fractions with everything not shown to the right being zeros and thus not needed to be shown explicitly. Starting with the decimal point, read this from left to right to see the powers in the denominator rising so 1/2 then 1/4 then 1/8 ...:
> 
> 0.0 would be 0.
> 0.1 would be 1/2
> 0.101 would be 1/2 + 1/8 or 5/8
> 0.11 would be 1/2 + 1/4 or 3/4
> 0.111 would be 1/2 + 1/4 + 1/8 or 7/8
> 
> We are now using negative powers where 2 raised to the minus one power is one over two raised to the plus one power, or 1/2 and so on. As you head to the right you get to fairly small numbers like 1/2048 ...
> 
> Every single binary fraction is thus a possibly infinite sum of negative powers of two, or rather the reciprocals of those in positive terms.
> 
> If you want to make 1/7, to some number of decimal places, it looks like this up to some point where I stop:
> 
> 0.00100100100100100101
> 
> So no halves, no quarters, 1/8, no sixteenths, no thirty-seconds, 1/64, and so on. But if you add all that up, and note the sequence was STOPPED before it could continue further, you get this translated into decimal:
> 
> 0.142857 55157470703125
> 
> Recall 1/7 in decimal notation is
> 0.142857 142857142857142857...
> 
> Note the divergence at the seventh digit after the decimal point. I left a space to show where they diverge. If I used more binary digits, I can get as close as I want but computers these days do not allow too many more digits unless you use highly specialized programs. There are packages that give you access such as "mpfr" but generally nothing can give you infinite precision. R will not handle an infinite number of infinitesimals.
> 
> The original problem that began our thread was about numbers like 0.1 and 0.2 and so on. In base ten, they look nice but I repeat in base 2 only powers of TWO reign.
> 
> 0.1 in base two is about 0.0001100110011001101
> 
> that reads as 1/16 + 1/32 + 1/256 + 1/512 + ...
> 
> If I convert the above segment, which I repeat was stopped short, I get 0.1000003814697265625 which is a tad over and had I taken the last 1 and changed it to a zero as in 0.0001100110011001100 then we would have a bit under at 0.09999847412109375
> 
> So the only way to write 0.1 exactly is to continue infinitely, again. Do the analysis and understand why most rational numbers will not easily convert to a small number of bits. But the advantages of computers doing operations in binary are huge and need not be explained. You may THINK you are entering numbers in decimal form but they rarely remain that way for long before they simply become binary and often remain binary unless and until you ask to print them out, usually in decimal.
> 
> BTW, I used a random web site to do the above conversion calculations:
> 
> https://www.rapidtables.com/convert/number/binary-to-decimal.html
> 
> Since I am writing in plain text, I cannot show what it says in the box on that page further down under Decimal Calculation Steps so I wonder what the rest of this message looks like:
> 
> (0.0001100110011001100)? = (0 ? 2?) + (0 ? 2??) + (0 ? 2??) + (0 ? 2??) + (1 ? 2??) + (1 ? 2??) + (0 ? 2??) + (0 ? 2??) + (1 ? 2??) + (1 ? 2??) + (0 ? 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 2???) + (0 ? 2???) = (0.09999847412109375)??
> 
> I think my part in this particular discussion can now finally come to an end. R and everything else can be incomplete. Deal with it!
> 
> -----Original Message-----
> From: Richard M. Heiberger <rmh at temple.edu>
> To: Avi Gross <avigross at verizon.net>
> Cc: nboeger at gmail.com <nboeger at gmail.com>; r-help at r-project.org <r-help at r-project.org>
> Sent: Tue, Feb 1, 2022 9:04 pm
> Subject: Re: [External] [R] Funky calculations
> 
> 
> I apologize if my tone came across wrong.? I enjoy reading your comments on this list.
> 
> My goal was to describe what the IEEE and R interpret "careful coding" to be.
> 
> 
>> On Feb 01, 2022, at 20:42, Avi Gross <avigross at verizon.net> wrote:
>>
>> Richard,
>>
>> I think it was fairly clear I was explaining how people do arithmetic manually and often truncate or round to some number of decimal places. I said nothing about what R does or what the IEEE standards say and I do not particularly care when making MY point.
>>
>> My point is that humans before computers also had trouble writing down any decimals that continue indefinitely. It cannot be expected computer versions of arithmetic can do much better. Different people can opt to do the calculation with the same or different numbers of digits ad when compared to each other they may not match.
>>
>> I do care what it does in my programs, of course. My goal here was to explain to someone that the anomaly found was not really an anomaly and that careful coding may be required in these situations.
>>
>>
>> -----Original Message-----
>> From: Richard M. Heiberger <rmh at temple.edu>
>> To: Avi Gross <avigross at verizon.net>
>> Cc: Nathan Boeger <nboeger at gmail.com>; r-help at r-project.org <r-help at r-project.org>
>> Sent: Tue, Feb 1, 2022 2:44 pm
>> Subject: Re: [External] [R] Funky calculations
>>
>>
>> RShowDoc('FAQ')
>>
>>
>> then search for 7.31
>>
>>
>> This statement
>> "If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone."
>> is not quite right.? The recommendation in IEEE 754, and this is how R does arithmetic, is to Round Even.
>>
>> I ilustrate here with decimal, even though R and other programs use binary.
>>
>>> x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
>>> r <- round(x)
>>> cbind(x, r)
>>  ? ? ? ?  x r
>> [1,] 1.4 1
>> [2,] 1.5 2
>> [3,] 1.6 2
>> [4,] 2.4 2
>> [5,] 2.5 2
>> [6,] 2.6 3
>> [7,] 3.4 3
>> [8,] 3.5 4
>> [9,] 3.6 4
>> [10,] 4.4 4
>> [11,] 4.5 4
>> [12,] 4.6 5
>>>
>>
>> Numbers whose last digit is not 5 (when in decimal) round to the nearest integer.
>> Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above)
>> round to the nearest EVEN integer.
>> Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
>> 2.5 and 4.5 round down do the even numbers 2 and 4.
>>
>> This way the round ups and downs average out to 0.? If we always went up from .5 we would have
>> an updrift over time.
>>
>> For even more detail click on the link in FAQ 7.31 to my appendix
>> https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
>> and search for "Appendix G".
>>
>> Section G.5 explains Round to Even.
>> Sections G.6 onward illustrate specific examples, such as the one that started this email thread.
>>
>> Rich
>>
> 
> 
>   
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@e||ck @end|ng |rom gm@||@com  Wed Feb  2 14:39:09 2022
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Wed, 2 Feb 2022 08:39:09 -0500
Subject: [R] Funky calculations
In-Reply-To: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
Message-ID: <CADKEMqjLh+dcwvusYCCMqhUjqaL8pQaTV04NBptaoKN1aY26fQ@mail.gmail.com>

I have not looked into this, but maybe this is related to floating point
rounding?
Kindest regards,

Stephen Sefick, PhD

On Tue, Feb 1, 2022, 11:28 Nathan Boeger <nboeger at gmail.com> wrote:

> Hello,
>
> I found something strange and maybe I am going nuts but this does not make
> sense:
>
> >  (0.4 + 0.2 + 0 + 0.3 + 0 + 0.1) > 1
> [1] TRUE
>
> I tried it on my mac M1 (R v4.1.2) and my Linux box (R v4.0.4). If I use
> other values, it does not work (see below). It seems only that combination,
> granted I did not try them all.
>
> >  (0.4 + 0.2 + 0 + 0.2 + 0 + 0.2) > 1
> [1] FALSE
>
> Am I missing something?
>
> Cheers
>
> -nb
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Feb  2 15:23:54 2022
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 2 Feb 2022 06:23:54 -0800
Subject: [R] [External] Funky calculations
In-Reply-To: <CAFxA6Qr93D4VYjrZDvvrQgnTnToNQj3RQ21pLYrm8tJFHpA=1Q@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <CAFxA6Qq1sGwh9ZwEaV6zvtfd0yq6A1W6U4oDMuy1KXs_CV9ryQ@mail.gmail.com>
 <CAHqSRuT7KsOnUEKQRz2+Y_Z0ZoE+y3LHm4q9JLzqsSATe-85iA@mail.gmail.com>
 <CAFxA6Qr93D4VYjrZDvvrQgnTnToNQj3RQ21pLYrm8tJFHpA=1Q@mail.gmail.com>
Message-ID: <CAHqSRuTcqLizbAFy2jRBKoqFTNuV6mi08au6ox2iwbLgWew1QA@mail.gmail.com>

Floats have 23 bits of precision so the rounding is done there instead of
at 52 bits, hence a different example is needed to show the problem with
floats.

bill at Bill-T490:~$ cat b.c
#include <stdio.h>

int main(int argc, char* argv[])
{
    float d = 0.4 + 0.4 + 0.4 + 0.4;
    printf("0.4+0.4+0.4+0.4 -> %24.17g\n", (double)d);
    printf("0.4+0.4+0.4+0.4 == 1.6 -> %s\n", d == 1.0 ? "true" : "false");
    return 0;
}
bill at Bill-T490:~$ gcc b.c
bill at Bill-T490:~$ ./a.out
0.4+0.4+0.4+0.4 ->       1.6000000238418579
0.4+0.4+0.4+0.4 == 1.6 -> false

There is no getting around the fact that rounding will happen.

-Bill

On Tue, Feb 1, 2022 at 9:06 PM Nathan Boeger <nboeger at gmail.com> wrote:

>
> I understand this and with C the data type used is important. For this
> type of calculation, I would normally use a float (basic single precision
> is all I require).
>
> #include <stdio.h>
>
> void main() {
>   float foo = (0.4 + 0.2 + 0.30 + 0.1) ;
>   printf("foo: %f , foo > 1: %s \n", foo, (foo > 1.0 ? "true" : "false"));
>   double bar = (0.4 + 0.2 + 0.30 + 0.1) ;
>   printf("bar: %lf , bar > 1: %s \n", bar, (bar > 1.0 ? "true" : "false"));
> }
>
> gcc  c-check.c -o c-check
> ./c-check
> foo: 1.000000 , foo > 1: false
> bar: 1.000000 , bar > 1: true
>
> Again, it was my mistake for not reading the R-FAQ. I had no idea it would
> spark such a long thread.
>
> Cheers
>
> -nb
>
> On Wed, 2 Feb 2022 at 10:30, Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
>> The base 2 representation of 0.4 repeats the digit sequence 1001
>> infinitely, hence must be rounded.  The problem occurs in C the same as it
>> does in R.
>>
>> bill at Bill-T490:~$ cat a.c
>> #include <stdio.h>
>>
>> int main(int argc, char* argv[])
>> {
>>     double d = 0.4 + 0.3 + 0.2 + 0.1;
>>     printf("0.4+0.3+0.2+0.1 -> %24.17g\n", d);
>>     printf("0.4+0.3+0.2+0.1 == 1.0 -> %s\n", d == 1.0 ? "true" : "false");
>>     return 0;
>> }
>> bill at Bill-T490:~$ gcc a.c
>> bill at Bill-T490:~$ ./a.out
>> 0.4+0.3+0.2+0.1 ->      0.99999999999999989
>> 0.4+0.3+0.2+0.1 == 1.0 -> false
>>
>> -Bill
>>
>> On Tue, Feb 1, 2022 at 7:01 PM Nathan Boeger <nboeger at gmail.com> wrote:
>>
>>> Thank you for this explanation!
>>>
>>> I have a long background in C/C++ and never realized this was such an
>>> issue
>>> with some languages. At least, with trivial single digit decimals. I
>>> understand accuracy issues with very large decimals, repeating or
>>> non-terminating rationals and I have handled them in the past. It makes
>>> me
>>> worried about all the R scripts I have written before (yikes!).
>>>
>>> Cheers
>>>
>>> -nb
>>>
>>> On Wed, 2 Feb 2022 at 02:44, Richard M. Heiberger <rmh at temple.edu>
>>> wrote:
>>>
>>> > RShowDoc('FAQ')
>>> >
>>> > then search for 7.31
>>> >
>>> >
>>> > This statement
>>> > "If you stop at a 5 or 7 or 8 and back up to the previous digit, you
>>> round
>>> > up. Else you leave the previous result alone."
>>> > is not quite right.  The recommendation in IEEE 754, and this is how R
>>> > does arithmetic, is to Round Even.
>>> >
>>> > I ilustrate here with decimal, even though R and other programs use
>>> binary.
>>> >
>>> > > x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
>>> > > r <- round(x)
>>> > > cbind(x, r)
>>> >         x r
>>> >  [1,] 1.4 1
>>> >  [2,] 1.5 2
>>> >  [3,] 1.6 2
>>> >  [4,] 2.4 2
>>> >  [5,] 2.5 2
>>> >  [6,] 2.6 3
>>> >  [7,] 3.4 3
>>> >  [8,] 3.5 4
>>> >  [9,] 3.6 4
>>> > [10,] 4.4 4
>>> > [11,] 4.5 4
>>> > [12,] 4.6 5
>>> > >
>>> >
>>> > Numbers whose last digit is not 5 (when in decimal) round to the
>>> nearest
>>> > integer.
>>> > Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above)
>>> > round to the nearest EVEN integer.
>>> > Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
>>> > 2.5 and 4.5 round down do the even numbers 2 and 4.
>>> >
>>> > This way the round ups and downs average out to 0.  If we always went
>>> up
>>> > from .5 we would have
>>> > an updrift over time.
>>> >
>>> > For even more detail click on the link in FAQ 7.31 to my appendix
>>> > https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
>>> > and search for "Appendix G".
>>> >
>>> > Section G.5 explains Round to Even.
>>> > Sections G.6 onward illustrate specific examples, such as the one that
>>> > started this email thread.
>>> >
>>> > Rich
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Feb  2 19:07:02 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 2 Feb 2022 18:07:02 +0000 (UTC)
Subject: [R] [External] Funky calculations
In-Reply-To: <f7f69f1b-e19c-42e3-863f-27681a8fb618@gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <1240726547.2663210.1643766132419@mail.yahoo.com>
 <1A13EFE0-C500-40D0-9BD0-8546E4EECBEA@temple.edu>
 <801628629.2676628.1643773508952@mail.yahoo.com>
 <f7f69f1b-e19c-42e3-863f-27681a8fb618@gmail.com>
Message-ID: <1219089011.2808560.1643825222712@mail.yahoo.com>

JC,

Interesting. People often misunderstand standards and the need for them as well as the way they are a compromise by lots of people representing different interests. You say you were one of 31, but in my experience, many more people are involved than the ones who show up. I had some involvements with standards back in the nineties and sometimes the results made sense and sometimes we ended up with designing a camel with stripes while trying to design a horse.

The issue here that needs repeating is that some things are basically impossible and the best we can do is to go part-way and make it as sane as we can.

Binary is NOT a must but for now it is. Electronic circuits that work in two modes we call zero and one are not the only choices and we may someday work with more complex circuits. Some mechanical devices have been built that work in a decimal manner. But given what we are using, a standard that lets you work with numbers to a reasonable level of representation is the best we can do. As has been pointed out, mathematically, only selected real numbers can be represented exactly in base two, and even fewer if you limit the number of bits you can use.

So floating point can be used with caution. I have seen some problems where it was chosen to deliberately convert all the numbers used to integers by say changing from measuring in continuous ways in meters to measuring in millimeters with no fractional millimeters allowed. All calculations done (excluding standard division) could now be compared to others without ambiguity. But for most cases, this is not necessary or even possible.

-----Original Message-----
From: J C Nash <profjcnash at gmail.com>
To: r-help at r-project.org
Sent: Wed, Feb 2, 2022 8:35 am
Subject: Re: [R] [External] Funky calculations


I was one of the 31 names on the 1985 IEEE standard. If anyone thinks things are awkward now,
try looking at the swamp we had beforehand.

What I believe IS useful is to provide examples and to explain them in tutorial fashion.
We need to recognize that our computations have limitations. Most common computing platforms
use IEEE binary arithmetic, but not all.

This was much more "in our face" when we used slide rules or hand-crank calculators. I still
have slide rules and a Monroe "Portable" calculator -- 5 kg! It's worth bringing them out every
so often and being thankful for the power and speed of modern computing, while remembering to
watch for the cowpads of REAL and REAL*8 arithmetic.

JN

On 2022-02-01 22:45, Avi Gross via R-help wrote:
> This is a discussion forum, Richard, and I welcome requests to clarify what I wrote or to be corrected, especially when my words have been read with an attempt to understand. I do get private responses too and some days i wonder if I am not communicating the way people like!
> 
> But let me repeat. The question we started with asked about R. My answer applies to quite a few languages besides R and maybe just about all of them.
> 
> I got private email insisting the numbers being added were not irrational so why would they not be represented easily as a sum. I know my answers included parts at various levels of abstraction as well as examples of cases when Decimals notation for a number like 1/7 results in an infinite repeating sequence. So, I think it wise to follow up with what binary looks like and why hardly ANYTHING that looks reasonable is hard to represent exactly.
> 
> Consider that binary means POWERS OF TWO. The sequence 1101 before a decimal point means (starting from the right and heading left) that you have one ONES and no TWOS and one FOURS and one EIGHTS. Powers of two ranging from 2 to the zero power to two cubed. You can make any integer whatsoever using as long a sequence of zeros and ones as you like. Compare this to decimal notation where you use powers of ten and of course can use any of 0-9.
> 
> But looking at fractional numbers, like 1/7 and 1/10, it gets hard and inexact.
> 
> Remember now we are in BINARY. Here are some fractions with everything not shown to the right being zeros and thus not needed to be shown explicitly. Starting with the decimal point, read this from left to right to see the powers in the denominator rising so 1/2 then 1/4 then 1/8 ...:
> 
> 0.0 would be 0.
> 0.1 would be 1/2
> 0.101 would be 1/2 + 1/8 or 5/8
> 0.11 would be 1/2 + 1/4 or 3/4
> 0.111 would be 1/2 + 1/4 + 1/8 or 7/8
> 
> We are now using negative powers where 2 raised to the minus one power is one over two raised to the plus one power, or 1/2 and so on. As you head to the right you get to fairly small numbers like 1/2048 ...
> 
> Every single binary fraction is thus a possibly infinite sum of negative powers of two, or rather the reciprocals of those in positive terms.
> 
> If you want to make 1/7, to some number of decimal places, it looks like this up to some point where I stop:
> 
> 0.00100100100100100101
> 
> So no halves, no quarters, 1/8, no sixteenths, no thirty-seconds, 1/64, and so on. But if you add all that up, and note the sequence was STOPPED before it could continue further, you get this translated into decimal:
> 
> 0.142857 55157470703125
> 
> Recall 1/7 in decimal notation is
> 0.142857 142857142857142857...
> 
> Note the divergence at the seventh digit after the decimal point. I left a space to show where they diverge. If I used more binary digits, I can get as close as I want but computers these days do not allow too many more digits unless you use highly specialized programs. There are packages that give you access such as "mpfr" but generally nothing can give you infinite precision. R will not handle an infinite number of infinitesimals.
> 
> The original problem that began our thread was about numbers like 0.1 and 0.2 and so on. In base ten, they look nice but I repeat in base 2 only powers of TWO reign.
> 
> 0.1 in base two is about 0.0001100110011001101
> 
> that reads as 1/16 + 1/32 + 1/256 + 1/512 + ...
> 
> If I convert the above segment, which I repeat was stopped short, I get 0.1000003814697265625 which is a tad over and had I taken the last 1 and changed it to a zero as in 0.0001100110011001100 then we would have a bit under at 0.09999847412109375
> 
> So the only way to write 0.1 exactly is to continue infinitely, again. Do the analysis and understand why most rational numbers will not easily convert to a small number of bits. But the advantages of computers doing operations in binary are huge and need not be explained. You may THINK you are entering numbers in decimal form but they rarely remain that way for long before they simply become binary and often remain binary unless and until you ask to print them out, usually in decimal.
> 
> BTW, I used a random web site to do the above conversion calculations:
> 
> https://www.rapidtables.com/convert/number/binary-to-decimal.html
> 
> Since I am writing in plain text, I cannot show what it says in the box on that page further down under Decimal Calculation Steps so I wonder what the rest of this message looks like:
> 
> (0.0001100110011001100)? = (0 ? 2?) + (0 ? 2??) + (0 ? 2??) + (0 ? 2??) + (1 ? 2??) + (1 ? 2??) + (0 ? 2??) + (0 ? 2??) + (1 ? 2??) + (1 ? 2??) + (0 ? 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 2???) + (0 ? 2???) = (0.09999847412109375)??
> 
> I think my part in this particular discussion can now finally come to an end. R and everything else can be incomplete. Deal with it!
> 
> -----Original Message-----
> From: Richard M. Heiberger <rmh at temple.edu>
> To: Avi Gross <avigross at verizon.net>
> Cc: nboeger at gmail.com <nboeger at gmail.com>; r-help at r-project.org <r-help at r-project.org>
> Sent: Tue, Feb 1, 2022 9:04 pm
> Subject: Re: [External] [R] Funky calculations
> 
> 
> I apologize if my tone came across wrong.? I enjoy reading your comments on this list.
> 
> My goal was to describe what the IEEE and R interpret "careful coding" to be.
> 
> 
>> On Feb 01, 2022, at 20:42, Avi Gross <avigross at verizon.net> wrote:
>>
>> Richard,
>>
>> I think it was fairly clear I was explaining how people do arithmetic manually and often truncate or round to some number of decimal places. I said nothing about what R does or what the IEEE standards say and I do not particularly care when making MY point.
>>
>> My point is that humans before computers also had trouble writing down any decimals that continue indefinitely. It cannot be expected computer versions of arithmetic can do much better. Different people can opt to do the calculation with the same or different numbers of digits ad when compared to each other they may not match.
>>
>> I do care what it does in my programs, of course. My goal here was to explain to someone that the anomaly found was not really an anomaly and that careful coding may be required in these situations.
>>
>>
>> -----Original Message-----
>> From: Richard M. Heiberger <rmh at temple.edu>
>> To: Avi Gross <avigross at verizon.net>
>> Cc: Nathan Boeger <nboeger at gmail.com>; r-help at r-project.org <r-help at r-project.org>
>> Sent: Tue, Feb 1, 2022 2:44 pm
>> Subject: Re: [External] [R] Funky calculations
>>
>>
>> RShowDoc('FAQ')
>>
>>
>> then search for 7.31
>>
>>
>> This statement
>> "If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone."
>> is not quite right.? The recommendation in IEEE 754, and this is how R does arithmetic, is to Round Even.
>>
>> I ilustrate here with decimal, even though R and other programs use binary.
>>
>>> x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
>>> r <- round(x)
>>> cbind(x, r)
>>? ? ? ? ?? x r
>> [1,] 1.4 1
>> [2,] 1.5 2
>> [3,] 1.6 2
>> [4,] 2.4 2
>> [5,] 2.5 2
>> [6,] 2.6 3
>> [7,] 3.4 3
>> [8,] 3.5 4
>> [9,] 3.6 4
>> [10,] 4.4 4
>> [11,] 4.5 4
>> [12,] 4.6 5
>>>
>>
>> Numbers whose last digit is not 5 (when in decimal) round to the nearest integer.
>> Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above)
>> round to the nearest EVEN integer.
>> Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
>> 2.5 and 4.5 round down do the even numbers 2 and 4.
>>
>> This way the round ups and downs average out to 0.? If we always went up from .5 we would have
>> an updrift over time.
>>
>> For even more detail click on the link in FAQ 7.31 to my appendix
>> https:// link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
>> and search for "Appendix G".
>>
>> Section G.5 explains Round to Even.
>> Sections G.6 onward illustrate specific examples, such as the one that started this email thread.
>>
>> Rich


From tebert @end|ng |rom u||@edu  Wed Feb  2 19:27:28 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 2 Feb 2022 18:27:28 +0000
Subject: [R] [External] Funky calculations
In-Reply-To: <f7f69f1b-e19c-42e3-863f-27681a8fb618@gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <1240726547.2663210.1643766132419@mail.yahoo.com>
 <1A13EFE0-C500-40D0-9BD0-8546E4EECBEA@temple.edu>
 <801628629.2676628.1643773508952@mail.yahoo.com>
 <f7f69f1b-e19c-42e3-863f-27681a8fb618@gmail.com>
Message-ID: <BN6PR2201MB155343686950421C0B16BDFCCF279@BN6PR2201MB1553.namprd22.prod.outlook.com>

Punch cards and reams of green and white striped fanfold. A portable Cromemco we called a boat anchor, and hardly used because the Apple II was more in line with our computing tasks/skills. The relevant part is learning assembly and machine language on the Apple. Trying to describe an infinite value in a finite space results in inaccuracy no matter how you work it. The problem applies to all programs in all languages. The problem, while present, does not always matter. One way to identify the limits of accuracy is something like this:
1 + 1 == 2   #  returns TRUE
1 + 0.9 == 2 # returns FALSE
1 + 0.9999999 == 2 should return FALSE
Keep going and at some point you will get TRUE.
In my version of R, here is the last time I get FALSE.
1+ 0.999999999999999 == 2    #15 digits after decimal place

I can do something similar in Excel. In printing Excel rounds up to 1 when 10 nines are present. The if test quits returning FALSE after 14 decimal places. =if(1 + 0.9999999 = 2, "TRUE","FALSE")

One can play the game another way. This matters because it is NOT the number of digits after the decimal point, it is the total number of digits.

Here is the last correct answer in this game:
999999999999999 == 1000000000000000
That is 15 digits, add another 9 on the left and a zero on the right and you get TRUE.

123456789 + 0.00000001 == 123456789
Here is the last FALSE, but note that I have only added a number with 8 decimal places.

There are many other ways to play this game:
log10(10.00000000000001)==1 # add a zero before the decimal point, how many can one have after?

In statistics it is well know that it is a bad idea to model data that spans many orders of magnitude. At least for me, this is the simplest presentation for why this is the case. For a more exact reason consider the above results when taking the inverse of a matrix with elements that differ by several orders of magnitude.

The issue is well known, and programs like R and SAS and SPSS, (etc...) take care of the issue, up to a point. However, it is not hard to break the system if you try or are not careful. The point at which the system breaks is easy to identify in simple terms. However, just because R's limit is 15 digits does not mean that all packages in R will also have that limit. Just keep in mind that your data range in R needs to be such that the operations on that data all fit within this 15 digit limitation. Other programs may have different limitations, but there is always a limitation.

Tim 



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of J C Nash
Sent: Wednesday, February 2, 2022 8:36 AM
To: r-help at r-project.org
Subject: Re: [R] [External] Funky calculations

[External Email]

I was one of the 31 names on the 1985 IEEE standard. If anyone thinks things are awkward now, try looking at the swamp we had beforehand.

What I believe IS useful is to provide examples and to explain them in tutorial fashion.
We need to recognize that our computations have limitations. Most common computing platforms use IEEE binary arithmetic, but not all.

This was much more "in our face" when we used slide rules or hand-crank calculators. I still have slide rules and a Monroe "Portable" calculator -- 5 kg! It's worth bringing them out every so often and being thankful for the power and speed of modern computing, while remembering to watch for the cowpads of REAL and REAL*8 arithmetic.

JN

On 2022-02-01 22:45, Avi Gross via R-help wrote:
> This is a discussion forum, Richard, and I welcome requests to clarify what I wrote or to be corrected, especially when my words have been read with an attempt to understand. I do get private responses too and some days i wonder if I am not communicating the way people like!
>
> But let me repeat. The question we started with asked about R. My answer applies to quite a few languages besides R and maybe just about all of them.
>
> I got private email insisting the numbers being added were not irrational so why would they not be represented easily as a sum. I know my answers included parts at various levels of abstraction as well as examples of cases when Decimals notation for a number like 1/7 results in an infinite repeating sequence. So, I think it wise to follow up with what binary looks like and why hardly ANYTHING that looks reasonable is hard to represent exactly.
>
> Consider that binary means POWERS OF TWO. The sequence 1101 before a decimal point means (starting from the right and heading left) that you have one ONES and no TWOS and one FOURS and one EIGHTS. Powers of two ranging from 2 to the zero power to two cubed. You can make any integer whatsoever using as long a sequence of zeros and ones as you like. Compare this to decimal notation where you use powers of ten and of course can use any of 0-9.
>
> But looking at fractional numbers, like 1/7 and 1/10, it gets hard and inexact.
>
> Remember now we are in BINARY. Here are some fractions with everything not shown to the right being zeros and thus not needed to be shown explicitly. Starting with the decimal point, read this from left to right to see the powers in the denominator rising so 1/2 then 1/4 then 1/8 ...:
>
> 0.0 would be 0.
> 0.1 would be 1/2
> 0.101 would be 1/2 + 1/8 or 5/8
> 0.11 would be 1/2 + 1/4 or 3/4
> 0.111 would be 1/2 + 1/4 + 1/8 or 7/8
>
> We are now using negative powers where 2 raised to the minus one power is one over two raised to the plus one power, or 1/2 and so on. As you head to the right you get to fairly small numbers like 1/2048 ...
>
> Every single binary fraction is thus a possibly infinite sum of negative powers of two, or rather the reciprocals of those in positive terms.
>
> If you want to make 1/7, to some number of decimal places, it looks like this up to some point where I stop:
>
> 0.00100100100100100101
>
> So no halves, no quarters, 1/8, no sixteenths, no thirty-seconds, 1/64, and so on. But if you add all that up, and note the sequence was STOPPED before it could continue further, you get this translated into decimal:
>
> 0.142857 55157470703125
>
> Recall 1/7 in decimal notation is
> 0.142857 142857142857142857...
>
> Note the divergence at the seventh digit after the decimal point. I left a space to show where they diverge. If I used more binary digits, I can get as close as I want but computers these days do not allow too many more digits unless you use highly specialized programs. There are packages that give you access such as "mpfr" but generally nothing can give you infinite precision. R will not handle an infinite number of infinitesimals.
>
> The original problem that began our thread was about numbers like 0.1 and 0.2 and so on. In base ten, they look nice but I repeat in base 2 only powers of TWO reign.
>
> 0.1 in base two is about 0.0001100110011001101
>
> that reads as 1/16 + 1/32 + 1/256 + 1/512 + ...
>
> If I convert the above segment, which I repeat was stopped short, I 
> get 0.1000003814697265625 which is a tad over and had I taken the last 
> 1 and changed it to a zero as in 0.0001100110011001100 then we would 
> have a bit under at 0.09999847412109375
>
> So the only way to write 0.1 exactly is to continue infinitely, again. Do the analysis and understand why most rational numbers will not easily convert to a small number of bits. But the advantages of computers doing operations in binary are huge and need not be explained. You may THINK you are entering numbers in decimal form but they rarely remain that way for long before they simply become binary and often remain binary unless and until you ask to print them out, usually in decimal.
>
> BTW, I used a random web site to do the above conversion calculations:
>
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.rapidtables.c
> om_convert_number_binary-2Dto-2Ddecimal.html&d=DwIDaQ&c=sJ6xIWYx-zLMB3
> EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=m7vgw0V3XLMYZ26IDQFrX6s6LeffgRVmWQ
> d4FGv5GUaI_W1jJ_i7QSJKQrB8fON4&s=_HQxpbll2YuLGvrwfc0AJPK4NAQ9xCcqvfl0c
> 1i-8Tg&e=
>
> Since I am writing in plain text, I cannot show what it says in the box on that page further down under Decimal Calculation Steps so I wonder what the rest of this message looks like:
>
> (0.0001100110011001100)? = (0 ? 2?) + (0 ? 2??) + (0 ? 2??) + (0 ? 
> 2??) + (1 ? 2??) + (1 ? 2??) + (0 ? 2??) + (0 ? 2??) + (1 ? 2??) + (1 
> ? 2??) + (0 ? 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 
> 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 2???) + (0 ? 2???) 
> = (0.09999847412109375)??
>
> I think my part in this particular discussion can now finally come to an end. R and everything else can be incomplete. Deal with it!
>
> -----Original Message-----
> From: Richard M. Heiberger <rmh at temple.edu>
> To: Avi Gross <avigross at verizon.net>
> Cc: nboeger at gmail.com <nboeger at gmail.com>; r-help at r-project.org 
> <r-help at r-project.org>
> Sent: Tue, Feb 1, 2022 9:04 pm
> Subject: Re: [External] [R] Funky calculations
>
>
> I apologize if my tone came across wrong.  I enjoy reading your comments on this list.
>
> My goal was to describe what the IEEE and R interpret "careful coding" to be.
>
>
>> On Feb 01, 2022, at 20:42, Avi Gross <avigross at verizon.net> wrote:
>>
>> Richard,
>>
>> I think it was fairly clear I was explaining how people do arithmetic manually and often truncate or round to some number of decimal places. I said nothing about what R does or what the IEEE standards say and I do not particularly care when making MY point.
>>
>> My point is that humans before computers also had trouble writing down any decimals that continue indefinitely. It cannot be expected computer versions of arithmetic can do much better. Different people can opt to do the calculation with the same or different numbers of digits ad when compared to each other they may not match.
>>
>> I do care what it does in my programs, of course. My goal here was to explain to someone that the anomaly found was not really an anomaly and that careful coding may be required in these situations.
>>
>>
>> -----Original Message-----
>> From: Richard M. Heiberger <rmh at temple.edu>
>> To: Avi Gross <avigross at verizon.net>
>> Cc: Nathan Boeger <nboeger at gmail.com>; r-help at r-project.org 
>> <r-help at r-project.org>
>> Sent: Tue, Feb 1, 2022 2:44 pm
>> Subject: Re: [External] [R] Funky calculations
>>
>>
>> RShowDoc('FAQ')
>>
>>
>> then search for 7.31
>>
>>
>> This statement
>> "If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone."
>> is not quite right.  The recommendation in IEEE 754, and this is how R does arithmetic, is to Round Even.
>>
>> I ilustrate here with decimal, even though R and other programs use binary.
>>
>>> x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6) r 
>>> <- round(x) cbind(x, r)
>>           x r
>> [1,] 1.4 1
>> [2,] 1.5 2
>> [3,] 1.6 2
>> [4,] 2.4 2
>> [5,] 2.5 2
>> [6,] 2.6 3
>> [7,] 3.4 3
>> [8,] 3.5 4
>> [9,] 3.6 4
>> [10,] 4.4 4
>> [11,] 4.5 4
>> [12,] 4.6 5
>>>
>>
>> Numbers whose last digit is not 5 (when in decimal) round to the nearest integer.
>> Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above) round to the 
>> nearest EVEN integer.
>> Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
>> 2.5 and 4.5 round down do the even numbers 2 and 4.
>>
>> This way the round ups and downs average out to 0.  If we always went 
>> up from .5 we would have an updrift over time.
>>
>> For even more detail click on the link in FAQ 7.31 to my appendix 
>> https:// 
>> link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
>> and search for "Appendix G".
>>
>> Section G.5 explains Round to Even.
>> Sections G.6 onward illustrate specific examples, such as the one that started this email thread.
>>
>> Rich
>>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> man_listinfo_r-2Dhelp&d=DwIDaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> Rzsn7AkP-g&m=m7vgw0V3XLMYZ26IDQFrX6s6LeffgRVmWQd4FGv5GUaI_W1jJ_i7QSJKQ
> rB8fON4&s=HX4jIGehR02lpSThBSeyCJjGktkizJEOcq7FpBq2mOY&e=
> PLEASE do read the posting guide 
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> g_posting-2Dguide.html&d=DwIDaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> sRzsn7AkP-g&m=m7vgw0V3XLMYZ26IDQFrX6s6LeffgRVmWQd4FGv5GUaI_W1jJ_i7QSJK
> QrB8fON4&s=GDNe-9c0Z0dm3zV0Nqlnil_EDvpqQgJybFt5DdfZ3v4&e=
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=m7vgw0V3XLMYZ26IDQFrX6s6LeffgRVmWQd4FGv5GUaI_W1jJ_i7QSJKQrB8fON4&s=HX4jIGehR02lpSThBSeyCJjGktkizJEOcq7FpBq2mOY&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=m7vgw0V3XLMYZ26IDQFrX6s6LeffgRVmWQd4FGv5GUaI_W1jJ_i7QSJKQrB8fON4&s=GDNe-9c0Z0dm3zV0Nqlnil_EDvpqQgJybFt5DdfZ3v4&e=
and provide commented, minimal, self-contained, reproducible code.

From @v|gro@@ @end|ng |rom ver|zon@net  Wed Feb  2 20:23:47 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 2 Feb 2022 19:23:47 +0000 (UTC)
Subject: [R] [External] Funky calculations
In-Reply-To: <BN6PR2201MB155343686950421C0B16BDFCCF279@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <1240726547.2663210.1643766132419@mail.yahoo.com>
 <1A13EFE0-C500-40D0-9BD0-8546E4EECBEA@temple.edu>
 <801628629.2676628.1643773508952@mail.yahoo.com>
 <f7f69f1b-e19c-42e3-863f-27681a8fb618@gmail.com>
 <BN6PR2201MB155343686950421C0B16BDFCCF279@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <88067166.2834644.1643829827893@mail.yahoo.com>

As discussed, Tim, your version of R has already built-in all kinds of values and limits and even ways to do approximate tests in the variable .Machine such as:

> .Machine$double.eps
[1] 2.220446e-16
> .Machine$sizeof.longdouble
[1] 16
> .Machine$double.eps
[1] 2.220446e-16
> .Machine$longdouble.eps
[1] 1.084202e-19

If you can figure out which ones correspond to what you are looking for, you can stay within bounds or set up your code to catch the rare cases when you are in a gray area where comparisons are not reliable and assume all other areas are valid for tests of equality or inequality.

Consider another common problem. You want to multiply two integers that are stored in integer variables of some capacity ranging from a byte to 4 or even more bytes. On many machines, if the multiplication needs even more digits than are available, the result is to return just the bits that fit and toss the others away. Your result is effectively nonsense. You may also throw an error and have to catch it.

But if your program runs portably on many machines, how can you be sure it worked properly if you multiply say a billion by a billion in an integer that only fits the following number on my machine at this time:

> .Machine$integer.max
[1] 2147483647

The above number is a bit more than 2 billion so clearly multiplying those two numbers will not fit. One solution, and not a great one, is to verify that each number being multiplied is less than the square root of the limit. Another is to do the multiplication and then divide the result by one of the multiplicands and verify the result is the same as the other multiplicand. If not, you had a problem, probably an overflow situation.

It should not be necessary to do this and in some ways it isn't. There are probably R packages supporting larger integers (and I don't mean by converting to floating point) and I know Python integers already are of any length and only limited by available memory.

But it is an example of how real computers using current methods are not mathematically whole and you can not demand they do what is mathematically possible and especially not in areas where things are truly meant to be continuous with no gaps or of infinite duration in various ways. The real world is not the ideal Platonic Realm.

Now I have to think about what may happen with quantum computers and algorithms using them. QBITS have a certain sense of infinity in them and can be a sort of superposition of many quantum states and thus may turn out to allow arbitrary precision, unless they hit some quantum wall.

But that is a topic for some futuristic R.



-----Original Message-----
From: Ebert,Timothy Aaron <tebert at ufl.edu>
To: J C Nash <profjcnash at gmail.com>; r-help at r-project.org <r-help at r-project.org>
Sent: Wed, Feb 2, 2022 1:27 pm
Subject: Re: [R] [External] Funky calculations


Punch cards and reams of green and white striped fanfold. A portable Cromemco we called a boat anchor, and hardly used because the Apple II was more in line with our computing tasks/skills. The relevant part is learning assembly and machine language on the Apple. Trying to describe an infinite value in a finite space results in inaccuracy no matter how you work it. The problem applies to all programs in all languages. The problem, while present, does not always matter. One way to identify the limits of accuracy is something like this:
1 + 1 == 2?  #? returns TRUE
1 + 0.9 == 2 # returns FALSE
1 + 0.9999999 == 2 should return FALSE
Keep going and at some point you will get TRUE.
In my version of R, here is the last time I get FALSE.
1+ 0.999999999999999 == 2? ? #15 digits after decimal place

I can do something similar in Excel. In printing Excel rounds up to 1 when 10 nines are present. The if test quits returning FALSE after 14 decimal places. =if(1 + 0.9999999 = 2, "TRUE","FALSE")

One can play the game another way. This matters because it is NOT the number of digits after the decimal point, it is the total number of digits.

Here is the last correct answer in this game:
999999999999999 == 1000000000000000
That is 15 digits, add another 9 on the left and a zero on the right and you get TRUE.

123456789 + 0.00000001 == 123456789
Here is the last FALSE, but note that I have only added a number with 8 decimal places.

There are many other ways to play this game:
log10(10.00000000000001)==1 # add a zero before the decimal point, how many can one have after?

In statistics it is well know that it is a bad idea to model data that spans many orders of magnitude. At least for me, this is the simplest presentation for why this is the case. For a more exact reason consider the above results when taking the inverse of a matrix with elements that differ by several orders of magnitude.

The issue is well known, and programs like R and SAS and SPSS, (etc...) take care of the issue, up to a point. However, it is not hard to break the system if you try or are not careful. The point at which the system breaks is easy to identify in simple terms. However, just because R's limit is 15 digits does not mean that all packages in R will also have that limit. Just keep in mind that your data range in R needs to be such that the operations on that data all fit within this 15 digit limitation. Other programs may have different limitations, but there is always a limitation.

Tim 



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of J C Nash
Sent: Wednesday, February 2, 2022 8:36 AM
To: r-help at r-project.org
Subject: Re: [R] [External] Funky calculations

[External Email]

I was one of the 31 names on the 1985 IEEE standard. If anyone thinks things are awkward now, try looking at the swamp we had beforehand.

What I believe IS useful is to provide examples and to explain them in tutorial fashion.
We need to recognize that our computations have limitations. Most common computing platforms use IEEE binary arithmetic, but not all.

This was much more "in our face" when we used slide rules or hand-crank calculators. I still have slide rules and a Monroe "Portable" calculator -- 5 kg! It's worth bringing them out every so often and being thankful for the power and speed of modern computing, while remembering to watch for the cowpads of REAL and REAL*8 arithmetic.

JN

On 2022-02-01 22:45, Avi Gross via R-help wrote:
> This is a discussion forum, Richard, and I welcome requests to clarify what I wrote or to be corrected, especially when my words have been read with an attempt to understand. I do get private responses too and some days i wonder if I am not communicating the way people like!
>
> But let me repeat. The question we started with asked about R. My answer applies to quite a few languages besides R and maybe just about all of them.
>
> I got private email insisting the numbers being added were not irrational so why would they not be represented easily as a sum. I know my answers included parts at various levels of abstraction as well as examples of cases when Decimals notation for a number like 1/7 results in an infinite repeating sequence. So, I think it wise to follow up with what binary looks like and why hardly ANYTHING that looks reasonable is hard to represent exactly.
>
> Consider that binary means POWERS OF TWO. The sequence 1101 before a decimal point means (starting from the right and heading left) that you have one ONES and no TWOS and one FOURS and one EIGHTS. Powers of two ranging from 2 to the zero power to two cubed. You can make any integer whatsoever using as long a sequence of zeros and ones as you like. Compare this to decimal notation where you use powers of ten and of course can use any of 0-9.
>
> But looking at fractional numbers, like 1/7 and 1/10, it gets hard and inexact.
>
> Remember now we are in BINARY. Here are some fractions with everything not shown to the right being zeros and thus not needed to be shown explicitly. Starting with the decimal point, read this from left to right to see the powers in the denominator rising so 1/2 then 1/4 then 1/8 ...:
>
> 0.0 would be 0.
> 0.1 would be 1/2
> 0.101 would be 1/2 + 1/8 or 5/8
> 0.11 would be 1/2 + 1/4 or 3/4
> 0.111 would be 1/2 + 1/4 + 1/8 or 7/8
>
> We are now using negative powers where 2 raised to the minus one power is one over two raised to the plus one power, or 1/2 and so on. As you head to the right you get to fairly small numbers like 1/2048 ...
>
> Every single binary fraction is thus a possibly infinite sum of negative powers of two, or rather the reciprocals of those in positive terms.
>
> If you want to make 1/7, to some number of decimal places, it looks like this up to some point where I stop:
>
> 0.00100100100100100101
>
> So no halves, no quarters, 1/8, no sixteenths, no thirty-seconds, 1/64, and so on. But if you add all that up, and note the sequence was STOPPED before it could continue further, you get this translated into decimal:
>
> 0.142857 55157470703125
>
> Recall 1/7 in decimal notation is
> 0.142857 142857142857142857...
>
> Note the divergence at the seventh digit after the decimal point. I left a space to show where they diverge. If I used more binary digits, I can get as close as I want but computers these days do not allow too many more digits unless you use highly specialized programs. There are packages that give you access such as "mpfr" but generally nothing can give you infinite precision. R will not handle an infinite number of infinitesimals.
>
> The original problem that began our thread was about numbers like 0.1 and 0.2 and so on. In base ten, they look nice but I repeat in base 2 only powers of TWO reign.
>
> 0.1 in base two is about 0.0001100110011001101
>
> that reads as 1/16 + 1/32 + 1/256 + 1/512 + ...
>
> If I convert the above segment, which I repeat was stopped short, I 
> get 0.1000003814697265625 which is a tad over and had I taken the last 
> 1 and changed it to a zero as in 0.0001100110011001100 then we would 
> have a bit under at 0.09999847412109375
>
> So the only way to write 0.1 exactly is to continue infinitely, again. Do the analysis and understand why most rational numbers will not easily convert to a small number of bits. But the advantages of computers doing operations in binary are huge and need not be explained. You may THINK you are entering numbers in decimal form but they rarely remain that way for long before they simply become binary and often remain binary unless and until you ask to print them out, usually in decimal.
>
> BTW, I used a random web site to do the above conversion calculations:
>
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.rapidtables.c
> om_convert_number_binary-2Dto-2Ddecimal.html&d=DwIDaQ&c=sJ6xIWYx-zLMB3
> EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=m7vgw0V3XLMYZ26IDQFrX6s6LeffgRVmWQ
> d4FGv5GUaI_W1jJ_i7QSJKQrB8fON4&s=_HQxpbll2YuLGvrwfc0AJPK4NAQ9xCcqvfl0c
> 1i-8Tg&e=
>
> Since I am writing in plain text, I cannot show what it says in the box on that page further down under Decimal Calculation Steps so I wonder what the rest of this message looks like:
>
> (0.0001100110011001100)? = (0 ? 2?) + (0 ? 2??) + (0 ? 2??) + (0 ? 
> 2??) + (1 ? 2??) + (1 ? 2??) + (0 ? 2??) + (0 ? 2??) + (1 ? 2??) + (1 
> ? 2??) + (0 ? 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 
> 2???) + (0 ? 2???) + (1 ? 2???) + (1 ? 2???) + (0 ? 2???) + (0 ? 2???) 
> = (0.09999847412109375)??
>
> I think my part in this particular discussion can now finally come to an end. R and everything else can be incomplete. Deal with it!
>
> -----Original Message-----
> From: Richard M. Heiberger <rmh at temple.edu>
> To: Avi Gross <avigross at verizon.net>
> Cc: nboeger at gmail.com <nboeger at gmail.com>; r-help at r-project.org 
> <r-help at r-project.org>
> Sent: Tue, Feb 1, 2022 9:04 pm
> Subject: Re: [External] [R] Funky calculations
>
>
> I apologize if my tone came across wrong.? I enjoy reading your comments on this list.
>
> My goal was to describe what the IEEE and R interpret "careful coding" to be.
>
>
>> On Feb 01, 2022, at 20:42, Avi Gross <avigross at verizon.net> wrote:
>>
>> Richard,
>>
>> I think it was fairly clear I was explaining how people do arithmetic manually and often truncate or round to some number of decimal places. I said nothing about what R does or what the IEEE standards say and I do not particularly care when making MY point.
>>
>> My point is that humans before computers also had trouble writing down any decimals that continue indefinitely. It cannot be expected computer versions of arithmetic can do much better. Different people can opt to do the calculation with the same or different numbers of digits ad when compared to each other they may not match.
>>
>> I do care what it does in my programs, of course. My goal here was to explain to someone that the anomaly found was not really an anomaly and that careful coding may be required in these situations.
>>
>>
>> -----Original Message-----
>> From: Richard M. Heiberger <rmh at temple.edu>
>> To: Avi Gross <avigross at verizon.net>
>> Cc: Nathan Boeger <nboeger at gmail.com>; r-help at r-project.org 
>> <r-help at r-project.org>
>> Sent: Tue, Feb 1, 2022 2:44 pm
>> Subject: Re: [External] [R] Funky calculations
>>
>>
>> RShowDoc('FAQ')
>>
>>
>> then search for 7.31
>>
>>
>> This statement
>> "If you stop at a 5 or 7 or 8 and back up to the previous digit, you round up. Else you leave the previous result alone."
>> is not quite right.? The recommendation in IEEE 754, and this is how R does arithmetic, is to Round Even.
>>
>> I ilustrate here with decimal, even though R and other programs use binary.
>>
>>> x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6) r 
>>> <- round(x) cbind(x, r)
>>? ? ? ? ?  x r
>> [1,] 1.4 1
>> [2,] 1.5 2
>> [3,] 1.6 2
>> [4,] 2.4 2
>> [5,] 2.5 2
>> [6,] 2.6 3
>> [7,] 3.4 3
>> [8,] 3.5 4
>> [9,] 3.6 4
>> [10,] 4.4 4
>> [11,] 4.5 4
>> [12,] 4.6 5
>>>
>>
>> Numbers whose last digit is not 5 (when in decimal) round to the nearest integer.
>> Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above) round to the 
>> nearest EVEN integer.
>> Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
>> 2.5 and 4.5 round down do the even numbers 2 and 4.
>>
>> This way the round ups and downs average out to 0.? If we always went 
>> up from .5 we would have an updrift over time.
>>
>> For even more detail click on the link in FAQ 7.31 to my appendix 
>> https:// 
>> link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
>> and search for "Appendix G".
>>
>> Section G.5 explains Round to Even.
>> Sections G.6 onward illustrate specific examples, such as the one that started this email thread.
>>
>> Rich
>>
>
>
>


From nboeger @end|ng |rom gm@||@com  Thu Feb  3 03:14:01 2022
From: nboeger @end|ng |rom gm@||@com (Nathan Boeger)
Date: Thu, 3 Feb 2022 09:14:01 +0700
Subject: [R] [External] Funky calculations
In-Reply-To: <CAHqSRuTcqLizbAFy2jRBKoqFTNuV6mi08au6ox2iwbLgWew1QA@mail.gmail.com>
References: <CAFxA6QotuTYyJ8Jz_9SeeGZNR_LRxCXHKXYO+o3JihnQdnQL+g@mail.gmail.com>
 <20220201193557.308209e8@Tarkus>
 <D24231AD-5CBF-4595-962E-2009821BD20B@temple.edu>
 <CAFxA6Qq1sGwh9ZwEaV6zvtfd0yq6A1W6U4oDMuy1KXs_CV9ryQ@mail.gmail.com>
 <CAHqSRuT7KsOnUEKQRz2+Y_Z0ZoE+y3LHm4q9JLzqsSATe-85iA@mail.gmail.com>
 <CAFxA6Qr93D4VYjrZDvvrQgnTnToNQj3RQ21pLYrm8tJFHpA=1Q@mail.gmail.com>
 <CAHqSRuTcqLizbAFy2jRBKoqFTNuV6mi08au6ox2iwbLgWew1QA@mail.gmail.com>
Message-ID: <CAFxA6Qo+Mq0H2Hhdb9K5FKgc_sq9fr1TbZHydN9Pw43DChCrfg@mail.gmail.com>

You have a typo:

   printf("0.4+0.4+0.4+0.4 == 1.6 -> %s\n", d == 1.0 ? "true" : "false");

should be:

   printf("0.4+0.4+0.4+0.4 == 1.6 -> %s\n", d == 1.6 ? "true" : "false");

The comparison was with 1.0 but should be 1.6. I ran it and it has the same
output as you show above. Very interesting.

-nb

On Wed, 2 Feb 2022 at 21:24, Bill Dunlap <williamwdunlap at gmail.com> wrote:

> Floats have 23 bits of precision so the rounding is done there instead of
> at 52 bits, hence a different example is needed to show the problem with
> floats.
>
> bill at Bill-T490:~$ cat b.c
> #include <stdio.h>
>
> int main(int argc, char* argv[])
> {
>     float d = 0.4 + 0.4 + 0.4 + 0.4;
>     printf("0.4+0.4+0.4+0.4 -> %24.17g\n", (double)d);
>     printf("0.4+0.4+0.4+0.4 == 1.6 -> %s\n", d == 1.0 ? "true" : "false");
>     return 0;
> }
> bill at Bill-T490:~$ gcc b.c
> bill at Bill-T490:~$ ./a.out
> 0.4+0.4+0.4+0.4 ->       1.6000000238418579
> 0.4+0.4+0.4+0.4 == 1.6 -> false
>
> There is no getting around the fact that rounding will happen.
>
> -Bill
>
> On Tue, Feb 1, 2022 at 9:06 PM Nathan Boeger <nboeger at gmail.com> wrote:
>
>>
>> I understand this and with C the data type used is important. For this
>> type of calculation, I would normally use a float (basic single precision
>> is all I require).
>>
>> #include <stdio.h>
>>
>> void main() {
>>   float foo = (0.4 + 0.2 + 0.30 + 0.1) ;
>>   printf("foo: %f , foo > 1: %s \n", foo, (foo > 1.0 ? "true" : "false"));
>>   double bar = (0.4 + 0.2 + 0.30 + 0.1) ;
>>   printf("bar: %lf , bar > 1: %s \n", bar, (bar > 1.0 ? "true" :
>> "false"));
>> }
>>
>> gcc  c-check.c -o c-check
>> ./c-check
>> foo: 1.000000 , foo > 1: false
>> bar: 1.000000 , bar > 1: true
>>
>> Again, it was my mistake for not reading the R-FAQ. I had no idea it
>> would spark such a long thread.
>>
>> Cheers
>>
>> -nb
>>
>> On Wed, 2 Feb 2022 at 10:30, Bill Dunlap <williamwdunlap at gmail.com>
>> wrote:
>>
>>> The base 2 representation of 0.4 repeats the digit sequence 1001
>>> infinitely, hence must be rounded.  The problem occurs in C the same as it
>>> does in R.
>>>
>>> bill at Bill-T490:~$ cat a.c
>>> #include <stdio.h>
>>>
>>> int main(int argc, char* argv[])
>>> {
>>>     double d = 0.4 + 0.3 + 0.2 + 0.1;
>>>     printf("0.4+0.3+0.2+0.1 -> %24.17g\n", d);
>>>     printf("0.4+0.3+0.2+0.1 == 1.0 -> %s\n", d == 1.0 ? "true" :
>>> "false");
>>>     return 0;
>>> }
>>> bill at Bill-T490:~$ gcc a.c
>>> bill at Bill-T490:~$ ./a.out
>>> 0.4+0.3+0.2+0.1 ->      0.99999999999999989
>>> 0.4+0.3+0.2+0.1 == 1.0 -> false
>>>
>>> -Bill
>>>
>>> On Tue, Feb 1, 2022 at 7:01 PM Nathan Boeger <nboeger at gmail.com> wrote:
>>>
>>>> Thank you for this explanation!
>>>>
>>>> I have a long background in C/C++ and never realized this was such an
>>>> issue
>>>> with some languages. At least, with trivial single digit decimals. I
>>>> understand accuracy issues with very large decimals, repeating or
>>>> non-terminating rationals and I have handled them in the past. It makes
>>>> me
>>>> worried about all the R scripts I have written before (yikes!).
>>>>
>>>> Cheers
>>>>
>>>> -nb
>>>>
>>>> On Wed, 2 Feb 2022 at 02:44, Richard M. Heiberger <rmh at temple.edu>
>>>> wrote:
>>>>
>>>> > RShowDoc('FAQ')
>>>> >
>>>> > then search for 7.31
>>>> >
>>>> >
>>>> > This statement
>>>> > "If you stop at a 5 or 7 or 8 and back up to the previous digit, you
>>>> round
>>>> > up. Else you leave the previous result alone."
>>>> > is not quite right.  The recommendation in IEEE 754, and this is how R
>>>> > does arithmetic, is to Round Even.
>>>> >
>>>> > I ilustrate here with decimal, even though R and other programs use
>>>> binary.
>>>> >
>>>> > > x <- c(1.4, 1.5, 1.6, 2.4, 2.5, 2.6, 3.4, 3.5, 3.6, 4.4, 4.5, 4.6)
>>>> > > r <- round(x)
>>>> > > cbind(x, r)
>>>> >         x r
>>>> >  [1,] 1.4 1
>>>> >  [2,] 1.5 2
>>>> >  [3,] 1.6 2
>>>> >  [4,] 2.4 2
>>>> >  [5,] 2.5 2
>>>> >  [6,] 2.6 3
>>>> >  [7,] 3.4 3
>>>> >  [8,] 3.5 4
>>>> >  [9,] 3.6 4
>>>> > [10,] 4.4 4
>>>> > [11,] 4.5 4
>>>> > [12,] 4.6 5
>>>> > >
>>>> >
>>>> > Numbers whose last digit is not 5 (when in decimal) round to the
>>>> nearest
>>>> > integer.
>>>> > Numbers who last digit is 5 (1.5, 2.5, 3.5, 4.5 above)
>>>> > round to the nearest EVEN integer.
>>>> > Hence 1.5 and 3.5 round up to the even numbers 2 and 4.
>>>> > 2.5 and 4.5 round down do the even numbers 2 and 4.
>>>> >
>>>> > This way the round ups and downs average out to 0.  If we always went
>>>> up
>>>> > from .5 we would have
>>>> > an updrift over time.
>>>> >
>>>> > For even more detail click on the link in FAQ 7.31 to my appendix
>>>> > https://
>>>> link.springer.com/content/pdf/bbm%3A978-1-4939-2122-5%2F1.pdf
>>>> > and search for "Appendix G".
>>>> >
>>>> > Section G.5 explains Round to Even.
>>>> > Sections G.6 onward illustrate specific examples, such as the one that
>>>> > started this email thread.
>>>> >
>>>> > Rich
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From d@nny @end|ng |rom |dem@@|ntern@t|on@|  Wed Feb  2 17:10:41 2022
From: d@nny @end|ng |rom |dem@@|ntern@t|on@| (Danny Parsons)
Date: Wed, 2 Feb 2022 16:10:41 +0000
Subject: [R] [R-pkgs] Package "naflex": Flexible Options for Handling
 Missing Values
Message-ID: <CABxkZL5b3Vfa=Q44iAgwQ0T6gK8BNU8W_3o_vzyb=azx=+t46g@mail.gmail.com>

Dear all,

I have recently released a new package "naflex" on CRAN:
https://cran.r-project.org/web/packages/naflex/index.html.

"naflex" provides helper functions that give additional flexibility for
handling missing values in summary functions (beyond the current extremes
of na.rm = TRUE/FALSE).

For example, allow up to 20% of values to be missing:

library(naflex)
library(magrittr)
x <- c(1, 3, NA, 4, 3, 2, NA, 5, 8, 7)
mean(x %>% na_omit_if(prop = 0.2))
# 4.125
mean(x %>% na_omit_if(prop = 0.1))
# NA

Please see the package details or vignette for the full set of checks
available.

I hope this may be of use to some as a convenient way to work with various
missing value rules.

Feedback, suggestions and bug reports are welcome at
https://github.com/dannyparsons/naflex or by email
(danny at idems.international)

Best regards,

Danny Parsons

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From d@rgo@ch @end|ng |rom gm@||@com  Thu Feb  3 11:06:04 2022
From: d@rgo@ch @end|ng |rom gm@||@com (Fredrik Karlsson)
Date: Thu, 3 Feb 2022 11:06:04 +0100
Subject: [R] exp / log scaled version of cut?
Message-ID: <CANO=ohJ_79HSXzBZDR+=B+8PmbcW8YXDmnE1ahKddTF=6i_++Q@mail.gmail.com>

Dear list,

For tasks involving people its often good to work with ages in exp or log
scale, since either not much or very much happens in the first 10 years of
life, and much less (or much more) happens the following years. For tables
with age range summary statistics, I sometimes would like to have a
function that would for instance cut a range of values into breaks exp()
scale equidistance bins, but with unconverted values in the labels.

Similar to the way log / exp scaling of figure axis tick marks work, but
with a factor returned.

i have not been able to find such a function. Is there one?

Thanks!

Fredrik Karlsson


-- 
"Life is like a trumpet - if you don't put anything into it, you don't get
anything out of it."

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Thu Feb  3 13:41:35 2022
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Thu, 3 Feb 2022 13:41:35 +0100
Subject: [R] exp / log scaled version of cut?
In-Reply-To: <CANO=ohJ_79HSXzBZDR+=B+8PmbcW8YXDmnE1ahKddTF=6i_++Q@mail.gmail.com>
References: <CANO=ohJ_79HSXzBZDR+=B+8PmbcW8YXDmnE1ahKddTF=6i_++Q@mail.gmail.com>
Message-ID: <c8773396-b593-c801-4949-67d32b7ccaef@statistik.tu-dortmund.de>



On 03.02.2022 11:06, Fredrik Karlsson wrote:
> Dear list,
> 
> For tasks involving people its often good to work with ages in exp or log
> scale, since either not much or very much happens in the first 10 years of
> life, and much less (or much more) happens the following years. For tables
> with age range summary statistics, I sometimes would like to have a
> function that would for instance cut a range of values into breaks exp()
> scale equidistance bins, but with unconverted values in the labels.
> 
> Similar to the way log / exp scaling of figure axis tick marks work, but
> with a factor returned.
> 
> i have not been able to find such a function. Is there one?
> 
> Thanks!
> 
> Fredrik Karlsson
> 
> 


Yes, cut():

x <- runif(100, 0, 100)
cut(x, c(0, 10, 100))

Best,
Uwe Ligges


From tebert @end|ng |rom u||@edu  Thu Feb  3 16:22:32 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 3 Feb 2022 15:22:32 +0000
Subject: [R] exp / log scaled version of cut?
In-Reply-To: <c8773396-b593-c801-4949-67d32b7ccaef@statistik.tu-dortmund.de>
References: <CANO=ohJ_79HSXzBZDR+=B+8PmbcW8YXDmnE1ahKddTF=6i_++Q@mail.gmail.com>
 <c8773396-b593-c801-4949-67d32b7ccaef@statistik.tu-dortmund.de>
Message-ID: <BN6PR2201MB15532150D3FABC1DADD7A94FCF289@BN6PR2201MB1553.namprd22.prod.outlook.com>

In plotting with ggplot the graphing function geom_histogram() can do this for you. https://www.tutorialgateway.org/r-ggplot2-histogram/#:~:text=The%20syntax%20to%20draw%20a%20ggplot%20Histogram%20in,%3D%20FALSE%2C%20show.legend%20%3D%20NA%2C%20inherit.aes%20%3D%20TRUE%29

Binning the raw data could be done using case_when() see https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/case_when

With case_when() you could create a new variable so that you have the original data to refer back to. You might be able to overlay a plot of the axes in the raw data and the graph in binned data. I am not sure that would make much sense, and might be a way to trick readers into making bad conclusions: plotting binned data onto a continuous axis. Might work better to plot the binned data and then change labels using commands like 
xlab(), ylab(), theme(axis_title.x=element_blank()), axis_title.x=element_text(), labs(x="my x", y="my y")

http://www.sthda.com/english/wiki/ggplot2-axis-ticks-a-guide-to-customize-tick-marks-and-labels
https://www.datanovia.com/en/blog/ggplot-axis-labels/

Depending on exactly what you want to do here.

Regards,
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Uwe Ligges
Sent: Thursday, February 3, 2022 7:42 AM
To: Fredrik Karlsson <dargosch at gmail.com>; R-help <r-help at r-project.org>
Subject: Re: [R] exp / log scaled version of cut?

[External Email]

On 03.02.2022 11:06, Fredrik Karlsson wrote:
> Dear list,
>
> For tasks involving people its often good to work with ages in exp or 
> log scale, since either not much or very much happens in the first 10 
> years of life, and much less (or much more) happens the following 
> years. For tables with age range summary statistics, I sometimes would 
> like to have a function that would for instance cut a range of values 
> into breaks exp() scale equidistance bins, but with unconverted values in the labels.
>
> Similar to the way log / exp scaling of figure axis tick marks work, 
> but with a factor returned.
>
> i have not been able to find such a function. Is there one?
>
> Thanks!
>
> Fredrik Karlsson
>
>


Yes, cut():

x <- runif(100, 0, 100)
cut(x, c(0, 10, 100))

Best,
Uwe Ligges

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=E5bX46POI6aWCVW2Sn1gYLSC19ff-eoqeKiPmpipinQEE2CU38mPX2ReGsGWTfwG&s=MsUQlOyfUie2u5p7BJAJzW-BHNtXOlFZMiq-hPxTRVQ&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=E5bX46POI6aWCVW2Sn1gYLSC19ff-eoqeKiPmpipinQEE2CU38mPX2ReGsGWTfwG&s=q8534zhXd2FeFS4Z_Dth5YadYUs4P_9ZXjxdohleFB0&e=
and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Feb  3 16:52:12 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 3 Feb 2022 15:52:12 +0000
Subject: [R] generate distribution based on summary data and add random noise
Message-ID: <9e7449825b9844678143a79a7b61fe04@SRVEXCHCM1301.precheza.cz>

Hallo all

I have summary data with size bins and percentage below that size.

dat <- structure(list(size = c(10L, 20L, 30L, 40L, 50L, 60L, 70L, 80L,
90L, 100L, 110L, 120L, 130L, 140L, 150L, 160L, 170L, 180L, 190L,
200L, 250L, 300L, 400L, 500L), percent = c(0L, 0L, 0L, 1L, 1L,
2L, 4L, 8L, 13L, 18L, 24L, 31L, 38L, 44L, 50L, 57L, 65L, 72L,
76L, 83L, 95L, 98L, 100L, 100L)), class = "data.frame", row.names = c(NA,
-24L))

#I want to generate original distribution (I know it is better not to do it but I have no other choice) so I calculated #mids of those bins

xd <-dat$size-c(5,diff(dat$size)/2)
xd<- xd[-1]

#I can sample the size bins with probability given by percent.
Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)
plot(ecdf(Result))

#and I can add some noise to it, which is satisfactory with lower size bins but not enough for higher size bins.

Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)+rnorm(1000, mean=0, sd=5)
plot(ecdf(Result))
I can increase sd to satisfy bigger bin size but in that case noise is too big for lower bin size.

I would like to add smaller random noise to lower size bins and bigger random noise to higher size bins, which seems to be easy task but I am stuck how to do it. It should be somehow proportional to size value.
The only way forward I see is to sort generated result and to use something like

+ rnorm(1000, mean=xd, sd=xd/10)
But it is not correct.

I'd appreciate any hint how to add random noise to values in ordered manner.

Best regards.
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb  3 17:09:43 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 3 Feb 2022 08:09:43 -0800
Subject: [R] generate distribution based on summary data and add random
 noise
In-Reply-To: <9e7449825b9844678143a79a7b61fe04@SRVEXCHCM1301.precheza.cz>
References: <9e7449825b9844678143a79a7b61fe04@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAGxFJbT55JBCC9DCRC2xo8t7gUq8u9K6u1v8LOhJU2D_UrRnEA@mail.gmail.com>

If I understand correctly:
To generate a sample of total size N, generate a uniform sample of size p*N
for a bin with proportion p?
?runif

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 3, 2022 at 7:52 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hallo all
>
> I have summary data with size bins and percentage below that size.
>
> dat <- structure(list(size = c(10L, 20L, 30L, 40L, 50L, 60L, 70L, 80L,
> 90L, 100L, 110L, 120L, 130L, 140L, 150L, 160L, 170L, 180L, 190L,
> 200L, 250L, 300L, 400L, 500L), percent = c(0L, 0L, 0L, 1L, 1L,
> 2L, 4L, 8L, 13L, 18L, 24L, 31L, 38L, 44L, 50L, 57L, 65L, 72L,
> 76L, 83L, 95L, 98L, 100L, 100L)), class = "data.frame", row.names = c(NA,
> -24L))
>
> #I want to generate original distribution (I know it is better not to do
> it but I have no other choice) so I calculated #mids of those bins
>
> xd <-dat$size-c(5,diff(dat$size)/2)
> xd<- xd[-1]
>
> #I can sample the size bins with probability given by percent.
> Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)
> plot(ecdf(Result))
>
> #and I can add some noise to it, which is satisfactory with lower size
> bins but not enough for higher size bins.
>
> Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)+rnorm(1000,
> mean=0, sd=5)
> plot(ecdf(Result))
> I can increase sd to satisfy bigger bin size but in that case noise is too
> big for lower bin size.
>
> I would like to add smaller random noise to lower size bins and bigger
> random noise to higher size bins, which seems to be easy task but I am
> stuck how to do it. It should be somehow proportional to size value.
> The only way forward I see is to sort generated result and to use
> something like
>
> + rnorm(1000, mean=xd, sd=xd/10)
> But it is not correct.
>
> I'd appreciate any hint how to add random noise to values in ordered
> manner.
>
> Best regards.
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Feb  3 17:44:51 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 3 Feb 2022 16:44:51 +0000
Subject: [R] generate distribution based on summary data and add random
 noise
In-Reply-To: <CAGxFJbT55JBCC9DCRC2xo8t7gUq8u9K6u1v8LOhJU2D_UrRnEA@mail.gmail.com>
References: <9e7449825b9844678143a79a7b61fe04@SRVEXCHCM1301.precheza.cz>
 <CAGxFJbT55JBCC9DCRC2xo8t7gUq8u9K6u1v8LOhJU2D_UrRnEA@mail.gmail.com>
Message-ID: <0299ea9503e64c03b9fe606a9c12ea11@SRVEXCHCM1301.precheza.cz>

Hallo Bert

probably not, sorry. Did you try my examples?

To make it maybe simpler
1. sample a vector with given proportion and generate new data
2. add random noise to each generated value with sd given by value of a vector.

let say

x <- c(10, 100)
y <- c(.6, .4)
set.seed(200)
z <- sample(x, 10, rep=TRUE, prob=y)
ind <- order(z)
bins <- rle(z[ind])
bin1 <- rnorm(bins$lengths[1], mean = 0, sd=bins$values[1]/5)
bin2 <- rnorm(bins$lengths[2], mean = 0, sd=bins$values[2]/5)
z[ind] + c(bin1, bin2)

Sorry that I did not explain myself more clearly, I hoped that example showed what I have on mind.

Basically it is particle size cumulative distribution but size is expressed as size bins. Normally I have exact size measurement for each particle.

S pozdravem | Best Regards
RNDr. Petr PIKAL
Vedouc? V?zkumu a v?voje | Research Manager
PRECHEZA a.s.
n?b?. Dr. Edvarda Bene?e 1170/24 | 750 02 P?erov | Czech Republic
Tel: +420 581 252 256 | GSM: +420 724 008 364
mailto:petr.pikal at precheza.cz | https://www.precheza.cz/

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

From: Bert Gunter <bgunter.4567 at gmail.com> 
Sent: Thursday, February 3, 2022 5:10 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] generate distribution based on summary data and add random noise

If I understand correctly:
To generate a sample of total size N, generate a uniform sample of size p*N for a bin with proportion p?
?runif


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 3, 2022 at 7:52 AM PIKAL Petr <mailto:petr.pikal at precheza.cz> wrote:
Hallo all

I have summary data with size bins and percentage below that size.

dat <- structure(list(size = c(10L, 20L, 30L, 40L, 50L, 60L, 70L, 80L,
90L, 100L, 110L, 120L, 130L, 140L, 150L, 160L, 170L, 180L, 190L,
200L, 250L, 300L, 400L, 500L), percent = c(0L, 0L, 0L, 1L, 1L,
2L, 4L, 8L, 13L, 18L, 24L, 31L, 38L, 44L, 50L, 57L, 65L, 72L,
76L, 83L, 95L, 98L, 100L, 100L)), class = "data.frame", row.names = c(NA,
-24L))

#I want to generate original distribution (I know it is better not to do it but I have no other choice) so I calculated #mids of those bins

xd <-dat$size-c(5,diff(dat$size)/2)
xd<- xd[-1]

#I can sample the size bins with probability given by percent.
Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)
plot(ecdf(Result))

#and I can add some noise to it, which is satisfactory with lower size bins but not enough for higher size bins.

Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)+rnorm(1000, mean=0, sd=5)
plot(ecdf(Result))
I can increase sd to satisfy bigger bin size but in that case noise is too big for lower bin size.

I would like to add smaller random noise to lower size bins and bigger random noise to higher size bins, which seems to be easy task but I am stuck how to do it. It should be somehow proportional to size value.
The only way forward I see is to sort generated result and to use something like

+ rnorm(1000, mean=xd, sd=xd/10)
But it is not correct.

I'd appreciate any hint how to add random noise to values in ordered manner.

Best regards.
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb  3 18:34:39 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 3 Feb 2022 09:34:39 -0800
Subject: [R] generate distribution based on summary data and add random
 noise
In-Reply-To: <0299ea9503e64c03b9fe606a9c12ea11@SRVEXCHCM1301.precheza.cz>
References: <9e7449825b9844678143a79a7b61fe04@SRVEXCHCM1301.precheza.cz>
 <CAGxFJbT55JBCC9DCRC2xo8t7gUq8u9K6u1v8LOhJU2D_UrRnEA@mail.gmail.com>
 <0299ea9503e64c03b9fe606a9c12ea11@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAGxFJbQ7WcTt_fMFwRRez2TV+JNov92Hak1Y1Mnc7TUb+Bw+2A@mail.gmail.com>

Nope. I think I provided what you asked for, random data in each bin with
the amount of data proportional to bin percentage and the distribution of
that data uniform (nor normal) within the bin. So maybe someone else can
give you what you want if this ain't it.

Cheers,
Bert

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 3, 2022 at 8:44 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hallo Bert
>
> probably not, sorry. Did you try my examples?
>
> To make it maybe simpler
> 1. sample a vector with given proportion and generate new data
> 2. add random noise to each generated value with sd given by value of a
> vector.
>
> let say
>
> x <- c(10, 100)
> y <- c(.6, .4)
> set.seed(200)
> z <- sample(x, 10, rep=TRUE, prob=y)
> ind <- order(z)
> bins <- rle(z[ind])
> bin1 <- rnorm(bins$lengths[1], mean = 0, sd=bins$values[1]/5)
> bin2 <- rnorm(bins$lengths[2], mean = 0, sd=bins$values[2]/5)
> z[ind] + c(bin1, bin2)
>
> Sorry that I did not explain myself more clearly, I hoped that example
> showed what I have on mind.
>
> Basically it is particle size cumulative distribution but size is
> expressed as size bins. Normally I have exact size measurement for each
> particle.
>
> S pozdravem | Best Regards
> RNDr. Petr PIKAL
> Vedouc? V?zkumu a v?voje | Research Manager
> PRECHEZA a.s.
> n?b?. Dr. Edvarda Bene?e 1170/24 | 750 02 P?erov | Czech Republic
> Tel: +420 581 252 256 | GSM: +420 724 008 364
> mailto:petr.pikal at precheza.cz | https://www.precheza.cz/
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Thursday, February 3, 2022 5:10 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] generate distribution based on summary data and add
> random noise
>
> If I understand correctly:
> To generate a sample of total size N, generate a uniform sample of size
> p*N for a bin with proportion p?
> ?runif
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Feb 3, 2022 at 7:52 AM PIKAL Petr <mailto:petr.pikal at precheza.cz>
> wrote:
> Hallo all
>
> I have summary data with size bins and percentage below that size.
>
> dat <- structure(list(size = c(10L, 20L, 30L, 40L, 50L, 60L, 70L, 80L,
> 90L, 100L, 110L, 120L, 130L, 140L, 150L, 160L, 170L, 180L, 190L,
> 200L, 250L, 300L, 400L, 500L), percent = c(0L, 0L, 0L, 1L, 1L,
> 2L, 4L, 8L, 13L, 18L, 24L, 31L, 38L, 44L, 50L, 57L, 65L, 72L,
> 76L, 83L, 95L, 98L, 100L, 100L)), class = "data.frame", row.names = c(NA,
> -24L))
>
> #I want to generate original distribution (I know it is better not to do
> it but I have no other choice) so I calculated #mids of those bins
>
> xd <-dat$size-c(5,diff(dat$size)/2)
> xd<- xd[-1]
>
> #I can sample the size bins with probability given by percent.
> Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)
> plot(ecdf(Result))
>
> #and I can add some noise to it, which is satisfactory with lower size
> bins but not enough for higher size bins.
>
> Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)+rnorm(1000,
> mean=0, sd=5)
> plot(ecdf(Result))
> I can increase sd to satisfy bigger bin size but in that case noise is too
> big for lower bin size.
>
> I would like to add smaller random noise to lower size bins and bigger
> random noise to higher size bins, which seems to be easy task but I am
> stuck how to do it. It should be somehow proportional to size value.
> The only way forward I see is to sort generated result and to use
> something like
>
> + rnorm(1000, mean=xd, sd=xd/10)
> But it is not correct.
>
> I'd appreciate any hint how to add random noise to values in ordered
> manner.
>
> Best regards.
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Thu Feb  3 22:16:47 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 3 Feb 2022 21:16:47 +0000
Subject: [R] generate distribution based on summary data and add random
 noise
In-Reply-To: <CAGxFJbQ7WcTt_fMFwRRez2TV+JNov92Hak1Y1Mnc7TUb+Bw+2A@mail.gmail.com>
References: <9e7449825b9844678143a79a7b61fe04@SRVEXCHCM1301.precheza.cz>
 <CAGxFJbT55JBCC9DCRC2xo8t7gUq8u9K6u1v8LOhJU2D_UrRnEA@mail.gmail.com>
 <0299ea9503e64c03b9fe606a9c12ea11@SRVEXCHCM1301.precheza.cz>
 <CAGxFJbQ7WcTt_fMFwRRez2TV+JNov92Hak1Y1Mnc7TUb+Bw+2A@mail.gmail.com>
Message-ID: <BN6PR2201MB155369689F1BEE40D401F054CF289@BN6PR2201MB1553.namprd22.prod.outlook.com>

I suggest taking Bert's suggestion and looking more closely. Take a different dataset where you have measures for each particle. Then apply the binning function. Use Bert's approach to recovering the "raw" data and then plot the real raw data and the approximated raw data. If you are happy with the result then proceed. If you are not happy, then consider that there is always the option not to do something. 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Thursday, February 3, 2022 12:35 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] generate distribution based on summary data and add random noise

[External Email]

Nope. I think I provided what you asked for, random data in each bin with the amount of data proportional to bin percentage and the distribution of that data uniform (nor normal) within the bin. So maybe someone else can give you what you want if this ain't it.

Cheers,
Bert

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 3, 2022 at 8:44 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hallo Bert
>
> probably not, sorry. Did you try my examples?
>
> To make it maybe simpler
> 1. sample a vector with given proportion and generate new data 2. add 
> random noise to each generated value with sd given by value of a 
> vector.
>
> let say
>
> x <- c(10, 100)
> y <- c(.6, .4)
> set.seed(200)
> z <- sample(x, 10, rep=TRUE, prob=y)
> ind <- order(z)
> bins <- rle(z[ind])
> bin1 <- rnorm(bins$lengths[1], mean = 0, sd=bins$values[1]/5)
> bin2 <- rnorm(bins$lengths[2], mean = 0, sd=bins$values[2]/5) z[ind] + 
> c(bin1, bin2)
>
> Sorry that I did not explain myself more clearly, I hoped that example 
> showed what I have on mind.
>
> Basically it is particle size cumulative distribution but size is 
> expressed as size bins. Normally I have exact size measurement for 
> each particle.
>
> S pozdravem | Best Regards
> RNDr. Petr PIKAL
> Vedouc? V?zkumu a v?voje | Research Manager PRECHEZA a.s.
> n?b?. Dr. Edvarda Bene?e 1170/24 | 750 02 P?erov | Czech Republic
> Tel: +420 581 252 256 | GSM: +420 724 008 364 
> mailto:petr.pikal at precheza.cz | 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_&
> d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=-AB8wceVe
> 94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s=2A8zlu8YYruq
> c_HvJ_ZM1ZUyHYUxhnkzEcK0r7gqw1U&e=
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? 
> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_z
> asady-2Dochrany-2Dosobnich-2Dudaju_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&
> r=9PEhQh2kVeAsRzsn7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s=LnvV0OF3Gt0WokwkVLzk8zlw5EIaPMiJnIlIV4FQWzs&e=  | Information about processing and protection of business partner?s personal data are available on website:
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_e
> n_personal-2Ddata-2Dprotection-2Dprinciples_&d=DwIFaQ&c=sJ6xIWYx-zLMB3
> EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--
> H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s=1ctBn30QSySXAHR0-xjdk_VQKrru3bF2TNX4j
> 2buz7I&e=
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou 
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_0
> 1-2Ddovetek_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-
> g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s
> =Xyy9O_noGq_K3Nto-64iGqZC0R-JhoAwiMSNQIixvZU&e=  | This email and any 
> documents attached to it may be confidential and are subject to the 
> legally binding disclaimer: 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_e
> n_01-2Ddisclaimer_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzs
> n7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-
> _CUq&s=FQbPQ1XP9xb1RJMbKZlXhQQaa9zSnUxJOevqrzrypRo&e=
>
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Thursday, February 3, 2022 5:10 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] generate distribution based on summary data and add 
> random noise
>
> If I understand correctly:
> To generate a sample of total size N, generate a uniform sample of 
> size p*N for a bin with proportion p?
> ?runif
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Feb 3, 2022 at 7:52 AM PIKAL Petr 
> <mailto:petr.pikal at precheza.cz>
> wrote:
> Hallo all
>
> I have summary data with size bins and percentage below that size.
>
> dat <- structure(list(size = c(10L, 20L, 30L, 40L, 50L, 60L, 70L, 80L, 
> 90L, 100L, 110L, 120L, 130L, 140L, 150L, 160L, 170L, 180L, 190L, 200L, 
> 250L, 300L, 400L, 500L), percent = c(0L, 0L, 0L, 1L, 1L, 2L, 4L, 8L, 
> 13L, 18L, 24L, 31L, 38L, 44L, 50L, 57L, 65L, 72L, 76L, 83L, 95L, 98L, 
> 100L, 100L)), class = "data.frame", row.names = c(NA,
> -24L))
>
> #I want to generate original distribution (I know it is better not to 
> do it but I have no other choice) so I calculated #mids of those bins
>
> xd <-dat$size-c(5,diff(dat$size)/2)
> xd<- xd[-1]
>
> #I can sample the size bins with probability given by percent.
> Result <- sample(xd, 1000, rep=T, prob=diff(dat$percent)/100)
> plot(ecdf(Result))
>
> #and I can add some noise to it, which is satisfactory with lower size 
> bins but not enough for higher size bins.
>
> Result <- sample(xd, 1000, rep=T, 
> prob=diff(dat$percent)/100)+rnorm(1000,
> mean=0, sd=5)
> plot(ecdf(Result))
> I can increase sd to satisfy bigger bin size but in that case noise is 
> too big for lower bin size.
>
> I would like to add smaller random noise to lower size bins and bigger 
> random noise to higher size bins, which seems to be easy task but I am 
> stuck how to do it. It should be somehow proportional to size value.
> The only way forward I see is to sort generated result and to use 
> something like
>
> + rnorm(1000, mean=xd, sd=xd/10)
> But it is not correct.
>
> I'd appreciate any hint how to add random noise to values in ordered 
> manner.
>
> Best regards.
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? 
> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_z
> asady-2Dochrany-2Dosobnich-2Dudaju_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&
> r=9PEhQh2kVeAsRzsn7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s=LnvV0OF3Gt0WokwkVLzk8zlw5EIaPMiJnIlIV4FQWzs&e=  | Information about processing and protection of business partner?s personal data are available on website:
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_e
> n_personal-2Ddata-2Dprotection-2Dprinciples_&d=DwIFaQ&c=sJ6xIWYx-zLMB3
> EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--
> H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s=1ctBn30QSySXAHR0-xjdk_VQKrru3bF2TNX4j
> 2buz7I&e=
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou 
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_0
> 1-2Ddovetek_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-
> g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s
> =Xyy9O_noGq_K3Nto-64iGqZC0R-JhoAwiMSNQIixvZU&e=  | This email and any 
> documents attached to it may be confidential and are subject to the 
> legally binding disclaimer: 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.precheza.cz_e
> n_01-2Ddisclaimer_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzs
> n7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-
> _CUq&s=FQbPQ1XP9xb1RJMbKZlXhQQaa9zSnUxJOevqrzrypRo&e=
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, 
> see 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> man_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> Rzsn7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJ
> xR-_CUq&s=G7mrJcOOgGTjgbVjY_TNsusk-0cEKAFjvYGjiD5RZeM&e=
> PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> g_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> sRzsn7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3N
> JxR-_CUq&s=b-P7V72w6IHT7gpAGwzaTN42gMwGRy9jkOWeQ4dX1QI&e=
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s=G7mrJcOOgGTjgbVjY_TNsusk-0cEKAFjvYGjiD5RZeM&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=-AB8wceVe94Vlj5r4Ys5b6hqY2KsI4sq--H-Gl-PqL2ayWSE3H0EGJ3NJxR-_CUq&s=b-P7V72w6IHT7gpAGwzaTN42gMwGRy9jkOWeQ4dX1QI&e=
and provide commented, minimal, self-contained, reproducible code.

From m@pjg @end|ng |rom br|@to|@@c@uk  Fri Feb  4 11:21:11 2022
From: m@pjg @end|ng |rom br|@to|@@c@uk (Peter Green)
Date: Fri, 4 Feb 2022 10:21:11 +0000
Subject: [R] Using .Fortran in R - how can I use file i/o flexibly OR arrays
 of variable length as arguments?
Message-ID: <2a1e95d2-8570-ebb0-f093-8bfbab642287@bristol.ac.uk>

I have a legacy Fortran code many thousands of lines long, a 
free-standing program that I now want to adapt with minimum re-writing 
to drive an R package, using .Fortran to pass control to a version of 
that legacy code re-written as a subroutine. BUT the output I want to 
return to R is copious, and variable in length, the length being 
computed within the Fortran code (it is a variable-dimension 
simulation). I'm looking for a solution general enough to include in a 
package that would pass CRAN checks.

I can think of two broad approaches

(1) to write this output to files in the Fortran code, to be read back 
later in R.? Of course I know about realpr, etc., but this is pretty 
ugly - apparently there's no binary i/o and no way to direct to a named 
file.

(2) to? dynamically allocate memory in the Fortran code for this output, 
and find a way for the address of this memory to be available in the 
result returned to R by .Fortran. The nearest to a possible solution 
that I can find in "Writing R extensions" involve use of C concepts, 
poorly explained, and I am not sure whether and how these could be used 
in my context.

Advice or information please!

-- 
Peter Green, p.j.green at bristol.ac.uk, peter.green at uts.edu.au
-- 
Emeritus Professor of Statistics & Professorial Research Fellow, University
of Bristol, Bristol BS8 1UG, UK
Phone: +44 117 428 4845; Fax: +44 117 928 7999
-- 
Distinguished Professor of Statistics, University of Technology, Sydney
Room: CB07.05.051; PO Box 123, Broadway NSW 2007, Australia
Phone: +61 2 9514 1742; Fax: +61 2 9514 2260


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Feb  5 09:09:25 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 5 Feb 2022 11:09:25 +0300
Subject: [R] 
 Using .Fortran in R - how can I use file i/o flexibly OR arrays
 of variable length as arguments?
In-Reply-To: <2a1e95d2-8570-ebb0-f093-8bfbab642287@bristol.ac.uk>
References: <2a1e95d2-8570-ebb0-f093-8bfbab642287@bristol.ac.uk>
Message-ID: <20220205110925.7e60d6e6@Tarkus>

On Fri, 4 Feb 2022 10:21:11 +0000
Peter Green <mapjg at bristol.ac.uk> wrote:

> the output I want to return to R is copious, and variable in length,
> the length being computed within the Fortran code (it is a
> variable-dimension simulation)

Is there a way to separate the calculation of the output size from the
rest of the subroutine? If yes, the simplest option would be to pass
pre-allocated vectors to the .Fortran() call.

Unfortunately, .Fortran() is not expressive enough for more complicated
use cases. Memory that you intend to return to R must be allocated
using its own allocator/garbage collector system, which (like any other
call into R from user code) may longjmp() away from your functions on
interrupt, error or allocation failure, abandoning any resources the
garbage collector doesn't know about. In turn, this requires the use of
C and the PROTECT() macro. In theory, you could use Fortran 2003 "C
interoperability" to call C entry points, but I expect that to be very
inconvenient (at least due to the lack of CPP macros).

Since you mention CRAN checks, this might be a better question for
<r-package-devel at r-project.org>, not R-help.

-- 
Best regards,
Ivan


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Feb  5 12:38:41 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 5 Feb 2022 14:38:41 +0300
Subject: [R] 
 Using .Fortran in R - how can I use file i/o flexibly OR arrays
 of variable length as arguments?
In-Reply-To: <1f6a1df3-50fb-de67-b174-158b5d0fd681@bristol.ac.uk>
References: <2a1e95d2-8570-ebb0-f093-8bfbab642287@bristol.ac.uk>
 <20220205110925.7e60d6e6@Tarkus>
 <1f6a1df3-50fb-de67-b174-158b5d0fd681@bristol.ac.uk>
Message-ID: <20220205143841.7684e5e1@Tarkus>

On Sat, 5 Feb 2022 09:41:02 +0000
Peter Green <mapjg at bristol.ac.uk> wrote:

> Any thought on the other route I suggested, that is, binary file i/o 
> from with the Fortran code (e.g. full use of the connections 
> functionality), again perhaps via C?

I think that Fortran I/O is only forbidden when it comes to units * and
6. It should be allowed to open a unit, use unformatted I/O to write an
array into it and readBin() back on the R side.

On the other hand, the use of connections means that we're calling into
R, which means that we have to interact with the garbage collector. It's
easier to just return the values to R in that case.

> I wondered whether you (or anyone) thought there was a way to do this 
> using C wrapper routines in some way?

I've never done this myself, but I think that the following should work:

/*
 * We'll need a single pointer to everything returned by the function,
 * so we'll store the outputs in a struct. If the function returns only
 * one allocated pointer, we don't need this structure.
 */
struct calculation_result {
 double *a, *b, *c; // ...
};

/* See WRE 5.13 */
static void free_calculation_result(SEXP * ptr) {
 struct calculation_result * res = R_ExternalPtrAddr(ptr);
 if (!res) return;
 /*
  * Call the Fortran function to deallocate a, b, c here, using C
  * interoperability or the F77_CALL macro.
  */
 Free(res);
 R_ClearExternalPtr(ptr);
}

/* See WRE 5.10.1 */
SEXP run_calculation(SEXP arg1, SEXP arg2, ...) {
 /*
  * Allocate the result store and make it known to R, including how to
  * dispose of it.
  */
 SEXP sres = PROTECT(R_MakeExternalPtr(NULL, R_NilValue, R_NilValue));
 R_RegisterCFinalizerEx(sres, free_calculation_result, TRUE);
 /* NOTE: if Calloc fails, it longjmp()s instead of returning NULL */
 struct calculation_result * res = Calloc(1, struct calculation_result);
 R_SetExternalPtrAddr(sres, res);

 /*
  * Call the Fortran function to perform the calculation here, store the
  * pointers it returns inside the res structure.
  */

 /*
  * It is now safe to call into R again. If an error happens or we're
  * interrupted, free_calculation_result will prevent a memory leak.
  * Allocate a result object (e.g. a named list) and store the data from
  * `res` in R vectors.
  */

 UNPROTECT(as many as PROTECT() calls above);
 return the_result_list;
}

Alternatively, provide some place with a static lifetime for the
pointers to the calculation results (put them in a COMMON block with
the SAVE attribute?) and split the code into three functions:

1. Perform the calculations and remember the pointers in variables
   with static lifetime; return the sizes of the arrays.
2. Copy the data from the COMMON pointers to the provided arrays.
3. Deallocate the Fortran-owned COMMON arrays.

Then the R wrapper should do the following:

on.exit(.Fortran('free_fortran_arrays'))
sizes <- .Fortran('perform_calculations', sizes = integer(k))$sizes
result <- .Fortran(
 'copy_fortran_arrays',
 a = double(sizes[1]), b = double(sizes[2]), ...
)

If R is interrupted or has an allocation failure between
perform_calculations and copy_fortran_arrays, the destructor still runs
and prevents resource leaks. This makes the code non-reentrant, but so
is R itself.

A third solution would be to abstract the Fortran code behind a C++
class and use the magic of Rcpp to return the data as R objects while
keeping the promise that the destructor eventually runs. This is more
or less the same as the first solution, but most of the work is done by
Rcpp.

Now that we both had to mention Writing R Extensions, I think we're
firmly in the <r-package-devel at r-project.org> territory.

-- 
Best regards,
Ivan


From m@pjg @end|ng |rom br|@to|@@c@uk  Sat Feb  5 10:41:02 2022
From: m@pjg @end|ng |rom br|@to|@@c@uk (Peter Green)
Date: Sat, 5 Feb 2022 09:41:02 +0000
Subject: [R] 
 Using .Fortran in R - how can I use file i/o flexibly OR arrays
 of variable length as arguments?
In-Reply-To: <20220205110925.7e60d6e6@Tarkus>
References: <2a1e95d2-8570-ebb0-f093-8bfbab642287@bristol.ac.uk>
 <20220205110925.7e60d6e6@Tarkus>
Message-ID: <1f6a1df3-50fb-de67-b174-158b5d0fd681@bristol.ac.uk>

Thank you, Ivan, it's reassuring in a way to learn from your reply that 
I am not missing something very obvious.

It's unfortunate that a computation that could be done cleanly, using 
dynamic allocation of memory, within either R or Fortran separately, 
cannot be split between the two in a way that is optimal for the 
capabilities of each language, because of the .Fortran bottleneck. I 
wondered whether you (or anyone) thought there was a way to do this 
using C wrapper routines in some way? Unfortunately, the ultimate size 
of the output is something the algorithm would only learn very late in 
the computation, so pre-calculating that size is not a practical option 
(else indeed I would do that within R before use of .Fortran).

Any thought on the other route I suggested, that is, binary file i/o 
from with the Fortran code (e.g. full use of the connections 
functionality), again perhaps via C?

Although I mentioned CRAN, that was really just to stress I wanted a 
platform-independent solution ideally.

Peter Green

On 05/02/2022 08:09, Ivan Krylov wrote:
> On Fri, 4 Feb 2022 10:21:11 +0000
> Peter Green <mapjg at bristol.ac.uk> wrote:
>
>> the output I want to return to R is copious, and variable in length,
>> the length being computed within the Fortran code (it is a
>> variable-dimension simulation)
> Is there a way to separate the calculation of the output size from the
> rest of the subroutine? If yes, the simplest option would be to pass
> pre-allocated vectors to the .Fortran() call.
>
> Unfortunately, .Fortran() is not expressive enough for more complicated
> use cases. Memory that you intend to return to R must be allocated
> using its own allocator/garbage collector system, which (like any other
> call into R from user code) may longjmp() away from your functions on
> interrupt, error or allocation failure, abandoning any resources the
> garbage collector doesn't know about. In turn, this requires the use of
> C and the PROTECT() macro. In theory, you could use Fortran 2003 "C
> interoperability" to call C entry points, but I expect that to be very
> inconvenient (at least due to the lack of CPP macros).
>
> Since you mention CRAN checks, this might be a better question for
> <r-package-devel at r-project.org>, not R-help.
>


From m@pjg @end|ng |rom br|@to|@@c@uk  Sat Feb  5 14:58:46 2022
From: m@pjg @end|ng |rom br|@to|@@c@uk (Peter Green)
Date: Sat, 5 Feb 2022 13:58:46 +0000
Subject: [R] 
 Using .Fortran in R - how can I use file i/o flexibly OR arrays
 of variable length as arguments?
In-Reply-To: <20220205143841.7684e5e1@Tarkus>
References: <2a1e95d2-8570-ebb0-f093-8bfbab642287@bristol.ac.uk>
 <20220205110925.7e60d6e6@Tarkus>
 <1f6a1df3-50fb-de67-b174-158b5d0fd681@bristol.ac.uk>
 <20220205143841.7684e5e1@Tarkus>
Message-ID: <84480fe0-7d4e-3ed7-196d-1d74452cfcf1@bristol.ac.uk>

>> Any thought on the other route I suggested, that is, binary file i/o
>> from with the Fortran code (e.g. full use of the connections
>> functionality), again perhaps via C?
> I think that Fortran I/O is only forbidden when it comes to units * and
> 6. It should be allowed to open a unit, use unformatted I/O to write an
> array into it and readBin() back on the R side.
>
> On the other hand, the use of connections means that we're calling into
> R, which means that we have to interact with the garbage collector. It's
> easier to just return the values to R in that case.

Thank you, Ivan - you've detected an unusual example of my 
over-interpreting, rather than underestimating something in Writing R 
extensions!

Peter


From dscoiby17 m@iii@g oii gm@ii@com  Fri Feb  4 21:31:59 2022
From: dscoiby17 m@iii@g oii gm@ii@com (dscoiby17 m@iii@g oii gm@ii@com)
Date: Fri, 4 Feb 2022 15:31:59 -0500
Subject: [R] [R-pkgs] spacejamr v0.2
Message-ID: <031e01d81a06$4fa88600$eef99200$@gmail.com>

Dear R users,

 

I am pleased to announce that v0.2 of the spacejamr package is now available
on CRAN.  This package enables social network analysis when social network
data is unavailable. spacejamr simulates points from a spatial point process
or sequence in a user-specified spatial window, converts distances between
points into tie formation probabilities, and outputs an igraph object that
can be analyzed with normal network analysis methods. In addition, the
package includes plotting methods for spatial boundaries, point processes,
and social networks.

 

Some changes to this version are:

 

            * Users can decide whether to use the coordinate reference
system in the supplied shapefile or let the as.spacejamr() method find the
best projected CRS.

    

             * spacejamr no longer depends on the methods package.

    

            * In line with new versions of the spatstat metapackage,
spacejamr now calls functions from spatstat.random to simulate spatial point
processes.

 

Please check it out here:

https://cran.r-project.org/package=spacejamr

 

For more details on the methodology used in the package see:

Carter T. Butts, (2002, ISBN:978-0-493-72676-2), "Spatial models of
large-scale interpersonal networks."

 

Best regards,

 

Darren Colby

 


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Feb  6 00:37:47 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 05 Feb 2022 15:37:47 -0800
Subject: [R] 
 Using .Fortran in R - how can I use file i/o flexibly OR arrays
 of variable length as arguments?
In-Reply-To: <1f6a1df3-50fb-de67-b174-158b5d0fd681@bristol.ac.uk>
References: <2a1e95d2-8570-ebb0-f093-8bfbab642287@bristol.ac.uk>
 <20220205110925.7e60d6e6@Tarkus>
 <1f6a1df3-50fb-de67-b174-158b5d0fd681@bristol.ac.uk>
Message-ID: <DE8E4B32-7E5C-480C-BB6C-FA33BDF9ED85@dcn.davis.ca.us>

This really does belong on r-package-devel. Do reply there if at all.

As regards your whining about dynamic memory... differences of opinion about heap memory handling are pervasive between languages and even between libraries used within the same language, and Fortran was used for many decades without dynamic memory options at all. So this situation is normal, and R can't force other code to conform to its requirements. We live in a world of multi-gigabyte RAM and 100Mflop computation resources... pre-allocate more than you need and fail if it isn't enough. Or figure out a way to provide an estimate of the needed memory as Ivan suggested. Or split your computations into an early (don't know yet but are figuring out out) and late phase (when you do know and can pass in sufficient allocated memory from R).

On February 5, 2022 1:41:02 AM PST, Peter Green <mapjg at bristol.ac.uk> wrote:
>Thank you, Ivan, it's reassuring in a way to learn from your reply that 
>I am not missing something very obvious.
>
>It's unfortunate that a computation that could be done cleanly, using 
>dynamic allocation of memory, within either R or Fortran separately, 
>cannot be split between the two in a way that is optimal for the 
>capabilities of each language, because of the .Fortran bottleneck. I 
>wondered whether you (or anyone) thought there was a way to do this 
>using C wrapper routines in some way? Unfortunately, the ultimate size 
>of the output is something the algorithm would only learn very late in 
>the computation, so pre-calculating that size is not a practical option 
>(else indeed I would do that within R before use of .Fortran).
>
>Any thought on the other route I suggested, that is, binary file i/o 
>from with the Fortran code (e.g. full use of the connections 
>functionality), again perhaps via C?
>
>Although I mentioned CRAN, that was really just to stress I wanted a 
>platform-independent solution ideally.
>
>Peter Green
>
>On 05/02/2022 08:09, Ivan Krylov wrote:
>> On Fri, 4 Feb 2022 10:21:11 +0000
>> Peter Green <mapjg at bristol.ac.uk> wrote:
>>
>>> the output I want to return to R is copious, and variable in length,
>>> the length being computed within the Fortran code (it is a
>>> variable-dimension simulation)
>> Is there a way to separate the calculation of the output size from the
>> rest of the subroutine? If yes, the simplest option would be to pass
>> pre-allocated vectors to the .Fortran() call.
>>
>> Unfortunately, .Fortran() is not expressive enough for more complicated
>> use cases. Memory that you intend to return to R must be allocated
>> using its own allocator/garbage collector system, which (like any other
>> call into R from user code) may longjmp() away from your functions on
>> interrupt, error or allocation failure, abandoning any resources the
>> garbage collector doesn't know about. In turn, this requires the use of
>> C and the PROTECT() macro. In theory, you could use Fortran 2003 "C
>> interoperability" to call C entry points, but I expect that to be very
>> inconvenient (at least due to the lack of CPP macros).
>>
>> Since you mention CRAN checks, this might be a better question for
>> <r-package-devel at r-project.org>, not R-help.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Feb  6 19:55:43 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 6 Feb 2022 18:55:43 +0000
Subject: [R] handling breaks in a for loop
Message-ID: <PU4P216MB15686C23955B69980F00DD4AC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

dear members,
                         I have a very large for loop (basically a web scraping loop) with 500 iterations(over different stocks). I am concerned about the loop breaking midway.

My question is: is there any method to store the succesful iterations and continue with the iteration (ofcourse, after fixing the bug) where the exception occured? I can insert a save () function in the body of the loop and save the succesful iterations but this would slow down the execution speed. Any other method? I want to avoid trycatch as much as possible because an NA in the place of a succesful iteration would cost me much.

Thanking you,
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Sun Feb  6 20:03:19 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sun, 6 Feb 2022 19:03:19 +0000
Subject: [R] handling breaks in a for loop
In-Reply-To: <PU4P216MB15686C23955B69980F00DD4AC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB15686C23955B69980F00DD4AC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <BN6PR2201MB15533D86058E68EA33E851E1CF2B9@BN6PR2201MB1553.namprd22.prod.outlook.com>

Is the bug in the data or in the code?
Can you identify the cause? Can you get a subset of the data to find the bug using fewer resources?
If you can identify the root cause, then you can set an error trap.
If the error is a memory problem, they you either need to save, reallocate memory, or get more memory.

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
Sent: Sunday, February 6, 2022 1:56 PM
To: R help Mailing list <r-help at r-project.org>
Subject: [R] handling breaks in a for loop

[External Email]

dear members,
                         I have a very large for loop (basically a web scraping loop) with 500 iterations(over different stocks). I am concerned about the loop breaking midway.

My question is: is there any method to store the succesful iterations and continue with the iteration (ofcourse, after fixing the bug) where the exception occured? I can insert a save () function in the body of the loop and save the succesful iterations but this would slow down the execution speed. Any other method? I want to avoid trycatch as much as possible because an NA in the place of a succesful iteration would cost me much.

Thanking you,
Yours sincerely,
AKSHAY M KULKARNI

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=jmZ4HPdnRH6ive_u-90RBNQQtFrnMey9AZv8MRZGQbc&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=Tpxb0boNRBRe0_7_FZteYKLLal9zfDXAXImIExuV35o&e=
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Feb  6 20:27:11 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 06 Feb 2022 11:27:11 -0800
Subject: [R] handling breaks in a for loop
In-Reply-To: <BN6PR2201MB15533D86058E68EA33E851E1CF2B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <PU4P216MB15686C23955B69980F00DD4AC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <BN6PR2201MB15533D86058E68EA33E851E1CF2B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <4085B4A1-B4FC-4875-AD30-A45B7F1F7455@dcn.davis.ca.us>

Perhaps a more conventional division of functional concerns should be applied? Separate collection of data from computation. Input functions should do input, analysis functions should do analysis, and output functions should do output... effectively lowering the cost of failure. If your first stage is simply storing the webscraped data, restarting should be easy.

On February 6, 2022 11:03:19 AM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>Is the bug in the data or in the code?
>Can you identify the cause? Can you get a subset of the data to find the bug using fewer resources?
>If you can identify the root cause, then you can set an error trap.
>If the error is a memory problem, they you either need to save, reallocate memory, or get more memory.
>
>Tim
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
>Sent: Sunday, February 6, 2022 1:56 PM
>To: R help Mailing list <r-help at r-project.org>
>Subject: [R] handling breaks in a for loop
>
>[External Email]
>
>dear members,
>                         I have a very large for loop (basically a web scraping loop) with 500 iterations(over different stocks). I am concerned about the loop breaking midway.
>
>My question is: is there any method to store the succesful iterations and continue with the iteration (ofcourse, after fixing the bug) where the exception occured? I can insert a save () function in the body of the loop and save the succesful iterations but this would slow down the execution speed. Any other method? I want to avoid trycatch as much as possible because an NA in the place of a succesful iteration would cost me much.
>
>Thanking you,
>Yours sincerely,
>AKSHAY M KULKARNI
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=jmZ4HPdnRH6ive_u-90RBNQQtFrnMey9AZv8MRZGQbc&e=
>PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=Tpxb0boNRBRe0_7_FZteYKLLal9zfDXAXImIExuV35o&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Feb  6 20:27:27 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 6 Feb 2022 19:27:27 +0000
Subject: [R] handling breaks in a for loop
In-Reply-To: <BN6PR2201MB15533D86058E68EA33E851E1CF2B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <PU4P216MB15686C23955B69980F00DD4AC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <BN6PR2201MB15533D86058E68EA33E851E1CF2B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <PU4P216MB156892F8BFDD3AA2B112C9BBC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

dear Tim,
                I have not yet ran the function. I just wanted to be prepared. The data is the html document and the code is the scraping code, but the point is, the error might be from neither data nor code, but due to the inconsistencies in the web page. THis can happen however perfect I make my code. I think save () function in the body might save me, but any other faster method?

Thanking you,
Yours sincerely,
AKSHAY M KULKARNI
________________________________
From: Ebert,Timothy Aaron <tebert at ufl.edu>
Sent: Monday, February 7, 2022 12:33 AM
To: akshay kulkarni <akshay_e4 at hotmail.com>; R help Mailing list <r-help at r-project.org>
Subject: RE: handling breaks in a for loop

Is the bug in the data or in the code?
Can you identify the cause? Can you get a subset of the data to find the bug using fewer resources?
If you can identify the root cause, then you can set an error trap.
If the error is a memory problem, they you either need to save, reallocate memory, or get more memory.

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
Sent: Sunday, February 6, 2022 1:56 PM
To: R help Mailing list <r-help at r-project.org>
Subject: [R] handling breaks in a for loop

[External Email]

dear members,
                         I have a very large for loop (basically a web scraping loop) with 500 iterations(over different stocks). I am concerned about the loop breaking midway.

My question is: is there any method to store the succesful iterations and continue with the iteration (ofcourse, after fixing the bug) where the exception occured? I can insert a save () function in the body of the loop and save the succesful iterations but this would slow down the execution speed. Any other method? I want to avoid trycatch as much as possible because an NA in the place of a succesful iteration would cost me much.

Thanking you,
Yours sincerely,
AKSHAY M KULKARNI

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=jmZ4HPdnRH6ive_u-90RBNQQtFrnMey9AZv8MRZGQbc&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=Tpxb0boNRBRe0_7_FZteYKLLal9zfDXAXImIExuV35o&e=
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Feb  6 20:41:54 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 6 Feb 2022 19:41:54 +0000
Subject: [R] handling breaks in a for loop
In-Reply-To: <4085B4A1-B4FC-4875-AD30-A45B7F1F7455@dcn.davis.ca.us>
References: <PU4P216MB15686C23955B69980F00DD4AC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <BN6PR2201MB15533D86058E68EA33E851E1CF2B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <4085B4A1-B4FC-4875-AD30-A45B7F1F7455@dcn.davis.ca.us>
Message-ID: <PU4P216MB1568B029AC3EDFADCB7BBE87C82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

dear jeff,
                restarting the storing of webscraped data should be easy, but what if it takes more than a few tries? I am using a very costly AWS EC2 instance and am hard pressed for funds. You should know that it is very difficult for me to afford even one break. I think the execution should take about two hours, but even one break could make it 5 - 6 hours (including fixing of the bug). What if I use save () in the body of the loop? It might make it run for about three hours, but it is better than 5 -6 hours right?

THanking you,
Yours sincerely,
AKSHAY M KULKARNI
________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Monday, February 7, 2022 12:57 AM
To: r-help at r-project.org <r-help at r-project.org>; Ebert,Timothy Aaron <tebert at ufl.edu>; akshay kulkarni <akshay_e4 at hotmail.com>; R help Mailing list <r-help at r-project.org>
Subject: Re: [R] handling breaks in a for loop

Perhaps a more conventional division of functional concerns should be applied? Separate collection of data from computation. Input functions should do input, analysis functions should do analysis, and output functions should do output... effectively lowering the cost of failure. If your first stage is simply storing the webscraped data, restarting should be easy.

On February 6, 2022 11:03:19 AM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>Is the bug in the data or in the code?
>Can you identify the cause? Can you get a subset of the data to find the bug using fewer resources?
>If you can identify the root cause, then you can set an error trap.
>If the error is a memory problem, they you either need to save, reallocate memory, or get more memory.
>
>Tim
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
>Sent: Sunday, February 6, 2022 1:56 PM
>To: R help Mailing list <r-help at r-project.org>
>Subject: [R] handling breaks in a for loop
>
>[External Email]
>
>dear members,
>                         I have a very large for loop (basically a web scraping loop) with 500 iterations(over different stocks). I am concerned about the loop breaking midway.
>
>My question is: is there any method to store the succesful iterations and continue with the iteration (ofcourse, after fixing the bug) where the exception occured? I can insert a save () function in the body of the loop and save the succesful iterations but this would slow down the execution speed. Any other method? I want to avoid trycatch as much as possible because an NA in the place of a succesful iteration would cost me much.
>
>Thanking you,
>Yours sincerely,
>AKSHAY M KULKARNI
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=jmZ4HPdnRH6ive_u-90RBNQQtFrnMey9AZv8MRZGQbc&e=
>PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=Tpxb0boNRBRe0_7_FZteYKLLal9zfDXAXImIExuV35o&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Feb  6 20:58:25 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 06 Feb 2022 11:58:25 -0800
Subject: [R] handling breaks in a for loop
In-Reply-To: <PU4P216MB1568B029AC3EDFADCB7BBE87C82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB15686C23955B69980F00DD4AC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <BN6PR2201MB15533D86058E68EA33E851E1CF2B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <4085B4A1-B4FC-4875-AD30-A45B7F1F7455@dcn.davis.ca.us>
 <PU4P216MB1568B029AC3EDFADCB7BBE87C82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CE873E32-A003-4DFF-BE99-072B486BE0E0@dcn.davis.ca.us>

If your inout loop is ONLY storing data, then failures are either in the retrieval or storing actions. If you have sufficient storage space then the latter should be reliable. Network failures are however inevitable... you have no choice but to deal with them somehow... the internet is intrinsically unreliable. If missing one stock invalidates your analysis then you have set yourself up for failure and no amount of tricky coding will save you.

On February 6, 2022 11:41:54 AM PST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear jeff,
>                restarting the storing of webscraped data should be easy, but what if it takes more than a few tries? I am using a very costly AWS EC2 instance and am hard pressed for funds. You should know that it is very difficult for me to afford even one break. I think the execution should take about two hours, but even one break could make it 5 - 6 hours (including fixing of the bug). What if I use save () in the body of the loop? It might make it run for about three hours, but it is better than 5 -6 hours right?
>
>THanking you,
>Yours sincerely,
>AKSHAY M KULKARNI
>________________________________
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Monday, February 7, 2022 12:57 AM
>To: r-help at r-project.org <r-help at r-project.org>; Ebert,Timothy Aaron <tebert at ufl.edu>; akshay kulkarni <akshay_e4 at hotmail.com>; R help Mailing list <r-help at r-project.org>
>Subject: Re: [R] handling breaks in a for loop
>
>Perhaps a more conventional division of functional concerns should be applied? Separate collection of data from computation. Input functions should do input, analysis functions should do analysis, and output functions should do output... effectively lowering the cost of failure. If your first stage is simply storing the webscraped data, restarting should be easy.
>
>On February 6, 2022 11:03:19 AM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>>Is the bug in the data or in the code?
>>Can you identify the cause? Can you get a subset of the data to find the bug using fewer resources?
>>If you can identify the root cause, then you can set an error trap.
>>If the error is a memory problem, they you either need to save, reallocate memory, or get more memory.
>>
>>Tim
>>
>>-----Original Message-----
>>From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
>>Sent: Sunday, February 6, 2022 1:56 PM
>>To: R help Mailing list <r-help at r-project.org>
>>Subject: [R] handling breaks in a for loop
>>
>>[External Email]
>>
>>dear members,
>>                         I have a very large for loop (basically a web scraping loop) with 500 iterations(over different stocks). I am concerned about the loop breaking midway.
>>
>>My question is: is there any method to store the succesful iterations and continue with the iteration (ofcourse, after fixing the bug) where the exception occured? I can insert a save () function in the body of the loop and save the succesful iterations but this would slow down the execution speed. Any other method? I want to avoid trycatch as much as possible because an NA in the place of a succesful iteration would cost me much.
>>
>>Thanking you,
>>Yours sincerely,
>>AKSHAY M KULKARNI
>>
>>        [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=jmZ4HPdnRH6ive_u-90RBNQQtFrnMey9AZv8MRZGQbc&e=
>>PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=Tpxb0boNRBRe0_7_FZteYKLLal9zfDXAXImIExuV35o&e=
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Feb  6 21:05:09 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 6 Feb 2022 20:05:09 +0000
Subject: [R] handling breaks in a for loop
In-Reply-To: <CE873E32-A003-4DFF-BE99-072B486BE0E0@dcn.davis.ca.us>
References: <PU4P216MB15686C23955B69980F00DD4AC82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <BN6PR2201MB15533D86058E68EA33E851E1CF2B9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <4085B4A1-B4FC-4875-AD30-A45B7F1F7455@dcn.davis.ca.us>
 <PU4P216MB1568B029AC3EDFADCB7BBE87C82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CE873E32-A003-4DFF-BE99-072B486BE0E0@dcn.davis.ca.us>
Message-ID: <PU4P216MB156815913ADCA63AF8CCA551C82B9@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

dear jeff,
               thanks. I think there is no free lunch for me now!

thanking you,
Yours sincerely,
Akshay M Kulkarni
________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Monday, February 7, 2022 1:28 AM
To: akshay kulkarni <akshay_e4 at hotmail.com>; r-help at r-project.org <r-help at r-project.org>; Ebert,Timothy Aaron <tebert at ufl.edu>
Subject: Re: [R] handling breaks in a for loop

If your inout loop is ONLY storing data, then failures are either in the retrieval or storing actions. If you have sufficient storage space then the latter should be reliable. Network failures are however inevitable... you have no choice but to deal with them somehow... the internet is intrinsically unreliable. If missing one stock invalidates your analysis then you have set yourself up for failure and no amount of tricky coding will save you.

On February 6, 2022 11:41:54 AM PST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear jeff,
>                restarting the storing of webscraped data should be easy, but what if it takes more than a few tries? I am using a very costly AWS EC2 instance and am hard pressed for funds. You should know that it is very difficult for me to afford even one break. I think the execution should take about two hours, but even one break could make it 5 - 6 hours (including fixing of the bug). What if I use save () in the body of the loop? It might make it run for about three hours, but it is better than 5 -6 hours right?
>
>THanking you,
>Yours sincerely,
>AKSHAY M KULKARNI
>________________________________
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Monday, February 7, 2022 12:57 AM
>To: r-help at r-project.org <r-help at r-project.org>; Ebert,Timothy Aaron <tebert at ufl.edu>; akshay kulkarni <akshay_e4 at hotmail.com>; R help Mailing list <r-help at r-project.org>
>Subject: Re: [R] handling breaks in a for loop
>
>Perhaps a more conventional division of functional concerns should be applied? Separate collection of data from computation. Input functions should do input, analysis functions should do analysis, and output functions should do output... effectively lowering the cost of failure. If your first stage is simply storing the webscraped data, restarting should be easy.
>
>On February 6, 2022 11:03:19 AM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>>Is the bug in the data or in the code?
>>Can you identify the cause? Can you get a subset of the data to find the bug using fewer resources?
>>If you can identify the root cause, then you can set an error trap.
>>If the error is a memory problem, they you either need to save, reallocate memory, or get more memory.
>>
>>Tim
>>
>>-----Original Message-----
>>From: R-help <r-help-bounces at r-project.org> On Behalf Of akshay kulkarni
>>Sent: Sunday, February 6, 2022 1:56 PM
>>To: R help Mailing list <r-help at r-project.org>
>>Subject: [R] handling breaks in a for loop
>>
>>[External Email]
>>
>>dear members,
>>                         I have a very large for loop (basically a web scraping loop) with 500 iterations(over different stocks). I am concerned about the loop breaking midway.
>>
>>My question is: is there any method to store the succesful iterations and continue with the iteration (ofcourse, after fixing the bug) where the exception occured? I can insert a save () function in the body of the loop and save the succesful iterations but this would slow down the execution speed. Any other method? I want to avoid trycatch as much as possible because an NA in the place of a succesful iteration would cost me much.
>>
>>Thanking you,
>>Yours sincerely,
>>AKSHAY M KULKARNI
>>
>>        [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=jmZ4HPdnRH6ive_u-90RBNQQtFrnMey9AZv8MRZGQbc&e=
>>PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=F0cPNGUlUW-Cd9RJzYladHn1oypv0cPLA-d9dEO42hExw8rxis6aw3FPV6DtBQU2&s=Tpxb0boNRBRe0_7_FZteYKLLal9zfDXAXImIExuV35o&e=
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Mon Feb  7 23:55:13 2022
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Mon, 7 Feb 2022 15:55:13 -0700
Subject: [R] Convert a character string to variable names
Message-ID: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>

Hello!

I have a character string that is a vector of variable names.  I would like
to use those names to access the variables and create a matrix.
I tried the following:

> .x

[1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"

> .y <- NULL

> for(i in 1:3) {

+ .y[i] <- c(as.name(.x[[i]]))

+ }

> .y

[[1]]

`mtcars$disp`


[[2]]

`mtcars$hp`


[[3]]

`mtcars$cyl`


But I am having trouble converting the variables in .y into a matrix.


I tried all kinds of stuff with bquote, deparse, do.call, but no good.


I have a feeling that it's something simple, and I'm just not seeing it.


Thanks,

Erin




Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Tue Feb  8 00:05:41 2022
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Mon, 7 Feb 2022 23:05:41 +0000
Subject: [R] [External]  Convert a character string to variable names
In-Reply-To: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
Message-ID: <9E2C362A-E86B-4932-86FF-D4916F2F3C7C@temple.edu>

> x <- c("mtcars$disp", "mtcars$hp", "mtcars$cyl")
> x
[1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl" 
> eval(parse(text=x))
 [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
> for (i in x) print(eval(parse(text=i)))
 [1] 160.0 160.0 108.0 258.0 360.0 225.0 360.0 146.7 140.8 167.6 167.6 275.8 275.8 275.8 472.0 460.0 440.0  78.7  75.7  71.1 120.1 318.0
[23] 304.0 350.0 400.0  79.0 120.3  95.1 351.0 145.0 301.0 121.0
 [1] 110 110  93 110 175 105 245  62  95 123 123 180 180 180 205 215 230  66  52  65  97 150 150 245 175  66  91 113 264 175 335 109
 [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4


> On Feb 07, 2022, at 17:55, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> 
>> .x
> 
> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"


From er|nm@hodge@@ @end|ng |rom gm@||@com  Tue Feb  8 00:08:08 2022
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Mon, 7 Feb 2022 16:08:08 -0700
Subject: [R] [External]  Convert a character string to variable names
In-Reply-To: <9E2C362A-E86B-4932-86FF-D4916F2F3C7C@temple.edu>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <9E2C362A-E86B-4932-86FF-D4916F2F3C7C@temple.edu>
Message-ID: <CACxE24ngwRRuUc7HSVhKh7My6QUj4k-Ekxn1Y5egj_kbn50wWQ@mail.gmail.com>

Awesome, thank you so much!

Sincerely,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Mon, Feb 7, 2022 at 4:05 PM Richard M. Heiberger <rmh at temple.edu> wrote:

> > x <- c("mtcars$disp", "mtcars$hp", "mtcars$cyl")
> > x
> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> > eval(parse(text=x))
>  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
> > for (i in x) print(eval(parse(text=i)))
>  [1] 160.0 160.0 108.0 258.0 360.0 225.0 360.0 146.7 140.8 167.6 167.6
> 275.8 275.8 275.8 472.0 460.0 440.0  78.7  75.7  71.1 120.1 318.0
> [23] 304.0 350.0 400.0  79.0 120.3  95.1 351.0 145.0 301.0 121.0
>  [1] 110 110  93 110 175 105 245  62  95 123 123 180 180 180 205 215 230
> 66  52  65  97 150 150 245 175  66  91 113 264 175 335 109
>  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
>
>
> > On Feb 07, 2022, at 17:55, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> >
> >> .x
> >
> > [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb  8 00:21:28 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 7 Feb 2022 15:21:28 -0800
Subject: [R] [External] Convert a character string to variable names
In-Reply-To: <9E2C362A-E86B-4932-86FF-D4916F2F3C7C@temple.edu>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <9E2C362A-E86B-4932-86FF-D4916F2F3C7C@temple.edu>
Message-ID: <CAGxFJbSp0cc4tB-tH4yF-NKQvNS0uLNQre4gPTg2GY4Ap23sBQ@mail.gmail.com>

I assume that the mtcars components were used only as an example, as you
could convert them to a matrix via as.matrix(). Unfortunately, it was a bad
choice: as.name("x$something") is not the name of 'something' in the data
frame (or list) x. Moreover, as.name("x") does not point to an object x --
as Rich indicated, it has to be evaluated to do so.
> x<- 1:10
> z <- as.name("x")
> z
x
> length(z)
[1] 1
> eval(z)
 [1]  1  2  3  4  5  6  7  8  9 10

But more to the point, I think you are attempting to drive from Brooklyn to
New York City by way of Los Angeles. If I understand correctly, I think all
you need is ?get:

> x <- runif(5)
> y <- 1:5
> z <- 21:25
> nm <- c('x', 'y','z')
> sapply(nm, get)
              x y  z
[1,] 0.99602479 1 21
[2,] 0.97458756 2 22
[3,] 0.09496625 3 23
[4,] 0.91444550 4 24
[5,] 0.68331484 5 25

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 7, 2022 at 3:06 PM Richard M. Heiberger <rmh at temple.edu> wrote:

> > x <- c("mtcars$disp", "mtcars$hp", "mtcars$cyl")
> > x
> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> > eval(parse(text=x))
>  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
> > for (i in x) print(eval(parse(text=i)))
>  [1] 160.0 160.0 108.0 258.0 360.0 225.0 360.0 146.7 140.8 167.6 167.6
> 275.8 275.8 275.8 472.0 460.0 440.0  78.7  75.7  71.1 120.1 318.0
> [23] 304.0 350.0 400.0  79.0 120.3  95.1 351.0 145.0 301.0 121.0
>  [1] 110 110  93 110 175 105 245  62  95 123 123 180 180 180 205 215 230
> 66  52  65  97 150 150 245 175  66  91 113 264 175 335 109
>  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
>
>
> > On Feb 07, 2022, at 17:55, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> >
> >> .x
> >
> > [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Feb  8 00:32:42 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 7 Feb 2022 23:32:42 +0000
Subject: [R] Convert a character string to variable names
In-Reply-To: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
Message-ID: <781e11be-ef4b-812c-5282-3b4448ac2825@sapo.pt>

Hello,

If you want to avoid eval(parse(.)), here is another solution.

First split the strings by '$' giving the data set name in the 1st 
element of each list member and the column name in the 2nd. With a 
sapply loop find the data set name then ?get the data itself in df1. 
Finally, another sapply loop creates a vector of column names. And it's 
a matter of extracting those columns with standard '[' (or '[['.


.x <- scan(text = '"mtcars$disp" "mtcars$hp"   "mtcars$cyl"', what = 
character())

s <- strsplit(.x, "\\$")
df1 <- unique(sapply(s, `[`, 1))
df1 <- get(df1, envir = .GlobalEnv)
cols <- sapply(s, `[`, 2)

# all columns, result is a data.frame
head(df1[cols])
#>                   disp  hp cyl
#> Mazda RX4          160 110   6
#> Mazda RX4 Wag      160 110   6
#> Datsun 710         108  93   4
#> Hornet 4 Drive     258 110   6
#> Hornet Sportabout  360 175   8
#> Valiant            225 105   6

# first column in 'cols', result is a data.frame
head(df1[ cols[1] ])
#>                   disp
#> Mazda RX4          160
#> Mazda RX4 Wag      160
#> Datsun 710         108
#> Hornet 4 Drive     258
#> Hornet Sportabout  360
#> Valiant            225

# second column in 'cols', result is a vector
head(df1[[ cols[2] ]])
#> [1] 110 110  93 110 175 105


Hope this helps,

Rui Barradas

?s 22:55 de 07/02/2022, Erin Hodgess escreveu:
> Hello!
> 
> I have a character string that is a vector of variable names.  I would like
> to use those names to access the variables and create a matrix.
> I tried the following:
> 
>> .x
> 
> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> 
>> .y <- NULL
> 
>> for(i in 1:3) {
> 
> + .y[i] <- c(as.name(.x[[i]]))
> 
> + }
> 
>> .y
> 
> [[1]]
> 
> `mtcars$disp`
> 
> 
> [[2]]
> 
> `mtcars$hp`
> 
> 
> [[3]]
> 
> `mtcars$cyl`
> 
> 
> But I am having trouble converting the variables in .y into a matrix.
> 
> 
> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
> 
> 
> I have a feeling that it's something simple, and I'm just not seeing it.
> 
> 
> Thanks,
> 
> Erin
> 
> 
> 
> 
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Feb  8 00:36:56 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 7 Feb 2022 23:36:56 +0000
Subject: [R] [External] Convert a character string to variable names
In-Reply-To: <CAGxFJbSp0cc4tB-tH4yF-NKQvNS0uLNQre4gPTg2GY4Ap23sBQ@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <9E2C362A-E86B-4932-86FF-D4916F2F3C7C@temple.edu>
 <CAGxFJbSp0cc4tB-tH4yF-NKQvNS0uLNQre4gPTg2GY4Ap23sBQ@mail.gmail.com>
Message-ID: <573c04e9-41da-0fc7-b71b-77ad25e4853a@sapo.pt>

Hello,

But that doesn't work in the OP's case:


sapply(.x, get)
#Error in FUN(X[[i]], ...) : object 'mtcars$disp' not found


Like you say, as.name(x$something) is not the name of an object.

Hope this helps,

Rui Barradas

?s 23:21 de 07/02/2022, Bert Gunter escreveu:
> I assume that the mtcars components were used only as an example, as you
> could convert them to a matrix via as.matrix(). Unfortunately, it was a bad
> choice: as.name("x$something") is not the name of 'something' in the data
> frame (or list) x. Moreover, as.name("x") does not point to an object x --
> as Rich indicated, it has to be evaluated to do so.
>> x<- 1:10
>> z <- as.name("x")
>> z
> x
>> length(z)
> [1] 1
>> eval(z)
>   [1]  1  2  3  4  5  6  7  8  9 10
> 
> But more to the point, I think you are attempting to drive from Brooklyn to
> New York City by way of Los Angeles. If I understand correctly, I think all
> you need is ?get:
> 
>> x <- runif(5)
>> y <- 1:5
>> z <- 21:25
>> nm <- c('x', 'y','z')
>> sapply(nm, get)
>                x y  z
> [1,] 0.99602479 1 21
> [2,] 0.97458756 2 22
> [3,] 0.09496625 3 23
> [4,] 0.91444550 4 24
> [5,] 0.68331484 5 25
> 
> Cheers,
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Feb 7, 2022 at 3:06 PM Richard M. Heiberger <rmh at temple.edu> wrote:
> 
>>> x <- c("mtcars$disp", "mtcars$hp", "mtcars$cyl")
>>> x
>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>> eval(parse(text=x))
>>   [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
>>> for (i in x) print(eval(parse(text=i)))
>>   [1] 160.0 160.0 108.0 258.0 360.0 225.0 360.0 146.7 140.8 167.6 167.6
>> 275.8 275.8 275.8 472.0 460.0 440.0  78.7  75.7  71.1 120.1 318.0
>> [23] 304.0 350.0 400.0  79.0 120.3  95.1 351.0 145.0 301.0 121.0
>>   [1] 110 110  93 110 175 105 245  62  95 123 123 180 180 180 205 215 230
>> 66  52  65  97 150 150 245 175  66  91 113 264 175 335 109
>>   [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
>>
>>
>>> On Feb 07, 2022, at 17:55, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>>>
>>>> .x
>>>
>>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb  8 00:46:31 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 7 Feb 2022 15:46:31 -0800
Subject: [R] [External] Convert a character string to variable names
In-Reply-To: <573c04e9-41da-0fc7-b71b-77ad25e4853a@sapo.pt>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <9E2C362A-E86B-4932-86FF-D4916F2F3C7C@temple.edu>
 <CAGxFJbSp0cc4tB-tH4yF-NKQvNS0uLNQre4gPTg2GY4Ap23sBQ@mail.gmail.com>
 <573c04e9-41da-0fc7-b71b-77ad25e4853a@sapo.pt>
Message-ID: <CAGxFJbQa5giNpo=FFpzD9EmxLk_CKZLwmvFoz+J7rokzL6VXrQ@mail.gmail.com>

Yes, I said that Rui. If she is really just trying to extract equal length
columns from a data frame or list by names(as strings), as I said,  then
none of this is necessary:
as.matrix(mtcars[, x])  ## does it

Or have I missed something?

Bert

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 7, 2022 at 3:36 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> But that doesn't work in the OP's case:
>
>
> sapply(.x, get)
> #Error in FUN(X[[i]], ...) : object 'mtcars$disp' not found
>
>
> Like you say, as.name(x$something) is not the name of an object.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 23:21 de 07/02/2022, Bert Gunter escreveu:
> > I assume that the mtcars components were used only as an example, as you
> > could convert them to a matrix via as.matrix(). Unfortunately, it was a
> bad
> > choice: as.name("x$something") is not the name of 'something' in the
> data
> > frame (or list) x. Moreover, as.name("x") does not point to an object x
> --
> > as Rich indicated, it has to be evaluated to do so.
> >> x<- 1:10
> >> z <- as.name("x")
> >> z
> > x
> >> length(z)
> > [1] 1
> >> eval(z)
> >   [1]  1  2  3  4  5  6  7  8  9 10
> >
> > But more to the point, I think you are attempting to drive from Brooklyn
> to
> > New York City by way of Los Angeles. If I understand correctly, I think
> all
> > you need is ?get:
> >
> >> x <- runif(5)
> >> y <- 1:5
> >> z <- 21:25
> >> nm <- c('x', 'y','z')
> >> sapply(nm, get)
> >                x y  z
> > [1,] 0.99602479 1 21
> > [2,] 0.97458756 2 22
> > [3,] 0.09496625 3 23
> > [4,] 0.91444550 4 24
> > [5,] 0.68331484 5 25
> >
> > Cheers,
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Feb 7, 2022 at 3:06 PM Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >
> >>> x <- c("mtcars$disp", "mtcars$hp", "mtcars$cyl")
> >>> x
> >> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> >>> eval(parse(text=x))
> >>   [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
> >>> for (i in x) print(eval(parse(text=i)))
> >>   [1] 160.0 160.0 108.0 258.0 360.0 225.0 360.0 146.7 140.8 167.6 167.6
> >> 275.8 275.8 275.8 472.0 460.0 440.0  78.7  75.7  71.1 120.1 318.0
> >> [23] 304.0 350.0 400.0  79.0 120.3  95.1 351.0 145.0 301.0 121.0
> >>   [1] 110 110  93 110 175 105 245  62  95 123 123 180 180 180 205 215
> 230
> >> 66  52  65  97 150 150 245 175  66  91 113 264 175 335 109
> >>   [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
> >>
> >>
> >>> On Feb 07, 2022, at 17:55, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >>>
> >>>> .x
> >>>
> >>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Tue Feb  8 01:05:26 2022
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Mon, 7 Feb 2022 17:05:26 -0700
Subject: [R] [External] Convert a character string to variable names
In-Reply-To: <CAGxFJbQa5giNpo=FFpzD9EmxLk_CKZLwmvFoz+J7rokzL6VXrQ@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <9E2C362A-E86B-4932-86FF-D4916F2F3C7C@temple.edu>
 <CAGxFJbSp0cc4tB-tH4yF-NKQvNS0uLNQre4gPTg2GY4Ap23sBQ@mail.gmail.com>
 <573c04e9-41da-0fc7-b71b-77ad25e4853a@sapo.pt>
 <CAGxFJbQa5giNpo=FFpzD9EmxLk_CKZLwmvFoz+J7rokzL6VXrQ@mail.gmail.com>
Message-ID: <CACxE24kEmh_O_U8kcUM2Z_nXqh_GAno34s+DwN9zjyJdePVdLw@mail.gmail.com>

Thanks to all!



On Mon, Feb 7, 2022 at 4:56 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Yes, I said that Rui. If she is really just trying to extract equal length
> columns from a data frame or list by names(as strings), as I said,  then
> none of this is necessary:
> as.matrix(mtcars[, x])  ## does it
>
> Or have I missed something?
>
> Bert
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Feb 7, 2022 at 3:36 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> > Hello,
> >
> > But that doesn't work in the OP's case:
> >
> >
> > sapply(.x, get)
> > #Error in FUN(X[[i]], ...) : object 'mtcars$disp' not found
> >
> >
> > Like you say, as.name(x$something) is not the name of an object.
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 23:21 de 07/02/2022, Bert Gunter escreveu:
> > > I assume that the mtcars components were used only as an example, as
> you
> > > could convert them to a matrix via as.matrix(). Unfortunately, it was a
> > bad
> > > choice: as.name("x$something") is not the name of 'something' in the
> > data
> > > frame (or list) x. Moreover, as.name("x") does not point to an object
> x
> > --
> > > as Rich indicated, it has to be evaluated to do so.
> > >> x<- 1:10
> > >> z <- as.name("x")
> > >> z
> > > x
> > >> length(z)
> > > [1] 1
> > >> eval(z)
> > >   [1]  1  2  3  4  5  6  7  8  9 10
> > >
> > > But more to the point, I think you are attempting to drive from
> Brooklyn
> > to
> > > New York City by way of Los Angeles. If I understand correctly, I think
> > all
> > > you need is ?get:
> > >
> > >> x <- runif(5)
> > >> y <- 1:5
> > >> z <- 21:25
> > >> nm <- c('x', 'y','z')
> > >> sapply(nm, get)
> > >                x y  z
> > > [1,] 0.99602479 1 21
> > > [2,] 0.97458756 2 22
> > > [3,] 0.09496625 3 23
> > > [4,] 0.91444550 4 24
> > > [5,] 0.68331484 5 25
> > >
> > > Cheers,
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> > and
> > > sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Mon, Feb 7, 2022 at 3:06 PM Richard M. Heiberger <rmh at temple.edu>
> > wrote:
> > >
> > >>> x <- c("mtcars$disp", "mtcars$hp", "mtcars$cyl")
> > >>> x
> > >> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> > >>> eval(parse(text=x))
> > >>   [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
> > >>> for (i in x) print(eval(parse(text=i)))
> > >>   [1] 160.0 160.0 108.0 258.0 360.0 225.0 360.0 146.7 140.8 167.6
> 167.6
> > >> 275.8 275.8 275.8 472.0 460.0 440.0  78.7  75.7  71.1 120.1 318.0
> > >> [23] 304.0 350.0 400.0  79.0 120.3  95.1 351.0 145.0 301.0 121.0
> > >>   [1] 110 110  93 110 175 105 245  62  95 123 123 180 180 180 205 215
> > 230
> > >> 66  52  65  97 150 150 245 175  66  91 113 264 175 335 109
> > >>   [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
> > >>
> > >>
> > >>> On Feb 07, 2022, at 17:55, Erin Hodgess <erinm.hodgess at gmail.com>
> > wrote:
> > >>>
> > >>>> .x
> > >>>
> > >>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Wed Feb  9 02:17:17 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 9 Feb 2022 14:17:17 +1300
Subject: [R] Convert a character string to variable names
In-Reply-To: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
Message-ID: <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>

"mtcars$disp" is not a variable name.
"mtcars" is a variable name, and
get("mtcars") will get the value of that variable
assign("mtcars", ~~whatever~~) will set it.
mtcars$disp is an *expression*,
where $ is an indexing operator
https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing
so what you want is
> mtcars <- list(cyl=4, disp=1.8)
> eval(parse(text="mtcars$disp"))
[1] 1.8

Though it's easy to do this, it's very seldom a good idea.
The combination of parse and eval can do ANYTHING, no matter
how disastrous.  Less powerful techniques are safer.
Where do these strings come from in the first place?
Why isn't it c("disp", "hp", "cyl")?

On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Hello!
>
> I have a character string that is a vector of variable names.  I would like
> to use those names to access the variables and create a matrix.
> I tried the following:
>
> > .x
>
> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>
> > .y <- NULL
>
> > for(i in 1:3) {
>
> + .y[i] <- c(as.name(.x[[i]]))
>
> + }
>
> > .y
>
> [[1]]
>
> `mtcars$disp`
>
>
> [[2]]
>
> `mtcars$hp`
>
>
> [[3]]
>
> `mtcars$cyl`
>
>
> But I am having trouble converting the variables in .y into a matrix.
>
>
> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>
>
> I have a feeling that it's something simple, and I'm just not seeing it.
>
>
> Thanks,
>
> Erin
>
>
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Wed Feb  9 02:45:39 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 9 Feb 2022 01:45:39 +0000
Subject: [R] Convert a character string to variable names
In-Reply-To: <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
Message-ID: <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>


I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).

Tim


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
Sent: Tuesday, February 8, 2022 8:17 PM
To: Erin Hodgess <erinm.hodgess at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Convert a character string to variable names

[External Email]

"mtcars$disp" is not a variable name.
"mtcars" is a variable name, and
get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
mtcars$disp is an *expression*,
where $ is an indexing operator
https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yfLPBhHxSlWk&e=
so what you want is
> mtcars <- list(cyl=4, disp=1.8)
> eval(parse(text="mtcars$disp"))
[1] 1.8

Though it's easy to do this, it's very seldom a good idea.
The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
Where do these strings come from in the first place?
Why isn't it c("disp", "hp", "cyl")?

On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Hello!
>
> I have a character string that is a vector of variable names.  I would 
> like to use those names to access the variables and create a matrix.
> I tried the following:
>
> > .x
>
> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>
> > .y <- NULL
>
> > for(i in 1:3) {
>
> + .y[i] <- c(as.name(.x[[i]]))
>
> + }
>
> > .y
>
> [[1]]
>
> `mtcars$disp`
>
>
> [[2]]
>
> `mtcars$hp`
>
>
> [[3]]
>
> `mtcars$cyl`
>
>
> But I am having trouble converting the variables in .y into a matrix.
>
>
> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>
>
> I have a feeling that it's something simple, and I'm just not seeing it.
>
>
> Thanks,
>
> Erin
>
>
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5
> -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
> 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Feb  9 04:09:36 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 08 Feb 2022 19:09:36 -0800
Subject: [R] Convert a character string to variable names
In-Reply-To: <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>

A variable in R can refer to many things, but it cannot be an element of a vector. It absolutely _can_ refer to a list, a list of lists, a function, an environment, and any of the various kinds of atomic vectors that you seem to think of as variables. (R does _not_ name individual elements of vectors, unlike many other languages.)

The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.

R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.

I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.

On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>
>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>
>Tim
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
>Sent: Tuesday, February 8, 2022 8:17 PM
>To: Erin Hodgess <erinm.hodgess at gmail.com>
>Cc: r-help at r-project.org
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>
>"mtcars$disp" is not a variable name.
>"mtcars" is a variable name, and
>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>mtcars$disp is an *expression*,
>where $ is an indexing operator
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yfLPBhHxSlWk&e=
>so what you want is
>> mtcars <- list(cyl=4, disp=1.8)
>> eval(parse(text="mtcars$disp"))
>[1] 1.8
>
>Though it's easy to do this, it's very seldom a good idea.
>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>Where do these strings come from in the first place?
>Why isn't it c("disp", "hp", "cyl")?
>
>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
>> Hello!
>>
>> I have a character string that is a vector of variable names.  I would 
>> like to use those names to access the variables and create a matrix.
>> I tried the following:
>>
>> > .x
>>
>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>
>> > .y <- NULL
>>
>> > for(i in 1:3) {
>>
>> + .y[i] <- c(as.name(.x[[i]]))
>>
>> + }
>>
>> > .y
>>
>> [[1]]
>>
>> `mtcars$disp`
>>
>>
>> [[2]]
>>
>> `mtcars$hp`
>>
>>
>> [[3]]
>>
>> `mtcars$cyl`
>>
>>
>> But I am having trouble converting the variables in .y into a matrix.
>>
>>
>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>
>>
>> I have a feeling that it's something simple, and I'm just not seeing it.
>>
>>
>> Thanks,
>>
>> Erin
>>
>>
>>
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5
>> -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
>> 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From tebert @end|ng |rom u||@edu  Wed Feb  9 05:05:12 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 9 Feb 2022 04:05:12 +0000
Subject: [R] Convert a character string to variable names
In-Reply-To: <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
Message-ID: <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>

"A variable in R can refer to many things, ..." I agree.
"It absolutely _can_ refer to a list, ..." I partly agree. In R as a programming language I agree. In R as a statistical analysis tool then only partly. Typically one would need to limit the list so each variable would be of the same length and all values within the variable be of the same data type (integer, real, factor, character). As a programmer yes, as a statistician not really unless you always qualify the type of list considered and that gets tiresome.

R does name individual elements using numeric place names: hence df[row, column]. Each element must have a unique address, and that is true in all computer languages.

A dataframe is a list of columns of the same length containing the same data type within a column. 

mtcars$disp does not have a value (a value is one number). With 32 elements I can calculate a mean and the mean is a value. 32 numbers is not a value. I suppose a single value could be the starting memory address of the name, but I don't see how that distinction helps unless one is doing Assembly or Machine language programming. 

I have never used get(), so I will keep that in mind. I agree that it makes life much easier to enter the data in the way it will be analyzed. 


 

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Tuesday, February 8, 2022 10:10 PM
To: r-help at r-project.org; Ebert,Timothy Aaron <tebert at ufl.edu>; Richard O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Convert a character string to variable names

[External Email]

A variable in R can refer to many things, but it cannot be an element of a vector. It absolutely _can_ refer to a list, a list of lists, a function, an environment, and any of the various kinds of atomic vectors that you seem to think of as variables. (R does _not_ name individual elements of vectors, unlike many other languages.)

The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.

R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.

I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.

On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>
>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>
>Tim
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard 
>O'Keefe
>Sent: Tuesday, February 8, 2022 8:17 PM
>To: Erin Hodgess <erinm.hodgess at gmail.com>
>Cc: r-help at r-project.org
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>
>"mtcars$disp" is not a variable name.
>"mtcars" is a variable name, and
>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>mtcars$disp is an *expression*,
>where $ is an indexing operator
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
>rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
>-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
>y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
>LPBhHxSlWk&e=
>so what you want is
>> mtcars <- list(cyl=4, disp=1.8)
>> eval(parse(text="mtcars$disp"))
>[1] 1.8
>
>Though it's easy to do this, it's very seldom a good idea.
>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>Where do these strings come from in the first place?
>Why isn't it c("disp", "hp", "cyl")?
>
>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
>> Hello!
>>
>> I have a character string that is a vector of variable names.  I 
>> would like to use those names to access the variables and create a matrix.
>> I tried the following:
>>
>> > .x
>>
>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>
>> > .y <- NULL
>>
>> > for(i in 1:3) {
>>
>> + .y[i] <- c(as.name(.x[[i]]))
>>
>> + }
>>
>> > .y
>>
>> [[1]]
>>
>> `mtcars$disp`
>>
>>
>> [[2]]
>>
>> `mtcars$hp`
>>
>>
>> [[3]]
>>
>> `mtcars$cyl`
>>
>>
>> But I am having trouble converting the variables in .y into a matrix.
>>
>>
>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>
>>
>> I have a feeling that it's something simple, and I'm just not seeing it.
>>
>>
>> Thanks,
>>
>> Erin
>>
>>
>>
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
>> l 
>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>> s
>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
>> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
>> r 
>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
>> A 
>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
>> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
>D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>PLEASE do read the posting guide 
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
>mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
>iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
>PLEASE do read the posting guide 
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
>ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Feb  9 05:26:30 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 08 Feb 2022 20:26:30 -0800
Subject: [R] Convert a character string to variable names
In-Reply-To: <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <3C9D657C-3F27-4AF8-8697-72D26FD8A0E8@dcn.davis.ca.us>

Your definition of "value" is inappropriately limited. A data frame is a value. It is not a numeric value, but it is a value. See 3.1.3 in the R Language Definition document.

Likewise, an atomic vector is a value. All of the elements of the vector together are in fact a value. Not just the individual elements (which don't stand on their own anyway... a scalar is really a length 1 vector). So yes, mtcars$disp does refer to a value.

As to whether you get tired when using variable length elements in a list, that is your problem. Lots of data are passed through APIs in irregular lists.

On February 8, 2022 8:05:12 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>"A variable in R can refer to many things, ..." I agree.
>"It absolutely _can_ refer to a list, ..." I partly agree. In R as a programming language I agree. In R as a statistical analysis tool then only partly. Typically one would need to limit the list so each variable would be of the same length and all values within the variable be of the same data type (integer, real, factor, character). As a programmer yes, as a statistician not really unless you always qualify the type of list considered and that gets tiresome.
>
>R does name individual elements using numeric place names: hence df[row, column]. Each element must have a unique address, and that is true in all computer languages.
>
>A dataframe is a list of columns of the same length containing the same data type within a column. 
>
>mtcars$disp does not have a value (a value is one number). With 32 elements I can calculate a mean and the mean is a value. 32 numbers is not a value. I suppose a single value could be the starting memory address of the name, but I don't see how that distinction helps unless one is doing Assembly or Machine language programming. 
>
>I have never used get(), so I will keep that in mind. I agree that it makes life much easier to enter the data in the way it will be analyzed. 
>
>
> 
>
>-----Original Message-----
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
>Sent: Tuesday, February 8, 2022 10:10 PM
>To: r-help at r-project.org; Ebert,Timothy Aaron <tebert at ufl.edu>; Richard O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
>Cc: r-help at r-project.org
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>
>A variable in R can refer to many things, but it cannot be an element of a vector. It absolutely _can_ refer to a list, a list of lists, a function, an environment, and any of the various kinds of atomic vectors that you seem to think of as variables. (R does _not_ name individual elements of vectors, unlike many other languages.)
>
>The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.
>
>R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.
>
>I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.
>
>On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>>
>>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>>
>>Tim
>>
>>
>>-----Original Message-----
>>From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard 
>>O'Keefe
>>Sent: Tuesday, February 8, 2022 8:17 PM
>>To: Erin Hodgess <erinm.hodgess at gmail.com>
>>Cc: r-help at r-project.org
>>Subject: Re: [R] Convert a character string to variable names
>>
>>[External Email]
>>
>>"mtcars$disp" is not a variable name.
>>"mtcars" is a variable name, and
>>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>>mtcars$disp is an *expression*,
>>where $ is an indexing operator
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
>>rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
>>-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
>>y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
>>LPBhHxSlWk&e=
>>so what you want is
>>> mtcars <- list(cyl=4, disp=1.8)
>>> eval(parse(text="mtcars$disp"))
>>[1] 1.8
>>
>>Though it's easy to do this, it's very seldom a good idea.
>>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>>Where do these strings come from in the first place?
>>Why isn't it c("disp", "hp", "cyl")?
>>
>>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>>
>>> Hello!
>>>
>>> I have a character string that is a vector of variable names.  I 
>>> would like to use those names to access the variables and create a matrix.
>>> I tried the following:
>>>
>>> > .x
>>>
>>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>>
>>> > .y <- NULL
>>>
>>> > for(i in 1:3) {
>>>
>>> + .y[i] <- c(as.name(.x[[i]]))
>>>
>>> + }
>>>
>>> > .y
>>>
>>> [[1]]
>>>
>>> `mtcars$disp`
>>>
>>>
>>> [[2]]
>>>
>>> `mtcars$hp`
>>>
>>>
>>> [[3]]
>>>
>>> `mtcars$cyl`
>>>
>>>
>>> But I am having trouble converting the variables in .y into a matrix.
>>>
>>>
>>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>>
>>>
>>> I have a feeling that it's something simple, and I'm just not seeing it.
>>>
>>>
>>> Thanks,
>>>
>>> Erin
>>>
>>>
>>>
>>>
>>> Erin Hodgess, PhD
>>> mailto: erinm.hodgess at gmail.com
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
>>> l 
>>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>>> s
>>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
>>> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>>> PLEASE do read the posting guide
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
>>> r 
>>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
>>> A 
>>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
>>> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>        [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>>sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
>>D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>>PLEASE do read the posting guide 
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
>>mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>>an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>>sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
>>iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
>>PLEASE do read the posting guide 
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>>_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
>>ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From tebert @end|ng |rom u||@edu  Wed Feb  9 12:33:35 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 9 Feb 2022 11:33:35 +0000
Subject: [R] Convert a character string to variable names
In-Reply-To: <3C9D657C-3F27-4AF8-8697-72D26FD8A0E8@dcn.davis.ca.us>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <3C9D657C-3F27-4AF8-8697-72D26FD8A0E8@dcn.davis.ca.us>
Message-ID: <BN6PR2201MB1553AB6243B7FEB47219C1CECF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>

Section 3.1.3 is about function calls. It does not have the word value anywhere https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf. 

If a data frame can have a value, what is that value? If I have a data frame named df, the value of df cannot be df. That would be a circular definition.



-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Tuesday, February 8, 2022 11:27 PM
To: Ebert,Timothy Aaron <tebert at ufl.edu>; r-help at r-project.org; Richard O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
Subject: RE: [R] Convert a character string to variable names

[External Email]

Your definition of "value" is inappropriately limited. A data frame is a value. It is not a numeric value, but it is a value. See 3.1.3 in the R Language Definition document.

Likewise, an atomic vector is a value. All of the elements of the vector together are in fact a value. Not just the individual elements (which don't stand on their own anyway... a scalar is really a length 1 vector). So yes, mtcars$disp does refer to a value.

As to whether you get tired when using variable length elements in a list, that is your problem. Lots of data are passed through APIs in irregular lists.

On February 8, 2022 8:05:12 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>"A variable in R can refer to many things, ..." I agree.
>"It absolutely _can_ refer to a list, ..." I partly agree. In R as a programming language I agree. In R as a statistical analysis tool then only partly. Typically one would need to limit the list so each variable would be of the same length and all values within the variable be of the same data type (integer, real, factor, character). As a programmer yes, as a statistician not really unless you always qualify the type of list considered and that gets tiresome.
>
>R does name individual elements using numeric place names: hence df[row, column]. Each element must have a unique address, and that is true in all computer languages.
>
>A dataframe is a list of columns of the same length containing the same data type within a column.
>
>mtcars$disp does not have a value (a value is one number). With 32 elements I can calculate a mean and the mean is a value. 32 numbers is not a value. I suppose a single value could be the starting memory address of the name, but I don't see how that distinction helps unless one is doing Assembly or Machine language programming.
>
>I have never used get(), so I will keep that in mind. I agree that it makes life much easier to enter the data in the way it will be analyzed.
>
>
>
>
>-----Original Message-----
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Tuesday, February 8, 2022 10:10 PM
>To: r-help at r-project.org; Ebert,Timothy Aaron <tebert at ufl.edu>; Richard 
>O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
>Cc: r-help at r-project.org
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>
>A variable in R can refer to many things, but it cannot be an element 
>of a vector. It absolutely _can_ refer to a list, a list of lists, a 
>function, an environment, and any of the various kinds of atomic 
>vectors that you seem to think of as variables. (R does _not_ name 
>individual elements of vectors, unlike many other languages.)
>
>The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.
>
>R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.
>
>I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.
>
>On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>>
>>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>>
>>Tim
>>
>>
>>-----Original Message-----
>>From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard 
>>O'Keefe
>>Sent: Tuesday, February 8, 2022 8:17 PM
>>To: Erin Hodgess <erinm.hodgess at gmail.com>
>>Cc: r-help at r-project.org
>>Subject: Re: [R] Convert a character string to variable names
>>
>>[External Email]
>>
>>"mtcars$disp" is not a variable name.
>>"mtcars" is a variable name, and
>>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>>mtcars$disp is an *expression*,
>>where $ is an indexing operator
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.
>>o 
>>rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWY
>>x 
>>-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSS
>>W 
>>y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1y
>>f
>>LPBhHxSlWk&e=
>>so what you want is
>>> mtcars <- list(cyl=4, disp=1.8)
>>> eval(parse(text="mtcars$disp"))
>>[1] 1.8
>>
>>Though it's easy to do this, it's very seldom a good idea.
>>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>>Where do these strings come from in the first place?
>>Why isn't it c("disp", "hp", "cyl")?
>>
>>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>>
>>> Hello!
>>>
>>> I have a character string that is a vector of variable names.  I 
>>> would like to use those names to access the variables and create a matrix.
>>> I tried the following:
>>>
>>> > .x
>>>
>>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>>
>>> > .y <- NULL
>>>
>>> > for(i in 1:3) {
>>>
>>> + .y[i] <- c(as.name(.x[[i]]))
>>>
>>> + }
>>>
>>> > .y
>>>
>>> [[1]]
>>>
>>> `mtcars$disp`
>>>
>>>
>>> [[2]]
>>>
>>> `mtcars$hp`
>>>
>>>
>>> [[3]]
>>>
>>> `mtcars$cyl`
>>>
>>>
>>> But I am having trouble converting the variables in .y into a matrix.
>>>
>>>
>>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>>
>>>
>>> I have a feeling that it's something simple, and I'm just not seeing it.
>>>
>>>
>>> Thanks,
>>>
>>> Erin
>>>
>>>
>>>
>>>
>>> Erin Hodgess, PhD
>>> mailto: erinm.hodgess at gmail.com
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
>>> i
>>> l
>>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
>>> A
>>> s
>>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
>>> n
>>> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>>> PLEASE do read the posting guide
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.
>>> o
>>> r
>>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kV
>>> e
>>> A
>>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVq
>>> y n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>        [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>m 
>>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>z 
>>sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
>>m D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>>PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>g 
>>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
>>R 
>>zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-
>>f mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>m 
>>an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>z 
>>sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
>>c iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
>>PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>g 
>>_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
>>R 
>>zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVD
>>F ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

--
Sent from my phone. Please excuse my brevity.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Feb  9 14:21:21 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 09 Feb 2022 05:21:21 -0800
Subject: [R] Convert a character string to variable names
In-Reply-To: <BN6PR2201MB1553AB6243B7FEB47219C1CECF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <3C9D657C-3F27-4AF8-8697-72D26FD8A0E8@dcn.davis.ca.us>
 <BN6PR2201MB1553AB6243B7FEB47219C1CECF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <B5FF8615-68F5-4194-A6B9-847A6AF653B2@dcn.davis.ca.us>

Sorry, I had an off-by-one error in looking up the citation... should have been 3.1.2.

A coordinate (3,4) is a value, different than (4,3). A vector of 32 elements like 1:32 is also a value. Anything that is looked up using a name can be a value... for a data frame it is all of the columns with all of the elements and the column names therein viewed together. The symbol you use to refer to the data frame is not part of its value, as df2 <- df creates another name for that specific value. (In meta-programming df and df2 can be symbol-type values, but in normal programming they are variable names, distinctly different than values.)

On February 9, 2022 3:33:35 AM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>Section 3.1.3 is about function calls. It does not have the word value anywhere https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf. 
>
>If a data frame can have a value, what is that value? If I have a data frame named df, the value of df cannot be df. That would be a circular definition.
>
>
>
>-----Original Message-----
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
>Sent: Tuesday, February 8, 2022 11:27 PM
>To: Ebert,Timothy Aaron <tebert at ufl.edu>; r-help at r-project.org; Richard O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
>Subject: RE: [R] Convert a character string to variable names
>
>[External Email]
>
>Your definition of "value" is inappropriately limited. A data frame is a value. It is not a numeric value, but it is a value. See 3.1.3 in the R Language Definition document.
>
>Likewise, an atomic vector is a value. All of the elements of the vector together are in fact a value. Not just the individual elements (which don't stand on their own anyway... a scalar is really a length 1 vector). So yes, mtcars$disp does refer to a value.
>
>As to whether you get tired when using variable length elements in a list, that is your problem. Lots of data are passed through APIs in irregular lists.
>
>On February 8, 2022 8:05:12 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>>"A variable in R can refer to many things, ..." I agree.
>>"It absolutely _can_ refer to a list, ..." I partly agree. In R as a programming language I agree. In R as a statistical analysis tool then only partly. Typically one would need to limit the list so each variable would be of the same length and all values within the variable be of the same data type (integer, real, factor, character). As a programmer yes, as a statistician not really unless you always qualify the type of list considered and that gets tiresome.
>>
>>R does name individual elements using numeric place names: hence df[row, column]. Each element must have a unique address, and that is true in all computer languages.
>>
>>A dataframe is a list of columns of the same length containing the same data type within a column.
>>
>>mtcars$disp does not have a value (a value is one number). With 32 elements I can calculate a mean and the mean is a value. 32 numbers is not a value. I suppose a single value could be the starting memory address of the name, but I don't see how that distinction helps unless one is doing Assembly or Machine language programming.
>>
>>I have never used get(), so I will keep that in mind. I agree that it makes life much easier to enter the data in the way it will be analyzed.
>>
>>
>>
>>
>>-----Original Message-----
>>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>Sent: Tuesday, February 8, 2022 10:10 PM
>>To: r-help at r-project.org; Ebert,Timothy Aaron <tebert at ufl.edu>; Richard 
>>O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
>>Cc: r-help at r-project.org
>>Subject: Re: [R] Convert a character string to variable names
>>
>>[External Email]
>>
>>A variable in R can refer to many things, but it cannot be an element 
>>of a vector. It absolutely _can_ refer to a list, a list of lists, a 
>>function, an environment, and any of the various kinds of atomic 
>>vectors that you seem to think of as variables. (R does _not_ name 
>>individual elements of vectors, unlike many other languages.)
>>
>>The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.
>>
>>R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.
>>
>>I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.
>>
>>On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>>>
>>>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>>>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>>>
>>>Tim
>>>
>>>
>>>-----Original Message-----
>>>From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard 
>>>O'Keefe
>>>Sent: Tuesday, February 8, 2022 8:17 PM
>>>To: Erin Hodgess <erinm.hodgess at gmail.com>
>>>Cc: r-help at r-project.org
>>>Subject: Re: [R] Convert a character string to variable names
>>>
>>>[External Email]
>>>
>>>"mtcars$disp" is not a variable name.
>>>"mtcars" is a variable name, and
>>>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>>>mtcars$disp is an *expression*,
>>>where $ is an indexing operator
>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.
>>>o 
>>>rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWY
>>>x 
>>>-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSS
>>>W 
>>>y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1y
>>>f
>>>LPBhHxSlWk&e=
>>>so what you want is
>>>> mtcars <- list(cyl=4, disp=1.8)
>>>> eval(parse(text="mtcars$disp"))
>>>[1] 1.8
>>>
>>>Though it's easy to do this, it's very seldom a good idea.
>>>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>>>Where do these strings come from in the first place?
>>>Why isn't it c("disp", "hp", "cyl")?
>>>
>>>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>>>
>>>> Hello!
>>>>
>>>> I have a character string that is a vector of variable names.  I 
>>>> would like to use those names to access the variables and create a matrix.
>>>> I tried the following:
>>>>
>>>> > .x
>>>>
>>>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>>>
>>>> > .y <- NULL
>>>>
>>>> > for(i in 1:3) {
>>>>
>>>> + .y[i] <- c(as.name(.x[[i]]))
>>>>
>>>> + }
>>>>
>>>> > .y
>>>>
>>>> [[1]]
>>>>
>>>> `mtcars$disp`
>>>>
>>>>
>>>> [[2]]
>>>>
>>>> `mtcars$hp`
>>>>
>>>>
>>>> [[3]]
>>>>
>>>> `mtcars$cyl`
>>>>
>>>>
>>>> But I am having trouble converting the variables in .y into a matrix.
>>>>
>>>>
>>>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>>>
>>>>
>>>> I have a feeling that it's something simple, and I'm just not seeing it.
>>>>
>>>>
>>>> Thanks,
>>>>
>>>> Erin
>>>>
>>>>
>>>>
>>>>
>>>> Erin Hodgess, PhD
>>>> mailto: erinm.hodgess at gmail.com
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
>>>> i
>>>> l
>>>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
>>>> A
>>>> s
>>>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
>>>> n
>>>> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.
>>>> o
>>>> r
>>>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kV
>>>> e
>>>> A
>>>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVq
>>>> y n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>>m 
>>>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>>z 
>>>sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
>>>m D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>>>PLEASE do read the posting guide
>>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>>g 
>>>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
>>>R 
>>>zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-
>>>f mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>>m 
>>>an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>>z 
>>>sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
>>>c iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
>>>PLEASE do read the posting guide
>>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>>g 
>>>_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
>>>R 
>>>zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVD
>>>F ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>--
>>Sent from my phone. Please excuse my brevity.
>
>--
>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From jbrom@gh|n @end|ng |rom u@g@@gov  Wed Feb  9 23:00:40 2022
From: jbrom@gh|n @end|ng |rom u@g@@gov (Bromaghin, Jeffrey F)
Date: Wed, 9 Feb 2022 22:00:40 +0000
Subject: [R] Question About lm()
Message-ID: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>

Hello,

I was constructing a simple linear model with one categorical (3-levels) and one quantitative predictor variable for a colleague. I estimated model parameters with and without an intercept, sometimes called reference cell coding and cell means coding.

Model 1: yResp ~ -1 + xCat + xCont
Model 2: yResp ~ xCat + xCont

These models are equivalent and the estimated coefficients come out fine, but the R-squared and F statistics returned by summary() differ markedly. I spent some time looking at the code for both lm() and summary.lm() but did not find the source of the difference. aov() and anova() results also differ, so I suspect the issue involves how the sums of squares are being computed. I've also spent some time trying to search online for information on this, without success. I haven't used lm() for quite a while, but my memory is that these differences didn't occur in the distant past when I was teaching.

Thanks in advance for any insights you might have,
Jeff

Jeffrey F. Bromaghin
Research Statistician
USGS Alaska Science Center
907-786-7086
Jeffrey Bromaghin, Ph.D. | U.S. Geological Survey (usgs.gov)<https://www.usgs.gov/staff-profiles/jeffrey-bromaghin>
Ecosystems Analytics | U.S. Geological Survey (usgs.gov)<https://www.usgs.gov/centers/alaska-science-center/science/ecosystems-analytics>


	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Feb 10 08:16:13 2022
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 9 Feb 2022 23:16:13 -0800
Subject: [R] Question About lm()
In-Reply-To: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>
References: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>
Message-ID: <A11ACE29-9CB1-4464-929B-727A709BB9E0@comcast.net>

The models are NOT equivalent. Why would you?ll think they were?

? 
David

Sent from my iPhone

> On Feb 9, 2022, at 11:10 PM, Bromaghin, Jeffrey F via R-help <r-help at r-project.org> wrote:
> 
> ?Hello,
> 
> I was constructing a simple linear model with one categorical (3-levels) and one quantitative predictor variable for a colleague. I estimated model parameters with and without an intercept, sometimes called reference cell coding and cell means coding.
> 
> Model 1: yResp ~ -1 + xCat + xCont
> Model 2: yResp ~ xCat + xCont
> 
> These models are equivalent and the estimated coefficients come out fine, but the R-squared and F statistics returned by summary() differ markedly. I spent some time looking at the code for both lm() and summary.lm() but did not find the source of the difference. aov() and anova() results also differ, so I suspect the issue involves how the sums of squares are being computed. I've also spent some time trying to search online for information on this, without success. I haven't used lm() for quite a while, but my memory is that these differences didn't occur in the distant past when I was teaching.
> 
> Thanks in advance for any insights you might have,
> Jeff
> 
> Jeffrey F. Bromaghin
> Research Statistician
> USGS Alaska Science Center
> 907-786-7086
> Jeffrey Bromaghin, Ph.D. | U.S. Geological Survey (usgs.gov)<https://www.usgs.gov/staff-profiles/jeffrey-bromaghin>
> Ecosystems Analytics | U.S. Geological Survey (usgs.gov)<https://www.usgs.gov/centers/alaska-science-center/science/ecosystems-analytics>
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Feb 10 08:20:41 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 10 Feb 2022 10:20:41 +0300
Subject: [R] Question About lm()
In-Reply-To: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>
References: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>
Message-ID: <20220210102041.30699c73@Tarkus>

On Wed, 9 Feb 2022 22:00:40 +0000
"Bromaghin, Jeffrey F via R-help" <r-help at r-project.org> wrote:

> These models are equivalent and the estimated coefficients come out
> fine, but the R-squared and F statistics returned by summary() differ
> markedly.

Is the mean of yResp far from zero? Here's what summary.lm says about
that:

>> r.squared: R^2, the ?fraction of variance explained by the model?,
>> 
>>               R^2 = 1 - Sum(R[i]^2) / Sum((y[i] - y*)^2),
>> 
>>            where y* is the mean of y[i] if there is an intercept and
>>            zero otherwise.

-- 
Best regards,
Ivan


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Feb 10 08:28:40 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 10 Feb 2022 07:28:40 +0000
Subject: [R] Question About lm()
In-Reply-To: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>
References: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>
Message-ID: <e53791b96d01407d977b42198a81a4af@SRVEXCHCM1301.precheza.cz>

Hi

Is it enough for explanation?

https://stats.stackexchange.com/questions/26176/removal-of-statistically-sig
nificant-intercept-term-increases-r2-in-linear-mo

https://stackoverflow.com/questions/57415793/r-squared-in-lm-for-zero-interc
ept-model

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bromaghin,
Jeffrey
> F via R-help
> Sent: Wednesday, February 9, 2022 11:01 PM
> To: r-help at r-project.org
> Subject: [R] Question About lm()
> 
> Hello,
> 
> I was constructing a simple linear model with one categorical (3-levels)
and one
> quantitative predictor variable for a colleague. I estimated model
parameters
> with and without an intercept, sometimes called reference cell coding and
cell
> means coding.
> 
> Model 1: yResp ~ -1 + xCat + xCont
> Model 2: yResp ~ xCat + xCont
> 
> These models are equivalent and the estimated coefficients come out fine,
but
> the R-squared and F statistics returned by summary() differ markedly. I
spent
> some time looking at the code for both lm() and summary.lm() but did not
find
> the source of the difference. aov() and anova() results also differ, so I
suspect
> the issue involves how the sums of squares are being computed. I've also
spent
> some time trying to search online for information on this, without
success. I
> haven't used lm() for quite a while, but my memory is that these
differences
> didn't occur in the distant past when I was teaching.
> 
> Thanks in advance for any insights you might have, Jeff
> 
> Jeffrey F. Bromaghin
> Research Statistician
> USGS Alaska Science Center
> 907-786-7086
> Jeffrey Bromaghin, Ph.D. | U.S. Geological Survey
> (usgs.gov)<https://www.usgs.gov/staff-profiles/jeffrey-bromaghin>
> Ecosystems Analytics | U.S. Geological Survey
> (usgs.gov)<https://www.usgs.gov/centers/alaska-science-
> center/science/ecosystems-analytics>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Feb 10 22:08:30 2022
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 11 Feb 2022 10:08:30 +1300
Subject: [R] Question About lm()
In-Reply-To: <A11ACE29-9CB1-4464-929B-727A709BB9E0@comcast.net>
References: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>
 <A11ACE29-9CB1-4464-929B-727A709BB9E0@comcast.net>
Message-ID: <20220211100830.4fa69236@rolf-Latitude-E7470>


On Wed, 9 Feb 2022 23:16:13 -0800
David Winsemius <dwinsemius at comcast.net> wrote:

> The models are NOT equivalent. Why would you?ll think they were?

'Scuse me, David, but they *are* "equivalent".  They are simply
different parametrisations of the same model.  *However* the different
parametrisations imply, according to the conventions of lm(), different
*null* models.

For yResp ~ xCat + xCont, the null model is yResp ~ 1.

For yResp ~ -1 + xCat + xCont, the null model is yResp ~ 0.

For the first null model, the residual sum of squares is
ssr1 = sum((yResp-mean(yResp))^2).

For the second null model, the residual sum of squares is
ssr2 = sum(yResp^2).

Thus for the first parametrisation one gets

RSquared = 1 - ssr1/ssr

and for the second parametrisation one gets

RSquared = 1 - ssr2/ssr

in both cases "ssr" is the sum of squares of the residuals from the
full model (which is of course the same in both cases).

I hope that this clarifies things a bit for the OP.

One further comment:  RSquared is a bit of a dubious concept;  it is
particularly dubious for models with no intercept.  Caveat utilitor.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From or|o|eb@|t|more @end|ng |rom gm@||@com  Thu Feb 10 22:13:40 2022
From: or|o|eb@|t|more @end|ng |rom gm@||@com (Adrian Johnson)
Date: Thu, 10 Feb 2022 16:13:40 -0500
Subject: [R] Mclust - data type
Message-ID: <CAL2fYnMcKwZCe1j-Hxsy6FiSnhrnz=pF9Tn-UgdbA1y-Bq8mrQ@mail.gmail.com>

Dear Mclust users,
Pardon me for naive question.  Mclust defines clustering based on
parameterized finite Gaussian mixture models.  The diabetes example data in
vignette vectors glucose,.insulin and sspg are not exactly appear to be
following a Gaussian distribution.
I like to use mclust to cluster my data with two different observations. In
my data, there are two observations. One observation follow a std.normal
with right extended tail and second observation follow a negative binomial
distribution.  Is it appropriate to use mclustBIC Mclust and
mclustBootstrapLRT?  and  If it is not an appropriate method and  package,
which package could help for my data.
Thanks
Adrian

	[[alternative HTML version deleted]]


From jbrom@gh|n @end|ng |rom u@g@@gov  Thu Feb 10 22:50:04 2022
From: jbrom@gh|n @end|ng |rom u@g@@gov (Bromaghin, Jeffrey F)
Date: Thu, 10 Feb 2022 21:50:04 +0000
Subject: [R] [EXTERNAL] Re:  Question About lm()
In-Reply-To: <20220211100830.4fa69236@rolf-Latitude-E7470>
References: <SA1PR09MB7806EEEA1509B826E5DFD619A92E9@SA1PR09MB7806.namprd09.prod.outlook.com>
 <A11ACE29-9CB1-4464-929B-727A709BB9E0@comcast.net>
 <20220211100830.4fa69236@rolf-Latitude-E7470>
Message-ID: <SA1PR09MB78063D67DA0CBD86BE846654A92F9@SA1PR09MB7806.namprd09.prod.outlook.com>

Rolf,

Yes, that is what is happening. I thought that lm() recognized the presence of a categorical variable as a replacement, if you will, for the intercept, but either my memory is faulty or the behavior of the function changed somewhere along the way.

Thank you,
Jeff

-----Original Message-----
From: Rolf Turner <r.turner at auckland.ac.nz> 
Sent: Thursday, February 10, 2022 12:09 PM
To: David Winsemius <dwinsemius at comcast.net>; r-help at r-project.org
Cc: Bromaghin, Jeffrey F <jbromaghin at usgs.gov>
Subject: [EXTERNAL] Re: [R] Question About lm()



 This email has been received from outside of DOI - Use caution before clicking on links, opening attachments, or responding.



On Wed, 9 Feb 2022 23:16:13 -0800
David Winsemius <dwinsemius at comcast.net> wrote:

> The models are NOT equivalent. Why would you?ll think they were?

'Scuse me, David, but they *are* "equivalent".  They are simply different parametrisations of the same model.  *However* the different parametrisations imply, according to the conventions of lm(), different
*null* models.

For yResp ~ xCat + xCont, the null model is yResp ~ 1.

For yResp ~ -1 + xCat + xCont, the null model is yResp ~ 0.

For the first null model, the residual sum of squares is
ssr1 = sum((yResp-mean(yResp))^2).

For the second null model, the residual sum of squares is
ssr2 = sum(yResp^2).

Thus for the first parametrisation one gets

RSquared = 1 - ssr1/ssr

and for the second parametrisation one gets

RSquared = 1 - ssr2/ssr

in both cases "ssr" is the sum of squares of the residuals from the full model (which is of course the same in both cases).

I hope that this clarifies things a bit for the OP.

One further comment:  RSquared is a bit of a dubious concept;  it is particularly dubious for models with no intercept.  Caveat utilitor.

cheers,

Rolf

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

From r@oknz @end|ng |rom gm@||@com  Fri Feb 11 06:10:15 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 11 Feb 2022 18:10:15 +1300
Subject: [R] Convert a character string to variable names
In-Reply-To: <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CABcYAdJGhuCBru_7QHxT_uM09YbhzZTh8XmQK2YvAsd_cR_xKQ@mail.gmail.com>

Yes, in the expression mtcars$disp mtcars is a variable name
(and the value of that variable should be a list or data.frame
or something of the sort) and $disp is an indexing operation
that could also be written mtcars[["disp"]].

When you use mtcars$disp, you are necessarily using mtcars as
a variable.  The point was that there is no variable called
mtcars$disp.

The question remains: why are you doing this?  If you had
x <- c("mtcars", "trucks", "subs")
y <- c("disp", "load", "depth")
you could do
lapply(1:3, function (i) get(x[i])[[y[i]]])
in which get(x[2]) returns the data.frame that is the value
of trucks and trucks[["load"]] returns the $load column.
For that matter, you could have
x <- list(mtcars, trucks, subs)
lapply(1:3, function(i) x[i][[y[i]]])

I want to understand what the circumstances are that make
pasting the variable name and the column name together
more appropriate than keeping the two separate.

I want to understand whether the table name just *happened*
to be the same every time in your example or whether it
*had* to be the same.

What's actually going on here?


On Wed, 9 Feb 2022 at 14:45, Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

>
> I had thought that mtcars in "mtcars$disp" was the name of a dataframe and
> that "disp" was the name of a column in the dataframe. If I would make a
> model like horse power = displacement then "disp" would be a variable in
> the model and I can find values for this variable in the "disp" column in
> the "mtcars" dataframe. I am not sure how I would use "mtcars" as a
> variable.
> "mtcars$disp" has no specific value, though it will have a specific value
> for any given row of data (assuming rows are observations).
>
> Tim
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
> Sent: Tuesday, February 8, 2022 8:17 PM
> To: Erin Hodgess <erinm.hodgess at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Convert a character string to variable names
>
> [External Email]
>
> "mtcars$disp" is not a variable name.
> "mtcars" is a variable name, and
> get("mtcars") will get the value of that variable assign("mtcars",
> ~~whatever~~) will set it.
> mtcars$disp is an *expression*,
> where $ is an indexing operator
>
> https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yfLPBhHxSlWk&e=
> so what you want is
> > mtcars <- list(cyl=4, disp=1.8)
> > eval(parse(text="mtcars$disp"))
> [1] 1.8
>
> Though it's easy to do this, it's very seldom a good idea.
> The combination of parse and eval can do ANYTHING, no matter how
> disastrous.  Less powerful techniques are safer.
> Where do these strings come from in the first place?
> Why isn't it c("disp", "hp", "cyl")?
>
> On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> > Hello!
> >
> > I have a character string that is a vector of variable names.  I would
> > like to use those names to access the variables and create a matrix.
> > I tried the following:
> >
> > > .x
> >
> > [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> >
> > > .y <- NULL
> >
> > > for(i in 1:3) {
> >
> > + .y[i] <- c(as.name(.x[[i]]))
> >
> > + }
> >
> > > .y
> >
> > [[1]]
> >
> > `mtcars$disp`
> >
> >
> > [[2]]
> >
> > `mtcars$hp`
> >
> >
> > [[3]]
> >
> > `mtcars$cyl`
> >
> >
> > But I am having trouble converting the variables in .y into a matrix.
> >
> >
> > I tried all kinds of stuff with bquote, deparse, do.call, but no good.
> >
> >
> > I have a feeling that it's something simple, and I'm just not seeing it.
> >
> >
> > Thanks,
> >
> > Erin
> >
> >
> >
> >
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> > man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> > Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5
> > -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> > PLEASE do read the posting guide
> > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> > g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> > sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
> > 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Fri Feb 11 06:25:02 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 11 Feb 2022 18:25:02 +1300
Subject: [R] Convert a character string to variable names
In-Reply-To: <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CABcYAdLF3_3Re7XeSBG8FspaLSidtjXSi2=8CBZ337SQEspmjA@mail.gmail.com>

You wrote "32 numbers is not a value".
It is, it really is.  When you have a vector like
 x <- 1:32
you have a simple variable (x) referring to an immutable value
(1, 2, ..., 32).  A vector in R is NOT a collection of mutable
boxes, it is a collection of *numbers* (or strings).  The vector
itself is a good a value as ever twanged.  You cannot change it.
A statement like
 x[i] <- 77
is just shorthand for
 x <- "[<-"(x, i, 77)
which constructs a whole new 32-number value and assigns that to x.
(The actual implementation is cleverer when it can be, but often it
cannot be clever.)
Pure values like vectors can be shared: if x is a vector,
then y <- x is a constant time operation.  If you then change
y, you only change y, not the vector.  x is unchanged.


On Wed, 9 Feb 2022 at 17:06, Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> "A variable in R can refer to many things, ..." I agree.
> "It absolutely _can_ refer to a list, ..." I partly agree. In R as a
> programming language I agree. In R as a statistical analysis tool then only
> partly. Typically one would need to limit the list so each variable would
> be of the same length and all values within the variable be of the same
> data type (integer, real, factor, character). As a programmer yes, as a
> statistician not really unless you always qualify the type of list
> considered and that gets tiresome.
>
> R does name individual elements using numeric place names: hence df[row,
> column]. Each element must have a unique address, and that is true in all
> computer languages.
>
> A dataframe is a list of columns of the same length containing the same
> data type within a column.
>
> mtcars$disp does not have a value (a value is one number). With 32
> elements I can calculate a mean and the mean is a value. 32 numbers is not
> a value. I suppose a single value could be the starting memory address of
> the name, but I don't see how that distinction helps unless one is doing
> Assembly or Machine language programming.
>
> I have never used get(), so I will keep that in mind. I agree that it
> makes life much easier to enter the data in the way it will be analyzed.
>
>
>
>
> -----Original Message-----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Tuesday, February 8, 2022 10:10 PM
> To: r-help at r-project.org; Ebert,Timothy Aaron <tebert at ufl.edu>; Richard
> O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Convert a character string to variable names
>
> [External Email]
>
> A variable in R can refer to many things, but it cannot be an element of a
> vector. It absolutely _can_ refer to a list, a list of lists, a function,
> an environment, and any of the various kinds of atomic vectors that you
> seem to think of as variables. (R does _not_ name individual elements of
> vectors, unlike many other languages.)
>
> The things you can do with the mtcars object may be different than the
> things you can do with the object identified by the expression mtcars$disp,
> but the former has a variable name in an environment while the latter is
> embedded within the former. mtcars$disp is shorthand for the expression
> mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a
> data frame is a list of columns) to refer to that object.
>
> R allows non-standard evaluation to make elements of lists accessible as
> though they were variables in an environment, such as with( mtcars, disp )
> or various tidyverse evaluation conventions. But while the expression
> mtcars$disp DOES have a value( it is an atomic vector of 32 integer
> elements) it is not a variable so get("mtcars$disp") cannot be expected to
> work (as it does not). You may be confusing "variable" with "object" ...
> lots of objects have no variable names.
>
> I have done all sorts of complicated data manipulations in R, but I have
> never found a situation where a use of get() could not be replaced with a
> clearer way to get the job done. Using lists is central to this... avoid
> making distinct variables in the first place if you plan to be retrieving
> them later indirectly like this.
>
> On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu>
> wrote:
> >
> >I had thought that mtcars in "mtcars$disp" was the name of a dataframe
> and that "disp" was the name of a column in the dataframe. If I would make
> a model like horse power = displacement then "disp" would be a variable in
> the model and I can find values for this variable in the "disp" column in
> the "mtcars" dataframe. I am not sure how I would use "mtcars" as a
> variable.
> >"mtcars$disp" has no specific value, though it will have a specific value
> for any given row of data (assuming rows are observations).
> >
> >Tim
> >
> >
> >-----Original Message-----
> >From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard
> >O'Keefe
> >Sent: Tuesday, February 8, 2022 8:17 PM
> >To: Erin Hodgess <erinm.hodgess at gmail.com>
> >Cc: r-help at r-project.org
> >Subject: Re: [R] Convert a character string to variable names
> >
> >[External Email]
> >
> >"mtcars$disp" is not a variable name.
> >"mtcars" is a variable name, and
> >get("mtcars") will get the value of that variable assign("mtcars",
> ~~whatever~~) will set it.
> >mtcars$disp is an *expression*,
> >where $ is an indexing operator
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
> >rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
> >-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
> >y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
> >LPBhHxSlWk&e=
> >so what you want is
> >> mtcars <- list(cyl=4, disp=1.8)
> >> eval(parse(text="mtcars$disp"))
> >[1] 1.8
> >
> >Though it's easy to do this, it's very seldom a good idea.
> >The combination of parse and eval can do ANYTHING, no matter how
> disastrous.  Less powerful techniques are safer.
> >Where do these strings come from in the first place?
> >Why isn't it c("disp", "hp", "cyl")?
> >
> >On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >
> >> Hello!
> >>
> >> I have a character string that is a vector of variable names.  I
> >> would like to use those names to access the variables and create a
> matrix.
> >> I tried the following:
> >>
> >> > .x
> >>
> >> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> >>
> >> > .y <- NULL
> >>
> >> > for(i in 1:3) {
> >>
> >> + .y[i] <- c(as.name(.x[[i]]))
> >>
> >> + }
> >>
> >> > .y
> >>
> >> [[1]]
> >>
> >> `mtcars$disp`
> >>
> >>
> >> [[2]]
> >>
> >> `mtcars$hp`
> >>
> >>
> >> [[3]]
> >>
> >> `mtcars$cyl`
> >>
> >>
> >> But I am having trouble converting the variables in .y into a matrix.
> >>
> >>
> >> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
> >>
> >>
> >> I have a feeling that it's something simple, and I'm just not seeing it.
> >>
> >>
> >> Thanks,
> >>
> >> Erin
> >>
> >>
> >>
> >>
> >> Erin Hodgess, PhD
> >> mailto: erinm.hodgess at gmail.com
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
> >> l
> >> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> >> s
> >> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
> >> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> >> PLEASE do read the posting guide
> >> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
> >> r
> >> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
> >> A
> >> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
> >> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
> >an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
> >sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
> >D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> >PLEASE do read the posting guide
> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
> >_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
> >zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
> >mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
> >an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
> >sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
> >iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
> >PLEASE do read the posting guide
> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
> >_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
> >zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
> >ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Fri Feb 11 06:25:24 2022
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Thu, 10 Feb 2022 21:25:24 -0800
Subject: [R] How to add "slope" in the scatter plot
Message-ID: <CAMwU6B1Yg8RT9i9PdGGWEr0+fdSLubjmww1c2TnfyDASvb2Sug@mail.gmail.com>

Hi R users,
I was trying to add slope, R2 and p value in the scatter plot, but I was
able to add only r2 and p value but not slope in the example data using the
following code. Would you mind checking the code?

daT<-structure(list(x = c(59.9, 96.4, 91.2, 51.4, 11.8, 38.3, 65,
38.3, 35.6, 48.2, 15, 24.6, 60.9), y = c(77.9, 51.8, 53.8, 1.8,
84.7, 49.6, 21.2, 39.5, 22.7, 71, 16.5, 85.8, 10.7)),
row.names = c(NA,-13L), class = "data.frame")

formula <- y ~ poly(x, 1, raw = TRUE)
ggplot(daT, aes(x= x, y=y, group=1))+
  geom_point(size=0, alpha=0.3, colour="pink")+geom_smooth(method =
"lm",linetype="dashed",
formula = formula, se = T, size = 2)+stat_poly_eq(formula = y ~ x,
aes(label = paste(..coef.., ..rr.label..,..p.value.label.., sep = "*`,`~")),
parse = TRUE,label.x.npc = "right", vstep = 0.05, size = 5)

thanks,
MW

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Feb 11 16:16:09 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 11 Feb 2022 15:16:09 +0000
Subject: [R] How to add "slope" in the scatter plot
In-Reply-To: <CAMwU6B1Yg8RT9i9PdGGWEr0+fdSLubjmww1c2TnfyDASvb2Sug@mail.gmail.com>
References: <CAMwU6B1Yg8RT9i9PdGGWEr0+fdSLubjmww1c2TnfyDASvb2Sug@mail.gmail.com>
Message-ID: <5b0efe75-eeff-3fb2-0bc1-97133381e51c@sapo.pt>

Hello,

If instead of ..coef.. you use ..eq.label.. you'll have the equation.


library(ggplot2)
library(ggpmisc)

ggplot(daT, aes(x= x, y=y, group=1)) +
   geom_point(size=0, alpha=0.3, colour="pink") +
   geom_smooth(
     method = "lm",
     formula = formula, se = TRUE,
     linetype="dashed",
     size = 2) +
   stat_poly_eq(
     aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., 
sep = "*`,`~~")),
     formula = y ~ x,
     parse = TRUE,
     label.x.npc = "right",
     vstep = 0.05,
     size = 5)


Hope this helps,

Rui Barradas



?s 05:25 de 11/02/2022, Marna Wagley escreveu:
> Hi R users,
> I was trying to add slope, R2 and p value in the scatter plot, but I was
> able to add only r2 and p value but not slope in the example data using the
> following code. Would you mind checking the code?
> 
> daT<-structure(list(x = c(59.9, 96.4, 91.2, 51.4, 11.8, 38.3, 65,
> 38.3, 35.6, 48.2, 15, 24.6, 60.9), y = c(77.9, 51.8, 53.8, 1.8,
> 84.7, 49.6, 21.2, 39.5, 22.7, 71, 16.5, 85.8, 10.7)),
> row.names = c(NA,-13L), class = "data.frame")
> 
> formula <- y ~ poly(x, 1, raw = TRUE)
> ggplot(daT, aes(x= x, y=y, group=1))+
>    geom_point(size=0, alpha=0.3, colour="pink")+geom_smooth(method =
> "lm",linetype="dashed",
> formula = formula, se = T, size = 2)+stat_poly_eq(formula = y ~ x,
> aes(label = paste(..coef.., ..rr.label..,..p.value.label.., sep = "*`,`~")),
> parse = TRUE,label.x.npc = "right", vstep = 0.05, size = 5)
> 
> thanks,
> MW
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From P@M@rt|n-19 @end|ng |rom @tudent@|boro@@c@uk  Fri Feb 11 16:24:30 2022
From: P@M@rt|n-19 @end|ng |rom @tudent@|boro@@c@uk ((s) Phoebe Martin)
Date: Fri, 11 Feb 2022 15:24:30 +0000
Subject: [R] Animated Face plot in R (Moving golf club face)
Message-ID: <DBBPR04MB749907A1713F77A1F39CD945AB309@DBBPR04MB7499.eurprd04.prod.outlook.com>

Hi,

I am wanting to create an animated 3d plot that mimics a golf club face in a swing. The data I have is fiducials (marker point coordinates) through various time stamps. So far, I have been able to create one 3d plot using mesh3d of the club face in one moment in time. However here I would like to make many of these plots at the different time stamps (see image 2 for coordinates) and create an animation of this face moving.

Image 1 shows the output of the current graph, which can rotate and hover over markers to show their labels i.e. Heel. [Current plot outcome][1]: https://i.stack.imgur.com/Ne3Po.png

Image 2 is the coordinates of the required plots (to make a moving graph). [Coordinates that I want multiple plots for, to create moving animation] https://i.stack.imgur.com/srEdW.png

Below is the example code where I have inputted the x, y & z data very simply as an example of what I am wanting to achieve.

Any help would be greatly appreciated, thank you. Please let me know if you need any more information from me!
    library(rgl)
    library(tidyverse)
    library(plotly)

    df <- data.frame(x=c('-278.76', '-302.2','-283.57','-275.18','-281.165'),
                     y=c('52.66','-4.39','-3.84','-3.29','24.41'),
                     z=c('40.87','63.68','36.95','24.25','38.91')) # Create a table of coordinates
    marker<-c("Heel","TToe","MToe","BToe","Centre")
    rownames(df)<-marker # Label row names
    #head(df) #display table
    x <- as.numeric(df$x) # Assigning elements of dataframe to x, y & z
    y <- as.numeric(df$y)
    z <- as.numeric(df$z)

    ##PLANE/SURFACE PLOT
     plot_ly(x=~x, y=~y, z=~z, type='mesh3d', text = ~paste('Marker:', marker),
             hoverinfo='text') # Enables hover to identify marker points and rotation




	[[alternative HTML version deleted]]


From chr|@ @end|ng |rom p@yctc@org  Fri Feb 11 18:46:32 2022
From: chr|@ @end|ng |rom p@yctc@org (Chris Evans)
Date: Fri, 11 Feb 2022 17:46:32 +0000 (UTC)
Subject: [R] How to add "slope" in the scatter plot
Message-ID: <2123587457.4523461.1644601592091.JavaMail.zimbra@psyctc.org>

[Damn, forgot default reply-to is to the last poster: sorry Rui.] 

That's taught me some fun stuff but I wonder if the first "formula = formula" is correct. 
It throws an error for me and I think the code works when I comment it out and it looks 
to me from ?geom_smooth that it is optional here (and defaults to NULL). 

Very best Rui and all, 

Chris 

----- Original Message ----- 
> From: "Rui Barradas" <ruipbarradas at sapo.pt> 
> To: "Marna Wagley" <marna.wagley at gmail.com>, "r-help mailing list" <r-help at r-project.org> 
> Sent: Friday, 11 February, 2022 16:16:09 
> Subject: Re: [R] How to add "slope" in the scatter plot 

> Hello, 
> 
> If instead of ..coef.. you use ..eq.label.. you'll have the equation. 
> 
> 
> library(ggplot2) 
> library(ggpmisc) 
> 
> ggplot(daT, aes(x= x, y=y, group=1)) + 
> geom_point(size=0, alpha=0.3, colour="pink") + 
> geom_smooth( 
> method = "lm", 
> formula = formula, se = TRUE, 
> linetype="dashed", 
> size = 2) + 
> stat_poly_eq( 
> aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label.., 
> sep = "*`,`~~")), 
> formula = y ~ x, 
> parse = TRUE, 
> label.x.npc = "right", 
> vstep = 0.05, 
> size = 5) 
> 
> 
> Hope this helps, 
> 
> Rui Barradas 
> 
> 
> 
> ?s 05:25 de 11/02/2022, Marna Wagley escreveu: 
>> Hi R users, 
>> I was trying to add slope, R2 and p value in the scatter plot, but I was 
>> able to add only r2 and p value but not slope in the example data using the 
>> following code. Would you mind checking the code? 
>> 
>> daT<-structure(list(x = c(59.9, 96.4, 91.2, 51.4, 11.8, 38.3, 65, 
>> 38.3, 35.6, 48.2, 15, 24.6, 60.9), y = c(77.9, 51.8, 53.8, 1.8, 
>> 84.7, 49.6, 21.2, 39.5, 22.7, 71, 16.5, 85.8, 10.7)), 
>> row.names = c(NA,-13L), class = "data.frame") 
>> 
>> formula <- y ~ poly(x, 1, raw = TRUE) 
>> ggplot(daT, aes(x= x, y=y, group=1))+ 
>> geom_point(size=0, alpha=0.3, colour="pink")+geom_smooth(method = 
>> "lm",linetype="dashed", 
>> formula = formula, se = T, size = 2)+stat_poly_eq(formula = y ~ x, 
>> aes(label = paste(..coef.., ..rr.label..,..p.value.label.., sep = "*`,`~")), 
>> parse = TRUE,label.x.npc = "right", vstep = 0.05, size = 5) 
>> 
>> thanks, 
>> MW 
>> 
>> [[alternative HTML version deleted]] 
>> 
>> ______________________________________________ 
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help 
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
>> and provide commented, minimal, self-contained, reproducible code. 


-- 
Chris Evans (he/him) <chris at psyctc.org> 
Visiting Professor, UDLA, Quito, Ecuador & Honorary Professor, University of Roehampton, London, UK. 
Work web site: https://www.psyctc.org/psyctc/ 
CORE site: https://www.coresystemtrust.org.uk/ 
Personal site: https://www.psyctc.org/pelerinage2016/ 
OMbook: https://ombook.psyctc.org/book/ 

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Feb 12 18:31:02 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 12 Feb 2022 09:31:02 -0800
Subject: [R] Animated Face plot in R (Moving golf club face)
In-Reply-To: <DBBPR04MB749907A1713F77A1F39CD945AB309@DBBPR04MB7499.eurprd04.prod.outlook.com>
References: <DBBPR04MB749907A1713F77A1F39CD945AB309@DBBPR04MB7499.eurprd04.prod.outlook.com>
Message-ID: <CAGxFJbQSEJrvRkwmbcndpKJ1K3Jf1SDxc-zjcsM72sqxaknAWg@mail.gmail.com>

Please note, per the posting guide linked below:

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R), ask questions on R-help.
[The link is:
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R
This gives the list of current _standard_ packages]
If the question relates to a contributed package , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. Only send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

In particular, plotly is NOT an R package and is a product of a for-profit
software company who you should contact for your query:
either here:  https://plotly.com/r/getting-started/
or here: https://community.plotly.com/c/graphing-libraries/5

(I think)


Cheers,
Bert

On Fri, Feb 11, 2022 at 8:41 PM (s) Phoebe Martin <
P.Martin-19 at student.lboro.ac.uk> wrote:

> Hi,
>
> I am wanting to create an animated 3d plot that mimics a golf club face in
> a swing. The data I have is fiducials (marker point coordinates) through
> various time stamps. So far, I have been able to create one 3d plot using
> mesh3d of the club face in one moment in time. However here I would like to
> make many of these plots at the different time stamps (see image 2 for
> coordinates) and create an animation of this face moving.
>
> Image 1 shows the output of the current graph, which can rotate and hover
> over markers to show their labels i.e. Heel. [Current plot outcome][1]:
> https://i.stack.imgur.com/Ne3Po.png
>
> Image 2 is the coordinates of the required plots (to make a moving graph).
> [Coordinates that I want multiple plots for, to create moving animation]
> https://i.stack.imgur.com/srEdW.png
>
> Below is the example code where I have inputted the x, y & z data very
> simply as an example of what I am wanting to achieve.
>
> Any help would be greatly appreciated, thank you. Please let me know if
> you need any more information from me!
>     library(rgl)
>     library(tidyverse)
>     library(plotly)
>
>     df <- data.frame(x=c('-278.76',
> '-302.2','-283.57','-275.18','-281.165'),
>                      y=c('52.66','-4.39','-3.84','-3.29','24.41'),
>                      z=c('40.87','63.68','36.95','24.25','38.91')) #
> Create a table of coordinates
>     marker<-c("Heel","TToe","MToe","BToe","Centre")
>     rownames(df)<-marker # Label row names
>     #head(df) #display table
>     x <- as.numeric(df$x) # Assigning elements of dataframe to x, y & z
>     y <- as.numeric(df$y)
>     z <- as.numeric(df$z)
>
>     ##PLANE/SURFACE PLOT
>      plot_ly(x=~x, y=~y, z=~z, type='mesh3d', text = ~paste('Marker:',
> marker),
>              hoverinfo='text') # Enables hover to identify marker points
> and rotation
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Feb 12 18:32:47 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 12 Feb 2022 09:32:47 -0800
Subject: [R] Animated Face plot in R (Moving golf club face)
In-Reply-To: <CAGxFJbQSEJrvRkwmbcndpKJ1K3Jf1SDxc-zjcsM72sqxaknAWg@mail.gmail.com>
References: <DBBPR04MB749907A1713F77A1F39CD945AB309@DBBPR04MB7499.eurprd04.prod.outlook.com>
 <CAGxFJbQSEJrvRkwmbcndpKJ1K3Jf1SDxc-zjcsM72sqxaknAWg@mail.gmail.com>
Message-ID: <CAGxFJbQnE9KUW2KqsL-Me2RtHpu9JcstSDKWuWPPEWO5cBprgg@mail.gmail.com>

I beg your pardon. plotly is not a *standard* R package. It is, of course,
an R package.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 12, 2022 at 9:31 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Please note, per the posting guide linked below:
>
> "For questions about functions in standard packages distributed with R
> (see the FAQ Add-on packages in R), ask questions on R-help.
> [The link is:
> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R
> This gives the list of current _standard_ packages]
> If the question relates to a contributed package , e.g., one downloaded
> from CRAN, try contacting the package maintainer first. You can also use
> find("functionname") and packageDescription("packagename") to find this
> information. Only send such questions to R-help or R-devel if you get no
> reply or need further assistance. This applies to both requests for help
> and to bug reports."
>
> In particular, plotly is NOT an R package and is a product of a for-profit
> software company who you should contact for your query:
> either here:  https://plotly.com/r/getting-started/
> or here: https://community.plotly.com/c/graphing-libraries/5
>
> (I think)
>
>
> Cheers,
> Bert
>
> On Fri, Feb 11, 2022 at 8:41 PM (s) Phoebe Martin <
> P.Martin-19 at student.lboro.ac.uk> wrote:
>
>> Hi,
>>
>> I am wanting to create an animated 3d plot that mimics a golf club face
>> in a swing. The data I have is fiducials (marker point coordinates) through
>> various time stamps. So far, I have been able to create one 3d plot using
>> mesh3d of the club face in one moment in time. However here I would like to
>> make many of these plots at the different time stamps (see image 2 for
>> coordinates) and create an animation of this face moving.
>>
>> Image 1 shows the output of the current graph, which can rotate and hover
>> over markers to show their labels i.e. Heel. [Current plot outcome][1]:
>> https://i.stack.imgur.com/Ne3Po.png
>>
>> Image 2 is the coordinates of the required plots (to make a moving
>> graph). [Coordinates that I want multiple plots for, to create moving
>> animation] https://i.stack.imgur.com/srEdW.png
>>
>> Below is the example code where I have inputted the x, y & z data very
>> simply as an example of what I am wanting to achieve.
>>
>> Any help would be greatly appreciated, thank you. Please let me know if
>> you need any more information from me!
>>     library(rgl)
>>     library(tidyverse)
>>     library(plotly)
>>
>>     df <- data.frame(x=c('-278.76',
>> '-302.2','-283.57','-275.18','-281.165'),
>>                      y=c('52.66','-4.39','-3.84','-3.29','24.41'),
>>                      z=c('40.87','63.68','36.95','24.25','38.91')) #
>> Create a table of coordinates
>>     marker<-c("Heel","TToe","MToe","BToe","Centre")
>>     rownames(df)<-marker # Label row names
>>     #head(df) #display table
>>     x <- as.numeric(df$x) # Assigning elements of dataframe to x, y & z
>>     y <- as.numeric(df$y)
>>     z <- as.numeric(df$z)
>>
>>     ##PLANE/SURFACE PLOT
>>      plot_ly(x=~x, y=~y, z=~z, type='mesh3d', text = ~paste('Marker:',
>> marker),
>>              hoverinfo='text') # Enables hover to identify marker points
>> and rotation
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Feb 12 18:43:14 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 12 Feb 2022 09:43:14 -0800
Subject: [R] Animated Face plot in R (Moving golf club face)
In-Reply-To: <CAGxFJbQSEJrvRkwmbcndpKJ1K3Jf1SDxc-zjcsM72sqxaknAWg@mail.gmail.com>
References: <DBBPR04MB749907A1713F77A1F39CD945AB309@DBBPR04MB7499.eurprd04.prod.outlook.com>
 <CAGxFJbQSEJrvRkwmbcndpKJ1K3Jf1SDxc-zjcsM72sqxaknAWg@mail.gmail.com>
Message-ID: <F58ED7C1-9316-4FFA-8F74-51253BA26938@dcn.davis.ca.us>

True, but the core question seems to be about iteration, which may be accomplished with or without the aid of contributed packages. R is quite rich in iteration techniques.

One approach for OP might be to boil down the question so it is about iteration, though a for loop or lapply is pretty straightforward.

Another would be for OP do a web search for "r animation" which ought to lead to some useful examples such as https://www.r-graph-gallery.com/animation.html.

On February 12, 2022 9:31:02 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Please note, per the posting guide linked below:
>
>"For questions about functions in standard packages distributed with R (see
>the FAQ Add-on packages in R), ask questions on R-help.
>[The link is:
>https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R
>This gives the list of current _standard_ packages]
>If the question relates to a contributed package , e.g., one downloaded
>from CRAN, try contacting the package maintainer first. You can also use
>find("functionname") and packageDescription("packagename") to find this
>information. Only send such questions to R-help or R-devel if you get no
>reply or need further assistance. This applies to both requests for help
>and to bug reports."
>
>In particular, plotly is NOT an R package and is a product of a for-profit
>software company who you should contact for your query:
>either here:  https://plotly.com/r/getting-started/
>or here: https://community.plotly.com/c/graphing-libraries/5
>
>(I think)
>
>
>Cheers,
>Bert
>
>On Fri, Feb 11, 2022 at 8:41 PM (s) Phoebe Martin <
>P.Martin-19 at student.lboro.ac.uk> wrote:
>
>> Hi,
>>
>> I am wanting to create an animated 3d plot that mimics a golf club face in
>> a swing. The data I have is fiducials (marker point coordinates) through
>> various time stamps. So far, I have been able to create one 3d plot using
>> mesh3d of the club face in one moment in time. However here I would like to
>> make many of these plots at the different time stamps (see image 2 for
>> coordinates) and create an animation of this face moving.
>>
>> Image 1 shows the output of the current graph, which can rotate and hover
>> over markers to show their labels i.e. Heel. [Current plot outcome][1]:
>> https://i.stack.imgur.com/Ne3Po.png
>>
>> Image 2 is the coordinates of the required plots (to make a moving graph).
>> [Coordinates that I want multiple plots for, to create moving animation]
>> https://i.stack.imgur.com/srEdW.png
>>
>> Below is the example code where I have inputted the x, y & z data very
>> simply as an example of what I am wanting to achieve.
>>
>> Any help would be greatly appreciated, thank you. Please let me know if
>> you need any more information from me!
>>     library(rgl)
>>     library(tidyverse)
>>     library(plotly)
>>
>>     df <- data.frame(x=c('-278.76',
>> '-302.2','-283.57','-275.18','-281.165'),
>>                      y=c('52.66','-4.39','-3.84','-3.29','24.41'),
>>                      z=c('40.87','63.68','36.95','24.25','38.91')) #
>> Create a table of coordinates
>>     marker<-c("Heel","TToe","MToe","BToe","Centre")
>>     rownames(df)<-marker # Label row names
>>     #head(df) #display table
>>     x <- as.numeric(df$x) # Assigning elements of dataframe to x, y & z
>>     y <- as.numeric(df$y)
>>     z <- as.numeric(df$z)
>>
>>     ##PLANE/SURFACE PLOT
>>      plot_ly(x=~x, y=~y, z=~z, type='mesh3d', text = ~paste('Marker:',
>> marker),
>>              hoverinfo='text') # Enables hover to identify marker points
>> and rotation
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From tebert @end|ng |rom u||@edu  Sun Feb 13 04:24:18 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sun, 13 Feb 2022 03:24:18 +0000
Subject: [R] Convert a character string to variable names
In-Reply-To: <CABcYAdLF3_3Re7XeSBG8FspaLSidtjXSi2=8CBZ337SQEspmjA@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAdLF3_3Re7XeSBG8FspaLSidtjXSi2=8CBZ337SQEspmjA@mail.gmail.com>
Message-ID: <BN6PR2201MB15539D4D06CB06DD6219AC82CF329@BN6PR2201MB1553.namprd22.prod.outlook.com>

How does ?a value? differ from ?an object??

From: Richard O'Keefe <raoknz at gmail.com>
Sent: Friday, February 11, 2022 12:25 AM
To: Ebert,Timothy Aaron <tebert at ufl.edu>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org; Erin Hodgess <erinm.hodgess at gmail.com>
Subject: Re: [R] Convert a character string to variable names

[External Email]
You wrote "32 numbers is not a value".
It is, it really is.  When you have a vector like
 x <- 1:32
you have a simple variable (x) referring to an immutable value
(1, 2, ..., 32).  A vector in R is NOT a collection of mutable
boxes, it is a collection of *numbers* (or strings).  The vector
itself is a good a value as ever twanged.  You cannot change it.
A statement like
 x[i] <- 77
is just shorthand for
 x <- "[<-"(x, i, 77)
which constructs a whole new 32-number value and assigns that to x.
(The actual implementation is cleverer when it can be, but often it
cannot be clever.)
Pure values like vectors can be shared: if x is a vector,
then y <- x is a constant time operation.  If you then change
y, you only change y, not the vector.  x is unchanged.


On Wed, 9 Feb 2022 at 17:06, Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
"A variable in R can refer to many things, ..." I agree.
"It absolutely _can_ refer to a list, ..." I partly agree. In R as a programming language I agree. In R as a statistical analysis tool then only partly. Typically one would need to limit the list so each variable would be of the same length and all values within the variable be of the same data type (integer, real, factor, character). As a programmer yes, as a statistician not really unless you always qualify the type of list considered and that gets tiresome.

R does name individual elements using numeric place names: hence df[row, column]. Each element must have a unique address, and that is true in all computer languages.

A dataframe is a list of columns of the same length containing the same data type within a column.

mtcars$disp does not have a value (a value is one number). With 32 elements I can calculate a mean and the mean is a value. 32 numbers is not a value. I suppose a single value could be the starting memory address of the name, but I don't see how that distinction helps unless one is doing Assembly or Machine language programming.

I have never used get(), so I will keep that in mind. I agree that it makes life much easier to enter the data in the way it will be analyzed.




-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>
Sent: Tuesday, February 8, 2022 10:10 PM
To: r-help at r-project.org<mailto:r-help at r-project.org>; Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>>; Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>>; Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Convert a character string to variable names

[External Email]

A variable in R can refer to many things, but it cannot be an element of a vector. It absolutely _can_ refer to a list, a list of lists, a function, an environment, and any of the various kinds of atomic vectors that you seem to think of as variables. (R does _not_ name individual elements of vectors, unlike many other languages.)

The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.

R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.

I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.

On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
>
>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>
>Tim
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Richard
>O'Keefe
>Sent: Tuesday, February 8, 2022 8:17 PM
>To: Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
>Cc: r-help at r-project.org<mailto:r-help at r-project.org>
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>
>"mtcars$disp" is not a variable name.
>"mtcars" is a variable name, and
>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>mtcars$disp is an *expression*,
>where $ is an indexing operator
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
>rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
>-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
>y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
>LPBhHxSlWk&e=
>so what you want is
>> mtcars <- list(cyl=4, disp=1.8)
>> eval(parse(text="mtcars$disp"))
>[1] 1.8
>
>Though it's easy to do this, it's very seldom a good idea.
>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>Where do these strings come from in the first place?
>Why isn't it c("disp", "hp", "cyl")?
>
>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>> wrote:
>
>> Hello!
>>
>> I have a character string that is a vector of variable names.  I
>> would like to use those names to access the variables and create a matrix.
>> I tried the following:
>>
>> > .x
>>
>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>
>> > .y <- NULL
>>
>> > for(i in 1:3) {
>>
>> + .y[i] <- c(as.name<https://urldefense.proofpoint.com/v2/url?u=http-3A__as.name&d=DwMFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=vzlTpQd9zYJkQ77y8VRROjzMQQJrJce_5rInko9TViGjuIt93PxagLXs9prJsMwy&s=Yrczdj8QHFrWSBSm_k4WyKN7ppY20M360b7tUmMCJaY&e=>(.x[[i]]))
>>
>> + }
>>
>> > .y
>>
>> [[1]]
>>
>> `mtcars$disp`
>>
>>
>> [[2]]
>>
>> `mtcars$hp`
>>
>>
>> [[3]]
>>
>> `mtcars$cyl`
>>
>>
>> But I am having trouble converting the variables in .y into a matrix.
>>
>>
>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>
>>
>> I have a feeling that it's something simple, and I'm just not seeing it.
>>
>>
>> Thanks,
>>
>> Erin
>>
>>
>>
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
>> l
>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>> s
>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
>> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
>> r
>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
>> A
>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
>> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
>D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
>mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
>iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
>ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Feb 13 07:54:48 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 12 Feb 2022 22:54:48 -0800
Subject: [R] Convert a character string to variable names
In-Reply-To: <BN6PR2201MB15539D4D06CB06DD6219AC82CF329@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAdLF3_3Re7XeSBG8FspaLSidtjXSi2=8CBZ337SQEspmjA@mail.gmail.com>
 <BN6PR2201MB15539D4D06CB06DD6219AC82CF329@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <EF144BA3-FC96-42DB-A0B7-F5BA12D96836@dcn.davis.ca.us>

Value is all the information in the object. In R, for pretty much everything except environment objects the two terms are interchangeable (object is equivalent to value) because R works hard to make it so.

For environment objects (the exception), the contents of the environment can change even while different variables continue to refer to the same environment object. This is how f(3) ends up as c(7,6) in the following code:

x <- c(3,4)
f <- function(a) x+a
x <- c(4,3)
f(3)

The f object knows to look in the global environment for x from when it was created, but the x name embedded in that environment was replaced with a different object by the time f was called. That is, x referred to an object containing a value c(3,4) first, and then later to a completely different location in memory (object identity) with a different value c(4,3). The same global environment object thus contained different information at different times, even though the identity (address) of the global environment object was never changed, so f could store that identity information for use later.

If you use read.csv to import a data set into a data frame and assign that to a variable name DF, all of that information represents the value of that data frame. If you change an element of the first column:

DF[1,1] <- 9

then R will only modify the value of that data frame object in place if no other variable is referring to it... that is, if you have passed DF to a function then it makes a whole new object when you try to change part of it in the function. But the details about changing parts of an object this way are mostly useful for avoiding inefficient memory use... while the fact that the value of an object consists of all of the information in it is useful from a statistical analysis point of view... different values in the large sense in general lead to different results. A specific example being that an lm object has a value based on the input objects that were used to create it.

See http://adv-r.had.co.nz/memory.html for a more complete discussion.

On February 12, 2022 7:24:18 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>How does ?a value? differ from ?an object??
>
>From: Richard O'Keefe <raoknz at gmail.com>
>Sent: Friday, February 11, 2022 12:25 AM
>To: Ebert,Timothy Aaron <tebert at ufl.edu>
>Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org; Erin Hodgess <erinm.hodgess at gmail.com>
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>You wrote "32 numbers is not a value".
>It is, it really is.  When you have a vector like
> x <- 1:32
>you have a simple variable (x) referring to an immutable value
>(1, 2, ..., 32).  A vector in R is NOT a collection of mutable
>boxes, it is a collection of *numbers* (or strings).  The vector
>itself is a good a value as ever twanged.  You cannot change it.
>A statement like
> x[i] <- 77
>is just shorthand for
> x <- "[<-"(x, i, 77)
>which constructs a whole new 32-number value and assigns that to x.
>(The actual implementation is cleverer when it can be, but often it
>cannot be clever.)
>Pure values like vectors can be shared: if x is a vector,
>then y <- x is a constant time operation.  If you then change
>y, you only change y, not the vector.  x is unchanged.
>
>
>On Wed, 9 Feb 2022 at 17:06, Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
>"A variable in R can refer to many things, ..." I agree.
>"It absolutely _can_ refer to a list, ..." I partly agree. In R as a programming language I agree. In R as a statistical analysis tool then only partly. Typically one would need to limit the list so each variable would be of the same length and all values within the variable be of the same data type (integer, real, factor, character). As a programmer yes, as a statistician not really unless you always qualify the type of list considered and that gets tiresome.
>
>R does name individual elements using numeric place names: hence df[row, column]. Each element must have a unique address, and that is true in all computer languages.
>
>A dataframe is a list of columns of the same length containing the same data type within a column.
>
>mtcars$disp does not have a value (a value is one number). With 32 elements I can calculate a mean and the mean is a value. 32 numbers is not a value. I suppose a single value could be the starting memory address of the name, but I don't see how that distinction helps unless one is doing Assembly or Machine language programming.
>
>I have never used get(), so I will keep that in mind. I agree that it makes life much easier to enter the data in the way it will be analyzed.
>
>
>
>
>-----Original Message-----
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>
>Sent: Tuesday, February 8, 2022 10:10 PM
>To: r-help at r-project.org<mailto:r-help at r-project.org>; Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>>; Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>>; Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
>Cc: r-help at r-project.org<mailto:r-help at r-project.org>
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>
>A variable in R can refer to many things, but it cannot be an element of a vector. It absolutely _can_ refer to a list, a list of lists, a function, an environment, and any of the various kinds of atomic vectors that you seem to think of as variables. (R does _not_ name individual elements of vectors, unlike many other languages.)
>
>The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.
>
>R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.
>
>I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.
>
>On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
>>
>>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>>
>>Tim
>>
>>
>>-----Original Message-----
>>From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Richard
>>O'Keefe
>>Sent: Tuesday, February 8, 2022 8:17 PM
>>To: Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
>>Cc: r-help at r-project.org<mailto:r-help at r-project.org>
>>Subject: Re: [R] Convert a character string to variable names
>>
>>[External Email]
>>
>>"mtcars$disp" is not a variable name.
>>"mtcars" is a variable name, and
>>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>>mtcars$disp is an *expression*,
>>where $ is an indexing operator
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
>>rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
>>-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
>>y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
>>LPBhHxSlWk&e=
>>so what you want is
>>> mtcars <- list(cyl=4, disp=1.8)
>>> eval(parse(text="mtcars$disp"))
>>[1] 1.8
>>
>>Though it's easy to do this, it's very seldom a good idea.
>>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>>Where do these strings come from in the first place?
>>Why isn't it c("disp", "hp", "cyl")?
>>
>>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>> wrote:
>>
>>> Hello!
>>>
>>> I have a character string that is a vector of variable names.  I
>>> would like to use those names to access the variables and create a matrix.
>>> I tried the following:
>>>
>>> > .x
>>>
>>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>>
>>> > .y <- NULL
>>>
>>> > for(i in 1:3) {
>>>
>>> + .y[i] <- c(as.name<https://urldefense.proofpoint.com/v2/url?u=http-3A__as.name&d=DwMFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=vzlTpQd9zYJkQ77y8VRROjzMQQJrJce_5rInko9TViGjuIt93PxagLXs9prJsMwy&s=Yrczdj8QHFrWSBSm_k4WyKN7ppY20M360b7tUmMCJaY&e=>(.x[[i]]))
>>>
>>> + }
>>>
>>> > .y
>>>
>>> [[1]]
>>>
>>> `mtcars$disp`
>>>
>>>
>>> [[2]]
>>>
>>> `mtcars$hp`
>>>
>>>
>>> [[3]]
>>>
>>> `mtcars$cyl`
>>>
>>>
>>> But I am having trouble converting the variables in .y into a matrix.
>>>
>>>
>>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>>
>>>
>>> I have a feeling that it's something simple, and I'm just not seeing it.
>>>
>>>
>>> Thanks,
>>>
>>> Erin
>>>
>>>
>>>
>>>
>>> Erin Hodgess, PhD
>>> mailto: erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
>>> l
>>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>>> s
>>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
>>> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>>> PLEASE do read the posting guide
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
>>> r
>>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
>>> A
>>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
>>> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>        [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>>sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
>>D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>>PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
>>mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>>an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>>sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
>>iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
>>PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>>_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>>zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
>>ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From chr|@ho|d @end|ng |rom p@yctc@org  Sun Feb 13 10:07:33 2022
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Sun, 13 Feb 2022 09:07:33 +0000 (UTC)
Subject: [R] [Impersonated] Re:  How to add "slope" in the scatter plot
In-Reply-To: <2123587457.4523461.1644601592091.JavaMail.zimbra@psyctc.org>
References: <2123587457.4523461.1644601592091.JavaMail.zimbra@psyctc.org>
Message-ID: <1148458383.5892208.1644743253461.JavaMail.zimbra@psyctc.org>

My bad: I had not noticed that the line:
   formula <- y ~ poly(x, 1, raw = TRUE)
that was in the OP post was not in Rui's reply.

As ever, I should concentrate harder!  Apologies for cruft on cruft but thought 
I should put this in the archived thread.

Very best all,

Chris

----- Original Message -----
> From: "Chris Evans" <chris at psyctc.org>
> To: R-help at r-project.org
> Sent: Friday, 11 February, 2022 18:46:32
> Subject: [Impersonated] Re: [R] How to add "slope" in the scatter plot

> [Damn, forgot default reply-to is to the last poster: sorry Rui.]
> 
> That's taught me some fun stuff but I wonder if the first "formula = formula" is
> correct.
> It throws an error for me and I think the code works when I comment it out and
> it looks
> to me from ?geom_smooth that it is optional here (and defaults to NULL).
> 
> Very best Rui and all,
> 
> Chris
> 
> ----- Original Message -----
>> From: "Rui Barradas" <ruipbarradas at sapo.pt>
>> To: "Marna Wagley" <marna.wagley at gmail.com>, "r-help mailing list"
>> <r-help at r-project.org>
>> Sent: Friday, 11 February, 2022 16:16:09
>> Subject: Re: [R] How to add "slope" in the scatter plot
> 
>> Hello,
>> 
>> If instead of ..coef.. you use ..eq.label.. you'll have the equation.
>> 
>> 
>> library(ggplot2)
>> library(ggpmisc)
>> 
>> ggplot(daT, aes(x= x, y=y, group=1)) +
>> geom_point(size=0, alpha=0.3, colour="pink") +
>> geom_smooth(
>> method = "lm",
>> formula = formula, se = TRUE,
>> linetype="dashed",
>> size = 2) +
>> stat_poly_eq(
>> aes(label = paste(..eq.label.., ..rr.label.., ..p.value.label..,
>> sep = "*`,`~~")),
>> formula = y ~ x,
>> parse = TRUE,
>> label.x.npc = "right",
>> vstep = 0.05,
>> size = 5)
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> 
>> ?s 05:25 de 11/02/2022, Marna Wagley escreveu:
>>> Hi R users,
>>> I was trying to add slope, R2 and p value in the scatter plot, but I was
>>> able to add only r2 and p value but not slope in the example data using the
>>> following code. Would you mind checking the code?
>>> 
>>> daT<-structure(list(x = c(59.9, 96.4, 91.2, 51.4, 11.8, 38.3, 65,
>>> 38.3, 35.6, 48.2, 15, 24.6, 60.9), y = c(77.9, 51.8, 53.8, 1.8,
>>> 84.7, 49.6, 21.2, 39.5, 22.7, 71, 16.5, 85.8, 10.7)),
>>> row.names = c(NA,-13L), class = "data.frame")
>>> 
>>> formula <- y ~ poly(x, 1, raw = TRUE)
>>> ggplot(daT, aes(x= x, y=y, group=1))+
>>> geom_point(size=0, alpha=0.3, colour="pink")+geom_smooth(method =
>>> "lm",linetype="dashed",
>>> formula = formula, se = T, size = 2)+stat_poly_eq(formula = y ~ x,
>>> aes(label = paste(..coef.., ..rr.label..,..p.value.label.., sep = "*`,`~")),
>>> parse = TRUE,label.x.npc = "right", vstep = 0.05, size = 5)
>>> 
>>> thanks,
>>> MW
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


-- 
Chris Evans (he/him) <chris at psyctc.org> 
Visiting Professor, UDLA, Quito, Ecuador & Honorary Professor, University of Roehampton, London, UK.
Work web site: https://www.psyctc.org/psyctc/ 
CORE site:     https://www.coresystemtrust.org.uk/
Personal site: https://www.psyctc.org/pelerinage2016/
OMbook:        https://ombook.psyctc.org/book/


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun Feb 13 11:44:22 2022
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 13 Feb 2022 10:44:22 +0000 (UTC)
Subject: [R] Exact 95% CIs around the mean for Weibull distribution
References: <1387483335.1628933.1644749062688.ref@mail.yahoo.com>
Message-ID: <1387483335.1628933.1644749062688@mail.yahoo.com>

Dear R-experts,

Here below my R code. I am trying to get the exact 95% confidence intervals around the meanlog for lognormal, around the mean for gamma and around the mean for weibull distributions. For lognormal and gamma everything is working but for weibull, I get error messages. After having used the ??eweibull function, I am not sure I can get the 95% CIs around the mean. Is there a way to get the exact 95% CIs around the mean for the weibull distribution ?

##########################
#Exact 95% CIs for the mean lognormal distribution
library(EnvStats)

x=rlnorm(100000,0,1)
elnorm(x,method="mvue",ci=TRUE,ci.type="two-sided",ci.method="exact",conf.level=0.95)

#Exact 95% CIs for the mean gamma distribution
library(EnvStats)

x=rgamma(n=100000,shape=2,rate=5)
egamma(x,method="mle",ci=TRUE,ci.type="two-sided",conf.level=0.95)


#Exact 95% CIs for the mean weibull distribution
library(EnvStats)

x=rweibull(100000,2,2) 
eweibull(x,method="mle",ci=TRUE,ci.type="two-sided",conf.level=0.95)

##########################


From er|cjberger @end|ng |rom gm@||@com  Sun Feb 13 12:10:59 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 13 Feb 2022 13:10:59 +0200
Subject: [R] Exact 95% CIs around the mean for Weibull distribution
In-Reply-To: <1387483335.1628933.1644749062688@mail.yahoo.com>
References: <1387483335.1628933.1644749062688.ref@mail.yahoo.com>
 <1387483335.1628933.1644749062688@mail.yahoo.com>
Message-ID: <CAGgJW76FaCtsjD5LskYbZ_iodSZWRx5c7ApCbfLCoqDbga85FQ@mail.gmail.com>

I did a Google search on "R confidence interval for Weibull
distribution parameters"
and there were several packages that appear to provide that
information. Have you tried any of them?


On Sun, Feb 13, 2022 at 12:44 PM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> Here below my R code. I am trying to get the exact 95% confidence intervals around the meanlog for lognormal, around the mean for gamma and around the mean for weibull distributions. For lognormal and gamma everything is working but for weibull, I get error messages. After having used the ??eweibull function, I am not sure I can get the 95% CIs around the mean. Is there a way to get the exact 95% CIs around the mean for the weibull distribution ?
>
> ##########################
> #Exact 95% CIs for the mean lognormal distribution
> library(EnvStats)
>
> x=rlnorm(100000,0,1)
> elnorm(x,method="mvue",ci=TRUE,ci.type="two-sided",ci.method="exact",conf.level=0.95)
>
> #Exact 95% CIs for the mean gamma distribution
> library(EnvStats)
>
> x=rgamma(n=100000,shape=2,rate=5)
> egamma(x,method="mle",ci=TRUE,ci.type="two-sided",conf.level=0.95)
>
>
> #Exact 95% CIs for the mean weibull distribution
> library(EnvStats)
>
> x=rweibull(100000,2,2)
> eweibull(x,method="mle",ci=TRUE,ci.type="two-sided",conf.level=0.95)
>
> ##########################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Feb 13 17:33:12 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 13 Feb 2022 16:33:12 +0000
Subject: [R] SDLC methodology for R and Data science......
Message-ID: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

dear members,
                         I am Stock trader and using R for research.

Until now I was coding very haphazardly, but recently I stumbled upon the Software Development Life Cycle (SDLC), which introduced me to principled software design. I am college dropout and don't have in depth knowledge in Software Engineering principles. However, now, I want to go in a structured manner.

I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the R programming language and specifically for data science, but was bootless. Do you people have any idea on which software engineering methodology to use in R and data science, so that I can code efficiently and in a structured manner? The point to note, with regards to R, is that statistical ANALYSIS sometimes takes very little code as compared to other programming languages. Any SDLC method for these types of analysis, besides, rigorous scripting with R?

Thanking you,
Yours sincerely,
AKSHAY M KULKARNI


	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Feb 14 00:53:05 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 14 Feb 2022 12:53:05 +1300
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>

There are at least two ways to use R.
If you have devised a statistical/data science technique
and are writing a package to be used by other people,
that is normal software development that happens to be
using R and the R tool.  Lots of attention to documentation
and tests.  Test-Driven Development is one approach.

Many R users aren't developing code for other people.
They are trying to make sense of some kind of data.
This is what used to be called "exploratory programming".
And heavyweight development processes aren't really
appropriate for this kind of work.  In traditional terms,
when you are doing exploratory programming, you spend
most of your time in the requirements phase.

Perhaps the most important thing here is to keep a log
of what you are doing and record things that didn't work,
why they didn't work, and what you learned from it.
When something DOES give you some insight, you want to
be able to do it again.

The tricky thing is scaling from exploration to development.
After playing around with one data set, you might want to
provide a script that other people can use to process
similar data sets the same way.
Use a light weight process, but make sure you have plenty
of tests, and adequate documentation.

Watts Humphrey developed something he called the "Personal
Software Process" and wrote a book about it.  I don't like
his examples for several reasons, but the point about
watching what you do and measuring it so you can improve is
well made.



On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com> wrote:

> dear members,
>                          I am Stock trader and using R for research.
>
> Until now I was coding very haphazardly, but recently I stumbled upon the
> Software Development Life Cycle (SDLC), which introduced me to principled
> software design. I am college dropout and don't have in depth knowledge in
> Software Engineering principles. However, now, I want to go in a structured
> manner.
>
> I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the
> R programming language and specifically for data science, but was bootless.
> Do you people have any idea on which software engineering methodology to
> use in R and data science, so that I can code efficiently and in a
> structured manner? The point to note, with regards to R, is that
> statistical ANALYSIS sometimes takes very little code as compared to other
> programming languages. Any SDLC method for these types of analysis,
> besides, rigorous scripting with R?
>
> Thanking you,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Feb 14 00:55:15 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 14 Feb 2022 12:55:15 +1300
Subject: [R] Convert a character string to variable names
In-Reply-To: <BN6PR2201MB15539D4D06CB06DD6219AC82CF329@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAdLF3_3Re7XeSBG8FspaLSidtjXSi2=8CBZ337SQEspmjA@mail.gmail.com>
 <BN6PR2201MB15539D4D06CB06DD6219AC82CF329@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CABcYAd+dsnXy4S+n_HXp782iFEuywGNv1TfxiHFrw4aQcD+yjw@mail.gmail.com>

Objects have mutable state, values don't.

On Sun, 13 Feb 2022 at 16:26, Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> How does ?a value? differ from ?an object??
>
>
>
> *From:* Richard O'Keefe <raoknz at gmail.com>
> *Sent:* Friday, February 11, 2022 12:25 AM
> *To:* Ebert,Timothy Aaron <tebert at ufl.edu>
> *Cc:* Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org;
> Erin Hodgess <erinm.hodgess at gmail.com>
> *Subject:* Re: [R] Convert a character string to variable names
>
>
>
> *[External Email]*
>
> You wrote "32 numbers is not a value".
>
> It is, it really is.  When you have a vector like
>
>  x <- 1:32
>
> you have a simple variable (x) referring to an immutable value
>
> (1, 2, ..., 32).  A vector in R is NOT a collection of mutable
>
> boxes, it is a collection of *numbers* (or strings).  The vector
>
> itself is a good a value as ever twanged.  You cannot change it.
>
> A statement like
>
>  x[i] <- 77
>
> is just shorthand for
>
>  x <- "[<-"(x, i, 77)
>
> which constructs a whole new 32-number value and assigns that to x.
>
> (The actual implementation is cleverer when it can be, but often it
>
> cannot be clever.)
>
> Pure values like vectors can be shared: if x is a vector,
>
> then y <- x is a constant time operation.  If you then change
>
> y, you only change y, not the vector.  x is unchanged.
>
>
>
>
>
> On Wed, 9 Feb 2022 at 17:06, Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>
> "A variable in R can refer to many things, ..." I agree.
> "It absolutely _can_ refer to a list, ..." I partly agree. In R as a
> programming language I agree. In R as a statistical analysis tool then only
> partly. Typically one would need to limit the list so each variable would
> be of the same length and all values within the variable be of the same
> data type (integer, real, factor, character). As a programmer yes, as a
> statistician not really unless you always qualify the type of list
> considered and that gets tiresome.
>
> R does name individual elements using numeric place names: hence df[row,
> column]. Each element must have a unique address, and that is true in all
> computer languages.
>
> A dataframe is a list of columns of the same length containing the same
> data type within a column.
>
> mtcars$disp does not have a value (a value is one number). With 32
> elements I can calculate a mean and the mean is a value. 32 numbers is not
> a value. I suppose a single value could be the starting memory address of
> the name, but I don't see how that distinction helps unless one is doing
> Assembly or Machine language programming.
>
> I have never used get(), so I will keep that in mind. I agree that it
> makes life much easier to enter the data in the way it will be analyzed.
>
>
>
>
> -----Original Message-----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Tuesday, February 8, 2022 10:10 PM
> To: r-help at r-project.org; Ebert,Timothy Aaron <tebert at ufl.edu>; Richard
> O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Convert a character string to variable names
>
> [External Email]
>
> A variable in R can refer to many things, but it cannot be an element of a
> vector. It absolutely _can_ refer to a list, a list of lists, a function,
> an environment, and any of the various kinds of atomic vectors that you
> seem to think of as variables. (R does _not_ name individual elements of
> vectors, unlike many other languages.)
>
> The things you can do with the mtcars object may be different than the
> things you can do with the object identified by the expression mtcars$disp,
> but the former has a variable name in an environment while the latter is
> embedded within the former. mtcars$disp is shorthand for the expression
> mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a
> data frame is a list of columns) to refer to that object.
>
> R allows non-standard evaluation to make elements of lists accessible as
> though they were variables in an environment, such as with( mtcars, disp )
> or various tidyverse evaluation conventions. But while the expression
> mtcars$disp DOES have a value( it is an atomic vector of 32 integer
> elements) it is not a variable so get("mtcars$disp") cannot be expected to
> work (as it does not). You may be confusing "variable" with "object" ...
> lots of objects have no variable names.
>
> I have done all sorts of complicated data manipulations in R, but I have
> never found a situation where a use of get() could not be replaced with a
> clearer way to get the job done. Using lists is central to this... avoid
> making distinct variables in the first place if you plan to be retrieving
> them later indirectly like this.
>
> On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu>
> wrote:
> >
> >I had thought that mtcars in "mtcars$disp" was the name of a dataframe
> and that "disp" was the name of a column in the dataframe. If I would make
> a model like horse power = displacement then "disp" would be a variable in
> the model and I can find values for this variable in the "disp" column in
> the "mtcars" dataframe. I am not sure how I would use "mtcars" as a
> variable.
> >"mtcars$disp" has no specific value, though it will have a specific value
> for any given row of data (assuming rows are observations).
> >
> >Tim
> >
> >
> >-----Original Message-----
> >From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard
> >O'Keefe
> >Sent: Tuesday, February 8, 2022 8:17 PM
> >To: Erin Hodgess <erinm.hodgess at gmail.com>
> >Cc: r-help at r-project.org
> >Subject: Re: [R] Convert a character string to variable names
> >
> >[External Email]
> >
> >"mtcars$disp" is not a variable name.
> >"mtcars" is a variable name, and
> >get("mtcars") will get the value of that variable assign("mtcars",
> ~~whatever~~) will set it.
> >mtcars$disp is an *expression*,
> >where $ is an indexing operator
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
> >rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
> >-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
> >y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
> >LPBhHxSlWk&e=
> >so what you want is
> >> mtcars <- list(cyl=4, disp=1.8)
> >> eval(parse(text="mtcars$disp"))
> >[1] 1.8
> >
> >Though it's easy to do this, it's very seldom a good idea.
> >The combination of parse and eval can do ANYTHING, no matter how
> disastrous.  Less powerful techniques are safer.
> >Where do these strings come from in the first place?
> >Why isn't it c("disp", "hp", "cyl")?
> >
> >On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >
> >> Hello!
> >>
> >> I have a character string that is a vector of variable names.  I
> >> would like to use those names to access the variables and create a
> matrix.
> >> I tried the following:
> >>
> >> > .x
> >>
> >> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> >>
> >> > .y <- NULL
> >>
> >> > for(i in 1:3) {
> >>
> >> + .y[i] <- c(as.name
> <https://urldefense.proofpoint.com/v2/url?u=http-3A__as.name&d=DwMFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=vzlTpQd9zYJkQ77y8VRROjzMQQJrJce_5rInko9TViGjuIt93PxagLXs9prJsMwy&s=Yrczdj8QHFrWSBSm_k4WyKN7ppY20M360b7tUmMCJaY&e=>
> (.x[[i]]))
> >>
> >> + }
> >>
> >> > .y
> >>
> >> [[1]]
> >>
> >> `mtcars$disp`
> >>
> >>
> >> [[2]]
> >>
> >> `mtcars$hp`
> >>
> >>
> >> [[3]]
> >>
> >> `mtcars$cyl`
> >>
> >>
> >> But I am having trouble converting the variables in .y into a matrix.
> >>
> >>
> >> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
> >>
> >>
> >> I have a feeling that it's something simple, and I'm just not seeing it.
> >>
> >>
> >> Thanks,
> >>
> >> Erin
> >>
> >>
> >>
> >>
> >> Erin Hodgess, PhD
> >> mailto: erinm.hodgess at gmail.com
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
> >> l
> >> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> >> s
> >> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
> >> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> >> PLEASE do read the posting guide
> >> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
> >> r
> >> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
> >> A
> >> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
> >> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
> >an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
> >sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
> >D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> >PLEASE do read the posting guide
> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
> >_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
> >zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
> >mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
> >an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
> >sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
> >iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
> >PLEASE do read the posting guide
> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
> >_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
> >zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
> >ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Mon Feb 14 02:57:14 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 14 Feb 2022 01:57:14 +0000
Subject: [R] Convert a character string to variable names
In-Reply-To: <CABcYAd+dsnXy4S+n_HXp782iFEuywGNv1TfxiHFrw4aQcD+yjw@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAdLF3_3Re7XeSBG8FspaLSidtjXSi2=8CBZ337SQEspmjA@mail.gmail.com>
 <BN6PR2201MB15539D4D06CB06DD6219AC82CF329@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAd+dsnXy4S+n_HXp782iFEuywGNv1TfxiHFrw4aQcD+yjw@mail.gmail.com>
Message-ID: <BN6PR2201MB15538ADE46831ED77B5378B2CF339@BN6PR2201MB1553.namprd22.prod.outlook.com>

But I find things like this website on mutable and immutable objects in python ?https://www.geeksforgeeks.org/mutable-vs-immutable-objects-in-python/? Would this be better titled ?Objects versus values in Python??

From: Richard O'Keefe <raoknz at gmail.com>
Sent: Sunday, February 13, 2022 6:55 PM
To: Ebert,Timothy Aaron <tebert at ufl.edu>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org; Erin Hodgess <erinm.hodgess at gmail.com>
Subject: Re: [R] Convert a character string to variable names

[External Email]
Objects have mutable state, values don't.

On Sun, 13 Feb 2022 at 16:26, Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
How does ?a value? differ from ?an object??

From: Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>>
Sent: Friday, February 11, 2022 12:25 AM
To: Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>; r-help at r-project.org<mailto:r-help at r-project.org>; Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
Subject: Re: [R] Convert a character string to variable names

[External Email]
You wrote "32 numbers is not a value".
It is, it really is.  When you have a vector like
 x <- 1:32
you have a simple variable (x) referring to an immutable value
(1, 2, ..., 32).  A vector in R is NOT a collection of mutable
boxes, it is a collection of *numbers* (or strings).  The vector
itself is a good a value as ever twanged.  You cannot change it.
A statement like
 x[i] <- 77
is just shorthand for
 x <- "[<-"(x, i, 77)
which constructs a whole new 32-number value and assigns that to x.
(The actual implementation is cleverer when it can be, but often it
cannot be clever.)
Pure values like vectors can be shared: if x is a vector,
then y <- x is a constant time operation.  If you then change
y, you only change y, not the vector.  x is unchanged.


On Wed, 9 Feb 2022 at 17:06, Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
"A variable in R can refer to many things, ..." I agree.
"It absolutely _can_ refer to a list, ..." I partly agree. In R as a programming language I agree. In R as a statistical analysis tool then only partly. Typically one would need to limit the list so each variable would be of the same length and all values within the variable be of the same data type (integer, real, factor, character). As a programmer yes, as a statistician not really unless you always qualify the type of list considered and that gets tiresome.

R does name individual elements using numeric place names: hence df[row, column]. Each element must have a unique address, and that is true in all computer languages.

A dataframe is a list of columns of the same length containing the same data type within a column.

mtcars$disp does not have a value (a value is one number). With 32 elements I can calculate a mean and the mean is a value. 32 numbers is not a value. I suppose a single value could be the starting memory address of the name, but I don't see how that distinction helps unless one is doing Assembly or Machine language programming.

I have never used get(), so I will keep that in mind. I agree that it makes life much easier to enter the data in the way it will be analyzed.




-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>
Sent: Tuesday, February 8, 2022 10:10 PM
To: r-help at r-project.org<mailto:r-help at r-project.org>; Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>>; Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>>; Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Convert a character string to variable names

[External Email]

A variable in R can refer to many things, but it cannot be an element of a vector. It absolutely _can_ refer to a list, a list of lists, a function, an environment, and any of the various kinds of atomic vectors that you seem to think of as variables. (R does _not_ name individual elements of vectors, unlike many other languages.)

The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.

R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.

I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.

On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
>
>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>
>Tim
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Richard
>O'Keefe
>Sent: Tuesday, February 8, 2022 8:17 PM
>To: Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
>Cc: r-help at r-project.org<mailto:r-help at r-project.org>
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>
>"mtcars$disp" is not a variable name.
>"mtcars" is a variable name, and
>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>mtcars$disp is an *expression*,
>where $ is an indexing operator
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
>rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
>-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
>y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
>LPBhHxSlWk&e=
>so what you want is
>> mtcars <- list(cyl=4, disp=1.8)
>> eval(parse(text="mtcars$disp"))
>[1] 1.8
>
>Though it's easy to do this, it's very seldom a good idea.
>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>Where do these strings come from in the first place?
>Why isn't it c("disp", "hp", "cyl")?
>
>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>> wrote:
>
>> Hello!
>>
>> I have a character string that is a vector of variable names.  I
>> would like to use those names to access the variables and create a matrix.
>> I tried the following:
>>
>> > .x
>>
>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>
>> > .y <- NULL
>>
>> > for(i in 1:3) {
>>
>> + .y[i] <- c(as.name<https://urldefense.proofpoint.com/v2/url?u=http-3A__as.name&d=DwMFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=vzlTpQd9zYJkQ77y8VRROjzMQQJrJce_5rInko9TViGjuIt93PxagLXs9prJsMwy&s=Yrczdj8QHFrWSBSm_k4WyKN7ppY20M360b7tUmMCJaY&e=>(.x[[i]]))
>>
>> + }
>>
>> > .y
>>
>> [[1]]
>>
>> `mtcars$disp`
>>
>>
>> [[2]]
>>
>> `mtcars$hp`
>>
>>
>> [[3]]
>>
>> `mtcars$cyl`
>>
>>
>> But I am having trouble converting the variables in .y into a matrix.
>>
>>
>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>
>>
>> I have a feeling that it's something simple, and I'm just not seeing it.
>>
>>
>> Thanks,
>>
>> Erin
>>
>>
>>
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
>> l
>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>> s
>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
>> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
>> r
>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
>> A
>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
>> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
>D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
>mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
>iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
>ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Tue Feb 15 04:49:22 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 15 Feb 2022 16:49:22 +1300
Subject: [R] Convert a character string to variable names
In-Reply-To: <BN6PR2201MB15538ADE46831ED77B5378B2CF339@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAdLF3_3Re7XeSBG8FspaLSidtjXSi2=8CBZ337SQEspmjA@mail.gmail.com>
 <BN6PR2201MB15539D4D06CB06DD6219AC82CF329@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAd+dsnXy4S+n_HXp782iFEuywGNv1TfxiHFrw4aQcD+yjw@mail.gmail.com>
 <BN6PR2201MB15538ADE46831ED77B5378B2CF339@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CABcYAdKhBA8H1JpL--w0g=5NMo5gyYaPwvS_-uJNvbX-zmpKsg@mail.gmail.com>

How soon they forget.
An object is characterised by three things:
- Identity, a property that distinguishes the
  object from all other objects regardless of
  their state
- State, what the object "knows", the information
  it contains, typically mutable
- Behaviour, what the object can "do", methods,
  generic functions, whatever.

Back in the days when there was much debate about what OOP
was and whether language X was an OOP language or merely an
"object-based" language, these were the criteria.

The thing about values is that they don't have an
identity.  Is there one copy of the number 137.035999206
in the computer or several?  If you can *tell* one
occurrence of 137.035999206 from another, you may be
dealing with objects, if not, with values.

There is no way to tell one copy of 137.035999206
from another in the R *language*.
However, there is a package "pryr" which provides
what used to be called "A Window into Hell".  It
provides things that relate to the R *implementation*
like refs(x) -- a number counting how many references
there are to x -- and address(x) -- a string with the
address of x as a string of hexadecimal digits.
One could imagine a different implementation of R in which
refs() was hideously expensive and in which address() could
change unpredictably, so I advise you to forget about them
at once.  Since the outcome of
   x <- 137.035999206
   y <- x + 0
   address(x) == address(y)
depends on the cleverness of the compiler, a thing
that is subject to change, you'll appreciate this is
not a smart thing to depend on.

The point is that you can only tell the difference
between copies of 137.035999206 by hacking into the
implementation in a way that isn't really consistent with
the spirit of the language.





On Mon, 14 Feb 2022 at 14:57, Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> But I find things like this website on mutable and immutable objects in
> python ?
> https://www.geeksforgeeks.org/mutable-vs-immutable-objects-in-python/?
> Would this be better titled ?Objects versus values in Python??
>
>
>
> *From:* Richard O'Keefe <raoknz at gmail.com>
> *Sent:* Sunday, February 13, 2022 6:55 PM
> *To:* Ebert,Timothy Aaron <tebert at ufl.edu>
> *Cc:* Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org;
> Erin Hodgess <erinm.hodgess at gmail.com>
> *Subject:* Re: [R] Convert a character string to variable names
>
>
>
> *[External Email]*
>
> Objects have mutable state, values don't.
>
>
>
> On Sun, 13 Feb 2022 at 16:26, Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>
> How does ?a value? differ from ?an object??
>
>
>
> *From:* Richard O'Keefe <raoknz at gmail.com>
> *Sent:* Friday, February 11, 2022 12:25 AM
> *To:* Ebert,Timothy Aaron <tebert at ufl.edu>
> *Cc:* Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org;
> Erin Hodgess <erinm.hodgess at gmail.com>
> *Subject:* Re: [R] Convert a character string to variable names
>
>
>
> *[External Email]*
>
> You wrote "32 numbers is not a value".
>
> It is, it really is.  When you have a vector like
>
>  x <- 1:32
>
> you have a simple variable (x) referring to an immutable value
>
> (1, 2, ..., 32).  A vector in R is NOT a collection of mutable
>
> boxes, it is a collection of *numbers* (or strings).  The vector
>
> itself is a good a value as ever twanged.  You cannot change it.
>
> A statement like
>
>  x[i] <- 77
>
> is just shorthand for
>
>  x <- "[<-"(x, i, 77)
>
> which constructs a whole new 32-number value and assigns that to x.
>
> (The actual implementation is cleverer when it can be, but often it
>
> cannot be clever.)
>
> Pure values like vectors can be shared: if x is a vector,
>
> then y <- x is a constant time operation.  If you then change
>
> y, you only change y, not the vector.  x is unchanged.
>
>
>
>
>
> On Wed, 9 Feb 2022 at 17:06, Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>
> "A variable in R can refer to many things, ..." I agree.
> "It absolutely _can_ refer to a list, ..." I partly agree. In R as a
> programming language I agree. In R as a statistical analysis tool then only
> partly. Typically one would need to limit the list so each variable would
> be of the same length and all values within the variable be of the same
> data type (integer, real, factor, character). As a programmer yes, as a
> statistician not really unless you always qualify the type of list
> considered and that gets tiresome.
>
> R does name individual elements using numeric place names: hence df[row,
> column]. Each element must have a unique address, and that is true in all
> computer languages.
>
> A dataframe is a list of columns of the same length containing the same
> data type within a column.
>
> mtcars$disp does not have a value (a value is one number). With 32
> elements I can calculate a mean and the mean is a value. 32 numbers is not
> a value. I suppose a single value could be the starting memory address of
> the name, but I don't see how that distinction helps unless one is doing
> Assembly or Machine language programming.
>
> I have never used get(), so I will keep that in mind. I agree that it
> makes life much easier to enter the data in the way it will be analyzed.
>
>
>
>
> -----Original Message-----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Tuesday, February 8, 2022 10:10 PM
> To: r-help at r-project.org; Ebert,Timothy Aaron <tebert at ufl.edu>; Richard
> O'Keefe <raoknz at gmail.com>; Erin Hodgess <erinm.hodgess at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Convert a character string to variable names
>
> [External Email]
>
> A variable in R can refer to many things, but it cannot be an element of a
> vector. It absolutely _can_ refer to a list, a list of lists, a function,
> an environment, and any of the various kinds of atomic vectors that you
> seem to think of as variables. (R does _not_ name individual elements of
> vectors, unlike many other languages.)
>
> The things you can do with the mtcars object may be different than the
> things you can do with the object identified by the expression mtcars$disp,
> but the former has a variable name in an environment while the latter is
> embedded within the former. mtcars$disp is shorthand for the expression
> mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a
> data frame is a list of columns) to refer to that object.
>
> R allows non-standard evaluation to make elements of lists accessible as
> though they were variables in an environment, such as with( mtcars, disp )
> or various tidyverse evaluation conventions. But while the expression
> mtcars$disp DOES have a value( it is an atomic vector of 32 integer
> elements) it is not a variable so get("mtcars$disp") cannot be expected to
> work (as it does not). You may be confusing "variable" with "object" ...
> lots of objects have no variable names.
>
> I have done all sorts of complicated data manipulations in R, but I have
> never found a situation where a use of get() could not be replaced with a
> clearer way to get the job done. Using lists is central to this... avoid
> making distinct variables in the first place if you plan to be retrieving
> them later indirectly like this.
>
> On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu>
> wrote:
> >
> >I had thought that mtcars in "mtcars$disp" was the name of a dataframe
> and that "disp" was the name of a column in the dataframe. If I would make
> a model like horse power = displacement then "disp" would be a variable in
> the model and I can find values for this variable in the "disp" column in
> the "mtcars" dataframe. I am not sure how I would use "mtcars" as a
> variable.
> >"mtcars$disp" has no specific value, though it will have a specific value
> for any given row of data (assuming rows are observations).
> >
> >Tim
> >
> >
> >-----Original Message-----
> >From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard
> >O'Keefe
> >Sent: Tuesday, February 8, 2022 8:17 PM
> >To: Erin Hodgess <erinm.hodgess at gmail.com>
> >Cc: r-help at r-project.org
> >Subject: Re: [R] Convert a character string to variable names
> >
> >[External Email]
> >
> >"mtcars$disp" is not a variable name.
> >"mtcars" is a variable name, and
> >get("mtcars") will get the value of that variable assign("mtcars",
> ~~whatever~~) will set it.
> >mtcars$disp is an *expression*,
> >where $ is an indexing operator
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
> >rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
> >-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
> >y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
> >LPBhHxSlWk&e=
> >so what you want is
> >> mtcars <- list(cyl=4, disp=1.8)
> >> eval(parse(text="mtcars$disp"))
> >[1] 1.8
> >
> >Though it's easy to do this, it's very seldom a good idea.
> >The combination of parse and eval can do ANYTHING, no matter how
> disastrous.  Less powerful techniques are safer.
> >Where do these strings come from in the first place?
> >Why isn't it c("disp", "hp", "cyl")?
> >
> >On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >
> >> Hello!
> >>
> >> I have a character string that is a vector of variable names.  I
> >> would like to use those names to access the variables and create a
> matrix.
> >> I tried the following:
> >>
> >> > .x
> >>
> >> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
> >>
> >> > .y <- NULL
> >>
> >> > for(i in 1:3) {
> >>
> >> + .y[i] <- c(as.name
> <https://urldefense.proofpoint.com/v2/url?u=http-3A__as.name&d=DwMFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=vzlTpQd9zYJkQ77y8VRROjzMQQJrJce_5rInko9TViGjuIt93PxagLXs9prJsMwy&s=Yrczdj8QHFrWSBSm_k4WyKN7ppY20M360b7tUmMCJaY&e=>
> (.x[[i]]))
> >>
> >> + }
> >>
> >> > .y
> >>
> >> [[1]]
> >>
> >> `mtcars$disp`
> >>
> >>
> >> [[2]]
> >>
> >> `mtcars$hp`
> >>
> >>
> >> [[3]]
> >>
> >> `mtcars$cyl`
> >>
> >>
> >> But I am having trouble converting the variables in .y into a matrix.
> >>
> >>
> >> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
> >>
> >>
> >> I have a feeling that it's something simple, and I'm just not seeing it.
> >>
> >>
> >> Thanks,
> >>
> >> Erin
> >>
> >>
> >>
> >>
> >> Erin Hodgess, PhD
> >> mailto: erinm.hodgess at gmail.com
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
> >> l
> >> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> >> s
> >> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
> >> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> >> PLEASE do read the posting guide
> >> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
> >> r
> >> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
> >> A
> >> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
> >> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
> >an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
> >sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
> >D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
> >PLEASE do read the posting guide
> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
> >_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
> >zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
> >mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
> >an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
> >sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
> >iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
> >PLEASE do read the posting guide
> >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
> >_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
> >zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
> >ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Tue Feb 15 14:44:29 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Tue, 15 Feb 2022 13:44:29 +0000
Subject: [R] Convert a character string to variable names
In-Reply-To: <CABcYAdKhBA8H1JpL--w0g=5NMo5gyYaPwvS_-uJNvbX-zmpKsg@mail.gmail.com>
References: <CACxE24=yw1MOghkL56b+EHJwxfDCKWqfjHeDZxESqbGf8vp55w@mail.gmail.com>
 <CABcYAdLLsmjmRJA_Pzpmmn+YtrVV1dZPv-mgfwcLD3dJM6uFKA@mail.gmail.com>
 <BN6PR2201MB1553CD7D53D129B4B938F4F6CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <18A23D60-A5CA-4BC8-9E7E-DF986511D14A@dcn.davis.ca.us>
 <BN6PR2201MB15538AD80F0842888D442F34CF2E9@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAdLF3_3Re7XeSBG8FspaLSidtjXSi2=8CBZ337SQEspmjA@mail.gmail.com>
 <BN6PR2201MB15539D4D06CB06DD6219AC82CF329@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAd+dsnXy4S+n_HXp782iFEuywGNv1TfxiHFrw4aQcD+yjw@mail.gmail.com>
 <BN6PR2201MB15538ADE46831ED77B5378B2CF339@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABcYAdKhBA8H1JpL--w0g=5NMo5gyYaPwvS_-uJNvbX-zmpKsg@mail.gmail.com>
Message-ID: <BN6PR2201MB15536D5BF3A77FCB4A429D6ECF349@BN6PR2201MB1553.namprd22.prod.outlook.com>

Thank you Richard and Jeff.


From: Richard O'Keefe <raoknz at gmail.com>
Sent: Monday, February 14, 2022 10:49 PM
To: Ebert,Timothy Aaron <tebert at ufl.edu>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org; Erin Hodgess <erinm.hodgess at gmail.com>
Subject: Re: [R] Convert a character string to variable names

[External Email]
How soon they forget.
An object is characterised by three things:
- Identity, a property that distinguishes the
  object from all other objects regardless of
  their state
- State, what the object "knows", the information
  it contains, typically mutable
- Behaviour, what the object can "do", methods,
  generic functions, whatever.

Back in the days when there was much debate about what OOP
was and whether language X was an OOP language or merely an
"object-based" language, these were the criteria.

The thing about values is that they don't have an
identity.  Is there one copy of the number 137.035999206
in the computer or several?  If you can *tell* one
occurrence of 137.035999206 from another, you may be
dealing with objects, if not, with values.

There is no way to tell one copy of 137.035999206
from another in the R *language*.
However, there is a package "pryr" which provides
what used to be called "A Window into Hell".  It
provides things that relate to the R *implementation*
like refs(x) -- a number counting how many references
there are to x -- and address(x) -- a string with the
address of x as a string of hexadecimal digits.
One could imagine a different implementation of R in which
refs() was hideously expensive and in which address() could
change unpredictably, so I advise you to forget about them
at once.  Since the outcome of
   x <- 137.035999206
   y <- x + 0
   address(x) == address(y)
depends on the cleverness of the compiler, a thing
that is subject to change, you'll appreciate this is
not a smart thing to depend on.

The point is that you can only tell the difference
between copies of 137.035999206 by hacking into the
implementation in a way that isn't really consistent with
the spirit of the language.





On Mon, 14 Feb 2022 at 14:57, Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
But I find things like this website on mutable and immutable objects in python ?https://www.geeksforgeeks.org/mutable-vs-immutable-objects-in-python/<https://urldefense.proofpoint.com/v2/url?u=https-3A__www.geeksforgeeks.org_mutable-2Dvs-2Dimmutable-2Dobjects-2Din-2Dpython_&d=DwMFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=n7nCoQKipnYWUuAv-GWY4k99KmhdcyEyYVD-kv-f04vp3MRD7TF5HecsNt0zmQ0C&s=vWKs8nGXPwSttJMa1pAk682Ai1Y3_B5OL-C5d6Ufb7Y&e=>? Would this be better titled ?Objects versus values in Python??

From: Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>>
Sent: Sunday, February 13, 2022 6:55 PM
To: Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>; r-help at r-project.org<mailto:r-help at r-project.org>; Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
Subject: Re: [R] Convert a character string to variable names

[External Email]
Objects have mutable state, values don't.

On Sun, 13 Feb 2022 at 16:26, Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
How does ?a value? differ from ?an object??

From: Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>>
Sent: Friday, February 11, 2022 12:25 AM
To: Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>; r-help at r-project.org<mailto:r-help at r-project.org>; Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
Subject: Re: [R] Convert a character string to variable names

[External Email]
You wrote "32 numbers is not a value".
It is, it really is.  When you have a vector like
 x <- 1:32
you have a simple variable (x) referring to an immutable value
(1, 2, ..., 32).  A vector in R is NOT a collection of mutable
boxes, it is a collection of *numbers* (or strings).  The vector
itself is a good a value as ever twanged.  You cannot change it.
A statement like
 x[i] <- 77
is just shorthand for
 x <- "[<-"(x, i, 77)
which constructs a whole new 32-number value and assigns that to x.
(The actual implementation is cleverer when it can be, but often it
cannot be clever.)
Pure values like vectors can be shared: if x is a vector,
then y <- x is a constant time operation.  If you then change
y, you only change y, not the vector.  x is unchanged.


On Wed, 9 Feb 2022 at 17:06, Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
"A variable in R can refer to many things, ..." I agree.
"It absolutely _can_ refer to a list, ..." I partly agree. In R as a programming language I agree. In R as a statistical analysis tool then only partly. Typically one would need to limit the list so each variable would be of the same length and all values within the variable be of the same data type (integer, real, factor, character). As a programmer yes, as a statistician not really unless you always qualify the type of list considered and that gets tiresome.

R does name individual elements using numeric place names: hence df[row, column]. Each element must have a unique address, and that is true in all computer languages.

A dataframe is a list of columns of the same length containing the same data type within a column.

mtcars$disp does not have a value (a value is one number). With 32 elements I can calculate a mean and the mean is a value. 32 numbers is not a value. I suppose a single value could be the starting memory address of the name, but I don't see how that distinction helps unless one is doing Assembly or Machine language programming.

I have never used get(), so I will keep that in mind. I agree that it makes life much easier to enter the data in the way it will be analyzed.




-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>
Sent: Tuesday, February 8, 2022 10:10 PM
To: r-help at r-project.org<mailto:r-help at r-project.org>; Ebert,Timothy Aaron <tebert at ufl.edu<mailto:tebert at ufl.edu>>; Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>>; Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Convert a character string to variable names

[External Email]

A variable in R can refer to many things, but it cannot be an element of a vector. It absolutely _can_ refer to a list, a list of lists, a function, an environment, and any of the various kinds of atomic vectors that you seem to think of as variables. (R does _not_ name individual elements of vectors, unlike many other languages.)

The things you can do with the mtcars object may be different than the things you can do with the object identified by the expression mtcars$disp, but the former has a variable name in an environment while the latter is embedded within the former. mtcars$disp is shorthand for the expression mtcars[[ "disp" ]] which searches the names attribute of the mtcars list (a data frame is a list of columns) to refer to that object.

R allows non-standard evaluation to make elements of lists accessible as though they were variables in an environment, such as with( mtcars, disp ) or various tidyverse evaluation conventions. But while the expression mtcars$disp DOES have a value( it is an atomic vector of 32 integer elements) it is not a variable so get("mtcars$disp") cannot be expected to work (as it does not). You may be confusing "variable" with "object" ... lots of objects have no variable names.

I have done all sorts of complicated data manipulations in R, but I have never found a situation where a use of get() could not be replaced with a clearer way to get the job done. Using lists is central to this... avoid making distinct variables in the first place if you plan to be retrieving them later indirectly like this.

On February 8, 2022 5:45:39 PM PST, "Ebert,Timothy Aaron" <tebert at ufl.edu<mailto:tebert at ufl.edu>> wrote:
>
>I had thought that mtcars in "mtcars$disp" was the name of a dataframe and that "disp" was the name of a column in the dataframe. If I would make a model like horse power = displacement then "disp" would be a variable in the model and I can find values for this variable in the "disp" column in the "mtcars" dataframe. I am not sure how I would use "mtcars" as a variable.
>"mtcars$disp" has no specific value, though it will have a specific value for any given row of data (assuming rows are observations).
>
>Tim
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Richard
>O'Keefe
>Sent: Tuesday, February 8, 2022 8:17 PM
>To: Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>>
>Cc: r-help at r-project.org<mailto:r-help at r-project.org>
>Subject: Re: [R] Convert a character string to variable names
>
>[External Email]
>
>"mtcars$disp" is not a variable name.
>"mtcars" is a variable name, and
>get("mtcars") will get the value of that variable assign("mtcars", ~~whatever~~) will set it.
>mtcars$disp is an *expression*,
>where $ is an indexing operator
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.o
>rg_doc_manuals_r-2Drelease_R-2Dlang.html-23Indexing&d=DwICAg&c=sJ6xIWYx
>-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSW
>y4ix2Iz1netW81V-NUV8aOVVqyn5-fmD6cf&s=RjRC5kve6D8k59qZQYcX-PR-aA4TTu1yf
>LPBhHxSlWk&e=
>so what you want is
>> mtcars <- list(cyl=4, disp=1.8)
>> eval(parse(text="mtcars$disp"))
>[1] 1.8
>
>Though it's easy to do this, it's very seldom a good idea.
>The combination of parse and eval can do ANYTHING, no matter how disastrous.  Less powerful techniques are safer.
>Where do these strings come from in the first place?
>Why isn't it c("disp", "hp", "cyl")?
>
>On Tue, 8 Feb 2022 at 11:56, Erin Hodgess <erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>> wrote:
>
>> Hello!
>>
>> I have a character string that is a vector of variable names.  I
>> would like to use those names to access the variables and create a matrix.
>> I tried the following:
>>
>> > .x
>>
>> [1] "mtcars$disp" "mtcars$hp"   "mtcars$cyl"
>>
>> > .y <- NULL
>>
>> > for(i in 1:3) {
>>
>> + .y[i] <- c(as.name<https://urldefense.proofpoint.com/v2/url?u=http-3A__as.name&d=DwMFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=vzlTpQd9zYJkQ77y8VRROjzMQQJrJce_5rInko9TViGjuIt93PxagLXs9prJsMwy&s=Yrczdj8QHFrWSBSm_k4WyKN7ppY20M360b7tUmMCJaY&e=>(.x[[i]]))
>>
>> + }
>>
>> > .y
>>
>> [[1]]
>>
>> `mtcars$disp`
>>
>>
>> [[2]]
>>
>> `mtcars$hp`
>>
>>
>> [[3]]
>>
>> `mtcars$cyl`
>>
>>
>> But I am having trouble converting the variables in .y into a matrix.
>>
>>
>> I tried all kinds of stuff with bquote, deparse, do.call, but no good.
>>
>>
>> I have a feeling that it's something simple, and I'm just not seeing it.
>>
>>
>> Thanks,
>>
>> Erin
>>
>>
>>
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com<mailto:erinm.hodgess at gmail.com>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
>> l
>> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>> s
>> Rzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn
>> 5 -fmD6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.o
>> r
>> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVe
>> A
>> sRzsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqy
>> n 5-fmD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-fm
>D6cf&s=c8oCLZK8TFAAs5d3vhDyB52KR2I9WWSTg6kDjL8orcI&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=CI-7ZdIwlhUvhmOkVD7KJkv3IvSSWy4ix2Iz1netW81V-NUV8aOVVqyn5-f
>mD6cf&s=fTO2Qrx6DmlzcB2uqN4fsDmTMVZwfCsDbLtzMigHWXI&e=
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDFc
>iokP&s=6B9_2qIT3ZzL4bGqJfWfMBQofnf6I2_bpLvdQIMDXj0&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=jyG_tiJYdPBF8hat6uuafk5_ucrnBk_CkkVVmV3SLbXFMTeEFy-zgo7hVDF
>ciokP&s=TTQhZrau_AmlW41w76jtlT7yR-niL17-f1QgYsWePvQ&e=
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Tue Feb 15 17:27:07 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Tue, 15 Feb 2022 16:27:07 +0000
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
Message-ID: <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

Dear richard,
                      I am very grateful for your informative reply.

THe fact is, I am doing a project, which is not less complex,(if not more) than those of Microsoft or Accenture or Google , but I am doing it all by myself. Can you please let me the full title of the book by Watts Humphrey? Or any online resources for "personal software process"? Perhaps I can get some tips on how to go about my project ( I've mostly taken into account standard methods of the state of the art, I am looking for something "whizzy" than aids development by one person).

Thanks again,
Yours sinecerly,
AKSHAY M KULKARNI
________________________________
From: Richard O'Keefe <raoknz at gmail.com>
Sent: Monday, February 14, 2022 5:23 AM
To: akshay kulkarni <akshay_e4 at hotmail.com>
Cc: R help Mailing list <r-help at r-project.org>
Subject: Re: [R] SDLC methodology for R and Data science......

There are at least two ways to use R.
If you have devised a statistical/data science technique
and are writing a package to be used by other people,
that is normal software development that happens to be
using R and the R tool.  Lots of attention to documentation
and tests.  Test-Driven Development is one approach.

Many R users aren't developing code for other people.
They are trying to make sense of some kind of data.
This is what used to be called "exploratory programming".
And heavyweight development processes aren't really
appropriate for this kind of work.  In traditional terms,
when you are doing exploratory programming, you spend
most of your time in the requirements phase.

Perhaps the most important thing here is to keep a log
of what you are doing and record things that didn't work,
why they didn't work, and what you learned from it.
When something DOES give you some insight, you want to
be able to do it again.

The tricky thing is scaling from exploration to development.
After playing around with one data set, you might want to
provide a script that other people can use to process
similar data sets the same way.
Use a light weight process, but make sure you have plenty
of tests, and adequate documentation.

Watts Humphrey developed something he called the "Personal
Software Process" and wrote a book about it.  I don't like
his examples for several reasons, but the point about
watching what you do and measuring it so you can improve is
well made.



On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>> wrote:
dear members,
                         I am Stock trader and using R for research.

Until now I was coding very haphazardly, but recently I stumbled upon the Software Development Life Cycle (SDLC), which introduced me to principled software design. I am college dropout and don't have in depth knowledge in Software Engineering principles. However, now, I want to go in a structured manner.

I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the R programming language and specifically for data science, but was bootless. Do you people have any idea on which software engineering methodology to use in R and data science, so that I can code efficiently and in a structured manner? The point to note, with regards to R, is that statistical ANALYSIS sometimes takes very little code as compared to other programming languages. Any SDLC method for these types of analysis, besides, rigorous scripting with R?

Thanking you,
Yours sincerely,
AKSHAY M KULKARNI


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb 15 17:36:34 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 15 Feb 2022 08:36:34 -0800
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
 <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQVvGwwimV7djguMBjR7z_fDMo7bW0g8p1XqP6_VHZkQA@mail.gmail.com>

1. This dialogue should be taken offlist imo.

2. And really, make some effort of your own before posting: An internet
search on "Watts Humphrey Software Development" immediately brought up what
appeared to be answers to at least some of your queries.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 15, 2022 at 8:27 AM akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> Dear richard,
>                       I am very grateful for your informative reply.
>
> THe fact is, I am doing a project, which is not less complex,(if not more)
> than those of Microsoft or Accenture or Google , but I am doing it all by
> myself. Can you please let me the full title of the book by Watts Humphrey?
> Or any online resources for "personal software process"? Perhaps I can get
> some tips on how to go about my project ( I've mostly taken into account
> standard methods of the state of the art, I am looking for something
> "whizzy" than aids development by one person).
>
> Thanks again,
> Yours sinecerly,
> AKSHAY M KULKARNI
> ________________________________
> From: Richard O'Keefe <raoknz at gmail.com>
> Sent: Monday, February 14, 2022 5:23 AM
> To: akshay kulkarni <akshay_e4 at hotmail.com>
> Cc: R help Mailing list <r-help at r-project.org>
> Subject: Re: [R] SDLC methodology for R and Data science......
>
> There are at least two ways to use R.
> If you have devised a statistical/data science technique
> and are writing a package to be used by other people,
> that is normal software development that happens to be
> using R and the R tool.  Lots of attention to documentation
> and tests.  Test-Driven Development is one approach.
>
> Many R users aren't developing code for other people.
> They are trying to make sense of some kind of data.
> This is what used to be called "exploratory programming".
> And heavyweight development processes aren't really
> appropriate for this kind of work.  In traditional terms,
> when you are doing exploratory programming, you spend
> most of your time in the requirements phase.
>
> Perhaps the most important thing here is to keep a log
> of what you are doing and record things that didn't work,
> why they didn't work, and what you learned from it.
> When something DOES give you some insight, you want to
> be able to do it again.
>
> The tricky thing is scaling from exploration to development.
> After playing around with one data set, you might want to
> provide a script that other people can use to process
> similar data sets the same way.
> Use a light weight process, but make sure you have plenty
> of tests, and adequate documentation.
>
> Watts Humphrey developed something he called the "Personal
> Software Process" and wrote a book about it.  I don't like
> his examples for several reasons, but the point about
> watching what you do and measuring it so you can improve is
> well made.
>
>
>
> On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com
> <mailto:akshay_e4 at hotmail.com>> wrote:
> dear members,
>                          I am Stock trader and using R for research.
>
> Until now I was coding very haphazardly, but recently I stumbled upon the
> Software Development Life Cycle (SDLC), which introduced me to principled
> software design. I am college dropout and don't have in depth knowledge in
> Software Engineering principles. However, now, I want to go in a structured
> manner.
>
> I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the
> R programming language and specifically for data science, but was bootless.
> Do you people have any idea on which software engineering methodology to
> use in R and data science, so that I can code efficiently and in a
> structured manner? The point to note, with regards to R, is that
> statistical ANALYSIS sometimes takes very little code as compared to other
> programming languages. Any SDLC method for these types of analysis,
> besides, rigorous scripting with R?
>
> Thanking you,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Tue Feb 15 17:52:29 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Tue, 15 Feb 2022 16:52:29 +0000
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <CADsG8gO0DWZxd9kxE_N4BkqoCJZZxEjTJ9dgQCJhLrSfjrR+sw@mail.gmail.com>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
 <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CADsG8gO0DWZxd9kxE_N4BkqoCJZZxEjTJ9dgQCJhLrSfjrR+sw@mail.gmail.com>
Message-ID: <PU4P216MB1568D9DFB125C9D46EF301F9C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

Dear Khalil,
                    THanks a lot.
________________________________
From: Huzefa Khalil <huzefak at umich.edu>
Sent: Tuesday, February 15, 2022 10:04 PM
To: akshay kulkarni <akshay_e4 at hotmail.com>
Cc: Richard O'Keefe <raoknz at gmail.com>; R help Mailing list <r-help at r-project.org>
Subject: Re: [R] SDLC methodology for R and Data science......

A book I have found useful in this regard is The Workflow of Data
Analysis Using Stata by J. Scott Long. Obviously the book is targeted
towards Stata users but the concepts work just as well for R.


On Tue, Feb 15, 2022 at 11:27 AM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> Dear richard,
>                       I am very grateful for your informative reply.
>
> THe fact is, I am doing a project, which is not less complex,(if not more) than those of Microsoft or Accenture or Google , but I am doing it all by myself. Can you please let me the full title of the book by Watts Humphrey
t some tips on how to go about my project ( I've mostly taken into account standard methods of the state of the art, I am looking for something "whizzy" than aids development by one person).
>
> Thanks again,
> Yours sinecerly,
> AKSHAY M KULKARNI
> ________________________________
> From: Richard O'Keefe <raoknz at gmail.com>
> Sent: Monday, February 14, 2022 5:23 AM
> To: akshay kulkarni <akshay_e4 at hotmail.com>
> Cc: R help Mailing list <r-help at r-project.org>
> Subject: Re: [R] SDLC methodology for R and Data science......
>
> There are at least two ways to use R.
> If you have devised a statistical/data science technique
> and are writing a package to be used by other people,
> that is normal software development that happens to be
> using R and the R tool.  Lots of attention to documentation
> and tests.  Test-Driven Development is one approach.
>
> Many R users aren't developing code for other people.
> They are trying to make sense of some kind of data.
> This is what used to be called "exploratory programming".
> And heavyweight development processes aren't really
> appropriate for this kind of work.  In traditional terms,
> when you are doing exploratory programming, you spend
> most of your time in the requirements phase.
>
> Perhaps the most important thing here is to keep a log
> of what you are doing and record things that didn't work,
> why they didn't work, and what you learned from it.
> When something DOES give you some insight, you want to
> be able to do it again.
>
> The tricky thing is scaling from exploration to development.
> After playing around with one data set, you might want to
> provide a script that other people can use to process
> similar data sets the same way.
> Use a light weight process, but make sure you have plenty
> of tests, and adequate documentation.
>
> Watts Humphrey developed something he called the "Personal
> Software Process" and wrote a book about it.  I don't like
> his examples for several reasons, but the point about
> watching what you do and measuring it so you can improve is
> well made.
>
>
>
> On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>> wrote:
> dear members,
>                          I am Stock trader and using R for research.
>
> Until now I was coding very haphazardly, but recently I stumbled upon the Software Development Life Cycle (SDLC), which introduced me to principled software design. I am college dropout and don't have in depth knowledge in Software Engineering principles. However, now, I want to go in a structured manner.
>
> I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the R programming language and specifically for data science, but was bootless. Do you people have any idea on which software engineering methodology to use in R and data science, so that I can code efficiently and in a structured manner? The point to note, with regards to R, is that statistical ANALYSIS sometimes takes very little code as compared to other programming languages. Any SDLC method for these types of analysis, besides, rigorous scripting with R?
>
> Thanking you,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Feb 15 17:56:08 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 15 Feb 2022 18:56:08 +0200
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <CAGxFJbQVvGwwimV7djguMBjR7z_fDMo7bW0g8p1XqP6_VHZkQA@mail.gmail.com>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
 <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CAGxFJbQVvGwwimV7djguMBjR7z_fDMo7bW0g8p1XqP6_VHZkQA@mail.gmail.com>
Message-ID: <CAGgJW75081Zk7cQUm_b8890xPnGCQwez7ru8oikjLwgHwoPXeg@mail.gmail.com>

Bert Gunter writes:
>> 1. This dialogue should be taken offlist imo.

Akshay, I think you asked a great question and I was looking forward
to seeing the answers.
After reading Bert's comment I checked the posting guide for this list
and I see that a better fit for your question would be the r-devel
list.

https://stat.ethz.ch/mailman/listinfo/r-devel

Best,
Eric



On Tue, Feb 15, 2022 at 6:37 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> 1. This dialogue should be taken offlist imo.
>
> 2. And really, make some effort of your own before posting: An internet
> search on "Watts Humphrey Software Development" immediately brought up what
> appeared to be answers to at least some of your queries.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 15, 2022 at 8:27 AM akshay kulkarni <akshay_e4 at hotmail.com>
> wrote:
>
> > Dear richard,
> >                       I am very grateful for your informative reply.
> >
> > THe fact is, I am doing a project, which is not less complex,(if not more)
> > than those of Microsoft or Accenture or Google , but I am doing it all by
> > myself. Can you please let me the full title of the book by Watts Humphrey?
> > Or any online resources for "personal software process"? Perhaps I can get
> > some tips on how to go about my project ( I've mostly taken into account
> > standard methods of the state of the art, I am looking for something
> > "whizzy" than aids development by one person).
> >
> > Thanks again,
> > Yours sinecerly,
> > AKSHAY M KULKARNI
> > ________________________________
> > From: Richard O'Keefe <raoknz at gmail.com>
> > Sent: Monday, February 14, 2022 5:23 AM
> > To: akshay kulkarni <akshay_e4 at hotmail.com>
> > Cc: R help Mailing list <r-help at r-project.org>
> > Subject: Re: [R] SDLC methodology for R and Data science......
> >
> > There are at least two ways to use R.
> > If you have devised a statistical/data science technique
> > and are writing a package to be used by other people,
> > that is normal software development that happens to be
> > using R and the R tool.  Lots of attention to documentation
> > and tests.  Test-Driven Development is one approach.
> >
> > Many R users aren't developing code for other people.
> > They are trying to make sense of some kind of data.
> > This is what used to be called "exploratory programming".
> > And heavyweight development processes aren't really
> > appropriate for this kind of work.  In traditional terms,
> > when you are doing exploratory programming, you spend
> > most of your time in the requirements phase.
> >
> > Perhaps the most important thing here is to keep a log
> > of what you are doing and record things that didn't work,
> > why they didn't work, and what you learned from it.
> > When something DOES give you some insight, you want to
> > be able to do it again.
> >
> > The tricky thing is scaling from exploration to development.
> > After playing around with one data set, you might want to
> > provide a script that other people can use to process
> > similar data sets the same way.
> > Use a light weight process, but make sure you have plenty
> > of tests, and adequate documentation.
> >
> > Watts Humphrey developed something he called the "Personal
> > Software Process" and wrote a book about it.  I don't like
> > his examples for several reasons, but the point about
> > watching what you do and measuring it so you can improve is
> > well made.
> >
> >
> >
> > On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com
> > <mailto:akshay_e4 at hotmail.com>> wrote:
> > dear members,
> >                          I am Stock trader and using R for research.
> >
> > Until now I was coding very haphazardly, but recently I stumbled upon the
> > Software Development Life Cycle (SDLC), which introduced me to principled
> > software design. I am college dropout and don't have in depth knowledge in
> > Software Engineering principles. However, now, I want to go in a structured
> > manner.
> >
> > I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the
> > R programming language and specifically for data science, but was bootless.
> > Do you people have any idea on which software engineering methodology to
> > use in R and data science, so that I can code efficiently and in a
> > structured manner? The point to note, with regards to R, is that
> > statistical ANALYSIS sometimes takes very little code as compared to other
> > programming languages. Any SDLC method for these types of analysis,
> > besides, rigorous scripting with R?
> >
> > Thanking you,
> > Yours sincerely,
> > AKSHAY M KULKARNI
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> > UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Tue Feb 15 17:59:47 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Tue, 15 Feb 2022 16:59:47 +0000
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <CAGxFJbQVvGwwimV7djguMBjR7z_fDMo7bW0g8p1XqP6_VHZkQA@mail.gmail.com>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
 <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CAGxFJbQVvGwwimV7djguMBjR7z_fDMo7bW0g8p1XqP6_VHZkQA@mail.gmail.com>
Message-ID: <PU4P216MB1568EBF0862DC52AAE6E85CBC8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

Dear Bert,
                  I don't know what made you to state that this dialogue to be taken off the list, but if there is something wrong in my wordings or tone or the way of argument, I highly welcome criticism. Anyway thanks for your reply. I will make sure that I do a thorough research before posting here next time.

Thanks  again,
Yours sincerely
AKSHAY M KULKARNI
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Tuesday, February 15, 2022 10:06 PM
To: akshay kulkarni <akshay_e4 at hotmail.com>
Cc: Richard O'Keefe <raoknz at gmail.com>; R help Mailing list <r-help at r-project.org>
Subject: Re: [R] SDLC methodology for R and Data science......

1. This dialogue should be taken offlist imo.

2. And really, make some effort of your own before posting: An internet search on "Watts Humphrey Software Development" immediately brought up what appeared to be answers to at least some of your queries.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 15, 2022 at 8:27 AM akshay kulkarni <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>> wrote:
Dear richard,
                      I am very grateful for your informative reply.

THe fact is, I am doing a project, which is not less complex,(if not more) than those of Microsoft or Accenture or Google , but I am doing it all by myself. Can you please let me the full title of the book by Watts Humphrey? 
some tips on how to go about my project ( I've mostly taken into account standard methods of the state of the art, I am looking for something "whizzy" than aids development by one person).

Thanks again,
Yours sinecerly,
AKSHAY M KULKARNI
________________________________
From: Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>>
Sent: Monday, February 14, 2022 5:23 AM
To: akshay kulkarni <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>>
Cc: R help Mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] SDLC methodology for R and Data science......

There are at least two ways to use R.
If you have devised a statistical/data science technique
and are writing a package to be used by other people,
that is normal software development that happens to be
using R and the R tool.  Lots of attention to documentation
and tests.  Test-Driven Development is one approach.

Many R users aren't developing code for other people.
They are trying to make sense of some kind of data.
This is what used to be called "exploratory programming".
And heavyweight development processes aren't really
appropriate for this kind of work.  In traditional terms,
when you are doing exploratory programming, you spend
most of your time in the requirements phase.

Perhaps the most important thing here is to keep a log
of what you are doing and record things that didn't work,
why they didn't work, and what you learned from it.
When something DOES give you some insight, you want to
be able to do it again.

The tricky thing is scaling from exploration to development.
After playing around with one data set, you might want to
provide a script that other people can use to process
similar data sets the same way.
Use a light weight process, but make sure you have plenty
of tests, and adequate documentation.

Watts Humphrey developed something he called the "Personal
Software Process" and wrote a book about it.  I don't like
his examples for several reasons, but the point about
watching what you do and measuring it so you can improve is
well made.



On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com><mailto:akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>>> wrote:
dear members,
                         I am Stock trader and using R for research.

Until now I was coding very haphazardly, but recently I stumbled upon the Software Development Life Cycle (SDLC), which introduced me to principled software design. I am college dropout and don't have in depth knowledge in Software Engineering principles. However, now, I want to go in a structured manner.

I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the R programming language and specifically for data science, but was bootless. Do you people have any idea on which software engineering methodology to use in R and data science, so that I can code efficiently and in a structured manner? The point to note, with regards to R, is that statistical ANALYSIS sometimes takes very little code as compared to other programming languages. Any SDLC method for these types of analysis, besides, rigorous scripting with R?

Thanking you,
Yours sincerely,
AKSHAY M KULKARNI


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Tue Feb 15 18:03:41 2022
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Tue, 15 Feb 2022 17:03:41 +0000
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <CAGgJW75081Zk7cQUm_b8890xPnGCQwez7ru8oikjLwgHwoPXeg@mail.gmail.com>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
 <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CAGxFJbQVvGwwimV7djguMBjR7z_fDMo7bW0g8p1XqP6_VHZkQA@mail.gmail.com>
 <CAGgJW75081Zk7cQUm_b8890xPnGCQwez7ru8oikjLwgHwoPXeg@mail.gmail.com>
Message-ID: <PU4P216MB1568436CC004425706223C32C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

dear ERic,
                 Thanks for your reply. As mentioned, I will post my issue in the R devel list.

Thanking you,
Yours sinecerly,
AKSHAY M KULKARNI
________________________________
From: Eric Berger <ericjberger at gmail.com>
Sent: Tuesday, February 15, 2022 10:26 PM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: akshay kulkarni <akshay_e4 at hotmail.com>; R help Mailing list <r-help at r-project.org>
Subject: Re: [R] SDLC methodology for R and Data science......

Bert Gunter writes:
>> 1. This dialogue should be taken offlist imo.

Akshay, I think you asked a great question and I was looking forward
to seeing the answers.
After reading Bert's comment I checked the posting guide for this list
and I see that a better fit for your question would be the r-devel
list.

https://stat.ethz.ch/mailman/listinfo/r-devel

Best,
Eric



On Tue, Feb 15, 2022 at 6:37 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> 1. This dialogue should be taken offlist imo.
>
> 2. And really, make some effort of your own before posting: An internet
> search on "Watts Humphrey Software Development" immediately brought up what
> appeared to be answers to at least some of your queries.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 15, 2022 at 8:27 AM akshay kulkarni <akshay_e4 at hotmail.com>
> wrote:
>
> > Dear richard,
> >                       I am very grateful for your informative reply.
> >
> > THe fact is, I am doing a project, which is not less complex,(if not more)
> > than those of Microsoft or Accenture or Google , but I am doing it all by
> > myself. Can you please let me the full title of the book by Watts Humphrey?

get
> > some tips on how to go about my project ( I've mostly taken into account
> > standard methods of the state of the art, I am looking for something
> > "whizzy" than aids development by one person).
> >
> > Thanks again,
> > Yours sinecerly,
> > AKSHAY M KULKARNI
> > ________________________________
> > From: Richard O'Keefe <raoknz at gmail.com>
> > Sent: Monday, February 14, 2022 5:23 AM
> > To: akshay kulkarni <akshay_e4 at hotmail.com>
> > Cc: R help Mailing list <r-help at r-project.org>
> > Subject: Re: [R] SDLC methodology for R and Data science......
> >
> > There are at least two ways to use R.
> > If you have devised a statistical/data science technique
> > and are writing a package to be used by other people,
> > that is normal software development that happens to be
> > using R and the R tool.  Lots of attention to documentation
> > and tests.  Test-Driven Development is one approach.
> >
> > Many R users aren't developing code for other people.
> > They are trying to make sense of some kind of data.
> > This is what used to be called "exploratory programming".
> > And heavyweight development processes aren't really
> > appropriate for this kind of work.  In traditional terms,
> > when you are doing exploratory programming, you spend
> > most of your time in the requirements phase.
> >
> > Perhaps the most important thing here is to keep a log
> > of what you are doing and record things that didn't work,
> > why they didn't work, and what you learned from it.
> > When something DOES give you some insight, you want to
> > be able to do it again.
> >
> > The tricky thing is scaling from exploration to development.
> > After playing around with one data set, you might want to
> > provide a script that other people can use to process
> > similar data sets the same way.
> > Use a light weight process, but make sure you have plenty
> > of tests, and adequate documentation.
> >
> > Watts Humphrey developed something he called the "Personal
> > Software Process" and wrote a book about it.  I don't like
> > his examples for several reasons, but the point about
> > watching what you do and measuring it so you can improve is
> > well made.
> >
> >
> >
> > On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com
> > <mailto:akshay_e4 at hotmail.com>> wrote:
> > dear members,
> >                          I am Stock trader and using R for research.
> >
> > Until now I was coding very haphazardly, but recently I stumbled upon the
> > Software Development Life Cycle (SDLC), which introduced me to principled
> > software design. I am college dropout and don't have in depth knowledge in
> > Software Engineering principles. However, now, I want to go in a structured
> > manner.
> >
> > I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the
> > R programming language and specifically for data science, but was bootless.
> > Do you people have any idea on which software engineering methodology to
> > use in R and data science, so that I can code efficiently and in a
> > structured manner? The point to note, with regards to R, is that
> > statistical ANALYSIS sometimes takes very little code as compared to other
> > programming languages. Any SDLC method for these types of analysis,
> > besides, rigorous scripting with R?
> >
> > Thanking you,
> > Yours sincerely,
> > AKSHAY M KULKARNI
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> > UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From huze|@k @end|ng |rom um|ch@edu  Tue Feb 15 17:34:51 2022
From: huze|@k @end|ng |rom um|ch@edu (Huzefa Khalil)
Date: Tue, 15 Feb 2022 11:34:51 -0500
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
 <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CADsG8gO0DWZxd9kxE_N4BkqoCJZZxEjTJ9dgQCJhLrSfjrR+sw@mail.gmail.com>

A book I have found useful in this regard is The Workflow of Data
Analysis Using Stata by J. Scott Long. Obviously the book is targeted
towards Stata users but the concepts work just as well for R.


On Tue, Feb 15, 2022 at 11:27 AM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> Dear richard,
>                       I am very grateful for your informative reply.
>
> THe fact is, I am doing a project, which is not less complex,(if not more) than those of Microsoft or Accenture or Google , but I am doing it all by myself. Can you please let me the full title of the book by Watts Humphrey? Or any online resources for "personal software process"? Perhaps I can get some tips on how to go about my project ( I've mostly taken into account standard methods of the state of the art, I am looking for something "whizzy" than aids development by one person).
>
> Thanks again,
> Yours sinecerly,
> AKSHAY M KULKARNI
> ________________________________
> From: Richard O'Keefe <raoknz at gmail.com>
> Sent: Monday, February 14, 2022 5:23 AM
> To: akshay kulkarni <akshay_e4 at hotmail.com>
> Cc: R help Mailing list <r-help at r-project.org>
> Subject: Re: [R] SDLC methodology for R and Data science......
>
> There are at least two ways to use R.
> If you have devised a statistical/data science technique
> and are writing a package to be used by other people,
> that is normal software development that happens to be
> using R and the R tool.  Lots of attention to documentation
> and tests.  Test-Driven Development is one approach.
>
> Many R users aren't developing code for other people.
> They are trying to make sense of some kind of data.
> This is what used to be called "exploratory programming".
> And heavyweight development processes aren't really
> appropriate for this kind of work.  In traditional terms,
> when you are doing exploratory programming, you spend
> most of your time in the requirements phase.
>
> Perhaps the most important thing here is to keep a log
> of what you are doing and record things that didn't work,
> why they didn't work, and what you learned from it.
> When something DOES give you some insight, you want to
> be able to do it again.
>
> The tricky thing is scaling from exploration to development.
> After playing around with one data set, you might want to
> provide a script that other people can use to process
> similar data sets the same way.
> Use a light weight process, but make sure you have plenty
> of tests, and adequate documentation.
>
> Watts Humphrey developed something he called the "Personal
> Software Process" and wrote a book about it.  I don't like
> his examples for several reasons, but the point about
> watching what you do and measuring it so you can improve is
> well made.
>
>
>
> On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>> wrote:
> dear members,
>                          I am Stock trader and using R for research.
>
> Until now I was coding very haphazardly, but recently I stumbled upon the Software Development Life Cycle (SDLC), which introduced me to principled software design. I am college dropout and don't have in depth knowledge in Software Engineering principles. However, now, I want to go in a structured manner.
>
> I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the R programming language and specifically for data science, but was bootless. Do you people have any idea on which software engineering methodology to use in R and data science, so that I can code efficiently and in a structured manner? The point to note, with regards to R, is that statistical ANALYSIS sometimes takes very little code as compared to other programming languages. Any SDLC method for these types of analysis, besides, rigorous scripting with R?
>
> Thanking you,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @k@|@|er1 @end|ng |rom comc@@t@net  Tue Feb 15 18:44:55 2022
From: @k@|@|er1 @end|ng |rom comc@@t@net (STEPHEN KAISLER)
Date: Tue, 15 Feb 2022 12:44:55 -0500 (EST)
Subject: [R] Question re predict.glm & predict.lm in STATS
Message-ID: <143807157.753616.1644947095173@connect.xfinity.com>

Folks:

I haved glm/lm to build a model on a training set derived from auto_mpg data of 274 records (70% sampling)

The test data set has 118 records.

I am trying to use predict.glm or predict.lm to predict the values of mpg from disp, hp,weight, accel, and cyl.

However I get the following message:


So, the resulting vector has 274 rows, when I believe it should have just 118 rows - the size of the test data set.

I would appreciate it if someone could explain if am making the call
in error.

Steve Kaisler

From o||ve|r@jc1 @end|ng |rom gm@||@com  Tue Feb 15 21:17:34 2022
From: o||ve|r@jc1 @end|ng |rom gm@||@com (julio cesar oliveira)
Date: Tue, 15 Feb 2022 17:17:34 -0300
Subject: [R] Volume / Area from MDT
Message-ID: <CAG+u5gqDjeUhgXASmuShhVQhHHpqnZkfhQURHvtZpo+=MYB15Q@mail.gmail.com>

Dears,

I have a Digital Terrain Model - DTM (raster format) and I need to
calculate the volume and area from an altitude.
Is there already a function or package I can use?
Thanks

Julio

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Feb 15 21:57:35 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 15 Feb 2022 12:57:35 -0800
Subject: [R] Volume / Area from MDT
In-Reply-To: <CAG+u5gqDjeUhgXASmuShhVQhHHpqnZkfhQURHvtZpo+=MYB15Q@mail.gmail.com>
References: <CAG+u5gqDjeUhgXASmuShhVQhHHpqnZkfhQURHvtZpo+=MYB15Q@mail.gmail.com>
Message-ID: <86F77A44-ECDB-4FFB-A88E-398D1D5E571A@dcn.davis.ca.us>

You don't appear to have read the Posting Guide mentioned below, which mentions the R-sig-geo mailing list and warns you to send your email using the plain text format rather than HTML so they will see the same thing you saw when you sent it.

I would recommend being more specific about your data (format? how did you import it?) and calculation details (what if there are two adjacent mountains?) when you post on the other mailing list.

On February 15, 2022 12:17:34 PM PST, julio cesar oliveira <oliveirajc1 at gmail.com> wrote:
>Dears,
>
>I have a Digital Terrain Model - DTM (raster format) and I need to
>calculate the volume and area from an altitude.
>Is there already a function or package I can use?
>Thanks
>
>Julio
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb 15 22:05:17 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 15 Feb 2022 13:05:17 -0800
Subject: [R] Question re predict.glm & predict.lm in STATS
In-Reply-To: <143807157.753616.1644947095173@connect.xfinity.com>
References: <143807157.753616.1644947095173@connect.xfinity.com>
Message-ID: <CAGxFJbREHmonKNydR4cxNwcWwuXt0R3KGasZWZKM35wNVEyckA@mail.gmail.com>

??
Show us the error. Show us the call.


On Tue, Feb 15, 2022, 12:14 PM STEPHEN KAISLER <skaisler1 at comcast.net>
wrote:

> Folks:
>
> I haved glm/lm to build a model on a training set derived from auto_mpg
> data of 274 records (70% sampling)
>
> The test data set has 118 records.
>
> I am trying to use predict.glm or predict.lm to predict the values of mpg
> from disp, hp,weight, accel, and cyl.
>
> However I get the following message:
>
>
> So, the resulting vector has 274 rows, when I believe it should have just
> 118 rows - the size of the test data set.
>
> I would appreciate it if someone could explain if am making the call
> in error.
>
> Steve Kaisler
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Tue Feb 15 22:17:42 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Tue, 15 Feb 2022 22:17:42 +0100
Subject: [R] confusion matrix like detail with continuous data?
Message-ID: <CA+nrPnu=OUXsh5j3-TvCyW-k4hePydP6=TRXfqbxjr1WQF6vMA@mail.gmail.com>

Hello everyone

(1) Can we get the details like the confusion matrix with continuous data?

(2) How can we get the mean absolute error for an individual instance? For
example, if the ground truth is 4 and our model predicted as 6, how to find
the mean absolute error for this instance?

Thank you

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Tue Feb 15 22:27:35 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Tue, 15 Feb 2022 21:27:35 +0000
Subject: [R] Volume / Area from MDT
In-Reply-To: <86F77A44-ECDB-4FFB-A88E-398D1D5E571A@dcn.davis.ca.us>
References: <CAG+u5gqDjeUhgXASmuShhVQhHHpqnZkfhQURHvtZpo+=MYB15Q@mail.gmail.com>
 <86F77A44-ECDB-4FFB-A88E-398D1D5E571A@dcn.davis.ca.us>
Message-ID: <BN6PR2201MB155353364D98DB321B6BB077CF349@BN6PR2201MB1553.namprd22.prod.outlook.com>

In posting to R-sig-geo consider what parts of my answer do not work for you and phrase your question to get a better answer. The simple answer that comes to mind is that volume is the length times width of a pixel times its height. Surface area is the mean absolute value of the hypotenuse between the current pixel and its neighbors multiplied by the average length of the sides (at least that is my first guess, and subject to revision if I were to think about it more carefully). On the other hand, a trivial answer is that the area is effectively infinite as area will continue to increase as your magnification increases.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
Sent: Tuesday, February 15, 2022 3:58 PM
To: r-help at r-project.org; julio cesar oliveira <oliveirajc1 at gmail.com>
Subject: Re: [R] Volume / Area from MDT

[External Email]

You don't appear to have read the Posting Guide mentioned below, which mentions the R-sig-geo mailing list and warns you to send your email using the plain text format rather than HTML so they will see the same thing you saw when you sent it.

I would recommend being more specific about your data (format? how did you import it?) and calculation details (what if there are two adjacent mountains?) when you post on the other mailing list.

On February 15, 2022 12:17:34 PM PST, julio cesar oliveira <oliveirajc1 at gmail.com> wrote:
>Dears,
>
>I have a Digital Terrain Model - DTM (raster format) and I need to 
>calculate the volume and area from an altitude.
>Is there already a function or package I can use?
>Thanks
>
>Julio
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRz
>sn7AkP-g&m=g7VoAY_Nmj1CscdkBOM2rtlEL0C6E36qQaHoMqSSPJZ8jojgdwegwUF2f4R-
>QBGW&s=L2AckrLC56Nkqxo9XZjBFJMU1CCYmSmC6F65242-has&e=
>PLEASE do read the posting guide 
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsR
>zsn7AkP-g&m=g7VoAY_Nmj1CscdkBOM2rtlEL0C6E36qQaHoMqSSPJZ8jojgdwegwUF2f4R
>-QBGW&s=fWR6bDOxUw_229EAsnGa5dRijDOHmkUt9MD-0UcthjA&e=
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=g7VoAY_Nmj1CscdkBOM2rtlEL0C6E36qQaHoMqSSPJZ8jojgdwegwUF2f4R-QBGW&s=L2AckrLC56Nkqxo9XZjBFJMU1CCYmSmC6F65242-has&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=g7VoAY_Nmj1CscdkBOM2rtlEL0C6E36qQaHoMqSSPJZ8jojgdwegwUF2f4R-QBGW&s=fWR6bDOxUw_229EAsnGa5dRijDOHmkUt9MD-0UcthjA&e=
and provide commented, minimal, self-contained, reproducible code.


From |en@houwer@ @end|ng |rom @rete||m|ted@com  Tue Feb 15 22:17:28 2022
From: |en@houwer@ @end|ng |rom @rete||m|ted@com (Len Houwers)
Date: Wed, 16 Feb 2022 10:17:28 +1300
Subject: [R] Simulating tbats object in R
Message-ID: <002901d822b1$71081320$53183960$@aretelimited.com>

Hi,

 

First time subscriber and first request. Hope that I'm doing it right!

 

I'm working on a time series model for gas demand using monthly data. In
addition to developing a monthly forecast from this, I'm also interested to
find the prediction interval for an annual demand.

 

I've been working with ARIMA, ets, and tbats functions including using the
forecast package to forecast ahead. This also gives me the monthly
prediction intervals and works fine for all three methods.

 

However when I try to simulate the tbats model to create an annual forecast
that also gives me the expected 95% prediction interval, the function
simulate()doesn't work for object created as tbats.

 

Is there another function or package in R that allows me to simulate a tbats
object? I've looked through the internet, plus R-help sites to find a
solution, but no luck so far.

 

Len

 

 


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb 15 23:37:31 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 15 Feb 2022 14:37:31 -0800
Subject: [R] Simulating tbats object in R
In-Reply-To: <002901d822b1$71081320$53183960$@aretelimited.com>
References: <002901d822b1$71081320$53183960$@aretelimited.com>
Message-ID: <CAGxFJbS4EELbrsFCMO=5WER-P1Wke_YuhF+HGAezJ+_ppDPLog@mail.gmail.com>

1. Read and follow the posting guide (linked below). It says to use plain
text, not html (the mail server strips html for security reasons, and that
can leave an unreadable mess sometimes).

2. Per the posting guide,
""For questions about functions in standard packages distributed with R
(see the FAQ Add-on packages in R), ask questions on R-help.
[The link is:
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R
This gives the list of current _standard_ packages]

If the question relates to a contributed package , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. Only send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

This may be good advice for your situation, where you may be asking for
functionality that's missing or buggy.

3. Did you try your various search queries on rseek.org, which is a site
"tuned" to R. "Tbats model simulation" there brought up some stuff that may
be relevant, including:
https://medium.com/analytics-vidhya/time-series-forecasting-using-tbats-model-ce8c429442a9



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 15, 2022 at 2:07 PM Len Houwers <len.houwers at aretelimited.com>
wrote:

> Hi,
>
>
>
> First time subscriber and first request. Hope that I'm doing it right!
>
>
>
> I'm working on a time series model for gas demand using monthly data. In
> addition to developing a monthly forecast from this, I'm also interested to
> find the prediction interval for an annual demand.
>
>
>
> I've been working with ARIMA, ets, and tbats functions including using the
> forecast package to forecast ahead. This also gives me the monthly
> prediction intervals and works fine for all three methods.
>
>
>
> However when I try to simulate the tbats model to create an annual forecast
> that also gives me the expected 95% prediction interval, the function
> simulate()doesn't work for object created as tbats.
>
>
>
> Is there another function or package in R that allows me to simulate a
> tbats
> object? I've looked through the internet, plus R-help sites to find a
> solution, but no luck so far.
>
>
>
> Len
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Feb 16 11:00:05 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 16 Feb 2022 13:00:05 +0300
Subject: [R] confusion matrix like detail with continuous data?
In-Reply-To: <CA+nrPnu=OUXsh5j3-TvCyW-k4hePydP6=TRXfqbxjr1WQF6vMA@mail.gmail.com>
References: <CA+nrPnu=OUXsh5j3-TvCyW-k4hePydP6=TRXfqbxjr1WQF6vMA@mail.gmail.com>
Message-ID: <20220216130005.331f4959@arachnoid>

On Tue, 15 Feb 2022 22:17:42 +0100
Neha gupta <neha.bologna90 at gmail.com> wrote:

> (1) Can we get the details like the confusion matrix with continuous
> data?

I think the closest you can get is a predicted-reference plot. That is,
plot true values on the X axis and the corresponding predicted values
on the Y axis.

Unsatisfying option: use cut() to transform a continuous variable into
a categorical variable and make a confusion matrix out of that.

> (2) How can we get the mean absolute error for an individual
> instance? For example, if the ground truth is 4 and our model
> predicted as 6, how to find the mean absolute error for this instance?

Mathematically speaking, mean absolute error of an individual instance
would be just the absolute value of the error in that instance, but
that's probably not what you're looking for. If you need some kind of
confidence bands for the predictions, it's the model's responsibility
to provide them. There's lots of options, ranging from the use of the
loss function derivative around the optimum to Monte-Carlo simulations.
For examples, see the confint() method.

-- 
Best regards,
Ivan


From tebert @end|ng |rom u||@edu  Wed Feb 16 14:05:22 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 16 Feb 2022 13:05:22 +0000
Subject: [R] confusion matrix like detail with continuous data?
In-Reply-To: <20220216130005.331f4959@arachnoid>
References: <CA+nrPnu=OUXsh5j3-TvCyW-k4hePydP6=TRXfqbxjr1WQF6vMA@mail.gmail.com>
 <20220216130005.331f4959@arachnoid>
Message-ID: <BN6PR2201MB1553D1C1C3E24DAADB91CF12CF359@BN6PR2201MB1553.namprd22.prod.outlook.com>

In your prediction you will have a target level of accuracy. Something like "I need to predict the slope of the regression to within 1%." You break your data into a training and testing data sets, then for the testing data set you ask is the prediction within 1% of the observed value. That is about as close as I can come as I have trouble thinking how to get a false positive out of a regression with a continuous dependent variable.
   Of course, you have to have enough data that splitting the data set into two pieces leaves enough observations to make a reasonable model. 
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Ivan Krylov
Sent: Wednesday, February 16, 2022 5:00 AM
To: r-help at r-project.org
Subject: Re: [R] confusion matrix like detail with continuous data?

[External Email]

On Tue, 15 Feb 2022 22:17:42 +0100
Neha gupta <neha.bologna90 at gmail.com> wrote:

> (1) Can we get the details like the confusion matrix with continuous 
> data?

I think the closest you can get is a predicted-reference plot. That is, plot true values on the X axis and the corresponding predicted values on the Y axis.

Unsatisfying option: use cut() to transform a continuous variable into a categorical variable and make a confusion matrix out of that.

> (2) How can we get the mean absolute error for an individual instance? 
> For example, if the ground truth is 4 and our model predicted as 6, 
> how to find the mean absolute error for this instance?

Mathematically speaking, mean absolute error of an individual instance would be just the absolute value of the error in that instance, but that's probably not what you're looking for. If you need some kind of confidence bands for the predictions, it's the model's responsibility to provide them. There's lots of options, ranging from the use of the loss function derivative around the optimum to Monte-Carlo simulations.
For examples, see the confint() method.

--
Best regards,
Ivan

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=n0Pz_t-BEeazrrz7r5DIs0qGgfyJ0E0_F5sGlJyjhnwJRydXFvfNs1g5Pe25PGK0&s=ZeN73VTXr4Z-qwxODgOWPyhqtvKWIXp6xVsLle-eWYA&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=n0Pz_t-BEeazrrz7r5DIs0qGgfyJ0E0_F5sGlJyjhnwJRydXFvfNs1g5Pe25PGK0&s=CqgXaJDSeFk1kD9-xcMjcbZYWKXSCkuJZodGf0yvRDk&e=
and provide commented, minimal, self-contained, reproducible code.


From j@vedbtk111 @end|ng |rom gm@||@com  Wed Feb 16 21:54:00 2022
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Wed, 16 Feb 2022 21:54:00 +0100
Subject: [R] Error after updating a package
Message-ID: <CAJhui+sqOL_Dxz1AOPAcj-B1DoSExG5suuZzVLC4qdSDuybyng@mail.gmail.com>

Hello

My RStudio was working fine and then I installed tidyverse & updated dplyr.
Now when I opened RStudio, I get the following message

Error: package or namespace load failed for ?farff? in loadNamespace(i,
c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
 namespace ?ellipsis? 0.3.1 is already loaded, but >= 0.3.2 is required
In addition: Warning message:
package ?farff? was built under R version 4.0.5

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Feb 16 22:12:57 2022
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 16 Feb 2022 16:12:57 -0500
Subject: [R] Error after updating a package
In-Reply-To: <CAJhui+sqOL_Dxz1AOPAcj-B1DoSExG5suuZzVLC4qdSDuybyng@mail.gmail.com>
References: <CAJhui+sqOL_Dxz1AOPAcj-B1DoSExG5suuZzVLC4qdSDuybyng@mail.gmail.com>
Message-ID: <CAM_vju=yrdM_5d2Nz8ZpaDO0cWMSkuY1+oWseYg5gQsSrZjEng@mail.gmail.com>

Hi,

The solution to that kind of error is always to update R to the
current version (4.1.2), and then to update all of your packages.

At the R command line, you could use
update.packages(ask=FALSE) # possibly with checkBuilt=TRUE

but I expect R Studio has a snazzy menu item to update everything.

Sarah

On Wed, Feb 16, 2022 at 3:54 PM javed khan <javedbtk111 at gmail.com> wrote:
>
> Hello
>
> My RStudio was working fine and then I installed tidyverse & updated dplyr.
> Now when I opened RStudio, I get the following message
>
> Error: package or namespace load failed for ?farff? in loadNamespace(i,
> c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>  namespace ?ellipsis? 0.3.1 is already loaded, but >= 0.3.2 is required
> In addition: Warning message:
> package ?farff? was built under R version 4.0.5
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb 17 01:09:26 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 16 Feb 2022 16:09:26 -0800
Subject: [R] Question re predict.glm & predict.lm in STATS
In-Reply-To: <CAGxFJbRHokxmJvcek44rQiE+EaMN_-DXPUwyXPpz=jczuQg1uA@mail.gmail.com>
References: <143807157.753616.1644947095173@connect.xfinity.com>
 <CAGxFJbREHmonKNydR4cxNwcWwuXt0R3KGasZWZKM35wNVEyckA@mail.gmail.com>
 <372715244.778207.1645011539574@connect.xfinity.com>
 <CAGxFJbRHokxmJvcek44rQiE+EaMN_-DXPUwyXPpz=jczuQg1uA@mail.gmail.com>
Message-ID: <CAGxFJbQaYkw_WccvRWzX4ynVh2LbSaVt_+Bw8CYLd8OR_Vk-9Q@mail.gmail.com>

Ok, I looked at what you sent me privately and saw your error. I'll
reproduce and fix it just using a trivial example with lm(), for which
the predict() semantics are identical. Before I do, I note that your
claim:

"The predict.glm documentation says a warning will be given if the
length of newdata is not the same as the training set used to create
the model." is **completely wrong**. What predict.glm (and predict.lm)
actually says is:

"Variables are first looked for in newdata and then searched for in
the usual way (which will include the environment of the formula used
in the fit). A warning will be given if the variables found are not of
the same length as those in newdata if it was supplied."

This is *NOT AT ALL* what you claimed. The key point that you are
missing is the phrase 'searched for in the usual way.'  The details
are a bit technical but in many ways fundamental. They can be found in
any good tutorial or perhaps by searching on "scoping in R" or
"function environments in R". It's about how R finds the objects that
variable names point to. Section 10.7 of the Intro.R manual shipped
with R (and available to you therefore) on "Scope" gives a brief
overview.

Anyway, here's the example that explains your error:

> train <- data.frame( y = runif(10), x = runif(10)) ## 10 rows
> test <- data.frame(x = runif(5))  ## 5 rows

## The following line is the source of your error
## You have specified your model incorrectly

> mdl <- lm(train$y ~train$x, data = train)

## The model is properly fitted because the variables in it, "train$y"
and "train$x" are found  "in the usual way" in the global environment,
the "enclosing environment" of the formula. (This is the technical
bit).  This leads to the sort of problem you saw with the predict
call:

> predict(mdl, newdat = test)
        1         2         3         4         5         6         7
0.6089476 0.6385268 0.9075589 0.3403276 0.2709199 0.5876634 0.8668307
        8         9        10
0.4689961 0.2571259 0.3281054
Warning message:
'newdata' had 5 rows but variables found have 10 rows

##Explanation: predict() is looking for a variable 'train$x', but test
only has a variable 'x', not 'train$x'. Since it doesn't find it, it
goes looking for 'train$x' "in the usual way" in the global
environment and finds it -- all 10 values as before. The prediction is
done using that data (the original fit) and the warning message is
emitted as per the documentation. Predicting without the newdat
argument does the same thing.

The correct syntax for fitting the original model is:
> mdl <- lm(y ~ x, data = train)

## and then the predict() call works fine using the newdat argument
(as 'x' is found there)
> predict(mdl, newdat = test)
        1         2         3         4         5
0.5134899 0.4619013 0.2458162 0.0446871 0.3146897

All of this is documented and exampled in ?glm or even ?lm or in any
tutorials on their use. Please spend the time to study these
carefully. Trying to mimic examples you find, which seems to be what
you are doing, is rarely sufficient.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 16, 2022 at 7:24 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> You should (almost) always reply to the list to maximize your opportunity for useful help. Also, I don't do private consulting.
>
> See ?dput and ?str for ways to put code and data as plain text into a post via copying and pasting from the R Console. You can also just type the code directly, of course. The RHelp server will strip most attachments (I think .png is OK for graphs, though. You can ask on list) if necessary). I don't recall whether Word makes it through, but you really shouldn't need such attachments anyway.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 16, 2022 at 3:39 AM STEPHEN KAISLER <skaisler1 at comcast.net> wrote:
>>
>> Bert:
>>
>> Please see the attached file which shows the approach I used.
>> Thanks for any assistance that you can offer.
>>
>> Steve Kaisler
>>
>> On 02/15/2022 4:05 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>>
>> ??
>> Show us the error. Show us the call.
>>
>>
>> On Tue, Feb 15, 2022, 12:14 PM STEPHEN KAISLER <skaisler1 at comcast.net> wrote:
>>
>> Folks:
>>
>> I haved glm/lm to build a model on a training set derived from auto_mpg data of 274 records (70% sampling)
>>
>> The test data set has 118 records.
>>
>> I am trying to use predict.glm or predict.lm to predict the values of mpg from disp, hp,weight, accel, and cyl.
>>
>> However I get the following message:
>>
>>
>> So, the resulting vector has 274 rows, when I believe it should have just 118 rows - the size of the test data set.
>>
>> I would appreciate it if someone could explain if am making the call
>> in error.
>>
>> Steve Kaisler
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Feb 17 01:11:17 2022
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 17 Feb 2022 13:11:17 +1300
Subject: [R] The dbd package --- accompanying paper now published.
Message-ID: <20220217131117.54880294@rolf-Latitude-E7470>


Anyone who is interested in my dbd package may also be interested to
know that the paper that I wrote to accompany the package is now
published in the R Journal: 

DOI https://doi.org/10.32614/RJ-2021-067

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From j@vedbtk111 @end|ng |rom gm@||@com  Thu Feb 17 11:24:08 2022
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Thu, 17 Feb 2022 11:24:08 +0100
Subject: [R] Error after updating a package
In-Reply-To: <CAM_vju=yrdM_5d2Nz8ZpaDO0cWMSkuY1+oWseYg5gQsSrZjEng@mail.gmail.com>
References: <CAJhui+sqOL_Dxz1AOPAcj-B1DoSExG5suuZzVLC4qdSDuybyng@mail.gmail.com>
 <CAM_vju=yrdM_5d2Nz8ZpaDO0cWMSkuY1+oWseYg5gQsSrZjEng@mail.gmail.com>
Message-ID: <CAJhui+vFEXOTZ14O_0OQvrKegVW8v3ZB226PS=K7x-KytJTJMw@mail.gmail.com>

@Sarah Goslee

How much time it takes? Its been 8 hours and I am waiting to finish the
updates.

On Wed, Feb 16, 2022 at 10:13 PM Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi,
>
> The solution to that kind of error is always to update R to the
> current version (4.1.2), and then to update all of your packages.
>
> At the R command line, you could use
> update.packages(ask=FALSE) # possibly with checkBuilt=TRUE
>
> but I expect R Studio has a snazzy menu item to update everything.
>
> Sarah
>
> On Wed, Feb 16, 2022 at 3:54 PM javed khan <javedbtk111 at gmail.com> wrote:
> >
> > Hello
> >
> > My RStudio was working fine and then I installed tidyverse & updated
> dplyr.
> > Now when I opened RStudio, I get the following message
> >
> > Error: package or namespace load failed for ?farff? in loadNamespace(i,
> > c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> >  namespace ?ellipsis? 0.3.1 is already loaded, but >= 0.3.2 is required
> > In addition: Warning message:
> > package ?farff? was built under R version 4.0.5
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.sarahgoslee.com
>

	[[alternative HTML version deleted]]


From emm@nue|@po|zot @end|ng |rom |ecn@m@net  Wed Feb 16 15:20:48 2022
From: emm@nue|@po|zot @end|ng |rom |ecn@m@net (Poizot Emmanuel)
Date: Wed, 16 Feb 2022 15:20:48 +0100
Subject: [R] gstat installation problem
Message-ID: <60e1ad05-5ae2-cf12-7497-b21946c8633a@lecnam.net>

Dear all,
I tried to install gstat package via install.packages('gstat') command 
on R (version 3.5.2) and my OS is Debian buster.

the install failed with message:

......
gcc -std=gnu99 -I"/usr/share/R/include" -DNDEBUG      -fpic  -g -O2 
-fdebug-prefix-map=/build/r-base-3.5.2=. -fstack-protector-strong 
-Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c 
mtrx.c -o mtrx.o
In file included from /usr/share/R/include/R.h:85,
                  from mtrx.c:18:
/usr/share/R/include/R_ext/Constants.h:36: warning: "PI" redefined
  #define PI             M_PI

In file included from mtrx.c:12:
utils.h:20: note: this is the location of the previous definition
  # define PI 3.14159265359

mtrx.c: In function ?CHfactor?:
mtrx.c:391:74: error: ?FC_LEN_T? undeclared (first use in this 
function); did you mean ?FD_SET??
    F77_CALL(dpotrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n), 
info, (FC_LEN_T) 5);
 
    ^~~~~~~~
 
    FD_SET
mtrx.c:391:74: note: each undeclared identifier is reported only once 
for each function it appears in
mtrx.c:391:83: error: expected ?)? before numeric constant
    F77_CALL(dpotrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n), 
info, (FC_LEN_T) 5);
 
             ^~
 
             )
In file included from /usr/share/R/include/R_ext/Lapack.h:39,
                  from mtrx.c:6:
mtrx.c:391:12: error: too many arguments to function ?dpotrf_?
    F77_CALL(dpotrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n), 
info, (FC_LEN_T) 5);
             ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:815:10: note: declared here
  F77_NAME(dpotrf)(const char* uplo, const int* n,
           ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:815:1: note: in expansion of macro 
?F77_NAME?
  F77_NAME(dpotrf)(const char* uplo, const int* n,
  ^~~~~~~~
mtrx.c:404:112: error: expected ?)? before numeric constant
    F77_CALL(dsytrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n), (int 
*) piv->pe, &w, &lwork, info, (FC_LEN_T) 5);
 
                                          ^~
 
                                          )
In file included from /usr/share/R/include/R_ext/Lapack.h:39,
                  from mtrx.c:6:
mtrx.c:404:12: error: too many arguments to function ?dsytrf_?
    F77_CALL(dsytrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n), (int 
*) piv->pe, &w, &lwork, info, (FC_LEN_T) 5);
             ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:1350:10: note: declared here
  F77_NAME(dsytrf)(const char* uplo, const int* n,
           ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:1350:1: note: in expansion of macro 
?F77_NAME?
  F77_NAME(dsytrf)(const char* uplo, const int* n,
  ^~~~~~~~
mtrx.c:407:114: error: expected ?)? before numeric constant
    F77_CALL(dsytrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n), (int 
*) piv->pe, work, &lwork, info, (FC_LEN_T) 5);
 
                                            ^~
 
                                            )
In file included from /usr/share/R/include/R_ext/Lapack.h:39,
                  from mtrx.c:6:
mtrx.c:407:12: error: too many arguments to function ?dsytrf_?
    F77_CALL(dsytrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n), (int 
*) piv->pe, work, &lwork, info, (FC_LEN_T) 5);
             ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:1350:10: note: declared here
  F77_NAME(dsytrf)(const char* uplo, const int* n,
           ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:1350:1: note: in expansion of macro 
?F77_NAME?
  F77_NAME(dsytrf)(const char* uplo, const int* n,
  ^~~~~~~~
mtrx.c: In function ?CHsolve?:
mtrx.c:427:128: error: ?FC_LEN_T? undeclared (first use in this 
function); did you mean ?FD_SET??
  L(dpotrs)("Upper", (int *) &(m->m), (int *) &(b->n), m->v, (int *) 
&(m->m),          out->v, (int *) &(m->m), &info, (FC_LEN_T) 5);
 
                                                 ^~~~~~~~
 
                                                 FD_SET
mtrx.c:427:137: error: expected ?)? before numeric constant
  dpotrs)("Upper", (int *) &(m->m), (int *) &(b->n), m->v, (int *) 
&(m->m),          out->v, (int *) &(m->m), &info, (FC_LEN_T) 5);
 
                                                        ^~
 
                                                        )
In file included from /usr/share/R/include/R_ext/Lapack.h:39,
                  from mtrx.c:6:
mtrx.c:427:12: error: too many arguments to function ?dpotrs_?
    F77_CALL(dpotrs)("Upper", (int *) &(m->m), (int *) &(b->n), m->v, 
(int *) &(m->m),          out->v, (int *) &(m->m), &info, (FC_LEN_T) 5);
             ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:827:10: note: declared here
  F77_NAME(dpotrs)(const char* uplo, const int* n,
           ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:827:1: note: in expansion of macro 
?F77_NAME?
  F77_NAME(dpotrs)(const char* uplo, const int* n,
  ^~~~~~~~
mtrx.c:429:137: error: expected ?)? before numeric constant
  dsytrs)("Upper", (int *) &(m->m), (int *) &(b->n), m->v, (int *) 
&(m->m), piv->pe, out->v, (int *) &(m->m), &info, (FC_LEN_T) 5);
 
                                                        ^~
 
                                                        )
In file included from /usr/share/R/include/R_ext/Lapack.h:39,
                  from mtrx.c:6:
mtrx.c:429:12: error: too many arguments to function ?dsytrs_?
    F77_CALL(dsytrs)("Upper", (int *) &(m->m), (int *) &(b->n), m->v, 
(int *) &(m->m), piv->pe, out->v, (int *) &(m->m), &info, (FC_LEN_T) 5);
             ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:1366:10: note: declared here
  F77_NAME(dsytrs)(const char* uplo, const int* n,
           ^~~~~~
/usr/share/R/include/R_ext/RS.h:92:22: note: in definition of macro 
?F77_CALL?
  # define F77_CALL(x) x ## _
                       ^
/usr/share/R/include/R_ext/Lapack.h:1366:1: note: in expansion of macro 
?F77_NAME?
  F77_NAME(dsytrs)(const char* uplo, const int* n,
  ^~~~~~~~
make: *** [/usr/lib/R/etc/Makeconf:162: mtrx.o] Error 1
ERROR: compilation failed for package ?gstat?
* removing ?/home/epoizot/R/x86_64-pc-linux-gnu-library/3.5/gstat?

Les packages source t?l?charg?s sont dans
	?/tmp/RtmpX08lSy/downloaded_packages?
Warning message:
In install.packages("gstat") :
   l'installation du package ?gstat? a eu un statut de sortie non nul

Is there a workaround to deal with gstat install ?

-- 
Cordialement

/------------------------------------------------
*Emmanuel Poizot*
------------------------------------------------
*** "Quand le dernier arbre sera abattu, la derni?re rivi?re
empoisonn?e, le dernier poisson captur?, alors le visage pale
s'apercevra que l'argent ne se mange pas" (Sitting Bull) ***
/

From tebert @end|ng |rom u||@edu  Thu Feb 17 13:31:16 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 17 Feb 2022 12:31:16 +0000
Subject: [R] Error after updating a package
In-Reply-To: <CAJhui+vFEXOTZ14O_0OQvrKegVW8v3ZB226PS=K7x-KytJTJMw@mail.gmail.com>
References: <CAJhui+sqOL_Dxz1AOPAcj-B1DoSExG5suuZzVLC4qdSDuybyng@mail.gmail.com>
 <CAM_vju=yrdM_5d2Nz8ZpaDO0cWMSkuY1+oWseYg5gQsSrZjEng@mail.gmail.com>
 <CAJhui+vFEXOTZ14O_0OQvrKegVW8v3ZB226PS=K7x-KytJTJMw@mail.gmail.com>
Message-ID: <BN6PR2201MB15539E25F7488455175A2CD3CF369@BN6PR2201MB1553.namprd22.prod.outlook.com>

If you have a large number of packages it can take a long time. You can update packages individually in R or RStudio. In RStudio there is a "Packages" tab in the lower right window. 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of javed khan
Sent: Thursday, February 17, 2022 5:24 AM
To: Sarah Goslee <sarah.goslee at gmail.com>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Error after updating a package

[External Email]

@Sarah Goslee

How much time it takes? Its been 8 hours and I am waiting to finish the updates.

On Wed, Feb 16, 2022 at 10:13 PM Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi,
>
> The solution to that kind of error is always to update R to the 
> current version (4.1.2), and then to update all of your packages.
>
> At the R command line, you could use
> update.packages(ask=FALSE) # possibly with checkBuilt=TRUE
>
> but I expect R Studio has a snazzy menu item to update everything.
>
> Sarah
>
> On Wed, Feb 16, 2022 at 3:54 PM javed khan <javedbtk111 at gmail.com> wrote:
> >
> > Hello
> >
> > My RStudio was working fine and then I installed tidyverse & updated
> dplyr.
> > Now when I opened RStudio, I get the following message
> >
> > Error: package or namespace load failed for ?farff? in 
> > loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> >  namespace ?ellipsis? 0.3.1 is already loaded, but >= 0.3.2 is 
> > required In addition: Warning message:
> > package ?farff? was built under R version 4.0.5
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
> > ilman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2k
> > VeAsRzsn7AkP-g&m=PKw17g1fY0t4g-ZOVDY0LaIqpuI5g58W2TpPEoXdhJiBHw4vayF
> > 7d2u8EG8jijMX&s=K_p3IGXbIuHATasxk-daK7zBKa-yJ7slYo-5mlEtCzI&e=
> > PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> g_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> sRzsn7AkP-g&m=PKw17g1fY0t4g-ZOVDY0LaIqpuI5g58W2TpPEoXdhJiBHw4vayF7d2u8
> EG8jijMX&s=pD3DZn7V9RpxPxz_LnBjkpi4vE6IFmqzLk4Ng0weAtI&e=
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.sarahgoslee.co
> m&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=PKw17g1
> fY0t4g-ZOVDY0LaIqpuI5g58W2TpPEoXdhJiBHw4vayF7d2u8EG8jijMX&s=ctNNy2E5s3
> DBGzB63iyscT9dmzn_epnU9zu8LmFIMlo&e=
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=PKw17g1fY0t4g-ZOVDY0LaIqpuI5g58W2TpPEoXdhJiBHw4vayF7d2u8EG8jijMX&s=K_p3IGXbIuHATasxk-daK7zBKa-yJ7slYo-5mlEtCzI&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=PKw17g1fY0t4g-ZOVDY0LaIqpuI5g58W2TpPEoXdhJiBHw4vayF7d2u8EG8jijMX&s=pD3DZn7V9RpxPxz_LnBjkpi4vE6IFmqzLk4Ng0weAtI&e=
and provide commented, minimal, self-contained, reproducible code.

From kry|ov@r00t @end|ng |rom gm@||@com  Thu Feb 17 13:34:57 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 17 Feb 2022 15:34:57 +0300
Subject: [R] gstat installation problem
In-Reply-To: <60e1ad05-5ae2-cf12-7497-b21946c8633a@lecnam.net>
References: <60e1ad05-5ae2-cf12-7497-b21946c8633a@lecnam.net>
Message-ID: <20220217153457.0f0f1118@arachnoid>

On Wed, 16 Feb 2022 15:20:48 +0100
Poizot Emmanuel <emmanuel.poizot at lecnam.net> wrote:

> I tried to install gstat package via install.packages('gstat')
> command on R (version 3.5.2) and my OS is Debian buster.

> mtrx.c: In function ?CHfactor?:
> mtrx.c:391:74: error: ?FC_LEN_T? undeclared (first use in this 
> function); did you mean ?FD_SET??
>     F77_CALL(dpotrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n), 
> info, (FC_LEN_T) 5);

The gstat package doesn't declare a correct R version dependency, but
it does use a feature that appeared in a newer version of R. (3.6.2, I
think?)

Try installing older versions of gstat from
<https://cran.r-project.org/src/contrib/Archive/gstat/> until you find
one that's working. Alternatively, install a newer version of R from
<https://cran.r-project.org/bin/linux/debian/>.

-- 
Best regards,
Ivan


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Feb 17 13:49:20 2022
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 17 Feb 2022 07:49:20 -0500
Subject: [R] Error after updating a package
In-Reply-To: <CAJhui+vFEXOTZ14O_0OQvrKegVW8v3ZB226PS=K7x-KytJTJMw@mail.gmail.com>
References: <CAJhui+sqOL_Dxz1AOPAcj-B1DoSExG5suuZzVLC4qdSDuybyng@mail.gmail.com>
 <CAM_vju=yrdM_5d2Nz8ZpaDO0cWMSkuY1+oWseYg5gQsSrZjEng@mail.gmail.com>
 <CAJhui+vFEXOTZ14O_0OQvrKegVW8v3ZB226PS=K7x-KytJTJMw@mail.gmail.com>
Message-ID: <CAM_vjun_4ugUQvtkR5JBLhjTktU+6=Ty8FORysE=ssrSQ9kvVA@mail.gmail.com>

I find that updating all packages is more effective than trying to chase
down all the dependencies through an endless string of errors.

It?s never taken me eight hours, but that would depend on computer,
Internet connection, number of packages, and how long it?s been since
you?ve done that maintenance. I do it routinely, so it never takes very
long, except after a major R version release.

None of which helps you, but I imagine by now it?s completed.

Sarah

On Thu, Feb 17, 2022 at 5:24 AM javed khan <javedbtk111 at gmail.com> wrote:

> @Sarah Goslee
>
> How much time it takes? Its been 8 hours and I am waiting to finish the
> updates.
>
> On Wed, Feb 16, 2022 at 10:13 PM Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>> Hi,
>>
>> The solution to that kind of error is always to update R to the
>> current version (4.1.2), and then to update all of your packages.
>>
>> At the R command line, you could use
>> update.packages(ask=FALSE) # possibly with checkBuilt=TRUE
>>
>> but I expect R Studio has a snazzy menu item to update everything.
>>
>> Sarah
>>
>> On Wed, Feb 16, 2022 at 3:54 PM javed khan <javedbtk111 at gmail.com> wrote:
>> >
>> > Hello
>> >
>> > My RStudio was working fine and then I installed tidyverse & updated
>> dplyr.
>> > Now when I opened RStudio, I get the following message
>> >
>> > Error: package or namespace load failed for ?farff? in loadNamespace(i,
>> > c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>> >  namespace ?ellipsis? 0.3.1 is already loaded, but >= 0.3.2 is required
>> > In addition: Warning message:
>> > package ?farff? was built under R version 4.0.5
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Sarah Goslee (she/her)
>> http://www.sarahgoslee.com
>>
> --
Sarah Goslee (she/her)
http://www.sarahgoslee.com

	[[alternative HTML version deleted]]


From emm@nue|@po|zot @end|ng |rom |ecn@m@net  Thu Feb 17 14:25:24 2022
From: emm@nue|@po|zot @end|ng |rom |ecn@m@net (Poizot Emmanuel)
Date: Thu, 17 Feb 2022 14:25:24 +0100
Subject: [R] gstat installation problem
In-Reply-To: <20220217153457.0f0f1118@arachnoid>
References: <60e1ad05-5ae2-cf12-7497-b21946c8633a@lecnam.net>
 <20220217153457.0f0f1118@arachnoid>
Message-ID: <2a9a0f2c-54ec-3a40-8a2c-c38c1cb63a27@lecnam.net>

Dear all,
thanks for advise. I succedded with version 2.0.0 of gstat. :)
regards

Le 17/02/2022 ? 13:34, Ivan Krylov a ?crit?:
> On Wed, 16 Feb 2022 15:20:48 +0100
> Poizot Emmanuel <emmanuel.poizot at lecnam.net> wrote:
> 
>> I tried to install gstat package via install.packages('gstat')
>> command on R (version 3.5.2) and my OS is Debian buster.
> 
>> mtrx.c: In function ?CHfactor?:
>> mtrx.c:391:74: error: ?FC_LEN_T? undeclared (first use in this
>> function); did you mean ?FD_SET??
>>      F77_CALL(dpotrf)("Upper", (int *)&(m->n), m->v, (int *)&(m->n),
>> info, (FC_LEN_T) 5);
> 
> The gstat package doesn't declare a correct R version dependency, but
> it does use a feature that appeared in a newer version of R. (3.6.2, I
> think?)
> 
> Try installing older versions of gstat from
> <https://cran.r-project.org/src/contrib/Archive/gstat/> until you find
> one that's working. Alternatively, install a newer version of R from
> <https://cran.r-project.org/bin/linux/debian/>.
> 

-- 
Cordialement

/------------------------------------------------
*Emmanuel Poizot*
Cnam/Intechmer
Bv. de Collignon
50110 Tourlaville
Cherbourg-En-Cotentin

Web: http://www.intechmer.cnam.fr <http://www.intechmer.cnam.fr>
Phone (Direct) : (00 33)(0)233887342 ou 41
Mobile : (00 33)(0)621425488
------------------------------------------------
*** "Quand le dernier arbre sera abattu, la derni?re rivi?re
empoisonn?e, le dernier poisson captur?, alors le visage pale
s'apercevra que l'argent ne se mange pas" (Sitting Bull) ***
/


/Ce message et toutes les pi?ces jointes sont confidentiels et ?tablis ?
l'intention exclusive de son ou ses destinataires. Si vous avez re?u ce
message par erreur, merci d'en avertir imm?diatement l'?metteur et de
d?truire le message. Toute modification, ?dition, utilisation ou
diffusion non autoris?e est interdite. L'?metteur d?cline toute
responsabilit? au titre de ce message s'il a ?t? modifi?, d?form?,
falsifi?, infect? par un virus ou encore ?dit? ou diffus? sans
autorisation.
This message and any attachments are confidential and intended for the
named addressee(s) only. If you have received this message in error,
please notify immediately the sender, then delete the message. Any
unauthorized modification, edition, use or dissemination is forbhide.
Sender declin any responsabibility on this message if it has been
modified, distorted, falsified, infected by virus or edited or broadcast
without authorization. /

From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Feb 17 19:54:45 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 17 Feb 2022 19:54:45 +0100
Subject: [R] Problem with data distribution
Message-ID: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>

Hello everyone

I have a dataset with output variable "bug" having the following values (at
the bottom of this email). My advisor asked me to provide data distribution
of bugs with 0 values and bugs with more than 0 values.

data = readARFF("synapse.arff")
data2 = readARFF("synapse.arff")
data$bug
library(tidyverse)
data %>%
  filter(bug == 0)
data2 %>%
  filter(bug >= 1)
boxplot(data2$bug, data$bug, range=0)

But both the graphs are exactly the same, how is it possible? Where I am
doing wrong?


data$bug
  [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
0 4 1 0
 [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
0 0 0 0
 [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
7 0 0 1
[118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
0 1 0 0
[157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
0 0 0 1
[196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Thu Feb 17 20:00:21 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 17 Feb 2022 19:00:21 +0000
Subject: [R] Problem with data distribution
In-Reply-To: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
Message-ID: <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>

You pipe the filter but do not save the result. A reproducible example might help.
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
Sent: Thursday, February 17, 2022 1:55 PM
To: r-help mailing list <r-help at r-project.org>
Subject: [R] Problem with data distribution

[External Email]

Hello everyone

I have a dataset with output variable "bug" having the following values (at the bottom of this email). My advisor asked me to provide data distribution of bugs with 0 values and bugs with more than 0 values.

data = readARFF("synapse.arff")
data2 = readARFF("synapse.arff")
data$bug
library(tidyverse)
data %>%
  filter(bug == 0)
data2 %>%
  filter(bug >= 1)
boxplot(data2$bug, data$bug, range=0)

But both the graphs are exactly the same, how is it possible? Where I am doing wrong?


data$bug
  [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
0 4 1 0
 [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
0 0 0 0
 [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
7 0 0 1
[118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
0 1 0 0
[157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
0 0 0 1
[196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
and provide commented, minimal, self-contained, reproducible code.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Feb 17 20:03:07 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 17 Feb 2022 20:03:07 +0100
Subject: [R] Problem with data distribution
In-Reply-To: <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CA+nrPnvf9700BO7nn7cP-d6sB96dTxegbQrfJO51jxf1d=HAng@mail.gmail.com>

That is all the code I have. How can I provide a  reproducible code ?

How can I save this result?

On Thu, Feb 17, 2022 at 8:00 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> You pipe the filter but do not save the result. A reproducible example
> might help.
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
> Sent: Thursday, February 17, 2022 1:55 PM
> To: r-help mailing list <r-help at r-project.org>
> Subject: [R] Problem with data distribution
>
> [External Email]
>
> Hello everyone
>
> I have a dataset with output variable "bug" having the following values
> (at the bottom of this email). My advisor asked me to provide data
> distribution of bugs with 0 values and bugs with more than 0 values.
>
> data = readARFF("synapse.arff")
> data2 = readARFF("synapse.arff")
> data$bug
> library(tidyverse)
> data %>%
>   filter(bug == 0)
> data2 %>%
>   filter(bug >= 1)
> boxplot(data2$bug, data$bug, range=0)
>
> But both the graphs are exactly the same, how is it possible? Where I am
> doing wrong?
>
>
> data$bug
>   [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
> 0 4 1 0
>  [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
> 0 0 0 0
>  [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
> 7 0 0 1
> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
> 0 1 0 0
> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
> 0 0 0 1
> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
> PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu Feb 17 20:21:39 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 17 Feb 2022 14:21:39 -0500
Subject: [R] Problem with data distribution
In-Reply-To: <19370_1645124120_21HItJe3026644_CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
References: <19370_1645124120_21HItJe3026644_CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
Message-ID: <4bcc262a-b940-7228-623c-5a8b5a5e7ec7@mcmaster.ca>

Dear Nega gupta,

On 2022-02-17 1:54 p.m., Neha gupta wrote:
> Hello everyone
> 
> I have a dataset with output variable "bug" having the following values (at
> the bottom of this email). My advisor asked me to provide data distribution
> of bugs with 0 values and bugs with more than 0 values.
> 
> data = readARFF("synapse.arff")
> data2 = readARFF("synapse.arff")
> data$bug
> library(tidyverse)
> data %>%
>    filter(bug == 0)
> data2 %>%
>    filter(bug >= 1)
> boxplot(data2$bug, data$bug, range=0)
> 
> But both the graphs are exactly the same, how is it possible? Where I am
> doing wrong?

As it turns out, you're doing several things wrong.

First, you're not using pipes and filter() correctly. That is, you don't 
do anything with the filtered versions of the data sets. You're 
apparently under the incorrect impression that filtering modifies the 
original data set.

Second, you're greatly complicating a simple problem. You don't need to 
read the data twice and keep two versions of the data set. As well, 
processing the data with pipes and filter() is entirely unnecessary. The 
following code works:

    with(data, boxplot(bug[bug == 0], bug[bug >= 1], range=0))

Third, and most fundamentally, the parallel boxplots you're apparently 
trying to construct don't really make sense. The first "boxplot" is just 
a horizontal line at 0 and so conveys no information. Why not just plot 
the nonzero values if that's what you're interested in?

Fourth, you didn't share your data in a convenient form. I was able to 
reconstruct them via

   bug <- scan()
   0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
   0 4 1 0
   0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
   0 0 0 0
   1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
   7 0 0 1
   0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
   0 1 0 0
   0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
   0 0 0 1
   0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0

   data <- data.frame(bug)

Finally, it's better not to post to the list in plain-text email, rather 
than html (as the posting guide suggests).

I hope this helps,
  John

> 
> 
> data$bug
>    [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
> 0 4 1 0
>   [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
> 0 0 0 0
>   [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
> 7 0 0 1
> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
> 0 1 0 0
> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
> 0 0 0 1
> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Feb 17 20:28:31 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 17 Feb 2022 19:28:31 +0000
Subject: [R] Problem with data distribution
In-Reply-To: <CA+nrPnvf9700BO7nn7cP-d6sB96dTxegbQrfJO51jxf1d=HAng@mail.gmail.com>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CA+nrPnvf9700BO7nn7cP-d6sB96dTxegbQrfJO51jxf1d=HAng@mail.gmail.com>
Message-ID: <a4ad4ab3-a30e-efda-6085-99dac5a298c7@sapo.pt>

Hello,

In your original post you read the same file "synapse.arff" twice, 
apparently to filter each of them by its own criterion. You don't need 
to do that, read once and filter that one by different criteria.

As for the data as posted, I have read it in with the following code:


x <- "
0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0 0 
4 1 0
0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0 0 
0 0 0
1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0 7 
0 0 1
0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0 0 
1 0 0
0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0 0 
0 0 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
"
bug <- scan(text = x)
data <- data.frame(bug)


This is not the right way to post data, the posting guide asks to post 
the output of


dput(data)
structure(list(bug = c(0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0,
0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 0, 0,
3, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,
0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0,
1, 0, 0, 1, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 1, 0,
1, 1, 0, 2, 0, 3, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
0, 1, 0, 3, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0,
0, 0, 0, 0, 1, 0, 4, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0)),
class = "data.frame", row.names = c(NA, -222L))



This can be copied into an R session and the data set recreated with

data <- structure(etc)


Now the boxplots.

(Why would you want to plot a vector of all zeros, btw?)



library(dplyr)

boxplot(filter(data, bug == 0))    # nonsense
boxplot(filter(data, bug > 0), range = 0)

# Another way
data %>%
   filter(bug > 0) %>%
   boxplot(range = 0)


Hope this helps,

Rui Barradas


?s 19:03 de 17/02/2022, Neha gupta escreveu:
> That is all the code I have. How can I provide a  reproducible code ?
> 
> How can I save this result?
> 
> On Thu, Feb 17, 2022 at 8:00 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
> 
>> You pipe the filter but do not save the result. A reproducible example
>> might help.
>> Tim
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
>> Sent: Thursday, February 17, 2022 1:55 PM
>> To: r-help mailing list <r-help at r-project.org>
>> Subject: [R] Problem with data distribution
>>
>> [External Email]
>>
>> Hello everyone
>>
>> I have a dataset with output variable "bug" having the following values
>> (at the bottom of this email). My advisor asked me to provide data
>> distribution of bugs with 0 values and bugs with more than 0 values.
>>
>> data = readARFF("synapse.arff")
>> data2 = readARFF("synapse.arff")
>> data$bug
>> library(tidyverse)
>> data %>%
>>    filter(bug == 0)
>> data2 %>%
>>    filter(bug >= 1)
>> boxplot(data2$bug, data$bug, range=0)
>>
>> But both the graphs are exactly the same, how is it possible? Where I am
>> doing wrong?
>>
>>
>> data$bug
>>    [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
>> 0 4 1 0
>>   [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
>> 0 0 0 0
>>   [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
>> 7 0 0 1
>> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
>> 0 1 0 0
>> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
>> 0 0 0 1
>> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Thu Feb 17 20:31:30 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 17 Feb 2022 14:31:30 -0500
Subject: [R] Problem with data distribution
In-Reply-To: <CA+nrPnt3mr6i_qVepU5Lnw48dtKJUvjyDDQCLFM1Q8gddxyj5w@mail.gmail.com>
References: <19370_1645124120_21HItJe3026644_CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <4bcc262a-b940-7228-623c-5a8b5a5e7ec7@mcmaster.ca>
 <CA+nrPnt3mr6i_qVepU5Lnw48dtKJUvjyDDQCLFM1Q8gddxyj5w@mail.gmail.com>
Message-ID: <9f8b4dd7-ef77-289a-f7b1-b561f5f16a8d@mcmaster.ca>

Dear Neha gupta,

I hope that I'm not overstepping my role when I say that googling 
solutions to specific problems isn't an inefficient way to learn a 
programming language, and will probably waste your time in the long run. 
There are many good introductions to R.

Best,
  John

On 2022-02-17 2:27 p.m., Neha gupta wrote:
> Dear John, thanks a lot for the detailed answer.
> 
> Yes, I am not an expert in R language and when a problem comes in, I 
> google it or post it on these forums. (I have just a little bit 
> experience of ML in R).
> 
> 
> 
> On Thu, Feb 17, 2022 at 8:21 PM John Fox <jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>> wrote:
> 
>     Dear Nega gupta,
> 
>     On 2022-02-17 1:54 p.m., Neha gupta wrote:
>      > Hello everyone
>      >
>      > I have a dataset with output variable "bug" having the following
>     values (at
>      > the bottom of this email). My advisor asked me to provide data
>     distribution
>      > of bugs with 0 values and bugs with more than 0 values.
>      >
>      > data = readARFF("synapse.arff")
>      > data2 = readARFF("synapse.arff")
>      > data$bug
>      > library(tidyverse)
>      > data %>%
>      >? ? filter(bug == 0)
>      > data2 %>%
>      >? ? filter(bug >= 1)
>      > boxplot(data2$bug, data$bug, range=0)
>      >
>      > But both the graphs are exactly the same, how is it possible?
>     Where I am
>      > doing wrong?
> 
>     As it turns out, you're doing several things wrong.
> 
>     First, you're not using pipes and filter() correctly. That is, you
>     don't
>     do anything with the filtered versions of the data sets. You're
>     apparently under the incorrect impression that filtering modifies the
>     original data set.
> 
>     Second, you're greatly complicating a simple problem. You don't need to
>     read the data twice and keep two versions of the data set. As well,
>     processing the data with pipes and filter() is entirely unnecessary.
>     The
>     following code works:
> 
>      ? ? with(data, boxplot(bug[bug == 0], bug[bug >= 1], range=0))
> 
>     Third, and most fundamentally, the parallel boxplots you're apparently
>     trying to construct don't really make sense. The first "boxplot" is
>     just
>     a horizontal line at 0 and so conveys no information. Why not just plot
>     the nonzero values if that's what you're interested in?
> 
>     Fourth, you didn't share your data in a convenient form. I was able to
>     reconstruct them via
> 
>      ? ?bug <- scan()
>      ? ?0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0
>     0 0 0
>      ? ?0 4 1 0
>      ? ?0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1
>     1 0 0
>      ? ?0 0 0 0
>      ? ?1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0
>     0 0 0
>      ? ?7 0 0 1
>      ? ?0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0
>     0 0 0
>      ? ?0 1 0 0
>      ? ?0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4
>     1 1 0
>      ? ?0 0 0 1
>      ? ?0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> 
>      ? ?data <- data.frame(bug)
> 
>     Finally, it's better not to post to the list in plain-text email,
>     rather
>     than html (as the posting guide suggests).
> 
>     I hope this helps,
>      ? John
> 
>      >
>      >
>      > data$bug
>      >? ? [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0
>     1 0 0 0 0 0
>      > 0 4 1 0
>      >? ?[40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0
>     0 1 1 1 0 0
>      > 0 0 0 0
>      >? ?[79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5
>     0 0 0 0 0 0
>      > 7 0 0 1
>      > [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0
>     0 0 0 0 0
>      > 0 1 0 0
>      > [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1
>     0 4 1 1 0
>      > 0 0 0 1
>      > [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>      > and provide commented, minimal, self-contained, reproducible code.
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>     <https://socialsciences.mcmaster.ca/jfox/>
> 
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From tebert @end|ng |rom u||@edu  Thu Feb 17 20:26:28 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 17 Feb 2022 19:26:28 +0000
Subject: [R] Problem with data distribution
In-Reply-To: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
Message-ID: <BN6PR2201MB155381CFD5EE9307FE69D734CF369@BN6PR2201MB1553.namprd22.prod.outlook.com>

data <- data %>% filter(bug==0) is one option, but you need to save the output somewhere.

Can you tell us more about the expected distribution of bug==0? More than a count of zero bugs.... number of zeros between non-zeros, or something else? 

You could provide the data but rename variables and treatments. Alternatively you could make fake data. It doesn't have to have the same distribution as the real data.

If bugs is the only variable you have then I could recover the data from what you printed (though it will take some effort to remove [#]). For our purposes this would also work:
sample(0:5,50,replace=TRUE)   #draws 50 values with replacement from 0 through 5 inclusive
sample(c(0,0,0,0,1,1,1,2,3,4,5),50,replace=TRUE) #draws 50 samples with replacement from a list of values

abs( round( rnorm(50, mean=2, sd=2),0)) #generates a random number, rounds it to integer, and takes the absolute value.

To make it fully reproducible in this approach one needs to set the random seed.



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
Sent: Thursday, February 17, 2022 1:55 PM
To: r-help mailing list <r-help at r-project.org>
Subject: [R] Problem with data distribution

[External Email]

Hello everyone

I have a dataset with output variable "bug" having the following values (at the bottom of this email). My advisor asked me to provide data distribution of bugs with 0 values and bugs with more than 0 values.

data = readARFF("synapse.arff")
data2 = readARFF("synapse.arff")
data$bug
library(tidyverse)
data %>%
  filter(bug == 0)
data2 %>%
  filter(bug >= 1)
boxplot(data2$bug, data$bug, range=0)

But both the graphs are exactly the same, how is it possible? Where I am doing wrong?


data$bug
  [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
0 4 1 0
 [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
0 0 0 0
 [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
7 0 0 1
[118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
0 1 0 0
[157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
0 0 0 1
[196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Thu Feb 17 20:27:25 2022
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 17 Feb 2022 14:27:25 -0500
Subject: [R] Problem with data distribution
In-Reply-To: <4bcc262a-b940-7228-623c-5a8b5a5e7ec7@mcmaster.ca>
References: <19370_1645124120_21HItJe3026644_CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <4bcc262a-b940-7228-623c-5a8b5a5e7ec7@mcmaster.ca>
Message-ID: <6c204910-f7ef-f55a-e324-ac79dae257ec@mcmaster.ca>

Dear Nega gupta,

In the last point, I meant to say, "Finally, it's better to post to the 
list in plain-text email, rather than html (as the posting guide 
suggests)." (I accidentally inserted a "not" in this sentence.)

Sorry,
  John

On 2022-02-17 2:21 p.m., John Fox wrote:
> Dear Nega gupta,
> 
> On 2022-02-17 1:54 p.m., Neha gupta wrote:
>> Hello everyone
>>
>> I have a dataset with output variable "bug" having the following 
>> values (at
>> the bottom of this email). My advisor asked me to provide data 
>> distribution
>> of bugs with 0 values and bugs with more than 0 values.
>>
>> data = readARFF("synapse.arff")
>> data2 = readARFF("synapse.arff")
>> data$bug
>> library(tidyverse)
>> data %>%
>> ?? filter(bug == 0)
>> data2 %>%
>> ?? filter(bug >= 1)
>> boxplot(data2$bug, data$bug, range=0)
>>
>> But both the graphs are exactly the same, how is it possible? Where I am
>> doing wrong?
> 
> As it turns out, you're doing several things wrong.
> 
> First, you're not using pipes and filter() correctly. That is, you don't 
> do anything with the filtered versions of the data sets. You're 
> apparently under the incorrect impression that filtering modifies the 
> original data set.
> 
> Second, you're greatly complicating a simple problem. You don't need to 
> read the data twice and keep two versions of the data set. As well, 
> processing the data with pipes and filter() is entirely unnecessary. The 
> following code works:
> 
>  ?? with(data, boxplot(bug[bug == 0], bug[bug >= 1], range=0))
> 
> Third, and most fundamentally, the parallel boxplots you're apparently 
> trying to construct don't really make sense. The first "boxplot" is just 
> a horizontal line at 0 and so conveys no information. Why not just plot 
> the nonzero values if that's what you're interested in?
> 
> Fourth, you didn't share your data in a convenient form. I was able to 
> reconstruct them via
> 
>  ? bug <- scan()
>  ? 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
>  ? 0 4 1 0
>  ? 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
>  ? 0 0 0 0
>  ? 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
>  ? 7 0 0 1
>  ? 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
>  ? 0 1 0 0
>  ? 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
>  ? 0 0 0 1
>  ? 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> 
>  ? data <- data.frame(bug)
> 
> Finally, it's better not to post to the list in plain-text email, rather 
> than html (as the posting guide suggests).
> 
> I hope this helps,
>  ?John
> 
>>
>>
>> data$bug
>> ?? [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 
>> 0 0 0
>> 0 4 1 0
>> ? [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 
>> 1 0 0
>> 0 0 0 0
>> ? [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 
>> 0 0 0
>> 7 0 0 1
>> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 
>> 0 0 0
>> 0 1 0 0
>> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 
>> 1 1 0
>> 0 0 0 1
>> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Feb 17 20:27:40 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 17 Feb 2022 20:27:40 +0100
Subject: [R] Problem with data distribution
In-Reply-To: <4bcc262a-b940-7228-623c-5a8b5a5e7ec7@mcmaster.ca>
References: <19370_1645124120_21HItJe3026644_CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <4bcc262a-b940-7228-623c-5a8b5a5e7ec7@mcmaster.ca>
Message-ID: <CA+nrPnt3mr6i_qVepU5Lnw48dtKJUvjyDDQCLFM1Q8gddxyj5w@mail.gmail.com>

Dear John, thanks a lot for the detailed answer.

Yes, I am not an expert in R language and when a problem comes in, I google
it or post it on these forums. (I have just a little bit experience of ML
in R).



On Thu, Feb 17, 2022 at 8:21 PM John Fox <jfox at mcmaster.ca> wrote:

> Dear Nega gupta,
>
> On 2022-02-17 1:54 p.m., Neha gupta wrote:
> > Hello everyone
> >
> > I have a dataset with output variable "bug" having the following values
> (at
> > the bottom of this email). My advisor asked me to provide data
> distribution
> > of bugs with 0 values and bugs with more than 0 values.
> >
> > data = readARFF("synapse.arff")
> > data2 = readARFF("synapse.arff")
> > data$bug
> > library(tidyverse)
> > data %>%
> >    filter(bug == 0)
> > data2 %>%
> >    filter(bug >= 1)
> > boxplot(data2$bug, data$bug, range=0)
> >
> > But both the graphs are exactly the same, how is it possible? Where I am
> > doing wrong?
>
> As it turns out, you're doing several things wrong.
>
> First, you're not using pipes and filter() correctly. That is, you don't
> do anything with the filtered versions of the data sets. You're
> apparently under the incorrect impression that filtering modifies the
> original data set.
>
> Second, you're greatly complicating a simple problem. You don't need to
> read the data twice and keep two versions of the data set. As well,
> processing the data with pipes and filter() is entirely unnecessary. The
> following code works:
>
>     with(data, boxplot(bug[bug == 0], bug[bug >= 1], range=0))
>
> Third, and most fundamentally, the parallel boxplots you're apparently
> trying to construct don't really make sense. The first "boxplot" is just
> a horizontal line at 0 and so conveys no information. Why not just plot
> the nonzero values if that's what you're interested in?
>
> Fourth, you didn't share your data in a convenient form. I was able to
> reconstruct them via
>
>    bug <- scan()
>    0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0
>    0 4 1 0
>    0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0
>    0 0 0 0
>    1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0
>    7 0 0 1
>    0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0
>    0 1 0 0
>    0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0
>    0 0 0 1
>    0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
>
>    data <- data.frame(bug)
>
> Finally, it's better not to post to the list in plain-text email, rather
> than html (as the posting guide suggests).
>
> I hope this helps,
>   John
>
> >
> >
> > data$bug
> >    [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0
> 0 0
> > 0 4 1 0
> >   [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1
> 0 0
> > 0 0 0 0
> >   [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0
> 0 0
> > 7 0 0 1
> > [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0
> 0 0
> > 0 1 0 0
> > [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1
> 1 0
> > 0 0 0 1
> > [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Feb 17 20:42:01 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 17 Feb 2022 20:42:01 +0100
Subject: [R] Problem with data distribution
In-Reply-To: <a4ad4ab3-a30e-efda-6085-99dac5a298c7@sapo.pt>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CA+nrPnvf9700BO7nn7cP-d6sB96dTxegbQrfJO51jxf1d=HAng@mail.gmail.com>
 <a4ad4ab3-a30e-efda-6085-99dac5a298c7@sapo.pt>
Message-ID: <CA+nrPnuqEswN_cFpJ6Nvi+7G4Zn3rhTdNdNRd3izvP5_aTN1_g@mail.gmail.com>

Ebert and Rui, thank you for providing the tips (in fact, for providing the
answer I needed).

Yes, you are right that boxplot of all zero values will not make sense.
Maybe histogram will work.

I am providing a few details of my data here and the context of the
question I asked.

My data is about bugs/defects in different classes of a large software
system. I have to predict which class will contain bugs and which will be
free of bugs (bug=0). I trained ML models and predict but my advisor asked
me to provide first the data distribution about bugs e.g details of how
many classes with bugs (bug > 0) and how many are free of bugs (bug=0).

That is why I need to provide the data distribution of both types of values
(i.e. bug=0 and bug >0)

Thank you again.

On Thu, Feb 17, 2022 at 8:28 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> In your original post you read the same file "synapse.arff" twice,
> apparently to filter each of them by its own criterion. You don't need
> to do that, read once and filter that one by different criteria.
>
> As for the data as posted, I have read it in with the following code:
>
>
> x <- "
> 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0 0
> 4 1 0
> 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0 0
> 0 0 0
> 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0 7
> 0 0 1
> 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0 0
> 1 0 0
> 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0 0
> 0 0 1
> 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> "
> bug <- scan(text = x)
> data <- data.frame(bug)
>
>
> This is not the right way to post data, the posting guide asks to post
> the output of
>
>
> dput(data)
> structure(list(bug = c(0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0,
> 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 0, 0,
> 3, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,
> 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0,
> 1, 0, 0, 1, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 1, 0,
> 1, 1, 0, 2, 0, 3, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
> 0, 1, 0, 3, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0,
> 0, 0, 0, 0, 1, 0, 4, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0)),
> class = "data.frame", row.names = c(NA, -222L))
>
>
>
> This can be copied into an R session and the data set recreated with
>
> data <- structure(etc)
>
>
> Now the boxplots.
>
> (Why would you want to plot a vector of all zeros, btw?)
>
>
>
> library(dplyr)
>
> boxplot(filter(data, bug == 0))    # nonsense
> boxplot(filter(data, bug > 0), range = 0)
>
> # Another way
> data %>%
>    filter(bug > 0) %>%
>    boxplot(range = 0)
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 19:03 de 17/02/2022, Neha gupta escreveu:
> > That is all the code I have. How can I provide a  reproducible code ?
> >
> > How can I save this result?
> >
> > On Thu, Feb 17, 2022 at 8:00 PM Ebert,Timothy Aaron <tebert at ufl.edu>
> wrote:
> >
> >> You pipe the filter but do not save the result. A reproducible example
> >> might help.
> >> Tim
> >>
> >> -----Original Message-----
> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
> >> Sent: Thursday, February 17, 2022 1:55 PM
> >> To: r-help mailing list <r-help at r-project.org>
> >> Subject: [R] Problem with data distribution
> >>
> >> [External Email]
> >>
> >> Hello everyone
> >>
> >> I have a dataset with output variable "bug" having the following values
> >> (at the bottom of this email). My advisor asked me to provide data
> >> distribution of bugs with 0 values and bugs with more than 0 values.
> >>
> >> data = readARFF("synapse.arff")
> >> data2 = readARFF("synapse.arff")
> >> data$bug
> >> library(tidyverse)
> >> data %>%
> >>    filter(bug == 0)
> >> data2 %>%
> >>    filter(bug >= 1)
> >> boxplot(data2$bug, data$bug, range=0)
> >>
> >> But both the graphs are exactly the same, how is it possible? Where I am
> >> doing wrong?
> >>
> >>
> >> data$bug
> >>    [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0
> 0 0 0
> >> 0 4 1 0
> >>   [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1
> 1 0 0
> >> 0 0 0 0
> >>   [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0
> 0 0 0
> >> 7 0 0 1
> >> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0
> 0 0
> >> 0 1 0 0
> >> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1
> 1 0
> >> 0 0 0 1
> >> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
> >> PLEASE do read the posting guide
> >>
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb 17 22:37:43 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 17 Feb 2022 13:37:43 -0800
Subject: [R] Problem with data distribution
In-Reply-To: <CA+nrPnuqEswN_cFpJ6Nvi+7G4Zn3rhTdNdNRd3izvP5_aTN1_g@mail.gmail.com>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CA+nrPnvf9700BO7nn7cP-d6sB96dTxegbQrfJO51jxf1d=HAng@mail.gmail.com>
 <a4ad4ab3-a30e-efda-6085-99dac5a298c7@sapo.pt>
 <CA+nrPnuqEswN_cFpJ6Nvi+7G4Zn3rhTdNdNRd3izvP5_aTN1_g@mail.gmail.com>
Message-ID: <CAGxFJbTZ0U1cJR2R_N2SKAmqwJoapSgjPP5VkF4sRaZVumwndA@mail.gmail.com>

imo, with such simple data, a plot is mere chartjunk. A simple table(=
the distribution) would suffice and be more informative:

> table(bug) ## bug is a vector. No data frame is needed

  0   1     2    3   4   5   7   ## bug count
162  40   9   7   2   1   1   ## nmbr of cases with the given count

You or others may disagree, of course.

Bert Gunter



On Thu, Feb 17, 2022 at 11:56 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
> Ebert and Rui, thank you for providing the tips (in fact, for providing the
> answer I needed).
>
> Yes, you are right that boxplot of all zero values will not make sense.
> Maybe histogram will work.
>
> I am providing a few details of my data here and the context of the
> question I asked.
>
> My data is about bugs/defects in different classes of a large software
> system. I have to predict which class will contain bugs and which will be
> free of bugs (bug=0). I trained ML models and predict but my advisor asked
> me to provide first the data distribution about bugs e.g details of how
> many classes with bugs (bug > 0) and how many are free of bugs (bug=0).
>
> That is why I need to provide the data distribution of both types of values
> (i.e. bug=0 and bug >0)
>
> Thank you again.
>
> On Thu, Feb 17, 2022 at 8:28 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> > Hello,
> >
> > In your original post you read the same file "synapse.arff" twice,
> > apparently to filter each of them by its own criterion. You don't need
> > to do that, read once and filter that one by different criteria.
> >
> > As for the data as posted, I have read it in with the following code:
> >
> >
> > x <- "
> > 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0 0
> > 4 1 0
> > 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0 0
> > 0 0 0
> > 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0 7
> > 0 0 1
> > 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0 0
> > 1 0 0
> > 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0 0
> > 0 0 1
> > 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> > "
> > bug <- scan(text = x)
> > data <- data.frame(bug)
> >
> >
> > This is not the right way to post data, the posting guide asks to post
> > the output of
> >
> >
> > dput(data)
> > structure(list(bug = c(0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0,
> > 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 0, 0,
> > 3, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,
> > 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0,
> > 1, 0, 0, 1, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 1, 0,
> > 1, 1, 0, 2, 0, 3, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
> > 0, 1, 0, 3, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0,
> > 0, 0, 0, 0, 1, 0, 4, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0)),
> > class = "data.frame", row.names = c(NA, -222L))
> >
> >
> >
> > This can be copied into an R session and the data set recreated with
> >
> > data <- structure(etc)
> >
> >
> > Now the boxplots.
> >
> > (Why would you want to plot a vector of all zeros, btw?)
> >
> >
> >
> > library(dplyr)
> >
> > boxplot(filter(data, bug == 0))    # nonsense
> > boxplot(filter(data, bug > 0), range = 0)
> >
> > # Another way
> > data %>%
> >    filter(bug > 0) %>%
> >    boxplot(range = 0)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > ?s 19:03 de 17/02/2022, Neha gupta escreveu:
> > > That is all the code I have. How can I provide a  reproducible code ?
> > >
> > > How can I save this result?
> > >
> > > On Thu, Feb 17, 2022 at 8:00 PM Ebert,Timothy Aaron <tebert at ufl.edu>
> > wrote:
> > >
> > >> You pipe the filter but do not save the result. A reproducible example
> > >> might help.
> > >> Tim
> > >>
> > >> -----Original Message-----
> > >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
> > >> Sent: Thursday, February 17, 2022 1:55 PM
> > >> To: r-help mailing list <r-help at r-project.org>
> > >> Subject: [R] Problem with data distribution
> > >>
> > >> [External Email]
> > >>
> > >> Hello everyone
> > >>
> > >> I have a dataset with output variable "bug" having the following values
> > >> (at the bottom of this email). My advisor asked me to provide data
> > >> distribution of bugs with 0 values and bugs with more than 0 values.
> > >>
> > >> data = readARFF("synapse.arff")
> > >> data2 = readARFF("synapse.arff")
> > >> data$bug
> > >> library(tidyverse)
> > >> data %>%
> > >>    filter(bug == 0)
> > >> data2 %>%
> > >>    filter(bug >= 1)
> > >> boxplot(data2$bug, data$bug, range=0)
> > >>
> > >> But both the graphs are exactly the same, how is it possible? Where I am
> > >> doing wrong?
> > >>
> > >>
> > >> data$bug
> > >>    [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0
> > 0 0 0
> > >> 0 4 1 0
> > >>   [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1
> > 1 0 0
> > >> 0 0 0 0
> > >>   [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0
> > 0 0 0
> > >> 7 0 0 1
> > >> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0
> > 0 0
> > >> 0 1 0 0
> > >> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1
> > 1 0
> > >> 0 0 0 1
> > >> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> > >>
> > >>          [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
> > >> PLEASE do read the posting guide
> > >>
> > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Feb 17 22:53:51 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 17 Feb 2022 22:53:51 +0100
Subject: [R] Problem with data distribution
In-Reply-To: <CAGxFJbTZ0U1cJR2R_N2SKAmqwJoapSgjPP5VkF4sRaZVumwndA@mail.gmail.com>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CA+nrPnvf9700BO7nn7cP-d6sB96dTxegbQrfJO51jxf1d=HAng@mail.gmail.com>
 <a4ad4ab3-a30e-efda-6085-99dac5a298c7@sapo.pt>
 <CA+nrPnuqEswN_cFpJ6Nvi+7G4Zn3rhTdNdNRd3izvP5_aTN1_g@mail.gmail.com>
 <CAGxFJbTZ0U1cJR2R_N2SKAmqwJoapSgjPP5VkF4sRaZVumwndA@mail.gmail.com>
Message-ID: <CA+nrPnuh29AMfjtcJgBhURUFx9vO1TTdfMOS-jBbNQUEFf8NDw@mail.gmail.com>

:) :)

On Thu, Feb 17, 2022 at 10:37 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> imo, with such simple data, a plot is mere chartjunk. A simple table(=
> the distribution) would suffice and be more informative:
>
> > table(bug) ## bug is a vector. No data frame is needed
>
>   0   1     2    3   4   5   7   ## bug count
> 162  40   9   7   2   1   1   ## nmbr of cases with the given count
>
> You or others may disagree, of course.
>
> Bert Gunter
>
>
>
> On Thu, Feb 17, 2022 at 11:56 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >
> > Ebert and Rui, thank you for providing the tips (in fact, for providing
> the
> > answer I needed).
> >
> > Yes, you are right that boxplot of all zero values will not make sense.
> > Maybe histogram will work.
> >
> > I am providing a few details of my data here and the context of the
> > question I asked.
> >
> > My data is about bugs/defects in different classes of a large software
> > system. I have to predict which class will contain bugs and which will be
> > free of bugs (bug=0). I trained ML models and predict but my advisor
> asked
> > me to provide first the data distribution about bugs e.g details of how
> > many classes with bugs (bug > 0) and how many are free of bugs (bug=0).
> >
> > That is why I need to provide the data distribution of both types of
> values
> > (i.e. bug=0 and bug >0)
> >
> > Thank you again.
> >
> > On Thu, Feb 17, 2022 at 8:28 PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> > > Hello,
> > >
> > > In your original post you read the same file "synapse.arff" twice,
> > > apparently to filter each of them by its own criterion. You don't need
> > > to do that, read once and filter that one by different criteria.
> > >
> > > As for the data as posted, I have read it in with the following code:
> > >
> > >
> > > x <- "
> > > 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 0 0 0
> > > 4 1 0
> > > 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 0 0 0
> > > 0 0 0
> > > 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 0 0 7
> > > 0 0 1
> > > 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 0 0 0
> > > 1 0 0
> > > 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 1 0 0
> > > 0 0 1
> > > 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> > > "
> > > bug <- scan(text = x)
> > > data <- data.frame(bug)
> > >
> > >
> > > This is not the right way to post data, the posting guide asks to post
> > > the output of
> > >
> > >
> > > dput(data)
> > > structure(list(bug = c(0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0,
> > > 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 0, 0,
> > > 3, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,
> > > 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0,
> > > 1, 0, 0, 1, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 1, 0,
> > > 1, 1, 0, 2, 0, 3, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,
> > > 0, 1, 0, 3, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 3, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 1, 0, 4, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0)),
> > > class = "data.frame", row.names = c(NA, -222L))
> > >
> > >
> > >
> > > This can be copied into an R session and the data set recreated with
> > >
> > > data <- structure(etc)
> > >
> > >
> > > Now the boxplots.
> > >
> > > (Why would you want to plot a vector of all zeros, btw?)
> > >
> > >
> > >
> > > library(dplyr)
> > >
> > > boxplot(filter(data, bug == 0))    # nonsense
> > > boxplot(filter(data, bug > 0), range = 0)
> > >
> > > # Another way
> > > data %>%
> > >    filter(bug > 0) %>%
> > >    boxplot(range = 0)
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > > ?s 19:03 de 17/02/2022, Neha gupta escreveu:
> > > > That is all the code I have. How can I provide a  reproducible code ?
> > > >
> > > > How can I save this result?
> > > >
> > > > On Thu, Feb 17, 2022 at 8:00 PM Ebert,Timothy Aaron <tebert at ufl.edu>
> > > wrote:
> > > >
> > > >> You pipe the filter but do not save the result. A reproducible
> example
> > > >> might help.
> > > >> Tim
> > > >>
> > > >> -----Original Message-----
> > > >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
> > > >> Sent: Thursday, February 17, 2022 1:55 PM
> > > >> To: r-help mailing list <r-help at r-project.org>
> > > >> Subject: [R] Problem with data distribution
> > > >>
> > > >> [External Email]
> > > >>
> > > >> Hello everyone
> > > >>
> > > >> I have a dataset with output variable "bug" having the following
> values
> > > >> (at the bottom of this email). My advisor asked me to provide data
> > > >> distribution of bugs with 0 values and bugs with more than 0 values.
> > > >>
> > > >> data = readARFF("synapse.arff")
> > > >> data2 = readARFF("synapse.arff")
> > > >> data$bug
> > > >> library(tidyverse)
> > > >> data %>%
> > > >>    filter(bug == 0)
> > > >> data2 %>%
> > > >>    filter(bug >= 1)
> > > >> boxplot(data2$bug, data$bug, range=0)
> > > >>
> > > >> But both the graphs are exactly the same, how is it possible? Where
> I am
> > > >> doing wrong?
> > > >>
> > > >>
> > > >> data$bug
> > > >>    [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1
> 0 0
> > > 0 0 0
> > > >> 0 4 1 0
> > > >>   [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0
> 1 1
> > > 1 0 0
> > > >> 0 0 0 0
> > > >>   [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0
> 0 0
> > > 0 0 0
> > > >> 7 0 0 1
> > > >> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0
> 0 0
> > > 0 0
> > > >> 0 1 0 0
> > > >> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0
> 4 1
> > > 1 0
> > > >> 0 0 0 1
> > > >> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> > > >>
> > > >>          [[alternative HTML version deleted]]
> > > >>
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>
> > >
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
> > > >> PLEASE do read the posting guide
> > > >>
> > >
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > > >>
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@r|u@@ho|ert @end|ng |rom uw@ter|oo@c@  Thu Feb 17 23:40:09 2022
From: m@r|u@@ho|ert @end|ng |rom uw@ter|oo@c@ (Marius Hofert)
Date: Thu, 17 Feb 2022 22:40:09 +0000
Subject: [R] Why does the print method fail for very small numbers?
Message-ID: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>

Dear expeRts,

I'm familiar with IEEE 754. Is there an easy way to explain why even
just printing of small numbers fails?

1e-317 # 1e-317 => fine
1e-318 # 9.999987e-319 => gets tricky; seems to call print() => as.character() => format() => paste()
1e-318 == 9.999987e-319 # TRUE
2.48e-324 # prints 4.940656e-324 for me
2.48e-324 == 4.940656e-324 # TRUE
## Relative error as a plot
rel_error <- function(x)
    plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
         ylab = "Relative error between x and as.numeric(as.character(x))")
rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) # fine
rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing breaks down

Of course, [0,.Machine$double.xmin] is somewhat of a strange set of numbers to consider,
and I expect things like "==" to be easily fooled there, but already the print method (?)

Thanks & cheers,
Marius

sessionInfo()
R version 4.1.2 (2021-11-01)
Platform: x86_64-apple-darwin21.2.0 (64-bit)
Running under: macOS Monterey 12.1
...



From tebert @end|ng |rom u||@edu  Thu Feb 17 23:43:45 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 17 Feb 2022 22:43:45 +0000
Subject: [R] Problem with data distribution
In-Reply-To: <CA+nrPnuh29AMfjtcJgBhURUFx9vO1TTdfMOS-jBbNQUEFf8NDw@mail.gmail.com>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CA+nrPnvf9700BO7nn7cP-d6sB96dTxegbQrfJO51jxf1d=HAng@mail.gmail.com>
 <a4ad4ab3-a30e-efda-6085-99dac5a298c7@sapo.pt>
 <CA+nrPnuqEswN_cFpJ6Nvi+7G4Zn3rhTdNdNRd3izvP5_aTN1_g@mail.gmail.com>
 <CAGxFJbTZ0U1cJR2R_N2SKAmqwJoapSgjPP5VkF4sRaZVumwndA@mail.gmail.com>
 <CA+nrPnuh29AMfjtcJgBhURUFx9vO1TTdfMOS-jBbNQUEFf8NDw@mail.gmail.com>
Message-ID: <BN6PR2201MB15532242F13A1C5811C1EC12CF369@BN6PR2201MB1553.namprd22.prod.outlook.com>

Maybe what you want is to recode your data differently.
One data set has bug versus no bug. What is the probability of having one or more bugs?
The other data set has bugs only. Given that I have bugs how many will I get?

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
Sent: Thursday, February 17, 2022 4:54 PM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Problem with data distribution

[External Email]

:) :)

On Thu, Feb 17, 2022 at 10:37 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> imo, with such simple data, a plot is mere chartjunk. A simple table(= 
> the distribution) would suffice and be more informative:
>
> > table(bug) ## bug is a vector. No data frame is needed
>
>   0   1     2    3   4   5   7   ## bug count
> 162  40   9   7   2   1   1   ## nmbr of cases with the given count
>
> You or others may disagree, of course.
>
> Bert Gunter
>
>
>
> On Thu, Feb 17, 2022 at 11:56 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >
> > Ebert and Rui, thank you for providing the tips (in fact, for 
> > providing
> the
> > answer I needed).
> >
> > Yes, you are right that boxplot of all zero values will not make sense.
> > Maybe histogram will work.
> >
> > I am providing a few details of my data here and the context of the 
> > question I asked.
> >
> > My data is about bugs/defects in different classes of a large 
> > software system. I have to predict which class will contain bugs and 
> > which will be free of bugs (bug=0). I trained ML models and predict 
> > but my advisor
> asked
> > me to provide first the data distribution about bugs e.g details of 
> > how many classes with bugs (bug > 0) and how many are free of bugs (bug=0).
> >
> > That is why I need to provide the data distribution of both types of
> values
> > (i.e. bug=0 and bug >0)
> >
> > Thank you again.
> >
> > On Thu, Feb 17, 2022 at 8:28 PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> > > Hello,
> > >
> > > In your original post you read the same file "synapse.arff" twice, 
> > > apparently to filter each of them by its own criterion. You don't 
> > > need to do that, read once and filter that one by different criteria.
> > >
> > > As for the data as posted, I have read it in with the following code:
> > >
> > >
> > > x <- "
> > > 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0 
> > > 0 0 0
> > > 4 1 0
> > > 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1 
> > > 0 0 0
> > > 0 0 0
> > > 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0 
> > > 0 0 7
> > > 0 0 1
> > > 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0 
> > > 0 0 0
> > > 1 0 0
> > > 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1 
> > > 1 0 0
> > > 0 0 1
> > > 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0 "
> > > bug <- scan(text = x)
> > > data <- data.frame(bug)
> > >
> > >
> > > This is not the right way to post data, the posting guide asks to 
> > > post the output of
> > >
> > >
> > > dput(data)
> > > structure(list(bug = c(0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 
> > > 4, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 
> > > 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 
> > > 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 
> > > 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 1, 0, 1, 1, 0, 2, 0, 3, 
> > > 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 3, 2, 1, 1, 
> > > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 
> > > 0, 0, 3, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 1, 1, 
> > > 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
> > > 0, 0, 3, 0, 1, 0, 0, 0, 0, 0)), class = "data.frame", row.names = 
> > > c(NA, -222L))
> > >
> > >
> > >
> > > This can be copied into an R session and the data set recreated 
> > > with
> > >
> > > data <- structure(etc)
> > >
> > >
> > > Now the boxplots.
> > >
> > > (Why would you want to plot a vector of all zeros, btw?)
> > >
> > >
> > >
> > > library(dplyr)
> > >
> > > boxplot(filter(data, bug == 0))    # nonsense
> > > boxplot(filter(data, bug > 0), range = 0)
> > >
> > > # Another way
> > > data %>%
> > >    filter(bug > 0) %>%
> > >    boxplot(range = 0)
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > > ?s 19:03 de 17/02/2022, Neha gupta escreveu:
> > > > That is all the code I have. How can I provide a  reproducible code ?
> > > >
> > > > How can I save this result?
> > > >
> > > > On Thu, Feb 17, 2022 at 8:00 PM Ebert,Timothy Aaron 
> > > > <tebert at ufl.edu>
> > > wrote:
> > > >
> > > >> You pipe the filter but do not save the result. A reproducible
> example
> > > >> might help.
> > > >> Tim
> > > >>
> > > >> -----Original Message-----
> > > >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha 
> > > >> gupta
> > > >> Sent: Thursday, February 17, 2022 1:55 PM
> > > >> To: r-help mailing list <r-help at r-project.org>
> > > >> Subject: [R] Problem with data distribution
> > > >>
> > > >> [External Email]
> > > >>
> > > >> Hello everyone
> > > >>
> > > >> I have a dataset with output variable "bug" having the 
> > > >> following
> values
> > > >> (at the bottom of this email). My advisor asked me to provide 
> > > >> data distribution of bugs with 0 values and bugs with more than 0 values.
> > > >>
> > > >> data = readARFF("synapse.arff")
> > > >> data2 = readARFF("synapse.arff") data$bug
> > > >> library(tidyverse)
> > > >> data %>%
> > > >>    filter(bug == 0)
> > > >> data2 %>%
> > > >>    filter(bug >= 1)
> > > >> boxplot(data2$bug, data$bug, range=0)
> > > >>
> > > >> But both the graphs are exactly the same, how is it possible? 
> > > >> Where
> I am
> > > >> doing wrong?
> > > >>
> > > >>
> > > >> data$bug
> > > >>    [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 
> > > >> 0 1
> 0 0
> > > 0 0 0
> > > >> 0 4 1 0
> > > >>   [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 
> > > >> 0 0
> 1 1
> > > 1 0 0
> > > >> 0 0 0 0
> > > >>   [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 
> > > >> 5 0
> 0 0
> > > 0 0 0
> > > >> 7 0 0 1
> > > >> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 
> > > >> 0 0
> 0 0
> > > 0 0
> > > >> 0 1 0 0
> > > >> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 
> > > >> 1 0
> 4 1
> > > 1 0
> > > >> 0 0 0 1
> > > >> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> > > >>
> > > >>          [[alternative HTML version deleted]]
> > > >>
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, 
> > > >> see
> > > >>
> > >
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> Rzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8
> YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
> > > >> PLEASE do read the posting guide
> > > >>
> > >
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> sRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR
> 8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > > >>
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, 
> > > > see 
> > > > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.c
> > > > h_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=
> > > > 9PEhQh2kVeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgM
> > > > CpncRRH1bjKjIUqHjMj8vHCeH&s=53w0MvIpfAklRelSPE5abL_5YG-wyIrrXiFa
> > > > oqbAfLo&e= PLEASE do read the posting guide
> > > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dprojec
> > > t.org_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PE
> > > hQh2kVeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncR
> > > RH1bjKjIUqHjMj8vHCeH&s=MBVLtPJJyplOC4i8e5ZupFYAXaiICGuK6qsIzxnCEP4
> > > &e=
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
> > ilman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2k
> > VeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncRRH1bjKj
> > IUqHjMj8vHCeH&s=53w0MvIpfAklRelSPE5abL_5YG-wyIrrXiFaoqbAfLo&e=
> > PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> g_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> sRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncRRH1bjKjIUqHj
> Mj8vHCeH&s=MBVLtPJJyplOC4i8e5ZupFYAXaiICGuK6qsIzxnCEP4&e=
> > and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncRRH1bjKjIUqHjMj8vHCeH&s=53w0MvIpfAklRelSPE5abL_5YG-wyIrrXiFaoqbAfLo&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncRRH1bjKjIUqHjMj8vHCeH&s=MBVLtPJJyplOC4i8e5ZupFYAXaiICGuK6qsIzxnCEP4&e=
and provide commented, minimal, self-contained, reproducible code.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 18 00:20:39 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Feb 2022 15:20:39 -0800
Subject: [R] Why does the print method fail for very small numbers?
In-Reply-To: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
References: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <595F2B47-719A-4D6F-9150-C15A47D185F0@dcn.davis.ca.us>

Go to https://cs.lmu.edu/~ray/demos/ieee754.html

and enter

2.48e-324

into the encoder box. You get

0000000000000001

which means you are well beyond normalized representation and are approximating this value with a total of 1 bit of precision.

Do you really want to fault the print method for having difficulty returning your value to you after this much rounding?

On February 17, 2022 2:40:09 PM PST, Marius Hofert <marius.hofert at uwaterloo.ca> wrote:
>Dear expeRts,
>
>I'm familiar with IEEE 754. Is there an easy way to explain why even
>just printing of small numbers fails?
>
>1e-317 # 1e-317 => fine
>1e-318 # 9.999987e-319 => gets tricky; seems to call print() => as.character() => format() => paste()
>1e-318 == 9.999987e-319 # TRUE
>2.48e-324 # prints 4.940656e-324 for me
>2.48e-324 == 4.940656e-324 # TRUE
>## Relative error as a plot
>rel_error <- function(x)
>    plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
>         ylab = "Relative error between x and as.numeric(as.character(x))")
>rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) # fine
>rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing breaks down
>
>Of course, [0,.Machine$double.xmin] is somewhat of a strange set of numbers to consider,
>and I expect things like "==" to be easily fooled there, but already the print method (?)
>
>Thanks & cheers,
>Marius
>
>sessionInfo()
>R version 4.1.2 (2021-11-01)
>Platform: x86_64-apple-darwin21.2.0 (64-bit)
>Running under: macOS Monterey 12.1
>...
>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@r|u@@ho|ert @end|ng |rom uw@ter|oo@c@  Fri Feb 18 00:36:09 2022
From: m@r|u@@ho|ert @end|ng |rom uw@ter|oo@c@ (Marius Hofert)
Date: Thu, 17 Feb 2022 23:36:09 +0000
Subject: [R] Why does the print method fail for very small numbers?
In-Reply-To: <595F2B47-719A-4D6F-9150-C15A47D185F0@dcn.davis.ca.us>
References: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
 <595F2B47-719A-4D6F-9150-C15A47D185F0@dcn.davis.ca.us>
Message-ID: <YQXPR01MB6464F04BB10E16A5707C29C187369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>

Thanks, Jeff.

... all clear (as I wrote, I'm familiar with IEEE 754). I'm just wondering why this happens since the print method seems to call print() => as.character()... so shouldn't this *not* be a problem then (?). I guess at some point it is indeed handled as a number and then (as you wrote) the problem appears (for which one shouldn't blame anybody of course :-) ).

Thanks & cheers,
M

________________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Thursday, February 17, 2022 18:20
To: r-help at r-project.org; Marius Hofert; r-help at r-project.org
Subject: Re: [R] Why does the print method fail for very small numbers?

Go to https://cs.lmu.edu/~ray/demos/ieee754.html

and enter

2.48e-324

into the encoder box. You get

0000000000000001

which means you are well beyond normalized representation and are approximating this value with a total of 1 bit of precision.

Do you really want to fault the print method for having difficulty returning your value to you after this much rounding?

On February 17, 2022 2:40:09 PM PST, Marius Hofert <marius.hofert at uwaterloo.ca> wrote:
>Dear expeRts,
>
>I'm familiar with IEEE 754. Is there an easy way to explain why even
>just printing of small numbers fails?
>
>1e-317 # 1e-317 => fine
>1e-318 # 9.999987e-319 => gets tricky; seems to call print() => as.character() => format() => paste()
>1e-318 == 9.999987e-319 # TRUE
>2.48e-324 # prints 4.940656e-324 for me
>2.48e-324 == 4.940656e-324 # TRUE
>## Relative error as a plot
>rel_error <- function(x)
>    plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
>         ylab = "Relative error between x and as.numeric(as.character(x))")
>rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) # fine
>rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing breaks down
>
>Of course, [0,.Machine$double.xmin] is somewhat of a strange set of numbers to consider,
>and I expect things like "==" to be easily fooled there, but already the print method (?)
>
>Thanks & cheers,
>Marius
>
>sessionInfo()
>R version 4.1.2 (2021-11-01)
>Platform: x86_64-apple-darwin21.2.0 (64-bit)
>Running under: macOS Monterey 12.1
>...
>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.


From iuke-tier@ey m@iii@g oii uiow@@edu  Fri Feb 18 00:50:15 2022
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Thu, 17 Feb 2022 17:50:15 -0600 (CST)
Subject: [R] [External] Why does the print method fail for very small
 numbers?
In-Reply-To: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
References: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <2e76873c-8d43-489f-a713-202b24aebab4@uiowa.edu>

Values this small are denormalized numbers and only have a few binary
digits of accuracy.  The smallest positive value an IEEE double
precision number can have is 2^-1074.  The second smallest IEEE double
precision number is 2^-1073, and the third smallest is 2^-1073 +
2^-1074.

The numbers 2.48e-324 and 4.940656e-324 are both read in as 2^-1074:

> 2.48e-324 == 2^-1074
[1] TRUE
> 4.940656e-324 == 2^-1074
[1] TRUE

You can see the binary representations with

example(numToBits) ## for bitC
bitC(2^-1074)
bitC(2^-1073)
bitC(2^-1073 + 2^-1074)

Look up 'denormalized numbers' if you want to learn more.

Best,

luke

On Thu, 17 Feb 2022, Marius Hofert wrote:

> Dear expeRts,
>
> I'm familiar with IEEE 754. Is there an easy way to explain why even
> just printing of small numbers fails?
>
> 1e-317 # 1e-317 => fine
> 1e-318 # 9.999987e-319 => gets tricky; seems to call print() => as.character() => format() => paste()
> 1e-318 == 9.999987e-319 # TRUE
> 2.48e-324 # prints 4.940656e-324 for me
> 2.48e-324 == 4.940656e-324 # TRUE
> ## Relative error as a plot
> rel_error <- function(x)
>    plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
>         ylab = "Relative error between x and as.numeric(as.character(x))")
> rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) # fine
> rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing breaks down
>
> Of course, [0,.Machine$double.xmin] is somewhat of a strange set of numbers to consider,
> and I expect things like "==" to be easily fooled there, but already the print method (?)
>
> Thanks & cheers,
> Marius
>
> sessionInfo()
> R version 4.1.2 (2021-11-01)
> Platform: x86_64-apple-darwin21.2.0 (64-bit)
> Running under: macOS Monterey 12.1
> ...
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 18 00:56:13 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Feb 2022 15:56:13 -0800
Subject: [R] Why does the print method fail for very small numbers?
In-Reply-To: <YQXPR01MB6464F04BB10E16A5707C29C187369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
References: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
 <595F2B47-719A-4D6F-9150-C15A47D185F0@dcn.davis.ca.us>
 <YQXPR01MB6464F04BB10E16A5707C29C187369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <56C156F8-1E02-4BDD-B093-6F6FD79BF184@dcn.davis.ca.us>

Indeed, if the value that is printed starts out as the character string you typed, then none of this would apply. But if you type in a numeric literal in R source code (even interactively) then R will first turn that literal into a numeric value when evaluating the print expression, which is why format()/as.character is needed to retrieve something printable.

On February 17, 2022 3:36:09 PM PST, Marius Hofert <marius.hofert at uwaterloo.ca> wrote:
>Thanks, Jeff.
>
>... all clear (as I wrote, I'm familiar with IEEE 754). I'm just wondering why this happens since the print method seems to call print() => as.character()... so shouldn't this *not* be a problem then (?). I guess at some point it is indeed handled as a number and then (as you wrote) the problem appears (for which one shouldn't blame anybody of course :-) ).
>
>Thanks & cheers,
>M
>
>________________________________________
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Thursday, February 17, 2022 18:20
>To: r-help at r-project.org; Marius Hofert; r-help at r-project.org
>Subject: Re: [R] Why does the print method fail for very small numbers?
>
>Go to https://cs.lmu.edu/~ray/demos/ieee754.html
>
>and enter
>
>2.48e-324
>
>into the encoder box. You get
>
>0000000000000001
>
>which means you are well beyond normalized representation and are approximating this value with a total of 1 bit of precision.
>
>Do you really want to fault the print method for having difficulty returning your value to you after this much rounding?
>
>On February 17, 2022 2:40:09 PM PST, Marius Hofert <marius.hofert at uwaterloo.ca> wrote:
>>Dear expeRts,
>>
>>I'm familiar with IEEE 754. Is there an easy way to explain why even
>>just printing of small numbers fails?
>>
>>1e-317 # 1e-317 => fine
>>1e-318 # 9.999987e-319 => gets tricky; seems to call print() => as.character() => format() => paste()
>>1e-318 == 9.999987e-319 # TRUE
>>2.48e-324 # prints 4.940656e-324 for me
>>2.48e-324 == 4.940656e-324 # TRUE
>>## Relative error as a plot
>>rel_error <- function(x)
>>    plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
>>         ylab = "Relative error between x and as.numeric(as.character(x))")
>>rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) # fine
>>rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing breaks down
>>
>>Of course, [0,.Machine$double.xmin] is somewhat of a strange set of numbers to consider,
>>and I expect things like "==" to be easily fooled there, but already the print method (?)
>>
>>Thanks & cheers,
>>Marius
>>
>>sessionInfo()
>>R version 4.1.2 (2021-11-01)
>>Platform: x86_64-apple-darwin21.2.0 (64-bit)
>>Running under: macOS Monterey 12.1
>>...
>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From @kw@|mmo @end|ng |rom gm@||@com  Fri Feb 18 01:04:53 2022
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 17 Feb 2022 19:04:53 -0500
Subject: [R] Why does the print method fail for very small numbers?
In-Reply-To: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
References: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAPcHnpSrTcpEWJZjyfhY0n+1F8hz5_j=WRAQOBE8SC4_jVH6jg@mail.gmail.com>

It should also be noted that format(x, digits = 17) instead of
as.character(x) won't lose any accuracy.

On Thu, Feb 17, 2022, 17:41 Marius Hofert <marius.hofert at uwaterloo.ca>
wrote:

> Dear expeRts,
>
> I'm familiar with IEEE 754. Is there an easy way to explain why even
> just printing of small numbers fails?
>
> 1e-317 # 1e-317 => fine
> 1e-318 # 9.999987e-319 => gets tricky; seems to call print() =>
> as.character() => format() => paste()
> 1e-318 == 9.999987e-319 # TRUE
> 2.48e-324 # prints 4.940656e-324 for me
> 2.48e-324 == 4.940656e-324 # TRUE
> ## Relative error as a plot
> rel_error <- function(x)
>     plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
>          ylab = "Relative error between x and as.numeric(as.character(x))")
> rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) #
> fine
> rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing
> breaks down
>
> Of course, [0,.Machine$double.xmin] is somewhat of a strange set of
> numbers to consider,
> and I expect things like "==" to be easily fooled there, but already the
> print method (?)
>
> Thanks & cheers,
> Marius
>
> sessionInfo()
> R version 4.1.2 (2021-11-01)
> Platform: x86_64-apple-darwin21.2.0 (64-bit)
> Running under: macOS Monterey 12.1
> ...
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 18 01:27:25 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Feb 2022 16:27:25 -0800
Subject: [R] Why does the print method fail for very small numbers?
In-Reply-To: <CAPcHnpSrTcpEWJZjyfhY0n+1F8hz5_j=WRAQOBE8SC4_jVH6jg@mail.gmail.com>
References: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
 <CAPcHnpSrTcpEWJZjyfhY0n+1F8hz5_j=WRAQOBE8SC4_jVH6jg@mail.gmail.com>
Message-ID: <43E87D85-41DD-4F83-AF19-0C21145FD878@dcn.davis.ca.us>

In this case, that is too little too late. See the other messages in this thread.

On February 17, 2022 4:04:53 PM PST, Andrew Simmons <akwsimmo at gmail.com> wrote:
>It should also be noted that format(x, digits = 17) instead of
>as.character(x) won't lose any accuracy.
>
>On Thu, Feb 17, 2022, 17:41 Marius Hofert <marius.hofert at uwaterloo.ca>
>wrote:
>
>> Dear expeRts,
>>
>> I'm familiar with IEEE 754. Is there an easy way to explain why even
>> just printing of small numbers fails?
>>
>> 1e-317 # 1e-317 => fine
>> 1e-318 # 9.999987e-319 => gets tricky; seems to call print() =>
>> as.character() => format() => paste()
>> 1e-318 == 9.999987e-319 # TRUE
>> 2.48e-324 # prints 4.940656e-324 for me
>> 2.48e-324 == 4.940656e-324 # TRUE
>> ## Relative error as a plot
>> rel_error <- function(x)
>>     plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
>>          ylab = "Relative error between x and as.numeric(as.character(x))")
>> rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) #
>> fine
>> rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing
>> breaks down
>>
>> Of course, [0,.Machine$double.xmin] is somewhat of a strange set of
>> numbers to consider,
>> and I expect things like "==" to be easily fooled there, but already the
>> print method (?)
>>
>> Thanks & cheers,
>> Marius
>>
>> sessionInfo()
>> R version 4.1.2 (2021-11-01)
>> Platform: x86_64-apple-darwin21.2.0 (64-bit)
>> Running under: macOS Monterey 12.1
>> ...
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Fri Feb 18 09:29:24 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Fri, 18 Feb 2022 09:29:24 +0100
Subject: [R] Problem with data distribution
In-Reply-To: <BN6PR2201MB15532242F13A1C5811C1EC12CF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CA+nrPnuxztEuH5+0PBCi=1-nNB3-es48RmXh3TBT_1KRZqNJnw@mail.gmail.com>
 <BN6PR2201MB155377DC0229AA28B372765FCF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CA+nrPnvf9700BO7nn7cP-d6sB96dTxegbQrfJO51jxf1d=HAng@mail.gmail.com>
 <a4ad4ab3-a30e-efda-6085-99dac5a298c7@sapo.pt>
 <CA+nrPnuqEswN_cFpJ6Nvi+7G4Zn3rhTdNdNRd3izvP5_aTN1_g@mail.gmail.com>
 <CAGxFJbTZ0U1cJR2R_N2SKAmqwJoapSgjPP5VkF4sRaZVumwndA@mail.gmail.com>
 <CA+nrPnuh29AMfjtcJgBhURUFx9vO1TTdfMOS-jBbNQUEFf8NDw@mail.gmail.com>
 <BN6PR2201MB15532242F13A1C5811C1EC12CF369@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CA+nrPnt-csWjGbb1tCbtZmR8pJKUyDoJ+cnQfO_0UYySoWS7WQ@mail.gmail.com>

Yes Elbert, but how to report details like,
What is the probability of having one or more bugs?

Can we do it?


On Thursday, February 17, 2022, Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> Maybe what you want is to recode your data differently.
> One data set has bug versus no bug. What is the probability of having one
> or more bugs?
> The other data set has bugs only. Given that I have bugs how many will I
> get?
>
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha gupta
> Sent: Thursday, February 17, 2022 4:54 PM
> To: Bert Gunter <bgunter.4567 at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Problem with data distribution
>
> [External Email]
>
> :) :)
>
> On Thu, Feb 17, 2022 at 10:37 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
> > imo, with such simple data, a plot is mere chartjunk. A simple table(=
> > the distribution) would suffice and be more informative:
> >
> > > table(bug) ## bug is a vector. No data frame is needed
> >
> >   0   1     2    3   4   5   7   ## bug count
> > 162  40   9   7   2   1   1   ## nmbr of cases with the given count
> >
> > You or others may disagree, of course.
> >
> > Bert Gunter
> >
> >
> >
> > On Thu, Feb 17, 2022 at 11:56 AM Neha gupta <neha.bologna90 at gmail.com>
> > wrote:
> > >
> > > Ebert and Rui, thank you for providing the tips (in fact, for
> > > providing
> > the
> > > answer I needed).
> > >
> > > Yes, you are right that boxplot of all zero values will not make sense.
> > > Maybe histogram will work.
> > >
> > > I am providing a few details of my data here and the context of the
> > > question I asked.
> > >
> > > My data is about bugs/defects in different classes of a large
> > > software system. I have to predict which class will contain bugs and
> > > which will be free of bugs (bug=0). I trained ML models and predict
> > > but my advisor
> > asked
> > > me to provide first the data distribution about bugs e.g details of
> > > how many classes with bugs (bug > 0) and how many are free of bugs
> (bug=0).
> > >
> > > That is why I need to provide the data distribution of both types of
> > values
> > > (i.e. bug=0 and bug >0)
> > >
> > > Thank you again.
> > >
> > > On Thu, Feb 17, 2022 at 8:28 PM Rui Barradas <ruipbarradas at sapo.pt>
> > wrote:
> > >
> > > > Hello,
> > > >
> > > > In your original post you read the same file "synapse.arff" twice,
> > > > apparently to filter each of them by its own criterion. You don't
> > > > need to do that, read once and filter that one by different criteria.
> > > >
> > > > As for the data as posted, I have read it in with the following code:
> > > >
> > > >
> > > > x <- "
> > > > 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0 0
> > > > 0 0 0
> > > > 4 1 0
> > > > 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0 0 0 1 1 1
> > > > 0 0 0
> > > > 0 0 0
> > > > 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 5 0 0 0 0
> > > > 0 0 7
> > > > 0 0 1
> > > > 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1 0 0 0 0
> > > > 0 0 0
> > > > 1 0 0
> > > > 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0 1 0 4 1
> > > > 1 0 0
> > > > 0 0 1
> > > > 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0 "
> > > > bug <- scan(text = x)
> > > > data <- data.frame(bug)
> > > >
> > > >
> > > > This is not the right way to post data, the posting guide asks to
> > > > post the output of
> > > >
> > > >
> > > > dput(data)
> > > > structure(list(bug = c(0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0,
> > > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,
> > > > 4, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0,
> > > > 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,
> > > > 2, 1, 0, 1, 0, 0, 0, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,
> > > > 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 1, 0, 1, 1, 0, 2, 0, 3,
> > > > 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 3, 2, 1, 1,
> > > > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,
> > > > 0, 0, 3, 0, 0, 1, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 1, 1,
> > > > 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > > 0, 0, 3, 0, 1, 0, 0, 0, 0, 0)), class = "data.frame", row.names =
> > > > c(NA, -222L))
> > > >
> > > >
> > > >
> > > > This can be copied into an R session and the data set recreated
> > > > with
> > > >
> > > > data <- structure(etc)
> > > >
> > > >
> > > > Now the boxplots.
> > > >
> > > > (Why would you want to plot a vector of all zeros, btw?)
> > > >
> > > >
> > > >
> > > > library(dplyr)
> > > >
> > > > boxplot(filter(data, bug == 0))    # nonsense
> > > > boxplot(filter(data, bug > 0), range = 0)
> > > >
> > > > # Another way
> > > > data %>%
> > > >    filter(bug > 0) %>%
> > > >    boxplot(range = 0)
> > > >
> > > >
> > > > Hope this helps,
> > > >
> > > > Rui Barradas
> > > >
> > > >
> > > > ?s 19:03 de 17/02/2022, Neha gupta escreveu:
> > > > > That is all the code I have. How can I provide a  reproducible
> code ?
> > > > >
> > > > > How can I save this result?
> > > > >
> > > > > On Thu, Feb 17, 2022 at 8:00 PM Ebert,Timothy Aaron
> > > > > <tebert at ufl.edu>
> > > > wrote:
> > > > >
> > > > >> You pipe the filter but do not save the result. A reproducible
> > example
> > > > >> might help.
> > > > >> Tim
> > > > >>
> > > > >> -----Original Message-----
> > > > >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Neha
> > > > >> gupta
> > > > >> Sent: Thursday, February 17, 2022 1:55 PM
> > > > >> To: r-help mailing list <r-help at r-project.org>
> > > > >> Subject: [R] Problem with data distribution
> > > > >>
> > > > >> [External Email]
> > > > >>
> > > > >> Hello everyone
> > > > >>
> > > > >> I have a dataset with output variable "bug" having the
> > > > >> following
> > values
> > > > >> (at the bottom of this email). My advisor asked me to provide
> > > > >> data distribution of bugs with 0 values and bugs with more than 0
> values.
> > > > >>
> > > > >> data = readARFF("synapse.arff")
> > > > >> data2 = readARFF("synapse.arff") data$bug
> > > > >> library(tidyverse)
> > > > >> data %>%
> > > > >>    filter(bug == 0)
> > > > >> data2 %>%
> > > > >>    filter(bug >= 1)
> > > > >> boxplot(data2$bug, data$bug, range=0)
> > > > >>
> > > > >> But both the graphs are exactly the same, how is it possible?
> > > > >> Where
> > I am
> > > > >> doing wrong?
> > > > >>
> > > > >>
> > > > >> data$bug
> > > > >>    [1] 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0
> > > > >> 0 1
> > 0 0
> > > > 0 0 0
> > > > >> 0 4 1 0
> > > > >>   [40] 0 1 0 0 0 0 0 0 1 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 1 0 0
> > > > >> 0 0
> > 1 1
> > > > 1 0 0
> > > > >> 0 0 0 0
> > > > >>   [79] 1 1 2 1 0 1 0 0 0 2 2 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0
> > > > >> 5 0
> > 0 0
> > > > 0 0 0
> > > > >> 7 0 0 1
> > > > >> [118] 0 1 1 0 2 0 3 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 3 2 1 1
> > > > >> 0 0
> > 0 0
> > > > 0 0
> > > > >> 0 1 0 0
> > > > >> [157] 0 0 0 0 0 0 0 0 0 1 0 1 0 0 3 0 0 1 0 1 3 0 0 0 0 0 0 0 0
> > > > >> 1 0
> > 4 1
> > > > 1 0
> > > > >> 0 0 0 1
> > > > >> [196] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0
> > > > >>
> > > > >>          [[alternative HTML version deleted]]
> > > > >>
> > > > >> ______________________________________________
> > > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > >> see
> > > > >>
> > > >
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> > man_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> > Rzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR8
> > YIVfiod&s=NxfkBJHBnd8naYPQTd9Z8dZ2m-RCwh_lpGvHVQ8MwYQ&e=
> > > > >> PLEASE do read the posting guide
> > > > >>
> > > >
> > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> > g_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> > sRzsn7AkP-g&m=TZx8pDTF9x1Tu4QZW3x_99uu9RowVjAna39KcjCXSElI1AOk1C_6L2pR
> > 8YIVfiod&s=exznSElUW1tc6ajt0C8uw5cR8ZqwHRD6tUPAarFYdYo&e=
> > > > >> and provide commented, minimal, self-contained, reproducible code.
> > > > >>
> > > > >
> > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see
> > > > > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.c
> > > > > h_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=
> > > > > 9PEhQh2kVeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgM
> > > > > CpncRRH1bjKjIUqHjMj8vHCeH&s=53w0MvIpfAklRelSPE5abL_5YG-wyIrrXiFa
> > > > > oqbAfLo&e= PLEASE do read the posting guide
> > > > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dprojec
> > > > t.org_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PE
> > > > hQh2kVeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncR
> > > > RH1bjKjIUqHjMj8vHCeH&s=MBVLtPJJyplOC4i8e5ZupFYAXaiICGuK6qsIzxnCEP4
> > > > &e=
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
> > > ilman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2k
> > > VeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncRRH1bjKj
> > > IUqHjMj8vHCeH&s=53w0MvIpfAklRelSPE5abL_5YG-wyIrrXiFaoqbAfLo&e=
> > > PLEASE do read the posting guide
> > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> > g_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> > sRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncRRH1bjKjIUqHj
> > Mj8vHCeH&s=MBVLtPJJyplOC4i8e5ZupFYAXaiICGuK6qsIzxnCEP4&e=
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.
> ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=
> 9PEhQh2kVeAsRzsn7AkP-g&m=3hWViXJSTXDpoNVYXho6Boeq6QUtot
> K37L0ChgMCpncRRH1bjKjIUqHjMj8vHCeH&s=53w0MvIpfAklRelSPE5abL_
> 5YG-wyIrrXiFaoqbAfLo&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.
> com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.
> html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=
> 3hWViXJSTXDpoNVYXho6Boeq6QUtotK37L0ChgMCpncRRH1bjKjIUqHjMj8vHCeH&s=
> MBVLtPJJyplOC4i8e5ZupFYAXaiICGuK6qsIzxnCEP4&e=
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Feb 18 10:15:37 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 18 Feb 2022 09:15:37 +0000
Subject: [R] Why does the print method fail for very small numbers?
In-Reply-To: <CAPcHnpSrTcpEWJZjyfhY0n+1F8hz5_j=WRAQOBE8SC4_jVH6jg@mail.gmail.com>
References: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
 <CAPcHnpSrTcpEWJZjyfhY0n+1F8hz5_j=WRAQOBE8SC4_jVH6jg@mail.gmail.com>
Message-ID: <4ec8dc52-6be2-678e-9fb6-8e18091ab93a@sapo.pt>

Hello,

It doesn't lose accuracy?


print(2.48e-324)
#[1] 4.940656e-324
as.character(2.48e-324)
#[1] "4.94065645841247e-324"

format(2.48e-324, digits = 17)
#[1] "4.9406564584124654e-324"


Those are the same loss of accuracy errors.

Hope this helps,

Rui Barradas


?s 00:04 de 18/02/2022, Andrew Simmons escreveu:
> It should also be noted that format(x, digits = 17) instead of
> as.character(x) won't lose any accuracy.
> 
> On Thu, Feb 17, 2022, 17:41 Marius Hofert <marius.hofert at uwaterloo.ca>
> wrote:
> 
>> Dear expeRts,
>>
>> I'm familiar with IEEE 754. Is there an easy way to explain why even
>> just printing of small numbers fails?
>>
>> 1e-317 # 1e-317 => fine
>> 1e-318 # 9.999987e-319 => gets tricky; seems to call print() =>
>> as.character() => format() => paste()
>> 1e-318 == 9.999987e-319 # TRUE
>> 2.48e-324 # prints 4.940656e-324 for me
>> 2.48e-324 == 4.940656e-324 # TRUE
>> ## Relative error as a plot
>> rel_error <- function(x)
>>      plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
>>           ylab = "Relative error between x and as.numeric(as.character(x))")
>> rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) #
>> fine
>> rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing
>> breaks down
>>
>> Of course, [0,.Machine$double.xmin] is somewhat of a strange set of
>> numbers to consider,
>> and I expect things like "==" to be easily fooled there, but already the
>> print method (?)
>>
>> Thanks & cheers,
>> Marius
>>
>> sessionInfo()
>> R version 4.1.2 (2021-11-01)
>> Platform: x86_64-apple-darwin21.2.0 (64-bit)
>> Running under: macOS Monterey 12.1
>> ...
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Fri Feb 18 11:33:11 2022
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 18 Feb 2022 11:33:11 +0100
Subject: [R] [Rd] R 4.1.3 scheduled for March 10
In-Reply-To: <7BC92570-396C-47AD-A035-6558E1FEEAC0@gmail.com>
References: <7BC92570-396C-47AD-A035-6558E1FEEAC0@gmail.com>
Message-ID: <A66F6B8E-DDFD-4220-B281-571B8FE0B705@gmail.com>

Schedule will appear on developer.r-project.org when it gets updated from SVN.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Fri Feb 18 11:45:36 2022
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Fri, 18 Feb 2022 10:45:36 +0000 (UTC)
Subject: [R] Exact 95% CIs around the mean for Weibull distribution
In-Reply-To: <CAGgJW76FaCtsjD5LskYbZ_iodSZWRx5c7ApCbfLCoqDbga85FQ@mail.gmail.com>
References: <1387483335.1628933.1644749062688.ref@mail.yahoo.com>
 <1387483335.1628933.1644749062688@mail.yahoo.com>
 <CAGgJW76FaCtsjD5LskYbZ_iodSZWRx5c7ApCbfLCoqDbga85FQ@mail.gmail.com>
Message-ID: <2058584672.4620356.1645181136349@mail.yahoo.com>

Dear R-experts,

With weibulltools we can only compute the CI for the median. 

Best,



?






Le dimanche 13 f?vrier 2022, 12:11:09 UTC+1, Eric Berger <ericjberger at gmail.com> a ?crit : 





I did a Google search on "R confidence interval for Weibull
distribution parameters"
and there were several packages that appear to provide that
information. Have you tried any of them?


On Sun, Feb 13, 2022 at 12:44 PM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> Here below my R code. I am trying to get the exact 95% confidence intervals around the meanlog for lognormal, around the mean for gamma and around the mean for weibull distributions. For lognormal and gamma everything is working but for weibull, I get error messages. After having used the ??eweibull function, I am not sure I can get the 95% CIs around the mean. Is there a way to get the exact 95% CIs around the mean for the weibull distribution ?
>
> ##########################
> #Exact 95% CIs for the mean lognormal distribution
> library(EnvStats)
>
> x=rlnorm(100000,0,1)
> elnorm(x,method="mvue",ci=TRUE,ci.type="two-sided",ci.method="exact",conf.level=0.95)
>
> #Exact 95% CIs for the mean gamma distribution
> library(EnvStats)
>
> x=rgamma(n=100000,shape=2,rate=5)
> egamma(x,method="mle",ci=TRUE,ci.type="two-sided",conf.level=0.95)
>
>
> #Exact 95% CIs for the mean weibull distribution
> library(EnvStats)
>
> x=rweibull(100000,2,2)
> eweibull(x,method="mle",ci=TRUE,ci.type="two-sided",conf.level=0.95)

>
> ##########################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ||@| @end|ng |rom m@||@n|h@gov  Fri Feb 18 19:32:00 2022
From: ||@| @end|ng |rom m@||@n|h@gov (Li, Aiguo (NIH/NCI) [E])
Date: Fri, 18 Feb 2022 18:32:00 +0000
Subject: [R] A question of data frame filter based on another one
Message-ID: <94E5D134-AC3C-4A5C-ABD4-9A82F49C8931@nih.gov>

I have tow dataframes as below:
> x
  id  g
1  1 21
2  3 52
3  2 43
4  4 94
5  5 35

> y
  id g
1  1 1
2  0 0
3  0 1
4  1 0
5  1 0

Results dataframe I want is:
1 21
2 43
4 94
5 35

Basically I want to extract all the values in x which corresponding those values =1 in y.

I tried:
x[which(y==1),].  It gets:
id  g
1     1 21
4     4 94
5     5 35
NA   NA NA
NA.1 NA NA

But missing the row: 2 43.

Any help will be appreciated.

Thanks,
Aiguo

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Feb 18 21:30:22 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 18 Feb 2022 20:30:22 +0000
Subject: [R] A question of data frame filter based on another one
In-Reply-To: <94E5D134-AC3C-4A5C-ABD4-9A82F49C8931@nih.gov>
References: <94E5D134-AC3C-4A5C-ABD4-9A82F49C8931@nih.gov>
Message-ID: <1705bafa-d017-ddb4-df52-bea944d1ee79@sapo.pt>

Hello,

Use ?rowSums and compare its result to 0. You want the sums greater than 
zero.


x <- "
   id  g
1  1 21
2  3 52
3  2 43
4  4 94
5  5 35"
y <- "
id g
1  1 1
2  0 0
3  0 1
4  1 0
5  1 0"

x <- read.table(textConnection(x), header = TRUE)
y <- read.table(textConnection(y), header = TRUE)

x[rowSums(x) > 0L, ]
#  id  g
#1  1 21
#2  3 52
#3  2 43
#4  4 94
#5  5 35


Hope this helps,

Rui Barradas

?s 18:32 de 18/02/2022, Li, Aiguo (NIH/NCI) [E] via R-help escreveu:
> I have tow dataframes as below:
>> x
>    id  g
> 1  1 21
> 2  3 52
> 3  2 43
> 4  4 94
> 5  5 35
> 
>> y
>    id g
> 1  1 1
> 2  0 0
> 3  0 1
> 4  1 0
> 5  1 0
> 
> Results dataframe I want is:
> 1 21
> 2 43
> 4 94
> 5 35
> 
> Basically I want to extract all the values in x which corresponding those values =1 in y.
> 
> I tried:
> x[which(y==1),].  It gets:
> id  g
> 1     1 21
> 4     4 94
> 5     5 35
> NA   NA NA
> NA.1 NA NA
> 
> But missing the row: 2 43.
> 
> Any help will be appreciated.
> 
> Thanks,
> Aiguo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Fri Feb 18 21:35:01 2022
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 18 Feb 2022 22:35:01 +0200
Subject: [R] A question of data frame filter based on another one
In-Reply-To: <94E5D134-AC3C-4A5C-ABD4-9A82F49C8931@nih.gov>
References: <94E5D134-AC3C-4A5C-ABD4-9A82F49C8931@nih.gov>
Message-ID: <CAGgJW76j7ifG0nb=D4nFDo7HpuGVicZ7B1ndNZkp76EuCZkXtg@mail.gmail.com>

x[apply(y,MAR=1,sum) > 0,]


On Fri, Feb 18, 2022 at 10:24 PM Li, Aiguo (NIH/NCI) [E] via R-help <
r-help at r-project.org> wrote:

> I have tow dataframes as below:
> > x
>   id  g
> 1  1 21
> 2  3 52
> 3  2 43
> 4  4 94
> 5  5 35
>
> > y
>   id g
> 1  1 1
> 2  0 0
> 3  0 1
> 4  1 0
> 5  1 0
>
> Results dataframe I want is:
> 1 21
> 2 43
> 4 94
> 5 35
>
> Basically I want to extract all the values in x which corresponding those
> values =1 in y.
>
> I tried:
> x[which(y==1),].  It gets:
> id  g
> 1     1 21
> 4     4 94
> 5     5 35
> NA   NA NA
> NA.1 NA NA
>
> But missing the row: 2 43.
>
> Any help will be appreciated.
>
> Thanks,
> Aiguo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@| @end|ng |rom m@||@n|h@gov  Fri Feb 18 21:52:42 2022
From: ||@| @end|ng |rom m@||@n|h@gov (Li, Aiguo (NIH/NCI) [E])
Date: Fri, 18 Feb 2022 20:52:42 +0000
Subject: [R] 
 [EXTERNAL] Re: A question of data frame filter based on another one
In-Reply-To: <CAGgJW76j7ifG0nb=D4nFDo7HpuGVicZ7B1ndNZkp76EuCZkXtg@mail.gmail.com>
References: <94E5D134-AC3C-4A5C-ABD4-9A82F49C8931@nih.gov>
 <CAGgJW76j7ifG0nb=D4nFDo7HpuGVicZ7B1ndNZkp76EuCZkXtg@mail.gmail.com>
Message-ID: <7E990732-23F7-41CD-9DC5-8FF738330642@nih.gov>

Hi Eric,

Thanks for your quick response.  It works.

Have a nice weekend!

Aiguo

From: Eric Berger <ericjberger at gmail.com>
Date: Friday, February 18, 2022 at 3:35 PM
To: "Li, Aiguo (NIH/NCI) [E]" <liai at mail.nih.gov>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: [EXTERNAL] Re: [R] A question of data frame filter based on another one

CAUTION: This email originated from outside of the organization. Do not click links or open attachments unless you recognize the sender and are confident the content is safe.

x[apply(y,MAR=1,sum) > 0,]


On Fri, Feb 18, 2022 at 10:24 PM Li, Aiguo (NIH/NCI) [E] via R-help <r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
I have tow dataframes as below:
> x
  id  g
1  1 21
2  3 52
3  2 43
4  4 94
5  5 35

> y
  id g
1  1 1
2  0 0
3  0 1
4  1 0
5  1 0

Results dataframe I want is:
1 21
2 43
4 94
5 35

Basically I want to extract all the values in x which corresponding those values =1 in y.

I tried:
x[which(y==1),].  It gets:
id  g
1     1 21
4     4 94
5     5 35
NA   NA NA
NA.1 NA NA

But missing the row: 2 43.

Any help will be appreciated.

Thanks,
Aiguo

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Feb 19 00:38:25 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 18 Feb 2022 23:38:25 +0000
Subject: [R] A question of data frame filter based on another one
In-Reply-To: <1705bafa-d017-ddb4-df52-bea944d1ee79@sapo.pt>
References: <94E5D134-AC3C-4A5C-ABD4-9A82F49C8931@nih.gov>
 <1705bafa-d017-ddb4-df52-bea944d1ee79@sapo.pt>
Message-ID: <4d6bd679-bd13-5b07-af21-734d22808255@sapo.pt>

Hello,

Sorry, typo. It's rowSums(y), not x.

x[rowSums(y) > 0L, ]

Rui Barradas

?s 20:30 de 18/02/2022, Rui Barradas escreveu:
> Hello,
> 
> Use ?rowSums and compare its result to 0. You want the sums greater than 
> zero.
> 
> 
> x <- "
>  ? id? g
> 1? 1 21
> 2? 3 52
> 3? 2 43
> 4? 4 94
> 5? 5 35"
> y <- "
> id g
> 1? 1 1
> 2? 0 0
> 3? 0 1
> 4? 1 0
> 5? 1 0"
> 
> x <- read.table(textConnection(x), header = TRUE)
> y <- read.table(textConnection(y), header = TRUE)
> 
> x[rowSums(x) > 0L, ]
> #? id? g
> #1? 1 21
> #2? 3 52
> #3? 2 43
> #4? 4 94
> #5? 5 35
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 18:32 de 18/02/2022, Li, Aiguo (NIH/NCI) [E] via R-help escreveu:
>> I have tow dataframes as below:
>>> x
>> ?? id? g
>> 1? 1 21
>> 2? 3 52
>> 3? 2 43
>> 4? 4 94
>> 5? 5 35
>>
>>> y
>> ?? id g
>> 1? 1 1
>> 2? 0 0
>> 3? 0 1
>> 4? 1 0
>> 5? 1 0
>>
>> Results dataframe I want is:
>> 1 21
>> 2 43
>> 4 94
>> 5 35
>>
>> Basically I want to extract all the values in x which corresponding 
>> those values =1 in y.
>>
>> I tried:
>> x[which(y==1),].? It gets:
>> id? g
>> 1???? 1 21
>> 4???? 4 94
>> 5???? 5 35
>> NA?? NA NA
>> NA.1 NA NA
>>
>> But missing the row: 2 43.
>>
>> Any help will be appreciated.
>>
>> Thanks,
>> Aiguo
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Sat Feb 19 10:54:13 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 19 Feb 2022 22:54:13 +1300
Subject: [R] Why does the print method fail for very small numbers?
In-Reply-To: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
References: <YQXPR01MB6464BBC1C2D6CA826D93959287369@YQXPR01MB6464.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CABcYAdJxqk6sMKJd5acEepzQs2g7KsXCTt4vTjmK5bSwzaX96g@mail.gmail.com>

You say that you already understand IEEE floating point
arithmetic, but you have placed the problem at the wrong
end.  The problem is at the INPUT end.  The smallest
number that can be represented in IEEE double format
is 4.940656458412465d-324
but you asked for 2.48e-324.
The two representable numbers closest to that are
+0.0 and 4.94...e-324.  Of those, 4.94...e-324 is
a little bit closer.  So 4.94...e-324 was THE BEST
ANSWER YOU COULD POSSIBLY GET.

The number having been rounded up to the nearest
representable number, that representable number was
printed pretty darned well.  So:
- you have NOT found an error in printing
- you have NOT found an error in comparison
- you HAVE found that rounding in the range of
  denormalised numbers is pretty harsh.

One more time: the print function DID NOT FAIL
for tiny numbers.  It printed what you gave it
and printed it well.  The problem was at the
INPUT end.

On Fri, 18 Feb 2022 at 11:41, Marius Hofert <marius.hofert at uwaterloo.ca>
wrote:

> Dear expeRts,
>
> I'm familiar with IEEE 754. Is there an easy way to explain why even
> just printing of small numbers fails?
>
> 1e-317 # 1e-317 => fine
> 1e-318 # 9.999987e-319 => gets tricky; seems to call print() =>
> as.character() => format() => paste()
> 1e-318 == 9.999987e-319 # TRUE
> 2.48e-324 # prints 4.940656e-324 for me
> 2.48e-324 == 4.940656e-324 # TRUE
> ## Relative error as a plot
> rel_error <- function(x)
>     plot(abs((as.numeric(as.character(x)) - x) / x), type = "l",
>          ylab = "Relative error between x and as.numeric(as.character(x))")
> rel_error(seq(0.001, 0.001 + .Machine$double.xmin, length.out = 1001)) #
> fine
> rel_error(seq(0, .Machine$double.xmin, length.out = 1001)) # printing
> breaks down
>
> Of course, [0,.Machine$double.xmin] is somewhat of a strange set of
> numbers to consider,
> and I expect things like "==" to be easily fooled there, but already the
> print method (?)
>
> Thanks & cheers,
> Marius
>
> sessionInfo()
> R version 4.1.2 (2021-11-01)
> Platform: x86_64-apple-darwin21.2.0 (64-bit)
> Running under: macOS Monterey 12.1
> ...
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@zh@o @end|ng |rom ye@h@net  Sat Feb 19 13:46:45 2022
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Sat, 19 Feb 2022 20:46:45 +0800
Subject: [R] x-axis in interaction plot is weird
Message-ID: <23e9f894-4978-30ab-c15d-d6130aec12fd@yeah.net>

Hi there,

When `xtick = TRUE`, the x-axis in interaction plot is weird:

with(ToothGrowth, {interaction.plot(dose, supp, len, xtick = TRUE)})

you may notice that the x-axis is position at line 1, and the labels at 
line 2.

And when set

par(mgp = c(-4, -2, -1))

The x-axis is also positioned at line 1, but the labels at line -1.

When `xtick = FALSE`, according the source code of interaction.plot(), 
the mgp[2] set to 0, however, the labels is also at line 1 instead of 
line 0.

I don't know whether those behaviors were designed.

Best,
Jinsong

PS:
 > sessionInfo()
R version 4.1.2 (2021-11-01)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19044)

Matrix products: default

locale:
[1] LC_COLLATE=Chinese (Simplified)_China.936
[2] LC_CTYPE=Chinese (Simplified)_China.936
[3] LC_MONETARY=Chinese (Simplified)_China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_China.936

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.1.2 tools_4.1.2


From he|mut@@chuetz @end|ng |rom beb@c@@t  Sat Feb 19 16:00:39 2022
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Sat, 19 Feb 2022 16:00:39 +0100
Subject: [R] Why does the print method fail for very small numbers?
In-Reply-To: <mailman.365853.1.1645268401.59606.r-help@r-project.org>
References: <mailman.365853.1.1645268401.59606.r-help@r-project.org>
Message-ID: <db4b5e24-4629-cdb7-5a6c-a63a53f608e7@bebac.at>

Hi Marius,

as others already noted, you request something which is beyond the 
numeric resolution.
That's also elaborated in the famous FAQ 7.31 
(https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f).
As you know - according to IEEE 754 a binary in double precision holds 
64 bits (where 1 bit is the sign, 11 the exponent, and 52 the mantissa). 
That translates into ~15.7 digits decimal. Hence, the 16th digit is noise.

IMHO, print(foo, digits = bar) should provide the result but 
additionally throw for any bar > 15 a message like
"From the hard-/software to the wetware: We cannot provide what you were 
asking for."

Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
W https://bebac.at/
F https://forum.bebac.at/


From d@go@t|no|@b| @end|ng |rom gm@||@com  Sat Feb 19 16:38:03 2022
From: d@go@t|no|@b| @end|ng |rom gm@||@com (Fabio D'Agostino)
Date: Sat, 19 Feb 2022 16:38:03 +0100
Subject: [R] '[' vs subset() behaviors when filtering a dataframe with NA
 values
Message-ID: <CADUGNTwD_po4q+wuVXGd_YKxjhq8TjVeTHoObAa+-YH-DZT7uw@mail.gmail.com>

Hi All,
I just have two questions since I did not understand the behavior of
'['  vs the  subset() function when filtering a dataframe that has NA
values

I was filtering a dataframe named 'weight' according to values of the
column named 'weight_rec' ...
str(weight)
'data.frame': 17307 obs. of  6 variables:
 $ ICUSTAY_ID: num  229904 229904 229904 247844 247844 ...
 $ INTIME    : chr  "2127-08-11 20:43:43 UTC" "2127-08-11 20:43:43
UTC" "2127-08-11 20:43:43 UTC" "2179-09-29 18:46:50 UTC" ...
 $ ITEMID    : num  224639 224639 226512 762 762 ...
 $ VALUENUM  : num  61 59.2 59.8 86 86 86 85.5 93 128 128 ...
 $ CHARTTIME : chr  "2127-08-14 08:00:00 UTC" "2127-08-13 08:00:00
UTC" "2127-08-11 21:01:00 UTC" "2179-10-02 19:39:00 UTC" ...
 $ weight_rec: num  51.3 27.3 -20.7 53.2 -18.8 ...

... using the following script:
weight[weight$weight_rec <= 24 & weight$weight_rec >= 0, ]   #I get an
output of 1055 rows

while using:
subset(weight, weight$weight_rec <= 24 & weight$weight_rec >= 0)   #I
get an output of 1040 rows

analyzing the values in the column 'weight_rec' I found that
sum(is.na(weight$weight_rec))
[1] 15   #15 values are NA

My two questions are:
1) Why are NA values considered when using '[' ? I only filtered for a
condition of numeric values (i.e., >=0 & <=24)... and subset() did
what I expected.
2) Why are all the values of the columns of that 15 rows equal to NA
and not only the values of the column named 'weight_rec'?

Thanks in advance for clarifying this!
Fabio


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Feb 20 05:06:36 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 19 Feb 2022 20:06:36 -0800
Subject: [R] 
 '[' vs subset() behaviors when filtering a dataframe with NA values
In-Reply-To: <CADUGNTwD_po4q+wuVXGd_YKxjhq8TjVeTHoObAa+-YH-DZT7uw@mail.gmail.com>
References: <CADUGNTwD_po4q+wuVXGd_YKxjhq8TjVeTHoObAa+-YH-DZT7uw@mail.gmail.com>
Message-ID: <A1D40C0E-DE59-4E61-BA8E-E1A45B37B636@dcn.davis.ca.us>

That is how logical indexing works... an NA index returns an NA element. Integer indexing is the same, but the which function returns all of the index positions of TRUE values and ignores NA values as it chooses integer positions, so

weight[ which(weight$weight_rec <= 24 & weight$weight_rec >= 0), ]

will skip the NAs.

BTW: the subset function works best when you let it lookup data in the data frame:

subset(weight, weight_rec <= 24 & weight_rec >= 0)

You can introduce obscure bugs (your logic, not bugs in R) by directly specifying which data frame to look in when using non-standard evaluation functions like subset, with, and within.

On February 19, 2022 7:38:03 AM PST, Fabio D'Agostino <dagostinofabi at gmail.com> wrote:
>Hi All,
>I just have two questions since I did not understand the behavior of
>'['  vs the  subset() function when filtering a dataframe that has NA
>values
>
>I was filtering a dataframe named 'weight' according to values of the
>column named 'weight_rec' ...
>str(weight)
>'data.frame': 17307 obs. of  6 variables:
> $ ICUSTAY_ID: num  229904 229904 229904 247844 247844 ...
> $ INTIME    : chr  "2127-08-11 20:43:43 UTC" "2127-08-11 20:43:43
>UTC" "2127-08-11 20:43:43 UTC" "2179-09-29 18:46:50 UTC" ...
> $ ITEMID    : num  224639 224639 226512 762 762 ...
> $ VALUENUM  : num  61 59.2 59.8 86 86 86 85.5 93 128 128 ...
> $ CHARTTIME : chr  "2127-08-14 08:00:00 UTC" "2127-08-13 08:00:00
>UTC" "2127-08-11 21:01:00 UTC" "2179-10-02 19:39:00 UTC" ...
> $ weight_rec: num  51.3 27.3 -20.7 53.2 -18.8 ...
>
>... using the following script:
>weight[weight$weight_rec <= 24 & weight$weight_rec >= 0, ]   #I get an
>output of 1055 rows
>
>while using:
>subset(weight, weight$weight_rec <= 24 & weight$weight_rec >= 0)   #I
>get an output of 1040 rows
>
>analyzing the values in the column 'weight_rec' I found that
>sum(is.na(weight$weight_rec))
>[1] 15   #15 values are NA
>
>My two questions are:
>1) Why are NA values considered when using '[' ? I only filtered for a
>condition of numeric values (i.e., >=0 & <=24)... and subset() did
>what I expected.
>2) Why are all the values of the columns of that 15 rows equal to NA
>and not only the values of the column named 'weight_rec'?
>
>Thanks in advance for clarifying this!
>Fabio
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@oknz @end|ng |rom gm@||@com  Sun Feb 20 09:38:14 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 20 Feb 2022 21:38:14 +1300
Subject: [R] SDLC methodology for R and Data science......
In-Reply-To: <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB156866BF2C8975A1554221FBC8329@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
 <CABcYAdLAm-AgkkEvgfJXTM4nag-T-AojR4ZRVe99KH+9K9uopA@mail.gmail.com>
 <PU4P216MB1568F2EA54E01A098C89FE34C8349@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CABcYAd+taCuOVL2awT=MHN8uMSVabs1gnm+PRnShWAbM95V5sw@mail.gmail.com>

Come to think of it, there's a CMU report
you can get free:
https://resources.sei.cmu.edu/asset_files/TechnicalReport/2000_005_001_13751.pdf
The books are "Introduction to the Personal
Software Process" by Watts S. Humphrey,
https://www.amazon.com/Introduction-Personal-Software-Process-Humphrey/dp/0201548097
and "PSP: A Self-Improvement Process for
Software Engineers",
https://www.amazon.com/gp/product/B001EWOG8A/ref=dbs_a_def_rwt_bibl_vppi_i0

You might like to look into using R's "testthat"
package (or some other testing framework), see
http://rstudio-pubs-static.s3.amazonaws.com/278724_4d8935a2955c49d9934e2113c737e70e.html
for an introduction.

Way back in 1982(?) when I was getting stuck on
my PhD thesis, my co-supervisor (Lawrence Byrd)
said "write an example of using your system, and
then explain how it does that."  That unstuck me,
and it was pretty much test-driven development
in a nutshell (as we put it in those days, program
by debugging the empty program).

If you're looking for whizzy tools,
- knitr (documentation, there's a good little book)
- testthat (testing)
- lintr (static checking).



On Wed, 16 Feb 2022 at 05:27, akshay kulkarni <akshay_e4 at hotmail.com> wrote:

> Dear richard,
>                       I am very grateful for your informative reply.
>
> THe fact is, I am doing a project, which is not less complex,(if not more)
> than those of Microsoft or Accenture or Google , but I am doing it all by
> myself. Can you please let me the full title of the book by Watts Humphrey?
> Or any online resources for "personal software process"? Perhaps I can get
> some tips on how to go about my project ( I've mostly taken into account
> standard methods of the state of the art, I am looking for something
> "whizzy" than aids development by one person).
>
> Thanks again,
> Yours sinecerly,
> AKSHAY M KULKARNI
> ------------------------------
> *From:* Richard O'Keefe <raoknz at gmail.com>
> *Sent:* Monday, February 14, 2022 5:23 AM
> *To:* akshay kulkarni <akshay_e4 at hotmail.com>
> *Cc:* R help Mailing list <r-help at r-project.org>
> *Subject:* Re: [R] SDLC methodology for R and Data science......
>
> There are at least two ways to use R.
> If you have devised a statistical/data science technique
> and are writing a package to be used by other people,
> that is normal software development that happens to be
> using R and the R tool.  Lots of attention to documentation
> and tests.  Test-Driven Development is one approach.
>
> Many R users aren't developing code for other people.
> They are trying to make sense of some kind of data.
> This is what used to be called "exploratory programming".
> And heavyweight development processes aren't really
> appropriate for this kind of work.  In traditional terms,
> when you are doing exploratory programming, you spend
> most of your time in the requirements phase.
>
> Perhaps the most important thing here is to keep a log
> of what you are doing and record things that didn't work,
> why they didn't work, and what you learned from it.
> When something DOES give you some insight, you want to
> be able to do it again.
>
> The tricky thing is scaling from exploration to development.
> After playing around with one data set, you might want to
> provide a script that other people can use to process
> similar data sets the same way.
> Use a light weight process, but make sure you have plenty
> of tests, and adequate documentation.
>
> Watts Humphrey developed something he called the "Personal
> Software Process" and wrote a book about it.  I don't like
> his examples for several reasons, but the point about
> watching what you do and measuring it so you can improve is
> well made.
>
>
>
> On Mon, 14 Feb 2022 at 05:33, akshay kulkarni <akshay_e4 at hotmail.com>
> wrote:
>
> dear members,
>                          I am Stock trader and using R for research.
>
> Until now I was coding very haphazardly, but recently I stumbled upon the
> Software Development Life Cycle (SDLC), which introduced me to principled
> software design. I am college dropout and don't have in depth knowledge in
> Software Engineering principles. However, now, I want to go in a structured
> manner.
>
> I googled for a SDLC method (like XP, AGILE and WATERFALL) that suits the
> R programming language and specifically for data science, but was bootless.
> Do you people have any idea on which software engineering methodology to
> use in R and data science, so that I can code efficiently and in a
> structured manner? The point to note, with regards to R, is that
> statistical ANALYSIS sometimes takes very little code as compared to other
> programming languages. Any SDLC method for these types of analysis,
> besides, rigorous scripting with R?
>
> Thanking you,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From rhe|p @end|ng |rom eoo@@dd@@n|  Mon Feb 21 10:25:05 2022
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Mon, 21 Feb 2022 10:25:05 +0100
Subject: [R] Get background colour of terminal
Message-ID: <3b323947-0f8f-20fc-2d25-2b31e8fcc90a@eoos.dds.nl>



I am trying to get the background colour of the terminal R is running 
in. There is a xterm control sequence for that: running the following in 
a suitable terminal returns the background colour:

cat("\033]11;?\033\\")

Except that the result is written to stdin and I can't seem to figure 
out how to get that into a variable in R.

Following a shell script example from stackoverflow [1], I had a little 
bit of success using

cat("\033]11;?\033\\")
Sys.sleep(1)
bg <- readLines(n=1)

where one has to press an enter manually, but this is not something that 
can be put into a function.

Wrapping that shell script into a system call works. That does introduce 
some dependencies, but on systems where this is relevant sh and sed are 
probably present anyway. But I still would prefers an R-solution.

Does anyone know how one can get the background colour of the terminal R 
is running in?

Suggestions other than using the xterm control sequence are, of course, 
also welcome. Perhaps a c-routine that can be wrapped into a Rcpp-call?

Thanks for the help.

Best,
Jan



[1] 
https://stackoverflow.com/questions/2507337/how-to-determine-a-terminals-background-color


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Feb 21 11:15:45 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 21 Feb 2022 02:15:45 -0800
Subject: [R] Get background colour of terminal
In-Reply-To: <3b323947-0f8f-20fc-2d25-2b31e8fcc90a@eoos.dds.nl>
References: <3b323947-0f8f-20fc-2d25-2b31e8fcc90a@eoos.dds.nl>
Message-ID: <8CB486FB-BE45-49D1-9744-5B7662B911B0@dcn.davis.ca.us>

You can capture stdin using system(), but you should be cautious as this whole mechanism is highly OS-and-configuration-specific. R is not always running connected to a terminal, and not all terminals respond to the same escape commands.

On February 21, 2022 1:25:05 AM PST, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>
>
>I am trying to get the background colour of the terminal R is running 
>in. There is a xterm control sequence for that: running the following in 
>a suitable terminal returns the background colour:
>
>cat("\033]11;?\033\\")
>
>Except that the result is written to stdin and I can't seem to figure 
>out how to get that into a variable in R.
>
>Following a shell script example from stackoverflow [1], I had a little 
>bit of success using
>
>cat("\033]11;?\033\\")
>Sys.sleep(1)
>bg <- readLines(n=1)
>
>where one has to press an enter manually, but this is not something that 
>can be put into a function.
>
>Wrapping that shell script into a system call works. That does introduce 
>some dependencies, but on systems where this is relevant sh and sed are 
>probably present anyway. But I still would prefers an R-solution.
>
>Does anyone know how one can get the background colour of the terminal R 
>is running in?
>
>Suggestions other than using the xterm control sequence are, of course, 
>also welcome. Perhaps a c-routine that can be wrapped into a Rcpp-call?
>
>Thanks for the help.
>
>Best,
>Jan
>
>
>
>[1] 
>https://stackoverflow.com/questions/2507337/how-to-determine-a-terminals-background-color
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @kw@|mmo @end|ng |rom gm@||@com  Thu Feb 17 22:25:39 2022
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 17 Feb 2022 16:25:39 -0500
Subject: [R] [R-pkgs] this.path-package: get executing script's path
Message-ID: <CAPcHnpQrOWjep3Js5UXJyhKmCCk=aw6kp_UygUKhyxGTc64MEA@mail.gmail.com>

Hello everyone,


R package 'this.path' has received an update, the current version
number is 0.5.0
You can find this package at:

https://CRAN.R-project.org/package=this.path

Updates include:

(1) added this.path::here (similar to here::here), for constructing
the path to a file, starting with the executing script's directory

(2) this.path::this.path is compatible with URLs in base::source, for
example source("https://raw.githubusercontent.com/ArcadeAntics/this.path/main/tests/this.path_w_URLs.R")

(3) added separate methods for extracting the shell argument 'FILE'
for Windows and Unix-alikes (shell arguments are handled slightly
differently between the two)

(4) on Windows, in Rgui, added support for all languages listed by
list.dirs(system.file(package = "translations"), full.names = FALSE,
recursive = FALSE)

If you're using version 0.4.4 or less, it is well worth upgrading.


Regards,
    Andrew Simmons

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From tcmu|g@| @end|ng |rom gm@||@com  Mon Feb 21 12:16:55 2022
From: tcmu|g@| @end|ng |rom gm@||@com (Charles Thuo)
Date: Mon, 21 Feb 2022 14:16:55 +0300
Subject: [R] Comma separators in r console output
Message-ID: <CAAJc=rO__wJr=sxg31eRXn1FQWyuppdqKEo+nmX8d_D=ViGaJg@mail.gmail.com>

Dear Sirs,

How are comma separators inserted in big figures appearing in r console
outputs.

Charles

	[[alternative HTML version deleted]]


From rhe|p @end|ng |rom eoo@@dd@@n|  Mon Feb 21 12:35:31 2022
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Mon, 21 Feb 2022 12:35:31 +0100
Subject: [R] Get background colour of terminal
In-Reply-To: <8CB486FB-BE45-49D1-9744-5B7662B911B0@dcn.davis.ca.us>
References: <3b323947-0f8f-20fc-2d25-2b31e8fcc90a@eoos.dds.nl>
 <8CB486FB-BE45-49D1-9744-5B7662B911B0@dcn.davis.ca.us>
Message-ID: <02808c50-a267-7894-6e25-8e25226b1e7f@eoos.dds.nl>


Thanks. I am not completely sure what you mean with "You can capture 
stdin using system()". How? I had another look at the documentation of 
system and could not figure out how to do this with system.

I know this is really system/terminal specific. Finding out how to 
determine the capabilities of the terminal is another thing on my todo 
list, but I first want to get this to work on my own terminal for which 
I know the capabilities.

Jan




On 21-02-2022 11:15, Jeff Newmiller wrote:
> You can capture stdin using system(), but you should be cautious as this whole mechanism is highly OS-and-configuration-specific. R is not always running connected to a terminal, and not all terminals respond to the same escape commands.
> 
> On February 21, 2022 1:25:05 AM PST, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
>>
>>
>> I am trying to get the background colour of the terminal R is running
>> in. There is a xterm control sequence for that: running the following in
>> a suitable terminal returns the background colour:
>>
>> cat("\033]11;?\033\\")
>>
>> Except that the result is written to stdin and I can't seem to figure
>> out how to get that into a variable in R.
>>
>> Following a shell script example from stackoverflow [1], I had a little
>> bit of success using
>>
>> cat("\033]11;?\033\\")
>> Sys.sleep(1)
>> bg <- readLines(n=1)
>>
>> where one has to press an enter manually, but this is not something that
>> can be put into a function.
>>
>> Wrapping that shell script into a system call works. That does introduce
>> some dependencies, but on systems where this is relevant sh and sed are
>> probably present anyway. But I still would prefers an R-solution.
>>
>> Does anyone know how one can get the background colour of the terminal R
>> is running in?
>>
>> Suggestions other than using the xterm control sequence are, of course,
>> also welcome. Perhaps a c-routine that can be wrapped into a Rcpp-call?
>>
>> Thanks for the help.
>>
>> Best,
>> Jan
>>
>>
>>
>> [1]
>> https://stackoverflow.com/questions/2507337/how-to-determine-a-terminals-background-color
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From rhe|p @end|ng |rom eoo@@dd@@n|  Mon Feb 21 15:23:21 2022
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Mon, 21 Feb 2022 15:23:21 +0100
Subject: [R] Comma separators in r console output
In-Reply-To: <CAAJc=rO__wJr=sxg31eRXn1FQWyuppdqKEo+nmX8d_D=ViGaJg@mail.gmail.com>
References: <CAAJc=rO__wJr=sxg31eRXn1FQWyuppdqKEo+nmX8d_D=ViGaJg@mail.gmail.com>
Message-ID: <28247d47-4516-d5e7-f869-a5d933ef295f@eoos.dds.nl>


See `format`, `formatC` or `prettyNum`. The last one is used by 
`format.default`.

For example

 > format(1E6, big.mark=',', scientific = FALSE)
[1] "1,000,000"

Is this what you are looking for?

Jan





On 21-02-2022 12:16, Charles Thuo wrote:
> Dear Sirs,
> 
> How are comma separators inserted in big figures appearing in r console
> outputs.
> 
> Charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Feb 21 17:19:20 2022
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 21 Feb 2022 17:19:20 +0100
Subject: [R] How to superimpose jitter and barplot in ggplot2?
Message-ID: <CAMk+s2SvWgYqtbZuYi+q_Ei5ZDjq2b-ZfzaRPrttiBfnVh=5jA@mail.gmail.com>

Hello,
I am following this post
https://www.datanovia.com/en/lessons/ggplot-error-bars/ to superimpose
a jitter plot and a barplot with error bars.

Te example works:
```
df2 <- ToothGrowth
df2$dose <- as.factor(df2$dose)
head(df2, 3)
df2.summary <- df2 %>%
  group_by(dose) %>%
  summarise(
    sd = sd(len, na.rm = TRUE),
    len = mean(len)
  )
df2.summary

ggplot(df2, aes(dose, len)) +
  geom_col(data = df2.summary, fill = NA, color = "black") +
  geom_jitter( position = position_jitter(0.2), color = "black") +
  geom_errorbar( aes(ymin = len-sd, ymax = len+sd),
                 data = df2.summary, width = 0.2)
```
but on my data, it does not. The data I have is   similar to the
example, only with 2 classes rather than 3:
```
> str(df)
'data.frame': 82 obs. of  33 variables:
$ id              : int  1 2 3 4 5 6 7 8 9 10 ...
...
$ tocopherol      : num  22.39 15.93 19.91 9.52 35 ...
$ tot_ascorb      : num  7.306 NA NA 0.102 NA ...
...
$ covid           : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2 ...
> df.summary <- df %>%
  +   group_by(covid) %>%
  +   summarise(
    +     sd = sd(tot_ascorb, na.rm = TRUE),
    +     len = mean(tot_ascorb, na.rm = TRUE)
    +   )
`summarise()` ungrouping output (override with `.groups` argument)
> df.summary
# A tibble: 2 x 3
covid    sd   len
<fct> <dbl> <dbl>
  1 No     6.79  47.8
2 Yes   31.4   14.5
```
but when I try to run ggplot, it works in part. The bar plot works:
```
> ggplot(df, aes(covid, len)) +
  geom_col(data = df.summary, fill = NA, color = "black") +
  geom_errorbar(aes(ymin = len, ymax = len+sd),
                data = df.summary, width = 0.2)
```
but the jitter does not:
```
> ggplot(df, aes(covid, len)) +
  +   geom_col(data = df.summary, fill = NA, color = "black") +
  +   geom_errorbar(aes(ymin = len, ymax = len+sd),
                    +                  data = df.summary, width = 0.2) +
  + geom_jitter(position = position_jitter(0.2), color = "black")
Error in FUN(X[[i]], ...) : object 'len' not found
```
What am I getting wrong?
Thanks



-- 
Best regards,
Luigi


From k@ttw|nke|-m|r@ @end|ng |rom un|-|@nd@u@de  Tue Feb 15 10:11:39 2022
From: k@ttw|nke|-m|r@ @end|ng |rom un|-|@nd@u@de (Mira Kattwinkel)
Date: Tue, 15 Feb 2022 10:11:39 +0100
Subject: [R] [R-pkgs] update openSTARS
Message-ID: <a32be8de-3ca0-bc62-d08b-b15b6865d6ab@uni-landau.de>

Dear R users

There is an update of openSTARS available on CRAN (now version 1.2.3), 
fixing some problems in correct_complex_confluences.

openSTARS provides GIS functionalities to delineate streams from DEMs, 
derive catchments of sampling sites along streams and intersect with 
potential covariates of stream monitoring data. It also prepares the 
data to be further processed by geostatistical regression models using ssn.

All the best,

Mira

-- 
Dr. Mira Kattwinkel
Quantitative Landscape Ecology
iES Landau, Institute for Environmental Sciences
University of Koblenz-Landau
Fortstra?e 7
76829 Landau
Germany
Phone: + 49 6341 280-31553
Office: Building I, Room 2.02

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Feb 22 11:15:51 2022
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 22 Feb 2022 11:15:51 +0100
Subject: [R] How to set colors, axis gap, and free scale in ggplot?
Message-ID: <CAMk+s2QAY_3ic+FTn0MaDBAnTSBhfLM4k8KL6khbPK_UyH-oDw@mail.gmail.com>

Hello,
I have a dataframe with 3 columns: the actual measurement
(Concentration), and two groups (Vitamin and Group). I would like to
plot a barplot with superimposed a jitterplot, with error bars. I am
using facet_grid. All that I can do, but the customization does not
work. The customization is as follows:
I need to supply custom colors to the two classes of the Group column,
then have different scales for each panel and give an axis break on
the first panel.
I made a working example:
```
data("iris")
bins <- c(1.5)
iris$Group = findInterval(iris$Petal.Width, 1.5)
iris$Group = as.factor(iris$Group)
levels(iris$Group) <- c("Small", "Large")
# plot
library(ggplot2)
ggplot(iris, aes(Group, Sepal.Length, fill = Group)) +
geom_bar(position="dodge", stat="summary", fun.y="mean") +
geom_errorbar(stat="summary", position="dodge", width=0.5) +
geom_jitter(aes(x=Group), shape=21) +
xlab(expression(bold("Plant species"))) +
ylab(expression(bold("Measure"))) +
# FROM HERE IT DOES NOT WORK
facet_grid(. ~ Species, scales="free_y") + # THE SCALE IS FIXED FOR ALL PANELS
scale_colour_manual(values = c("palegreen4", "orangered3")) # THE
COLORS ARE AUTOMATIC
```

I would also like to increase the size of the axis labels and the
title size of the panels.
What is the correct syntax?
Thanks


From judej@ck121 @end|ng |rom gm@||@com  Tue Feb 22 05:58:29 2022
From: judej@ck121 @end|ng |rom gm@||@com (J H)
Date: Tue, 22 Feb 2022 04:58:29 +0000
Subject: [R] Java and Compilation
Message-ID: <D08BACE8-1239-4740-A75D-149B0DFB9229@gmail.com>

It seems like compiling R failed due to a lack of a Java Interpreter, but i don?t see this as a requirement anywhere on the website.
I?m using Hyperbola GNU/Linux-Libre, which doesn?t support Java (which I like)
So is Java a hard requirement for compiling R? Or is this something I can work around? 
Thanks 

From me@@@du@ @end|ng |rom y@hoo@|t  Tue Feb 22 09:51:29 2022
From: me@@@du@ @end|ng |rom y@hoo@|t (Diego Bellavia)
Date: Tue, 22 Feb 2022 08:51:29 +0000 (UTC)
Subject: [R] How to compute ggplot2 boxplot outliers after Reshape/Melt in
 LONG/stacked format (in aloop)
References: <304539449.1410336.1645519889734.ref@mail.yahoo.com>
Message-ID: <304539449.1410336.1645519889734@mail.yahoo.com>

Here it is a test Dataframe (just a subset of the real one), that is in LONG format (each subject / PID has several repeated measures over time)
dput(head(testdf))
structure(list(pid = c(1, 1, 1, 1, 1, 2), age = c(52, 52, 52, 
52, 52, 76), height = c(175, 175, 175, 175, 175, 164), weight = c(68, 
70, 68, 68, 68, 95.5), bsa = c(1.82549041118621, 1.84811901382349, 
1.82549041118621, 1.82549041118621, 1.82549041118621, 2.01198114104261
), lab_bnp_log = c(5.96100533962327, 5.29330482472449, 5.9597158487934, 
5.76205138278018, 5.03695260241363, 6.85583020611722), lab_tni_log = c(-5.49676830527187, 
-5.36019277026612, -5.80914299031403, -5.5727542122498, -5.59942245933196, 
-4.56594947283481), lab_crp_log = c(NA, 1.50407739677627, 0.955511445027436, 
1.54756250871601, 1.54756250871601, 0.8754687373539), lab_bun = c(57, 
47, 57, 49, 61, 52), lab_creat = c(1.2, 1, 1.3, 1.2, 1.4, 1.5
)), row.names = c(NA, 6L), class = "data.frame"
I am trying to correctly label boxplot outliers using GGPLOT2 package, as a step of my exploratory analysis.
To plot an Histogram and a Boxplot I use a For loop, that starts after having "melted" the dataset
library(ggplot2)
library(reshape2)
library(tidyverse)
library(egg)

myplots <- melt(testdf, id.vars = "pid", na.rm = TRUE)

is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}

pdf(paste("EXPL_QUANT.pdf",sep=""))
# Start the FOR Loop, where i = Variable name and value = variable value (number)
for(i in 1:length(levels(myplots$variable)))
{
  MyHisto <- ggplot(myplots[myplots$variable == levels(myplots$variable)[i],], aes(x=value)) + 
    geom_histogram(aes(y = ..density..),
                   binwidth = 0.7, # Modify it to have more/less bins in the histo
                   fill = 'yellow',
                   alpha = 0.7,
                   col = 'black') +
    geom_density(colour="#00000040", lwd = 1, fill="lightyellow", alpha=0.5) +
    geom_vline(aes(xintercept = summarised_value, color = stat), 
               size = 1,
               data = . %>% 
                 summarise(mean = mean(value), median = median(value)) %>% 
                 gather ("stat", "summarised_value", mean:median)) +
    scale_color_manual(values = c("blue", "red")) +
    theme_bw() +
    theme(axis.text.x=element_text(size=14), axis.title.x=element_text(size=16),
          axis.text.y=element_text(size=14), axis.title.y=element_text(size=16),
          legend.position = c(.95, .95),
          legend.justification = c(1,1),
          legend.background = element_rect(color = "black")) +
    ggtitle(paste0("Explorative Analysis of ",levels(myplots$variable)[i]))
  
  }
  
  # Plot the BoxPlot
  dat <- myplots[myplots$variable == levels(myplots$variable)[i],]  %>% 
                tibble::rownames_to_column(var="outlier") %>%  
                  mutate(outlier = ifelse(is_outlier(myplots$value[i]), myplots$value[i], as.numeric(NA)))
  dat$outlier[which(is.na(dat$is_outlier))] <- as.numeric(NA)
  MyBox <- ggplot(dat, aes(x = i, y = value)) +
    geom_boxplot(fill = "royalblue"
                 , colour = "black"
                 , outlier.colour = "red" 
                 , outlier.shape = 20 # 
                 , outlier.size = 1
    ) +
    coord_flip() + # Horizontal Boxplot 
    scale_y_continuous(name = levels(myplots$variable)[i]) + # Variable name on the Y Axis 
    scale_x_continuous(name = levels(myplots$variable)[i]) + # Variable name on the X Axis 
    geom_text(aes(label=outlier),na.rm=TRUE,nudge_y=0.05)
 

  egg::ggarrange(MyHisto, MyBox, heights = 2:1) # Combine and Line up Histogram and Boxplot (EGG Package)
  
}

dev.off()The loop complete with no errors and the graphs are programmatically built, I can see the outliers in the boxplots depicted as red dots (that is fine) BUT I cannot see the labels. I believe the problem is that outliers column contains just NAs for each variable, so of course I cannot label anything, and I think the following line

mutate(outlier = ifelse(is_outlier(myplots$value[i]), myplots$value[i], as.numeric(NA))should be modified so to provide the is_outlier() function with a proper vector of values, each grouped by PID and by variable, but, even if I am correct I do not know how to do that. 
Any help in understanding why the loop is not working and how to fix it would be greatly appreciated
Best, 
Diego 

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Feb 22 12:41:16 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 22 Feb 2022 11:41:16 +0000
Subject: [R] How to set colors, axis gap, and free scale in ggplot?
In-Reply-To: <CAMk+s2QAY_3ic+FTn0MaDBAnTSBhfLM4k8KL6khbPK_UyH-oDw@mail.gmail.com>
References: <CAMk+s2QAY_3ic+FTn0MaDBAnTSBhfLM4k8KL6khbPK_UyH-oDw@mail.gmail.com>
Message-ID: <98c953c6d4b6410c97a7ea43fb871caa@SRVEXCHCM1301.precheza.cz>

Hi Luigi

change last two ggplot commands as follows

facet_wrap(. ~ Species, scales="free_y") +
scale_fill_manual(values = c("palegreen4", "orangered3"))

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Tuesday, February 22, 2022 11:16 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] How to set colors, axis gap, and free scale in ggplot?
> 
> Hello,
> I have a dataframe with 3 columns: the actual measurement (Concentration),
> and two groups (Vitamin and Group). I would like to plot a barplot with
> superimposed a jitterplot, with error bars. I am using facet_grid. All
that I can
> do, but the customization does not work. The customization is as follows:
> I need to supply custom colors to the two classes of the Group column,
then
> have different scales for each panel and give an axis break on the first
panel.
> I made a working example:
> ```
> data("iris")
> bins <- c(1.5)
> iris$Group = findInterval(iris$Petal.Width, 1.5) iris$Group =
> as.factor(iris$Group)
> levels(iris$Group) <- c("Small", "Large") # plot
> library(ggplot2)
> ggplot(iris, aes(Group, Sepal.Length, fill = Group)) +
> geom_bar(position="dodge", stat="summary", fun.y="mean") +
> geom_errorbar(stat="summary", position="dodge", width=0.5) +
> geom_jitter(aes(x=Group), shape=21) + xlab(expression(bold("Plant
species")))
> +
> ylab(expression(bold("Measure"))) +
> # FROM HERE IT DOES NOT WORK
> facet_grid(. ~ Species, scales="free_y") + # THE SCALE IS FIXED FOR ALL
PANELS
> scale_colour_manual(values = c("palegreen4", "orangered3")) # THE COLORS
> ARE AUTOMATIC ```
> 
> I would also like to increase the size of the axis labels and the title
size of the
> panels.
> What is the correct syntax?
> Thanks
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@e@crump @end|ng |rom w@rw|ck@@c@uk  Tue Feb 22 12:41:47 2022
From: r@e@crump @end|ng |rom w@rw|ck@@c@uk (Ron Crump)
Date: Tue, 22 Feb 2022 11:41:47 +0000
Subject: [R] How to set colors, axis gap, and free scale in ggplot?
Message-ID: <dcd3319b-be8c-13f1-54c2-30be12f7533f@warwick.ac.uk>

Hi Luigi,

> # FROM HERE IT DOES NOT WORK
> facet_grid(. ~ Species, scales="free_y") + # THE SCALE IS FIXED FOR ALL PANELS

I don't think you can force facet_grid to do this: the y scale will
always be fixed within a row (unless someone else tells you differently,
I may have misunderstood this)  - this is to allow easy comparison and,
consequently, comprehension of the graphic as you scan across a row.

You can achieve what you want with:
facet_wrap(~ Species, nrow = 1, scales = "free_y")
but for the reason above, I'm not sure it's a good thing to do.

> scale_colour_manual(values = c("palegreen4", "orangered3")) # THE
> COLORS ARE AUTOMATIC

You're setting the colour manually - which relates to lines, not fill
and you have no colour aesthetic set, just a fill one.

Use scale_fill_manual(values = c("palegreen4", "orangered3")) instead.

> I would also like to increase the size of the axis labels and the
> title size of the panels.
> What is the correct syntax?

See ?theme - you are interested in axis.title (maybe axis.title.x,
axis.title.y) and strip.text (the labels for the facets). See also
?element_text as in theme, you basically want to put something like
axis.title = element_text(...), replacing ... with the settings you
want.

For help specifically on ggplot2 and other tidyverse packages, I'd
recommend using https://community.rstudio.com in the future.

Best wishes,
Ron.


From tebert @end|ng |rom u||@edu  Tue Feb 22 13:10:14 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Tue, 22 Feb 2022 12:10:14 +0000
Subject: [R] Java and Compilation
In-Reply-To: <D08BACE8-1239-4740-A75D-149B0DFB9229@gmail.com>
References: <D08BACE8-1239-4740-A75D-149B0DFB9229@gmail.com>
Message-ID: <BN6PR2201MB15534430766FFF8E1B72B776CF3B9@BN6PR2201MB1553.namprd22.prod.outlook.com>

Can you share the error and tell us a bit more about your system? It might be a requirement of a package that you are using?

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of J H
Sent: Monday, February 21, 2022 11:58 PM
To: r-help at R-project.org
Subject: [R] Java and Compilation

[External Email]

It seems like compiling R failed due to a lack of a Java Interpreter, but i don?t see this as a requirement anywhere on the website.
I?m using Hyperbola GNU/Linux-Libre, which doesn?t support Java (which I like) So is Java a hard requirement for compiling R? Or is this something I can work around?
Thanks
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=JgjqHjyVb_i356ThBLBt1U4fxz1FY6CLDedr9xDqcG_PUD3AOxgJyOJrLC5Xo5Sg&s=KzyYoDZcZZ6HhIHb77gtjm9Fmj1DpplauMDUoCAGd04&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=JgjqHjyVb_i356ThBLBt1U4fxz1FY6CLDedr9xDqcG_PUD3AOxgJyOJrLC5Xo5Sg&s=4YaxmK2K0ZpnjZJW16pbLehEfVK6B4e1MPna4nV8_jI&e=
and provide commented, minimal, self-contained, reproducible code.

From kry|ov@r00t @end|ng |rom gm@||@com  Tue Feb 22 13:15:18 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 22 Feb 2022 15:15:18 +0300
Subject: [R] Java and Compilation
In-Reply-To: <D08BACE8-1239-4740-A75D-149B0DFB9229@gmail.com>
References: <D08BACE8-1239-4740-A75D-149B0DFB9229@gmail.com>
Message-ID: <20220222151518.5aa63a08@arachnoid>

On Tue, 22 Feb 2022 04:58:29 +0000
J H <judejack121 at gmail.com> wrote:

> It seems like compiling R failed due to a lack of a Java Interpreter

On one of my machines, I can see Java-related error messages when
compiling R, but the build actually succeeds: the Java parts are only
attempted to build after bin/R and library/* are already produced in
working order.

-- 
Best regards,
Ivan


From he|mut@@chuetz @end|ng |rom beb@c@@t  Tue Feb 22 14:46:23 2022
From: he|mut@@chuetz @end|ng |rom beb@c@@t (Helmut Schuetz)
Date: Tue, 22 Feb 2022 14:46:23 +0100
Subject: [R] Comma separators in r console output
In-Reply-To: <mailman.365867.1.1645527601.21066.r-help@r-project.org>
References: <mailman.365867.1.1645527601.21066.r-help@r-project.org>
Message-ID: <b5ad5e3f-953c-599d-27e1-e31fd4d18449@bebac.at>

Hi Charles,

> Dear Sirs, [...]

Not interested in opinions of Madams? R-help is not a 'males-only-club'.

Helmut (Sir)

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
W https://bebac.at/
F https://forum.bebac.at/


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Feb 22 15:09:58 2022
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 22 Feb 2022 15:09:58 +0100
Subject: [R] How to set colors, axis gap, and free scale in ggplot?
In-Reply-To: <dcd3319b-be8c-13f1-54c2-30be12f7533f@warwick.ac.uk>
References: <dcd3319b-be8c-13f1-54c2-30be12f7533f@warwick.ac.uk>
Message-ID: <CAMk+s2Qm3X0DJKq9Gn0CukeDs9=9ahJTU-8VM=GG7ojQhzKmwA@mail.gmail.com>

No wonder it was not working: I was using the wrong functions (so far
of manuals....)
This is great, thank you! All tips worked fine, including the free axis scale.

On Tue, Feb 22, 2022 at 12:41 PM Ron Crump <r.e.crump at warwick.ac.uk> wrote:
>
> Hi Luigi,
>
> > # FROM HERE IT DOES NOT WORK
> > facet_grid(. ~ Species, scales="free_y") + # THE SCALE IS FIXED FOR ALL PANELS
>
> I don't think you can force facet_grid to do this: the y scale will
> always be fixed within a row (unless someone else tells you differently,
> I may have misunderstood this)  - this is to allow easy comparison and,
> consequently, comprehension of the graphic as you scan across a row.
>
> You can achieve what you want with:
> facet_wrap(~ Species, nrow = 1, scales = "free_y")
> but for the reason above, I'm not sure it's a good thing to do.
>
> > scale_colour_manual(values = c("palegreen4", "orangered3")) # THE
> > COLORS ARE AUTOMATIC
>
> You're setting the colour manually - which relates to lines, not fill
> and you have no colour aesthetic set, just a fill one.
>
> Use scale_fill_manual(values = c("palegreen4", "orangered3")) instead.
>
> > I would also like to increase the size of the axis labels and the
> > title size of the panels.
> > What is the correct syntax?
>
> See ?theme - you are interested in axis.title (maybe axis.title.x,
> axis.title.y) and strip.text (the labels for the facets). See also
> ?element_text as in theme, you basically want to put something like
> axis.title = element_text(...), replacing ... with the settings you
> want.
>
> For help specifically on ggplot2 and other tidyverse packages, I'd
> recommend using https://community.rstudio.com in the future.
>
> Best wishes,
> Ron.
>


-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Feb 22 15:25:09 2022
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 22 Feb 2022 15:25:09 +0100
Subject: [R] How to set colors, axis gap, and free scale in ggplot?
In-Reply-To: <dcd3319b-be8c-13f1-54c2-30be12f7533f@warwick.ac.uk>
References: <dcd3319b-be8c-13f1-54c2-30be12f7533f@warwick.ac.uk>
Message-ID: <CAMk+s2Q0x6FAO0Kq0_G+3Oe3CwirS8XHNV1MMERvfNa1k3qbuw@mail.gmail.com>

I am trying instead to increase the size with `theme(strip.text.x =
element_text(size = 10))` (evem from 1 onwards) or `theme(strip.text.x
= element_text(face = "bold"))` but it gives an error (same in both
cases, even when using `strip.text`):
```
No summary function supplied, defaulting to `mean_se()`
No summary function supplied, defaulting to `mean_se()`
No summary function supplied, defaulting to `mean_se()`
No summary function supplied, defaulting to `mean_se()`
No summary function supplied, defaulting to `mean_se()`
No summary function supplied, defaulting to `mean_se()`
No summary function supplied, defaulting to `mean_se()`
No summary function supplied, defaulting to `mean_se()`
Warning messages:
1: Ignoring unknown parameters: fun.y
2: Removed 24 rows containing non-finite values (stat_summary).
3: Removed 24 rows containing non-finite values (stat_summary).
4: Removed 24 rows containing missing values (geom_point).

On Tue, Feb 22, 2022 at 12:41 PM Ron Crump <r.e.crump at warwick.ac.uk> wrote:
>
> Hi Luigi,
>
> > # FROM HERE IT DOES NOT WORK
> > facet_grid(. ~ Species, scales="free_y") + # THE SCALE IS FIXED FOR ALL PANELS
>
> I don't think you can force facet_grid to do this: the y scale will
> always be fixed within a row (unless someone else tells you differently,
> I may have misunderstood this)  - this is to allow easy comparison and,
> consequently, comprehension of the graphic as you scan across a row.
>
> You can achieve what you want with:
> facet_wrap(~ Species, nrow = 1, scales = "free_y")
> but for the reason above, I'm not sure it's a good thing to do.
>
> > scale_colour_manual(values = c("palegreen4", "orangered3")) # THE
> > COLORS ARE AUTOMATIC
>
> You're setting the colour manually - which relates to lines, not fill
> and you have no colour aesthetic set, just a fill one.
>
> Use scale_fill_manual(values = c("palegreen4", "orangered3")) instead.
>
> > I would also like to increase the size of the axis labels and the
> > title size of the panels.
> > What is the correct syntax?
>
> See ?theme - you are interested in axis.title (maybe axis.title.x,
> axis.title.y) and strip.text (the labels for the facets). See also
> ?element_text as in theme, you basically want to put something like
> axis.title = element_text(...), replacing ... with the settings you
> want.
>
> For help specifically on ggplot2 and other tidyverse packages, I'd
> recommend using https://community.rstudio.com in the future.
>
> Best wishes,
> Ron.
>


-- 
Best regards,
Luigi


From r@e@crump @end|ng |rom w@rw|ck@@c@uk  Tue Feb 22 15:35:44 2022
From: r@e@crump @end|ng |rom w@rw|ck@@c@uk (Ron Crump)
Date: Tue, 22 Feb 2022 14:35:44 +0000
Subject: [R] How to set colors, axis gap, and free scale in ggplot?
In-Reply-To: <CAMk+s2Q0x6FAO0Kq0_G+3Oe3CwirS8XHNV1MMERvfNa1k3qbuw@mail.gmail.com>
References: <dcd3319b-be8c-13f1-54c2-30be12f7533f@warwick.ac.uk>
 <CAMk+s2Q0x6FAO0Kq0_G+3Oe3CwirS8XHNV1MMERvfNa1k3qbuw@mail.gmail.com>
Message-ID: <70e6dfbd-ab6d-bdce-bab9-5895a62c3cf0@warwick.ac.uk>

What error?
Those are warning messages to do with your call to geom_bar. I've never
used geom_bar in that way, I'd create my summaries independently of
the graphing, so can't comment on how it should be used.

This simple example works fine for me:
```
library(ggplot2)
data(iris)
ggplot(iris) +
     geom_point(aes(x = Sepal.Width, y = Sepal.Length)) +
     facet_wrap(~ Species, nrow = 1) +
     theme(strip.text = element_text(size = 10,face = 'bold'))
```

Ron.


On 22/02/2022 14:25, Luigi Marongiu wrote:
> I am trying instead to increase the size with `theme(strip.text.x =
> element_text(size = 10))` (evem from 1 onwards) or `theme(strip.text.x
> = element_text(face = "bold"))` but it gives an error (same in both
> cases, even when using `strip.text`):
> ```
> No summary function supplied, defaulting to `mean_se()`
> No summary function supplied, defaulting to `mean_se()`
> No summary function supplied, defaulting to `mean_se()`
> No summary function supplied, defaulting to `mean_se()`
> No summary function supplied, defaulting to `mean_se()`
> No summary function supplied, defaulting to `mean_se()`
> No summary function supplied, defaulting to `mean_se()`
> No summary function supplied, defaulting to `mean_se()`
> Warning messages:
> 1: Ignoring unknown parameters: fun.y
> 2: Removed 24 rows containing non-finite values (stat_summary).
> 3: Removed 24 rows containing non-finite values (stat_summary).
> 4: Removed 24 rows containing missing values (geom_point).
> 
> On Tue, Feb 22, 2022 at 12:41 PM Ron Crump <r.e.crump at warwick.ac.uk> wrote:
>>
>> Hi Luigi,
>>
>>> # FROM HERE IT DOES NOT WORK
>>> facet_grid(. ~ Species, scales="free_y") + # THE SCALE IS FIXED FOR ALL PANELS
>>
>> I don't think you can force facet_grid to do this: the y scale will
>> always be fixed within a row (unless someone else tells you differently,
>> I may have misunderstood this)  - this is to allow easy comparison and,
>> consequently, comprehension of the graphic as you scan across a row.
>>
>> You can achieve what you want with:
>> facet_wrap(~ Species, nrow = 1, scales = "free_y")
>> but for the reason above, I'm not sure it's a good thing to do.
>>
>>> scale_colour_manual(values = c("palegreen4", "orangered3")) # THE
>>> COLORS ARE AUTOMATIC
>>
>> You're setting the colour manually - which relates to lines, not fill
>> and you have no colour aesthetic set, just a fill one.
>>
>> Use scale_fill_manual(values = c("palegreen4", "orangered3")) instead.
>>
>>> I would also like to increase the size of the axis labels and the
>>> title size of the panels.
>>> What is the correct syntax?
>>
>> See ?theme - you are interested in axis.title (maybe axis.title.x,
>> axis.title.y) and strip.text (the labels for the facets). See also
>> ?element_text as in theme, you basically want to put something like
>> axis.title = element_text(...), replacing ... with the settings you
>> want.
>>
>> For help specifically on ggplot2 and other tidyverse packages, I'd
>> recommend using https://community.rstudio.com in the future.
>>
>> Best wishes,
>> Ron.
>>
> 
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Feb 22 15:38:38 2022
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 22 Feb 2022 15:38:38 +0100
Subject: [R] How to set colors, axis gap, and free scale in ggplot?
In-Reply-To: <70e6dfbd-ab6d-bdce-bab9-5895a62c3cf0@warwick.ac.uk>
References: <dcd3319b-be8c-13f1-54c2-30be12f7533f@warwick.ac.uk>
 <CAMk+s2Q0x6FAO0Kq0_G+3Oe3CwirS8XHNV1MMERvfNa1k3qbuw@mail.gmail.com>
 <70e6dfbd-ab6d-bdce-bab9-5895a62c3cf0@warwick.ac.uk>
Message-ID: <CAMk+s2S4bqKt=zO2KrH8CfDMW209K9xrvXRPD3foFSWcvz=DEw@mail.gmail.com>

You are right, it did work.
Thanks
Case closed.

On Tue, Feb 22, 2022 at 3:35 PM Ron Crump <r.e.crump at warwick.ac.uk> wrote:
>
> What error?
> Those are warning messages to do with your call to geom_bar. I've never
> used geom_bar in that way, I'd create my summaries independently of
> the graphing, so can't comment on how it should be used.
>
> This simple example works fine for me:
> ```
> library(ggplot2)
> data(iris)
> ggplot(iris) +
>      geom_point(aes(x = Sepal.Width, y = Sepal.Length)) +
>      facet_wrap(~ Species, nrow = 1) +
>      theme(strip.text = element_text(size = 10,face = 'bold'))
> ```
>
> Ron.
>
>
> On 22/02/2022 14:25, Luigi Marongiu wrote:
> > I am trying instead to increase the size with `theme(strip.text.x =
> > element_text(size = 10))` (evem from 1 onwards) or `theme(strip.text.x
> > = element_text(face = "bold"))` but it gives an error (same in both
> > cases, even when using `strip.text`):
> > ```
> > No summary function supplied, defaulting to `mean_se()`
> > No summary function supplied, defaulting to `mean_se()`
> > No summary function supplied, defaulting to `mean_se()`
> > No summary function supplied, defaulting to `mean_se()`
> > No summary function supplied, defaulting to `mean_se()`
> > No summary function supplied, defaulting to `mean_se()`
> > No summary function supplied, defaulting to `mean_se()`
> > No summary function supplied, defaulting to `mean_se()`
> > Warning messages:
> > 1: Ignoring unknown parameters: fun.y
> > 2: Removed 24 rows containing non-finite values (stat_summary).
> > 3: Removed 24 rows containing non-finite values (stat_summary).
> > 4: Removed 24 rows containing missing values (geom_point).
> >
> > On Tue, Feb 22, 2022 at 12:41 PM Ron Crump <r.e.crump at warwick.ac.uk> wrote:
> >>
> >> Hi Luigi,
> >>
> >>> # FROM HERE IT DOES NOT WORK
> >>> facet_grid(. ~ Species, scales="free_y") + # THE SCALE IS FIXED FOR ALL PANELS
> >>
> >> I don't think you can force facet_grid to do this: the y scale will
> >> always be fixed within a row (unless someone else tells you differently,
> >> I may have misunderstood this)  - this is to allow easy comparison and,
> >> consequently, comprehension of the graphic as you scan across a row.
> >>
> >> You can achieve what you want with:
> >> facet_wrap(~ Species, nrow = 1, scales = "free_y")
> >> but for the reason above, I'm not sure it's a good thing to do.
> >>
> >>> scale_colour_manual(values = c("palegreen4", "orangered3")) # THE
> >>> COLORS ARE AUTOMATIC
> >>
> >> You're setting the colour manually - which relates to lines, not fill
> >> and you have no colour aesthetic set, just a fill one.
> >>
> >> Use scale_fill_manual(values = c("palegreen4", "orangered3")) instead.
> >>
> >>> I would also like to increase the size of the axis labels and the
> >>> title size of the panels.
> >>> What is the correct syntax?
> >>
> >> See ?theme - you are interested in axis.title (maybe axis.title.x,
> >> axis.title.y) and strip.text (the labels for the facets). See also
> >> ?element_text as in theme, you basically want to put something like
> >> axis.title = element_text(...), replacing ... with the settings you
> >> want.
> >>
> >> For help specifically on ggplot2 and other tidyverse packages, I'd
> >> recommend using https://community.rstudio.com in the future.
> >>
> >> Best wishes,
> >> Ron.
> >>
> >
> >



-- 
Best regards,
Luigi


From |eg|d| @end|ng |rom un|t@@|t  Tue Feb 22 15:41:48 2022
From: |eg|d| @end|ng |rom un|t@@|t (EGIDI LEONARDO)
Date: Tue, 22 Feb 2022 14:41:48 +0000
Subject: [R] [R-pkgs] footBayes 0.1.0 for football modelling is on CRAN!
Message-ID: <AS8P250MB0008A7F0B87BEE6E89344EE9B63B9@AS8P250MB0008.EURP250.PROD.OUTLOOK.COM>

Hi all,

just to inform you that the 'footBayes' package (version 0.1.0) is now on CRAN:

 https://CRAN.R-project.org/package=footBayes<https://cran.r-project.org/package=footBayes>

The package wants to be the most comprehensive tool for the football (soccer) modelling ecosystem.
As such, it allows the estimation, the visualization and the prediction for the most
well-known football (soccer) models, according to the references:

Dixon and Coles (1997) <doi:10.1111/1467-9876.00065>,
Karlis and Ntzoufras (2003) <doi:10.1111/1467-9884.00366> and
Egidi, Pauli and Torelli (2018) <doi:10.1177/1471082X18798414>.

In brief, the goal of ```footBayes``` is to propose a complete workflow to:

- fit the most well-known football models: double Poisson, bivariate Poisson, Skellam, student-t, according to both maximum likelihood and Bayesian methods (+ Hamiltonian Monte Carlo engine);

- visualize the teams' abilities, the model checks, the rank-league reconstruction;

- predict out-of-sample matches.

Try the package now and enjoy!
Best.

Leonardo Egidi
University of Trieste



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From p@u|bern@|07 @end|ng |rom gm@||@com  Thu Feb 24 17:00:08 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Thu, 24 Feb 2022 11:00:08 -0500
Subject: [R] Pixel Image Reshaping using R
Message-ID: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>

Dear friends,

I apologize if the description is  a bit long, but I think that I need to
be as specific as possible so that you guys can help.

I wil share with you a file (train.csv), which contains gray-scale images
of hand-drawn digits, from zero through 9.

Each image is 28 pixels in height and 28 pixels in width, for a total of
784 pixels in total. Each pixel has a single pixel-value associated with
it, indicating the lightness or darkness of that pixel, with higher numbers
meaning darker. This pixel-value is an integer between 0 and 255,
inclusive. The training data set, (train.csv), has 785 columns. The first
column, called ?label?, is the digit that was drawn by the user. The rest
of the columns contain the pixel-values of the associated image. Each pixel
column in the training set has a name like pixel x, where x is an integer
between 0 and 783, inclusive. To locate this pixel on the image, suppose
that we have decomposed x as x = i ? 28 + j, where i and j are integers
between 0 and 27, inclusive. Then pixel x is located on row i and column j
of a 28 x 28 matrix, (indexing by zero). or example, pixel 31 indicates the
pixel that is in the fourth column from the left, and the second row from
the top, as in the ascii-diagram below.

  This data is set up in a csv file which will require the reshaping of the
data to be 28 ? 28 matrix representing images. There are 42000 images in
the train.csv file. For this problem it is only necessary to process
approximately 100 images, 10 each of the numbers from 0 through 9. The goal
is to learn how to generate features from images using transforms and first
order statistics.

So I need to develop an algorithm to store the data in a data structure
such that the data is reshaped into a matrix of size 28 x 28 and then I
have to plot the developed matrix for indices 1, 2, 4, 7, 8, 9, 11. 12, 17
and 22.

I have been looking for information about how to process this with R, but
have not found anything yet.

The dataset is attached in this e-mail for your reference.

Any help and/or guidance will be greatly appreciated.

Best regards,
Paul
 train.csv
<https://drive.google.com/file/d/1WPb7bKHJ8BlzuLKJogMOAOqb-VCoXDMp/view?usp=drive_web>

	[[alternative HTML version deleted]]


From er|cwe|ne15 @end|ng |rom gm@||@com  Thu Feb 24 05:18:50 2022
From: er|cwe|ne15 @end|ng |rom gm@||@com (Eric Weine)
Date: Wed, 23 Feb 2022 23:18:50 -0500
Subject: [R] [R-pkgs] qqconf update to 1.2.0
Message-ID: <CAO=DOOa+UjJgvd67=vHPtvsSusgsqfh_PrvQ1X3jge1SpyMVoQ@mail.gmail.com>

Hello,

qqconf has received an update to version 1.2.0. All interfaces are exactly
the same, but the code to derive testing bands for qq plots has gotten
substantially faster due to a new FFT method thanks to Amit Moscovich and
Boaz Nadler (see documentation for more details).

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Feb 24 18:00:13 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 24 Feb 2022 20:00:13 +0300
Subject: [R] Pixel Image Reshaping using R
In-Reply-To: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
References: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
Message-ID: <20220224200013.4bd496df@Tarkus>

On Thu, 24 Feb 2022 11:00:08 -0500
Paul Bernal <paulbernal07 at gmail.com> wrote:

> Each pixel column in the training set has a name like pixel x, where
> x is an integer between 0 and 783, inclusive. To locate this pixel on
> the image, suppose that we have decomposed x as x = i ? 28 + j, where
> i and j are integers between 0 and 27, inclusive. 

> I have been looking for information about how to process this with R,
> but have not found anything yet.

Given a 784-element vector x, you can reshape it into a 28 by 28 matrix:

dim(x) <- c(28, 28)

Or create a new matrix: matrix(x, 28, 28)

Working with more dimensions is also possible. A matrix X with dim(X)
== c(n, 784) can be transformed into a three-way array in place or
copied into one:

dim(X) <- c(dim(X)[1], 28, 28)
array(X, c(dim(X)[1], 28, 28))

(Replace 28,28 with 784 for an inverse transformation. In modern
versions of R, two-way arrays are more or less the same as matrices,
but old versions may disagree with that in some corner cases.)

For more information, see ?dim, ?matrix, ?array.

-- 
Best regards,
Ivan


From p@u|bern@|07 @end|ng |rom gm@||@com  Thu Feb 24 18:01:27 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Thu, 24 Feb 2022 12:01:27 -0500
Subject: [R] Pixel Image Reshaping using R
In-Reply-To: <20220224200013.4bd496df@Tarkus>
References: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
 <20220224200013.4bd496df@Tarkus>
Message-ID: <CAMOcQfMJonFpno4=KcLur8yb1fyhXO6S9FKnOTdFVbKDRWkBxw@mail.gmail.com>

Thank you very much Ivan!

El El jue, 24 de feb. de 2022 a la(s) 12:00 p. m., Ivan Krylov <
krylov.r00t at gmail.com> escribi?:

> On Thu, 24 Feb 2022 11:00:08 -0500
> Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> > Each pixel column in the training set has a name like pixel x, where
> > x is an integer between 0 and 783, inclusive. To locate this pixel on
> > the image, suppose that we have decomposed x as x = i ? 28 + j, where
> > i and j are integers between 0 and 27, inclusive.
>
> > I have been looking for information about how to process this with R,
> > but have not found anything yet.
>
> Given a 784-element vector x, you can reshape it into a 28 by 28 matrix:
>
> dim(x) <- c(28, 28)
>
> Or create a new matrix: matrix(x, 28, 28)
>
> Working with more dimensions is also possible. A matrix X with dim(X)
> == c(n, 784) can be transformed into a three-way array in place or
> copied into one:
>
> dim(X) <- c(dim(X)[1], 28, 28)
> array(X, c(dim(X)[1], 28, 28))
>
> (Replace 28,28 with 784 for an inverse transformation. In modern
> versions of R, two-way arrays are more or less the same as matrices,
> but old versions may disagree with that in some corner cases.)
>
> For more information, see ?dim, ?matrix, ?array.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Feb 24 18:03:34 2022
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 24 Feb 2022 12:03:34 -0500
Subject: [R] Pixel Image Reshaping using R
In-Reply-To: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
References: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
Message-ID: <CAM_vjumSoQ6ZExKkxKL-4eJ171D+udBCKph0jgsThKmSMJXysQ@mail.gmail.com>

Hi Paul,

I may be missing something, but you can transform a vector to a matrix
of any desired size by using matrix().

For more nuanced processing of images, you might look into one of the
many image processing packages in R, or even the raster package (or
the newer terra).

Sarah

On Thu, Feb 24, 2022 at 11:00 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> I apologize if the description is  a bit long, but I think that I need to
> be as specific as possible so that you guys can help.
>
> I wil share with you a file (train.csv), which contains gray-scale images
> of hand-drawn digits, from zero through 9.
>
> Each image is 28 pixels in height and 28 pixels in width, for a total of
> 784 pixels in total. Each pixel has a single pixel-value associated with
> it, indicating the lightness or darkness of that pixel, with higher numbers
> meaning darker. This pixel-value is an integer between 0 and 255,
> inclusive. The training data set, (train.csv), has 785 columns. The first
> column, called ?label?, is the digit that was drawn by the user. The rest
> of the columns contain the pixel-values of the associated image. Each pixel
> column in the training set has a name like pixel x, where x is an integer
> between 0 and 783, inclusive. To locate this pixel on the image, suppose
> that we have decomposed x as x = i ? 28 + j, where i and j are integers
> between 0 and 27, inclusive. Then pixel x is located on row i and column j
> of a 28 x 28 matrix, (indexing by zero). or example, pixel 31 indicates the
> pixel that is in the fourth column from the left, and the second row from
> the top, as in the ascii-diagram below.
>
>   This data is set up in a csv file which will require the reshaping of the
> data to be 28 ? 28 matrix representing images. There are 42000 images in
> the train.csv file. For this problem it is only necessary to process
> approximately 100 images, 10 each of the numbers from 0 through 9. The goal
> is to learn how to generate features from images using transforms and first
> order statistics.
>
> So I need to develop an algorithm to store the data in a data structure
> such that the data is reshaped into a matrix of size 28 x 28 and then I
> have to plot the developed matrix for indices 1, 2, 4, 7, 8, 9, 11. 12, 17
> and 22.
>
> I have been looking for information about how to process this with R, but
> have not found anything yet.
>
> The dataset is attached in this e-mail for your reference.
>
> Any help and/or guidance will be greatly appreciated.
>
> Best regards,
> Paul
>  train.csv
> <https://drive.google.com/file/d/1WPb7bKHJ8BlzuLKJogMOAOqb-VCoXDMp/view?usp=drive_web>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From p@u|bern@|07 @end|ng |rom gm@||@com  Thu Feb 24 18:09:58 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Thu, 24 Feb 2022 12:09:58 -0500
Subject: [R] Pixel Image Reshaping using R
In-Reply-To: <CAM_vjumSoQ6ZExKkxKL-4eJ171D+udBCKph0jgsThKmSMJXysQ@mail.gmail.com>
References: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
 <CAM_vjumSoQ6ZExKkxKL-4eJ171D+udBCKph0jgsThKmSMJXysQ@mail.gmail.com>
Message-ID: <CAMOcQfMWeoKGx0GQk=U7XY45cXoMFGM5yDvEWr=GEP_JuGBQqw@mail.gmail.com>

Thank you dear Sarah.

Have a great day!

El El jue, 24 de feb. de 2022 a la(s) 12:03 p. m., Sarah Goslee <
sarah.goslee at gmail.com> escribi?:

> Hi Paul,
>
> I may be missing something, but you can transform a vector to a matrix
> of any desired size by using matrix().
>
> For more nuanced processing of images, you might look into one of the
> many image processing packages in R, or even the raster package (or
> the newer terra).
>
> Sarah
>
> On Thu, Feb 24, 2022 at 11:00 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >
> > Dear friends,
> >
> > I apologize if the description is  a bit long, but I think that I need to
> > be as specific as possible so that you guys can help.
> >
> > I wil share with you a file (train.csv), which contains gray-scale images
> > of hand-drawn digits, from zero through 9.
> >
> > Each image is 28 pixels in height and 28 pixels in width, for a total of
> > 784 pixels in total. Each pixel has a single pixel-value associated with
> > it, indicating the lightness or darkness of that pixel, with higher
> numbers
> > meaning darker. This pixel-value is an integer between 0 and 255,
> > inclusive. The training data set, (train.csv), has 785 columns. The first
> > column, called ?label?, is the digit that was drawn by the user. The rest
> > of the columns contain the pixel-values of the associated image. Each
> pixel
> > column in the training set has a name like pixel x, where x is an integer
> > between 0 and 783, inclusive. To locate this pixel on the image, suppose
> > that we have decomposed x as x = i ? 28 + j, where i and j are integers
> > between 0 and 27, inclusive. Then pixel x is located on row i and column
> j
> > of a 28 x 28 matrix, (indexing by zero). or example, pixel 31 indicates
> the
> > pixel that is in the fourth column from the left, and the second row from
> > the top, as in the ascii-diagram below.
> >
> >   This data is set up in a csv file which will require the reshaping of
> the
> > data to be 28 ? 28 matrix representing images. There are 42000 images in
> > the train.csv file. For this problem it is only necessary to process
> > approximately 100 images, 10 each of the numbers from 0 through 9. The
> goal
> > is to learn how to generate features from images using transforms and
> first
> > order statistics.
> >
> > So I need to develop an algorithm to store the data in a data structure
> > such that the data is reshaped into a matrix of size 28 x 28 and then I
> > have to plot the developed matrix for indices 1, 2, 4, 7, 8, 9, 11. 12,
> 17
> > and 22.
> >
> > I have been looking for information about how to process this with R, but
> > have not found anything yet.
> >
> > The dataset is attached in this e-mail for your reference.
> >
> > Any help and/or guidance will be greatly appreciated.
> >
> > Best regards,
> > Paul
> >  train.csv
> > <
> https://drive.google.com/file/d/1WPb7bKHJ8BlzuLKJogMOAOqb-VCoXDMp/view?usp=drive_web
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.sarahgoslee.com
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Thu Feb 24 19:12:16 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Thu, 24 Feb 2022 13:12:16 -0500
Subject: [R] Pixel Image Reshaping using R
In-Reply-To: <20220224200013.4bd496df@Tarkus>
References: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
 <20220224200013.4bd496df@Tarkus>
Message-ID: <CAMOcQfPQRLitnwG-V1cJ++s91+MKiA=cU-nXvwyQ6FAz1TAnTg@mail.gmail.com>

Dear Ivan, this is what I did:

dataframe_train <- as.matrix((read.csv(file_path_2, header=TRUE,
stringsAsFactors = FALSE)))
dim(dataframe_train) <- c(28,28)
The file I read was the one I attached in the first email. Would this do
the work to reshape original dataset into a 28 x 28 matrix? When I print
the original dataframe I get the message: [ reached getOption("max.print")
-- omitted 41999 rows ] this only means that R will not pront the whole
data, but is not trimming anything right?

Best regards,
Paul


El jue, 24 feb 2022 a las 12:00, Ivan Krylov (<krylov.r00t at gmail.com>)
escribi?:

> On Thu, 24 Feb 2022 11:00:08 -0500
> Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> > Each pixel column in the training set has a name like pixel x, where
> > x is an integer between 0 and 783, inclusive. To locate this pixel on
> > the image, suppose that we have decomposed x as x = i ? 28 + j, where
> > i and j are integers between 0 and 27, inclusive.
>
> > I have been looking for information about how to process this with R,
> > but have not found anything yet.
>
> Given a 784-element vector x, you can reshape it into a 28 by 28 matrix:
>
> dim(x) <- c(28, 28)
>
> Or create a new matrix: matrix(x, 28, 28)
>
> Working with more dimensions is also possible. A matrix X with dim(X)
> == c(n, 784) can be transformed into a three-way array in place or
> copied into one:
>
> dim(X) <- c(dim(X)[1], 28, 28)
> array(X, c(dim(X)[1], 28, 28))
>
> (Replace 28,28 with 784 for an inverse transformation. In modern
> versions of R, two-way arrays are more or less the same as matrices,
> but old versions may disagree with that in some corner cases.)
>
> For more information, see ?dim, ?matrix, ?array.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Feb 24 19:25:43 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 24 Feb 2022 21:25:43 +0300
Subject: [R] Pixel Image Reshaping using R
In-Reply-To: <CAMOcQfPQRLitnwG-V1cJ++s91+MKiA=cU-nXvwyQ6FAz1TAnTg@mail.gmail.com>
References: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
 <20220224200013.4bd496df@Tarkus>
 <CAMOcQfPQRLitnwG-V1cJ++s91+MKiA=cU-nXvwyQ6FAz1TAnTg@mail.gmail.com>
Message-ID: <20220224212543.5225f01b@Tarkus>

On Thu, 24 Feb 2022 13:12:16 -0500
Paul Bernal <paulbernal07 at gmail.com> wrote:

> dataframe_train <- as.matrix((read.csv(file_path_2, header=TRUE,
> stringsAsFactors = FALSE)))

Have you removed the first column containing the labels?

> dim(dataframe_train) <- c(28,28)

This assumes that dataframe_train is a single 784-element vector.
Presumably, it's a whole matrix containing many such vectors as rows.

> Would this do the work to reshape original dataset into a 28 x 28
> matrix?

Probably not. Use image() to plot a matrix and check. Wouldn't you want
the original dataset to consist of many such matrices, that is, a
three-way array?

> When I print the original dataframe I get the message:
> [ reached getOption("max.print") -- omitted 41999 rows ] this only
> means that R will not pront the whole data, but is not trimming
> anything right?

That's right. Use str() to examine objects. Most of them (except long
and/or deeply nested lists) should produce shorter output that's easier
to understand.

-- 
Best regards,
Ivan


From p@u|bern@|07 @end|ng |rom gm@||@com  Thu Feb 24 19:31:09 2022
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Thu, 24 Feb 2022 13:31:09 -0500
Subject: [R] Pixel Image Reshaping using R
In-Reply-To: <20220224212543.5225f01b@Tarkus>
References: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
 <20220224200013.4bd496df@Tarkus>
 <CAMOcQfPQRLitnwG-V1cJ++s91+MKiA=cU-nXvwyQ6FAz1TAnTg@mail.gmail.com>
 <20220224212543.5225f01b@Tarkus>
Message-ID: <CAMOcQfOOCw0us0Y0AHEjADmBL0jQQOgMepveX0N6ROtM0SY+rw@mail.gmail.com>

Thank you Ivan. Basically, what I am being asked to do is to take the
train.csv dataset, and store it in a data structure so that the data can be
reshaped into a matrix of size 28 x 28, then I just need to print some
indices of that (e.g. index 1, 2, 4, 7,, etc.)

I basically tried the following:
dataframe_train <- array(read.csv(file_path_2, header=TRUE,
stringsAsFactors = FALSE), 28, 28)

then printing out several indices by doing (I know this could be done with
a for loop better but I tried this):

print(dataframe_train[1])
print(dataframe_train[2])
print(dataframe_train[4])
print(dataframe_train[7])
print(dataframe_train[8])
print(dataframe_train[9])
print(dataframe_train[11])
print(dataframe_train[12])
print(dataframe_train[17])
print(dataframe_train[22])

I am just unsure if I am achieving what is asked.

Best regards,
Paul


El jue, 24 feb 2022 a las 13:25, Ivan Krylov (<krylov.r00t at gmail.com>)
escribi?:

> On Thu, 24 Feb 2022 13:12:16 -0500
> Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> > dataframe_train <- as.matrix((read.csv(file_path_2, header=TRUE,
> > stringsAsFactors = FALSE)))
>
> Have you removed the first column containing the labels?
>
> > dim(dataframe_train) <- c(28,28)
>
> This assumes that dataframe_train is a single 784-element vector.
> Presumably, it's a whole matrix containing many such vectors as rows.
>
> > Would this do the work to reshape original dataset into a 28 x 28
> > matrix?
>
> Probably not. Use image() to plot a matrix and check. Wouldn't you want
> the original dataset to consist of many such matrices, that is, a
> three-way array?
>
> > When I print the original dataframe I get the message:
> > [ reached getOption("max.print") -- omitted 41999 rows ] this only
> > means that R will not pront the whole data, but is not trimming
> > anything right?
>
> That's right. Use str() to examine objects. Most of them (except long
> and/or deeply nested lists) should produce shorter output that's easier
> to understand.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Feb 24 19:50:49 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 24 Feb 2022 21:50:49 +0300
Subject: [R] Pixel Image Reshaping using R
In-Reply-To: <CAMOcQfOOCw0us0Y0AHEjADmBL0jQQOgMepveX0N6ROtM0SY+rw@mail.gmail.com>
References: <CAMOcQfOXmhvG82____nG43y-BubdF5hSNkA8+C9c7L6W86ANWQ@mail.gmail.com>
 <20220224200013.4bd496df@Tarkus>
 <CAMOcQfPQRLitnwG-V1cJ++s91+MKiA=cU-nXvwyQ6FAz1TAnTg@mail.gmail.com>
 <20220224212543.5225f01b@Tarkus>
 <CAMOcQfOOCw0us0Y0AHEjADmBL0jQQOgMepveX0N6ROtM0SY+rw@mail.gmail.com>
Message-ID: <20220224215049.07dc03c6@Tarkus>

On Thu, 24 Feb 2022 13:31:09 -0500
Paul Bernal <paulbernal07 at gmail.com> wrote:

> Basically, what I am being asked to do is to take the
> train.csv dataset, and store it in a data structure so that the data
> can be reshaped into a matrix of size 28 x 28, then I just need to
> print some indices of that (e.g. index 1, 2, 4, 7,, etc.)

Is this homework? It's considered a good idea to contact your
instructor with homework questions.

> dataframe_train <- array(read.csv(file_path_2, header=TRUE,
> stringsAsFactors = FALSE), 28, 28)

Almost there. Two problems left:

1. You did not remove the first column. R will do what is asked of it
and mix the labels with the pixel values. You will probably need to
subset the data frame that read.csv() returns to remove it before
reshaping the rest of it into a three-way array.

3. The dimensions of the array should be specified in a single
3-element vector: c(N, 28, 28). I don't think there's a convenient way
to do that in a single expression. Once you have your pixels in an N by
784 matrix, use c(nrow(your.matrix), 28, 28) to construct the
dimension vector.

> then printing out several indices by doing (I know this could be done
> with a for loop better but I tried this):

> print(dataframe_train[1])

That chooses the N'th pixel value from the whole array. The syntax to
extract whole slices of an array is different:
https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Array-indexing

-- 
Best regards,
Ivan


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Thu Feb 24 20:43:05 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Thu, 24 Feb 2022 13:43:05 -0600
Subject: [R] installation problem for a new package
Message-ID: <CAFy_oHAPm8wW0ZuwP1bwKWu42JDK_PgNsk74m0-LRY1+CCTSZg@mail.gmail.com>

Hello everyone,

I'm trying to install a package honestdid and following the commands of the
developer of that package

# Install some packages
library(devtools)
install_github("bcallaway11/BMisc", dependencies = TRUE)
install_github("bcallaway11/did", dependencies = TRUE)
install_github("asheshrambachan/HonestDiD", dependencies = TRUE)


But, the error message is saying:

* installing *source* package ?HonestDiD? ...
** using staged installation
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Error: package or namespace load failed for ?CVXR? in loadNamespace(j
<- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
 there is no package called ?gmp?
Error: package ?CVXR? could not be loaded
Execution halted
ERROR: lazy loading failed for package ?HonestDiD?
* removing ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/HonestDiD?
Warning messages:
1: In i.p(...) : installation of package ?gmp? had non-zero exit status
2: In i.p(...) :
  installation of package
?/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T//Rtmpk3pocK/file86e83034c58c/HonestDiD_0.2.0.tar.gz?
had non-zero exit status


Can anyone guide me why i'm having this issue? Thanks in advance !

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Feb 24 20:57:39 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 24 Feb 2022 22:57:39 +0300
Subject: [R] installation problem for a new package
In-Reply-To: <CAFy_oHAPm8wW0ZuwP1bwKWu42JDK_PgNsk74m0-LRY1+CCTSZg@mail.gmail.com>
References: <CAFy_oHAPm8wW0ZuwP1bwKWu42JDK_PgNsk74m0-LRY1+CCTSZg@mail.gmail.com>
Message-ID: <20220224225739.6e8505e0@Tarkus>

On Thu, 24 Feb 2022 13:43:05 -0600
Tariq Khasiri <tariqkhasiri at gmail.com> wrote:

> Error: package or namespace load failed for ?CVXR? in loadNamespace(j
> <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
>  there is no package called ?gmp?
> Error: package ?CVXR? could not be loaded

What exactly happens when you try to install the CVXR and gmp packages?
They are the dependencies preventing you from progressing further.

-- 
Best regards,
Ivan


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Feb 24 20:57:46 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 24 Feb 2022 11:57:46 -0800
Subject: [R] installation problem for a new package
In-Reply-To: <CAFy_oHAPm8wW0ZuwP1bwKWu42JDK_PgNsk74m0-LRY1+CCTSZg@mail.gmail.com>
References: <CAFy_oHAPm8wW0ZuwP1bwKWu42JDK_PgNsk74m0-LRY1+CCTSZg@mail.gmail.com>
Message-ID: <928D1777-F5C3-49CF-8D67-E245E202F206@dcn.davis.ca.us>

These messages seem relevant:

>Error: package ?CVXR? could not be loaded
>Warning messages:
>1: In i.p(...) : installation of package ?gmp? had non-zero exit status

You need to make sure these packages are installed successfully before the package you are interested will install.

Please don't send formatted email to this list ... as the Posting Guide indicates, the list is for plain text and others may receive a garbled version of what you sent it your email program is not configured properly.

On February 24, 2022 11:43:05 AM PST, Tariq Khasiri <tariqkhasiri at gmail.com> wrote:
>Hello everyone,
>
>I'm trying to install a package honestdid and following the commands of the
>developer of that package
>
># Install some packages
>library(devtools)
>install_github("bcallaway11/BMisc", dependencies = TRUE)
>install_github("bcallaway11/did", dependencies = TRUE)
>install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
>
>
>But, the error message is saying:
>
>* installing *source* package ?HonestDiD? ...
>** using staged installation
>** R
>** data
>*** moving datasets to lazyload DB
>** inst
>** byte-compile and prepare package for lazy loading
>Error: package or namespace load failed for ?CVXR? in loadNamespace(j
><- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
> there is no package called ?gmp?
>Error: package ?CVXR? could not be loaded
>Execution halted
>ERROR: lazy loading failed for package ?HonestDiD?
>* removing ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/HonestDiD?
>Warning messages:
>1: In i.p(...) : installation of package ?gmp? had non-zero exit status
>2: In i.p(...) :
>  installation of package
>?/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T//Rtmpk3pocK/file86e83034c58c/HonestDiD_0.2.0.tar.gz?
>had non-zero exit status
>
>
>Can anyone guide me why i'm having this issue? Thanks in advance !
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Feb 24 23:05:20 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 24 Feb 2022 14:05:20 -0800
Subject: [R] installation problem for a new package
In-Reply-To: <CAFy_oHBsN-kCVABwz3=-Z6h7CA_O4t8wYbt0hXcsBi38HBrSwQ@mail.gmail.com>
References: <CAFy_oHAPm8wW0ZuwP1bwKWu42JDK_PgNsk74m0-LRY1+CCTSZg@mail.gmail.com>
 <928D1777-F5C3-49CF-8D67-E245E202F206@dcn.davis.ca.us>
 <CAFy_oHBsN-kCVABwz3=-Z6h7CA_O4t8wYbt0hXcsBi38HBrSwQ@mail.gmail.com>
Message-ID: <24245A92-E1F7-4197-8AA3-44501668167B@dcn.davis.ca.us>

Do use "reply-all"... others may be able to respond more quickly or more accurately than I. I have re-introduced the mailing list to this reply.

For example, if you read [1] it says there is a system requirement that the completely separate gmp software be installed using your system software installation tools. I happen to be unfamiliar with the details of MacOS system administration, so I cannot offer useful guidance other than that you need to solve this and that there exists a mailing list dedicated to such MacOS-specific questions about R [2]. You can of course simply Google for similar threads or blogs about gmp on MacOS to find clues as well.

I will also add that there seem to be a variety of conditions that can cause the automatic dependency management features of install.packages() to fail, and in such cases it is normal to focus on installing the problematic dependent packages one at a time. This is particularly true in this case where there are requirements for the dependency beyond what R can deal with, so ignoring advice from those with more experience than yourself about focusing on the dependency separately is probably less productive than simply following that advice.

[1] https://cran.r-project.org/web/packages/gmp/index.html
[2] https://stat.ethz.ch/mailman/listinfo/r-sig-mac

On February 24, 2022 12:11:14 PM PST, Tariq Khasiri <tariqkhasiri at gmail.com> wrote:
>Will correct my formatting as you kindly suggested.
>
>I believe gmp and CVXR is not getting installed but with the dependencies,
>it's supposed to be installed as the package builder posted in his website.
>Therefore, I'm quite puzzled that do I need to install the other two
>packages separately or not?
>
>install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
>Downloading GitHub repo asheshrambachan/HonestDiD at HEAD
>Installing 1 packages: gmp
>
>  There is a binary version available but the source version is later:
>     binary source needs_compilation
>gmp 0.6-2.1  0.6-4              TRUE
>
>Do you want to install from sources the package which needs compilation?
>(Yes/no/cancel) yes
>installing the source package ?gmp?
>
>trying URL 'https://cran.rstudio.com/src/contrib/gmp_0.6-4.tar.gz'
>Content type 'application/x-gzip' length 163941 bytes (160 KB)
>==================================================
>downloaded 160 KB
>
>* installing *source* package ?gmp? ...
>** package ?gmp? successfully unpacked and MD5 sums checked
>** using staged installation
>checking for gcc... clang -mmacosx-version-min=10.13
>checking whether the C compiler works... yes
>checking for C compiler default output file name... a.out
>checking for suffix of executables...
>checking whether we are cross compiling... no
>checking for suffix of object files... o
>checking whether we are using the GNU C compiler... yes
>checking whether clang -mmacosx-version-min=10.13 accepts -g... yes
>checking for clang -mmacosx-version-min=10.13 option to accept ISO C89...
>none needed
>checking how to run the C preprocessor... clang -mmacosx-version-min=10.13
>-E
>checking whether we are using the GNU C++ compiler... yes
>checking whether clang++ -mmacosx-version-min=10.13 -std=gnu++14 accepts
>-g... yes
>checking for grep that handles long lines and -e... /usr/bin/grep
>checking for egrep... /usr/bin/grep -E
>checking for ANSI C header files... rm: conftest.dSYM: is a directory
>rm: conftest.dSYM: is a directory
>yes
>checking for sys/types.h... yes
>checking for sys/stat.h... yes
>checking for stdlib.h... yes
>checking for string.h... yes
>checking for memory.h... yes
>checking for strings.h... yes
>checking for inttypes.h... yes
>checking for stdint.h... yes
>checking for unistd.h... yes
>checking gmp.h usability... no
>checking gmp.h presence... no
>checking for gmp.h... no
>configure: error: Header file gmp.h not found; maybe use
>--with-gmp-include=INCLUDE_PATH
>ERROR: configuration failed for package ?gmp?
>* removing
>?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/gmp?
>
>The downloaded source packages are in
>?/private/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T/Rtmpk3pocK/downloaded_packages?
>?  checking for file
>?/private/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T/Rtmpk3pocK/remotes86e84daddc5e/asheshrambachan-HonestDiD-419f305/DESCRIPTION?
>...
>?  preparing ?HonestDiD?:
>?  checking DESCRIPTION meta-information ...
>?  checking for LF line-endings in source and make files and shell scripts
>?  checking for empty or unneeded directories
>?  building ?HonestDiD_0.2.0.tar.gz?
>
>* installing *source* package ?HonestDiD? ...
>** using staged installation
>** R
>** data
>*** moving datasets to lazyload DB
>** inst
>** byte-compile and prepare package for lazy loading
>Error: package or namespace load failed for ?CVXR? in loadNamespace(j <-
>i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
> there is no package called ?gmp?
>Error: package ?CVXR? could not be loaded
>Execution halted
>ERROR: lazy loading failed for package ?HonestDiD?
>* removing
>?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/HonestDiD?
>Warning messages:
>1: In i.p(...) : installation of package ?gmp? had non-zero exit status
>2: In i.p(...) :
>  installation of package
>?/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T//Rtmpk3pocK/file86e825657e7b/HonestDiD_0.2.0.tar.gz?
>had non-zero exit status
>
>
>
>
>On Thu, 24 Feb 2022 at 13:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> These messages seem relevant:
>>
>> >Error: package ?CVXR? could not be loaded
>> >Warning messages:
>> >1: In i.p(...) : installation of package ?gmp? had non-zero exit status
>>
>> You need to make sure these packages are installed successfully before the
>> package you are interested will install.
>>
>> Please don't send formatted email to this list ... as the Posting Guide
>> indicates, the list is for plain text and others may receive a garbled
>> version of what you sent it your email program is not configured properly.
>>
>> On February 24, 2022 11:43:05 AM PST, Tariq Khasiri <
>> tariqkhasiri at gmail.com> wrote:
>> >Hello everyone,
>> >
>> >I'm trying to install a package honestdid and following the commands of
>> the
>> >developer of that package
>> >
>> ># Install some packages
>> >library(devtools)
>> >install_github("bcallaway11/BMisc", dependencies = TRUE)
>> >install_github("bcallaway11/did", dependencies = TRUE)
>> >install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
>> >
>> >
>> >But, the error message is saying:
>> >
>> >* installing *source* package ?HonestDiD? ...
>> >** using staged installation
>> >** R
>> >** data
>> >*** moving datasets to lazyload DB
>> >** inst
>> >** byte-compile and prepare package for lazy loading
>> >Error: package or namespace load failed for ?CVXR? in loadNamespace(j
>> ><- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
>> > there is no package called ?gmp?
>> >Error: package ?CVXR? could not be loaded
>> >Execution halted
>> >ERROR: lazy loading failed for package ?HonestDiD?
>> >* removing
>> ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/HonestDiD?
>> >Warning messages:
>> >1: In i.p(...) : installation of package ?gmp? had non-zero exit status
>> >2: In i.p(...) :
>> >  installation of package
>>
>> >?/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T//Rtmpk3pocK/file86e83034c58c/HonestDiD_0.2.0.tar.gz?
>> >had non-zero exit status
>> >
>> >
>> >Can anyone guide me why i'm having this issue? Thanks in advance !
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Feb 25 00:01:32 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 24 Feb 2022 23:01:32 +0000 (UTC)
Subject: [R] R WORDLE tool concepts vary
References: <892517930.1168435.1645743692769.ref@mail.yahoo.com>
Message-ID: <892517930.1168435.1645743692769@mail.yahoo.com>

This forum often discusses different ways of looking at a problem that result in often very different R formulations. Many may be RIGHT in a sense but some clearly have tradeoffs or work only in limited circumstances or come from some limited way of thinking. Note this message got to be a bit long, so feel free to skip it.

With this in mind, I saw the following article mentioned on R-bloggers about a sort of helper function that can be used as a way to identify what your next possible moves might be in the popular new game called WORDLE. The following article explains it well if interested:

https://www.r-bloggers.com/2022/02/wordle-solve-wordle-with-r/

I am not sure who the author is and clearly you can solve the problem in many ways using many languages. I looked at the code they used to learn from it. It is fairly compact and depends on another package that is used to look up potential words to see if they exist.

  library(hunspell)
 
  black <- ""

  exclude <- function(local, global = black) {
    LETTERS[!LETTERS %in% c(local, global)]
  }

  wordle <- function(one, two, three, four, five, include = "") {
    words <- apply(expand.grid(one, two, three, four, five), 1, \(x) paste(x, collapse = ""))
    words <- words[grepl(paste0("(?=.*", include, ")", collapse = ""), words, perl = TRUE)]
    words[hunspell_check(words)]
  }

Rather than explaining everything again, each move in this game is a guess of a five letter word. The feedback is to tell you which letters in your guess are NOT in the word of the day and which, if any, are correct and in the right position and which are correct but in a wrong position. Based on the feedback, you try another 5-letter word that may illuminate you further. You get six tries. I do not generally need help and always guess it in no more than 4-5 and several times in 3 and once, weirdly, in 2 tries. But it can be helpful to get a list of what words remain potentially valid and thus this function.

In English, the code above accepts inputs that boil down to which of the 26 uppercase letters are allowed at this point in column ONE, and another set for two through five. It also uses info (one oddly kept in a global variable) that keep track of which letters are known not to be in the word at all as well as another holding those known to be there at least one time.

The first line can be translated into English:

  words <- apply(expand.grid(one, two, three, four, five), 1, \(x) paste(x, collapse = ""))

Basically it makes a potentially huge data.frame containing all combinations of words. Early in the game that may mean something in the neighborhood of 20 possible letters for as many as five positions which can mean creating a data.frame on the order of millions of rows. The five columns are then stitched together into the potentially millions of 5-letter strings. UGH!

The next line of code uses a regular expression to test that all letters KNOWN at that point to be in the answer MUST  be present and any other filtered out. 

  words <- words[grepl(paste0("(?=.*", include, ")", collapse = ""), words, perl = TRUE)]

Finally, the other package is asked to look up tons of remaining words and return those deemed to be TRUE words.

  words[hunspell_check(words)]

Although I appreciated the terseness of the code, I was appalled, especially at how long this ran at times. It seems too brute force! Why make all possible 5 letter words first, rather than select only 5 letter words that match a pattern?

My solution, in English, was to make a regular expression dynamically that looked like:

  "^[cond1][cond2][cond2][cond4][cond5]$"

With appropriate actual conditions, the above would match only five-letter words. If you said that that the first character was the letter "S" the condition was written as [S] and if you had a vector of possible letters like c("A", "E", "I", "O", "U") the condition would obviously be [AEIOU] and finally my version of the exclude function above added a caret symbol as in [^AEIOU] to mean the negation.

On top of that, why search the entire dictionary rather than one with just 5 letter words? On my machine, it searches a file called en_US.dic with 49,271 lines/words that also includes additional info on some words like:

  zucchini/MS
  zwieback/M

So the first thing I did was run the above code as if the game had just begun and saved the results in a character vector called dict. The length is down nicely to 6494 five-letter words. And the technique is now not to search the entire set of possible words potentially repeatedly in that larger framework, but to match one word at a time for a pattern and keep the results. This runs much quicker, even if the word list is now saved as a file. Here is my first attempt and I am wondering if this approach has positives or negatives I have not considered/


  ##### WORDLE checker

  ## Find available WORDLE words given stated conditions
  ## assuming "dict" has been already initialized to
  ## contain all legal five-letter words.

  ## Function to gather all possible letters to exclude,
  ## either because they cannot be in the current column
  ## or in any part of the word. The letters selected
  ## are preceded by the ^ symbol to mean negation later.

  xcl <- function(local, global = black) {
    lett <- paste0(c(local, global), collapse="")
    toupper(paste0("^", lett, sep=""))
  }

  ## Function to make a part of a regular expression containing
  ## the letters handed in between [] but note the first component
  ## will sometimes be a caret.

  re_prepare <- function(lettervec) {
    paste0("[", toupper(paste0(lettervec, collapse="")), "]", sep="")
  }

  ## Finally, a function that takes conditions describing what
  ## letters may be used (or not used) and more, and generates
  ## a regular expression that selects possible 5-letter words, 
  ## then removes any that do not have known letters and returns
  ## the result. Normally the result gets auto-printed unless diverted.

  wordle2 <- function(one="", two="", three="", four="", five="", include = "") {
    one.pat <- re_prepare(one)
    two.pat <- re_prepare(two)
    three.pat <- re_prepare(three)
    four.pat <- re_prepare(four)
    five.pat <- re_prepare(five)

    pat <- paste0("^", one.pat, two.pat, three.pat, four.pat, five.pat, "$", sep="")
    words <- grep(pat, dict, value=TRUE)
    words <- words[grepl(paste0("(?=.*", include, ")", collapse = ""), words, perl = TRUE)]
    return(words)
  }

Back to me. If I run the following:

  black <- c("O", "R", "A", "F", "L", "U", "T", "P")

  wordle2(
    one = "S",
    two = "W",
    three = "I",
    four = xcl("S"),
    five = "E",
   include = c( "E", "S", "W", "I")
  )

It generates:

  [1] "SWINE"

Of course this would be late in the game. Earlier you get many potential answers and it remains up to the player to use one that helps them solve the puzzle by gathering more data and then updating some of the above variables and calling wordle2 again.

I am SURE plenty of others looking at these two solutions, will find a way to do it yet another way, or automate other parts like asking you at the end of each round, what the results showed, and then updating the variables like the above so the next call is trivial!

What, I wonder, is the thinking process? The anonymous sharer of the first version clearly knew about the grep family of functions as they used it. But they may have relied on the concept of building on a dictionary checker and thus headed down another path. I used grep twice. But what about generality and expansion?

Has anyone made a WORDLE variation that does exactly 4 letters or perhaps 7 letters? The method used starts to fail if you need to create a data.frame with N columns containing as many as 26**N rows when N is a number like 7 and we are as high as 8 trillion rows! Brute force does not scale up well. And asking to search a dictionary with even a fraction of that many possible words could take hours or more. 

My solution just makes a slightly longer Regular Expression with seven components even using the standard dictionary. It is simple enough that I assume it aborts a possible match as soon as any of the letters viewed do not fit as there is no conditional nature to the expression so that it never tries multiple ways as it is anchored to the start (and end). The number of items it tries is limited to the size of the dictionary no matter how many letters long the words being looked for..

To end this monologue and invite discussion, I repeat that I am not suggesting anyone play WORDLE or create or use tools like this one. I am curious about ways people think and solve such problems. I am open to better ways.

Avi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Feb 25 00:38:36 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 24 Feb 2022 23:38:36 +0000
Subject: [R] installation problem for a new package
In-Reply-To: <24245A92-E1F7-4197-8AA3-44501668167B@dcn.davis.ca.us>
References: <CAFy_oHAPm8wW0ZuwP1bwKWu42JDK_PgNsk74m0-LRY1+CCTSZg@mail.gmail.com>
 <928D1777-F5C3-49CF-8D67-E245E202F206@dcn.davis.ca.us>
 <CAFy_oHBsN-kCVABwz3=-Z6h7CA_O4t8wYbt0hXcsBi38HBrSwQ@mail.gmail.com>
 <24245A92-E1F7-4197-8AA3-44501668167B@dcn.davis.ca.us>
Message-ID: <02e0b3f3-b750-25ee-f35f-36cbd186a1db@sapo.pt>

Hello,

When I tried to run the OP's code I too got the error about package 
VCXR. The solution was to run first


install.packages("CVXR")


This installs its dependency gmp.
Then run the 3 install_github and there was no problem, just a warning 
about package colorspace.

package ?colorspace? successfully unpacked and MD5 sums checked
Warning: cannot remove prior installation of package ?colorspace?
Warning: restored ?colorspace?

Anyway, it's true that when install.packages throws errors about 
dependencies the solution is invariably to install them one by one, 
which can be time consuming. In this case it wasn't

Hope this helps,

Rui Barradas


?s 22:05 de 24/02/2022, Jeff Newmiller escreveu:
> Do use "reply-all"... others may be able to respond more quickly or more accurately than I. I have re-introduced the mailing list to this reply.
> 
> For example, if you read [1] it says there is a system requirement that the completely separate gmp software be installed using your system software installation tools. I happen to be unfamiliar with the details of MacOS system administration, so I cannot offer useful guidance other than that you need to solve this and that there exists a mailing list dedicated to such MacOS-specific questions about R [2]. You can of course simply Google for similar threads or blogs about gmp on MacOS to find clues as well.
> 
> I will also add that there seem to be a variety of conditions that can cause the automatic dependency management features of install.packages() to fail, and in such cases it is normal to focus on installing the problematic dependent packages one at a time. This is particularly true in this case where there are requirements for the dependency beyond what R can deal with, so ignoring advice from those with more experience than yourself about focusing on the dependency separately is probably less productive than simply following that advice.
> 
> [1] https://cran.r-project.org/web/packages/gmp/index.html
> [2] https://stat.ethz.ch/mailman/listinfo/r-sig-mac
> 
> On February 24, 2022 12:11:14 PM PST, Tariq Khasiri <tariqkhasiri at gmail.com> wrote:
>> Will correct my formatting as you kindly suggested.
>>
>> I believe gmp and CVXR is not getting installed but with the dependencies,
>> it's supposed to be installed as the package builder posted in his website.
>> Therefore, I'm quite puzzled that do I need to install the other two
>> packages separately or not?
>>
>> install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
>> Downloading GitHub repo asheshrambachan/HonestDiD at HEAD
>> Installing 1 packages: gmp
>>
>>   There is a binary version available but the source version is later:
>>      binary source needs_compilation
>> gmp 0.6-2.1  0.6-4              TRUE
>>
>> Do you want to install from sources the package which needs compilation?
>> (Yes/no/cancel) yes
>> installing the source package ?gmp?
>>
>> trying URL 'https://cran.rstudio.com/src/contrib/gmp_0.6-4.tar.gz'
>> Content type 'application/x-gzip' length 163941 bytes (160 KB)
>> ==================================================
>> downloaded 160 KB
>>
>> * installing *source* package ?gmp? ...
>> ** package ?gmp? successfully unpacked and MD5 sums checked
>> ** using staged installation
>> checking for gcc... clang -mmacosx-version-min=10.13
>> checking whether the C compiler works... yes
>> checking for C compiler default output file name... a.out
>> checking for suffix of executables...
>> checking whether we are cross compiling... no
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether clang -mmacosx-version-min=10.13 accepts -g... yes
>> checking for clang -mmacosx-version-min=10.13 option to accept ISO C89...
>> none needed
>> checking how to run the C preprocessor... clang -mmacosx-version-min=10.13
>> -E
>> checking whether we are using the GNU C++ compiler... yes
>> checking whether clang++ -mmacosx-version-min=10.13 -std=gnu++14 accepts
>> -g... yes
>> checking for grep that handles long lines and -e... /usr/bin/grep
>> checking for egrep... /usr/bin/grep -E
>> checking for ANSI C header files... rm: conftest.dSYM: is a directory
>> rm: conftest.dSYM: is a directory
>> yes
>> checking for sys/types.h... yes
>> checking for sys/stat.h... yes
>> checking for stdlib.h... yes
>> checking for string.h... yes
>> checking for memory.h... yes
>> checking for strings.h... yes
>> checking for inttypes.h... yes
>> checking for stdint.h... yes
>> checking for unistd.h... yes
>> checking gmp.h usability... no
>> checking gmp.h presence... no
>> checking for gmp.h... no
>> configure: error: Header file gmp.h not found; maybe use
>> --with-gmp-include=INCLUDE_PATH
>> ERROR: configuration failed for package ?gmp?
>> * removing
>> ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/gmp?
>>
>> The downloaded source packages are in
>> ?/private/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T/Rtmpk3pocK/downloaded_packages?
>> ?  checking for file
>> ?/private/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T/Rtmpk3pocK/remotes86e84daddc5e/asheshrambachan-HonestDiD-419f305/DESCRIPTION?
>> ...
>> ?  preparing ?HonestDiD?:
>> ?  checking DESCRIPTION meta-information ...
>> ?  checking for LF line-endings in source and make files and shell scripts
>> ?  checking for empty or unneeded directories
>> ?  building ?HonestDiD_0.2.0.tar.gz?
>>
>> * installing *source* package ?HonestDiD? ...
>> ** using staged installation
>> ** R
>> ** data
>> *** moving datasets to lazyload DB
>> ** inst
>> ** byte-compile and prepare package for lazy loading
>> Error: package or namespace load failed for ?CVXR? in loadNamespace(j <-
>> i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
>> there is no package called ?gmp?
>> Error: package ?CVXR? could not be loaded
>> Execution halted
>> ERROR: lazy loading failed for package ?HonestDiD?
>> * removing
>> ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/HonestDiD?
>> Warning messages:
>> 1: In i.p(...) : installation of package ?gmp? had non-zero exit status
>> 2: In i.p(...) :
>>   installation of package
>> ?/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T//Rtmpk3pocK/file86e825657e7b/HonestDiD_0.2.0.tar.gz?
>> had non-zero exit status
>>
>>
>>
>>
>> On Thu, 24 Feb 2022 at 13:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> These messages seem relevant:
>>>
>>>> Error: package ?CVXR? could not be loaded
>>>> Warning messages:
>>>> 1: In i.p(...) : installation of package ?gmp? had non-zero exit status
>>>
>>> You need to make sure these packages are installed successfully before the
>>> package you are interested will install.
>>>
>>> Please don't send formatted email to this list ... as the Posting Guide
>>> indicates, the list is for plain text and others may receive a garbled
>>> version of what you sent it your email program is not configured properly.
>>>
>>> On February 24, 2022 11:43:05 AM PST, Tariq Khasiri <
>>> tariqkhasiri at gmail.com> wrote:
>>>> Hello everyone,
>>>>
>>>> I'm trying to install a package honestdid and following the commands of
>>> the
>>>> developer of that package
>>>>
>>>> # Install some packages
>>>> library(devtools)
>>>> install_github("bcallaway11/BMisc", dependencies = TRUE)
>>>> install_github("bcallaway11/did", dependencies = TRUE)
>>>> install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
>>>>
>>>>
>>>> But, the error message is saying:
>>>>
>>>> * installing *source* package ?HonestDiD? ...
>>>> ** using staged installation
>>>> ** R
>>>> ** data
>>>> *** moving datasets to lazyload DB
>>>> ** inst
>>>> ** byte-compile and prepare package for lazy loading
>>>> Error: package or namespace load failed for ?CVXR? in loadNamespace(j
>>>> <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
>>>> there is no package called ?gmp?
>>>> Error: package ?CVXR? could not be loaded
>>>> Execution halted
>>>> ERROR: lazy loading failed for package ?HonestDiD?
>>>> * removing
>>> ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/HonestDiD?
>>>> Warning messages:
>>>> 1: In i.p(...) : installation of package ?gmp? had non-zero exit status
>>>> 2: In i.p(...) :
>>>>   installation of package
>>>
>>>> ?/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T//Rtmpk3pocK/file86e83034c58c/HonestDiD_0.2.0.tar.gz?
>>>> had non-zero exit status
>>>>
>>>>
>>>> Can anyone guide me why i'm having this issue? Thanks in advance !
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Feb 25 18:40:07 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 25 Feb 2022 17:40:07 +0000 (UTC)
Subject: [R] features that go away and indirection
References: <1459159811.1303021.1645810807142.ref@mail.yahoo.com>
Message-ID: <1459159811.1303021.1645810807142@mail.yahoo.com>

I have had to do some things indirectly lately and keep finding ways to do them that seem to be deprecated. Searching the Internet with key words often gets you info that is out of date but may still work.

Yes, much of this happen with packages outside base R. in particular, I am wanting to do things like make multiple plots using the ggplot2 package while varying some of the parameters using character strings such as binding a feature to a specific column dynamically. I have created some rather odd ways to get it done but prefer doing.
 things in a more accepted and reproducible manner.

So, yes, I can find a set of functions meant to replace the aes() aesthetic constructor used in ggplot with aes_() or aes_string() but they are now deprecated in favor of a new set of selecting functions that may not be as useful elsewhere.

Can someone point me to info on how to interpolate things in standard R that can reliable convert some things into the right context?

As an example, if you have a data.frame mydf with columns called alpha/beta/gamma, the construct mydf$alpha works but if I set

x <- "alpha"

then mydf$x fails.

The answer for this scenario is to use the bracket operators as in:

mydf[x]
mydf[[x]

depending on whether you want a data.frame or a vector. Or the somewhat clunkier versions like:

`[`(mydf, x)
`[[`(mydf, x)

But the wonderful features of R an also be terribly frustrating when they seemingly work against you. I am talking about things like delayed evaluation. If I want to something seemingly simply like take a subset of the columns of a data.frame and plot each column as a new graph of some kind, how does one do it?

Assume you are in middle of a loop and the index variable is called "ind" and sequentially takes on the name of the columns you want.

One solution I have used is to make a modified copy of the data where there is always a new column made that has the data you want from the current "ind' column that has a fixed name like do_me and then the ggplot (or whatever) command has hardcoded the info to make a plot of do_me. The other strings that mention the name of the variable such as on an axis label, are easier to adjust. This solution can work but it seems forced and does not necessarily generalize well.

An even weirder solution is to use techniques to generate a little program section as a character string or written to a file and then execute it or source it. Again, it works well, especially if I use something like the glue package to interpolate needed things. But it just feels like much more work than is needed.

Again, this is not a problem specific to packages like the tidyverse for me. It is about making sure I can control what is interpolated into my code at the time of my choosing. Some packages come with all kinds of tools that allow various kinds of misdirection or indirection and in some contexts that is fine. As an example, there are accessory functions in the tidyverse that can be used to select columns dynamically as in starts_with("SMALL") or matches("^EXACTLY$") that might allow me to do things there but how do I get that functionality in middle of ggplot?

I know this is not a new issue and I have read widely and may already have seen some of the methods used such as using substitute() and parse() and others in some combination that may convert a string or variable containing a string into a "name' or other internal R structure. I am wondering if someone can point me in that direction.

Avi


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Fri Feb 25 18:50:58 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Fri, 25 Feb 2022 11:50:58 -0600
Subject: [R] installation problem for a new package
In-Reply-To: <02e0b3f3-b750-25ee-f35f-36cbd186a1db@sapo.pt>
References: <CAFy_oHAPm8wW0ZuwP1bwKWu42JDK_PgNsk74m0-LRY1+CCTSZg@mail.gmail.com>
 <928D1777-F5C3-49CF-8D67-E245E202F206@dcn.davis.ca.us>
 <CAFy_oHBsN-kCVABwz3=-Z6h7CA_O4t8wYbt0hXcsBi38HBrSwQ@mail.gmail.com>
 <24245A92-E1F7-4197-8AA3-44501668167B@dcn.davis.ca.us>
 <02e0b3f3-b750-25ee-f35f-36cbd186a1db@sapo.pt>
Message-ID: <CAFy_oHCVZWGwzDKdRSOLWVKmSOEK9bZj-mR2pj=+z-rrHM64MQ@mail.gmail.com>

Thanks to everyone for their kind and insightful feedback! After following
the instruction, I successfully install the package. Much obliged for your
time!



On Thu, 24 Feb 2022 at 17:38, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> When I tried to run the OP's code I too got the error about package
> VCXR. The solution was to run first
>
>
> install.packages("CVXR")
>
>
> This installs its dependency gmp.
> Then run the 3 install_github and there was no problem, just a warning
> about package colorspace.
>
> package ?colorspace? successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package ?colorspace?
> Warning: restored ?colorspace?
>
> Anyway, it's true that when install.packages throws errors about
> dependencies the solution is invariably to install them one by one,
> which can be time consuming. In this case it wasn't
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 22:05 de 24/02/2022, Jeff Newmiller escreveu:
> > Do use "reply-all"... others may be able to respond more quickly or more
> accurately than I. I have re-introduced the mailing list to this reply.
> >
> > For example, if you read [1] it says there is a system requirement that
> the completely separate gmp software be installed using your system
> software installation tools. I happen to be unfamiliar with the details of
> MacOS system administration, so I cannot offer useful guidance other than
> that you need to solve this and that there exists a mailing list dedicated
> to such MacOS-specific questions about R [2]. You can of course simply
> Google for similar threads or blogs about gmp on MacOS to find clues as
> well.
> >
> > I will also add that there seem to be a variety of conditions that can
> cause the automatic dependency management features of install.packages() to
> fail, and in such cases it is normal to focus on installing the problematic
> dependent packages one at a time. This is particularly true in this case
> where there are requirements for the dependency beyond what R can deal
> with, so ignoring advice from those with more experience than yourself
> about focusing on the dependency separately is probably less productive
> than simply following that advice.
> >
> > [1] https://cran.r-project.org/web/packages/gmp/index.html
> > [2] https://stat.ethz.ch/mailman/listinfo/r-sig-mac
> >
> > On February 24, 2022 12:11:14 PM PST, Tariq Khasiri <
> tariqkhasiri at gmail.com> wrote:
> >> Will correct my formatting as you kindly suggested.
> >>
> >> I believe gmp and CVXR is not getting installed but with the
> dependencies,
> >> it's supposed to be installed as the package builder posted in his
> website.
> >> Therefore, I'm quite puzzled that do I need to install the other two
> >> packages separately or not?
> >>
> >> install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
> >> Downloading GitHub repo asheshrambachan/HonestDiD at HEAD
> >> Installing 1 packages: gmp
> >>
> >>   There is a binary version available but the source version is later:
> >>      binary source needs_compilation
> >> gmp 0.6-2.1  0.6-4              TRUE
> >>
> >> Do you want to install from sources the package which needs compilation?
> >> (Yes/no/cancel) yes
> >> installing the source package ?gmp?
> >>
> >> trying URL 'https://cran.rstudio.com/src/contrib/gmp_0.6-4.tar.gz'
> >> Content type 'application/x-gzip' length 163941 bytes (160 KB)
> >> ==================================================
> >> downloaded 160 KB
> >>
> >> * installing *source* package ?gmp? ...
> >> ** package ?gmp? successfully unpacked and MD5 sums checked
> >> ** using staged installation
> >> checking for gcc... clang -mmacosx-version-min=10.13
> >> checking whether the C compiler works... yes
> >> checking for C compiler default output file name... a.out
> >> checking for suffix of executables...
> >> checking whether we are cross compiling... no
> >> checking for suffix of object files... o
> >> checking whether we are using the GNU C compiler... yes
> >> checking whether clang -mmacosx-version-min=10.13 accepts -g... yes
> >> checking for clang -mmacosx-version-min=10.13 option to accept ISO
> C89...
> >> none needed
> >> checking how to run the C preprocessor... clang
> -mmacosx-version-min=10.13
> >> -E
> >> checking whether we are using the GNU C++ compiler... yes
> >> checking whether clang++ -mmacosx-version-min=10.13 -std=gnu++14 accepts
> >> -g... yes
> >> checking for grep that handles long lines and -e... /usr/bin/grep
> >> checking for egrep... /usr/bin/grep -E
> >> checking for ANSI C header files... rm: conftest.dSYM: is a directory
> >> rm: conftest.dSYM: is a directory
> >> yes
> >> checking for sys/types.h... yes
> >> checking for sys/stat.h... yes
> >> checking for stdlib.h... yes
> >> checking for string.h... yes
> >> checking for memory.h... yes
> >> checking for strings.h... yes
> >> checking for inttypes.h... yes
> >> checking for stdint.h... yes
> >> checking for unistd.h... yes
> >> checking gmp.h usability... no
> >> checking gmp.h presence... no
> >> checking for gmp.h... no
> >> configure: error: Header file gmp.h not found; maybe use
> >> --with-gmp-include=INCLUDE_PATH
> >> ERROR: configuration failed for package ?gmp?
> >> * removing
> >> ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/gmp?
> >>
> >> The downloaded source packages are in
> >>
> ?/private/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T/Rtmpk3pocK/downloaded_packages?
> >> ?  checking for file
> >>
> ?/private/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T/Rtmpk3pocK/remotes86e84daddc5e/asheshrambachan-HonestDiD-419f305/DESCRIPTION?
> >> ...
> >> ?  preparing ?HonestDiD?:
> >> ?  checking DESCRIPTION meta-information ...
> >> ?  checking for LF line-endings in source and make files and shell
> scripts
> >> ?  checking for empty or unneeded directories
> >> ?  building ?HonestDiD_0.2.0.tar.gz?
> >>
> >> * installing *source* package ?HonestDiD? ...
> >> ** using staged installation
> >> ** R
> >> ** data
> >> *** moving datasets to lazyload DB
> >> ** inst
> >> ** byte-compile and prepare package for lazy loading
> >> Error: package or namespace load failed for ?CVXR? in loadNamespace(j <-
> >> i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
> >> there is no package called ?gmp?
> >> Error: package ?CVXR? could not be loaded
> >> Execution halted
> >> ERROR: lazy loading failed for package ?HonestDiD?
> >> * removing
> >>
> ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/HonestDiD?
> >> Warning messages:
> >> 1: In i.p(...) : installation of package ?gmp? had non-zero exit status
> >> 2: In i.p(...) :
> >>   installation of package
> >>
> ?/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T//Rtmpk3pocK/file86e825657e7b/HonestDiD_0.2.0.tar.gz?
> >> had non-zero exit status
> >>
> >>
> >>
> >>
> >> On Thu, 24 Feb 2022 at 13:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> >> wrote:
> >>
> >>> These messages seem relevant:
> >>>
> >>>> Error: package ?CVXR? could not be loaded
> >>>> Warning messages:
> >>>> 1: In i.p(...) : installation of package ?gmp? had non-zero exit
> status
> >>>
> >>> You need to make sure these packages are installed successfully before
> the
> >>> package you are interested will install.
> >>>
> >>> Please don't send formatted email to this list ... as the Posting Guide
> >>> indicates, the list is for plain text and others may receive a garbled
> >>> version of what you sent it your email program is not configured
> properly.
> >>>
> >>> On February 24, 2022 11:43:05 AM PST, Tariq Khasiri <
> >>> tariqkhasiri at gmail.com> wrote:
> >>>> Hello everyone,
> >>>>
> >>>> I'm trying to install a package honestdid and following the commands
> of
> >>> the
> >>>> developer of that package
> >>>>
> >>>> # Install some packages
> >>>> library(devtools)
> >>>> install_github("bcallaway11/BMisc", dependencies = TRUE)
> >>>> install_github("bcallaway11/did", dependencies = TRUE)
> >>>> install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
> >>>>
> >>>>
> >>>> But, the error message is saying:
> >>>>
> >>>> * installing *source* package ?HonestDiD? ...
> >>>> ** using staged installation
> >>>> ** R
> >>>> ** data
> >>>> *** moving datasets to lazyload DB
> >>>> ** inst
> >>>> ** byte-compile and prepare package for lazy loading
> >>>> Error: package or namespace load failed for ?CVXR? in loadNamespace(j
> >>>> <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
> >>>> there is no package called ?gmp?
> >>>> Error: package ?CVXR? could not be loaded
> >>>> Execution halted
> >>>> ERROR: lazy loading failed for package ?HonestDiD?
> >>>> * removing
> >>>
> ?/Library/Frameworks/R.framework/Versions/4.1/Resources/library/HonestDiD?
> >>>> Warning messages:
> >>>> 1: In i.p(...) : installation of package ?gmp? had non-zero exit
> status
> >>>> 2: In i.p(...) :
> >>>>   installation of package
> >>>
> >>>>
> ?/var/folders/4m/tvx9lnqs0rx6wgnysxz36vm00000gp/T//Rtmpk3pocK/file86e83034c58c/HonestDiD_0.2.0.tar.gz?
> >>>> had non-zero exit status
> >>>>
> >>>>
> >>>> Can anyone guide me why i'm having this issue? Thanks in advance !
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> --
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 25 18:59:10 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 25 Feb 2022 09:59:10 -0800
Subject: [R] features that go away and indirection
In-Reply-To: <1459159811.1303021.1645810807142@mail.yahoo.com>
References: <1459159811.1303021.1645810807142.ref@mail.yahoo.com>
 <1459159811.1303021.1645810807142@mail.yahoo.com>
Message-ID: <1625E945-7447-4961-9E2D-7338CDE0295A@dcn.davis.ca.us>

Your posts have recently become longer and less focused... which makes them challenging to engage with.

One thing that frustrates me with the effort to make all code use NSE is that it seems to entangle code and output constraints excessively. IMO formulating labels for plots should not be generally linked with the column names... depending on context, the same variable may represent different points of comparison.

With this in mind I make functions that build the plots I want to generate with different input data, and include parameters to replace column names in the plot labels. Then I make tables that define the appropriate tuples of source spec (column names) and output spec (labels) and call my functions one row at a time (usually but not always in a loop).

Which is not to say that it isn't convenient to use NSE in the middle of the work... just that when it comes to output functions I focus on the presentation needs and generally ignore presentation concerns in the middle of my analysis functions.

On February 25, 2022 9:40:07 AM PST, Avi Gross via R-help <r-help at r-project.org> wrote:
>I have had to do some things indirectly lately and keep finding ways to do them that seem to be deprecated. Searching the Internet with key words often gets you info that is out of date but may still work.
>
>Yes, much of this happen with packages outside base R. in particular, I am wanting to do things like make multiple plots using the ggplot2 package while varying some of the parameters using character strings such as binding a feature to a specific column dynamically. I have created some rather odd ways to get it done but prefer doing.
> things in a more accepted and reproducible manner.
>
>So, yes, I can find a set of functions meant to replace the aes() aesthetic constructor used in ggplot with aes_() or aes_string() but they are now deprecated in favor of a new set of selecting functions that may not be as useful elsewhere.
>
>Can someone point me to info on how to interpolate things in standard R that can reliable convert some things into the right context?
>
>As an example, if you have a data.frame mydf with columns called alpha/beta/gamma, the construct mydf$alpha works but if I set
>
>x <- "alpha"
>
>then mydf$x fails.
>
>The answer for this scenario is to use the bracket operators as in:
>
>mydf[x]
>mydf[[x]
>
>depending on whether you want a data.frame or a vector. Or the somewhat clunkier versions like:
>
>`[`(mydf, x)
>`[[`(mydf, x)
>
>But the wonderful features of R an also be terribly frustrating when they seemingly work against you. I am talking about things like delayed evaluation. If I want to something seemingly simply like take a subset of the columns of a data.frame and plot each column as a new graph of some kind, how does one do it?
>
>Assume you are in middle of a loop and the index variable is called "ind" and sequentially takes on the name of the columns you want.
>
>One solution I have used is to make a modified copy of the data where there is always a new column made that has the data you want from the current "ind' column that has a fixed name like do_me and then the ggplot (or whatever) command has hardcoded the info to make a plot of do_me. The other strings that mention the name of the variable such as on an axis label, are easier to adjust. This solution can work but it seems forced and does not necessarily generalize well.
>
>An even weirder solution is to use techniques to generate a little program section as a character string or written to a file and then execute it or source it. Again, it works well, especially if I use something like the glue package to interpolate needed things. But it just feels like much more work than is needed.
>
>Again, this is not a problem specific to packages like the tidyverse for me. It is about making sure I can control what is interpolated into my code at the time of my choosing. Some packages come with all kinds of tools that allow various kinds of misdirection or indirection and in some contexts that is fine. As an example, there are accessory functions in the tidyverse that can be used to select columns dynamically as in starts_with("SMALL") or matches("^EXACTLY$") that might allow me to do things there but how do I get that functionality in middle of ggplot?
>
>I know this is not a new issue and I have read widely and may already have seen some of the methods used such as using substitute() and parse() and others in some combination that may convert a string or variable containing a string into a "name' or other internal R structure. I am wondering if someone can point me in that direction.
>
>Avi
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Fri Feb 25 23:14:05 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Fri, 25 Feb 2022 16:14:05 -0600
Subject: [R] error as in unused argument of a new package
Message-ID: <CAFy_oHDu7-uYy-jAH4ezAF+4G-UcU1waQaxeez7f22Wf6F6wQg@mail.gmail.com>

# Install some packages
# you might have some issue installing the third package (honestdid) from
github. In that case, just don't select yes for update in case of the
honestdid package. Or you could install CRVXR package before running that
command .
library(devtools)
install_github("bcallaway11/BMisc", dependencies = TRUE)
install_github("bcallaway11/did", dependencies = TRUE)
install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
#--------------------------------------------------------------------------
# Load packages
#--------------------------------------------------------------------------
# Libraries
# Load libraries
library(ggplot2)
library(here)
library(foreign)
library(tidyverse)
library(dplyr)
library(did)
library(HonestDiD)

After installing the package I'm using the data used as in the creator of
the package (https://github.com/pedrohcgs/CS_RR). You can call it easily

min_wage <- readRDS((here("data",'min_wage_CS.rds')))

# Formula for covariates
xformla <- ~ region + (medinc + pop ) + I(pop^2) + I(medinc^2)  + white +
hs  + pov
#---------------------------------------------------------------------------
# Using covariates and DR DiD with never-treated as comparison group
# Fix the reference time periods
CS_never_cond <- did::att_gt(yname="lemp",
                             tname="year",
                             idname="countyreal",
                             gname="first.treat",
                             #xformla=~1,
                             xformla = xformla,
                             control_group="nevertreated",
                             data = min_wage,
                             panel = TRUE,
                             base_period="universal",
                             bstrap = TRUE,
                             cband = TRUE)

Unfortunately, its returing me the error that : Error in did::att_gt(yname
= "lemp", tname = "year", idname = "countyreal",  :
  unused argument (base_period = "universal")

since I've all the necessary packages and especially did package installed,
I shouldn't have the problem. Some suggestions will be highly appreciated.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 25 23:31:47 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 25 Feb 2022 14:31:47 -0800
Subject: [R] error as in unused argument of a new package
In-Reply-To: <CAFy_oHDu7-uYy-jAH4ezAF+4G-UcU1waQaxeez7f22Wf6F6wQg@mail.gmail.com>
References: <CAFy_oHDu7-uYy-jAH4ezAF+4G-UcU1waQaxeez7f22Wf6F6wQg@mail.gmail.com>
Message-ID: <868E7342-1F84-46CC-B436-33637544B8E3@dcn.davis.ca.us>

Communicate with the maintainer of that GitHub-distributed package... there is an "Issues" option in the GitHub repo. Also, read the Posting Guide linked below... formatted email interferes with us getting your message clearly, and this isn't a question about R... it is a question about that package.

On February 25, 2022 2:14:05 PM PST, Tariq Khasiri <tariqkhasiri at gmail.com> wrote:
># Install some packages
># you might have some issue installing the third package (honestdid) from
>github. In that case, just don't select yes for update in case of the
>honestdid package. Or you could install CRVXR package before running that
>command .
>library(devtools)
>install_github("bcallaway11/BMisc", dependencies = TRUE)
>install_github("bcallaway11/did", dependencies = TRUE)
>install_github("asheshrambachan/HonestDiD", dependencies = TRUE)
>#--------------------------------------------------------------------------
># Load packages
>#--------------------------------------------------------------------------
># Libraries
># Load libraries
>library(ggplot2)
>library(here)
>library(foreign)
>library(tidyverse)
>library(dplyr)
>library(did)
>library(HonestDiD)
>
>After installing the package I'm using the data used as in the creator of
>the package (https://github.com/pedrohcgs/CS_RR). You can call it easily
>
>min_wage <- readRDS((here("data",'min_wage_CS.rds')))
>
># Formula for covariates
>xformla <- ~ region + (medinc + pop ) + I(pop^2) + I(medinc^2)  + white +
>hs  + pov
>#---------------------------------------------------------------------------
># Using covariates and DR DiD with never-treated as comparison group
># Fix the reference time periods
>CS_never_cond <- did::att_gt(yname="lemp",
>                             tname="year",
>                             idname="countyreal",
>                             gname="first.treat",
>                             #xformla=~1,
>                             xformla = xformla,
>                             control_group="nevertreated",
>                             data = min_wage,
>                             panel = TRUE,
>                             base_period="universal",
>                             bstrap = TRUE,
>                             cband = TRUE)
>
>Unfortunately, its returing me the error that : Error in did::att_gt(yname
>= "lemp", tname = "year", idname = "countyreal",  :
>  unused argument (base_period = "universal")
>
>since I've all the necessary packages and especially did package installed,
>I shouldn't have the problem. Some suggestions will be highly appreciated.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Feb 26 08:57:46 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 26 Feb 2022 10:57:46 +0300
Subject: [R] error as in unused argument of a new package
In-Reply-To: <CAFy_oHDu7-uYy-jAH4ezAF+4G-UcU1waQaxeez7f22Wf6F6wQg@mail.gmail.com>
References: <CAFy_oHDu7-uYy-jAH4ezAF+4G-UcU1waQaxeez7f22Wf6F6wQg@mail.gmail.com>
Message-ID: <20220226105746.124a03b2@Tarkus>

On Fri, 25 Feb 2022 16:14:05 -0600
Tariq Khasiri <tariqkhasiri at gmail.com> wrote:

> CS_never_cond <- did::att_gt(yname="lemp",
>                              tname="year",
>                              idname="countyreal",
>                              gname="first.treat",
>                              #xformla=~1,
>                              xformla = xformla,
>                              control_group="nevertreated",
>                              data = min_wage,
>                              panel = TRUE,
>                              base_period="universal", # <-- here
>                              bstrap = TRUE,
>                              cband = TRUE)

> Error in did::att_gt(yname = "lemp", tname = "year", idname =
> "countyreal",  :
>  unused argument (base_period = "universal")

Does ?did::att_gt specify that the att_gt function accepts an
argument named "base_period" (marked by me with "# <-- here")?
If it does, it's a documentation error, contact maintainer('did') and
tell them about it. If it doesn't, you need to adjust your call to
did::att_gt to provide the correct arguments.

-- 
Best regards,
Ivan


From ekt@r@k @end|ng |rom gm@||@com  Sat Feb 26 07:59:34 2022
From: ekt@r@k @end|ng |rom gm@||@com (ektaraful)
Date: Sat, 26 Feb 2022 12:29:34 +0530
Subject: [R] Plot by month
Message-ID: <CANfs=fu+Oyu=mjqNa=YuAM9yX_bExRFG8FpeNZ550i46HyCXsg@mail.gmail.com>

Hi,

I want to plot temp data from a csv file by month. Can you help me how I
can do it in R?

A sample csv file is attached herewith. Please use left hand data.

Thanks.
ektaraK

From tebert @end|ng |rom u||@edu  Sat Feb 26 15:06:14 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sat, 26 Feb 2022 14:06:14 +0000
Subject: [R] Plot by month
In-Reply-To: <CANfs=fu+Oyu=mjqNa=YuAM9yX_bExRFG8FpeNZ550i46HyCXsg@mail.gmail.com>
References: <CANfs=fu+Oyu=mjqNa=YuAM9yX_bExRFG8FpeNZ550i46HyCXsg@mail.gmail.com>
Message-ID: <BN6PR2201MB1553A233321A229CC1E09FF0CF3F9@BN6PR2201MB1553.namprd22.prod.outlook.com>

I did not get the data .... but I was wondering what you have already tried.
Try group_by() function
Try fill= or color= in the aes() statement in ggplot.

What is the goal?
Do you want lines, bars, or dots?

Is this a class?

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of ektaraful
Sent: Saturday, February 26, 2022 2:00 AM
To: r-help at r-project.org
Subject: [R] Plot by month

[External Email]

Hi,

I want to plot temp data from a csv file by month. Can you help me how I can do it in R?

A sample csv file is attached herewith. Please use left hand data.

Thanks.
ektaraK
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=JeHylIm3ibHTYNZ-mLAAkF4JTrj_xyBnd0IQBZDJvV6HeovFeOLa5GwBe0LLBOwN&s=WJLtDEQ05d0kvlWFlrGCadjyBvwqCm_j37wsJ-CObyA&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=JeHylIm3ibHTYNZ-mLAAkF4JTrj_xyBnd0IQBZDJvV6HeovFeOLa5GwBe0LLBOwN&s=QyEPln_51yStVY2Ec1hcAqygLeEh1CNf5JJT_vv1dto&e=
and provide commented, minimal, self-contained, reproducible code.


From t@n@@@ @end|ng |rom gm@||@com  Fri Feb 25 01:14:49 2022
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 24 Feb 2022 16:14:49 -0800
Subject: [R] arrow keys in R
Message-ID: <CA+JEM00jv3Zw=eTyfEFzKQmMBbfJR6_GQmCUViw9phO6d2=QBg@mail.gmail.com>

In R, I do press the arrow keys, and 2 things happen :

On one hand, the symbols ^[[A^[[A^[[A appear;

On the other hand, shall I start typing a command, such as "library", I
begin by typing the first 2 letters "li", click "left arrow", and the
result is "li "(i.e. lots of spaces) instead of having the command
"library" written on the screen.

Is there any way to fix it please ? Thanks,

Bogdan

	[[alternative HTML version deleted]]


From t@n@@@ @end|ng |rom gm@||@com  Fri Feb 25 13:33:38 2022
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Fri, 25 Feb 2022 04:33:38 -0800
Subject: [R] saving png images and X11
Message-ID: <CA+JEM016yPZVOw98_xGhFE74+Pv9A6Gf-1u15B526p2RqDz8Mw@mail.gmail.com>

Dear all,

I am using a R package that renders the png images. As I am running the
command below in a script, I would like to avoid the error below and still
be able to save the images. How shall I do it ?

> ChIPQCreport(SAMPLE, +              reportName = paste(ENTRY, "ChIPQC", sep="."), +              reportFolder = paste(ENTRY, "ChIPQCreport", sep="."))
Saving 7 x 7 in image
Error in png_dev(..., res = dpi, units = "in") : X11 is not available

Shall I add the option :

options(bitmapType='cairo')

the png images are skipped and not saved on the disk. Thanks a lot,

Bogdan

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Feb 26 17:09:38 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 26 Feb 2022 08:09:38 -0800
Subject: [R] arrow keys in R
In-Reply-To: <CA+JEM00jv3Zw=eTyfEFzKQmMBbfJR6_GQmCUViw9phO6d2=QBg@mail.gmail.com>
References: <CA+JEM00jv3Zw=eTyfEFzKQmMBbfJR6_GQmCUViw9phO6d2=QBg@mail.gmail.com>
Message-ID: <BB22453C-C589-4B09-A518-33746D20C5CC@dcn.davis.ca.us>

Can you provide the output of sessionInfo()? And are you connected remotely?

On February 24, 2022 4:14:49 PM PST, Bogdan Tanasa <tanasa at gmail.com> wrote:
>In R, I do press the arrow keys, and 2 things happen :
>
>On one hand, the symbols ^[[A^[[A^[[A appear;
>
>On the other hand, shall I start typing a command, such as "library", I
>begin by typing the first 2 letters "li", click "left arrow", and the
>result is "li "(i.e. lots of spaces) instead of having the command
>"library" written on the screen.
>
>Is there any way to fix it please ? Thanks,
>
>Bogdan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Feb 26 17:14:13 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 26 Feb 2022 19:14:13 +0300
Subject: [R] arrow keys in R
In-Reply-To: <CA+JEM00jv3Zw=eTyfEFzKQmMBbfJR6_GQmCUViw9phO6d2=QBg@mail.gmail.com>
References: <CA+JEM00jv3Zw=eTyfEFzKQmMBbfJR6_GQmCUViw9phO6d2=QBg@mail.gmail.com>
Message-ID: <20220226191413.59b3dc85@Tarkus>

On Thu, 24 Feb 2022 16:14:49 -0800
Bogdan Tanasa <tanasa at gmail.com> wrote:

> On one hand, the symbols ^[[A^[[A^[[A appear;

> On the other hand, shall I start typing a command, such as "library",
> I begin by typing the first 2 letters "li", click "left arrow", and
> the result is "li "(i.e. lots of spaces) instead of having the command
> "library" written on the screen.

Did you mean Tab here? I.e. you type "libr", you press Tab, and R
autocompletes that to "library".

Sounds like readline and/or terminal problems. How was R compiled and
installed on this system? What terminal are you running R in, and is the
$TERM variable set correctly? Does the target system have the correct
termcap definitions for this terminal?

Perhaps https://cran.r-project.org/doc/manuals/r-release/R-admin.html
could be of some help to you.

-- 
Best regards,
Ivan


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Feb 26 17:18:21 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 26 Feb 2022 08:18:21 -0800
Subject: [R] saving png images and X11
In-Reply-To: <CA+JEM016yPZVOw98_xGhFE74+Pv9A6Gf-1u15B526p2RqDz8Mw@mail.gmail.com>
References: <CA+JEM016yPZVOw98_xGhFE74+Pv9A6Gf-1u15B526p2RqDz8Mw@mail.gmail.com>
Message-ID: <C10ACB9E-8EDA-47DA-90E0-EE3D10FD6E3A@dcn.davis.ca.us>

This is rather OS-dependent. You should read [1] and if if you need more help consider asking in one of the OS-specific mailing lists mentioned in the Posting Guide.

https://cran.r-project.org/doc/manuals/r-release/R-admin.html

On February 25, 2022 4:33:38 AM PST, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Dear all,
>
>I am using a R package that renders the png images. As I am running the
>command below in a script, I would like to avoid the error below and still
>be able to save the images. How shall I do it ?
>
>> ChIPQCreport(SAMPLE, +              reportName = paste(ENTRY, "ChIPQC", sep="."), +              reportFolder = paste(ENTRY, "ChIPQCreport", sep="."))
>Saving 7 x 7 in image
>Error in png_dev(..., res = dpi, units = "in") : X11 is not available
>
>Shall I add the option :
>
>options(bitmapType='cairo')
>
>the png images are skipped and not saved on the disk. Thanks a lot,
>
>Bogdan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Feb 26 17:19:00 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 26 Feb 2022 19:19:00 +0300
Subject: [R] saving png images and X11
In-Reply-To: <CA+JEM016yPZVOw98_xGhFE74+Pv9A6Gf-1u15B526p2RqDz8Mw@mail.gmail.com>
References: <CA+JEM016yPZVOw98_xGhFE74+Pv9A6Gf-1u15B526p2RqDz8Mw@mail.gmail.com>
Message-ID: <20220226191900.3d4ccd9c@Tarkus>

On Fri, 25 Feb 2022 04:33:38 -0800
Bogdan Tanasa <tanasa at gmail.com> wrote:

> Error in png_dev(..., res = dpi, units = "in") : X11 is not available
> 
> Shall I add the option :
> 
> options(bitmapType='cairo')
> 
> the png images are skipped and not saved on the disk.

Is this a question or a statement that png('file.png', type = 'cairo');
plot(1,1); dev.off() doesn't produce any files for you?

What's the output of capabilities() and sessionInfo() in this build of
R?

> 	[[alternative HTML version deleted]]

P.S. Please compose your messages in plain text. Since this mailing
list strips the HTML parts of your messages, we only get the plain text
part automatically produced by your mailer, some of it mangled quite a
bit.

-- 
Best regards,
Ivan


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Sat Feb 26 21:26:57 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Sat, 26 Feb 2022 14:26:57 -0600
Subject: [R] error as in unused argument of a new package
In-Reply-To: <20220226105746.124a03b2@Tarkus>
References: <CAFy_oHDu7-uYy-jAH4ezAF+4G-UcU1waQaxeez7f22Wf6F6wQg@mail.gmail.com>
 <20220226105746.124a03b2@Tarkus>
Message-ID: <CAFy_oHDh4f42fbYuEUQv_+j+Yhe1ZrN9JE24eVrxKn32f6SrPg@mail.gmail.com>

I took care of the issue by simply updating an already installed package.
Really appreciate for the valuable feedback from R community. Glad to have
such kind guidelines.

On Sat, Feb 26, 2022 at 1:57 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:

> On Fri, 25 Feb 2022 16:14:05 -0600
> Tariq Khasiri <tariqkhasiri at gmail.com> wrote:
>
> > CS_never_cond <- did::att_gt(yname="lemp",
> >                              tname="year",
> >                              idname="countyreal",
> >                              gname="first.treat",
> >                              #xformla=~1,
> >                              xformla = xformla,
> >                              control_group="nevertreated",
> >                              data = min_wage,
> >                              panel = TRUE,
> >                              base_period="universal", # <-- here
> >                              bstrap = TRUE,
> >                              cband = TRUE)
>
> > Error in did::att_gt(yname = "lemp", tname = "year", idname =
> > "countyreal",  :
> >  unused argument (base_period = "universal")
>
> Does ?did::att_gt specify that the att_gt function accepts an
> argument named "base_period" (marked by me with "# <-- here")?
> If it does, it's a documentation error, contact maintainer('did') and
> tell them about it. If it doesn't, you need to adjust your call to
> did::att_gt to provide the correct arguments.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Feb 26 22:43:29 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 27 Feb 2022 08:43:29 +1100
Subject: [R] saving png images and X11
In-Reply-To: <CA+JEM016yPZVOw98_xGhFE74+Pv9A6Gf-1u15B526p2RqDz8Mw@mail.gmail.com>
References: <CA+JEM016yPZVOw98_xGhFE74+Pv9A6Gf-1u15B526p2RqDz8Mw@mail.gmail.com>
Message-ID: <CA+8X3fVd4vtkeRKW3ZKpoGELpJyLdGuX+0NFKD4GzCnG-VkMnA@mail.gmail.com>

Hi Bogdan,
If we take the error message seriously, it may be that the initial X11
image was never displayed. When this very suspicious black box
function tried to transfer the image to a PNG file, it wasn't there or
the function couldn't find it.

Jim

On Sun, Feb 27, 2022 at 2:51 AM Bogdan Tanasa <tanasa at gmail.com> wrote:
>
> Dear all,
>
> I am using a R package that renders the png images. As I am running the
> command below in a script, I would like to avoid the error below and still
> be able to save the images. How shall I do it ?
>
> > ChIPQCreport(SAMPLE, +              reportName = paste(ENTRY, "ChIPQC", sep="."), +              reportFolder = paste(ENTRY, "ChIPQCreport", sep="."))
> Saving 7 x 7 in image
> Error in png_dev(..., res = dpi, units = "in") : X11 is not available
>
> Shall I add the option :
>
> options(bitmapType='cairo')
>
> the png images are skipped and not saved on the disk. Thanks a lot,
>
> Bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Sat Feb 26 22:44:14 2022
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 27 Feb 2022 10:44:14 +1300
Subject: [R] arrow keys in R
In-Reply-To: <CA+JEM00jv3Zw=eTyfEFzKQmMBbfJR6_GQmCUViw9phO6d2=QBg@mail.gmail.com>
References: <CA+JEM00jv3Zw=eTyfEFzKQmMBbfJR6_GQmCUViw9phO6d2=QBg@mail.gmail.com>
Message-ID: <CABcYAd+KHKpBjySoG1=mSoiTmwsKyuMYc2UcYsC7uEZd3LDRTw@mail.gmail.com>

You do not say anything about the operating system you are
using, about whether it was built with "readline" support
or not, whether you are calling R directly or through a
pseudo-tty or remotely through ssh or PuTty.

(1) ^[[A is simply an echo of the ANSI escape sequence for
the move-left terminal function.  This is exactly what you
would expect to see from a program that doesn't understand
escape sequences.
(2) You can tell whether R was built with "readline" support
by entering
> extSoftVersion()["readline"]
"7.0" is the answer I get.
(3) R-with-readline uses the "move left" terminal function
to MOVE LEFT within the line you
 are entering (and the "move
right" terminal function to move right, strange as it may seem).
It does not use the left arrow for completion.
That's the job of "tab".
(4) If I type "li<COMPLETE>" R (readline) beeps at me because
it does not know what character comes next.  If I type
"<COMPLETE>" again, it shows me a list of possibilities.
There are 17 of them.  If I type "lib<COMPLETE>" I get another
beep, and typing "<COMPLETE>" again shows me a list of 4
possibilities.  Typing "libr<COMPLETE>" gives me "library"
and *another* beep because there are still 3 possibilities.
(5) Once again, the <COMPLETE> key is Tab.



On Sun, 27 Feb 2022 at 04:51, Bogdan Tanasa <tanasa at gmail.com> wrote:

> In R, I do press the arrow keys, and 2 things happen :
>
> On one hand, the symbols ^[[A^[[A^[[A appear;
>
> On the other hand, shall I start typing a command, such as "library", I
> begin by typing the first 2 letters "li", click "left arrow", and the
> result is "li "(i.e. lots of spaces) instead of having the command
> "library" written on the screen.
>
> Is there any way to fix it please ? Thanks,
>
> Bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ho@@@|nmm @end|ng |rom jun|v@edu  Sat Feb 26 23:03:53 2022
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sat, 26 Feb 2022 22:03:53 +0000
Subject: [R] Plots not showing up in the RStudio plot pane
Message-ID: <CAO29qn4pOjGYtD6SjO9rDm_r4Yscf+fpgT3dpZSP5OkUoYKy+g@mail.gmail.com>

Dear R-experts,

I hope that you are doing well.

Whenever I use the plot command in RStudio, the plot is shown in a new
device window. I want the device to stay in the RStudio plot window in the
lower righthand corner.

I have tried in the following way.

1. I have used the dev.off() command. It just closes the window but when I
use the plot command then a new window opened again.
2. Tools->Global options->R Mark down In that phase select "window" from
that list in the "show output preview in:" then apply.
3. Tools > Global Options > Pane Layout, "Plots" is checked.
4. Update the RStudio.

However, still have the same problem.

I would be happy if anyone has any help to solve it.
Thanks in advance.

Hossain
-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342, Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *[image: Google Scholar]
<https://scholar.google.com/citations?hl=en&user=-U03XCgAAAAJ>* | *ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>* | *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Feb 26 23:30:35 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 26 Feb 2022 14:30:35 -0800
Subject: [R] Plots not showing up in the RStudio plot pane
In-Reply-To: <CAO29qn4pOjGYtD6SjO9rDm_r4Yscf+fpgT3dpZSP5OkUoYKy+g@mail.gmail.com>
References: <CAO29qn4pOjGYtD6SjO9rDm_r4Yscf+fpgT3dpZSP5OkUoYKy+g@mail.gmail.com>
Message-ID: <0E3327C1-DAE7-4FC6-822D-73E1DE7C2E34@dcn.davis.ca.us>

This mailing list is about R, not RStudio [1]. RStudio normally sets up the default graphics device to be their IDE device, but details as to why that behavior may be broken for you wouldn't normally be discussed here.

FWIW if you are using some contributed package it may bypass the default graphics device setting... but you have not provided a reproducible example so no one else could know if that could be the problem.

You may also have a `.Rprofile` R file in your home directory with some commands in it that could mess with your settings.

[1] https://community.rstudio.com/

On February 26, 2022 2:03:53 PM PST, "Md. Moyazzem Hossain" <hossainmm at juniv.edu> wrote:
>Dear R-experts,
>
>I hope that you are doing well.
>
>Whenever I use the plot command in RStudio, the plot is shown in a new
>device window. I want the device to stay in the RStudio plot window in the
>lower righthand corner.
>
>I have tried in the following way.
>
>1. I have used the dev.off() command. It just closes the window but when I
>use the plot command then a new window opened again.
>2. Tools->Global options->R Mark down In that phase select "window" from
>that list in the "show output preview in:" then apply.
>3. Tools > Global Options > Pane Layout, "Plots" is checked.
>4. Update the RStudio.
>
>However, still have the same problem.
>
>I would be happy if anyone has any help to solve it.
>Thanks in advance.
>
>Hossain

-- 
Sent from my phone. Please excuse my brevity.


From m@k|@we @end|ng |rom gm@||@com  Sun Feb 27 13:36:37 2022
From: m@k|@we @end|ng |rom gm@||@com (Edjabou Vincent)
Date: Sun, 27 Feb 2022 13:36:37 +0100
Subject: [R] Plots not showing up in the RStudio plot pane
In-Reply-To: <CAO29qn4pOjGYtD6SjO9rDm_r4Yscf+fpgT3dpZSP5OkUoYKy+g@mail.gmail.com>
References: <CAO29qn4pOjGYtD6SjO9rDm_r4Yscf+fpgT3dpZSP5OkUoYKy+g@mail.gmail.com>
Message-ID: <CALFkoEr3GoCPRPsuohs7juh4vVFFY0Xn8Kp87f7V6X-wztjSPw@mail.gmail.com>

Hej
Try maybe: dev.off() before plotting.
Regards,

Vincent Edjabou
Mobile: +45 31 95 99 33
linkedin.com/vincent
<http://linkedin.com/in/vincent-maklawe-edjabou-9742a41b>

Orcid: 0000-0003-2849-6151



On Sat, Feb 26, 2022 at 11:04 PM Md. Moyazzem Hossain <hossainmm at juniv.edu>
wrote:

> Dear R-experts,
>
> I hope that you are doing well.
>
> Whenever I use the plot command in RStudio, the plot is shown in a new
> device window. I want the device to stay in the RStudio plot window in the
> lower righthand corner.
>
> I have tried in the following way.
>
> 1. I have used the dev.off() command. It just closes the window but when I
> use the plot command then a new window opened again.
> 2. Tools->Global options->R Mark down In that phase select "window" from
> that list in the "show output preview in:" then apply.
> 3. Tools > Global Options > Pane Layout, "Plots" is checked.
> 4. Update the RStudio.
>
> However, still have the same problem.
>
> I would be happy if anyone has any help to solve it.
> Thanks in advance.
>
> Hossain
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342, Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: *[image: Google Scholar]
> <https://scholar.google.com/citations?hl=en&user=-U03XCgAAAAJ>* |
> *ResearchGate
> <https://www.researchgate.net/profile/Md_Hossain107>* | *ORCID iD
> <https://orcid.org/0000-0003-3593-6936>*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ho@@@|nmm @end|ng |rom jun|v@edu  Sun Feb 27 14:08:33 2022
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sun, 27 Feb 2022 13:08:33 +0000
Subject: [R] Plots not showing up in the RStudio plot pane
In-Reply-To: <CALFkoEr3GoCPRPsuohs7juh4vVFFY0Xn8Kp87f7V6X-wztjSPw@mail.gmail.com>
References: <CAO29qn4pOjGYtD6SjO9rDm_r4Yscf+fpgT3dpZSP5OkUoYKy+g@mail.gmail.com>
 <CALFkoEr3GoCPRPsuohs7juh4vVFFY0Xn8Kp87f7V6X-wztjSPw@mail.gmail.com>
Message-ID: <CAO29qn7+TdVdrmegOJ60y0GDeBiFQJSqYq8Gw=B0wUayq5Fb9g@mail.gmail.com>

Dear Vincent Edjabou

Thank you very much. I already tried it several times but not worked.

Take care.

Hossain

On Sun, Feb 27, 2022 at 12:36 PM Edjabou Vincent <maklawe at gmail.com> wrote:

> Hej
> Try maybe: dev.off() before plotting.
> Regards,
>
> Vincent Edjabou
> Mobile: +45 31 95 99 33
> linkedin.com/vincent
> <http://linkedin.com/in/vincent-maklawe-edjabou-9742a41b>
>
> Orcid: 0000-0003-2849-6151
>
>
>
> On Sat, Feb 26, 2022 at 11:04 PM Md. Moyazzem Hossain <hossainmm at juniv.edu>
> wrote:
>
>> Dear R-experts,
>>
>> I hope that you are doing well.
>>
>> Whenever I use the plot command in RStudio, the plot is shown in a new
>> device window. I want the device to stay in the RStudio plot window in the
>> lower righthand corner.
>>
>> I have tried in the following way.
>>
>> 1. I have used the dev.off() command. It just closes the window but when I
>> use the plot command then a new window opened again.
>> 2. Tools->Global options->R Mark down In that phase select "window" from
>> that list in the "show output preview in:" then apply.
>> 3. Tools > Global Options > Pane Layout, "Plots" is checked.
>> 4. Update the RStudio.
>>
>> However, still have the same problem.
>>
>> I would be happy if anyone has any help to solve it.
>> Thanks in advance.
>>
>> Hossain
>> --
>> Best Regards,
>> Md. Moyazzem Hossain
>> Associate Professor
>> Department of Statistics
>> Jahangirnagar University
>> Savar, Dhaka-1342, Bangladesh
>> Website: http://www.juniv.edu/teachers/hossainmm
>> Research: *[image: Google Scholar]
>> <https://scholar.google.com/citations?hl=en&user=-U03XCgAAAAJ>* |
>> *ResearchGate
>> <https://www.researchgate.net/profile/Md_Hossain107>* | *ORCID iD
>> <https://orcid.org/0000-0003-3593-6936>*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342, Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *[image: Google Scholar]
<https://scholar.google.com/citations?hl=en&user=-U03XCgAAAAJ>* | *ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>* | *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From ho@@@|nmm @end|ng |rom jun|v@edu  Sun Feb 27 14:09:27 2022
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sun, 27 Feb 2022 13:09:27 +0000
Subject: [R] Plots not showing up in the RStudio plot pane
In-Reply-To: <0E3327C1-DAE7-4FC6-822D-73E1DE7C2E34@dcn.davis.ca.us>
References: <CAO29qn4pOjGYtD6SjO9rDm_r4Yscf+fpgT3dpZSP5OkUoYKy+g@mail.gmail.com>
 <0E3327C1-DAE7-4FC6-822D-73E1DE7C2E34@dcn.davis.ca.us>
Message-ID: <CAO29qn7BdM76iuxQ08fUyfuKxPshXiXNVoEO9YFZDL-qkakYEQ@mail.gmail.com>

Dear Jeff Newmiller

Thank you very much for your reply.

Take care.

Hossain


On Sat, Feb 26, 2022 at 10:30 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This mailing list is about R, not RStudio [1]. RStudio normally sets up
> the default graphics device to be their IDE device, but details as to why
> that behavior may be broken for you wouldn't normally be discussed here.
>
> FWIW if you are using some contributed package it may bypass the default
> graphics device setting... but you have not provided a reproducible example
> so no one else could know if that could be the problem.
>
> You may also have a `.Rprofile` R file in your home directory with some
> commands in it that could mess with your settings.
>
> [1] https://community.rstudio.com/
>
> On February 26, 2022 2:03:53 PM PST, "Md. Moyazzem Hossain" <
> hossainmm at juniv.edu> wrote:
> >Dear R-experts,
> >
> >I hope that you are doing well.
> >
> >Whenever I use the plot command in RStudio, the plot is shown in a new
> >device window. I want the device to stay in the RStudio plot window in the
> >lower righthand corner.
> >
> >I have tried in the following way.
> >
> >1. I have used the dev.off() command. It just closes the window but when I
> >use the plot command then a new window opened again.
> >2. Tools->Global options->R Mark down In that phase select "window" from
> >that list in the "show output preview in:" then apply.
> >3. Tools > Global Options > Pane Layout, "Plots" is checked.
> >4. Update the RStudio.
> >
> >However, still have the same problem.
> >
> >I would be happy if anyone has any help to solve it.
> >Thanks in advance.
> >
> >Hossain
>
> --
> Sent from my phone. Please excuse my brevity.
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342, Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *[image: Google Scholar]
<https://scholar.google.com/citations?hl=en&user=-U03XCgAAAAJ>* | *ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>* | *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Sun Feb 27 20:34:33 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 27 Feb 2022 19:34:33 +0000 (UTC)
Subject: [R] tidying up
References: <336709036.1577552.1645990473450.ref@mail.yahoo.com>
Message-ID: <336709036.1577552.1645990473450@mail.yahoo.com>

This mailing list seems to steadily get messages that some see as not relevant to this forum. In particular, some see it as wrong to bring up some things here and keep reminding people of some ground rules.

So I want to know, briefly, if it is reasonable to ask a person with a question or problem to reproduce their problem another way. If using RSTUDIO or one of many IDE, can they run the code on a naked R interpreter by sourcing the file or copying it in or typing it anew, or perhaps using IDLE which comes by default with many installations of R? If using a library (which I like so I am not really in agreement about the unsuitability) like the tidyverse which is free and available to all even if loosely associated with the RSTUDIO folks and that can be run on any version of R that I am aware of, then some questions may still be fair if they are really about more general R issues as much of the rest of the code may be base R and may be the cause of whatever issue is being reported. And, some simple requests like pointing out a missing comma, ...

I have stated my thought before and it boils down to the reality that there are some things about earlier versions of R that were far from perfect or complete and a little healthy competition is not a bad thing and may help base R evolve. Not everything in the tidyverse is better and it keeps evolving and deprecating older features, but it cannot really be ignored any longer. If you apply for a job at some company as something of an R expert, you may well be asked by all kinds of people about their programs that use the tidyverse for help or to help them solve a problem. You don't have to like it, but if you cannot read it, you no longer are really qualified in many places.

Ask yourself if a language like R was created from scratch, what graphics might be built into the base distribution? Would you rather have lattice or ggplot or perhaps both as well as base R graphics? Would you make many of the built-in functions more consistent, so for instance, the data being worked on would be the first argument whenever possible? 

One reason there are so many packages is not so much due to the superiority of R but because people find it lacks quite a bit. Much of that should not be included, of course, if R is meant to be somewhat on the lean side, and yes, packages are a deliberate way to extend it when needed. But when people use it and think they are programming in R, ...


From drj|m|emon @end|ng |rom gm@||@com  Sun Feb 27 22:39:22 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 28 Feb 2022 08:39:22 +1100
Subject: [R] Plot by month
In-Reply-To: <BN6PR2201MB1553A233321A229CC1E09FF0CF3F9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CANfs=fu+Oyu=mjqNa=YuAM9yX_bExRFG8FpeNZ550i46HyCXsg@mail.gmail.com>
 <BN6PR2201MB1553A233321A229CC1E09FF0CF3F9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CA+8X3fWYsroxkUatUtks8Pk5875_a4nzobVVVnsSLHek=F6XyA@mail.gmail.com>

Hi ektaraK,
Here is a step by step way to create an example and get your plot:

# make up a lot of dates
dates<-as.Date("2021-1-1")+sample(0:364,100)
# make up the temperatures
temps<-runif(100,0,40)
# create a data frame
mydf<-data.frame(date=dates,temp=temps)
# create a month variable
mydf$month<-factor(format(mydf$date,"%b"),levels=month.abb)
# calculate mean temperature for months
temp_x_month<-by(mydf$temp,mydf$month,mean)
# create a factor of the months of the year for plotting
months<-factor(month.abb,levels=month.abb)
# plot mean temperature by month
plot(months,temp_x_month,main="Mean temperature by month")

You may only need to apply the last three steps to your data.

Jim

On Sun, Feb 27, 2022 at 1:07 AM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>
> I did not get the data .... but I was wondering what you have already tried.
> Try group_by() function
> Try fill= or color= in the aes() statement in ggplot.
>
> What is the goal?
> Do you want lines, bars, or dots?
>
> Is this a class?
>
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of ektaraful
> Sent: Saturday, February 26, 2022 2:00 AM
> To: r-help at r-project.org
> Subject: [R] Plot by month
>
> [External Email]
>
> Hi,
>
> I want to plot temp data from a csv file by month. Can you help me how I can do it in R?
>
> A sample csv file is attached herewith. Please use left hand data.
>
> Thanks.
> ektaraK
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=JeHylIm3ibHTYNZ-mLAAkF4JTrj_xyBnd0IQBZDJvV6HeovFeOLa5GwBe0LLBOwN&s=WJLtDEQ05d0kvlWFlrGCadjyBvwqCm_j37wsJ-CObyA&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwICAg&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=JeHylIm3ibHTYNZ-mLAAkF4JTrj_xyBnd0IQBZDJvV6HeovFeOLa5GwBe0LLBOwN&s=QyEPln_51yStVY2Ec1hcAqygLeEh1CNf5JJT_vv1dto&e=
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sun Feb 27 22:52:39 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 28 Feb 2022 08:52:39 +1100
Subject: [R] tidying up
In-Reply-To: <336709036.1577552.1645990473450@mail.yahoo.com>
References: <336709036.1577552.1645990473450.ref@mail.yahoo.com>
 <336709036.1577552.1645990473450@mail.yahoo.com>
Message-ID: <CA+8X3fWAPtZ9XYmCkiq+P4EEV1Crh0VZG9v9wFc2adKG0902KQ@mail.gmail.com>

Hi Avi,
I just sent in an answer to a very simple question. In many cases it
seems to me that the real problem isn't apparent from the request.
ektaraK appears to have almost no experience with R (sorry if I'm
wrong). A person in this position may sort of know what they want to
do but do not know how to ask the question. What's a reproducible
example? So I often submit really dumb looking answers that show the
person how to ask the question. If I'm successful, the OP learns how
to do some basic operation, but also learns how to ask the next
question. Until they get there, most responses just give them a typing
exercise.

Jim

On Mon, Feb 28, 2022 at 6:35 AM Avi Gross via R-help
<r-help at r-project.org> wrote:
>
> This mailing list seems to steadily get messages that some see as not relevant to this forum. In particular, some see it as wrong to bring up some things here and keep reminding people of some ground rules.
>
> So I want to know, briefly, if it is reasonable to ask a person with a question or problem to reproduce their problem another way. If using RSTUDIO or one of many IDE, can they run the code on a naked R interpreter by sourcing the file or copying it in or typing it anew, or perhaps using IDLE which comes by default with many installations of R? If using a library (which I like so I am not really in agreement about the unsuitability) like the tidyverse which is free and available to all even if loosely associated with the RSTUDIO folks and that can be run on any version of R that I am aware of, then some questions may still be fair if they are really about more general R issues as much of the rest of the code may be base R and may be the cause of whatever issue is being reported. And, some simple requests like pointing out a missing comma, ...
>
> I have stated my thought before and it boils down to the reality that there are some things about earlier versions of R that were far from perfect or complete and a little healthy competition is not a bad thing and may help base R evolve. Not everything in the tidyverse is better and it keeps evolving and deprecating older features, but it cannot really be ignored any longer. If you apply for a job at some company as something of an R expert, you may well be asked by all kinds of people about their programs that use the tidyverse for help or to help them solve a problem. You don't have to like it, but if you cannot read it, you no longer are really qualified in many places.
>
> Ask yourself if a language like R was created from scratch, what graphics might be built into the base distribution? Would you rather have lattice or ggplot or perhaps both as well as base R graphics? Would you make many of the built-in functions more consistent, so for instance, the data being worked on would be the first argument whenever possible?
>
> One reason there are so many packages is not so much due to the superiority of R but because people find it lacks quite a bit. Much of that should not be included, of course, if R is meant to be somewhat on the lean side, and yes, packages are a deliberate way to extend it when needed. But when people use it and think they are programming in R, ...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Sun Feb 27 22:59:41 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 27 Feb 2022 21:59:41 +0000 (UTC)
Subject: [R] tidying up
In-Reply-To: <CA+8X3fWAPtZ9XYmCkiq+P4EEV1Crh0VZG9v9wFc2adKG0902KQ@mail.gmail.com>
References: <336709036.1577552.1645990473450.ref@mail.yahoo.com>
 <336709036.1577552.1645990473450@mail.yahoo.com>
 <CA+8X3fWAPtZ9XYmCkiq+P4EEV1Crh0VZG9v9wFc2adKG0902KQ@mail.gmail.com>
Message-ID: <1182161945.1594668.1645999181069@mail.yahoo.com>

Indeed, Jim, the hopeful purpose of interactions here is to help people without doing the job for them. As you note, sometimes it is help in getting them to formulate what they are trying to do and maybe see the resolution on their own, or give enough info that others can troubleshoot.

I have dealt with people on and off forums like this who know very little and have done some rudimentary search and found something they hope is helpful and then get stuck. Some have no actual interest in learning R or Python or anything and see it as a one-time thing. For them, any sustained interaction is just frustrating. Others may want a tutor, albeit mahy of us here are not willing or able to provide endless hours to volunteer. And some, may be better off spending the money to hire someone and I assume there are places they can be directed.




-----Original Message-----
From: Jim Lemon <drjimlemon at gmail.com>
To: Avi Gross <avigross at verizon.net>
Cc: r-help at r-project.org <r-help at r-project.org>
Sent: Sun, Feb 27, 2022 4:52 pm
Subject: Re: [R] tidying up


Hi Avi,
I just sent in an answer to a very simple question. In many cases it
seems to me that the real problem isn't apparent from the request.
ektaraK appears to have almost no experience with R (sorry if I'm
wrong). A person in this position may sort of know what they want to
do but do not know how to ask the question. What's a reproducible
example? So I often submit really dumb looking answers that show the
person how to ask the question. If I'm successful, the OP learns how
to do some basic operation, but also learns how to ask the next
question. Until they get there, most responses just give them a typing
exercise.

Jim


On Mon, Feb 28, 2022 at 6:35 AM Avi Gross via R-help
<r-help at r-project.org> wrote:
>
> This mailing list seems to steadily get messages that some see as not relevant to this forum. In particular, some see it as wrong to bring up some things here and keep reminding people of some ground rules.
>
> So I want to know, briefly, if it is reasonable to ask a person with a question or problem to reproduce their problem another way. If using RSTUDIO or one of many IDE, can they run the code on a naked R interpreter by sourcing the file or copying it in or typing it anew, or perhaps using IDLE which comes by default with many installations of R? If using a library (which I like so I am not really in agreement about the unsuitability) like the tidyverse which is free and available to all even if loosely associated with the RSTUDIO folks and that can be run on any version of R that I am aware of, then some questions may still be fair if they are really about more general R issues as much of the rest of the code may be base R and may be the cause of whatever issue is being reported. And, some simple requests like pointing out a missing comma, ...
>
> I have stated my thought before and it boils down to the reality that there are some things about earlier versions of R that were far from perfect or complete and a little healthy competition is not a bad thing and may help base R evolve. Not everything in the tidyverse is better and it keeps evolving and deprecating older features, but it cannot really be ignored any longer. If you apply for a job at some company as something of an R expert, you may well be asked by all kinds of people about their programs that use the tidyverse for help or to help them solve a problem. You don't have to like it, but if you cannot read it, you no longer are really qualified in many places.
>
> Ask yourself if a language like R was created from scratch, what graphics might be built into the base distribution? Would you rather have lattice or ggplot or perhaps both as well as base R graphics? Would you make many of the built-in functions more consistent, so for instance, the data being worked on would be the first argument whenever possible?
>
> One reason there are so many packages is not so much due to the superiority of R but because people find it lacks quite a bit. Much of that should not be included, of course, if R is meant to be somewhat on the lean side, and yes, packages are a deliberate way to extend it when needed. But when people use it and think they are programming in R, ...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Feb 28 00:35:16 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 27 Feb 2022 15:35:16 -0800
Subject: [R] tidying up
In-Reply-To: <336709036.1577552.1645990473450@mail.yahoo.com>
References: <336709036.1577552.1645990473450.ref@mail.yahoo.com>
 <336709036.1577552.1645990473450@mail.yahoo.com>
Message-ID: <DFCF67A9-3194-42AB-B9E6-72316DB80BDC@dcn.davis.ca.us>

FWIW my brief answer to your brief question is "of course" it is okay. The real problem however are the questions that can only be answered by people with detailed understanding of non-R-related issues, such as the workings of the custom interactive graphics device used by RStudio or the broken behavior of some random GitHub-hosted package. There are a continuum of possible "degrees of relevance" that a question can have to the topic of a given discussion area (e.g. web forum or mailing list). The people who don't use RStudio don't gain benefit from wading through discussions that only have relevance to that tangential topic, and the more of that there is the lower the signal-to-noise ratio is from their perspective... and the sooner they leave. Ideally we will be kind in our redirection of the uninitiated, but an actual answer may not be feasible here... going elsewhere for a specific question should not be viewed as a negative outcome.

Since there are various interpretations of where the line should be drawn, it is best that it be drawn as the discussion area charter says it should... in this case, about R, the language. It is pretty explicit that discussion of contributed packages is not on-topic... presumably because allowing that can easily lead to highly arcane discussions that don't necessarily help people understand the R language better.

I think the existence of contributed packages and various development tools is hugely beneficial and I depend on many of them... but that doesn't automatically give any of them carte blanche to become actual topics of discussion here.

On February 27, 2022 11:34:33 AM PST, Avi Gross via R-help <r-help at r-project.org> wrote:
>This mailing list seems to steadily get messages that some see as not relevant to this forum. In particular, some see it as wrong to bring up some things here and keep reminding people of some ground rules.
>
>So I want to know, briefly, if it is reasonable to ask a person with a question or problem to reproduce their problem another way. If using RSTUDIO or one of many IDE, can they run the code on a naked R interpreter by sourcing the file or copying it in or typing it anew, or perhaps using IDLE which comes by default with many installations of R? If using a library (which I like so I am not really in agreement about the unsuitability) like the tidyverse which is free and available to all even if loosely associated with the RSTUDIO folks and that can be run on any version of R that I am aware of, then some questions may still be fair if they are really about more general R issues as much of the rest of the code may be base R and may be the cause of whatever issue is being reported. And, some simple requests like pointing out a missing comma, ...
>
>I have stated my thought before and it boils down to the reality that there are some things about earlier versions of R that were far from perfect or complete and a little healthy competition is not a bad thing and may help base R evolve. Not everything in the tidyverse is better and it keeps evolving and deprecating older features, but it cannot really be ignored any longer. If you apply for a job at some company as something of an R expert, you may well be asked by all kinds of people about their programs that use the tidyverse for help or to help them solve a problem. You don't have to like it, but if you cannot read it, you no longer are really qualified in many places.
>
>Ask yourself if a language like R was created from scratch, what graphics might be built into the base distribution? Would you rather have lattice or ggplot or perhaps both as well as base R graphics? Would you make many of the built-in functions more consistent, so for instance, the data being worked on would be the first argument whenever possible? 
>
>One reason there are so many packages is not so much due to the superiority of R but because people find it lacks quite a bit. Much of that should not be included, of course, if R is meant to be somewhat on the lean side, and yes, packages are a deliberate way to extend it when needed. But when people use it and think they are programming in R, ...
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From eoo@ @end|ng |rom dd@@n|  Sun Feb 27 12:45:20 2022
From: eoo@ @end|ng |rom dd@@n| (Jan van der Laan)
Date: Sun, 27 Feb 2022 11:45:20 +0000 (UTC)
Subject: [R] Plots not showing up in the RStudio plot pane
In-Reply-To: <0E3327C1-DAE7-4FC6-822D-73E1DE7C2E34@dcn.davis.ca.us>
References: <CAO29qn4pOjGYtD6SjO9rDm_r4Yscf+fpgT3dpZSP5OkUoYKy+g@mail.gmail.com>
 <0E3327C1-DAE7-4FC6-822D-73E1DE7C2E34@dcn.davis.ca.us>
Message-ID: <0cc48529-b0db-4d2e-a0a6-2c44a1d3739b@dds.nl>

R-studio might not support your R-version. In that case the R-studio graphics device does not work and it uses the default device from R which results in a new window. However, this is usually accompanied with a warning message when starting R telling you this.

So, you might want to update R-studio.

HTH,
Jan


From @||verm @end|ng |rom po@t@bgu@@c@||  Sun Feb 27 21:33:23 2022
From: @||verm @end|ng |rom po@t@bgu@@c@|| (Micha Silver)
Date: Sun, 27 Feb 2022 22:33:23 +0200
Subject: [R] tidying up
In-Reply-To: <336709036.1577552.1645990473450@mail.yahoo.com>
References: <336709036.1577552.1645990473450.ref@mail.yahoo.com>
 <336709036.1577552.1645990473450@mail.yahoo.com>
Message-ID: <4075ae63-4dd7-1914-53c8-982ab79f348b@post.bgu.ac.il>


On 27/02/2022 21:34, Avi Gross via R-help wrote:
> This mailing list seems to steadily get messages that some see as not relevant to this forum. In particular, some see it as wrong to bring up some things here and keep reminding people of some ground rules.
> So I want to know, briefly, if it is reasonable to ask a person with a question or problem to reproduce their problem another way. If using RSTUDIO or one of many IDE, can they run the code on a naked R interpreter by sourcing the file or copying it in or typing it anew, or perhaps using IDLE which comes by default with many installations of R? If using a library (which I like so I am not really in agreement about the unsuitability) like the tidyverse which is free and available to all even if loosely associated with the RSTUDIO folks and that can be run on any version of R that I am aware of, then some questions may still be fair if they are really about more general R issues as much of the rest of the code may be base R and may be the cause of whatever issue is being reported. And, some simple requests like pointing out a missing comma, ...
>
> I have stated my thought before and it boils down to the reality that there are some things about earlier versions of R that were far from perfect or complete and a little healthy competition is not a bad thing and may help base R evolve. Not everything in the tidyverse is better and it keeps evolving and deprecating older features, but it cannot really be ignored any longer. If you apply for a job at some company as something of an R expert, you may well be asked by all kinds of people about their programs that use the tidyverse for help or to help them solve a problem. You don't have to like it, but if you cannot read it, you no longer are really qualified in many places.


There's an easy way to test this:

There are already several r-sig-* lists. I might suggest to create a new 
r-sig-base list. Those who want to ask and answer issues dealing with 
base R only would be invited to migrate to that list. Then this current 
list could be broadened to address questions about R as well as other 
(popular) packages.


Yes, the list might get flooded with questions about obscure packages, 
or about statistics. But if no one answers, posters will eventually 
learn to go straight to the package maintainers, or elsewhere. And, 
along the way, it would save the numerous "irrelevant, off topic..." 
responses that you refer to.


Kind regards,


> Ask yourself if a language like R was created from scratch, what graphics might be built into the base distribution? Would you rather have lattice or ggplot or perhaps both as well as base R graphics? Would you make many of the built-in functions more consistent, so for instance, the data being worked on would be the first argument whenever possible?
>
> One reason there are so many packages is not so much due to the superiority of R but because people find it lacks quite a bit. Much of that should not be included, of course, if R is meant to be somewhat on the lean side, and yes, packages are a deliberate way to extend it when needed. But when people use it and think they are programming in R, ...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918
https://orcid.org/0000-0002-1128-1325


From bgunter@4567 @end|ng |rom gm@||@com  Mon Feb 28 01:59:09 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 27 Feb 2022 16:59:09 -0800
Subject: [R] tidying up
In-Reply-To: <4075ae63-4dd7-1914-53c8-982ab79f348b@post.bgu.ac.il>
References: <336709036.1577552.1645990473450.ref@mail.yahoo.com>
 <336709036.1577552.1645990473450@mail.yahoo.com>
 <4075ae63-4dd7-1914-53c8-982ab79f348b@post.bgu.ac.il>
Message-ID: <CAGxFJbSPs_5nwxR-bOvfwKygDiaLy=bpWAeOj-3bmN4-ML9+dw@mail.gmail.com>

For those wishing to make changes to r-help or seeking info on the R
mailing lists in general, please consult:
https://www.r-project.org/mail.html   You may wish to cc Martin
Maechler on any proposals for change, as he is one of the maintainers
-- or at least can contact the maintainers -- of these lists. Nothing
will change if they don't change it. (I believe he does monitor the
traffic here, though.)

Note the first line on that mailing list page: "**Please** read the
instructions below and the posting guide before sending anything to
any mailing list!" Still THE definitive statement of proper use of
these lists, alas often more honored in the breach than the
observance.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Feb 27, 2022 at 4:07 PM Micha Silver <silverm at post.bgu.ac.il> wrote:
>
>
> On 27/02/2022 21:34, Avi Gross via R-help wrote:
> > This mailing list seems to steadily get messages that some see as not relevant to this forum. In particular, some see it as wrong to bring up some things here and keep reminding people of some ground rules.
> > So I want to know, briefly, if it is reasonable to ask a person with a question or problem to reproduce their problem another way. If using RSTUDIO or one of many IDE, can they run the code on a naked R interpreter by sourcing the file or copying it in or typing it anew, or perhaps using IDLE which comes by default with many installations of R? If using a library (which I like so I am not really in agreement about the unsuitability) like the tidyverse which is free and available to all even if loosely associated with the RSTUDIO folks and that can be run on any version of R that I am aware of, then some questions may still be fair if they are really about more general R issues as much of the rest of the code may be base R and may be the cause of whatever issue is being reported. And, some simple requests like pointing out a missing comma, ...
> >
> > I have stated my thought before and it boils down to the reality that there are some things about earlier versions of R that were far from perfect or complete and a little healthy competition is not a bad thing and may help base R evolve. Not everything in the tidyverse is better and it keeps evolving and deprecating older features, but it cannot really be ignored any longer. If you apply for a job at some company as something of an R expert, you may well be asked by all kinds of people about their programs that use the tidyverse for help or to help them solve a problem. You don't have to like it, but if you cannot read it, you no longer are really qualified in many places.
>
>
> There's an easy way to test this:
>
> There are already several r-sig-* lists. I might suggest to create a new
> r-sig-base list. Those who want to ask and answer issues dealing with
> base R only would be invited to migrate to that list. Then this current
> list could be broadened to address questions about R as well as other
> (popular) packages.
>
>
> Yes, the list might get flooded with questions about obscure packages,
> or about statistics. But if no one answers, posters will eventually
> learn to go straight to the package maintainers, or elsewhere. And,
> along the way, it would save the numerous "irrelevant, off topic..."
> responses that you refer to.
>
>
> Kind regards,
>
>
> > Ask yourself if a language like R was created from scratch, what graphics might be built into the base distribution? Would you rather have lattice or ggplot or perhaps both as well as base R graphics? Would you make many of the built-in functions more consistent, so for instance, the data being worked on would be the first argument whenever possible?
> >
> > One reason there are so many packages is not so much due to the superiority of R but because people find it lacks quite a bit. Much of that should not be included, of course, if R is meant to be somewhat on the lean side, and yes, packages are a deliberate way to extend it when needed. But when people use it and think they are programming in R, ...
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918
> https://orcid.org/0000-0002-1128-1325
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m|ch@e|@bonert @end|ng |rom @|umn|@utoronto@c@  Mon Feb 28 02:02:17 2022
From: m|ch@e|@bonert @end|ng |rom @|umn|@utoronto@c@ (Michael Bonert)
Date: Mon, 28 Feb 2022 01:02:17 +0000
Subject: [R] ggplot2 with an arbitrary number of curves from geom_function +
 legend?
Message-ID: <YT3PR01MB97389F056822C68C582DED33A5019@YT3PR01MB9738.CANPRD01.PROD.OUTLOOK.COM>

Dear R-help,

I am trying to create a ggplot with an arbitrary number of curves + legend.

The plot should contain:
1. data points + a line that is either user defined *or* represents the median of the data points
2. an arbitrary number of confidence intervals (CIs) around the line, where the CIs are defined by a function

#1: this is easy enough
#2: I don't know how to combine this with #1

I can write #2 as a loop (see below) but it is then seems to be impossible to get ggplot to do a proper legend.

The challenge I have seems similar to this problem:
https://stackoverflow.com/questions/12169289/ggplot2-fail-to-apply-color-with-scale-fill-manual-inside-a-loop

I read that one should not use a loop with ggplot ( https://stackoverflow.com/questions/62603533/adding-ggplot2-legend-with-many-lines-using-for-loop ).
(Interesting: there are probably a half dozen posts on ggplot + loops floating around on the web.  I do not feel alone in my problem... but I also do not think I am close to solving it.)
(As a user of GNU/Octave ( octave.org ) using a loop seems the intuitive solution. In GNU/Octave one does a "hold on" and then plots however many lines/objects one wants within a figure.)

Is there a way to freeze the 'scale_colour_manual' attribute?
(The way the code is written: the colour scale seems to be overwritten with the 'fp=fp ...' statement)
(I have gotten the message: "Scale for 'colour' is already present. Adding another scale for 'colour',
which will replace the existing scale.")

Loop aside:
Is there a way to elegantly pipe an arbitrary number of 'geom_function' calls to the 'ggplot'?
(I wondered whether the '%>%' operator in 'dplyr' is a possible solution -- as suggested here:
https://stackoverflow.com/questions/30655364/ggplot2-getting-a-color-legend-to-appear-using-stat-function-in-a-for-loop )


I could write code to generate a data frame that has the data points and points for arbitrary curves; however,
this would necessitate writing a function that replicates 'geom_function'.

Is there a way to generate the text string and then execute it?
( https://stackoverflow.com/questions/1743698/evaluate-expression-given-as-a-string )
(In my humble opinion: this would be a hack.)

Is there a way to generate a legend with 'override.aes'?
( https://www.r-bloggers.com/2020/07/controlling-legend-appearance-in-ggplot2-with-override-aes/ )


Below is the attempt at creating a legend:
~~
  # plot the data points
  fp = ggplot(df,aes(x=x_var, y=y_var), colour4labels[num_of_funnels+2]) + geom_point(size=4, na.rm = TRUE, alpha = 0.75) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits")) + geom_hline(aes(yintercept = funnel_centre_line, colour = colour4labels[num_of_funnels+1]), linetype = 2) + xlab(x_label) + ylab(y_label) + ggtitle(plot_title) + theme(axis.title=element_text(face="bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))

  # add funnel plot curves (limits)
  for (ci_ctr in 1:length(limits)) {
    if (ci_ctr==1) {
      fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.1, na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.1, na.rm = TRUE, linetype = 5) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))

    } else if (ci_ctr==2) {
      fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.3, na.rm = TRUE) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.3, na.rm = TRUE) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))

    } else {
      fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), na.rm = TRUE, linetype = 5) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))
    }
  }
~~

Code without elements to generate a legend (that otherwise does what I want it to):
~~
  # plot the data points
  fp = ggplot(df,aes(x=x_var, y=y_var)) + geom_point(size=4, na.rm = TRUE, colour = "blue", alpha = 0.75) + theme_bw()

  # add centre line, axis labels and plot title
  fp = fp + geom_hline(aes(yintercept = funnel_centre_line), linetype = 2, colour = "black") + xlab(x_label) + ylab(y_label) + ggtitle(plot_title) + theme(axis.title=element_text(face="bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))

  # add funnel plot curves (limits)
  for (ci_ctr in 1:length(limits)) {
    if (ci_ctr==1) {
      fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.1, na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.1, na.rm = TRUE, linetype = 5)

    } else if (ci_ctr==2) {
      fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.3, na.rm = TRUE) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.3, na.rm = TRUE)

    } else {
      fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], na.rm = TRUE, linetype = 5)
    }
  }
~~

Happy to post the complete code. I was thinking it might be a contribution--if deemed non-trivial.
(I also have a test function that runs the code with a data set already in r-cran.)

Take Care,
Michael Bonert, BASc, MASc, MD, FRCPC

PS -
Environment details:
 R version: 4.0.4 (2021-02-15)
 Platform: Debian GNU/Linux 11 (stable)

I am trying to generate R code similar to that in this paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8219089/
(If you want to know where I am coming from: it is in that paper.)

The code I wrote is somewhat similar to the package 'FunnelPlotR' ( https://cran.rstudio.com/web/packages/FunnelPlotR/index.html ). I did look at the code in that package.

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Feb 28 07:00:31 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 28 Feb 2022 06:00:31 +0000 (UTC)
Subject: [R] 
 ggplot2 with an arbitrary number of curves from geom_function +
 legend?
In-Reply-To: <YT3PR01MB97389F056822C68C582DED33A5019@YT3PR01MB9738.CANPRD01.PROD.OUTLOOK.COM>
References: <YT3PR01MB97389F056822C68C582DED33A5019@YT3PR01MB9738.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <564857273.1641053.1646028031423@mail.yahoo.com>

I would reply but since ggplot was mentioned, I must abstain. ;-)

I will say that you can use ggplot in a loop in some cases if you do this:

p <- ggplot(...) + ...

Then you can in your loop keep adding to p as in:

p <- p + geom_whatever() + ...

You do at some point need to make p print itself and generate a graph. Until then, it can be amended, albeit some changes undo or overwrite earlier ones if not done carefully.

Having said all that, there is often a way to do a kind of looping within ggplot by say grouping your data and having it draw things grouped, or say making multiple vertical (or horizontal) lines by supplying a vector of positions.

But as noted, this is not considered a good place by some to discuss this, so forget I said anything.




-----Original Message-----
From: Michael Bonert <michael.bonert at alumni.utoronto.ca>
To: r-help at r-project.org <r-help at r-project.org>
Sent: Sun, Feb 27, 2022 8:02 pm
Subject: [R] ggplot2 with an arbitrary number of curves from geom_function + legend?

Dear R-help,

I am trying to create a ggplot with an arbitrary number of curves + legend.

The plot should contain:
1. data points + a line that is either user defined *or* represents the median of the data points
2. an arbitrary number of confidence intervals (CIs) around the line, where the CIs are defined by a function

#1: this is easy enough
#2: I don't know how to combine this with #1

I can write #2 as a loop (see below) but it is then seems to be impossible to get ggplot to do a proper legend.

The challenge I have seems similar to this problem:
https://stackoverflow.com/questions/12169289/ggplot2-fail-to-apply-color-with-scale-fill-manual-inside-a-loop

I read that one should not use a loop with ggplot ( https://stackoverflow.com/questions/62603533/adding-ggplot2-legend-with-many-lines-using-for-loop ).
(Interesting: there are probably a half dozen posts on ggplot + loops floating around on the web.? I do not feel alone in my problem... but I also do not think I am close to solving it.)
(As a user of GNU/Octave ( octave.org ) using a loop seems the intuitive solution. In GNU/Octave one does a "hold on" and then plots however many lines/objects one wants within a figure.)

Is there a way to freeze the 'scale_colour_manual' attribute?
(The way the code is written: the colour scale seems to be overwritten with the 'fp=fp ...' statement)
(I have gotten the message: "Scale for 'colour' is already present. Adding another scale for 'colour',
which will replace the existing scale.")

Loop aside:
Is there a way to elegantly pipe an arbitrary number of 'geom_function' calls to the 'ggplot'?
(I wondered whether the '%>%' operator in 'dplyr' is a possible solution -- as suggested here:
https://stackoverflow.com/questions/30655364/ggplot2-getting-a-color-legend-to-appear-using-stat-function-in-a-for-loop )


I could write code to generate a data frame that has the data points and points for arbitrary curves; however,
this would necessitate writing a function that replicates 'geom_function'.

Is there a way to generate the text string and then execute it?
( https://stackoverflow.com/questions/1743698/evaluate-expression-given-as-a-string )
(In my humble opinion: this would be a hack.)

Is there a way to generate a legend with 'override.aes'?
( https://www.r-bloggers.com/2020/07/controlling-legend-appearance-in-ggplot2-with-override-aes/ )


Below is the attempt at creating a legend:
~~
? # plot the data points
? fp = ggplot(df,aes(x=x_var, y=y_var), colour4labels[num_of_funnels+2]) + geom_point(size=4, na.rm = TRUE, alpha = 0.75) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits")) + geom_hline(aes(yintercept = funnel_centre_line, colour = colour4labels[num_of_funnels+1]), linetype = 2) + xlab(x_label) + ylab(y_label) + ggtitle(plot_title) + theme(axis.title=element_text(face="bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))

? # add funnel plot curves (limits)
? for (ci_ctr in 1:length(limits)) {
? ? if (ci_ctr==1) {
? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.1, na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.1, na.rm = TRUE, linetype = 5) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))

? ? } else if (ci_ctr==2) {
? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.3, na.rm = TRUE) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.3, na.rm = TRUE) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))

? ? } else {
? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), na.rm = TRUE, linetype = 5) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))
? ? }
? }
~~

Code without elements to generate a legend (that otherwise does what I want it to):
~~
? # plot the data points
? fp = ggplot(df,aes(x=x_var, y=y_var)) + geom_point(size=4, na.rm = TRUE, colour = "blue", alpha = 0.75) + theme_bw()

? # add centre line, axis labels and plot title
? fp = fp + geom_hline(aes(yintercept = funnel_centre_line), linetype = 2, colour = "black") + xlab(x_label) + ylab(y_label) + ggtitle(plot_title) + theme(axis.title=element_text(face="bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))

? # add funnel plot curves (limits)
? for (ci_ctr in 1:length(limits)) {
? ? if (ci_ctr==1) {
? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.1, na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.1, na.rm = TRUE, linetype = 5)

? ? } else if (ci_ctr==2) {
? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.3, na.rm = TRUE) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.3, na.rm = TRUE)

? ? } else {
? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], na.rm = TRUE, linetype = 5)
? ? }
? }
~~

Happy to post the complete code. I was thinking it might be a contribution--if deemed non-trivial.
(I also have a test function that runs the code with a data set already in r-cran.)

Take Care,
Michael Bonert, BASc, MASc, MD, FRCPC

PS -
Environment details:
 R version: 4.0.4 (2021-02-15)
 Platform: Debian GNU/Linux 11 (stable)

I am trying to generate R code similar to that in this paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8219089/
(If you want to know where I am coming from: it is in that paper.)

The code I wrote is somewhat similar to the package 'FunnelPlotR' ( https://cran.rstudio.com/web/packages/FunnelPlotR/index.html ). I did look at the code in that package.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Feb 28 08:53:51 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 27 Feb 2022 23:53:51 -0800
Subject: [R] 
 ggplot2 with an arbitrary number of curves from geom_function +
 legend?
In-Reply-To: <564857273.1641053.1646028031423@mail.yahoo.com>
References: <YT3PR01MB97389F056822C68C582DED33A5019@YT3PR01MB9738.CANPRD01.PROD.OUTLOOK.COM>
 <564857273.1641053.1646028031423@mail.yahoo.com>
Message-ID: <EAE8B915-DDB1-4124-81E2-10DB81BE80AB@dcn.davis.ca.us>

Well, the ggplot2 CRAN page [1] points people to [2], which in turn points out that support can be found on the RStudio community forums and StackOverflow, so there is a path from here (where contributed packages are off-topic per the Posting Guide) to getting help.

I will point out that the canonical solution is definitely to put all of your data into one long-form data frame and use a factor column to distinguish aesthetics (one google result is [3]) ... loops really don't work well to add layers to ggplots.

But yes, if you have further questions on a contributed package, do follow the breadcrumbs from CRAN for sources of help, and come back when your question is about the R language.

[1] https://cran.r-project.org/web/packages/ggplot2/index.html
[2] https://ggplot2.tidyverse.org/
[3] https://stackoverflow.com/questions/64523271/how-to-insert-a-legend-in-a-ggplot-with-multiple-time-series

On February 27, 2022 10:00:31 PM PST, Avi Gross via R-help <r-help at r-project.org> wrote:
>I would reply but since ggplot was mentioned, I must abstain. ;-)
>
>I will say that you can use ggplot in a loop in some cases if you do this:
>
>p <- ggplot(...) + ...
>
>Then you can in your loop keep adding to p as in:
>
>p <- p + geom_whatever() + ...
>
>You do at some point need to make p print itself and generate a graph. Until then, it can be amended, albeit some changes undo or overwrite earlier ones if not done carefully.
>
>Having said all that, there is often a way to do a kind of looping within ggplot by say grouping your data and having it draw things grouped, or say making multiple vertical (or horizontal) lines by supplying a vector of positions.
>
>But as noted, this is not considered a good place by some to discuss this, so forget I said anything.
>
>
>
>
>-----Original Message-----
>From: Michael Bonert <michael.bonert at alumni.utoronto.ca>
>To: r-help at r-project.org <r-help at r-project.org>
>Sent: Sun, Feb 27, 2022 8:02 pm
>Subject: [R] ggplot2 with an arbitrary number of curves from geom_function + legend?
>
>Dear R-help,
>
>I am trying to create a ggplot with an arbitrary number of curves + legend.
>
>The plot should contain:
>1. data points + a line that is either user defined *or* represents the median of the data points
>2. an arbitrary number of confidence intervals (CIs) around the line, where the CIs are defined by a function
>
>#1: this is easy enough
>#2: I don't know how to combine this with #1
>
>I can write #2 as a loop (see below) but it is then seems to be impossible to get ggplot to do a proper legend.
>
>The challenge I have seems similar to this problem:
>https://stackoverflow.com/questions/12169289/ggplot2-fail-to-apply-color-with-scale-fill-manual-inside-a-loop
>
>I read that one should not use a loop with ggplot ( https://stackoverflow.com/questions/62603533/adding-ggplot2-legend-with-many-lines-using-for-loop ).
>(Interesting: there are probably a half dozen posts on ggplot + loops floating around on the web.? I do not feel alone in my problem... but I also do not think I am close to solving it.)
>(As a user of GNU/Octave ( octave.org ) using a loop seems the intuitive solution. In GNU/Octave one does a "hold on" and then plots however many lines/objects one wants within a figure.)
>
>Is there a way to freeze the 'scale_colour_manual' attribute?
>(The way the code is written: the colour scale seems to be overwritten with the 'fp=fp ...' statement)
>(I have gotten the message: "Scale for 'colour' is already present. Adding another scale for 'colour',
>which will replace the existing scale.")
>
>Loop aside:
>Is there a way to elegantly pipe an arbitrary number of 'geom_function' calls to the 'ggplot'?
>(I wondered whether the '%>%' operator in 'dplyr' is a possible solution -- as suggested here:
>https://stackoverflow.com/questions/30655364/ggplot2-getting-a-color-legend-to-appear-using-stat-function-in-a-for-loop )
>
>
>I could write code to generate a data frame that has the data points and points for arbitrary curves; however,
>this would necessitate writing a function that replicates 'geom_function'.
>
>Is there a way to generate the text string and then execute it?
>( https://stackoverflow.com/questions/1743698/evaluate-expression-given-as-a-string )
>(In my humble opinion: this would be a hack.)
>
>Is there a way to generate a legend with 'override.aes'?
>( https://www.r-bloggers.com/2020/07/controlling-legend-appearance-in-ggplot2-with-override-aes/ )
>
>
>Below is the attempt at creating a legend:
>~~
>? # plot the data points
>? fp = ggplot(df,aes(x=x_var, y=y_var), colour4labels[num_of_funnels+2]) + geom_point(size=4, na.rm = TRUE, alpha = 0.75) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits")) + geom_hline(aes(yintercept = funnel_centre_line, colour = colour4labels[num_of_funnels+1]), linetype = 2) + xlab(x_label) + ylab(y_label) + ggtitle(plot_title) + theme(axis.title=element_text(face="bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
>
>? # add funnel plot curves (limits)
>? for (ci_ctr in 1:length(limits)) {
>? ? if (ci_ctr==1) {
>? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.1, na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.1, na.rm = TRUE, linetype = 5) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))
>
>? ? } else if (ci_ctr==2) {
>? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.3, na.rm = TRUE) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), size = 1.3, na.rm = TRUE) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))
>
>? ? } else {
>? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), aes(colour = colour4labels[ci_ctr]), na.rm = TRUE, linetype = 5) + theme(legend.position="bottom") + scale_color_manual(labels = legend_labels, values = colour4labels) + guides(color=guide_legend("Control Limits"))
>? ? }
>? }
>~~
>
>Code without elements to generate a legend (that otherwise does what I want it to):
>~~
>? # plot the data points
>? fp = ggplot(df,aes(x=x_var, y=y_var)) + geom_point(size=4, na.rm = TRUE, colour = "blue", alpha = 0.75) + theme_bw()
>
>? # add centre line, axis labels and plot title
>? fp = fp + geom_hline(aes(yintercept = funnel_centre_line), linetype = 2, colour = "black") + xlab(x_label) + ylab(y_label) + ggtitle(plot_title) + theme(axis.title=element_text(face="bold"), plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
>
>? # add funnel plot curves (limits)
>? for (ci_ctr in 1:length(limits)) {
>? ? if (ci_ctr==1) {
>? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.1, na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.1, na.rm = TRUE, linetype = 5)
>
>? ? } else if (ci_ctr==2) {
>? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.3, na.rm = TRUE) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], size = 1.3, na.rm = TRUE)
>
>? ? } else {
>? ? ? fp = fp + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 1, trunc_val = 0), colour = colour4labels[ci_ctr], na.rm = TRUE, linetype = 5) + geom_function(fun = calc_fpc, args = list(ci_or_alpha = limits[ci_ctr], probability = funnel_centre_line, upper_or_lower = 2, trunc_val = 0), colour = colour4labels[ci_ctr], na.rm = TRUE, linetype = 5)
>? ? }
>? }
>~~
>
>Happy to post the complete code. I was thinking it might be a contribution--if deemed non-trivial.
>(I also have a test function that runs the code with a data set already in r-cran.)
>
>Take Care,
>Michael Bonert, BASc, MASc, MD, FRCPC
>
>PS -
>Environment details:
> R version: 4.0.4 (2021-02-15)
> Platform: Debian GNU/Linux 11 (stable)
>
>I am trying to generate R code similar to that in this paper: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8219089/
>(If you want to know where I am coming from: it is in that paper.)
>
>The code I wrote is somewhat similar to the package 'FunnelPlotR' ( https://cran.rstudio.com/web/packages/FunnelPlotR/index.html ). I did look at the code in that package.
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From tebert @end|ng |rom u||@edu  Mon Feb 28 13:36:09 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 28 Feb 2022 12:36:09 +0000
Subject: [R] Searching for packages
Message-ID: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>

If I want help on a package I can usually go to google and type "package.name in r" and I get what I need in the first few hits. Google typically offers suggestions if my spelling is a bit off, and I get hits that are close. I searched for the binGroup package in the usual way and found that it is no longer supported. I asked the authors only to discover that there is a binGroup2 package.

If I search for "tidyv in R" I get tidyverse.

Any idea why I did not get binGroup2 in the binGroup search?

Regards,
Tim

	[[alternative HTML version deleted]]


From @erv|ce @end|ng |rom @hd@w@on@com  Mon Feb 28 13:45:48 2022
From: @erv|ce @end|ng |rom @hd@w@on@com (Stephen H. Dawson, DSL)
Date: Mon, 28 Feb 2022 07:45:48 -0500
Subject: [R] Searching for packages
In-Reply-To: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <170d7701-6ac1-bca5-182a-bed93dfb4d6d@shdawson.com>

When was binGroup2 released?

When is your last system update?

*Stephen Dawson, DSL*
/Executive Strategy Consultant/
Business & Technology
+1 (865) 804-3454
http://www.shdawson.com


On 2/28/22 07:36, Ebert,Timothy Aaron wrote:
> If I want help on a package I can usually go to google and type "package.name in r" and I get what I need in the first few hits. Google typically offers suggestions if my spelling is a bit off, and I get hits that are close. I searched for the binGroup package in the usual way and found that it is no longer supported. I asked the authors only to discover that there is a binGroup2 package.
>
> If I search for "tidyv in R" I get tidyverse.
>
> Any idea why I did not get binGroup2 in the binGroup search?
>
> Regards,
> Tim
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Feb 28 13:49:28 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 28 Feb 2022 12:49:28 +0000
Subject: [R] Searching for packages
In-Reply-To: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <a299efef-8be2-4f90-9795-485b51884df2@sapo.pt>

Hello,

I don't know why Google couldn't find it but

RSiteSearch("binGroup*")

found binGroup2. It's in the 3rd page but it did find it.

Rui Barradas

?s 12:36 de 28/02/2022, Ebert,Timothy Aaron escreveu:
> If I want help on a package I can usually go to google and type "package.name in r" and I get what I need in the first few hits. Google typically offers suggestions if my spelling is a bit off, and I get hits that are close. I searched for the binGroup package in the usual way and found that it is no longer supported. I asked the authors only to discover that there is a binGroup2 package.
> 
> If I search for "tidyv in R" I get tidyverse.
> 
> Any idea why I did not get binGroup2 in the binGroup search?
> 
> Regards,
> Tim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @erv|ce @end|ng |rom @hd@w@on@com  Mon Feb 28 14:21:57 2022
From: @erv|ce @end|ng |rom @hd@w@on@com (Stephen H. Dawson, DSL)
Date: Mon, 28 Feb 2022 08:21:57 -0500
Subject: [R] tidying up
In-Reply-To: <1182161945.1594668.1645999181069@mail.yahoo.com>
References: <336709036.1577552.1645990473450.ref@mail.yahoo.com>
 <336709036.1577552.1645990473450@mail.yahoo.com>
 <CA+8X3fWAPtZ9XYmCkiq+P4EEV1Crh0VZG9v9wFc2adKG0902KQ@mail.gmail.com>
 <1182161945.1594668.1645999181069@mail.yahoo.com>
Message-ID: <804829ff-f78b-e097-5c7e-53134e124ed7@shdawson.com>

Hi Avi,


I thought about your question over the past few days. A new email list 
may help, but I doubt the help will suffice to solve the problem of 
forming emails as the existing list prefers.

Here is where I see the source of the problem with using R by way of 
getting questions answers.

https://cran.r-project.org/doc/manuals/r-release/R-intro.html

This writing is not an introductory learning piece. This work needs to 
be restructured and expanded. It is evident another author would need to 
be found who has the writing skills to accomplish the necessary 
improvements.


*Stephen Dawson, DSL*
/Executive Strategy Consultant/
Business & Technology
+1 (865) 804-3454
http://www.shdawson.com


On 2/27/22 16:59, Avi Gross via R-help wrote:
> Indeed, Jim, the hopeful purpose of interactions here is to help people without doing the job for them. As you note, sometimes it is help in getting them to formulate what they are trying to do and maybe see the resolution on their own, or give enough info that others can troubleshoot.
>
> I have dealt with people on and off forums like this who know very little and have done some rudimentary search and found something they hope is helpful and then get stuck. Some have no actual interest in learning R or Python or anything and see it as a one-time thing. For them, any sustained interaction is just frustrating. Others may want a tutor, albeit mahy of us here are not willing or able to provide endless hours to volunteer. And some, may be better off spending the money to hire someone and I assume there are places they can be directed.
>
>
>
>
> -----Original Message-----
> From: Jim Lemon <drjimlemon at gmail.com>
> To: Avi Gross <avigross at verizon.net>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Sent: Sun, Feb 27, 2022 4:52 pm
> Subject: Re: [R] tidying up
>
>
> Hi Avi,
> I just sent in an answer to a very simple question. In many cases it
> seems to me that the real problem isn't apparent from the request.
> ektaraK appears to have almost no experience with R (sorry if I'm
> wrong). A person in this position may sort of know what they want to
> do but do not know how to ask the question. What's a reproducible
> example? So I often submit really dumb looking answers that show the
> person how to ask the question. If I'm successful, the OP learns how
> to do some basic operation, but also learns how to ask the next
> question. Until they get there, most responses just give them a typing
> exercise.
>
> Jim
>
>
> On Mon, Feb 28, 2022 at 6:35 AM Avi Gross via R-help
> <r-help at r-project.org> wrote:
>> This mailing list seems to steadily get messages that some see as not relevant to this forum. In particular, some see it as wrong to bring up some things here and keep reminding people of some ground rules.
>>
>> So I want to know, briefly, if it is reasonable to ask a person with a question or problem to reproduce their problem another way. If using RSTUDIO or one of many IDE, can they run the code on a naked R interpreter by sourcing the file or copying it in or typing it anew, or perhaps using IDLE which comes by default with many installations of R? If using a library (which I like so I am not really in agreement about the unsuitability) like the tidyverse which is free and available to all even if loosely associated with the RSTUDIO folks and that can be run on any version of R that I am aware of, then some questions may still be fair if they are really about more general R issues as much of the rest of the code may be base R and may be the cause of whatever issue is being reported. And, some simple requests like pointing out a missing comma, ...
>>
>> I have stated my thought before and it boils down to the reality that there are some things about earlier versions of R that were far from perfect or complete and a little healthy competition is not a bad thing and may help base R evolve. Not everything in the tidyverse is better and it keeps evolving and deprecating older features, but it cannot really be ignored any longer. If you apply for a job at some company as something of an R expert, you may well be asked by all kinds of people about their programs that use the tidyverse for help or to help them solve a problem. You don't have to like it, but if you cannot read it, you no longer are really qualified in many places.
>>
>> Ask yourself if a language like R was created from scratch, what graphics might be built into the base distribution? Would you rather have lattice or ggplot or perhaps both as well as base R graphics? Would you make many of the built-in functions more consistent, so for instance, the data being worked on would be the first argument whenever possible?
>>
>> One reason there are so many packages is not so much due to the superiority of R but because people find it lacks quite a bit. Much of that should not be included, of course, if R is meant to be somewhat on the lean side, and yes, packages are a deliberate way to extend it when needed. But when people use it and think they are programming in R, ...
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tebert @end|ng |rom u||@edu  Mon Feb 28 14:32:02 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 28 Feb 2022 13:32:02 +0000
Subject: [R] Searching for packages
In-Reply-To: <170d7701-6ac1-bca5-182a-bed93dfb4d6d@shdawson.com>
References: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <170d7701-6ac1-bca5-182a-bed93dfb4d6d@shdawson.com>
Message-ID: <BN6PR2201MB15531739A3BF86A9EE3C71B1CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>

binGroup2 (version 1.02) was released 2020-04-07. There was one update on 2021-03-17 (according to available.versions("binGroup2").
My last system update was (I assume) recent. My system is governed by my University. I get monthly updates, rarely more often. My version of R is 4.1.
I tried Rui's suggestion (thank you) of searching using R. I read through the list several times but did not find binGroup2, though it is possible that it was there as binGroup.... and I need to open all the documents to find it.

Tim


-----Original Message-----
From: Stephen H. Dawson, DSL <service at shdawson.com> 
Sent: Monday, February 28, 2022 7:46 AM
To: Ebert,Timothy Aaron <tebert at ufl.edu>; r-help at r-project.org
Subject: Re: [R] Searching for packages

[External Email]

When was binGroup2 released?

When is your last system update?

*Stephen Dawson, DSL*
/Executive Strategy Consultant/
Business & Technology
+1 (865) 804-3454
https://urldefense.proofpoint.com/v2/url?u=http-3A__www.shdawson.com&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04nGi2PSLKn&s=J6gEolZqXpDtRFdEzUW6R1ySBhZw3FgsLL2GoKQ1vg0&e=


On 2/28/22 07:36, Ebert,Timothy Aaron wrote:
> If I want help on a package I can usually go to google and type "package.name in r" and I get what I need in the first few hits. Google typically offers suggestions if my spelling is a bit off, and I get hits that are close. I searched for the binGroup package in the usual way and found that it is no longer supported. I asked the authors only to discover that there is a binGroup2 package.
>
> If I search for "tidyv in R" I get tidyverse.
>
> Any idea why I did not get binGroup2 in the binGroup search?
>
> Regards,
> Tim
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> man_listinfo_r-2Dhelp&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> Rzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04nG
> i2PSLKn&s=1lwcSxFoUFNj5-s-czuFCrPlhteONuK8xl-a2CkpnVA&e=
> PLEASE do read the posting guide 
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> g_posting-2Dguide.html&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> sRzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04n
> Gi2PSLKn&s=rVBDL-rnzLnz-rie3bN1-pU8DPfnVxnJMTfbsKzW3nw&e=
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Feb 28 14:43:56 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 28 Feb 2022 13:43:56 +0000
Subject: [R] Searching for packages
In-Reply-To: <BN6PR2201MB15531739A3BF86A9EE3C71B1CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <170d7701-6ac1-bca5-182a-bed93dfb4d6d@shdawson.com>
 <BN6PR2201MB15531739A3BF86A9EE3C71B1CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <91bdbde3-1134-6620-0e48-8dab9f21a80c@sapo.pt>

Hello,

Actually, I only found it at the second try. The RSiteSearch webpage has 
a search bar, I've used it search binGroup* and found it on screen 3.

Rui Barradas

?s 13:32 de 28/02/2022, Ebert,Timothy Aaron escreveu:
> binGroup2 (version 1.02) was released 2020-04-07. There was one update on 2021-03-17 (according to available.versions("binGroup2").
> My last system update was (I assume) recent. My system is governed by my University. I get monthly updates, rarely more often. My version of R is 4.1.
> I tried Rui's suggestion (thank you) of searching using R. I read through the list several times but did not find binGroup2, though it is possible that it was there as binGroup.... and I need to open all the documents to find it.
> 
> Tim
> 
> 
> -----Original Message-----
> From: Stephen H. Dawson, DSL <service at shdawson.com>
> Sent: Monday, February 28, 2022 7:46 AM
> To: Ebert,Timothy Aaron <tebert at ufl.edu>; r-help at r-project.org
> Subject: Re: [R] Searching for packages
> 
> [External Email]
> 
> When was binGroup2 released?
> 
> When is your last system update?
> 
> *Stephen Dawson, DSL*
> /Executive Strategy Consultant/
> Business & Technology
> +1 (865) 804-3454
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.shdawson.com&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04nGi2PSLKn&s=J6gEolZqXpDtRFdEzUW6R1ySBhZw3FgsLL2GoKQ1vg0&e=
> 
> 
> On 2/28/22 07:36, Ebert,Timothy Aaron wrote:
>> If I want help on a package I can usually go to google and type "package.name in r" and I get what I need in the first few hits. Google typically offers suggestions if my spelling is a bit off, and I get hits that are close. I searched for the binGroup package in the usual way and found that it is no longer supported. I asked the authors only to discover that there is a binGroup2 package.
>>
>> If I search for "tidyv in R" I get tidyverse.
>>
>> Any idea why I did not get binGroup2 in the binGroup search?
>>
>> Regards,
>> Tim
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>> man_listinfo_r-2Dhelp&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
>> Rzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04nG
>> i2PSLKn&s=1lwcSxFoUFNj5-s-czuFCrPlhteONuK8xl-a2CkpnVA&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>> g_posting-2Dguide.html&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>> sRzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04n
>> Gi2PSLKn&s=rVBDL-rnzLnz-rie3bN1-pU8DPfnVxnJMTfbsKzW3nw&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Feb 28 16:46:33 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 28 Feb 2022 07:46:33 -0800
Subject: [R] Searching for packages
In-Reply-To: <91bdbde3-1134-6620-0e48-8dab9f21a80c@sapo.pt>
References: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <170d7701-6ac1-bca5-182a-bed93dfb4d6d@shdawson.com>
 <BN6PR2201MB15531739A3BF86A9EE3C71B1CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <91bdbde3-1134-6620-0e48-8dab9f21a80c@sapo.pt>
Message-ID: <CAGxFJbSt0m37FMzs7syvaoc+wu-FxEE0qEaeDT95ow1MLaFJSg@mail.gmail.com>

Other places beside google to look for R info:

https://rdrr.io/
https://www.rdocumentation.org/
https://rseek.org/

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 28, 2022 at 5:44 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Actually, I only found it at the second try. The RSiteSearch webpage has
> a search bar, I've used it search binGroup* and found it on screen 3.
>
> Rui Barradas
>
> ?s 13:32 de 28/02/2022, Ebert,Timothy Aaron escreveu:
> > binGroup2 (version 1.02) was released 2020-04-07. There was one update on 2021-03-17 (according to available.versions("binGroup2").
> > My last system update was (I assume) recent. My system is governed by my University. I get monthly updates, rarely more often. My version of R is 4.1.
> > I tried Rui's suggestion (thank you) of searching using R. I read through the list several times but did not find binGroup2, though it is possible that it was there as binGroup.... and I need to open all the documents to find it.
> >
> > Tim
> >
> >
> > -----Original Message-----
> > From: Stephen H. Dawson, DSL <service at shdawson.com>
> > Sent: Monday, February 28, 2022 7:46 AM
> > To: Ebert,Timothy Aaron <tebert at ufl.edu>; r-help at r-project.org
> > Subject: Re: [R] Searching for packages
> >
> > [External Email]
> >
> > When was binGroup2 released?
> >
> > When is your last system update?
> >
> > *Stephen Dawson, DSL*
> > /Executive Strategy Consultant/
> > Business & Technology
> > +1 (865) 804-3454
> > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.shdawson.com&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04nGi2PSLKn&s=J6gEolZqXpDtRFdEzUW6R1ySBhZw3FgsLL2GoKQ1vg0&e=
> >
> >
> > On 2/28/22 07:36, Ebert,Timothy Aaron wrote:
> >> If I want help on a package I can usually go to google and type "package.name in r" and I get what I need in the first few hits. Google typically offers suggestions if my spelling is a bit off, and I get hits that are close. I searched for the binGroup package in the usual way and found that it is no longer supported. I asked the authors only to discover that there is a binGroup2 package.
> >>
> >> If I search for "tidyv in R" I get tidyverse.
> >>
> >> Any idea why I did not get binGroup2 in the binGroup search?
> >>
> >> Regards,
> >> Tim
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> >> man_listinfo_r-2Dhelp&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> >> Rzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04nG
> >> i2PSLKn&s=1lwcSxFoUFNj5-s-czuFCrPlhteONuK8xl-a2CkpnVA&e=
> >> PLEASE do read the posting guide
> >> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> >> g_posting-2Dguide.html&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> >> sRzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04n
> >> Gi2PSLKn&s=rVBDL-rnzLnz-rie3bN1-pU8DPfnVxnJMTfbsKzW3nw&e=
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Mon Feb 28 20:47:45 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 28 Feb 2022 19:47:45 +0000
Subject: [R] Searching for packages
In-Reply-To: <CAGxFJbSt0m37FMzs7syvaoc+wu-FxEE0qEaeDT95ow1MLaFJSg@mail.gmail.com>
References: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <170d7701-6ac1-bca5-182a-bed93dfb4d6d@shdawson.com>
 <BN6PR2201MB15531739A3BF86A9EE3C71B1CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <91bdbde3-1134-6620-0e48-8dab9f21a80c@sapo.pt>
 <CAGxFJbSt0m37FMzs7syvaoc+wu-FxEE0qEaeDT95ow1MLaFJSg@mail.gmail.com>
Message-ID: <BN6PR2201MB1553AADAE42B7F835409BFFBCF019@BN6PR2201MB1553.namprd22.prod.outlook.com>

Thank you for the list.

-----Original Message-----
From: Bert Gunter <bgunter.4567 at gmail.com> 
Sent: Monday, February 28, 2022 10:47 AM
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: Ebert,Timothy Aaron <tebert at ufl.edu>; service at shdawson.com; r-help at r-project.org
Subject: Re: [R] Searching for packages

[External Email]

Other places beside google to look for R info:

https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTnFBnnDpaM&s=oi6J8PKSQJp4dd82zs3hlWnFQWnHaXrfDLawV-2gDkg&e=
https://urldefense.proofpoint.com/v2/url?u=https-3A__www.rdocumentation.org_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTnFBnnDpaM&s=WlC49B04XegAvmAosdabM_1CYDvQ3QHC6bzZ_-cVU00&e=
https://urldefense.proofpoint.com/v2/url?u=https-3A__rseek.org_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTnFBnnDpaM&s=3H-rSYG6BgbLVYLsFTZAOZBvPc43aw16HtLgcX4S2_o&e=

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 28, 2022 at 5:44 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Actually, I only found it at the second try. The RSiteSearch webpage 
> has a search bar, I've used it search binGroup* and found it on screen 3.
>
> Rui Barradas
>
> ?s 13:32 de 28/02/2022, Ebert,Timothy Aaron escreveu:
> > binGroup2 (version 1.02) was released 2020-04-07. There was one update on 2021-03-17 (according to available.versions("binGroup2").
> > My last system update was (I assume) recent. My system is governed by my University. I get monthly updates, rarely more often. My version of R is 4.1.
> > I tried Rui's suggestion (thank you) of searching using R. I read through the list several times but did not find binGroup2, though it is possible that it was there as binGroup.... and I need to open all the documents to find it.
> >
> > Tim
> >
> >
> > -----Original Message-----
> > From: Stephen H. Dawson, DSL <service at shdawson.com>
> > Sent: Monday, February 28, 2022 7:46 AM
> > To: Ebert,Timothy Aaron <tebert at ufl.edu>; r-help at r-project.org
> > Subject: Re: [R] Searching for packages
> >
> > [External Email]
> >
> > When was binGroup2 released?
> >
> > When is your last system update?
> >
> > *Stephen Dawson, DSL*
> > /Executive Strategy Consultant/
> > Business & Technology
> > +1 (865) 804-3454
> > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.shdawson.com
> > &d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=WEV48V
> > _ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04nGi2PSLKn&s=J6gEolZ
> > qXpDtRFdEzUW6R1ySBhZw3FgsLL2GoKQ1vg0&e=
> >
> >
> > On 2/28/22 07:36, Ebert,Timothy Aaron wrote:
> >> If I want help on a package I can usually go to google and type "package.name in r" and I get what I need in the first few hits. Google typically offers suggestions if my spelling is a bit off, and I get hits that are close. I searched for the binGroup package in the usual way and found that it is no longer supported. I asked the authors only to discover that there is a binGroup2 package.
> >>
> >> If I search for "tidyv in R" I get tidyverse.
> >>
> >> Any idea why I did not get binGroup2 in the binGroup search?
> >>
> >> Regards,
> >> Tim
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
> >> ail 
> >> man_listinfo_r-2Dhelp&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kV
> >> eAs 
> >> Rzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R0
> >> 4nG i2PSLKn&s=1lwcSxFoUFNj5-s-czuFCrPlhteONuK8xl-a2CkpnVA&e=
> >> PLEASE do read the posting guide
> >> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
> >> .or 
> >> g_posting-2Dguide.html&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2k
> >> VeA 
> >> sRzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R
> >> 04n Gi2PSLKn&s=rVBDL-rnzLnz-rie3bN1-pU8DPfnVxnJMTfbsKzW3nw&e=
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
> > ilman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2k
> > VeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg
> > 1hwTnFBnnDpaM&s=-RJNhDPRaNYddtXX_a_4NSLl92KUzBAvdX91A0YYgN8&e=
> > PLEASE do read the posting guide 
> > https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.
> > org_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2
> > kVeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhEl
> > g1hwTnFBnnDpaM&s=-K-KXw7glY_Yz9Sw6qmm_5TT3lkQvpBig2Dpj0m3nS8&e=
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> man_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
> Rzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTnF
> BnnDpaM&s=-RJNhDPRaNYddtXX_a_4NSLl92KUzBAvdX91A0YYgN8&e=
> PLEASE do read the posting guide 
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
> g_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
> sRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTn
> FBnnDpaM&s=-K-KXw7glY_Yz9Sw6qmm_5TT3lkQvpBig2Dpj0m3nS8&e=
> and provide commented, minimal, self-contained, reproducible code.

From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Mon Feb 28 21:43:51 2022
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Mon, 28 Feb 2022 14:43:51 -0600
Subject: [R] Searching for packages
In-Reply-To: <BN6PR2201MB1553AADAE42B7F835409BFFBCF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <BN6PR2201MB1553B05F97354D89182DE294CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <170d7701-6ac1-bca5-182a-bed93dfb4d6d@shdawson.com>
 <BN6PR2201MB15531739A3BF86A9EE3C71B1CF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <91bdbde3-1134-6620-0e48-8dab9f21a80c@sapo.pt>
 <CAGxFJbSt0m37FMzs7syvaoc+wu-FxEE0qEaeDT95ow1MLaFJSg@mail.gmail.com>
 <BN6PR2201MB1553AADAE42B7F835409BFFBCF019@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <a7ea3eb0-047d-ed45-95d0-c0084cca6867@effectivedefense.org>

	  There is also sos::findFn, discussed in a vignette included in that 
package.  When I created that package, I felt it was the fastest 
literature search for anything statistical:  It will identify all help 
pages that match a search string and sort them by package.  It creates 
an object so related searches can be combined by union or intersection. 
  And the print method by default creates two pages in your default 
browser, one listing the help pages and the second giving the package 
summary.


	  See also:


https://en.wikiversity.org/wiki/Searching_R_Packages


https://journal.r-project.org/archive/2018/RJ-2018-058/RJ-2018-058.pdf


	  sg


On 2/28/22 1:47 PM, Ebert,Timothy Aaron wrote:
> Thank you for the list.
> 
> -----Original Message-----
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Monday, February 28, 2022 10:47 AM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: Ebert,Timothy Aaron <tebert at ufl.edu>; service at shdawson.com; r-help at r-project.org
> Subject: Re: [R] Searching for packages
> 
> [External Email]
> 
> Other places beside google to look for R info:
> 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTnFBnnDpaM&s=oi6J8PKSQJp4dd82zs3hlWnFQWnHaXrfDLawV-2gDkg&e=
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.rdocumentation.org_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTnFBnnDpaM&s=WlC49B04XegAvmAosdabM_1CYDvQ3QHC6bzZ_-cVU00&e=
> https://urldefense.proofpoint.com/v2/url?u=https-3A__rseek.org_&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTnFBnnDpaM&s=3H-rSYG6BgbLVYLsFTZAOZBvPc43aw16HtLgcX4S2_o&e=
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Feb 28, 2022 at 5:44 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> Actually, I only found it at the second try. The RSiteSearch webpage
>> has a search bar, I've used it search binGroup* and found it on screen 3.
>>
>> Rui Barradas
>>
>> ?s 13:32 de 28/02/2022, Ebert,Timothy Aaron escreveu:
>>> binGroup2 (version 1.02) was released 2020-04-07. There was one update on 2021-03-17 (according to available.versions("binGroup2").
>>> My last system update was (I assume) recent. My system is governed by my University. I get monthly updates, rarely more often. My version of R is 4.1.
>>> I tried Rui's suggestion (thank you) of searching using R. I read through the list several times but did not find binGroup2, though it is possible that it was there as binGroup.... and I need to open all the documents to find it.
>>>
>>> Tim
>>>
>>>
>>> -----Original Message-----
>>> From: Stephen H. Dawson, DSL <service at shdawson.com>
>>> Sent: Monday, February 28, 2022 7:46 AM
>>> To: Ebert,Timothy Aaron <tebert at ufl.edu>; r-help at r-project.org
>>> Subject: Re: [R] Searching for packages
>>>
>>> [External Email]
>>>
>>> When was binGroup2 released?
>>>
>>> When is your last system update?
>>>
>>> *Stephen Dawson, DSL*
>>> /Executive Strategy Consultant/
>>> Business & Technology
>>> +1 (865) 804-3454
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.shdawson.com
>>> &d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAsRzsn7AkP-g&m=WEV48V
>>> _ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R04nGi2PSLKn&s=J6gEolZ
>>> qXpDtRFdEzUW6R1ySBhZw3FgsLL2GoKQ1vg0&e=
>>>
>>>
>>> On 2/28/22 07:36, Ebert,Timothy Aaron wrote:
>>>> If I want help on a package I can usually go to google and type "package.name in r" and I get what I need in the first few hits. Google typically offers suggestions if my spelling is a bit off, and I get hits that are close. I searched for the binGroup package in the usual way and found that it is no longer supported. I asked the authors only to discover that there is a binGroup2 package.
>>>>
>>>> If I search for "tidyv in R" I get tidyverse.
>>>>
>>>> Any idea why I did not get binGroup2 in the binGroup search?
>>>>
>>>> Regards,
>>>> Tim
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
>>>> ail
>>>> man_listinfo_r-2Dhelp&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kV
>>>> eAs
>>>> Rzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R0
>>>> 4nG i2PSLKn&s=1lwcSxFoUFNj5-s-czuFCrPlhteONuK8xl-a2CkpnVA&e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
>>>> .or
>>>> g_posting-2Dguide.html&d=DwICaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2k
>>>> VeA
>>>> sRzsn7AkP-g&m=WEV48V_ui8Oz-EeQtPAqqF1cRT83c11S15V05P3diVQoJspuLdN1R
>>>> 04n Gi2PSLKn&s=rVBDL-rnzLnz-rie3bN1-pU8DPfnVxnJMTfbsKzW3nw&e=
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
>>> ilman_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2k
>>> VeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg
>>> 1hwTnFBnnDpaM&s=-RJNhDPRaNYddtXX_a_4NSLl92KUzBAvdX91A0YYgN8&e=
>>> PLEASE do read the posting guide
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.
>>> org_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2
>>> kVeAsRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhEl
>>> g1hwTnFBnnDpaM&s=-K-KXw7glY_Yz9Sw6qmm_5TT3lkQvpBig2Dpj0m3nS8&e=
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>> man_listinfo_r-2Dhelp&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeAs
>> Rzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTnF
>> BnnDpaM&s=-RJNhDPRaNYddtXX_a_4NSLl92KUzBAvdX91A0YYgN8&e=
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>> g_posting-2Dguide.html&d=DwIFaQ&c=sJ6xIWYx-zLMB3EPkvcnVg&r=9PEhQh2kVeA
>> sRzsn7AkP-g&m=NX0Xg1Ds2e1R_R7VKRbwJ9Nj-9mEmj5NnaA8zGWLlX904sfhElg1hwTn
>> FBnnDpaM&s=-K-KXw7glY_Yz9Sw6qmm_5TT3lkQvpBig2Dpj0m3nS8&e=
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Feb 28 22:56:23 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 28 Feb 2022 22:56:23 +0100
Subject: [R] How to perform statistical test with multiple variables
Message-ID: <CA+nrPnu7nzs1K9wLL+ScCWoReM8qVA+UsNQPEmUWf=ajqgeyXQ@mail.gmail.com>

Hello everyone,

I have 'mean absolute error' values from different folds of CV of 6 ML
models..
a= c(0.3, 0.5, ..... 0.4)
b= c(0.4, 0.6,...... 0.2)
....
..
f= c(0.1, 0.4, .....0.5)
Now algorithm 'a' performed better than all the others (in terms of mean
absolute error scores) and then I used wilcoxon signed rank test to compare
'a' with all other models for significance difference.

Now, I have been asked to compare all the models with all others for
significant differences at once and not compare one with the other, how can
I do it, plz guide me? At this time, I just know about the Wilcoxon signed
rank test.
Regards

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Feb 28 23:14:29 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 1 Mar 2022 09:14:29 +1100
Subject: [R] How to perform statistical test with multiple variables
In-Reply-To: <CA+nrPnu7nzs1K9wLL+ScCWoReM8qVA+UsNQPEmUWf=ajqgeyXQ@mail.gmail.com>
References: <CA+nrPnu7nzs1K9wLL+ScCWoReM8qVA+UsNQPEmUWf=ajqgeyXQ@mail.gmail.com>
Message-ID: <CA+8X3fWrnRJf03QuJJm_UeFV4TuBzYx-4MmCTQ8okcm6siXrcQ@mail.gmail.com>

Hi neha,
Ouch! I've just been run over by homework. What you are probably being
asked to do is an "omnibus test", but I can't figure out what you are
actually testing. Maybe that phrase will help you in _your_ search for
the answer.

Jim

On Tue, Mar 1, 2022 at 8:56 AM Neha gupta <neha.bologna90 at gmail.com> wrote:
>
> Hello everyone,
>
> I have 'mean absolute error' values from different folds of CV of 6 ML
> models..
> a= c(0.3, 0.5, ..... 0.4)
> b= c(0.4, 0.6,...... 0.2)
> ....
> ..
> f= c(0.1, 0.4, .....0.5)
> Now algorithm 'a' performed better than all the others (in terms of mean
> absolute error scores) and then I used wilcoxon signed rank test to compare
> 'a' with all other models for significance difference.
>
> Now, I have been asked to compare all the models with all others for
> significant differences at once and not compare one with the other, how can
> I do it, plz guide me? At this time, I just know about the Wilcoxon signed
> rank test.
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Feb 28 23:28:29 2022
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 28 Feb 2022 23:28:29 +0100
Subject: [R] How to perform statistical test with multiple variables
In-Reply-To: <CA+8X3fWrnRJf03QuJJm_UeFV4TuBzYx-4MmCTQ8okcm6siXrcQ@mail.gmail.com>
References: <CA+nrPnu7nzs1K9wLL+ScCWoReM8qVA+UsNQPEmUWf=ajqgeyXQ@mail.gmail.com>
 <CA+8X3fWrnRJf03QuJJm_UeFV4TuBzYx-4MmCTQ8okcm6siXrcQ@mail.gmail.com>
Message-ID: <CA+nrPnv-cZzfvsaTd90-i9FifhEaPyUSM-BCQPNMRBh7scRnMg@mail.gmail.com>

Thank you Jim

I want to evaluate if there is a significant difference between several ML
models I have just run. Evaluation metric is Mean Absolute Error (MAE).
Values in brackets are MAE values of a particular model (e.g. RF) for
different folds of k-fold CV. I found that 'a' performed better (in terms
of MAE score) than the other models i.e. b, c, d, e.

But is there any significant difference ? I have used Wilcoxon test like
below:

wilcox.test(a, b, paired = T, conf.int = T, conf.level = 0.95) ,
then wilcox.test(a, c, paired = T, conf.int = T, conf.level = 0.95),
wilcox.test(a, d, paired = T, conf.int = T, conf.level = 0.95)   and so on,
I compared the best model with all the other models for statistical
differences.

Can I do a test which compares it in just one time (and one step) and not
repeating the wilcoxon test to compare the best model with all others.



a= c(0.3, 0.5, ..... 0.4)
b= c(0.4, 0.6,...... 0.2)
....
..
f= c(0.1, 0.4, .....0.5)

On Mon, Feb 28, 2022 at 11:14 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi neha,
> Ouch! I've just been run over by homework. What you are probably being
> asked to do is an "omnibus test", but I can't figure out what you are
> actually testing. Maybe that phrase will help you in _your_ search for
> the answer.
>
> Jim
>
> On Tue, Mar 1, 2022 at 8:56 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >
> > Hello everyone,
> >
> > I have 'mean absolute error' values from different folds of CV of 6 ML
> > models..
> > a= c(0.3, 0.5, ..... 0.4)
> > b= c(0.4, 0.6,...... 0.2)
> > ....
> > ..
> > f= c(0.1, 0.4, .....0.5)
> > Now algorithm 'a' performed better than all the others (in terms of mean
> > absolute error scores) and then I used wilcoxon signed rank test to
> compare
> > 'a' with all other models for significance difference.
> >
> > Now, I have been asked to compare all the models with all others for
> > significant differences at once and not compare one with the other, how
> can
> > I do it, plz guide me? At this time, I just know about the Wilcoxon
> signed
> > rank test.
> > Regards
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


