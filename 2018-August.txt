From drjimlemon @ending from gm@il@com  Wed Aug  1 00:04:05 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 1 Aug 2018 08:04:05 +1000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
Message-ID: <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>

Hi Diego,
I think the error is due to NA values in your data file. If I extend
your example and run it, I get no errors:

MyData<-read.table(text="103001930 103001580 103001530
1998-10-01 00:00:00 0.6 0 0
1998-10-01 01:00:00 0.2 0.2 0.2
1998-10-01 02:00:00 0.6 0.2 0.4
1998-10-01 03:00:00 0 0 0.6
1998-10-01 04:00:00 0 0 0
1998-10-01 05:00:00 0 0 0
1998-10-01 06:00:00 0 0 0
1998-10-01 07:00:00 0.2 0 0
1998-10-01 08:00:00 0.6 0 0
1998-10-01 09:00:00 0.2 0.2 0.2
1998-10-01 10:00:00 0.6 0.2 0.4
1998-10-01 11:00:00 0 0 0.6
1998-10-01 12:00:00 0 0 0
1998-10-01 13:00:00 0 0 0
1998-10-01 14:00:00 0 0 0
1998-10-01 15:00:00 0.2 0 0
1998-10-01 16:00:00 0.6 0 0
1998-10-01 17:00:00 0.2 0.2 0.2
1998-10-01 18:00:00 0.6 0.2 0.4
1998-10-01 19:00:00 0 0 0.6
1998-10-01 20:00:00 0 0 0
1998-10-01 21:00:00 0 0 0
1998-10-01 22:00:00 0 0 0
1998-10-01 23:00:00 0.2 0 0
1998-10-02 00:00:00 0.6 0 0
1998-10-02 01:00:00 0.2 0.2 0.2
1998-10-02 02:00:00 0.6 0.2 0.4
1998-10-02 03:00:00 0 0 0.6
1998-10-02 04:00:00 0 0 0
1998-10-02 05:00:00 0 0 0
1998-10-02 06:00:00 0 0 0
1998-10-02 07:00:00 0.2 0 0
1998-10-02 08:00:00 0.6 0 0
1998-10-02 09:00:00 0.2 0.2 0.2
1998-10-02 10:00:00 0.6 0.2 0.4
1998-10-02 11:00:00 0 0 0.6
1998-10-02 12:00:00 0 0 0
1998-10-02 13:00:00 0 0 0
1998-10-02 14:00:00 0 0 0
1998-10-02 15:00:00 0.2 0 0
1998-10-02 16:00:00 0.6 0 0
1998-10-02 17:00:00 0.2 0.2 0.2
1998-10-02 18:00:00 0.6 0.2 0.4
1998-10-02 19:00:00 0 0 0.6
1998-10-02 20:00:00 0 0 0
1998-10-02 21:00:00 0 0 0
1998-10-02 22:00:00 0 0 0
1998-10-02 23:00:00 0.2 0 0",
skip=1,stringsAsFactors=FALSE)
names(MyData)<-c("date","time","st1","st2","st3")
MyData$datetime<-strptime(paste(MyData$date,MyData$time),
 format="%Y-%m-%d %H:%M:%S")
MyData$datetime
st1_daily<-by(MyData$st1,MyData$date,mean)
st2_daily<-by(MyData$st2,MyData$date,mean)
st3_daily<-by(MyData$st3,MyData$date,mean)
st1_daily
st2_daily
st3_daily

Try adding na.rm=TRUE to the "by" calls:

st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)

Jim

On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani <diego.avesani at gmail.com> wrote:
> Dear all,
>
> I have still problem with date.
> Could you please tel me how to use POSIXct.
> Indeed I have found this command:
> timeAverage, but I am not able to convert MyDate to properly date.
>
> Thank a lot
> I hope to no bother you, at least too much
>
>
> Diego
>
>
> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com> wrote:
>>
>> Dear Jim, Dear all,
>>
>> thanks a lot.
>>
>> Unfortunately, I get the following error:
>>
>>
>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L, 925L,  :
>>   arguments must have same length
>>
>>
>> This is particularly strange. indeed, if I apply
>>
>>
>> mean(MyData$str1,na.rm=TRUE)
>>
>>
>> it works
>>
>>
>> Sorry, I have to learn a lot.
>> You are really boosting me
>>
>> Diego
>>
>>
>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Diego,
>>> One way you can get daily means is:
>>>
>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>>>
>>> Jim
>>>
>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani <diego.avesani at gmail.com>
>>> wrote:
>>> > Dear all,
>>> > I have found the error, my fault. Sorry.
>>> > There was an extra come in the headers line.
>>> > Thanks again.
>>> >
>>> > If I can I would like to ask you another questions about the imported
>>> > data.
>>> > I would like to compute the daily average of the different date.
>>> > Basically I
>>> > have hourly data, I would like to ave the daily mean of them.
>>> >
>>> > Is there some special commands?
>>> >
>>> > Thanks a lot.
>>> >
>>> >
>>> > Diego
>>> >
>>> >
>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
>>> > wrote:
>>> >>
>>> >> Dear all,
>>> >> I move to csv file because originally the date where in csv file.
>>> >> In addition, due to the fact that, as you told me, read.csv is a
>>> >> special
>>> >> case of read.table, I prefer start to learn from the simplest one.
>>> >> After that, I will try also the *.txt format.
>>> >>
>>> >> with read.csv, something strange happened:
>>> >>
>>> >> This us now the file:
>>> >>
>>> >> date,st1,st2,st3,
>>> >> 10/1/1998 0:00,0.6,0,0
>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>>> >> 10/1/1998 3:00,0,0,0.6
>>> >> 10/1/1998 4:00,0,0,0
>>> >> 10/1/1998 5:00,0,0,0
>>> >> 10/1/1998 6:00,0,0,0
>>> >> 10/1/1998 7:00,0.2,0,0
>>> >> 10/1/1998 8:00,0.6,0.2,0
>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>>> >> 10/1/1998 10:00,0,0.4,0.2
>>> >>
>>> >> When I apply:
>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>> >>
>>> >> this is the results:
>>> >>
>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>>> >>
>>> >> I do not understand why.
>>> >> Something wrong with date?
>>> >>
>>> >> really really thanks,
>>> >> I appreciate a lot all your helps.
>>> >>
>>> >> Diedro
>>> >>
>>> >>
>>> >> Diego
>>> >>
>>> >>
>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>>> >>>
>>> >>> Or, without removing the first line
>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>>> >>>
>>> >>> Another alternative,
>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>>> >>> since the dates appear to be in the default format.
>>> >>> (I generally prefer to work with datetimes in POSIXct class rather
>>> >>> than
>>> >>> POSIXlt class)
>>> >>>
>>> >>> -Don
>>> >>>
>>> >>> --
>>> >>> Don MacQueen
>>> >>> Lawrence Livermore National Laboratory
>>> >>> 7000 East Ave., L-627
>>> >>> Livermore, CA 94550
>>> >>> 925-423-1062
>>> >>> Lab cell 925-724-7509
>>> >>>
>>> >>>
>>> >>>
>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>>> >>> <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com>
>>> >>> wrote:
>>> >>>
>>> >>>     Hi Diego,
>>> >>>     You may have to do some conversion as you have three fields in
>>> >>> the
>>> >>>     first line using the default space separator and five fields in
>>> >>>     subsequent lines. If the first line doesn't contain any important
>>> >>> data
>>> >>>     you can just delete it or replace it with a meaningful header
>>> >>> line
>>> >>>     with five fields and save the file under another name.
>>> >>>
>>> >>>     It looks as thought you have date-time as two fields. If so, you
>>> >>> can
>>> >>>     just read the first field if you only want the date:
>>> >>>
>>> >>>     # assume you have removed the first line
>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>> >>>
>>> >>>     If you want the date/time:
>>> >>>
>>> >>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>>> >>> %H:%M:%S")
>>> >>>
>>> >>>     Jim
>>> >>>
>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>>> >>> <diego.avesani at gmail.com> wrote:
>>> >>>     > Dear all,
>>> >>>     >
>>> >>>     > I am dealing with the reading of a *.txt file.
>>> >>>     > The txt file the following shape:
>>> >>>     >
>>> >>>     > 103001930 103001580 103001530
>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>>> >>>     > 1998-10-01 04:00:00 0 0 0
>>> >>>     > 1998-10-01 05:00:00 0 0 0
>>> >>>     > 1998-10-01 06:00:00 0 0 0
>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>>> >>>     >
>>> >>>     > If it is possible I have a coupe of questions, which will sound
>>> >>> stupid but
>>> >>>     > they are important to me in order to understand ho R deal with
>>> >>> file
>>> >>> or date.
>>> >>>     >
>>> >>>     > 1) Do I have to convert it to a *csv file?
>>> >>>     > 2) Can a deal with space and not ","
>>> >>>     > 3) How can I read date?
>>> >>>     >
>>> >>>     > thanks a lot to all of you,
>>> >>>     > Thanks
>>> >>>     >
>>> >>>     >
>>> >>>     > Diego
>>> >>>     >
>>> >>>     >         [[alternative HTML version deleted]]
>>> >>>     >
>>> >>>     > ______________________________________________
>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> >>> see
>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>     > PLEASE do read the posting guide
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>>     > and provide commented, minimal, self-contained, reproducible
>>> >>> code.
>>> >>>
>>> >>>     ______________________________________________
>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>     PLEASE do read the posting guide
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>>     and provide commented, minimal, self-contained, reproducible
>>> >>> code.
>>> >>>
>>> >>>
>>> >>
>>> >
>>
>>
>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Aug  1 01:01:48 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 31 Jul 2018 16:01:48 -0700
Subject: [R] read txt file - date - no space
In-Reply-To: <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
Message-ID: <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>

... and the most common source of NA values in time data is wrong timezones. You really need to make sure the timezone that is assumed when the character data are converted to POSIXt agrees with the data. In most cases the easiest way to insure this is to use

Sys.setenv(TZ="US/Pacific")

or whatever timezone from

OlsonNames()

corresponds with your data. Execute this setenv function before the strptime or as.POSIXct() function call.

You can use 

MyData[ is.na(MyData$datetime), ]

to see which records are failing to convert time.

[1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1

On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Diego,
>I think the error is due to NA values in your data file. If I extend
>your example and run it, I get no errors:
>
>MyData<-read.table(text="103001930 103001580 103001530
>1998-10-01 00:00:00 0.6 0 0
>1998-10-01 01:00:00 0.2 0.2 0.2
>1998-10-01 02:00:00 0.6 0.2 0.4
>1998-10-01 03:00:00 0 0 0.6
>1998-10-01 04:00:00 0 0 0
>1998-10-01 05:00:00 0 0 0
>1998-10-01 06:00:00 0 0 0
>1998-10-01 07:00:00 0.2 0 0
>1998-10-01 08:00:00 0.6 0 0
>1998-10-01 09:00:00 0.2 0.2 0.2
>1998-10-01 10:00:00 0.6 0.2 0.4
>1998-10-01 11:00:00 0 0 0.6
>1998-10-01 12:00:00 0 0 0
>1998-10-01 13:00:00 0 0 0
>1998-10-01 14:00:00 0 0 0
>1998-10-01 15:00:00 0.2 0 0
>1998-10-01 16:00:00 0.6 0 0
>1998-10-01 17:00:00 0.2 0.2 0.2
>1998-10-01 18:00:00 0.6 0.2 0.4
>1998-10-01 19:00:00 0 0 0.6
>1998-10-01 20:00:00 0 0 0
>1998-10-01 21:00:00 0 0 0
>1998-10-01 22:00:00 0 0 0
>1998-10-01 23:00:00 0.2 0 0
>1998-10-02 00:00:00 0.6 0 0
>1998-10-02 01:00:00 0.2 0.2 0.2
>1998-10-02 02:00:00 0.6 0.2 0.4
>1998-10-02 03:00:00 0 0 0.6
>1998-10-02 04:00:00 0 0 0
>1998-10-02 05:00:00 0 0 0
>1998-10-02 06:00:00 0 0 0
>1998-10-02 07:00:00 0.2 0 0
>1998-10-02 08:00:00 0.6 0 0
>1998-10-02 09:00:00 0.2 0.2 0.2
>1998-10-02 10:00:00 0.6 0.2 0.4
>1998-10-02 11:00:00 0 0 0.6
>1998-10-02 12:00:00 0 0 0
>1998-10-02 13:00:00 0 0 0
>1998-10-02 14:00:00 0 0 0
>1998-10-02 15:00:00 0.2 0 0
>1998-10-02 16:00:00 0.6 0 0
>1998-10-02 17:00:00 0.2 0.2 0.2
>1998-10-02 18:00:00 0.6 0.2 0.4
>1998-10-02 19:00:00 0 0 0.6
>1998-10-02 20:00:00 0 0 0
>1998-10-02 21:00:00 0 0 0
>1998-10-02 22:00:00 0 0 0
>1998-10-02 23:00:00 0.2 0 0",
>skip=1,stringsAsFactors=FALSE)
>names(MyData)<-c("date","time","st1","st2","st3")
>MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> format="%Y-%m-%d %H:%M:%S")
>MyData$datetime
>st1_daily<-by(MyData$st1,MyData$date,mean)
>st2_daily<-by(MyData$st2,MyData$date,mean)
>st3_daily<-by(MyData$st3,MyData$date,mean)
>st1_daily
>st2_daily
>st3_daily
>
>Try adding na.rm=TRUE to the "by" calls:
>
>st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
>st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
>st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
>
>Jim
>
>On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
><diego.avesani at gmail.com> wrote:
>> Dear all,
>>
>> I have still problem with date.
>> Could you please tel me how to use POSIXct.
>> Indeed I have found this command:
>> timeAverage, but I am not able to convert MyDate to properly date.
>>
>> Thank a lot
>> I hope to no bother you, at least too much
>>
>>
>> Diego
>>
>>
>> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
>wrote:
>>>
>>> Dear Jim, Dear all,
>>>
>>> thanks a lot.
>>>
>>> Unfortunately, I get the following error:
>>>
>>>
>>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
>925L,  :
>>>   arguments must have same length
>>>
>>>
>>> This is particularly strange. indeed, if I apply
>>>
>>>
>>> mean(MyData$str1,na.rm=TRUE)
>>>
>>>
>>> it works
>>>
>>>
>>> Sorry, I have to learn a lot.
>>> You are really boosting me
>>>
>>> Diego
>>>
>>>
>>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>
>>>> Hi Diego,
>>>> One way you can get daily means is:
>>>>
>>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>>>>
>>>> Jim
>>>>
>>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
><diego.avesani at gmail.com>
>>>> wrote:
>>>> > Dear all,
>>>> > I have found the error, my fault. Sorry.
>>>> > There was an extra come in the headers line.
>>>> > Thanks again.
>>>> >
>>>> > If I can I would like to ask you another questions about the
>imported
>>>> > data.
>>>> > I would like to compute the daily average of the different date.
>>>> > Basically I
>>>> > have hourly data, I would like to ave the daily mean of them.
>>>> >
>>>> > Is there some special commands?
>>>> >
>>>> > Thanks a lot.
>>>> >
>>>> >
>>>> > Diego
>>>> >
>>>> >
>>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
>>>> > wrote:
>>>> >>
>>>> >> Dear all,
>>>> >> I move to csv file because originally the date where in csv
>file.
>>>> >> In addition, due to the fact that, as you told me, read.csv is a
>>>> >> special
>>>> >> case of read.table, I prefer start to learn from the simplest
>one.
>>>> >> After that, I will try also the *.txt format.
>>>> >>
>>>> >> with read.csv, something strange happened:
>>>> >>
>>>> >> This us now the file:
>>>> >>
>>>> >> date,st1,st2,st3,
>>>> >> 10/1/1998 0:00,0.6,0,0
>>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>>>> >> 10/1/1998 3:00,0,0,0.6
>>>> >> 10/1/1998 4:00,0,0,0
>>>> >> 10/1/1998 5:00,0,0,0
>>>> >> 10/1/1998 6:00,0,0,0
>>>> >> 10/1/1998 7:00,0.2,0,0
>>>> >> 10/1/1998 8:00,0.6,0.2,0
>>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>>>> >> 10/1/1998 10:00,0,0.4,0.2
>>>> >>
>>>> >> When I apply:
>>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>>> >>
>>>> >> this is the results:
>>>> >>
>>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>>>> >>
>>>> >> I do not understand why.
>>>> >> Something wrong with date?
>>>> >>
>>>> >> really really thanks,
>>>> >> I appreciate a lot all your helps.
>>>> >>
>>>> >> Diedro
>>>> >>
>>>> >>
>>>> >> Diego
>>>> >>
>>>> >>
>>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
>wrote:
>>>> >>>
>>>> >>> Or, without removing the first line
>>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>>>> >>>
>>>> >>> Another alternative,
>>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>>>> >>> since the dates appear to be in the default format.
>>>> >>> (I generally prefer to work with datetimes in POSIXct class
>rather
>>>> >>> than
>>>> >>> POSIXlt class)
>>>> >>>
>>>> >>> -Don
>>>> >>>
>>>> >>> --
>>>> >>> Don MacQueen
>>>> >>> Lawrence Livermore National Laboratory
>>>> >>> 7000 East Ave., L-627
>>>> >>> Livermore, CA 94550
>>>> >>> 925-423-1062
>>>> >>> Lab cell 925-724-7509
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>>>> >>> <r-help-bounces at r-project.org on behalf of
>drjimlemon at gmail.com>
>>>> >>> wrote:
>>>> >>>
>>>> >>>     Hi Diego,
>>>> >>>     You may have to do some conversion as you have three fields
>in
>>>> >>> the
>>>> >>>     first line using the default space separator and five
>fields in
>>>> >>>     subsequent lines. If the first line doesn't contain any
>important
>>>> >>> data
>>>> >>>     you can just delete it or replace it with a meaningful
>header
>>>> >>> line
>>>> >>>     with five fields and save the file under another name.
>>>> >>>
>>>> >>>     It looks as thought you have date-time as two fields. If
>so, you
>>>> >>> can
>>>> >>>     just read the first field if you only want the date:
>>>> >>>
>>>> >>>     # assume you have removed the first line
>>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>>> >>>
>>>> >>>     If you want the date/time:
>>>> >>>
>>>> >>>    
>dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>>>> >>> %H:%M:%S")
>>>> >>>
>>>> >>>     Jim
>>>> >>>
>>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>>>> >>> <diego.avesani at gmail.com> wrote:
>>>> >>>     > Dear all,
>>>> >>>     >
>>>> >>>     > I am dealing with the reading of a *.txt file.
>>>> >>>     > The txt file the following shape:
>>>> >>>     >
>>>> >>>     > 103001930 103001580 103001530
>>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>>>> >>>     > 1998-10-01 04:00:00 0 0 0
>>>> >>>     > 1998-10-01 05:00:00 0 0 0
>>>> >>>     > 1998-10-01 06:00:00 0 0 0
>>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>>>> >>>     >
>>>> >>>     > If it is possible I have a coupe of questions, which will
>sound
>>>> >>> stupid but
>>>> >>>     > they are important to me in order to understand ho R deal
>with
>>>> >>> file
>>>> >>> or date.
>>>> >>>     >
>>>> >>>     > 1) Do I have to convert it to a *csv file?
>>>> >>>     > 2) Can a deal with space and not ","
>>>> >>>     > 3) How can I read date?
>>>> >>>     >
>>>> >>>     > thanks a lot to all of you,
>>>> >>>     > Thanks
>>>> >>>     >
>>>> >>>     >
>>>> >>>     > Diego
>>>> >>>     >
>>>> >>>     >         [[alternative HTML version deleted]]
>>>> >>>     >
>>>> >>>     > ______________________________________________
>>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more,
>>>> >>> see
>>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>     > PLEASE do read the posting guide
>>>> >>> http://www.R-project.org/posting-guide.html
>>>> >>>     > and provide commented, minimal, self-contained,
>reproducible
>>>> >>> code.
>>>> >>>
>>>> >>>     ______________________________________________
>>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more, see
>>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>     PLEASE do read the posting guide
>>>> >>> http://www.R-project.org/posting-guide.html
>>>> >>>     and provide commented, minimal, self-contained,
>reproducible
>>>> >>> code.
>>>> >>>
>>>> >>>
>>>> >>
>>>> >
>>>
>>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @tyen @ending from ntu@edu@tw  Wed Aug  1 08:35:21 2018
From: @tyen @ending from ntu@edu@tw (Steven Yen)
Date: Wed, 1 Aug 2018 14:35:21 +0800
Subject: [R] Problem with Rtools version 3.5.0.4
In-Reply-To: <f0bbfe43-f123-7939-251e-dac280331408@gmail.com>
References: <f0bbfe43-f123-7939-251e-dac280331408@gmail.com>
Message-ID: <cf7eb226-f447-1079-547b-5334ab4a9b36@ntu.edu.tw>

I am trying to build an R package with Rtools version 3.5.0.4 along with 
R-3.5.1
using the following? sequence of commands:

File -> Open Project -> Build -> Build Binary Package

I received the following error message:

zip I/O error: No such file or directory
zip error: Temporary file failure (Y:/ziPu2G1b)
running 'zip' failed

I then removed Rtools version 3.5.0.4 and installed Rtools version 3.4. 
It worked. What am I missing? Or, shall I wait till the next version of 
Rtools?

Full log file below.

==> Rcmd.exe INSTALL --build --preclean yenlib3

* installing to library 'C:/Users/syen01/Documents/R/win-library/3.5'
* installing *source* package 'yenlib3' ...
** R
** data
*** moving datasets to lazyload DB
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
 ? converting help for package 'yenlib3'
 ??? finding HTML links ... done
 ??? aids??????????????????????????????????? html
 ??? all.variables?????????????????????????? html
 ??? ate.boprobit??????????????????????????? html
(list truncated)
 ??? ate.boprobitE0????????????????????????? html
 ??? zxcombined????????????????????????????? html
** building package indices
** testing if installed package can be loaded
*** arch - i386
*** arch - x64
* MD5 sums
zip I/O error: No such file or directory
zip error: Temporary file failure (Y:/ziPu2G1b)
running 'zip' failed
* DONE (yenlib3)
In R CMD INSTALL

Binary package written to Y:/
-- 

styen at ntu.edu.tw (S.T. Yen)


	[[alternative HTML version deleted]]


From diego@@ve@@ni @ending from gm@il@com  Wed Aug  1 08:54:38 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Wed, 1 Aug 2018 08:54:38 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
Message-ID: <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>

Dear all,
I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
all again in order to understand.
If I could I would like to start again, without mixing strategy and waiting
for your advice.

I am really appreciate you help, really really.
Here my new file, a *.csv file (buy the way, it is possible to attach it in
the mailing list?)

date,str1,str2,str3
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0


I read it as:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

at this point I would like to have the daily mean.
What would you suggest?

Really Really thanks,
You are my lifesaver

Thanks



Diego


On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> ... and the most common source of NA values in time data is wrong
> timezones. You really need to make sure the timezone that is assumed when
> the character data are converted to POSIXt agrees with the data. In most
> cases the easiest way to insure this is to use
>
> Sys.setenv(TZ="US/Pacific")
>
> or whatever timezone from
>
> OlsonNames()
>
> corresponds with your data. Execute this setenv function before the
> strptime or as.POSIXct() function call.
>
> You can use
>
> MyData[ is.na(MyData$datetime), ]
>
> to see which records are failing to convert time.
>
> [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>
> On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> >Hi Diego,
> >I think the error is due to NA values in your data file. If I extend
> >your example and run it, I get no errors:
> >
> >MyData<-read.table(text="103001930 103001580 103001530
> >1998-10-01 00:00:00 0.6 0 0
> >1998-10-01 01:00:00 0.2 0.2 0.2
> >1998-10-01 02:00:00 0.6 0.2 0.4
> >1998-10-01 03:00:00 0 0 0.6
> >1998-10-01 04:00:00 0 0 0
> >1998-10-01 05:00:00 0 0 0
> >1998-10-01 06:00:00 0 0 0
> >1998-10-01 07:00:00 0.2 0 0
> >1998-10-01 08:00:00 0.6 0 0
> >1998-10-01 09:00:00 0.2 0.2 0.2
> >1998-10-01 10:00:00 0.6 0.2 0.4
> >1998-10-01 11:00:00 0 0 0.6
> >1998-10-01 12:00:00 0 0 0
> >1998-10-01 13:00:00 0 0 0
> >1998-10-01 14:00:00 0 0 0
> >1998-10-01 15:00:00 0.2 0 0
> >1998-10-01 16:00:00 0.6 0 0
> >1998-10-01 17:00:00 0.2 0.2 0.2
> >1998-10-01 18:00:00 0.6 0.2 0.4
> >1998-10-01 19:00:00 0 0 0.6
> >1998-10-01 20:00:00 0 0 0
> >1998-10-01 21:00:00 0 0 0
> >1998-10-01 22:00:00 0 0 0
> >1998-10-01 23:00:00 0.2 0 0
> >1998-10-02 00:00:00 0.6 0 0
> >1998-10-02 01:00:00 0.2 0.2 0.2
> >1998-10-02 02:00:00 0.6 0.2 0.4
> >1998-10-02 03:00:00 0 0 0.6
> >1998-10-02 04:00:00 0 0 0
> >1998-10-02 05:00:00 0 0 0
> >1998-10-02 06:00:00 0 0 0
> >1998-10-02 07:00:00 0.2 0 0
> >1998-10-02 08:00:00 0.6 0 0
> >1998-10-02 09:00:00 0.2 0.2 0.2
> >1998-10-02 10:00:00 0.6 0.2 0.4
> >1998-10-02 11:00:00 0 0 0.6
> >1998-10-02 12:00:00 0 0 0
> >1998-10-02 13:00:00 0 0 0
> >1998-10-02 14:00:00 0 0 0
> >1998-10-02 15:00:00 0.2 0 0
> >1998-10-02 16:00:00 0.6 0 0
> >1998-10-02 17:00:00 0.2 0.2 0.2
> >1998-10-02 18:00:00 0.6 0.2 0.4
> >1998-10-02 19:00:00 0 0 0.6
> >1998-10-02 20:00:00 0 0 0
> >1998-10-02 21:00:00 0 0 0
> >1998-10-02 22:00:00 0 0 0
> >1998-10-02 23:00:00 0.2 0 0",
> >skip=1,stringsAsFactors=FALSE)
> >names(MyData)<-c("date","time","st1","st2","st3")
> >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > format="%Y-%m-%d %H:%M:%S")
> >MyData$datetime
> >st1_daily<-by(MyData$st1,MyData$date,mean)
> >st2_daily<-by(MyData$st2,MyData$date,mean)
> >st3_daily<-by(MyData$st3,MyData$date,mean)
> >st1_daily
> >st2_daily
> >st3_daily
> >
> >Try adding na.rm=TRUE to the "by" calls:
> >
> >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> >
> >Jim
> >
> >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> ><diego.avesani at gmail.com> wrote:
> >> Dear all,
> >>
> >> I have still problem with date.
> >> Could you please tel me how to use POSIXct.
> >> Indeed I have found this command:
> >> timeAverage, but I am not able to convert MyDate to properly date.
> >>
> >> Thank a lot
> >> I hope to no bother you, at least too much
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> >wrote:
> >>>
> >>> Dear Jim, Dear all,
> >>>
> >>> thanks a lot.
> >>>
> >>> Unfortunately, I get the following error:
> >>>
> >>>
> >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> >925L,  :
> >>>   arguments must have same length
> >>>
> >>>
> >>> This is particularly strange. indeed, if I apply
> >>>
> >>>
> >>> mean(MyData$str1,na.rm=TRUE)
> >>>
> >>>
> >>> it works
> >>>
> >>>
> >>> Sorry, I have to learn a lot.
> >>> You are really boosting me
> >>>
> >>> Diego
> >>>
> >>>
> >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>>>
> >>>> Hi Diego,
> >>>> One way you can get daily means is:
> >>>>
> >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> >>>>
> >>>> Jim
> >>>>
> >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> ><diego.avesani at gmail.com>
> >>>> wrote:
> >>>> > Dear all,
> >>>> > I have found the error, my fault. Sorry.
> >>>> > There was an extra come in the headers line.
> >>>> > Thanks again.
> >>>> >
> >>>> > If I can I would like to ask you another questions about the
> >imported
> >>>> > data.
> >>>> > I would like to compute the daily average of the different date.
> >>>> > Basically I
> >>>> > have hourly data, I would like to ave the daily mean of them.
> >>>> >
> >>>> > Is there some special commands?
> >>>> >
> >>>> > Thanks a lot.
> >>>> >
> >>>> >
> >>>> > Diego
> >>>> >
> >>>> >
> >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
> >>>> > wrote:
> >>>> >>
> >>>> >> Dear all,
> >>>> >> I move to csv file because originally the date where in csv
> >file.
> >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> >>>> >> special
> >>>> >> case of read.table, I prefer start to learn from the simplest
> >one.
> >>>> >> After that, I will try also the *.txt format.
> >>>> >>
> >>>> >> with read.csv, something strange happened:
> >>>> >>
> >>>> >> This us now the file:
> >>>> >>
> >>>> >> date,st1,st2,st3,
> >>>> >> 10/1/1998 0:00,0.6,0,0
> >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> >>>> >> 10/1/1998 3:00,0,0,0.6
> >>>> >> 10/1/1998 4:00,0,0,0
> >>>> >> 10/1/1998 5:00,0,0,0
> >>>> >> 10/1/1998 6:00,0,0,0
> >>>> >> 10/1/1998 7:00,0.2,0,0
> >>>> >> 10/1/1998 8:00,0.6,0.2,0
> >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> >>>> >> 10/1/1998 10:00,0,0.4,0.2
> >>>> >>
> >>>> >> When I apply:
> >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>>> >>
> >>>> >> this is the results:
> >>>> >>
> >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>>> >>
> >>>> >> I do not understand why.
> >>>> >> Something wrong with date?
> >>>> >>
> >>>> >> really really thanks,
> >>>> >> I appreciate a lot all your helps.
> >>>> >>
> >>>> >> Diedro
> >>>> >>
> >>>> >>
> >>>> >> Diego
> >>>> >>
> >>>> >>
> >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> >wrote:
> >>>> >>>
> >>>> >>> Or, without removing the first line
> >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>> >>>
> >>>> >>> Another alternative,
> >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>>> >>> since the dates appear to be in the default format.
> >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> >rather
> >>>> >>> than
> >>>> >>> POSIXlt class)
> >>>> >>>
> >>>> >>> -Don
> >>>> >>>
> >>>> >>> --
> >>>> >>> Don MacQueen
> >>>> >>> Lawrence Livermore National Laboratory
> >>>> >>> 7000 East Ave., L-627
> >>>> >>> Livermore, CA 94550
> >>>> >>> 925-423-1062
> >>>> >>> Lab cell 925-724-7509
> >>>> >>>
> >>>> >>>
> >>>> >>>
> >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>>> >>> <r-help-bounces at r-project.org on behalf of
> >drjimlemon at gmail.com>
> >>>> >>> wrote:
> >>>> >>>
> >>>> >>>     Hi Diego,
> >>>> >>>     You may have to do some conversion as you have three fields
> >in
> >>>> >>> the
> >>>> >>>     first line using the default space separator and five
> >fields in
> >>>> >>>     subsequent lines. If the first line doesn't contain any
> >important
> >>>> >>> data
> >>>> >>>     you can just delete it or replace it with a meaningful
> >header
> >>>> >>> line
> >>>> >>>     with five fields and save the file under another name.
> >>>> >>>
> >>>> >>>     It looks as thought you have date-time as two fields. If
> >so, you
> >>>> >>> can
> >>>> >>>     just read the first field if you only want the date:
> >>>> >>>
> >>>> >>>     # assume you have removed the first line
> >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>> >>>
> >>>> >>>     If you want the date/time:
> >>>> >>>
> >>>> >>>
> >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>>> >>> %H:%M:%S")
> >>>> >>>
> >>>> >>>     Jim
> >>>> >>>
> >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>>> >>> <diego.avesani at gmail.com> wrote:
> >>>> >>>     > Dear all,
> >>>> >>>     >
> >>>> >>>     > I am dealing with the reading of a *.txt file.
> >>>> >>>     > The txt file the following shape:
> >>>> >>>     >
> >>>> >>>     > 103001930 103001580 103001530
> >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>> >>>     >
> >>>> >>>     > If it is possible I have a coupe of questions, which will
> >sound
> >>>> >>> stupid but
> >>>> >>>     > they are important to me in order to understand ho R deal
> >with
> >>>> >>> file
> >>>> >>> or date.
> >>>> >>>     >
> >>>> >>>     > 1) Do I have to convert it to a *csv file?
> >>>> >>>     > 2) Can a deal with space and not ","
> >>>> >>>     > 3) How can I read date?
> >>>> >>>     >
> >>>> >>>     > thanks a lot to all of you,
> >>>> >>>     > Thanks
> >>>> >>>     >
> >>>> >>>     >
> >>>> >>>     > Diego
> >>>> >>>     >
> >>>> >>>     >         [[alternative HTML version deleted]]
> >>>> >>>     >
> >>>> >>>     > ______________________________________________
> >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more,
> >>>> >>> see
> >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     > PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     > and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>     ______________________________________________
> >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more, see
> >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>
> >>>> >>
> >>>> >
> >>>
> >>>
> >>
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Aug  1 13:58:59 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 1 Aug 2018 11:58:59 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
Message-ID: <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>

Hi

I did not get through all answers you already got and you probably obtained similar advice as mine.

# read data (if you have csv file just use read.csv)
> test<-read.table("clipboard", header=T, sep=",")

# control your object(s)
> str(test)
'data.frame':   8 obs. of  4 variables:
 $ date: Factor w/ 8 levels "10/1/1998 0:00",..: 1 2 3 4 5 6 7 8
 $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2
 $ str2: num  0 0.2 0.2 0 0 0 0 0
 $ str3: num  0 0.2 0.4 0.6 0 0 0 0

#if it is OK change first column to real date by POSIXct
test$date<-as.POSIXct(test$date, format="%d/%m/%Y %H:%M")

#attach lubridate
> library(lubridate)

# aggregate your object(s) and use lubridate function

> aggregate(test[,-1], list(day(test$date)), mean)
  Group.1 str1 str2 str3
1      10  0.2 0.05 0.15

# or format function

> aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
     Group.1 str1 str2 str3
1 1998-01-10  0.2 0.05 0.15

If it does not work with your data you should post at least result of

str(yourdata)

or preferably

dput(yourdata[1:20,])

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Diego Avesani
> Sent: Wednesday, August 1, 2018 8:55 AM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] read txt file - date - no space
>
> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat all again
> in order to understand.
> If I could I would like to start again, without mixing strategy and waiting for
> your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in the
> mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed
> > when the character data are converted to POSIXt agrees with the data.
> > In most cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani
> > >>>> > <diego.avesani at gmail.com>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is
> > >>>> >> a special case of read.table, I prefer start to learn from the
> > >>>> >> simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
> > >>>> >>> skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > >drjimlemon at gmail.com>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three
> > >>>> >>> fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which
> > >>>> >>> will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R
> > >>>> >>> deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From diego@@ve@@ni @ending from gm@il@com  Wed Aug  1 14:29:53 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Wed, 1 Aug 2018 14:29:53 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>

Dear Pikal, Deal all,

again really thank.

it seems not working.
Some specifications: My non data are -999, but I could change it.

My final results is:

1        1  -55.86242 -55.84764660 -277.4775
2        2  -55.47554 -94.58921682 -277.4845
3        3  -55.47095 -99.20239198 -277.4709
4        4  -55.46470 -55.45952932 -392.9071
5        5  -55.43335 -55.40171682 -388.4110
6        6  -55.40108 -55.37399691 -332.9068
7        7  -55.39201 -55.35156250 -332.8902
8        8 -110.87184   0.16136188 -281.8230
9        9 -110.95077 -55.63856096 -332.9564
10      10 -157.64430  -0.06602705 -315.3840
11      11 -105.06157   0.11507675 -315.4152
12      12  -70.08677 -52.54501096 -316.7247


So it is not correct.
For example for the first day in my csv I would have expected 0.167.

I am going to post what you have suggested:

for  str(MyData)

'data.frame': 160008 obs. of  4 variables:
 $ date: POSIXct, format: "1998-01-10 00:00:00" "1998-01-10 01:00:00"
"1998-01-10 02:00:00" "1998-01-10 03:00:00" ...
 $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
 $ str2: num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
 $ str3: num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...

unfortunately, I am not able to post

dput(str[1:20,])

it gives me

Error in str[1:20, ] : object of type 'closure' is not subsettable


Thanks again,
I hope that what I posted could be enough in order to help me.



Diego


On 1 August 2018 at 13:58, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> I did not get through all answers you already got and you probably
> obtained similar advice as mine.
>
> # read data (if you have csv file just use read.csv)
> > test<-read.table("clipboard", header=T, sep=",")
>
> # control your object(s)
> > str(test)
> 'data.frame':   8 obs. of  4 variables:
>  $ date: Factor w/ 8 levels "10/1/1998 0:00",..: 1 2 3 4 5 6 7 8
>  $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2
>  $ str2: num  0 0.2 0.2 0 0 0 0 0
>  $ str3: num  0 0.2 0.4 0.6 0 0 0 0
>
> #if it is OK change first column to real date by POSIXct
> test$date<-as.POSIXct(test$date, format="%d/%m/%Y %H:%M")
>
> #attach lubridate
> > library(lubridate)
>
> # aggregate your object(s) and use lubridate function
>
> > aggregate(test[,-1], list(day(test$date)), mean)
>   Group.1 str1 str2 str3
> 1      10  0.2 0.05 0.15
>
> # or format function
>
> > aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
>      Group.1 str1 str2 str3
> 1 1998-01-10  0.2 0.05 0.15
>
> If it does not work with your data you should post at least result of
>
> str(yourdata)
>
> or preferably
>
> dput(yourdata[1:20,])
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Diego Avesani
> > Sent: Wednesday, August 1, 2018 8:55 AM
> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] read txt file - date - no space
> >
> > Dear all,
> > I am sorry, I did a lot of confusion. I am sorry, I have to relax and
> stat all again
> > in order to understand.
> > If I could I would like to start again, without mixing strategy and
> waiting for
> > your advice.
> >
> > I am really appreciate you help, really really.
> > Here my new file, a *.csv file (buy the way, it is possible to attach it
> in the
> > mailing list?)
> >
> > date,str1,str2,str3
> > 10/1/1998 0:00,0.6,0,0
> > 10/1/1998 1:00,0.2,0.2,0.2
> > 10/1/1998 2:00,0.6,0.2,0.4
> > 10/1/1998 3:00,0,0,0.6
> > 10/1/1998 4:00,0,0,0
> > 10/1/1998 5:00,0,0,0
> > 10/1/1998 6:00,0,0,0
> > 10/1/1998 7:00,0.2,0,0
> >
> >
> > I read it as:
> > MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >
> > at this point I would like to have the daily mean.
> > What would you suggest?
> >
> > Really Really thanks,
> > You are my lifesaver
> >
> > Thanks
> >
> >
> >
> > Diego
> >
> >
> > On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > > ... and the most common source of NA values in time data is wrong
> > > timezones. You really need to make sure the timezone that is assumed
> > > when the character data are converted to POSIXt agrees with the data.
> > > In most cases the easiest way to insure this is to use
> > >
> > > Sys.setenv(TZ="US/Pacific")
> > >
> > > or whatever timezone from
> > >
> > > OlsonNames()
> > >
> > > corresponds with your data. Execute this setenv function before the
> > > strptime or as.POSIXct() function call.
> > >
> > > You can use
> > >
> > > MyData[ is.na(MyData$datetime), ]
> > >
> > > to see which records are failing to convert time.
> > >
> > > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> > >
> > > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
> > wrote:
> > > >Hi Diego,
> > > >I think the error is due to NA values in your data file. If I extend
> > > >your example and run it, I get no errors:
> > > >
> > > >MyData<-read.table(text="103001930 103001580 103001530
> > > >1998-10-01 00:00:00 0.6 0 0
> > > >1998-10-01 01:00:00 0.2 0.2 0.2
> > > >1998-10-01 02:00:00 0.6 0.2 0.4
> > > >1998-10-01 03:00:00 0 0 0.6
> > > >1998-10-01 04:00:00 0 0 0
> > > >1998-10-01 05:00:00 0 0 0
> > > >1998-10-01 06:00:00 0 0 0
> > > >1998-10-01 07:00:00 0.2 0 0
> > > >1998-10-01 08:00:00 0.6 0 0
> > > >1998-10-01 09:00:00 0.2 0.2 0.2
> > > >1998-10-01 10:00:00 0.6 0.2 0.4
> > > >1998-10-01 11:00:00 0 0 0.6
> > > >1998-10-01 12:00:00 0 0 0
> > > >1998-10-01 13:00:00 0 0 0
> > > >1998-10-01 14:00:00 0 0 0
> > > >1998-10-01 15:00:00 0.2 0 0
> > > >1998-10-01 16:00:00 0.6 0 0
> > > >1998-10-01 17:00:00 0.2 0.2 0.2
> > > >1998-10-01 18:00:00 0.6 0.2 0.4
> > > >1998-10-01 19:00:00 0 0 0.6
> > > >1998-10-01 20:00:00 0 0 0
> > > >1998-10-01 21:00:00 0 0 0
> > > >1998-10-01 22:00:00 0 0 0
> > > >1998-10-01 23:00:00 0.2 0 0
> > > >1998-10-02 00:00:00 0.6 0 0
> > > >1998-10-02 01:00:00 0.2 0.2 0.2
> > > >1998-10-02 02:00:00 0.6 0.2 0.4
> > > >1998-10-02 03:00:00 0 0 0.6
> > > >1998-10-02 04:00:00 0 0 0
> > > >1998-10-02 05:00:00 0 0 0
> > > >1998-10-02 06:00:00 0 0 0
> > > >1998-10-02 07:00:00 0.2 0 0
> > > >1998-10-02 08:00:00 0.6 0 0
> > > >1998-10-02 09:00:00 0.2 0.2 0.2
> > > >1998-10-02 10:00:00 0.6 0.2 0.4
> > > >1998-10-02 11:00:00 0 0 0.6
> > > >1998-10-02 12:00:00 0 0 0
> > > >1998-10-02 13:00:00 0 0 0
> > > >1998-10-02 14:00:00 0 0 0
> > > >1998-10-02 15:00:00 0.2 0 0
> > > >1998-10-02 16:00:00 0.6 0 0
> > > >1998-10-02 17:00:00 0.2 0.2 0.2
> > > >1998-10-02 18:00:00 0.6 0.2 0.4
> > > >1998-10-02 19:00:00 0 0 0.6
> > > >1998-10-02 20:00:00 0 0 0
> > > >1998-10-02 21:00:00 0 0 0
> > > >1998-10-02 22:00:00 0 0 0
> > > >1998-10-02 23:00:00 0.2 0 0",
> > > >skip=1,stringsAsFactors=FALSE)
> > > >names(MyData)<-c("date","time","st1","st2","st3")
> > > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > > format="%Y-%m-%d %H:%M:%S")
> > > >MyData$datetime
> > > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > > >st1_daily
> > > >st2_daily
> > > >st3_daily
> > > >
> > > >Try adding na.rm=TRUE to the "by" calls:
> > > >
> > > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > > >
> > > >Jim
> > > >
> > > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > > ><diego.avesani at gmail.com> wrote:
> > > >> Dear all,
> > > >>
> > > >> I have still problem with date.
> > > >> Could you please tel me how to use POSIXct.
> > > >> Indeed I have found this command:
> > > >> timeAverage, but I am not able to convert MyDate to properly date.
> > > >>
> > > >> Thank a lot
> > > >> I hope to no bother you, at least too much
> > > >>
> > > >>
> > > >> Diego
> > > >>
> > > >>
> > > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > > >wrote:
> > > >>>
> > > >>> Dear Jim, Dear all,
> > > >>>
> > > >>> thanks a lot.
> > > >>>
> > > >>> Unfortunately, I get the following error:
> > > >>>
> > > >>>
> > > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > > >925L,  :
> > > >>>   arguments must have same length
> > > >>>
> > > >>>
> > > >>> This is particularly strange. indeed, if I apply
> > > >>>
> > > >>>
> > > >>> mean(MyData$str1,na.rm=TRUE)
> > > >>>
> > > >>>
> > > >>> it works
> > > >>>
> > > >>>
> > > >>> Sorry, I have to learn a lot.
> > > >>> You are really boosting me
> > > >>>
> > > >>> Diego
> > > >>>
> > > >>>
> > > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >>>>
> > > >>>> Hi Diego,
> > > >>>> One way you can get daily means is:
> > > >>>>
> > > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > > >>>>
> > > >>>> Jim
> > > >>>>
> > > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > > ><diego.avesani at gmail.com>
> > > >>>> wrote:
> > > >>>> > Dear all,
> > > >>>> > I have found the error, my fault. Sorry.
> > > >>>> > There was an extra come in the headers line.
> > > >>>> > Thanks again.
> > > >>>> >
> > > >>>> > If I can I would like to ask you another questions about the
> > > >imported
> > > >>>> > data.
> > > >>>> > I would like to compute the daily average of the different date.
> > > >>>> > Basically I
> > > >>>> > have hourly data, I would like to ave the daily mean of them.
> > > >>>> >
> > > >>>> > Is there some special commands?
> > > >>>> >
> > > >>>> > Thanks a lot.
> > > >>>> >
> > > >>>> >
> > > >>>> > Diego
> > > >>>> >
> > > >>>> >
> > > >>>> > On 31 July 2018 at 10:40, Diego Avesani
> > > >>>> > <diego.avesani at gmail.com>
> > > >>>> > wrote:
> > > >>>> >>
> > > >>>> >> Dear all,
> > > >>>> >> I move to csv file because originally the date where in csv
> > > >file.
> > > >>>> >> In addition, due to the fact that, as you told me, read.csv is
> > > >>>> >> a special case of read.table, I prefer start to learn from the
> > > >>>> >> simplest
> > > >one.
> > > >>>> >> After that, I will try also the *.txt format.
> > > >>>> >>
> > > >>>> >> with read.csv, something strange happened:
> > > >>>> >>
> > > >>>> >> This us now the file:
> > > >>>> >>
> > > >>>> >> date,st1,st2,st3,
> > > >>>> >> 10/1/1998 0:00,0.6,0,0
> > > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > > >>>> >> 10/1/1998 3:00,0,0,0.6
> > > >>>> >> 10/1/1998 4:00,0,0,0
> > > >>>> >> 10/1/1998 5:00,0,0,0
> > > >>>> >> 10/1/1998 6:00,0,0,0
> > > >>>> >> 10/1/1998 7:00,0.2,0,0
> > > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > > >>>> >>
> > > >>>> >> When I apply:
> > > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > > >>>> >>
> > > >>>> >> this is the results:
> > > >>>> >>
> > > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > > >>>> >>
> > > >>>> >> I do not understand why.
> > > >>>> >> Something wrong with date?
> > > >>>> >>
> > > >>>> >> really really thanks,
> > > >>>> >> I appreciate a lot all your helps.
> > > >>>> >>
> > > >>>> >> Diedro
> > > >>>> >>
> > > >>>> >>
> > > >>>> >> Diego
> > > >>>> >>
> > > >>>> >>
> > > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > > >wrote:
> > > >>>> >>>
> > > >>>> >>> Or, without removing the first line
> > > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
> > > >>>> >>> skip=1)
> > > >>>> >>>
> > > >>>> >>> Another alternative,
> > > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > > >>>> >>> since the dates appear to be in the default format.
> > > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > > >rather
> > > >>>> >>> than
> > > >>>> >>> POSIXlt class)
> > > >>>> >>>
> > > >>>> >>> -Don
> > > >>>> >>>
> > > >>>> >>> --
> > > >>>> >>> Don MacQueen
> > > >>>> >>> Lawrence Livermore National Laboratory
> > > >>>> >>> 7000 East Ave., L-627
> > > >>>> >>> Livermore, CA 94550
> > > >>>> >>> 925-423-1062
> > > >>>> >>> Lab cell 925-724-7509
> > > >>>> >>>
> > > >>>> >>>
> > > >>>> >>>
> > > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > > >drjimlemon at gmail.com>
> > > >>>> >>> wrote:
> > > >>>> >>>
> > > >>>> >>>     Hi Diego,
> > > >>>> >>>     You may have to do some conversion as you have three
> > > >>>> >>> fields
> > > >in
> > > >>>> >>> the
> > > >>>> >>>     first line using the default space separator and five
> > > >fields in
> > > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > > >important
> > > >>>> >>> data
> > > >>>> >>>     you can just delete it or replace it with a meaningful
> > > >header
> > > >>>> >>> line
> > > >>>> >>>     with five fields and save the file under another name.
> > > >>>> >>>
> > > >>>> >>>     It looks as thought you have date-time as two fields. If
> > > >so, you
> > > >>>> >>> can
> > > >>>> >>>     just read the first field if you only want the date:
> > > >>>> >>>
> > > >>>> >>>     # assume you have removed the first line
> > > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > > >>>> >>>
> > > >>>> >>>     If you want the date/time:
> > > >>>> >>>
> > > >>>> >>>
> > > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > > >>>> >>> %H:%M:%S")
> > > >>>> >>>
> > > >>>> >>>     Jim
> > > >>>> >>>
> > > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > > >>>> >>> <diego.avesani at gmail.com> wrote:
> > > >>>> >>>     > Dear all,
> > > >>>> >>>     >
> > > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > > >>>> >>>     > The txt file the following shape:
> > > >>>> >>>     >
> > > >>>> >>>     > 103001930 103001580 103001530
> > > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > > >>>> >>>     >
> > > >>>> >>>     > If it is possible I have a coupe of questions, which
> > > >>>> >>> will
> > > >sound
> > > >>>> >>> stupid but
> > > >>>> >>>     > they are important to me in order to understand ho R
> > > >>>> >>> deal
> > > >with
> > > >>>> >>> file
> > > >>>> >>> or date.
> > > >>>> >>>     >
> > > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > > >>>> >>>     > 2) Can a deal with space and not ","
> > > >>>> >>>     > 3) How can I read date?
> > > >>>> >>>     >
> > > >>>> >>>     > thanks a lot to all of you,
> > > >>>> >>>     > Thanks
> > > >>>> >>>     >
> > > >>>> >>>     >
> > > >>>> >>>     > Diego
> > > >>>> >>>     >
> > > >>>> >>>     >         [[alternative HTML version deleted]]
> > > >>>> >>>     >
> > > >>>> >>>     > ______________________________________________
> > > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > > >more,
> > > >>>> >>> see
> > > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>> >>>     > PLEASE do read the posting guide
> > > >>>> >>> http://www.R-project.org/posting-guide.html
> > > >>>> >>>     > and provide commented, minimal, self-contained,
> > > >reproducible
> > > >>>> >>> code.
> > > >>>> >>>
> > > >>>> >>>     ______________________________________________
> > > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > > >more, see
> > > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>> >>>     PLEASE do read the posting guide
> > > >>>> >>> http://www.R-project.org/posting-guide.html
> > > >>>> >>>     and provide commented, minimal, self-contained,
> > > >reproducible
> > > >>>> >>> code.
> > > >>>> >>>
> > > >>>> >>>
> > > >>>> >>
> > > >>>> >
> > > >>>
> > > >>>
> > > >>
> > > >
> > > >______________________________________________
> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > >PLEASE do read the posting guide
> > > >http://www.R-project.org/posting-guide.html
> > > >and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Sent from my phone. Please excuse my brevity.
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> zasady-ochrany-osobnich-udaju/ | Information about processing and
> protection of business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

	[[alternative HTML version deleted]]


From diego@@ve@@ni @ending from gm@il@com  Wed Aug  1 14:37:55 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Wed, 1 Aug 2018 14:37:55 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>
Message-ID: <CAG8o1y65ccvCpRQ8QvmC=vDgVhzD2acB6xb+f0NVEkPsuEhmsA@mail.gmail.com>

Dear Pikal, DEar all,

I do not if it could help:
if I print MyData%date, I get (at some point)

[281] "1998-12-10 16:00:00 CET"  "1998-12-10 17:00:00 CET"
"1998-12-10 18:00:00 CET"  "1998-12-10 19:00:00 CET"
 [285] "1998-12-10 20:00:00 CET"  "1998-12-10 21:00:00 CET"
"1998-12-10 22:00:00 CET"  "1998-12-10 23:00:00 CET"
 [289] NA                         NA                         NA
                 NA
 [293] NA                         NA                         NA
                 NA
 [297] NA                         NA                         NA
                 NA


Again Thanks

Diego


On 1 August 2018 at 14:29, Diego Avesani <diego.avesani at gmail.com> wrote:

> Dear Pikal, Deal all,
>
> again really thank.
>
> it seems not working.
> Some specifications: My non data are -999, but I could change it.
>
> My final results is:
>
> 1        1  -55.86242 -55.84764660 -277.4775
> 2        2  -55.47554 -94.58921682 -277.4845
> 3        3  -55.47095 -99.20239198 -277.4709
> 4        4  -55.46470 -55.45952932 -392.9071
> 5        5  -55.43335 -55.40171682 -388.4110
> 6        6  -55.40108 -55.37399691 -332.9068
> 7        7  -55.39201 -55.35156250 -332.8902
> 8        8 -110.87184   0.16136188 -281.8230
> 9        9 -110.95077 -55.63856096 -332.9564
> 10      10 -157.64430  -0.06602705 -315.3840
> 11      11 -105.06157   0.11507675 -315.4152
> 12      12  -70.08677 -52.54501096 -316.7247
>
>
> So it is not correct.
> For example for the first day in my csv I would have expected 0.167.
>
> I am going to post what you have suggested:
>
> for  str(MyData)
>
> 'data.frame': 160008 obs. of  4 variables:
>  $ date: POSIXct, format: "1998-01-10 00:00:00" "1998-01-10 01:00:00"
> "1998-01-10 02:00:00" "1998-01-10 03:00:00" ...
>  $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
>  $ str2: num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
>  $ str3: num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...
>
> unfortunately, I am not able to post
>
> dput(str[1:20,])
>
> it gives me
>
> Error in str[1:20, ] : object of type 'closure' is not subsettable
>
>
> Thanks again,
> I hope that what I posted could be enough in order to help me.
>
>
>
> Diego
>
>
> On 1 August 2018 at 13:58, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> I did not get through all answers you already got and you probably
>> obtained similar advice as mine.
>>
>> # read data (if you have csv file just use read.csv)
>> > test<-read.table("clipboard", header=T, sep=",")
>>
>> # control your object(s)
>> > str(test)
>> 'data.frame':   8 obs. of  4 variables:
>>  $ date: Factor w/ 8 levels "10/1/1998 0:00",..: 1 2 3 4 5 6 7 8
>>  $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2
>>  $ str2: num  0 0.2 0.2 0 0 0 0 0
>>  $ str3: num  0 0.2 0.4 0.6 0 0 0 0
>>
>> #if it is OK change first column to real date by POSIXct
>> test$date<-as.POSIXct(test$date, format="%d/%m/%Y %H:%M")
>>
>> #attach lubridate
>> > library(lubridate)
>>
>> # aggregate your object(s) and use lubridate function
>>
>> > aggregate(test[,-1], list(day(test$date)), mean)
>>   Group.1 str1 str2 str3
>> 1      10  0.2 0.05 0.15
>>
>> # or format function
>>
>> > aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
>>      Group.1 str1 str2 str3
>> 1 1998-01-10  0.2 0.05 0.15
>>
>> If it does not work with your data you should post at least result of
>>
>> str(yourdata)
>>
>> or preferably
>>
>> dput(yourdata[1:20,])
>>
>> Cheers
>> Petr
>>
>>
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Diego Avesani
>> > Sent: Wednesday, August 1, 2018 8:55 AM
>> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > Cc: r-help mailing list <r-help at r-project.org>
>> > Subject: Re: [R] read txt file - date - no space
>> >
>> > Dear all,
>> > I am sorry, I did a lot of confusion. I am sorry, I have to relax and
>> stat all again
>> > in order to understand.
>> > If I could I would like to start again, without mixing strategy and
>> waiting for
>> > your advice.
>> >
>> > I am really appreciate you help, really really.
>> > Here my new file, a *.csv file (buy the way, it is possible to attach
>> it in the
>> > mailing list?)
>> >
>> > date,str1,str2,str3
>> > 10/1/1998 0:00,0.6,0,0
>> > 10/1/1998 1:00,0.2,0.2,0.2
>> > 10/1/1998 2:00,0.6,0.2,0.4
>> > 10/1/1998 3:00,0,0,0.6
>> > 10/1/1998 4:00,0,0,0
>> > 10/1/1998 5:00,0,0,0
>> > 10/1/1998 6:00,0,0,0
>> > 10/1/1998 7:00,0.2,0,0
>> >
>> >
>> > I read it as:
>> > MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>> >
>> > at this point I would like to have the daily mean.
>> > What would you suggest?
>> >
>> > Really Really thanks,
>> > You are my lifesaver
>> >
>> > Thanks
>> >
>> >
>> >
>> > Diego
>> >
>> >
>> > On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> >
>> > > ... and the most common source of NA values in time data is wrong
>> > > timezones. You really need to make sure the timezone that is assumed
>> > > when the character data are converted to POSIXt agrees with the data.
>> > > In most cases the easiest way to insure this is to use
>> > >
>> > > Sys.setenv(TZ="US/Pacific")
>> > >
>> > > or whatever timezone from
>> > >
>> > > OlsonNames()
>> > >
>> > > corresponds with your data. Execute this setenv function before the
>> > > strptime or as.POSIXct() function call.
>> > >
>> > > You can use
>> > >
>> > > MyData[ is.na(MyData$datetime), ]
>> > >
>> > > to see which records are failing to convert time.
>> > >
>> > > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>> > >
>> > > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
>> > wrote:
>> > > >Hi Diego,
>> > > >I think the error is due to NA values in your data file. If I extend
>> > > >your example and run it, I get no errors:
>> > > >
>> > > >MyData<-read.table(text="103001930 103001580 103001530
>> > > >1998-10-01 00:00:00 0.6 0 0
>> > > >1998-10-01 01:00:00 0.2 0.2 0.2
>> > > >1998-10-01 02:00:00 0.6 0.2 0.4
>> > > >1998-10-01 03:00:00 0 0 0.6
>> > > >1998-10-01 04:00:00 0 0 0
>> > > >1998-10-01 05:00:00 0 0 0
>> > > >1998-10-01 06:00:00 0 0 0
>> > > >1998-10-01 07:00:00 0.2 0 0
>> > > >1998-10-01 08:00:00 0.6 0 0
>> > > >1998-10-01 09:00:00 0.2 0.2 0.2
>> > > >1998-10-01 10:00:00 0.6 0.2 0.4
>> > > >1998-10-01 11:00:00 0 0 0.6
>> > > >1998-10-01 12:00:00 0 0 0
>> > > >1998-10-01 13:00:00 0 0 0
>> > > >1998-10-01 14:00:00 0 0 0
>> > > >1998-10-01 15:00:00 0.2 0 0
>> > > >1998-10-01 16:00:00 0.6 0 0
>> > > >1998-10-01 17:00:00 0.2 0.2 0.2
>> > > >1998-10-01 18:00:00 0.6 0.2 0.4
>> > > >1998-10-01 19:00:00 0 0 0.6
>> > > >1998-10-01 20:00:00 0 0 0
>> > > >1998-10-01 21:00:00 0 0 0
>> > > >1998-10-01 22:00:00 0 0 0
>> > > >1998-10-01 23:00:00 0.2 0 0
>> > > >1998-10-02 00:00:00 0.6 0 0
>> > > >1998-10-02 01:00:00 0.2 0.2 0.2
>> > > >1998-10-02 02:00:00 0.6 0.2 0.4
>> > > >1998-10-02 03:00:00 0 0 0.6
>> > > >1998-10-02 04:00:00 0 0 0
>> > > >1998-10-02 05:00:00 0 0 0
>> > > >1998-10-02 06:00:00 0 0 0
>> > > >1998-10-02 07:00:00 0.2 0 0
>> > > >1998-10-02 08:00:00 0.6 0 0
>> > > >1998-10-02 09:00:00 0.2 0.2 0.2
>> > > >1998-10-02 10:00:00 0.6 0.2 0.4
>> > > >1998-10-02 11:00:00 0 0 0.6
>> > > >1998-10-02 12:00:00 0 0 0
>> > > >1998-10-02 13:00:00 0 0 0
>> > > >1998-10-02 14:00:00 0 0 0
>> > > >1998-10-02 15:00:00 0.2 0 0
>> > > >1998-10-02 16:00:00 0.6 0 0
>> > > >1998-10-02 17:00:00 0.2 0.2 0.2
>> > > >1998-10-02 18:00:00 0.6 0.2 0.4
>> > > >1998-10-02 19:00:00 0 0 0.6
>> > > >1998-10-02 20:00:00 0 0 0
>> > > >1998-10-02 21:00:00 0 0 0
>> > > >1998-10-02 22:00:00 0 0 0
>> > > >1998-10-02 23:00:00 0.2 0 0",
>> > > >skip=1,stringsAsFactors=FALSE)
>> > > >names(MyData)<-c("date","time","st1","st2","st3")
>> > > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
>> > > > format="%Y-%m-%d %H:%M:%S")
>> > > >MyData$datetime
>> > > >st1_daily<-by(MyData$st1,MyData$date,mean)
>> > > >st2_daily<-by(MyData$st2,MyData$date,mean)
>> > > >st3_daily<-by(MyData$st3,MyData$date,mean)
>> > > >st1_daily
>> > > >st2_daily
>> > > >st3_daily
>> > > >
>> > > >Try adding na.rm=TRUE to the "by" calls:
>> > > >
>> > > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
>> > > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
>> > > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
>> > > >
>> > > >Jim
>> > > >
>> > > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
>> > > ><diego.avesani at gmail.com> wrote:
>> > > >> Dear all,
>> > > >>
>> > > >> I have still problem with date.
>> > > >> Could you please tel me how to use POSIXct.
>> > > >> Indeed I have found this command:
>> > > >> timeAverage, but I am not able to convert MyDate to properly date.
>> > > >>
>> > > >> Thank a lot
>> > > >> I hope to no bother you, at least too much
>> > > >>
>> > > >>
>> > > >> Diego
>> > > >>
>> > > >>
>> > > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
>> > > >wrote:
>> > > >>>
>> > > >>> Dear Jim, Dear all,
>> > > >>>
>> > > >>> thanks a lot.
>> > > >>>
>> > > >>> Unfortunately, I get the following error:
>> > > >>>
>> > > >>>
>> > > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>> > > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
>> > > >925L,  :
>> > > >>>   arguments must have same length
>> > > >>>
>> > > >>>
>> > > >>> This is particularly strange. indeed, if I apply
>> > > >>>
>> > > >>>
>> > > >>> mean(MyData$str1,na.rm=TRUE)
>> > > >>>
>> > > >>>
>> > > >>> it works
>> > > >>>
>> > > >>>
>> > > >>> Sorry, I have to learn a lot.
>> > > >>> You are really boosting me
>> > > >>>
>> > > >>> Diego
>> > > >>>
>> > > >>>
>> > > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>> > > >>>>
>> > > >>>> Hi Diego,
>> > > >>>> One way you can get daily means is:
>> > > >>>>
>> > > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>> > > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>> > > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>> > > >>>>
>> > > >>>> Jim
>> > > >>>>
>> > > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
>> > > ><diego.avesani at gmail.com>
>> > > >>>> wrote:
>> > > >>>> > Dear all,
>> > > >>>> > I have found the error, my fault. Sorry.
>> > > >>>> > There was an extra come in the headers line.
>> > > >>>> > Thanks again.
>> > > >>>> >
>> > > >>>> > If I can I would like to ask you another questions about the
>> > > >imported
>> > > >>>> > data.
>> > > >>>> > I would like to compute the daily average of the different
>> date.
>> > > >>>> > Basically I
>> > > >>>> > have hourly data, I would like to ave the daily mean of them.
>> > > >>>> >
>> > > >>>> > Is there some special commands?
>> > > >>>> >
>> > > >>>> > Thanks a lot.
>> > > >>>> >
>> > > >>>> >
>> > > >>>> > Diego
>> > > >>>> >
>> > > >>>> >
>> > > >>>> > On 31 July 2018 at 10:40, Diego Avesani
>> > > >>>> > <diego.avesani at gmail.com>
>> > > >>>> > wrote:
>> > > >>>> >>
>> > > >>>> >> Dear all,
>> > > >>>> >> I move to csv file because originally the date where in csv
>> > > >file.
>> > > >>>> >> In addition, due to the fact that, as you told me, read.csv is
>> > > >>>> >> a special case of read.table, I prefer start to learn from the
>> > > >>>> >> simplest
>> > > >one.
>> > > >>>> >> After that, I will try also the *.txt format.
>> > > >>>> >>
>> > > >>>> >> with read.csv, something strange happened:
>> > > >>>> >>
>> > > >>>> >> This us now the file:
>> > > >>>> >>
>> > > >>>> >> date,st1,st2,st3,
>> > > >>>> >> 10/1/1998 0:00,0.6,0,0
>> > > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>> > > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>> > > >>>> >> 10/1/1998 3:00,0,0,0.6
>> > > >>>> >> 10/1/1998 4:00,0,0,0
>> > > >>>> >> 10/1/1998 5:00,0,0,0
>> > > >>>> >> 10/1/1998 6:00,0,0,0
>> > > >>>> >> 10/1/1998 7:00,0.2,0,0
>> > > >>>> >> 10/1/1998 8:00,0.6,0.2,0
>> > > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>> > > >>>> >> 10/1/1998 10:00,0,0.4,0.2
>> > > >>>> >>
>> > > >>>> >> When I apply:
>> > > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>> > > >>>> >>
>> > > >>>> >> this is the results:
>> > > >>>> >>
>> > > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>> > > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>> > > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>> > > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>> > > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>> > > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>> > > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>> > > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>> > > >>>> >>
>> > > >>>> >> I do not understand why.
>> > > >>>> >> Something wrong with date?
>> > > >>>> >>
>> > > >>>> >> really really thanks,
>> > > >>>> >> I appreciate a lot all your helps.
>> > > >>>> >>
>> > > >>>> >> Diedro
>> > > >>>> >>
>> > > >>>> >>
>> > > >>>> >> Diego
>> > > >>>> >>
>> > > >>>> >>
>> > > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
>> > > >wrote:
>> > > >>>> >>>
>> > > >>>> >>> Or, without removing the first line
>> > > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
>> > > >>>> >>> skip=1)
>> > > >>>> >>>
>> > > >>>> >>> Another alternative,
>> > > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>> > > >>>> >>> since the dates appear to be in the default format.
>> > > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
>> > > >rather
>> > > >>>> >>> than
>> > > >>>> >>> POSIXlt class)
>> > > >>>> >>>
>> > > >>>> >>> -Don
>> > > >>>> >>>
>> > > >>>> >>> --
>> > > >>>> >>> Don MacQueen
>> > > >>>> >>> Lawrence Livermore National Laboratory
>> > > >>>> >>> 7000 East Ave., L-627
>> > > >>>> >>> Livermore, CA 94550
>> > > >>>> >>> 925-423-1062
>> > > >>>> >>> Lab cell 925-724-7509
>> > > >>>> >>>
>> > > >>>> >>>
>> > > >>>> >>>
>> > > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>> > > >>>> >>> <r-help-bounces at r-project.org on behalf of
>> > > >drjimlemon at gmail.com>
>> > > >>>> >>> wrote:
>> > > >>>> >>>
>> > > >>>> >>>     Hi Diego,
>> > > >>>> >>>     You may have to do some conversion as you have three
>> > > >>>> >>> fields
>> > > >in
>> > > >>>> >>> the
>> > > >>>> >>>     first line using the default space separator and five
>> > > >fields in
>> > > >>>> >>>     subsequent lines. If the first line doesn't contain any
>> > > >important
>> > > >>>> >>> data
>> > > >>>> >>>     you can just delete it or replace it with a meaningful
>> > > >header
>> > > >>>> >>> line
>> > > >>>> >>>     with five fields and save the file under another name.
>> > > >>>> >>>
>> > > >>>> >>>     It looks as thought you have date-time as two fields. If
>> > > >so, you
>> > > >>>> >>> can
>> > > >>>> >>>     just read the first field if you only want the date:
>> > > >>>> >>>
>> > > >>>> >>>     # assume you have removed the first line
>> > > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>> > > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>> > > >>>> >>>
>> > > >>>> >>>     If you want the date/time:
>> > > >>>> >>>
>> > > >>>> >>>
>> > > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>> > > >>>> >>> %H:%M:%S")
>> > > >>>> >>>
>> > > >>>> >>>     Jim
>> > > >>>> >>>
>> > > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>> > > >>>> >>> <diego.avesani at gmail.com> wrote:
>> > > >>>> >>>     > Dear all,
>> > > >>>> >>>     >
>> > > >>>> >>>     > I am dealing with the reading of a *.txt file.
>> > > >>>> >>>     > The txt file the following shape:
>> > > >>>> >>>     >
>> > > >>>> >>>     > 103001930 103001580 103001530
>> > > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>> > > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>> > > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>> > > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>> > > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
>> > > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
>> > > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
>> > > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>> > > >>>> >>>     >
>> > > >>>> >>>     > If it is possible I have a coupe of questions, which
>> > > >>>> >>> will
>> > > >sound
>> > > >>>> >>> stupid but
>> > > >>>> >>>     > they are important to me in order to understand ho R
>> > > >>>> >>> deal
>> > > >with
>> > > >>>> >>> file
>> > > >>>> >>> or date.
>> > > >>>> >>>     >
>> > > >>>> >>>     > 1) Do I have to convert it to a *csv file?
>> > > >>>> >>>     > 2) Can a deal with space and not ","
>> > > >>>> >>>     > 3) How can I read date?
>> > > >>>> >>>     >
>> > > >>>> >>>     > thanks a lot to all of you,
>> > > >>>> >>>     > Thanks
>> > > >>>> >>>     >
>> > > >>>> >>>     >
>> > > >>>> >>>     > Diego
>> > > >>>> >>>     >
>> > > >>>> >>>     >         [[alternative HTML version deleted]]
>> > > >>>> >>>     >
>> > > >>>> >>>     > ______________________________________________
>> > > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE
>> and
>> > > >more,
>> > > >>>> >>> see
>> > > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >>>> >>>     > PLEASE do read the posting guide
>> > > >>>> >>> http://www.R-project.org/posting-guide.html
>> > > >>>> >>>     > and provide commented, minimal, self-contained,
>> > > >reproducible
>> > > >>>> >>> code.
>> > > >>>> >>>
>> > > >>>> >>>     ______________________________________________
>> > > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> > > >more, see
>> > > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >>>> >>>     PLEASE do read the posting guide
>> > > >>>> >>> http://www.R-project.org/posting-guide.html
>> > > >>>> >>>     and provide commented, minimal, self-contained,
>> > > >reproducible
>> > > >>>> >>> code.
>> > > >>>> >>>
>> > > >>>> >>>
>> > > >>>> >>
>> > > >>>> >
>> > > >>>
>> > > >>>
>> > > >>
>> > > >
>> > > >______________________________________________
>> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >PLEASE do read the posting guide
>> > > >http://www.R-project.org/posting-guide.html
>> > > >and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > > --
>> > > Sent from my phone. Please excuse my brevity.
>> > >
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady
>> -ochrany-osobnich-udaju/ | Information about processing and protection
>> of business partner?s personal data are available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>> documents attached to it may be confidential and are subject to the legally
>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>>
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Aug  1 15:09:18 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 1 Aug 2018 13:09:18 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>
Message-ID: <38987a7e64a945f0b164783a6cf717d7@SRVEXCHCM1302.precheza.cz>

Hi

see in line

From: Diego Avesani <diego.avesani at gmail.com>
Sent: Wednesday, August 1, 2018 2:30 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] read txt file - date - no space

Dear Pikal, Deal all,

again really thank.

it seems not working.
Some specifications: My non data are -999, but I could change it.

You must change it to NA. How the poor R should know that -999 is missing and not a real value.

something like

Mydata[Mydata== -999] <- NA

should do it.

My final results is:


1        1  -55.86242 -55.84764660 -277.4775

2        2  -55.47554 -94.58921682 -277.4845

3        3  -55.47095 -99.20239198 -277.4709

4        4  -55.46470 -55.45952932 -392.9071

5        5  -55.43335 -55.40171682 -388.4110

6        6  -55.40108 -55.37399691 -332.9068

7        7  -55.39201 -55.35156250 -332.8902

8        8 -110.87184   0.16136188 -281.8230

9        9 -110.95077 -55.63856096 -332.9564

10      10 -157.64430  -0.06602705 -315.3840

11      11 -105.06157   0.11507675 -315.4152

12      12  -70.08677 -52.54501096 -316.7247

So it is not correct.
For example for the first day in my csv I would have expected 0.167.

I am going to post what you have suggested:

for  str(MyData)

Your data seems to be OK, so after you change your -999 to NA everything should be OK.

'data.frame':                 160008 obs. of  4 variables:
 $ date: POSIXct, format: "1998-01-10 00:00:00" "1998-01-10 01:00:00" "1998-01-10 02:00:00" "1998-01-10 03:00:00" ...
 $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
 $ str2: num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
 $ str3: num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...

unfortunately, I am not able to post

dput(str[1:20,])

it gives me

Error in str[1:20, ] : object of type 'closure' is not subsettable



dput(MyData[1:20,])



I would recommend you to spend some time reading R-intro which should be located in doc/manual folder of your installation. It could help you in many situations.



Cheers

Petr


Thanks again,
I hope that what I posted could be enough in order to help me.



Diego

On 1 August 2018 at 13:58, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

I did not get through all answers you already got and you probably obtained similar advice as mine.

# read data (if you have csv file just use read.csv)
> test<-read.table("clipboard", header=T, sep=",")

# control your object(s)
> str(test)
'data.frame':   8 obs. of  4 variables:
 $ date: Factor w/ 8 levels "10/1/1998 0:00",..: 1 2 3 4 5 6 7 8
 $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2
 $ str2: num  0 0.2 0.2 0 0 0 0 0
 $ str3: num  0 0.2 0.4 0.6 0 0 0 0

#if it is OK change first column to real date by POSIXct
test$date<-as.POSIXct(test$date, format="%d/%m/%Y %H:%M")

#attach lubridate
> library(lubridate)

# aggregate your object(s) and use lubridate function

> aggregate(test[,-1], list(day(test$date)), mean)
  Group.1 str1 str2 str3
1      10  0.2 0.05 0.15

# or format function

> aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
     Group.1 str1 str2 str3
1 1998-01-10  0.2 0.05 0.15

If it does not work with your data you should post at least result of

str(yourdata)

or preferably

dput(yourdata[1:20,])

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Diego Avesani
> Sent: Wednesday, August 1, 2018 8:55 AM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>
> Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] read txt file - date - no space
>
> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat all again
> in order to understand.
> If I could I would like to start again, without mixing strategy and waiting for
> your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in the
> mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed
> > when the character data are converted to POSIXt agrees with the data.
> > In most cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na<http://is.na>(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani
> > >>>> > <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is
> > >>>> >> a special case of read.table, I prefer start to learn from the
> > >>>> >> simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
> > >>>> >>> skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of
> > >drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three
> > >>>> >>> fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which
> > >>>> >>> will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R
> > >>>> >>> deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From jholtm@n @ending from gm@il@com  Wed Aug  1 17:01:17 2018
From: jholtm@n @ending from gm@il@com (jim holtman)
Date: Wed, 1 Aug 2018 08:01:17 -0700
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
Message-ID: <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>

Try this:

> library(lubridate)
> library(tidyverse)
> input <- read.csv(text = "date,str1,str2,str3
+ 10/1/1998 0:00,0.6,0,0
+                   10/1/1998 1:00,0.2,0.2,0.2
+                   10/1/1998 2:00,0.6,0.2,0.4
+                   10/1/1998 3:00,0,0,0.6
+                   10/1/1998 4:00,0,0,0
+                   10/1/1998 5:00,0,0,0
+                   10/1/1998 6:00,0,0,0
+                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
> # convert the date and add the "day" so summarize
> input <- input %>%
+   mutate(date = mdy_hm(date),
+          day = floor_date(date, unit = 'day')
+   )
>
> by_day <- input %>%
+   group_by(day) %>%
+   summarise(m_s1 = mean(str1),
+             m_s2 = mean(str2),
+             m_s3 = mean(str3)
+   )
>
> by_day
# A tibble: 1 x 4
  day                  m_s1   m_s2  m_s3
  <dttm>              <dbl>  <dbl> <dbl>
1 1998-10-01 00:00:00 0.200 0.0500 0.150

Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
wrote:

> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
> all again in order to understand.
> If I could I would like to start again, without mixing strategy and waiting
> for your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in
> the mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed when
> > the character data are converted to POSIXt agrees with the data. In most
> > cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> > >>>> >> special
> > >>>> >> case of read.table, I prefer start to learn from the simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > >drjimlemon at gmail.com>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @ilve@tri@c@@@li @ending from gm@il@com  Wed Aug  1 17:40:54 2018
From: @ilve@tri@c@@@li @ending from gm@il@com (Edoardo Silvestri)
Date: Wed, 1 Aug 2018 17:40:54 +0200
Subject: [R] New post for Rhelp
Message-ID: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>

I have a database based on hourly data and I need to forecast next 24h of a
single variable. I was thinking about applying an ARIMA model with some
exogenous variables but I don't succeed to configure the hourly frequency,
estimate ARIMA parameters, pdq ( exists some tests to check which
parameters are better for the model?) and the structure of the model in its
easy form because I would also like to introduce some seasonality form by
analyzing some variables I highlighted some daily and weekly behaviours
similar.



I recognize that it could be quite difficult the problem but if you have
also some useful links or some codes that can help me, please send me.

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Aug  1 21:51:49 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 1 Aug 2018 12:51:49 -0700
Subject: [R] New post for Rhelp
In-Reply-To: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>
References: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>
Message-ID: <CAGxFJbQDpANZJwoyk-NG1CU4KFV59p_S5nJcXUUbNSxuZpuaNA@mail.gmail.com>

Statistics issues are generally off topic here; and we generally prefer
posters to show us their own efforts rather than expecting us to solve the
problem for them.

However, this CRAN time series task view may be useful to you:

https://cran.r-project.org/web/views/TimeSeries.html

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 1, 2018 at 8:40 AM, Edoardo Silvestri <
silvestri.casali at gmail.com> wrote:

> I have a database based on hourly data and I need to forecast next 24h of a
> single variable. I was thinking about applying an ARIMA model with some
> exogenous variables but I don't succeed to configure the hourly frequency,
> estimate ARIMA parameters, pdq ( exists some tests to check which
> parameters are better for the model?) and the structure of the model in its
> easy form because I would also like to introduce some seasonality form by
> analyzing some variables I highlighted some daily and weekly behaviours
> similar.
>
>
>
> I recognize that it could be quite difficult the problem but if you have
> also some useful links or some codes that can help me, please send me.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rod@@t@fford @ending from gm@il@com  Thu Aug  2 03:20:04 2018
From: rod@@t@fford @ending from gm@il@com (R Stafford)
Date: Wed, 1 Aug 2018 21:20:04 -0400
Subject: [R] Combinations of true/false values where one pair is mutually
 exclusive
Message-ID: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>

I have 6 variables, (A,B,C,D,E,F) that can either pass or fail (i.e., true
or false).
I can get a table of all pass/fail combinations with this:

scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"), F =
c("pass", "fail"))

But I have the extra condition that if E is true, then F must be false, and
vice versa, so what I don't know is how to get all combinations when E and F
are mutually exclusive.

	[[alternative HTML version deleted]]


From chk@tr @ending from unife@it  Thu Aug  2 04:01:24 2018
From: chk@tr @ending from unife@it (Saptorshee Kanto Chakraborty)
Date: Thu, 2 Aug 2018 04:01:24 +0200
Subject: [R] CODE HELP
Message-ID: <CAAr3ZhjhfE8ED+EwZeUOmM6gd8vcoKoZrWdswe-CVE3MXvF8oA@mail.gmail.com>

Hello,

I am interested to apply an econometric technique of  Latent Variable
framework on Environmental Kuznets Curve for 164 countries for a span of 25
years.

The methodology and the code are from Simulation exercise from an
unpublished paper "Two Examples of Convex-Programming-Based
High-Dimensional Econometric Estimators" in R. Is it somehow possible to
apply it to my data.


I am attaching the codes

Thanking You

-- 
Saptorshee Chakraborty

Personal Website: http://saptorshee.weebly.com/

From drjimlemon @ending from gm@il@com  Thu Aug  2 07:20:37 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 2 Aug 2018 15:20:37 +1000
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
Message-ID: <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>

Hi Rod,
How about this?

scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"))
scenarios$F<-ifelse(scenarios$E=="pass","fail","pass")

Jim



On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com> wrote:
> I have 6 variables, (A,B,C,D,E,F) that can either pass or fail (i.e., true
> or false).
> I can get a table of all pass/fail combinations with this:
>
> scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
> c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"), F =
> c("pass", "fail"))
>
> But I have the extra condition that if E is true, then F must be false, and
> vice versa, so what I don't know is how to get all combinations when E and F
> are mutually exclusive.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd @ending from @urewe@t@net  Thu Aug  2 07:35:07 2018
From: jwd @ending from @urewe@t@net (John)
Date: Wed, 1 Aug 2018 22:35:07 -0700
Subject: [R] New post for Rhelp
In-Reply-To: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>
References: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>
Message-ID: <20180801223507.505eba68@Draco.localdomain>

On Wed, 1 Aug 2018 17:40:54 +0200
Edoardo Silvestri <silvestri.casali at gmail.com> wrote:

> I have a database based on hourly data and I need to forecast next
> 24h of a single variable. I was thinking about applying an ARIMA
> model with some exogenous variables but I don't succeed to configure
> the hourly frequency, estimate ARIMA parameters, pdq ( exists some
> tests to check which parameters are better for the model?) and the
> structure of the model in its easy form because I would also like to
> introduce some seasonality form by analyzing some variables I
> highlighted some daily and weekly behaviours similar.
> 
> 
> 
> I recognize that it could be quite difficult the problem but if you
> have also some useful links or some codes that can help me, please
> send me.
> 
You are talking about analyzing data in a regular time series.  R has
wide ranging time series analysis packages.  I would suggest starting
with the basic package that comes with an R download and reading the
basic information associated with it.  You could also checkout Venables
and Ripley, _Modern Applied Statistics with S [which R is a dialect
of].  If this is a homework question, hit the books.

JWDougherty


From diego@@ve@@ni @ending from gm@il@com  Thu Aug  2 08:55:34 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Thu, 2 Aug 2018 08:55:34 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
Message-ID: <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>

Dear

I have check the one of the line that gives me problem. I mean, which give
NA after R processing. I think that is similar to the others:

10/12/1998 10:00,0,0,0
10/12/1998 11:00,0,0,0
10/12/1998 12:00,0,0,0
10/12/1998 13:00,0,0,0
10/12/1998 14:00,0,0,0
10/12/1998 15:00,0,0,0
10/12/1998 16:00,0,0,0
10/12/1998 17:00,0,0,0

@jim: It seems that you suggestion is focus on reading data from the
terminal. It is possible to apply it to a *.csv file?

@Pikal: Could it be that there are some date conversion error?

Thanks again,
Diego


Diego


On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com> wrote:

>
> Try this:
>
> > library(lubridate)
> > library(tidyverse)
> > input <- read.csv(text = "date,str1,str2,str3
> + 10/1/1998 0:00,0.6,0,0
> +                   10/1/1998 1:00,0.2,0.2,0.2
> +                   10/1/1998 2:00,0.6,0.2,0.4
> +                   10/1/1998 3:00,0,0,0.6
> +                   10/1/1998 4:00,0,0,0
> +                   10/1/1998 5:00,0,0,0
> +                   10/1/1998 6:00,0,0,0
> +                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
> > # convert the date and add the "day" so summarize
> > input <- input %>%
> +   mutate(date = mdy_hm(date),
> +          day = floor_date(date, unit = 'day')
> +   )
> >
> > by_day <- input %>%
> +   group_by(day) %>%
> +   summarise(m_s1 = mean(str1),
> +             m_s2 = mean(str2),
> +             m_s3 = mean(str3)
> +   )
> >
> > by_day
> # A tibble: 1 x 4
>   day                  m_s1   m_s2  m_s3
>   <dttm>              <dbl>  <dbl> <dbl>
> 1 1998-10-01 00:00:00 0.200 0.0500 0.150
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve?Tell me what you want to
> do, not how you want to do it.*
>
>
> On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
> wrote:
>
>> Dear all,
>> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
>> all again in order to understand.
>> If I could I would like to start again, without mixing strategy and
>> waiting
>> for your advice.
>>
>> I am really appreciate you help, really really.
>> Here my new file, a *.csv file (buy the way, it is possible to attach it
>> in
>> the mailing list?)
>>
>> date,str1,str2,str3
>> 10/1/1998 0:00,0.6,0,0
>> 10/1/1998 1:00,0.2,0.2,0.2
>> 10/1/1998 2:00,0.6,0.2,0.4
>> 10/1/1998 3:00,0,0,0.6
>> 10/1/1998 4:00,0,0,0
>> 10/1/1998 5:00,0,0,0
>> 10/1/1998 6:00,0,0,0
>> 10/1/1998 7:00,0.2,0,0
>>
>>
>> I read it as:
>> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>
>> at this point I would like to have the daily mean.
>> What would you suggest?
>>
>> Really Really thanks,
>> You are my lifesaver
>>
>> Thanks
>>
>>
>>
>> Diego
>>
>>
>> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>> > ... and the most common source of NA values in time data is wrong
>> > timezones. You really need to make sure the timezone that is assumed
>> when
>> > the character data are converted to POSIXt agrees with the data. In most
>> > cases the easiest way to insure this is to use
>> >
>> > Sys.setenv(TZ="US/Pacific")
>> >
>> > or whatever timezone from
>> >
>> > OlsonNames()
>> >
>> > corresponds with your data. Execute this setenv function before the
>> > strptime or as.POSIXct() function call.
>> >
>> > You can use
>> >
>> > MyData[ is.na(MyData$datetime), ]
>> >
>> > to see which records are failing to convert time.
>> >
>> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>> >
>> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>> > >Hi Diego,
>> > >I think the error is due to NA values in your data file. If I extend
>> > >your example and run it, I get no errors:
>> > >
>> > >MyData<-read.table(text="103001930 103001580 103001530
>> > >1998-10-01 00:00:00 0.6 0 0
>> > >1998-10-01 01:00:00 0.2 0.2 0.2
>> > >1998-10-01 02:00:00 0.6 0.2 0.4
>> > >1998-10-01 03:00:00 0 0 0.6
>> > >1998-10-01 04:00:00 0 0 0
>> > >1998-10-01 05:00:00 0 0 0
>> > >1998-10-01 06:00:00 0 0 0
>> > >1998-10-01 07:00:00 0.2 0 0
>> > >1998-10-01 08:00:00 0.6 0 0
>> > >1998-10-01 09:00:00 0.2 0.2 0.2
>> > >1998-10-01 10:00:00 0.6 0.2 0.4
>> > >1998-10-01 11:00:00 0 0 0.6
>> > >1998-10-01 12:00:00 0 0 0
>> > >1998-10-01 13:00:00 0 0 0
>> > >1998-10-01 14:00:00 0 0 0
>> > >1998-10-01 15:00:00 0.2 0 0
>> > >1998-10-01 16:00:00 0.6 0 0
>> > >1998-10-01 17:00:00 0.2 0.2 0.2
>> > >1998-10-01 18:00:00 0.6 0.2 0.4
>> > >1998-10-01 19:00:00 0 0 0.6
>> > >1998-10-01 20:00:00 0 0 0
>> > >1998-10-01 21:00:00 0 0 0
>> > >1998-10-01 22:00:00 0 0 0
>> > >1998-10-01 23:00:00 0.2 0 0
>> > >1998-10-02 00:00:00 0.6 0 0
>> > >1998-10-02 01:00:00 0.2 0.2 0.2
>> > >1998-10-02 02:00:00 0.6 0.2 0.4
>> > >1998-10-02 03:00:00 0 0 0.6
>> > >1998-10-02 04:00:00 0 0 0
>> > >1998-10-02 05:00:00 0 0 0
>> > >1998-10-02 06:00:00 0 0 0
>> > >1998-10-02 07:00:00 0.2 0 0
>> > >1998-10-02 08:00:00 0.6 0 0
>> > >1998-10-02 09:00:00 0.2 0.2 0.2
>> > >1998-10-02 10:00:00 0.6 0.2 0.4
>> > >1998-10-02 11:00:00 0 0 0.6
>> > >1998-10-02 12:00:00 0 0 0
>> > >1998-10-02 13:00:00 0 0 0
>> > >1998-10-02 14:00:00 0 0 0
>> > >1998-10-02 15:00:00 0.2 0 0
>> > >1998-10-02 16:00:00 0.6 0 0
>> > >1998-10-02 17:00:00 0.2 0.2 0.2
>> > >1998-10-02 18:00:00 0.6 0.2 0.4
>> > >1998-10-02 19:00:00 0 0 0.6
>> > >1998-10-02 20:00:00 0 0 0
>> > >1998-10-02 21:00:00 0 0 0
>> > >1998-10-02 22:00:00 0 0 0
>> > >1998-10-02 23:00:00 0.2 0 0",
>> > >skip=1,stringsAsFactors=FALSE)
>> > >names(MyData)<-c("date","time","st1","st2","st3")
>> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
>> > > format="%Y-%m-%d %H:%M:%S")
>> > >MyData$datetime
>> > >st1_daily<-by(MyData$st1,MyData$date,mean)
>> > >st2_daily<-by(MyData$st2,MyData$date,mean)
>> > >st3_daily<-by(MyData$st3,MyData$date,mean)
>> > >st1_daily
>> > >st2_daily
>> > >st3_daily
>> > >
>> > >Try adding na.rm=TRUE to the "by" calls:
>> > >
>> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
>> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
>> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
>> > >
>> > >Jim
>> > >
>> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
>> > ><diego.avesani at gmail.com> wrote:
>> > >> Dear all,
>> > >>
>> > >> I have still problem with date.
>> > >> Could you please tel me how to use POSIXct.
>> > >> Indeed I have found this command:
>> > >> timeAverage, but I am not able to convert MyDate to properly date.
>> > >>
>> > >> Thank a lot
>> > >> I hope to no bother you, at least too much
>> > >>
>> > >>
>> > >> Diego
>> > >>
>> > >>
>> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
>> > >wrote:
>> > >>>
>> > >>> Dear Jim, Dear all,
>> > >>>
>> > >>> thanks a lot.
>> > >>>
>> > >>> Unfortunately, I get the following error:
>> > >>>
>> > >>>
>> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
>> > >925L,  :
>> > >>>   arguments must have same length
>> > >>>
>> > >>>
>> > >>> This is particularly strange. indeed, if I apply
>> > >>>
>> > >>>
>> > >>> mean(MyData$str1,na.rm=TRUE)
>> > >>>
>> > >>>
>> > >>> it works
>> > >>>
>> > >>>
>> > >>> Sorry, I have to learn a lot.
>> > >>> You are really boosting me
>> > >>>
>> > >>> Diego
>> > >>>
>> > >>>
>> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>> > >>>>
>> > >>>> Hi Diego,
>> > >>>> One way you can get daily means is:
>> > >>>>
>> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>> > >>>>
>> > >>>> Jim
>> > >>>>
>> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
>> > ><diego.avesani at gmail.com>
>> > >>>> wrote:
>> > >>>> > Dear all,
>> > >>>> > I have found the error, my fault. Sorry.
>> > >>>> > There was an extra come in the headers line.
>> > >>>> > Thanks again.
>> > >>>> >
>> > >>>> > If I can I would like to ask you another questions about the
>> > >imported
>> > >>>> > data.
>> > >>>> > I would like to compute the daily average of the different date.
>> > >>>> > Basically I
>> > >>>> > have hourly data, I would like to ave the daily mean of them.
>> > >>>> >
>> > >>>> > Is there some special commands?
>> > >>>> >
>> > >>>> > Thanks a lot.
>> > >>>> >
>> > >>>> >
>> > >>>> > Diego
>> > >>>> >
>> > >>>> >
>> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com
>> >
>> > >>>> > wrote:
>> > >>>> >>
>> > >>>> >> Dear all,
>> > >>>> >> I move to csv file because originally the date where in csv
>> > >file.
>> > >>>> >> In addition, due to the fact that, as you told me, read.csv is a
>> > >>>> >> special
>> > >>>> >> case of read.table, I prefer start to learn from the simplest
>> > >one.
>> > >>>> >> After that, I will try also the *.txt format.
>> > >>>> >>
>> > >>>> >> with read.csv, something strange happened:
>> > >>>> >>
>> > >>>> >> This us now the file:
>> > >>>> >>
>> > >>>> >> date,st1,st2,st3,
>> > >>>> >> 10/1/1998 0:00,0.6,0,0
>> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>> > >>>> >> 10/1/1998 3:00,0,0,0.6
>> > >>>> >> 10/1/1998 4:00,0,0,0
>> > >>>> >> 10/1/1998 5:00,0,0,0
>> > >>>> >> 10/1/1998 6:00,0,0,0
>> > >>>> >> 10/1/1998 7:00,0.2,0,0
>> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
>> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
>> > >>>> >>
>> > >>>> >> When I apply:
>> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>> > >>>> >>
>> > >>>> >> this is the results:
>> > >>>> >>
>> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>> > >>>> >>
>> > >>>> >> I do not understand why.
>> > >>>> >> Something wrong with date?
>> > >>>> >>
>> > >>>> >> really really thanks,
>> > >>>> >> I appreciate a lot all your helps.
>> > >>>> >>
>> > >>>> >> Diedro
>> > >>>> >>
>> > >>>> >>
>> > >>>> >> Diego
>> > >>>> >>
>> > >>>> >>
>> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
>> > >wrote:
>> > >>>> >>>
>> > >>>> >>> Or, without removing the first line
>> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>> > >>>> >>>
>> > >>>> >>> Another alternative,
>> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>> > >>>> >>> since the dates appear to be in the default format.
>> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
>> > >rather
>> > >>>> >>> than
>> > >>>> >>> POSIXlt class)
>> > >>>> >>>
>> > >>>> >>> -Don
>> > >>>> >>>
>> > >>>> >>> --
>> > >>>> >>> Don MacQueen
>> > >>>> >>> Lawrence Livermore National Laboratory
>> > >>>> >>> 7000 East Ave., L-627
>> > >>>> >>> Livermore, CA 94550
>> > >>>> >>> 925-423-1062
>> > >>>> >>> Lab cell 925-724-7509
>> > >>>> >>>
>> > >>>> >>>
>> > >>>> >>>
>> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>> > >>>> >>> <r-help-bounces at r-project.org on behalf of
>> > >drjimlemon at gmail.com>
>> > >>>> >>> wrote:
>> > >>>> >>>
>> > >>>> >>>     Hi Diego,
>> > >>>> >>>     You may have to do some conversion as you have three fields
>> > >in
>> > >>>> >>> the
>> > >>>> >>>     first line using the default space separator and five
>> > >fields in
>> > >>>> >>>     subsequent lines. If the first line doesn't contain any
>> > >important
>> > >>>> >>> data
>> > >>>> >>>     you can just delete it or replace it with a meaningful
>> > >header
>> > >>>> >>> line
>> > >>>> >>>     with five fields and save the file under another name.
>> > >>>> >>>
>> > >>>> >>>     It looks as thought you have date-time as two fields. If
>> > >so, you
>> > >>>> >>> can
>> > >>>> >>>     just read the first field if you only want the date:
>> > >>>> >>>
>> > >>>> >>>     # assume you have removed the first line
>> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>> > >>>> >>>
>> > >>>> >>>     If you want the date/time:
>> > >>>> >>>
>> > >>>> >>>
>> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>> > >>>> >>> %H:%M:%S")
>> > >>>> >>>
>> > >>>> >>>     Jim
>> > >>>> >>>
>> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>> > >>>> >>> <diego.avesani at gmail.com> wrote:
>> > >>>> >>>     > Dear all,
>> > >>>> >>>     >
>> > >>>> >>>     > I am dealing with the reading of a *.txt file.
>> > >>>> >>>     > The txt file the following shape:
>> > >>>> >>>     >
>> > >>>> >>>     > 103001930 103001580 103001530
>> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
>> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
>> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
>> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>> > >>>> >>>     >
>> > >>>> >>>     > If it is possible I have a coupe of questions, which will
>> > >sound
>> > >>>> >>> stupid but
>> > >>>> >>>     > they are important to me in order to understand ho R deal
>> > >with
>> > >>>> >>> file
>> > >>>> >>> or date.
>> > >>>> >>>     >
>> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
>> > >>>> >>>     > 2) Can a deal with space and not ","
>> > >>>> >>>     > 3) How can I read date?
>> > >>>> >>>     >
>> > >>>> >>>     > thanks a lot to all of you,
>> > >>>> >>>     > Thanks
>> > >>>> >>>     >
>> > >>>> >>>     >
>> > >>>> >>>     > Diego
>> > >>>> >>>     >
>> > >>>> >>>     >         [[alternative HTML version deleted]]
>> > >>>> >>>     >
>> > >>>> >>>     > ______________________________________________
>> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> > >more,
>> > >>>> >>> see
>> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>> >>>     > PLEASE do read the posting guide
>> > >>>> >>> http://www.R-project.org/posting-guide.html
>> > >>>> >>>     > and provide commented, minimal, self-contained,
>> > >reproducible
>> > >>>> >>> code.
>> > >>>> >>>
>> > >>>> >>>     ______________________________________________
>> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> > >more, see
>> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>> >>>     PLEASE do read the posting guide
>> > >>>> >>> http://www.R-project.org/posting-guide.html
>> > >>>> >>>     and provide commented, minimal, self-contained,
>> > >reproducible
>> > >>>> >>> code.
>> > >>>> >>>
>> > >>>> >>>
>> > >>>> >>
>> > >>>> >
>> > >>>
>> > >>>
>> > >>
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Thu Aug  2 09:32:38 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 2 Aug 2018 07:32:38 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
Message-ID: <8a286c58191c4dfebcd7e1fb60db9bca@SRVEXCHCM1302.precheza.cz>

Hi

see in line (and please do not post HTML formated messages, it could be scrammbled)

From: Diego Avesani <diego.avesani at gmail.com>
Sent: Thursday, August 2, 2018 8:56 AM
To: jim holtman <jholtman at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] read txt file - date - no space

Dear

I have check the one of the line that gives me problem. I mean, which give NA after R processing. I think that is similar to the others:

You should stop **thinking** and instead do real inspection of ?offending? values.

10/12/1998 10:00,0,0,0
10/12/1998 11:00,0,0,0
10/12/1998 12:00,0,0,0
10/12/1998 13:00,0,0,0
10/12/1998 14:00,0,0,0
10/12/1998 15:00,0,0,0
10/12/1998 16:00,0,0,0
10/12/1998 17:00,0,0,0

These lines do not pose any problem with formating.

>  test<-read.table("clipboard", sep=",")
> str(test)
'data.frame':   8 obs. of  4 variables:
$ V1: Factor w/ 8 levels "10/12/1998 10:00",..: 1 2 3 4 5 6 7 8
$ V2: int  0 0 0 0 0 0 0 0
$ V3: int  0 0 0 0 0 0 0 0
$ V4: int  0 0 0 0 0 0 0 0
> as.POSIXct(test$V1, format="%d/%m/%Y %H:%M")
[1] "1998-12-10 10:00:00 CET" "1998-12-10 11:00:00 CET"
[3] "1998-12-10 12:00:00 CET" "1998-12-10 13:00:00 CET"
[5] "1998-12-10 14:00:00 CET" "1998-12-10 15:00:00 CET"
[7] "1998-12-10 16:00:00 CET" "1998-12-10 17:00:00 CET"


@jim: It seems that you suggestion is focus on reading data from the terminal. It is possible to apply it to a *.csv file?

@Pikal: Could it be that there are some date conversion error?

Well, your str(MyData) result suggest, that conversion from character to POSIX was done correctly (at least partly).

However NAs in date column you posted in second mail suggest, that some values in the input are probably formated differently and they are changed to NA during POSIX conversion.

You could check which values are problematic if instead directly changing date column to POSIX you put a new column to you data with converted POSIX values

So read your data from csv file and change date to POSIX but store it in different column of data frame.

MyData$date2 <- as.POSIXct(MyData$date, format="%d/%m/%Y %H:%M")

and check which values in your original file are formated differently.

something like
MyData$date[is.na(MyData$date2)]

However your (very basic) questions suggest, that you have only minor understanding what are R objects, how to check, inspect and manipulate them. You could do a big favour to yourself going through basic documentation as I suggested before.

Cheers
Petr

Thanks again,
Diego


Diego

On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com<mailto:jholtman at gmail.com>> wrote:

Try this:

> library(lubridate)
> library(tidyverse)
> input <- read.csv(text = "date,str1,str2,str3
+ 10/1/1998 0:00,0.6,0,0
+                   10/1/1998 1:00,0.2,0.2,0.2
+                   10/1/1998 2:00,0.6,0.2,0.4
+                   10/1/1998 3:00,0,0,0.6
+                   10/1/1998 4:00,0,0,0
+                   10/1/1998 5:00,0,0,0
+                   10/1/1998 6:00,0,0,0
+                   10/1/1998 7:00,0.2,0,0", as.is<http://as.is> = TRUE)
> # convert the date and add the "day" so summarize
> input <- input %>%
+   mutate(date = mdy_hm(date),
+          day = floor_date(date, unit = 'day')
+   )
>
> by_day <- input %>%
+   group_by(day) %>%
+   summarise(m_s1 = mean(str1),
+             m_s2 = mean(str2),
+             m_s3 = mean(str3)
+   )
>
> by_day
# A tibble: 1 x 4
  day                  m_s1   m_s2  m_s3
  <dttm>              <dbl>  <dbl> <dbl>
1 1998-10-01 00:00:00 0.200 0.0500 0.150

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear all,
I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
all again in order to understand.
If I could I would like to start again, without mixing strategy and waiting
for your advice.

I am really appreciate you help, really really.
Here my new file, a *.csv file (buy the way, it is possible to attach it in
the mailing list?)

date,str1,str2,str3
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0


I read it as:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

at this point I would like to have the daily mean.
What would you suggest?

Really Really thanks,
You are my lifesaver

Thanks



Diego


On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:

> ... and the most common source of NA values in time data is wrong
> timezones. You really need to make sure the timezone that is assumed when
> the character data are converted to POSIXt agrees with the data. In most
> cases the easiest way to insure this is to use
>
> Sys.setenv(TZ="US/Pacific")
>
> or whatever timezone from
>
> OlsonNames()
>
> corresponds with your data. Execute this setenv function before the
> strptime or as.POSIXct() function call.
>
> You can use
>
> MyData[ is.na<http://is.na>(MyData$datetime), ]
>
> to see which records are failing to convert time.
>
> [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>
> On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >Hi Diego,
> >I think the error is due to NA values in your data file. If I extend
> >your example and run it, I get no errors:
> >
> >MyData<-read.table(text="103001930 103001580 103001530
> >1998-10-01 00:00:00 0.6 0 0
> >1998-10-01 01:00:00 0.2 0.2 0.2
> >1998-10-01 02:00:00 0.6 0.2 0.4
> >1998-10-01 03:00:00 0 0 0.6
> >1998-10-01 04:00:00 0 0 0
> >1998-10-01 05:00:00 0 0 0
> >1998-10-01 06:00:00 0 0 0
> >1998-10-01 07:00:00 0.2 0 0
> >1998-10-01 08:00:00 0.6 0 0
> >1998-10-01 09:00:00 0.2 0.2 0.2
> >1998-10-01 10:00:00 0.6 0.2 0.4
> >1998-10-01 11:00:00 0 0 0.6
> >1998-10-01 12:00:00 0 0 0
> >1998-10-01 13:00:00 0 0 0
> >1998-10-01 14:00:00 0 0 0
> >1998-10-01 15:00:00 0.2 0 0
> >1998-10-01 16:00:00 0.6 0 0
> >1998-10-01 17:00:00 0.2 0.2 0.2
> >1998-10-01 18:00:00 0.6 0.2 0.4
> >1998-10-01 19:00:00 0 0 0.6
> >1998-10-01 20:00:00 0 0 0
> >1998-10-01 21:00:00 0 0 0
> >1998-10-01 22:00:00 0 0 0
> >1998-10-01 23:00:00 0.2 0 0
> >1998-10-02 00:00:00 0.6 0 0
> >1998-10-02 01:00:00 0.2 0.2 0.2
> >1998-10-02 02:00:00 0.6 0.2 0.4
> >1998-10-02 03:00:00 0 0 0.6
> >1998-10-02 04:00:00 0 0 0
> >1998-10-02 05:00:00 0 0 0
> >1998-10-02 06:00:00 0 0 0
> >1998-10-02 07:00:00 0.2 0 0
> >1998-10-02 08:00:00 0.6 0 0
> >1998-10-02 09:00:00 0.2 0.2 0.2
> >1998-10-02 10:00:00 0.6 0.2 0.4
> >1998-10-02 11:00:00 0 0 0.6
> >1998-10-02 12:00:00 0 0 0
> >1998-10-02 13:00:00 0 0 0
> >1998-10-02 14:00:00 0 0 0
> >1998-10-02 15:00:00 0.2 0 0
> >1998-10-02 16:00:00 0.6 0 0
> >1998-10-02 17:00:00 0.2 0.2 0.2
> >1998-10-02 18:00:00 0.6 0.2 0.4
> >1998-10-02 19:00:00 0 0 0.6
> >1998-10-02 20:00:00 0 0 0
> >1998-10-02 21:00:00 0 0 0
> >1998-10-02 22:00:00 0 0 0
> >1998-10-02 23:00:00 0.2 0 0",
> >skip=1,stringsAsFactors=FALSE)
> >names(MyData)<-c("date","time","st1","st2","st3")
> >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > format="%Y-%m-%d %H:%M:%S")
> >MyData$datetime
> >st1_daily<-by(MyData$st1,MyData$date,mean)
> >st2_daily<-by(MyData$st2,MyData$date,mean)
> >st3_daily<-by(MyData$st3,MyData$date,mean)
> >st1_daily
> >st2_daily
> >st3_daily
> >
> >Try adding na.rm=TRUE to the "by" calls:
> >
> >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> >
> >Jim
> >
> >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >> Dear all,
> >>
> >> I have still problem with date.
> >> Could you please tel me how to use POSIXct.
> >> Indeed I have found this command:
> >> timeAverage, but I am not able to convert MyDate to properly date.
> >>
> >> Thank a lot
> >> I hope to no bother you, at least too much
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >wrote:
> >>>
> >>> Dear Jim, Dear all,
> >>>
> >>> thanks a lot.
> >>>
> >>> Unfortunately, I get the following error:
> >>>
> >>>
> >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> >925L,  :
> >>>   arguments must have same length
> >>>
> >>>
> >>> This is particularly strange. indeed, if I apply
> >>>
> >>>
> >>> mean(MyData$str1,na.rm=TRUE)
> >>>
> >>>
> >>> it works
> >>>
> >>>
> >>> Sorry, I have to learn a lot.
> >>> You are really boosting me
> >>>
> >>> Diego
> >>>
> >>>
> >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >>>>
> >>>> Hi Diego,
> >>>> One way you can get daily means is:
> >>>>
> >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> >>>>
> >>>> Jim
> >>>>
> >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> wrote:
> >>>> > Dear all,
> >>>> > I have found the error, my fault. Sorry.
> >>>> > There was an extra come in the headers line.
> >>>> > Thanks again.
> >>>> >
> >>>> > If I can I would like to ask you another questions about the
> >imported
> >>>> > data.
> >>>> > I would like to compute the daily average of the different date.
> >>>> > Basically I
> >>>> > have hourly data, I would like to ave the daily mean of them.
> >>>> >
> >>>> > Is there some special commands?
> >>>> >
> >>>> > Thanks a lot.
> >>>> >
> >>>> >
> >>>> > Diego
> >>>> >
> >>>> >
> >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> > wrote:
> >>>> >>
> >>>> >> Dear all,
> >>>> >> I move to csv file because originally the date where in csv
> >file.
> >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> >>>> >> special
> >>>> >> case of read.table, I prefer start to learn from the simplest
> >one.
> >>>> >> After that, I will try also the *.txt format.
> >>>> >>
> >>>> >> with read.csv, something strange happened:
> >>>> >>
> >>>> >> This us now the file:
> >>>> >>
> >>>> >> date,st1,st2,st3,
> >>>> >> 10/1/1998 0:00,0.6,0,0
> >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> >>>> >> 10/1/1998 3:00,0,0,0.6
> >>>> >> 10/1/1998 4:00,0,0,0
> >>>> >> 10/1/1998 5:00,0,0,0
> >>>> >> 10/1/1998 6:00,0,0,0
> >>>> >> 10/1/1998 7:00,0.2,0,0
> >>>> >> 10/1/1998 8:00,0.6,0.2,0
> >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> >>>> >> 10/1/1998 10:00,0,0.4,0.2
> >>>> >>
> >>>> >> When I apply:
> >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>>> >>
> >>>> >> this is the results:
> >>>> >>
> >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>>> >>
> >>>> >> I do not understand why.
> >>>> >> Something wrong with date?
> >>>> >>
> >>>> >> really really thanks,
> >>>> >> I appreciate a lot all your helps.
> >>>> >>
> >>>> >> Diedro
> >>>> >>
> >>>> >>
> >>>> >> Diego
> >>>> >>
> >>>> >>
> >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>
> >wrote:
> >>>> >>>
> >>>> >>> Or, without removing the first line
> >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>> >>>
> >>>> >>> Another alternative,
> >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>>> >>> since the dates appear to be in the default format.
> >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> >rather
> >>>> >>> than
> >>>> >>> POSIXlt class)
> >>>> >>>
> >>>> >>> -Don
> >>>> >>>
> >>>> >>> --
> >>>> >>> Don MacQueen
> >>>> >>> Lawrence Livermore National Laboratory
> >>>> >>> 7000 East Ave., L-627
> >>>> >>> Livermore, CA 94550
> >>>> >>> 925-423-1062
> >>>> >>> Lab cell 925-724-7509
> >>>> >>>
> >>>> >>>
> >>>> >>>
> >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>>> >>> <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of
> >drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> >>>> >>> wrote:
> >>>> >>>
> >>>> >>>     Hi Diego,
> >>>> >>>     You may have to do some conversion as you have three fields
> >in
> >>>> >>> the
> >>>> >>>     first line using the default space separator and five
> >fields in
> >>>> >>>     subsequent lines. If the first line doesn't contain any
> >important
> >>>> >>> data
> >>>> >>>     you can just delete it or replace it with a meaningful
> >header
> >>>> >>> line
> >>>> >>>     with five fields and save the file under another name.
> >>>> >>>
> >>>> >>>     It looks as thought you have date-time as two fields. If
> >so, you
> >>>> >>> can
> >>>> >>>     just read the first field if you only want the date:
> >>>> >>>
> >>>> >>>     # assume you have removed the first line
> >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>> >>>
> >>>> >>>     If you want the date/time:
> >>>> >>>
> >>>> >>>
> >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>>> >>> %H:%M:%S")
> >>>> >>>
> >>>> >>>     Jim
> >>>> >>>
> >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>>> >>> <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >>>> >>>     > Dear all,
> >>>> >>>     >
> >>>> >>>     > I am dealing with the reading of a *.txt file.
> >>>> >>>     > The txt file the following shape:
> >>>> >>>     >
> >>>> >>>     > 103001930 103001580 103001530
> >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>> >>>     >
> >>>> >>>     > If it is possible I have a coupe of questions, which will
> >sound
> >>>> >>> stupid but
> >>>> >>>     > they are important to me in order to understand ho R deal
> >with
> >>>> >>> file
> >>>> >>> or date.
> >>>> >>>     >
> >>>> >>>     > 1) Do I have to convert it to a *csv file?
> >>>> >>>     > 2) Can a deal with space and not ","
> >>>> >>>     > 3) How can I read date?
> >>>> >>>     >
> >>>> >>>     > thanks a lot to all of you,
> >>>> >>>     > Thanks
> >>>> >>>     >
> >>>> >>>     >
> >>>> >>>     > Diego
> >>>> >>>     >
> >>>> >>>     >         [[alternative HTML version deleted]]
> >>>> >>>     >
> >>>> >>>     > ______________________________________________
> >>>> >>>     > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more,
> >>>> >>> see
> >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     > PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     > and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>     ______________________________________________
> >>>> >>>     R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more, see
> >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>
> >>>> >>
> >>>> >
> >>>
> >>>
> >>
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From diego@@ve@@ni @ending from gm@il@com  Thu Aug  2 09:30:53 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Thu, 2 Aug 2018 09:30:53 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
Message-ID: <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>

Dear all,

I have found and error in the date conversion. Now it looks like:

MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
# change date to real
MyData$date<-as.POSIXct(MyData$date, format="%*m*/%*d*/%Y %H:%M")

After that I apply the PIKAL's suggestions:

aggregate(MyData[,-1], list(day(MyData$date)), mean)

And this is the final results:

 1 -82.43636 -46.12437 -319.2710
2        2 -82.06105 -45.74184 -319.2696
3        3 -82.05527 -45.52650 -319.2416
4        4 -82.03535 -47.59191 -319.2275
5        5 -77.44928 -50.05953 -320.5798
...
31    -86.10234 -47.06247 -340.0968

However, it is not correct.
This because I have not made myself clear about my purpose. As I told you
some days ago, I have a *.csv file with hourly data from 10/21/1998
to 12/31/2016. I would like to compute the daily means. Basically, I would
like to have the mean of the hourly date for each day from 10/21/1998
to 12/31/2016 and not 31 values.

Really really thanks again,
Diego


Diego


On 2 August 2018 at 08:55, Diego Avesani <diego.avesani at gmail.com> wrote:

> Dear
>
> I have check the one of the line that gives me problem. I mean, which give
> NA after R processing. I think that is similar to the others:
>
> 10/12/1998 10:00,0,0,0
> 10/12/1998 11:00,0,0,0
> 10/12/1998 12:00,0,0,0
> 10/12/1998 13:00,0,0,0
> 10/12/1998 14:00,0,0,0
> 10/12/1998 15:00,0,0,0
> 10/12/1998 16:00,0,0,0
> 10/12/1998 17:00,0,0,0
>
> @jim: It seems that you suggestion is focus on reading data from the
> terminal. It is possible to apply it to a *.csv file?
>
> @Pikal: Could it be that there are some date conversion error?
>
> Thanks again,
> Diego
>
>
> Diego
>
>
> On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com> wrote:
>
>>
>> Try this:
>>
>> > library(lubridate)
>> > library(tidyverse)
>> > input <- read.csv(text = "date,str1,str2,str3
>> + 10/1/1998 0:00,0.6,0,0
>> +                   10/1/1998 1:00,0.2,0.2,0.2
>> +                   10/1/1998 2:00,0.6,0.2,0.4
>> +                   10/1/1998 3:00,0,0,0.6
>> +                   10/1/1998 4:00,0,0,0
>> +                   10/1/1998 5:00,0,0,0
>> +                   10/1/1998 6:00,0,0,0
>> +                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
>> > # convert the date and add the "day" so summarize
>> > input <- input %>%
>> +   mutate(date = mdy_hm(date),
>> +          day = floor_date(date, unit = 'day')
>> +   )
>> >
>> > by_day <- input %>%
>> +   group_by(day) %>%
>> +   summarise(m_s1 = mean(str1),
>> +             m_s2 = mean(str2),
>> +             m_s3 = mean(str3)
>> +   )
>> >
>> > by_day
>> # A tibble: 1 x 4
>>   day                  m_s1   m_s2  m_s3
>>   <dttm>              <dbl>  <dbl> <dbl>
>> 1 1998-10-01 00:00:00 0.200 0.0500 0.150
>>
>> Jim Holtman
>> *Data Munger Guru*
>>
>>
>> *What is the problem that you are trying to solve?Tell me what you want
>> to do, not how you want to do it.*
>>
>>
>> On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
>> wrote:
>>
>>> Dear all,
>>> I am sorry, I did a lot of confusion. I am sorry, I have to relax and
>>> stat
>>> all again in order to understand.
>>> If I could I would like to start again, without mixing strategy and
>>> waiting
>>> for your advice.
>>>
>>> I am really appreciate you help, really really.
>>> Here my new file, a *.csv file (buy the way, it is possible to attach it
>>> in
>>> the mailing list?)
>>>
>>> date,str1,str2,str3
>>> 10/1/1998 0:00,0.6,0,0
>>> 10/1/1998 1:00,0.2,0.2,0.2
>>> 10/1/1998 2:00,0.6,0.2,0.4
>>> 10/1/1998 3:00,0,0,0.6
>>> 10/1/1998 4:00,0,0,0
>>> 10/1/1998 5:00,0,0,0
>>> 10/1/1998 6:00,0,0,0
>>> 10/1/1998 7:00,0.2,0,0
>>>
>>>
>>> I read it as:
>>> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>>
>>> at this point I would like to have the daily mean.
>>> What would you suggest?
>>>
>>> Really Really thanks,
>>> You are my lifesaver
>>>
>>> Thanks
>>>
>>>
>>>
>>> Diego
>>>
>>>
>>> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>> > ... and the most common source of NA values in time data is wrong
>>> > timezones. You really need to make sure the timezone that is assumed
>>> when
>>> > the character data are converted to POSIXt agrees with the data. In
>>> most
>>> > cases the easiest way to insure this is to use
>>> >
>>> > Sys.setenv(TZ="US/Pacific")
>>> >
>>> > or whatever timezone from
>>> >
>>> > OlsonNames()
>>> >
>>> > corresponds with your data. Execute this setenv function before the
>>> > strptime or as.POSIXct() function call.
>>> >
>>> > You can use
>>> >
>>> > MyData[ is.na(MyData$datetime), ]
>>> >
>>> > to see which records are failing to convert time.
>>> >
>>> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>>> >
>>> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>> > >Hi Diego,
>>> > >I think the error is due to NA values in your data file. If I extend
>>> > >your example and run it, I get no errors:
>>> > >
>>> > >MyData<-read.table(text="103001930 103001580 103001530
>>> > >1998-10-01 00:00:00 0.6 0 0
>>> > >1998-10-01 01:00:00 0.2 0.2 0.2
>>> > >1998-10-01 02:00:00 0.6 0.2 0.4
>>> > >1998-10-01 03:00:00 0 0 0.6
>>> > >1998-10-01 04:00:00 0 0 0
>>> > >1998-10-01 05:00:00 0 0 0
>>> > >1998-10-01 06:00:00 0 0 0
>>> > >1998-10-01 07:00:00 0.2 0 0
>>> > >1998-10-01 08:00:00 0.6 0 0
>>> > >1998-10-01 09:00:00 0.2 0.2 0.2
>>> > >1998-10-01 10:00:00 0.6 0.2 0.4
>>> > >1998-10-01 11:00:00 0 0 0.6
>>> > >1998-10-01 12:00:00 0 0 0
>>> > >1998-10-01 13:00:00 0 0 0
>>> > >1998-10-01 14:00:00 0 0 0
>>> > >1998-10-01 15:00:00 0.2 0 0
>>> > >1998-10-01 16:00:00 0.6 0 0
>>> > >1998-10-01 17:00:00 0.2 0.2 0.2
>>> > >1998-10-01 18:00:00 0.6 0.2 0.4
>>> > >1998-10-01 19:00:00 0 0 0.6
>>> > >1998-10-01 20:00:00 0 0 0
>>> > >1998-10-01 21:00:00 0 0 0
>>> > >1998-10-01 22:00:00 0 0 0
>>> > >1998-10-01 23:00:00 0.2 0 0
>>> > >1998-10-02 00:00:00 0.6 0 0
>>> > >1998-10-02 01:00:00 0.2 0.2 0.2
>>> > >1998-10-02 02:00:00 0.6 0.2 0.4
>>> > >1998-10-02 03:00:00 0 0 0.6
>>> > >1998-10-02 04:00:00 0 0 0
>>> > >1998-10-02 05:00:00 0 0 0
>>> > >1998-10-02 06:00:00 0 0 0
>>> > >1998-10-02 07:00:00 0.2 0 0
>>> > >1998-10-02 08:00:00 0.6 0 0
>>> > >1998-10-02 09:00:00 0.2 0.2 0.2
>>> > >1998-10-02 10:00:00 0.6 0.2 0.4
>>> > >1998-10-02 11:00:00 0 0 0.6
>>> > >1998-10-02 12:00:00 0 0 0
>>> > >1998-10-02 13:00:00 0 0 0
>>> > >1998-10-02 14:00:00 0 0 0
>>> > >1998-10-02 15:00:00 0.2 0 0
>>> > >1998-10-02 16:00:00 0.6 0 0
>>> > >1998-10-02 17:00:00 0.2 0.2 0.2
>>> > >1998-10-02 18:00:00 0.6 0.2 0.4
>>> > >1998-10-02 19:00:00 0 0 0.6
>>> > >1998-10-02 20:00:00 0 0 0
>>> > >1998-10-02 21:00:00 0 0 0
>>> > >1998-10-02 22:00:00 0 0 0
>>> > >1998-10-02 23:00:00 0.2 0 0",
>>> > >skip=1,stringsAsFactors=FALSE)
>>> > >names(MyData)<-c("date","time","st1","st2","st3")
>>> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
>>> > > format="%Y-%m-%d %H:%M:%S")
>>> > >MyData$datetime
>>> > >st1_daily<-by(MyData$st1,MyData$date,mean)
>>> > >st2_daily<-by(MyData$st2,MyData$date,mean)
>>> > >st3_daily<-by(MyData$st3,MyData$date,mean)
>>> > >st1_daily
>>> > >st2_daily
>>> > >st3_daily
>>> > >
>>> > >Try adding na.rm=TRUE to the "by" calls:
>>> > >
>>> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
>>> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
>>> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
>>> > >
>>> > >Jim
>>> > >
>>> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
>>> > ><diego.avesani at gmail.com> wrote:
>>> > >> Dear all,
>>> > >>
>>> > >> I have still problem with date.
>>> > >> Could you please tel me how to use POSIXct.
>>> > >> Indeed I have found this command:
>>> > >> timeAverage, but I am not able to convert MyDate to properly date.
>>> > >>
>>> > >> Thank a lot
>>> > >> I hope to no bother you, at least too much
>>> > >>
>>> > >>
>>> > >> Diego
>>> > >>
>>> > >>
>>> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
>>> > >wrote:
>>> > >>>
>>> > >>> Dear Jim, Dear all,
>>> > >>>
>>> > >>> thanks a lot.
>>> > >>>
>>> > >>> Unfortunately, I get the following error:
>>> > >>>
>>> > >>>
>>> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>>> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
>>> > >925L,  :
>>> > >>>   arguments must have same length
>>> > >>>
>>> > >>>
>>> > >>> This is particularly strange. indeed, if I apply
>>> > >>>
>>> > >>>
>>> > >>> mean(MyData$str1,na.rm=TRUE)
>>> > >>>
>>> > >>>
>>> > >>> it works
>>> > >>>
>>> > >>>
>>> > >>> Sorry, I have to learn a lot.
>>> > >>> You are really boosting me
>>> > >>>
>>> > >>> Diego
>>> > >>>
>>> > >>>
>>> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> > >>>>
>>> > >>>> Hi Diego,
>>> > >>>> One way you can get daily means is:
>>> > >>>>
>>> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>>> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>>> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>>> > >>>>
>>> > >>>> Jim
>>> > >>>>
>>> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
>>> > ><diego.avesani at gmail.com>
>>> > >>>> wrote:
>>> > >>>> > Dear all,
>>> > >>>> > I have found the error, my fault. Sorry.
>>> > >>>> > There was an extra come in the headers line.
>>> > >>>> > Thanks again.
>>> > >>>> >
>>> > >>>> > If I can I would like to ask you another questions about the
>>> > >imported
>>> > >>>> > data.
>>> > >>>> > I would like to compute the daily average of the different date.
>>> > >>>> > Basically I
>>> > >>>> > have hourly data, I would like to ave the daily mean of them.
>>> > >>>> >
>>> > >>>> > Is there some special commands?
>>> > >>>> >
>>> > >>>> > Thanks a lot.
>>> > >>>> >
>>> > >>>> >
>>> > >>>> > Diego
>>> > >>>> >
>>> > >>>> >
>>> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <
>>> diego.avesani at gmail.com>
>>> > >>>> > wrote:
>>> > >>>> >>
>>> > >>>> >> Dear all,
>>> > >>>> >> I move to csv file because originally the date where in csv
>>> > >file.
>>> > >>>> >> In addition, due to the fact that, as you told me, read.csv is
>>> a
>>> > >>>> >> special
>>> > >>>> >> case of read.table, I prefer start to learn from the simplest
>>> > >one.
>>> > >>>> >> After that, I will try also the *.txt format.
>>> > >>>> >>
>>> > >>>> >> with read.csv, something strange happened:
>>> > >>>> >>
>>> > >>>> >> This us now the file:
>>> > >>>> >>
>>> > >>>> >> date,st1,st2,st3,
>>> > >>>> >> 10/1/1998 0:00,0.6,0,0
>>> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>>> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>>> > >>>> >> 10/1/1998 3:00,0,0,0.6
>>> > >>>> >> 10/1/1998 4:00,0,0,0
>>> > >>>> >> 10/1/1998 5:00,0,0,0
>>> > >>>> >> 10/1/1998 6:00,0,0,0
>>> > >>>> >> 10/1/1998 7:00,0.2,0,0
>>> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
>>> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>>> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
>>> > >>>> >>
>>> > >>>> >> When I apply:
>>> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>> > >>>> >>
>>> > >>>> >> this is the results:
>>> > >>>> >>
>>> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>>> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>>> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>>> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>>> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>>> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>>> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>>> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>>> > >>>> >>
>>> > >>>> >> I do not understand why.
>>> > >>>> >> Something wrong with date?
>>> > >>>> >>
>>> > >>>> >> really really thanks,
>>> > >>>> >> I appreciate a lot all your helps.
>>> > >>>> >>
>>> > >>>> >> Diedro
>>> > >>>> >>
>>> > >>>> >>
>>> > >>>> >> Diego
>>> > >>>> >>
>>> > >>>> >>
>>> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
>>> > >wrote:
>>> > >>>> >>>
>>> > >>>> >>> Or, without removing the first line
>>> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
>>> skip=1)
>>> > >>>> >>>
>>> > >>>> >>> Another alternative,
>>> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>>> > >>>> >>> since the dates appear to be in the default format.
>>> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
>>> > >rather
>>> > >>>> >>> than
>>> > >>>> >>> POSIXlt class)
>>> > >>>> >>>
>>> > >>>> >>> -Don
>>> > >>>> >>>
>>> > >>>> >>> --
>>> > >>>> >>> Don MacQueen
>>> > >>>> >>> Lawrence Livermore National Laboratory
>>> > >>>> >>> 7000 East Ave., L-627
>>> > >>>> >>> Livermore, CA 94550
>>> > >>>> >>> 925-423-1062
>>> > >>>> >>> Lab cell 925-724-7509
>>> > >>>> >>>
>>> > >>>> >>>
>>> > >>>> >>>
>>> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>>> > >>>> >>> <r-help-bounces at r-project.org on behalf of
>>> > >drjimlemon at gmail.com>
>>> > >>>> >>> wrote:
>>> > >>>> >>>
>>> > >>>> >>>     Hi Diego,
>>> > >>>> >>>     You may have to do some conversion as you have three
>>> fields
>>> > >in
>>> > >>>> >>> the
>>> > >>>> >>>     first line using the default space separator and five
>>> > >fields in
>>> > >>>> >>>     subsequent lines. If the first line doesn't contain any
>>> > >important
>>> > >>>> >>> data
>>> > >>>> >>>     you can just delete it or replace it with a meaningful
>>> > >header
>>> > >>>> >>> line
>>> > >>>> >>>     with five fields and save the file under another name.
>>> > >>>> >>>
>>> > >>>> >>>     It looks as thought you have date-time as two fields. If
>>> > >so, you
>>> > >>>> >>> can
>>> > >>>> >>>     just read the first field if you only want the date:
>>> > >>>> >>>
>>> > >>>> >>>     # assume you have removed the first line
>>> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>> > >>>> >>>
>>> > >>>> >>>     If you want the date/time:
>>> > >>>> >>>
>>> > >>>> >>>
>>> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>>> > >>>> >>> %H:%M:%S")
>>> > >>>> >>>
>>> > >>>> >>>     Jim
>>> > >>>> >>>
>>> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>>> > >>>> >>> <diego.avesani at gmail.com> wrote:
>>> > >>>> >>>     > Dear all,
>>> > >>>> >>>     >
>>> > >>>> >>>     > I am dealing with the reading of a *.txt file.
>>> > >>>> >>>     > The txt file the following shape:
>>> > >>>> >>>     >
>>> > >>>> >>>     > 103001930 103001580 103001530
>>> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>>> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>>> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
>>> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
>>> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
>>> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>>> > >>>> >>>     >
>>> > >>>> >>>     > If it is possible I have a coupe of questions, which
>>> will
>>> > >sound
>>> > >>>> >>> stupid but
>>> > >>>> >>>     > they are important to me in order to understand ho R
>>> deal
>>> > >with
>>> > >>>> >>> file
>>> > >>>> >>> or date.
>>> > >>>> >>>     >
>>> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
>>> > >>>> >>>     > 2) Can a deal with space and not ","
>>> > >>>> >>>     > 3) How can I read date?
>>> > >>>> >>>     >
>>> > >>>> >>>     > thanks a lot to all of you,
>>> > >>>> >>>     > Thanks
>>> > >>>> >>>     >
>>> > >>>> >>>     >
>>> > >>>> >>>     > Diego
>>> > >>>> >>>     >
>>> > >>>> >>>     >         [[alternative HTML version deleted]]
>>> > >>>> >>>     >
>>> > >>>> >>>     > ______________________________________________
>>> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>> > >more,
>>> > >>>> >>> see
>>> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>>> >>>     > PLEASE do read the posting guide
>>> > >>>> >>> http://www.R-project.org/posting-guide.html
>>> > >>>> >>>     > and provide commented, minimal, self-contained,
>>> > >reproducible
>>> > >>>> >>> code.
>>> > >>>> >>>
>>> > >>>> >>>     ______________________________________________
>>> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>> > >more, see
>>> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>>> >>>     PLEASE do read the posting guide
>>> > >>>> >>> http://www.R-project.org/posting-guide.html
>>> > >>>> >>>     and provide commented, minimal, self-contained,
>>> > >reproducible
>>> > >>>> >>> code.
>>> > >>>> >>>
>>> > >>>> >>>
>>> > >>>> >>
>>> > >>>> >
>>> > >>>
>>> > >>>
>>> > >>
>>> > >
>>> > >______________________________________________
>>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >PLEASE do read the posting guide
>>> > >http://www.R-project.org/posting-guide.html
>>> > >and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > --
>>> > Sent from my phone. Please excuse my brevity.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Thu Aug  2 09:56:54 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 2 Aug 2018 07:56:54 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
 <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>
Message-ID: <7cc52fbb86b84fe3bd9234906559d145@SRVEXCHCM1302.precheza.cz>

Well,

you followed my advice only partly. Did you get rid of your silly -999 values before averaging? Probably not.
Did you tried aggregating by slightly longer construction
aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
which keeps difference in month and year? Probably not.

We do not have your data, we do not know what exactly you want to do so it is really difficult to give you a help.

If I calculate correctly there are 24 hour in one day and you have data for 18 years which gives me approximately 158000 distinct values.

I can get either 18 values (averaging years) or aproximately 6600 values (averaging days).

So my advice is:

Read your data to R
Change date column to POSIX but store it in different column
Change NA values from -999 to real NA values
Check dimension of your data ?dim
Check structure of your data ?str
Check if all dates are changed to POSIX correctly, are some of them NA?
Aggregate your values (not by lubridate function day) and store them in another object

Cheers
Petr


From: Diego Avesani <diego.avesani at gmail.com>
Sent: Thursday, August 2, 2018 9:31 AM
To: jim holtman <jholtman at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] read txt file - date - no space

Dear all,

I have found and error in the date conversion. Now it looks like:

MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
# change date to real
MyData$date<-as.POSIXct(MyData$date, format="%m/%d/%Y %H:%M")

After that I apply the PIKAL's suggestions:

aggregate(MyData[,-1], list(day(MyData$date)), mean)

And this is the final results:

 1 -82.43636 -46.12437 -319.2710
2        2 -82.06105 -45.74184 -319.2696
3        3 -82.05527 -45.52650 -319.2416
4        4 -82.03535 -47.59191 -319.2275
5        5 -77.44928 -50.05953 -320.5798
...
31    -86.10234 -47.06247 -340.0968

However, it is not correct.
This because I have not made myself clear about my purpose. As I told you some days ago, I have a *.csv file with hourly data from 10/21/1998 to 12/31/2016. I would like to compute the daily means. Basically, I would like to have the mean of the hourly date for each day from 10/21/1998 to 12/31/2016 and not 31 values.

Really really thanks again,
Diego


Diego

On 2 August 2018 at 08:55, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear

I have check the one of the line that gives me problem. I mean, which give NA after R processing. I think that is similar to the others:

10/12/1998 10:00,0,0,0
10/12/1998 11:00,0,0,0
10/12/1998 12:00,0,0,0
10/12/1998 13:00,0,0,0
10/12/1998 14:00,0,0,0
10/12/1998 15:00,0,0,0
10/12/1998 16:00,0,0,0
10/12/1998 17:00,0,0,0

@jim: It seems that you suggestion is focus on reading data from the terminal. It is possible to apply it to a *.csv file?

@Pikal: Could it be that there are some date conversion error?

Thanks again,
Diego


Diego

On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com<mailto:jholtman at gmail.com>> wrote:

Try this:

> library(lubridate)
> library(tidyverse)
> input <- read.csv(text = "date,str1,str2,str3
+ 10/1/1998 0:00,0.6,0,0
+                   10/1/1998 1:00,0.2,0.2,0.2
+                   10/1/1998 2:00,0.6,0.2,0.4
+                   10/1/1998 3:00,0,0,0.6
+                   10/1/1998 4:00,0,0,0
+                   10/1/1998 5:00,0,0,0
+                   10/1/1998 6:00,0,0,0
+                   10/1/1998 7:00,0.2,0,0", as.is<http://as.is> = TRUE)
> # convert the date and add the "day" so summarize
> input <- input %>%
+   mutate(date = mdy_hm(date),
+          day = floor_date(date, unit = 'day')
+   )
>
> by_day <- input %>%
+   group_by(day) %>%
+   summarise(m_s1 = mean(str1),
+             m_s2 = mean(str2),
+             m_s3 = mean(str3)
+   )
>
> by_day
# A tibble: 1 x 4
  day                  m_s1   m_s2  m_s3
  <dttm>              <dbl>  <dbl> <dbl>
1 1998-10-01 00:00:00 0.200 0.0500 0.150

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear all,
I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
all again in order to understand.
If I could I would like to start again, without mixing strategy and waiting
for your advice.

I am really appreciate you help, really really.
Here my new file, a *.csv file (buy the way, it is possible to attach it in
the mailing list?)

date,str1,str2,str3
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0


I read it as:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

at this point I would like to have the daily mean.
What would you suggest?

Really Really thanks,
You are my lifesaver

Thanks



Diego


On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:

> ... and the most common source of NA values in time data is wrong
> timezones. You really need to make sure the timezone that is assumed when
> the character data are converted to POSIXt agrees with the data. In most
> cases the easiest way to insure this is to use
>
> Sys.setenv(TZ="US/Pacific")
>
> or whatever timezone from
>
> OlsonNames()
>
> corresponds with your data. Execute this setenv function before the
> strptime or as.POSIXct() function call.
>
> You can use
>
> MyData[ is.na<http://is.na>(MyData$datetime), ]
>
> to see which records are failing to convert time.
>
> [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>
> On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >Hi Diego,
> >I think the error is due to NA values in your data file. If I extend
> >your example and run it, I get no errors:
> >
> >MyData<-read.table(text="103001930 103001580 103001530
> >1998-10-01 00:00:00 0.6 0 0
> >1998-10-01 01:00:00 0.2 0.2 0.2
> >1998-10-01 02:00:00 0.6 0.2 0.4
> >1998-10-01 03:00:00 0 0 0.6
> >1998-10-01 04:00:00 0 0 0
> >1998-10-01 05:00:00 0 0 0
> >1998-10-01 06:00:00 0 0 0
> >1998-10-01 07:00:00 0.2 0 0
> >1998-10-01 08:00:00 0.6 0 0
> >1998-10-01 09:00:00 0.2 0.2 0.2
> >1998-10-01 10:00:00 0.6 0.2 0.4
> >1998-10-01 11:00:00 0 0 0.6
> >1998-10-01 12:00:00 0 0 0
> >1998-10-01 13:00:00 0 0 0
> >1998-10-01 14:00:00 0 0 0
> >1998-10-01 15:00:00 0.2 0 0
> >1998-10-01 16:00:00 0.6 0 0
> >1998-10-01 17:00:00 0.2 0.2 0.2
> >1998-10-01 18:00:00 0.6 0.2 0.4
> >1998-10-01 19:00:00 0 0 0.6
> >1998-10-01 20:00:00 0 0 0
> >1998-10-01 21:00:00 0 0 0
> >1998-10-01 22:00:00 0 0 0
> >1998-10-01 23:00:00 0.2 0 0
> >1998-10-02 00:00:00 0.6 0 0
> >1998-10-02 01:00:00 0.2 0.2 0.2
> >1998-10-02 02:00:00 0.6 0.2 0.4
> >1998-10-02 03:00:00 0 0 0.6
> >1998-10-02 04:00:00 0 0 0
> >1998-10-02 05:00:00 0 0 0
> >1998-10-02 06:00:00 0 0 0
> >1998-10-02 07:00:00 0.2 0 0
> >1998-10-02 08:00:00 0.6 0 0
> >1998-10-02 09:00:00 0.2 0.2 0.2
> >1998-10-02 10:00:00 0.6 0.2 0.4
> >1998-10-02 11:00:00 0 0 0.6
> >1998-10-02 12:00:00 0 0 0
> >1998-10-02 13:00:00 0 0 0
> >1998-10-02 14:00:00 0 0 0
> >1998-10-02 15:00:00 0.2 0 0
> >1998-10-02 16:00:00 0.6 0 0
> >1998-10-02 17:00:00 0.2 0.2 0.2
> >1998-10-02 18:00:00 0.6 0.2 0.4
> >1998-10-02 19:00:00 0 0 0.6
> >1998-10-02 20:00:00 0 0 0
> >1998-10-02 21:00:00 0 0 0
> >1998-10-02 22:00:00 0 0 0
> >1998-10-02 23:00:00 0.2 0 0",
> >skip=1,stringsAsFactors=FALSE)
> >names(MyData)<-c("date","time","st1","st2","st3")
> >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > format="%Y-%m-%d %H:%M:%S")
> >MyData$datetime
> >st1_daily<-by(MyData$st1,MyData$date,mean)
> >st2_daily<-by(MyData$st2,MyData$date,mean)
> >st3_daily<-by(MyData$st3,MyData$date,mean)
> >st1_daily
> >st2_daily
> >st3_daily
> >
> >Try adding na.rm=TRUE to the "by" calls:
> >
> >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> >
> >Jim
> >
> >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >> Dear all,
> >>
> >> I have still problem with date.
> >> Could you please tel me how to use POSIXct.
> >> Indeed I have found this command:
> >> timeAverage, but I am not able to convert MyDate to properly date.
> >>
> >> Thank a lot
> >> I hope to no bother you, at least too much
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >wrote:
> >>>
> >>> Dear Jim, Dear all,
> >>>
> >>> thanks a lot.
> >>>
> >>> Unfortunately, I get the following error:
> >>>
> >>>
> >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> >925L,  :
> >>>   arguments must have same length
> >>>
> >>>
> >>> This is particularly strange. indeed, if I apply
> >>>
> >>>
> >>> mean(MyData$str1,na.rm=TRUE)
> >>>
> >>>
> >>> it works
> >>>
> >>>
> >>> Sorry, I have to learn a lot.
> >>> You are really boosting me
> >>>
> >>> Diego
> >>>
> >>>
> >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >>>>
> >>>> Hi Diego,
> >>>> One way you can get daily means is:
> >>>>
> >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> >>>>
> >>>> Jim
> >>>>
> >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> wrote:
> >>>> > Dear all,
> >>>> > I have found the error, my fault. Sorry.
> >>>> > There was an extra come in the headers line.
> >>>> > Thanks again.
> >>>> >
> >>>> > If I can I would like to ask you another questions about the
> >imported
> >>>> > data.
> >>>> > I would like to compute the daily average of the different date.
> >>>> > Basically I
> >>>> > have hourly data, I would like to ave the daily mean of them.
> >>>> >
> >>>> > Is there some special commands?
> >>>> >
> >>>> > Thanks a lot.
> >>>> >
> >>>> >
> >>>> > Diego
> >>>> >
> >>>> >
> >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> > wrote:
> >>>> >>
> >>>> >> Dear all,
> >>>> >> I move to csv file because originally the date where in csv
> >file.
> >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> >>>> >> special
> >>>> >> case of read.table, I prefer start to learn from the simplest
> >one.
> >>>> >> After that, I will try also the *.txt format.
> >>>> >>
> >>>> >> with read.csv, something strange happened:
> >>>> >>
> >>>> >> This us now the file:
> >>>> >>
> >>>> >> date,st1,st2,st3,
> >>>> >> 10/1/1998 0:00,0.6,0,0
> >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> >>>> >> 10/1/1998 3:00,0,0,0.6
> >>>> >> 10/1/1998 4:00,0,0,0
> >>>> >> 10/1/1998 5:00,0,0,0
> >>>> >> 10/1/1998 6:00,0,0,0
> >>>> >> 10/1/1998 7:00,0.2,0,0
> >>>> >> 10/1/1998 8:00,0.6,0.2,0
> >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> >>>> >> 10/1/1998 10:00,0,0.4,0.2
> >>>> >>
> >>>> >> When I apply:
> >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>>> >>
> >>>> >> this is the results:
> >>>> >>
> >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>>> >>
> >>>> >> I do not understand why.
> >>>> >> Something wrong with date?
> >>>> >>
> >>>> >> really really thanks,
> >>>> >> I appreciate a lot all your helps.
> >>>> >>
> >>>> >> Diedro
> >>>> >>
> >>>> >>
> >>>> >> Diego
> >>>> >>
> >>>> >>
> >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>
> >wrote:
> >>>> >>>
> >>>> >>> Or, without removing the first line
> >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>> >>>
> >>>> >>> Another alternative,
> >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>>> >>> since the dates appear to be in the default format.
> >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> >rather
> >>>> >>> than
> >>>> >>> POSIXlt class)
> >>>> >>>
> >>>> >>> -Don
> >>>> >>>
> >>>> >>> --
> >>>> >>> Don MacQueen
> >>>> >>> Lawrence Livermore National Laboratory
> >>>> >>> 7000 East Ave., L-627
> >>>> >>> Livermore, CA 94550
> >>>> >>> 925-423-1062
> >>>> >>> Lab cell 925-724-7509
> >>>> >>>
> >>>> >>>
> >>>> >>>
> >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>>> >>> <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of
> >drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> >>>> >>> wrote:
> >>>> >>>
> >>>> >>>     Hi Diego,
> >>>> >>>     You may have to do some conversion as you have three fields
> >in
> >>>> >>> the
> >>>> >>>     first line using the default space separator and five
> >fields in
> >>>> >>>     subsequent lines. If the first line doesn't contain any
> >important
> >>>> >>> data
> >>>> >>>     you can just delete it or replace it with a meaningful
> >header
> >>>> >>> line
> >>>> >>>     with five fields and save the file under another name.
> >>>> >>>
> >>>> >>>     It looks as thought you have date-time as two fields. If
> >so, you
> >>>> >>> can
> >>>> >>>     just read the first field if you only want the date:
> >>>> >>>
> >>>> >>>     # assume you have removed the first line
> >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>> >>>
> >>>> >>>     If you want the date/time:
> >>>> >>>
> >>>> >>>
> >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>>> >>> %H:%M:%S")
> >>>> >>>
> >>>> >>>     Jim
> >>>> >>>
> >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>>> >>> <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >>>> >>>     > Dear all,
> >>>> >>>     >
> >>>> >>>     > I am dealing with the reading of a *.txt file.
> >>>> >>>     > The txt file the following shape:
> >>>> >>>     >
> >>>> >>>     > 103001930 103001580 103001530
> >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>> >>>     >
> >>>> >>>     > If it is possible I have a coupe of questions, which will
> >sound
> >>>> >>> stupid but
> >>>> >>>     > they are important to me in order to understand ho R deal
> >with
> >>>> >>> file
> >>>> >>> or date.
> >>>> >>>     >
> >>>> >>>     > 1) Do I have to convert it to a *csv file?
> >>>> >>>     > 2) Can a deal with space and not ","
> >>>> >>>     > 3) How can I read date?
> >>>> >>>     >
> >>>> >>>     > thanks a lot to all of you,
> >>>> >>>     > Thanks
> >>>> >>>     >
> >>>> >>>     >
> >>>> >>>     > Diego
> >>>> >>>     >
> >>>> >>>     >         [[alternative HTML version deleted]]
> >>>> >>>     >
> >>>> >>>     > ______________________________________________
> >>>> >>>     > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more,
> >>>> >>> see
> >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     > PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     > and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>     ______________________________________________
> >>>> >>>     R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more, see
> >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>
> >>>> >>
> >>>> >
> >>>
> >>>
> >>
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From diego@@ve@@ni @ending from gm@il@com  Thu Aug  2 10:00:27 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Thu, 2 Aug 2018 10:00:27 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <8a286c58191c4dfebcd7e1fb60db9bca@SRVEXCHCM1302.precheza.cz>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
 <8a286c58191c4dfebcd7e1fb60db9bca@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAG8o1y7MTYCZnd8P-S2YDunbZL3M3tSfosSVa18aDwyP+H_PQw@mail.gmail.com>

Dear PIKAL, Dear all,

thanks again a lot.
I have finally understood what "in line" means.
I would definitely read some "R-intro" and in this moment I am reading a
R-tutorial.
I would not post formatted messages.

I would ask if it is possible to have some final suggestions:
- how to have daily mean;
- how to deal with NA;

Indeed, after changing the ate format I get

   Group.1      str1      str2      str3
1        1 -82.43636 -46.12437 -319.2710
2        2 -82.06105 -45.74184 -319.2696
3        3 -82.05527 -45.52650 -319.2416
4        4 -82.03535 -47.59191 -319.2275
...
31      31 -86.10234 -47.06247 -340.0968

As I said in the previously this is not correct.
This because I have not made myself clear about my purpose. As I told you
some days ago, I have a *.csv file with hourly data from 10/21/1998 to
12/31/2016.
I would like to compute the daily means.
Basically, I would like to have the mean of the hourly date for each day
from 10/21/1998 to 12/31/2016 and not 31 values.

I really really thank, especially for you patience.
I am leaning a lot,
Again thanks

Diego


On 2 August 2018 at 09:32, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> see in line (and please do not post HTML formated messages, it could be
> scrammbled)
>
>
>
> *From:* Diego Avesani <diego.avesani at gmail.com>
> *Sent:* Thursday, August 2, 2018 8:56 AM
> *To:* jim holtman <jholtman at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz
> >
> *Cc:* R mailing list <r-help at r-project.org>
> *Subject:* Re: [R] read txt file - date - no space
>
>
>
> Dear
>
>
>
> I have check the one of the line that gives me problem. I mean, which give
> NA after R processing. I think that is similar to the others:
>
>
>
> You should stop **thinking** and instead do real inspection of ?offending?
> values.
>
>
>
> 10/12/1998 10:00,0,0,0
>
> 10/12/1998 11:00,0,0,0
>
> 10/12/1998 12:00,0,0,0
>
> 10/12/1998 13:00,0,0,0
>
> 10/12/1998 14:00,0,0,0
>
> 10/12/1998 15:00,0,0,0
>
> 10/12/1998 16:00,0,0,0
>
> 10/12/1998 17:00,0,0,0
>
>
>
> These lines do not pose any problem with formating.
>
>
>
> >  test<-read.table("clipboard", sep=",")
>
> > str(test)
>
> 'data.frame':   8 obs. of  4 variables:
>
> $ V1: Factor w/ 8 levels "10/12/1998 10:00",..: 1 2 3 4 5 6 7 8
>
> $ V2: int  0 0 0 0 0 0 0 0
>
> $ V3: int  0 0 0 0 0 0 0 0
>
> $ V4: int  0 0 0 0 0 0 0 0
>
> > as.POSIXct(test$V1, format="%d/%m/%Y %H:%M")
>
> [1] "1998-12-10 10:00:00 CET" "1998-12-10 11:00:00 CET"
>
> [3] "1998-12-10 12:00:00 CET" "1998-12-10 13:00:00 CET"
>
> [5] "1998-12-10 14:00:00 CET" "1998-12-10 15:00:00 CET"
>
> [7] "1998-12-10 16:00:00 CET" "1998-12-10 17:00:00 CET"
>
>
>
>
>
> @jim: It seems that you suggestion is focus on reading data from the
> terminal. It is possible to apply it to a *.csv file?
>
>
>
> @Pikal: Could it be that there are some date conversion error?
>
>
>
> Well, your str(MyData) result suggest, that conversion from character to
> POSIX was done correctly (at least partly).
>
>
>
> However NAs in date column you posted in second mail suggest, that some
> values in the input are probably formated differently and they are changed
> to NA during POSIX conversion.
>
>
>
> You could check which values are problematic if instead directly changing
> date column to POSIX you put a new column to you data with converted POSIX
> values
>
>
>
> So read your data from csv file and change date to POSIX but store it in
> different column of data frame.
>
>
>
> MyData$date2 <- as.POSIXct(MyData$date, format="%d/%m/%Y %H:%M")
>
>
>
> and check which values in your original file are formated differently.
>
>
>
> something like
>
> MyData$date[is.na(MyData$date2)]
>
>
>
> However your (very basic) questions suggest, that you have only minor
> understanding what are R objects, how to check, inspect and manipulate
> them. You could do a big favour to yourself going through basic
> documentation as I suggested before.
>
>
>
> Cheers
>
> Petr
>
>
>
> Thanks again,
>
> Diego
>
>
>
>
> Diego
>
>
>
> On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com> wrote:
>
>
> Try this:
>
>
>
> > library(lubridate)
>
> > library(tidyverse)
>
> > input <- read.csv(text = "date,str1,str2,str3
>
> + 10/1/1998 0:00,0.6,0,0
>
> +                   10/1/1998 1:00,0.2,0.2,0.2
>
> +                   10/1/1998 2:00,0.6,0.2,0.4
>
> +                   10/1/1998 3:00,0,0,0.6
>
> +                   10/1/1998 4:00,0,0,0
>
> +                   10/1/1998 5:00,0,0,0
>
> +                   10/1/1998 6:00,0,0,0
>
> +                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
>
> > # convert the date and add the "day" so summarize
>
> > input <- input %>%
>
> +   mutate(date = mdy_hm(date),
>
> +          day = floor_date(date, unit = 'day')
>
> +   )
>
> >
>
> > by_day <- input %>%
>
> +   group_by(day) %>%
>
> +   summarise(m_s1 = mean(str1),
>
> +             m_s2 = mean(str2),
>
> +             m_s3 = mean(str3)
>
> +   )
>
> >
>
> > by_day
>
> # A tibble: 1 x 4
>
>   day                  m_s1   m_s2  m_s3
>
>   <dttm>              <dbl>  <dbl> <dbl>
>
> 1 1998-10-01 00:00:00 0.200 0.0500 0.150
>
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve? Tell me what you want
> to do, not how you want to do it.*
>
>
>
>
>
> On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
> wrote:
>
> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
> all again in order to understand.
> If I could I would like to start again, without mixing strategy and waiting
> for your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in
> the mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed when
> > the character data are converted to POSIXt agrees with the data. In most
> > cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> > >>>> >> special
> > >>>> >> case of read.table, I prefer start to learn from the simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > >drjimlemon at gmail.com>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> *Osobn? ?daje: *Informace o zpracov?n? a ochran? osobn?ch ?daj?
> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: *https://www.precheza.cz/zasady-ochrany-osobnich-udaju/
> <https://www.precheza.cz/zasady-ochrany-osobnich-udaju/>* | Information
> about processing and protection of business partner?s personal data are
> available on website: *https://www.precheza.cz/en/personal-data-protection-principles/
> <https://www.precheza.cz/en/personal-data-protection-principles/>*
>
> *D?v?rnost: *Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: *https://www.precheza.cz/01-dovetek/
> <https://www.precheza.cz/01-dovetek/>* | This email and any documents
> attached to it may be confidential and are subject to the legally binding
> disclaimer: *https://www.precheza.cz/en/01-disclaimer/
> <https://www.precheza.cz/en/01-disclaimer/>*
>
>
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Thu Aug  2 10:22:31 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Thu, 2 Aug 2018 11:22:31 +0300
Subject: [R] CODE HELP
In-Reply-To: <CAAr3ZhjhfE8ED+EwZeUOmM6gd8vcoKoZrWdswe-CVE3MXvF8oA@mail.gmail.com>
References: <CAAr3ZhjhfE8ED+EwZeUOmM6gd8vcoKoZrWdswe-CVE3MXvF8oA@mail.gmail.com>
Message-ID: <CAGgJW75YCXaJXoResfpJcOu4EBFxBmfHXR=bAeoToQpbCwrxSw@mail.gmail.com>

Hi Saptorshee,
Two comments:
1. no attachments made it through to the list. You probably need to include
the code directly in your email, and send your email as plain text
(otherwise information gets stripped)
2. for anyone interested in following up on Saptorshee's question, I
searched for the paper "Two Examples ..." and found that it is available
for download from https://arxiv.org/pdf/1806.10423.pdf. (It looks quite
interesting with a lot of discussion regarding various optimization
packages and their current status regarding availability from R.)

Best,
Eric


On Thu, Aug 2, 2018 at 5:01 AM, Saptorshee Kanto Chakraborty <
chkstr at unife.it> wrote:

> Hello,
>
> I am interested to apply an econometric technique of  Latent Variable
> framework on Environmental Kuznets Curve for 164 countries for a span of 25
> years.
>
> The methodology and the code are from Simulation exercise from an
> unpublished paper "Two Examples of Convex-Programming-Based
> High-Dimensional Econometric Estimators" in R. Is it somehow possible to
> apply it to my data.
>
>
> I am attaching the codes
>
> Thanking You
>
> --
> Saptorshee Chakraborty
>
> Personal Website: http://saptorshee.weebly.com/
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mi@ojpm @ending from gm@il@com  Thu Aug  2 10:30:44 2018
From: mi@ojpm @ending from gm@il@com (John)
Date: Thu, 2 Aug 2018 16:30:44 +0800
Subject: [R] F-test where the coefficients in the H_0 is nonzero
Message-ID: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>

Hi,

   I try to run the regression
   y = beta_0 + beta_1 x
   and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
   I believe I can run the regression
   (y-x) = beta_0 +beta_1? x
   and do the regular F-test (using lm functio) where the hypothesized
coefficients are all zero.

   Is there any function in R that deal with the case where the
coefficients are nonzero?

John

	[[alternative HTML version deleted]]


From diego@@ve@@ni @ending from gm@il@com  Thu Aug  2 10:53:22 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Thu, 2 Aug 2018 10:53:22 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <4fd59c09ca87481198eb0a6f338db729@SRVEXCHCM1302.precheza.cz>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
 <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>
 <7cc52fbb86b84fe3bd9234906559d145@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y6YtK9uhDxsnEPNsnQ5WPQUsaffpjG9uVKrPWBFUh4BAQ@mail.gmail.com>
 <4fd59c09ca87481198eb0a6f338db729@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAG8o1y7r=t9oRH-gYcfF8RuwKQx9VNkc3vV=AEQB-pCb18Vn1w@mail.gmail.com>

Dear Petr,

I have read the file:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

I have used  POSIXct to convert properly the date
MyData$date2<-as.POSIXct(MyData$date, format="%m/%d/%Y %H:%M")
creating a second field inside MyDate.

I have converted the -999 to NA:
MyData[MyData== -999] <- NA

dim(MyData):
160008      5
And this is clear because I have 160008 days and 5 field:
date2,date,str1,str2,str3

I have chech the structure of my data:
str(MyData)

'data.frame': 160008 obs. of  5 variables:
 $ date : Factor w/ 160008 levels "10/10/1998 0:00",..: 913 914 925 930 931
932 933 934 935 936 ...
 $ str1 : num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
 $ str2 : num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
 $ str3 : num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...
 $ date2: POSIXct, format: "1998-10-01 00:00:00" "1998-10-01 01:00:00"
"1998-10-01 02:00:00" "1998-10-01 03:00:00" ...

Almost everything is clear:
str1,str2,str3 are mumbers,
date2 are date in the format according to POSIXct: Y-m-d h:m:s
date has 160008 Factor, i.e. 160008  factors which are the number of
category.
I do not understand "913 914 925 930" are the possibilitiues in levels?

I have no NA in date2:

which(MyData$date2 == NA)
integer(0)

as well in date.

At this point I have applied:

daily_mean1<-aggregate(MyData$str1, list(format(MyData$date, "%Y-%m-%d")),
mean)

which seems to be correct:
I have

dim(daily_mean1):
6667    2
str(daily_mean1)
'data.frame': 6667 obs. of  2 variables:
 $ Group.1: chr  "1998-10-01" "1998-10-02" "1998-10-03" "1998-10-04" ...
 $ x      : num  0.1667 0.0583 0.0417 0.3417 0.3333 ...

Really Really thanks:
You not only taught me R  but also how to dealwith learning.

Can I ask you anover question about aggregate?

Again thanks

Diego


On 2 August 2018 at 10:10, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> *From:* Diego Avesani <diego.avesani at gmail.com>
> *Sent:* Thursday, August 2, 2018 10:03 AM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Subject:* Re: [R] read txt file - date - no space
>
>
>
> Thanks,
>
> I have just send you a e-mail, before reading this one.
>
> Let's me read your last mail and go carefully through it.
>
>
>
> Thanks again, really really,
>
> I mean it
>
>
>
> P.S.
>
> Do you wand my *.csv file?
>
>
>
> Not necessarily, you should better learn things yourself if you really
> want to use R. Only if after you tested all suggested ways and did not get
> desired result.
>
>
>
> Cheers
>
> Petr
>
>
>
>
> Diego
>
>
>
> On 2 August 2018 at 09:56, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Well,
>
>
>
> you followed my advice only partly. Did you get rid of your silly -999
> values before averaging? Probably not.
>
> Did you tried aggregating by slightly longer construction
>
> aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
>
> which keeps difference in month and year? Probably not.
>
>
>
> We do not have your data, we do not know what exactly you want to do so it
> is really difficult to give you a help.
>
>
>
> If I calculate correctly there are 24 hour in one day and you have data
> for 18 years which gives me approximately 158000 distinct values.
>
>
>
> I can get either 18 values (averaging years) or aproximately 6600 values
> (averaging days).
>
>
>
> So my advice is:
>
>
>
> Read your data to R
>
> Change date column to POSIX but store it in different column
>
> Change NA values from -999 to real NA values
>
> Check dimension of your data ?dim
>
> Check structure of your data ?str
>
> Check if all dates are changed to POSIX correctly, are some of them NA?
>
> Aggregate your values (not by lubridate function day) and store them in
> another object
>
>
>
> Cheers
>
> Petr
>
>
>
>
>
> *From:* Diego Avesani <diego.avesani at gmail.com>
> *Sent:* Thursday, August 2, 2018 9:31 AM
> *To:* jim holtman <jholtman at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz
> >
> *Cc:* R mailing list <r-help at r-project.org>
> *Subject:* Re: [R] read txt file - date - no space
>
>
>
> Dear all,
>
>
>
> I have found and error in the date conversion. Now it looks like:
>
>
>
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> # change date to real
>
> MyData$date<-as.POSIXct(MyData$date, format="%*m*/%*d*/%Y %H:%M")
>
>
>
> After that I apply the PIKAL's suggestions:
>
>
>
> aggregate(MyData[,-1], list(day(MyData$date)), mean)
>
>
>
> And this is the final results:
>
>
>
>  1 -82.43636 -46.12437 -319.2710
>
> 2        2 -82.06105 -45.74184 -319.2696
>
> 3        3 -82.05527 -45.52650 -319.2416
>
> 4        4 -82.03535 -47.59191 -319.2275
>
> 5        5 -77.44928 -50.05953 -320.5798
>
> ...
>
> 31    -86.10234 -47.06247 -340.0968
>
>
>
> However, it is not correct.
>
> This because I have not made myself clear about my purpose. As I told you
> some days ago, I have a *.csv file with hourly data from 10/21/1998
> to 12/31/2016. I would like to compute the daily means. Basically, I would
> like to have the mean of the hourly date for each day from 10/21/1998
> to 12/31/2016 and not 31 values.
>
>
>
> Really really thanks again,
>
> Diego
>
>
>
>
> Diego
>
>
>
> On 2 August 2018 at 08:55, Diego Avesani <diego.avesani at gmail.com> wrote:
>
> Dear
>
>
>
> I have check the one of the line that gives me problem. I mean, which give
> NA after R processing. I think that is similar to the others:
>
>
>
> 10/12/1998 10:00,0,0,0
>
> 10/12/1998 11:00,0,0,0
>
> 10/12/1998 12:00,0,0,0
>
> 10/12/1998 13:00,0,0,0
>
> 10/12/1998 14:00,0,0,0
>
> 10/12/1998 15:00,0,0,0
>
> 10/12/1998 16:00,0,0,0
>
> 10/12/1998 17:00,0,0,0
>
>
>
> @jim: It seems that you suggestion is focus on reading data from the
> terminal. It is possible to apply it to a *.csv file?
>
>
>
> @Pikal: Could it be that there are some date conversion error?
>
>
>
> Thanks again,
>
> Diego
>
>
>
>
> Diego
>
>
>
> On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com> wrote:
>
>
> Try this:
>
>
>
> > library(lubridate)
>
> > library(tidyverse)
>
> > input <- read.csv(text = "date,str1,str2,str3
>
> + 10/1/1998 0:00,0.6,0,0
>
> +                   10/1/1998 1:00,0.2,0.2,0.2
>
> +                   10/1/1998 2:00,0.6,0.2,0.4
>
> +                   10/1/1998 3:00,0,0,0.6
>
> +                   10/1/1998 4:00,0,0,0
>
> +                   10/1/1998 5:00,0,0,0
>
> +                   10/1/1998 6:00,0,0,0
>
> +                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
>
> > # convert the date and add the "day" so summarize
>
> > input <- input %>%
>
> +   mutate(date = mdy_hm(date),
>
> +          day = floor_date(date, unit = 'day')
>
> +   )
>
> >
>
> > by_day <- input %>%
>
> +   group_by(day) %>%
>
> +   summarise(m_s1 = mean(str1),
>
> +             m_s2 = mean(str2),
>
> +             m_s3 = mean(str3)
>
> +   )
>
> >
>
> > by_day
>
> # A tibble: 1 x 4
>
>   day                  m_s1   m_s2  m_s3
>
>   <dttm>              <dbl>  <dbl> <dbl>
>
> 1 1998-10-01 00:00:00 0.200 0.0500 0.150
>
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve? Tell me what you want
> to do, not how you want to do it.*
>
>
>
>
>
> On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
> wrote:
>
> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
> all again in order to understand.
> If I could I would like to start again, without mixing strategy and waiting
> for your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in
> the mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed when
> > the character data are converted to POSIXt agrees with the data. In most
> > cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> > >>>> >> special
> > >>>> >> case of read.table, I prefer start to learn from the simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > >drjimlemon at gmail.com>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> *Osobn? ?daje: *Informace o zpracov?n? a ochran? osobn?ch ?daj?
> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: *https://www.precheza.cz/zasady-ochrany-osobnich-udaju/
> <https://www.precheza.cz/zasady-ochrany-osobnich-udaju/>* | Information
> about processing and protection of business partner?s personal data are
> available on website: *https://www.precheza.cz/en/personal-data-protection-principles/
> <https://www.precheza.cz/en/personal-data-protection-principles/>*
>
> *D?v?rnost: *Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: *https://www.precheza.cz/01-dovetek/
> <https://www.precheza.cz/01-dovetek/>* | This email and any documents
> attached to it may be confidential and are subject to the legally binding
> disclaimer: *https://www.precheza.cz/en/01-disclaimer/
> <https://www.precheza.cz/en/01-disclaimer/>*
>
>
>
>
>

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Thu Aug  2 11:06:15 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Thu, 2 Aug 2018 11:06:15 +0200
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
Message-ID: <97AED34A-EBD9-47C2-8C39-CF149EC0C3E0@gmail.com>

This should do it:

> x <- rnorm(10)
> y <- x+rnorm(10)
> fit1 <- lm(y~x)
> fit2 <- lm(y~-1 + offset(0 + 1 * x))
> anova(fit2, fit1)
Analysis of Variance Table

Model 1: y ~ -1 + offset(0 + 1 * x)
Model 2: y ~ x
  Res.Df     RSS Df Sum of Sq      F Pr(>F)
1     10 10.6381                           
2      8  7.8096  2    2.8285 1.4487 0.2904


> On 2 Aug 2018, at 10:30 , John <miaojpm at gmail.com> wrote:
> 
> Hi,
> 
>   I try to run the regression
>   y = beta_0 + beta_1 x
>   and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
>   I believe I can run the regression
>   (y-x) = beta_0 +beta_1? x
>   and do the regular F-test (using lm functio) where the hypothesized
> coefficients are all zero.
> 
>   Is there any function in R that deal with the case where the
> coefficients are nonzero?
> 
> John
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr@pik@l @ending from prechez@@cz  Thu Aug  2 11:09:16 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 2 Aug 2018 09:09:16 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y7r=t9oRH-gYcfF8RuwKQx9VNkc3vV=AEQB-pCb18Vn1w@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
 <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>
 <7cc52fbb86b84fe3bd9234906559d145@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y6YtK9uhDxsnEPNsnQ5WPQUsaffpjG9uVKrPWBFUh4BAQ@mail.gmail.com>
 <4fd59c09ca87481198eb0a6f338db729@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y7r=t9oRH-gYcfF8RuwKQx9VNkc3vV=AEQB-pCb18Vn1w@mail.gmail.com>
Message-ID: <d9d6dad0c1374038a8c986b80b59fe65@SRVEXCHCM1302.precheza.cz>

Hi

Good that you have finally got desired result.
Regarding aggregate, you could consult help page

?aggregate

It has many good examples how to use it.

and for understanding factors

?factor is your friend and/or pages 16+ from R intro.

Cheers
Petr

From: Diego Avesani <diego.avesani at gmail.com>
Sent: Thursday, August 2, 2018 10:53 AM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] read txt file - date - no space


Dear Petr,

I have read the file:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

I have used  POSIXct to convert properly the date
MyData$date2<-as.POSIXct(MyData$date, format="%m/%d/%Y %H:%M")
creating a second field inside MyDate.

I have converted the -999 to NA:
MyData[MyData== -999] <- NA

dim(MyData):
160008      5
And this is clear because I have 160008 days and 5 field:
date2,date,str1,str2,str3

I have chech the structure of my data:
str(MyData)

'data.frame':   160008 obs. of  5 variables:
 $ date : Factor w/ 160008 levels "10/10/1998 0:00",..: 913 914 925 930 931 932 933 934 935 936 ...
 $ str1 : num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
 $ str2 : num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
 $ str3 : num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...
 $ date2: POSIXct, format: "1998-10-01 00:00:00" "1998-10-01 01:00:00" "1998-10-01 02:00:00" "1998-10-01 03:00:00" ...

Almost everything is clear:
str1,str2,str3 are mumbers,
date2 are date in the format according to POSIXct: Y-m-d h:m:s
date has 160008 Factor, i.e. 160008  factors which are the number of category.
I do not understand "913 914 925 930" are the possibilitiues in levels?

I have no NA in date2:

which(MyData$date2 == NA)
integer(0)

as well in date.

At this point I have applied:

daily_mean1<-aggregate(MyData$str1, list(format(MyData$date, "%Y-%m-%d")), mean)

which seems to be correct:
I have

dim(daily_mean1):
6667    2
str(daily_mean1)
'data.frame':   6667 obs. of  2 variables:
 $ Group.1: chr  "1998-10-01" "1998-10-02" "1998-10-03" "1998-10-04" ...
 $ x      : num  0.1667 0.0583 0.0417 0.3417 0.3333 ...

Really Really thanks:
You not only taught me R  but also how to dealwith learning.

Can I ask you anover question about aggregate?

Again thanks

Diego

On 2 August 2018 at 10:10, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

From: Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
Sent: Thursday, August 2, 2018 10:03 AM
To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Subject: Re: [R] read txt file - date - no space

Thanks,
I have just send you a e-mail, before reading this one.
Let's me read your last mail and go carefully through it.

Thanks again, really really,
I mean it

P.S.
Do you wand my *.csv file?

Not necessarily, you should better learn things yourself if you really want to use R. Only if after you tested all suggested ways and did not get desired result.

Cheers
Petr


Diego

On 2 August 2018 at 09:56, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Well,

you followed my advice only partly. Did you get rid of your silly -999 values before averaging? Probably not.
Did you tried aggregating by slightly longer construction
aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
which keeps difference in month and year? Probably not.

We do not have your data, we do not know what exactly you want to do so it is really difficult to give you a help.

If I calculate correctly there are 24 hour in one day and you have data for 18 years which gives me approximately 158000 distinct values.

I can get either 18 values (averaging years) or aproximately 6600 values (averaging days).

So my advice is:

Read your data to R
Change date column to POSIX but store it in different column
Change NA values from -999 to real NA values
Check dimension of your data ?dim
Check structure of your data ?str
Check if all dates are changed to POSIX correctly, are some of them NA?
Aggregate your values (not by lubridate function day) and store them in another object

Cheers
Petr


From: Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
Sent: Thursday, August 2, 2018 9:31 AM
To: jim holtman <jholtman at gmail.com<mailto:jholtman at gmail.com>>; PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Cc: R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] read txt file - date - no space

Dear all,

I have found and error in the date conversion. Now it looks like:

MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
# change date to real
MyData$date<-as.POSIXct(MyData$date, format="%m/%d/%Y %H:%M")

After that I apply the PIKAL's suggestions:

aggregate(MyData[,-1], list(day(MyData$date)), mean)

And this is the final results:

 1 -82.43636 -46.12437 -319.2710
2        2 -82.06105 -45.74184 -319.2696
3        3 -82.05527 -45.52650 -319.2416
4        4 -82.03535 -47.59191 -319.2275
5        5 -77.44928 -50.05953 -320.5798
...
31    -86.10234 -47.06247 -340.0968

However, it is not correct.
This because I have not made myself clear about my purpose. As I told you some days ago, I have a *.csv file with hourly data from 10/21/1998 to 12/31/2016. I would like to compute the daily means. Basically, I would like to have the mean of the hourly date for each day from 10/21/1998 to 12/31/2016 and not 31 values.

Really really thanks again,
Diego


Diego

On 2 August 2018 at 08:55, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear

I have check the one of the line that gives me problem. I mean, which give NA after R processing. I think that is similar to the others:

10/12/1998 10:00,0,0,0
10/12/1998 11:00,0,0,0
10/12/1998 12:00,0,0,0
10/12/1998 13:00,0,0,0
10/12/1998 14:00,0,0,0
10/12/1998 15:00,0,0,0
10/12/1998 16:00,0,0,0
10/12/1998 17:00,0,0,0

@jim: It seems that you suggestion is focus on reading data from the terminal. It is possible to apply it to a *.csv file?

@Pikal: Could it be that there are some date conversion error?

Thanks again,
Diego


Diego

On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com<mailto:jholtman at gmail.com>> wrote:

Try this:

> library(lubridate)
> library(tidyverse)
> input <- read.csv(text = "date,str1,str2,str3
+ 10/1/1998 0:00,0.6,0,0
+                   10/1/1998 1:00,0.2,0.2,0.2
+                   10/1/1998 2:00,0.6,0.2,0.4
+                   10/1/1998 3:00,0,0,0.6
+                   10/1/1998 4:00,0,0,0
+                   10/1/1998 5:00,0,0,0
+                   10/1/1998 6:00,0,0,0
+                   10/1/1998 7:00,0.2,0,0", as.is<http://as.is> = TRUE)
> # convert the date and add the "day" so summarize
> input <- input %>%
+   mutate(date = mdy_hm(date),
+          day = floor_date(date, unit = 'day')
+   )
>
> by_day <- input %>%
+   group_by(day) %>%
+   summarise(m_s1 = mean(str1),
+             m_s2 = mean(str2),
+             m_s3 = mean(str3)
+   )
>
> by_day
# A tibble: 1 x 4
  day                  m_s1   m_s2  m_s3
  <dttm>              <dbl>  <dbl> <dbl>
1 1998-10-01 00:00:00 0.200 0.0500 0.150

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear all,
I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
all again in order to understand.
If I could I would like to start again, without mixing strategy and waiting
for your advice.

I am really appreciate you help, really really.
Here my new file, a *.csv file (buy the way, it is possible to attach it in
the mailing list?)

date,str1,str2,str3
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0


I read it as:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

at this point I would like to have the daily mean.
What would you suggest?

Really Really thanks,
You are my lifesaver

Thanks



Diego


On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:

> ... and the most common source of NA values in time data is wrong
> timezones. You really need to make sure the timezone that is assumed when
> the character data are converted to POSIXt agrees with the data. In most
> cases the easiest way to insure this is to use
>
> Sys.setenv(TZ="US/Pacific")
>
> or whatever timezone from
>
> OlsonNames()
>
> corresponds with your data. Execute this setenv function before the
> strptime or as.POSIXct() function call.
>
> You can use
>
> MyData[ is.na<http://is.na>(MyData$datetime), ]
>
> to see which records are failing to convert time.
>
> [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>
> On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >Hi Diego,
> >I think the error is due to NA values in your data file. If I extend
> >your example and run it, I get no errors:
> >
> >MyData<-read.table(text="103001930 103001580 103001530
> >1998-10-01 00:00:00 0.6 0 0
> >1998-10-01 01:00:00 0.2 0.2 0.2
> >1998-10-01 02:00:00 0.6 0.2 0.4
> >1998-10-01 03:00:00 0 0 0.6
> >1998-10-01 04:00:00 0 0 0
> >1998-10-01 05:00:00 0 0 0
> >1998-10-01 06:00:00 0 0 0
> >1998-10-01 07:00:00 0.2 0 0
> >1998-10-01 08:00:00 0.6 0 0
> >1998-10-01 09:00:00 0.2 0.2 0.2
> >1998-10-01 10:00:00 0.6 0.2 0.4
> >1998-10-01 11:00:00 0 0 0.6
> >1998-10-01 12:00:00 0 0 0
> >1998-10-01 13:00:00 0 0 0
> >1998-10-01 14:00:00 0 0 0
> >1998-10-01 15:00:00 0.2 0 0
> >1998-10-01 16:00:00 0.6 0 0
> >1998-10-01 17:00:00 0.2 0.2 0.2
> >1998-10-01 18:00:00 0.6 0.2 0.4
> >1998-10-01 19:00:00 0 0 0.6
> >1998-10-01 20:00:00 0 0 0
> >1998-10-01 21:00:00 0 0 0
> >1998-10-01 22:00:00 0 0 0
> >1998-10-01 23:00:00 0.2 0 0
> >1998-10-02 00:00:00 0.6 0 0
> >1998-10-02 01:00:00 0.2 0.2 0.2
> >1998-10-02 02:00:00 0.6 0.2 0.4
> >1998-10-02 03:00:00 0 0 0.6
> >1998-10-02 04:00:00 0 0 0
> >1998-10-02 05:00:00 0 0 0
> >1998-10-02 06:00:00 0 0 0
> >1998-10-02 07:00:00 0.2 0 0
> >1998-10-02 08:00:00 0.6 0 0
> >1998-10-02 09:00:00 0.2 0.2 0.2
> >1998-10-02 10:00:00 0.6 0.2 0.4
> >1998-10-02 11:00:00 0 0 0.6
> >1998-10-02 12:00:00 0 0 0
> >1998-10-02 13:00:00 0 0 0
> >1998-10-02 14:00:00 0 0 0
> >1998-10-02 15:00:00 0.2 0 0
> >1998-10-02 16:00:00 0.6 0 0
> >1998-10-02 17:00:00 0.2 0.2 0.2
> >1998-10-02 18:00:00 0.6 0.2 0.4
> >1998-10-02 19:00:00 0 0 0.6
> >1998-10-02 20:00:00 0 0 0
> >1998-10-02 21:00:00 0 0 0
> >1998-10-02 22:00:00 0 0 0
> >1998-10-02 23:00:00 0.2 0 0",
> >skip=1,stringsAsFactors=FALSE)
> >names(MyData)<-c("date","time","st1","st2","st3")
> >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > format="%Y-%m-%d %H:%M:%S")
> >MyData$datetime
> >st1_daily<-by(MyData$st1,MyData$date,mean)
> >st2_daily<-by(MyData$st2,MyData$date,mean)
> >st3_daily<-by(MyData$st3,MyData$date,mean)
> >st1_daily
> >st2_daily
> >st3_daily
> >
> >Try adding na.rm=TRUE to the "by" calls:
> >
> >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> >
> >Jim
> >
> >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >> Dear all,
> >>
> >> I have still problem with date.
> >> Could you please tel me how to use POSIXct.
> >> Indeed I have found this command:
> >> timeAverage, but I am not able to convert MyDate to properly date.
> >>
> >> Thank a lot
> >> I hope to no bother you, at least too much
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >wrote:
> >>>
> >>> Dear Jim, Dear all,
> >>>
> >>> thanks a lot.
> >>>
> >>> Unfortunately, I get the following error:
> >>>
> >>>
> >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> >925L,  :
> >>>   arguments must have same length
> >>>
> >>>
> >>> This is particularly strange. indeed, if I apply
> >>>
> >>>
> >>> mean(MyData$str1,na.rm=TRUE)
> >>>
> >>>
> >>> it works
> >>>
> >>>
> >>> Sorry, I have to learn a lot.
> >>> You are really boosting me
> >>>
> >>> Diego
> >>>
> >>>
> >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >>>>
> >>>> Hi Diego,
> >>>> One way you can get daily means is:
> >>>>
> >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> >>>>
> >>>> Jim
> >>>>
> >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> wrote:
> >>>> > Dear all,
> >>>> > I have found the error, my fault. Sorry.
> >>>> > There was an extra come in the headers line.
> >>>> > Thanks again.
> >>>> >
> >>>> > If I can I would like to ask you another questions about the
> >imported
> >>>> > data.
> >>>> > I would like to compute the daily average of the different date.
> >>>> > Basically I
> >>>> > have hourly data, I would like to ave the daily mean of them.
> >>>> >
> >>>> > Is there some special commands?
> >>>> >
> >>>> > Thanks a lot.
> >>>> >
> >>>> >
> >>>> > Diego
> >>>> >
> >>>> >
> >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> > wrote:
> >>>> >>
> >>>> >> Dear all,
> >>>> >> I move to csv file because originally the date where in csv
> >file.
> >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> >>>> >> special
> >>>> >> case of read.table, I prefer start to learn from the simplest
> >one.
> >>>> >> After that, I will try also the *.txt format.
> >>>> >>
> >>>> >> with read.csv, something strange happened:
> >>>> >>
> >>>> >> This us now the file:
> >>>> >>
> >>>> >> date,st1,st2,st3,
> >>>> >> 10/1/1998 0:00,0.6,0,0
> >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> >>>> >> 10/1/1998 3:00,0,0,0.6
> >>>> >> 10/1/1998 4:00,0,0,0
> >>>> >> 10/1/1998 5:00,0,0,0
> >>>> >> 10/1/1998 6:00,0,0,0
> >>>> >> 10/1/1998 7:00,0.2,0,0
> >>>> >> 10/1/1998 8:00,0.6,0.2,0
> >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> >>>> >> 10/1/1998 10:00,0,0.4,0.2
> >>>> >>
> >>>> >> When I apply:
> >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>>> >>
> >>>> >> this is the results:
> >>>> >>
> >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>>> >>
> >>>> >> I do not understand why.
> >>>> >> Something wrong with date?
> >>>> >>
> >>>> >> really really thanks,
> >>>> >> I appreciate a lot all your helps.
> >>>> >>
> >>>> >> Diedro
> >>>> >>
> >>>> >>
> >>>> >> Diego
> >>>> >>
> >>>> >>
> >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>
> >wrote:
> >>>> >>>
> >>>> >>> Or, without removing the first line
> >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>> >>>
> >>>> >>> Another alternative,
> >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>>> >>> since the dates appear to be in the default format.
> >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> >rather
> >>>> >>> than
> >>>> >>> POSIXlt class)
> >>>> >>>
> >>>> >>> -Don
> >>>> >>>
> >>>> >>> --
> >>>> >>> Don MacQueen
> >>>> >>> Lawrence Livermore National Laboratory
> >>>> >>> 7000 East Ave., L-627
> >>>> >>> Livermore, CA 94550
> >>>> >>> 925-423-1062
> >>>> >>> Lab cell 925-724-7509
> >>>> >>>
> >>>> >>>
> >>>> >>>
> >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>>> >>> <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of
> >drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> >>>> >>> wrote:
> >>>> >>>
> >>>> >>>     Hi Diego,
> >>>> >>>     You may have to do some conversion as you have three fields
> >in
> >>>> >>> the
> >>>> >>>     first line using the default space separator and five
> >fields in
> >>>> >>>     subsequent lines. If the first line doesn't contain any
> >important
> >>>> >>> data
> >>>> >>>     you can just delete it or replace it with a meaningful
> >header
> >>>> >>> line
> >>>> >>>     with five fields and save the file under another name.
> >>>> >>>
> >>>> >>>     It looks as thought you have date-time as two fields. If
> >so, you
> >>>> >>> can
> >>>> >>>     just read the first field if you only want the date:
> >>>> >>>
> >>>> >>>     # assume you have removed the first line
> >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>> >>>
> >>>> >>>     If you want the date/time:
> >>>> >>>
> >>>> >>>
> >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>>> >>> %H:%M:%S")
> >>>> >>>
> >>>> >>>     Jim
> >>>> >>>
> >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>>> >>> <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >>>> >>>     > Dear all,
> >>>> >>>     >
> >>>> >>>     > I am dealing with the reading of a *.txt file.
> >>>> >>>     > The txt file the following shape:
> >>>> >>>     >
> >>>> >>>     > 103001930 103001580 103001530
> >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>> >>>     >
> >>>> >>>     > If it is possible I have a coupe of questions, which will
> >sound
> >>>> >>> stupid but
> >>>> >>>     > they are important to me in order to understand ho R deal
> >with
> >>>> >>> file
> >>>> >>> or date.
> >>>> >>>     >
> >>>> >>>     > 1) Do I have to convert it to a *csv file?
> >>>> >>>     > 2) Can a deal with space and not ","
> >>>> >>>     > 3) How can I read date?
> >>>> >>>     >
> >>>> >>>     > thanks a lot to all of you,
> >>>> >>>     > Thanks
> >>>> >>>     >
> >>>> >>>     >
> >>>> >>>     > Diego
> >>>> >>>     >
> >>>> >>>     >         [[alternative HTML version deleted]]
> >>>> >>>     >
> >>>> >>>     > ______________________________________________
> >>>> >>>     > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more,
> >>>> >>> see
> >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     > PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     > and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>     ______________________________________________
> >>>> >>>     R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more, see
> >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>
> >>>> >>
> >>>> >
> >>>
> >>>
> >>
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/




	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Thu Aug  2 11:33:20 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Thu, 2 Aug 2018 09:33:20 +0000
Subject: [R] inconsistency in forecast package....
Message-ID: <SL2P216MB0091CE3772EA1B4B540B6F38C82C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                           I am using R to do my research for Day Trading in INDIA. I have a list of 206 stocks to work with.

I have extracted a parameter of a stock based on the OHLC data of the stock. It includes values both less than and greater than 1 ( It basically is a ratio). I am using forecast package to predict the value of the parameter for the next day.

However, the value of the parameter is greater than 1 for all stocks! Actually, according to statistics, half of the stocks should have value less than 1 and half greater than 1.

Is this because of  a one odd day or is there some techniques of properly handling the forecast package?

very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From Kevin@Fl@ment @ending from pmi@com  Thu Aug  2 10:45:25 2018
From: Kevin@Fl@ment @ending from pmi@com (Flament, Kevin)
Date: Thu, 2 Aug 2018 08:45:25 +0000
Subject: [R] Philip Morris International - Windows10 migration assessment
Message-ID: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>

Dear R Project team,

I am representing the System Toxicology department of Philip Morris International in the scope of a Windows 10 migration project.
This project is currently at the end of the assessment phase. We would require an answer to this email by the end of this week.

I would like to ask you some questions related to the following software we are using at PMI :

R for Windows 3.0.2
R for Windows 3.1.2

Are all of those software compatible with Windows 10 Enterprise (version 10.0.16299 build 16299)?
Are all of those software compatible with Windows 10 LTSC (version 14393.2399)?
Are those software compatible with a 32 and/or 64 bit version of Windows 10?
Are those application dependent on MS Office?
Have those applications any pre-requisites? Such as Java, .Net, Oracle.

If the software are not compatible, do you have a new version of this software compatible with the mentioned version of Windows 10?
What would be the cost of such migration (instrument replacement if necessary, licence cost, ...)?

If the software are not compatible and a new version is not yet available, could you give me an estimation for the future release availability?

Best Regards,

Kevin Flament

Data & Systems Specialist
PMI Science and Innovation
Quai Jeanrenaud 3
2000 Neuch?tel

	[[alternative HTML version deleted]]


From S@Elli@on @ending from LGCGroup@com  Thu Aug  2 13:26:44 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Thu, 2 Aug 2018 11:26:44 +0000
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
Message-ID: <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>

> On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
> wrote:
> > But I have the extra condition that if E is true, then F must be false, and
> > vice versa, 

Question: Does 'vice versa' mean 
a) "if E is False, F must be True"
or
b) "if F is True, E must be False"?
... which are not the same.

b) (and mutual exclusivity in general) does not rule out the condition "E False, F False", which would not be addressed by the 
pass/fail equivalent equivalent of F <- !E




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S@Elli@on @ending from LGCGroup@com  Thu Aug  2 13:32:42 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Thu, 2 Aug 2018 11:32:42 +0000
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
Message-ID: <cdf35fd4267b47dbb9b872684d2aa378@GBDCVPEXC04.corp.lgc-group.com>

Suggest you take a look at the R website at www.r-project.org; the most important answers are evident there.

If you 'require' more authoritative answers within a particular timescale, I suggest you engage an R consultant and pay for them. This is a voluntary list.


S Ellison
 

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Flament,
> Kevin
> Sent: 02 August 2018 09:45
> To: r-help at R-project.org
> Subject: [R] Philip Morris International - Windows10 migration assessment
> 
> Dear R Project team,
> 
> I am representing the System Toxicology department of Philip Morris
> International in the scope of a Windows 10 migration project.
> This project is currently at the end of the assessment phase. We would
> require an answer to this email by the end of this week.
> 
> I would like to ask you some questions related to the following software we
> are using at PMI :
> 
> R for Windows 3.0.2
> R for Windows 3.1.2
> 
> Are all of those software compatible with Windows 10 Enterprise (version
> 10.0.16299 build 16299)?
> Are all of those software compatible with Windows 10 LTSC (version
> 14393.2399)?
> Are those software compatible with a 32 and/or 64 bit version of Windows
> 10?
> Are those application dependent on MS Office?
> Have those applications any pre-requisites? Such as Java, .Net, Oracle.
> 
> If the software are not compatible, do you have a new version of this
> software compatible with the mentioned version of Windows 10?
> What would be the cost of such migration (instrument replacement if
> necessary, licence cost, ...)?
> 
> If the software are not compatible and a new version is not yet available,
> could you give me an estimation for the future release availability?
> 
> Best Regards,
> 
> Kevin Flament
> 
> Data & Systems Specialist
> PMI Science and Innovation
> Quai Jeanrenaud 3
> 2000 Neuch?tel
> 
> 	[[alternative HTML version deleted]]



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From chk@tr @ending from unife@it  Thu Aug  2 13:43:28 2018
From: chk@tr @ending from unife@it (Saptorshee Kanto Chakraborty)
Date: Thu, 2 Aug 2018 13:43:28 +0200
Subject: [R] CODE HELP
In-Reply-To: <CAGgJW75YCXaJXoResfpJcOu4EBFxBmfHXR=bAeoToQpbCwrxSw@mail.gmail.com>
References: <CAAr3ZhjhfE8ED+EwZeUOmM6gd8vcoKoZrWdswe-CVE3MXvF8oA@mail.gmail.com>
 <CAGgJW75YCXaJXoResfpJcOu4EBFxBmfHXR=bAeoToQpbCwrxSw@mail.gmail.com>
Message-ID: <CAAr3ZhiF1X-MDX48PeZBZe_0seZ=TYybr5kCHMV859PeWpV1fg@mail.gmail.com>

Hello,

Thank you for replying. I am sorry te codes were not attached, I did attach
them but I think it got blocked due to some filters. I am pasting the link
for the codes:
https://github.com/zhentaoshi/convex_prog_in_econometrics/tree/master/C-Lasso/PLS_static

The authors never replied I have contacted them twice, I think they are
very busy.

Any help will be useful.

On Thu, 2 Aug 2018 at 10:22, Eric Berger <ericjberger at gmail.com> wrote:

> Hi Saptorshee,
> Two comments:
> 1. no attachments made it through to the list. You probably need to
> include the code directly in your email, and send your email as plain text
> (otherwise information gets stripped)
> 2. for anyone interested in following up on Saptorshee's question, I
> searched for the paper "Two Examples ..." and found that it is available
> for download from https://arxiv.org/pdf/1806.10423.pdf. (It looks quite
> interesting with a lot of discussion regarding various optimization
> packages and their current status regarding availability from R.)
>
> Best,
> Eric
>
>
> On Thu, Aug 2, 2018 at 5:01 AM, Saptorshee Kanto Chakraborty <
> chkstr at unife.it> wrote:
>
>> Hello,
>>
>> I am interested to apply an econometric technique of  Latent Variable
>> framework on Environmental Kuznets Curve for 164 countries for a span of
>> 25
>> years.
>>
>> The methodology and the code are from Simulation exercise from an
>> unpublished paper "Two Examples of Convex-Programming-Based
>> High-Dimensional Econometric Estimators" in R. Is it somehow possible to
>> apply it to my data.
>>
>>
>> I am attaching the codes
>>
>> Thanking You
>>
>> --
>> Saptorshee Chakraborty
>>
>> Personal Website: http://saptorshee.weebly.com/
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

-- 
Saptorshee Chakraborty

Personal Website: http://saptorshee.weebly.com/

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Thu Aug  2 14:23:33 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Thu, 2 Aug 2018 12:23:33 +0000
Subject: [R] how to allign data
Message-ID: <41e5dda4b6a84bda9c0896c4bc6bcf3b@SRVEXCHCM1302.precheza.cz>

Dear all

Before I start to reinvent wheel I would like to ask you if you have some easy solution for aligning data

I have something like this
x<-1:100
set.seed(42)
y1<-c(runif(20)+1, 1.2*x[1:80]+runif(80))
y2<-c(runif(40)+1, 1.2*x[1:60]+runif(60))

plot(x,y1)
points(x,y2, col=2)

with y increase starting at various x.

I would like to allign data so that the increase starts at the same x point, something like

plot(x,y1)
points(x[-(1:20)]-20,y2[-(1:20)], col=2)

I consider using strucchange or segmented packages to find break(s) and "shift" x values according to this break. But maybe somebody already did similar task (aligning several vectors according to some common breakpoint) and could offer better or simpler solution.

Best regards.
Petr
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From bgunter@4567 @ending from gm@il@com  Thu Aug  2 16:54:54 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 2 Aug 2018 07:54:54 -0700
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
Message-ID: <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>

R is free and open source. Your queries are inappropriate for this list,
which is about help for programming in R.  Please go here and follow the
relevant links to answer your questions:

https://www.r-project.org/

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 2, 2018 at 1:45 AM, Flament, Kevin <Kevin.Flament at pmi.com>
wrote:

> Dear R Project team,
>
> I am representing the System Toxicology department of Philip Morris
> International in the scope of a Windows 10 migration project.
> This project is currently at the end of the assessment phase. We would
> require an answer to this email by the end of this week.
>
> I would like to ask you some questions related to the following software
> we are using at PMI :
>
> R for Windows 3.0.2
> R for Windows 3.1.2
>
> Are all of those software compatible with Windows 10 Enterprise (version
> 10.0.16299 build 16299)?
> Are all of those software compatible with Windows 10 LTSC (version
> 14393.2399)?
> Are those software compatible with a 32 and/or 64 bit version of Windows
> 10?
> Are those application dependent on MS Office?
> Have those applications any pre-requisites? Such as Java, .Net, Oracle.
>
> If the software are not compatible, do you have a new version of this
> software compatible with the mentioned version of Windows 10?
> What would be the cost of such migration (instrument replacement if
> necessary, licence cost, ...)?
>
> If the software are not compatible and a new version is not yet available,
> could you give me an estimation for the future release availability?
>
> Best Regards,
>
> Kevin Flament
>
> Data & Systems Specialist
> PMI Science and Innovation
> Quai Jeanrenaud 3
> 2000 Neuch?tel
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From rod@@t@fford @ending from gm@il@com  Thu Aug  2 17:41:36 2018
From: rod@@t@fford @ending from gm@il@com (R Stafford)
Date: Thu, 2 Aug 2018 11:41:36 -0400
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>

Thank you for pointing that out, I realize not only did I use the wrong
language but I did not describe the situation accurately.  I do need to
address the situation where both variables E and F actually pass, that is
the majority case, one or the other can fail, but there can never be a
situation where E and F both fail.  I do not know a specific term for that
situation, but you are correct that mutual exclusivity is wrong.   While I
can generate a list of all possible combinations with the expand.grid
function (which I am not committed to by the way), it would be very helpful
if I could exclude the combinations where E and F both fail.  I am not sure
where to go from here, but the solution does not have to be elegant or even
efficient because I do not need to scale higher than 6 variables.



On Thu, Aug 2, 2018 at 7:26 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
> > wrote:
> > > But I have the extra condition that if E is true, then F must be
> false, and
> > > vice versa,
>
> Question: Does 'vice versa' mean
> a) "if E is False, F must be True"
> or
> b) "if F is True, E must be False"?
> ... which are not the same.
>
> b) (and mutual exclusivity in general) does not rule out the condition "E
> False, F False", which would not be addressed by the
> pass/fail equivalent equivalent of F <- !E
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:13}}


From m@cqueen1 @ending from llnl@gov  Thu Aug  2 17:52:57 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 2 Aug 2018 15:52:57 +0000
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
 <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
Message-ID: <34DFD051-2E07-4D0D-9924-1E56FAEB471E@llnl.gov>

From what I can tell, the simplest way is to
   First generate all the combinations
   Then exclude those you don't want.

Here's an example, with only three variables (D, E, and F), that excludes those where E and F both fail

> tmp <- c('p','f')
> X <- expand.grid(D=tmp, E=tmp, F=tmp)
> X <- subset(X, !(E=='f' & F=='f'))
> X
  D E F
1 p p p
2 f p p
3 p f p
4 f f p
5 p p f
6 f p f


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/2/18, 8:41 AM, "R-help on behalf of R Stafford" <r-help-bounces at r-project.org on behalf of rod.stafford at gmail.com> wrote:

    Thank you for pointing that out, I realize not only did I use the wrong
    language but I did not describe the situation accurately.  I do need to
    address the situation where both variables E and F actually pass, that is
    the majority case, one or the other can fail, but there can never be a
    situation where E and F both fail.  I do not know a specific term for that
    situation, but you are correct that mutual exclusivity is wrong.   While I
    can generate a list of all possible combinations with the expand.grid
    function (which I am not committed to by the way), it would be very helpful
    if I could exclude the combinations where E and F both fail.  I am not sure
    where to go from here, but the solution does not have to be elegant or even
    efficient because I do not need to scale higher than 6 variables.
    
    
    
    On Thu, Aug 2, 2018 at 7:26 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
    
    > > On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
    > > wrote:
    > > > But I have the extra condition that if E is true, then F must be
    > false, and
    > > > vice versa,
    >
    > Question: Does 'vice versa' mean
    > a) "if E is False, F must be True"
    > or
    > b) "if F is True, E must be False"?
    > ... which are not the same.
    >
    > b) (and mutual exclusivity in general) does not rule out the condition "E
    > False, F False", which would not be addressed by the
    > pass/fail equivalent equivalent of F <- !E
    >
    >
    >
    >
    > *******************************************************************
    > This email and any attachments are confidential. Any u...{{dropped:13}}
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @@r@h@go@lee @ending from gm@il@com  Thu Aug  2 17:57:24 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Thu, 2 Aug 2018 11:57:24 -0400
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
 <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
Message-ID: <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>

Given that clarification, I'd just generate the full set and remove
the ones you aren't interested in, as in:


scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"), F =
c("pass", "fail"))


scenarios <- subset(scenarios, !(E == "fail" & F == "fail))

Sarah

On Thu, Aug 2, 2018 at 11:41 AM, R Stafford <rod.stafford at gmail.com> wrote:
> Thank you for pointing that out, I realize not only did I use the wrong
> language but I did not describe the situation accurately.  I do need to
> address the situation where both variables E and F actually pass, that is
> the majority case, one or the other can fail, but there can never be a
> situation where E and F both fail.  I do not know a specific term for that
> situation, but you are correct that mutual exclusivity is wrong.   While I
> can generate a list of all possible combinations with the expand.grid
> function (which I am not committed to by the way), it would be very helpful
> if I could exclude the combinations where E and F both fail.  I am not sure
> where to go from here, but the solution does not have to be elegant or even
> efficient because I do not need to scale higher than 6 variables.
>
>
>
> On Thu, Aug 2, 2018 at 7:26 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>
>> > On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
>> > wrote:
>> > > But I have the extra condition that if E is true, then F must be
>> false, and
>> > > vice versa,
>>
>> Question: Does 'vice versa' mean
>> a) "if E is False, F must be True"
>> or
>> b) "if F is True, E must be False"?
>> ... which are not the same.
>>
>> b) (and mutual exclusivity in general) does not rule out the condition "E
>> False, F False", which would not be addressed by the
>> pass/fail equivalent equivalent of F <- !E
>>
>>
>>


From bgunter@4567 @ending from gm@il@com  Thu Aug  2 19:11:03 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 2 Aug 2018 10:11:03 -0700
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
 <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
 <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>
Message-ID: <CAGxFJbQj5BaggSS9LysSb-a58ectvsuc=LJ_C3HRPLTJfdUqpA@mail.gmail.com>

Logic:

!(E == "fail" & F == "fail)   <==>

(E == "pass" | F == "pass")


-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 2, 2018 at 8:57 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Given that clarification, I'd just generate the full set and remove
> the ones you aren't interested in, as in:
>
>
> scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
> c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"), F =
> c("pass", "fail"))
>
>
> scenarios <- subset(scenarios, !(E == "fail" & F == "fail))
>
> Sarah
>
> On Thu, Aug 2, 2018 at 11:41 AM, R Stafford <rod.stafford at gmail.com>
> wrote:
> > Thank you for pointing that out, I realize not only did I use the wrong
> > language but I did not describe the situation accurately.  I do need to
> > address the situation where both variables E and F actually pass, that is
> > the majority case, one or the other can fail, but there can never be a
> > situation where E and F both fail.  I do not know a specific term for
> that
> > situation, but you are correct that mutual exclusivity is wrong.   While
> I
> > can generate a list of all possible combinations with the expand.grid
> > function (which I am not committed to by the way), it would be very
> helpful
> > if I could exclude the combinations where E and F both fail.  I am not
> sure
> > where to go from here, but the solution does not have to be elegant or
> even
> > efficient because I do not need to scale higher than 6 variables.
> >
> >
> >
> > On Thu, Aug 2, 2018 at 7:26 AM, S Ellison <S.Ellison at lgcgroup.com>
> wrote:
> >
> >> > On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
> >> > wrote:
> >> > > But I have the extra condition that if E is true, then F must be
> >> false, and
> >> > > vice versa,
> >>
> >> Question: Does 'vice versa' mean
> >> a) "if E is False, F must be True"
> >> or
> >> b) "if F is True, E must be False"?
> >> ... which are not the same.
> >>
> >> b) (and mutual exclusivity in general) does not rule out the condition
> "E
> >> False, F False", which would not be addressed by the
> >> pass/fail equivalent equivalent of F <- !E
> >>
> >>
> >>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From motyoc@k@ @ending from y@hoo@com  Thu Aug  2 21:00:08 2018
From: motyoc@k@ @ending from y@hoo@com (Andras Farkas)
Date: Thu, 2 Aug 2018 19:00:08 +0000 (UTC)
Subject: [R] kSamples ad.test question
References: <2131690356.1175565.1533236408682.ref@mail.yahoo.com>
Message-ID: <2131690356.1175565.1533236408682@mail.yahoo.com>

Dear All,

once we run the following code, the results of the test will give us the expected obvious, samples are?from the common distribution...


library(kSamples)

u1 <- sample(rnorm(500,10,1),20,replace = TRUE)
u2 <- sample(rnorm(500,10,1),20,replace = TRUE)
u3 <- sample(rnorm(500,10,1),20,replace = TRUE)
u4 <- sample(rnorm(500,10,1),20,replace = TRUE)
u5 <- sample(rnorm(500,10,1),20,replace = TRUE)

ad.test(u1, u2, u3,u4,u5, method = "exact", dist = FALSE, Nsim = 1000)

next, if I change "u5" to:

u5 <- sample(rnorm(500,20,1),20,replace = TRUE)

the results of the test again gives us what we expect, ie samples are not from the common distribution.... my question is: would you know of a way to be able to automatically select out or identify? "u5", the distribution that is "responsible"? for the results generated showing that the?samples are?not?from the common distribution??

much appreciate your help,


Andras?


From bgunter@4567 @ending from gm@il@com  Thu Aug  2 21:37:53 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 2 Aug 2018 12:37:53 -0700
Subject: [R] kSamples ad.test question
In-Reply-To: <2131690356.1175565.1533236408682@mail.yahoo.com>
References: <2131690356.1175565.1533236408682.ref@mail.yahoo.com>
 <2131690356.1175565.1533236408682@mail.yahoo.com>
Message-ID: <CAGxFJbS=XF2fJmGxLMqf5FPd9b+9Eaj4oHDCT4tYa5KFQkV9Zg@mail.gmail.com>

You may get a response here, but as this is primarily a statistical
question, not a question about R programming, so it is off topic here. I
would suggest that you post this on stats.stackexchange.com or other
statistics site instead. There is a large literature on this sort of thing .

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 2, 2018 at 12:00 PM, Andras Farkas via R-help <
r-help at r-project.org> wrote:

> Dear All,
>
> once we run the following code, the results of the test will give us the
> expected obvious, samples are from the common distribution...
>
>
> library(kSamples)
>
> u1 <- sample(rnorm(500,10,1),20,replace = TRUE)
> u2 <- sample(rnorm(500,10,1),20,replace = TRUE)
> u3 <- sample(rnorm(500,10,1),20,replace = TRUE)
> u4 <- sample(rnorm(500,10,1),20,replace = TRUE)
> u5 <- sample(rnorm(500,10,1),20,replace = TRUE)
>
> ad.test(u1, u2, u3,u4,u5, method = "exact", dist = FALSE, Nsim = 1000)
>
> next, if I change "u5" to:
>
> u5 <- sample(rnorm(500,20,1),20,replace = TRUE)
>
> the results of the test again gives us what we expect, ie samples are not
> from the common distribution.... my question is: would you know of a way to
> be able to automatically select out or identify  "u5", the distribution
> that is "responsible"  for the results generated showing that the samples
> are not from the common distribution?
>
> much appreciate your help,
>
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Fri Aug  3 00:32:18 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 3 Aug 2018 08:32:18 +1000
Subject: [R] how to allign data
In-Reply-To: <41e5dda4b6a84bda9c0896c4bc6bcf3b@SRVEXCHCM1302.precheza.cz>
References: <41e5dda4b6a84bda9c0896c4bc6bcf3b@SRVEXCHCM1302.precheza.cz>
Message-ID: <CA+8X3fV_joQ95iqfM7tGDEwQUX91XEAOoZfyxtx1nhAPYqg9Dw@mail.gmail.com>

Hi Petr,
I recently had to align the minima of deceleration events to form an
aggregate "braking profile" for different locations. It seems as
though you are looking for something like:

find_increase<-function(x,surround=10) {
 inc_index<-which.max(diff(x))
 indices<-(inc_index-surround):(inc_index+surround)
 nneg<-sum(indices < 1)
 # pad both ends with NA if needed
 newx<-x[1:max(indices)]
 if(nneg > 0) newx<-c(rep(NA,nneg),newx)
 return(newx)
}

Jim

On Thu, Aug 2, 2018 at 10:23 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> Before I start to reinvent wheel I would like to ask you if you have some easy solution for aligning data
>
> I have something like this
> x<-1:100
> set.seed(42)
> y1<-c(runif(20)+1, 1.2*x[1:80]+runif(80))
> y2<-c(runif(40)+1, 1.2*x[1:60]+runif(60))
>
> plot(x,y1)
> points(x,y2, col=2)
>
> with y increase starting at various x.
>
> I would like to allign data so that the increase starts at the same x point, something like
>
> plot(x,y1)
> points(x[-(1:20)]-20,y2[-(1:20)], col=2)
>
> I consider using strucchange or segmented packages to find break(s) and "shift" x values according to this break. But maybe somebody already did similar task (aligning several vectors according to some common breakpoint) and could offer better or simpler solution.
>
> Best regards.
> Petr
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cjgroening @ending from gm@il@com  Fri Aug  3 04:11:07 2018
From: cjgroening @ending from gm@il@com (cjg15)
Date: Thu, 2 Aug 2018 22:11:07 -0400
Subject: [R] Rendo and dataMultilevelIV
Message-ID: <CAFM=56cW2jwit3ehn3OQrspzEt7Z74dOaQwOGdHzYdjQQEiGxA@mail.gmail.com>

Hi - Does anyone know what the variables CID and SID are in the
dataMultilevelIV dataset?

The example from page 18-19 of
https://cran.r-project.org/web/packages/REndo/REndo.pdf has

formula1 <- y ~ X11 + X12 + X13 + X14 + X15 + X21 + X22 + X23 + X24 + X31 +
X32 + X33 + (1 + X11 | CID) + (1|SID)

what exactly are the (1 + X11|CID) and (1|SID) terms?

does (1|SID) mean random intercepts for SID, and SID is student ID?

Thanks in advance, Chris

	[[alternative HTML version deleted]]


From j@n@@nn@ert @ending from u@ntwerpen@be  Fri Aug  3 07:54:36 2018
From: j@n@@nn@ert @ending from u@ntwerpen@be (Annaert Jan)
Date: Fri, 3 Aug 2018 05:54:36 +0000
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
Message-ID: <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>

You can easily test linear restrictions using the function linearHypothesis() from the car package.
There are several ways to set up the null hypothesis, but a straightforward one here is:
 
> library(car)
> x <- rnorm(10)
> y <- x+rnorm(10)
> linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
Linear hypothesis test

Hypothesis:
(Intercept) = 0
x = 1

Model 1: restricted model
Model 2: y ~ x

  Res.Df     RSS Df Sum of Sq      F Pr(>F)
1     10 10.6218                           
2      8  9.0001  2    1.6217 0.7207 0.5155


Jan

From: R-help <r-help-bounces at r-project.org> on behalf of John <miaojpm at gmail.com>
Date: Thursday, 2 August 2018 at 10:44
To: r-help <r-help at r-project.org>
Subject: [R] F-test where the coefficients in the H_0 is nonzero

Hi,

?? I try to run the regression
?? y = beta_0 + beta_1 x
?? and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
?? I believe I can run the regression
?? (y-x) = beta_0 +beta_1? x
?? and do the regular F-test (using lm functio) where the hypothesized
coefficients are all zero.

?? Is there any function in R that deal with the case where the
coefficients are nonzero?

John

	[[alternative HTML version deleted]]

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From djnordlund @ending from gm@il@com  Fri Aug  3 08:20:52 2018
From: djnordlund @ending from gm@il@com (Daniel Nordlund)
Date: Thu, 2 Aug 2018 23:20:52 -0700
Subject: [R] Rendo and dataMultilevelIV
In-Reply-To: <CAFM=56cW2jwit3ehn3OQrspzEt7Z74dOaQwOGdHzYdjQQEiGxA@mail.gmail.com>
References: <CAFM=56cW2jwit3ehn3OQrspzEt7Z74dOaQwOGdHzYdjQQEiGxA@mail.gmail.com>
Message-ID: <4b5fb2c5-9f6d-9d85-70cf-f522db288aef@gmail.com>

On 8/2/2018 7:11 PM, cjg15 wrote:
> Hi - Does anyone know what the variables CID and SID are in the
> dataMultilevelIV dataset?
> 
> The example from page 18-19 of
> https://cran.r-project.org/web/packages/REndo/REndo.pdf has
> 
> formula1 <- y ~ X11 + X12 + X13 + X14 + X15 + X21 + X22 + X23 + X24 + X31 +
> X32 + X33 + (1 + X11 | CID) + (1|SID)
> 
> what exactly are the (1 + X11|CID) and (1|SID) terms?
> 
> does (1|SID) mean random intercepts for SID, and SID is student ID?
> 
> Thanks in advance, Chris
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Did you read pages 9-10 of the document you provided a link to above 
(which describes the dataMultilevelIV dataset)?


Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From R@iner @ending from krug@@de  Fri Aug  3 09:03:43 2018
From: R@iner @ending from krug@@de (Rainer Krug)
Date: Fri, 3 Aug 2018 09:03:43 +0200
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
 <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>
Message-ID: <C42F8302-FA61-4C1B-9C1A-33AC3708676E@krugs.de>

Let?s not alienate the business users!

I agree that this is not the right / best forum to ask these type of questions, but where is? I would suggest to at least point them to the right resources. and not say that there questions are inappropriate here.

Actually, if I as a private user would ask that question, I guess I would get an answer here.

So please - not alienate the business users.

Cheers and good luck with Windows,

Rainer




> On 2 Aug 2018, at 16:54, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> R is free and open source. Your queries are inappropriate for this list,
> which is about help for programming in R.  Please go here and follow the
> relevant links to answer your questions:
> 
> https://www.r-project.org/
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Thu, Aug 2, 2018 at 1:45 AM, Flament, Kevin <Kevin.Flament at pmi.com>
> wrote:
> 
>> Dear R Project team,
>> 
>> I am representing the System Toxicology department of Philip Morris
>> International in the scope of a Windows 10 migration project.
>> This project is currently at the end of the assessment phase. We would
>> require an answer to this email by the end of this week.
>> 
>> I would like to ask you some questions related to the following software
>> we are using at PMI :
>> 
>> R for Windows 3.0.2
>> R for Windows 3.1.2
>> 
>> Are all of those software compatible with Windows 10 Enterprise (version
>> 10.0.16299 build 16299)?
>> Are all of those software compatible with Windows 10 LTSC (version
>> 14393.2399)?
>> Are those software compatible with a 32 and/or 64 bit version of Windows
>> 10?
>> Are those application dependent on MS Office?
>> Have those applications any pre-requisites? Such as Java, .Net, Oracle.
>> 
>> If the software are not compatible, do you have a new version of this
>> software compatible with the mentioned version of Windows 10?
>> What would be the cost of such migration (instrument replacement if
>> necessary, licence cost, ...)?
>> 
>> If the software are not compatible and a new version is not yet available,
>> could you give me an estimation for the future release availability?
>> 
>> Best Regards,
>> 
>> Kevin Flament
>> 
>> Data & Systems Specialist
>> PMI Science and Innovation
>> Quai Jeanrenaud 3
>> 2000 Neuch?tel
>> 
>>        [[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180803/ab615859/attachment.sig>

From leeth0323 @ending from vm@-@olution@@com  Fri Aug  3 05:07:28 2018
From: leeth0323 @ending from vm@-@olution@@com (=?ks_c_5601-1987?B?wMzFwsjx?=)
Date: Fri, 3 Aug 2018 03:07:28 +0000
Subject: [R] Questions for Licensing
Message-ID: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>

To whom it may concern,

I am very new to GNU GPL License and I have no idea how using GPL licensed software can affect the software that my company has developed.

My company develops and distributes S/W to clients. Our product is a proprietary software under EULA license.
When we sell our products and sign contracts we do not open the source code of our products to our clients. Although we do provide documents for methods, property, fields with definition and sample codes.

Since our product is mainly used for simulation, scheduling and analyzation, we are considering to use R for creating data visualization.
We would also like to deliver our product including R as bundle to customers.
So basically, the product components would be looking like the one attached to this mail.

Red box : Overall package of our product to be delivered to our customers.
Blue box: Components of our company developed programs.
Blue color filled box : Our company?s main program and class library Dlls.
R link module : Functions defined to connect and communicate with R through R.Net
Interface : R.Net or something similar to play the same role. If needed, develop our own interface to call R libraries.
R scripts : R scripts to process result data from our engine, convert it using the R engine and finally display the visualized data through our product.
R Engine : R controls and DLLs

We are not planning to modify any part of the libraries of R.
Also the engine of our product will not be directly calling R controls but through R.Net as an interface to communicate with R.

Now the questions I would like to ask are the following :

1.   R is licensed under GPL2/GPL3 and R.Net is licensed under BDS. In case we sell the content of the blue box (shown above), do we need to provide the source code for our entire product because we are using GPL licensed S/W?

2.   One our components from our product will be referring to DLLs provided from R.Net such as R link module in this case. In this scenario, do we need to provide the source code for the R-link Module?


3.   Instead of using R.Net, in case we develop our own DLLs to directly communicate with R (without R modification), do we need to provide the source code for our entire product?


5.   Are we allowed to deliver our products as a package as in the Red box? (Sell our products including R)
A. If not, which of components are we allowed to sell as a package to our customers.
B.  If we sell our products including R installation, do we need to open our product?s source code?


Last but not least, we would like to know a way how we could use R and treat as an individual license so it does not violate our EULA license and for us not to open any part of source code of our products.
The end-users of our customers are developers and analysts. I?m pretty sure analysts would not request for open source but developers would.
We just want to avoid a situation in which our product accidentally falls under the GPL license because of our use of R and us therefore having to provide the source code for our product.

Thank you for your precious time reading this mail and any advices and information you provide will be a great help to me.

Best regards,
Tae Hee, Lee
Junior Engineer
Technical Supports
VMS-Solutions Co.,Ltd, South Korea


-------------- next part --------------
A non-text attachment was scrubbed...
Name: ProductComponentGroup.png
Type: image/png
Size: 72144 bytes
Desc: ProductComponentGroup.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180803/1ba0750c/attachment.png>

From pd@lgd @ending from gm@il@com  Fri Aug  3 09:54:07 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Fri, 3 Aug 2018 09:54:07 +0200
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
Message-ID: <EAD84A10-9C8C-4419-8831-701DAAE31B52@gmail.com>

It is difficult to answer such questions authoritatively, but

- we have, to my recollection, no reports of major incompatibility with Windows 10

- however, the version numbers of R increase with .1 per year, and we are currently at 3.5.1, so your versions are 4 and 5 years out of date. Most users are upgraded at least annually, so problems with older versions could go undetected

- there is no external cost of migrating to a newer version. R is free software. Rolling it out within an organization could require some manpower, as could sorting out changed behaviour of R and its add-on packages. It should be fairly easy to do a test install of 3.5.1 and run it by your user base to see whether there are issues. 

- R works cross-platform and has no specific dependency on MS Office products

- R can interact with Java, but Java is not generally a prerequisite. You may want to check whether your users use packages with Java dependencies

- Peter Dalgaard

> On 2 Aug 2018, at 10:45 , Flament, Kevin <Kevin.Flament at pmi.com> wrote:
> 
> Dear R Project team,
> 
> I am representing the System Toxicology department of Philip Morris International in the scope of a Windows 10 migration project.
> This project is currently at the end of the assessment phase. We would require an answer to this email by the end of this week.
> 
> I would like to ask you some questions related to the following software we are using at PMI :
> 
> R for Windows 3.0.2
> R for Windows 3.1.2
> 
> Are all of those software compatible with Windows 10 Enterprise (version 10.0.16299 build 16299)?
> Are all of those software compatible with Windows 10 LTSC (version 14393.2399)?
> Are those software compatible with a 32 and/or 64 bit version of Windows 10?
> Are those application dependent on MS Office?
> Have those applications any pre-requisites? Such as Java, .Net, Oracle.
> 
> If the software are not compatible, do you have a new version of this software compatible with the mentioned version of Windows 10?
> What would be the cost of such migration (instrument replacement if necessary, licence cost, ...)?
> 
> If the software are not compatible and a new version is not yet available, could you give me an estimation for the future release availability?
> 
> Best Regards,
> 
> Kevin Flament
> 
> Data & Systems Specialist
> PMI Science and Innovation
> Quai Jeanrenaud 3
> 2000 Neuch?tel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r@turner @ending from @uckl@nd@@c@nz  Fri Aug  3 10:25:07 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Fri, 3 Aug 2018 20:25:07 +1200
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <C42F8302-FA61-4C1B-9C1A-33AC3708676E@krugs.de>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
 <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>
 <C42F8302-FA61-4C1B-9C1A-33AC3708676E@krugs.de>
Message-ID: <4723b4d8-225c-ae3a-e429-ee5623c50188@auckland.ac.nz>

On 03/08/18 19:03, Rainer Krug wrote:
> Let?s not alienate the business users!
> 
> I agree that this is not the right / best forum to ask these type of questions, but where is? I would suggest to at least point them to the right resources. and not say that there questions are inappropriate here.
> 
> Actually, if I as a private user would ask that question, I guess I would get an answer here.
> 
> So please - not alienate the business users.
> 
> Cheers and good luck with Windows.

On the contrary, I would say that one has a moral obligation to alienate 
tobacco companies.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From S@Elli@on @ending from LGCGroup@com  Fri Aug  3 12:46:50 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Fri, 3 Aug 2018 10:46:50 +0000
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
 <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
 <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>
Message-ID: <60d0eee9c6a44804b79f77cd060cbcd5@GBDCVPEXC04.corp.lgc-group.com>

> Given that clarification, I'd just generate the full set and remove
> the ones you aren't interested in, as in:
I'd agree; that is probably the most efficient thing to do with only half a dozen binary variables and a single condition.

A way of going about it for a more complex case might be to generate a single dummy variable encoding the special case combinations in the expand.grid step, and then decode that. For example (using this case):

allowed.EF <- data.frame(E=c("pass", "pass", "fail"), F=c("pass", "fail", "pass" ))

AtoEF <- expand.grid(A=c("pass", "fail"),B=c("pass", "fail"), C=c("pass", "fail"), D=c("pass", "fail"), EF=1:3 )

AtoF <- cbind(AtoEF[1:4], allowed.EF[AtoEF$EF,])

#Which gives the same combinations as Sarah's complete/subset method, albeit in a different order and with silly row names.




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S@Elli@on @ending from LGCGroup@com  Fri Aug  3 13:04:10 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Fri, 3 Aug 2018 11:04:10 +0000
Subject: [R] Questions for Licensing
In-Reply-To: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>
References: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>
Message-ID: <0357062e62d24f07a72e2fce79fce4cb@GBDCVPEXC04.corp.lgc-group.com>

> I am very new to GNU GPL License and I have no idea how using GPL licensed
> software can affect the software that my company has developed.
Short answer: in that situation, consult a qualified legal expert under contract to give you advice.

Nothing less  will be of any use in defending your business.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From petr@pik@l @ending from prechez@@cz  Fri Aug  3 13:34:34 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Fri, 3 Aug 2018 11:34:34 +0000
Subject: [R] how to allign data
In-Reply-To: <CA+8X3fV_joQ95iqfM7tGDEwQUX91XEAOoZfyxtx1nhAPYqg9Dw@mail.gmail.com>
References: <41e5dda4b6a84bda9c0896c4bc6bcf3b@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fV_joQ95iqfM7tGDEwQUX91XEAOoZfyxtx1nhAPYqg9Dw@mail.gmail.com>
Message-ID: <eb934025d57d451c89cb3bfe7cc86c83@SRVEXCHCM1302.precheza.cz>

Hi Jim

Thanks for your function, however I either do not understand its purpose or I did not explained my aim correctly.

with segmented package I could find x value for break in slope
fit<-lm(y1~x)
segmented(fit, seg.Z=~x)
Estimated Break-Point(s):
psi1.x
 20.77
fit<-lm(y2~x)
segmented(fit, seg.Z=~x)
Estimated Break-Point(s):
psi1.x
 40.99

After that I need to allign both y1 and y2 to common x, for which I could use the difference in estimated beakpoints for each y, which is
> round(40.99-20.77)
[1] 20

and use this difference for aligning data

plot(x,y1)
points(x[-(1:(psi20)]-20,y2[-(1:20)], col=2)

But this seems to me rather complicated so I just asked if there is some shorter and less tedious option.

Actually I cannot decipher how your function could help me to plot y1 and y2 and starting to increase at the same point.

Cheers
Petr

> -----Original Message-----
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Friday, August 3, 2018 12:32 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] how to allign data
>
> Hi Petr,
> I recently had to align the minima of deceleration events to form an
> aggregate "braking profile" for different locations. It seems as
> though you are looking for something like:
>
> find_increase<-function(x,surround=10) {
>  inc_index<-which.max(diff(x))
>  indices<-(inc_index-surround):(inc_index+surround)
>  nneg<-sum(indices < 1)
>  # pad both ends with NA if needed
>  newx<-x[1:max(indices)]
>  if(nneg > 0) newx<-c(rep(NA,nneg),newx)
>  return(newx)
> }
>
> Jim
>
> On Thu, Aug 2, 2018 at 10:23 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > Dear all
> >
> > Before I start to reinvent wheel I would like to ask you if you have some easy
> solution for aligning data
> >
> > I have something like this
> > x<-1:100
> > set.seed(42)
> > y1<-c(runif(20)+1, 1.2*x[1:80]+runif(80))
> > y2<-c(runif(40)+1, 1.2*x[1:60]+runif(60))
> >
> > plot(x,y1)
> > points(x,y2, col=2)
> >
> > with y increase starting at various x.
> >
> > I would like to allign data so that the increase starts at the same x point,
> something like
> >
> > plot(x,y1)
> > points(x[-(1:20)]-20,y2[-(1:20)], col=2)
> >
> > I consider using strucchange or segmented packages to find break(s) and
> "shift" x values according to this break. But maybe somebody already did
> similar task (aligning several vectors according to some common breakpoint)
> and could offer better or simpler solution.
> >
> > Best regards.
> > Petr
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-
> ochrany-osobnich-udaju/ | Information about processing and protection of
> business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From m@rc_@chw@rtz @ending from me@com  Fri Aug  3 13:44:17 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Fri, 03 Aug 2018 07:44:17 -0400
Subject: [R] Questions for Licensing
In-Reply-To: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>
References: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>
Message-ID: <725F442C-F765-42D1-8134-D4CD8997B732@me.com>

Hi,

As was mentioned in another reply, you will not get formal legal advice here, as none of us are intellectual property (IP) lawyers, and there can even be country specific issues when it comes to such things, based upon local laws and legal precedents that may be relevant.

That being said, on an informal basis, you should at least review the GPL FAQ:

  https://www.gnu.org/licenses/gpl-faq.en.html

to begin to educate yourself on key issues, which really come down to whether or not, your proprietary application can be considered a "derivative work" and therefore be impacted by the so-called "viral" implications of the GPL.

Given the liability risks (legal and financial) that your company faces if you "get it wrong", you need to seek out local legal expertise, specifically with IP related issues, and get a formal legal opinion and guidance.

Regards,

Marc Schwartz


> On Aug 2, 2018, at 11:07 PM, ??? <leeth0323 at vms-solutions.com> wrote:
> 
> To whom it may concern,
> 
> I am very new to GNU GPL License and I have no idea how using GPL licensed software can affect the software that my company has developed.
> 
> My company develops and distributes S/W to clients. Our product is a proprietary software under EULA license.
> When we sell our products and sign contracts we do not open the source code of our products to our clients. Although we do provide documents for methods, property, fields with definition and sample codes.
> 
> Since our product is mainly used for simulation, scheduling and analyzation, we are considering to use R for creating data visualization.
> We would also like to deliver our product including R as bundle to customers.
> So basically, the product components would be looking like the one attached to this mail.
> 
> Red box : Overall package of our product to be delivered to our customers.
> Blue box: Components of our company developed programs.
> Blue color filled box : Our company?s main program and class library Dlls.
> R link module : Functions defined to connect and communicate with R through R.Net
> Interface : R.Net or something similar to play the same role. If needed, develop our own interface to call R libraries.
> R scripts : R scripts to process result data from our engine, convert it using the R engine and finally display the visualized data through our product.
> R Engine : R controls and DLLs
> 
> We are not planning to modify any part of the libraries of R.
> Also the engine of our product will not be directly calling R controls but through R.Net as an interface to communicate with R.
> 
> Now the questions I would like to ask are the following :
> 
> 1.   R is licensed under GPL2/GPL3 and R.Net is licensed under BDS. In case we sell the content of the blue box (shown above), do we need to provide the source code for our entire product because we are using GPL licensed S/W?
> 
> 2.   One our components from our product will be referring to DLLs provided from R.Net such as R link module in this case. In this scenario, do we need to provide the source code for the R-link Module?
> 
> 
> 3.   Instead of using R.Net, in case we develop our own DLLs to directly communicate with R (without R modification), do we need to provide the source code for our entire product?
> 
> 
> 5.   Are we allowed to deliver our products as a package as in the Red box? (Sell our products including R)
> A. If not, which of components are we allowed to sell as a package to our customers.
> B.  If we sell our products including R installation, do we need to open our product?s source code?
> 
> 
> Last but not least, we would like to know a way how we could use R and treat as an individual license so it does not violate our EULA license and for us not to open any part of source code of our products.
> The end-users of our customers are developers and analysts. I?m pretty sure analysts would not request for open source but developers would.
> We just want to avoid a situation in which our product accidentally falls under the GPL license because of our use of R and us therefore having to provide the source code for our product.
> 
> Thank you for your precious time reading this mail and any advices and information you provide will be a great help to me.
> 
> Best regards,
> Tae Hee, Lee
> Junior Engineer
> Technical Supports
> VMS-Solutions Co.,Ltd, South Korea


From ericjberger @ending from gm@il@com  Fri Aug  3 13:57:39 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Fri, 3 Aug 2018 14:57:39 +0300
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <4723b4d8-225c-ae3a-e429-ee5623c50188@auckland.ac.nz>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
 <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>
 <C42F8302-FA61-4C1B-9C1A-33AC3708676E@krugs.de>
 <4723b4d8-225c-ae3a-e429-ee5623c50188@auckland.ac.nz>
Message-ID: <CAGgJW75ZR+8NRF_V4mhxSb1sXMi0ozMJ3wDQS11AmjdpF+e7tA@mail.gmail.com>

Hi Kevin,
For what it's worth I use R on Windows 10 Pro with the 16299 build (and
also with a later build on a different Windows 10 Pro computer.)
I also use R on Linux machines (specifically Ubuntu).
I use 64 bit versions but both 32bit and 64bit version are available.
As Peter wrote previously, R itself has no dependency on MS Office products.
However there are thousands of R packages freely downloadable (e.g. from
CRAN but also from other sources.)
Some of these packages may have explicit dependencies on commercial
packages.
(e.g. Rmosek is a free package that makes it easy to access the commercial
optimization software mosek.)
Peter also wrote that the latest release of R is version 3.5.1 which makes
your referenced versions quite old.
As far as I know it is generally possible to install any version of R (even
multiple versions of R) on your computer.
For example, when R 3.5.0 was released recently some users experienced some
glitches (some of which have presumably been fixed in 3.5.1.)
Personally I am staying with R 3.4.2 for a while longer.

If PMI requires "commercial" support and has the budget for it, you might
consider contacting Rstudio.com which produces some of the major
software tools used by the R community - Rstudio and Shiny and additional R
packages. They provide both free and commercial versions of
RStudio and Shiny and should have a lot of experience dealing with
corporate customers. Also by supporting them PMI would be indirectly
supporting
the R community at large which greatly benefits from the work they do.

I hope that helps.

Regards,

Eric Berger



On Fri, Aug 3, 2018 at 11:25 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 03/08/18 19:03, Rainer Krug wrote:
>
>> Let?s not alienate the business users!
>>
>> I agree that this is not the right / best forum to ask these type of
>> questions, but where is? I would suggest to at least point them to the
>> right resources. and not say that there questions are inappropriate here.
>>
>> Actually, if I as a private user would ask that question, I guess I would
>> get an answer here.
>>
>> So please - not alienate the business users.
>>
>> Cheers and good luck with Windows.
>>
>
> On the contrary, I would say that one has a moral obligation to alienate
> tobacco companies.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cliveli@t@ @ending from googlem@il@com  Fri Aug  3 21:47:01 2018
From: cliveli@t@ @ending from googlem@il@com (Clive Nicholas)
Date: Fri, 3 Aug 2018 20:47:01 +0100
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
Message-ID: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>

On 03/08/18 19:03, Rainer Krug wrote:
> Let?s not alienate the business users!
>
> I agree that this is not the right / best forum to ask these type of
questions, but where is? I would suggest to at least point them to the
right resources. and not say that there questions are inappropriate here.
>
> Actually, if I as a private user would ask that question, I guess I would
get an answer here.
>
> So please - not alienate the business users.
>
> Cheers and good luck with Windows.

On the contrary, I would say that one has a moral obligation to alienate
tobacco companies.

cheers,

Rolf Turner

-- 

And I'm down with this moral sentiment 10,000%.

I frankly couldn't believe what I was reading whilst perusing the digest,
and from whom. This smug bloke thinks he can land his 14-ton todger onto
the list, demand answers by a fixed deadline, and all in the service of
doing his bit to help replace the 7 million tobacco users who die every
year - according to the World Health Organisation - with preferably new,
young customers for the likes of PMI to sell their cancer sticks.

Disgusting. *Absolutely* disgusting! What on Bod's Earth are we doing
helping these people? They should be nowhere near this list. Do you hear
that, Philip Morris Angel of Death? I sincerely hope you crash and burn.

-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

	[[alternative HTML version deleted]]


From interzone @ending from gm@il@com  Sat Aug  4 00:07:51 2018
From: interzone @ending from gm@il@com (Dylan Distasio)
Date: Fri, 3 Aug 2018 18:07:51 -0400
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
References: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
Message-ID: <CAJrqPH9k=vWV9=5ojTgdwkNHYfd3WwKNpsOz_WXLEeAt1n4u+g@mail.gmail.com>

Nice virtue signalling, feel better now?

On Fri, Aug 3, 2018, 3:47 PM Clive Nicholas via R-help <r-help at r-project.org>
wrote:

> On 03/08/18 19:03, Rainer Krug wrote:
> > Let?s not alienate the business users!
> >
> > I agree that this is not the right / best forum to ask these type of
> questions, but where is? I would suggest to at least point them to the
> right resources. and not say that there questions are inappropriate here.
> >
> > Actually, if I as a private user would ask that question, I guess I would
> get an answer here.
> >
> > So please - not alienate the business users.
> >
> > Cheers and good luck with Windows.
>
> On the contrary, I would say that one has a moral obligation to alienate
> tobacco companies.
>
> cheers,
>
> Rolf Turner
>
> --
>
> And I'm down with this moral sentiment 10,000%.
>
> I frankly couldn't believe what I was reading whilst perusing the digest,
> and from whom. This smug bloke thinks he can land his 14-ton todger onto
> the list, demand answers by a fixed deadline, and all in the service of
> doing his bit to help replace the 7 million tobacco users who die every
> year - according to the World Health Organisation - with preferably new,
> young customers for the likes of PMI to sell their cancer sticks.
>
> Disgusting. *Absolutely* disgusting! What on Bod's Earth are we doing
> helping these people? They should be nowhere near this list. Do you hear
> that, Philip Morris Angel of Death? I sincerely hope you crash and burn.
>
> --
> Clive Nicholas
>
> "My colleagues in the social sciences talk a great deal about methodology.
> I prefer to call it style." -- Freeman J. Dyson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Sat Aug  4 00:58:48 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 4 Aug 2018 10:58:48 +1200
Subject: [R] 
 [FORGED] Re: Philip Morris International - Windows10 migration
 assessment
In-Reply-To: <CAJrqPH9k=vWV9=5ojTgdwkNHYfd3WwKNpsOz_WXLEeAt1n4u+g@mail.gmail.com>
References: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
 <CAJrqPH9k=vWV9=5ojTgdwkNHYfd3WwKNpsOz_WXLEeAt1n4u+g@mail.gmail.com>
Message-ID: <3024e898-f009-24ba-7c6a-6c805116c3b4@auckland.ac.nz>


On 04/08/18 10:07, Dylan Distasio wrote:

> Nice virtue signalling, feel better now?

I was going to respond to this, but then I thought that it would be 
better to heed the ancient wisdom: "Do not feed the trolls."

cheers,

Rolf Turner

> 
> On Fri, Aug 3, 2018, 3:47 PM Clive Nicholas via R-help <r-help at r-project.org>
> wrote:
> 
>> On 03/08/18 19:03, Rainer Krug wrote:
>>> Let?s not alienate the business users!
>>>
>>> I agree that this is not the right / best forum to ask these type of
>> questions, but where is? I would suggest to at least point them to the
>> right resources. and not say that there questions are inappropriate here.
>>>
>>> Actually, if I as a private user would ask that question, I guess I would
>> get an answer here.
>>>
>>> So please - not alienate the business users.
>>>
>>> Cheers and good luck with Windows.
>>
>> On the contrary, I would say that one has a moral obligation to alienate
>> tobacco companies.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>>
>> And I'm down with this moral sentiment 10,000%.
>>
>> I frankly couldn't believe what I was reading whilst perusing the digest,
>> and from whom. This smug bloke thinks he can land his 14-ton todger onto
>> the list, demand answers by a fixed deadline, and all in the service of
>> doing his bit to help replace the 7 million tobacco users who die every
>> year - according to the World Health Organisation - with preferably new,
>> young customers for the likes of PMI to sell their cancer sticks.
>>
>> Disgusting. *Absolutely* disgusting! What on Bod's Earth are we doing
>> helping these people? They should be nowhere near this list. Do you hear
>> that, Philip Morris Angel of Death? I sincerely hope you crash and burn.
>>
>> --
>> Clive Nicholas
>>
>> "My colleagues in the social sciences talk a great deal about methodology.
>> I prefer to call it style." -- Freeman J. Dyson


From r@turner @ending from @uckl@nd@@c@nz  Sat Aug  4 07:52:37 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 4 Aug 2018 17:52:37 +1200
Subject: [R] A slightly unorthodox matrix product.
Message-ID: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>


Can anyone think of a sexy way of forming following "product"?

Given matrices A and B, both with m rows, form a 3 dimensional array C 
such that:

     C[i,j,k] = A[i,j]*B[i,k]

I *think* that the following does what I want.  (I keep confusing 
myself, so I'm not sure!)

library(abind)
xxx <- lapply(1:nrow(a),function(i,a,b){a[i,]%o%b[i,]},a=A,b=B)
do.call(abind,c(xxx,list(along=3)))

Is there a cleverer way?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From euthymio@@k@k@@viki@ @ending from gm@il@com  Fri Aug  3 23:29:46 2018
From: euthymio@@k@k@@viki@ @ending from gm@il@com (euthymios kasvikis)
Date: Sat, 4 Aug 2018 00:29:46 +0300
Subject: [R] Perform GEE regression in R with multiple dependent variables
Message-ID: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>

Im trying to perform generalized estimating equation (GEE) on the (sample)
dataset below with R and I would like some little guidance. First of all I
will describe my dataset. As you can see below it includes 5 variables.
Country_ID shows the country of the politician, Ideo_Ordinal his poltical
belief from 1 to 7 (far left to far right). Then we have measurements
regarding three characteristics. I would like to run an analysis based on
the country and the political beliefs of every politician (dependent
variables) in relation with the 3 characteristics. I have used the geepack
package using:

library(geepack)

        samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
sample$Ideo_Ordinal,
                                       corstr = "independence"))) %>%
          rownames_to_column() %>%
          mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
                 upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
                 df=1,
                 ExpBeta = exp(Estimate)) %>%       # Transformed estimate
          mutate(lWald=exp(lowerWald),              # Upper transformed
                 uWald=exp(upperWald))              # Lower transformed
        samplem

I would like to know if it is valid to add in this method the Country_ID
simultaneously with Ideo_Ordinal and how to do it.

Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
    3             1            3      0.250895132  0.155238716  0.128683755
    5             1            3     -0.117725000 -0.336256435 -0.203137879
    7             1            3      0.269509029 -0.260728261  0.086819555
    9             1            6      0.108873496  0.175528190  0.182884928
    14            1            3      0.173129951  0.054468468  0.155030794
    15            1            6     -0.312088872 -0.414358301 -0.212599946
    17            1            3     -0.297647658 -0.096523143 -0.228533352
    18            1            3     -0.020389157 -0.210180866 -0.046687695
    20            1            3     -0.523432382 -0.125114982 -0.431070629
    21            1            1      0.040304508  0.022743463  0.233657881
    22            1            3      0.253695988 -0.330825166  0.101122320
    23            1            3     -0.478673895 -0.421801231 -0.422894791
    27            1            6     -0.040856419 -0.566728704 -0.136069484
    28            1            3      0.240040249 -0.398404825  0.135603114
    29            1            6     -0.207631653 -0.005347621 -0.294935155
    30            1            3      0.458042533  0.462935386  0.586244831
    31            1            3     -0.259850232 -0.233074787 -0.092249465
    33            1            3      0.002164223 -0.637668706 -0.267158031
    34            1            6      0.050991955 -0.098030021 -0.043826848
    36            1            3     -0.338052871 -0.168894328 -0.230198200
    38            1            3      0.174382347  0.023807812  0.192963609
    41            2            3     -0.227322148 -0.010016330 -0.095576329
    42            2            3     -0.267514920  0.066108837 -0.218979873
    43            2            3      0.421277754  0.385223920  0.421274111
    44            2            3     -0.399592341 -0.498154998 -0.320402699
    45            2            1      0.162038344  0.328116118  0.104105963
    47            2            3     -0.080755709  0.003080287 -0.043568723
    48            2            3      0.059474124 -0.447305420  0.003988071
    49            2            3     -0.219773040 -0.312902659 -0.239057883
    51            2            3      0.438659431  0.364042111  0.393014172
    52            2            3     -0.088560903 -0.490889275 -0.006041054
    53            2            3     -0.122612591  0.074438944  0.103722836
    54            2            3     -0.450586055 -0.304253061 -0.132365179
    55            2            6     -0.710545197 -0.451329850 -0.764201786
    56            2            3      0.330718447  0.335460128  0.429173481
    57            2            3      0.442508023  0.297522144  0.407155726
    60            2            3      0.060797815 -0.096516876 -0.012802977
    61            2            3     -0.250757764 -0.113219864 -0.215345379
    62            2            1      0.153654345 -0.089615287  0.118626045
    65            2            3      0.042969508 -0.486999608 -0.080829636
    66            3            3      0.158337022  0.208229002  0.241607154
    67            3            3      0.220237408  0.397914524  0.262207709
    69            3            3      0.200558577  0.244419633  0.301732113
    71            3            3      0.690244689  0.772692418  0.625921098
    72            3            3      0.189810070  0.377774321  0.293988340
    73            3            3     -0.385724422 -0.262131032 -0.373159652
    74            3            3     -0.124095769 -0.109816334 -0.127157915
    75            3            1      0.173299879  0.453592671  0.325357383
    76            3            3     -0.598215129 -0.643286651 -0.423824759
    77            3            3     -0.420558406 -0.361763025 -0.465612116
    78            3            3     -0.176788569 -0.305506924 -0.203730879
    80            3            3     -0.114790731  0.262392918  0.061382073
    81            3            3     -0.274904173 -0.342603918 -0.302761994
    82            3            3     -0.146902101 -0.059558818 -0.120550957
    84            3            3      0.038303792 -0.139833875  0.170005914
    85            3            3     -0.220212221 -0.541399757 -0.555201764
    87            3            3      0.255300386  0.179484246  0.421428096
    88            3            6     -0.548823069 -0.405541620 -0.322935805

	[[alternative HTML version deleted]]


From bkok@@l @ending from gm@il@com  Fri Aug  3 23:46:32 2018
From: bkok@@l @ending from gm@il@com (=?UTF-8?B?QsO8bGVudCBLw7Zrc2Fs?=)
Date: Fri, 3 Aug 2018 23:46:32 +0200
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
References: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
Message-ID: <CAGze6DmKCcq-Dj6CX+KK65YgUaqoAEMg4ZNuh+xgtJMdarWP3Q@mail.gmail.com>

Well said Clive. Thanks.

Bulent

On Fri, Aug 3, 2018, 21:47 Clive Nicholas via R-help <r-help at r-project.org>
wrote:

> On 03/08/18 19:03, Rainer Krug wrote:
> > Let?s not alienate the business users!
> >
> > I agree that this is not the right / best forum to ask these type of
> questions, but where is? I would suggest to at least point them to the
> right resources. and not say that there questions are inappropriate here.
> >
> > Actually, if I as a private user would ask that question, I guess I would
> get an answer here.
> >
> > So please - not alienate the business users.
> >
> > Cheers and good luck with Windows.
>
> On the contrary, I would say that one has a moral obligation to alienate
> tobacco companies.
>
> cheers,
>
> Rolf Turner
>
> --
>
> And I'm down with this moral sentiment 10,000%.
>
> I frankly couldn't believe what I was reading whilst perusing the digest,
> and from whom. This smug bloke thinks he can land his 14-ton todger onto
> the list, demand answers by a fixed deadline, and all in the service of
> doing his bit to help replace the 7 million tobacco users who die every
> year - according to the World Health Organisation - with preferably new,
> young customers for the likes of PMI to sell their cancer sticks.
>
> Disgusting. *Absolutely* disgusting! What on Bod's Earth are we doing
> helping these people? They should be nowhere near this list. Do you hear
> that, Philip Morris Angel of Death? I sincerely hope you crash and burn.
>
> --
> Clive Nicholas
>
> "My colleagues in the social sciences talk a great deal about methodology.
> I prefer to call it style." -- Freeman J. Dyson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Sat Aug  4 19:01:02 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Sat, 4 Aug 2018 20:01:02 +0300
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
Message-ID: <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>

Hi Rolf,
A few edits because (i) nrow(a) should be nrow(A) and (ii) you have
calculated C[j,k,i] = A[i,j]*B[i,k], (iii) minor style change on lapply.

library(abind)
xxx <- lapply(1:nrow(A),function(i){A[i,]%o%B[i,]})
yyy <- do.call(abind,c(xxx,list(along=3)))
zzz <- aperm(yyy,c(3,1,2))

HTH,
Eric


On Sat, Aug 4, 2018 at 8:52 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> Can anyone think of a sexy way of forming following "product"?
>
> Given matrices A and B, both with m rows, form a 3 dimensional array C
> such that:
>
>     C[i,j,k] = A[i,j]*B[i,k]
>
> I *think* that the following does what I want.  (I keep confusing myself,
> so I'm not sure!)
>
> library(abind)
> xxx <- lapply(1:nrow(a),function(i,a,b){a[i,]%o%b[i,]},a=A,b=B)
> do.call(abind,c(xxx,list(along=3)))
>
> Is there a cleverer way?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ccberry @ending from uc@d@edu  Sat Aug  4 19:34:26 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Sat, 4 Aug 2018 17:34:26 +0000
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
Message-ID: <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>



> On Aug 4, 2018, at 10:01 AM, Eric Berger <ericjberger at gmail.com> wrote:
> 
> Hi Rolf,
> A few edits because (i) nrow(a) should be nrow(A) and (ii) you have
> calculated C[j,k,i] = A[i,j]*B[i,k], (iii) minor style change on lapply.
> 
> library(abind)
> xxx <- lapply(1:nrow(A),function(i){A[i,]%o%B[i,]})
> yyy <- do.call(abind,c(xxx,list(along=3)))

Or use the simplify="array" gambit in sapply:

yyy <- sapply(1:nrow(A), function(i) A[i,] %o% B[i,], simplify="array")

> zzz <- aperm(yyy,c(3,1,2))
> 

HTH, 

Chuck


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Aug  4 20:43:16 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 4 Aug 2018 11:43:16 -0700 (PDT)
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
Message-ID: <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>

Sometimes a good old for loop performs best, even if it doesn't look sexy:

########
A <- matrix( 1:12, nrow = 3 )
B <- matrix( 1:15, nrow = 3 )

library(abind)
# Eric
ans1 <- function( a, b ) {
   xxx <- lapply( seq.int( nrow( A ) )
                , function( i ) {
                     A[ i, ] %o% B[ i, ]
                  }
                )
   yyy <- do.call( abind, c( xxx, list( along = 3 ) ) )
   zzz <- aperm( yyy, c( 3, 1, 2 ) )
   zzz
}
# Charles
ans1b <- function( a, b ) {
   xxx <- lapply( seq.int( nrow( A ) )
                , function( i ) {
                     A[ i, ] %o% B[ i, ]
                  }
                )
   yyy <- sapply( seq.int( nrow( a ) )
                , function( i ) a[ i, ] %o% b[ i, ]
                , simplify = "array"
                )
   zzz <- aperm( yyy, c( 3, 1, 2 ) )
   zzz
}
# Jeff #1
ans2 <- function( a, b ) {
   zzz <- array( rep( NA, nrow( a ) * ncol( a ) * ncol( b ) )
               , dim = c( nrow( a ), ncol( a ), ncol( b ) )
               )
   jseq <- seq.int( ncol( a ) )
   kseq <- seq.int( ncol( b ) )
   for ( i in seq.int( nrow( a ) ) ) {
     zzz[ i, jseq, kseq ] <- outer( a[ i, ], b[ i, ] )
   }
   zzz
}
# Jeff #2
ans3 <- function( a, b ) {
   idxs <- expand.grid( i = seq.int( nrow( a ) )
                      , j = seq.int( ncol( a ) )
                      , k = seq.int( ncol( b ) )
                      )
   ij <- as.matrix( idxs[ , c( "i", "j" ) ] )
   ik <- as.matrix( idxs[ , c( "i", "k" ) ] )
   array( a[ ij ] * b[ ik ]
        , dim = c( nrow( a ), ncol( a ), ncol( b ) )
        )
}

library(microbenchmark)

microbenchmark( res1 <- ans1( A, B )
               , res1b <- ans1b( A, B )
               , res2 <- ans2( A, B )
               , res3 <- ans3( A, B )
               )
#> Unit: microseconds
#>                  expr     min       lq      mean   median       uq
#>    res1 <- ans1(A, B) 660.489 688.3460 4199.5385 742.5505 805.1860
#>  res1b <- ans1b(A, B) 224.436 236.2250  427.4806 246.3240 269.6425
#>    res2 <- ans2(A, B)  91.538  96.9075  287.9596 102.0335 110.8825
#>    res3 <- ans3(A, B) 508.642 528.9700  860.6295 563.5470 619.5285
#>        max neval
#>  344769.27   100
#>   17062.63   100
#>   18212.11   100
#>   23041.89   100
all( res1 == res2 )
#> [1] TRUE
all( res1 == res1b )
#> [1] TRUE
all( res1 == res3 )
#> [1] TRUE
res3
#> , , 1
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]    1    4    7   10
#> [2,]    4   10   16   22
#> [3,]    9   18   27   36
#>
#> , , 2
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]    4   16   28   40
#> [2,]   10   25   40   55
#> [3,]   18   36   54   72
#>
#> , , 3
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]    7   28   49   70
#> [2,]   16   40   64   88
#> [3,]   27   54   81  108
#>
#> , , 4
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]   10   40   70  100
#> [2,]   22   55   88  121
#> [3,]   36   72  108  144
#>
#> , , 5
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]   13   52   91  130
#> [2,]   28   70  112  154
#> [3,]   45   90  135  180

#' Created on 2018-08-04 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
########

On Sat, 4 Aug 2018, Berry, Charles wrote:

>
>
>> On Aug 4, 2018, at 10:01 AM, Eric Berger <ericjberger at gmail.com> wrote:
>>
>> Hi Rolf,
>> A few edits because (i) nrow(a) should be nrow(A) and (ii) you have
>> calculated C[j,k,i] = A[i,j]*B[i,k], (iii) minor style change on lapply.
>>
>> library(abind)
>> xxx <- lapply(1:nrow(A),function(i){A[i,]%o%B[i,]})
>> yyy <- do.call(abind,c(xxx,list(along=3)))
>
> Or use the simplify="array" gambit in sapply:
>
> yyy <- sapply(1:nrow(A), function(i) A[i,] %o% B[i,], simplify="array")
>
>> zzz <- aperm(yyy,c(3,1,2))
>>
>
> HTH,
>
> Chuck
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ccberry @ending from uc@d@edu  Sat Aug  4 21:31:31 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Sat, 4 Aug 2018 19:31:31 +0000
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
 <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
Message-ID: <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>



> On Aug 4, 2018, at 11:43 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Sometimes a good old for loop performs best, even if it doesn't look sexy:
> 
> 

Fair enough, but a vectorized solution beats them all (see below).

Also,

[SNIP]


> # Charles
> ans1b <- function( a, b )
> {

The lapply you put here was from Eric's solution:

>  xxx <- lapply( seq.int( nrow( A ) )
>               , function( i ) {
>                    A[ i, ] %o% B[ i, ]
>                 }


This is what I had in mind:

ans1b.corrected <- function( a, b ) {
  yyy <- sapply( seq.int( nrow( a ) )
                 , function( i ) a[ i, ] %o% b[ i, ]
                 , simplify = "array"
  )
  zzz <- aperm( yyy, c( 3, 1, 2 ) )
  zzz
}

On my system it is slower than a for loop but a lot faster than your benchmark showed with the superfluous code from Eric's solution.

For speed, a vectorized solution is faster than a for loop by a factor of 3 on my laptop:

ans0 <- function(A,B){
  nca <- ncol(A)
  ncb <- ncol(B)
  j.index <- rep(1:nca, times = ncb)
  k.index <- rep(1:nca, each = ncb)
  res <- array(A[, j.index] * B[, k.index], c(nrow(A), nca, ncb))
  res
  }


> microbenchmark(
+   res0 <- ans0(A, B),
+   res1 <- ans1(A, B),
+   res1b <- ans1b.corrected(A, B),
+   res2 <- ans2(A, B),
+   res3 <- ans3(A, B)
+ )
Unit: microseconds
                           expr     min       lq      mean   median       uq     max neval   cld
             res0 <- ans0(A, B)  13.281  18.4960  21.52723  19.9905  23.4750  61.556   100 a    
             res1 <- ans1(A, B) 353.121 369.8635 409.77788 381.5840 444.3290 701.256   100     e
 res1b <- ans1b.corrected(A, B)  82.816  89.4185 101.52321  95.4275 107.1700 217.357   100   c  
             res2 <- ans2(A, B)  49.674  54.4825  61.78278  58.7540  65.5265 172.625   100  b   
             res3 <- ans3(A, B) 317.772 342.4220 392.25065 360.4675 436.2125 602.346   100    d 
> 


FWIW, if there are dimnames on A and B, sapply( row names(A), ..., simplify="array") preserves them without further ado.

Chuck

From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Aug  4 21:59:15 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 4 Aug 2018 12:59:15 -0700 (PDT)
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
 <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
 <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>
Message-ID: <alpine.BSF.2.00.1808041249340.89457@pedal.dcn.davis.ca.us>

Sorry I missed your intent on the sapply.

Slick work on the vectorizing, but for the future reference it was 
slightly buggy:

#######
A <- matrix( 1:12, nrow = 3 )
B <- matrix( 1:15, nrow = 3 )

# for loop
ans2 <- function( a, b ) {
   zzz <- array( rep( NA, nrow( a ) * ncol( a ) * ncol( b ) )
               , dim = c( nrow( a ), ncol( a ), ncol( b ) )
               )
   jseq <- seq.int( ncol( a ) )
   kseq <- seq.int( ncol( b ) )
   for ( i in seq.int( nrow( a ) ) ) {
     zzz[ i, jseq, kseq ] <- outer( a[ i, ], b[ i, ] )
   }
   zzz
}

# fast but buggy
ans0 <- function( A, B ) {
   nca <- ncol( A )
   ncb <- ncol( B )
   j.index <- rep( seq.int( nca ), times = ncb)
   k.index <- rep( seq.int( nca ), each = ncb)
   res <- array( A[ , j.index ] * B[ , k.index ]
               , c( nrow( A ), nca, ncb )
               )
   res
   }

# bugfixed
ans0b <- function( A, B ) {
   nca <- ncol( A )
   ncb <- ncol( B )
   j.index <- rep( seq.int( nca ), times = ncb )
   k.index <- rep( seq.int( ncb ), each = nca )
   res <- array( A[ , j.index ] * B[ , k.index ]
               , c( nrow( A ), nca, ncb )
               )
   res
   }

library(microbenchmark)

microbenchmark( res2 <- ans2( A, B )
               , res0b <- ans0b( A, B )
               , res0 <- ans0( A, B )
               )
#> Unit: microseconds
#>                  expr    min      lq     mean  median      uq      max
#>    res2 <- ans2(A, B) 84.987 87.8185 270.2153 96.4315 99.4175 17531.77
#>  res0b <- ans0b(A, B) 17.940 19.2055 126.8974 20.8800 22.2865 10616.36
#>    res0 <- ans0(A, B) 18.041 19.1670 126.1183 20.5530 21.9545 10532.44
#>  neval
#>    100
#>    100
#>    100
all( res2 == res0 )
#> [1] FALSE
all( res2 == res0b )
#> [1] TRUE

#' Created on 2018-08-04 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
#######

On Sat, 4 Aug 2018, Berry, Charles wrote:

>
>
>> On Aug 4, 2018, at 11:43 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Sometimes a good old for loop performs best, even if it doesn't look sexy:
>>
>>
>
> Fair enough, but a vectorized solution beats them all (see below).
>
> Also,
>
> [SNIP]
>
>
>> # Charles
>> ans1b <- function( a, b )
>> {
>
> The lapply you put here was from Eric's solution:
>
>>  xxx <- lapply( seq.int( nrow( A ) )
>>               , function( i ) {
>>                    A[ i, ] %o% B[ i, ]
>>                 }
>
>
> This is what I had in mind:
>
> ans1b.corrected <- function( a, b ) {
>  yyy <- sapply( seq.int( nrow( a ) )
>                 , function( i ) a[ i, ] %o% b[ i, ]
>                 , simplify = "array"
>  )
>  zzz <- aperm( yyy, c( 3, 1, 2 ) )
>  zzz
> }
>
> On my system it is slower than a for loop but a lot faster than your benchmark showed with the superfluous code from Eric's solution.
>
> For speed, a vectorized solution is faster than a for loop by a factor of 3 on my laptop:
>
> ans0 <- function(A,B){
>  nca <- ncol(A)
>  ncb <- ncol(B)
>  j.index <- rep(1:nca, times = ncb)
>  k.index <- rep(1:nca, each = ncb)
>  res <- array(A[, j.index] * B[, k.index], c(nrow(A), nca, ncb))
>  res
>  }
>
>
>> microbenchmark(
> +   res0 <- ans0(A, B),
> +   res1 <- ans1(A, B),
> +   res1b <- ans1b.corrected(A, B),
> +   res2 <- ans2(A, B),
> +   res3 <- ans3(A, B)
> + )
> Unit: microseconds
>                           expr     min       lq      mean   median       uq     max neval   cld
>             res0 <- ans0(A, B)  13.281  18.4960  21.52723  19.9905  23.4750  61.556   100 a
>             res1 <- ans1(A, B) 353.121 369.8635 409.77788 381.5840 444.3290 701.256   100     e
> res1b <- ans1b.corrected(A, B)  82.816  89.4185 101.52321  95.4275 107.1700 217.357   100   c
>             res2 <- ans2(A, B)  49.674  54.4825  61.78278  58.7540  65.5265 172.625   100  b
>             res3 <- ans3(A, B) 317.772 342.4220 392.25065 360.4675 436.2125 602.346   100    d
>>
>
>
> FWIW, if there are dimnames on A and B, sapply( row names(A), ..., simplify="array") preserves them without further ado.
>
> Chuck
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ccberry @ending from uc@d@edu  Sat Aug  4 21:59:45 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Sat, 4 Aug 2018 19:59:45 +0000
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <alpine.BSF.2.00.1808041249340.89457@pedal.dcn.davis.ca.us>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
 <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
 <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>
 <alpine.BSF.2.00.1808041249340.89457@pedal.dcn.davis.ca.us>
Message-ID: <32F4EDE4-FE5D-4AF0-8FDF-8281A7F67401@ucsd.edu>



> On Aug 4, 2018, at 12:59 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
...

> Slick work on the vectorizing, but for the future reference it was slightly buggy:
> 

Thanks for catching that!

Chuck


From r@turner @ending from @uckl@nd@@c@nz  Sun Aug  5 01:21:17 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 5 Aug 2018 11:21:17 +1200
Subject: [R] [FORGED] Re:  A slightly unorthodox matrix product.
In-Reply-To: <32F4EDE4-FE5D-4AF0-8FDF-8281A7F67401@ucsd.edu>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
 <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
 <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>
 <alpine.BSF.2.00.1808041249340.89457@pedal.dcn.davis.ca.us>
 <32F4EDE4-FE5D-4AF0-8FDF-8281A7F67401@ucsd.edu>
Message-ID: <f95a5ac9-19a6-3159-e414-aa38a7b2bddc@auckland.ac.nz>



Thanks to Eric Berger, Jeff Newmiller and Chuck Berry for their help 
with this.  Thanks especially to Eric for catching the bugs in my 
proposed solution.  I can *never* keep the indexing straight in 
multidimensional arrays!  It's tough being a <expletive deleted>-wit!

I wouldn't have figured out the "ans0b" solution in a million years.

Thanks again.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @ending from @uckl@nd@@c@nz  Sun Aug  5 07:23:40 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 5 Aug 2018 17:23:40 +1200
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <CABoW5_Vusxxr=Fxtq7qcA-BwDB_70fm1s3NzvxRO_bgWkk66hg@mail.gmail.com>
References: <CABoW5_Vusxxr=Fxtq7qcA-BwDB_70fm1s3NzvxRO_bgWkk66hg@mail.gmail.com>
Message-ID: <3f5166d9-4ae6-99fd-aede-b2f5c3d2632c@auckland.ac.nz>

On 05/08/18 16:41, Thomas Jagger wrote:
>  > Date: Sat, 4 Aug 2018 17:52:37 +1200
>  >
>  > From: Rolf Turner <r.turner at auckland.ac.nz 
> <mailto:r.turner at auckland.ac.nz>>
>  > To: r-help <r-help at r-project.org <mailto:r-help at r-project.org>>
>  > Subject: [R] A slightly unorthodox matrix product.
>  > Message-ID: <e0073e07-31b3-20df-c20d-6c565c857554 at auckland.ac.nz 
> <mailto:e0073e07-31b3-20df-c20d-6c565c857554 at auckland.ac.nz>>
>  > Content-Type: text/plain; charset="utf-8"; Format="flowed"
>  >
>  >
>  > Can anyone think of a sexy way of forming following "product"?
>  >
>  > Given matrices A and B, both with m rows, form a 3 dimensional array C
>  > such that:
>  >
>  > ? ? ?C[i,j,k] = A[i,j]*B[i,k]
>  >
>  > I *think* that the following does what I want. ?(I keep confusing
>  > myself, so I'm not sure!)
>  >
>  > library(abind)
>  > xxx <- lapply(1:nrow(a),function(i,a,b){a[i,]%o%b[i,]},a=A,b=B)
>  > do.call(abind,c(xxx,list(along=3)))
>  >
>  > Is there a cleverer way?
>  >
>  > cheers,
>  >
>  > Rolf Turner
>  >
>  > --
>  > Technical Editor ANZJS
>  > Department of Statistics
>  > University of Auckland
>  > Phone: +64-9-373-7599 ext. 88276
> 
> Dear Rolf,
> Try the following:
> 
> B<-matrix(1:12,3,4)
> 
> C<-as.vector(A[,rep(seq(ncol(A)),ncol(B))])*as.vector(B[,rep(seq(ncol(B)),each=ncol(A))])
> dim(C) <- c(nrow(A),ncol(A),ncol(B))
> 
> #test it on column 2 should return true
> all(C[,,2]==A*B[,rep(2,ncol(A))])
> #on all columns (sapply returns 9 rows with 3 columns all values are TRUE)
> 
> all( sapply(seq(ncol(C)),function(i) (C[,,i]==A*B[,rep(i,ncol(A))]) ) )
> 
> Note that it creates the final array by taking advantage of the 
> column-major ordering in R.
> Initially, we create a vector by multiplying elementwise the 2 vectors 
> internally associated with each matrix,
> finally,? we generate our? 3D array by adding the dimensions attribute, 
> a vector of 3? elements.
> 
> This method should be fairly fast since we are using internal R matrix 
> addressing, and not multiple function calls required by lapply ().
> I hope this helps

Neat, and much better than anything I could have thought of.  However
microbenchmark() indicates that the Chuck Berry/Jeff Newmiller solution 
is about twice as fast.  Not that this speed difference is Any Big Deal, 
but.

Thanks for taking an interest in this obscure query of mine.

cheers,

Rolf
-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From thj@gger @ending from gm@il@com  Sun Aug  5 06:41:22 2018
From: thj@gger @ending from gm@il@com (Thomas Jagger)
Date: Sat, 4 Aug 2018 22:41:22 -0600
Subject: [R] A slightly unorthodox matrix product.
Message-ID: <CABoW5_Vusxxr=Fxtq7qcA-BwDB_70fm1s3NzvxRO_bgWkk66hg@mail.gmail.com>

> Date: Sat, 4 Aug 2018 17:52:37 +1200
>
> From: Rolf Turner <r.turner at auckland.ac.nz>
> To: r-help <r-help at r-project.org>
> Subject: [R] A slightly unorthodox matrix product.
> Message-ID: <e0073e07-31b3-20df-c20d-6c565c857554 at auckland.ac.nz>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
>
> Can anyone think of a sexy way of forming following "product"?
>
> Given matrices A and B, both with m rows, form a 3 dimensional array C
> such that:
>
>      C[i,j,k] = A[i,j]*B[i,k]
>
> I *think* that the following does what I want.  (I keep confusing
> myself, so I'm not sure!)
>
> library(abind)
> xxx <- lapply(1:nrow(a),function(i,a,b){a[i,]%o%b[i,]},a=A,b=B)
> do.call(abind,c(xxx,list(along=3)))
>
> Is there a cleverer way?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276

Dear Rolf,
Try the following:

B<-matrix(1:12,3,4)

C<-as.vector(A[,rep(seq(ncol(A)),ncol(B))])*as.vector(B[,rep(seq(ncol(B)),each=ncol(A))])
dim(C) <- c(nrow(A),ncol(A),ncol(B))

#test it on column 2 should return true
all(C[,,2]==A*B[,rep(2,ncol(A))])
#on all columns (sapply returns 9 rows with 3 columns all values are TRUE)

all( sapply(seq(ncol(C)),function(i) (C[,,i]==A*B[,rep(i,ncol(A))]) ) )

Note that it creates the final array by taking advantage of the
column-major ordering in R.
Initially, we create a vector by multiplying elementwise the 2 vectors
internally associated with each matrix,
finally,  we generate our  3D array by adding the dimensions attribute, a
vector of 3  elements.

This method should be fairly fast since we are using internal R matrix
addressing, and not multiple function calls required by lapply ().
I hope this helps
Thomas Jagger

	[[alternative HTML version deleted]]


From j@zh@o @ending from ye@h@net  Sun Aug  5 14:36:21 2018
From: j@zh@o @ending from ye@h@net (Jinsong Zhao)
Date: Sun, 5 Aug 2018 20:36:21 +0800 (CST)
Subject: [R] MASS::boxcox "object not found"
Message-ID: <6ed54e57.1067.1650a16a89d.Coremail.jszhao@yeah.net>

Hi there,

I wrote a function that wraps MASS::boxcox as:

bc <- function(vec) {
   lam <- boxcox(lm(vec ~ 1))
   lam <- lam$x[which.max(lam$y)]
   (vec^lam - 1)/lam
}

When I invoke it as:

> x <- runif(20)
> bc(x)
Error in eval(predvars, data, env) : object 'vec' not found

I have googled, and rewrote the above function as:

bc <- function(vec) {
   dat <<- data.frame(vec = vec)
   lam <- boxcox(lm(vec ~ 1, dat))
   lam <- lam$x[which.max(lam$y)]
   rm(dat, envir = .GlobalEnv)
   (vec^lam - 1)/lam
}

It works. But, I am wondering why MASS::boxcox have to wrap in such way that have to use the data in .GlobalEnv.

Best,
Jinsong
	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Sun Aug  5 15:04:12 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Sun, 5 Aug 2018 18:34:12 +0530
Subject: [R] Adding % sign to ticks in persp()
Message-ID: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>

Hi,

Is there any way to add styles to the tick marks in persp() function?

For eample I want to add '%' suffix to the z-axis tick marks.in below plot :

x <- seq(-10, 10, length= 30)
y <- x
f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
z <- outer(x, y, f)
z[is.na(z)] <- 1
op <- par(bg = "white")
persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
ticktype = "detailed")

	[[alternative HTML version deleted]]


From p@ul @ending from @t@t@@uckl@nd@@c@nz  Sun Aug  5 23:24:17 2018
From: p@ul @ending from @t@t@@uckl@nd@@c@nz (Paul Murrell)
Date: Mon, 6 Aug 2018 09:24:17 +1200
Subject: [R] [FORGED]  Adding % sign to ticks in persp()
In-Reply-To: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>
References: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>
Message-ID: <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>

Hi

Not in the persp() function itself, but the following code converts the 
persp() output to 'grid' output then modifies the labels to add 
percentage signs ...

x <- seq(-10, 10, length= 30)
y <- x
f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
z <- outer(x, y, f)
z[is.na(z)] <- 1
op <- par(bg = "white")
persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
       ticktype = "detailed")

library(gridGraphics)
grid.echo()
labelGrobs <- grid.grep("z-axis-labels", grep=TRUE, global=TRUE)
addPercent <- function(x) {
     lab <- grid.get(x)
     grid.edit(x, label=paste0(lab$label, "%"), redraw=FALSE)
}
lapply(labelGrobs, addPercent)
grid.refresh()

... is that what you meant?  The positioning of the labels relative to 
the tick marks is imperfect and could perhaps be improved by also 
editing the 'cex' for the labels, but hopefully this gets close enough 
to be useful.

Paul

On 06/08/18 01:04, Christofer Bogaso wrote:
> Hi,
> 
> Is there any way to add styles to the tick marks in persp() function?
> 
> For eample I want to add '%' suffix to the z-axis tick marks.in below plot :
> 
> x <- seq(-10, 10, length= 30)
> y <- x
> f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
> z <- outer(x, y, f)
> z[is.na(z)] <- 1
> op <- par(bg = "white")
> persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
> ticktype = "detailed")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From dulc@lm@ @ending from bigpond@com  Mon Aug  6 06:29:07 2018
From: dulc@lm@ @ending from bigpond@com (Duncan Mackay)
Date: Mon, 6 Aug 2018 14:29:07 +1000
Subject: [R] 
 Perform GEE regression in R with multiple dependent variables
In-Reply-To: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
References: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
Message-ID: <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>

Hi

Please read the geepack manual carefully.
GEE ordinal regression is not simple.
You need to format your data and do not use sample as a storage name. It is
the name of a function

dta is storage
dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal))
 
m0 <-
ordgee(Ideo_Ordinal ~ Machiavellianism+Psychopathy+Narcissism ,data = dta,
id = Country_ID,
       corstr = "independence")

You need to see if the model is appropriate first and whether the sandwich
errors are right before you go further

If this is your data you may not get credible results.
You need to read up on the requirements of GEEs and  ordinal GEEs in
particular
There are a number of packages with different data requirements and methods 
If you have repeated measurements   repolr; ?multgee (just from memory)
Small sample sizes are a problem there are a number of packages dealing with
this but you will have to see which is best for you
Many do not offer a method for ordinal or multinomial GEE.
One further question to ask  population specific or subject specific  ie to
GEE or not to GEE


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of euthymios
kasvikis
Sent: Saturday, 4 August 2018 07:30
To: r-help at r-project.org
Subject: [R] Perform GEE regression in R with multiple dependent variables

Im trying to perform generalized estimating equation (GEE) on the (sample)
dataset below with R and I would like some little guidance. First of all I
will describe my dataset. As you can see below it includes 5 variables.
Country_ID shows the country of the politician, Ideo_Ordinal his poltical
belief from 1 to 7 (far left to far right). Then we have measurements
regarding three characteristics. I would like to run an analysis based on
the country and the political beliefs of every politician (dependent
variables) in relation with the 3 characteristics. I have used the geepack
package using:

library(geepack)

        samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
sample$Ideo_Ordinal,
                                       corstr = "independence"))) %>%
          rownames_to_column() %>%
          mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
                 upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
                 df=1,
                 ExpBeta = exp(Estimate)) %>%       # Transformed estimate
          mutate(lWald=exp(lowerWald),              # Upper transformed
                 uWald=exp(upperWald))              # Lower transformed
        samplem

I would like to know if it is valid to add in this method the Country_ID
simultaneously with Ideo_Ordinal and how to do it.

Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
    3             1            3      0.250895132  0.155238716  0.128683755
    5             1            3     -0.117725000 -0.336256435 -0.203137879
    7             1            3      0.269509029 -0.260728261  0.086819555
    9             1            6      0.108873496  0.175528190  0.182884928
    14            1            3      0.173129951  0.054468468  0.155030794
    15            1            6     -0.312088872 -0.414358301 -0.212599946
    17            1            3     -0.297647658 -0.096523143 -0.228533352
    18            1            3     -0.020389157 -0.210180866 -0.046687695
    20            1            3     -0.523432382 -0.125114982 -0.431070629
    21            1            1      0.040304508  0.022743463  0.233657881
    22            1            3      0.253695988 -0.330825166  0.101122320
    23            1            3     -0.478673895 -0.421801231 -0.422894791
    27            1            6     -0.040856419 -0.566728704 -0.136069484
    28            1            3      0.240040249 -0.398404825  0.135603114
    29            1            6     -0.207631653 -0.005347621 -0.294935155
    30            1            3      0.458042533  0.462935386  0.586244831
    31            1            3     -0.259850232 -0.233074787 -0.092249465
    33            1            3      0.002164223 -0.637668706 -0.267158031
    34            1            6      0.050991955 -0.098030021 -0.043826848
    36            1            3     -0.338052871 -0.168894328 -0.230198200
    38            1            3      0.174382347  0.023807812  0.192963609
    41            2            3     -0.227322148 -0.010016330 -0.095576329
    42            2            3     -0.267514920  0.066108837 -0.218979873
    43            2            3      0.421277754  0.385223920  0.421274111
    44            2            3     -0.399592341 -0.498154998 -0.320402699
    45            2            1      0.162038344  0.328116118  0.104105963
    47            2            3     -0.080755709  0.003080287 -0.043568723
    48            2            3      0.059474124 -0.447305420  0.003988071
    49            2            3     -0.219773040 -0.312902659 -0.239057883
    51            2            3      0.438659431  0.364042111  0.393014172
    52            2            3     -0.088560903 -0.490889275 -0.006041054
    53            2            3     -0.122612591  0.074438944  0.103722836
    54            2            3     -0.450586055 -0.304253061 -0.132365179
    55            2            6     -0.710545197 -0.451329850 -0.764201786
    56            2            3      0.330718447  0.335460128  0.429173481
    57            2            3      0.442508023  0.297522144  0.407155726
    60            2            3      0.060797815 -0.096516876 -0.012802977
    61            2            3     -0.250757764 -0.113219864 -0.215345379
    62            2            1      0.153654345 -0.089615287  0.118626045
    65            2            3      0.042969508 -0.486999608 -0.080829636
    66            3            3      0.158337022  0.208229002  0.241607154
    67            3            3      0.220237408  0.397914524  0.262207709
    69            3            3      0.200558577  0.244419633  0.301732113
    71            3            3      0.690244689  0.772692418  0.625921098
    72            3            3      0.189810070  0.377774321  0.293988340
    73            3            3     -0.385724422 -0.262131032 -0.373159652
    74            3            3     -0.124095769 -0.109816334 -0.127157915
    75            3            1      0.173299879  0.453592671  0.325357383
    76            3            3     -0.598215129 -0.643286651 -0.423824759
    77            3            3     -0.420558406 -0.361763025 -0.465612116
    78            3            3     -0.176788569 -0.305506924 -0.203730879
    80            3            3     -0.114790731  0.262392918  0.061382073
    81            3            3     -0.274904173 -0.342603918 -0.302761994
    82            3            3     -0.146902101 -0.059558818 -0.120550957
    84            3            3      0.038303792 -0.139833875  0.170005914
    85            3            3     -0.220212221 -0.541399757 -0.555201764
    87            3            3      0.255300386  0.179484246  0.421428096
    88            3            6     -0.548823069 -0.405541620 -0.322935805

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bog@@o@chri@tofer @ending from gm@il@com  Mon Aug  6 07:33:59 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 6 Aug 2018 11:03:59 +0530
Subject: [R] [FORGED]  Adding % sign to ticks in persp()
In-Reply-To: <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>
References: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>
 <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>
Message-ID: <CA+dpOJkjLvr1G5SjGWsWe4-TZWDoOD9qsjUyUPznMQW==wBDrQ@mail.gmail.com>

Awesome, thanks!

On Mon, Aug 6, 2018 at 2:54 AM Paul Murrell <paul at stat.auckland.ac.nz>
wrote:

> Hi
>
> Not in the persp() function itself, but the following code converts the
> persp() output to 'grid' output then modifies the labels to add
> percentage signs ...
>
> x <- seq(-10, 10, length= 30)
> y <- x
> f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
> z <- outer(x, y, f)
> z[is.na(z)] <- 1
> op <- par(bg = "white")
> persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
>        ticktype = "detailed")
>
> library(gridGraphics)
> grid.echo()
> labelGrobs <- grid.grep("z-axis-labels", grep=TRUE, global=TRUE)
> addPercent <- function(x) {
>      lab <- grid.get(x)
>      grid.edit(x, label=paste0(lab$label, "%"), redraw=FALSE)
> }
> lapply(labelGrobs, addPercent)
> grid.refresh()
>
> ... is that what you meant?  The positioning of the labels relative to
> the tick marks is imperfect and could perhaps be improved by also
> editing the 'cex' for the labels, but hopefully this gets close enough
> to be useful.
>
> Paul
>
> On 06/08/18 01:04, Christofer Bogaso wrote:
> > Hi,
> >
> > Is there any way to add styles to the tick marks in persp() function?
> >
> > For eample I want to add '%' suffix to the z-axis tick marks.in below
> plot :
> >
> > x <- seq(-10, 10, length= 30)
> > y <- x
> > f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
> > z <- outer(x, y, f)
> > z[is.na(z)] <- 1
> > op <- par(bg = "white")
> > persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
> > ticktype = "detailed")
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>

	[[alternative HTML version deleted]]


From m@ij@@@irkj@rvi @ending from gm@il@com  Mon Aug  6 11:02:23 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Mon, 6 Aug 2018 12:02:23 +0300
Subject: [R] loop over matrix: subscript out of bounds
Message-ID: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>

I have a basic for loop with a simple matrix. The code is doing what it is
supposed to do, but I'm still wondering the error "subscript out of
bounds". What would be a smoother way to code such a basic for loop?

myMatrix <- matrix(0,5,12)
for(i in 1:nrow(myMatrix)) {
  for(i in 1:ncol(myMatrix)) {
    myMatrix[i,i] = -1
    myMatrix[i,i+1] = 1
}}
print(myMatrix)

Thanks in advance!

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Mon Aug  6 11:24:14 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 6 Aug 2018 12:24:14 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
Message-ID: <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>

Both loops are on 'i', which is a bad idea. :-)
Also myMatrix[i,i+1] will be out-of-bounds if i = ncol(myMatrix)


On Mon, Aug 6, 2018 at 12:02 PM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
wrote:

> I have a basic for loop with a simple matrix. The code is doing what it is
> supposed to do, but I'm still wondering the error "subscript out of
> bounds". What would be a smoother way to code such a basic for loop?
>
> myMatrix <- matrix(0,5,12)
> for(i in 1:nrow(myMatrix)) {
>   for(i in 1:ncol(myMatrix)) {
>     myMatrix[i,i] = -1
>     myMatrix[i,i+1] = 1
> }}
> print(myMatrix)
>
> Thanks in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e@ @ending from enrico@chum@nn@net  Mon Aug  6 13:23:48 2018
From: e@ @ending from enrico@chum@nn@net (Enrico Schumann)
Date: Mon, 06 Aug 2018 13:23:48 +0200
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
Message-ID: <20180806132348.Horde.Lrxdz_1YNo5hSjZmHWsQWi-@webmail.your-server.de>


Quoting Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>:

> I have a basic for loop with a simple matrix. The code is doing what it is
> supposed to do, but I'm still wondering the error "subscript out of
> bounds". What would be a smoother way to code such a basic for loop?
>
> myMatrix <- matrix(0,5,12)
> for(i in 1:nrow(myMatrix)) {
>   for(i in 1:ncol(myMatrix)) {
>     myMatrix[i,i] = -1
>     myMatrix[i,i+1] = 1
> }}
> print(myMatrix)
>
> Thanks in advance!
>

Perhaps you do not need loops at all?

     myMatrix <- matrix(0, 5, 12)
     diag(myMatrix) <- -1
     diag(myMatrix[, -1]) <- 1

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ruipb@rr@d@@ @ending from @@po@pt  Mon Aug  6 12:58:44 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Mon, 6 Aug 2018 11:58:44 +0100
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
Message-ID: <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>

Hello,

Eric is right but...

You have two assignments. The second sets a value that will be 
overwritten is the next iteration by myMatrix[i,i] = -1 when 'i' becomes 
the next value.

If you fix the second index and use 'j', you might as well do

myMatrix[] = -1
myMatrix[, ncol(myMatrix)] = 1

Hope this helps,

Rui Barradas

?s 10:24 de 06/08/2018, Eric Berger escreveu:
> Both loops are on 'i', which is a bad idea. :-)
> Also myMatrix[i,i+1] will be out-of-bounds if i = ncol(myMatrix)
> 
> 
> On Mon, Aug 6, 2018 at 12:02 PM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> wrote:
> 
>> I have a basic for loop with a simple matrix. The code is doing what it is
>> supposed to do, but I'm still wondering the error "subscript out of
>> bounds". What would be a smoother way to code such a basic for loop?
>>
>> myMatrix <- matrix(0,5,12)
>> for(i in 1:nrow(myMatrix)) {
>>    for(i in 1:ncol(myMatrix)) {
>>      myMatrix[i,i] = -1
>>      myMatrix[i,i+1] = 1
>> }}
>> print(myMatrix)
>>
>> Thanks in advance!
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From euthymio@@k@k@@viki@ @ending from gm@il@com  Mon Aug  6 17:00:30 2018
From: euthymio@@k@k@@viki@ @ending from gm@il@com (euthymios kasvikis)
Date: Mon, 6 Aug 2018 18:00:30 +0300
Subject: [R] 
 Perform GEE regression in R with multiple dependent variables
In-Reply-To: <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>
References: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
 <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>
Message-ID: <CABNxSU2d0hwv+vN8YuecS3TPvhA--_hF+R_bv+MGmBYGKSYp6g@mail.gmail.com>

First of all thanks for your advice. So suppose that I would like to use
the multgee package. The model would be like:
library(multgee)
fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism,
data=RightWomen,
                    id= ordered(factor(Country_ID)))
summary(fitord)

???? ???, 6 ??? 2018 ???? 7:29 ?.?., ?/? Duncan Mackay <dulcalma at bigpond.com>
??????:

> Hi
>
> Please read the geepack manual carefully.
> GEE ordinal regression is not simple.
> You need to format your data and do not use sample as a storage name. It is
> the name of a function
>
> dta is storage
> dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal))
>
> m0 <-
> ordgee(Ideo_Ordinal ~ Machiavellianism+Psychopathy+Narcissism ,data = dta,
> id = Country_ID,
>        corstr = "independence")
>
> You need to see if the model is appropriate first and whether the sandwich
> errors are right before you go further
>
> If this is your data you may not get credible results.
> You need to read up on the requirements of GEEs and  ordinal GEEs in
> particular
> There are a number of packages with different data requirements and
> methods
> If you have repeated measurements   repolr; ?multgee (just from memory)
> Small sample sizes are a problem there are a number of packages dealing
> with
> this but you will have to see which is best for you
> Many do not offer a method for ordinal or multinomial GEE.
> One further question to ask  population specific or subject specific  ie to
> GEE or not to GEE
>
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2350
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of euthymios
> kasvikis
> Sent: Saturday, 4 August 2018 07:30
> To: r-help at r-project.org
> Subject: [R] Perform GEE regression in R with multiple dependent variables
>
> Im trying to perform generalized estimating equation (GEE) on the (sample)
> dataset below with R and I would like some little guidance. First of all I
> will describe my dataset. As you can see below it includes 5 variables.
> Country_ID shows the country of the politician, Ideo_Ordinal his poltical
> belief from 1 to 7 (far left to far right). Then we have measurements
> regarding three characteristics. I would like to run an analysis based on
> the country and the political beliefs of every politician (dependent
> variables) in relation with the 3 characteristics. I have used the geepack
> package using:
>
> library(geepack)
>
>         samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
> ~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
> sample$Ideo_Ordinal,
>                                        corstr = "independence"))) %>%
>           rownames_to_column() %>%
>           mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
>                  upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
>                  df=1,
>                  ExpBeta = exp(Estimate)) %>%       # Transformed estimate
>           mutate(lWald=exp(lowerWald),              # Upper transformed
>                  uWald=exp(upperWald))              # Lower transformed
>         samplem
>
> I would like to know if it is valid to add in this method the Country_ID
> simultaneously with Ideo_Ordinal and how to do it.
>
> Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
>     3             1            3      0.250895132  0.155238716  0.128683755
>     5             1            3     -0.117725000 -0.336256435 -0.203137879
>     7             1            3      0.269509029 -0.260728261  0.086819555
>     9             1            6      0.108873496  0.175528190  0.182884928
>     14            1            3      0.173129951  0.054468468  0.155030794
>     15            1            6     -0.312088872 -0.414358301 -0.212599946
>     17            1            3     -0.297647658 -0.096523143 -0.228533352
>     18            1            3     -0.020389157 -0.210180866 -0.046687695
>     20            1            3     -0.523432382 -0.125114982 -0.431070629
>     21            1            1      0.040304508  0.022743463  0.233657881
>     22            1            3      0.253695988 -0.330825166  0.101122320
>     23            1            3     -0.478673895 -0.421801231 -0.422894791
>     27            1            6     -0.040856419 -0.566728704 -0.136069484
>     28            1            3      0.240040249 -0.398404825  0.135603114
>     29            1            6     -0.207631653 -0.005347621 -0.294935155
>     30            1            3      0.458042533  0.462935386  0.586244831
>     31            1            3     -0.259850232 -0.233074787 -0.092249465
>     33            1            3      0.002164223 -0.637668706 -0.267158031
>     34            1            6      0.050991955 -0.098030021 -0.043826848
>     36            1            3     -0.338052871 -0.168894328 -0.230198200
>     38            1            3      0.174382347  0.023807812  0.192963609
>     41            2            3     -0.227322148 -0.010016330 -0.095576329
>     42            2            3     -0.267514920  0.066108837 -0.218979873
>     43            2            3      0.421277754  0.385223920  0.421274111
>     44            2            3     -0.399592341 -0.498154998 -0.320402699
>     45            2            1      0.162038344  0.328116118  0.104105963
>     47            2            3     -0.080755709  0.003080287 -0.043568723
>     48            2            3      0.059474124 -0.447305420  0.003988071
>     49            2            3     -0.219773040 -0.312902659 -0.239057883
>     51            2            3      0.438659431  0.364042111  0.393014172
>     52            2            3     -0.088560903 -0.490889275 -0.006041054
>     53            2            3     -0.122612591  0.074438944  0.103722836
>     54            2            3     -0.450586055 -0.304253061 -0.132365179
>     55            2            6     -0.710545197 -0.451329850 -0.764201786
>     56            2            3      0.330718447  0.335460128  0.429173481
>     57            2            3      0.442508023  0.297522144  0.407155726
>     60            2            3      0.060797815 -0.096516876 -0.012802977
>     61            2            3     -0.250757764 -0.113219864 -0.215345379
>     62            2            1      0.153654345 -0.089615287  0.118626045
>     65            2            3      0.042969508 -0.486999608 -0.080829636
>     66            3            3      0.158337022  0.208229002  0.241607154
>     67            3            3      0.220237408  0.397914524  0.262207709
>     69            3            3      0.200558577  0.244419633  0.301732113
>     71            3            3      0.690244689  0.772692418  0.625921098
>     72            3            3      0.189810070  0.377774321  0.293988340
>     73            3            3     -0.385724422 -0.262131032 -0.373159652
>     74            3            3     -0.124095769 -0.109816334 -0.127157915
>     75            3            1      0.173299879  0.453592671  0.325357383
>     76            3            3     -0.598215129 -0.643286651 -0.423824759
>     77            3            3     -0.420558406 -0.361763025 -0.465612116
>     78            3            3     -0.176788569 -0.305506924 -0.203730879
>     80            3            3     -0.114790731  0.262392918  0.061382073
>     81            3            3     -0.274904173 -0.342603918 -0.302761994
>     82            3            3     -0.146902101 -0.059558818 -0.120550957
>     84            3            3      0.038303792 -0.139833875  0.170005914
>     85            3            3     -0.220212221 -0.541399757 -0.555201764
>     87            3            3      0.255300386  0.179484246  0.421428096
>     88            3            6     -0.548823069 -0.405541620 -0.322935805
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From S@Elli@on @ending from LGCGroup@com  Mon Aug  6 17:18:18 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Mon, 6 Aug 2018 15:18:18 +0000
Subject: [R] [FORGED]  Adding % sign to ticks in persp()
In-Reply-To: <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>
References: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>
 <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>
Message-ID: <3fe0f752751a4edb8bc1ec423268dde2@GBDCVPEXC08.corp.lgc-group.com>

Another possible approach, using the transformation returned by persp() to locate axes explicitly and using base graphics to place labels etc, is given at 
http://entrenchant.blogspot.com/2014/03/custom-tick-labels-in-r-perspective.html


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Murrell
> Sent: 05 August 2018 22:24
> To: Christofer Bogaso; r-help
> Subject: Re: [R] [FORGED] Adding % sign to ticks in persp()
> 
> Hi
> 
> Not in the persp() function itself, but the following code converts the
> persp() output to 'grid' output then modifies the labels to add
> percentage signs ...
> 


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From Bill@Poling @ending from zeli@@com  Mon Aug  6 17:31:44 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Mon, 6 Aug 2018 15:31:44 +0000
Subject: [R] help with read function in Azure Data Lake Remote environment
Message-ID: <CY1PR0201MB18346E3267AB8466D6CA0BD0EA200@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi,

Locally I am using windows:
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Locally on my laptop using RStudio I normally set my working directory and read in my csv files.

setwd("C:/WHP/Appeals")

getwd()#-----------------------------Check to verify

read.csv("WHP_EditAppealRev_Tmp V1.csv",nrows=1, head=FALSE)#N=61 columns

appdf1 <- fread("WHP_EditAppealRev_Tmp V1.csv",select=c(5,9,10,11,14,15,16,17,18,25,31,28,32,42,45,46,47,48,49,53,54,58,59,61),header=TRUE, stringsAsFactors=TRUE)

This all works fine locally.

Now I am working in RStudio in a Remote desk top AZURE Data Lake environment (DSVM) however the remote file path out there is does not appear to be that different.

Remotley I am using windows:
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows Server >= 2012 x64 (build 9200)

setwd("C:/Users/sysAdmin/Documents/WHP/NJDemo082018")
getwd()#-----------------------------Check to verify

The directory gets set but the csv does not get read for some reason?

read.csv("C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv",nrows=1, head=FALSE)#N= columns
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv': No such file or directory

demo1 <- fread("C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv",select=c(1,2,3),header=TRUE, stringsAsFactors=TRUE)
Error in fread("C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv",  :
  File 'C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv' does not exist; getwd()=='C:/Users/sysAdmin/Documents/WHP/NJDemo082018'.
Include correct full path, or one or more spaces to consider the input a system command.

I have tried moving the csv file further forward to the root C: but still no luck?

read.csv("C:/TestDemoV1.csv",nrows=1, head=FALSE)#N= columns
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'C:/TestDemoV1.csv': No such file or directory


Any suggestions would be appreciated, thank you.

WHP


Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Aug  6 19:26:17 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 6 Aug 2018 10:26:17 -0700 (PDT)
Subject: [R] MASS::boxcox "object not found"
In-Reply-To: <6ed54e57.1067.1650a16a89d.Coremail.jszhao@yeah.net>
References: <6ed54e57.1067.1650a16a89d.Coremail.jszhao@yeah.net>
Message-ID: <alpine.BSF.2.00.1808061011230.91548@pedal.dcn.davis.ca.us>

It is rarely a good idea to invoke lm without providing the inputs in a 
data frame through the data argument. In this case, just making that 
change is insufficient though... the boxcox.lm function calls the update 
function, which re-retreives the data in a new context. The workaround is 
to supply the data= argument to boxplot which will pass it on to the 
update function to keep the data visible in the updated lm model.  None of 
this seemed obvious to me from the boxplot help, but I think I would 
regard using the data= argument to boxplot as being about as essential as 
it is in lm, because the alternative is to assume that all the data are 
as-named in the global environment (x is different than vec).

#######
library(MASS)
bc <- function(vec) {
    dta <- data.frame( vec = vec ) # Rarely a good idea to call "lm"
                                   # without the data argument.
    model <- lm( vec ~ 1, data = dta )
    lam <- boxcox( model, data=dta )
    lam <- lam$x[which.max(lam$y)]
    (vec^lam - 1)/lam
}
x <- runif(20)
bc(x)

#' ![](https://i.imgur.com/lhKymfQ.png)

#'     #>  [1] -0.92115159 -0.21776512 -1.20946708 -0.16700312 -0.76096811
#'     #>  [6] -0.12208801 -0.61723623 -0.78302973 -0.62455538 -1.40636663
#'     #> [11] -0.52627869 -0.09377700 -1.02867887 -0.68288810 -0.93872856
#'     #> [16] -0.17005783 -0.01754519 -0.83549564 -0.35399612 -1.34878425

#' Created on 2018-08-06 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).

#######

On Sun, 5 Aug 2018, Jinsong Zhao wrote:

> Hi there,
>
> I wrote a function that wraps MASS::boxcox as:
>
> bc <- function(vec) {
>   lam <- boxcox(lm(vec ~ 1))
>   lam <- lam$x[which.max(lam$y)]
>   (vec^lam - 1)/lam
> }
>
> When I invoke it as:
>
>> x <- runif(20)
>> bc(x)
> Error in eval(predvars, data, env) : object 'vec' not found
>
> I have googled, and rewrote the above function as:
>
> bc <- function(vec) {
>   dat <<- data.frame(vec = vec)
>   lam <- boxcox(lm(vec ~ 1, dat))
>   lam <- lam$x[which.max(lam$y)]
>   rm(dat, envir = .GlobalEnv)
>   (vec^lam - 1)/lam
> }
>
> It works. But, I am wondering why MASS::boxcox have to wrap in such way that have to use the data in .GlobalEnv.
>
> Best,
> Jinsong
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From euthymio@@k@k@@viki@ @ending from gm@il@com  Mon Aug  6 18:21:44 2018
From: euthymio@@k@k@@viki@ @ending from gm@il@com (euthymios kasvikis)
Date: Mon, 6 Aug 2018 19:21:44 +0300
Subject: [R] 
 Perform GEE regression in R with multiple dependent variables
In-Reply-To: <CABNxSU2d0hwv+vN8YuecS3TPvhA--_hF+R_bv+MGmBYGKSYp6g@mail.gmail.com>
References: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
 <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>
 <CABNxSU2d0hwv+vN8YuecS3TPvhA--_hF+R_bv+MGmBYGKSYp6g@mail.gmail.com>
Message-ID: <CABNxSU0D29NXmAoNzw7gU95+tPFb=XvYA6gYUyNiS6VQ209egQ@mail.gmail.com>

Or
library(multgee)
fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism,
data=RightWomen,
                    id= Politician_ID,repeated=Country_ID)
summary(fitord)

Should I use dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal)) ?


???? ???, 6 ??? 2018 ???? 6:00 ?.?., ?/? euthymios kasvikis <
euthymios.k.kasvikis at gmail.com> ??????:

> First of all thanks for your advice. So suppose that I would like to use
> the multgee package. The model would be like:
> library(multgee)
> fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism,
> data=RightWomen,
>                     id= ordered(factor(Country_ID)))
> summary(fitord)
>
> ???? ???, 6 ??? 2018 ???? 7:29 ?.?., ?/? Duncan Mackay <
> dulcalma at bigpond.com> ??????:
>
>> Hi
>>
>> Please read the geepack manual carefully.
>> GEE ordinal regression is not simple.
>> You need to format your data and do not use sample as a storage name. It
>> is
>> the name of a function
>>
>> dta is storage
>> dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal))
>>
>> m0 <-
>> ordgee(Ideo_Ordinal ~ Machiavellianism+Psychopathy+Narcissism ,data = dta,
>> id = Country_ID,
>>        corstr = "independence")
>>
>> You need to see if the model is appropriate first and whether the sandwich
>> errors are right before you go further
>>
>> If this is your data you may not get credible results.
>> You need to read up on the requirements of GEEs and  ordinal GEEs in
>> particular
>> There are a number of packages with different data requirements and
>> methods
>> If you have repeated measurements   repolr; ?multgee (just from memory)
>> Small sample sizes are a problem there are a number of packages dealing
>> with
>> this but you will have to see which is best for you
>> Many do not offer a method for ordinal or multinomial GEE.
>> One further question to ask  population specific or subject specific  ie
>> to
>> GEE or not to GEE
>>
>>
>> Regards
>>
>> Duncan
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2350
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of euthymios
>> kasvikis
>> Sent: Saturday, 4 August 2018 07:30
>> To: r-help at r-project.org
>> Subject: [R] Perform GEE regression in R with multiple dependent variables
>>
>> Im trying to perform generalized estimating equation (GEE) on the (sample)
>> dataset below with R and I would like some little guidance. First of all I
>> will describe my dataset. As you can see below it includes 5 variables.
>> Country_ID shows the country of the politician, Ideo_Ordinal his poltical
>> belief from 1 to 7 (far left to far right). Then we have measurements
>> regarding three characteristics. I would like to run an analysis based on
>> the country and the political beliefs of every politician (dependent
>> variables) in relation with the 3 characteristics. I have used the geepack
>> package using:
>>
>> library(geepack)
>>
>>         samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
>> ~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
>> sample$Ideo_Ordinal,
>>                                        corstr = "independence"))) %>%
>>           rownames_to_column() %>%
>>           mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
>>                  upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
>>                  df=1,
>>                  ExpBeta = exp(Estimate)) %>%       # Transformed estimate
>>           mutate(lWald=exp(lowerWald),              # Upper transformed
>>                  uWald=exp(upperWald))              # Lower transformed
>>         samplem
>>
>> I would like to know if it is valid to add in this method the Country_ID
>> simultaneously with Ideo_Ordinal and how to do it.
>>
>> Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
>>     3             1            3      0.250895132  0.155238716
>> 0.128683755
>>     5             1            3     -0.117725000 -0.336256435
>> -0.203137879
>>     7             1            3      0.269509029 -0.260728261
>> 0.086819555
>>     9             1            6      0.108873496  0.175528190
>> 0.182884928
>>     14            1            3      0.173129951  0.054468468
>> 0.155030794
>>     15            1            6     -0.312088872 -0.414358301
>> -0.212599946
>>     17            1            3     -0.297647658 -0.096523143
>> -0.228533352
>>     18            1            3     -0.020389157 -0.210180866
>> -0.046687695
>>     20            1            3     -0.523432382 -0.125114982
>> -0.431070629
>>     21            1            1      0.040304508  0.022743463
>> 0.233657881
>>     22            1            3      0.253695988 -0.330825166
>> 0.101122320
>>     23            1            3     -0.478673895 -0.421801231
>> -0.422894791
>>     27            1            6     -0.040856419 -0.566728704
>> -0.136069484
>>     28            1            3      0.240040249 -0.398404825
>> 0.135603114
>>     29            1            6     -0.207631653 -0.005347621
>> -0.294935155
>>     30            1            3      0.458042533  0.462935386
>> 0.586244831
>>     31            1            3     -0.259850232 -0.233074787
>> -0.092249465
>>     33            1            3      0.002164223 -0.637668706
>> -0.267158031
>>     34            1            6      0.050991955 -0.098030021
>> -0.043826848
>>     36            1            3     -0.338052871 -0.168894328
>> -0.230198200
>>     38            1            3      0.174382347  0.023807812
>> 0.192963609
>>     41            2            3     -0.227322148 -0.010016330
>> -0.095576329
>>     42            2            3     -0.267514920  0.066108837
>> -0.218979873
>>     43            2            3      0.421277754  0.385223920
>> 0.421274111
>>     44            2            3     -0.399592341 -0.498154998
>> -0.320402699
>>     45            2            1      0.162038344  0.328116118
>> 0.104105963
>>     47            2            3     -0.080755709  0.003080287
>> -0.043568723
>>     48            2            3      0.059474124 -0.447305420
>> 0.003988071
>>     49            2            3     -0.219773040 -0.312902659
>> -0.239057883
>>     51            2            3      0.438659431  0.364042111
>> 0.393014172
>>     52            2            3     -0.088560903 -0.490889275
>> -0.006041054
>>     53            2            3     -0.122612591  0.074438944
>> 0.103722836
>>     54            2            3     -0.450586055 -0.304253061
>> -0.132365179
>>     55            2            6     -0.710545197 -0.451329850
>> -0.764201786
>>     56            2            3      0.330718447  0.335460128
>> 0.429173481
>>     57            2            3      0.442508023  0.297522144
>> 0.407155726
>>     60            2            3      0.060797815 -0.096516876
>> -0.012802977
>>     61            2            3     -0.250757764 -0.113219864
>> -0.215345379
>>     62            2            1      0.153654345 -0.089615287
>> 0.118626045
>>     65            2            3      0.042969508 -0.486999608
>> -0.080829636
>>     66            3            3      0.158337022  0.208229002
>> 0.241607154
>>     67            3            3      0.220237408  0.397914524
>> 0.262207709
>>     69            3            3      0.200558577  0.244419633
>> 0.301732113
>>     71            3            3      0.690244689  0.772692418
>> 0.625921098
>>     72            3            3      0.189810070  0.377774321
>> 0.293988340
>>     73            3            3     -0.385724422 -0.262131032
>> -0.373159652
>>     74            3            3     -0.124095769 -0.109816334
>> -0.127157915
>>     75            3            1      0.173299879  0.453592671
>> 0.325357383
>>     76            3            3     -0.598215129 -0.643286651
>> -0.423824759
>>     77            3            3     -0.420558406 -0.361763025
>> -0.465612116
>>     78            3            3     -0.176788569 -0.305506924
>> -0.203730879
>>     80            3            3     -0.114790731  0.262392918
>> 0.061382073
>>     81            3            3     -0.274904173 -0.342603918
>> -0.302761994
>>     82            3            3     -0.146902101 -0.059558818
>> -0.120550957
>>     84            3            3      0.038303792 -0.139833875
>> 0.170005914
>>     85            3            3     -0.220212221 -0.541399757
>> -0.555201764
>>     87            3            3      0.255300386  0.179484246
>> 0.421428096
>>     88            3            6     -0.548823069 -0.405541620
>> -0.322935805
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From dulc@lm@ @ending from bigpond@com  Tue Aug  7 06:16:19 2018
From: dulc@lm@ @ending from bigpond@com (Duncan Mackay)
Date: Tue, 7 Aug 2018 14:16:19 +1000
Subject: [R] 
 Perform GEE regression in R with multiple dependent variables
In-Reply-To: <CABNxSU0D29NXmAoNzw7gU95+tPFb=XvYA6gYUyNiS6VQ209egQ@mail.gmail.com>
References: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
 <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>
 <CABNxSU2d0hwv+vN8YuecS3TPvhA--_hF+R_bv+MGmBYGKSYp6g@mail.gmail.com>
 <CABNxSU0D29NXmAoNzw7gU95+tPFb=XvYA6gYUyNiS6VQ209egQ@mail.gmail.com>
Message-ID: <000b01d42e05$64785970$2d690c50$@bigpond.com>

It is quite a while (years) since I used multgee.

There are several papers published by Agresti and ?Touloumis et al   1 in Biometrics in 2013  and another in JSS. I am unable to reference  them at the moment; you need to read them.

 

I cannot remember how the dependent variable (y) is formatted: ordered or numerical see package help.

 

The repeated argument is for longitudinal/ repeated measurements:

Country_ID if is refers to countries is therefore an x  variable (factor) 

 

How you set up you model depends on what your model is testing.

 

Remember ordinal GEE in unlike normal modelling

 

Regards

 

Duncan

 

From: euthymios kasvikis [mailto:euthymios.k.kasvikis at gmail.com] 
Sent: Tuesday, 7 August 2018 02:22
To: dulcalma at bigpond.com
Cc: r-help at r-project.org
Subject: Re: [R] Perform GEE regression in R with multiple dependent variables

 

Or 

library(multgee)

fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism, data=RightWomen,

                    id= Politician_ID,repeated=Country_ID)

summary(fitord)

 

Should I use dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal)) ?

 

 

???? ???, 6 ??? 2018 ???? 6:00 ?.?., ?/? euthymios kasvikis <euthymios.k.kasvikis at gmail.com> ??????:

First of all thanks for your advice. So suppose that I would like to use the multgee package. The model would be like: 

library(multgee)

fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism, data=RightWomen,

                    id= ordered(factor(Country_ID)))

summary(fitord)

 

???? ???, 6 ??? 2018 ???? 7:29 ?.?., ?/? Duncan Mackay <dulcalma at bigpond.com> ??????:

Hi

Please read the geepack manual carefully.
GEE ordinal regression is not simple.
You need to format your data and do not use sample as a storage name. It is
the name of a function

dta is storage
dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal))

m0 <-
ordgee(Ideo_Ordinal ~ Machiavellianism+Psychopathy+Narcissism ,data = dta,
id = Country_ID,
       corstr = "independence")

You need to see if the model is appropriate first and whether the sandwich
errors are right before you go further

If this is your data you may not get credible results.
You need to read up on the requirements of GEEs and  ordinal GEEs in
particular
There are a number of packages with different data requirements and methods 
If you have repeated measurements   repolr; ?multgee (just from memory)
Small sample sizes are a problem there are a number of packages dealing with
this but you will have to see which is best for you
Many do not offer a method for ordinal or multinomial GEE.
One further question to ask  population specific or subject specific  ie to
GEE or not to GEE


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of euthymios
kasvikis
Sent: Saturday, 4 August 2018 07:30
To: r-help at r-project.org
Subject: [R] Perform GEE regression in R with multiple dependent variables

Im trying to perform generalized estimating equation (GEE) on the (sample)
dataset below with R and I would like some little guidance. First of all I
will describe my dataset. As you can see below it includes 5 variables.
Country_ID shows the country of the politician, Ideo_Ordinal his poltical
belief from 1 to 7 (far left to far right). Then we have measurements
regarding three characteristics. I would like to run an analysis based on
the country and the political beliefs of every politician (dependent
variables) in relation with the 3 characteristics. I have used the geepack
package using:

library(geepack)

        samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
sample$Ideo_Ordinal,
                                       corstr = "independence"))) %>%
          rownames_to_column() %>%
          mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
                 upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
                 df=1,
                 ExpBeta = exp(Estimate)) %>%       # Transformed estimate
          mutate(lWald=exp(lowerWald),              # Upper transformed
                 uWald=exp(upperWald))              # Lower transformed
        samplem

I would like to know if it is valid to add in this method the Country_ID
simultaneously with Ideo_Ordinal and how to do it.

Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
    3             1            3      0.250895132  0.155238716  0.128683755
    5             1            3     -0.117725000 -0.336256435 -0.203137879
    7             1            3      0.269509029 -0.260728261  0.086819555
    9             1            6      0.108873496  0.175528190  0.182884928
    14            1            3      0.173129951  0.054468468  0.155030794
    15            1            6     -0.312088872 -0.414358301 -0.212599946
    17            1            3     -0.297647658 -0.096523143 -0.228533352
    18            1            3     -0.020389157 -0.210180866 -0.046687695
    20            1            3     -0.523432382 -0.125114982 -0.431070629
    21            1            1      0.040304508  0.022743463  0.233657881
    22            1            3      0.253695988 -0.330825166  0.101122320
    23            1            3     -0.478673895 -0.421801231 -0.422894791
    27            1            6     -0.040856419 -0.566728704 -0.136069484
    28            1            3      0.240040249 -0.398404825  0.135603114
    29            1            6     -0.207631653 -0.005347621 -0.294935155
    30            1            3      0.458042533  0.462935386  0.586244831
    31            1            3     -0.259850232 -0.233074787 -0.092249465
    33            1            3      0.002164223 -0.637668706 -0.267158031
    34            1            6      0.050991955 -0.098030021 -0.043826848
    36            1            3     -0.338052871 -0.168894328 -0.230198200
    38            1            3      0.174382347  0.023807812  0.192963609
    41            2            3     -0.227322148 -0.010016330 -0.095576329
    42            2            3     -0.267514920  0.066108837 -0.218979873
    43            2            3      0.421277754  0.385223920  0.421274111
    44            2            3     -0.399592341 -0.498154998 -0.320402699
    45            2            1      0.162038344  0.328116118  0.104105963
    47            2            3     -0.080755709  0.003080287 -0.043568723
    48            2            3      0.059474124 -0.447305420  0.003988071
    49            2            3     -0.219773040 -0.312902659 -0.239057883
    51            2            3      0.438659431  0.364042111  0.393014172
    52            2            3     -0.088560903 -0.490889275 -0.006041054
    53            2            3     -0.122612591  0.074438944  0.103722836
    54            2            3     -0.450586055 -0.304253061 -0.132365179
    55            2            6     -0.710545197 -0.451329850 -0.764201786
    56            2            3      0.330718447  0.335460128  0.429173481
    57            2            3      0.442508023  0.297522144  0.407155726
    60            2            3      0.060797815 -0.096516876 -0.012802977
    61            2            3     -0.250757764 -0.113219864 -0.215345379
    62            2            1      0.153654345 -0.089615287  0.118626045
    65            2            3      0.042969508 -0.486999608 -0.080829636
    66            3            3      0.158337022  0.208229002  0.241607154
    67            3            3      0.220237408  0.397914524  0.262207709
    69            3            3      0.200558577  0.244419633  0.301732113
    71            3            3      0.690244689  0.772692418  0.625921098
    72            3            3      0.189810070  0.377774321  0.293988340
    73            3            3     -0.385724422 -0.262131032 -0.373159652
    74            3            3     -0.124095769 -0.109816334 -0.127157915
    75            3            1      0.173299879  0.453592671  0.325357383
    76            3            3     -0.598215129 -0.643286651 -0.423824759
    77            3            3     -0.420558406 -0.361763025 -0.465612116
    78            3            3     -0.176788569 -0.305506924 -0.203730879
    80            3            3     -0.114790731  0.262392918  0.061382073
    81            3            3     -0.274904173 -0.342603918 -0.302761994
    82            3            3     -0.146902101 -0.059558818 -0.120550957
    84            3            3      0.038303792 -0.139833875  0.170005914
    85            3            3     -0.220212221 -0.541399757 -0.555201764
    87            3            3      0.255300386  0.179484246  0.421428096
    88            3            6     -0.548823069 -0.405541620 -0.322935805

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From kenneth@b@rnhoorn @ending from telenet@be  Mon Aug  6 20:18:38 2018
From: kenneth@b@rnhoorn @ending from telenet@be (kenneth Barnhoorn)
Date: Mon, 6 Aug 2018 20:18:38 +0200
Subject: [R] linear regression
Message-ID: <D0B03FB6-08D7-45CB-9D53-DD4EC3EAD4DA@telenet.be>

I have a problem with a linear regression output. 

In January I made an analysis of some data and received an certain output, if I run the same code now I don?t receive the same output and I don?t see why. It is important to know the country, so I would like to see the country names behind the coefficient names like in January? 

January:




Now: 


From y@@@@_m@lik@ @ending from y@hoo@fr  Tue Aug  7 07:51:12 2018
From: y@@@@_m@lik@ @ending from y@hoo@fr (malika yassa)
Date: Tue, 7 Aug 2018 05:51:12 +0000 (UTC)
Subject: [R] (no subject)
References: <18410916.4678238.1533621072638.ref@mail.yahoo.com>
Message-ID: <18410916.4678238.1533621072638@mail.yahoo.com>

hellothis is my programmeyou can help me, i cann't found a solution for H? and this? function i calculate for all value for x1thank you 


x<-rexp(N,2)

z<-rnorm(0,1,n)

g<rexp(2,n)

h=max(x)-min(x)

n1=n^0.17

h1=h/n1

k=2

x1<-seq(from=-2,to=2,by=0.1)

s[i]=(x[i]+x[i+1])/2

for(i in 1:N)

fkS<-function(m,k){fkm=-m*(abs(Z-m)<k)+k*(Z-m>=k)-k*(Z-m<=-k)}

k1<-function(u,x1){-1/(2*pi)exp((x1-u)/h1}

for (i in 1:n)

{k1(u,x1)=integrate(-1/(2*pi)exp((x1-u)/h1,lower=s[i-1],upper=s[i])}

?

?

H<-function(u,x1)

for (i in 1:n)

{H(u,x1)=sum(g[i]*fkS*integrate(k1,lower=s[i-1],upper=s[i])

}


	[[alternative HTML version deleted]]


From m@ij@@@irkj@rvi @ending from gm@il@com  Tue Aug  7 09:36:10 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 7 Aug 2018 10:36:10 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
Message-ID: <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>

Thanks for help!

However, changing the index from i to j for the column vector changes the
output. I would like the matrix to be the following:

-1 1 0 0 0 0 0
0 -1 1 0 0 0 0
0 0 -1 1 0 0 0
.....
etc.

How to code it?

Best,
Maija


>> myMatrix <- matrix(0,5,12)
>> for(i in 1:nrow(myMatrix)) {
>>    for(i in 1:ncol(myMatrix)) {
>>      myMatrix[i,i] = -1
>>      myMatrix[i,i+1] = 1
>> }}
>> print(myMatrix)



ma 6. elok. 2018 klo 13.58 Rui Barradas (ruipbarradas at sapo.pt) kirjoitti:

> Hello,
>
> Eric is right but...
>
> You have two assignments. The second sets a value that will be
> overwritten is the next iteration by myMatrix[i,i] = -1 when 'i' becomes
> the next value.
>
> If you fix the second index and use 'j', you might as well do
>
> myMatrix[] = -1
> myMatrix[, ncol(myMatrix)] = 1
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 10:24 de 06/08/2018, Eric Berger escreveu:
> > Both loops are on 'i', which is a bad idea. :-)
> > Also myMatrix[i,i+1] will be out-of-bounds if i = ncol(myMatrix)
> >
> >
> > On Mon, Aug 6, 2018 at 12:02 PM, Maija Sirkj?rvi <
> maija.sirkjarvi at gmail.com>
> > wrote:
> >
> >> I have a basic for loop with a simple matrix. The code is doing what it
> is
> >> supposed to do, but I'm still wondering the error "subscript out of
> >> bounds". What would be a smoother way to code such a basic for loop?
> >>
> >> myMatrix <- matrix(0,5,12)
> >> for(i in 1:nrow(myMatrix)) {
> >>    for(i in 1:ncol(myMatrix)) {
> >>      myMatrix[i,i] = -1
> >>      myMatrix[i,i+1] = 1
> >> }}
> >> print(myMatrix)
> >>
> >> Thanks in advance!
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From m@echler @ending from @t@t@m@th@ethz@ch  Tue Aug  7 09:47:18 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 7 Aug 2018 09:47:18 +0200
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
Message-ID: <23401.20102.253070.593345@stat.math.ethz.ch>


> Thanks for help!
> However, changing the index from i to j for the column vector changes the
> output. I would like the matrix to be the following:

> -1 1 0 0 0 0 0
> 0 -1 1 0 0 0 0
> 0 0 -1 1 0 0 0
> .....
> etc.

> How to code it?

as Enrico Schumann showed you:  Without any loop, a very nice
R-ish way (see his message)!

Martin

> Best,
> Maija


From m@ij@@@irkj@rvi @ending from gm@il@com  Tue Aug  7 10:20:04 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 7 Aug 2018 11:20:04 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <23401.20102.253070.593345@stat.math.ethz.ch>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
Message-ID: <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>

Thanks, but I didn't quite get it. And I don't get it running as it should.

ti 7. elok. 2018 klo 10.47 Martin Maechler (maechler at stat.math.ethz.ch)
kirjoitti:

>
> > Thanks for help!
> > However, changing the index from i to j for the column vector changes the
> > output. I would like the matrix to be the following:
>
> > -1 1 0 0 0 0 0
> > 0 -1 1 0 0 0 0
> > 0 0 -1 1 0 0 0
> > .....
> > etc.
>
> > How to code it?
>
> as Enrico Schumann showed you:  Without any loop, a very nice
> R-ish way (see his message)!
>
> Martin
>
> > Best,
> > Maija
>
>

	[[alternative HTML version deleted]]


From jwd @ending from @urewe@t@net  Tue Aug  7 10:38:22 2018
From: jwd @ending from @urewe@t@net (John)
Date: Tue, 7 Aug 2018 01:38:22 -0700
Subject: [R] linear regression
In-Reply-To: <D0B03FB6-08D7-45CB-9D53-DD4EC3EAD4DA@telenet.be>
References: <D0B03FB6-08D7-45CB-9D53-DD4EC3EAD4DA@telenet.be>
Message-ID: <20180807013822.2cd8e967@Draco.localdomain>

On Mon, 6 Aug 2018 20:18:38 +0200
kenneth Barnhoorn <kenneth.barnhoorn at telenet.be> wrote:

Your examples did not appear.  Remember to use plain text rather
than html.

JWDougherty

> I have a problem with a linear regression output. 
> 
> In January I made an analysis of some data and received an certain
> output, if I run the same code now I don?t receive the same output
> and I don?t see why. It is important to know the country, so I would
> like to see the country names behind the coefficient names like in
> January? 
> 
> January:
> 
> 
> 
> 
> Now: 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.
> 


From drjimlemon @ending from gm@il@com  Tue Aug  7 11:13:03 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 7 Aug 2018 19:13:03 +1000
Subject: [R] linear regression
In-Reply-To: <20180807013822.2cd8e967@Draco.localdomain>
References: <D0B03FB6-08D7-45CB-9D53-DD4EC3EAD4DA@telenet.be>
 <20180807013822.2cd8e967@Draco.localdomain>
Message-ID: <CA+8X3fU09ou2tK7cH9_mBu_40PYN3GbfuTQMNa2cpeHaahSADQ@mail.gmail.com>

Hi Kenneth,
My guess is that you have tried to send screenshots of your output and
these were blocked. Try to cut and paste the output into your message.

Jim


On Tue, Aug 7, 2018 at 6:38 PM, John <jwd at surewest.net> wrote:
> On Mon, 6 Aug 2018 20:18:38 +0200
> kenneth Barnhoorn <kenneth.barnhoorn at telenet.be> wrote:
>
> Your examples did not appear.  Remember to use plain text rather
> than html.
>
> JWDougherty
>
>> I have a problem with a linear regression output.
>>
>> In January I made an analysis of some data and received an certain
>> output, if I run the same code now I don?t receive the same output
>> and I don?t see why. It is important to know the country, so I would
>> like to see the country names behind the coefficient names like in
>> January?
>>
>> January:
>>
>>
>>
>>
>> Now:
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @k@h@y_e4 @ending from hotm@il@com  Tue Aug  7 11:38:15 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Tue, 7 Aug 2018 09:38:15 +0000
Subject: [R] installing R in Amazon linux AMI
Message-ID: <SL2P216MB009118AE60FC40C66C01E61AC8270@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am using R in AWS. I am currently using RHEL AMI in ec2 instance. I want to shift to Amazon LINUX AMI to lower costs.

How do you install R in Amazon lINUX AMI? I have searched the web, and , to my disappointment have not found any articles on how to install R in Amazon linux AMI, as is there for RED HAT AMI.

Any help?

Very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Tue Aug  7 16:37:27 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 7 Aug 2018 15:37:27 +0100
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
Message-ID: <5B69AEA7.70408@sapo.pt>

Hello,

If it is not running as you want it, you should say what went wrong.
Post the code that you have tried and the expected output, please.
(In fact, the lack of expected output was the reason why my suggestion 
was completely off target.)

Rui Barradas

On 07/08/2018 09:20, Maija Sirkj?rvi wrote:
> Thanks, but I didn't quite get it. And I don't get it running as it should.
>
> ti 7. elok. 2018 klo 10.47 Martin Maechler (maechler at stat.math.ethz.ch
> <mailto:maechler at stat.math.ethz.ch>) kirjoitti:
>
>
>      > Thanks for help!
>      > However, changing the index from i to j for the column vector
>     changes the
>      > output. I would like the matrix to be the following:
>
>      > -1 1 0 0 0 0 0
>      > 0 -1 1 0 0 0 0
>      > 0 0 -1 1 0 0 0
>      > .....
>      > etc.
>
>      > How to code it?
>
>     as Enrico Schumann showed you:  Without any loop, a very nice
>     R-ish way (see his message)!
>
>     Martin
>
>      > Best,
>      > Maija
>


From @ilve@tri@c@@@li @ending from gm@il@com  Tue Aug  7 16:47:40 2018
From: @ilve@tri@c@@@li @ending from gm@il@com (Edoardo Silvestri)
Date: Tue, 7 Aug 2018 16:47:40 +0200
Subject: [R] Lag function
Message-ID: <CAEv8TnR2B02aWbcb=XD_DQ=c5Eo2Ln9z5aRORXcH2Cfd3nsDQQ@mail.gmail.com>

I have an hourly database and I defined a variable as follows:
time<-ts(data$variable, frequency=24)

If i need to create the variables with one day lag, the corresponding
command is lag(time,24)?

Thank you

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Aug  7 19:13:28 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 7 Aug 2018 10:13:28 -0700
Subject: [R] Lag function
In-Reply-To: <CAEv8TnR2B02aWbcb=XD_DQ=c5Eo2Ln9z5aRORXcH2Cfd3nsDQQ@mail.gmail.com>
References: <CAEv8TnR2B02aWbcb=XD_DQ=c5Eo2Ln9z5aRORXcH2Cfd3nsDQQ@mail.gmail.com>
Message-ID: <CAGxFJbTpO1=wSCGK8UycsmsAshYsLsswQXagVeNbdOfnLNaTUg@mail.gmail.com>

Well, maybe. Whether it's +24 or -24 depends on what you mean by "one day
lag." I suspect you mean -24, but perhaps this will help you decide:

test <- ts(1:72, frequency = 24)
plot(lag(test,24))
plot(lag(test,-24))

Note that the +24 moves the time base back 24 observable units (= hours)
and -24 moves it forward 24 hours. This means that the day 2 observations
are those from day 1, etc., which is usually what is wanted for lag. But
you decide.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 7, 2018 at 7:47 AM, Edoardo Silvestri <
silvestri.casali at gmail.com> wrote:

> I have an hourly database and I defined a variable as follows:
> time<-ts(data$variable, frequency=24)
>
> If i need to create the variables with one day lag, the corresponding
> command is lag(time,24)?
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Wed Aug  8 03:06:07 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 8 Aug 2018 11:06:07 +1000
Subject: [R] (no subject)
In-Reply-To: <18410916.4678238.1533621072638@mail.yahoo.com>
References: <18410916.4678238.1533621072638.ref@mail.yahoo.com>
 <18410916.4678238.1533621072638@mail.yahoo.com>
Message-ID: <CA+8X3fWP6f+co3RHs_RdwQ24ucXOCHaA7r=TbwdUUxUm2TPZ4Q@mail.gmail.com>

Hi malika,
You don't seem to have defined your functions correctly. For example:

H<-function(u,x1)

would define an empty function H if that command worked, but it doesn't

Jim


On Tue, Aug 7, 2018 at 3:51 PM, malika yassa via R-help
<r-help at r-project.org> wrote:
> hellothis is my programmeyou can help me, i cann't found a solution for H  and this  function i calculate for all value for x1thank you
>
>
> x<-rexp(N,2)
>
> z<-rnorm(0,1,n)
>
> g<rexp(2,n)
>
> h=max(x)-min(x)
>
> n1=n^0.17
>
> h1=h/n1
>
> k=2
>
> x1<-seq(from=-2,to=2,by=0.1)
>
> s[i]=(x[i]+x[i+1])/2
>
> for(i in 1:N)
>
> fkS<-function(m,k){fkm=-m*(abs(Z-m)<k)+k*(Z-m>=k)-k*(Z-m<=-k)}
>
> k1<-function(u,x1){-1/(2*pi)exp((x1-u)/h1}
>
> for (i in 1:n)
>
> {k1(u,x1)=integrate(-1/(2*pi)exp((x1-u)/h1,lower=s[i-1],upper=s[i])}
>
>
>
>
>
> H<-function(u,x1)
>
> for (i in 1:n)
>
> {H(u,x1)=sum(g[i]*fkS*integrate(k1,lower=s[i-1],upper=s[i])
>
> }
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From joh@nn@-@chw@rz @ending from gmx@de  Wed Aug  8 09:08:09 2018
From: joh@nn@-@chw@rz @ending from gmx@de (Johanna Schwarz)
Date: Wed, 8 Aug 2018 09:08:09 +0200
Subject: [R] Submit your own R package - @examples
Message-ID: <003401d42ee6$90521040$b0f630c0$@gmx.de>

Dear community, 

I am trying to submit my first R package to CRAN and stumbled upon the
following problem:

Most of my methods, are not exported to the namespace using the @examples
options.

Will I have to provide @examples for these methods in the documentation? If
yes, I have the problem that when I run the @examples for the method that is
not exported, I receive the error 

Error in foo() : could not find function "foo"

Execution halted

 

What am I missing? Will I even have to provide examples to pass the CRAN
tests?

 

Thank you in advance for your help,

schwart

 


	[[alternative HTML version deleted]]


From m@ij@@@irkj@rvi @ending from gm@il@com  Wed Aug  8 11:40:59 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Wed, 8 Aug 2018 12:40:59 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <5B69AEA7.70408@sapo.pt>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
Message-ID: <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>

Thanks!

If I do it like this:

myMatrix <- matrix(0,5,5*2-3)
print(myMatrix)
for(i in 2:nrow(myMatrix))
  for(j in 2:ncol(myMatrix))
    myMatrix[i-1,j-1] = -1
    myMatrix[i-1,j] = 1
print(myMatrix)

I get the following result:

   [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]   -1   -1   -1   -1   -1   -1    0
[2,]   -1   -1   -1   -1   -1   -1    0
[3,]   -1   -1   -1   -1   -1   -1    0
[4,]   -1   -1   -1   -1   -1   -1    1
[5,]    0    0    0    0    0    0    0

However. The result that I would need to get would be like this:

   [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]   -1   1   0   0   0   0    0
[2,]   0   -1   1   0   0   0    0
[3,]   0   0   -1   1   0   0    0
[4,]   0   0   0   -1   1   0    0
[5,]    0    0    0    0    -1  1    0

I'd rather not create symmetric matrices as I would really like to learn
how to do this thing "the hard way" as I find matrix iteration to be quite
a basic procedure in everything I'm trying to do.

Thanks again!
Maija




ti 7. elok. 2018 klo 17.37 Rui Barradas (ruipbarradas at sapo.pt) kirjoitti:

> Hello,
>
> If it is not running as you want it, you should say what went wrong.
> Post the code that you have tried and the expected output, please.
> (In fact, the lack of expected output was the reason why my suggestion
> was completely off target.)
>
> Rui Barradas
>
> On 07/08/2018 09:20, Maija Sirkj?rvi wrote:
> > Thanks, but I didn't quite get it. And I don't get it running as it
> should.
> >
> > ti 7. elok. 2018 klo 10.47 Martin Maechler (maechler at stat.math.ethz.ch
> > <mailto:maechler at stat.math.ethz.ch>) kirjoitti:
> >
> >
> >      > Thanks for help!
> >      > However, changing the index from i to j for the column vector
> >     changes the
> >      > output. I would like the matrix to be the following:
> >
> >      > -1 1 0 0 0 0 0
> >      > 0 -1 1 0 0 0 0
> >      > 0 0 -1 1 0 0 0
> >      > .....
> >      > etc.
> >
> >      > How to code it?
> >
> >     as Enrico Schumann showed you:  Without any loop, a very nice
> >     R-ish way (see his message)!
> >
> >     Martin
> >
> >      > Best,
> >      > Maija
> >
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Wed Aug  8 11:53:32 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 8 Aug 2018 12:53:32 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
Message-ID: <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>

You only need one "for loop"

for(i in 2:nrow(myMatrix)) {
   myMatrix[i-1,i-1] = -1
   myMatrix[i-1,i] = 1
}

HTH,
Eric


On Wed, Aug 8, 2018 at 12:40 PM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
wrote:

> Thanks!
>
> If I do it like this:
>
> myMatrix <- matrix(0,5,5*2-3)
> print(myMatrix)
> for(i in 2:nrow(myMatrix))
>   for(j in 2:ncol(myMatrix))
>     myMatrix[i-1,j-1] = -1
>     myMatrix[i-1,j] = 1
> print(myMatrix)
>
> I get the following result:
>
>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]   -1   -1   -1   -1   -1   -1    0
> [2,]   -1   -1   -1   -1   -1   -1    0
> [3,]   -1   -1   -1   -1   -1   -1    0
> [4,]   -1   -1   -1   -1   -1   -1    1
> [5,]    0    0    0    0    0    0    0
>
> However. The result that I would need to get would be like this:
>
>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]   -1   1   0   0   0   0    0
> [2,]   0   -1   1   0   0   0    0
> [3,]   0   0   -1   1   0   0    0
> [4,]   0   0   0   -1   1   0    0
> [5,]    0    0    0    0    -1  1    0
>
> I'd rather not create symmetric matrices as I would really like to learn
> how to do this thing "the hard way" as I find matrix iteration to be quite
> a basic procedure in everything I'm trying to do.
>
> Thanks again!
> Maija
>
>
>
>
> ti 7. elok. 2018 klo 17.37 Rui Barradas (ruipbarradas at sapo.pt) kirjoitti:
>
> > Hello,
> >
> > If it is not running as you want it, you should say what went wrong.
> > Post the code that you have tried and the expected output, please.
> > (In fact, the lack of expected output was the reason why my suggestion
> > was completely off target.)
> >
> > Rui Barradas
> >
> > On 07/08/2018 09:20, Maija Sirkj?rvi wrote:
> > > Thanks, but I didn't quite get it. And I don't get it running as it
> > should.
> > >
> > > ti 7. elok. 2018 klo 10.47 Martin Maechler (maechler at stat.math.ethz.ch
> > > <mailto:maechler at stat.math.ethz.ch>) kirjoitti:
> > >
> > >
> > >      > Thanks for help!
> > >      > However, changing the index from i to j for the column vector
> > >     changes the
> > >      > output. I would like the matrix to be the following:
> > >
> > >      > -1 1 0 0 0 0 0
> > >      > 0 -1 1 0 0 0 0
> > >      > 0 0 -1 1 0 0 0
> > >      > .....
> > >      > etc.
> > >
> > >      > How to code it?
> > >
> > >     as Enrico Schumann showed you:  Without any loop, a very nice
> > >     R-ish way (see his message)!
> > >
> > >     Martin
> > >
> > >      > Best,
> > >      > Maija
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@ij@@@irkj@rvi @ending from gm@il@com  Wed Aug  8 12:03:11 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Wed, 8 Aug 2018 13:03:11 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
 <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
Message-ID: <CAJxz9NZZjTusrGW2vj7wSjuNHvjQ-zpDkHBwg82N2HonZJypkg@mail.gmail.com>

Thanks a lot ! That's it!

Maija

ke 8. elok. 2018 klo 12.53 Eric Berger (ericjberger at gmail.com) kirjoitti:

> You only need one "for loop"
>
> for(i in 2:nrow(myMatrix)) {
>    myMatrix[i-1,i-1] = -1
>    myMatrix[i-1,i] = 1
> }
>
> HTH,
> Eric
>
>
> On Wed, Aug 8, 2018 at 12:40 PM, Maija Sirkj?rvi <
> maija.sirkjarvi at gmail.com> wrote:
>
>> Thanks!
>>
>> If I do it like this:
>>
>> myMatrix <- matrix(0,5,5*2-3)
>> print(myMatrix)
>> for(i in 2:nrow(myMatrix))
>>   for(j in 2:ncol(myMatrix))
>>     myMatrix[i-1,j-1] = -1
>>     myMatrix[i-1,j] = 1
>> print(myMatrix)
>>
>> I get the following result:
>>
>>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
>> [1,]   -1   -1   -1   -1   -1   -1    0
>> [2,]   -1   -1   -1   -1   -1   -1    0
>> [3,]   -1   -1   -1   -1   -1   -1    0
>> [4,]   -1   -1   -1   -1   -1   -1    1
>> [5,]    0    0    0    0    0    0    0
>>
>> However. The result that I would need to get would be like this:
>>
>>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
>> [1,]   -1   1   0   0   0   0    0
>> [2,]   0   -1   1   0   0   0    0
>> [3,]   0   0   -1   1   0   0    0
>> [4,]   0   0   0   -1   1   0    0
>> [5,]    0    0    0    0    -1  1    0
>>
>> I'd rather not create symmetric matrices as I would really like to learn
>> how to do this thing "the hard way" as I find matrix iteration to be quite
>> a basic procedure in everything I'm trying to do.
>>
>> Thanks again!
>> Maija
>>
>>
>>
>>
>> ti 7. elok. 2018 klo 17.37 Rui Barradas (ruipbarradas at sapo.pt) kirjoitti:
>>
>> > Hello,
>> >
>> > If it is not running as you want it, you should say what went wrong.
>> > Post the code that you have tried and the expected output, please.
>> > (In fact, the lack of expected output was the reason why my suggestion
>> > was completely off target.)
>> >
>> > Rui Barradas
>> >
>> > On 07/08/2018 09:20, Maija Sirkj?rvi wrote:
>> > > Thanks, but I didn't quite get it. And I don't get it running as it
>> > should.
>> > >
>> > > ti 7. elok. 2018 klo 10.47 Martin Maechler (
>> maechler at stat.math.ethz.ch
>> > > <mailto:maechler at stat.math.ethz.ch>) kirjoitti:
>> > >
>> > >
>> > >      > Thanks for help!
>> > >      > However, changing the index from i to j for the column vector
>> > >     changes the
>> > >      > output. I would like the matrix to be the following:
>> > >
>> > >      > -1 1 0 0 0 0 0
>> > >      > 0 -1 1 0 0 0 0
>> > >      > 0 0 -1 1 0 0 0
>> > >      > .....
>> > >      > etc.
>> > >
>> > >      > How to code it?
>> > >
>> > >     as Enrico Schumann showed you:  Without any loop, a very nice
>> > >     R-ish way (see his message)!
>> > >
>> > >     Martin
>> > >
>> > >      > Best,
>> > >      > Maija
>> > >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From m@echler @ending from @t@t@m@th@ethz@ch  Wed Aug  8 13:09:01 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 8 Aug 2018 13:09:01 +0200
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
 <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
Message-ID: <23402.53069.24933.691484@stat.math.ethz.ch>

>>>>> Eric Berger    on Wed, 8 Aug 2018 12:53:32 +0300 writes:

> You only need one "for loop"
> for(i in 2:nrow(myMatrix)) {
>    myMatrix[i-1,i-1] = -1
>    myMatrix[i-1,i] = 1
> }
> 
> HTH,
> Eric

and why are you not using Enrico Schumann's even nicer solution
(from August 6) that I had mentioned too ?
Here's the link to it in the (official) R-help archives:
 https://stat.ethz.ch/pipermail/r-help/2018-August/455673.html

Maija said
> Thanks, but I didn't quite get it. And I don't get it running as it should.

and actually she is right that that version does not work for
all dimensions of 'myMatrix' -- it does need  ncol(.) >= 3
but neither does the above solution -- it only works for nrow(.) >= 2

Here's a function version of Enrico's that does work in all cases(!)
without a for loop -- including examples (as comments)

mkMat <- function(n=5, m=7) {
    M <- matrix(0, n,m)
    diag(M) <- -1
    ## this fails when m == ncol(M) <= 2, and ', drop=FALSE' does *not* help :
    ## diag(M[, -1]) <- 1
    ## diag(M[, -1, drop=FALSE]) <- 1
    ## This *does* work:
    M[col(M) - row(M) == 1L] <- 1

    M
}
mkMat()
##      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
## [1,]   -1    1    0    0    0    0    0
## [2,]    0   -1    1    0    0    0    0
## [3,]    0    0   -1    1    0    0    0
## [4,]    0    0    0   -1    1    0    0
## [5,]    0    0    0    0   -1    1    0
mkMat(3,5)
##      [,1] [,2] [,3] [,4] [,5]
## [1,]   -1    1    0    0    0
## [2,]    0   -1    1    0    0
## [3,]    0    0   -1    1    0
mkMat(5,3)
##      [,1] [,2] [,3]
## [1,]   -1    1    0
## [2,]    0   -1    1
## [3,]    0    0   -1
## [4,]    0    0    0
## [5,]    0    0    0

## Show that all small (m,n) work:
for(m in 0:3)
    for(n in 0:3) {
        cat(sprintf("(%d,%d):\n", n,m)); print(mkMat(n,m))
    }

## (output not shown here)


> 
> On Wed, Aug 8, 2018 at 12:40 PM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> wrote:
> 
> >   [.............]
> >   [.............]

> > However. The result that I would need to get would be like this:
> >
> >     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> > [1,]  -1    1    0    0    0    0    0
> > [2,]   0   -1    1    0    0    0    0
> > [3,]   0    0   -1    1    0    0    0
> > [4,]   0    0    0   -1    1    0    0
> > [5,]   0    0    0    0   -1    1    0


From S@Elli@on @ending from LGCGroup@com  Wed Aug  8 13:59:42 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Wed, 8 Aug 2018 11:59:42 +0000
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <23402.53069.24933.691484@stat.math.ethz.ch>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
 <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
 <23402.53069.24933.691484@stat.math.ethz.ch>
Message-ID: <0d7366e7965c471dbea4a9100cef391c@GBDCVPEXC08.corp.lgc-group.com>

 
> >>>>> Eric Berger    on Wed, 8 Aug 2018 12:53:32 +0300 writes:
> 
> > You only need one "for loop"
> > for(i in 2:nrow(myMatrix)) {
> >    myMatrix[i-1,i-1] = -1
> >    myMatrix[i-1,i] = 1
> > }

Or none, with matrix-based array indexing and explicit control of the indices to prevent overrun in :

mkMat <- function(n=5, m=7) {
   M <- matrix(0, n,m)
   i <- 1:min(n,m)
   j <- i[i<m]
   M[ cbind(i,i) ] <- -1
   M[ cbind(j, j+1) ] <- 1
   M
}




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S@Elli@on @ending from LGCGroup@com  Wed Aug  8 14:24:46 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Wed, 8 Aug 2018 12:24:46 +0000
Subject: [R] Submit your own R package - @examples
In-Reply-To: <003401d42ee6$90521040$b0f630c0$@gmx.de>
References: <003401d42ee6$90521040$b0f630c0$@gmx.de>
Message-ID: <de52b1f08bec4ad0bce1c0cac22fbc33@GBDCVPEXC08.corp.lgc-group.com>

> Most of my methods, are not exported to the namespace using the
> @examples
> options.

Joanna,
You normally need to export _all_ the objects/functions that you expect users to be able to run.
And if you are giving an example of a function, it seems likely that you expect users to use it, so it needs to be exported.

But it looks like you're using Roxygen and if I'm reading the documentation correctly, @examples doesn't export anything at all. @export does that. See https://cran.r-project.org/web/packages/roxygen2/vignettes/namespace.html

This is also a development question: maybe try the R-package-devel or R-devel lists?

Steve Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From Bill@Poling @ending from zeli@@com  Wed Aug  8 15:49:18 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 8 Aug 2018 13:49:18 +0000
Subject: [R] Help with finalfit and knitr
Message-ID: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi using some of my own data I am trying to reproduce examples from this tutorial:

https://cran.r-project.org/web/packages/finalfit/vignettes/finalfit_basics.html

Here are my sys info:
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows Server >= 2012 x64 (build 9200)

Here is my data structure:
str(df6)
# 'data.frame': 78407 obs. of  6 variables:
#   $ ProductName    : Factor w/ 2 levels "Editing","OON": 2 2 2 2 2 2 2 2 2 2 ...
# $ RevCodeCats    : Factor w/ 20 levels "BHAccomodations",..: 10 10 12 12 8 8 12 20 8 19 ...
# $ AgeCat         : Factor w/ 10 levels "[>80]","[0-5]",..: 9 9 5 5 7 4 7 7 7 9 ...
# $ PatientGender  : Factor w/ 3 levels "F","M","U": 2 2 2 2 2 1 1 1 1 1 ...
# $ AcceptedSavings: num  0 0 0 0 48.9 ...
# $ BinaryAccSav   : Factor w/ 2 levels "0","1": 1 1 1 1 2 2 2 2 2 2 ...

Here is my call:

explanatory = c("ProductName", "AgeCat", "PatientGender")
dependent = "BinaryAccSav" #------------------------------------------------------- AcceptedSavings 1=Y 0=N
df6 %>%  finalfit(dependent, explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

Here is the error:
#Error: unexpected symbol in " df6 %>%  finalfit(dependent, explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr"

The error is identifying the knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r")) as the problem

I believe I have copied the procedure correctly from the tutorial and replaced the tutorial variables with mine.

Libraries I believe are necessary:
library("knitr", lib.loc="~/R/win-library/3.5")
library("rmarkdown", lib.loc="~/R/win-library/3.5")
library("htmlTable", lib.loc="~/R/win-library/3.5")

And I see --Warning in install.packages :  package 'kable' is not available (for R version 3.5.1) which I believe is my problem?


  1.  can my hunch be validated by someone please?
  2.  Is there a solution for this?
  3.  or do I contact the package authors directly?

Thank you all!

WHP


Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From bgunter@4567 @ending from gm@il@com  Wed Aug  8 16:21:19 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 8 Aug 2018 07:21:19 -0700
Subject: [R] Submit your own R package - @examples
In-Reply-To: <003401d42ee6$90521040$b0f630c0$@gmx.de>
References: <003401d42ee6$90521040$b0f630c0$@gmx.de>
Message-ID: <CAGxFJbQ093sqm=_tbSySGg+KBArgQ9+G1w2YNTu7za5apL9UPg@mail.gmail.com>

This should be posted on the r-package-devel list rather than here:

https://stat.ethz.ch/mailman/listinfo/r-package-devel

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 8, 2018 at 12:08 AM, Johanna Schwarz <johanna-schwarz at gmx.de>
wrote:

> Dear community,
>
> I am trying to submit my first R package to CRAN and stumbled upon the
> following problem:
>
> Most of my methods, are not exported to the namespace using the @examples
> options.
>
> Will I have to provide @examples for these methods in the documentation? If
> yes, I have the problem that when I run the @examples for the method that
> is
> not exported, I receive the error
>
> Error in foo() : could not find function "foo"
>
> Execution halted
>
>
>
> What am I missing? Will I even have to provide examples to pass the CRAN
> tests?
>
>
>
> Thank you in advance for your help,
>
> schwart
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Aug  8 17:06:48 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Aug 2018 08:06:48 -0700
Subject: [R] Help with finalfit and knitr
In-Reply-To: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>

R syntax does not allow for objects to be plopped next to each other separated by a space. There should be a newline after the t1 variable. This kind of problem plagues people copying HTML into emails on this mailing list (losing newlines), and was probably introduced into your code during a copy-paste as well.

There is no package called "kable"... that is a function in the knitr package.

My advice is to enter one line of each example at a time and study what it does before proceeding to the next line. Copying whole swathes of code and marveling at the result is exhilarating but ultimately leaves you handicapped in creating your own code.

On August 8, 2018 6:49:18 AM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Hi using some of my own data I am trying to reproduce examples from
>this tutorial:
>
>https://cran.r-project.org/web/packages/finalfit/vignettes/finalfit_basics.html
>
>Here are my sys info:
>R version 3.5.1 (2018-07-02)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows Server >= 2012 x64 (build 9200)
>
>Here is my data structure:
>str(df6)
># 'data.frame': 78407 obs. of  6 variables:
>#   $ ProductName    : Factor w/ 2 levels "Editing","OON": 2 2 2 2 2 2
>2 2 2 2 ...
># $ RevCodeCats    : Factor w/ 20 levels "BHAccomodations",..: 10 10 12
>12 8 8 12 20 8 19 ...
># $ AgeCat         : Factor w/ 10 levels "[>80]","[0-5]",..: 9 9 5 5 7
>4 7 7 7 9 ...
># $ PatientGender  : Factor w/ 3 levels "F","M","U": 2 2 2 2 2 1 1 1 1
>1 ...
># $ AcceptedSavings: num  0 0 0 0 48.9 ...
># $ BinaryAccSav   : Factor w/ 2 levels "0","1": 1 1 1 1 2 2 2 2 2 2
>...
>
>Here is my call:
>
>explanatory = c("ProductName", "AgeCat", "PatientGender")
>dependent = "BinaryAccSav"
>#-------------------------------------------------------
>AcceptedSavings 1=Y 0=N
>df6 %>%  finalfit(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE) -> t1 knitr::kable(t1, row.names=FALSE,
>align=c("l", "l", "r", "r", "r"))
>
>Here is the error:
>#Error: unexpected symbol in " df6 %>%  finalfit(dependent,
>explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr"
>
>The error is identifying the knitr::kable(t1, row.names=FALSE,
>align=c("l", "l", "r", "r", "r")) as the problem
>
>I believe I have copied the procedure correctly from the tutorial and
>replaced the tutorial variables with mine.
>
>Libraries I believe are necessary:
>library("knitr", lib.loc="~/R/win-library/3.5")
>library("rmarkdown", lib.loc="~/R/win-library/3.5")
>library("htmlTable", lib.loc="~/R/win-library/3.5")
>
>And I see --Warning in install.packages :  package 'kable' is not
>available (for R version 3.5.1) which I believe is my problem?
>
>
>  1.  can my hunch be validated by someone please?
>  2.  Is there a solution for this?
>  3.  or do I contact the package authors directly?
>
>Thank you all!
>
>WHP
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:15}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Wed Aug  8 17:21:05 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 8 Aug 2018 08:21:05 -0700
Subject: [R] Fwd:  Help with finalfit and knitr
In-Reply-To: <CAGxFJbQC3m8-x9gX9c=1kKFMqDH3c5wbzL35Dvxa6-LgHnR8oA@mail.gmail.com>
References: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>
 <CAGxFJbQC3m8-x9gX9c=1kKFMqDH3c5wbzL35Dvxa6-LgHnR8oA@mail.gmail.com>
Message-ID: <CAGxFJbTOMvi=C50mrHFO7YVGRr7sZBbWhEKgv374OATZREwKRA@mail.gmail.com>

(From Jeff Newmiller)


"My advice is to enter one line of each example at a time and study what it
does before proceeding to the next line. Copying whole swathes of code and
marveling at the result is exhilarating but ultimately leaves you
handicapped in creating your own code."

Fortune nomination!

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 8, 2018 at 8:06 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> R syntax does not allow for objects to be plopped next to each other
> separated by a space. There should be a newline after the t1 variable. This
> kind of problem plagues people copying HTML into emails on this mailing
> list (losing newlines), and was probably introduced into your code during a
> copy-paste as well.
>
> There is no package called "kable"... that is a function in the knitr
> package.
>
> My advice is to enter one line of each example at a time and study what it
> does before proceeding to the next line. Copying whole swathes of code and
> marveling at the result is exhilarating but ultimately leaves you
> handicapped in creating your own code.
>
> On August 8, 2018 6:49:18 AM PDT, Bill Poling <Bill.Poling at zelis.com>
> wrote:
> >Hi using some of my own data I am trying to reproduce examples from
> >this tutorial:
> >
> >https://cran.r-project.org/web/packages/finalfit/vignettes/
> finalfit_basics.html
> >
> >Here are my sys info:
> >R version 3.5.1 (2018-07-02)
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >Running under: Windows Server >= 2012 x64 (build 9200)
> >
> >Here is my data structure:
> >str(df6)
> ># 'data.frame': 78407 obs. of  6 variables:
> >#   $ ProductName    : Factor w/ 2 levels "Editing","OON": 2 2 2 2 2 2
> >2 2 2 2 ...
> ># $ RevCodeCats    : Factor w/ 20 levels "BHAccomodations",..: 10 10 12
> >12 8 8 12 20 8 19 ...
> ># $ AgeCat         : Factor w/ 10 levels "[>80]","[0-5]",..: 9 9 5 5 7
> >4 7 7 7 9 ...
> ># $ PatientGender  : Factor w/ 3 levels "F","M","U": 2 2 2 2 2 1 1 1 1
> >1 ...
> ># $ AcceptedSavings: num  0 0 0 0 48.9 ...
> ># $ BinaryAccSav   : Factor w/ 2 levels "0","1": 1 1 1 1 2 2 2 2 2 2
> >...
> >
> >Here is my call:
> >
> >explanatory = c("ProductName", "AgeCat", "PatientGender")
> >dependent = "BinaryAccSav"
> >#-------------------------------------------------------
> >AcceptedSavings 1=Y 0=N
> >df6 %>%  finalfit(dependent, explanatory, p=TRUE,
> >add_dependent_label=TRUE) -> t1 knitr::kable(t1, row.names=FALSE,
> >align=c("l", "l", "r", "r", "r"))
> >
> >Here is the error:
> >#Error: unexpected symbol in " df6 %>%  finalfit(dependent,
> >explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr"
> >
> >The error is identifying the knitr::kable(t1, row.names=FALSE,
> >align=c("l", "l", "r", "r", "r")) as the problem
> >
> >I believe I have copied the procedure correctly from the tutorial and
> >replaced the tutorial variables with mine.
> >
> >Libraries I believe are necessary:
> >library("knitr", lib.loc="~/R/win-library/3.5")
> >library("rmarkdown", lib.loc="~/R/win-library/3.5")
> >library("htmlTable", lib.loc="~/R/win-library/3.5")
> >
> >And I see --Warning in install.packages :  package 'kable' is not
> >available (for R version 3.5.1) which I believe is my problem?
> >
> >
> >  1.  can my hunch be validated by someone please?
> >  2.  Is there a solution for this?
> >  3.  or do I contact the package authors directly?
> >
> >Thank you all!
> >
> >WHP
> >
> >
> >Confidentiality Notice This message is sent from Zelis.
> >...{{dropped:15}}
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From L@urence@Cl@rk @ending from he@lthm@nltd@com  Wed Aug  8 17:09:35 2018
From: L@urence@Cl@rk @ending from he@lthm@nltd@com (Laurence Clark)
Date: Wed, 8 Aug 2018 15:09:35 +0000
Subject: [R] security using R at work
Message-ID: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>

Hello all,

I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.

My question is:

If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security. Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?

Thank you

Laurence


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Laurence Clark
Business Data Analyst
Account Management
Health Management Ltd

Mobile: 		07584 556498
Switchboard: 	0845 504 1000
Email: 		Laurence.Clark at healthmanltd.com
Web: 		www.healthmanagement.co.uk

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ, United Kingdom.</font> 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


#####################################################################################
Scanned by MailMarshal - M86 Security's comprehensive email content security solution. 
Download a free evaluation of MailMarshal at www.m86security.com
#####################################################################################


From m@echler @ending from @t@t@m@th@ethz@ch  Wed Aug  8 17:56:38 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 8 Aug 2018 17:56:38 +0200
Subject: [R] Fwd:  Help with finalfit and knitr
In-Reply-To: <CAGxFJbTOMvi=C50mrHFO7YVGRr7sZBbWhEKgv374OATZREwKRA@mail.gmail.com>
References: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>
 <CAGxFJbQC3m8-x9gX9c=1kKFMqDH3c5wbzL35Dvxa6-LgHnR8oA@mail.gmail.com>
 <CAGxFJbTOMvi=C50mrHFO7YVGRr7sZBbWhEKgv374OATZREwKRA@mail.gmail.com>
Message-ID: <23403.4790.687877.63875@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Wed, 8 Aug 2018 08:21:05 -0700 writes:

    > (From Jeff Newmiller) "My advice is to enter one line of
    > each example at a time and study what it does before
    > proceeding to the next line. Copying whole swathes of code
    > and marveling at the result is exhilarating but ultimately
    > leaves you handicapped in creating your own code."

    > Fortune nomination!

seconded!
Martin

    > Cheers, Bert

    > Bert Gunter


From b@rowling@on @ending from l@nc@@ter@@c@uk  Wed Aug  8 18:10:30 2018
From: b@rowling@on @ending from l@nc@@ter@@c@uk (Barry Rowlingson)
Date: Wed, 8 Aug 2018 17:10:30 +0100
Subject: [R] security using R at work
In-Reply-To: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
References: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
Message-ID: <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>

On Wed, Aug 8, 2018 at 4:09 PM, Laurence Clark
<Laurence.Clark at healthmanltd.com> wrote:
> Hello all,
>
> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>
> My question is:
>
> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security.

> Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?

You are talking mostly to statisticians here, and if p>0 then there's
"a chance". I'd say yes, there's a chance, but its pretty small, and
would only occur through stupidity, accident or malice.

 In the ordinary course of things your data will be on your hard disk,
or on your corporate network drives, and only exist between your
corporate network server and your PC's memory. R will load the data
into that memory, do stuff with it in that memory, and write results
back to hard disk. Nothing leaves the network this way.

However... R has facilities for talking to the internet. You can save
data to google docs spreadsheets, for example, but you'd have to be
signed in to google, and have to type something like:

 > writeGoogleDoc(my_data, "secretdata.xls")

that covers "stupid". You should know that google docs are on google's
servers, and google's servers aren't on your network, and your secret
data shouldn't go on google's servers.

Accidents happen. You might be working on non-secret data which you
want to save to google docs, and accidentally save "data1" which is
secret instead of "data2" which is okay to be public. Oops. You sent
it to google. Accidents happen.

"malice" would be if someone had put code into R or an add-on package
that you use that sends your data over the network without you
knowing. For example maybe every time you fit a linear model with:

 lm(age~beauty, data=people)

R could be transmitting the data to hackers. But the chance of this is
very small, and I don't think any malicious code has ever been
discovered in R or the 12000 add-on packages downloadable from CRAN.
Doesn't mean it hasn't been discovered yet or won't be in the future.

It used to be said that the only machine safe from hackers was one
unplugged from the network. But now hackers can get to your machine
via malicious USB sticks, keyboard loggers, and various other nasties.
The only machine safe from hackers is one with the power off. But take
the power plug out because a wake-on-lan packet could switch your
machine on remotely....

Barry







> Thank you
>
> Laurence
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> Laurence Clark
> Business Data Analyst
> Account Management
> Health Management Ltd
>
> Mobile:                 07584 556498
> Switchboard:    0845 504 1000
> Email:          Laurence.Clark at healthmanltd.com
> Web:            www.healthmanagement.co.uk
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ, United Kingdom.</font>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> #####################################################################################
> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
> Download a free evaluation of MailMarshal at www.m86security.com
> #####################################################################################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Aug  8 18:17:16 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 8 Aug 2018 09:17:16 -0700 (PDT)
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <alpine.LNX.2.20.1808080912520.1236@salmo.appl-ecosys.com>

On Wed, 8 Aug 2018, Laurence Clark wrote:

> I want to download R and use it for work purposes. I hope to use it to
> analyse very sensitive data from our clients.

Laurence,

   Good choice.

> My question is:
>
> If I install R on my work network computer, will the data ever leave our
> network? I need to know if the data goes anywhere other than our network,
> because this could compromise it's security. Is there is any chance the
> data could go to a server owned by 'R' or anything else that's not
> immediately obvious, but constitutes the data leaving our network?

   Your sensitive data are no more, and no less, secure than any other data
on your desktop computer or the company's network. Assuming company
personnel and payroll data are on your local network, and proposals written
with Microsoft's tools are happily created by employees, then your client
data are equally secure (or at risk) regardless of the application used on
them. This is a network security issue, not an R issue.

Rich


From d@vid@mi @ending from micro@oft@com  Wed Aug  8 18:35:55 2018
From: d@vid@mi @ending from micro@oft@com (David Smith (CDA))
Date: Wed, 8 Aug 2018 16:35:55 +0000
Subject: [R] Revolutions blog: July 2018 roundup
Message-ID: <DM5PR2101MB10486A1008E5DE26BA43BE9BC8260@DM5PR2101MB1048.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of July:

R package authors validate quality and security for their packages with the
Linux Foundation's CII Best Practices Badge Program:
http://blog.revolutionanalytics.com/2018/07/cii-certification-for-r-packages.html

R scripts to generate images in the style of famous artworks, like Mondrian's:
http://blog.revolutionanalytics.com/2018/07/art-with-code.html

A 6-minute video tour of the AI and Machine Learning services in Azure,
including R:
http://blog.revolutionanalytics.com/2018/07/a-quick-tour-of-ai-services-in-azure.html

The July roundup of AI, Machine Learning and Data Science news:
http://blog.revolutionanalytics.com/2018/07/ai-roundup-july-2018.html

An R package used to tile hexagons, used to create a striking banner of hex
stickers for useR!2018:
http://blog.revolutionanalytics.com/2018/07/user-2017-hexwall.html

Highlights and links to videos from the useR!2018 conference:
http://blog.revolutionanalytics.com/2018/07/user-2018-recap.html

Video and R scripts from my workshop on creating an app to detect images of
hotdogs: http://blog.revolutionanalytics.com/2018/07/r-for-ai-video.html

Microsoft has released a number of open data sets produced from its research
programs: http://blog.revolutionanalytics.com/2018/07/msr-open-data.html

R 3.5.1 has been released:
http://blog.revolutionanalytics.com/2018/07/r-351-update-now-available-.html

And some general interest stories (not necessarily related to R):

* An app to visualize the distribution of street orientations in cities:
  http://blog.revolutionanalytics.com/2018/07/because-its-friday-urban-planning-fight.html

* A TED talk explores the link between spoken language and the way we think:
  http://blog.revolutionanalytics.com/2018/07/because-its-friday-language-and-thought.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From Bill@Poling @ending from zeli@@com  Wed Aug  8 18:35:57 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 8 Aug 2018 16:35:57 +0000
Subject: [R] Help with finalfit and knitr
In-Reply-To: <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>
References: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>
Message-ID: <CY1PR0201MB183443FCB40C6EAA676B4D0CEA260@CY1PR0201MB1834.namprd02.prod.outlook.com>

Wow, thank you Jeff, that?s got it!

explanatory = c("ProductName", "AgeCat", "PatientGender","RevCodeCats")
 View(explanatory)
dependent = "BinaryAccSav" # ---------------------------------------------------- AcceptedSavings AcceptedSavings 1=Y 0=N
View(dependent)
df6 %>% summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE) -> t1
View(t1)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

WHP


From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Wednesday, August 08, 2018 11:07 AM
To: r-help at r-project.org; Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with finalfit and knitr

R syntax does not allow for objects to be plopped next to each other separated by a space. There should be a newline after the t1 variable. This kind of problem plagues people copying HTML into emails on this mailing list (losing newlines), and was probably introduced into your code during a copy-paste as well.

There is no package called "kable"... that is a function in the knitr package.

My advice is to enter one line of each example at a time and study what it does before proceeding to the next line. Copying whole swathes of code and marveling at the result is exhilarating but ultimately leaves you handicapped in creating your own code.

On August 8, 2018 6:49:18 AM PDT, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>Hi using some of my own data I am trying to reproduce examples from
>this tutorial:
>
>https://cran.r-project.org/web/packages/finalfit/vignettes/finalfit_basics.html<https://cran.r-project.org/web/packages/finalfit/vignettes/finalfit_basics.html>
>
>Here are my sys info:
>R version 3.5.1 (2018-07-02)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows Server >= 2012 x64 (build 9200)
>
>Here is my data structure:
>str(df6)
># 'data.frame': 78407 obs. of 6 variables:
># $ ProductName : Factor w/ 2 levels "Editing","OON": 2 2 2 2 2 2
>2 2 2 2 ...
># $ RevCodeCats : Factor w/ 20 levels "BHAccomodations",..: 10 10 12
>12 8 8 12 20 8 19 ...
># $ AgeCat : Factor w/ 10 levels "[>80]","[0-5]",..: 9 9 5 5 7
>4 7 7 7 9 ...
># $ PatientGender : Factor w/ 3 levels "F","M","U": 2 2 2 2 2 1 1 1 1
>1 ...
># $ AcceptedSavings: num 0 0 0 0 48.9 ...
># $ BinaryAccSav : Factor w/ 2 levels "0","1": 1 1 1 1 2 2 2 2 2 2
>...
>
>Here is my call:
>
>explanatory = c("ProductName", "AgeCat", "PatientGender")
>dependent = "BinaryAccSav"
>#-------------------------------------------------------
>AcceptedSavings 1=Y 0=N
>df6 %>% finalfit(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE) -> t1 knitr::kable(t1, row.names=FALSE,
>align=c("l", "l", "r", "r", "r"))
>
>Here is the error:
>#Error: unexpected symbol in " df6 %>% finalfit(dependent,
>explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr"
>
>The error is identifying the knitr::kable(t1, row.names=FALSE,
>align=c("l", "l", "r", "r", "r")) as the problem
>
>I believe I have copied the procedure correctly from the tutorial and
>replaced the tutorial variables with mine.
>
>Libraries I believe are necessary:
>library("knitr", lib.loc="~/R/win-library/3.5")
>library("rmarkdown", lib.loc="~/R/win-library/3.5")
>library("htmlTable", lib.loc="~/R/win-library/3.5")
>
>And I see --Warning in install.packages : package 'kable' is not
>available (for R version 3.5.1) which I believe is my problem?
>
>
> 1. can my hunch be validated by someone please?
> 2. Is there a solution for this?
> 3. or do I contact the package authors directly?
>
>Thank you all!
>
>WHP
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:15}}
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Wed Aug  8 18:52:07 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Wed, 8 Aug 2018 17:52:07 +0100
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <0d7366e7965c471dbea4a9100cef391c@GBDCVPEXC08.corp.lgc-group.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
 <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
 <23402.53069.24933.691484@stat.math.ethz.ch>
 <0d7366e7965c471dbea4a9100cef391c@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <5B6B1FB7.2070309@sapo.pt>

Hello,

There are now three solutions to the OP's problem.
I have timed them and the results depend on the matrix size.

The solution I thought would be better, Enrico's diag(), is in fact the 
slowest. As for the other two, Eric's for loop is 50% fastest than the 
matrix index for small matrices but its relative performance degrades as 
the matrix becomes bigger and bigger.


library(microbenchmark)

#Enrico Schumann
mkMat_diag <- function(nr = 5, nc = 7) {
     M <- matrix(0, nr, nc)
     diag(M) <- -1
     diag(M[, -1]) <- 1
     M
}

#Eric Berger
mkMat_loop <- function(nr = 5, nc = 7) {
     M <- matrix(0, nr, nc)
     for(i in 2:nrow(M)) {
        M[i - 1, i - 1] <- -1
        M[i - 1, i] <- 1
     }
     M
}


#S.Ellison
mkMat_index <- function(nr = 5, nc = 7) {
    M <- matrix(0, nr, nc)
    i <- 1:min(nr, nc)
    j <- i[i < nc]
    M[ cbind(i, i) ] <- -1
    M[ cbind(j, j + 1) ] <- 1
    M
}



microbenchmark(
     loop = mkMat_loop(),
     index = mkMat_index(),
     diag = mkMat_diag(),
     times = 1e3
)


microbenchmark(
     loop = mkMat_loop(50, 70),
     index = mkMat_index(50, 70),
     diag = mkMat_diag(50, 70)
)


microbenchmark(
     loop = mkMat_loop(500, 700),
     index = mkMat_index(500, 700),
     diag = mkMat_diag(500, 700)
)


Hope this helps,

Rui Barradas

On 08/08/2018 12:59, S Ellison wrote:
>
>>>>>>> Eric Berger    on Wed, 8 Aug 2018 12:53:32 +0300 writes:
>>
>>> You only need one "for loop"
>>> for(i in 2:nrow(myMatrix)) {
>>>     myMatrix[i-1,i-1] = -1
>>>     myMatrix[i-1,i] = 1
>>> }
>
> Or none, with matrix-based array indexing and explicit control of the indices to prevent overrun in :
>
> mkMat <- function(n=5, m=7) {
>     M <- matrix(0, n,m)
>     i <- 1:min(n,m)
>     j <- i[i<m]
>     M[ cbind(i,i) ] <- -1
>     M[ cbind(j, j+1) ] <- 1
>     M
> }
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@herry8 @ending from comc@@t@net  Wed Aug  8 18:40:25 2018
From: r@herry8 @ending from comc@@t@net (rsherry8)
Date: Wed, 8 Aug 2018 12:40:25 -0400
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <5B6B1CF9.3090005@comcast.net>

I consider R to be secure. It is possible, but very unlikely, that there 
are some back door traps in R where somebody could access your data. 
There is no software that is 100% secure and R is not 100% secure.

Bob

On 8/8/2018 11:09 AM, Laurence Clark wrote:
> Hello all,
>
> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>
> My question is:
>
> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security. Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?
>
> Thank you
>
> Laurence
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> Laurence Clark
> Business Data Analyst
> Account Management
> Health Management Ltd
>
> Mobile: 		07584 556498
> Switchboard: 	0845 504 1000
> Email: 		Laurence.Clark at healthmanltd.com
> Web: 		www.healthmanagement.co.uk
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ, United Kingdom.</font>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> #####################################################################################
> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
> Download a free evaluation of MailMarshal at www.m86security.com
> #####################################################################################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From fr@nci@@bo@teng @ending from ver@@ntphy@ic@@com  Thu Aug  9 00:42:04 2018
From: fr@nci@@bo@teng @ending from ver@@ntphy@ic@@com (Francis Boateng)
Date: Wed, 8 Aug 2018 22:42:04 +0000
Subject: [R] exponential day
Message-ID: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>

Hi,
Please, how can I determine parameters from exponential equation
Example one:  y = a*exp(-b*x);  how do I determine ?a? and ?b?, as well as R-square from data sets. And also fitting y = a*exp(-b*x) into the data sets
Assuming data sets
A = (0,2,4,6,8,10)
B = (1,0.8,0.6,0.4,0.2,0.1)

Thanks
Francis


Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]


From R@iner @ending from krug@@de  Thu Aug  9 09:17:06 2018
From: R@iner @ending from krug@@de (Rainer M Krug)
Date: Thu, 9 Aug 2018 09:17:06 +0200
Subject: [R] security using R at work
In-Reply-To: <5B6B1CF9.3090005@comcast.net>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
 <5B6B1CF9.3090005@comcast.net>
Message-ID: <80F1EB77-A6B0-4B42-9459-93958E7FC41C@krugs.de>

This can likely be answered for R itself, but R itself (without additional packages) is very limited. As soon as you install packages, it all depends on the package you install and if you trust the authors of these packages.

As far as I know, there is no code checking for security on CRAN (please correct me if I am wrong!).

The advantage of R and open source: you can always look into the source code and see yourself.

And as this can be done, and R is not written by a single person or company, the likelihood of a backdoor in R is very very low (lower than in many commercial products I would say).

Cheers,

Rainer


> On 8 Aug 2018, at 18:40, rsherry8 <rsherry8 at comcast.net> wrote:
> 
> I consider R to be secure. It is possible, but very unlikely, that there are some back door traps in R where somebody could access your data. There is no software that is 100% secure and R is not 100% secure.
> 
> Bob
> 
> On 8/8/2018 11:09 AM, Laurence Clark wrote:
>> Hello all,
>> 
>> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>> 
>> My question is:
>> 
>> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security. Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?
>> 
>> Thank you
>> 
>> Laurence
>> 
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> Laurence Clark
>> Business Data Analyst
>> Account Management
>> Health Management Ltd
>> 
>> Mobile: 		07584 556498
>> Switchboard: 	0845 504 1000
>> Email: 		Laurence.Clark at healthmanltd.com
>> Web: 		www.healthmanagement.co.uk
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester,
> Leicestershire, LE19 1WZ, United Kingdom.</font>
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> 
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> 
>> 
>> #####################################################################################
>> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
>> Download a free evaluation of MailMarshal at www.m86security.com
>> #####################################################################################
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180809/84663dec/attachment.sig>

From R@iner @ending from krug@@de  Thu Aug  9 09:19:23 2018
From: R@iner @ending from krug@@de (Rainer M Krug)
Date: Thu, 9 Aug 2018 09:19:23 +0200
Subject: [R] security using R at work
In-Reply-To: <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>
References: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>
Message-ID: <5ABC8474-E080-438A-8D9D-6E7B69F5F438@krugs.de>

I can not agree more, Barry. Very nicely put.

Rainer


> On 8 Aug 2018, at 18:10, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> 
> On Wed, Aug 8, 2018 at 4:09 PM, Laurence Clark
> <Laurence.Clark at healthmanltd.com> wrote:
>> Hello all,
>> 
>> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>> 
>> My question is:
>> 
>> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security.
> 
>> Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?
> 
> You are talking mostly to statisticians here, and if p>0 then there's
> "a chance". I'd say yes, there's a chance, but its pretty small, and
> would only occur through stupidity, accident or malice.
> 
> In the ordinary course of things your data will be on your hard disk,
> or on your corporate network drives, and only exist between your
> corporate network server and your PC's memory. R will load the data
> into that memory, do stuff with it in that memory, and write results
> back to hard disk. Nothing leaves the network this way.
> 
> However... R has facilities for talking to the internet. You can save
> data to google docs spreadsheets, for example, but you'd have to be
> signed in to google, and have to type something like:
> 
>> writeGoogleDoc(my_data, "secretdata.xls")
> 
> that covers "stupid". You should know that google docs are on google's
> servers, and google's servers aren't on your network, and your secret
> data shouldn't go on google's servers.
> 
> Accidents happen. You might be working on non-secret data which you
> want to save to google docs, and accidentally save "data1" which is
> secret instead of "data2" which is okay to be public. Oops. You sent
> it to google. Accidents happen.
> 
> "malice" would be if someone had put code into R or an add-on package
> that you use that sends your data over the network without you
> knowing. For example maybe every time you fit a linear model with:
> 
> lm(age~beauty, data=people)
> 
> R could be transmitting the data to hackers. But the chance of this is
> very small, and I don't think any malicious code has ever been
> discovered in R or the 12000 add-on packages downloadable from CRAN.
> Doesn't mean it hasn't been discovered yet or won't be in the future.
> 
> It used to be said that the only machine safe from hackers was one
> unplugged from the network. But now hackers can get to your machine
> via malicious USB sticks, keyboard loggers, and various other nasties.
> The only machine safe from hackers is one with the power off. But take
> the power plug out because a wake-on-lan packet could switch your
> machine on remotely....
> 
> Barry
> 
> 
> 
> 
> 
> 
> 
>> Thank you
>> 
>> Laurence
>> 
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> Laurence Clark
>> Business Data Analyst
>> Account Management
>> Health Management Ltd
>> 
>> Mobile:                 07584 556498
>> Switchboard:    0845 504 1000
>> Email:          Laurence.Clark at healthmanltd.com
>> Web:            www.healthmanagement.co.uk
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester,
>  Leicestershire, LE19 1WZ, United Kingdom.</font>
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> 
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> 
>> 
>> #####################################################################################
>> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
>> Download a free evaluation of MailMarshal at www.m86security.com
>> #####################################################################################
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180809/cf997365/attachment.sig>

From m@rc_grt @ending from y@hoo@fr  Thu Aug  9 09:57:48 2018
From: m@rc_grt @ending from y@hoo@fr (Marc Girondot)
Date: Thu, 9 Aug 2018 09:57:48 +0200
Subject: [R] sub/grep question: extract year
Message-ID: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>

Hi everybody,

I have some questions about the way that sub is working. I hope that 
someone has the answer:

1/ Why the second example does not return an empty string ? There is no 
match.

subtext <- "-1980-"
sub(".*(1980).*", "\\1", subtext) # return 1980
sub(".*(1981).*", "\\1", subtext) # return -1980-

2/ Based on sub documentation, it replaces the first occurence of a 
pattern: why it does not return 1980 ?

subtext <- " 1980 1981 "
sub(".*(198[01]).*", "\\1", subtext) # return 1981

3/ I want extract year from text; I use:

subtext <- "bla 1980 bla"
sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) # 
return 1980
subtext <- "bla 2010 bla"
sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) # 
return 2010

but

subtext <- "bla 1010 bla"
sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) # 
return 1010

I would like exclude the case 1010 and other like this.

The solution would be:

18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]

Is there a solution to write such a pattern in grep ?

Thanks a lot

Marc


From rhelp @ending from eoo@@dd@@nl  Thu Aug  9 10:14:01 2018
From: rhelp @ending from eoo@@dd@@nl (Jan van der Laan)
Date: Thu, 9 Aug 2018 10:14:01 +0200
Subject: [R] security using R at work
In-Reply-To: <5ABC8474-E080-438A-8D9D-6E7B69F5F438@krugs.de>
References: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>
 <5ABC8474-E080-438A-8D9D-6E7B69F5F438@krugs.de>
Message-ID: <bed18a4a-c40c-06c2-e6b5-ae86de697080@eoos.dds.nl>

You can also inadvertently transmit data to the internet using a package 
without being obviously 'stupid', e.g. by using a package that uses an 
external service for data processing. For example, some javascript 
visualisation libs can do that (not sure if those wrapped in R-packages 
do), or, for example, a geocoding service.

Not having an (outgoing) internet connection at least helps against 
mistakes like this (and probably against many untargeted attacks). If it 
is allowed to have the sensitive data on that computer, using R on that 
computer is probably not going to make is less safe.

Jan


On 09-08-18 09:19, Rainer M Krug wrote:
> I can not agree more, Barry. Very nicely put.
> 
> Rainer
> 
> 
>> On 8 Aug 2018, at 18:10, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
>>
>> On Wed, Aug 8, 2018 at 4:09 PM, Laurence Clark
>> <Laurence.Clark at healthmanltd.com> wrote:
>>> Hello all,
>>>
>>> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>>>
>>> My question is:
>>>
>>> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security.
>>
>>> Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?
>>
>> You are talking mostly to statisticians here, and if p>0 then there's
>> "a chance". I'd say yes, there's a chance, but its pretty small, and
>> would only occur through stupidity, accident or malice.
>>
>> In the ordinary course of things your data will be on your hard disk,
>> or on your corporate network drives, and only exist between your
>> corporate network server and your PC's memory. R will load the data
>> into that memory, do stuff with it in that memory, and write results
>> back to hard disk. Nothing leaves the network this way.
>>
>> However... R has facilities for talking to the internet. You can save
>> data to google docs spreadsheets, for example, but you'd have to be
>> signed in to google, and have to type something like:
>>
>>> writeGoogleDoc(my_data, "secretdata.xls")
>>
>> that covers "stupid". You should know that google docs are on google's
>> servers, and google's servers aren't on your network, and your secret
>> data shouldn't go on google's servers.
>>
>> Accidents happen. You might be working on non-secret data which you
>> want to save to google docs, and accidentally save "data1" which is
>> secret instead of "data2" which is okay to be public. Oops. You sent
>> it to google. Accidents happen.
>>
>> "malice" would be if someone had put code into R or an add-on package
>> that you use that sends your data over the network without you
>> knowing. For example maybe every time you fit a linear model with:
>>
>> lm(age~beauty, data=people)
>>
>> R could be transmitting the data to hackers. But the chance of this is
>> very small, and I don't think any malicious code has ever been
>> discovered in R or the 12000 add-on packages downloadable from CRAN.
>> Doesn't mean it hasn't been discovered yet or won't be in the future.
>>
>> It used to be said that the only machine safe from hackers was one
>> unplugged from the network. But now hackers can get to your machine
>> via malicious USB sticks, keyboard loggers, and various other nasties.
>> The only machine safe from hackers is one with the power off. But take
>> the power plug out because a wake-on-lan packet could switch your
>> machine on remotely....
>>
>> Barry
>>
>>
>>
>>
>>
>>
>>
>>> Thank you
>>>
>>> Laurence
>>>
>>>
>>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>> Laurence Clark
>>> Business Data Analyst
>>> Account Management
>>> Health Management Ltd
>>>
>>> Mobile:                 07584 556498
>>> Switchboard:    0845 504 1000
>>> Email:          Laurence.Clark at healthmanltd.com
>>> Web:            www.healthmanagement.co.uk
>>>
>>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester,
>>   Leicestershire, LE19 1WZ, United Kingdom.</font>
>>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>
>>>
>>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>
>>>
>>> #####################################################################################
>>> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
>>> Download a free evaluation of MailMarshal at www.m86security.com
>>> #####################################################################################
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
> 
> University of Z?rich
> 
> Cell:       +41 (0)78 630 66 57
> email:      Rainer at krugs.de
> Skype:      RMkrug
> 
> PGP: 0x0F52F982
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

From b@rowling@on @ending from l@nc@@ter@@c@uk  Thu Aug  9 10:25:03 2018
From: b@rowling@on @ending from l@nc@@ter@@c@uk (Barry Rowlingson)
Date: Thu, 9 Aug 2018 09:25:03 +0100
Subject: [R] security using R at work
In-Reply-To: <c8f6ca37d73f4b2bbfb64478775a6b08@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
References: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>
 <5ABC8474-E080-438A-8D9D-6E7B69F5F438@krugs.de>
 <c8f6ca37d73f4b2bbfb64478775a6b08@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CANVKczOoKLWm9GB+NGcFUpn=oZGXrYoxYp=Z61TRVwuyJ1nMig@mail.gmail.com>

On Thu, Aug 9, 2018 at 9:14 AM, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
> You can also inadvertently transmit data to the internet using a package
> without being obviously 'stupid', e.g. by using a package that uses an
> external service for data processing. For example, some javascript
> visualisation libs can do that (not sure if those wrapped in R-packages
> do), or, for example, a geocoding service.

 Ooh yes, that's probably a whole new category.  Maybe "Unwittingly"
describes this - it could be the users fault for not reading or
understanding the documentation or the package authors fault for not
documenting the network activity properly. Leave that one to the
lawyers to decide.

Barry


From poi@@on200 @ending from googlem@il@com  Thu Aug  9 10:44:31 2018
From: poi@@on200 @ending from googlem@il@com (john matthew)
Date: Thu, 9 Aug 2018 09:44:31 +0100
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <CA+b7HP1q4juNNXJ0JOR-g1+NjiDt4PrqMLjHUmHtn=q3_wszMA@mail.gmail.com>

Hello Laurence.
Taking a pragmatic approach.

If the data is so valuable and secret but also needs some analysis in R,
here is suggested steps to minimise security risks.

1. Plan the analysis up front, what exactly what you want and the outcomes.
2. Take a laptop with Internet, install R and all packages needed for the
planned analysis.
3. Unplug ethernet and turn off blue tooth and wifi. So no internet access
at all.
4. Bring your secret data via USB or cd.
5. Perform the R analysis and export reports and figures etc to safe place.
6. Delete R, the data and all packages from laptop before using online
again.

A bit extreme and may still be some risk but its minimal as the analysis
was done offline, and you removed R etc after. But now have a set of R
results.

Just an idea.

John.


On 8 Aug 2018 16:53, "Laurence Clark" <Laurence.Clark at healthmanltd.com>
wrote:

> Hello all,
>
> I want to download R and use it for work purposes. I hope to use it to
> analyse very sensitive data from our clients.
>
> My question is:
>
> If I install R on my work network computer, will the data ever leave our
> network? I need to know if the data goes anywhere other than our network,
> because this could compromise it's security. Is there is any chance the
> data could go to a server owned by 'R' or anything else that's not
> immediately obvious, but constitutes the data leaving our network?
>
> Thank you
>
> Laurence
>
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
> Laurence Clark
> Business Data Analyst
> Account Management
> Health Management Ltd
>
> Mobile:                 07584 556498
> Switchboard:    0845 504 1000
> Email:          Laurence.Clark at healthmanltd.com
> Web:            www.healthmanagement.co.uk
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole
> use of the intended recipients and may contain confidential and privileged
> information or otherwise be protected by law. Any unauthorised review, use,
> disclosure or distribution is prohibited. If you are not the intended
> recipient, please contact the sender, and destroy all copies and the
> original message.<BR><BR>MAXIMUS People Services Limited is registered in
> England and Wales (registered number: 03752300); registered office: 202 -
> 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health
> and Disability Assessments Ltd (registered number: 9072343) and Health
> Management Ltd (registered number: 4369949) are registered in England and
> Wales. The registered office for each is Ash House, The Broyle, Ringmer,
> East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in
> England and Wales (registered number: 09457025); registered office: 18c
> Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ,
> United Kingdom.</font>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
>
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
>
>
> ############################################################
> #########################
> Scanned by MailMarshal - M86 Security's comprehensive email content
> security solution.
> Download a free evaluation of MailMarshal at www.m86security.com
> ############################################################
> #########################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mi@ojpm @ending from gm@il@com  Thu Aug  9 10:58:14 2018
From: mi@ojpm @ending from gm@il@com (John)
Date: Thu, 9 Aug 2018 16:58:14 +0800
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
 <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
Message-ID: <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>

Hi,

   I try to run the same f-test by lm (with summary) and the function
"linearHypothesis" in car package. Why are the results (p-values for the
f-test) different?


> df1<-data.frame(x=c(2,3,4), y=c(7,6,8))
> lm1<-lm(y~x, df1)
> lm1

Call:
lm(formula = y ~ x, data = df1)

Coefficients:
(Intercept)            x
        5.5          0.5

> summary(lm1)

Call:
lm(formula = y ~ x, data = df1)

Residuals:
   1    2    3
 0.5 -1.0  0.5

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)    5.500      2.693   2.043    0.290
x              0.500      0.866   0.577    0.667

Residual standard error: 1.225 on 1 degrees of freedom
Multiple R-squared:   0.25, Adjusted R-squared:   -0.5
F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667

> linearHypothesis(lm1, c("(Intercept)=0", "x=0"))
Linear hypothesis test

Hypothesis:
(Intercept) = 0
x = 0

Model 1: restricted model
Model 2: y ~ x

  Res.Df   RSS Df Sum of Sq      F Pr(>F)
1      3 149.0
2      1   1.5  2     147.5 49.167 0.1003

2018-08-03 13:54 GMT+08:00 Annaert Jan <jan.annaert at uantwerpen.be>:

> You can easily test linear restrictions using the function
> linearHypothesis() from the car package.
> There are several ways to set up the null hypothesis, but a
> straightforward one here is:
>
> > library(car)
> > x <- rnorm(10)
> > y <- x+rnorm(10)
> > linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
> Linear hypothesis test
>
> Hypothesis:
> (Intercept) = 0
> x = 1
>
> Model 1: restricted model
> Model 2: y ~ x
>
>   Res.Df     RSS Df Sum of Sq      F Pr(>F)
> 1     10 10.6218
> 2      8  9.0001  2    1.6217 0.7207 0.5155
>
>
> Jan
>
> From: R-help <r-help-bounces at r-project.org> on behalf of John <
> miaojpm at gmail.com>
> Date: Thursday, 2 August 2018 at 10:44
> To: r-help <r-help at r-project.org>
> Subject: [R] F-test where the coefficients in the H_0 is nonzero
>
> Hi,
>
>    I try to run the regression
>    y = beta_0 + beta_1 x
>    and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
>    I believe I can run the regression
>    (y-x) = beta_0 +beta_1? x
>    and do the regular F-test (using lm functio) where the hypothesized
> coefficients are all zero.
>
>    Is there any function in R that deal with the case where the
> coefficients are nonzero?
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From m@rkleed@2 @ending from gm@il@com  Thu Aug  9 11:10:27 2018
From: m@rkleed@2 @ending from gm@il@com (Mark Leeds)
Date: Thu, 9 Aug 2018 05:10:27 -0400
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
 <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
 <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
Message-ID: <CAHz+bWYsk5_QikbM5P_2S9mrSCBtDwH6xAgLs-tMLtG+8Ua__w@mail.gmail.com>

Hi: the F-test is a joint hypothesis ( I never used that function from the
car package but it sounds like it is )  and the t-statistics
that come  out of a  regression are "conditional" in the sense that they
test the significance of one coefficient given the other so you wouldn't
expect the two outputs to be the same.




On Thu, Aug 9, 2018 at 4:58 AM, John <miaojpm at gmail.com> wrote:

> Hi,
>
>    I try to run the same f-test by lm (with summary) and the function
> "linearHypothesis" in car package. Why are the results (p-values for the
> f-test) different?
>
>
> > df1<-data.frame(x=c(2,3,4), y=c(7,6,8))
> > lm1<-lm(y~x, df1)
> > lm1
>
> Call:
> lm(formula = y ~ x, data = df1)
>
> Coefficients:
> (Intercept)            x
>         5.5          0.5
>
> > summary(lm1)
>
> Call:
> lm(formula = y ~ x, data = df1)
>
> Residuals:
>    1    2    3
>  0.5 -1.0  0.5
>
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)    5.500      2.693   2.043    0.290
> x              0.500      0.866   0.577    0.667
>
> Residual standard error: 1.225 on 1 degrees of freedom
> Multiple R-squared:   0.25, Adjusted R-squared:   -0.5
> F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667
>
> > linearHypothesis(lm1, c("(Intercept)=0", "x=0"))
> Linear hypothesis test
>
> Hypothesis:
> (Intercept) = 0
> x = 0
>
> Model 1: restricted model
> Model 2: y ~ x
>
>   Res.Df   RSS Df Sum of Sq      F Pr(>F)
> 1      3 149.0
> 2      1   1.5  2     147.5 49.167 0.1003
>
> 2018-08-03 13:54 GMT+08:00 Annaert Jan <jan.annaert at uantwerpen.be>:
>
> > You can easily test linear restrictions using the function
> > linearHypothesis() from the car package.
> > There are several ways to set up the null hypothesis, but a
> > straightforward one here is:
> >
> > > library(car)
> > > x <- rnorm(10)
> > > y <- x+rnorm(10)
> > > linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
> > Linear hypothesis test
> >
> > Hypothesis:
> > (Intercept) = 0
> > x = 1
> >
> > Model 1: restricted model
> > Model 2: y ~ x
> >
> >   Res.Df     RSS Df Sum of Sq      F Pr(>F)
> > 1     10 10.6218
> > 2      8  9.0001  2    1.6217 0.7207 0.5155
> >
> >
> > Jan
> >
> > From: R-help <r-help-bounces at r-project.org> on behalf of John <
> > miaojpm at gmail.com>
> > Date: Thursday, 2 August 2018 at 10:44
> > To: r-help <r-help at r-project.org>
> > Subject: [R] F-test where the coefficients in the H_0 is nonzero
> >
> > Hi,
> >
> >    I try to run the regression
> >    y = beta_0 + beta_1 x
> >    and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
> >    I believe I can run the regression
> >    (y-x) = beta_0 +beta_1? x
> >    and do the regular F-test (using lm functio) where the hypothesized
> > coefficients are all zero.
> >
> >    Is there any function in R that deal with the case where the
> > coefficients are nonzero?
> >
> > John
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_grt @ending from y@hoo@fr  Thu Aug  9 11:19:51 2018
From: m@rc_grt @ending from y@hoo@fr (Marc Girondot)
Date: Thu, 9 Aug 2018 11:19:51 +0200
Subject: [R] sub/grep question: extract year
In-Reply-To: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
References: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
Message-ID: <2c6cfa13-34e7-b327-2617-9c74ab25e45e@yahoo.fr>

I answer myself to the third point:
This pattern is better to get a year:

pattern.year <- ".*\\b(18|19|20)([0-9][0-9])\\b.*"

subtext <- "bla 1880 bla"
sub(pattern.year, "\\1\\2", subtext) # return 1880
subtext <- "bla 1980 bla"
sub(pattern.year, "\\1\\2", subtext) # return 1980
subtext <- "bla 2010 bla"
sub(pattern.year, "\\1\\2", subtext) # return 2010
subtext <- "bla 1010 bla"
sub(pattern.year, "\\1\\2", subtext) # return bla 1010 bla
subtext <- "bla 3010 bla"
sub(pattern.year, "\\1\\2", subtext) # return bla 3010 bla

Marc


Le 09/08/2018 ? 09:57, Marc Girondot via R-help a ?crit?:
> Hi everybody,
>
> I have some questions about the way that sub is working. I hope that 
> someone has the answer:
>
> 1/ Why the second example does not return an empty string ? There is 
> no match.
>
> subtext <- "-1980-"
> sub(".*(1980).*", "\\1", subtext) # return 1980
> sub(".*(1981).*", "\\1", subtext) # return -1980-
>
> 2/ Based on sub documentation, it replaces the first occurence of a 
> pattern: why it does not return 1980 ?
>
> subtext <- " 1980 1981 "
> sub(".*(198[01]).*", "\\1", subtext) # return 1981
>
> 3/ I want extract year from text; I use:
>
> subtext <- "bla 1980 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 1980
> subtext <- "bla 2010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 2010
>
> but
>
> subtext <- "bla 1010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 1010
>
> I would like exclude the case 1010 and other like this.
>
> The solution would be:
>
> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>
> Is there a solution to write such a pattern in grep ?
>
> Thanks a lot
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From poi@@on200 @ending from googlem@il@com  Thu Aug  9 11:36:36 2018
From: poi@@on200 @ending from googlem@il@com (john matthew)
Date: Thu, 9 Aug 2018 10:36:36 +0100
Subject: [R] sub/grep question: extract year
In-Reply-To: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
References: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
Message-ID: <CA+b7HP27j0uHjRdfPNnRSyDYqCp6a23wKe39uGWLaUc5a=P8FQ@mail.gmail.com>

Hi Marc.
For question 1.
I know in Perl that regular expressions when captured can be saved if not
overwritten. \\1 is the capture variable in your R examples.

So the 2nd regular expression does not match but \\1 still has 1980
captured from the previous expression, hence the result.

Maybe if you restart R and try your 2nd expression first, \\1 will be empty
or no match result.

Just speculation :)

John


On 9 Aug 2018 08:58, "Marc Girondot via R-help" <r-help at r-project.org>
wrote:

> Hi everybody,
>
> I have some questions about the way that sub is working. I hope that
> someone has the answer:
>
> 1/ Why the second example does not return an empty string ? There is no
> match.
>
> subtext <- "-1980-"
> sub(".*(1980).*", "\\1", subtext) # return 1980
> sub(".*(1981).*", "\\1", subtext) # return -1980-
>
> 2/ Based on sub documentation, it replaces the first occurence of a
> pattern: why it does not return 1980 ?
>
> subtext <- " 1980 1981 "
> sub(".*(198[01]).*", "\\1", subtext) # return 1981
>
> 3/ I want extract year from text; I use:
>
> subtext <- "bla 1980 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
> return 1980
> subtext <- "bla 2010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
> return 2010
>
> but
>
> subtext <- "bla 1010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
> return 1010
>
> I would like exclude the case 1010 and other like this.
>
> The solution would be:
>
> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>
> Is there a solution to write such a pattern in grep ?
>
> Thanks a lot
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@yur@t@de @ending from gm@il@com  Thu Aug  9 08:20:06 2018
From: m@yur@t@de @ending from gm@il@com (Mayur Tade)
Date: Thu, 9 Aug 2018 11:50:06 +0530
Subject: [R] error with the expand.grid command
Message-ID: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>

 hello sir...
i am trying to extract the chlorophyll data of particular lat and lon from
the world chlorophyll data from the netcdf file in R. as i am new to R i am
facing the problem related to it when i am trying expand.grid command it is
showing me this message.....message is followed.....its my kind request
please help me with the same
ttt<-expand.grid(lon,lat,time)
Error in paste0(nmc[i], "=", if (is.numeric(x)) format(x) else x) :
  cannot coerce type 'closure' to vector of type 'character'

here is the print of my netcdf file for you kind information.....follow...

> print(tt)
File E:\chlorophyll data research student..mayur
t..KUFOS\1997\ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_
GEO_PML_OCx-199709-fv3.1.nc
<http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
(NC_FORMAT_NETCDF4_CLASSIC):

     9 variables (excluding dimension variables):
        float MERIS_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the number of observations from the MERIS
sensor contributing to this bin cell
            number_of_files_composited: 19
        float MODISA_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the number of observations from the MODIS
(Aqua) sensor contributing to this bin cell
            number_of_files_composited: 19
        float SeaWiFS_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the number of observations from the SeaWiFS
(GAC and LAC) sensor contributing to this bin cell
            number_of_files_composited: 19
        float VIIRS_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the number of observations from the VIIRS
sensor contributing to this bin cell
            number_of_files_composited: 19
        float chlor_a[lon,lat,time]
            _FillValue: 9.96920996838687e+36
            long_name: Chlorophyll-a concentration in seawater (not
log-transformed), generated by SeaDAS using a blended combination of OCI
(OC4v6 + Hu's CI), OC3 and OC5, depending on water class memberships
            units: milligram m-3
            ancillary_variables: chlor_a_log10_rmsd chlor_a_log10_bias
            grid_mapping: crs
            standard_name: mass_concentration_of_chlorophyll_a_in_sea_water
            units_nonstandard: mg m^-3
            parameter_vocab_uri:
http://vocab.nerc.ac.uk/collection/P04/current/
        float chlor_a_log10_bias[lon,lat,time]
            _FillValue: 9.96920996838687e+36
            long_name: Bias of log10-transformed chlorophyll-a concentration
in seawater.
            grid_mapping: crs
            rel: uncertainty
            comment: Uncertainty lookups derived from file:
/data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
cci_chla_bias.dat
            ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
        float chlor_a_log10_rmsd[lon,lat,time]
            _FillValue: 9.96920996838687e+36
            long_name: Root-mean-square-difference of log10-transformed
chlorophyll-a concentration in seawater.
            grid_mapping: crs
            rel: uncertainty
            comment: Uncertainty lookups derived from file:
/data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
cci_chla_rmsd.dat
            ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
        int crs[time]
            grid_mapping_name: latitude_longitude
        float total_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the total number of observations
contributing to this bin cell
            number_of_files_composited: 19

     3 dimensions:
        time  Size:1
            axis: T
            standard_name: time
            units: days since 1970-01-01 00:00:00
        lat  Size:4320
            units: degrees_north
            long_name: latitude
            standard_name: latitude
            valid_min: -89.9791641235352
            valid_max: 89.9791641235352
            axis: Y
        lon  Size:8640
            units: degrees_east
            long_name: longitude
            standard_name: longitude
            valid_min: -179.97917175293
            valid_max: 179.97917175293
            axis: X

    47 global attributes:
        Metadata_Conventions: Unidata Dataset Discovery v1.0
        cdm_data_type: Grid
        comment: See summary attribute
        creator_email: help at esa-oceancolour-cci.org
        creator_name: Plymouth Marine Laboratory
        creator_url: http://esa-oceancolour-cci.org
        geospatial_lat_max: 90
        geospatial_lat_min: -90
        geospatial_lat_resolution: .04166666666666666666
        geospatial_lat_units: decimal degrees north
        geospatial_lon_max: 180
        geospatial_lon_min: -180
        geospatial_lon_resolution: .04166666666666666666
        geospatial_lon_units: decimal degrees east
        geospatial_vertical_max: 0
        geospatial_vertical_min: 0
        institution: Plymouth Marine Laboratory
        keywords: satellite,observation,ocean,ocean colour
        keywords_vocabulary: none
        license: ESA CCI Data Policy: free and open access.  When
referencing, please use: Ocean Colour Climate Change Initiative dataset,
Version <Version Number>, European Space Agency, available online at
http://www.esa-oceancolour-cci.org.  We would also appreciate being notified
of publications so that we can list them on the project website at
http://www.esa-oceancolour-cci.org/?q=publications
        naming_authority: uk.ac.pml
        number_of_optical_water_types: 14
        platform: Orbview-2,Aqua,Envisat,Suomi-NPP
        processing_level: Level-3
        project: Climate Change Initiative - European Space Agency
        references: http://www.esa-oceancolour-cci.org/
        sensor: SeaWiFS,MODIS,MERIS,VIIRS
        source: NASA SeaWiFS L2 R2014.0 LAC and GAC, MODIS-Aqua L1A, MERIS
L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L2 R2014.0.1 (data
identical to R2014.0.2)
        spatial_resolution: 4km nominal at equator
        standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata
Conventions Version 1.6
        title: ESA CCI Ocean Colour Product
        number_of_files_composited: 19
        creation_date: Tue Aug 23 09:00:23 2016
        date_created: Tue Aug 23 09:00:23 2016
        time_coverage_resolution: P1M
        time_coverage_duration: P1M
        start_date: 01-SEP-1997 00:00:00.000000
        stop_date: 30-SEP-1997 23:59:00.000000
        time_coverage_start: 199709010000Z
        time_coverage_end: 199709302359Z
        netcdf_file_type: NETCDF4_CLASSIC
        history: Source data were:
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970904-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970904-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970906-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970906-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970909-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970909-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970910-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970910-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970915-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970915-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970916-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970916-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970918-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970918-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970919-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970919-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970920-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970920-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970921-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970921-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970922-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970922-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970923-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970923-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970924-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970924-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970925-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970925-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970926-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970926-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970927-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970927-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970928-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970928-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970929-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970929-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970930-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970930-fv3.1.nc/>
;
netcdf_compositor_cci composites  Rrs_412, Rrs_443, Rrs_490, Rrs_510,
Rrs_555, Rrs_670, water_class1, water_class2, water_class3, water_class4,
water_class5, water_class6, water_class7, water_class8, water_class9,
water_class10, water_class11, water_class12, water_class13, water_class14,
atot_412, atot_443, atot_490, atot_510, atot_555, atot_670, aph_412,
aph_443, aph_490, aph_510, aph_555, aph_670, adg_412, adg_443, adg_490,
adg_510, adg_555, adg_670, bbp_412, bbp_443, bbp_490, bbp_510, bbp_555,
bbp_670, chlor_a, kd_490, chlor_a_log10_bias, Rrs_412_bias, Rrs_443_bias,
Rrs_490_bias, Rrs_510_bias, Rrs_555_bias, Rrs_670_bias, aph_412_bias,
aph_443_bias, aph_490_bias, aph_510_bias, aph_555_bias, aph_670_bias,
adg_412_bias, adg_443_bias, adg_490_bias, adg_510_bias, adg_555_bias,
adg_670_bias, kd_490_bias with --mean,  chlor_a_log10_rmsd, Rrs_412_rmsd,
Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_555_rmsd, Rrs_670_rmsd,
aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_555_rmsd,
aph_670_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd,
adg_555_rmsd, adg_670_rmsd, kd_490_rmsd with --root-mean-square, and
SeaWiFS_nobs, MODISA_nobs, MERIS_nobs, VIIRS_nobs, total_nobs - with --total
1471940520 Subsetted from
standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_
MONTHLY_4km_GEO_PML_OCx_QAA-199709-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1m_monthly_4km_geo_pml_ocx_qaa-199709-fv3.1.nc/>
to only include variables
MERIS_nobs_sum,MODISA_nobs_sum,SeaWiFS_nobs_sum,VIIRS_
nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,
crs,lat,lon,time,total_nobs_sum
        Conventions: CF-1.6
        product_version: 3.1
        summary: Data products generated by the Ocean Colour component of
the European Space Agency Climate Change Initiative project. These files are
daily composites of merged sensor (MERIS, MODIS Aqua, SeaWiFS LAC & GAC,
VIIRS) products.  MODIS Aqua and MERIS were band-shifted and bias-corrected
to SeaWiFS bands and values using a temporally and spatially varying scheme
based on the overlap years of 2003-2007.  VIIRS was band-shifted and
bias-corrected in a second stage against the MODIS Rrs that had already been
corrected to SeaWiFS levels, for the overlap period 2012-2013.  VIIRS and
SeaWiFS Rrs were derived from standard NASA L2 products; MERIS and MODIS
from a combination of NASA's l2gen (for basic sensor geometry corrections,
etc) and HYGEOS Polymer v3.5 (for atmospheric correction).  The Rrs were
binned to a sinusoidal 4km level-3 grid, and later to 4km geographic
projection, by Brockmann Consult's BEAM.  Derived products were generally
computed with the standard SeaDAS algorithms.  QAA IOPs were derived using
the standard SeaDAS algorithm but with a modified backscattering table to
match that used in the bandshifting.  The final chlorophyll is a combination
of OC4, Hu's CI and OC5, depending on the water class memberships.
Uncertainty estimates were added using the fuzzy water classifier and
uncertainty estimation algorithm of Tim Moore as documented in Jackson et al
(2017).
        tracking_id: 659b397a-953c-4814-a3e2-460d6218fcfa
        id:
ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-199709-fv3.1.nc
<http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>

	[[alternative HTML version deleted]]


From K@th@rin@@Frit@ch @ending from nnl@co@uk  Thu Aug  9 10:24:15 2018
From: K@th@rin@@Frit@ch @ending from nnl@co@uk (Fritsch, Katharina (NNL))
Date: Thu, 9 Aug 2018 08:24:15 +0000
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <1B674C66F0DD4343BA5DD0C025217F9F02270AAD@CSSPWD2PRAP1147.SSA-Intra.net>

Hiya,
I work in a very security conscious organisation and we happily use R. The average user can only use R via RStudio Server, with a limited number of packages available, so that adds an additional level of control.
That said, are you sure that the sentence 'a few people on a mailing list said it would be alright' is going to convince your IT department of the harmlessness of R?
Cheers,
Katharina.

--

Dr Katharina Fritsch B.Sc. M.Sc. MRSC
Chemical Modeller, Chemical and Process Modelling


E.
katharina.fritsch at nnl.co.uk
T.
+44 (0)1925 289387
@uknnl

National Nuclear Laboratory Limited, 5th Floor, Chadwick House,
Birchwood Park, Warrington, WA3 6AE, UK

www.nnl.co.uk


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Laurence Clark
Sent: 08 August 2018 16:10
To: 'r-help at r-project.org'
Subject: [R] security using R at work

Hello all,

I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.

My question is:

If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security. Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?

Thank you

Laurence


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Laurence Clark
Business Data Analyst
Account Management
Health Management Ltd

Mobile:                 07584 556498
Switchboard:    0845 504 1000
Email:          Laurence.Clark at healthmanltd.com
Web:            BLOCKEDhealthmanagement[.]co[.]ukBLOCKED

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ, United Kingdom.</font>
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


#####################################################################################
Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
Download a free evaluation of MailMarshal at BLOCKEDm86security[.]comBLOCKED
#####################################################################################

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
BLOCKEDstat[.]ethz[.]ch/mailman/listinfo/r-helpBLOCKED
PLEASE do read the posting guide BLOCKEDR-project[.]org/posting-guide[.]htmlBLOCKED
and provide commented, minimal, self-contained, reproducible code.
*****************************************************************************
This message was received by the Cloud Security Email Gateway

and was checked for Viruses and SPAM by the Cloud Security Email Management Service.
Please forward any suspicious or unwanted emails to "Spam Helpdesk"
*****************************************************************************


This e-mail is from National Nuclear Laboratory Limited ("NNL"). This e-mail and any attachments are intended for the addressee and may also be legally privileged. If you are not the intended recipient please do not print, re-transmit, store or act in reliance on it or any attachments. Instead, please e-mail it back to the sender and then immediately permanently delete it.

National Nuclear Laboratory Limited (Company number 3857752) Registered in England and Wales. Registered office: Chadwick House, Warrington Road, Birchwood Park, Warrington, WA3 6AE.


From m@rc@girondot @ending from u-p@ud@fr  Thu Aug  9 11:17:28 2018
From: m@rc@girondot @ending from u-p@ud@fr (Marc Girondot)
Date: Thu, 9 Aug 2018 11:17:28 +0200
Subject: [R] sub/grep question: extract year
In-Reply-To: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
References: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
Message-ID: <43e498eb-21e7-605a-f58c-dc66fec49fb2@u-psud.fr>

I answer myself to the third point:
This pattern is better :

pattern.year <- ".*\\b(18|19|20)([0-9][0-9])\\b.*"

subtext <- "bla 1880 bla"
sub(pattern.year, "\\1\\2", subtext) # return 1880
subtext <- "bla 1980 bla"
sub(pattern.year, "\\1\\2", subtext) # return 1980
subtext <- "bla 2010 bla"
sub(pattern.year, "\\1\\2", subtext) # return 2010
subtext <- "bla 1010 bla"
sub(pattern.year, "\\1\\2", subtext) # return bla 1010 bla
subtext <- "bla 3010 bla"
sub(pattern.year, "\\1\\2", subtext) # return bla 3010 bla

Marc

Le 09/08/2018 ? 09:57, Marc Girondot via R-help a ?crit?:
> Hi everybody,
>
> I have some questions about the way that sub is working. I hope that 
> someone has the answer:
>
> 1/ Why the second example does not return an empty string ? There is 
> no match.
>
> subtext <- "-1980-"
> sub(".*(1980).*", "\\1", subtext) # return 1980
> sub(".*(1981).*", "\\1", subtext) # return -1980-
>
> 2/ Based on sub documentation, it replaces the first occurence of a 
> pattern: why it does not return 1980 ?
>
> subtext <- " 1980 1981 "
> sub(".*(198[01]).*", "\\1", subtext) # return 1981
>
> 3/ I want extract year from text; I use:
>
> subtext <- "bla 1980 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 1980
> subtext <- "bla 2010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 2010
>
> but
>
> subtext <- "bla 1010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 1010
>
> I would like exclude the case 1010 and other like this.
>
> The solution would be:
>
> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>
> Is there a solution to write such a pattern in grep ?
>
> Thanks a lot
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
__________________________________________________________
Marc Girondot, Pr

Laboratoire Ecologie, Syst?matique et Evolution
Equipe de Conservation des Populations et des Communaut?s
CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
B?timent 362
91405 Orsay Cedex, France

Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
e-mail: marc.girondot at u-psud.fr
Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
Skype: girondot


From Achim@Zeilei@ @ending from uibk@@c@@t  Thu Aug  9 11:32:36 2018
From: Achim@Zeilei@ @ending from uibk@@c@@t (Achim Zeileis)
Date: Thu, 9 Aug 2018 11:32:36 +0200 (CEST)
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
 <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
 <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1808091129010.22455@paninaro>

On Thu, 9 Aug 2018, John wrote:

> Hi,
>
>   I try to run the same f-test by lm (with summary) and the function
> "linearHypothesis" in car package. Why are the results (p-values for the
> f-test) different?

The standard F test in the summary output tests the hypothesis that all 
coefficients _except the intercept_ are zero. Thus, all of these are the 
same:

summary(lm1)
## ...
## F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667

linearHypothesis(lm1, "x = 0")
## ...
##   Res.Df RSS Df Sum of Sq      F Pr(>F)
## 1      2 2.0
## 2      1 1.5  1       0.5 0.3333 0.6667

lm0 <- lm(y ~ 1, data = df1)
anova(lm0, lm1)
## ...
##   Res.Df RSS Df Sum of Sq      F Pr(>F)
## 1      2 2.0
## 2      1 1.5  1       0.5 0.3333 0.6667


>
>> df1<-data.frame(x=c(2,3,4), y=c(7,6,8))
>> lm1<-lm(y~x, df1)
>> lm1
>
> Call:
> lm(formula = y ~ x, data = df1)
>
> Coefficients:
> (Intercept)            x
>        5.5          0.5
>
>> summary(lm1)
>
> Call:
> lm(formula = y ~ x, data = df1)
>
> Residuals:
>   1    2    3
> 0.5 -1.0  0.5
>
> Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
> (Intercept)    5.500      2.693   2.043    0.290
> x              0.500      0.866   0.577    0.667
>
> Residual standard error: 1.225 on 1 degrees of freedom
> Multiple R-squared:   0.25, Adjusted R-squared:   -0.5
> F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667
>
>> linearHypothesis(lm1, c("(Intercept)=0", "x=0"))
> Linear hypothesis test
>
> Hypothesis:
> (Intercept) = 0
> x = 0
>
> Model 1: restricted model
> Model 2: y ~ x
>
>  Res.Df   RSS Df Sum of Sq      F Pr(>F)
> 1      3 149.0
> 2      1   1.5  2     147.5 49.167 0.1003
>
> 2018-08-03 13:54 GMT+08:00 Annaert Jan <jan.annaert at uantwerpen.be>:
>
>> You can easily test linear restrictions using the function
>> linearHypothesis() from the car package.
>> There are several ways to set up the null hypothesis, but a
>> straightforward one here is:
>>
>>> library(car)
>>> x <- rnorm(10)
>>> y <- x+rnorm(10)
>>> linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
>> Linear hypothesis test
>>
>> Hypothesis:
>> (Intercept) = 0
>> x = 1
>>
>> Model 1: restricted model
>> Model 2: y ~ x
>>
>>   Res.Df     RSS Df Sum of Sq      F Pr(>F)
>> 1     10 10.6218
>> 2      8  9.0001  2    1.6217 0.7207 0.5155
>>
>>
>> Jan
>>
>> From: R-help <r-help-bounces at r-project.org> on behalf of John <
>> miaojpm at gmail.com>
>> Date: Thursday, 2 August 2018 at 10:44
>> To: r-help <r-help at r-project.org>
>> Subject: [R] F-test where the coefficients in the H_0 is nonzero
>>
>> Hi,
>>
>>    I try to run the regression
>>    y = beta_0 + beta_1 x
>>    and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
>>    I believe I can run the regression
>>    (y-x) = beta_0 +beta_1? x
>>    and do the regular F-test (using lm functio) where the hypothesized
>> coefficients are all zero.
>>
>>    Is there any function in R that deal with the case where the
>> coefficients are nonzero?
>>
>> John
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From poi@@on200 @ending from googlem@il@com  Thu Aug  9 11:40:12 2018
From: poi@@on200 @ending from googlem@il@com (john matthew)
Date: Thu, 9 Aug 2018 10:40:12 +0100
Subject: [R] sub/grep question: extract year
In-Reply-To: <CA+b7HP27j0uHjRdfPNnRSyDYqCp6a23wKe39uGWLaUc5a=P8FQ@mail.gmail.com>
References: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
 <CA+b7HP27j0uHjRdfPNnRSyDYqCp6a23wKe39uGWLaUc5a=P8FQ@mail.gmail.com>
Message-ID: <CA+b7HP1yNnif7jDaYwFL8E+9vAc9jqRTRHFTmJ7DEsUQOPHn3A@mail.gmail.com>

So there is probably a command that resets the capture variables as I call
them. No doubt someone will write what it is.

On 9 Aug 2018 10:36, "john matthew" <poisson200 at googlemail.com> wrote:

> Hi Marc.
> For question 1.
> I know in Perl that regular expressions when captured can be saved if not
> overwritten. \\1 is the capture variable in your R examples.
>
> So the 2nd regular expression does not match but \\1 still has 1980
> captured from the previous expression, hence the result.
>
> Maybe if you restart R and try your 2nd expression first, \\1 will be
> empty or no match result.
>
> Just speculation :)
>
> John
>
>
> On 9 Aug 2018 08:58, "Marc Girondot via R-help" <r-help at r-project.org>
> wrote:
>
>> Hi everybody,
>>
>> I have some questions about the way that sub is working. I hope that
>> someone has the answer:
>>
>> 1/ Why the second example does not return an empty string ? There is no
>> match.
>>
>> subtext <- "-1980-"
>> sub(".*(1980).*", "\\1", subtext) # return 1980
>> sub(".*(1981).*", "\\1", subtext) # return -1980-
>>
>> 2/ Based on sub documentation, it replaces the first occurence of a
>> pattern: why it does not return 1980 ?
>>
>> subtext <- " 1980 1981 "
>> sub(".*(198[01]).*", "\\1", subtext) # return 1981
>>
>> 3/ I want extract year from text; I use:
>>
>> subtext <- "bla 1980 bla"
>> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
>> return 1980
>> subtext <- "bla 2010 bla"
>> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
>> return 2010
>>
>> but
>>
>> subtext <- "bla 1010 bla"
>> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
>> return 1010
>>
>> I would like exclude the case 1010 and other like this.
>>
>> The solution would be:
>>
>> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>>
>> Is there a solution to write such a pattern in grep ?
>>
>> Thanks a lot
>>
>> Marc
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Thu Aug  9 11:45:58 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Thu, 9 Aug 2018 11:45:58 +0200
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
 <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
 <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
Message-ID: <96DA15B2-46DA-43B7-9B34-211C67DD3C0B@gmail.com>

The null hypothesis is different (and the different numerator Df is the givaway).

> lm0 <- lm(y~-1, df1)
> anova(lm0,lm1)
Analysis of Variance Table

Model 1: y ~ -1
Model 2: y ~ x
  Res.Df   RSS Df Sum of Sq      F Pr(>F)
1      3 149.0                           
2      1   1.5  2     147.5 49.167 0.1003

-pd

> On 9 Aug 2018, at 10:58 , John <miaojpm at gmail.com> wrote:
> 
> Hi,
> 
>   I try to run the same f-test by lm (with summary) and the function
> "linearHypothesis" in car package. Why are the results (p-values for the
> f-test) different?
> 
> 
>> df1<-data.frame(x=c(2,3,4), y=c(7,6,8))
>> lm1<-lm(y~x, df1)
>> lm1
> 
> Call:
> lm(formula = y ~ x, data = df1)
> 
> Coefficients:
> (Intercept)            x
>        5.5          0.5
> 
>> summary(lm1)
> 
> Call:
> lm(formula = y ~ x, data = df1)
> 
> Residuals:
>   1    2    3
> 0.5 -1.0  0.5
> 
> Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
> (Intercept)    5.500      2.693   2.043    0.290
> x              0.500      0.866   0.577    0.667
> 
> Residual standard error: 1.225 on 1 degrees of freedom
> Multiple R-squared:   0.25, Adjusted R-squared:   -0.5
> F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667
> 
>> linearHypothesis(lm1, c("(Intercept)=0", "x=0"))
> Linear hypothesis test
> 
> Hypothesis:
> (Intercept) = 0
> x = 0
> 
> Model 1: restricted model
> Model 2: y ~ x
> 
>  Res.Df   RSS Df Sum of Sq      F Pr(>F)
> 1      3 149.0
> 2      1   1.5  2     147.5 49.167 0.1003
> 
> 2018-08-03 13:54 GMT+08:00 Annaert Jan <jan.annaert at uantwerpen.be>:
> 
>> You can easily test linear restrictions using the function
>> linearHypothesis() from the car package.
>> There are several ways to set up the null hypothesis, but a
>> straightforward one here is:
>> 
>>> library(car)
>>> x <- rnorm(10)
>>> y <- x+rnorm(10)
>>> linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
>> Linear hypothesis test
>> 
>> Hypothesis:
>> (Intercept) = 0
>> x = 1
>> 
>> Model 1: restricted model
>> Model 2: y ~ x
>> 
>>  Res.Df     RSS Df Sum of Sq      F Pr(>F)
>> 1     10 10.6218
>> 2      8  9.0001  2    1.6217 0.7207 0.5155
>> 
>> 
>> Jan
>> 
>> From: R-help <r-help-bounces at r-project.org> on behalf of John <
>> miaojpm at gmail.com>
>> Date: Thursday, 2 August 2018 at 10:44
>> To: r-help <r-help at r-project.org>
>> Subject: [R] F-test where the coefficients in the H_0 is nonzero
>> 
>> Hi,
>> 
>>   I try to run the regression
>>   y = beta_0 + beta_1 x
>>   and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
>>   I believe I can run the regression
>>   (y-x) = beta_0 +beta_1? x
>>   and do the regular F-test (using lm functio) where the hypothesized
>> coefficients are all zero.
>> 
>>   Is there any function in R that deal with the case where the
>> coefficients are nonzero?
>> 
>> John
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From poi@@on200 @ending from googlem@il@com  Thu Aug  9 12:05:40 2018
From: poi@@on200 @ending from googlem@il@com (john matthew)
Date: Thu, 9 Aug 2018 11:05:40 +0100
Subject: [R] security using R at work
In-Reply-To: <1B674C66F0DD4343BA5DD0C025217F9F02270AAD@CSSPWD2PRAP1147.SSA-Intra.net>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
 <1B674C66F0DD4343BA5DD0C025217F9F02270AAD@CSSPWD2PRAP1147.SSA-Intra.net>
Message-ID: <CA+b7HP3xPsxn3ZRrhDH8k-fBmKcd1gCTsjmH96EthA+716G5-g@mail.gmail.com>

Hi Katherina.
Good point you make. What makes your IT department happy with the use of R
studio server? What are the safe packages?

Can I trust your answer? :)
John.



On 9 Aug 2018 10:38, "Fritsch, Katharina (NNL) via R-help" <
r-help at r-project.org> wrote:

> Hiya,
> I work in a very security conscious organisation and we happily use R. The
> average user can only use R via RStudio Server, with a limited number of
> packages available, so that adds an additional level of control.
> That said, are you sure that the sentence 'a few people on a mailing list
> said it would be alright' is going to convince your IT department of the
> harmlessness of R?
> Cheers,
> Katharina.
>
> --
>
> Dr Katharina Fritsch B.Sc. M.Sc. MRSC
> Chemical Modeller, Chemical and Process Modelling
>
>
> E.
> katharina.fritsch at nnl.co.uk
> T.
> +44 (0)1925 289387
> @uknnl
>
> National Nuclear Laboratory Limited, 5th Floor, Chadwick House,
> Birchwood Park, Warrington, WA3 6AE, UK
>
> www.nnl.co.uk
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Laurence
> Clark
> Sent: 08 August 2018 16:10
> To: 'r-help at r-project.org'
> Subject: [R] security using R at work
>
> Hello all,
>
> I want to download R and use it for work purposes. I hope to use it to
> analyse very sensitive data from our clients.
>
> My question is:
>
> If I install R on my work network computer, will the data ever leave our
> network? I need to know if the data goes anywhere other than our network,
> because this could compromise it's security. Is there is any chance the
> data could go to a server owned by 'R' or anything else that's not
> immediately obvious, but constitutes the data leaving our network?
>
> Thank you
>
> Laurence
>
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
> Laurence Clark
> Business Data Analyst
> Account Management
> Health Management Ltd
>
> Mobile:                 07584 556498
> Switchboard:    0845 504 1000
> Email:          Laurence.Clark at healthmanltd.com
> Web:            BLOCKEDhealthmanagement[.]co[.]ukBLOCKED
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole
> use of the intended recipients and may contain confidential and privileged
> information or otherwise be protected by law. Any unauthorised review, use,
> disclosure or distribution is prohibited. If you are not the intended
> recipient, please contact the sender, and destroy all copies and the
> original message.<BR><BR>MAXIMUS People Services Limited is registered in
> England and Wales (registered number: 03752300); registered office: 202 -
> 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health
> and Disability Assessments Ltd (registered number: 9072343) and Health
> Management Ltd (registered number: 4369949) are registered in England and
> Wales. The registered office for each is Ash House, The Broyle, Ringmer,
> East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in
> England and Wales (registered number: 09457025); registered office: 18c
> Meridian East, Meridian Business Park, Leicester, L
>  eicestershire, LE19 1WZ, United Kingdom.</font>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
>
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
>
>
> ############################################################
> #########################
> Scanned by MailMarshal - M86 Security's comprehensive email content
> security solution.
> Download a free evaluation of MailMarshal at BLOCKEDm86security[.]
> comBLOCKED
> ############################################################
> #########################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> BLOCKEDstat[.]ethz[.]ch/mailman/listinfo/r-helpBLOCKED
> PLEASE do read the posting guide BLOCKEDR-project[.]org/
> posting-guide[.]htmlBLOCKED
> and provide commented, minimal, self-contained, reproducible code.
> ************************************************************
> *****************
> This message was received by the Cloud Security Email Gateway
>
> and was checked for Viruses and SPAM by the Cloud Security Email
> Management Service.
> Please forward any suspicious or unwanted emails to "Spam Helpdesk"
> ************************************************************
> *****************
>
>
> This e-mail is from National Nuclear Laboratory Limited ("NNL"). This
> e-mail and any attachments are intended for the addressee and may also be
> legally privileged. If you are not the intended recipient please do not
> print, re-transmit, store or act in reliance on it or any attachments.
> Instead, please e-mail it back to the sender and then immediately
> permanently delete it.
>
> National Nuclear Laboratory Limited (Company number 3857752) Registered in
> England and Wales. Registered office: Chadwick House, Warrington Road,
> Birchwood Park, Warrington, WA3 6AE.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e@ @ending from enrico@chum@nn@net  Thu Aug  9 12:14:52 2018
From: e@ @ending from enrico@chum@nn@net (Enrico Schumann)
Date: Thu, 09 Aug 2018 12:14:52 +0200
Subject: [R] sub/grep question: extract year
In-Reply-To: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
Message-ID: <20180809121452.Horde.uxO51lQThuuhDXBPVsVAIMH@webmail.your-server.de>


Quoting Marc Girondot via R-help <r-help at r-project.org>:

> Hi everybody,
>
> I have some questions about the way that sub is working. I hope that  
> someone has the answer:
>
> 1/ Why the second example does not return an empty string ? There is  
> no match.
>
> subtext <- "-1980-"
> sub(".*(1980).*", "\\1", subtext) # return 1980
> sub(".*(1981).*", "\\1", subtext) # return -1980-

This is as documented in ?sub:
    "Elements of character vectors x which are not
     substituted will be returned unchanged"

> 2/ Based on sub documentation, it replaces the first occurence of a  
> pattern: why it does not return 1980 ?
>
> subtext <- " 1980 1981 "
> sub(".*(198[01]).*", "\\1", subtext) # return 1981

Because the pattern matches the whole string,
not just the year:

     regexpr(".*(198[01]).*", subtext)
     ## [1] 1
     ## attr(,"match.length")
     ## [1] 11
     ## attr(,"useBytes")
     ## [1] TRUE

 From this match, the RE engine will give you the last backreference-match,
which is "1981". If you want to _extract_ the first year, use a  
non-greedy RE instead:

     sub(".*?(198[01]).*", "\\1", subtext)
     ## [1] "1980"

I say _extract_ because you may _replace_ the pattern, as expected:

     sub("198[01]", "YYYY", subtext)
     ## [1] " YYYY 1981 "

That is because the pattern does not match the whole string.
Perhaps this example makes it clearer:

     test <- "1 2 3 4 5"
     sub("([0-9])", "\\1\\1", test)
     ## [1] "11 2 3 4 5"
     sub(".*([0-9]).*", "\\1\\1", test)
     ## [1] "55"
     sub(".*?([0-9]).*", "\\1\\1", test)
     ## [1] "11"



> 3/ I want extract year from text; I use:
>
> subtext <- "bla 1980 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1",  
> subtext) # return 1980
> subtext <- "bla 2010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1",  
> subtext) # return 2010
>
> but
>
> subtext <- "bla 1010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1",  
> subtext) # return 1010
>
> I would like exclude the case 1010 and other like this.
>
> The solution would be:
>
> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>
> Is there a solution to write such a pattern in grep ?

You answered this yourself, I think.


> Thanks a lot
>
> Marc
>


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From S@Elli@on @ending from LGCGroup@com  Thu Aug  9 13:56:11 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Thu, 9 Aug 2018 11:56:11 +0000
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <998a40ef9cfe4b5a876fce9f4f441a58@GBDCVPEXC08.corp.lgc-group.com>

> If I install R on my work network computer, will the data ever leave our
> network? 
As far as I know, if you run R locally (and not, say, on an amazon EC2 instance) your data - indeed anything about you or your machine - will only leave your desktop if you download and run an R package that transfers data intentionally. I don't know of _any_, but there are 10000 or so out there and I've probably used less than a hundred of them over the last decade. 
Other than malice, I can't imagine why an R package would upload data to anywhere else, but I suppose it's conceivable that someone has a server farm out there for doing parallel MCMC and has written a package to access it, and that might be a use-case for data upload. Again, I don't know of one.

But here are three things that don't depend on a mailing list opinion.
a) If you are genuinely concerned, airgap. Only run sensitive data on machines that are not connected to the outside world. Install any necessary packages from local .zip on USB drives or something.

b) Install something like wireshark and test for unexpected outgoing traffic on a dummy data set before applying the package to anything sensitive.

c) Have your IT department mark R as an unauthorised package (in your machine's firewall/security package) for TCP/IP transport so that R cannot talk to the internet.*

*That is a pain as the ability to download packages on demand is really helpful. However, it does mean that you can restrict _just_ R and does not require an airgap.



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S@Elli@on @ending from LGCGroup@com  Thu Aug  9 14:11:31 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Thu, 9 Aug 2018 12:11:31 +0000
Subject: [R] exponential day
In-Reply-To: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
References: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
Message-ID: <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>

> Please, how can I determine parameters from exponential equation Example
> one:  y = a*exp(-b*x);  how do I determine  a  and  b , as well as R-square
> from data sets. And also fitting y = a*exp(-b*x) into the data sets Assuming
> data sets A = (0,2,4,6,8,10) B = (1,0.8,0.6,0.4,0.2,0.1)

For least squares fitting, you could take logs and do a simple linear fit, if the resduals are reasonably homoscedastic in the log domain (or if you can sort the weighting out properly).

For non-linear least squares, look at ?nlm, ?nls or (if you want to roll your own) ?optim

For max likelihood, maybe nlme in the nlme package.

For other ideas, look up 'non-linear fitting with R' on any search engine, or check the R Task Views

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From btupper @ending from bigelow@org  Thu Aug  9 14:32:50 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Thu, 9 Aug 2018 08:32:50 -0400
Subject: [R] error with the expand.grid command
In-Reply-To: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>
References: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>
Message-ID: <A25D3183-897C-48C4-8F49-DCBDB6C3B7AB@bigelow.org>

Hello,

You will have much better success if you subscribe and post to the R-sig-geo mailing list rather than the R-help mailing list.  You can subscribe to that list here... https://www.r-project.org/mail.html <https://www.r-project.org/mail.html>

If you are open to other suggestions, here are a couple of other tips to help you get help.

Change your email client to send plain text rather than richly formatted messages.  Using richly formatted text will often result in a garbled message and always results in this little gem you can see a the bottom of your message...

> [[alternative HTML version deleted]]


More specifically to your problem, there isn't anyway for others to help you since we could not access your data (like the NCDF file) and variables (like lon, lat, time, tt and ttt).  Anything you can do to make the issue super easy for someone to help means you are more likely to get the help you seek.  There are some really nice tutorials on how to ask a question on a help list that will most likely score you the help you seek.  Here's an example... https://www.r-project.org/posting-guide.html <https://www.r-project.org/posting-guide.html> but there are more out there on the world wild web.

Best of luck and see you over on R-sig-geo!

Ben

> On Aug 9, 2018, at 2:20 AM, Mayur Tade <mayur.tade at gmail.com> wrote:
> 
> hello sir...
> i am trying to extract the chlorophyll data of particular lat and lon from
> the world chlorophyll data from the netcdf file in R. as i am new to R i am
> facing the problem related to it when i am trying expand.grid command it is
> showing me this message.....message is followed.....its my kind request
> please help me with the same
> ttt<-expand.grid(lon,lat,time)
> Error in paste0(nmc[i], "=", if (is.numeric(x)) format(x) else x) :
>  cannot coerce type 'closure' to vector of type 'character'
> 
> here is the print of my netcdf file for you kind information.....follow...
> 
>> print(tt)
> File E:\chlorophyll data research student..mayur
> t..KUFOS\1997\ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_
> GEO_PML_OCx-199709-fv3.1.nc
> <http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
> (NC_FORMAT_NETCDF4_CLASSIC):
> 
>     9 variables (excluding dimension variables):
>        float MERIS_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the number of observations from the MERIS
> sensor contributing to this bin cell
>            number_of_files_composited: 19
>        float MODISA_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the number of observations from the MODIS
> (Aqua) sensor contributing to this bin cell
>            number_of_files_composited: 19
>        float SeaWiFS_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the number of observations from the SeaWiFS
> (GAC and LAC) sensor contributing to this bin cell
>            number_of_files_composited: 19
>        float VIIRS_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the number of observations from the VIIRS
> sensor contributing to this bin cell
>            number_of_files_composited: 19
>        float chlor_a[lon,lat,time]
>            _FillValue: 9.96920996838687e+36
>            long_name: Chlorophyll-a concentration in seawater (not
> log-transformed), generated by SeaDAS using a blended combination of OCI
> (OC4v6 + Hu's CI), OC3 and OC5, depending on water class memberships
>            units: milligram m-3
>            ancillary_variables: chlor_a_log10_rmsd chlor_a_log10_bias
>            grid_mapping: crs
>            standard_name: mass_concentration_of_chlorophyll_a_in_sea_water
>            units_nonstandard: mg m^-3
>            parameter_vocab_uri:
> http://vocab.nerc.ac.uk/collection/P04/current/
>        float chlor_a_log10_bias[lon,lat,time]
>            _FillValue: 9.96920996838687e+36
>            long_name: Bias of log10-transformed chlorophyll-a concentration
> in seawater.
>            grid_mapping: crs
>            rel: uncertainty
>            comment: Uncertainty lookups derived from file:
> /data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
> cci_chla_bias.dat
>            ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
>        float chlor_a_log10_rmsd[lon,lat,time]
>            _FillValue: 9.96920996838687e+36
>            long_name: Root-mean-square-difference of log10-transformed
> chlorophyll-a concentration in seawater.
>            grid_mapping: crs
>            rel: uncertainty
>            comment: Uncertainty lookups derived from file:
> /data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
> cci_chla_rmsd.dat
>            ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
>        int crs[time]
>            grid_mapping_name: latitude_longitude
>        float total_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the total number of observations
> contributing to this bin cell
>            number_of_files_composited: 19
> 
>     3 dimensions:
>        time  Size:1
>            axis: T
>            standard_name: time
>            units: days since 1970-01-01 00:00:00
>        lat  Size:4320
>            units: degrees_north
>            long_name: latitude
>            standard_name: latitude
>            valid_min: -89.9791641235352
>            valid_max: 89.9791641235352
>            axis: Y
>        lon  Size:8640
>            units: degrees_east
>            long_name: longitude
>            standard_name: longitude
>            valid_min: -179.97917175293
>            valid_max: 179.97917175293
>            axis: X
> 
>    47 global attributes:
>        Metadata_Conventions: Unidata Dataset Discovery v1.0
>        cdm_data_type: Grid
>        comment: See summary attribute
>        creator_email: help at esa-oceancolour-cci.org
>        creator_name: Plymouth Marine Laboratory
>        creator_url: http://esa-oceancolour-cci.org
>        geospatial_lat_max: 90
>        geospatial_lat_min: -90
>        geospatial_lat_resolution: .04166666666666666666
>        geospatial_lat_units: decimal degrees north
>        geospatial_lon_max: 180
>        geospatial_lon_min: -180
>        geospatial_lon_resolution: .04166666666666666666
>        geospatial_lon_units: decimal degrees east
>        geospatial_vertical_max: 0
>        geospatial_vertical_min: 0
>        institution: Plymouth Marine Laboratory
>        keywords: satellite,observation,ocean,ocean colour
>        keywords_vocabulary: none
>        license: ESA CCI Data Policy: free and open access.  When
> referencing, please use: Ocean Colour Climate Change Initiative dataset,
> Version <Version Number>, European Space Agency, available online at
> http://www.esa-oceancolour-cci.org.  We would also appreciate being notified
> of publications so that we can list them on the project website at
> http://www.esa-oceancolour-cci.org/?q=publications
>        naming_authority: uk.ac.pml
>        number_of_optical_water_types: 14
>        platform: Orbview-2,Aqua,Envisat,Suomi-NPP
>        processing_level: Level-3
>        project: Climate Change Initiative - European Space Agency
>        references: http://www.esa-oceancolour-cci.org/
>        sensor: SeaWiFS,MODIS,MERIS,VIIRS
>        source: NASA SeaWiFS L2 R2014.0 LAC and GAC, MODIS-Aqua L1A, MERIS
> L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L2 R2014.0.1 (data
> identical to R2014.0.2)
>        spatial_resolution: 4km nominal at equator
>        standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata
> Conventions Version 1.6
>        title: ESA CCI Ocean Colour Product
>        number_of_files_composited: 19
>        creation_date: Tue Aug 23 09:00:23 2016
>        date_created: Tue Aug 23 09:00:23 2016
>        time_coverage_resolution: P1M
>        time_coverage_duration: P1M
>        start_date: 01-SEP-1997 00:00:00.000000
>        stop_date: 30-SEP-1997 23:59:00.000000
>        time_coverage_start: 199709010000Z
>        time_coverage_end: 199709302359Z
>        netcdf_file_type: NETCDF4_CLASSIC
>        history: Source data were:
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970904-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970904-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970906-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970906-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970909-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970909-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970910-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970910-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970915-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970915-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970916-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970916-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970918-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970918-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970919-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970919-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970920-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970920-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970921-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970921-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970922-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970922-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970923-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970923-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970924-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970924-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970925-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970925-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970926-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970926-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970927-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970927-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970928-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970928-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970929-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970929-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970930-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970930-fv3.1.nc/>
> ;
> netcdf_compositor_cci composites  Rrs_412, Rrs_443, Rrs_490, Rrs_510,
> Rrs_555, Rrs_670, water_class1, water_class2, water_class3, water_class4,
> water_class5, water_class6, water_class7, water_class8, water_class9,
> water_class10, water_class11, water_class12, water_class13, water_class14,
> atot_412, atot_443, atot_490, atot_510, atot_555, atot_670, aph_412,
> aph_443, aph_490, aph_510, aph_555, aph_670, adg_412, adg_443, adg_490,
> adg_510, adg_555, adg_670, bbp_412, bbp_443, bbp_490, bbp_510, bbp_555,
> bbp_670, chlor_a, kd_490, chlor_a_log10_bias, Rrs_412_bias, Rrs_443_bias,
> Rrs_490_bias, Rrs_510_bias, Rrs_555_bias, Rrs_670_bias, aph_412_bias,
> aph_443_bias, aph_490_bias, aph_510_bias, aph_555_bias, aph_670_bias,
> adg_412_bias, adg_443_bias, adg_490_bias, adg_510_bias, adg_555_bias,
> adg_670_bias, kd_490_bias with --mean,  chlor_a_log10_rmsd, Rrs_412_rmsd,
> Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_555_rmsd, Rrs_670_rmsd,
> aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_555_rmsd,
> aph_670_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd,
> adg_555_rmsd, adg_670_rmsd, kd_490_rmsd with --root-mean-square, and
> SeaWiFS_nobs, MODISA_nobs, MERIS_nobs, VIIRS_nobs, total_nobs - with --total
> 1471940520 Subsetted from
> standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_
> MONTHLY_4km_GEO_PML_OCx_QAA-199709-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1m_monthly_4km_geo_pml_ocx_qaa-199709-fv3.1.nc/>
> to only include variables
> MERIS_nobs_sum,MODISA_nobs_sum,SeaWiFS_nobs_sum,VIIRS_
> nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,
> crs,lat,lon,time,total_nobs_sum
>        Conventions: CF-1.6
>        product_version: 3.1
>        summary: Data products generated by the Ocean Colour component of
> the European Space Agency Climate Change Initiative project. These files are
> daily composites of merged sensor (MERIS, MODIS Aqua, SeaWiFS LAC & GAC,
> VIIRS) products.  MODIS Aqua and MERIS were band-shifted and bias-corrected
> to SeaWiFS bands and values using a temporally and spatially varying scheme
> based on the overlap years of 2003-2007.  VIIRS was band-shifted and
> bias-corrected in a second stage against the MODIS Rrs that had already been
> corrected to SeaWiFS levels, for the overlap period 2012-2013.  VIIRS and
> SeaWiFS Rrs were derived from standard NASA L2 products; MERIS and MODIS
> from a combination of NASA's l2gen (for basic sensor geometry corrections,
> etc) and HYGEOS Polymer v3.5 (for atmospheric correction).  The Rrs were
> binned to a sinusoidal 4km level-3 grid, and later to 4km geographic
> projection, by Brockmann Consult's BEAM.  Derived products were generally
> computed with the standard SeaDAS algorithms.  QAA IOPs were derived using
> the standard SeaDAS algorithm but with a modified backscattering table to
> match that used in the bandshifting.  The final chlorophyll is a combination
> of OC4, Hu's CI and OC5, depending on the water class memberships.
> Uncertainty estimates were added using the fuzzy water classifier and
> uncertainty estimation algorithm of Tim Moore as documented in Jackson et al
> (2017).
>        tracking_id: 659b397a-953c-4814-a3e2-460d6218fcfa
>        id:
> ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-199709-fv3.1.nc
> <http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From b@h@mevik @ending from u@it@uio@no  Thu Aug  9 15:21:05 2018
From: b@h@mevik @ending from u@it@uio@no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Thu, 09 Aug 2018 15:21:05 +0200
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
 (Laurence Clark's message of "Wed, 8 Aug 2018 15:09:35 +0000")
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <s3szhxvd6bi.fsf@varelg.uio.no>

The section I'm working in runs a facility for sensitive research data
(https://www.uio.no/english/services/it/research/sensitive-data/).  Our
users use R (along with other analysis software).  We don't consider R
safe or unsafe, but have designed the services so that it should not be
possible (or at least very difficult) for sensitive information to leak
out of the network.

I would say that your best bet is to expect all analysis software to
have security holes or be compromised, and design your setup/network
around that assumption.

-- 
Regards,
Bj?rn-Helge Mevik

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 832 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180809/3c512239/attachment.sig>

From k@n@gi@n@tt@@io @ending from gm@il@com  Thu Aug  9 16:22:55 2018
From: k@n@gi@n@tt@@io @ending from gm@il@com (Kan Z. Gianattasio)
Date: Thu, 9 Aug 2018 10:22:55 -0400
Subject: [R] Warnings using SuperLearner?
Message-ID: <CAOBENzeSXQitCEGmRnu6tV24CagjxG_BQrNcBkLwbcmxD6Wn-g@mail.gmail.com>

 Hello,

I'm using the CV.SuperLearner to model a binary outcome using a set of
predictors, specifying family=binomial(), method = "method.AUC", and
SL.library = c("SL.glmnet", "SL.glm", "SL.randomForest", "SL.gam",
"SL.polymars", "SL.mean").

I'm getting a number of warning messages (copied below), and have not been
able to find anything about what they imply, or how to address them. Any
insight would be greatly appreciated.

Thank you in advance!

---

I get the following warnings as the models are being run (many times over):

step half ouch...
step half ouch...
warning - model size was reduced
warning - model size was reduced
step half ouch...
step half ouch...
step half ouch...
step half ouch...
warning - model size was reduced
step half ouch...
warning - model size was reduced

At the very end, I'm also getting the following:

1: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
2: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
3: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
4: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
5: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
6: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
7: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH

	[[alternative HTML version deleted]]


From @ilve@tri@c@@@li @ending from gm@il@com  Thu Aug  9 16:51:19 2018
From: @ilve@tri@c@@@li @ending from gm@il@com (Edoardo Silvestri)
Date: Thu, 9 Aug 2018 16:51:19 +0200
Subject: [R] Plot function: hourly data and x-axis
Message-ID: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>

Hi all,
I have a little problem with plot function..
I have an hourly dataset and I would like plot a variable with x-axis based
on daily or monthly frequency, just to have a better visualization and
avoid on x-axis all hours of the dataset.

Do you know what is the solution?
Thanks
Edo

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Thu Aug  9 18:39:54 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 9 Aug 2018 16:39:54 +0000
Subject: [R] Plot function: hourly data and x-axis
In-Reply-To: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>
References: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>
Message-ID: <C5CACF0D-3DC6-403F-BBD3-FE6D0BED1F67@llnl.gov>

Normally, one turns off the x-axis tick marks and labels by supplying   xaxt='n'  in the plot() call, and then adds a customized x-axis using the axis() function.

But without more information, little help can be provided (a vague question receives a vague answer).

I'd suggest reviewing the posting guide and other advice shown at the bottom of every email sent by R-help.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/9/18, 7:51 AM, "R-help on behalf of Edoardo Silvestri" <r-help-bounces at r-project.org on behalf of silvestri.casali at gmail.com> wrote:

    Hi all,
    I have a little problem with plot function..
    I have an hourly dataset and I would like plot a variable with x-axis based
    on daily or monthly frequency, just to have a better visualization and
    avoid on x-axis all hours of the dataset.
    
    Do you know what is the solution?
    Thanks
    Edo
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @ending from llnl@gov  Thu Aug  9 18:45:32 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 9 Aug 2018 16:45:32 +0000
Subject: [R] error with the expand.grid command
In-Reply-To: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>
References: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>
Message-ID: <B8AD139A-1A29-4B37-9225-FF5EF1DF0B6B@llnl.gov>

In my experience, error messages that reference a closure usually mean that you have supplied a function where you aren't supposed to.

In this case, I'd look and see if lon, lat, or time is a function (by accident, of course).

More specifically, right now in one of my R sessions, I get:

> class(time)
[1] "function"
> find('time')
[1] "package:stats"

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/8/18, 11:20 PM, "R-help on behalf of Mayur Tade" <r-help-bounces at r-project.org on behalf of mayur.tade at gmail.com> wrote:

     hello sir...
    i am trying to extract the chlorophyll data of particular lat and lon from
    the world chlorophyll data from the netcdf file in R. as i am new to R i am
    facing the problem related to it when i am trying expand.grid command it is
    showing me this message.....message is followed.....its my kind request
    please help me with the same
    ttt<-expand.grid(lon,lat,time)
    Error in paste0(nmc[i], "=", if (is.numeric(x)) format(x) else x) :
      cannot coerce type 'closure' to vector of type 'character'
    
    here is the print of my netcdf file for you kind information.....follow...
    
    > print(tt)
    File E:\chlorophyll data research student..mayur
    t..KUFOS\1997\ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_
    GEO_PML_OCx-199709-fv3.1.nc
    <http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
    (NC_FORMAT_NETCDF4_CLASSIC):
    
         9 variables (excluding dimension variables):
            float MERIS_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the number of observations from the MERIS
    sensor contributing to this bin cell
                number_of_files_composited: 19
            float MODISA_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the number of observations from the MODIS
    (Aqua) sensor contributing to this bin cell
                number_of_files_composited: 19
            float SeaWiFS_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the number of observations from the SeaWiFS
    (GAC and LAC) sensor contributing to this bin cell
                number_of_files_composited: 19
            float VIIRS_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the number of observations from the VIIRS
    sensor contributing to this bin cell
                number_of_files_composited: 19
            float chlor_a[lon,lat,time]
                _FillValue: 9.96920996838687e+36
                long_name: Chlorophyll-a concentration in seawater (not
    log-transformed), generated by SeaDAS using a blended combination of OCI
    (OC4v6 + Hu's CI), OC3 and OC5, depending on water class memberships
                units: milligram m-3
                ancillary_variables: chlor_a_log10_rmsd chlor_a_log10_bias
                grid_mapping: crs
                standard_name: mass_concentration_of_chlorophyll_a_in_sea_water
                units_nonstandard: mg m^-3
                parameter_vocab_uri:
    http://vocab.nerc.ac.uk/collection/P04/current/
            float chlor_a_log10_bias[lon,lat,time]
                _FillValue: 9.96920996838687e+36
                long_name: Bias of log10-transformed chlorophyll-a concentration
    in seawater.
                grid_mapping: crs
                rel: uncertainty
                comment: Uncertainty lookups derived from file:
    /data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
    cci_chla_bias.dat
                ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
            float chlor_a_log10_rmsd[lon,lat,time]
                _FillValue: 9.96920996838687e+36
                long_name: Root-mean-square-difference of log10-transformed
    chlorophyll-a concentration in seawater.
                grid_mapping: crs
                rel: uncertainty
                comment: Uncertainty lookups derived from file:
    /data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
    cci_chla_rmsd.dat
                ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
            int crs[time]
                grid_mapping_name: latitude_longitude
            float total_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the total number of observations
    contributing to this bin cell
                number_of_files_composited: 19
    
         3 dimensions:
            time  Size:1
                axis: T
                standard_name: time
                units: days since 1970-01-01 00:00:00
            lat  Size:4320
                units: degrees_north
                long_name: latitude
                standard_name: latitude
                valid_min: -89.9791641235352
                valid_max: 89.9791641235352
                axis: Y
            lon  Size:8640
                units: degrees_east
                long_name: longitude
                standard_name: longitude
                valid_min: -179.97917175293
                valid_max: 179.97917175293
                axis: X
    
        47 global attributes:
            Metadata_Conventions: Unidata Dataset Discovery v1.0
            cdm_data_type: Grid
            comment: See summary attribute
            creator_email: help at esa-oceancolour-cci.org
            creator_name: Plymouth Marine Laboratory
            creator_url: http://esa-oceancolour-cci.org
            geospatial_lat_max: 90
            geospatial_lat_min: -90
            geospatial_lat_resolution: .04166666666666666666
            geospatial_lat_units: decimal degrees north
            geospatial_lon_max: 180
            geospatial_lon_min: -180
            geospatial_lon_resolution: .04166666666666666666
            geospatial_lon_units: decimal degrees east
            geospatial_vertical_max: 0
            geospatial_vertical_min: 0
            institution: Plymouth Marine Laboratory
            keywords: satellite,observation,ocean,ocean colour
            keywords_vocabulary: none
            license: ESA CCI Data Policy: free and open access.  When
    referencing, please use: Ocean Colour Climate Change Initiative dataset,
    Version <Version Number>, European Space Agency, available online at
    http://www.esa-oceancolour-cci.org.  We would also appreciate being notified
    of publications so that we can list them on the project website at
    http://www.esa-oceancolour-cci.org/?q=publications
            naming_authority: uk.ac.pml
            number_of_optical_water_types: 14
            platform: Orbview-2,Aqua,Envisat,Suomi-NPP
            processing_level: Level-3
            project: Climate Change Initiative - European Space Agency
            references: http://www.esa-oceancolour-cci.org/
            sensor: SeaWiFS,MODIS,MERIS,VIIRS
            source: NASA SeaWiFS L2 R2014.0 LAC and GAC, MODIS-Aqua L1A, MERIS
    L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L2 R2014.0.1 (data
    identical to R2014.0.2)
            spatial_resolution: 4km nominal at equator
            standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata
    Conventions Version 1.6
            title: ESA CCI Ocean Colour Product
            number_of_files_composited: 19
            creation_date: Tue Aug 23 09:00:23 2016
            date_created: Tue Aug 23 09:00:23 2016
            time_coverage_resolution: P1M
            time_coverage_duration: P1M
            start_date: 01-SEP-1997 00:00:00.000000
            stop_date: 30-SEP-1997 23:59:00.000000
            time_coverage_start: 199709010000Z
            time_coverage_end: 199709302359Z
            netcdf_file_type: NETCDF4_CLASSIC
            history: Source data were:
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970904-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970904-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970906-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970906-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970909-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970909-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970910-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970910-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970915-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970915-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970916-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970916-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970918-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970918-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970919-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970919-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970920-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970920-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970921-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970921-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970922-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970922-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970923-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970923-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970924-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970924-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970925-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970925-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970926-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970926-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970927-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970927-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970928-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970928-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970929-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970929-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970930-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970930-fv3.1.nc/>
    ;
    netcdf_compositor_cci composites  Rrs_412, Rrs_443, Rrs_490, Rrs_510,
    Rrs_555, Rrs_670, water_class1, water_class2, water_class3, water_class4,
    water_class5, water_class6, water_class7, water_class8, water_class9,
    water_class10, water_class11, water_class12, water_class13, water_class14,
    atot_412, atot_443, atot_490, atot_510, atot_555, atot_670, aph_412,
    aph_443, aph_490, aph_510, aph_555, aph_670, adg_412, adg_443, adg_490,
    adg_510, adg_555, adg_670, bbp_412, bbp_443, bbp_490, bbp_510, bbp_555,
    bbp_670, chlor_a, kd_490, chlor_a_log10_bias, Rrs_412_bias, Rrs_443_bias,
    Rrs_490_bias, Rrs_510_bias, Rrs_555_bias, Rrs_670_bias, aph_412_bias,
    aph_443_bias, aph_490_bias, aph_510_bias, aph_555_bias, aph_670_bias,
    adg_412_bias, adg_443_bias, adg_490_bias, adg_510_bias, adg_555_bias,
    adg_670_bias, kd_490_bias with --mean,  chlor_a_log10_rmsd, Rrs_412_rmsd,
    Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_555_rmsd, Rrs_670_rmsd,
    aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_555_rmsd,
    aph_670_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd,
    adg_555_rmsd, adg_670_rmsd, kd_490_rmsd with --root-mean-square, and
    SeaWiFS_nobs, MODISA_nobs, MERIS_nobs, VIIRS_nobs, total_nobs - with --total
    1471940520 Subsetted from
    standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_
    MONTHLY_4km_GEO_PML_OCx_QAA-199709-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1m_monthly_4km_geo_pml_ocx_qaa-199709-fv3.1.nc/>
    to only include variables
    MERIS_nobs_sum,MODISA_nobs_sum,SeaWiFS_nobs_sum,VIIRS_
    nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,
    crs,lat,lon,time,total_nobs_sum
            Conventions: CF-1.6
            product_version: 3.1
            summary: Data products generated by the Ocean Colour component of
    the European Space Agency Climate Change Initiative project. These files are
    daily composites of merged sensor (MERIS, MODIS Aqua, SeaWiFS LAC & GAC,
    VIIRS) products.  MODIS Aqua and MERIS were band-shifted and bias-corrected
    to SeaWiFS bands and values using a temporally and spatially varying scheme
    based on the overlap years of 2003-2007.  VIIRS was band-shifted and
    bias-corrected in a second stage against the MODIS Rrs that had already been
    corrected to SeaWiFS levels, for the overlap period 2012-2013.  VIIRS and
    SeaWiFS Rrs were derived from standard NASA L2 products; MERIS and MODIS
    from a combination of NASA's l2gen (for basic sensor geometry corrections,
    etc) and HYGEOS Polymer v3.5 (for atmospheric correction).  The Rrs were
    binned to a sinusoidal 4km level-3 grid, and later to 4km geographic
    projection, by Brockmann Consult's BEAM.  Derived products were generally
    computed with the standard SeaDAS algorithms.  QAA IOPs were derived using
    the standard SeaDAS algorithm but with a modified backscattering table to
    match that used in the bandshifting.  The final chlorophyll is a combination
    of OC4, Hu's CI and OC5, depending on the water class memberships.
    Uncertainty estimates were added using the fuzzy water classifier and
    uncertainty estimation algorithm of Tim Moore as documented in Jackson et al
    (2017).
            tracking_id: 659b397a-953c-4814-a3e2-460d6218fcfa
            id:
    ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-199709-fv3.1.nc
    <http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @ending from gm@il@com  Thu Aug  9 18:52:55 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 9 Aug 2018 09:52:55 -0700
Subject: [R] Warnings using SuperLearner?
In-Reply-To: <CAOBENzeSXQitCEGmRnu6tV24CagjxG_BQrNcBkLwbcmxD6Wn-g@mail.gmail.com>
References: <CAOBENzeSXQitCEGmRnu6tV24CagjxG_BQrNcBkLwbcmxD6Wn-g@mail.gmail.com>
Message-ID: <CAGxFJbQ2u2CTWfYdEF4vicaW7AWhU71W0Pv0M-K5Pa-u+UU13g@mail.gmail.com>

A guess:

It sounds like you are overspecifying models leading to numerical issues
during the various optimizations being performed. Try simplifying your
model (reducing the number of predictors).  Without more details on your
data and model, it may be difficult to diagnose beyond such a guess, though
there are certainy wiser folks than I out there.

Also, this is a plain text maiing list. Please post in plain text, not HTML.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 9, 2018 at 7:22 AM, Kan Z. Gianattasio <
kan.gianattasio at gmail.com> wrote:

>  Hello,
>
> I'm using the CV.SuperLearner to model a binary outcome using a set of
> predictors, specifying family=binomial(), method = "method.AUC", and
> SL.library = c("SL.glmnet", "SL.glm", "SL.randomForest", "SL.gam",
> "SL.polymars", "SL.mean").
>
> I'm getting a number of warning messages (copied below), and have not been
> able to find anything about what they imply, or how to address them. Any
> insight would be greatly appreciated.
>
> Thank you in advance!
>
> ---
>
> I get the following warnings as the models are being run (many times over):
>
> step half ouch...
> step half ouch...
> warning - model size was reduced
> warning - model size was reduced
> step half ouch...
> step half ouch...
> step half ouch...
> step half ouch...
> warning - model size was reduced
> step half ouch...
> warning - model size was reduced
>
> At the very end, I'm also getting the following:
>
> 1: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 2: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 3: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 4: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 5: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 6: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 7: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Aug  9 19:23:43 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 09 Aug 2018 10:23:43 -0700
Subject: [R] Plot function: hourly data and x-axis
In-Reply-To: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>
References: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>
Message-ID: <54A20E35-750B-469B-9A1A-6047F0098B29@dcn.davis.ca.us>

Pre-process your data into per-day or per-month records, then plot it. There are many ways to do this... for example, base R has the aggregate function, and the dplyr package has the group_by/summarise functions, and the data.table package can do this as well (read the vignettes).

All of these techniques require that you learn how to deal with timestamps using one or more of the time classes. The most common of these can be introduced by reading

?DateTimeClasses

and/or reading some of the fine blogs online regarding this topic. Note that the trunc.POSIXt function offers one way to identify which time interval each record of your data belongs to.

If you need more assistance, read the Posting Guide and create a reproducible example similar to the data you are working with, and be sure to post it using plain text so it does not get corrupted in the mailing list.

On August 9, 2018 7:51:19 AM PDT, Edoardo Silvestri <silvestri.casali at gmail.com> wrote:
>Hi all,
>I have a little problem with plot function..
>I have an hourly dataset and I would like plot a variable with x-axis
>based
>on daily or monthly frequency, just to have a better visualization and
>avoid on x-axis all hours of the dataset.
>
>Do you know what is the solution?
>Thanks
>Edo
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@m@hkow73 @ending from gm@il@com  Thu Aug  9 20:08:12 2018
From: @@m@hkow73 @ending from gm@il@com (Ekow Asmah)
Date: Thu, 9 Aug 2018 19:08:12 +0100
Subject: [R] Assistance needed to run bootstrapping using benchmarking
 package
Message-ID: <CAPh=1bzf4niR_dodPE0rgd3DBV3Up_nmKK+vJtBbs+iiB4NYCA@mail.gmail.com>

Hello everyone. I am trying to run bootstrapping with DEA's directional
distance function using benchmarking Package. i have tried all i could but
without success. the actual problem is with the following commands:
1. dhat <- dea.direct(...)
2. Bm[i,] <- dea.direct (.....)
The details of the commands and the data are attached to this mail. Please
help me out

the error message is at the ending part of the commands

-- 
Emmanuel E. Asmah
Lecturer
Cape Coast Technical University
Cape Coast, Ghana
0233 -244759147
 easmah at cpoly.edu.gh
asmahkow73 at gmail.com
asmahkow at hahoo.com

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: BENCH 1.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180809/4fdbb4e1/attachment.txt>

From r@herry8 @ending from comc@@t@net  Thu Aug  9 19:12:45 2018
From: r@herry8 @ending from comc@@t@net (rsherry8)
Date: Thu, 9 Aug 2018 13:12:45 -0400
Subject: [R] Trying to Generalize a Function in R
Message-ID: <5B6C760D.5050404@comcast.net>


I wrote the following function:

# This method gets historical stock data for the stock Avalon Bay whose 
symbol is AVB.
getReturns <- function(norm = FALSE)
{
     library(quantmod)

     getSymbols("AVB", src = "yahoo", from = start, to = end)
     length = length(  AVB$AVB.Close )
     close = as.numeric( AVB$AVB.Close )
     cat( "length = ", length(close ), "\n" )
     for( i in 1:length-1 )
         diff[i] = ((close[i+1] - close[i]) ) / close[i]
     u = mean(diff)
     stdDev = sd(diff)
     cat( "stdDev = ", stdDev, "\n" )

     if ( norm == TRUE ) {
         diff = (diff - u)
         diff = diff / stdDev
     }
     return (diff)
}

I would like to generalize it to work for any stock by passing in the 
stock symbol. So the header for the
function would be:

getReturns <- function(symbol, norm = FALSE)

Now how do I update this line:
     length = length(  AVB$AVB.Close )
This statement will not work:
     length = length(  symbol$AVB.Close )
because the name that holds the closing price is a function of the stock 
symbol.

Thanks,
Bob


From peter@l@ngfelder @ending from gm@il@com  Thu Aug  9 21:46:01 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 9 Aug 2018 12:46:01 -0700
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <5B6C760D.5050404@comcast.net>
References: <5B6C760D.5050404@comcast.net>
Message-ID: <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>

If I understand it correctly, the function getSymbols creates a
variable with the name being the stock symbol. Then use the function
get(symbol) to retrieve the value of the variable whose name is
contained in the character string `symbol'. Assign that to a variable
(e.g. AVB). You may also have to modify the names of the components
you retrieve from the list AVB. For that, you can use
AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
something like AVB[[paste0(symbol, ".Close"]] to generalize the
retrieval of list components.

HTH,

Peter
On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>
>
> I wrote the following function:
>
> # This method gets historical stock data for the stock Avalon Bay whose
> symbol is AVB.
> getReturns <- function(norm = FALSE)
> {
>      library(quantmod)
>
>      getSymbols("AVB", src = "yahoo", from = start, to = end)
>      length = length(  AVB$AVB.Close )
>      close = as.numeric( AVB$AVB.Close )
>      cat( "length = ", length(close ), "\n" )
>      for( i in 1:length-1 )
>          diff[i] = ((close[i+1] - close[i]) ) / close[i]
>      u = mean(diff)
>      stdDev = sd(diff)
>      cat( "stdDev = ", stdDev, "\n" )
>
>      if ( norm == TRUE ) {
>          diff = (diff - u)
>          diff = diff / stdDev
>      }
>      return (diff)
> }
>
> I would like to generalize it to work for any stock by passing in the
> stock symbol. So the header for the
> function would be:
>
> getReturns <- function(symbol, norm = FALSE)
>
> Now how do I update this line:
>      length = length(  AVB$AVB.Close )
> This statement will not work:
>      length = length(  symbol$AVB.Close )
> because the name that holds the closing price is a function of the stock
> symbol.
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@il @ending from @lex@ndr@thorn@com  Thu Aug  9 17:36:23 2018
From: m@il @ending from @lex@ndr@thorn@com (Alexandra Thorn)
Date: Thu, 9 Aug 2018 11:36:23 -0400
Subject: [R] Help reinstalling rgdal (Ubuntu 16.04)
Message-ID: <20180809113623.71e49ae7@athorn-Lemur-Ultra>

Hi all,

Following some updates to R that I received via Synaptic Package
Manager on Ubuntu 16.04 (looks like I now have R 3.4.4-1xenial0), I
have been unable to reinstall rgdal, and I need help.

Initially I was getting error messages about dependencies on GDAL
1.11.4, but after following instructions to install GDAL from source
(into my /usr/local directory) I'm now getting a different set of error
messages (see the output error messages posted below my signature).  

I can't tell if this means that I've made a mistake installing GDAL or
if there's some other problem with my setup/configuration.  I really
need rgdal for the analyses I do in R and could use some help figuring
this out.

Thanks,
Alex

> install.packages("rgdal")
Installing package into ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4?
(as ?lib? is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/rgdal_1.3-4.tar.gz'
Content type 'application/x-gzip' length 1664774 bytes (1.6 MB)
==================================================
downloaded 1.6 MB

* installing *source* package ?rgdal? ...
** package ?rgdal? successfully unpacked and MD5 sums checked
configure: R_HOME: /usr/lib/R
configure: CC: gcc -std=gnu99
configure: CXX: g++
configure: C++11 support available
configure: rgdal: 1.3-4
checking for /usr/bin/svnversion... no
configure: svn revision: 766
checking for gdal-config... /usr/local/bin/gdal-config
checking gdal-config usability... yes
configure: GDAL: 2.3.1
checking C++11 support for GDAL >= 2.3.0... yes
checking GDAL version >= 1.11.4... yes
checking gdal: linking with --libs only... no
checking gdal: linking with --libs and --dep-libs... no
In file included from /usr/local/include/gdal.h:45:0,
                 from gdal_test.cc:1:
/usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
  newer. #    error Must have C++11 or newer.
      ^
In file included from /usr/local/include/gdal.h:49:0,
                 from gdal_test.cc:1:
/usr/local/include/cpl_minixml.h:202:47: error: expected template-name
  before '<' token class CPLXMLTreeCloser: public
  std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
/usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
  token /usr/local/include/cpl_minixml.h:202:47: error: expected
  unqualified-id before '<' token In file included
  from /usr/local/include/ogr_api.h:45:0,
  from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
/usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
  line /usr/local/include/ogr_core.h:79:28: error: expected declaration
  before end of line In file included
  from /usr/local/include/gdal.h:45:0, from gdal_test.cc:1:
/usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
  newer. #    error Must have C++11 or newer.
      ^
In file included from /usr/local/include/gdal.h:49:0,
                 from gdal_test.cc:1:
/usr/local/include/cpl_minixml.h:202:47: error: expected template-name
  before '<' token class CPLXMLTreeCloser: public
  std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
/usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
  token /usr/local/include/cpl_minixml.h:202:47: error: expected
  unqualified-id before '<' token In file included
  from /usr/local/include/ogr_api.h:45:0,
  from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
/usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
  line /usr/local/include/ogr_core.h:79:28: error: expected declaration
  before end of line configure: Install failure: compilation and/or
  linkage problems. configure: error: GDALAllRegister not found in
  libgdal. ERROR: configuration failed for package ?rgdal?
* removing ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4/rgdal?

The downloaded source packages are in
	?/tmp/RtmpeuSDnj/downloaded_packages?
Warning message:
In install.packages("rgdal") :
  installation of package ?rgdal? had non-zero exit status
> 


From r@herry8 @ending from comc@@t@net  Thu Aug  9 23:24:17 2018
From: r@herry8 @ending from comc@@t@net (rsherry8)
Date: Thu, 9 Aug 2018 17:24:17 -0400
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
Message-ID: <5B6CB101.3000008@comcast.net>

Peter,

Thanks for the response. I tired the following command:
     AVB[["AVB.Close"]]
and I got:
     Error in AVB[["AVB.Close"]] : subscript out of bounds
Are you assuming that AVB is a data frame? I do not think AVB is a data 
frame. Is there a way
for me to check?
Thanks,
Bob

On 8/9/2018 3:46 PM, Peter Langfelder wrote:
> If I understand it correctly, the function getSymbols creates a
> variable with the name being the stock symbol. Then use the function
> get(symbol) to retrieve the value of the variable whose name is
> contained in the character string `symbol'. Assign that to a variable
> (e.g. AVB). You may also have to modify the names of the components
> you retrieve from the list AVB. For that, you can use
> AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
> something like AVB[[paste0(symbol, ".Close"]] to generalize the
> retrieval of list components.
>
> HTH,
>
> Peter
> On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>
>> I wrote the following function:
>>
>> # This method gets historical stock data for the stock Avalon Bay whose
>> symbol is AVB.
>> getReturns <- function(norm = FALSE)
>> {
>>       library(quantmod)
>>
>>       getSymbols("AVB", src = "yahoo", from = start, to = end)
>>       length = length(  AVB$AVB.Close )
>>       close = as.numeric( AVB$AVB.Close )
>>       cat( "length = ", length(close ), "\n" )
>>       for( i in 1:length-1 )
>>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>       u = mean(diff)
>>       stdDev = sd(diff)
>>       cat( "stdDev = ", stdDev, "\n" )
>>
>>       if ( norm == TRUE ) {
>>           diff = (diff - u)
>>           diff = diff / stdDev
>>       }
>>       return (diff)
>> }
>>
>> I would like to generalize it to work for any stock by passing in the
>> stock symbol. So the header for the
>> function would be:
>>
>> getReturns <- function(symbol, norm = FALSE)
>>
>> Now how do I update this line:
>>       length = length(  AVB$AVB.Close )
>> This statement will not work:
>>       length = length(  symbol$AVB.Close )
>> because the name that holds the closing price is a function of the stock
>> symbol.
>>
>> Thanks,
>> Bob
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From r@herry8 @ending from comc@@t@net  Thu Aug  9 23:25:05 2018
From: r@herry8 @ending from comc@@t@net (rsherry8)
Date: Thu, 9 Aug 2018 17:25:05 -0400
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
Message-ID: <5B6CB131.4010408@comcast.net>

Duncan,

Thanks for the response. I tired the following:
     >  series <- getSymbols("AVB", src = "yahoo", from = start, to = end)
     > series[0]
         character(0)
     > nrow( series )
         NULL
nrow( series ) returned NULL. I do not understand why. I am thinking 
that there should be an R command to
tell me about the structure of series. I tried: typeof( series ) and 
got: "character". Is there a better command for
me to use other than typeof?

I also tried this command:
     c1 <- as.numeric(series[, paste0(symbol, ".Close")])
where symbol held the value "AVB" and I got:
     Error in series[, paste0(symbol, ".Close")] :
     incorrect number of dimensions

Please help.
Thanks,
Bob

On 8/9/2018 3:46 PM, Peter Langfelder wrote:
> If I understand it correctly, the function getSymbols creates a
> variable with the name being the stock symbol. Then use the function
> get(symbol) to retrieve the value of the variable whose name is
> contained in the character string `symbol'. Assign that to a variable
> (e.g. AVB). You may also have to modify the names of the components
> you retrieve from the list AVB. For that, you can use
> AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
> something like AVB[[paste0(symbol, ".Close"]] to generalize the
> retrieval of list components.
>
> HTH,
>
> Peter
> On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>
>> I wrote the following function:
>>
>> # This method gets historical stock data for the stock Avalon Bay whose
>> symbol is AVB.
>> getReturns <- function(norm = FALSE)
>> {
>>       library(quantmod)
>>
>>       getSymbols("AVB", src = "yahoo", from = start, to = end)
>>       length = length(  AVB$AVB.Close )
>>       close = as.numeric( AVB$AVB.Close )
>>       cat( "length = ", length(close ), "\n" )
>>       for( i in 1:length-1 )
>>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>       u = mean(diff)
>>       stdDev = sd(diff)
>>       cat( "stdDev = ", stdDev, "\n" )
>>
>>       if ( norm == TRUE ) {
>>           diff = (diff - u)
>>           diff = diff / stdDev
>>       }
>>       return (diff)
>> }
>>
>> I would like to generalize it to work for any stock by passing in the
>> stock symbol. So the header for the
>> function would be:
>>
>> getReturns <- function(symbol, norm = FALSE)
>>
>> Now how do I update this line:
>>       length = length(  AVB$AVB.Close )
>> This statement will not work:
>>       length = length(  symbol$AVB.Close )
>> because the name that holds the closing price is a function of the stock
>> symbol.
>>
>> Thanks,
>> Bob
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From peter@l@ngfelder @ending from gm@il@com  Thu Aug  9 23:29:37 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 9 Aug 2018 14:29:37 -0700
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <5B6CB101.3000008@comcast.net>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
 <5B6CB101.3000008@comcast.net>
Message-ID: <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>

Well, your function uses AVB$AVB.Close, so I assumed AVB is a list (a
data frame can be thought of as a special list). What do you get when
you type class(AVB)?

Peter
On Thu, Aug 9, 2018 at 2:24 PM rsherry8 <rsherry8 at comcast.net> wrote:
>
> Peter,
>
> Thanks for the response. I tired the following command:
>      AVB[["AVB.Close"]]
> and I got:
>      Error in AVB[["AVB.Close"]] : subscript out of bounds
> Are you assuming that AVB is a data frame? I do not think AVB is a data
> frame. Is there a way
> for me to check?
> Thanks,
> Bob
>
> On 8/9/2018 3:46 PM, Peter Langfelder wrote:
> > If I understand it correctly, the function getSymbols creates a
> > variable with the name being the stock symbol. Then use the function
> > get(symbol) to retrieve the value of the variable whose name is
> > contained in the character string `symbol'. Assign that to a variable
> > (e.g. AVB). You may also have to modify the names of the components
> > you retrieve from the list AVB. For that, you can use
> > AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
> > something like AVB[[paste0(symbol, ".Close"]] to generalize the
> > retrieval of list components.
> >
> > HTH,
> >
> > Peter
> > On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
> >>
> >> I wrote the following function:
> >>
> >> # This method gets historical stock data for the stock Avalon Bay whose
> >> symbol is AVB.
> >> getReturns <- function(norm = FALSE)
> >> {
> >>       library(quantmod)
> >>
> >>       getSymbols("AVB", src = "yahoo", from = start, to = end)
> >>       length = length(  AVB$AVB.Close )
> >>       close = as.numeric( AVB$AVB.Close )
> >>       cat( "length = ", length(close ), "\n" )
> >>       for( i in 1:length-1 )
> >>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
> >>       u = mean(diff)
> >>       stdDev = sd(diff)
> >>       cat( "stdDev = ", stdDev, "\n" )
> >>
> >>       if ( norm == TRUE ) {
> >>           diff = (diff - u)
> >>           diff = diff / stdDev
> >>       }
> >>       return (diff)
> >> }
> >>
> >> I would like to generalize it to work for any stock by passing in the
> >> stock symbol. So the header for the
> >> function would be:
> >>
> >> getReturns <- function(symbol, norm = FALSE)
> >>
> >> Now how do I update this line:
> >>       length = length(  AVB$AVB.Close )
> >> This statement will not work:
> >>       length = length(  symbol$AVB.Close )
> >> because the name that holds the closing price is a function of the stock
> >> symbol.
> >>
> >> Thanks,
> >> Bob
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon @ending from gm@il@com  Fri Aug 10 00:11:09 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 10 Aug 2018 08:11:09 +1000
Subject: [R] Help reinstalling rgdal (Ubuntu 16.04)
In-Reply-To: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
References: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
Message-ID: <CA+8X3fUa=q43VNz-DQW1d10krSF7nPALpeay3zmx_jU0JnSJcw@mail.gmail.com>

Hi Alex,
I don't use Ubuntu, but if I saw that error message I would upgrade my
C++ compiler and try again. With luck, this is what caused the cascade
of errors beneath it.

Jim

On Fri, Aug 10, 2018 at 1:36 AM, Alexandra Thorn
<mail at alexandrathorn.com> wrote:
> Hi all,
>
> Following some updates to R that I received via Synaptic Package
> Manager on Ubuntu 16.04 (looks like I now have R 3.4.4-1xenial0), I
> have been unable to reinstall rgdal, and I need help.
>
> Initially I was getting error messages about dependencies on GDAL
> 1.11.4, but after following instructions to install GDAL from source
> (into my /usr/local directory) I'm now getting a different set of error
> messages (see the output error messages posted below my signature).
>
> I can't tell if this means that I've made a mistake installing GDAL or
> if there's some other problem with my setup/configuration.  I really
> need rgdal for the analyses I do in R and could use some help figuring
> this out.
>
> Thanks,
> Alex
>
>> install.packages("rgdal")
> Installing package into ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4?
> (as ?lib? is unspecified)
> trying URL 'https://cloud.r-project.org/src/contrib/rgdal_1.3-4.tar.gz'
> Content type 'application/x-gzip' length 1664774 bytes (1.6 MB)
> ==================================================
> downloaded 1.6 MB
>
> * installing *source* package ?rgdal? ...
> ** package ?rgdal? successfully unpacked and MD5 sums checked
> configure: R_HOME: /usr/lib/R
> configure: CC: gcc -std=gnu99
> configure: CXX: g++
> configure: C++11 support available
> configure: rgdal: 1.3-4
> checking for /usr/bin/svnversion... no
> configure: svn revision: 766
> checking for gdal-config... /usr/local/bin/gdal-config
> checking gdal-config usability... yes
> configure: GDAL: 2.3.1
> checking C++11 support for GDAL >= 2.3.0... yes
> checking GDAL version >= 1.11.4... yes
> checking gdal: linking with --libs only... no
> checking gdal: linking with --libs and --dep-libs... no
> In file included from /usr/local/include/gdal.h:45:0,
>                  from gdal_test.cc:1:
> /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>   newer. #    error Must have C++11 or newer.
>       ^
> In file included from /usr/local/include/gdal.h:49:0,
>                  from gdal_test.cc:1:
> /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
>   before '<' token class CPLXMLTreeCloser: public
>   std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
> /usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
>   token /usr/local/include/cpl_minixml.h:202:47: error: expected
>   unqualified-id before '<' token In file included
>   from /usr/local/include/ogr_api.h:45:0,
>   from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
> /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
>   line /usr/local/include/ogr_core.h:79:28: error: expected declaration
>   before end of line In file included
>   from /usr/local/include/gdal.h:45:0, from gdal_test.cc:1:
> /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>   newer. #    error Must have C++11 or newer.
>       ^
> In file included from /usr/local/include/gdal.h:49:0,
>                  from gdal_test.cc:1:
> /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
>   before '<' token class CPLXMLTreeCloser: public
>   std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
> /usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
>   token /usr/local/include/cpl_minixml.h:202:47: error: expected
>   unqualified-id before '<' token In file included
>   from /usr/local/include/ogr_api.h:45:0,
>   from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
> /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
>   line /usr/local/include/ogr_core.h:79:28: error: expected declaration
>   before end of line configure: Install failure: compilation and/or
>   linkage problems. configure: error: GDALAllRegister not found in
>   libgdal. ERROR: configuration failed for package ?rgdal?
> * removing ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4/rgdal?
>
> The downloaded source packages are in
>         ?/tmp/RtmpeuSDnj/downloaded_packages?
> Warning message:
> In install.packages("rgdal") :
>   installation of package ?rgdal? had non-zero exit status
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@cqueen1 @ending from llnl@gov  Fri Aug 10 00:13:38 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 9 Aug 2018 22:13:38 +0000
Subject: [R] Help reinstalling rgdal (Ubuntu 16.04)
In-Reply-To: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
References: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
Message-ID: <FDA106CA-4AF9-449C-93C7-609FFAE3B20A@llnl.gov>

There are quite a few messages on R-sig-geo about installing rgdal on Ubuntu. Maybe one of them contains your solution?
(I use Mac, so can't help directly)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/9/18, 8:36 AM, "R-help on behalf of Alexandra Thorn" <r-help-bounces at r-project.org on behalf of mail at alexandrathorn.com> wrote:

    Hi all,
    
    Following some updates to R that I received via Synaptic Package
    Manager on Ubuntu 16.04 (looks like I now have R 3.4.4-1xenial0), I
    have been unable to reinstall rgdal, and I need help.
    
    Initially I was getting error messages about dependencies on GDAL
    1.11.4, but after following instructions to install GDAL from source
    (into my /usr/local directory) I'm now getting a different set of error
    messages (see the output error messages posted below my signature).  
    
    I can't tell if this means that I've made a mistake installing GDAL or
    if there's some other problem with my setup/configuration.  I really
    need rgdal for the analyses I do in R and could use some help figuring
    this out.
    
    Thanks,
    Alex
    
    > install.packages("rgdal")
    Installing package into ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4?
    (as ?lib? is unspecified)
    trying URL 'https://cloud.r-project.org/src/contrib/rgdal_1.3-4.tar.gz'
    Content type 'application/x-gzip' length 1664774 bytes (1.6 MB)
    ==================================================
    downloaded 1.6 MB
    
    * installing *source* package ?rgdal? ...
    ** package ?rgdal? successfully unpacked and MD5 sums checked
    configure: R_HOME: /usr/lib/R
    configure: CC: gcc -std=gnu99
    configure: CXX: g++
    configure: C++11 support available
    configure: rgdal: 1.3-4
    checking for /usr/bin/svnversion... no
    configure: svn revision: 766
    checking for gdal-config... /usr/local/bin/gdal-config
    checking gdal-config usability... yes
    configure: GDAL: 2.3.1
    checking C++11 support for GDAL >= 2.3.0... yes
    checking GDAL version >= 1.11.4... yes
    checking gdal: linking with --libs only... no
    checking gdal: linking with --libs and --dep-libs... no
    In file included from /usr/local/include/gdal.h:45:0,
                     from gdal_test.cc:1:
    /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
      newer. #    error Must have C++11 or newer.
          ^
    In file included from /usr/local/include/gdal.h:49:0,
                     from gdal_test.cc:1:
    /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
      before '<' token class CPLXMLTreeCloser: public
      std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
    /usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
      token /usr/local/include/cpl_minixml.h:202:47: error: expected
      unqualified-id before '<' token In file included
      from /usr/local/include/ogr_api.h:45:0,
      from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
    /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
      line /usr/local/include/ogr_core.h:79:28: error: expected declaration
      before end of line In file included
      from /usr/local/include/gdal.h:45:0, from gdal_test.cc:1:
    /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
      newer. #    error Must have C++11 or newer.
          ^
    In file included from /usr/local/include/gdal.h:49:0,
                     from gdal_test.cc:1:
    /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
      before '<' token class CPLXMLTreeCloser: public
      std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
    /usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
      token /usr/local/include/cpl_minixml.h:202:47: error: expected
      unqualified-id before '<' token In file included
      from /usr/local/include/ogr_api.h:45:0,
      from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
    /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
      line /usr/local/include/ogr_core.h:79:28: error: expected declaration
      before end of line configure: Install failure: compilation and/or
      linkage problems. configure: error: GDALAllRegister not found in
      libgdal. ERROR: configuration failed for package ?rgdal?
    * removing ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4/rgdal?
    
    The downloaded source packages are in
    	?/tmp/RtmpeuSDnj/downloaded_packages?
    Warning message:
    In install.packages("rgdal") :
      installation of package ?rgdal? had non-zero exit status
    > 
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r@herry8 @ending from comc@@t@net  Fri Aug 10 00:18:40 2018
From: r@herry8 @ending from comc@@t@net (rsherry8)
Date: Thu, 9 Aug 2018 18:18:40 -0400
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
 <5B6CB101.3000008@comcast.net>
 <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>
Message-ID: <5B6CBDC0.2070206@comcast.net>

Peter,

Here is the R command and its output that you requested:

 > class(AVB)
[1] "xts" "zoo"

Bob
On 8/9/2018 5:29 PM, Peter Langfelder wrote:
> Well, your function uses AVB$AVB.Close, so I assumed AVB is a list (a
> data frame can be thought of as a special list). What do you get when
> you type class(AVB)?
>
> Peter
> On Thu, Aug 9, 2018 at 2:24 PM rsherry8 <rsherry8 at comcast.net> wrote:
>> Peter,
>>
>> Thanks for the response. I tired the following command:
>>       AVB[["AVB.Close"]]
>> and I got:
>>       Error in AVB[["AVB.Close"]] : subscript out of bounds
>> Are you assuming that AVB is a data frame? I do not think AVB is a data
>> frame. Is there a way
>> for me to check?
>> Thanks,
>> Bob
>>
>> On 8/9/2018 3:46 PM, Peter Langfelder wrote:
>>> If I understand it correctly, the function getSymbols creates a
>>> variable with the name being the stock symbol. Then use the function
>>> get(symbol) to retrieve the value of the variable whose name is
>>> contained in the character string `symbol'. Assign that to a variable
>>> (e.g. AVB). You may also have to modify the names of the components
>>> you retrieve from the list AVB. For that, you can use
>>> AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
>>> something like AVB[[paste0(symbol, ".Close"]] to generalize the
>>> retrieval of list components.
>>>
>>> HTH,
>>>
>>> Peter
>>> On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>> I wrote the following function:
>>>>
>>>> # This method gets historical stock data for the stock Avalon Bay whose
>>>> symbol is AVB.
>>>> getReturns <- function(norm = FALSE)
>>>> {
>>>>        library(quantmod)
>>>>
>>>>        getSymbols("AVB", src = "yahoo", from = start, to = end)
>>>>        length = length(  AVB$AVB.Close )
>>>>        close = as.numeric( AVB$AVB.Close )
>>>>        cat( "length = ", length(close ), "\n" )
>>>>        for( i in 1:length-1 )
>>>>            diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>>>        u = mean(diff)
>>>>        stdDev = sd(diff)
>>>>        cat( "stdDev = ", stdDev, "\n" )
>>>>
>>>>        if ( norm == TRUE ) {
>>>>            diff = (diff - u)
>>>>            diff = diff / stdDev
>>>>        }
>>>>        return (diff)
>>>> }
>>>>
>>>> I would like to generalize it to work for any stock by passing in the
>>>> stock symbol. So the header for the
>>>> function would be:
>>>>
>>>> getReturns <- function(symbol, norm = FALSE)
>>>>
>>>> Now how do I update this line:
>>>>        length = length(  AVB$AVB.Close )
>>>> This statement will not work:
>>>>        length = length(  symbol$AVB.Close )
>>>> because the name that holds the closing price is a function of the stock
>>>> symbol.
>>>>
>>>> Thanks,
>>>> Bob
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Fri Aug 10 00:40:47 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 9 Aug 2018 15:40:47 -0700
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
 <5B6CB101.3000008@comcast.net>
 <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>
Message-ID: <CAGxFJbTXnygOdHnCYRWEoZ5W1dwFu+dfH=OGcBFrjCD5iLaX8A@mail.gmail.com>

" I am thinking that there should be an R command to
tell me about the structure of series"

?str
## perhaps also/instead
?summary

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 9, 2018 at 2:29 PM, Peter Langfelder <peter.langfelder at gmail.com
> wrote:

> Well, your function uses AVB$AVB.Close, so I assumed AVB is a list (a
> data frame can be thought of as a special list). What do you get when
> you type class(AVB)?
>
> Peter
> On Thu, Aug 9, 2018 at 2:24 PM rsherry8 <rsherry8 at comcast.net> wrote:
> >
> > Peter,
> >
> > Thanks for the response. I tired the following command:
> >      AVB[["AVB.Close"]]
> > and I got:
> >      Error in AVB[["AVB.Close"]] : subscript out of bounds
> > Are you assuming that AVB is a data frame? I do not think AVB is a data
> > frame. Is there a way
> > for me to check?
> > Thanks,
> > Bob
> >
> > On 8/9/2018 3:46 PM, Peter Langfelder wrote:
> > > If I understand it correctly, the function getSymbols creates a
> > > variable with the name being the stock symbol. Then use the function
> > > get(symbol) to retrieve the value of the variable whose name is
> > > contained in the character string `symbol'. Assign that to a variable
> > > (e.g. AVB). You may also have to modify the names of the components
> > > you retrieve from the list AVB. For that, you can use
> > > AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
> > > something like AVB[[paste0(symbol, ".Close"]] to generalize the
> > > retrieval of list components.
> > >
> > > HTH,
> > >
> > > Peter
> > > On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > >>
> > >> I wrote the following function:
> > >>
> > >> # This method gets historical stock data for the stock Avalon Bay
> whose
> > >> symbol is AVB.
> > >> getReturns <- function(norm = FALSE)
> > >> {
> > >>       library(quantmod)
> > >>
> > >>       getSymbols("AVB", src = "yahoo", from = start, to = end)
> > >>       length = length(  AVB$AVB.Close )
> > >>       close = as.numeric( AVB$AVB.Close )
> > >>       cat( "length = ", length(close ), "\n" )
> > >>       for( i in 1:length-1 )
> > >>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
> > >>       u = mean(diff)
> > >>       stdDev = sd(diff)
> > >>       cat( "stdDev = ", stdDev, "\n" )
> > >>
> > >>       if ( norm == TRUE ) {
> > >>           diff = (diff - u)
> > >>           diff = diff / stdDev
> > >>       }
> > >>       return (diff)
> > >> }
> > >>
> > >> I would like to generalize it to work for any stock by passing in the
> > >> stock symbol. So the header for the
> > >> function would be:
> > >>
> > >> getReturns <- function(symbol, norm = FALSE)
> > >>
> > >> Now how do I update this line:
> > >>       length = length(  AVB$AVB.Close )
> > >> This statement will not work:
> > >>       length = length(  symbol$AVB.Close )
> > >> because the name that holds the closing price is a function of the
> stock
> > >> symbol.
> > >>
> > >> Thanks,
> > >> Bob
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jo@h@m@ulrich @ending from gm@il@com  Fri Aug 10 01:15:58 2018
From: jo@h@m@ulrich @ending from gm@il@com (Joshua Ulrich)
Date: Thu, 9 Aug 2018 18:15:58 -0500
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <5B6CB101.3000008@comcast.net>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
 <5B6CB101.3000008@comcast.net>
Message-ID: <CAPPM_gR+B5f46pat2KDSzy4LehQ+ywPGCoN2tBefEtpU9yjuXA@mail.gmail.com>

Peter was on the right track.  getSymbols() allows you to specify that
you want the value returned as an object instead of load()ed by
setting auto.assign = FALSE.

I've also made other changes to your function:
- Use requireNamespace() so you don't alter the search() path
- Use TTR::ROC() to calculate returns, instead of a loop
- Use more meaningful names for the mean and standard deviation objects
- Use isTRUE() to ensure 'norm' is 'TRUE' and not '1' or '"true"' or
anything else that could be coerced to TRUE

getReturns <-
function(symbol,
         start = "2015-01-01",
         end = Sys.Date(),
         norm = FALSE)
{
    stopifnot(requireNamespace("quantmod"))

    Data <- quantmod::getSymbols(symbol, src = "yahoo",
      from = start, to = end, auto.assign = FALSE)
    cat("length = ", NROW(Data), "\n")
    ret <- TTR::ROC(quantmod::Cl(Data), type = "discrete")
    mu <- mean(ret, na.rm = TRUE)
    sigma <- sd(ret, na.rm = TRUE)
    cat("stdDev = ", sigma, "\n")

    if (isTRUE(norm)) {
        ret <- (ret - mu)
        ret <- ret / sigma
    }
    return(ret)
}

x <- getReturns("IBM")
length =  907
stdDev =  0.01245428
head(x)
              IBM.Close
2015-01-02           NA
2015-01-05 -0.015734932
2015-01-06 -0.021565971
2015-01-07 -0.006535554
2015-01-08  0.021734892
2015-01-09  0.004355530


On Thu, Aug 9, 2018 at 4:24 PM, rsherry8 <rsherry8 at comcast.net> wrote:
> Peter,
>
> Thanks for the response. I tired the following command:
>     AVB[["AVB.Close"]]
> and I got:
>     Error in AVB[["AVB.Close"]] : subscript out of bounds
> Are you assuming that AVB is a data frame? I do not think AVB is a data
> frame. Is there a way
> for me to check?
> Thanks,
> Bob
>
>
> On 8/9/2018 3:46 PM, Peter Langfelder wrote:
>>
>> If I understand it correctly, the function getSymbols creates a
>> variable with the name being the stock symbol. Then use the function
>> get(symbol) to retrieve the value of the variable whose name is
>> contained in the character string `symbol'. Assign that to a variable
>> (e.g. AVB). You may also have to modify the names of the components
>> you retrieve from the list AVB. For that, you can use
>> AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
>> something like AVB[[paste0(symbol, ".Close"]] to generalize the
>> retrieval of list components.
>>
>> HTH,
>>
>> Peter
>> On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>
>>>
>>> I wrote the following function:
>>>
>>> # This method gets historical stock data for the stock Avalon Bay whose
>>> symbol is AVB.
>>> getReturns <- function(norm = FALSE)
>>> {
>>>       library(quantmod)
>>>
>>>       getSymbols("AVB", src = "yahoo", from = start, to = end)
>>>       length = length(  AVB$AVB.Close )
>>>       close = as.numeric( AVB$AVB.Close )
>>>       cat( "length = ", length(close ), "\n" )
>>>       for( i in 1:length-1 )
>>>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>>       u = mean(diff)
>>>       stdDev = sd(diff)
>>>       cat( "stdDev = ", stdDev, "\n" )
>>>
>>>       if ( norm == TRUE ) {
>>>           diff = (diff - u)
>>>           diff = diff / stdDev
>>>       }
>>>       return (diff)
>>> }
>>>
>>> I would like to generalize it to work for any stock by passing in the
>>> stock symbol. So the header for the
>>> function would be:
>>>
>>> getReturns <- function(symbol, norm = FALSE)
>>>
>>> Now how do I update this line:
>>>       length = length(  AVB$AVB.Close )
>>> This statement will not work:
>>>       length = length(  symbol$AVB.Close )
>>> because the name that holds the closing price is a function of the stock
>>> symbol.
>>>
>>> Thanks,
>>> Bob
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2018 | www.rinfinance.com


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Aug 10 03:19:49 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 09 Aug 2018 18:19:49 -0700
Subject: [R] Help reinstalling rgdal (Ubuntu 16.04)
In-Reply-To: <FDA106CA-4AF9-449C-93C7-609FFAE3B20A@llnl.gov>
References: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
 <FDA106CA-4AF9-449C-93C7-609FFAE3B20A@llnl.gov>
Message-ID: <B288ADA5-7C74-4184-9AA0-AD1D63F50E16@dcn.davis.ca.us>

Or ask on R-sig-debian...

On August 9, 2018 3:13:38 PM PDT, "MacQueen, Don via R-help" <r-help at r-project.org> wrote:
>There are quite a few messages on R-sig-geo about installing rgdal on
>Ubuntu. Maybe one of them contains your solution?
>(I use Mac, so can't help directly)
>
>-Don
>
>--
>Don MacQueen
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>Lab cell 925-724-7509
> 
> 
>
>?On 8/9/18, 8:36 AM, "R-help on behalf of Alexandra Thorn"
><r-help-bounces at r-project.org on behalf of mail at alexandrathorn.com>
>wrote:
>
>    Hi all,
>    
>    Following some updates to R that I received via Synaptic Package
>    Manager on Ubuntu 16.04 (looks like I now have R 3.4.4-1xenial0), I
>    have been unable to reinstall rgdal, and I need help.
>    
>    Initially I was getting error messages about dependencies on GDAL
>   1.11.4, but after following instructions to install GDAL from source
>(into my /usr/local directory) I'm now getting a different set of error
>  messages (see the output error messages posted below my signature).  
>    
> I can't tell if this means that I've made a mistake installing GDAL or
>   if there's some other problem with my setup/configuration.  I really
> need rgdal for the analyses I do in R and could use some help figuring
>    this out.
>    
>    Thanks,
>    Alex
>    
>    > install.packages("rgdal")
>Installing package into
>?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4?
>    (as ?lib? is unspecified)
>trying URL 'https://cloud.r-project.org/src/contrib/rgdal_1.3-4.tar.gz'
>    Content type 'application/x-gzip' length 1664774 bytes (1.6 MB)
>    ==================================================
>    downloaded 1.6 MB
>    
>    * installing *source* package ?rgdal? ...
>    ** package ?rgdal? successfully unpacked and MD5 sums checked
>    configure: R_HOME: /usr/lib/R
>    configure: CC: gcc -std=gnu99
>    configure: CXX: g++
>    configure: C++11 support available
>    configure: rgdal: 1.3-4
>    checking for /usr/bin/svnversion... no
>    configure: svn revision: 766
>    checking for gdal-config... /usr/local/bin/gdal-config
>    checking gdal-config usability... yes
>    configure: GDAL: 2.3.1
>    checking C++11 support for GDAL >= 2.3.0... yes
>    checking GDAL version >= 1.11.4... yes
>    checking gdal: linking with --libs only... no
>    checking gdal: linking with --libs and --dep-libs... no
>    In file included from /usr/local/include/gdal.h:45:0,
>                     from gdal_test.cc:1:
>  /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>      newer. #    error Must have C++11 or newer.
>          ^
>    In file included from /usr/local/include/gdal.h:49:0,
>                     from gdal_test.cc:1:
> /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
>      before '<' token class CPLXMLTreeCloser: public
>      std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
>/usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
>      token /usr/local/include/cpl_minixml.h:202:47: error: expected
>      unqualified-id before '<' token In file included
>      from /usr/local/include/ogr_api.h:45:0,
>      from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
> /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
>  line /usr/local/include/ogr_core.h:79:28: error: expected declaration
>      before end of line In file included
>      from /usr/local/include/gdal.h:45:0, from gdal_test.cc:1:
>  /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>      newer. #    error Must have C++11 or newer.
>          ^
>    In file included from /usr/local/include/gdal.h:49:0,
>                     from gdal_test.cc:1:
> /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
>      before '<' token class CPLXMLTreeCloser: public
>      std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
>/usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
>      token /usr/local/include/cpl_minixml.h:202:47: error: expected
>      unqualified-id before '<' token In file included
>      from /usr/local/include/ogr_api.h:45:0,
>      from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
> /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
>  line /usr/local/include/ogr_core.h:79:28: error: expected declaration
>      before end of line configure: Install failure: compilation and/or
>      linkage problems. configure: error: GDALAllRegister not found in
>      libgdal. ERROR: configuration failed for package ?rgdal?
>    * removing ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4/rgdal?
>    
>    The downloaded source packages are in
>    	?/tmp/RtmpeuSDnj/downloaded_packages?
>    Warning message:
>    In install.packages("rgdal") :
>      installation of package ?rgdal? had non-zero exit status
>    > 
>    
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
>    
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From mi@ojpm @ending from gm@il@com  Fri Aug 10 10:59:45 2018
From: mi@ojpm @ending from gm@il@com (John)
Date: Fri, 10 Aug 2018 16:59:45 +0800
Subject: [R] The auto.arima function in forecast package
Message-ID: <CABcx46ARs7rCdBS4FgQz25Eeh0euSf9-WGrz3r8dTXgWFw9c-g@mail.gmail.com>

Hi,

   I am wondering if I am doing correctly, but my auto.arima usually (if
not always) give me (0,1,0), whatever portion of the series I take. In the
following instances, only the last one yields ARIMA(0,1,1), and all the
other cases yield ARIMA(0,1,0). I would like to do forecast based on ARIMA.
The forecast with ARIMA(0,1,0) is exactly the random walk forecast for any
forecasting horizon h, so it does not make much sense.... Am I doing
anything wrong? Is the data very unusual?

   The length of the df_arima sequence is 68. My data is seasonally
adjusted, so I use seasonal = FALSE.

> auto.arima(df_arima, d=1, ic="aic", seasonal = FALSE)
Series: df_arima
ARIMA(0,1,0)

sigma^2 estimated as 0.9323:  log likelihood=-221.43
AIC=444.85   AICc=444.88   BIC=447.93

> auto.arima(df_arima[2:30], d=1, ic="aic", seasonal = FALSE)
Series: df_arima[2:30]
ARIMA(0,1,0)

sigma^2 estimated as 1.486:  log likelihood=-45.28
AIC=92.56   AICc=92.71   BIC=93.89
> auto.arima(df_arima[30:50], d=1, ic="aic", seasonal = FALSE)
Series: df_arima[30:50]
ARIMA(0,1,0)

sigma^2 estimated as 2.065:  log likelihood=-35.63
AIC=73.26   AICc=73.48   BIC=74.25
> auto.arima(df_arima[30:65], d=1, ic="aic", seasonal = FALSE)
Series: df_arima[30:65]
ARIMA(0,1,1)

Coefficients:
         ma1
      0.3684
s.e.  0.1591

sigma^2 estimated as 1.328:  log likelihood=-54.19
AIC=112.39   AICc=112.76   BIC=115.5


> dput(df_arima)
c(0.206955966502065, 0.572310398166964, 0.730924932354315,
1.41842200551883,
3.46103800972619, 3.61249423115895, 5.82223437508589, 4.16838241173942,
3.41346768155648, 0.862064978610255, 0.998745364906517, 0.519274399474301,
-1.11283353732583, -0.735660435061958, -0.780332562883557,
0.835729609943847,
2.72188993637388, 2.28434816118952, 1.89419627788212, 0.808622045623819,
0.628929267637468, -0.605142332415043, -1.50590253313166,
-0.288872689519148,
0.779724144195981, 1.77156391706856, 1.54853781756041, 3.31419159924959,
1.93558418905826, 1.2733744986462, 1.08821585241274, 2.62853576193935,
3.73925259835317, 4.36605858718784, 4.94030870469473, 4.95025405015856,
3.62293670685028, 2.66083271862916, 2.63088962945459, 2.64079870265661,
2.24308372288402, 4.60965981893589, 5.61665338477875, 4.13854855208327,
2.74923595127379, 1.95704807193253, 1.39700634338462, -3.2051540517546,
-4.14645815871689, -3.55954963127346, -2.75935917560429, -2.35979888878128,
-1.60997264659325, 0.107359485533354, 0.452171464181572, 1.83710430300006,
2.05388942618911, 1.42071194194746, 0.62281728667859, 0.66619920044817,
1.91899026506288, 0.876017396693274, 0.767997179685187, 0.960763098531148,
1.07168884361519, 1.7179971391635, 0.916107067445848, 0.488814956401007,
0.445930327726551, 0.700746383716555, 1.85843822164806, 0.892473264860727,
0.614568090119794, 2.4071141581713, 1.95656784524512, 1.97416030945137,
1.50143287537079, 2.16462319254254, 2.07797672518777, 0.272208427739407,
0.798064671535004, 0.754477049206304, 1.15345347401843, 1.2569270188491,
1.04667488857908, 1.61549969176582, 1.61397592409376, 2.15802281566817,
1.77514416862246, 1.37441120562698, 2.02489513295532, 2.58699935920175,
2.75245197313523, 2.23920076522477, 1.5517277192193, 2.1968256454034,
2.56612088350139, 1.58214013021238, 0.224868329892303, 0, 0.75815516785358,
0.306075421735685, -0.911618439021877, -0.851059960629386,
0.920475843398605,
0.204019124781452, 0.265049070791767, 0.693380201646732, 1.76190014304951,
1.7409678665274, 2.30875574967095, 3.1616985460498, 3.03416937102321,
2.51100317138793, 1.74651451299397, 2.1955027765292, 0.885663954102278,
0.42162278205693, -0.919995110735239, -1.09905745071531, -2.68791519080633,
-3.351439, -2.10834457783508, -2.20921682103322, -0.74375338663687,
-0.402576080931594, 1.20253696682322, 1.49061195023896, 0.526155117506621,
1.48289074384766, 0.627624111314717, 0.262639414167709, 0.101025401449073,
0.667507628973207, 0.86863891914688, 0.603620359927048, 1.53734977063493,
1.63989774985629, 2.06996035293847, 1.23150306020205, 1.00602988533123,
1.46753831297777, 1.28396719372157, 1.22372099999999, 0.42010456383097,
1.68739489046037, 1.0009947634714, 0.218850966640427, 0.218698677177565,
0.457733617597422, 1.42090579656218, 0.436897503947153, 1.05592733175737,
1.67544706250284, 2.69758588203255, 2.87640149597799, 2.13003529065778,
2.42946437023286, 2.32608159085508, 1.97956200691809, 0.274402066259904
)

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Aug 10 15:48:25 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 10 Aug 2018 06:48:25 -0700 (PDT)
Subject: [R] Resolving installed package updates warning
Message-ID: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>

   Updating installed packages ends with a warning:

Warning message:
In install.packages(update[instlib == l, "Package"], l, contriburl = contriburl,  :
   installation of package ?rgdal? had non-zero exit status

   What steps should I take to correct this?

Rich


From m@rko@lun@13 @ending from gm@il@com  Fri Aug 10 16:00:33 2018
From: m@rko@lun@13 @ending from gm@il@com (=?UTF-8?Q?Marco_Antonio_P=C3=A9rez?=)
Date: Fri, 10 Aug 2018 11:00:33 -0300
Subject: [R] help
Message-ID: <CAON01EbSs=z6Gd6vPaa9aQReiJTwi6rqHyKBFJ71Wo+bT=yh+g@mail.gmail.com>

 I am trying to write a function to make a matrix of precipitation with
this secuencie;
######## PRIMER PERIODO
cordex1 <-
nc_open("pr_CAM-44i_ICHEC-EC-EARTH_rcp45_r12i1p1_SMHI-RCA4_v1_mon_200601-201012.nc")
fullmon1<-ncvar_get(cordex1,"pr")
lat<-ncvar_get(cordex1,"lat", start=c(35.5),count=c(20))
lon <-ncvar_get(cordex1,"lon", start=c(125),count=c(21.5))
t <- ncvar_get(cordex1,"time")
nlon <- dim(lon)
nlat <- dim(lat)
nt <- dim(t)
fulldatav <- as.vector(fullmon1)
fulldata <- matrix(fulldatav, nrow=nlon*nlat, ncol=nt)
lonlat <- expand.grid(lon,lat)
df_cordex1<- data.frame(lonlat,fulldata)

but with the expresion  fulldata <- matrix(fulldatav, nrow=nlon*nlat,
ncol=nt) this error appears
Warning message:
In matrix(fulldatav, nrow = nlon * nlat, ncol = nt) :
  data length [1378620] is not a sub-multiple or multiple of the number of
rows [420]

Somebody help me!!!

	[[alternative HTML version deleted]]


From r@vi@v@r@dh@n @ending from jhu@edu  Fri Aug 10 17:22:12 2018
From: r@vi@v@r@dh@n @ending from jhu@edu (Ravi Varadhan)
Date: Fri, 10 Aug 2018 15:22:12 +0000
Subject: [R] Fast matrix multiplication
Message-ID: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>

Hi,

I would like to compute:  A %*% B %*% t(A)



A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).



Here is a sample code.



M <- 10000

N <- 100

A <- matrix(rnorm(M*N), M, N)

B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric positive-definite matrix



# method 1

system.time(D <- A %*% B %*% t(A))



# I can obtain speedup by using a Cholesky decomposition of B

# method 2

system.time({

C <- t(chol(B))

E <- tcrossprod(A%*%C)

})



all.equal(D, E)



I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.



Thanks,

Ravi



	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Fri Aug 10 18:15:37 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 10 Aug 2018 16:15:37 +0000
Subject: [R] Resolving installed package updates warning
In-Reply-To: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
Message-ID: <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>

I would start by trying to install rgdal by itself, rather than as part of a "batch" update. As in

  Install.packages('rgdal')

 My expectation is that you will see a more complete error message specific to rgdal, which presumably will provide a clue or pointer.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/10/18, 6:48 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       Updating installed packages ends with a warning:
    
    Warning message:
    In install.packages(update[instlib == l, "Package"], l, contriburl = contriburl,  :
       installation of package ?rgdal? had non-zero exit status
    
       What steps should I take to correct this?
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From i@t@z@hn @ending from gm@il@com  Fri Aug 10 18:19:57 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Fri, 10 Aug 2018 12:19:57 -0400
Subject: [R] Fast matrix multiplication
In-Reply-To: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
Message-ID: <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>

Hi Ravi,

You can achieve substantial speed up by using a faster BLAS (e.g.,
OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6
year old, but 8 core) system your example takes 3.9 seconds with using
the reference BLAS and only 0.9 seconds using OpenBLAS.

Best,
Ista
On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Hi,
>
> I would like to compute:  A %*% B %*% t(A)
>
>
>
> A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
>
>
>
> Here is a sample code.
>
>
>
> M <- 10000
>
> N <- 100
>
> A <- matrix(rnorm(M*N), M, N)
>
> B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric positive-definite matrix
>
>
>
> # method 1
>
> system.time(D <- A %*% B %*% t(A))
>
>
>
> # I can obtain speedup by using a Cholesky decomposition of B
>
> # method 2
>
> system.time({
>
> C <- t(chol(B))
>
> E <- tcrossprod(A%*%C)
>
> })
>
>
>
> all.equal(D, E)
>
>
>
> I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
>
>
>
> Thanks,
>
> Ravi
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From HDor@n @ending from @ir@org  Fri Aug 10 18:22:42 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Fri, 10 Aug 2018 16:22:42 +0000
Subject: [R] Fast matrix multiplication
Message-ID: <D79333E7.529D3%hdoran@air.org>

Yeah, you might not be able to go much faster here unless A has some
specialized structure that you can take advantage of (e.g., sparsity)?

On 8/10/18, 11:22 AM, "Ravi Varadhan" <ravi.varadhan at jhu.edu> wrote:

>Hi,
>
>I would like to compute:  A %*% B %*% t(A)
>
>
>
>A is a mxn matrix and B is an nxn symmetric, positive-definite matrix,
>where m is large relative to n (e.g., m=50,000 and n=100).
>
>
>
>Here is a sample code.
>
>
>
>M <- 10000
>
>N <- 100
>
>A <- matrix(rnorm(M*N), M, N)
>
>B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric
>positive-definite matrix
>
>
>
># method 1
>
>system.time(D <- A %*% B %*% t(A))
>
>
>
># I can obtain speedup by using a Cholesky decomposition of B
>
># method 2
>
>system.time({
>
>C <- t(chol(B))
>
>E <- tcrossprod(A%*%C)
>
>})
>
>
>
>all.equal(D, E)
>
>
>
>I am wondering how to obtain more substantial speedup.  Any suggestions
>would be greatly appreciated.
>
>
>
>Thanks,
>
>Ravi
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From @tef@no@@ofi@ @ending from regione@m@rche@it  Fri Aug 10 18:48:14 2018
From: @tef@no@@ofi@ @ending from regione@m@rche@it (Stefano Sofia)
Date: Fri, 10 Aug 2018 16:48:14 +0000
Subject: [R] cumulate of snow cumulates from daily values of different
 automatic stations for some time intervals
Message-ID: <8B435C9568170B469AE31E8891E8CC4F54CCBF0B@ESINO.regionemarche.intra>

Dear R-list users,
I have 10 data frames (called df1, df2, ... df10), where each of them contains snow data from an automatic meteorological station (obviously each station has a different station code).
Here is an example of df1:

station_code date_factor date_POSIX snow
217 1999-12-15 1999-12-15  0
217 1999-12-16 1999-12-16  0
217 1999-12-17 1999-12-17 38
217 1999-12-18 1999-12-18 31
217 1999-12-19 1999-12-19 21
217 1999-12-20 1999-12-20 12
217 1999-12-21 1999-12-21 42
217 1999-12-22 1999-12-22 61
217 1999-12-23 1999-12-23 57
217 1999-12-24 1999-12-24 48
...

where
> sapply(df1, class)
$station_code
[1] "numeric"

$date_factor
[1] "factor"

$date_POSIX
[1] "POSIXct" "POSIXt"

$snow
[1] "integer"

Given a series of max three intervals (example with two intervals: from 1st to 12th of January 2000 and from 23rd to 28th of March 2000), I need to evaluate for each station the total snow cumulate for all the intervals selected, and finally create a data frame where for each line there is the station code and the snow cumulate. It should be like

station_code total_snow_cumulate
217 125
218 80
...

Could somebody show me a direction for an efficient solution?

Thank you for your attention and your help
Stefano


         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Aug 10 18:53:54 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 10 Aug 2018 09:53:54 -0700 (PDT)
Subject: [R] Resolving installed package updates warning
In-Reply-To: <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
 <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
Message-ID: <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>

On Fri, 10 Aug 2018, MacQueen, Don wrote:

> I would start by trying to install rgdal by itself, rather than as part of
> a "batch" update. As in
>
>  Install.packages('rgdal')

Don,

   rgdal was supposed to be installed, but you have a valid point.

> My expectation is that you will see a more complete error message specific
> to rgdal, which presumably will provide a clue or pointer.

   Boy howdy! This is interesting:

* installing *source* package ?rgdal? ...
** package ?rgdal? successfully unpacked and MD5 sums checked
configure: R_HOME: /usr/lib/R
configure: CC: gcc
configure: CXX: g++
configure: C++11 support available
configure: rgdal: 1.3-4
checking for /usr/bin/svnversion... yes
configure: svn revision: 766
checking for gdal-config... /usr/bin/gdal-config
checking gdal-config usability... yes
configure: GDAL: 2.3.0
checking C++11 support for GDAL >= 2.3.0... yes
checking GDAL version >= 1.11.4... yes
checking gdal: linking with --libs only... no
checking gdal: linking with --libs and --dep-libs... no
In file included from /usr/include/gdal.h:45:0,
                  from gdal_test.cc:1:
/usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
  #    error Must have C++11 or newer.
       ^
In file included from /usr/include/gdal.h:49:0,
                  from gdal_test.cc:1:
/usr/include/cpl_minixml.h:202:47: error: expected template-name before '<' token
  class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter>
                                                ^
/usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
/usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before '<' token
In file included from /usr/include/ogr_api.h:45:0,
                  from /usr/include/gdal.h:50,
                  from gdal_test.cc:1:
/usr/include/ogr_core.h:79:28: error: expected '}' before end of line
/usr/include/ogr_core.h:79:28: error: expected declaration before end of line
In file included from /usr/include/gdal.h:45:0,
                  from gdal_test.cc:1:
/usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
  #    error Must have C++11 or newer.
       ^
In file included from /usr/include/gdal.h:49:0,
                  from gdal_test.cc:1:
/usr/include/cpl_minixml.h:202:47: error: expected template-name before '<' token
  class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter>
                                                ^
/usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
/usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before '<' token
In file included from /usr/include/ogr_api.h:45:0,
                  from /usr/include/gdal.h:50,
                  from gdal_test.cc:1:
/usr/include/ogr_core.h:79:28: error: expected '}' before end of line
/usr/include/ogr_core.h:79:28: error: expected declaration before end of line
configure: Install failure: compilation and/or linkage problems.
configure: error: GDALAllRegister not found in libgdal.
ERROR: configuration failed for package ?rgdal?
* removing ?/usr/lib/R/library/rgdal?
* restoring previous ?/usr/lib/R/library/rgdal?

The downloaded source packages are in
 	?/tmp/RtmpVGIz3Q/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("rgdal") :
   installation of package ?rgdal? had non-zero exit status

   Installed here are:
gcc-5.5.0-i586-1_slack14.2
gcc-g++-5.5.0-i586-1_slack14.2
gcc-gfortran-5.5.0-i586-1_slack14.2
gcc-gnat-5.5.0-i586-1_slack14.2
gcc-go-5.5.0-i586-1_slack14.2
gcc-java-5.5.0-i586-1_slack14.2
gcc-objc-5.5.0-i586-1_slack14.2
gccmakedep-1.0.3-noarch-1

and

gdal-2.3.0-i586-1_SBo

   What's C++11?

Rich


From m@cqueen1 @ending from llnl@gov  Fri Aug 10 19:19:45 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 10 Aug 2018 17:19:45 +0000
Subject: [R] Resolving installed package updates warning
In-Reply-To: <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
 <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
 <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
Message-ID: <AF50F4B7-DA00-4536-9CDA-FF03908F5A7F@llnl.gov>

Rich,

C++11 is a programming language.

Interestingly, someone else asked for help yesterday with exactly the same error message for rgdal. The subject line was

  "Help reinstalling rgdal (Ubuntu 16.04)"

The suggestions were to visit the mailing lists R-sig-geo and/or R-sig-debian.

It's puzzling to me that the output first says
   configure: C++11 support available
and then later says
  /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.

Maybe the C+11 on the system needs to be a newer version...but this level is pretty much over my head.

I wouldn't even look at the other error messages until that one has been solved.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/10/18, 9:53 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Fri, 10 Aug 2018, MacQueen, Don wrote:
    
    > I would start by trying to install rgdal by itself, rather than as part of
    > a "batch" update. As in
    >
    >  Install.packages('rgdal')
    
    Don,
    
       rgdal was supposed to be installed, but you have a valid point.
    
    > My expectation is that you will see a more complete error message specific
    > to rgdal, which presumably will provide a clue or pointer.
    
       Boy howdy! This is interesting:
    
    * installing *source* package ?rgdal? ...
    ** package ?rgdal? successfully unpacked and MD5 sums checked
    configure: R_HOME: /usr/lib/R
    configure: CC: gcc
    configure: CXX: g++
    configure: C++11 support available
    configure: rgdal: 1.3-4
    checking for /usr/bin/svnversion... yes
    configure: svn revision: 766
    checking for gdal-config... /usr/bin/gdal-config
    checking gdal-config usability... yes
    configure: GDAL: 2.3.0
    checking C++11 support for GDAL >= 2.3.0... yes
    checking GDAL version >= 1.11.4... yes
    checking gdal: linking with --libs only... no
    checking gdal: linking with --libs and --dep-libs... no
    In file included from /usr/include/gdal.h:45:0,
                      from gdal_test.cc:1:
    /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
      #    error Must have C++11 or newer.
           ^
    In file included from /usr/include/gdal.h:49:0,
                      from gdal_test.cc:1:
    /usr/include/cpl_minixml.h:202:47: error: expected template-name before '<' token
      class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter>
                                                    ^
    /usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
    /usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before '<' token
    In file included from /usr/include/ogr_api.h:45:0,
                      from /usr/include/gdal.h:50,
                      from gdal_test.cc:1:
    /usr/include/ogr_core.h:79:28: error: expected '}' before end of line
    /usr/include/ogr_core.h:79:28: error: expected declaration before end of line
    In file included from /usr/include/gdal.h:45:0,
                      from gdal_test.cc:1:
    /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
      #    error Must have C++11 or newer.
           ^
    In file included from /usr/include/gdal.h:49:0,
                      from gdal_test.cc:1:
    /usr/include/cpl_minixml.h:202:47: error: expected template-name before '<' token
      class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter>
                                                    ^
    /usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
    /usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before '<' token
    In file included from /usr/include/ogr_api.h:45:0,
                      from /usr/include/gdal.h:50,
                      from gdal_test.cc:1:
    /usr/include/ogr_core.h:79:28: error: expected '}' before end of line
    /usr/include/ogr_core.h:79:28: error: expected declaration before end of line
    configure: Install failure: compilation and/or linkage problems.
    configure: error: GDALAllRegister not found in libgdal.
    ERROR: configuration failed for package ?rgdal?
    * removing ?/usr/lib/R/library/rgdal?
    * restoring previous ?/usr/lib/R/library/rgdal?
    
    The downloaded source packages are in
     	?/tmp/RtmpVGIz3Q/downloaded_packages?
    Updating HTML index of packages in '.Library'
    Making 'packages.html' ... done
    Warning message:
    In install.packages("rgdal") :
       installation of package ?rgdal? had non-zero exit status
    
       Installed here are:
    gcc-5.5.0-i586-1_slack14.2
    gcc-g++-5.5.0-i586-1_slack14.2
    gcc-gfortran-5.5.0-i586-1_slack14.2
    gcc-gnat-5.5.0-i586-1_slack14.2
    gcc-go-5.5.0-i586-1_slack14.2
    gcc-java-5.5.0-i586-1_slack14.2
    gcc-objc-5.5.0-i586-1_slack14.2
    gccmakedep-1.0.3-noarch-1
    
    and
    
    gdal-2.3.0-i586-1_SBo
    
       What's C++11?
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @ending from gm@il@com  Fri Aug 10 19:20:58 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 10 Aug 2018 10:20:58 -0700
Subject: [R] Resolving installed package updates warning
In-Reply-To: <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
 <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
 <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSX7y3c2w8Vmh8s+sqU0Y_gEMw7JP6JeYj2sNruWmAkeg@mail.gmail.com>

  What's C++11?

Google it!

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Aug 10, 2018 at 9:53 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 10 Aug 2018, MacQueen, Don wrote:
>
> I would start by trying to install rgdal by itself, rather than as part of
>> a "batch" update. As in
>>
>>  Install.packages('rgdal')
>>
>
> Don,
>
>   rgdal was supposed to be installed, but you have a valid point.
>
> My expectation is that you will see a more complete error message specific
>> to rgdal, which presumably will provide a clue or pointer.
>>
>
>   Boy howdy! This is interesting:
>
> * installing *source* package ?rgdal? ...
> ** package ?rgdal? successfully unpacked and MD5 sums checked
> configure: R_HOME: /usr/lib/R
> configure: CC: gcc
> configure: CXX: g++
> configure: C++11 support available
> configure: rgdal: 1.3-4
> checking for /usr/bin/svnversion... yes
> configure: svn revision: 766
> checking for gdal-config... /usr/bin/gdal-config
> checking gdal-config usability... yes
> configure: GDAL: 2.3.0
> checking C++11 support for GDAL >= 2.3.0... yes
> checking GDAL version >= 1.11.4... yes
> checking gdal: linking with --libs only... no
> checking gdal: linking with --libs and --dep-libs... no
> In file included from /usr/include/gdal.h:45:0,
>                  from gdal_test.cc:1:
> /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
>  #    error Must have C++11 or newer.
>       ^
> In file included from /usr/include/gdal.h:49:0,
>                  from gdal_test.cc:1:
> /usr/include/cpl_minixml.h:202:47: error: expected template-name before
> '<' token
>  class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode,
> CPLXMLTreeCloserDeleter>
>                                                ^
> /usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
> /usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before
> '<' token
> In file included from /usr/include/ogr_api.h:45:0,
>                  from /usr/include/gdal.h:50,
>                  from gdal_test.cc:1:
> /usr/include/ogr_core.h:79:28: error: expected '}' before end of line
> /usr/include/ogr_core.h:79:28: error: expected declaration before end of
> line
> In file included from /usr/include/gdal.h:45:0,
>                  from gdal_test.cc:1:
> /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
>  #    error Must have C++11 or newer.
>       ^
> In file included from /usr/include/gdal.h:49:0,
>                  from gdal_test.cc:1:
> /usr/include/cpl_minixml.h:202:47: error: expected template-name before
> '<' token
>  class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode,
> CPLXMLTreeCloserDeleter>
>                                                ^
> /usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
> /usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before
> '<' token
> In file included from /usr/include/ogr_api.h:45:0,
>                  from /usr/include/gdal.h:50,
>                  from gdal_test.cc:1:
> /usr/include/ogr_core.h:79:28: error: expected '}' before end of line
> /usr/include/ogr_core.h:79:28: error: expected declaration before end of
> line
> configure: Install failure: compilation and/or linkage problems.
> configure: error: GDALAllRegister not found in libgdal.
> ERROR: configuration failed for package ?rgdal?
> * removing ?/usr/lib/R/library/rgdal?
> * restoring previous ?/usr/lib/R/library/rgdal?
>
> The downloaded source packages are in
>         ?/tmp/RtmpVGIz3Q/downloaded_packages?
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("rgdal") :
>   installation of package ?rgdal? had non-zero exit status
>
>   Installed here are:
> gcc-5.5.0-i586-1_slack14.2
> gcc-g++-5.5.0-i586-1_slack14.2
> gcc-gfortran-5.5.0-i586-1_slack14.2
> gcc-gnat-5.5.0-i586-1_slack14.2
> gcc-go-5.5.0-i586-1_slack14.2
> gcc-java-5.5.0-i586-1_slack14.2
> gcc-objc-5.5.0-i586-1_slack14.2
> gccmakedep-1.0.3-noarch-1
>
> and
>
> gdal-2.3.0-i586-1_SBo
>
>   What's C++11?
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@herry8 @ending from comc@@t@net  Fri Aug 10 19:32:33 2018
From: r@herry8 @ending from comc@@t@net (rsherry8)
Date: Fri, 10 Aug 2018 13:32:33 -0400
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <e6ac255f-5ffa-6b4d-1943-bd85a5f66e3b@gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <7dabb432-627a-a943-9c5c-f7b12d680b25@gmail.com>
 <5B6CAA92.8050806@comcast.net>
 <8bfc1997-c6ad-1600-f8be-1e28127ecfea@gmail.com> <5B6CBE70.409@comcast.net>
 <e6ac255f-5ffa-6b4d-1943-bd85a5f66e3b@gmail.com>
Message-ID: <5B6DCC31.4080109@comcast.net>

Duncan,

Since you asked, here is an updated version of my function.

# This method gets the Data.
getReturns1 <- function(symbol, norm = FALSE)
{
     library(quantmod)

     series = getSymbols(symbol, src = "yahoo", from = start, to = end, 
auto.assign = FALSE)
     length <- nrow(  series )
     close <- as.numeric(series[, paste0(symbol, ".Close")])
     cat( "length = ", length(close ), "\n" )
     diff = seq(1:(length-1))
     for( i in 1:length-1 )
         diff[i] = ((close[i+1] - close[i]) ) / close[i]
     u = mean(diff)
     stdDev = sd(diff)
     cat( "stdDev = ", stdDev, "\n" )

     if ( norm == TRUE ) {
         diff = (diff - u)
         diff = diff / stdDev
     }
     cat( "length = ", length(diff ), "\n" )

     return (diff)
}

I believe it is now working correctly. I did add the following statement:
         diff = seq(1:(length-1))
I thank you for your help. I also think the version of the function
posted by Joshua Ulrich is better. I found his post to be very educational.

Bob

On 8/9/2018 6:48 PM, Duncan Murdoch wrote:
> On 09/08/2018 6:21 PM, rsherry8 wrote:
>> Duncan,
>>
>> You are right and when I run with auto.assign=FALSE it works.
>
> You should post your working version of the function to the mailing list.
>
> Duncan Murdoch
>
>>
>> Thank you very much,
>> Bob
>>
>> On 8/9/2018 6:11 PM, Duncan Murdoch wrote:
>>> On 09/08/2018 4:56 PM, rsherry8 wrote:
>>>> Duncan,
>>>>
>>>> Thanks for the response. I tired the following:
>>>>        >  series <- getSymbols("AVB", src = "yahoo", from = start, to
>>>> = end)
>>>
>>> You missed the auto.assign=FALSE argument.
>>>
>>>>        > series[0]
>>>>            character(0)
>>>>        > nrow( series )
>>>>            NULL
>>>> nrow( series ) returned NULL. I do not understand why. I am thinking
>>>> that there should be an R command to
>>>> tell me about the structure of series. I tried: typeof( series ) and
>>>> got: "character". Is there a better command for
>>>> me to use other than typeof?
>>>
>>> Won't help here, but often str() is more informative than typeof().
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> I also tried this command:
>>>>        c1 <- as.numeric(series[, paste0(symbol, ".Close")])
>>>> where symbol held the value "AVB" and I got:
>>>>        Error in series[, paste0(symbol, ".Close")] :
>>>>        incorrect number of dimensions
>>>>
>>>> Please help.
>>>> Thanks,
>>>> Bob
>>>>
>>>> On 8/9/2018 3:51 PM, Duncan Murdoch wrote:
>>>>> On 09/08/2018 1:12 PM, rsherry8 wrote:
>>>>>>
>>>>>> I wrote the following function:
>>>>>>
>>>>>> # This method gets historical stock data for the stock Avalon Bay
>>>>>> whose
>>>>>> symbol is AVB.
>>>>>> getReturns <- function(norm = FALSE)
>>>>>> {
>>>>>>         library(quantmod)
>>>>>>
>>>>>>         getSymbols("AVB", src = "yahoo", from = start, to = end)
>>>>>>         length = length(  AVB$AVB.Close )
>>>>>>         close = as.numeric( AVB$AVB.Close )
>>>>>>         cat( "length = ", length(close ), "\n" )
>>>>>>         for( i in 1:length-1 )
>>>>>>             diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>>>>>         u = mean(diff)
>>>>>>         stdDev = sd(diff)
>>>>>>         cat( "stdDev = ", stdDev, "\n" )
>>>>>>
>>>>>>         if ( norm == TRUE ) {
>>>>>>             diff = (diff - u)
>>>>>>             diff = diff / stdDev
>>>>>>         }
>>>>>>         return (diff)
>>>>>> }
>>>>>>
>>>>>> I would like to generalize it to work for any stock by passing in 
>>>>>> the
>>>>>> stock symbol. So the header for the
>>>>>> function would be:
>>>>>>
>>>>>> getReturns <- function(symbol, norm = FALSE)
>>>>>
>>>>> The quantmod function getSymbols has arguments auto.assign which
>>>>> defaults to TRUE.  Set it to FALSE, and then keep the result of the
>>>>> call, instead of assuming that a variable named AVB has been created.
>>>>>
>>>>> That is,
>>>>>
>>>>>          series <- getSymbols(symbol, src = "yahoo", from = start, 
>>>>> to =
>>>>> end, auto.assign = FALSE)
>>>>>          length <- nrow(  series )
>>>>>
>>>>> It will still name the columns according to the symbol, so you would
>>>>> also need
>>>>>
>>>>>         close <- as.numeric(series[, paste0(symbol, ".Close")])
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>>
>>>>>> Now how do I update this line:
>>>>>>         length = length(  AVB$AVB.Close )
>>>>>> This statement will not work:
>>>>>>         length = length(  symbol$AVB.Close )
>>>>>> because the name that holds the closing price is a function of the
>>>>>> stock
>>>>>> symbol.
>>>>>>
>>>>>> Thanks,
>>>>>> Bob
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>>
>>
>
>


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Aug 10 20:08:57 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 10 Aug 2018 11:08:57 -0700 (PDT)
Subject: [R] Resolving installed package updates warning
In-Reply-To: <AF50F4B7-DA00-4536-9CDA-FF03908F5A7F@llnl.gov>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
 <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
 <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
 <AF50F4B7-DA00-4536-9CDA-FF03908F5A7F@llnl.gov>
Message-ID: <alpine.LNX.2.20.1808101104590.14707@salmo.appl-ecosys.com>

On Fri, 10 Aug 2018, MacQueen, Don wrote:

> C++11 is a programming language.

Don,

   That's what I assumed; a version of c++, which is installed here by
default. Perhaps not that verision, but ...

>   configure: C++11 support available
> and then later says
>  /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.

>    configure: CXX: g++
>    configure: C++11 support available
>    checking C++11 support for GDAL >= 2.3.0... yes
>    checking GDAL version >= 1.11.4... yes

   Since the configuration finds C++11 support available and a sufficiently
current version of gdal the warning/errors make no sense to me.

   FWIW, there's no issue compiling/using gdal on slackware; I've done so for
many years.

Rich


From rm@h@rp @ending from me@com  Fri Aug 10 22:08:24 2018
From: rm@h@rp @ending from me@com (R. Mark Sharp)
Date: Fri, 10 Aug 2018 16:08:24 -0400
Subject: [R] help
In-Reply-To: <CAON01EbSs=z6Gd6vPaa9aQReiJTwi6rqHyKBFJ71Wo+bT=yh+g@mail.gmail.com>
References: <CAON01EbSs=z6Gd6vPaa9aQReiJTwi6rqHyKBFJ71Wo+bT=yh+g@mail.gmail.com>
Message-ID: <144921FD-954D-4B92-BF6C-261DECB2535A@me.com>

Marco,

The error message indicates that nlon*nlat is 420 and that 1378620/420 has a remainder. For the matrix to form, all rows have to be complete. 

I am guessing you have at least one value incorrect among nlon, nlat, t or the length of fulldatav.

Mark
R. Mark Sharp, Ph.D.
Data Scientist and Biomedical Statistical Consultant
7526 Meadow Green St.
San Antonio, TX 78251
mobile: 210-218-2868
rmsharp at me.com











> On Aug 10, 2018, at 10:00 AM, Marco Antonio P?rez <marko.luna13 at gmail.com> wrote:
> 
> I am trying to write a function to make a matrix of precipitation with
> this secuencie;
> ######## PRIMER PERIODO
> cordex1 <-
> nc_open("pr_CAM-44i_ICHEC-EC-EARTH_rcp45_r12i1p1_SMHI-RCA4_v1_mon_200601-201012.nc")
> fullmon1<-ncvar_get(cordex1,"pr")
> lat<-ncvar_get(cordex1,"lat", start=c(35.5),count=c(20))
> lon <-ncvar_get(cordex1,"lon", start=c(125),count=c(21.5))
> t <- ncvar_get(cordex1,"time")
> nlon <- dim(lon)
> nlat <- dim(lat)
> nt <- dim(t)
> fulldatav <- as.vector(fullmon1)
> fulldata <- matrix(fulldatav, nrow=nlon*nlat, ncol=nt)
> lonlat <- expand.grid(lon,lat)
> df_cordex1<- data.frame(lonlat,fulldata)
> 
> but with the expresion  fulldata <- matrix(fulldatav, nrow=nlon*nlat,
> ncol=nt) this error appears
> Warning message:
> In matrix(fulldatav, nrow = nlon * nlat, ncol = nt) :
>  data length [1378620] is not a sub-multiple or multiple of the number of
> rows [420]
> 
> Somebody help me!!!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @hivipmp82 @ending from gm@il@com  Sat Aug 11 17:55:41 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Sat, 11 Aug 2018 21:25:41 +0530
Subject: [R] Assistance on Installing Rattle
Message-ID: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>

Hi,

Need assistance on installing Rattle.

I have followed the instructions on https://rattle.togaware.com/
but still facing error installing the package.
ERROR: dependency 'RGtk2' is not available for package 'rattle'.
Have tried installing RGt2 from multiple sources and its still failing.

One of the suggestion on stack overflow was to downgrade the R version here
:
https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
Request assistance.

Regards, Shivi

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Sat Aug 11 18:08:49 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Sat, 11 Aug 2018 19:08:49 +0300
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
Message-ID: <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>

Hi Shivi,
I have no experience with the rattle package but I just installed it with
no problem.
I am using a Windows 10 machine with R version 3.4.2.

I suggest you provide additional information so that others may have ideas.
e.g. your operating system version and output from sessionInfo() (in R)

Best,
Eric


On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Hi,
>
> Need assistance on installing Rattle.
>
> I have followed the instructions on https://rattle.togaware.com/
> but still facing error installing the package.
> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
> Have tried installing RGt2 from multiple sources and its still failing.
>
> One of the suggestion on stack overflow was to downgrade the R version here
> :
> https://stackoverflow.com/questions/24913643/downgrade-
> r-version-no-issues-with-bioconductor-installation
> Request assistance.
>
> Regards, Shivi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From f@ridcher @ending from gm@il@com  Sat Aug 11 10:47:54 2018
From: f@ridcher @ending from gm@il@com (Farid Ch)
Date: Sat, 11 Aug 2018 08:47:54 +0000
Subject: [R] source script file that contains Unicode non-English characters
Message-ID: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>

Hi all,

Please check the attached file.

Thanks
Farid



From r@turner @ending from @uckl@nd@@c@nz  Sat Aug 11 23:12:43 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 12 Aug 2018 09:12:43 +1200
Subject: [R] Mysterious seg fault.
Message-ID: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>


I am getting a seg fault from a package that I am working on, and I am 
totally flummoxed by it.  The fault presumably arises from dynamically
loaded Fortran code, but I'm damned if I can see where the error lies.

In an effort to diagnose the problem I created a "non-package" version 
of the code.  That is, I copied all the *.R files and *.f file into a
new directory.  In that directory I created a *.so file using
R CMD SHLIB.

In the R code I removed all the "PACKAGE=" lines from the calls to
.Fortran() and put in appropriate dyn.load() calls.

I then started R in this new "clean" directory and sourced all of the
*.R files.

I then issued the command that produces the seg fault when run under the 
aegis of the package.  The command ran without a murmur of complaint.
WTF?

Can anyone suggest a reason why a seg fault might arise when the code is 
run in the context of a package, but not when it is run in "standalone 
mode"?

I have checked and rechecked my init.c file --- which is the only thing 
that I can think of that might create a difference --- and cannot find 
any discrepancy between the declarations in the init.c file and the 
Fortran code.

The package is a bit complicated, so giving more detail would be 
cumbersome.  Also I have no idea what aspects of detail would be 
relevant.  If anyone would like more info, feel free to ask.

I would really appreciate it if someone could give me some suggestions
before I go *completely* mad!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From gor@n@bro@trom @ending from umu@@e  Sat Aug 11 23:52:01 2018
From: gor@n@bro@trom @ending from umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Sat, 11 Aug 2018 23:52:01 +0200
Subject: [R] Mysterious seg fault.
In-Reply-To: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
Message-ID: <06ccac94-300b-7497-3b61-2e898001c62b@umu.se>

Rolf,

have you tried to run R with a debugger, as in

$ R -d gdb

the gnu debugger?

G,

On 2018-08-11 23:12, Rolf Turner wrote:
> 
> I am getting a seg fault from a package that I am working on, and I am 
> totally flummoxed by it.? The fault presumably arises from dynamically
> loaded Fortran code, but I'm damned if I can see where the error lies.
> 
> In an effort to diagnose the problem I created a "non-package" version 
> of the code.? That is, I copied all the *.R files and *.f file into a
> new directory.? In that directory I created a *.so file using
> R CMD SHLIB.
> 
> In the R code I removed all the "PACKAGE=" lines from the calls to
> .Fortran() and put in appropriate dyn.load() calls.
> 
> I then started R in this new "clean" directory and sourced all of the
> *.R files.
> 
> I then issued the command that produces the seg fault when run under the 
> aegis of the package.? The command ran without a murmur of complaint.
> WTF?
> 
> Can anyone suggest a reason why a seg fault might arise when the code is 
> run in the context of a package, but not when it is run in "standalone 
> mode"?
> 
> I have checked and rechecked my init.c file --- which is the only thing 
> that I can think of that might create a difference --- and cannot find 
> any discrepancy between the declarations in the init.c file and the 
> Fortran code.
> 
> The package is a bit complicated, so giving more detail would be 
> cumbersome.? Also I have no idea what aspects of detail would be 
> relevant.? If anyone would like more info, feel free to ask.
> 
> I would really appreciate it if someone could give me some suggestions
> before I go *completely* mad!
> 
> cheers,
> 
> Rolf Turner
>


From drjimlemon @ending from gm@il@com  Sun Aug 12 01:51:43 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sun, 12 Aug 2018 09:51:43 +1000
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
Message-ID: <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>

Hi Farid,
Whatever you attached has not gotten through.

Jim

On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
> Hi all,
>
> Please check the attached file.
>
> Thanks
> Farid
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter@l@ngfelder @ending from gm@il@com  Sun Aug 12 04:13:38 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Sat, 11 Aug 2018 19:13:38 -0700
Subject: [R] Mysterious seg fault.
In-Reply-To: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
Message-ID: <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>

Segfaults are not always repeatable. You may have an undefined pointer that
sometime points into unreachable or unallocated memory, causing a segfault,
and sometimes may point into valid memory, without causing a segfault.

You may want to read
https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Checking-memory-access
for tips on how to diagnose such problems.

HTH,

Peter

On Sat, Aug 11, 2018 at 2:13 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> I am getting a seg fault from a package that I am working on, and I am
> totally flummoxed by it.  The fault presumably arises from dynamically
> loaded Fortran code, but I'm damned if I can see where the error lies.
>
> In an effort to diagnose the problem I created a "non-package" version
> of the code.  That is, I copied all the *.R files and *.f file into a
> new directory.  In that directory I created a *.so file using
> R CMD SHLIB.
>
> In the R code I removed all the "PACKAGE=" lines from the calls to
> .Fortran() and put in appropriate dyn.load() calls.
>
> I then started R in this new "clean" directory and sourced all of the
> *.R files.
>
> I then issued the command that produces the seg fault when run under the
> aegis of the package.  The command ran without a murmur of complaint.
> WTF?
>
> Can anyone suggest a reason why a seg fault might arise when the code is
> run in the context of a package, but not when it is run in "standalone
> mode"?
>
> I have checked and rechecked my init.c file --- which is the only thing
> that I can think of that might create a difference --- and cannot find
> any discrepancy between the declarations in the init.c file and the
> Fortran code.
>
> The package is a bit complicated, so giving more detail would be
> cumbersome.  Also I have no idea what aspects of detail would be
> relevant.  If anyone would like more info, feel free to ask.
>
> I would really appreciate it if someone could give me some suggestions
> before I go *completely* mad!
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Aug 12 04:54:52 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 11 Aug 2018 19:54:52 -0700
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
Message-ID: <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>

... and read the Posting Guide... only a few file types will ever make it through the mailing list so repeatedly sending files not among those few types would just be frustrating for everyone.

On August 11, 2018 4:51:43 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Farid,
>Whatever you attached has not gotten through.
>
>Jim
>
>On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
>> Hi all,
>>
>> Please check the attached file.
>>
>> Thanks
>> Farid
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ericjberger @ending from gm@il@com  Sun Aug 12 07:42:41 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Sun, 12 Aug 2018 08:42:41 +0300
Subject: [R] Mysterious seg fault.
In-Reply-To: <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
Message-ID: <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>

Hi Rolf,
When faced with such a situation I take the following approach which often
helps.
Use the same setup that caused the seg fault (you need a reproducible
problem.)
Start your R session using valgrind. e.g. in linux I do:

$ valgrind R

Assuming that a seg fault still occurs then valgrind should provide info as
to where.

HTH,
Eric


On Sun, Aug 12, 2018 at 5:13 AM, Peter Langfelder <
peter.langfelder at gmail.com> wrote:

> Segfaults are not always repeatable. You may have an undefined pointer that
> sometime points into unreachable or unallocated memory, causing a segfault,
> and sometimes may point into valid memory, without causing a segfault.
>
> You may want to read
> https://cran.r-project.org/doc/manuals/r-release/R-exts.
> html#Checking-memory-access
> for tips on how to diagnose such problems.
>
> HTH,
>
> Peter
>
> On Sat, Aug 11, 2018 at 2:13 PM Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
>
> >
> > I am getting a seg fault from a package that I am working on, and I am
> > totally flummoxed by it.  The fault presumably arises from dynamically
> > loaded Fortran code, but I'm damned if I can see where the error lies.
> >
> > In an effort to diagnose the problem I created a "non-package" version
> > of the code.  That is, I copied all the *.R files and *.f file into a
> > new directory.  In that directory I created a *.so file using
> > R CMD SHLIB.
> >
> > In the R code I removed all the "PACKAGE=" lines from the calls to
> > .Fortran() and put in appropriate dyn.load() calls.
> >
> > I then started R in this new "clean" directory and sourced all of the
> > *.R files.
> >
> > I then issued the command that produces the seg fault when run under the
> > aegis of the package.  The command ran without a murmur of complaint.
> > WTF?
> >
> > Can anyone suggest a reason why a seg fault might arise when the code is
> > run in the context of a package, but not when it is run in "standalone
> > mode"?
> >
> > I have checked and rechecked my init.c file --- which is the only thing
> > that I can think of that might create a difference --- and cannot find
> > any discrepancy between the declarations in the init.c file and the
> > Fortran code.
> >
> > The package is a bit complicated, so giving more detail would be
> > cumbersome.  Also I have no idea what aspects of detail would be
> > relevant.  If anyone would like more info, feel free to ask.
> >
> > I would really appreciate it if someone could give me some suggestions
> > before I go *completely* mad!
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Sun Aug 12 08:32:09 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 12 Aug 2018 18:32:09 +1200
Subject: [R] Mysterious seg fault.
In-Reply-To: <06ccac94-300b-7497-3b61-2e898001c62b@umu.se>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <06ccac94-300b-7497-3b61-2e898001c62b@umu.se>
Message-ID: <f66fd810-8066-f6dd-6bf7-5ae89ea32ecd@auckland.ac.nz>

On 12/08/18 09:52, G?ran Brostr?m wrote:
> Rolf,
> 
> have you tried to run R with a debugger, as in
> 
> $ R -d gdb
> 
> the gnu debugger?


No, I haven't.  Did not know about the gnu debugger.  I shall 
investigate.  Thanks

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From f@ridcher @ending from gm@il@com  Sun Aug 12 09:09:22 2018
From: f@ridcher @ending from gm@il@com (Faridedin Cheraghi)
Date: Sun, 12 Aug 2018 11:39:22 +0430
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
Message-ID: <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>

It was actually a .rmd file so you can get the coloring of the bug report
in your text editor. I changed the format to .txt.

-Farid

On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> ... and read the Posting Guide... only a few file types will ever make it
> through the mailing list so repeatedly sending files not among those few
> types would just be frustrating for everyone.
>
> On August 11, 2018 4:51:43 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> >Hi Farid,
> >Whatever you attached has not gotten through.
> >
> >Jim
> >
> >On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
> >> Hi all,
> >>
> >> Please check the attached file.
> >>
> >> Thanks
> >> Farid
> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: bug-source-unicode.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180812/db68446e/attachment.txt>

From @hivipmp82 @ending from gm@il@com  Sun Aug 12 12:49:18 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Sun, 12 Aug 2018 16:19:18 +0530
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
Message-ID: <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>

Hi Eric,

Thank you for the reply. I am adding the session details below, hope it
helps:
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default
locale:
[1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
LC_MONETARY=English_India.1252
[4] LC_NUMERIC=C                   LC_TIME=English_India.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Thanks.

On Sat, Aug 11, 2018 at 9:38 PM Eric Berger <ericjberger at gmail.com> wrote:

> Hi Shivi,
> I have no experience with the rattle package but I just installed it with
> no problem.
> I am using a Windows 10 machine with R version 3.4.2.
>
> I suggest you provide additional information so that others may have ideas.
> e.g. your operating system version and output from sessionInfo() (in R)
>
> Best,
> Eric
>
>
> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
>
>> Hi,
>>
>> Need assistance on installing Rattle.
>>
>> I have followed the instructions on https://rattle.togaware.com/
>> but still facing error installing the package.
>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
>> Have tried installing RGt2 from multiple sources and its still failing.
>>
>> One of the suggestion on stack overflow was to downgrade the R version
>> here
>> :
>>
>> https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>> Request assistance.
>>
>> Regards, Shivi
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From li@t@ @ending from dewey@myzen@co@uk  Sun Aug 12 15:50:48 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 12 Aug 2018 14:50:48 +0100
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
Message-ID: <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>

Dear Shivi

What error message do you get when you try to install RGtk2?

Michael

On 12/08/2018 11:49, Shivi Bhatia wrote:
> Hi Eric,
> 
> Thank you for the reply. I am adding the session details below, hope it
> helps:
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> Matrix products: default
> locale:
> [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
> LC_MONETARY=English_India.1252
> [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> Thanks.
> 
> On Sat, Aug 11, 2018 at 9:38 PM Eric Berger <ericjberger at gmail.com> wrote:
> 
>> Hi Shivi,
>> I have no experience with the rattle package but I just installed it with
>> no problem.
>> I am using a Windows 10 machine with R version 3.4.2.
>>
>> I suggest you provide additional information so that others may have ideas.
>> e.g. your operating system version and output from sessionInfo() (in R)
>>
>> Best,
>> Eric
>>
>>
>> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia <shivipmp82 at gmail.com>
>> wrote:
>>
>>> Hi,
>>>
>>> Need assistance on installing Rattle.
>>>
>>> I have followed the instructions on https://rattle.togaware.com/
>>> but still facing error installing the package.
>>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
>>> Have tried installing RGt2 from multiple sources and its still failing.
>>>
>>> One of the suggestion on stack overflow was to downgrade the R version
>>> here
>>> :
>>>
>>> https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>>> Request assistance.
>>>
>>> Regards, Shivi
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From murdoch@dunc@n @ending from gm@il@com  Sun Aug 12 17:30:47 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 12 Aug 2018 11:30:47 -0400
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
Message-ID: <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>

On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
> It was actually a .rmd file so you can get the coloring of the bug report
> in your text editor. I changed the format to .txt.

When I run your script on a Mac (in a UTF-8 locale), all lines work as 
expected.  I'm guessing you are working on Windows, in a non-UTF-8 locale?

Posting sessionInfo() would be helpful.

Duncan Murdoch

> 
> -Farid
> 
> On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> ... and read the Posting Guide... only a few file types will ever make it
>> through the mailing list so repeatedly sending files not among those few
>> types would just be frustrating for everyone.
>>
>> On August 11, 2018 4:51:43 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> Hi Farid,
>>> Whatever you attached has not gotten through.
>>>
>>> Jim
>>>
>>> On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
>>>> Hi all,
>>>>
>>>> Please check the attached file.
>>>>
>>>> Thanks
>>>> Farid
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From f@ridcher @ending from gm@il@com  Sun Aug 12 17:48:20 2018
From: f@ridcher @ending from gm@il@com (Faridedin Cheraghi)
Date: Sun, 12 Aug 2018 20:18:20 +0430
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
Message-ID: <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>

that's right and I don't want to change my locale. my sessionInfo() :

R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

thanks

On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
>
>> It was actually a .rmd file so you can get the coloring of the bug report
>> in your text editor. I changed the format to .txt.
>>
>
> When I run your script on a Mac (in a UTF-8 locale), all lines work as
> expected.  I'm guessing you are working on Windows, in a non-UTF-8 locale?
>
> Posting sessionInfo() would be helpful.
>
> Duncan Murdoch
>
>
>
>> -Farid
>>
>> On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us
>> >
>> wrote:
>>
>> ... and read the Posting Guide... only a few file types will ever make it
>>> through the mailing list so repeatedly sending files not among those few
>>> types would just be frustrating for everyone.
>>>
>>> On August 11, 2018 4:51:43 PM PDT, Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>>
>>>> Hi Farid,
>>>> Whatever you attached has not gotten through.
>>>>
>>>> Jim
>>>>
>>>> On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> Please check the attached file.
>>>>>
>>>>> Thanks
>>>>> Farid
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>>
>>>> http://www.R-project.org/posting-guide.html
>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Sun Aug 12 18:33:14 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 12 Aug 2018 12:33:14 -0400
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
 <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
Message-ID: <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>

On 12/08/2018 11:48 AM, Faridedin Cheraghi wrote:
> that's right and I don't want to change my locale. my sessionInfo() :

I think it could be another manifestation of a known bug on Windows, 
where strings are converted from UTF-8 to the current locale and back to 
UTF-8, a lossy conversion.  This has been present for many years, and 
requires a lot of internal changes to fix, so I wouldn't hold your 
breath waiting for a fix.

I believe the "right" fix is for R to always convert strings to UTF-8 
internally.  This wasn't possible when the internationalization code was 
added many years ago because not all platforms supported UTF-8.  It 
would be a lot of work now, and since it isn't needed now on the 
platforms most developers use, it's not receiving a lot of attention.

Your workaround

file(script,
      encoding = "UTF-8") %T>%
      source() %>%
      close()   # works fine

is a nice way to avoid this problem.

Duncan Murdoch

> 
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
> 
> thanks
> 
> On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
> 
>         It was actually a .rmd file so you can get the coloring of the
>         bug report
>         in your text editor. I changed the format to .txt.
> 
> 
>     When I run your script on a Mac (in a UTF-8 locale), all lines work
>     as expected.? I'm guessing you are working on Windows, in a
>     non-UTF-8 locale?
> 
>     Posting sessionInfo() would be helpful.
> 
>     Duncan Murdoch
> 
> 
> 
>         -Farid
> 
>         On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller
>         <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>
>         wrote:
> 
>             ... and read the Posting Guide... only a few file types will
>             ever make it
>             through the mailing list so repeatedly sending files not
>             among those few
>             types would just be frustrating for everyone.
> 
>             On August 11, 2018 4:51:43 PM PDT, Jim Lemon
>             <drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>> wrote:
> 
>                 Hi Farid,
>                 Whatever you attached has not gotten through.
> 
>                 Jim
> 
>                 On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch
>                 <faridcher at gmail.com <mailto:faridcher at gmail.com>> wrote:
> 
>                     Hi all,
> 
>                     Please check the attached file.
> 
>                     Thanks
>                     Farid
> 
> 
>                     ______________________________________________
>                     R-help at r-project.org <mailto:R-help at r-project.org>
>                     mailing list -- To UNSUBSCRIBE and more, see
>                     https://stat.ethz.ch/mailman/listinfo/r-help
>                     <https://stat.ethz.ch/mailman/listinfo/r-help>
>                     PLEASE do read the posting guide
> 
>                 http://www.R-project.org/posting-guide.html
>                 <http://www.R-project.org/posting-guide.html>
> 
>                     and provide commented, minimal, self-contained,
>                     reproducible code.
> 
> 
>                 ______________________________________________
>                 R-help at r-project.org <mailto:R-help at r-project.org>
>                 mailing list -- To UNSUBSCRIBE and more, see
>                 https://stat.ethz.ch/mailman/listinfo/r-help
>                 <https://stat.ethz.ch/mailman/listinfo/r-help>
>                 PLEASE do read the posting guide
>                 http://www.R-project.org/posting-guide.html
>                 <http://www.R-project.org/posting-guide.html>
>                 and provide commented, minimal, self-contained,
>                 reproducible code.
> 
> 
>             --
>             Sent from my phone. Please excuse my brevity.
> 
> 
> 
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
> 
> 
>


From peter@c@rbonetto @ending from gm@il@com  Sun Aug 12 16:49:10 2018
From: peter@c@rbonetto @ending from gm@il@com (Peter Carbonetto)
Date: Sun, 12 Aug 2018 09:49:10 -0500
Subject: [R] Fast matrix multiplication
Message-ID: <CAPvCojL19g6mQy7YrF8iN4h5pcoXwHxzBDuZ3aWKGZcBaFGGGw@mail.gmail.com>

Hi Ravi,

Like Ista, I have also had success in using R with OpenBLAS on our Linux
compute cluster.

This will involve installing R from source. If you'd like, I can send you
the configure settings I used, as well as the environment settings used to
control OpenBLAS multithreading. The CRAN site also has some good
documentation of this.

Note that I had issues using the latest version of OpenBLAS (0.3.x) with R
3.5.1. I'm not sure if you would have the same issues as me, but to be safe
I would suggest using OpenBLAS 0.2.x instead.

Peter

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Mon Aug 13 00:32:04 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Mon, 13 Aug 2018 10:32:04 +1200
Subject: [R] Mysterious seg fault.
In-Reply-To: <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
Message-ID: <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>


On 12/08/18 17:42, Eric Berger wrote:

> Hi Rolf,
> When faced with such a situation I take the following approach which 
> often helps.
> Use the same setup that caused the seg fault (you need a reproducible 
> problem.)
> Start your R session using valgrind. e.g. in linux I do:
> 
> $ valgrind R
> 
> Assuming that a seg fault still occurs then valgrind should provide info 
> as to where.
> 
> HTH

Well, it probably *would* help if I weren't such a thicko.

The story so far:  I have managed to install valgrind (downloaded a 
tarball and installed from source).  Seemed to go OK, but:

* when I type "valgrind" I get "command not found"
* however valgrind is in /usr/local/bin (I did "configure" with
   prefix="/usr/local" so this is as it should be)
* /usr/local/bin/valgrind is executable
* /usr/local/bin is in my path

So how in god's name can the command not be found?  And why do these 
things always happen to *me*???

I can work around this problem by giving the full path name, however.

So I did:

/usr/local/bin/valgrind R

and got a lot of (mysterious to me) output:

> /usr/local/bin/valgrind R
> ==18051== Memcheck, a memory error detector
> ==18051== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
> ==18051== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
> ==18051== Command: /usr/local/bin/R
> ==18051== 
> ==18051== Invalid free() / delete / delete[] / realloc()
> ==18051==    at 0x4C2ECF0: free (vg_replace_malloc.c:530)
> ==18051==    by 0x45E280: ??? (in /bin/bash)
> ==18051==    by 0x45E42F: run_unwind_frame (in /bin/bash)
> ==18051==    by 0x47B714: parse_and_execute (in /bin/bash)
> ==18051==    by 0x47B102: ??? (in /bin/bash)
> ==18051==    by 0x47B35C: source_file (in /bin/bash)
> ==18051==    by 0x4849C7: source_builtin (in /bin/bash)
> ==18051==    by 0x43378D: ??? (in /bin/bash)
> ==18051==    by 0x43592C: ??? (in /bin/bash)
> ==18051==    by 0x4369C7: execute_command_internal (in /bin/bash)
> ==18051==    by 0x43851D: execute_command (in /bin/bash)
> ==18051==    by 0x42139D: reader_loop (in /bin/bash)
> ==18051==  Address 0x4241008 is in the brk data segment 0x4228000-0x4246fff
> ==18051== 
> ==18051== Invalid free() / delete / delete[] / realloc()
> ==18051==    at 0x4C2ECF0: free (vg_replace_malloc.c:530)
> ==18051==    by 0x45E280: ??? (in /bin/bash)
> ==18051==    by 0x45E42F: run_unwind_frame (in /bin/bash)
> ==18051==    by 0x4849D3: source_builtin (in /bin/bash)
> ==18051==    by 0x43378D: ??? (in /bin/bash)
> ==18051==    by 0x43592C: ??? (in /bin/bash)
> ==18051==    by 0x4369C7: execute_command_internal (in /bin/bash)
> ==18051==    by 0x43851D: execute_command (in /bin/bash)
> ==18051==    by 0x42139D: reader_loop (in /bin/bash)
> ==18051==    by 0x41FDB0: main (in /bin/bash)
> ==18051==  Address 0x4240708 is in the brk data segment 0x4228000-0x4246fff
> ==18051== 
> 

Not at all clear to me what to make of this.  Does it indicate problems 
or memory leaks in my installation of R?  Anyhow, things then proceed in 
an expected manner:

> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>   Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> Loading required package: misc
> [Previously saved workspace restored]

I then loaded the problematic package and issued the problematic command:

> > library(hmm.discnp)
> hmm.discnp 2.0-9
> 
>      This package has changed SUBSTANTIALLY from its 
>      previous release.  Read the documentation 
>      carefully.  Note in particular that the meaning of 
>      the argument "nsim" of the function rhmm() has 
>      changed, and a new argument "ylengths" now plays 
>      essentially the role previously played by 
>      "nsim".
> 
> > xxx <- get.hgl(p3,2,yyy)
> 
>  *** caught segfault ***
> address (nil), cause 'unknown'
> Segmentation fault (core dumped)

Nothing informative.  Is there something else I should be doing?

Sorry for being a nuisance, but I am at a loss.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon @ending from gm@il@com  Mon Aug 13 01:55:28 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Mon, 13 Aug 2018 09:55:28 +1000
Subject: [R] cumulate of snow cumulates from daily values of different
 automatic stations for some time intervals
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F54CCBF0B@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F54CCBF0B@ESINO.regionemarche.intra>
Message-ID: <CA+8X3fUpyN9X6qZwjxdxaokAfo1QjtNZWxpSOOO3nDanKpVJ7g@mail.gmail.com>

Hi Stefano,
This was such a stinker of a problem that I just had to crack it:

# create some data the lazy man's way
year_dates<-c(paste(2000,rep("01",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("02",29),formatC(1:29,width=2,flag=0),sep="-"),
 paste(2000,rep("03",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("04",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("05",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("06",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("07",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("08",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("09",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("10",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("11",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("12",31),formatC(1:31,width=2,flag=0),sep="-"))

df1<-data.frame(station_code=rep(217,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df2<-data.frame(station_code=rep(218,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df3<-data.frame(station_code=rep(219,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df4<-data.frame(station_code=rep(220,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df5<-data.frame(station_code=rep(221,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df6<-data.frame(station_code=rep(222,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df7<-data.frame(station_code=rep(223,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df8<-data.frame(station_code=rep(224,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df9<-data.frame(station_code=rep(225,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df10<-data.frame(station_code=rep(226,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))

snow_list<-list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

for(station in 1:10)
 snow_list[[station]]$doy<-1:length(snow_list[[station]]$date_POSIX)

select_days<-c(1:12,83:88)

cum_snow<-function(x,which_days) {
 return(list(x$station_code[1],sum(x$snow[which_days])))
}

cum_list<-lapply(lapply(snow_list,cum_snow,select_days),unlist)

snow_totals<-data.frame(station_code=NULL,snow_cumulate=NULL)

for(station in 1:10) snow_totals<-rbind(snow_totals,cum_list[[station]])

names(snow_totals)<-c("station_code","snow_cumulate")

Jim


On Sat, Aug 11, 2018 at 2:48 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-list users,
> I have 10 data frames (called df1, df2, ... df10), where each of them contains snow data from an automatic meteorological station (obviously each station has a different station code).
> Here is an example of df1:
>
> station_code date_factor date_POSIX snow
> 217 1999-12-15 1999-12-15  0
> 217 1999-12-16 1999-12-16  0
> 217 1999-12-17 1999-12-17 38
> 217 1999-12-18 1999-12-18 31
> 217 1999-12-19 1999-12-19 21
> 217 1999-12-20 1999-12-20 12
> 217 1999-12-21 1999-12-21 42
> 217 1999-12-22 1999-12-22 61
> 217 1999-12-23 1999-12-23 57
> 217 1999-12-24 1999-12-24 48
> ...
>
> where
>> sapply(df1, class)
> $station_code
> [1] "numeric"
>
> $date_factor
> [1] "factor"
>
> $date_POSIX
> [1] "POSIXct" "POSIXt"
>
> $snow
> [1] "integer"
>
> Given a series of max three intervals (example with two intervals: from 1st to 12th of January 2000 and from 23rd to 28th of March 2000), I need to evaluate for each station the total snow cumulate for all the intervals selected, and finally create a data frame where for each line there is the station code and the snow cumulate. It should be like
>
> station_code total_snow_cumulate
> 217 125
> 218 80
> ...
>
> Could somebody show me a direction for an efficient solution?
>
> Thank you for your attention and your help
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @ending from gm@il@com  Mon Aug 13 02:03:58 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 12 Aug 2018 20:03:58 -0400
Subject: [R] Mysterious seg fault.
In-Reply-To: <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
Message-ID: <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>

On 12/08/2018 6:32 PM, Rolf Turner wrote:
> 
> On 12/08/18 17:42, Eric Berger wrote:
> 
>> Hi Rolf,
>> When faced with such a situation I take the following approach which
>> often helps.
>> Use the same setup that caused the seg fault (you need a reproducible
>> problem.)
>> Start your R session using valgrind. e.g. in linux I do:
>>
>> $ valgrind R
>>
>> Assuming that a seg fault still occurs then valgrind should provide info
>> as to where.
>>
>> HTH
> 
> Well, it probably *would* help if I weren't such a thicko.
> 
> The story so far:  I have managed to install valgrind (downloaded a
> tarball and installed from source).  Seemed to go OK, but:
> 
> * when I type "valgrind" I get "command not found"
> * however valgrind is in /usr/local/bin (I did "configure" with
>     prefix="/usr/local" so this is as it should be)
> * /usr/local/bin/valgrind is executable
> * /usr/local/bin is in my path
> 
> So how in god's name can the command not be found?  And why do these
> things always happen to *me*???
> 
> I can work around this problem by giving the full path name, however.
> 
> So I did:
> 
> /usr/local/bin/valgrind R

I believe on your system R is a script, so you can't run valgrind this 
way.  It's just debugging bash, not R.  You need to use

R -d valgrind

(though with your weird path problems, you might need a fully qualified 
/usr/local/bin/valgrind there).

You run gdb the same way:

R -d gdb

and then give the command "r" to gdb to start R.  It will give a report 
when you get the segfault.  I don't know which report will be more 
informative.

Duncan Murdoch

> 
> and got a lot of (mysterious to me) output:
> 
>> /usr/local/bin/valgrind R
>> ==18051== Memcheck, a memory error detector
>> ==18051== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
>> ==18051== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
>> ==18051== Command: /usr/local/bin/R
>> ==18051==
>> ==18051== Invalid free() / delete / delete[] / realloc()
>> ==18051==    at 0x4C2ECF0: free (vg_replace_malloc.c:530)
>> ==18051==    by 0x45E280: ??? (in /bin/bash)
>> ==18051==    by 0x45E42F: run_unwind_frame (in /bin/bash)
>> ==18051==    by 0x47B714: parse_and_execute (in /bin/bash)
>> ==18051==    by 0x47B102: ??? (in /bin/bash)
>> ==18051==    by 0x47B35C: source_file (in /bin/bash)
>> ==18051==    by 0x4849C7: source_builtin (in /bin/bash)
>> ==18051==    by 0x43378D: ??? (in /bin/bash)
>> ==18051==    by 0x43592C: ??? (in /bin/bash)
>> ==18051==    by 0x4369C7: execute_command_internal (in /bin/bash)
>> ==18051==    by 0x43851D: execute_command (in /bin/bash)
>> ==18051==    by 0x42139D: reader_loop (in /bin/bash)
>> ==18051==  Address 0x4241008 is in the brk data segment 0x4228000-0x4246fff
>> ==18051==
>> ==18051== Invalid free() / delete / delete[] / realloc()
>> ==18051==    at 0x4C2ECF0: free (vg_replace_malloc.c:530)
>> ==18051==    by 0x45E280: ??? (in /bin/bash)
>> ==18051==    by 0x45E42F: run_unwind_frame (in /bin/bash)
>> ==18051==    by 0x4849D3: source_builtin (in /bin/bash)
>> ==18051==    by 0x43378D: ??? (in /bin/bash)
>> ==18051==    by 0x43592C: ??? (in /bin/bash)
>> ==18051==    by 0x4369C7: execute_command_internal (in /bin/bash)
>> ==18051==    by 0x43851D: execute_command (in /bin/bash)
>> ==18051==    by 0x42139D: reader_loop (in /bin/bash)
>> ==18051==    by 0x41FDB0: main (in /bin/bash)
>> ==18051==  Address 0x4240708 is in the brk data segment 0x4228000-0x4246fff
>> ==18051==
>>
> 
> Not at all clear to me what to make of this.  Does it indicate problems
> or memory leaks in my installation of R?  Anyhow, things then proceed in
> an expected manner:
> 
>> R version 3.5.1 (2018-07-02) -- "Feather Spray"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>    Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> Loading required package: misc
>> [Previously saved workspace restored]
> 
> I then loaded the problematic package and issued the problematic command:
> 
>>> library(hmm.discnp)
>> hmm.discnp 2.0-9
>>
>>       This package has changed SUBSTANTIALLY from its
>>       previous release.  Read the documentation
>>       carefully.  Note in particular that the meaning of
>>       the argument "nsim" of the function rhmm() has
>>       changed, and a new argument "ylengths" now plays
>>       essentially the role previously played by
>>       "nsim".
>>
>>> xxx <- get.hgl(p3,2,yyy)
>>
>>   *** caught segfault ***
>> address (nil), cause 'unknown'
>> Segmentation fault (core dumped)
> 
> Nothing informative.  Is there something else I should be doing?
> 
> Sorry for being a nuisance, but I am at a loss.
> 
> cheers,
> 
> Rolf
>


From r@turner @ending from @uckl@nd@@c@nz  Mon Aug 13 03:29:39 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Mon, 13 Aug 2018 13:29:39 +1200
Subject: [R] Mysterious seg fault.
In-Reply-To: <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
Message-ID: <32f9ace9-58b5-1480-211e-fb8e5ec7eb68@auckland.ac.nz>

On 13/08/18 12:03, Duncan Murdoch wrote:

<SNIP>

>> So I did:
>>
>> /usr/local/bin/valgrind R
> 
> I believe on your system R is a script, so you can't run valgrind this 
> way.? It's just debugging bash, not R.? You need to use
> 
> R -d valgrind
> 
> (though with your weird path problems, you might need a fully qualified 
> /usr/local/bin/valgrind there).
> 
> You run gdb the same way:
> 
> R -d gdb
> 
> and then give the command "r" to gdb to start R.? It will give a report 
> when you get the segfault.? I don't know which report will be more 
> informative.

<SNIP>

Thanks Duncan.  I did as you said with valgrind and got output that is 
probably more relevant.  However it is still opaque to me.  I have no 
idea how to use it to track down the error that I am making in the code.

> xxx <- get.hgl(p3,2,yyy)
> ==20088== Invalid read of size 8
> ==20088==    at 0x5116CD: Rf_allocVector3 (memory.c:2539)
> ==20088==    by 0x4B40FF: Rf_allocVector (Rinlinedfuns.h:577)
> ==20088==    by 0x4B40FF: do_missing (envir.c:2265)
> ==20088==    by 0x4CA383: bcEval (eval.c:6801)
> ==20088==    by 0x4D99EF: Rf_eval (eval.c:624)
> ==20088==    by 0x4DB172: R_execClosure (eval.c:1773)
> ==20088==    by 0x4D0E6E: bcEval (eval.c:6749)
> ==20088==    by 0x4D99EF: Rf_eval (eval.c:624)
> ==20088==    by 0x4DB172: R_execClosure (eval.c:1773)
> ==20088==    by 0x4D0E6E: bcEval (eval.c:6749)
> ==20088==    by 0x4D99EF: Rf_eval (eval.c:624)
> ==20088==    by 0x4DB172: R_execClosure (eval.c:1773)
> ==20088==    by 0x4D99A1: Rf_eval (eval.c:747)
> ==20088==  Address 0x3fca86ccfb7de9cc is not stack'd, malloc'd or (recently) free'd
> ==20088== 
> 
>  *** caught segfault ***
> address (nil), cause 'unknown'
> ==20088== Invalid read of size 8
> ==20088==    at 0x511B23: Rf_allocVector3 (memory.c:2691)
> ==20088==    by 0x49137A: Rf_allocVector (Rinlinedfuns.h:577)
> ==20088==    by 0x49137A: deparse1WithCutoff (deparse.c:268)
> ==20088==    by 0x492EAF: Rf_deparse1m (deparse.c:197)
> ==20088==    by 0x4BA99C: R_GetTraceback (errors.c:1409)
> ==20088==    by 0x5053CE: sigactionSegv (main.c:592)
> ==20088==    by 0x6CA738F: ??? (in /lib/x86_64-linux-gnu/libpthread-2.23.so)
> ==20088==    by 0x5116CC: Rf_allocVector3 (memory.c:2539)
> ==20088==  Address 0x3fca86ccfb7de9cc is not stack'd, malloc'd or (recently) free'd
> ==20088== 
> ==20088== 
> ==20088== Process terminating with default action of signal 11 (SIGSEGV)
> ==20088==  General Protection Fault
> ==20088==    at 0x511B23: Rf_allocVector3 (memory.c:2691)
> ==20088==    by 0x49137A: Rf_allocVector (Rinlinedfuns.h:577)
> ==20088==    by 0x49137A: deparse1WithCutoff (deparse.c:268)
> ==20088==    by 0x492EAF: Rf_deparse1m (deparse.c:197)
> ==20088==    by 0x4BA99C: R_GetTraceback (errors.c:1409)
> ==20088==    by 0x5053CE: sigactionSegv (main.c:592)
> ==20088==    by 0x6CA738F: ??? (in /lib/x86_64-linux-gnu/libpthread-2.23.so)
> ==20088==    by 0x5116CC: Rf_allocVector3 (memory.c:2539)
> ==20088== 
> ==20088== HEAP SUMMARY:
> ==20088==     in use at exit: 210,111,063 bytes in 57,981 blocks
> ==20088==   total heap usage: 106,693 allocs, 48,712 frees, 349,208,345 bytes allocated
> ==20088== 
> ==20088== LEAK SUMMARY:
> ==20088==    definitely lost: 0 bytes in 0 blocks
> ==20088==    indirectly lost: 0 bytes in 0 blocks
> ==20088==      possibly lost: 0 bytes in 0 blocks
> ==20088==    still reachable: 210,111,063 bytes in 57,981 blocks
> ==20088==                       of which reachable via heuristic:
> ==20088==                         newarray           : 4,264 bytes in 1 blocks
> ==20088==         suppressed: 0 bytes in 0 blocks
> ==20088== Rerun with --leak-check=full to see details of leaked memory
> ==20088== 
> ==20088== For counts of detected and suppressed errors, rerun with: -v
> ==20088== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)
> Segmentation fault (core dumped)

Doesn't mean a thing to me, I'm afraid.  Does it mean anything to you?
I have not (yet) "rerun with: -v".  I suspect that this would not help.

I guess I'll try to get gdb going next, and see if that provides more 
lucid output.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @ending from @uckl@nd@@c@nz  Mon Aug 13 03:51:24 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Mon, 13 Aug 2018 13:51:24 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
Message-ID: <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>


OK everybody!  You can relax.  :-) I managed to spot the loony.  After 
mucking around with valgrind, and before trying gdb, I had one more look 
at my code and *finally* saw the stupid thing that I had been doing.

In the call to .Fortran() I had a line

     nphi=as.integer(nphi),

but "nphi" was nowhere defined (!!!) in the R code.  The name "nphi" 
appeared as an argument in the Fortran subroutine in question, but was 
nowhere actually *used*!!!

It seems that passing a non-existent value as an argument to a Fortran 
subroutine can *sometimes* confuse it.  Understandably.

I think that this "nphi" was a left-over from an earlier version of the 
code.  I must have changed the code so that nphi was no longer needed, 
but then forgot to remove it from some places.  Psigh!  I hate myself 
sometimes.

Anyhow, thanks to all those who took the time and made the effort to try 
to help me.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From deep@m@hm@ii@c @ending from gm@il@com  Mon Aug 13 07:10:10 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa Maheshvare)
Date: Mon, 13 Aug 2018 10:40:10 +0530
Subject: [R] searching for a specific row name in R
Message-ID: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>

Hello Everyone,

I have a 1000 x 20 matrix. The second column of the matrix has the names of identifiers. How do I check when a certain identifier is present in the set of 1000 identifier names present in the second column. For instance, let the names of identifiers be A1,A2,...A1000. I want to check whether A501 is present .How can this be checked?

Any help will be highly appreciated.


	[[alternative HTML version deleted]]


From @lk@uffm @ending from f@@tm@il@fm  Mon Aug 13 09:09:23 2018
From: @lk@uffm @ending from f@@tm@il@fm (Albrecht Kauffmann)
Date: Mon, 13 Aug 2018 09:09:23 +0200
Subject: [R] searching for a specific row name in R
In-Reply-To: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
Message-ID: <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>

Hello Deepa,

sum(x[,2] == "A501")
or
which(x[,2] == "A501")
.
Best,
Albrecht


-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
> Hello Everyone,
> 
> I have a 1000 x 20 matrix. The second column of the matrix has the names 
> of identifiers. How do I check when a certain identifier is present in 
> the set of 1000 identifier names present in the second column. For 
> instance, let the names of identifiers be A1,A2,...A1000. I want to 
> check whether A501 is present .How can this be checked?
> 
> Any help will be highly appreciated.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik@bengt@@on @ending from gm@il@com  Mon Aug 13 10:45:42 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Mon, 13 Aug 2018 10:45:42 +0200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
Message-ID: <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>

On Mon, Aug 13, 2018 at 3:51 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> OK everybody!  You can relax.  :-) I managed to spot the loony.  After
> mucking around with valgrind, and before trying gdb, I had one more look
> at my code and *finally* saw the stupid thing that I had been doing.
>
> In the call to .Fortran() I had a line
>
>      nphi=as.integer(nphi),
>
> but "nphi" was nowhere defined (!!!) in the R code.  The name "nphi"
> appeared as an argument in the Fortran subroutine in question, but was
> nowhere actually *used*!!!

Didn't R CMD check pick this up, that is, didn't it report that 'nphi'
is a "global" variable?

/Henrik

>
> It seems that passing a non-existent value as an argument to a Fortran
> subroutine can *sometimes* confuse it.  Understandably.
>
> I think that this "nphi" was a left-over from an earlier version of the
> code.  I must have changed the code so that nphi was no longer needed,
> but then forgot to remove it from some places.  Psigh!  I hate myself
> sometimes.
>
> Anyhow, thanks to all those who took the time and made the effort to try
> to help me.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @ending from @uckl@nd@@c@nz  Mon Aug 13 11:54:06 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Mon, 13 Aug 2018 21:54:06 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
Message-ID: <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>


On 13/08/18 20:45, Henrik Bengtsson wrote:

> On Mon, Aug 13, 2018 at 3:51 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> OK everybody!  You can relax.  :-) I managed to spot the loony.  After
>> mucking around with valgrind, and before trying gdb, I had one more look
>> at my code and *finally* saw the stupid thing that I had been doing.
>>
>> In the call to .Fortran() I had a line
>>
>>       nphi=as.integer(nphi),
>>
>> but "nphi" was nowhere defined (!!!) in the R code.  The name "nphi"
>> appeared as an argument in the Fortran subroutine in question, but was
>> nowhere actually *used*!!!
> 
> Didn't R CMD check pick this up, that is, didn't it report that 'nphi'
> is a "global" variable?

No it didn't.  The name only appears in the call to .Fortran().  I think 
if it appeared in a call to an ordinary garden-variety R function then a 
warning would have been issued.

Such a lapse would be hard for R CMD check to pick up.  E.g

    nphi=integer(1),

would be OK in a call to .Fortran (which would allow a value of nphi, 
calculated within the called subroutine, to be *returned*) whereas

    nphi=as.integer(nphi),

causes trouble when nphi has never been defined (as I found out after a 
great expenditure of time and torn-out hair).  In the former instance it 
doesn't matter an FTCF whether nphi has been defined or not.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pd@lgd @ending from gm@il@com  Mon Aug 13 13:39:30 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Mon, 13 Aug 2018 13:39:30 +0200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
Message-ID: <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>

It's odd, possibly a bug, that you don't get 

Error: object 'nphi' not found

but I can't offhand see where the evaluation of args to .C/.Fortran is supposed to take place.

-pd

> On 13 Aug 2018, at 11:54 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 13/08/18 20:45, Henrik Bengtsson wrote:
> 
>> On Mon, Aug 13, 2018 at 3:51 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> 
>>> 
>>> OK everybody!  You can relax.  :-) I managed to spot the loony.  After
>>> mucking around with valgrind, and before trying gdb, I had one more look
>>> at my code and *finally* saw the stupid thing that I had been doing.
>>> 
>>> In the call to .Fortran() I had a line
>>> 
>>>      nphi=as.integer(nphi),
>>> 
>>> but "nphi" was nowhere defined (!!!) in the R code.  The name "nphi"
>>> appeared as an argument in the Fortran subroutine in question, but was
>>> nowhere actually *used*!!!
>> Didn't R CMD check pick this up, that is, didn't it report that 'nphi'
>> is a "global" variable?
> 
> No it didn't.  The name only appears in the call to .Fortran().  I think if it appeared in a call to an ordinary garden-variety R function then a warning would have been issued.
> 
> Such a lapse would be hard for R CMD check to pick up.  E.g
> 
>   nphi=integer(1),
> 
> would be OK in a call to .Fortran (which would allow a value of nphi, calculated within the called subroutine, to be *returned*) whereas
> 
>   nphi=as.integer(nphi),
> 
> causes trouble when nphi has never been defined (as I found out after a great expenditure of time and torn-out hair).  In the former instance it doesn't matter an FTCF whether nphi has been defined or not.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chri@@@ @ending from med@umich@edu  Mon Aug 13 14:27:53 2018
From: chri@@@ @ending from med@umich@edu (Andrews, Chris)
Date: Mon, 13 Aug 2018 12:27:53 +0000
Subject: [R] Typo in print.aov
Message-ID: <cc3652e5c58d48a0bd63757e0bb9e7df@med.umich.edu>


While looking at the code of print.aov for a different reason, I noticed that 'coefficient' was spelled with 3 'f's in one location.  Perhaps this is on purpose but in another location it has just 2 'f's.  This has not caused me any problem (that I know of) but I found it curious.

Chris



R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)




> getAnywhere(print.aov)
A single object matching 'print.aov' was found
It was found in the following places
  registered S3 method for print from namespace stats
  namespace:stats
with value

function (x, intercept = FALSE, tol = sqrt(.Machine$double.eps), 
    ...) 
{
    if (!is.null(cl <- x$call)) {
        cat("Call:\n   ")
        dput(cl, control = NULL)
    }
    qrx <- if (x$rank) 
        qr(x)
    asgn <- x$assign[qrx$pivot[1L:x$rank]]
    effects <- x$effects
    if (!is.null(effects)) 
        effects <- as.matrix(effects)[seq_along(asgn), , drop = FALSE]
    rdf <- x$df.residual
    resid <- as.matrix(x$residuals)
    wt <- x$weights
    if (!is.null(wt)) 
        resid <- resid * sqrt(wt)
    RSS <- colSums(resid^2)
    uasgn <- unique(asgn)
    nmeffect <- c("(Intercept)", attr(x$terms, "term.labels"))[1 + 
        uasgn]
    nterms <- length(uasgn)
    nresp <- NCOL(effects)
    df <- numeric(nterms)
    ss <- matrix(NA, nterms, nresp)
    if (nterms) {
        for (i in seq(nterms)) {
            ai <- asgn == uasgn[i]
            df[i] <- sum(ai)
            ef <- effects[ai, , drop = FALSE]
            ss[i, ] <- if (sum(ai) > 1) 
                colSums(ef^2)
            else ef^2
        }
        keep <- df > 0L
        if (!intercept && uasgn[1L] == 0) 
            keep[1L] <- FALSE
        nmeffect <- nmeffect[keep]
        df <- df[keep]
        ss <- ss[keep, , drop = FALSE]
        nterms <- length(df)
    }
    cat("\nTerms:\n")
    if (nterms == 0L) {
        if (rdf > 0L) {
            ss <- RSS
            ssp <- sapply(ss, format)
            if (!is.matrix(ssp)) 
                ssp <- t(ssp)
            tmp <- as.matrix(c(ssp, format(rdf)))
            if (length(ss) > 1L) {
                rn <- colnames(x$fitted.values)
                if (is.null(rn)) 
                  rn <- paste("resp", seq_along(ss))
            }
            else rn <- "Sum of Squares"
            dimnames(tmp) <- list(c(rn, "Deg. of Freedom"), "Residuals")
            print(tmp, quote = FALSE, right = TRUE)
            cat("\n")
            rs <- sqrt(RSS/rdf)
            cat(if (length(rs) > 1L) 
                "Residual standard errors:"
            else "Residual standard error:", sapply(rs, format))
            cat("\n")
        }
        else print(matrix(0, 2L, 1L, dimnames = list(c("Sum of Squares", 
            "Deg. of Freedom"), "<empty>")))
    }
    else {
        if (rdf > 0L) {
            nterms <- nterms + 1L
            df <- c(df, rdf)
            ss <- rbind(ss, RSS)
            nmeffect <- c(nmeffect, "Residuals")
        }
        ssp <- apply(zapsmall(ss), 2L, format)
        tmp <- t(cbind(ssp, format(df)))
        if (ncol(effects) > 1L) {
            rn <- colnames(x$coeffficients) ###############************ <------- HERE
            if (is.null(rn)) 
                rn <- paste("resp", seq(ncol(effects)))
        }
        else rn <- "Sum of Squares"
        dimnames(tmp) <- list(c(rn, "Deg. of Freedom"), nmeffect)
        print(tmp, quote = FALSE, right = TRUE)
        rank <- x$rank
        cat("\n")
        if (rdf > 0L) {
            rs <- sqrt(RSS/rdf)
            cat(if (length(rs) > 1L) 
                "Residual standard errors:"
            else "Residual standard error:", sapply(rs, format))
            cat("\n")
        }
        coef <- as.matrix(x$coefficients)[, 1L]  ################## ************ <- NOT HERE
        R <- qrx$qr
        R <- R[1L:min(dim(R)), , drop = FALSE]
        R[lower.tri(R)] <- 0
        if (rank < (nc <- length(coef))) {
            cat(paste(nc - rank, "out of", nc, "effects not estimable\n"))
            R <- R[, 1L:rank, drop = FALSE]
        }
        d2 <- sum(abs(diag(R)))
        diag(R) <- 0
        if (sum(abs(R))/d2 > tol) 
            cat("Estimated effects may be unbalanced\n")
        else cat("Estimated effects are balanced\n")
        if (nzchar(mess <- naprint(x$na.action))) 
            cat(mess, "\n", sep = "")
    }
    invisible(x)
}
<bytecode: 0x0000000014c90ca0>
<environment: namespace:stats>


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From m@cqueen1 @ending from llnl@gov  Mon Aug 13 16:48:50 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 13 Aug 2018 14:48:50 +0000
Subject: [R] searching for a specific row name in R
In-Reply-To: <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
Message-ID: <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>

Or to return a logical value, i.e., TRUE if the column contains the value, FALSE if it does not:

  any( x[,2] == 'A501' )

-Don
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:

    Hello Deepa,
    
    sum(x[,2] == "A501")
    or
    which(x[,2] == "A501")
    .
    Best,
    Albrecht
    
    
    -- 
      Albrecht Kauffmann
      alkauffm at fastmail.fm
    
    Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
    > Hello Everyone,
    > 
    > I have a 1000 x 20 matrix. The second column of the matrix has the names 
    > of identifiers. How do I check when a certain identifier is present in 
    > the set of 1000 identifier names present in the second column. For 
    > instance, let the names of identifiers be A1,A2,...A1000. I want to 
    > check whether A501 is present .How can this be checked?
    > 
    > Any help will be highly appreciated.
    > 
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @hivipmp82 @ending from gm@il@com  Mon Aug 13 17:07:07 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Mon, 13 Aug 2018 20:37:07 +0530
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
 <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
Message-ID: <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>

Hi Michael,

I was able to install RGtk2 from install.packages("
https://cran.r-project.org/bin/windows/contrib/3.3/RGtk2_2.20.31.zip",
repos=NULL) but after installing this and trying to install rattle i get
this error:
Error : package 'RGtk2' was installed by an R version with different
internals; it needs to be reinstalled for use with this R version
ERROR: lazy loading failed for package 'rattle'

I tried installing rattle from install.packages("rattle", repos="
https://rattle.togaware.com", type="source").

Regards, Shivi


On Sun, Aug 12, 2018 at 7:20 PM Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Dear Shivi
>
> What error message do you get when you try to install RGtk2?
>
> Michael
>
> On 12/08/2018 11:49, Shivi Bhatia wrote:
> > Hi Eric,
> >
> > Thank you for the reply. I am adding the session details below, hope it
> > helps:
> > R version 3.5.1 (2018-07-02)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows >= 8 x64 (build 9200)
> >
> > Matrix products: default
> > locale:
> > [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
> > LC_MONETARY=English_India.1252
> > [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > Thanks.
> >
> > On Sat, Aug 11, 2018 at 9:38 PM Eric Berger <ericjberger at gmail.com>
> wrote:
> >
> >> Hi Shivi,
> >> I have no experience with the rattle package but I just installed it
> with
> >> no problem.
> >> I am using a Windows 10 machine with R version 3.4.2.
> >>
> >> I suggest you provide additional information so that others may have
> ideas.
> >> e.g. your operating system version and output from sessionInfo() (in R)
> >>
> >> Best,
> >> Eric
> >>
> >>
> >> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia <shivipmp82 at gmail.com>
> >> wrote:
> >>
> >>> Hi,
> >>>
> >>> Need assistance on installing Rattle.
> >>>
> >>> I have followed the instructions on https://rattle.togaware.com/
> >>> but still facing error installing the package.
> >>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
> >>> Have tried installing RGt2 from multiple sources and its still failing.
> >>>
> >>> One of the suggestion on stack overflow was to downgrade the R version
> >>> here
> >>> :
> >>>
> >>>
> https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
> >>> Request assistance.
> >>>
> >>> Regards, Shivi
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Mon Aug 13 18:11:02 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Mon, 13 Aug 2018 18:11:02 +0200
Subject: [R] Typo in print.aov
In-Reply-To: <cc3652e5c58d48a0bd63757e0bb9e7df@med.umich.edu>
References: <cc3652e5c58d48a0bd63757e0bb9e7df@med.umich.edu>
Message-ID: <9EE2B66A-9205-4961-A052-B4B650C90C22@gmail.com>

That's a bug... no other place in the sources has "coeffficients". The net result is that the NULL case is used even when colnames _are_ present. It does make a difference, e.g. to examples(manova). I am fixing this in r-devel since the urgency must be rather low.

- Peter D.

> On 13 Aug 2018, at 14:27 , Andrews, Chris <chrisaa at med.umich.edu> wrote:
> 
> 
> While looking at the code of print.aov for a different reason, I noticed that 'coefficient' was spelled with 3 'f's in one location.  Perhaps this is on purpose but in another location it has just 2 'f's.  This has not caused me any problem (that I know of) but I found it curious.
> 
> Chris
> 
> 
> 
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> 
> 
> 
>> getAnywhere(print.aov)
> A single object matching 'print.aov' was found
> It was found in the following places
>  registered S3 method for print from namespace stats
>  namespace:stats
> with value
> 
> function (x, intercept = FALSE, tol = sqrt(.Machine$double.eps), 
>    ...) 
> {
>    if (!is.null(cl <- x$call)) {
>        cat("Call:\n   ")
>        dput(cl, control = NULL)
>    }
>    qrx <- if (x$rank) 
>        qr(x)
>    asgn <- x$assign[qrx$pivot[1L:x$rank]]
>    effects <- x$effects
>    if (!is.null(effects)) 
>        effects <- as.matrix(effects)[seq_along(asgn), , drop = FALSE]
>    rdf <- x$df.residual
>    resid <- as.matrix(x$residuals)
>    wt <- x$weights
>    if (!is.null(wt)) 
>        resid <- resid * sqrt(wt)
>    RSS <- colSums(resid^2)
>    uasgn <- unique(asgn)
>    nmeffect <- c("(Intercept)", attr(x$terms, "term.labels"))[1 + 
>        uasgn]
>    nterms <- length(uasgn)
>    nresp <- NCOL(effects)
>    df <- numeric(nterms)
>    ss <- matrix(NA, nterms, nresp)
>    if (nterms) {
>        for (i in seq(nterms)) {
>            ai <- asgn == uasgn[i]
>            df[i] <- sum(ai)
>            ef <- effects[ai, , drop = FALSE]
>            ss[i, ] <- if (sum(ai) > 1) 
>                colSums(ef^2)
>            else ef^2
>        }
>        keep <- df > 0L
>        if (!intercept && uasgn[1L] == 0) 
>            keep[1L] <- FALSE
>        nmeffect <- nmeffect[keep]
>        df <- df[keep]
>        ss <- ss[keep, , drop = FALSE]
>        nterms <- length(df)
>    }
>    cat("\nTerms:\n")
>    if (nterms == 0L) {
>        if (rdf > 0L) {
>            ss <- RSS
>            ssp <- sapply(ss, format)
>            if (!is.matrix(ssp)) 
>                ssp <- t(ssp)
>            tmp <- as.matrix(c(ssp, format(rdf)))
>            if (length(ss) > 1L) {
>                rn <- colnames(x$fitted.values)
>                if (is.null(rn)) 
>                  rn <- paste("resp", seq_along(ss))
>            }
>            else rn <- "Sum of Squares"
>            dimnames(tmp) <- list(c(rn, "Deg. of Freedom"), "Residuals")
>            print(tmp, quote = FALSE, right = TRUE)
>            cat("\n")
>            rs <- sqrt(RSS/rdf)
>            cat(if (length(rs) > 1L) 
>                "Residual standard errors:"
>            else "Residual standard error:", sapply(rs, format))
>            cat("\n")
>        }
>        else print(matrix(0, 2L, 1L, dimnames = list(c("Sum of Squares", 
>            "Deg. of Freedom"), "<empty>")))
>    }
>    else {
>        if (rdf > 0L) {
>            nterms <- nterms + 1L
>            df <- c(df, rdf)
>            ss <- rbind(ss, RSS)
>            nmeffect <- c(nmeffect, "Residuals")
>        }
>        ssp <- apply(zapsmall(ss), 2L, format)
>        tmp <- t(cbind(ssp, format(df)))
>        if (ncol(effects) > 1L) {
>            rn <- colnames(x$coeffficients) ###############************ <------- HERE
>            if (is.null(rn)) 
>                rn <- paste("resp", seq(ncol(effects)))
>        }
>        else rn <- "Sum of Squares"
>        dimnames(tmp) <- list(c(rn, "Deg. of Freedom"), nmeffect)
>        print(tmp, quote = FALSE, right = TRUE)
>        rank <- x$rank
>        cat("\n")
>        if (rdf > 0L) {
>            rs <- sqrt(RSS/rdf)
>            cat(if (length(rs) > 1L) 
>                "Residual standard errors:"
>            else "Residual standard error:", sapply(rs, format))
>            cat("\n")
>        }
>        coef <- as.matrix(x$coefficients)[, 1L]  ################## ************ <- NOT HERE
>        R <- qrx$qr
>        R <- R[1L:min(dim(R)), , drop = FALSE]
>        R[lower.tri(R)] <- 0
>        if (rank < (nc <- length(coef))) {
>            cat(paste(nc - rank, "out of", nc, "effects not estimable\n"))
>            R <- R[, 1L:rank, drop = FALSE]
>        }
>        d2 <- sum(abs(diag(R)))
>        diag(R) <- 0
>        if (sum(abs(R))/d2 > tol) 
>            cat("Estimated effects may be unbalanced\n")
>        else cat("Estimated effects are balanced\n")
>        if (nzchar(mess <- naprint(x$na.action))) 
>            cat(mess, "\n", sep = "")
>    }
>    invisible(x)
> }
> <bytecode: 0x0000000014c90ca0>
> <environment: namespace:stats>
> 
> 
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From li@t@ @ending from dewey@myzen@co@uk  Mon Aug 13 18:26:38 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 13 Aug 2018 17:26:38 +0100
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
 <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
 <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>
Message-ID: <3d221e3e-52f0-fffe-f70d-31e43845fc57@dewey.myzen.co.uk>

Dear Shivi

You are running R 3.5.1 according to your session info. Why are you 
installing a version for R 3.3? Note that the up-to-date version depends 
on R > 3.4.0 so it is no surprise that you get problems.

Michael

On 13/08/2018 16:07, Shivi Bhatia wrote:
> Hi Michael,
> 
> I was able to install RGtk2 
> from?install.packages("https://cran.r-project.org/bin/windows/contrib/3.3/RGtk2_2.20.31.zip", 
> repos=NULL) but after installing this and trying to install rattle i get 
> this error:
> Error : package 'RGtk2' was installed by an R version with different 
> internals; it needs to be reinstalled for use with this R version
> ERROR: lazy loading failed for package 'rattle'
> 
> I tried installing rattle from?install.packages("rattle", 
> repos="https://rattle.togaware.com", type="source").
> 
> Regards, Shivi
> 
> 
> On Sun, Aug 12, 2018 at 7:20 PM Michael Dewey <lists at dewey.myzen.co.uk 
> <mailto:lists at dewey.myzen.co.uk>> wrote:
> 
>     Dear Shivi
> 
>     What error message do you get when you try to install RGtk2?
> 
>     Michael
> 
>     On 12/08/2018 11:49, Shivi Bhatia wrote:
>      > Hi Eric,
>      >
>      > Thank you for the reply. I am adding the session details below,
>     hope it
>      > helps:
>      > R version 3.5.1 (2018-07-02)
>      > Platform: x86_64-w64-mingw32/x64 (64-bit)
>      > Running under: Windows >= 8 x64 (build 9200)
>      >
>      > Matrix products: default
>      > locale:
>      > [1] LC_COLLATE=English_India.1252? LC_CTYPE=English_India.1252
>      > LC_MONETARY=English_India.1252
>      > [4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ?LC_TIME=English_India.1252
>      >
>      > attached base packages:
>      > [1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
>      >
>      > Thanks.
>      >
>      > On Sat, Aug 11, 2018 at 9:38 PM Eric Berger
>     <ericjberger at gmail.com <mailto:ericjberger at gmail.com>> wrote:
>      >
>      >> Hi Shivi,
>      >> I have no experience with the rattle package but I just
>     installed it with
>      >> no problem.
>      >> I am using a Windows 10 machine with R version 3.4.2.
>      >>
>      >> I suggest you provide additional information so that others may
>     have ideas.
>      >> e.g. your operating system version and output from sessionInfo()
>     (in R)
>      >>
>      >> Best,
>      >> Eric
>      >>
>      >>
>      >> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia
>     <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>>
>      >> wrote:
>      >>
>      >>> Hi,
>      >>>
>      >>> Need assistance on installing Rattle.
>      >>>
>      >>> I have followed the instructions on https://rattle.togaware.com/
>      >>> but still facing error installing the package.
>      >>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
>      >>> Have tried installing RGt2 from multiple sources and its still
>     failing.
>      >>>
>      >>> One of the suggestion on stack overflow was to downgrade the R
>     version
>      >>> here
>      >>> :
>      >>>
>      >>>
>     https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>      >>> Request assistance.
>      >>>
>      >>> Regards, Shivi
>      >>>
>      >>>? ? ? ? ? [[alternative HTML version deleted]]
>      >>>
>      >>> ______________________________________________
>      >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >>> PLEASE do read the posting guide
>      >>> http://www.R-project.org/posting-guide.html
>      >>> and provide commented, minimal, self-contained, reproducible code.
>      >>>
>      >>
>      >>
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
> 
>     -- 
>     Michael
>     http://www.dewey.myzen.co.uk/home.html
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From i@t@z@hn @ending from gm@il@com  Mon Aug 13 21:17:54 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Mon, 13 Aug 2018 15:17:54 -0400
Subject: [R] Fast matrix multiplication
In-Reply-To: <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
 <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
Message-ID: <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>

On Mon, Aug 13, 2018 at 2:41 PM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Hi Ista,
> Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?

Not sure. If you want an easy way I would use MRO. More info at
https://mran.microsoft.com/rro#intelmkl1

--Ista

> Thanks,
> Ravi
>
> -----Original Message-----
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Friday, August 10, 2018 12:20 PM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] Fast matrix multiplication
>
>
> Hi Ravi,
>
> You can achieve substantial speed up by using a faster BLAS (e.g., OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6 year old, but 8 core) system your example takes 3.9 seconds with using the reference BLAS and only 0.9 seconds using OpenBLAS.
>
> Best,
> Ista
> On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> >
> > Hi,
> >
> > I would like to compute:  A %*% B %*% t(A)
> >
> >
> >
> > A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
> >
> >
> >
> > Here is a sample code.
> >
> >
> >
> > M <- 10000
> >
> > N <- 100
> >
> > A <- matrix(rnorm(M*N), M, N)
> >
> > B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric
> > positive-definite matrix
> >
> >
> >
> > # method 1
> >
> > system.time(D <- A %*% B %*% t(A))
> >
> >
> >
> > # I can obtain speedup by using a Cholesky decomposition of B
> >
> > # method 2
> >
> > system.time({
> >
> > C <- t(chol(B))
> >
> > E <- tcrossprod(A%*%C)
> >
> > })
> >
> >
> >
> > all.equal(D, E)
> >
> >
> >
> > I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
> >
> >
> >
> > Thanks,
> >
> > Ravi
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From peter@l@ngfelder @ending from gm@il@com  Mon Aug 13 21:34:59 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Mon, 13 Aug 2018 12:34:59 -0700
Subject: [R] Fast matrix multiplication
In-Reply-To: <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
 <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
 <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
Message-ID: <CA+hbrhUPrWMkA6SAukZeCLt50SCZmkPctEgOV+mE7bB3D2kSnQ@mail.gmail.com>

On Mon, Aug 13, 2018 at 12:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Mon, Aug 13, 2018 at 2:41 PM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> >
> > Hi Ista,
> > Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?
>
> Not sure. If you want an easy way I would use MRO. More info at
> https://mran.microsoft.com/rro#intelmkl1

OpenBLAS is provided as a binary for Windows, see http://www.openblas.net/ .

You may need to compile R from source though, unless you can use an
equivalent of the linux trick to replace libRblas.so with a symlink to
the compiled openBLAS library.

Peter


From r@turner @ending from @uckl@nd@@c@nz  Tue Aug 14 01:16:09 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Tue, 14 Aug 2018 11:16:09 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
Message-ID: <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>

On 13/08/18 23:39, peter dalgaard wrote:
> It's odd, possibly a bug, that you don't get
> 
> Error: object 'nphi' not found
> 
> but I can't offhand see where the evaluation of args to .C/.Fortran is supposed to take place.

If it is indeed a bug then it would be nice an it were fixed.  If that 
is possible.  Way beyond my level of comprehension but.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From deep@m@hm@ii@c @ending from gm@il@com  Tue Aug 14 05:36:00 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa)
Date: Tue, 14 Aug 2018 09:06:00 +0530
Subject: [R] searching for a specific row name in R
In-Reply-To: <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
Message-ID: <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>

Hi Don,

When there is a list of identifier names that I want to check, the only way
is to loop over each entry stored in the list of identifier names or is
there is there any other shortcut?

Many thanks for the response?

On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Or to return a logical value, i.e., TRUE if the column contains the value,
> FALSE if it does not:
>
>   any( x[,2] == 'A501' )
>
> -Don
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
> r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
>
>     Hello Deepa,
>
>     sum(x[,2] == "A501")
>     or
>     which(x[,2] == "A501")
>     .
>     Best,
>     Albrecht
>
>
>     --
>       Albrecht Kauffmann
>       alkauffm at fastmail.fm
>
>     Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
>     > Hello Everyone,
>     >
>     > I have a 1000 x 20 matrix. The second column of the matrix has the
> names
>     > of identifiers. How do I check when a certain identifier is present
> in
>     > the set of 1000 identifier names present in the second column. For
>     > instance, let the names of identifiers be A1,A2,...A1000. I want to
>     > check whether A501 is present .How can this be checked?
>     >
>     > Any help will be highly appreciated.
>     >
>     >
>     >   [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From bori@@@teipe @ending from utoronto@c@  Tue Aug 14 05:46:05 2018
From: bori@@@teipe @ending from utoronto@c@ (Boris Steipe)
Date: Mon, 13 Aug 2018 23:46:05 -0400
Subject: [R] searching for a specific row name in R
In-Reply-To: <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
Message-ID: <11492AAE-6888-4D90-B408-F020FAD5DFC3@utoronto.ca>

Use the %in% operator:

help('%in%')

e.g.

R > c("d", "v", "4", "s") %in% letters
[1]  TRUE  TRUE FALSE  TRUE


B.


> On 2018-08-13, at 23:36, Deepa <deepamahm.iisc at gmail.com> wrote:
> 
> Hi Don,
> 
> When there is a list of identifier names that I want to check, the only way
> is to loop over each entry stored in the list of identifier names or is
> there is there any other shortcut?
> 
> Many thanks for the response?
> 
> On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
>> Or to return a logical value, i.e., TRUE if the column contains the value,
>> FALSE if it does not:
>> 
>>  any( x[,2] == 'A501' )
>> 
>> -Don
>> --
>> Don MacQueen
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> Lab cell 925-724-7509
>> 
>> 
>> 
>> ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
>> r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
>> 
>>    Hello Deepa,
>> 
>>    sum(x[,2] == "A501")
>>    or
>>    which(x[,2] == "A501")
>>    .
>>    Best,
>>    Albrecht
>> 
>> 
>>    --
>>      Albrecht Kauffmann
>>      alkauffm at fastmail.fm
>> 
>>    Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
>>> Hello Everyone,
>>> 
>>> I have a 1000 x 20 matrix. The second column of the matrix has the
>> names
>>> of identifiers. How do I check when a certain identifier is present
>> in
>>> the set of 1000 identifier names present in the second column. For
>>> instance, let the names of identifiers be A1,A2,...A1000. I want to
>>> check whether A501 is present .How can this be checked?
>>> 
>>> Any help will be highly appreciated.
>>> 
>>> 
>>>  [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>    ______________________________________________
>>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>    PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>    and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From deep@m@hm@ii@c @ending from gm@il@com  Tue Aug 14 06:16:15 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa)
Date: Tue, 14 Aug 2018 09:46:15 +0530
Subject: [R] searching for a specific row name in R
In-Reply-To: <11492AAE-6888-4D90-B408-F020FAD5DFC3@utoronto.ca>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
 <11492AAE-6888-4D90-B408-F020FAD5DFC3@utoronto.ca>
Message-ID: <CAGchuN5A4=mdGbynBZf4Mk3256rB5c07Htw9OR28fpM09Dd1Lg@mail.gmail.com>

I have a hundred identifier names that I want to check from the second
column of a matrix with 6000 entries in the column.
Instead of using  R > c("d", "v", "4", "s") %in% letters , is there an
alternative?

I have the hundred identifier names that are of my interest stored in an
array.




On Tue, Aug 14, 2018 at 9:16 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Use the %in% operator:
>
> help('%in%')
>
> e.g.
>
> R > c("d", "v", "4", "s") %in% letters
> [1]  TRUE  TRUE FALSE  TRUE
>
>
> B.
>
>
> > On 2018-08-13, at 23:36, Deepa <deepamahm.iisc at gmail.com> wrote:
> >
> > Hi Don,
> >
> > When there is a list of identifier names that I want to check, the only
> way
> > is to loop over each entry stored in the list of identifier names or is
> > there is there any other shortcut?
> >
> > Many thanks for the response?
> >
> > On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov>
> wrote:
> >
> >> Or to return a logical value, i.e., TRUE if the column contains the
> value,
> >> FALSE if it does not:
> >>
> >>  any( x[,2] == 'A501' )
> >>
> >> -Don
> >> --
> >> Don MacQueen
> >> Lawrence Livermore National Laboratory
> >> 7000 East Ave., L-627
> >> Livermore, CA 94550
> >> 925-423-1062
> >> Lab cell 925-724-7509
> >>
> >>
> >>
> >> ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
> >> r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
> >>
> >>    Hello Deepa,
> >>
> >>    sum(x[,2] == "A501")
> >>    or
> >>    which(x[,2] == "A501")
> >>    .
> >>    Best,
> >>    Albrecht
> >>
> >>
> >>    --
> >>      Albrecht Kauffmann
> >>      alkauffm at fastmail.fm
> >>
> >>    Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
> >>> Hello Everyone,
> >>>
> >>> I have a 1000 x 20 matrix. The second column of the matrix has the
> >> names
> >>> of identifiers. How do I check when a certain identifier is present
> >> in
> >>> the set of 1000 identifier names present in the second column. For
> >>> instance, let the names of identifiers be A1,A2,...A1000. I want to
> >>> check whether A501 is present .How can this be checked?
> >>>
> >>> Any help will be highly appreciated.
> >>>
> >>>
> >>>  [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>    ______________________________________________
> >>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>    https://stat.ethz.ch/mailman/listinfo/r-help
> >>    PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>    and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Aug 14 06:18:06 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 13 Aug 2018 21:18:06 -0700
Subject: [R] searching for a specific row name in R
In-Reply-To: <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
Message-ID: <CAGxFJbRQ=5Hn_E7PG+6xHVE01FJJuZGr7YZ3BXoxS3SqBbBpcw@mail.gmail.com>

These seem to be basic R questions. You should spend time with an R
tutorial or two for this sort of thing. This list is here to help, but you
also need to do homework on your own if you have not already done so.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Aug 13, 2018 at 8:36 PM, Deepa <deepamahm.iisc at gmail.com> wrote:

> Hi Don,
>
> When there is a list of identifier names that I want to check, the only way
> is to loop over each entry stored in the list of identifier names or is
> there is there any other shortcut?
>
> Many thanks for the response?
>
> On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>
> > Or to return a logical value, i.e., TRUE if the column contains the
> value,
> > FALSE if it does not:
> >
> >   any( x[,2] == 'A501' )
> >
> > -Don
> > --
> > Don MacQueen
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> > Lab cell 925-724-7509
> >
> >
> >
> > ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
> > r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
> >
> >     Hello Deepa,
> >
> >     sum(x[,2] == "A501")
> >     or
> >     which(x[,2] == "A501")
> >     .
> >     Best,
> >     Albrecht
> >
> >
> >     --
> >       Albrecht Kauffmann
> >       alkauffm at fastmail.fm
> >
> >     Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
> >     > Hello Everyone,
> >     >
> >     > I have a 1000 x 20 matrix. The second column of the matrix has the
> > names
> >     > of identifiers. How do I check when a certain identifier is present
> > in
> >     > the set of 1000 identifier names present in the second column. For
> >     > instance, let the names of identifiers be A1,A2,...A1000. I want to
> >     > check whether A501 is present .How can this be checked?
> >     >
> >     > Any help will be highly appreciated.
> >     >
> >     >
> >     >   [[alternative HTML version deleted]]
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >
> >     ______________________________________________
> >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mich@l@burd@ @ending from centrum@cz  Tue Aug 14 08:44:51 2018
From: mich@l@burd@ @ending from centrum@cz (Michal Burda)
Date: Tue, 14 Aug 2018 08:44:51 +0200
Subject: [R] Makefile generator - please comment
Message-ID: <CAP4zaHNhvA+XWbirUfGJryxh1u7exUVjZ-=JPAP4CX9m8R1ZUg@mail.gmail.com>

Dear R users,

I would like to ask you for comments on whether you find interesting a
package that would help you generate Makefiles for R analytical projects. I
am developing it for some time mainly for myself and now try to decide
whether it is worth an effort to continue and enhance it for wider
audience. Install the most recent version from github, if you wish:

devtools::install_github("beerda/rmake")

The use of the package is very simple. You write your rules as a pipe
similar to Magrittr's operator:

library(rmake)
job <- 'input.csv' %>>% rRule('preprocess.R') %>>% 'data.rds' %>>%
markdownRule('report.Rmd') %>>% 'report.pdf'
makefile(job, 'Makefile')

Thats it. This piece of code generates a complete Makefile that runs
preprocess.R, which reads input.csv and writes data.rds, and then compiles
a markdown report.Rmd, which depends on data.rds, and creates a final
report.pdf. (Of course more complicated pipelines are possible as well as
define dependencies programmatically, also some other features are
implemented already, you can imagine...) I ask the community of whether you
find it useful and whether it is good idea to continue in development of
such package. Recently, some other build tools appeared for R, which seem
very interesting, but which I am not so much experienced with (e.g.
"drake"). There are also some other projects with similar purpose, but they
seem more or less abandoned. Any comments are welcome.

Thanks, in advance.

Best regards,

Michal Burda

	[[alternative HTML version deleted]]


From ckelley @ending from @ir@org  Mon Aug 13 19:18:16 2018
From: ckelley @ending from @ir@org (Kelley, Claire)
Date: Mon, 13 Aug 2018 17:18:16 +0000
Subject: [R] Cannot set correct miktex path for pdflatex
Message-ID: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>

Hi all,

I am having a problem in R where R is finding an old non existent version of miktex rather than the new version. This occurs despite having set the path to the correct location.

For example in bash if I look for the location of pdflatex:

$ which pdflatex
/c/Program Files/MiKTeX 2.9/miktex/bin/x64/pdflatex


It points to the correct MikTex installation.

However in R:

Sys.which("pdflatex")
                                                pdflatex
C:\\PROGRA~1\\MIKTEX~1.9\\miktex\\bin\\x64\\pdflatex.exe"

Points to the old  (1.9) version of Miktex.

This is my session info:

R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.1

Any thoughts?

I have unsuccessfully tried:


  1.  Adding correct MikTex path to my Renviorn.site. this adds MikTex to my path and I can see the addition, but doesn?t fix the problem
  2.  Adding MikTex path to my $PATH variable. This lets bash find the right version of miktex but doesn?t help in R
  3.  Making sure I only have on version of MIktex. I don?t have tiny tex installed (nor can I because I need the full MIkTex for other work) .


Best,
Claire

	[[alternative HTML version deleted]]


From r@vi@v@r@dh@n @ending from jhu@edu  Mon Aug 13 20:41:57 2018
From: r@vi@v@r@dh@n @ending from jhu@edu (Ravi Varadhan)
Date: Mon, 13 Aug 2018 18:41:57 +0000
Subject: [R] Fast matrix multiplication
In-Reply-To: <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
Message-ID: <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>

Hi Ista,
Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?
Thanks,
Ravi

-----Original Message-----
From: Ista Zahn <istazahn at gmail.com> 
Sent: Friday, August 10, 2018 12:20 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: r-help at r-project.org
Subject: Re: [R] Fast matrix multiplication


Hi Ravi,

You can achieve substantial speed up by using a faster BLAS (e.g., OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6 year old, but 8 core) system your example takes 3.9 seconds with using the reference BLAS and only 0.9 seconds using OpenBLAS.

Best,
Ista
On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Hi,
>
> I would like to compute:  A %*% B %*% t(A)
>
>
>
> A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
>
>
>
> Here is a sample code.
>
>
>
> M <- 10000
>
> N <- 100
>
> A <- matrix(rnorm(M*N), M, N)
>
> B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric 
> positive-definite matrix
>
>
>
> # method 1
>
> system.time(D <- A %*% B %*% t(A))
>
>
>
> # I can obtain speedup by using a Cholesky decomposition of B
>
> # method 2
>
> system.time({
>
> C <- t(chol(B))
>
> E <- tcrossprod(A%*%C)
>
> })
>
>
>
> all.equal(D, E)
>
>
>
> I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
>
>
>
> Thanks,
>
> Ravi
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @hivipmp82 @ending from gm@il@com  Mon Aug 13 20:47:39 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Mon, 13 Aug 2018 18:47:39 +0000 (UTC)
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <3d221e3e-52f0-fffe-f70d-31e43845fc57@dewey.myzen.co.uk>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
 <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
 <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>
 <3d221e3e-52f0-fffe-f70d-31e43845fc57@dewey.myzen.co.uk>
Message-ID: <630087097.36649.1534186059024@mail.yahoo.com>

Hi Michael?Thank you for the reply.I have been looking for 3.5.1 version of this package but I cannot find one, would you recommend downgrading my current R version.?Would there be some or any other compatibly issue - please advice.?
Thank you, Shivi?


Sent from Yahoo Mail for iPhone


On Monday, August 13, 2018, 21:56, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

Dear Shivi

You are running R 3.5.1 according to your session info. Why are you 
installing a version for R 3.3? Note that the up-to-date version depends 
on R > 3.4.0 so it is no surprise that you get problems.

Michael

On 13/08/2018 16:07, Shivi Bhatia wrote:
> Hi Michael,
> 
> I was able to install RGtk2 
> from?install.packages("https://cran.r-project.org/bin/windows/contrib/3.3/RGtk2_2.20.31.zip", 
> repos=NULL) but after installing this and trying to install rattle i get 
> this error:
> Error : package 'RGtk2' was installed by an R version with different 
> internals; it needs to be reinstalled for use with this R version
> ERROR: lazy loading failed for package 'rattle'
> 
> I tried installing rattle from?install.packages("rattle", 
> repos="https://rattle.togaware.com", type="source").
> 
> Regards, Shivi
> 
> 
> On Sun, Aug 12, 2018 at 7:20 PM Michael Dewey <lists at dewey.myzen.co.uk 
> <mailto:lists at dewey.myzen.co.uk>> wrote:
> 
>? ? Dear Shivi
> 
>? ? What error message do you get when you try to install RGtk2?
> 
>? ? Michael
> 
>? ? On 12/08/2018 11:49, Shivi Bhatia wrote:
>? ? ? > Hi Eric,
>? ? ? >
>? ? ? > Thank you for the reply. I am adding the session details below,
>? ? hope it
>? ? ? > helps:
>? ? ? > R version 3.5.1 (2018-07-02)
>? ? ? > Platform: x86_64-w64-mingw32/x64 (64-bit)
>? ? ? > Running under: Windows >= 8 x64 (build 9200)
>? ? ? >
>? ? ? > Matrix products: default
>? ? ? > locale:
>? ? ? > [1] LC_COLLATE=English_India.1252? LC_CTYPE=English_India.1252
>? ? ? > LC_MONETARY=English_India.1252
>? ? ? > [4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ?LC_TIME=English_India.1252
>? ? ? >
>? ? ? > attached base packages:
>? ? ? > [1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
>? ? ? >
>? ? ? > Thanks.
>? ? ? >
>? ? ? > On Sat, Aug 11, 2018 at 9:38 PM Eric Berger
>? ? <ericjberger at gmail.com <mailto:ericjberger at gmail.com>> wrote:
>? ? ? >
>? ? ? >> Hi Shivi,
>? ? ? >> I have no experience with the rattle package but I just
>? ? installed it with
>? ? ? >> no problem.
>? ? ? >> I am using a Windows 10 machine with R version 3.4.2.
>? ? ? >>
>? ? ? >> I suggest you provide additional information so that others may
>? ? have ideas.
>? ? ? >> e.g. your operating system version and output from sessionInfo()
>? ? (in R)
>? ? ? >>
>? ? ? >> Best,
>? ? ? >> Eric
>? ? ? >>
>? ? ? >>
>? ? ? >> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia
>? ? <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>>
>? ? ? >> wrote:
>? ? ? >>
>? ? ? >>> Hi,
>? ? ? >>>
>? ? ? >>> Need assistance on installing Rattle.
>? ? ? >>>
>? ? ? >>> I have followed the instructions on https://rattle.togaware.com/
>? ? ? >>> but still facing error installing the package.
>? ? ? >>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
>? ? ? >>> Have tried installing RGt2 from multiple sources and its still
>? ? failing.
>? ? ? >>>
>? ? ? >>> One of the suggestion on stack overflow was to downgrade the R
>? ? version
>? ? ? >>> here
>? ? ? >>> :
>? ? ? >>>
>? ? ? >>>
>? ? https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>? ? ? >>> Request assistance.
>? ? ? >>>
>? ? ? >>> Regards, Shivi
>? ? ? >>>
>? ? ? >>>? ? ? ? ? [[alternative HTML version deleted]]
>? ? ? >>>
>? ? ? >>> ______________________________________________
>? ? ? >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>? ? -- To UNSUBSCRIBE and more, see
>? ? ? >>> https://stat.ethz.ch/mailman/listinfo/r-help
>? ? ? >>> PLEASE do read the posting guide
>? ? ? >>> http://www.R-project.org/posting-guide.html
>? ? ? >>> and provide commented, minimal, self-contained, reproducible code.
>? ? ? >>>
>? ? ? >>
>? ? ? >>
>? ? ? >
>? ? ? >? ? ? ?[[alternative HTML version deleted]]
>? ? ? >
>? ? ? > ______________________________________________
>? ? ? > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>? ? -- To UNSUBSCRIBE and more, see
>? ? ? > https://stat.ethz.ch/mailman/listinfo/r-help
>? ? ? > PLEASE do read the posting guide
>? ? http://www.R-project.org/posting-guide.html
>? ? ? > and provide commented, minimal, self-contained, reproducible code.
>? ? ? >
> 
>? ? -- 
>? ? Michael
>? ? http://www.dewey.myzen.co.uk/home.html
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html




	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Tue Aug 14 09:49:16 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Tue, 14 Aug 2018 10:49:16 +0300
Subject: [R] Cannot set correct miktex path for pdflatex
In-Reply-To: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>
References: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>
Message-ID: <CAGgJW74V+fWR7-rwPSJXHPxe15sAGK-5cdr5M-sJxad-KcbijQ@mail.gmail.com>

Hi Claire,
In Unix (linux) the 'which' command is documented as searching for the
command according to the PATH environment variable.
The different results from
$ which
and
> Sys.which()
would point to the fact that the PATH variable is different in the two
cases.

Compare:
$ echo $PATH

versus

Sys.getenv("PATH")

HTH,
Eric




On Mon, Aug 13, 2018 at 8:18 PM, Kelley, Claire <ckelley at air.org> wrote:

> Hi all,
>
> I am having a problem in R where R is finding an old non existent version
> of miktex rather than the new version. This occurs despite having set the
> path to the correct location.
>
> For example in bash if I look for the location of pdflatex:
>
> $ which pdflatex
> /c/Program Files/MiKTeX 2.9/miktex/bin/x64/pdflatex
>
>
> It points to the correct MikTex installation.
>
> However in R:
>
> Sys.which("pdflatex")
>                                                 pdflatex
> C:\\PROGRA~1\\MIKTEX~1.9\\miktex\\bin\\x64\\pdflatex.exe"
>
> Points to the old  (1.9) version of Miktex.
>
> This is my session info:
>
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.1
>
> Any thoughts?
>
> I have unsuccessfully tried:
>
>
>   1.  Adding correct MikTex path to my Renviorn.site. this adds MikTex to
> my path and I can see the addition, but doesn?t fix the problem
>   2.  Adding MikTex path to my $PATH variable. This lets bash find the
> right version of miktex but doesn?t help in R
>   3.  Making sure I only have on version of MIktex. I don?t have tiny tex
> installed (nor can I because I need the full MIkTex for other work) .
>
>
> Best,
> Claire
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Tue Aug 14 01:13:50 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Mon, 13 Aug 2018 19:13:50 -0400
Subject: [R] Request for help with R program
Message-ID: <CAPQaxLOAYS0q7-wzQ30Df6SL6JkuospJMY7Gvh-SLpvbRqRWcQ@mail.gmail.com>

Good evening,

  I am a high school research student who is partnering with Baylor
University (TX) on a Genomic research project, and was seeking to use the R
program to analysis our data? which is from GDC database. R-3.5.1 is
currently downloaded onto my Windows PC and I am looking to download the
CGDS and GAIA packages, and then to subsequently downloaded and analyze the
Genomic data we have extracted via the R packages. I attempted to utilize
the various help utilities you provide, but I am rather inexperienced with
computer programming and the R program as a whole. Therefore, I am
requesting a screen sharing session and/or phone or email correspondence
with one of your associates so to achieve my goals. Such would be very
helpful to my and my mentors work, and our pending publication.

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]


From @purdle@@ @ending from gm@il@com  Tue Aug 14 05:16:08 2018
From: @purdle@@ @ending from gm@il@com (Abs Spurdle)
Date: Tue, 14 Aug 2018 15:16:08 +1200
Subject: [R] Prevent Printing Function's Environment
Message-ID: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>

Hi All

When you print a function constructed within a function, R prints it's
environment.
For example:

> myfunction = function ()
+ {   f = function () NULL
+     attributes (f) = list (class="myfunction", myattribute=1)
+     f
+ }

> myfunction.f = myfunction ()

> myfunction.f
function ()
NULL
<environment: 0x03fcbc30>
attr(,"class")
[1] "myfunction"
attr(,"myattribute")
[1] 1

One way to prevent this is to set the function's environment to the global
environment.
But I was wondering if there's a way to stop R from printing the
environment without changing the environment?


kind regards
Abs

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Tue Aug 14 10:34:40 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 14 Aug 2018 09:34:40 +0100
Subject: [R] Prevent Printing Function's Environment
In-Reply-To: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>
References: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>
Message-ID: <ff749e3e-5467-a3a7-8d7f-89073be90fae@sapo.pt>

Hello,

I am not sure I understand the question.
You say that

One way to prevent this [to print the attributes] is to set the 
function's environment to the global environment.

But this is not true, just see the example below, where I set the 
function's environment to .GlobalEnv


myfunction2 = function (){
   f = function () NULL
   attributes (f) = list (class="myfunction2", myattribute2=1)
   environment(f) <- .GlobalEnv
   f
}

myfunction2.f = myfunction2 ()

myfunction2.f
#function ()
#  NULL
#attr(,"class")
#[1] "myfunction2"
#attr(,"myattribute2")
#[1] 1

environment(myfunction2.f)
#<environment: R_GlobalEnv>


When you run the function's name, the function's definition is printed, 
all of it. If you want to print its return value you have to call it 
with the parenthesis:

myfunction2.f()    # My function
#NULL

myfunction.f()     # Your function
#NULL


If you want to print the body of the function, use, well, body().

body(myfunction.f)
#NULL


Hope this helps,

Rui Barradas
?s 04:16 de 14/08/2018, Abs Spurdle escreveu:
> Hi All
> 
> When you print a function constructed within a function, R prints it's
> environment.
> For example:
> 
>> myfunction = function ()
> + {   f = function () NULL
> +     attributes (f) = list (class="myfunction", myattribute=1)
> +     f
> + }
> 
>> myfunction.f = myfunction ()
> 
>> myfunction.f
> function ()
> NULL
> <environment: 0x03fcbc30>
> attr(,"class")
> [1] "myfunction"
> attr(,"myattribute")
> [1] 1
> 
> One way to prevent this is to set the function's environment to the global
> environment.
> But I was wondering if there's a way to stop R from printing the
> environment without changing the environment?
> 
> 
> kind regards
> Abs
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@echler @ending from @t@t@m@th@ethz@ch  Tue Aug 14 10:58:45 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 14 Aug 2018 10:58:45 +0200
Subject: [R] Prevent Printing Function's Environment
In-Reply-To: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>
References: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>
Message-ID: <23410.39365.388183.563907@stat.math.ethz.ch>

>>>>> Abs Spurdle 
>>>>>     on Tue, 14 Aug 2018 15:16:08 +1200 writes:

    > Hi All

    > When you print a function constructed within a function, R
    > prints it's environment.  For example:

     > > myfunction = function ()
     > + {   f = function () NULL
     > +     attributes (f) = list (class="myfunction", myattribute=1)
     > +     f
     > + }

     > > myfunction.f = myfunction ()

     > > myfunction.f
     > function ()
     > NULL
     > <environment: 0x03fcbc30>
     > attr(,"class")
     > [1] "myfunction"
     > attr(,"myattribute")
     > [1] 1

     > One way to prevent this is to set the function's environment to the global
     > environment.
     > But I was wondering if there's a way to stop R from printing the
     > environment without changing the environment?

Probably, not the way you want, but if you need it e.g., for
didactical reasons, here's a way that may be didactically
relevant in it self:

  > ls.str
  function (pos = -1, name, envir, all.names = FALSE, pattern, 
      mode = "any") 
  {
      if (missing(envir)) 
	  envir <- as.environment(pos)
      nms <- ls(name, envir = envir, all.names = all.names, pattern = pattern)
      r <- unlist(lapply(nms, function(n) exists(n, envir = envir, 
	  mode = mode, inherits = FALSE)))
      structure(nms[r], envir = envir, mode = mode, class = "ls_str")
  }
  <bytecode: 0xb222858>
  <environment: namespace:utils>

so, I want to suppress the last two lines that are printed.
That's a piece of cake if you know  capture.output() :

  > P2 <- function(.) writeLines(head(capture.output(.), -2))
  > P2(ls.str)
  function (pos = -1, name, envir, all.names = FALSE, pattern, 
      mode = "any") 
  {
      if (missing(envir)) 
	  envir <- as.environment(pos)
      nms <- ls(name, envir = envir, all.names = all.names, pattern = pattern)
      r <- unlist(lapply(nms, function(n) exists(n, envir = envir, 
	  mode = mode, inherits = FALSE)))
      structure(nms[r], envir = envir, mode = mode, class = "ls_str")
  }
  >


From ruipb@rr@d@@ @ending from @@po@pt  Tue Aug 14 10:20:35 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 14 Aug 2018 09:20:35 +0100
Subject: [R] searching for a specific row name in R
In-Reply-To: <CAGchuN5A4=mdGbynBZf4Mk3256rB5c07Htw9OR28fpM09Dd1Lg@mail.gmail.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
 <11492AAE-6888-4D90-B408-F020FAD5DFC3@utoronto.ca>
 <CAGchuN5A4=mdGbynBZf4Mk3256rB5c07Htw9OR28fpM09Dd1Lg@mail.gmail.com>
Message-ID: <53204ebd-0403-f5bd-9eee-c1beff3caf24@sapo.pt>

Hello,

If you have one hundred identifier names that you want to check the 
result of

id %in% column

will have length 100, the same as length(id).
If you want a shorter result you can do

which(id %in% column)

This will give you only the TRUE values.

Hope this helps,

Rui Barradas


?s 05:16 de 14/08/2018, Deepa escreveu:
> I have a hundred identifier names that I want to check from the second
> column of a matrix with 6000 entries in the column.
> Instead of using  R > c("d", "v", "4", "s") %in% letters , is there an
> alternative?
> 
> I have the hundred identifier names that are of my interest stored in an
> array.
> 
> 
> 
> 
> On Tue, Aug 14, 2018 at 9:16 AM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> 
>> Use the %in% operator:
>>
>> help('%in%')
>>
>> e.g.
>>
>> R > c("d", "v", "4", "s") %in% letters
>> [1]  TRUE  TRUE FALSE  TRUE
>>
>>
>> B.
>>
>>
>>> On 2018-08-13, at 23:36, Deepa <deepamahm.iisc at gmail.com> wrote:
>>>
>>> Hi Don,
>>>
>>> When there is a list of identifier names that I want to check, the only
>> way
>>> is to loop over each entry stored in the list of identifier names or is
>>> there is there any other shortcut?
>>>
>>> Many thanks for the response?
>>>
>>> On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov>
>> wrote:
>>>
>>>> Or to return a logical value, i.e., TRUE if the column contains the
>> value,
>>>> FALSE if it does not:
>>>>
>>>>   any( x[,2] == 'A501' )
>>>>
>>>> -Don
>>>> --
>>>> Don MacQueen
>>>> Lawrence Livermore National Laboratory
>>>> 7000 East Ave., L-627
>>>> Livermore, CA 94550
>>>> 925-423-1062
>>>> Lab cell 925-724-7509
>>>>
>>>>
>>>>
>>>> ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
>>>> r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
>>>>
>>>>     Hello Deepa,
>>>>
>>>>     sum(x[,2] == "A501")
>>>>     or
>>>>     which(x[,2] == "A501")
>>>>     .
>>>>     Best,
>>>>     Albrecht
>>>>
>>>>
>>>>     --
>>>>       Albrecht Kauffmann
>>>>       alkauffm at fastmail.fm
>>>>
>>>>     Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
>>>>> Hello Everyone,
>>>>>
>>>>> I have a 1000 x 20 matrix. The second column of the matrix has the
>>>> names
>>>>> of identifiers. How do I check when a certain identifier is present
>>>> in
>>>>> the set of 1000 identifier names present in the second column. For
>>>>> instance, let the names of identifiers be A1,A2,...A1000. I want to
>>>>> check whether A501 is present .How can this be checked?
>>>>>
>>>>> Any help will be highly appreciated.
>>>>>
>>>>>
>>>>>   [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>     ______________________________________________
>>>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>>     PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>>     and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From li@t@ @ending from dewey@myzen@co@uk  Tue Aug 14 12:28:37 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 14 Aug 2018 11:28:37 +0100
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <630087097.36649.1534186059024@mail.yahoo.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
 <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
 <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>
 <3d221e3e-52f0-fffe-f70d-31e43845fc57@dewey.myzen.co.uk>
 <630087097.36649.1534186059024@mail.yahoo.com>
Message-ID: <db3b8bf6-b720-0ad7-7e17-3a4807c979c1@dewey.myzen.co.uk>

Dear Shivi

The current version is on CRAN so why not use that?

install.packages("RGtk2")

should install version 2.30.35
If it does not then try another mirror

Michael

On 13/08/2018 19:47, Shivi Bhatia wrote:
> Hi Michael
> Thank you for the reply.
> I have been looking for 3.5.1 version of this package but I cannot find 
> one, would you recommend downgrading my current R version.
> Would there be some or any other compatibly issue - please advice.
> 
> Thank you, Shivi
> 
> 
> Sent from Yahoo Mail for iPhone <https://overview.mail.yahoo.com/?.src=iOS>
> 
> On Monday, August 13, 2018, 21:56, Michael Dewey 
> <lists at dewey.myzen.co.uk> wrote:
> 
>     Dear Shivi
> 
>     You are running R 3.5.1 according to your session info. Why are you
>     installing a version for R 3.3? Note that the up-to-date version
>     depends
>     on R > 3.4.0 so it is no surprise that you get problems.
> 
>     Michael
> 
>     On 13/08/2018 16:07, Shivi Bhatia wrote:
>      > Hi Michael,
>      >
>      > I was able to install RGtk2
>      >
>     from?install.packages("https://cran.r-project.org/bin/windows/contrib/3.3/RGtk2_2.20.31.zip",
> 
>      > repos=NULL) but after installing this and trying to install
>     rattle i get
>      > this error:
>      > Error : package 'RGtk2' was installed by an R version with different
>      > internals; it needs to be reinstalled for use with this R version
>      > ERROR: lazy loading failed for package 'rattle'
>      >
>      > I tried installing rattle from?install.packages("rattle",
>      > repos="https://rattle.togaware.com", type="source").
>      >
>      > Regards, Shivi
>      >
>      >
>      > On Sun, Aug 12, 2018 at 7:20 PM Michael Dewey
>     <lists at dewey.myzen.co.uk <mailto:lists at dewey.myzen.co.uk>
>      > <mailto:lists at dewey.myzen.co.uk
>     <mailto:lists at dewey.myzen.co.uk>>> wrote:
>      >
>      >? ? Dear Shivi
>      >
>      >? ? What error message do you get when you try to install RGtk2?
>      >
>      >? ? Michael
>      >
>      >? ? On 12/08/2018 11:49, Shivi Bhatia wrote:
>      >? ? ? > Hi Eric,
>      >? ? ? >
>      >? ? ? > Thank you for the reply. I am adding the session details
>     below,
>      >? ? hope it
>      >? ? ? > helps:
>      >? ? ? > R version 3.5.1 (2018-07-02)
>      >? ? ? > Platform: x86_64-w64-mingw32/x64 (64-bit)
>      >? ? ? > Running under: Windows >= 8 x64 (build 9200)
>      >? ? ? >
>      >? ? ? > Matrix products: default
>      >? ? ? > locale:
>      >? ? ? > [1] LC_COLLATE=English_India.1252? LC_CTYPE=English_India.1252
>      >? ? ? > LC_MONETARY=English_India.1252
>      >? ? ? > [4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ?LC_TIME=English_India.1252
>      >? ? ? >
>      >? ? ? > attached base packages:
>      >? ? ? > [1] stats? ? ?graphics? grDevices utils? ? ?datasets 
>     methods? ?base
>      >? ? ? >
>      >? ? ? > Thanks.
>      >? ? ? >
>      >? ? ? > On Sat, Aug 11, 2018 at 9:38 PM Eric Berger
>      >? ? <ericjberger at gmail.com <mailto:ericjberger at gmail.com>
>     <mailto:ericjberger at gmail.com <mailto:ericjberger at gmail.com>>> wrote:
>      >? ? ? >
>      >? ? ? >> Hi Shivi,
>      >? ? ? >> I have no experience with the rattle package but I just
>      >? ? installed it with
>      >? ? ? >> no problem.
>      >? ? ? >> I am using a Windows 10 machine with R version 3.4.2.
>      >? ? ? >>
>      >? ? ? >> I suggest you provide additional information so that
>     others may
>      >? ? have ideas.
>      >? ? ? >> e.g. your operating system version and output from
>     sessionInfo()
>      >? ? (in R)
>      >? ? ? >>
>      >? ? ? >> Best,
>      >? ? ? >> Eric
>      >? ? ? >>
>      >? ? ? >>
>      >? ? ? >> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia
>      >? ? <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>
>     <mailto:shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>>>
>      >? ? ? >> wrote:
>      >? ? ? >>
>      >? ? ? >>> Hi,
>      >? ? ? >>>
>      >? ? ? >>> Need assistance on installing Rattle.
>      >? ? ? >>>
>      >? ? ? >>> I have followed the instructions on
>     https://rattle.togaware.com/
>      >? ? ? >>> but still facing error installing the package.
>      >? ? ? >>> ERROR: dependency 'RGtk2' is not available for package
>     'rattle'.
>      >? ? ? >>> Have tried installing RGt2 from multiple sources and its
>     still
>      >? ? failing.
>      >? ? ? >>>
>      >? ? ? >>> One of the suggestion on stack overflow was to downgrade
>     the R
>      >? ? version
>      >? ? ? >>> here
>      >? ? ? >>> :
>      >? ? ? >>>
>      >? ? ? >>>
>      >
>     https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>      >? ? ? >>> Request assistance.
>      >? ? ? >>>
>      >? ? ? >>> Regards, Shivi
>      >? ? ? >>>
>      >? ? ? >>>? ? ? ? ? [[alternative HTML version deleted]]
>      >? ? ? >>>
>      >? ? ? >>> ______________________________________________
>      >? ? ? >>> R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list
>      >? ? -- To UNSUBSCRIBE and more, see
>      >? ? ? >>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? >>> PLEASE do read the posting guide
>      >? ? ? >>> http://www.R-project.org/posting-guide.html
>      >? ? ? >>> and provide commented, minimal, self-contained,
>     reproducible code.
>      >? ? ? >>>
>      >? ? ? >>
>      >? ? ? >>
>      >? ? ? >
>      >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>      >? ? ? >
>      >? ? ? > ______________________________________________
>      >? ? ? > R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list
>      >? ? -- To UNSUBSCRIBE and more, see
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? > PLEASE do read the posting guide
>      > http://www.R-project.org/posting-guide.html
>      >? ? ? > and provide commented, minimal, self-contained,
>     reproducible code.
>      >? ? ? >
>      >
>      >? ? --
>      >? ? Michael
>      > http://www.dewey.myzen.co.uk/home.html
> 
>      >
> 
>     -- 
>     Michael
>     http://www.dewey.myzen.co.uk/home.html
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From pd@lgd @ending from gm@il@com  Tue Aug 14 13:01:39 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Tue, 14 Aug 2018 13:01:39 +0200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
Message-ID: <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>

Hmm, 

> .Fortran(stats:::C_setsmu, as.integer(0))
[[1]]
[1] 0

> .Fortran(stats:::C_setsmu, as.integer(fumble))
Error: object 'fumble' not found
> .Fortran(stats:::C_setsmu, fumble=as.integer(fumble))
Error: object 'fumble' not found
> .Fortran(stats:::C_setsmu, nphi=as.integer(nphi))
Error: object 'nphi' not found

so I think we need an alternative hypothesis about what went wrong for you... 

If nphi was NULL from the outset, that could explain things.

-pd


> On 14 Aug 2018, at 01:16 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 13/08/18 23:39, peter dalgaard wrote:
>> It's odd, possibly a bug, that you don't get
>> Error: object 'nphi' not found
>> but I can't offhand see where the evaluation of args to .C/.Fortran is supposed to take place.
> 
> If it is indeed a bug then it would be nice an it were fixed.  If that is possible.  Way beyond my level of comprehension but.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From i@t@z@hn @ending from gm@il@com  Tue Aug 14 15:46:35 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Tue, 14 Aug 2018 09:46:35 -0400
Subject: [R] Fast matrix multiplication
In-Reply-To: <54d4ce0aa9cc4a92bb0a534f734586c5@jhu.edu>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
 <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
 <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
 <54d4ce0aa9cc4a92bb0a534f734586c5@jhu.edu>
Message-ID: <CA+vqiLFVyHhHX+WDmXpBZkz3XiBQ9nwn_0g_vLSpRoxV8nyXtg@mail.gmail.com>

On Tue, Aug 14, 2018 at 9:41 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Does Microsoft open R come with pre-compiled BLAS that is optimized for matrix computations?

Yes, see https://mran.microsoft.com/rro#intelmkl1 for details.

--Ista

>
> Thanks,
> Ravi
>
> -----Original Message-----
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Monday, August 13, 2018 3:18 PM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] Fast matrix multiplication
>
>
> On Mon, Aug 13, 2018 at 2:41 PM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> >
> > Hi Ista,
> > Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?
>
> Not sure. If you want an easy way I would use MRO. More info at
> https://mran.microsoft.com/rro#intelmkl1
>
> --Ista
>
> > Thanks,
> > Ravi
> >
> > -----Original Message-----
> > From: Ista Zahn <istazahn at gmail.com>
> > Sent: Friday, August 10, 2018 12:20 PM
> > To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Fast matrix multiplication
> >
> >
> > Hi Ravi,
> >
> > You can achieve substantial speed up by using a faster BLAS (e.g., OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6 year old, but 8 core) system your example takes 3.9 seconds with using the reference BLAS and only 0.9 seconds using OpenBLAS.
> >
> > Best,
> > Ista
> > On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> > >
> > > Hi,
> > >
> > > I would like to compute:  A %*% B %*% t(A)
> > >
> > >
> > >
> > > A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
> > >
> > >
> > >
> > > Here is a sample code.
> > >
> > >
> > >
> > > M <- 10000
> > >
> > > N <- 100
> > >
> > > A <- matrix(rnorm(M*N), M, N)
> > >
> > > B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric
> > > positive-definite matrix
> > >
> > >
> > >
> > > # method 1
> > >
> > > system.time(D <- A %*% B %*% t(A))
> > >
> > >
> > >
> > > # I can obtain speedup by using a Cholesky decomposition of B
> > >
> > > # method 2
> > >
> > > system.time({
> > >
> > > C <- t(chol(B))
> > >
> > > E <- tcrossprod(A%*%C)
> > >
> > > })
> > >
> > >
> > >
> > > all.equal(D, E)
> > >
> > >
> > >
> > > I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
> > >
> > >
> > >
> > > Thanks,
> > >
> > > Ravi
> > >
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>


From r@vi@v@r@dh@n @ending from jhu@edu  Tue Aug 14 15:41:36 2018
From: r@vi@v@r@dh@n @ending from jhu@edu (Ravi Varadhan)
Date: Tue, 14 Aug 2018 13:41:36 +0000
Subject: [R] Fast matrix multiplication
In-Reply-To: <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
 <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
 <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
Message-ID: <54d4ce0aa9cc4a92bb0a534f734586c5@jhu.edu>

Does Microsoft open R come with pre-compiled BLAS that is optimized for matrix computations?

Thanks,
Ravi

-----Original Message-----
From: Ista Zahn <istazahn at gmail.com> 
Sent: Monday, August 13, 2018 3:18 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: r-help at r-project.org
Subject: Re: [R] Fast matrix multiplication


On Mon, Aug 13, 2018 at 2:41 PM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Hi Ista,
> Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?

Not sure. If you want an easy way I would use MRO. More info at
https://mran.microsoft.com/rro#intelmkl1

--Ista

> Thanks,
> Ravi
>
> -----Original Message-----
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Friday, August 10, 2018 12:20 PM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] Fast matrix multiplication
>
>
> Hi Ravi,
>
> You can achieve substantial speed up by using a faster BLAS (e.g., OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6 year old, but 8 core) system your example takes 3.9 seconds with using the reference BLAS and only 0.9 seconds using OpenBLAS.
>
> Best,
> Ista
> On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> >
> > Hi,
> >
> > I would like to compute:  A %*% B %*% t(A)
> >
> >
> >
> > A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
> >
> >
> >
> > Here is a sample code.
> >
> >
> >
> > M <- 10000
> >
> > N <- 100
> >
> > A <- matrix(rnorm(M*N), M, N)
> >
> > B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric 
> > positive-definite matrix
> >
> >
> >
> > # method 1
> >
> > system.time(D <- A %*% B %*% t(A))
> >
> >
> >
> > # I can obtain speedup by using a Cholesky decomposition of B
> >
> > # method 2
> >
> > system.time({
> >
> > C <- t(chol(B))
> >
> > E <- tcrossprod(A%*%C)
> >
> > })
> >
> >
> >
> > all.equal(D, E)
> >
> >
> >
> > I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
> >
> >
> >
> > Thanks,
> >
> > Ravi
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From rmh @ending from temple@edu  Tue Aug 14 17:03:47 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Tue, 14 Aug 2018 11:03:47 -0400
Subject: [R] Cannot set correct miktex path for pdflatex
In-Reply-To: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>
References: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>
Message-ID: <CAGx1TMBUKR=QV6ENzzrqxwT+3MD9YZ-k=yZZGRX+b_BveZa4+w@mail.gmail.com>

You are getting the correct version.  R is using the 8.3 version of the path.
MS DOS often can't handle long MS Windows pathnames, particularly with
blank space characters.
MS therefore provides an 8.3 equivalent for all long names.

C:\>dir /x prog*
dir /x prog*
 Volume in drive C has no label.
 Volume Serial Number is 188D-5BB8

 Directory of C:\

12/03/2017  03:39 PM    <DIR>          PROGRA~1     Program Files
05/17/2018  03:02 AM    <DIR>          PROGRA~2     Program Files (x86)
               0 File(s)              0 bytes
               2 Dir(s)   1,257,172,992 bytes free

C:\>dir /x progra~1\Miktex*
dir /x progra~1\Miktex*
 Volume in drive C has no label.
 Volume Serial Number is 188D-5BB8

 Directory of C:\progra~1

12/18/2015  09:50 PM    <DIR>          MIKTEX~1.9   MiKTeX 2.9
               0 File(s)              0 bytes
               1 Dir(s)   1,257,172,992 bytes free

C:\>
C:\>dir /?
dir /?
Displays a list of files and subdirectories in a directory.

DIR [drive:][path][filename] [/A[[:]attributes]] [/B] [/C] [/D] [/L] [/N]
  [/O[[:]sortorder]] [/P] [/Q] [/R] [/S] [/T[[:]timefield]] [/W] [/X] [/4]

  [drive:][path][filename]
              Specifies drive, directory, and/or files to list.

  /A          Displays files with specified attributes.
  attributes   D  Directories                R  Read-only files
               H  Hidden files               A  Files ready for archiving
               S  System files               I  Not content indexed files
               L  Reparse Points             -  Prefix meaning not
  /B          Uses bare format (no heading information or summary).
  /C          Display the thousand separator in file sizes.  This is the
              default.  Use /-C to disable display of separator.
  /D          Same as wide but files are list sorted by column.
  /L          Uses lowercase.
  /N          New long list format where filenames are on the far right.
  /O          List by files in sorted order.
  sortorder    N  By name (alphabetic)       S  By size (smallest first)
               E  By extension (alphabetic)  D  By date/time (oldest first)
               G  Group directories first    -  Prefix to reverse order
  /P          Pauses after each screenful of information.
  /Q          Display the owner of the file.
  /R          Display alternate data streams of the file.
  /S          Displays files in specified directory and all subdirectories.
  /T          Controls which time field displayed or used for sorting
  timefield   C  Creation
              A  Last Access
              W  Last Written
  /W          Uses wide list format.
  /X          This displays the short names generated for non-8dot3 file
              names.  The format is that of /N with the short name inserted
              before the long name. If no short name is present, blanks are
              displayed in its place.
  /4          Displays four-digit years

Switches may be preset in the DIRCMD environment variable.  Override
preset switches by prefixing any switch with - (hyphen)--for example, /-W.

On Mon, Aug 13, 2018 at 1:18 PM, Kelley, Claire <ckelley at air.org> wrote:
> Hi all,
>
> I am having a problem in R where R is finding an old non existent version of miktex rather than the new version. This occurs despite having set the path to the correct location.
>
> For example in bash if I look for the location of pdflatex:
>
> $ which pdflatex
> /c/Program Files/MiKTeX 2.9/miktex/bin/x64/pdflatex
>
>
> It points to the correct MikTex installation.
>
> However in R:
>
> Sys.which("pdflatex")
>                                                 pdflatex
> C:\\PROGRA~1\\MIKTEX~1.9\\miktex\\bin\\x64\\pdflatex.exe"
>
> Points to the old  (1.9) version of Miktex.
>
> This is my session info:
>
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.1
>
> Any thoughts?
>
> I have unsuccessfully tried:
>
>
>   1.  Adding correct MikTex path to my Renviorn.site. this adds MikTex to my path and I can see the addition, but doesn?t fix the problem
>   2.  Adding MikTex path to my $PATH variable. This lets bash find the right version of miktex but doesn?t help in R
>   3.  Making sure I only have on version of MIktex. I don?t have tiny tex installed (nor can I because I need the full MIkTex for other work) .
>
>
> Best,
> Claire
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Tue Aug 14 17:12:02 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 14 Aug 2018 08:12:02 -0700
Subject: [R] Request for help with R program
In-Reply-To: <CAPQaxLOAYS0q7-wzQ30Df6SL6JkuospJMY7Gvh-SLpvbRqRWcQ@mail.gmail.com>
References: <CAPQaxLOAYS0q7-wzQ30Df6SL6JkuospJMY7Gvh-SLpvbRqRWcQ@mail.gmail.com>
Message-ID: <CAGxFJbQcW0rV0Sdjp8fKsSC0A4s2k2g7tCX87r072eyBVT3ngg@mail.gmail.com>

R has no "associates". It is open source software with many users and
developers with varying skill levels and interests.

I think you are in over your head ("inexperienced in computer programming")
and should seek local resources at Baylor to help you. This list probably
cannot provide the level of assistance you seek.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Aug 13, 2018 at 4:13 PM, Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Good evening,
>
>   I am a high school research student who is partnering with Baylor
> University (TX) on a Genomic research project, and was seeking to use the R
> program to analysis our data? which is from GDC database. R-3.5.1 is
> currently downloaded onto my Windows PC and I am looking to download the
> CGDS and GAIA packages, and then to subsequently downloaded and analyze the
> Genomic data we have extracted via the R packages. I attempted to utilize
> the various help utilities you provide, but I am rather inexperienced with
> computer programming and the R program as a whole. Therefore, I am
> requesting a screen sharing session and/or phone or email correspondence
> with one of your associates so to achieve my goals. Such would be very
> helpful to my and my mentors work, and our pending publication.
>
> Many thanks,
>
> Spencer Brackett
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @t@t@@@tudent4647 @ending from gm@il@com  Tue Aug 14 21:46:48 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Tue, 14 Aug 2018 12:46:48 -0700
Subject: [R] Changing PDF orientation midstream
Message-ID: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>

Hi, I'm wondering whether it is possible to change the orientation of the PDF in the middle of the document. In other words, pages 1,2,3 - portrait, pages 4,5 - landscape, etc. 

This is how I call it -

pdf (file, paper="US") or USr for landscape 


Thanks!


From bgunter@4567 @ending from gm@il@com  Tue Aug 14 22:20:26 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 14 Aug 2018 13:20:26 -0700
Subject: [R] Changing PDF orientation midstream
In-Reply-To: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>
References: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>
Message-ID: <CAGxFJbTcUwKrPR83nfOFzHrfYQrJ-myTu53k37iTS-e73S3vog@mail.gmail.com>

1. Probably not. But I'm no pdf expert.

2. This adobe thread may be relevant:

https://forums.adobe.com/thread/1091826

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 14, 2018 at 12:46 PM, Stats Student <stats.student4647 at gmail.com
> wrote:

> Hi, I'm wondering whether it is possible to change the orientation of the
> PDF in the middle of the document. In other words, pages 1,2,3 - portrait,
> pages 4,5 - landscape, etc.
>
> This is how I call it -
>
> pdf (file, paper="US") or USr for landscape
>
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From profjcn@@h @ending from gm@il@com  Tue Aug 14 22:27:54 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Tue, 14 Aug 2018 16:27:54 -0400
Subject: [R] Changing PDF orientation midstream
In-Reply-To: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>
References: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>
Message-ID: <d25fe17e-a1e0-65a5-7720-9a7d5d7dcc4a@gmail.com>

Not an R issue, but for linux users pdf-shuffler is a great tool

JN

On 2018-08-14 03:46 PM, Stats Student wrote:
> Hi, I'm wondering whether it is possible to change the orientation of the PDF in the middle of the document. In other words, pages 1,2,3 - portrait, pages 4,5 - landscape, etc. 
> 
> This is how I call it -
> 
> pdf (file, paper="US") or USr for landscape 
> 
> 
> Thanks!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cdeterm@njr @ending from gm@il@com  Tue Aug 14 22:43:12 2018
From: cdeterm@njr @ending from gm@il@com (Charles Determan)
Date: Tue, 14 Aug 2018 15:43:12 -0500
Subject: [R] FPMC?
Message-ID: <CAKxd1KN+Fmn47Z-PvuEnuixM4yarXSYXZ791Gddw3wKUSHfw=g@mail.gmail.com>

Greetings R users,

I recently came across an interesting paper regarding recommender systems.
The particular method defined in the manuscript was Factorizing
Personalized Markov Chains.  You can find the article in question here (
http://www.ra.ethz.ch/cdstore/www2010/www/p811.pdf).  I am curious if
anyone here has ever come across anything like this before in the R
community.  I have found multiple packages on Markov Chains but nothing
with respect to combining them with matrix factorization.  I will continue
to search around but thought I would pose the question here as well.

Regards,
Charles

	[[alternative HTML version deleted]]


From tmg1970 @ending from gm@il@com  Tue Aug 14 17:48:54 2018
From: tmg1970 @ending from gm@il@com (Tania Morgado Garcia)
Date: Tue, 14 Aug 2018 10:48:54 -0500
Subject: [R] Spline function
Message-ID: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>

 Hello everyone. I'm new to R and I'm using spline functions. With the
command splinefun (x, y) I get the function of interpolating the values x
and y. Later, I can evaluate that function for values of x by obtaining the
respective values of y. The point is that I need the inverse operation,
with the function, for a value of Y I need to know the value of x. Could
you please help me?
A cordial greeting

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Aug 15 00:22:38 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 14 Aug 2018 15:22:38 -0700
Subject: [R] Spline function
In-Reply-To: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
References: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
Message-ID: <CAGxFJbQTGK3gHYOBQfooYyY8h4scEY7ick0gRYR0zeVK-MGf5A@mail.gmail.com>

If I understand correctly, not in general possible.

Suppose for a bunch of different x's the y's are all constant =0. What x
would correspond to y = 1.

Or suppose (x,y) pairs trace a sine function over several periods. Then
there is no unique x corresponding to y = .5, say.

Perhaps if you more explicitly specified the nature of your problem (e.g.
is y monotonic in x?) some assistance might be provided.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 14, 2018 at 8:48 AM, Tania Morgado Garcia <tmg1970 at gmail.com>
wrote:

>  Hello everyone. I'm new to R and I'm using spline functions. With the
> command splinefun (x, y) I get the function of interpolating the values x
> and y. Later, I can evaluate that function for values of x by obtaining the
> respective values of y. The point is that I need the inverse operation,
> with the function, for a value of Y I need to know the value of x. Could
> you please help me?
> A cordial greeting
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From 538280 @ending from gm@il@com  Wed Aug 15 00:33:58 2018
From: 538280 @ending from gm@il@com (Greg Snow)
Date: Tue, 14 Aug 2018 16:33:58 -0600
Subject: [R] Spline function
In-Reply-To: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
References: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
Message-ID: <CAFEqCdyL_o-89yVyiJJLB1qpcNm0LSGHdcfOr1SXhW5ZqE5=eA@mail.gmail.com>

The uniroot function can be used to find a value in a specified
interval, if it exists.
On Tue, Aug 14, 2018 at 3:30 PM Tania Morgado Garcia <tmg1970 at gmail.com> wrote:
>
>  Hello everyone. I'm new to R and I'm using spline functions. With the
> command splinefun (x, y) I get the function of interpolating the values x
> and y. Later, I can evaluate that function for values of x by obtaining the
> respective values of y. The point is that I need the inverse operation,
> with the function, for a value of Y I need to know the value of x. Could
> you please help me?
> A cordial greeting
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From r@turner @ending from @uckl@nd@@c@nz  Wed Aug 15 00:40:58 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 15 Aug 2018 10:40:58 +1200
Subject: [R] [FORGED]  Spline function
In-Reply-To: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
References: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
Message-ID: <04e90632-25a3-6726-5f83-401c6e86b6ea@auckland.ac.nz>


On 15/08/18 03:48, Tania Morgado Garcia wrote:

>   Hello everyone. I'm new to R and I'm using spline functions. With the
> command splinefun (x, y) I get the function of interpolating the values x
> and y. Later, I can evaluate that function for values of x by obtaining the
> respective values of y. The point is that I need the inverse operation,
> with the function, for a value of Y I need to know the value of x. Could
> you please help me?

Your question is ill-posed.  There could easily be multiple x values 
corresponding to a single y value, unless the spline function is monotone.

If you can specify an interval which encloses the x value that you are 
trying to and over which the spline function is monotone, then uniroot() 
might provide what you want.

Something like:

    spf <- splinefun(x,y)
    uniroot(f=function(x){spf-y0},interval=c(a,b))

where y0 is the y value for which you want the corresponding x value,
where spf() is monotone on [a,b], and where there *exists* an x value 
between a and b such that spf(x) = y0.

Good luck.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @ending from @uckl@nd@@c@nz  Wed Aug 15 01:12:00 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 15 Aug 2018 11:12:00 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
 <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
Message-ID: <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>

On 14/08/18 23:01, peter dalgaard wrote:
> Hmm,
> 
>> .Fortran(stats:::C_setsmu, as.integer(0))
> [[1]]
> [1] 0
> 
>> .Fortran(stats:::C_setsmu, as.integer(fumble))
> Error: object 'fumble' not found
>> .Fortran(stats:::C_setsmu, fumble=as.integer(fumble))
> Error: object 'fumble' not found
>> .Fortran(stats:::C_setsmu, nphi=as.integer(nphi))
> Error: object 'nphi' not found
> 
> so I think we need an alternative hypothesis about what went wrong for you...
> 
> If nphi was NULL from the outset, that could explain things.

No, I never set nphi to NULL.

I put the code back to the way it was previously, just now, and tried 
again. Now I get "object 'nphi' not found".

There is no explanation other than gremlins and the malevolence that the 
computer gods hold towards me.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch@dunc@n @ending from gm@il@com  Wed Aug 15 01:35:08 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Tue, 14 Aug 2018 19:35:08 -0400
Subject: [R] Spline function
In-Reply-To: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
References: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
Message-ID: <561b4d57-350d-3e30-12f5-4881d6038f2e@gmail.com>

On 14/08/2018 11:48 AM, Tania Morgado Garcia wrote:
>   Hello everyone. I'm new to R and I'm using spline functions. With the
> command splinefun (x, y) I get the function of interpolating the values x
> and y. Later, I can evaluate that function for values of x by obtaining the
> respective values of y. The point is that I need the inverse operation,
> with the function, for a value of Y I need to know the value of x. Could
> you please help me?

Others have pointed out uniroot().  One other possibility:  maybe you 
don't need both the function and its inverse, or an approximate inverse 
is good enough.  In either of those cases, just swap x and y in the call 
to splinefun(), and you'll get a new function mapping y values to the 
corresponding x values.  (You'll get nonsense or an error in cases where 
this mapping is not unique.)  It won't match the inverse of the original 
spline interpolator except at observed (x,y) pairs, but will usually be 
close, especially if the functions are pretty smooth.

Duncan Murdoch


From rmh @ending from temple@edu  Wed Aug 15 03:00:41 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Tue, 14 Aug 2018 21:00:41 -0400
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
 <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
 <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>
Message-ID: <CAGx1TMDq5QTcQ7pK3Z3EghSS9s9mCEvcd-+vcMvYcqcNtqSG3Q@mail.gmail.com>

There is no explanation other than gremlins and the malevolence that
the computer gods hold towards me.

fortune nomination.

On Tue, Aug 14, 2018 at 7:12 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 14/08/18 23:01, peter dalgaard wrote:
>>
>> Hmm,
>>
>>> .Fortran(stats:::C_setsmu, as.integer(0))
>>
>> [[1]]
>> [1] 0
>>
>>> .Fortran(stats:::C_setsmu, as.integer(fumble))
>>
>> Error: object 'fumble' not found
>>>
>>> .Fortran(stats:::C_setsmu, fumble=as.integer(fumble))
>>
>> Error: object 'fumble' not found
>>>
>>> .Fortran(stats:::C_setsmu, nphi=as.integer(nphi))
>>
>> Error: object 'nphi' not found
>>
>> so I think we need an alternative hypothesis about what went wrong for
>> you...
>>
>> If nphi was NULL from the outset, that could explain things.
>
>
> No, I never set nphi to NULL.
>
> I put the code back to the way it was previously, just now, and tried again.
> Now I get "object 'nphi' not found".
>
> There is no explanation other than gremlins and the malevolence that the
> computer gods hold towards me.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @ending from @uckl@nd@@c@nz  Wed Aug 15 04:58:32 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 15 Aug 2018 14:58:32 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <CAGx1TMDq5QTcQ7pK3Z3EghSS9s9mCEvcd-+vcMvYcqcNtqSG3Q@mail.gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
 <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
 <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>
 <CAGx1TMDq5QTcQ7pK3Z3EghSS9s9mCEvcd-+vcMvYcqcNtqSG3Q@mail.gmail.com>
Message-ID: <e2644b3e-ca15-fc84-5cac-1a21ec24fcf9@auckland.ac.nz>

On 15/08/18 13:00, Richard M. Heiberger wrote:
> There is no explanation other than gremlins and the malevolence that
> the computer gods hold towards me.
> 
> fortune nomination.

I demur.  I already have a fortune with gremlins in it attributed to me
(fortune(213)).

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From chri@hold @ending from p@yctc@org  Wed Aug 15 08:40:14 2018
From: chri@hold @ending from p@yctc@org (Chris Evans)
Date: Wed, 15 Aug 2018 07:40:14 +0100 (BST)
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <e2644b3e-ca15-fc84-5cac-1a21ec24fcf9@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
 <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
 <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>
 <CAGx1TMDq5QTcQ7pK3Z3EghSS9s9mCEvcd-+vcMvYcqcNtqSG3Q@mail.gmail.com>
 <e2644b3e-ca15-fc84-5cac-1a21ec24fcf9@auckland.ac.nz>
Message-ID: <1891588009.1366220.1534315214354.JavaMail.zimbra@psyctc.org>

Ah, if I'd had a fortune for every time I invoked the wrath of the IT gods and the malicious work of their gremlins, I'd be an obscenely wealthy person by now.

More seriously, I can't tell you how much I appreciate the joyous flickers of humour here, amidst all the pain and suffering (yes, I may be projecting a bit here), and the welcome, vital, but often humiliating genius many contributors bring as it underlines how low my statistical and computing IQ is. 

I have Rolf as #1 for self-deprecating humour on r-help.  Keep rescuing my sense of humour on my gremlin-beset days please Rolf, all!

Chris

----- Original Message -----
> From: "Rolf Turner" <r.turner at auckland.ac.nz>
> To: "Richard M. Heiberger" <rmh at temple.edu>
> Cc: r-help at r-project.org, "Achim Zeileis" <Achim.Zeileis at uibk.ac.at>, "peter dalgaard" <pdalgd at gmail.com>, "Henrik
> Bengtsson" <henrik.bengtsson at gmail.com>
> Sent: Wednesday, 15 August, 2018 04:58:32
> Subject: Re: [R] Mysterious seg fault --- SOLVED

> On 15/08/18 13:00, Richard M. Heiberger wrote:
>> There is no explanation other than gremlins and the malevolence that
>> the computer gods hold towards me.
>> 
>> fortune nomination.
> 
> I demur.  I already have a fortune with gremlins in it attributed to me
> (fortune(213)).
> 
> cheers,
> 
> Rolf
> 
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @t@t@@@tudent4647 @ending from gm@il@com  Wed Aug 15 16:21:55 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Wed, 15 Aug 2018 07:21:55 -0700
Subject: [R] Ordering of facet_wrap() panels
Message-ID: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>

Hi, I am generating multiple charts with facet_wrap() and what what I see, R/ggplot sorts the panels by the facet variable. So adding an index to the facet variable (1 - bucket, 2 - bucket, etc) does solve the sorting issue but it's ugly. 

I also read this post which, if I understand correctly, claims that ggplot should be using the initial ordering of the data for ordering the charts (instead of ordering the data itself). 

https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/

Wondering if anyone knows how to direct ggplot use the initial sorting of the data to order the panels. 

Thank you.


From bgunter@4567 @ending from gm@il@com  Wed Aug 15 16:50:49 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 15 Aug 2018 07:50:49 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
Message-ID: <CAGxFJbSGTPxSMKbo9SNbggMZN+LhGnHrvi31pFUEcFjp5xjBrA@mail.gmail.com>

See ?factor.

You can either use ?ordered to create an ordered factor to sort the levels
as you desire or sort them with factor(). e.g.

> f <- factor(letters[3:1])
> f
[1] c b a
Levels: a b c   ## default ordering

> f <- factor(f, levels = letters[3:1])
> f
[1] c b a
Levels: c b a  ## explicit ordering

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 15, 2018 at 7:21 AM, Stats Student <stats.student4647 at gmail.com>
wrote:

> Hi, I am generating multiple charts with facet_wrap() and what what I see,
> R/ggplot sorts the panels by the facet variable. So adding an index to the
> facet variable (1 - bucket, 2 - bucket, etc) does solve the sorting issue
> but it's ugly.
>
> I also read this post which, if I understand correctly, claims that ggplot
> should be using the initial ordering of the data for ordering the charts
> (instead of ordering the data itself).
>
> https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/
>
> Wondering if anyone knows how to direct ggplot use the initial sorting of
> the data to order the panels.
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Aug 15 18:23:42 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 15 Aug 2018 09:23:42 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <CAMZO7wL5CChzQ_g0BUeJQBW_7V3VWzKo8mwuoYODPVVAwDU1mw@mail.gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
 <CAGxFJbSGTPxSMKbo9SNbggMZN+LhGnHrvi31pFUEcFjp5xjBrA@mail.gmail.com>
 <CAMZO7wL5CChzQ_g0BUeJQBW_7V3VWzKo8mwuoYODPVVAwDU1mw@mail.gmail.com>
Message-ID: <CAGxFJbQcAGzCtXYfDXmyy4HS9PGD_Cuf-ML=dUr=toYOY5fwNg@mail.gmail.com>

1. Unless there is good reason to keep a reply private, always cc the list.
This allows more brains, possible corrections, etc.

2. Have you read ?factor and ?unique ? Always study the docs carefully.
They are generally terse but complete, especially the base docs, and you
can often find your answers there.

3. Your "solution" may work in this case, but if I understand correctly
what you're after,  won't in general. unique() gives the unique values in
the order they appear, which may not be the order you want:

## want ordering to be "a" < "b" < "c"

> f <- rep(letters[3:1],2)

> factor(f, levels = unique(f))
[1] c b a c b a
Levels: c b a  ## not your desired order

Again, please consult the docs and perhaps a tutorial or two as necessary.

-- Bert



On Wed, Aug 15, 2018 at 8:22 AM, Stats Student <stats.student4647 at gmail.com>
wrote:

> Many thanks, Bert.
>
> I did -
>
> facet_wrap(~factor(var, levels=unique (var))
>
> And it seems to be working fine.
> Do you see any issues with this?
>
> I'm fairly new to R so want to make sure I'm not doing something stupid.
>
> Thanks again.
>
> On Wed, Aug 15, 2018, 7:50 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> See ?factor.
>>
>> You can either use ?ordered to create an ordered factor to sort the
>> levels as you desire or sort them with factor(). e.g.
>>
>> > f <- factor(letters[3:1])
>> > f
>> [1] c b a
>> Levels: a b c   ## default ordering
>>
>> > f <- factor(f, levels = letters[3:1])
>> > f
>> [1] c b a
>> Levels: c b a  ## explicit ordering
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Wed, Aug 15, 2018 at 7:21 AM, Stats Student <
>> stats.student4647 at gmail.com> wrote:
>>
>>> Hi, I am generating multiple charts with facet_wrap() and what what I
>>> see, R/ggplot sorts the panels by the facet variable. So adding an index to
>>> the facet variable (1 - bucket, 2 - bucket, etc) does solve the sorting
>>> issue but it's ugly.
>>>
>>> I also read this post which, if I understand correctly, claims that
>>> ggplot should be using the initial ordering of the data for ordering the
>>> charts (instead of ordering the data itself).
>>>
>>> https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/
>>>
>>> Wondering if anyone knows how to direct ggplot use the initial sorting
>>> of the data to order the panels.
>>>
>>> Thank you.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]


From fr@nci@@bo@teng @ending from ver@@ntphy@ic@@com  Wed Aug 15 19:17:14 2018
From: fr@nci@@bo@teng @ending from ver@@ntphy@ic@@com (Francis Boateng)
Date: Wed, 15 Aug 2018 17:17:14 +0000
Subject: [R] exponential day
In-Reply-To: <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>
References: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
 <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <SN2PR17MB0717E59E1C00C9D0677FA3608F3F0@SN2PR17MB0717.namprd17.prod.outlook.com>

Thanks Ellison, I will try it. 

Francis


-----Original Message-----
From: S Ellison <S.Ellison at LGCGroup.com> 
Sent: Thursday, August 9, 2018 8:12 AM
To: Francis Boateng <francis.boateng at versantphysics.com>; r-help at r-project.org
Subject: RE: exponential day

> Please, how can I determine parameters from exponential equation 
> Example
> one:  y = a*exp(-b*x);  how do I determine  a  and  b , as well as 
> R-square from data sets. And also fitting y = a*exp(-b*x) into the 
> data sets Assuming data sets A = (0,2,4,6,8,10) B = 
> (1,0.8,0.6,0.4,0.2,0.1)

For least squares fitting, you could take logs and do a simple linear fit, if the resduals are reasonably homoscedastic in the log domain (or if you can sort the weighting out properly).

For non-linear least squares, look at ?nlm, ?nls or (if you want to roll your own) ?optim

For max likelihood, maybe nlme in the nlme package.

For other ideas, look up 'non-linear fitting with R' on any search engine, or check the R Task Views

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or disclosure other than by the intended recipient is unauthorised. If you have received this message in error, please notify the sender immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From bgunter@4567 @ending from gm@il@com  Wed Aug 15 20:04:36 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 15 Aug 2018 11:04:36 -0700
Subject: [R] exponential day
In-Reply-To: <SN2PR17MB0717E59E1C00C9D0677FA3608F3F0@SN2PR17MB0717.namprd17.prod.outlook.com>
References: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
 <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>
 <SN2PR17MB0717E59E1C00C9D0677FA3608F3F0@SN2PR17MB0717.namprd17.prod.outlook.com>
Message-ID: <CAGxFJbRBoq+ffRGeZ+r3tf9x045sD19muD3N4oSNazpvFZh=dg@mail.gmail.com>

Please note that R^2 for nonlinear models is nonsense.

Search on "R^2 in nonlinear models" for details, e.g.

http://statisticsbyjim.com/regression/r-squared-invalid-nonlinear-regression/

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 15, 2018 at 10:54 AM Francis Boateng <
francis.boateng at versantphysics.com> wrote:

> Thanks Ellison, I will try it.
>
> Francis
>
>
> -----Original Message-----
> From: S Ellison <S.Ellison at LGCGroup.com>
> Sent: Thursday, August 9, 2018 8:12 AM
> To: Francis Boateng <francis.boateng at versantphysics.com>;
> r-help at r-project.org
> Subject: RE: exponential day
>
> > Please, how can I determine parameters from exponential equation
> > Example
> > one:  y = a*exp(-b*x);  how do I determine  a  and  b , as well as
> > R-square from data sets. And also fitting y = a*exp(-b*x) into the
> > data sets Assuming data sets A = (0,2,4,6,8,10) B =
> > (1,0.8,0.6,0.4,0.2,0.1)
>
> For least squares fitting, you could take logs and do a simple linear fit,
> if the resduals are reasonably homoscedastic in the log domain (or if you
> can sort the weighting out properly).
>
> For non-linear least squares, look at ?nlm, ?nls or (if you want to roll
> your own) ?optim
>
> For max likelihood, maybe nlme in the nlme package.
>
> For other ideas, look up 'non-linear fitting with R' on any search engine,
> or check the R Task Views
>
> S Ellison
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:18}}


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Wed Aug 15 20:07:39 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Wed, 15 Aug 2018 14:07:39 -0400
Subject: [R] Problem with loaded R packages
Message-ID: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>

Good afternoon,

  I am trying to load the two R packages CGSDR and GAIA which I have
successfully installed onto my R program. Following installation of the two
packages, I proceeded upon recommendation to load both packages via the
library function. Therefore I inputed following...

library(cgdsr)
library(gaia)

This was successfull. Then did the following

source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf

This Bioconductorlink was reported to contain an error and was not loaded
successfully.

Any ideas of what exactly I am doing wrong in my lines?

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @ending from me@com  Wed Aug 15 20:33:25 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Wed, 15 Aug 2018 14:33:25 -0400
Subject: [R] Problem with loaded R packages
In-Reply-To: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
References: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
Message-ID: <D817FF91-4A51-47FC-8412-8F61747497AC@me.com>

Hi,

The ?source function is intended to read a plain text R source code file into the R console, not a PDF file.

Even if source() could read in a PDF file, you have a typo in the URL, which is CRAN, not BioConductor, and which should be:

  https://cran.r-project.org/web/packages/cgdsr/vignettes/cgdsr.pdf

Regards,

Marc Schwartz

> On Aug 15, 2018, at 2:07 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> Good afternoon,
> 
>  I am trying to load the two R packages CGSDR and GAIA which I have
> successfully installed onto my R program. Following installation of the two
> packages, I proceeded upon recommendation to load both packages via the
> library function. Therefore I inputed following...
> 
> library(cgdsr)
> library(gaia)
> 
> This was successfull. Then did the following
> 
> source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf
> 
> This Bioconductorlink was reported to contain an error and was not loaded
> successfully.
> 
> Any ideas of what exactly I am doing wrong in my lines?
> 
> Many thanks,
> 
> Spencer Brackett
> 
> 	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @ending from me@com  Wed Aug 15 20:52:44 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Wed, 15 Aug 2018 14:52:44 -0400
Subject: [R] Problem with loaded R packages
In-Reply-To: <CAPQaxLOexhvqGiBEaf8pU5tJ=EO-JKpCMdZRaJz0C6LHYFnMJA@mail.gmail.com>
References: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
 <D817FF91-4A51-47FC-8412-8F61747497AC@me.com>
 <CAPQaxLOexhvqGiBEaf8pU5tJ=EO-JKpCMdZRaJz0C6LHYFnMJA@mail.gmail.com>
Message-ID: <7590F990-933F-47BA-BC33-CC4C98E1E8B9@me.com>

Hi Spencer,

Please be sure to use reply-all to keep the thread on the list and in the list archives for the future benefit of others. It also allows others to participate with additional information, if needed.

You have already loaded the packages by using the two library() function calls as you have below.

Beyond that, if there are examples from the package vignettes that you want to run, just copy and paste the relevant code from the PDF file, within whatever application you use to view it, into the R console.

Each package also has it's own documentation as well, describing the functions, their arguments, any included datasets, and typically some examples. You can bring up the main package help index by using, for example:

  help(package = "cgdsr")
 
Regards,

Marc


> On Aug 15, 2018, at 2:41 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> Mr. Schwartz, 
> 
>   I see. Thank you for the correction! Is there any other line which I could input to load the two packages in question?
> 
> Many thanks, 
> 
> Spencer Brackett 
> 
> On Wed, Aug 15, 2018 at 2:33 PM Marc Schwartz <marc_schwartz at me.com> wrote:
> Hi,
> 
> The ?source function is intended to read a plain text R source code file into the R console, not a PDF file.
> 
> Even if source() could read in a PDF file, you have a typo in the URL, which is CRAN, not BioConductor, and which should be:
> 
>   https://cran.r-project.org/web/packages/cgdsr/vignettes/cgdsr.pdf
> 
> Regards,
> 
> Marc Schwartz
> 
> > On Aug 15, 2018, at 2:07 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> > 
> > Good afternoon,
> > 
> >  I am trying to load the two R packages CGSDR and GAIA which I have
> > successfully installed onto my R program. Following installation of the two
> > packages, I proceeded upon recommendation to load both packages via the
> > library function. Therefore I inputed following...
> > 
> > library(cgdsr)
> > library(gaia)
> > 
> > This was successfull. Then did the following
> > 
> > source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf
> > 
> > This Bioconductorlink was reported to contain an error and was not loaded
> > successfully.
> > 
> > Any ideas of what exactly I am doing wrong in my lines?
> > 
> > Many thanks,
> > 
> > Spencer Brackett
> > 
> >       [[alternative HTML version deleted]]
> 


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Wed Aug 15 21:06:10 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Wed, 15 Aug 2018 15:06:10 -0400
Subject: [R] Problem with loaded R packages
In-Reply-To: <581DFE3D-BCF5-4250-B581-8909E14F513E@dcn.davis.ca.us>
References: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
 <581DFE3D-BCF5-4250-B581-8909E14F513E@dcn.davis.ca.us>
Message-ID: <CAPQaxLNo2NGRGNA18fqea4BQpUAGS9LPgFc9RfY4nVLrZpxpaw@mail.gmail.com>

 Many thanks! I will look into apply the advice given.

-Spencer Brackett

On Wed, Aug 15, 2018 at 3:03 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> a) Raw URL text is not legal in R code. URLs MUST ALWAYS be enclosed in
> single (') or double (") quotes in R.
>
> b) The source function expects to go where you tell it to go and retrieve
> text composed of R statements. A PDF is a binary file... even if it
> happened to contain some R code that you could read with your PDF viewer it
> would be inaccessible to the R interpreter because it is not in a text file.
>
> c) I can't really tell where you are headed with this code you gave us...
> if you want to read the vignette you could use your web browser to download
> that PDF and use your viewer to open it. If you want to run any of the code
> shown in it you can copy it to the console interactively.
>
> d) The Bioconductor project has a different mailing list... for questions
> not generically about R you should look at
> https://www.bioconductor.org/help/support
>
> On August 15, 2018 11:07:39 AM PDT, Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
> >Good afternoon,
> >
> >  I am trying to load the two R packages CGSDR and GAIA which I have
> >successfully installed onto my R program. Following installation of the
> >two
> >packages, I proceeded upon recommendation to load both packages via the
> >library function. Therefore I inputed following...
> >
> >library(cgdsr)
> >library(gaia)
> >
> >This was successfull. Then did the following
> >
> >source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf
> >
> >This Bioconductorlink was reported to contain an error and was not
> >loaded
> >successfully.
> >
> >Any ideas of what exactly I am doing wrong in my lines?
> >
> >Many thanks,
> >
> >Spencer Brackett
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Aug 15 21:03:26 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 15 Aug 2018 12:03:26 -0700
Subject: [R] Problem with loaded R packages
In-Reply-To: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
References: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
Message-ID: <581DFE3D-BCF5-4250-B581-8909E14F513E@dcn.davis.ca.us>

a) Raw URL text is not legal in R code. URLs MUST ALWAYS be enclosed in single (') or double (") quotes in R.

b) The source function expects to go where you tell it to go and retrieve text composed of R statements. A PDF is a binary file... even if it happened to contain some R code that you could read with your PDF viewer it would be inaccessible to the R interpreter because it is not in a text file.

c) I can't really tell where you are headed with this code you gave us... if you want to read the vignette you could use your web browser to download that PDF and use your viewer to open it. If you want to run any of the code shown in it you can copy it to the console interactively.

d) The Bioconductor project has a different mailing list... for questions not generically about R you should look at https://www.bioconductor.org/help/support

On August 15, 2018 11:07:39 AM PDT, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>Good afternoon,
>
>  I am trying to load the two R packages CGSDR and GAIA which I have
>successfully installed onto my R program. Following installation of the
>two
>packages, I proceeded upon recommendation to load both packages via the
>library function. Therefore I inputed following...
>
>library(cgdsr)
>library(gaia)
>
>This was successfull. Then did the following
>
>source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf
>
>This Bioconductorlink was reported to contain an error and was not
>loaded
>successfully.
>
>Any ideas of what exactly I am doing wrong in my lines?
>
>Many thanks,
>
>Spencer Brackett
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From profjcn@@h @ending from gm@il@com  Wed Aug 15 22:11:13 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Wed, 15 Aug 2018 16:11:13 -0400
Subject: [R] exponential day
In-Reply-To: <CAGxFJbRBoq+ffRGeZ+r3tf9x045sD19muD3N4oSNazpvFZh=dg@mail.gmail.com>
References: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
 <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>
 <SN2PR17MB0717E59E1C00C9D0677FA3608F3F0@SN2PR17MB0717.namprd17.prod.outlook.com>
 <CAGxFJbRBoq+ffRGeZ+r3tf9x045sD19muD3N4oSNazpvFZh=dg@mail.gmail.com>
Message-ID: <4d5aae69-d630-8290-4d11-bb564c17ad26@gmail.com>

Since I'm associated with a lot of nonlinear modeling software, including nlsr and (now
deprecated) nlmrt, I'll perhaps seem an odd person to say that I calculate an R^2 quite
regularly for all sorts of models. I find it useful to know if my nonlinear models do
poorly compared to the model that is simply the mean of the data.

The big issue, of course, is to get across to people that all their linear model ideas
about this quantity -- and we need some other name here -- are indeed rubbish in this
context. All I'm doing is comparing two models in a very crude way. Useful? Sometimes,
esp. if the result is a negative number (i.e., a nonlinear model is less effective in
approximating data than a single value).  Is it important? No. We only want to avoid
using bad models, and this is a quick and dirty flag.

Best, JN


On 2018-08-15 02:04 PM, Bert Gunter wrote:
> Please note that R^2 for nonlinear models is nonsense.
> 
> Search on "R^2 in nonlinear models" for details, e.g.
> 
> http://statisticsbyjim.com/regression/r-squared-invalid-nonlinear-regression/
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Aug 15, 2018 at 10:54 AM Francis Boateng <
> francis.boateng at versantphysics.com> wrote:
> 
>> Thanks Ellison, I will try it.
>>
>> Francis
>>
>>
>> -----Original Message-----
>> From: S Ellison <S.Ellison at LGCGroup.com>
>> Sent: Thursday, August 9, 2018 8:12 AM
>> To: Francis Boateng <francis.boateng at versantphysics.com>;
>> r-help at r-project.org
>> Subject: RE: exponential day
>>
>>> Please, how can I determine parameters from exponential equation
>>> Example
>>> one:  y = a*exp(-b*x);  how do I determine  a  and  b , as well as
>>> R-square from data sets. And also fitting y = a*exp(-b*x) into the
>>> data sets Assuming data sets A = (0,2,4,6,8,10) B =
>>> (1,0.8,0.6,0.4,0.2,0.1)
>>
>> For least squares fitting, you could take logs and do a simple linear fit,
>> if the resduals are reasonably homoscedastic in the log domain (or if you
>> can sort the weighting out properly).
>>
>> For non-linear least squares, look at ?nlm, ?nls or (if you want to roll
>> your own) ?optim
>>
>> For max likelihood, maybe nlme in the nlme package.
>>
>> For other ideas, look up 'non-linear fitting with R' on any search engine,
>> or check the R Task Views
>>
>> S Ellison
>>
>>
>>
>> *******************************************************************
>> This email and any attachments are confidential. Any u...{{dropped:18}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jwd @ending from @urewe@t@net  Wed Aug 15 23:57:52 2018
From: jwd @ending from @urewe@t@net (John)
Date: Wed, 15 Aug 2018 14:57:52 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
Message-ID: <20180815145752.0124f307@Draco.localdomain>

On Wed, 15 Aug 2018 07:21:55 -0700
Stats Student <stats.student4647 at gmail.com> wrote:

> Hi, I am generating multiple charts with facet_wrap() and what what I
> see, R/ggplot sorts the panels by the facet variable. So adding an
> index to the facet variable (1 - bucket, 2 - bucket, etc) does solve
> the sorting issue but it's ugly. 
> 
You should also be looking at the ggplot help mailing list.  Since you
did not supply an example of your code it is not possible to really see
if anything in it might be overriding ggplot's normal behavior.

JDougherty


From m@cqueen1 @ending from llnl@gov  Thu Aug 16 01:38:58 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 15 Aug 2018 23:38:58 +0000
Subject: [R] searching for a specific row name in R
In-Reply-To: <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
Message-ID: <2FE3B7C3-F127-4B71-A9F4-5DD368DE37AD@llnl.gov>

It depends on what you want to check. There are a lot of things you can check without looping.

For example, if you want to check whether all of the first letters of the identifier names are "A", you could do
  table( substr(idnames,1,1))
to show you all of the first letters, and how many there are of each.

Like Bert said, some tutorials would be good. Even better would be to find someone nearby who knows R really well. I think R is probably difficult to learn all on one's own.

Small suggestion: be careful about using the word "list" in statements like "a list of identifier names".  It's ok in ordinary English, but in R a "list" is a special kind of data structure. Better to say "a vector of identifier names".

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Deepa <deepamahm.iisc at gmail.com>
Date: Monday, August 13, 2018 at 8:36 PM
To: "MacQueen, Don" <macqueen1 at llnl.gov>, array R-help <r-help at r-project.org>
Subject: Re: [R] searching for a specific row name in R

Hi Don,

When there is a list of identifier names that I want to check, the only way is to loop over each entry stored in the list of identifier names or is there is there any other shortcut?

Many thanks for the response?

On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>> wrote:
Or to return a logical value, i.e., TRUE if the column contains the value, FALSE if it does not:

  any( x[,2] == 'A501' )

-Don
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of alkauffm at fastmail.fm<mailto:alkauffm at fastmail.fm>> wrote:

    Hello Deepa,

    sum(x[,2] == "A501")
    or
    which(x[,2] == "A501")
    .
    Best,
    Albrecht


    --
      Albrecht Kauffmann
      alkauffm at fastmail.fm<mailto:alkauffm at fastmail.fm>

    Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
    > Hello Everyone,
    >
    > I have a 1000 x 20 matrix. The second column of the matrix has the names
    > of identifiers. How do I check when a certain identifier is present in
    > the set of 1000 identifier names present in the second column. For
    > instance, let the names of identifiers be A1,A2,...A1000. I want to
    > check whether A501 is present .How can this be checked?
    >
    > Any help will be highly appreciated.
    >
    >
    >   [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.

    ______________________________________________
    R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From @t@t@@@tudent4647 @ending from gm@il@com  Wed Aug 15 21:18:12 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Wed, 15 Aug 2018 12:18:12 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <CAGxFJbQcAGzCtXYfDXmyy4HS9PGD_Cuf-ML=dUr=toYOY5fwNg@mail.gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
 <CAGxFJbSGTPxSMKbo9SNbggMZN+LhGnHrvi31pFUEcFjp5xjBrA@mail.gmail.com>
 <CAMZO7wL5CChzQ_g0BUeJQBW_7V3VWzKo8mwuoYODPVVAwDU1mw@mail.gmail.com>
 <CAGxFJbQcAGzCtXYfDXmyy4HS9PGD_Cuf-ML=dUr=toYOY5fwNg@mail.gmail.com>
Message-ID: <43b623e6-de96-4dda-abb3-a97e4392baeb@gmail.com>

Understood. Will review the docs again. 

My data is from an external source which, among other things, ensures that it's sorted correctly. I was asking for a way to have ggplot use the ordering in place, instead of re-ordering everything. Apologies if it wasn't clear from the original post. 

Anyway, if the data is correctly presorted, unique should work ok, I think. 




On Aug 15, 2018, 9:23 AM, at 9:23 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>1. Unless there is good reason to keep a reply private, always cc the
>list.
>This allows more brains, possible corrections, etc.
>
>2. Have you read ?factor and ?unique ? Always study the docs carefully.
>They are generally terse but complete, especially the base docs, and
>you
>can often find your answers there.
>
>3. Your "solution" may work in this case, but if I understand correctly
>what you're after,  won't in general. unique() gives the unique values
>in
>the order they appear, which may not be the order you want:
>
>## want ordering to be "a" < "b" < "c"
>
>> f <- rep(letters[3:1],2)
>
>> factor(f, levels = unique(f))
>[1] c b a c b a
>Levels: c b a  ## not your desired order
>
>Again, please consult the docs and perhaps a tutorial or two as
>necessary.
>
>-- Bert
>
>
>
>On Wed, Aug 15, 2018 at 8:22 AM, Stats Student
><stats.student4647 at gmail.com>
>wrote:
>
>> Many thanks, Bert.
>>
>> I did -
>>
>> facet_wrap(~factor(var, levels=unique (var))
>>
>> And it seems to be working fine.
>> Do you see any issues with this?
>>
>> I'm fairly new to R so want to make sure I'm not doing something
>stupid.
>>
>> Thanks again.
>>
>> On Wed, Aug 15, 2018, 7:50 AM Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>>
>>> See ?factor.
>>>
>>> You can either use ?ordered to create an ordered factor to sort the
>>> levels as you desire or sort them with factor(). e.g.
>>>
>>> > f <- factor(letters[3:1])
>>> > f
>>> [1] c b a
>>> Levels: a b c   ## default ordering
>>>
>>> > f <- factor(f, levels = letters[3:1])
>>> > f
>>> [1] c b a
>>> Levels: c b a  ## explicit ordering
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming
>along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>> On Wed, Aug 15, 2018 at 7:21 AM, Stats Student <
>>> stats.student4647 at gmail.com> wrote:
>>>
>>>> Hi, I am generating multiple charts with facet_wrap() and what what
>I
>>>> see, R/ggplot sorts the panels by the facet variable. So adding an
>index to
>>>> the facet variable (1 - bucket, 2 - bucket, etc) does solve the
>sorting
>>>> issue but it's ugly.
>>>>
>>>> I also read this post which, if I understand correctly, claims that
>>>> ggplot should be using the initial ordering of the data for
>ordering the
>>>> charts (instead of ordering the data itself).
>>>>
>>>> https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/
>>>>
>>>> Wondering if anyone knows how to direct ggplot use the initial
>sorting
>>>> of the data to order the panels.
>>>>
>>>> Thank you.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>


From @tef@no@@ofi@ @ending from regione@m@rche@it  Thu Aug 16 12:33:28 2018
From: @tef@no@@ofi@ @ending from regione@m@rche@it (Stefano Sofia)
Date: Thu, 16 Aug 2018 10:33:28 +0000
Subject: [R] cumulate of snow cumulates from daily values of different
 automatic stations for some time intervals
In-Reply-To: <CA+8X3fUpyN9X6qZwjxdxaokAfo1QjtNZWxpSOOO3nDanKpVJ7g@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F54CCBF0B@ESINO.regionemarche.intra>,
 <CA+8X3fUpyN9X6qZwjxdxaokAfo1QjtNZWxpSOOO3nDanKpVJ7g@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F54CCDC0A@ESINO.regionemarche.intra>

Hi Jim.
Thank you for your help. I found very useful cum_snow and cum_list, but I decided to manage the list and dates in a different way.
First of all I decided to deal with a unique data frame (called df_CFS) where I attached all the 10 data frames, and instead to build a list with the 10 different data frames I created a list with the 10 station codes (217, 2018, ...):

list_station_code <- list(217, 218, 219, ...)

For managing dates, I created a vector of length 6. This is an example

my_date <- c("1999-12-17-00-00", "2000-01-07-00-00", "2000-01-10-00-00", "2000-01-15-00-00", NA, NA)

and then I created three functions based on the non NA elements of my_date:

sum_prec1 <- function(x, init_day1_POSIX, fin_day1_POSIX) {
  sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day1_POSIX & df_CFS$data_POSIX <= fin_day1_POSIX], na.rm=T)
}

sum_prec2 <- function(x, init_day1_POSIX, fin_day1_POSIX, init_day2_POSIX, fin_day2_POSIX) {
print("sum_prec2")
  sum1 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day1_POSIX & df_CFS$data_POSIX <= fin_day1_POSIX], na.rm=T)
  sum2 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day2_POSIX & df_CFS$data_POSIX <= fin_day2_POSIX], na.rm=T)
  sum <- sum1 + sum2
}

sum_prec3 <- function(x, init_day1_POSIX, fin_day1_POSIX, init_day2_POSIX, fin_day2_POSIX, init_day3_POSIX, fin_day3_POSIX) {
print("sum_prec3")
  sum1 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day1_POSIX & df_CFS$data_POSIX <= fin_day1_POSIX], na.rm=T)
  sum2 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day2_POSIX & df_CFS$data_POSIX <= fin_day2_POSIX], na.rm=T)
  sum3 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day3_POSIX & df_CFS$data_POSIX <= fin_day3_POSIX], na.rm=T)
  sum <- sum1 + sum2 + sum3
}

Finally

  my_date_POSIX <- as.POSIXct(my_date), format="%Y-%m-%d-%H-%M")
  my_date_POSIX <- my_dates[!is.na(my_date_POSIX)]
  if (length(my_date_POSIX)==2) my_output <- lapply(list_station_code, sum_prec1, my_date_POSIX[[1]], my_date_POSIX[[2]])
  else if (length(my_date_POSIX)==4) my_output <- lapply(list_station_code, sum_prec2, my_date_POSIX[[1]], my_date_POSIX[[2]], my_date_POSIX[[3]], my_date_POSIX[[4]])
  else if (length(my_dates)==6) my_output <- lapply(list_station_code, sum_prec3, my_date_POSIX[[1]], my_date_POSIX[[2]], my_date_POSIX[[3]], my_date_POSIX[[4]], my_date_POSIX[[5]], my_date_POSIX[[6]])

  df_snow_totals <- data.frame("station_code" = c(217, 218, 219))
  df_snow_totals$Cumulata <- as.vector(my_output)
  df_snow_totals$Cumulata <- as.numeric(as.character(unlist(df_snow_totals$Cumulata)))



It works.
Thank you for your help
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------
________________________________________
Da: Jim Lemon [drjimlemon at gmail.com]
Inviato: luned? 13 agosto 2018 1.55
A: Stefano Sofia
Cc: r-help at r-project.org
Oggetto: Re: [R] cumulate of snow cumulates from daily values of different automatic stations for some time intervals

Hi Stefano,
This was such a stinker of a problem that I just had to crack it:

# create some data the lazy man's way
year_dates<-c(paste(2000,rep("01",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("02",29),formatC(1:29,width=2,flag=0),sep="-"),
 paste(2000,rep("03",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("04",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("05",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("06",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("07",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("08",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("09",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("10",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("11",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("12",31),formatC(1:31,width=2,flag=0),sep="-"))

df1<-data.frame(station_code=rep(217,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df2<-data.frame(station_code=rep(218,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df3<-data.frame(station_code=rep(219,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df4<-data.frame(station_code=rep(220,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df5<-data.frame(station_code=rep(221,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df6<-data.frame(station_code=rep(222,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df7<-data.frame(station_code=rep(223,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df8<-data.frame(station_code=rep(224,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df9<-data.frame(station_code=rep(225,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df10<-data.frame(station_code=rep(226,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))

snow_list<-list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

for(station in 1:10)
 snow_list[[station]]$doy<-1:length(snow_list[[station]]$date_POSIX)

select_days<-c(1:12,83:88)

cum_snow<-function(x,which_days) {
 return(list(x$station_code[1],sum(x$snow[which_days])))
}

cum_list<-lapply(lapply(snow_list,cum_snow,select_days),unlist)

snow_totals<-data.frame(station_code=NULL,snow_cumulate=NULL)

for(station in 1:10) snow_totals<-rbind(snow_totals,cum_list[[station]])

names(snow_totals)<-c("station_code","snow_cumulate")

Jim


On Sat, Aug 11, 2018 at 2:48 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-list users,
> I have 10 data frames (called df1, df2, ... df10), where each of them contains snow data from an automatic meteorological station (obviously each station has a different station code).
> Here is an example of df1:
>
> station_code date_factor date_POSIX snow
> 217 1999-12-15 1999-12-15  0
> 217 1999-12-16 1999-12-16  0
> 217 1999-12-17 1999-12-17 38
> 217 1999-12-18 1999-12-18 31
> 217 1999-12-19 1999-12-19 21
> 217 1999-12-20 1999-12-20 12
> 217 1999-12-21 1999-12-21 42
> 217 1999-12-22 1999-12-22 61
> 217 1999-12-23 1999-12-23 57
> 217 1999-12-24 1999-12-24 48
> ...
>
> where
>> sapply(df1, class)
> $station_code
> [1] "numeric"
>
> $date_factor
> [1] "factor"
>
> $date_POSIX
> [1] "POSIXct" "POSIXt"
>
> $snow
> [1] "integer"
>
> Given a series of max three intervals (example with two intervals: from 1st to 12th of January 2000 and from 23rd to 28th of March 2000), I need to evaluate for each station the total snow cumulate for all the intervals selected, and finally create a data frame where for each line there is the station code and the snow cumulate. It should be like
>
> station_code total_snow_cumulate
> 217 125
> 218 80
> ...
>
> Could somebody show me a direction for an efficient solution?
>
> Thank you for your attention and your help
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> and provide commented, minimal, self-contained, reproducible code.

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From roy@mendel@@ohn @ending from no@@@gov  Thu Aug 16 22:01:13 2018
From: roy@mendel@@ohn @ending from no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 16 Aug 2018 13:01:13 -0700
Subject: [R] How deep into function calls does trycatch() work
Message-ID: <BEDFD820-13C1-4FCA-BB22-72B114F57B9D@noaa.gov>

Hi All:

I am using another package in a project I have. Because of that,  I have no control on how that package behaves or what it returns.  This package has a function foo()  that calls httr::GET(),  and if it gets an error from httr::GET() it calls the following routine:


err_handle2 <- function(x) {
  if (x$status_code > 201) {
    tt <- content(x, "text")
    mssg <- xml_text(xml_find_all(read_html(tt), "//h1"))
    stop(paste0(mssg, collapse = "\n\n"), call. = FALSE)
  }
}

My question is if I embed my call to foo() in try...catch will that override the stop() call or am I a goner, or is there another way to override it,  given that I can't change the code to err_handle2().

Thanks,

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From peter@l@ngfelder @ending from gm@il@com  Thu Aug 16 22:09:32 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 16 Aug 2018 13:09:32 -0700
Subject: [R] How deep into function calls does trycatch() work
In-Reply-To: <BEDFD820-13C1-4FCA-BB22-72B114F57B9D@noaa.gov>
References: <BEDFD820-13C1-4FCA-BB22-72B114F57B9D@noaa.gov>
Message-ID: <CA+hbrhUqTUfEYLDFwcjsJqbx1mLjq5WPeZhOQtT5HbNce_rXMQ@mail.gmail.com>

AFAIK a try or tryCatch will intercept the error thrown by stop(). Why
not try it and see if it works?

Peter
On Thu, Aug 16, 2018 at 1:05 PM Roy Mendelssohn - NOAA Federal via
R-help <r-help at r-project.org> wrote:
>
> Hi All:
>
> I am using another package in a project I have. Because of that,  I have no control on how that package behaves or what it returns.  This package has a function foo()  that calls httr::GET(),  and if it gets an error from httr::GET() it calls the following routine:
>
>
> err_handle2 <- function(x) {
>   if (x$status_code > 201) {
>     tt <- content(x, "text")
>     mssg <- xml_text(xml_find_all(read_html(tt), "//h1"))
>     stop(paste0(mssg, collapse = "\n\n"), call. = FALSE)
>   }
> }
>
> My question is if I embed my call to foo() in try...catch will that override the stop() call or am I a goner, or is there another way to override it,  given that I can't change the code to err_handle2().
>
> Thanks,
>
> -Roy
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@cqueen1 @ending from llnl@gov  Fri Aug 17 01:44:04 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 16 Aug 2018 23:44:04 +0000
Subject: [R] Using rmarkdown with many plots created in a loop
Message-ID: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>

I would appreciate some suggestions of a good way to prepare a report using rmarkdown,
in which I loop through subsets of a data set, creating a plot of each subset, and interspersing
among the figures some text relevant to each figure.

One way is to have an R script write the rmd file, then render it.
It works, but it's cumbersome and difficult to get the rmd syntax correct.
I would very much appreciate suggestions for a better way.

Reproducible example below.

Thanks
-Don


Example data (other data structures could be used), and an example using this approach.

myd <- lapply( 1:3,
              function(i) list(df=data.frame(x=1:5, y=rnorm(5)),
                               comment=paste('Data', LETTERS[i]))
              )

Example interactive review (details would change depending on data structure)
(I would typically insert pauses when working interactively)

for (i in 1:3) {
  cat(paste('Figure',i,'shows',myd[[i]]$comment),'\n')
  with(myd[[i]]$df , plot(x,y))
  mtext(myd[[i]]$comment)
  mtext( paste(nrow(myd[[i]]$df),'points'), adj=1)
}?

Note that along with the data I've saved some comments relevant to each subset.
I've calculated them in the example data, but in general they could be completely
arbitrary and come from anywhere.

Now I'd like to get the same plots and comments into a report prepared using rmarkdown.
Here's one way, having the loop create an rmd file, then rendering it.

### example script begins
library(rmarkdown)

myf <- 'myd.rmd'
sink(myf)
cat('---
title: Example
---

Here are some figures with a comment appearing before each.\n\n'
)
sink()

for (i in 1:3) {
  cat(paste('Figure',i,'comment:',myd[[i]]$comment),'\n', file=myf, append=TRUE)

  cat("
```{r  echo=FALSE, fig.cap='",paste('fig',i),"caption.'}
  with(myd[[",i,"]]$df , plot(x,y))
  mtext(myd[[",i,"]]$comment)
  mtext( paste(nrow(myd[[",i,"]]$df),'points'), adj=1)
```
", file=myf, append=TRUE)
   
}

cat('Done with report\n', file=myf, append=TRUE)

render(myf)

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Aug 16 15:44:45 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 16 Aug 2018 06:44:45 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <43b623e6-de96-4dda-abb3-a97e4392baeb@gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
 <CAGxFJbSGTPxSMKbo9SNbggMZN+LhGnHrvi31pFUEcFjp5xjBrA@mail.gmail.com>
 <CAMZO7wL5CChzQ_g0BUeJQBW_7V3VWzKo8mwuoYODPVVAwDU1mw@mail.gmail.com>
 <CAGxFJbQcAGzCtXYfDXmyy4HS9PGD_Cuf-ML=dUr=toYOY5fwNg@mail.gmail.com>
 <43b623e6-de96-4dda-abb3-a97e4392baeb@gmail.com>
Message-ID: <87786C9B-7F5F-427B-B843-E260109B2582@dcn.davis.ca.us>

The result does NOT depend on whether or how the data itself are sorted, but rather on how the levels of the factors in the data are sorted. Best results will be obtained if you modify the data frame factors before giving the data frame to ggplot. Doing so will allow all of the ggplot functions to work on a consistent set of data columns.

Some example ways to change the ordering:

factor(f, levels = sort(unique(f))) #alpha
factor(f, levels = unique(f)) #as first encountered in data
factor(f, levels = c("b","a","c")) #explicit
factor(f, levels = c("b","a","c"), labels=c("Ok","Best","Other") "#presentation coding

If for some reason you don't want to modify your original data, make a temporary copy of your data frame and set the appropriate factor levels for your presentation. However, it will then be up to you to avoid making substantive changes to the data records between multiple plots (views of the data).

On August 15, 2018 12:18:12 PM PDT, Stats Student <stats.student4647 at gmail.com> wrote:
>Understood. Will review the docs again. 
>
>My data is from an external source which, among other things, ensures
>that it's sorted correctly. I was asking for a way to have ggplot use
>the ordering in place, instead of re-ordering everything. Apologies if
>it wasn't clear from the original post. 
>
>Anyway, if the data is correctly presorted, unique should work ok, I
>think. 
>
>
>
>
>On Aug 15, 2018, 9:23 AM, at 9:23 AM, Bert Gunter
><bgunter.4567 at gmail.com> wrote:
>>1. Unless there is good reason to keep a reply private, always cc the
>>list.
>>This allows more brains, possible corrections, etc.
>>
>>2. Have you read ?factor and ?unique ? Always study the docs
>carefully.
>>They are generally terse but complete, especially the base docs, and
>>you
>>can often find your answers there.
>>
>>3. Your "solution" may work in this case, but if I understand
>correctly
>>what you're after,  won't in general. unique() gives the unique values
>>in
>>the order they appear, which may not be the order you want:
>>
>>## want ordering to be "a" < "b" < "c"
>>
>>> f <- rep(letters[3:1],2)
>>
>>> factor(f, levels = unique(f))
>>[1] c b a c b a
>>Levels: c b a  ## not your desired order
>>
>>Again, please consult the docs and perhaps a tutorial or two as
>>necessary.
>>
>>-- Bert
>>
>>
>>
>>On Wed, Aug 15, 2018 at 8:22 AM, Stats Student
>><stats.student4647 at gmail.com>
>>wrote:
>>
>>> Many thanks, Bert.
>>>
>>> I did -
>>>
>>> facet_wrap(~factor(var, levels=unique (var))
>>>
>>> And it seems to be working fine.
>>> Do you see any issues with this?
>>>
>>> I'm fairly new to R so want to make sure I'm not doing something
>>stupid.
>>>
>>> Thanks again.
>>>
>>> On Wed, Aug 15, 2018, 7:50 AM Bert Gunter <bgunter.4567 at gmail.com>
>>wrote:
>>>
>>>> See ?factor.
>>>>
>>>> You can either use ?ordered to create an ordered factor to sort the
>>>> levels as you desire or sort them with factor(). e.g.
>>>>
>>>> > f <- factor(letters[3:1])
>>>> > f
>>>> [1] c b a
>>>> Levels: a b c   ## default ordering
>>>>
>>>> > f <- factor(f, levels = letters[3:1])
>>>> > f
>>>> [1] c b a
>>>> Levels: c b a  ## explicit ordering
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming
>>along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>> On Wed, Aug 15, 2018 at 7:21 AM, Stats Student <
>>>> stats.student4647 at gmail.com> wrote:
>>>>
>>>>> Hi, I am generating multiple charts with facet_wrap() and what
>what
>>I
>>>>> see, R/ggplot sorts the panels by the facet variable. So adding an
>>index to
>>>>> the facet variable (1 - bucket, 2 - bucket, etc) does solve the
>>sorting
>>>>> issue but it's ugly.
>>>>>
>>>>> I also read this post which, if I understand correctly, claims
>that
>>>>> ggplot should be using the initial ordering of the data for
>>ordering the
>>>>> charts (instead of ordering the data itself).
>>>>>
>>>>> https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/
>>>>>
>>>>> Wondering if anyone knows how to direct ggplot use the initial
>>sorting
>>>>> of the data to order the panels.
>>>>>
>>>>> Thank you.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From citc m@ili@g off disroot@org  Fri Aug 17 13:55:43 2018
From: citc m@ili@g off disroot@org (citc m@ili@g off disroot@org)
Date: Fri, 17 Aug 2018 11:55:43 +0000
Subject: [R] bar plot add space to group data
Message-ID: <0283514711d8183ac79b865fd07f041d@disroot.org>

R-users,

Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.

barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
years<-c(2014,2015,2016,2017,2018)
mtext(years, side=1, at=c(5, 12, 19, 26, 33))
R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))

	[[alternative HTML version deleted]]


From cry@n @ending from bingh@mton@edu  Fri Aug 17 15:19:53 2018
From: cry@n @ending from bingh@mton@edu (Chris Ryan)
Date: Fri, 17 Aug 2018 09:19:53 -0400
Subject: [R] bar plot add space to group data
In-Reply-To: <0283514711d8183ac79b865fd07f041d@disroot.org>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
Message-ID: <A1BC743A-62DC-4B44-934A-F0601A2349C9@binghamton.edu>

Using the lattice package would provide an easy way to distinguish years, by putting them in different panels. Lattice would also help avoid some other features of this graph that, in my opinion, are suboptimal. See Tufte or Cleveland. 

Chris Ryan
-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.

On August 17, 2018 7:55:43 AM EDT, citc at disroot.org wrote:
>R-users,
>
>Can someone please advise how to improve the code below that was used
>to produce the graph shown at the following hyperlink
>(https://chemistryinthecity.neocities.org/content/entry1808.html#17)?
>The request is to add space between the annual data groups.
>
>barplot(gceac[,3], xlab='year', ylab='percentage of each grade',
>col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen',
>'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40,
>y = 30, title='grades'), main='A-level grades, chemistry', beside=T,
>space=c(0,2), ylim=c(0,30))
>years<-c(2014,2015,2016,2017,2018)
>mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>R-users, Can someone please advise how to improve the code below that
>was used to produce the graph shown at the following hyperlink
>(https://chemistryinthecity.neocities.org/content/entry1808.html#17)?
>The request is to add space between the annual data groups. 
>barplot(gceac[,3], xlab='year', ylab='percentage of each grade',
>col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen',
>'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40,
>y = 30, title='grades'), main='A-level grades, chemistry', beside=T,
>space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018)
>mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From f@ridcher @ending from gm@il@com  Fri Aug 17 16:07:59 2018
From: f@ridcher @ending from gm@il@com (Faridedin Cheraghi)
Date: Fri, 17 Aug 2018 18:37:59 +0430
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
 <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
 <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>
Message-ID: <CAJTBV4ULDuRNuvK5pADmXjKOLKa4VxDPHAtFG_gMvH3XLe9w3w@mail.gmail.com>

Dear Duncan,

thanks for your feedback on this. Even though most developers are not in
Windows (which I doubt it), there are a huge number of people who use R on
Windows and I am one of them who seriously work with R. Following my own
workaround to this bug, now I hit another issue with another workaround
when trying to render the Farsi Unicode characters. While these workarounds
work in ad hoc, they are not appealing in all scenarios;I hit other
problems related to this bug, e.g., when documenting a package with
Roxygen2 package.

Please see the attached files (r scripts) for the complete bug report.

thanks
Farid

On Sun, Aug 12, 2018 at 9:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 12/08/2018 11:48 AM, Faridedin Cheraghi wrote:
>
>> that's right and I don't want to change my locale. my sessionInfo() :
>>
>
> I think it could be another manifestation of a known bug on Windows, where
> strings are converted from UTF-8 to the current locale and back to UTF-8, a
> lossy conversion.  This has been present for many years, and requires a lot
> of internal changes to fix, so I wouldn't hold your breath waiting for a
> fix.
>
> I believe the "right" fix is for R to always convert strings to UTF-8
> internally.  This wasn't possible when the internationalization code was
> added many years ago because not all platforms supported UTF-8.  It would
> be a lot of work now, and since it isn't needed now on the platforms most
> developers use, it's not receiving a lot of attention.
>
> Your workaround
>
> file(script,
>      encoding = "UTF-8") %T>%
>      source() %>%
>      close()   # works fine
>
> is a nice way to avoid this problem.
>
> Duncan Murdoch
>
>
>> R version 3.5.1 (2018-07-02)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> thanks
>>
>> On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
>>
>>         It was actually a .rmd file so you can get the coloring of the
>>         bug report
>>         in your text editor. I changed the format to .txt.
>>
>>
>>     When I run your script on a Mac (in a UTF-8 locale), all lines work
>>     as expected.  I'm guessing you are working on Windows, in a
>>     non-UTF-8 locale?
>>
>>     Posting sessionInfo() would be helpful.
>>
>>     Duncan Murdoch
>>
>>
>>
>>         -Farid
>>
>>         On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller
>>         <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>
>>         wrote:
>>
>>             ... and read the Posting Guide... only a few file types will
>>             ever make it
>>             through the mailing list so repeatedly sending files not
>>             among those few
>>             types would just be frustrating for everyone.
>>
>>             On August 11, 2018 4:51:43 PM PDT, Jim Lemon
>>             <drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>> wrote:
>>
>>                 Hi Farid,
>>                 Whatever you attached has not gotten through.
>>
>>                 Jim
>>
>>                 On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch
>>                 <faridcher at gmail.com <mailto:faridcher at gmail.com>> wrote:
>>
>>                     Hi all,
>>
>>                     Please check the attached file.
>>
>>                     Thanks
>>                     Farid
>>
>>
>>                     ______________________________________________
>>                     R-help at r-project.org <mailto:R-help at r-project.org>
>>                     mailing list -- To UNSUBSCRIBE and more, see
>>                     https://stat.ethz.ch/mailman/listinfo/r-help
>>                     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                     PLEASE do read the posting guide
>>
>>                 http://www.R-project.org/posting-guide.html
>>                 <http://www.R-project.org/posting-guide.html>
>>
>>                     and provide commented, minimal, self-contained,
>>                     reproducible code.
>>
>>
>>                 ______________________________________________
>>                 R-help at r-project.org <mailto:R-help at r-project.org>
>>                 mailing list -- To UNSUBSCRIBE and more, see
>>                 https://stat.ethz.ch/mailman/listinfo/r-help
>>                 <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                 PLEASE do read the posting guide
>>                 http://www.R-project.org/posting-guide.html
>>                 <http://www.R-project.org/posting-guide.html>
>>                 and provide commented, minimal, self-contained,
>>                 reproducible code.
>>
>>
>>             --
>>             Sent from my phone. Please excuse my brevity.
>>
>>
>>
>>             ______________________________________________
>>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>             list -- To UNSUBSCRIBE and more, see
>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>             PLEASE do read the posting guide
>>             http://www.R-project.org/posting-guide.html
>>             <http://www.R-project.org/posting-guide.html>
>>             and provide commented, minimal, self-contained, reproducible
>>             code.
>>
>>
>>
>>
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: bug01_right.png
Type: image/png
Size: 3913 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180817/0f754c29/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: bug01_wrong.png
Type: image/png
Size: 6462 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180817/0f754c29/attachment-0001.png>

From dc@rl@on @ending from t@mu@edu  Fri Aug 17 16:37:28 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Fri, 17 Aug 2018 14:37:28 +0000
Subject: [R] bar plot add space to group data
In-Reply-To: <0283514711d8183ac79b865fd07f041d@disroot.org>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
Message-ID: <ef12bce1db1c412e8c02a2b6e26c879e@tamu.edu>

Notice below that your message is substantially scrambled. R-Help is a plain text only list so you should set your email client to produce plain text messages. 

The best place to start is with the manual page for the barplot() function:

?barplot or help(barplot)

You will find the description of the space= argument useful.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of citc at disroot.org
Sent: Friday, August 17, 2018 6:56 AM
To: r-help at r-project.org
Subject: [R] bar plot add space to group data

R-users,

Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.

barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
years<-c(2014,2015,2016,2017,2018)
mtext(years, side=1, at=c(5, 12, 19, 26, 33)) R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j@p@rk4 @ending from uic@edu  Fri Aug 17 19:34:07 2018
From: j@p@rk4 @ending from uic@edu (Sparks, John)
Date: Fri, 17 Aug 2018 17:34:07 +0000
Subject: [R] CARET NN Too Much Output Even with Trace=False
Message-ID: <SN6PR05MB4816206A6C9610E1F707C4FAFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>

Hi R Helpers,


I am using the Neural Net build in the CARET package and it produces a large amount of output that I don't need to see and interferes with my ability to get to the output that I want to see.  I am using the nnet.trace=FALSE setting, but still getting a disproportionate amount of output from this one procedure.


Is there another option setting that will turn off this output?


Reproducible example is below.  It has a little extra complication in it because I hacked it from a post.  Let me know if I need to do anything to it to make it more use-able.


Many thanks.

--John Sparks


library('caret')
set.seed(1)

data<-read.csv(url('https://datahack-prod.s3.ap-south-1.amazonaws.com/train_file/train_u6lujuX_CVtuZ9i.csv'))

#Imputing missing values using median
preProcValues <- preProcess(data, method = c("medianImpute","center","scale"))
library('RANN')
data_processed <- predict(preProcValues, data)
index <- createDataPartition(data_processed$Loan_Status, p=0.75, list=FALSE)
trainSet <- data_processed[ index,]
testSet <- data_processed[-index,]
fitControl <- trainControl(method = "cv",number = 5,savePredictions = 'final',classProbs = T)

trainSet<-subset(trainSet,select=-c(Loan_ID))
outcomeName<-"Loan_Status"
predictors<-names(trainSet)[!names(trainSet) %in% outcomeName]

NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',trControl=fitControl,tuneLength=5,nnet.trace=FALSE)



	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Fri Aug 17 19:45:28 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 17 Aug 2018 10:45:28 -0700
Subject: [R] CARET NN Too Much Output Even with Trace=False
In-Reply-To: <SN6PR05MB4816206A6C9610E1F707C4FAFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>
References: <SN6PR05MB4816206A6C9610E1F707C4FAFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>
Message-ID: <CAF8bMca8LjrspqHrv+GzZqzbLGRbNO59y_VCr3bmZk1epoutoA@mail.gmail.com>

You can use capture.output to store all that tracing information in a
character vector instead of having it printed.  You can look at it to
diagnose problems or just throw it away.

NN.text  <-
capture.output(NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',trControl=fitControl,tuneLength=5,nnet.trace=FALSE))

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 17, 2018 at 10:34 AM, Sparks, John <jspark4 at uic.edu> wrote:

> Hi R Helpers,
>
>
> I am using the Neural Net build in the CARET package and it produces a
> large amount of output that I don't need to see and interferes with my
> ability to get to the output that I want to see.  I am using the
> nnet.trace=FALSE setting, but still getting a disproportionate amount of
> output from this one procedure.
>
>
> Is there another option setting that will turn off this output?
>
>
> Reproducible example is below.  It has a little extra complication in it
> because I hacked it from a post.  Let me know if I need to do anything to
> it to make it more use-able.
>
>
> Many thanks.
>
> --John Sparks
>
>
> library('caret')
> set.seed(1)
>
> data<-read.csv(url('https://datahack-prod.s3.ap-south-1.
> amazonaws.com/train_file/train_u6lujuX_CVtuZ9i.csv'))
>
> #Imputing missing values using median
> preProcValues <- preProcess(data, method = c("medianImpute","center","
> scale"))
> library('RANN')
> data_processed <- predict(preProcValues, data)
> index <- createDataPartition(data_processed$Loan_Status, p=0.75,
> list=FALSE)
> trainSet <- data_processed[ index,]
> testSet <- data_processed[-index,]
> fitControl <- trainControl(method = "cv",number = 5,savePredictions =
> 'final',classProbs = T)
>
> trainSet<-subset(trainSet,select=-c(Loan_ID))
> outcomeName<-"Loan_Status"
> predictors<-names(trainSet)[!names(trainSet) %in% outcomeName]
>
> NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',
> trControl=fitControl,tuneLength=5,nnet.trace=FALSE)
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@p@rk4 @ending from uic@edu  Fri Aug 17 19:51:05 2018
From: j@p@rk4 @ending from uic@edu (Sparks, John)
Date: Fri, 17 Aug 2018 17:51:05 +0000
Subject: [R] CARET NN Too Much Output Even with Trace=False
In-Reply-To: <CAF8bMca8LjrspqHrv+GzZqzbLGRbNO59y_VCr3bmZk1epoutoA@mail.gmail.com>
References: <SN6PR05MB4816206A6C9610E1F707C4FAFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>,
 <CAF8bMca8LjrspqHrv+GzZqzbLGRbNO59y_VCr3bmZk1epoutoA@mail.gmail.com>
Message-ID: <SN6PR05MB481641D65683484F3D9F628BFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>

Terrific!  Thanks for the speedy and informative reply.


--JJS


________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: Friday, August 17, 2018 12:45 PM
To: Sparks, John
Cc: r-help at r-project.org
Subject: Re: [R] CARET NN Too Much Output Even with Trace=False

You can use capture.output to store all that tracing information in a character vector instead of having it printed.  You can look at it to diagnose problems or just throw it away.

NN.text  <- capture.output(NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',trControl=fitControl,tuneLength=5,nnet.trace=FALSE))

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Fri, Aug 17, 2018 at 10:34 AM, Sparks, John <jspark4 at uic.edu<mailto:jspark4 at uic.edu>> wrote:
Hi R Helpers,


I am using the Neural Net build in the CARET package and it produces a large amount of output that I don't need to see and interferes with my ability to get to the output that I want to see.  I am using the nnet.trace=FALSE setting, but still getting a disproportionate amount of output from this one procedure.


Is there another option setting that will turn off this output?


Reproducible example is below.  It has a little extra complication in it because I hacked it from a post.  Let me know if I need to do anything to it to make it more use-able.


Many thanks.

--John Sparks


library('caret')
set.seed(1)

data<-read.csv(url('https://datahack-prod.s3.ap-south-1.amazonaws.com/train_file/train_u6lujuX_CVtuZ9i.csv'))

#Imputing missing values using median
preProcValues <- preProcess(data, method = c("medianImpute","center","scale"))
library('RANN')
data_processed <- predict(preProcValues, data)
index <- createDataPartition(data_processed$Loan_Status, p=0.75, list=FALSE)
trainSet <- data_processed[ index,]
testSet <- data_processed[-index,]
fitControl <- trainControl(method = "cv",number = 5,savePredictions = 'final',classProbs = T)

trainSet<-subset(trainSet,select=-c(Loan_ID))
outcomeName<-"Loan_Status"
predictors<-names(trainSet)[!names(trainSet) %in% outcomeName]

NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',trControl=fitControl,tuneLength=5,nnet.trace=FALSE)



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ghk18 @ending from @c@rletm@il@rutger@@edu  Fri Aug 17 21:27:05 2018
From: ghk18 @ending from @c@rletm@il@rutger@@edu (GALIB KHAN)
Date: Fri, 17 Aug 2018 14:27:05 -0500
Subject: [R] RuGarch issue
Message-ID: <CAKGtyOmmnHJTTg9Aib9_Nhew-rfZJVF-vh0XYxN2kcrFvfDLEg@mail.gmail.com>

Sup guys,

Got an interesting issue with the rugarch package.

I noticed that when I changed the order of the external regressors, there
are different values for the robust coefficient matrix. The values should be
the same (according to the ordering of the variables). However, I am getting
drastically different results. At that time the model was arma(2,2) +
garch(1,0).

Is this considered a normal behavior of the rugarch package? I assume that
when you change the ordering of the external regressors the output should be
exactly the same....digit by digit.

I confirmed this issue by creating a generic script that can be tested by
anyone. Has anybody faced this issue before or is there post that describes
the issue that I am facing?

  Maybe I am going insane...for now I will look further into the
documentation that our Alexios has provided

Thanks!
  library(rugarch)


set.seed(1)

x1 <- rnorm(1000,5,1)
x2 <- rnorm(1000,3,3)

y    <- .5*(x1*x2) + rnorm(1000,1,3)
dat  <- data.frame(x1,x2,y)

var1 <- c("x1","x2")
var2 <- c("x2","x1")

# setbounds(spec)<-list(vxreg1=c(-1,1))
model_maker <- function(x_name){
  temp <- dat[,c("y",x_name)]

  spec <- ugarchspec(variance.model      = list(model = "sGARCH",
                                                garchOrder = c(1,0)),

                     mean.model          = list(armaOrder = c(2,2),
                                                external.regressors =
as.matrix(temp[,x_name]),
                                                include.mean= T),

                     distribution.model  = "std")

  fit         <- ugarchfit(spec = spec, data = as.matrix(temp$y),solver =
"hybrid")
  return(fit at fit$robust.matcoef)}

model_maker(var1)
model_maker(var2)

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Fri Aug 17 22:57:54 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Fri, 17 Aug 2018 16:57:54 -0400
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <CAJTBV4ULDuRNuvK5pADmXjKOLKa4VxDPHAtFG_gMvH3XLe9w3w@mail.gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
 <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
 <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>
 <CAJTBV4ULDuRNuvK5pADmXjKOLKa4VxDPHAtFG_gMvH3XLe9w3w@mail.gmail.com>
Message-ID: <8e7ca2ae-1e7e-83f2-1d5e-a6bb780af55d@gmail.com>

On 17/08/2018 10:07 AM, Faridedin Cheraghi wrote:
> Dear Duncan,
> 
> thanks for your feedback on this. Even though most developers are not in 
> Windows (which I doubt it),

I'm talking about the R Core developers.  I used to be one, but have 
retired from that role.

  there are a huge number of people who use R
> on Windows and I am one of them who seriously work with R.

Indeed, Microsoft promotes R, and they have a lot of developers; they 
just don't contribute much to R.  Honestly I'd suggest that if you are 
serious about working with languages not supported in the default code 
page, you should switch platforms.

> Following my 
> own workaround to this bug, now?I hit another issue with another 
> workaround when trying to render the Farsi Unicode characters. While 
> these workarounds work in ad hoc, they are not appealing in all 
> scenarios;I hit other problems related to this bug, e.g., when 
> documenting a package with Roxygen2 package.
> 
> Please see the attached files (r scripts) for the complete bug report.

If you think this is a new bug, you should report it to the bug tracking 
system (which requires you to be registered first).  Posting it to me or 
to R-help will probably not result in any action on it.  Posting it to 
the bug page will at least result in a fairly permanent record.

Duncan Murdoch
> 
> thanks
> Farid
> 
> On Sun, Aug 12, 2018 at 9:03 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 12/08/2018 11:48 AM, Faridedin Cheraghi wrote:
> 
>         that's right and I don't want to change my locale. my
>         sessionInfo() :
> 
> 
>     I think it could be another manifestation of a known bug on Windows,
>     where strings are converted from UTF-8 to the current locale and
>     back to UTF-8, a lossy conversion.? This has been present for many
>     years, and requires a lot of internal changes to fix, so I wouldn't
>     hold your breath waiting for a fix.
> 
>     I believe the "right" fix is for R to always convert strings to
>     UTF-8 internally.? This wasn't possible when the
>     internationalization code was added many years ago because not all
>     platforms supported UTF-8.? It would be a lot of work now, and since
>     it isn't needed now on the platforms most developers use, it's not
>     receiving a lot of attention.
> 
>     Your workaround
> 
>     file(script,
>      ? ? ?encoding = "UTF-8") %T>%
>      ? ? ?source() %>%
>      ? ? ?close()? ?# works fine
> 
>     is a nice way to avoid this problem.
> 
>     Duncan Murdoch
> 
> 
>         R version 3.5.1 (2018-07-02)
>         Platform: x86_64-w64-mingw32/x64 (64-bit)
>         Running under: Windows >= 8 x64 (build 9200)
> 
>         Matrix products: default
> 
>         locale:
>         [1] LC_COLLATE=English_United States.1252
>         [2] LC_CTYPE=English_United States.1252
>         [3] LC_MONETARY=English_United States.1252
>         [4] LC_NUMERIC=C
>         [5] LC_TIME=English_United States.1252
> 
>         attached base packages:
>         [1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
> 
>         thanks
> 
>         On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch
>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>         <mailto:murdoch.duncan at gmail.com
>         <mailto:murdoch.duncan at gmail.com>>> wrote:
> 
>          ? ? On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
> 
>          ? ? ? ? It was actually a .rmd file so you can get the coloring
>         of the
>          ? ? ? ? bug report
>          ? ? ? ? in your text editor. I changed the format to .txt.
> 
> 
>          ? ? When I run your script on a Mac (in a UTF-8 locale), all
>         lines work
>          ? ? as expected.? I'm guessing you are working on Windows, in a
>          ? ? non-UTF-8 locale?
> 
>          ? ? Posting sessionInfo() would be helpful.
> 
>          ? ? Duncan Murdoch
> 
> 
> 
>          ? ? ? ? -Farid
> 
>          ? ? ? ? On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller
>          ? ? ? ? <jdnewmil at dcn.davis.ca.us
>         <mailto:jdnewmil at dcn.davis.ca.us>
>         <mailto:jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>>
>          ? ? ? ? wrote:
> 
>          ? ? ? ? ? ? ... and read the Posting Guide... only a few file
>         types will
>          ? ? ? ? ? ? ever make it
>          ? ? ? ? ? ? through the mailing list so repeatedly sending
>         files not
>          ? ? ? ? ? ? among those few
>          ? ? ? ? ? ? types would just be frustrating for everyone.
> 
>          ? ? ? ? ? ? On August 11, 2018 4:51:43 PM PDT, Jim Lemon
>          ? ? ? ? ? ? <drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>         <mailto:drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>>> wrote:
> 
>          ? ? ? ? ? ? ? ? Hi Farid,
>          ? ? ? ? ? ? ? ? Whatever you attached has not gotten through.
> 
>          ? ? ? ? ? ? ? ? Jim
> 
>          ? ? ? ? ? ? ? ? On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch
>          ? ? ? ? ? ? ? ? <faridcher at gmail.com
>         <mailto:faridcher at gmail.com> <mailto:faridcher at gmail.com
>         <mailto:faridcher at gmail.com>>> wrote:
> 
>          ? ? ? ? ? ? ? ? ? ? Hi all,
> 
>          ? ? ? ? ? ? ? ? ? ? Please check the attached file.
> 
>          ? ? ? ? ? ? ? ? ? ? Thanks
>          ? ? ? ? ? ? ? ? ? ? Farid
> 
> 
>          ? ? ? ? ? ? ? ? ? ? ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>          ? ? ? ? ? ? ? ? ? ? mailing list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>                             
>         <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>          ? ? ? ? ? ? ? ? ? ? PLEASE do read the posting guide
> 
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>          ? ? ? ? ? ? ? ? <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
> 
>          ? ? ? ? ? ? ? ? ? ? and provide commented, minimal, self-contained,
>          ? ? ? ? ? ? ? ? ? ? reproducible code.
> 
> 
>          ? ? ? ? ? ? ? ? ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>          ? ? ? ? ? ? ? ? mailing list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>          ? ? ? ? ? ? ? ? <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>          ? ? ? ? ? ? ? ? PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>          ? ? ? ? ? ? ? ? <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>          ? ? ? ? ? ? ? ? and provide commented, minimal, self-contained,
>          ? ? ? ? ? ? ? ? reproducible code.
> 
> 
>          ? ? ? ? ? ? --
>          ? ? ? ? ? ? Sent from my phone. Please excuse my brevity.
> 
> 
> 
>          ? ? ? ? ? ? ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing
>          ? ? ? ? ? ? list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>          ? ? ? ? ? ? <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>          ? ? ? ? ? ? PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>          ? ? ? ? ? ? <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>          ? ? ? ? ? ? and provide commented, minimal, self-contained,
>         reproducible
>          ? ? ? ? ? ? code.
> 
> 
> 
> 
>


From philipsm m@ili@g off cp@@el1@stormweb@@et  Fri Aug 17 22:06:41 2018
From: philipsm m@ili@g off cp@@el1@stormweb@@et (philipsm m@ili@g off cp@@el1@stormweb@@et)
Date: Fri, 17 Aug 2018 16:06:41 -0400
Subject: [R] Finding and changing .Rprofile
Message-ID: <20180817160641.Horde.WjbChzhPRGG_mctw3k74ENm@webmail.philipsmith.ca>

I would like to change my .Rprofile file, but I cannot find it. I use  
a Mac Pro and RStudio. I believe the file is a hidden file and I have  
checked for it accordingly. I can not find it with a Spotlight search.  
It is not in my "default working directory". Is that the same thing as  
my "home directory"? I believe I can put a new .Rprofile file in any  
project directory, but that is not what I want to do. I want a  
.Rprofile file that will apply automatically whenever I start working  
on another project. Was one installed automatically when I installed R  
and RStudio many months ago and if so, where can I find it? If it was  
not installed automatically and I have to create my own, where should  
I put it?


From z267xu @ending from uw@terloo@c@  Fri Aug 17 23:32:07 2018
From: z267xu @ending from uw@terloo@c@ (Zehao Xu)
Date: Fri, 17 Aug 2018 21:32:07 +0000
Subject: [R] How to rotate label in tcltk R
Message-ID: <9d0c17f29c10498e8fa4eb7c0499aacd@uwaterloo.ca>

Dear sir (ma'am)

I just start the tcltk in R. I face a problem, how to rotate the labels in tcltk? I post the example on https://stackoverflow.com/questions/51825771/how-to-rotate-labels-in-tcltk.


Thank you

Z Xu



	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Sat Aug 18 00:08:19 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 17 Aug 2018 15:08:19 -0700 (PDT)
Subject: [R] Understanding read.csv error message
Message-ID: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>

   I have a data file, 'precip_projected.csv,' that starts like this:

name,easting,northing,elev,sampdate,prcp
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02

   There are a bunch of NAs in the data file.

   The command to read it produces an error:

rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)

Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
   replacement has 0 rows, data has 113569

   Is the error generated by finding a date that looks like the number zero
or by a prcp value of zero?

   BTW, I get the same error if I specify stringsAsFactors = F.

TIA,

Rich


From m@rc_@chw@rtz @ending from me@com  Sat Aug 18 00:17:57 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Fri, 17 Aug 2018 18:17:57 -0400
Subject: [R] Finding and changing .Rprofile
In-Reply-To: <20180817160641.Horde.WjbChzhPRGG_mctw3k74ENm@webmail.philipsmith.ca>
References: <20180817160641.Horde.WjbChzhPRGG_mctw3k74ENm@webmail.philipsmith.ca>
Message-ID: <93B2254D-438F-460B-8A12-65CC3D1B2C7C@me.com>


> On Aug 17, 2018, at 4:06 PM, philipsm at cpanel1.stormweb.net wrote:
> 
> I would like to change my .Rprofile file, but I cannot find it. I use a Mac Pro and RStudio. I believe the file is a hidden file and I have checked for it accordingly. I can not find it with a Spotlight search. It is not in my "default working directory". Is that the same thing as my "home directory"? I believe I can put a new .Rprofile file in any project directory, but that is not what I want to do. I want a .Rprofile file that will apply automatically whenever I start working on another project. Was one installed automatically when I installed R and RStudio many months ago and if so, where can I find it? If it was not installed automatically and I have to create my own, where should I put it?


Hi, 

As an FYI, there is a dedicated R list for macOS users:

  https://stat.ethz.ch/mailman/listinfo/r-sig-mac

which should be used for macOS specific questions vis-a-vis R.

The default .Rprofile is stored in your user home folder, which is /Users/YourUserName/.Rprofile or abbreviated as ~/.Rprofile.

As you note, because it is a hidden file, with a leading '.', Finder and Spotlight will not show it by default.

You can change that behavior relative to hidden files, by opening a Terminal and using the following command:

  defaults write com.apple.finder AppleShowAllFiles TRUE

then restart Finder, by using Alt-RightClick on the Finder icon in the dock and selecting Relaunch. You can reverse that behavior by changing the TRUE to FALSE in the above command.

If you don't want to make that global change, you can use the following command in a Terminal session:

  open -a Textedit ~/.Rprofile

That will bring up the Textedit editor application with the file loaded. You can then edit the file content and save it. 

Whichever way you edit the file, be sure to restart any R sessions you have running, so that future R sessions will pick up the changes.

Making the change to that file will generally affect all R sessions for your user profile.

I don't use RStudio, so it may have other relevant features, and they have their own support lists linked on their site.

Regards,

Marc Schwartz


From r@turner @ending from @uckl@nd@@c@nz  Sat Aug 18 00:22:45 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 18 Aug 2018 10:22:45 +1200
Subject: [R] bar plot add space to group data
In-Reply-To: <ef12bce1db1c412e8c02a2b6e26c879e@tamu.edu>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <ef12bce1db1c412e8c02a2b6e26c879e@tamu.edu>
Message-ID: <56e7fda9-284c-b16c-e3e5-f8460c34747c@auckland.ac.nz>


On 18/08/18 02:37, David L Carlson wrote:

> Notice below that your message is substantially scrambled. R-Help is a
> plain text only list so you should set your email client to produce plain text messages.
> 
> The best place to start is with the manual page for the barplot() function:
> 
> ?barplot or help(barplot)
> 
> You will find the description of the space= argument useful.

<SNIP>

If one struggles through the garbled html bumff, one sees that the OP 
*did* indeed use the "space=" argument.  However it does not appear to 
have had the desired effect, and I cannot see why.  Since the OP did not 
supply the data, I cannot experiment.

Perhaps someone else will have some insight.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From m@cqueen1 @ending from llnl@gov  Sat Aug 18 02:03:25 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Sat, 18 Aug 2018 00:03:25 +0000
Subject: [R] Understanding read.csv error message
In-Reply-To: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
Message-ID: <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>

Hi Rich,

It's not obvious what would be causing that error from read.csv. But here's what I would probably try:

Add quote='"" to your arguments. The default is to use surround text strings with double quotes, but your file doesn't.

Copy the first few rows into another file and try it. If it succeeds, that would suggest something later on in the file is causing the problem.

The argument sep=','   is redundant for read.csv. In other words, it sets sep for you. I'd try switching to the more general read.table.

Are the NAs in the file indicated by NA between a pair of commas? Or do you have successive commas with nothing between them for NA? Not sure what difference it will make, but it might affect what args you pass to read.table.

Are you absolutely sure there are never any commas in the name?

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/17/18, 3:08 PM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       I have a data file, 'precip_projected.csv,' that starts like this:
    
    name,easting,northing,elev,sampdate,prcp
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02
    
       There are a bunch of NAs in the data file.
    
       The command to read it produces an error:
    
    rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)
    
    Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
       replacement has 0 rows, data has 113569
    
       Is the error generated by finding a date that looks like the number zero
    or by a prcp value of zero?
    
       BTW, I get the same error if I specify stringsAsFactors = F.
    
    TIA,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @ending from llnl@gov  Sat Aug 18 02:07:56 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Sat, 18 Aug 2018 00:07:56 +0000
Subject: [R] Understanding read.csv error message
In-Reply-To: <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
 <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>
Message-ID: <732F05DD-7FCF-4509-8502-C58DDF33B273@llnl.gov>

small typo in previous: should be
  quote=""
(I left behind a single quote by mistake)

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/17/18, 5:03 PM, "R-help on behalf of MacQueen, Don via R-help" <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

    Hi Rich,
    
    It's not obvious what would be causing that error from read.csv. But here's what I would probably try:
    
    Add quote='"" to your arguments. The default is to use surround text strings with double quotes, but your file doesn't.
    
    Copy the first few rows into another file and try it. If it succeeds, that would suggest something later on in the file is causing the problem.
    
    The argument sep=','   is redundant for read.csv. In other words, it sets sep for you. I'd try switching to the more general read.table.
    
    Are the NAs in the file indicated by NA between a pair of commas? Or do you have successive commas with nothing between them for NA? Not sure what difference it will make, but it might affect what args you pass to read.table.
    
    Are you absolutely sure there are never any commas in the name?
    
    -Don
    
    --
    Don MacQueen
    Lawrence Livermore National Laboratory
    7000 East Ave., L-627
    Livermore, CA 94550
    925-423-1062
    Lab cell 925-724-7509
     
     
    
    On 8/17/18, 3:08 PM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:
    
           I have a data file, 'precip_projected.csv,' that starts like this:
        
        name,easting,northing,elev,sampdate,prcp
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02
        
           There are a bunch of NAs in the data file.
        
           The command to read it produces an error:
        
        rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)
        
        Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
           replacement has 0 rows, data has 113569
        
           Is the error generated by finding a date that looks like the number zero
        or by a prcp value of zero?
        
           BTW, I get the same error if I specify stringsAsFactors = F.
        
        TIA,
        
        Rich
        
        ______________________________________________
        R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
        https://stat.ethz.ch/mailman/listinfo/r-help
        PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
        and provide commented, minimal, self-contained, reproducible code.
        
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From philipsm m@ili@g off cp@@el1@stormweb@@et  Sat Aug 18 01:55:55 2018
From: philipsm m@ili@g off cp@@el1@stormweb@@et (philipsm m@ili@g off cp@@el1@stormweb@@et)
Date: Fri, 17 Aug 2018 19:55:55 -0400
Subject: [R] Finding and changing .Rprofile
In-Reply-To: <93B2254D-438F-460B-8A12-65CC3D1B2C7C@me.com>
References: <20180817160641.Horde.WjbChzhPRGG_mctw3k74ENm@webmail.philipsmith.ca>
 <93B2254D-438F-460B-8A12-65CC3D1B2C7C@me.com>
Message-ID: <20180817195555.Horde.SFShsFKx05HL5opVSej9nam@webmail.philipsmith.ca>

Thanks!


Quoting Marc Schwartz <marc_schwartz at me.com>:

>> On Aug 17, 2018, at 4:06 PM, philipsm at cpanel1.stormweb.net wrote:
>>
>> I would like to change my .Rprofile file, but I cannot find it. I  
>> use a Mac Pro and RStudio. I believe the file is a hidden file and  
>> I have checked for it accordingly. I can not find it with a  
>> Spotlight search. It is not in my "default working directory". Is  
>> that the same thing as my "home directory"? I believe I can put a  
>> new .Rprofile file in any project directory, but that is not what I  
>> want to do. I want a .Rprofile file that will apply automatically  
>> whenever I start working on another project. Was one installed  
>> automatically when I installed R and RStudio many months ago and if  
>> so, where can I find it? If it was not installed automatically and  
>> I have to create my own, where should I put it?
>
>
> Hi,
>
> As an FYI, there is a dedicated R list for macOS users:
>
>   https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>
> which should be used for macOS specific questions vis-a-vis R.
>
> The default .Rprofile is stored in your user home folder, which is  
> /Users/YourUserName/.Rprofile or abbreviated as ~/.Rprofile.
>
> As you note, because it is a hidden file, with a leading '.', Finder  
> and Spotlight will not show it by default.
>
> You can change that behavior relative to hidden files, by opening a  
> Terminal and using the following command:
>
>   defaults write com.apple.finder AppleShowAllFiles TRUE
>
> then restart Finder, by using Alt-RightClick on the Finder icon in  
> the dock and selecting Relaunch. You can reverse that behavior by  
> changing the TRUE to FALSE in the above command.
>
> If you don't want to make that global change, you can use the  
> following command in a Terminal session:
>
>   open -a Textedit ~/.Rprofile
>
> That will bring up the Textedit editor application with the file  
> loaded. You can then edit the file content and save it.
>
> Whichever way you edit the file, be sure to restart any R sessions  
> you have running, so that future R sessions will pick up the changes.
>
> Making the change to that file will generally affect all R sessions  
> for your user profile.
>
> I don't use RStudio, so it may have other relevant features, and  
> they have their own support lists linked on their site.
>
> Regards,
>
> Marc Schwartz


From ghk18 @ending from @c@rletm@il@rutger@@edu  Sat Aug 18 04:19:09 2018
From: ghk18 @ending from @c@rletm@il@rutger@@edu (GALIB KHAN)
Date: Fri, 17 Aug 2018 21:19:09 -0500
Subject: [R] RuGarch issue
In-Reply-To: <CAKGtyOmmnHJTTg9Aib9_Nhew-rfZJVF-vh0XYxN2kcrFvfDLEg@mail.gmail.com>
References: <CAKGtyOmmnHJTTg9Aib9_Nhew-rfZJVF-vh0XYxN2kcrFvfDLEg@mail.gmail.com>
Message-ID: <CAKGtyOmKsBf7mYhycjf2YHbpSVx0X6kOv8s5mwWzfMakRK7g7A@mail.gmail.com>

this post has been submitted to r-sig-finance

Galib Khan
Rutgers Business School '18
Business Analytics and Information Technology
(609) 412-3654

On Fri, Aug 17, 2018 at 2:27 PM, GALIB KHAN <ghk18 at scarletmail.rutgers.edu>
wrote:

> Sup guys,
>
> Got an interesting issue with the rugarch package.
>
> I noticed that when I changed the order of the external regressors, there
> are different values for the robust coefficient matrix. The values should
> be
> the same (according to the ordering of the variables). However, I am
> getting
> drastically different results. At that time the model was arma(2,2) +
> garch(1,0).
>
> Is this considered a normal behavior of the rugarch package? I assume that
> when you change the ordering of the external regressors the output should
> be
> exactly the same....digit by digit.
>
> I confirmed this issue by creating a generic script that can be tested by
> anyone. Has anybody faced this issue before or is there post that describes
> the issue that I am facing?
>
>   Maybe I am going insane...for now I will look further into the
> documentation that our Alexios has provided
>
> Thanks!
>   library(rugarch)
>
>
> set.seed(1)
>
> x1 <- rnorm(1000,5,1)
> x2 <- rnorm(1000,3,3)
>
> y    <- .5*(x1*x2) + rnorm(1000,1,3)
> dat  <- data.frame(x1,x2,y)
>
> var1 <- c("x1","x2")
> var2 <- c("x2","x1")
>
> # setbounds(spec)<-list(vxreg1=c(-1,1))
> model_maker <- function(x_name){
>   temp <- dat[,c("y",x_name)]
>
>   spec <- ugarchspec(variance.model      = list(model = "sGARCH",
>                                                 garchOrder = c(1,0)),
>
>                      mean.model          = list(armaOrder = c(2,2),
>                                                 external.regressors =
> as.matrix(temp[,x_name]),
>                                                 include.mean= T),
>
>                      distribution.model  = "std")
>
>   fit         <- ugarchfit(spec = spec, data = as.matrix(temp$y),solver =
> "hybrid")
>   return(fit at fit$robust.matcoef)}
>
> model_maker(var1)
> model_maker(var2)
>

	[[alternative HTML version deleted]]


From f@ridcher @ending from gm@il@com  Sat Aug 18 10:15:26 2018
From: f@ridcher @ending from gm@il@com (Faridedin Cheraghi)
Date: Sat, 18 Aug 2018 12:45:26 +0430
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <8e7ca2ae-1e7e-83f2-1d5e-a6bb780af55d@gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
 <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
 <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>
 <CAJTBV4ULDuRNuvK5pADmXjKOLKa4VxDPHAtFG_gMvH3XLe9w3w@mail.gmail.com>
 <8e7ca2ae-1e7e-83f2-1d5e-a6bb780af55d@gmail.com>
Message-ID: <CAJTBV4U2EQ89n=0nfJPmTssfRNH_+9_0Q-Tr6+=z-SWOU_CN3Q@mail.gmail.com>

Dear Duncan,

thanks again for your response.

>  I'm talking about the R Core developers.

Now it make sense. Those [R Core] are the key words that were omitted in
your original email.

> If you think this is a new bug, you should report it to the bug tracking
system (which requires you to be registered first).  Posting it to me or to
R-help will probably not result in any action on it.  Posting it to the bug
page will at least result in a fairly permanent record.

I already did. Deepayan told me to post it here first to make sure it is
"really" a bug.

Farid.

On Sat, Aug 18, 2018 at 1:27 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 17/08/2018 10:07 AM, Faridedin Cheraghi wrote:
>
>> Dear Duncan,
>>
>> thanks for your feedback on this. Even though most developers are not in
>> Windows (which I doubt it),
>>
>
> I'm talking about the R Core developers.  I used to be one, but have
> retired from that role.
>
>  there are a huge number of people who use R
>
>> on Windows and I am one of them who seriously work with R.
>>
>
> Indeed, Microsoft promotes R, and they have a lot of developers; they just
> don't contribute much to R.  Honestly I'd suggest that if you are serious
> about working with languages not supported in the default code page, you
> should switch platforms.
>
> Following my own workaround to this bug, now I hit another issue with
>> another workaround when trying to render the Farsi Unicode characters.
>> While these workarounds work in ad hoc, they are not appealing in all
>> scenarios;I hit other problems related to this bug, e.g., when documenting
>> a package with Roxygen2 package.
>>
>> Please see the attached files (r scripts) for the complete bug report.
>>
>
> If you think this is a new bug, you should report it to the bug tracking
> system (which requires you to be registered first).  Posting it to me or to
> R-help will probably not result in any action on it.  Posting it to the bug
> page will at least result in a fairly permanent record.
>
> Duncan Murdoch
>
>>
>> thanks
>> Farid
>>
>>
>> On Sun, Aug 12, 2018 at 9:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 12/08/2018 11:48 AM, Faridedin Cheraghi wrote:
>>
>>         that's right and I don't want to change my locale. my
>>         sessionInfo() :
>>
>>
>>     I think it could be another manifestation of a known bug on Windows,
>>     where strings are converted from UTF-8 to the current locale and
>>     back to UTF-8, a lossy conversion.  This has been present for many
>>     years, and requires a lot of internal changes to fix, so I wouldn't
>>     hold your breath waiting for a fix.
>>
>>     I believe the "right" fix is for R to always convert strings to
>>     UTF-8 internally.  This wasn't possible when the
>>     internationalization code was added many years ago because not all
>>     platforms supported UTF-8.  It would be a lot of work now, and since
>>     it isn't needed now on the platforms most developers use, it's not
>>     receiving a lot of attention.
>>
>>     Your workaround
>>
>>     file(script,
>>           encoding = "UTF-8") %T>%
>>           source() %>%
>>           close()   # works fine
>>
>>     is a nice way to avoid this problem.
>>
>>     Duncan Murdoch
>>
>>
>>         R version 3.5.1 (2018-07-02)
>>         Platform: x86_64-w64-mingw32/x64 (64-bit)
>>         Running under: Windows >= 8 x64 (build 9200)
>>
>>         Matrix products: default
>>
>>         locale:
>>         [1] LC_COLLATE=English_United States.1252
>>         [2] LC_CTYPE=English_United States.1252
>>         [3] LC_MONETARY=English_United States.1252
>>         [4] LC_NUMERIC=C
>>         [5] LC_TIME=English_United States.1252
>>
>>         attached base packages:
>>         [1] stats     graphics  grDevices utils     datasets  methods
>>  base
>>
>>         thanks
>>
>>         On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch
>>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>>         <mailto:murdoch.duncan at gmail.com
>>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>>
>>              On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
>>
>>                  It was actually a .rmd file so you can get the coloring
>>         of the
>>                  bug report
>>                  in your text editor. I changed the format to .txt.
>>
>>
>>              When I run your script on a Mac (in a UTF-8 locale), all
>>         lines work
>>              as expected.  I'm guessing you are working on Windows, in a
>>              non-UTF-8 locale?
>>
>>              Posting sessionInfo() would be helpful.
>>
>>              Duncan Murdoch
>>
>>
>>
>>                  -Farid
>>
>>                  On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller
>>                  <jdnewmil at dcn.davis.ca.us
>>         <mailto:jdnewmil at dcn.davis.ca.us>
>>         <mailto:jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us
>> >>>
>>                  wrote:
>>
>>                      ... and read the Posting Guide... only a few file
>>         types will
>>                      ever make it
>>                      through the mailing list so repeatedly sending
>>         files not
>>                      among those few
>>                      types would just be frustrating for everyone.
>>
>>                      On August 11, 2018 4:51:43 PM PDT, Jim Lemon
>>                      <drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>>         <mailto:drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>>>
>> wrote:
>>
>>                          Hi Farid,
>>                          Whatever you attached has not gotten through.
>>
>>                          Jim
>>
>>                          On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch
>>                          <faridcher at gmail.com
>>         <mailto:faridcher at gmail.com> <mailto:faridcher at gmail.com
>>         <mailto:faridcher at gmail.com>>> wrote:
>>
>>                              Hi all,
>>
>>                              Please check the attached file.
>>
>>                              Thanks
>>                              Farid
>>
>>
>>                              ______________________________
>> ________________
>>         R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>                              mailing list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                                     <https://stat.ethz.ch/mailman/
>> listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>                              PLEASE do read the posting guide
>>
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>                          <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>
>>                              and provide commented, minimal,
>> self-contained,
>>                              reproducible code.
>>
>>
>>                          ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>                          mailing list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                          <https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>                          PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>                          <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>                          and provide commented, minimal, self-contained,
>>                          reproducible code.
>>
>>
>>                      --
>>                      Sent from my phone. Please excuse my brevity.
>>
>>
>>
>>                      ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>> mailing
>>                      list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                      <https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>                      PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>                      <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>                      and provide commented, minimal, self-contained,
>>         reproducible
>>                      code.
>>
>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Sat Aug 18 10:45:51 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sat, 18 Aug 2018 18:45:51 +1000
Subject: [R] bar plot add space to group data
In-Reply-To: <0283514711d8183ac79b865fd07f041d@disroot.org>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
Message-ID: <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>

Hi citc,
Try this:

geac<-matrix(c(9,9,8,8,8,23,23,23,23,22,27,27,27,25,24,
 19,19,19,20,20,17,17,17,18,19,8,8,8,9,9,2,2,3,3,3),ncol=5,byrow=TRUE)
library(plotrix)
barp(geac,names.arg=2014:2018,main="A level grades chemistry",
 xlab="Year",ylab="Percentage of each grade",ylim=c(0,30),
 col=c("white","lightblue","blue","orange","green","red","pink"))

Jim

On Fri, Aug 17, 2018 at 9:55 PM,  <citc at disroot.org> wrote:
> R-users,
>
> Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.
>
> barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
> years<-c(2014,2015,2016,2017,2018)
> mtext(years, side=1, at=c(5, 12, 19, 26, 33))
> R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@lgd @ending from gm@il@com  Sat Aug 18 10:47:19 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Sat, 18 Aug 2018 10:47:19 +0200
Subject: [R] How to rotate label in tcltk R
In-Reply-To: <9d0c17f29c10498e8fa4eb7c0499aacd@uwaterloo.ca>
References: <9d0c17f29c10498e8fa4eb7c0499aacd@uwaterloo.ca>
Message-ID: <A232D4DB-8987-4C5D-AD8B-2395D9D8F96D@gmail.com>

I don't think labels as such can be rotated. Newer versions of Tk allows rotation in canvases but this was implemented some years after the tcltk package was developed, so some assembly may be required. If you can extrapolate from Python, there may be some relevant ideas in this post:

https://stackoverflow.com/questions/38008389/is-it-possible-to-have-a-vertical-oriented-button-in-tkinter

> On 17 Aug 2018, at 23:32 , Zehao Xu <z267xu at uwaterloo.ca> wrote:
> 
> Dear sir (ma'am)
> 
> I just start the tcltk in R. I face a problem, how to rotate the labels in tcltk? I post the example on https://stackoverflow.com/questions/51825771/how-to-rotate-labels-in-tcltk.
> 
> 
> Thank you
> 
> Z Xu
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd@lgd @ending from gm@il@com  Sat Aug 18 11:05:52 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Sat, 18 Aug 2018 11:05:52 +0200
Subject: [R] Understanding read.csv error message
In-Reply-To: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
Message-ID: <23F65233-CFA9-4A6C-B818-79D315B56FF7@gmail.com>

What Don said, and also notice that the error is not about anything having value 0, it is about replacing something with something of _length_ 0. It is not obvious where that happens, sometimes a traceback() can give a clue, but probably Don is right that the issue is that there is something not quite CSV in the file. 

One further idea is to read using colClasses="character" and see if that actually gives you 6 columns and then afterwards try and convert each column to the appropriate type.

-pd

> On 18 Aug 2018, at 00:08 , Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I have a data file, 'precip_projected.csv,' that starts like this:
> 
> name,easting,northing,elev,sampdate,prcp
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02
> 
>  There are a bunch of NAs in the data file.
> 
>  The command to read it produces an error:
> 
> rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)
> 
> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>  replacement has 0 rows, data has 113569
> 
>  Is the error generated by finding a date that looks like the number zero
> or by a prcp value of zero?
> 
>  BTW, I get the same error if I specify stringsAsFactors = F.
> 
> TIA,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From btupper @ending from bigelow@org  Sat Aug 18 14:00:16 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Sat, 18 Aug 2018 08:00:16 -0400
Subject: [R] Understanding read.csv error message
In-Reply-To: <23F65233-CFA9-4A6C-B818-79D315B56FF7@gmail.com>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
 <23F65233-CFA9-4A6C-B818-79D315B56FF7@gmail.com>
Message-ID: <78649DDA-F9EB-4A83-B8F5-F324394CD8E0@bigelow.org>

Hi,

I would be tempted, as a start, to read the entire file in as rows of text, split each line by the expected delimiter, and then count the number of elements each split line yields.  Once you know each row splits into the expected number of 

txt <- "name,easting,northing,elev,sampdate,prcp
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02"

txtCon <- textConnection(txt)
x <- readLines(txtCon)
close(txtCon)

n <- sapply(strsplit(x, ",", fixed = TRUE), length)
table(n)

If any have a different length then investigate that/those line(s).  If they all have the same length then it likely isn't about the delimiter.

Cheers,
Ben


 
> On Aug 18, 2018, at 5:05 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> What Don said, and also notice that the error is not about anything having value 0, it is about replacing something with something of _length_ 0. It is not obvious where that happens, sometimes a traceback() can give a clue, but probably Don is right that the issue is that there is something not quite CSV in the file. 
> 
> One further idea is to read using colClasses="character" and see if that actually gives you 6 columns and then afterwards try and convert each column to the appropriate type.
> 
> -pd
> 
>> On 18 Aug 2018, at 00:08 , Rich Shepard <rshepard at appl-ecosys.com> wrote:
>> 
>> I have a data file, 'precip_projected.csv,' that starts like this:
>> 
>> name,easting,northing,elev,sampdate,prcp
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02
>> 
>> There are a bunch of NAs in the data file.
>> 
>> The command to read it produces an error:
>> 
>> rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)
>> 
>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>> replacement has 0 rows, data has 113569
>> 
>> Is the error generated by finding a date that looks like the number zero
>> or by a prcp value of zero?
>> 
>> BTW, I get the same error if I specify stringsAsFactors = F.
>> 
>> TIA,
>> 
>> Rich
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Sat Aug 18 17:00:00 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sat, 18 Aug 2018 08:00:00 -0700 (PDT)
Subject: [R] Understanding read.csv error message [FIXED]
In-Reply-To: <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
 <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>
Message-ID: <alpine.LNX.2.20.1808180755290.21447@salmo.appl-ecosys.com>

On Sat, 18 Aug 2018, MacQueen, Don wrote:

> It's not obvious what would be causing that error from read.csv. But
> here's what I would probably try:

> I'd try switching to the more general read.table.

Don/Peter,

   I found the problem: it was in the following line in the script which
referenced 'date' rather than 'sampdate'.

   Single or double quotes make no difference within the script.

   I have a vague recollection from long ago that read.table() is a better
choice than read.csv(). I don't recall the details why, but I did change the
function to read.table(), fixed the column name, and have only the labeling
of the xyploy() left to fix.

Thanks very much, both of you,

Rich


From reichm@nj @ending from @bcglob@l@net  Sat Aug 18 23:20:19 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Sat, 18 Aug 2018 16:20:19 -0500
Subject: [R] Converting chr to num
Message-ID: <000001d43739$450cb030$cf261090$@sbcglobal.net>

R-Help Forum

 

How do I convert a chr variable that contains percentages to an integer

 

Example 12.6% (chr) to 12.6 (int)

 

Jeff


	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Sat Aug 18 23:32:41 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sat, 18 Aug 2018 22:32:41 +0100
Subject: [R] Converting chr to num
In-Reply-To: <000001d43739$450cb030$cf261090$@sbcglobal.net>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
Message-ID: <f12cc9f8-b96d-513e-e356-f16881fdf036@sapo.pt>

Hello,

You have to get rid of the percent sign first. This can be done with ?sub

x <- "12.6%"
y <- sub("%$", "", x)
z <- as.numeric(y)

1) The dollar sign means "end of string". See ?regexpr.
2) You can all of that in one code line, no need to create y.

z <- as.numeric(sub("%$", "", x))


Hope this helps,

Rui Barradas

On 18/08/2018 22:20, Jeff Reichman wrote:
> R-Help Forum
> 
>   
> 
> How do I convert a chr variable that contains percentages to an integer
> 
>   
> 
> Example 12.6% (chr) to 12.6 (int)
> 
>   
> 
> Jeff
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com


From reichm@nj @ending from @bcglob@l@net  Sun Aug 19 00:02:53 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Sat, 18 Aug 2018 17:02:53 -0500
Subject: [R] Converting chr to num
In-Reply-To: <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
Message-ID: <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>

Given it?s a variable would I just change the 12.6 in as.numeric(gsub(pattern = "%","","12.6%"))

To the variable name say ? as.numeric(gsub(pattern = "%","",df$variable))

 

 

From: GALIB KHAN <ghk18 at scarletmail.rutgers.edu> 
Sent: Saturday, August 18, 2018 4:23 PM
To: reichmanj at sbcglobal.net
Cc: r-help at r-project.org
Subject: Re: [R] Converting chr to num

 

Hey there,

 

as.numeric(gsub(pattern = "%","","12.6%"))

 

On Sat, Aug 18, 2018 at 4:20 PM, Jeff Reichman <reichmanj at sbcglobal.net <mailto:reichmanj at sbcglobal.net> > wrote:

R-Help Forum



How do I convert a chr variable that contains percentages to an integer



Example 12.6% (chr) to 12.6 (int)



Jeff


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sun Aug 19 00:52:15 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 18 Aug 2018 15:52:15 -0700
Subject: [R] Converting chr to num
In-Reply-To: <000001d43739$450cb030$cf261090$@sbcglobal.net>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
Message-ID: <CAGxFJbQ9DS_0a3bTNLO9LO4RPNzaA4BVsaiV-jCzHkYw-jybLQ@mail.gmail.com>

ummmm.... 12.6 is not an integer.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 18, 2018 at 2:20 PM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-Help Forum
>
>
>
> How do I convert a chr variable that contains percentages to an integer
>
>
>
> Example 12.6% (chr) to 12.6 (int)
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ghk18 @ending from @c@rletm@il@rutger@@edu  Sat Aug 18 23:22:36 2018
From: ghk18 @ending from @c@rletm@il@rutger@@edu (GALIB KHAN)
Date: Sat, 18 Aug 2018 16:22:36 -0500
Subject: [R] Converting chr to num
In-Reply-To: <000001d43739$450cb030$cf261090$@sbcglobal.net>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
Message-ID: <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>

Hey there,

as.numeric(gsub(pattern = "%","","12.6%"))

On Sat, Aug 18, 2018 at 4:20 PM, Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-Help Forum
>
>
>
> How do I convert a chr variable that contains percentages to an integer
>
>
>
> Example 12.6% (chr) to 12.6 (int)
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ghk18 @ending from @c@rletm@il@rutger@@edu  Sun Aug 19 00:08:21 2018
From: ghk18 @ending from @c@rletm@il@rutger@@edu (GALIB KHAN)
Date: Sat, 18 Aug 2018 17:08:21 -0500
Subject: [R] Converting chr to num
In-Reply-To: <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
Message-ID: <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>

So running the code in my head....as long as that column's data type is a
vector of characters then it should work.


Did you try it out?

On Sat, Aug 18, 2018, 5:02 PM Jeff Reichman <reichmanj at sbcglobal.net> wrote:

> Given it?s a variable would I just change the 12.6 in
> as.numeric(gsub(pattern = "%","","12.6%"))
>
> To the variable name say ? as.numeric(gsub(pattern = "%","",df$variable))
>
>
>
>
>
> *From:* GALIB KHAN <ghk18 at scarletmail.rutgers.edu>
> *Sent:* Saturday, August 18, 2018 4:23 PM
> *To:* reichmanj at sbcglobal.net
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] Converting chr to num
>
>
>
> Hey there,
>
>
>
> as.numeric(gsub(pattern = "%","","12.6%"))
>
>
>
> On Sat, Aug 18, 2018 at 4:20 PM, Jeff Reichman <reichmanj at sbcglobal.net>
> wrote:
>
> R-Help Forum
>
>
>
> How do I convert a chr variable that contains percentages to an integer
>
>
>
> Example 12.6% (chr) to 12.6 (int)
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Sun Aug 19 01:52:50 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 19 Aug 2018 11:52:50 +1200
Subject: [R] [FORGED] Re:  bar plot add space to group data
In-Reply-To: <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
Message-ID: <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>


Jim:

(a) There's no legend.

(b) I am still curious as to why the OP's code didn't work, in that
the "space=c(0,2)" argument seemed to have no effect.

cheers,

Rolf

On 18/08/18 20:45, Jim Lemon wrote:
> Hi citc,
> Try this:
> 
> geac<-matrix(c(9,9,8,8,8,23,23,23,23,22,27,27,27,25,24,
>   19,19,19,20,20,17,17,17,18,19,8,8,8,9,9,2,2,3,3,3),ncol=5,byrow=TRUE)
> library(plotrix)
> barp(geac,names.arg=2014:2018,main="A level grades chemistry",
>   xlab="Year",ylab="Percentage of each grade",ylim=c(0,30),
>   col=c("white","lightblue","blue","orange","green","red","pink"))
> 
> Jim
> 
> On Fri, Aug 17, 2018 at 9:55 PM,  <citc at disroot.org> wrote:
>> R-users,
>>
>> Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.
>>
>> barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
>> years<-c(2014,2015,2016,2017,2018)
>> mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>> R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))


From drjimlemon @ending from gm@il@com  Sun Aug 19 06:12:35 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sun, 19 Aug 2018 14:12:35 +1000
Subject: [R] [FORGED] Re:  bar plot add space to group data
In-Reply-To: <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
Message-ID: <CA+8X3fVTeJx6szP8DqdGOuKKitN+g8uQGadwzgo2Vz-=Cs9Q9Q@mail.gmail.com>

Hi Rolf,
That's what comes of being in a hurry.

legend(4.1,30,c("A+","A","B","C","D","E","U"),
 fill=c("white","lightblue","blue","orange","green","red","pink"))

and I thank you for alerting me to the fact that the legend arguments
in barp don't position the legend properly. I'll fix it.

Jim


On Sun, Aug 19, 2018 at 9:52 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> Jim:
>
> (a) There's no legend.
>
> (b) I am still curious as to why the OP's code didn't work, in that
> the "space=c(0,2)" argument seemed to have no effect.
>
> cheers,
>
> Rolf
>
> On 18/08/18 20:45, Jim Lemon wrote:
>>
>> Hi citc,
>> Try this:
>>
>> geac<-matrix(c(9,9,8,8,8,23,23,23,23,22,27,27,27,25,24,
>>   19,19,19,20,20,17,17,17,18,19,8,8,8,9,9,2,2,3,3,3),ncol=5,byrow=TRUE)
>> library(plotrix)
>> barp(geac,names.arg=2014:2018,main="A level grades chemistry",
>>   xlab="Year",ylab="Percentage of each grade",ylim=c(0,30),
>>   col=c("white","lightblue","blue","orange","green","red","pink"))
>>
>> Jim
>>
>> On Fri, Aug 17, 2018 at 9:55 PM,  <citc at disroot.org> wrote:
>>>
>>> R-users,
>>>
>>> Can someone please advise how to improve the code below that was used to
>>> produce the graph shown at the following hyperlink
>>> (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The
>>> request is to add space between the annual data groups.
>>>
>>> barplot(gceac[,3], xlab='year', ylab='percentage of each grade',
>>> col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen',
>>> 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y =
>>> 30, title='grades'), main='A-level grades, chemistry', beside=T,
>>> space=c(0,2), ylim=c(0,30))
>>> years<-c(2014,2015,2016,2017,2018)
>>> mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>>> R-users, Can someone please advise how to improve the code below that was
>>> used to produce the graph shown at the following hyperlink
>>> (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The
>>> request is to add space between the annual data groups.  barplot(gceac[,3],
>>> xlab='year', ylab='percentage of each grade', col=c('aliceblue',
>>> 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'),
>>> legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'),
>>> main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
>>> years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26,
>>> 33))


From peter@l@ngfelder @ending from gm@il@com  Sun Aug 19 06:58:04 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Sat, 18 Aug 2018 21:58:04 -0700
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
Message-ID: <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>

My guess is that space has no effect because (1) the first element is
zero and (2) the code in OP's message has
barplot(gceac[,3], ...

i.e. barplot does not see a matrix, only a vector.

To the OP, try formatting the data to be plotted as a matrix, not as a
vector, then the space argument should be useful to add space between
groups.

Peter


On Sat, Aug 18, 2018 at 4:53 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Jim:
>
> (a) There's no legend.
>
> (b) I am still curious as to why the OP's code didn't work, in that
> the "space=c(0,2)" argument seemed to have no effect.
>
> cheers,
>
> Rolf
>
> On 18/08/18 20:45, Jim Lemon wrote:
> > Hi citc,
> > Try this:
> >
> > geac<-matrix(c(9,9,8,8,8,23,23,23,23,22,27,27,27,25,24,
> >   19,19,19,20,20,17,17,17,18,19,8,8,8,9,9,2,2,3,3,3),ncol=5,byrow=TRUE)
> > library(plotrix)
> > barp(geac,names.arg=2014:2018,main="A level grades chemistry",
> >   xlab="Year",ylab="Percentage of each grade",ylim=c(0,30),
> >   col=c("white","lightblue","blue","orange","green","red","pink"))
> >
> > Jim
> >
> > On Fri, Aug 17, 2018 at 9:55 PM,  <citc at disroot.org> wrote:
> >> R-users,
> >>
> >> Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.
> >>
> >> barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
> >> years<-c(2014,2015,2016,2017,2018)
> >> mtext(years, side=1, at=c(5, 12, 19, 26, 33))
> >> R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipb@rr@d@@ @ending from @@po@pt  Sun Aug 19 07:06:23 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sun, 19 Aug 2018 06:06:23 +0100
Subject: [R] Converting chr to num
In-Reply-To: <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
 <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
Message-ID: <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>

Hello,

It also works with class "factor":

df <- data.frame(variable = c("12.6%", "30.9%", "61.4%"))
class(df$variable)
#[1] "factor"

as.numeric(gsub(pattern = "%", "", df$variable))
#[1] 12.6 30.9 61.4


This is because sub() and gsub() return a character vector and the 
instruction becomes an equivalent of what the help page ?factor 
documents in section Warning:

To transform a factor f to approximately its original numeric values, 
as.numeric(levels(f))[f] is recommended and slightly more efficient than 
as.numeric(as.character(f)).


Also, I would still prefer

as.numeric(sub(pattern = "%$","",df$variable))
#[1] 12.6 30.9 61.4

The pattern is more strict and there is no need to search&replace 
multiple occurrences of '%'.



Hope this helps,

Rui Barradas

On 18/08/2018 23:08, GALIB KHAN wrote:
> So running the code in my head....as long as that column's data type is a
> vector of characters then it should work.
> 
> 
> Did you try it out?
> 
> On Sat, Aug 18, 2018, 5:02 PM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> 
>> Given it?s a variable would I just change the 12.6 in
>> as.numeric(gsub(pattern = "%","","12.6%"))
>>
>> To the variable name say ? as.numeric(gsub(pattern = "%","",df$variable))
>>
>>
>>
>>
>>
>> *From:* GALIB KHAN <ghk18 at scarletmail.rutgers.edu>
>> *Sent:* Saturday, August 18, 2018 4:23 PM
>> *To:* reichmanj at sbcglobal.net
>> *Cc:* r-help at r-project.org
>> *Subject:* Re: [R] Converting chr to num
>>
>>
>>
>> Hey there,
>>
>>
>>
>> as.numeric(gsub(pattern = "%","","12.6%"))
>>
>>
>>
>> On Sat, Aug 18, 2018 at 4:20 PM, Jeff Reichman <reichmanj at sbcglobal.net>
>> wrote:
>>
>> R-Help Forum
>>
>>
>>
>> How do I convert a chr variable that contains percentages to an integer
>>
>>
>>
>> Example 12.6% (chr) to 12.6 (int)
>>
>>
>>
>> Jeff
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com


From r@turner @ending from @uckl@nd@@c@nz  Sun Aug 19 07:06:50 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 19 Aug 2018 17:06:50 +1200
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
 <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
Message-ID: <708a6692-61d2-8554-07a4-5d780b33e130@auckland.ac.nz>


On 19/08/18 16:58, Peter Langfelder wrote:

> My guess is that space has no effect because (1) the first element is
> zero and (2) the code in OP's message has
> barplot(gceac[,3], ...
> 
> i.e. barplot does not see a matrix, only a vector.
> 
> To the OP, try formatting the data to be plotted as a matrix, not as a
> vector, then the space argument should be useful to add space between
> groups.

Thanks Peter.  That would appear to be a sound analysis.  Thanks for the 
insight.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @ending from @uckl@nd@@c@nz  Sun Aug 19 07:08:30 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 19 Aug 2018 17:08:30 +1200
Subject: [R] [FORGED] Re:  bar plot add space to group data
In-Reply-To: <CA+8X3fVTeJx6szP8DqdGOuKKitN+g8uQGadwzgo2Vz-=Cs9Q9Q@mail.gmail.com>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
 <CA+8X3fVTeJx6szP8DqdGOuKKitN+g8uQGadwzgo2Vz-=Cs9Q9Q@mail.gmail.com>
Message-ID: <c4c86059-c912-c929-89fc-430742c769e2@auckland.ac.nz>

On 19/08/18 16:12, Jim Lemon wrote:
> Hi Rolf,
> That's what comes of being in a hurry.
> 
> legend(4.1,30,c("A+","A","B","C","D","E","U"),
>   fill=c("white","lightblue","blue","orange","green","red","pink"))
> 
> and I thank you for alerting me to the fact that the legend arguments
> in barp don't position the legend properly. I'll fix it.

And I wasn't even aware that I was doing any alerting! :-)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From citc m@ili@g off disroot@org  Sun Aug 19 16:12:55 2018
From: citc m@ili@g off disroot@org (citc m@ili@g off disroot@org)
Date: Sun, 19 Aug 2018 14:12:55 +0000
Subject: [R] bar plot add space to group data
In-Reply-To: <56e7fda9-284c-b16c-e3e5-f8460c34747c@auckland.ac.nz>
References: <56e7fda9-284c-b16c-e3e5-f8460c34747c@auckland.ac.nz>
 <0283514711d8183ac79b865fd07f041d@disroot.org>
 <ef12bce1db1c412e8c02a2b6e26c879e@tamu.edu>
Message-ID: <9f8092b4050c440332652a2a0726ec22@disroot.org>

August 17, 2018 10:24 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:

> On 18/08/18 02:37, David L Carlson wrote:
> 
>> Notice below that your message is substantially scrambled. R-Help is a
>> plain text only list so you should set your email client to produce plain text messages.

Apologies, forgot to change the default settings of the web-mail.

> 
> If one struggles through the garbled html bumff, one sees that the OP *did* indeed use the "space="
> argument. However it does not appear to have had the desired effect, and I cannot see why. Since
> the OP did not supply the data, I cannot experiment.
>

csv data below:

year,grade,percentage
2014,A*,9
2014,A,23
2014,B,27
2014,C,19
2014,D,13
2014,E,7
2014,U,2
2015,A*,9
2015,A,23
2015,B,27
2015,C,19
2015,D,13
2015,E,7
2015,U,2
2016,A*,8
2016,A,23
2016,B,27
2016,C,19
2016,D,13
2016,E,7
2016,U,3
2017,A*,8
2017,A,23
2017,B,24
2017,C,20
2017,D,14
2017,E,8
2017,U,3
2018,A*,8
2018,A,22
2018,B,23
2018,C,20
2018,D,15
2018,E,8
2018,U,3


From citc m@ili@g off disroot@org  Sun Aug 19 16:15:20 2018
From: citc m@ili@g off disroot@org (citc m@ili@g off disroot@org)
Date: Sun, 19 Aug 2018 14:15:20 +0000
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
References: <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
 <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
Message-ID: <f8f036333a82d6544d3be71e9436d160@disroot.org>

August 19, 2018 4:58 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:

> To the OP, try formatting the data to be plotted as a matrix, not as a
> vector

CSV data provided in a previous message; is not the data formatted as a matrix?


From peter@l@ngfelder @ending from gm@il@com  Sun Aug 19 17:51:13 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Sun, 19 Aug 2018 08:51:13 -0700
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <f8f036333a82d6544d3be71e9436d160@disroot.org>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
 <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
 <f8f036333a82d6544d3be71e9436d160@disroot.org>
Message-ID: <CA+hbrhVs31LSDMAErgAX5pHWSOC3Xy3WB10_aJ5ue3wk40SRZQ@mail.gmail.com>

On Sun, Aug 19, 2018 at 7:15 AM <citc at disroot.org> wrote:
>
> August 19, 2018 4:58 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:
>
> > To the OP, try formatting the data to be plotted as a matrix, not as a
> > vector
>
> CSV data provided in a previous message; is not the data formatted as a matrix?

I meant the data you give to barplot - your code supplies only the
third column of the data frame, so barplot only sees a vector. I would
try something like

plotData = do.call(cbind, tapply(csv.data$percentage, csv.data$year, identity))

barplot(plotData, <rest of your argument>)

Peter


From j@kperik@dioggb@n @ending from @tudent@@jku@t@@c@ke  Sun Aug 19 18:33:02 2018
From: j@kperik@dioggb@n @ending from @tudent@@jku@t@@c@ke (Dioggban Jakperik)
Date: Sun, 19 Aug 2018 19:33:02 +0300
Subject: [R] Computing the density of a median
Message-ID: <CANbn+9CL7zgn9Xnui43pEYYkPaAB030fkQCGP7UM_CaFR6SywQ@mail.gmail.com>

I have the following function

kdenor <- function(aa,q=NULL){
a=sample(aa,500,replace=F)
ab=quantile(a, p=0.75)-quantile(a, p=0.25)
h=(0.9*min(var(a),ab))/(1.34*n^(1/5))

if(is.null(q)) {
q = seq(min(a)-3*h, max(a)+3*h, length.out=length(a))
}
nx = length(a)
nq = length(q)
xmat = matrix(q,nq,nx) - matrix(a,nq,nx,byrow=TRUE)
denall= dnorm(xmat/h)/h
denhat = apply(denall,1,mean)

f<-denhat
f1<-median(f)
#das<-list(x=q, y=denhat, h=h)
#return(das)
}

f1<-kdenor(aa)

My interest is to obtain the estimate of the density at the median of the
sample data.
But the output of the current function  doesn't provide the correct result.
Kindly help.
Regards.


-- 
Jakperik Dioggban (Student, PAUISTI)
PhD Mathematics (Statistics Option)
Determination is Key to Success

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Sun Aug 19 20:10:29 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Sun, 19 Aug 2018 18:10:29 +0000
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <CA+hbrhVs31LSDMAErgAX5pHWSOC3Xy3WB10_aJ5ue3wk40SRZQ@mail.gmail.com>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
 <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
 <f8f036333a82d6544d3be71e9436d160@disroot.org>
 <CA+hbrhVs31LSDMAErgAX5pHWSOC3Xy3WB10_aJ5ue3wk40SRZQ@mail.gmail.com>
Message-ID: <6804ee0d924644fd83f9e6e7b0cdd2e7@tamu.edu>

Actually the data you provided are a data frame and not a matrix as R uses the term. Two columns of gceac are numeric and one is a factor. If we read your data with read.csv() we get:

> str(gceac)
'data.frame':   35 obs. of  3 variables:
 $ year      : int  2014 2014 2014 2014 2014 2014 2014 2015 2015 2015 ...
 $ grade     : Factor w/ 7 levels "A","A*","B","C",..: 2 1 3 4 5 6 7 2 1 3 ...
 $ percentage: int  9 23 27 19 13 7 2 9 23 27 ...

Now we see problem in grade column. Your plot has A* before A, but the factor is created alphabetically so A comes before A*. We can fix that

> gceac$grade <- factor(gceac$grade, levels=c("A*", "A", "B", "C", "D",
     "E", "U"))

> levels(gceac$grade)
[1] "A*" "A"  "B"  "C"  "D"  "E"  "U"

Now you need a matrix for the barplot. That is simple with xtabs()

> gceac.mat <- xtabs(percentage~grade+year, gceac)
> gceac.mat
     year
grade 2014 2015 2016 2017 2018
   A*    9    9    8    8    8
   A    23   23   23   23   22
   B    27   27   27   24   23
   C    19   19   19   20   20
   D    13   13   13   14   15
   E     7    7    7    8    8
   U     2    2    3    3    3

Now we can build your bar plot using almost the same command you used:

> clrs <- c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 
+      'firebrick', 'violet')
> barplot(gceac.mat, xlab='year', ylab='percentage of each grade', 
+      col=clrs, legend=TRUE, args.legend = list("topright",
+      title='grades'), main='A-level grades, chemistry', beside=T,
+      space=c(0, 1), ylim=c(0,35))

I defined clrs so that the barplot() function would be easier to read, but it works the same your way. Now we just need legend=TRUE and we can position the legend in the top right with the args.legend= argument. The legend overlaps the bars a bit so I increased the y-axis to 35. A .png file is attached.


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Langfelder
Sent: Sunday, August 19, 2018 10:51 AM
To: citc at disroot.org
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] [FORGED] Re: bar plot add space to group data

On Sun, Aug 19, 2018 at 7:15 AM <citc at disroot.org> wrote:
>
> August 19, 2018 4:58 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:
>
> > To the OP, try formatting the data to be plotted as a matrix, not as a
> > vector
>
> CSV data provided in a previous message; is not the data formatted as a matrix?

I meant the data you give to barplot - your code supplies only the
third column of the data frame, so barplot only sees a vector. I would
try something like

plotData = do.call(cbind, tapply(csv.data$percentage, csv.data$year, identity))

barplot(plotData, <rest of your argument>)

Peter

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: BarPlot.png
Type: image/png
Size: 8565 bytes
Desc: BarPlot.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180819/784c7f8c/attachment.png>

From @pbr@ckett20 @ending from @@intjo@ephh@@com  Sun Aug 19 21:11:44 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Sun, 19 Aug 2018 15:11:44 -0400
Subject: [R] Request for R Assistance: Downloading Data
Message-ID: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>

 Good evening,

  I am attempting to download Genomic data from the GDC onto R for analysis
and am experiencing some difficulty. I have downloaded the GDC data into an
Excel, CSV, and notepad (.txt) file and implemented what I believe to be
the proper arguments, with every attempting failing to properly load the
data onto R. The following is the various attempts I made in trying to take
one of these files (a translated version of the GDC data) and load it into R
.

> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?LGG Drug (CSV).csv? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
(CSV).csv",header=TRUE,sep=",")
Error: unexpected symbol in "LGG Drug"
> LGG Drug<-read.table("C:
Error: unexpected symbol in "LGG Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in " GBM Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
:
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
wrap).txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"

Any insight into what perhaps I am inputting that is causes this
reoccurring error? Any suggestions as to another procedure for moving
forward would be greatly appreciated!

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Sun Aug 19 21:19:06 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sun, 19 Aug 2018 12:19:06 -0700 (PDT)
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808191214080.8446@salmo.appl-ecosys.com>

On Sun, 19 Aug 2018, Spencer Brackett wrote:

> I am attempting to download Genomic data from the GDC onto R for analysis
> and am experiencing some difficulty. I have downloaded the GDC data into an
> Excel, CSV, and notepad (.txt) file and implemented what I believe to be
> the proper arguments, with every attempting failing to properly load the
> data onto R.

Spencer,

   Looks like you want to read the data into an R dataframe; I assume that's
the format for geonomic data as it is for environmental data.

>> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")

   Instead, try

mydata <- read.csv("lgg_drug.csv", header = TRUE, stringsAsFactors = FALSE)

Note: this assumes the data file has column headers. And, you can use your
.txt file with the read.table() function.

> Any insight into what perhaps I am inputting that is causes this
> reoccurring error? Any suggestions as to another procedure for moving
> forward would be greatly appreciated!

   How much about R have you read/learned? Taking a couple of steps back
might be well worth your while.

Regards,

Rich


From dc@rl@on @ending from t@mu@edu  Sun Aug 19 21:20:13 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Sun, 19 Aug 2018 19:20:13 +0000
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
Message-ID: <3534f9ed7ba44c40a0051579f78898ed@tamu.edu>

The load() function is only used for binary files that R creates with the save() function.

You are trying to assign the data to an object (variable) called LGG Drug. R does not allow spaces in variable names. You could try LGGDrug, LGG_Drug, or LGG.Drug. Same issue with GBM Drug. 

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Spencer Brackett
Sent: Sunday, August 19, 2018 2:12 PM
To: r-help at r-project.org
Subject: [R] Request for R Assistance: Downloading Data

 Good evening,

  I am attempting to download Genomic data from the GDC onto R for analysis
and am experiencing some difficulty. I have downloaded the GDC data into an
Excel, CSV, and notepad (.txt) file and implemented what I believe to be
the proper arguments, with every attempting failing to properly load the
data onto R. The following is the various attempts I made in trying to take
one of these files (a translated version of the GDC data) and load it into R
.

> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?LGG Drug (CSV).csv? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
(CSV).csv",header=TRUE,sep=",")
Error: unexpected symbol in "LGG Drug"
> LGG Drug<-read.table("C:
Error: unexpected symbol in "LGG Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in " GBM Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
:
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
wrap).txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"

Any insight into what perhaps I am inputting that is causes this
reoccurring error? Any suggestions as to another procedure for moving
forward would be greatly appreciated!

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From j@p@rk4 @ending from uic@edu  Sun Aug 19 21:16:14 2018
From: j@p@rk4 @ending from uic@edu (Sparks, John)
Date: Sun, 19 Aug 2018 19:16:14 +0000
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
Message-ID: <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>

Just a hunch, but I would recommend simplifying your filename:  remove the (CSV) portion.  It could be confusing in R read syntax.  Create a filename with no unnecessary punctuation and no blank spaces.


--John Sparks


________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Spencer Brackett <spbrackett20 at saintjosephhs.com>
Sent: Sunday, August 19, 2018 2:11 PM
To: r-help at r-project.org
Subject: [R] Request for R Assistance: Downloading Data

Good evening,

  I am attempting to download Genomic data from the GDC onto R for analysis
and am experiencing some difficulty. I have downloaded the GDC data into an
Excel, CSV, and notepad (.txt) file and implemented what I believe to be
the proper arguments, with every attempting failing to properly load the
data onto R. The following is the various attempts I made in trying to take
one of these files (a translated version of the GDC data) and load it into R
.

> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?LGG Drug (CSV).csv? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
(CSV).csv",header=TRUE,sep=",")
Error: unexpected symbol in "LGG Drug"
> LGG Drug<-read.table("C:
Error: unexpected symbol in "LGG Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in " GBM Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
:
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
wrap).txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"

Any insight into what perhaps I am inputting that is causes this
reoccurring error? Any suggestions as to another procedure for moving
forward would be greatly appreciated!

Many thanks,

Spencer Brackett

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
R-help -- Main R Mailing List: Primary help - Homepage - SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R, enhancements and patches to the source code and documentation of R, comparison and compatibility with S and S-plus, and for the posting of nice examples and benchmarks.



PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From erinm@hodge@@ @ending from gm@il@com  Sun Aug 19 22:28:49 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Sun, 19 Aug 2018 14:28:49 -0600
Subject: [R] learning tidyverse
Message-ID: <CACxE24nvUsjcxVcL7E26MUAmB3Fv1mRYNV-31oEXwOXOGxX0Ng@mail.gmail.com>

Hello everyone!

Could anyone recommend a good way to learn about tidyverse, please?  Is
there a book, please?

Thanks,
Erin



Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From i@t@z@hn @ending from gm@il@com  Sun Aug 19 22:41:59 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Sun, 19 Aug 2018 16:41:59 -0400
Subject: [R] learning tidyverse
In-Reply-To: <CACxE24nvUsjcxVcL7E26MUAmB3Fv1mRYNV-31oEXwOXOGxX0Ng@mail.gmail.com>
References: <CACxE24nvUsjcxVcL7E26MUAmB3Fv1mRYNV-31oEXwOXOGxX0Ng@mail.gmail.com>
Message-ID: <CA+vqiLFVSocCjo77qY+zf58ZXD9_11ApN9E5Z5CK1vpmMT6b+w@mail.gmail.com>

https://www.tidyverse.org/learn/
On Sun, Aug 19, 2018 at 4:29 PM Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> Hello everyone!
>
> Could anyone recommend a good way to learn about tidyverse, please?  Is
> there a book, please?
>
> Thanks,
> Erin
>
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm@hodge@@ @ending from gm@il@com  Sun Aug 19 22:43:38 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Sun, 19 Aug 2018 14:43:38 -0600
Subject: [R] learning tidyverse
In-Reply-To: <CA+vqiLFVSocCjo77qY+zf58ZXD9_11ApN9E5Z5CK1vpmMT6b+w@mail.gmail.com>
References: <CACxE24nvUsjcxVcL7E26MUAmB3Fv1mRYNV-31oEXwOXOGxX0Ng@mail.gmail.com>
 <CA+vqiLFVSocCjo77qY+zf58ZXD9_11ApN9E5Z5CK1vpmMT6b+w@mail.gmail.com>
Message-ID: <CACxE24nhaCCt6kUuPiU8y+NV4LEcXuC4F6DAN4vJZNm9hsmT5w@mail.gmail.com>

Thanks so much!!!!

e

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Sun, Aug 19, 2018 at 2:42 PM Ista Zahn <istazahn at gmail.com> wrote:

> https://www.tidyverse.org/learn/
> On Sun, Aug 19, 2018 at 4:29 PM Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >
> > Hello everyone!
> >
> > Could anyone recommend a good way to learn about tidyverse, please?  Is
> > there a book, please?
> >
> > Thanks,
> > Erin
> >
> >
> >
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From philipsm m@ili@g off cp@@el1@stormweb@@et  Sun Aug 19 23:20:29 2018
From: philipsm m@ili@g off cp@@el1@stormweb@@et (philipsm m@ili@g off cp@@el1@stormweb@@et)
Date: Sun, 19 Aug 2018 17:20:29 -0400
Subject: [R] as.Date() function
Message-ID: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>

I am having trouble with what must be a very simple problem. Here is a  
reproducible example:

library(lubridate)
st <- c("1961-01","1961-04","1983-02")
print(st)
#[1] "1961-01" "1961-04" "1983-02"
st1 <- as.Date(st, format=("%Y-%m"))
print(st1)
#[1] NA NA NA

Why the heck am I getting three NAs instead of three Dates?I have  
studied the R documentation for as.Date() and it has not turned on the  
light bulb for me.


From chem@ @ending from rinzewind@org  Sun Aug 19 23:30:34 2018
From: chem@ @ending from rinzewind@org (=?iso-8859-1?Q?Jos=E9_Mar=EDa?= Mateos)
Date: Sun, 19 Aug 2018 17:30:34 -0400
Subject: [R] as.Date() function
In-Reply-To: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
Message-ID: <20180819213034.GC5241@equipaje>

On Sun, Aug 19, 2018 at 05:20:29PM -0400, philipsm at cpanel1.stormweb.net wrote:
> Why the heck am I getting three NAs instead of three Dates?I have
> studied the R documentation for as.Date() and it has not turned on
> the light bulb for me.

I haven't encountered this problem before, but in my mind, if you want a 
date, you'll also need to specify the day. Only year and month won't cut 
it.

Cheers,

-- 
Jos? Mar?a (Chema) Mateos
https://rinzewind.org/blog-es || https://rinzewind.org/blog-en


From erinm@hodge@@ @ending from gm@il@com  Sun Aug 19 23:34:33 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Sun, 19 Aug 2018 15:34:33 -0600
Subject: [R] as.Date() function
In-Reply-To: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
Message-ID: <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>

Hi Philip:

Here is something to consider:

> #potential solution:
> sta <- paste(st,"-01",sep="")
> st1 <- as.Date(sta, format=("%Y-%m-%d"))
> print(st1)
[1] "1961-01-01" "1961-04-01" "1983-02-01"


Hope this helps!
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Sun, Aug 19, 2018 at 3:25 PM <philipsm at cpanel1.stormweb.net> wrote:

> I am having trouble with what must be a very simple problem. Here is a
> reproducible example:
>
> library(lubridate)
> st <- c("1961-01","1961-04","1983-02")
> print(st)
> #[1] "1961-01" "1961-04" "1983-02"
> st1 <- as.Date(st, format=("%Y-%m"))
> print(st1)
> #[1] NA NA NA
>
> Why the heck am I getting three NAs instead of three Dates?I have
> studied the R documentation for as.Date() and it has not turned on the
> light bulb for me.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Aug 19 23:38:40 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 19 Aug 2018 14:38:40 -0700
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
 <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
Message-ID: <9154F32C-253C-4061-8858-C6F6BB877726@dcn.davis.ca.us>

I think this hunch is off the mark... the file name is fine as it is... if anything will confuse R it would be that the data inside the file are not what was expected.

If in fact the file is csv formatted then the function to read it would be read.csv [1] or read.table [2]. Read the help pages for these functions and read the R Data Import/Export documentation [3].

[1] ?read.csv at R console
[2] ?read.table many of the options for this function will work for read.csv.
[3] https://cran.r-project.org/doc/manuals/r-release/R-data.html

On August 19, 2018 12:16:14 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>Just a hunch, but I would recommend simplifying your filename:  remove
>the (CSV) portion.  It could be confusing in R read syntax.  Create a
>filename with no unnecessary punctuation and no blank spaces.
>
>
>--John Sparks
>
>
>________________________________
>From: R-help <r-help-bounces at r-project.org> on behalf of Spencer
>Brackett <spbrackett20 at saintjosephhs.com>
>Sent: Sunday, August 19, 2018 2:11 PM
>To: r-help at r-project.org
>Subject: [R] Request for R Assistance: Downloading Data
>
>Good evening,
>
>I am attempting to download Genomic data from the GDC onto R for
>analysis
>and am experiencing some difficulty. I have downloaded the GDC data
>into an
>Excel, CSV, and notepad (.txt) file and implemented what I believe to
>be
>the proper arguments, with every attempting failing to properly load
>the
>data onto R. The following is the various attempts I made in trying to
>take
>one of these files (a translated version of the GDC data) and load it
>into R
>.
>
>> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
>Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?LGG Drug (CSV).csv? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
>(CSV).csv",header=TRUE,sep=",")
>Error: unexpected symbol in "LGG Drug"
>> LGG Drug<-read.table("C:
>Error: unexpected symbol in "LGG Drug"
>> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
>Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="\t")
>Error: unexpected symbol in "GBM Drug"
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="\t")
>Error: unexpected symbol in " GBM Drug"
>> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
>Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
>wrap).txt")
>:
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM(word
>wrap).txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>
>Any insight into what perhaps I am inputting that is causes this
>reoccurring error? Any suggestions as to another procedure for moving
>forward would be greatly appreciated!
>
>Many thanks,
>
>Spencer Brackett
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>R-help -- Main R Mailing List: Primary help - Homepage -
>SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
>stat.ethz.ch
>The main R mailing list, for announcements about the development of R
>and the availability of new code, questions and answers about problems
>and solutions using R, enhancements and patches to the source code and
>documentation of R, comparison and compatibility with S and S-plus, and
>for the posting of nice examples and benchmarks.
>
>
>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From j@p@rk4 @ending from uic@edu  Sun Aug 19 23:43:43 2018
From: j@p@rk4 @ending from uic@edu (Sparks, John)
Date: Sun, 19 Aug 2018 21:43:43 +0000
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <9154F32C-253C-4061-8858-C6F6BB877726@dcn.davis.ca.us>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
 <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>,
 <9154F32C-253C-4061-8858-C6F6BB877726@dcn.davis.ca.us>
Message-ID: <SN6PR05MB4816150D27E8995E51B0A6F8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>

I agree with Jeff.  The data type is the problem.  I wrote what I wrote without looking at the problem very carefully.


--JJS


________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Sunday, August 19, 2018 4:38 PM
To: r-help at r-project.org; Sparks, John; Spencer Brackett; r-help at r-project.org
Subject: Re: [R] Request for R Assistance: Downloading Data

I think this hunch is off the mark... the file name is fine as it is... if anything will confuse R it would be that the data inside the file are not what was expected.

If in fact the file is csv formatted then the function to read it would be read.csv [1] or read.table [2]. Read the help pages for these functions and read the R Data Import/Export documentation [3].

[1] ?read.csv at R console
[2] ?read.table many of the options for this function will work for read.csv.
[3] https://cran.r-project.org/doc/manuals/r-release/R-data.html
R Data Import/Export<https://cran.r-project.org/doc/manuals/r-release/R-data.html>
cran.r-project.org
1.1 Imports. The easiest form of data to import into R is a simple text file, and this will often be acceptable for problems of small or medium scale.




On August 19, 2018 12:16:14 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>Just a hunch, but I would recommend simplifying your filename:  remove
>the (CSV) portion.  It could be confusing in R read syntax.  Create a
>filename with no unnecessary punctuation and no blank spaces.
>
>
>--John Sparks
>
>
>________________________________
>From: R-help <r-help-bounces at r-project.org> on behalf of Spencer
>Brackett <spbrackett20 at saintjosephhs.com>
>Sent: Sunday, August 19, 2018 2:11 PM
>To: r-help at r-project.org
>Subject: [R] Request for R Assistance: Downloading Data
>
>Good evening,
>
>I am attempting to download Genomic data from the GDC onto R for
>analysis
>and am experiencing some difficulty. I have downloaded the GDC data
>into an
>Excel, CSV, and notepad (.txt) file and implemented what I believe to
>be
>the proper arguments, with every attempting failing to properly load
>the
>data onto R. The following is the various attempts I made in trying to
>take
>one of these files (a translated version of the GDC data) and load it
>into R
>.
>
>> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
>Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?LGG Drug (CSV).csv? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
>(CSV).csv",header=TRUE,sep=",")
>Error: unexpected symbol in "LGG Drug"
>> LGG Drug<-read.table("C:
>Error: unexpected symbol in "LGG Drug"
>> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
>Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="\t")
>Error: unexpected symbol in "GBM Drug"
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="\t")
>Error: unexpected symbol in " GBM Drug"
>> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
>Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
>wrap).txt")
>:
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM(word
>wrap).txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>
>Any insight into what perhaps I am inputting that is causes this
>reoccurring error? Any suggestions as to another procedure for moving
>forward would be greatly appreciated!
>
>Many thanks,
>
>Spencer Brackett
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>R-help -- Main R Mailing List: Primary help - Homepage -
>SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
>stat.ethz.ch
>The main R mailing list, for announcements about the development of R
>and the availability of new code, questions and answers about problems
>and solutions using R, enhancements and patches to the source code and
>documentation of R, comparison and compatibility with S and S-plus, and
>for the posting of nice examples and benchmarks.
>
>
>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Mon Aug 20 01:14:06 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Mon, 20 Aug 2018 09:14:06 +1000
Subject: [R] as.Date() function
In-Reply-To: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
Message-ID: <CA+8X3fWcbJecxOmNja+pdtHL9H_mjEE2p6Nron8xdgte5pZgyQ@mail.gmail.com>

Hi Phillip,
Jose has the correct answer. You probably missed this sentence in the
"Note" section of the help page:

"If the date string does not specify the date completely, the returned
answer may be system-specific."

In your case, the function throws up its hands and returns NA as you
haven't specified a date.

Jim

On Mon, Aug 20, 2018 at 7:20 AM,  <philipsm at cpanel1.stormweb.net> wrote:
> I am having trouble with what must be a very simple problem. Here is a
> reproducible example:
>
> library(lubridate)
> st <- c("1961-01","1961-04","1983-02")
> print(st)
> #[1] "1961-01" "1961-04" "1983-02"
> st1 <- as.Date(st, format=("%Y-%m"))
> print(st1)
> #[1] NA NA NA
>
> Why the heck am I getting three NAs instead of three Dates?I have studied
> the R documentation for as.Date() and it has not turned on the light bulb
> for me.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From djnordlund @ending from gm@il@com  Mon Aug 20 02:08:21 2018
From: djnordlund @ending from gm@il@com (Daniel Nordlund)
Date: Sun, 19 Aug 2018 17:08:21 -0700
Subject: [R] Converting chr to num
In-Reply-To: <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
 <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
 <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>
Message-ID: <b123a1a4-0f7c-6242-549c-c6be1572c503@gmail.com>

See comment inline below:

On 8/18/2018 10:06 PM, Rui Barradas wrote:
> Hello,
> 
> It also works with class "factor":
> 
> df <- data.frame(variable = c("12.6%", "30.9%", "61.4%"))
> class(df$variable)
> #[1] "factor"
> 
> as.numeric(gsub(pattern = "%", "", df$variable))
> #[1] 12.6 30.9 61.4
> 
> 
> This is because sub() and gsub() return a character vector and the 
> instruction becomes an equivalent of what the help page ?factor 
> documents in section Warning:
> 
> To transform a factor f to approximately its original numeric values, 
> as.numeric(levels(f))[f] is recommended and slightly more efficient than 
> as.numeric(as.character(f)).
> 
> 
> Also, I would still prefer
> 
> as.numeric(sub(pattern = "%$","",df$variable))
> #[1] 12.6 30.9 61.4
> 
> The pattern is more strict and there is no need to search&replace 
> multiple occurrences of '%'.

The pattern is more strict, and that could cause the conversion to fail 
if the process that created the strings resulted in trailing spaces. 
Without the '$' the conversion succeeds.

df <- data.frame(variable = c("12.6% ", "30.9%", "61.4%"))
as.numeric(sub('%$', '', df$variable))
[1]   NA 30.9 61.4
Warning message:
NAs introduced by coercion


<<<snip>>>


Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From philipsm m@ili@g off cp@@el1@stormweb@@et  Mon Aug 20 02:16:27 2018
From: philipsm m@ili@g off cp@@el1@stormweb@@et (philipsm m@ili@g off cp@@el1@stormweb@@et)
Date: Sun, 19 Aug 2018 20:16:27 -0400
Subject: [R] as.Date() function
In-Reply-To: <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
 <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>
Message-ID: <20180819201627.Horde.q2d4uhEE8_2mg8Bn_ouZiwV@webmail.philipsmith.ca>

Thanks Erin and Jim. You have indeed solved my problem.

Philip


Quoting Erin Hodgess <erinm.hodgess at gmail.com>:

> Hi Philip:
>
> Here is something to consider:
>
>> #potential solution:
>> sta <- paste(st,"-01",sep="")
>> st1 <- as.Date(sta, format=("%Y-%m-%d"))
>> print(st1)
> [1] "1961-01-01" "1961-04-01" "1983-02-01"
>
>
> Hope this helps!
> Erin
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>
> On Sun, Aug 19, 2018 at 3:25 PM <philipsm at cpanel1.stormweb.net> wrote:
>
>> I am having trouble with what must be a very simple problem. Here is a
>> reproducible example:
>>
>> library(lubridate)
>> st <- c("1961-01","1961-04","1983-02")
>> print(st)
>> #[1] "1961-01" "1961-04" "1983-02"
>> st1 <- as.Date(st, format=("%Y-%m"))
>> print(st1)
>> #[1] NA NA NA
>>
>> Why the heck am I getting three NAs instead of three Dates?I have
>> studied the R documentation for as.Date() and it has not turned on the
>> light bulb for me.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From ruipb@rr@d@@ @ending from @@po@pt  Mon Aug 20 07:26:19 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Mon, 20 Aug 2018 06:26:19 +0100
Subject: [R] Converting chr to num
In-Reply-To: <b123a1a4-0f7c-6242-549c-c6be1572c503@gmail.com>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
 <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
 <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>
 <b123a1a4-0f7c-6242-549c-c6be1572c503@gmail.com>
Message-ID: <311a6e24-a37d-46bd-7e1b-4d377a6fad3e@sapo.pt>

Hello,

Inline.

On 20/08/2018 01:08, Daniel Nordlund wrote:
> See comment inline below:
> 
> On 8/18/2018 10:06 PM, Rui Barradas wrote:
>> Hello,
>>
>> It also works with class "factor":
>>
>> df <- data.frame(variable = c("12.6%", "30.9%", "61.4%"))
>> class(df$variable)
>> #[1] "factor"
>>
>> as.numeric(gsub(pattern = "%", "", df$variable))
>> #[1] 12.6 30.9 61.4
>>
>>
>> This is because sub() and gsub() return a character vector and the 
>> instruction becomes an equivalent of what the help page ?factor 
>> documents in section Warning:
>>
>> To transform a factor f to approximately its original numeric values, 
>> as.numeric(levels(f))[f] is recommended and slightly more efficient 
>> than as.numeric(as.character(f)).
>>
>>
>> Also, I would still prefer
>>
>> as.numeric(sub(pattern = "%$","",df$variable))
>> #[1] 12.6 30.9 61.4
>>
>> The pattern is more strict and there is no need to search&replace 
>> multiple occurrences of '%'.
> 
> The pattern is more strict, and that could cause the conversion to fail 
> if the process that created the strings resulted in trailing spaces. 

That's true, and I had thought of that but it wasn't in the OP's problem 
description.
The '$' could still be used with something like "%\\s*$":

as.numeric(sub('%\\s*$', '', df$variable))
#[1] 12.6 30.9 61.4


Rui Barradas


> Without the '$' the conversion succeeds.
> 
> df <- data.frame(variable = c("12.6% ", "30.9%", "61.4%"))
> as.numeric(sub('%$', '', df$variable))
> [1]?? NA 30.9 61.4
> Warning message:
> NAs introduced by coercion
> 
> 
> <<<snip>>>
> 
> 
> Dan
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com


From @pencer@gr@ve@ @ending from effectivedefen@e@org  Mon Aug 20 07:39:20 2018
From: @pencer@gr@ve@ @ending from effectivedefen@e@org (Spencer Graves)
Date: Mon, 20 Aug 2018 00:39:20 -0500
Subject: [R] Converting chr to num
In-Reply-To: <311a6e24-a37d-46bd-7e1b-4d377a6fad3e@sapo.pt>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
 <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
 <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>
 <b123a1a4-0f7c-6242-549c-c6be1572c503@gmail.com>
 <311a6e24-a37d-46bd-7e1b-4d377a6fad3e@sapo.pt>
Message-ID: <5f3458ae-2a32-1690-8961-42cd8ae710dc@effectivedefense.org>

 ????? Have you considered "Ecfun::asNumericChar" (and 
"Ecfun::asNumericDF")?


DF <- data.frame(variable = c("12.6% ", "30.9%", "61.4%", "1"))
Ecfun::asNumericChar(DF$variable)
[1] 0.126 0.309 0.614 1.000


 ????? If you read the documentation including the examples, you will 
see that many of these issues and others are handled automatically in 
the way that I thought was the most sensible.? If you disagree, we can 
discuss other examples and perhaps modify the code for those functions.


 ????? Spencer Graves


On 2018-08-20 00:26, Rui Barradas wrote:
> Hello,
>
> Inline.
>
> On 20/08/2018 01:08, Daniel Nordlund wrote:
>> See comment inline below:
>>
>> On 8/18/2018 10:06 PM, Rui Barradas wrote:
>>> Hello,
>>>
>>> It also works with class "factor":
>>>
>>> df <- data.frame(variable = c("12.6%", "30.9%", "61.4%"))
>>> class(df$variable)
>>> #[1] "factor"
>>>
>>> as.numeric(gsub(pattern = "%", "", df$variable))
>>> #[1] 12.6 30.9 61.4
>>>
>>>
>>> This is because sub() and gsub() return a character vector and the 
>>> instruction becomes an equivalent of what the help page ?factor 
>>> documents in section Warning:
>>>
>>> To transform a factor f to approximately its original numeric 
>>> values, as.numeric(levels(f))[f] is recommended and slightly more 
>>> efficient than as.numeric(as.character(f)).
>>>
>>>
>>> Also, I would still prefer
>>>
>>> as.numeric(sub(pattern = "%$","",df$variable))
>>> #[1] 12.6 30.9 61.4
>>>
>>> The pattern is more strict and there is no need to search&replace 
>>> multiple occurrences of '%'.
>>
>> The pattern is more strict, and that could cause the conversion to 
>> fail if the process that created the strings resulted in trailing 
>> spaces. 
>
> That's true, and I had thought of that but it wasn't in the OP's 
> problem description.
> The '$' could still be used with something like "%\\s*$":
>
> as.numeric(sub('%\\s*$', '', df$variable))
> #[1] 12.6 30.9 61.4
>
>
> Rui Barradas
>
>
>> Without the '$' the conversion succeeds.
>>
>> df <- data.frame(variable = c("12.6% ", "30.9%", "61.4%"))
>> as.numeric(sub('%$', '', df$variable))
>> [1]?? NA 30.9 61.4
>> Warning message:
>> NAs introduced by coercion
>>
>>
>> <<<snip>>>
>>
>>
>> Dan
>>
>
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry@onkelinx @ending from inbo@be  Mon Aug 20 13:36:38 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 20 Aug 2018 13:36:38 +0200
Subject: [R] Using rmarkdown with many plots created in a loop
In-Reply-To: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>
References: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>
Message-ID: <CAJuCY5wrwGaRwHsiK+6kDxphQL_2+3yCVxumyZWFT2sPQ_ZrCw@mail.gmail.com>

Dear Don,

Have a look at the knit_expand() function. Then you can create two Rmd
files. One main file and one template file for the subsets. knit_expand()
will find and replace anything between double curly brackets ("{{x}}" in
the example below) with the value of the variable.

The main file:

---
title: "main"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
```

```{r}
mydf <- data.frame(
  id = 1:4,
  x = rnorm(100),
  y = rnorm(100)
)
```

```{r}
rmd <- sapply(
  1:4,
  function(x) {
    knit_expand("child.Rmd", x = x)
  }
)
rmd <- paste(rmd, collapse = "\n")
cat(rmd)
```
```{r results = "asis"}
rendered <- knit(text = rmd, quiet = TRUE)
cat(rendered, sep = "\n")
```


The child.Rmd file

## ID {{x}}

```{r, fig.cap = "The caption: ID = {{x}}", echo = FALSE}
i <- {{x}}
detail <- subset(mydf, id == i)
plot(x ~ y, data = detail)
```

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-08-17 1:44 GMT+02:00 MacQueen, Don via R-help <r-help at r-project.org>:

> I would appreciate some suggestions of a good way to prepare a report
> using rmarkdown,
> in which I loop through subsets of a data set, creating a plot of each
> subset, and interspersing
> among the figures some text relevant to each figure.
>
> One way is to have an R script write the rmd file, then render it.
> It works, but it's cumbersome and difficult to get the rmd syntax correct.
> I would very much appreciate suggestions for a better way.
>
> Reproducible example below.
>
> Thanks
> -Don
>
>
> Example data (other data structures could be used), and an example using
> this approach.
>
> myd <- lapply( 1:3,
>               function(i) list(df=data.frame(x=1:5, y=rnorm(5)),
>                                comment=paste('Data', LETTERS[i]))
>               )
>
> Example interactive review (details would change depending on data
> structure)
> (I would typically insert pauses when working interactively)
>
> for (i in 1:3) {
>   cat(paste('Figure',i,'shows',myd[[i]]$comment),'\n')
>   with(myd[[i]]$df , plot(x,y))
>   mtext(myd[[i]]$comment)
>   mtext( paste(nrow(myd[[i]]$df),'points'), adj=1)
> }?
>
> Note that along with the data I've saved some comments relevant to each
> subset.
> I've calculated them in the example data, but in general they could be
> completely
> arbitrary and come from anywhere.
>
> Now I'd like to get the same plots and comments into a report prepared
> using rmarkdown.
> Here's one way, having the loop create an rmd file, then rendering it.
>
> ### example script begins
> library(rmarkdown)
>
> myf <- 'myd.rmd'
> sink(myf)
> cat('---
> title: Example
> ---
>
> Here are some figures with a comment appearing before each.\n\n'
> )
> sink()
>
> for (i in 1:3) {
>   cat(paste('Figure',i,'comment:',myd[[i]]$comment),'\n', file=myf,
> append=TRUE)
>
>   cat("
> ```{r  echo=FALSE, fig.cap='",paste('fig',i),"caption.'}
>   with(myd[[",i,"]]$df , plot(x,y))
>   mtext(myd[[",i,"]]$comment)
>   mtext( paste(nrow(myd[[",i,"]]$df),'points'), adj=1)
> ```
> ", file=myf, append=TRUE)
>
> }
>
> cat('Done with report\n', file=myf, append=TRUE)
>
> render(myf)
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh @ending from temple@edu  Mon Aug 20 15:45:33 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Mon, 20 Aug 2018 09:45:33 -0400
Subject: [R] Using rmarkdown with many plots created in a loop
In-Reply-To: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>
References: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>
Message-ID: <CAGx1TMBEA7PDNQ9O1QkXtfpuqLd4y4r4+rF2tc2T2pSR8+0BRQ@mail.gmail.com>

## Don,

## This is how I would approach the task of a set of coordinated plots.
## I would place individual plots inside a table.  The rows would index the
## datasets and there would be one or more data or description columns
## in addition to the column containing the graphs.

## I use the microplot package that I placed on CRAN about two years ago.

## install.packages("microplot") ## if necessary


library(microplot)
latexSetOptions()

## I normally use lattice.  microplot also works with ggplot or base graphics
library(lattice)

## I placed your data into a single data.frame
myd <- lapply( 1:3,
              function(i) list(df=data.frame(x=1:5, y=rnorm(5)),
                               comment=paste('Data', LETTERS[i]))
              )

mydf <- cbind(group=rep(c("A", "B", "C"), each=5),
              rbind(myd[[1]]$df, myd[[2]]$df, myd[[3]]$df))
mydf


## construct a lattice with multiple panels
my.lattice <-
  xyplot(y ~ x | group, data=mydf,
         layout=c(1,3), as.table=TRUE, col="black",
         scales=list(alternating=FALSE),
         ylab=list(rot=1))
my.lattice


## microplot provides latex.trellis, which is a method for Hmisc::latex

## simplest display
latex(my.lattice)

## now with comments and optional additional arguments
mycomments <-
  c("Interesting Comment",
    "Full \\LaTeX\\ with an equation $e^{-x^2}$",
    "\\begin{tabular}{l}$\\frac{dy}{dx}$ \\\\is interesting \\\\and
has multiple lines\\end{tabular}")

latex(my.lattice,
      title="Dataset",
      height.panel=1, width.panel=1.5, ## inches
      height.x.axis=.38, width.y.axis=.45,
      graph.header="xyplot(y ~ x | group)",
      dataobject=mycomments,
      colheads=c("Comments", "", "", "xyplot( y \\~{} x )"),
      caption="Very Interesting Caption",
      caption.loc="bottom",
      arraystretch=1.5)

## microplot produces MS Word tables as well as LaTeX tables.
## microplot works with  ?Sweave?, ?knitr?, ?emacs? ?orgmode?, and ?rmarkdown?

## Start with ?microplot-package
## and look at the demos and examples and vignette.

## Rich

On Thu, Aug 16, 2018 at 7:44 PM, MacQueen, Don via R-help
<r-help at r-project.org> wrote:
> I would appreciate some suggestions of a good way to prepare a report using rmarkdown,
> in which I loop through subsets of a data set, creating a plot of each subset, and interspersing
> among the figures some text relevant to each figure.
>
> One way is to have an R script write the rmd file, then render it.
> It works, but it's cumbersome and difficult to get the rmd syntax correct.
> I would very much appreciate suggestions for a better way.
>
> Reproducible example below.
>
> Thanks
> -Don
>
>
> Example data (other data structures could be used), and an example using this approach.
>
> myd <- lapply( 1:3,
>               function(i) list(df=data.frame(x=1:5, y=rnorm(5)),
>                                comment=paste('Data', LETTERS[i]))
>               )
>
> Example interactive review (details would change depending on data structure)
> (I would typically insert pauses when working interactively)
>
> for (i in 1:3) {
>   cat(paste('Figure',i,'shows',myd[[i]]$comment),'\n')
>   with(myd[[i]]$df , plot(x,y))
>   mtext(myd[[i]]$comment)
>   mtext( paste(nrow(myd[[i]]$df),'points'), adj=1)
> }?
>
> Note that along with the data I've saved some comments relevant to each subset.
> I've calculated them in the example data, but in general they could be completely
> arbitrary and come from anywhere.
>
> Now I'd like to get the same plots and comments into a report prepared using rmarkdown.
> Here's one way, having the loop create an rmd file, then rendering it.
>
> ### example script begins
> library(rmarkdown)
>
> myf <- 'myd.rmd'
> sink(myf)
> cat('---
> title: Example
> ---
>
> Here are some figures with a comment appearing before each.\n\n'
> )
> sink()
>
> for (i in 1:3) {
>   cat(paste('Figure',i,'comment:',myd[[i]]$comment),'\n', file=myf, append=TRUE)
>
>   cat("
> ```{r  echo=FALSE, fig.cap='",paste('fig',i),"caption.'}
>   with(myd[[",i,"]]$df , plot(x,y))
>   mtext(myd[[",i,"]]$comment)
>   mtext( paste(nrow(myd[[",i,"]]$df),'points'), adj=1)
> ```
> ", file=myf, append=TRUE)
>
> }
>
> cat('Done with report\n', file=myf, append=TRUE)
>
> render(myf)
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kyd@viddoyle @ending from gm@il@com  Mon Aug 20 21:17:13 2018
From: kyd@viddoyle @ending from gm@il@com (David Doyle)
Date: Mon, 20 Aug 2018 14:17:13 -0500
Subject: [R] Transforming data for nice output table
Message-ID: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>

Hello everyone,

I'm trying to generate tables of my data out of R for my report.

My data is setup in the format as follows and the example can be found at:
http://doylesdartden.com/R/ExampleData.csv

Location        Date        Year      GW_Elevation
127(I)        5/14/2006     2006       752.46
119(I)        5/14/2006     2006       774.67
127(I)        6/11/2007     2007       752.06
119(I)        6/11/2007     2007       775.57

I would like to generate a table that showed

Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....

119(I)                    774.67                      775.57
          xxxx
127(I)                    752.46                      752.06
          xxxx
XXXX                          XX                           XX

 Any thoughts on how to transform the data so it would be in this format??

Thank you for your time

David Doyle

	[[alternative HTML version deleted]]


From @he@cott @ending from pennmedicine@upenn@edu  Mon Aug 20 21:42:22 2018
From: @he@cott @ending from pennmedicine@upenn@edu (Scott Sherrill-Mix)
Date: Mon, 20 Aug 2018 15:42:22 -0400
Subject: [R] download.file() problems with binary files containing EOF byte
 in Windows
In-Reply-To: <CAKwTkR2pin3HZVtwO8MvZ0phsE6Q3YYDdX=3+DZ-y7=8qdPECg@mail.gmail.com>
References: <CAKwTkR2pin3HZVtwO8MvZ0phsE6Q3YYDdX=3+DZ-y7=8qdPECg@mail.gmail.com>
Message-ID: <CAKwTkR3G-DAUCoA84+idEQphsZgewPqCPQtiVXD+SAObn8wBQg@mail.gmail.com>

Hello,
I'm trying to get a package to pass win-builder and have been having a
bit of trouble with Windows R and binary files (in my case a small
.tar.gz used in testing). After a little debugging, I think I've
narrowed it down to download.file() truncating files to the first '1a'
byte (often used for EOF but I think a valid byte inside gzip files)
on downloads from local "file://xxx". I'm trying to figure out if this
is a known "feature" of Windows that I should just avoid or does this
seem like a bug?

For example:

#write a file starting with byte 1a (decimal 26)
writeBin(26:100,'tmp.bin',size=1)
download.file('file://tmp.bin','download.bin')
file.size('tmp.bin')
file.size('download.bin')

On Windows (session info below), I get file sizes of 75 and 0 and on
Linux I get 75 and 75.

As a more real world example, if I download.file() on a .gz file then
a remote download seems to return different size files from a local
download. For example for a gz file from a google hit about gzip
(http://commandlinefanatic.com/cgi-bin/showarticle.cgi?article=art053):

download.file('http://commandlinefanatic.com/gunzip.c.gz','gunzip.c.gz')
download.file('file://gunzip.c.gz','dl.gz')
file.size('gunzip.c.gz')
file.size('dl.gz')

I get a 4704 byte file for the remote download and 360 for the local
download in Windows (versus 4704 and 4704 on Linux). Note that the
361st byte is 1a:

readBin('gunzip.c.gz','raw',361)

The various download.file options don't seem to fix this with the same 360 bytes
for:

download.file('file://gunzip.c.gz','dl.gz',mode='wb')
file.size('dl.gz')
download.file('file://gunzip.c.gz','dl.gz',mode='wb',method='internal')
file.size('dl.gz')

It looks like the 'auto' and 'internal' methods both resolve to the
'wininet' method on Windows and mode is automatically set to 'wb' for
gz files so maybe not surprising those don't change things.

Thanks,
Scott

## Windows sessionInfo():
R version 3.5.1 (2018-07-02)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 8.1 x64 (build 9600)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_3.5.1


## Linux sessionInfo():
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.5 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.4


From ruipb@rr@d@@ @ending from @@po@pt  Mon Aug 20 22:37:12 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Mon, 20 Aug 2018 21:37:12 +0100
Subject: [R] Transforming data for nice output table
In-Reply-To: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
Message-ID: <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>

Hello,

This is a very frequent question.
I could rewrite one or two answers taken from StackOverflow:

https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format


But there you will have more options.


Hope this helps,

Rui Barradas

On 20/08/2018 20:17, David Doyle wrote:
> Hello everyone,
> 
> I'm trying to generate tables of my data out of R for my report.
> 
> My data is setup in the format as follows and the example can be found at:
> http://doylesdartden.com/R/ExampleData.csv
> 
> Location        Date        Year      GW_Elevation
> 127(I)        5/14/2006     2006       752.46
> 119(I)        5/14/2006     2006       774.67
> 127(I)        6/11/2007     2007       752.06
> 119(I)        6/11/2007     2007       775.57
> 
> I would like to generate a table that showed
> 
> Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....
> 
> 119(I)                    774.67                      775.57
>            xxxx
> 127(I)                    752.46                      752.06
>            xxxx
> XXXX                          XX                           XX
> 
>   Any thoughts on how to transform the data so it would be in this format??
> 
> Thank you for your time
> 
> David Doyle
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com


From m@cqueen1 @ending from llnl@gov  Mon Aug 20 22:53:39 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 20 Aug 2018 20:53:39 +0000
Subject: [R] plotmath and logical operators?
Message-ID: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>

I would like to use plotmath to annotate a plot with an expression that includes a logical operator.

## works well
tmp <- expression(x >= 3)
plot(1)
mtext(tmp)

## not so well
tmp <- expression(x >= 3 &  y <= 3)
plot(1)
mtext(tmp)?

Although the text that's displayed makes sense, it won't be obvious to my non-mathematical audience.

I'd appreciate suggestions.


I've found a work-around that gets the annotation to look right
  tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
  plot(1)
  mtext(tmpw)


But it breaks my original purpose, illustrated by this example:

df <- data.frame(x=1:5, y=1:5)
tmp <- expression(x >= 3 & y <= 3)
tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
with(df, eval(tmp))
[1] FALSE FALSE  TRUE FALSE FALSE
with(df, eval(tmpw))
[1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE" "TRUE  &  FALSE"

Thanks
-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Mon Aug 20 23:04:58 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Mon, 20 Aug 2018 17:04:58 -0400
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <SN6PR05MB4816150D27E8995E51B0A6F8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
 <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
 <9154F32C-253C-4061-8858-C6F6BB877726@dcn.davis.ca.us>
 <SN6PR05MB4816150D27E8995E51B0A6F8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
Message-ID: <CAPQaxLN=mudVDk+7MuqAiHYq+aiQqEsjLe75p8S8KbRSd62d2A@mail.gmail.com>

 Please ignore my last post/inquiry... I have solved the problem. Thanks
again for the help!

On Sun, Aug 19, 2018 at 5:43 PM Sparks, John <jspark4 at uic.edu> wrote:

> I agree with Jeff.  The data type is the problem.  I wrote what I wrote
> without looking at the problem very carefully.
>
>
> --JJS
>
>
> ------------------------------
> *From:* Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> *Sent:* Sunday, August 19, 2018 4:38 PM
> *To:* r-help at r-project.org; Sparks, John; Spencer Brackett;
> r-help at r-project.org
> *Subject:* Re: [R] Request for R Assistance: Downloading Data
>
> I think this hunch is off the mark... the file name is fine as it is... if
> anything will confuse R it would be that the data inside the file are not
> what was expected.
>
> If in fact the file is csv formatted then the function to read it would be
> read.csv [1] or read.table [2]. Read the help pages for these functions and
> read the R Data Import/Export documentation [3].
>
> [1] ?read.csv at R console
> [2] ?read.table many of the options for this function will work for
> read.csv.
> [3] https://cran.r-project.org/doc/manuals/r-release/R-data.html
> R Data Import/Export
> <https://cran.r-project.org/doc/manuals/r-release/R-data.html>
> cran.r-project.org
> 1.1 Imports. The easiest form of data to import into R is a simple text
> file, and this will often be acceptable for problems of small or medium
> scale.
>
>
>
> On August 19, 2018 12:16:14 PM PDT, "Sparks, John" <jspark4 at uic.edu>
> wrote:
> >Just a hunch, but I would recommend simplifying your filename:  remove
> >the (CSV) portion.  It could be confusing in R read syntax.  Create a
> >filename with no unnecessary punctuation and no blank spaces.
> >
> >
> >--John Sparks
> >
> >
> >________________________________
> >From: R-help <r-help-bounces at r-project.org> on behalf of Spencer
> >Brackett <spbrackett20 at saintjosephhs.com>
> >Sent: Sunday, August 19, 2018 2:11 PM
> >To: r-help at r-project.org
> >Subject: [R] Request for R Assistance: Downloading Data
> >
> >Good evening,
> >
> >I am attempting to download Genomic data from the GDC onto R for
> >analysis
> >and am experiencing some difficulty. I have downloaded the GDC data
> >into an
> >Excel, CSV, and notepad (.txt) file and implemented what I believe to
> >be
> >the proper arguments, with every attempting failing to properly load
> >the
> >data onto R. The following is the various attempts I made in trying to
> >take
> >one of these files (a translated version of the GDC data) and load it
> >into R
> >.
> >
> >> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
> >Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
> >bad restore file magic number (file may be corrupted) -- no data loaded
> >In addition: Warning message:
> >file ?LGG Drug (CSV).csv? has magic number 'MANIF'
> >  Use of save versions prior to 2 is deprecated
> >> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
> >(CSV).csv",header=TRUE,sep=",")
> >Error: unexpected symbol in "LGG Drug"
> >> LGG Drug<-read.table("C:
> >Error: unexpected symbol in "LGG Drug"
> >> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
> >Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
> >bad restore file magic number (file may be corrupted) -- no data loaded
> >In addition: Warning message:
> >file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
> >  Use of save versions prior to 2 is deprecated
> >> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM.txt",header=TRUE,sep="")
> >Error: unexpected symbol in "GBM Drug"
> >> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM.txt",header=TRUE,sep="\t")
> >Error: unexpected symbol in "GBM Drug"
> >> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM.txt",header=TRUE,sep="")
> >Error: unexpected symbol in "GBM Drug"
> >>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM.txt",header=TRUE,sep="\t")
> >Error: unexpected symbol in " GBM Drug"
> >> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
> >Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
> >wrap).txt")
> >:
> >bad restore file magic number (file may be corrupted) -- no data loaded
> >In addition: Warning message:
> >file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
> >  Use of save versions prior to 2 is deprecated
> >> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM(word
> >wrap).txt",header=TRUE,sep="")
> >Error: unexpected symbol in "GBM Drug"
> >
> >Any insight into what perhaps I am inputting that is causes this
> >reoccurring error? Any suggestions as to another procedure for moving
> >forward would be greatly appreciated!
> >
> >Many thanks,
> >
> >Spencer Brackett
> >
> >        [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >R-help -- Main R Mailing List: Primary help - Homepage -
> >SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
> >stat.ethz.ch
> >The main R mailing list, for announcements about the development of R
> >and the availability of new code, questions and answers about problems
> >and solutions using R, enhancements and patches to the source code and
> >documentation of R, comparison and compatibility with S and S-plus, and
> >for the posting of nice examples and benchmarks.
> >
> >
> >
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From j@kperik@dioggb@n @ending from @tudent@@jku@t@@c@ke  Mon Aug 20 23:49:59 2018
From: j@kperik@dioggb@n @ending from @tudent@@jku@t@@c@ke (Dioggban Jakperik)
Date: Tue, 21 Aug 2018 00:49:59 +0300
Subject: [R] Fwd: Computing the density of a median
In-Reply-To: <CANbn+9CL7zgn9Xnui43pEYYkPaAB030fkQCGP7UM_CaFR6SywQ@mail.gmail.com>
References: <CANbn+9CL7zgn9Xnui43pEYYkPaAB030fkQCGP7UM_CaFR6SywQ@mail.gmail.com>
Message-ID: <CANbn+9DsS3Q0mUFq6otBc9LKLXAkSj-sTs8QXPp4y-6MpH-mMA@mail.gmail.com>

Dear all,


I have the following function

kdenor <- function(aa,q=NULL){
a=sample(aa,500,replace=F)
ab=quantile(a, p=0.75)-quantile(a, p=0.25)
h=(0.9*min(var(a),ab))/(1.34*n^(1/5))

if(is.null(q)) {
q = seq(min(a)-3*h, max(a)+3*h, length.out=length(a))
}
nx = length(a)
nq = length(q)
xmat = matrix(q,nq,nx) - matrix(a,nq,nx,byrow=TRUE)
denall= dnorm(xmat/h)/h
denhat = apply(denall,1,mean)

f<-denhat
f1<-median(f)
#das<-list(x=q, y=denhat, h=h)
#return(das)
}

f1<-kdenor(aa)

My interest is to obtain the estimate of the density at the median of the
sample data.
But the output of the current function  doesn't provide the correct result.
Kindly help.
Regards.


-- 
Jakperik Dioggban (Student, PAUISTI)
PhD Mathematics (Statistics Option)
Determination is Key to Success



-- 
Jakperik Dioggban (Student, PAUISTI)
PhD Mathematics (Statistics Option)
Determination is Key to Success

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Tue Aug 21 00:27:19 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 21 Aug 2018 08:27:19 +1000
Subject: [R] Transforming data for nice output table
In-Reply-To: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
Message-ID: <CA+8X3fWOkfSxOgRCoFZBYifJg6wMrGiY1sXQy7W+V-nhHqfqVg@mail.gmail.com>

Hi David,
As you want the _values_ of Year from the initial data frame appended
to the _names_ of GW_Elevation, you can't do it the easy way:

dddf<-read.table(text="Location        Date        Year      GW_Elevation
127(I)        5/14/2006     2006       752.46
119(I)        5/14/2006     2006       774.67
127(I)        6/11/2007     2007       752.06
119(I)        6/11/2007     2007       775.57",
header=TRUE)
library(prettyR)
# easy part
sdddf<-stretch_df(dddf[c(1,3,4)],"Location",c("Year","GW_Elevation"))
sdddf

This only works for a data frame with the structure and names of the initial one

# hard part
sdddf_dim<-dim(sdddf)
nyears<-(sdddf_dim[2] - 1)/2
fsdddf<-sdddf[,c(1,1:nyears+nyears+1)]
names(fsdddf)<-c("Location",paste("GW_Elevation",unique(dddf$Year),sep="_"))
fsdddf

I would strongly suggest being happy with the easy way, because if the
order of years isn't ascending, the hard way won't work.

Jim

On Tue, Aug 21, 2018 at 5:17 AM, David Doyle <kydaviddoyle at gmail.com> wrote:
> Hello everyone,
>
> I'm trying to generate tables of my data out of R for my report.
>
> My data is setup in the format as follows and the example can be found at:
> http://doylesdartden.com/R/ExampleData.csv
>
> Location        Date        Year      GW_Elevation
> 127(I)        5/14/2006     2006       752.46
> 119(I)        5/14/2006     2006       774.67
> 127(I)        6/11/2007     2007       752.06
> 119(I)        6/11/2007     2007       775.57
>
> I would like to generate a table that showed
>
> Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....
>
> 119(I)                    774.67                      775.57
>           xxxx
> 127(I)                    752.46                      752.06
>           xxxx
> XXXX                          XX                           XX
>
>  Any thoughts on how to transform the data so it would be in this format??
>
> Thank you for your time
>
> David Doyle
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Tue Aug 21 00:37:53 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 20 Aug 2018 15:37:53 -0700
Subject: [R] plotmath and logical operators?
In-Reply-To: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
Message-ID: <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>

This is clumsy and probably subject to considerable improvement, but does
it work for you:

left <- quote(x >= 3)
right <- quote(y <= 3) ## these can be anything

## the plot:
plot(1)
eval(substitute(mtext(expression(paste(left, " & ",right))), list(left =
left, right = right)))

## Expression evaluation
eval(substitute(with(df,left & right), list(left = left, right = right)))

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <
r-help at r-project.org> wrote:

> I would like to use plotmath to annotate a plot with an expression that
> includes a logical operator.
>
> ## works well
> tmp <- expression(x >= 3)
> plot(1)
> mtext(tmp)
>
> ## not so well
> tmp <- expression(x >= 3 &  y <= 3)
> plot(1)
> mtext(tmp)?
>
> Although the text that's displayed makes sense, it won't be obvious to my
> non-mathematical audience.
>
> I'd appreciate suggestions.
>
>
> I've found a work-around that gets the annotation to look right
>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>   plot(1)
>   mtext(tmpw)
>
>
> But it breaks my original purpose, illustrated by this example:
>
> df <- data.frame(x=1:5, y=1:5)
> tmp <- expression(x >= 3 & y <= 3)
> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
> with(df, eval(tmp))
> [1] FALSE FALSE  TRUE FALSE FALSE
> with(df, eval(tmpw))
> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE"
> "TRUE  &  FALSE"
>
> Thanks
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Aug 21 01:05:03 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 20 Aug 2018 16:05:03 -0700 (PDT)
Subject: [R] Transforming data for nice output table
In-Reply-To: <CA+8X3fWOkfSxOgRCoFZBYifJg6wMrGiY1sXQy7W+V-nhHqfqVg@mail.gmail.com>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
 <CA+8X3fWOkfSxOgRCoFZBYifJg6wMrGiY1sXQy7W+V-nhHqfqVg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1808201557520.25042@pedal.dcn.davis.ca.us>

If departing from base R into contributed territory, tidyr::spread is 
well-suited to this.

library(dplyr)
library(tidyr)
dta <- read.csv( "http://doylesdartden.com/R/ExampleData.csv"
                , header = TRUE
                , as.is = TRUE
                )
result <- (   dta # starting with your data...
           # keep only relevant columns
           %>% select( Location, Year, GW_Elevation )
           # make the key column look like your desired column names
           %>% mutate( Year = sprintf( "GW_Elevation %d", Year ) )
           # spread the "long" data out "wide"
           %>% spread( Year, GW_Elevation )
           )

On Tue, 21 Aug 2018, Jim Lemon wrote:

> Hi David,
> As you want the _values_ of Year from the initial data frame appended
> to the _names_ of GW_Elevation, you can't do it the easy way:
>
> dddf<-read.table(text="Location        Date        Year      GW_Elevation
> 127(I)        5/14/2006     2006       752.46
> 119(I)        5/14/2006     2006       774.67
> 127(I)        6/11/2007     2007       752.06
> 119(I)        6/11/2007     2007       775.57",
> header=TRUE)
> library(prettyR)
> # easy part
> sdddf<-stretch_df(dddf[c(1,3,4)],"Location",c("Year","GW_Elevation"))
> sdddf
>
> This only works for a data frame with the structure and names of the initial one
>
> # hard part
> sdddf_dim<-dim(sdddf)
> nyears<-(sdddf_dim[2] - 1)/2
> fsdddf<-sdddf[,c(1,1:nyears+nyears+1)]
> names(fsdddf)<-c("Location",paste("GW_Elevation",unique(dddf$Year),sep="_"))
> fsdddf
>
> I would strongly suggest being happy with the easy way, because if the
> order of years isn't ascending, the hard way won't work.
>
> Jim
>
> On Tue, Aug 21, 2018 at 5:17 AM, David Doyle <kydaviddoyle at gmail.com> wrote:
>> Hello everyone,
>>
>> I'm trying to generate tables of my data out of R for my report.
>>
>> My data is setup in the format as follows and the example can be found at:
>> http://doylesdartden.com/R/ExampleData.csv
>>
>> Location        Date        Year      GW_Elevation
>> 127(I)        5/14/2006     2006       752.46
>> 119(I)        5/14/2006     2006       774.67
>> 127(I)        6/11/2007     2007       752.06
>> 119(I)        6/11/2007     2007       775.57
>>
>> I would like to generate a table that showed
>>
>> Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....
>>
>> 119(I)                    774.67                      775.57
>>           xxxx
>> 127(I)                    752.46                      752.06
>>           xxxx
>> XXXX                          XX                           XX
>>
>>  Any thoughts on how to transform the data so it would be in this format??
>>
>> Thank you for your time
>>
>> David Doyle
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From m@cqueen1 @ending from llnl@gov  Tue Aug 21 01:14:06 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 20 Aug 2018 23:14:06 +0000
Subject: [R] plotmath and logical operators?
In-Reply-To: <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
 <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
Message-ID: <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>

Thanks Bert!

It certainly works for the example (and shows a much deeper understanding of eval, substitute, etc. than I have). But it doesn't appear to generalize very well in the way I need (which of course I didn't think of mentioning until after I sent the email -- sorry).

Suppose subs is any expression that would be valid for the subset argument of base::subset, for a given data frame. Then I can extract that subset of the data frame by using
   mydf[  with(mydf, eval(subs)) ,  ]
(or similar).

Then, having plotted some aspect of that subset, I want to annotate the plot with the subset specifications.

I've used this approach to  set up a system that helps me to interactively review various subsets of a large set of data. I save the final selected subsetting expressions in some sort of data structure, for later use in preparing a report using rmarkdown.

I was hoping to use plotmath to improve the appearance of the annotations -- but I now think it's not worth this kind of effort. I think I'm going to settle for mtext( as.character(subs) ).

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Monday, August 20, 2018 at 3:38 PM
To: "MacQueen, Don" <macqueen1 at llnl.gov>
Cc: array R-help <r-help at r-project.org>
Subject: Re: [R] plotmath and logical operators?

This is clumsy and probably subject to considerable improvement, but does it work for you:

left <- quote(x >= 3)
right <- quote(y <= 3) ## these can be anything

## the plot:
plot(1)
eval(substitute(mtext(expression(paste(left, " & ",right))), list(left = left, right = right)))

## Expression evaluation
eval(substitute(with(df,left & right), list(left = left, right = right)))
Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
I would like to use plotmath to annotate a plot with an expression that includes a logical operator.

## works well
tmp <- expression(x >= 3)
plot(1)
mtext(tmp)

## not so well
tmp <- expression(x >= 3 &  y <= 3)
plot(1)
mtext(tmp)

Although the text that's displayed makes sense, it won't be obvious to my non-mathematical audience.

I'd appreciate suggestions.


I've found a work-around that gets the annotation to look right
  tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
  plot(1)
  mtext(tmpw)


But it breaks my original purpose, illustrated by this example:

df <- data.frame(x=1:5, y=1:5)
tmp <- expression(x >= 3 & y <= 3)
tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
with(df, eval(tmp))
[1] FALSE FALSE  TRUE FALSE FALSE
with(df, eval(tmpw))
[1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE" "TRUE  &  FALSE"

Thanks
-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Aug 21 01:52:48 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 20 Aug 2018 16:52:48 -0700
Subject: [R] plotmath and logical operators?
In-Reply-To: <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
 <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
 <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
Message-ID: <CAGxFJbT3AY25L_C30t2QmbESdavqsRkGcJJWK6dTGWkNYWYAHA@mail.gmail.com>

As I understand it, the problem is:

"A mathematical expression must obey the normal rules of syntax for
any *R* expression,
but it is interpreted according to very different rules than for normal *R*
expressions."

I believe this means that you cannot do what you wanted to using plotmath.

Cheers,
Bert


On Mon, Aug 20, 2018 at 4:14 PM MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Thanks Bert!
>
>
>
> It certainly works for the example (and shows a much deeper understanding
> of eval, substitute, etc. than I have). But it doesn't appear to generalize
> very well in the way I need (which of course I didn't think of mentioning
> until after I sent the email -- sorry).
>
>
>
> Suppose subs is any expression that would be valid for the subset argument
> of base::subset, for a given data frame. Then I can extract that subset of
> the data frame by using
>
>    mydf[  with(mydf, eval(subs)) ,  ]
>
> (or similar).
>
>
>
> Then, having plotted some aspect of that subset, I want to annotate the
> plot with the subset specifications.
>
>
>
> I've used this approach to  set up a system that helps me to interactively
> review various subsets of a large set of data. I save the final selected
> subsetting expressions in some sort of data structure, for later use in
> preparing a report using rmarkdown.
>
>
>
> I was hoping to use plotmath to improve the appearance of the annotations
> -- but I now think it's not worth this kind of effort. I think I'm going to
> settle for mtext( as.character(subs) ).
>
>
>
> -Don
>
>
>
> --
>
> Don MacQueen
>
> Lawrence Livermore National Laboratory
>
> 7000 East Ave., L-627
>
> Livermore, CA 94550
>
> 925-423-1062
>
> Lab cell 925-724-7509
>
>
>
>
>
>
>
> *From: *Bert Gunter <bgunter.4567 at gmail.com>
> *Date: *Monday, August 20, 2018 at 3:38 PM
> *To: *"MacQueen, Don" <macqueen1 at llnl.gov>
> *Cc: *array R-help <r-help at r-project.org>
> *Subject: *Re: [R] plotmath and logical operators?
>
>
>
> This is clumsy and probably subject to considerable improvement, but does
> it work for you:
>
>
>
> left <- quote(x >= 3)
> right <- quote(y <= 3) ## these can be anything
>
>
>
> ## the plot:
>
> plot(1)
>
> eval(substitute(mtext(expression(paste(left, " & ",right))), list(left =
> left, right = right)))
>
>
>
> ## Expression evaluation
>
> eval(substitute(with(df,left & right), list(left = left, right = right)))
>
> Cheers,
>
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
>
>
> On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <
> r-help at r-project.org> wrote:
>
> I would like to use plotmath to annotate a plot with an expression that
> includes a logical operator.
>
> ## works well
> tmp <- expression(x >= 3)
> plot(1)
> mtext(tmp)
>
> ## not so well
> tmp <- expression(x >= 3 &  y <= 3)
> plot(1)
> mtext(tmp)
>
> Although the text that's displayed makes sense, it won't be obvious to my
> non-mathematical audience.
>
> I'd appreciate suggestions.
>
>
> I've found a work-around that gets the annotation to look right
>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>   plot(1)
>   mtext(tmpw)
>
>
> But it breaks my original purpose, illustrated by this example:
>
> df <- data.frame(x=1:5, y=1:5)
> tmp <- expression(x >= 3 & y <= 3)
> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
> with(df, eval(tmp))
> [1] FALSE FALSE  TRUE FALSE FALSE
> with(df, eval(tmpw))
> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE"
> "TRUE  &  FALSE"
>
> Thanks
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Tue Aug 21 04:12:43 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Mon, 20 Aug 2018 19:12:43 -0700
Subject: [R] plotmath and logical operators?
In-Reply-To: <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
 <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
 <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
Message-ID: <CAF8bMcY057MeBdmYgnMmNv0a81YFcjyHQXgVjyRVkkzX3at9Bw@mail.gmail.com>

A generalization of Bert's suggestion is

plotSubset <- function (data, subset, qsubset = substitute(subset))
{
    sdata <- data[eval(qsubset, data), ]
    with(sdata, plot(x, y, main = subsetToPlotmath(expr = qsubset)))
}


subsetToPlotmath <- function(expr) {
    # Argument 'expr': an expression used as subset argument to subset()
    # Return: an expression used by plotmath that is more readable to
non-programming people
    if (is.call(expr)) {
        for(i in seq_along(expr)) {
            expr[[i]] <- subsetToPlotmath(expr[[i]])
        }
        if (is.name(funcName <- expr[[1]]) && !is.null(func <-
env.subsetToPlotmath[[as.character(funcName)]])) {
            expr <- do.call(func, as.list(expr[-1]))
        }
    }
    expr
}
env.subsetToPlotmath <- new.env()
env.subsetToPlotmath[["&"]] <- function(x, y) substitute(x ~ italic(and) ~
y)
env.subsetToPlotmath[["|"]] <- function(x, y) substitute((x) ~ italic(or) ~
(y)) # internal parens not always needed
env.subsetToPlotmath[["log10"]] <- function(x)
substitute(italic(log)[10](x))
env.subsetToPlotmath[["exp"]] <- function(x) substitute(italic(e)^x)

You can add more conversions to the environment env.subsetToPlotmath.

Try it with

> df <- data.frame(x=1:5, y=1:5)
> plotSubset(df, x<1.5 | y>3.5) # see title "(x < 1.5) or (y > 3.5)" and
pts at x=1,4,5.

It doesn't get right the parentheses needed to enforce the order of
evaluation:
it always puts parentheses around the arguments to | and never puts them
around the arguments to &.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Aug 20, 2018 at 4:14 PM, MacQueen, Don via R-help <
r-help at r-project.org> wrote:

> Thanks Bert!
>
> It certainly works for the example (and shows a much deeper understanding
> of eval, substitute, etc. than I have). But it doesn't appear to generalize
> very well in the way I need (which of course I didn't think of mentioning
> until after I sent the email -- sorry).
>
> Suppose subs is any expression that would be valid for the subset argument
> of base::subset, for a given data frame. Then I can extract that subset of
> the data frame by using
>    mydf[  with(mydf, eval(subs)) ,  ]
> (or similar).
>
> Then, having plotted some aspect of that subset, I want to annotate the
> plot with the subset specifications.
>
> I've used this approach to  set up a system that helps me to interactively
> review various subsets of a large set of data. I save the final selected
> subsetting expressions in some sort of data structure, for later use in
> preparing a report using rmarkdown.
>
> I was hoping to use plotmath to improve the appearance of the annotations
> -- but I now think it's not worth this kind of effort. I think I'm going to
> settle for mtext( as.character(subs) ).
>
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Date: Monday, August 20, 2018 at 3:38 PM
> To: "MacQueen, Don" <macqueen1 at llnl.gov>
> Cc: array R-help <r-help at r-project.org>
> Subject: Re: [R] plotmath and logical operators?
>
> This is clumsy and probably subject to considerable improvement, but does
> it work for you:
>
> left <- quote(x >= 3)
> right <- quote(y <= 3) ## these can be anything
>
> ## the plot:
> plot(1)
> eval(substitute(mtext(expression(paste(left, " & ",right))), list(left =
> left, right = right)))
>
> ## Expression evaluation
> eval(substitute(with(df,left & right), list(left = left, right = right)))
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <
> r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
> I would like to use plotmath to annotate a plot with an expression that
> includes a logical operator.
>
> ## works well
> tmp <- expression(x >= 3)
> plot(1)
> mtext(tmp)
>
> ## not so well
> tmp <- expression(x >= 3 &  y <= 3)
> plot(1)
> mtext(tmp)
>
> Although the text that's displayed makes sense, it won't be obvious to my
> non-mathematical audience.
>
> I'd appreciate suggestions.
>
>
> I've found a work-around that gets the annotation to look right
>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>   plot(1)
>   mtext(tmpw)
>
>
> But it breaks my original purpose, illustrated by this example:
>
> df <- data.frame(x=1:5, y=1:5)
> tmp <- expression(x >= 3 & y <= 3)
> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
> with(df, eval(tmp))
> [1] FALSE FALSE  TRUE FALSE FALSE
> with(df, eval(tmpw))
> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE"
> "TRUE  &  FALSE"
>
> Thanks
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Tue Aug 21 06:10:52 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 21 Aug 2018 05:10:52 +0100
Subject: [R] Transforming data for nice output table
In-Reply-To: <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
 <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>
Message-ID: <a204d6bf-6bcc-c72a-8393-01c90e452f1d@sapo.pt>

Hello,

One of those would be with package reshape2.



dta <- read.csv( "http://doylesdartden.com/R/ExampleData.csv")

subdta <- dta[, c("Location", "Year", "GW_Elevation")]

res <- reshape2::dcast(subdta, Location ~ Year, value.var = "GW_Elevation")
names(res)[-1] <- paste("GW_Elevation", names(res)[-1], sep = "_")
head(res)


Hope this helps,

Rui Barradas

On 20/08/2018 21:37, Rui Barradas wrote:
> Hello,
> 
> This is a very frequent question.
> I could rewrite one or two answers taken from StackOverflow:
> 
> https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format 
> 
> 
> 
> But there you will have more options.
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> On 20/08/2018 20:17, David Doyle wrote:
>> Hello everyone,
>>
>> I'm trying to generate tables of my data out of R for my report.
>>
>> My data is setup in the format as follows and the example can be found 
>> at:
>> http://doylesdartden.com/R/ExampleData.csv
>>
>> Location??????? Date??????? Year????? GW_Elevation
>> 127(I)??????? 5/14/2006???? 2006?????? 752.46
>> 119(I)??????? 5/14/2006???? 2006?????? 774.67
>> 127(I)??????? 6/11/2007???? 2007?????? 752.06
>> 119(I)??????? 6/11/2007???? 2007?????? 775.57
>>
>> I would like to generate a table that showed
>>
>> Location??? GW_Elevation 2006??? GW_Elevation 2007??? GW_Elevation 
>> xxx.....
>>
>> 119(I)??????????????????? 774.67????????????????????? 775.57
>> ?????????? xxxx
>> 127(I)??????????????????? 752.46????????????????????? 752.06
>> ?????????? xxxx
>> XXXX????????????????????????? XX?????????????????????????? XX
>>
>> ? Any thoughts on how to transform the data so it would be in this 
>> format??
>>
>> Thank you for your time
>>
>> David Doyle
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipb@rr@d@@ @ending from @@po@pt  Tue Aug 21 06:39:03 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 21 Aug 2018 05:39:03 +0100
Subject: [R] Transforming data for nice output table
In-Reply-To: <a204d6bf-6bcc-c72a-8393-01c90e452f1d@sapo.pt>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
 <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>
 <a204d6bf-6bcc-c72a-8393-01c90e452f1d@sapo.pt>
Message-ID: <faf43c86-d740-fa42-5b3a-65bb949729cb@sapo.pt>

Sorry, there is no need to subset the data frame,

reshape2::dcast(dta, etc)

will do the same.

Rui Barradas

On 21/08/2018 05:10, Rui Barradas wrote:
> Hello,
> 
> One of those would be with package reshape2.
> 
> 
> 
> dta <- read.csv( "http://doylesdartden.com/R/ExampleData.csv")
> 
> subdta <- dta[, c("Location", "Year", "GW_Elevation")]
> 
> res <- reshape2::dcast(subdta, Location ~ Year, value.var = "GW_Elevation")
> names(res)[-1] <- paste("GW_Elevation", names(res)[-1], sep = "_")
> head(res)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> On 20/08/2018 21:37, Rui Barradas wrote:
>> Hello,
>>
>> This is a very frequent question.
>> I could rewrite one or two answers taken from StackOverflow:
>>
>> https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format 
>>
>>
>>
>> But there you will have more options.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> On 20/08/2018 20:17, David Doyle wrote:
>>> Hello everyone,
>>>
>>> I'm trying to generate tables of my data out of R for my report.
>>>
>>> My data is setup in the format as follows and the example can be 
>>> found at:
>>> http://doylesdartden.com/R/ExampleData.csv
>>>
>>> Location??????? Date??????? Year????? GW_Elevation
>>> 127(I)??????? 5/14/2006???? 2006?????? 752.46
>>> 119(I)??????? 5/14/2006???? 2006?????? 774.67
>>> 127(I)??????? 6/11/2007???? 2007?????? 752.06
>>> 119(I)??????? 6/11/2007???? 2007?????? 775.57
>>>
>>> I would like to generate a table that showed
>>>
>>> Location??? GW_Elevation 2006??? GW_Elevation 2007??? GW_Elevation 
>>> xxx.....
>>>
>>> 119(I)??????????????????? 774.67????????????????????? 775.57
>>> ?????????? xxxx
>>> 127(I)??????????????????? 752.46????????????????????? 752.06
>>> ?????????? xxxx
>>> XXXX????????????????????????? XX?????????????????????????? XX
>>>
>>> ? Any thoughts on how to transform the data so it would be in this 
>>> format??
>>>
>>> Thank you for your time
>>>
>>> David Doyle
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ---
>> This email has been checked for viruses by AVG.
>> https://www.avg.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @ending from temple@edu  Tue Aug 21 06:39:17 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Tue, 21 Aug 2018 00:39:17 -0400
Subject: [R] plotmath and logical operators?
In-Reply-To: <CAF8bMcY057MeBdmYgnMmNv0a81YFcjyHQXgVjyRVkkzX3at9Bw@mail.gmail.com>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
 <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
 <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
 <CAF8bMcY057MeBdmYgnMmNv0a81YFcjyHQXgVjyRVkkzX3at9Bw@mail.gmail.com>
Message-ID: <CAGx1TMCDX+X5ieObyNy8iecL_9nDpP2mZsOV1sgsrp-q8qR6gQ@mail.gmail.com>

## I would use microplot in this situation.
## This example produces a pdf file containing the graph.

library(lattice)
library(microplot)

## Hmisc options for pdflatex
## graphics files are .pdf
latexSetOptions()

RtoLatex <- function(subset , subset.char=substitute(subset)) {
  ## you might need some gsub calls in here
  paste0("$", subset.char, "$")
}

plotSubsetLatex <- function (data, subset, qsubset = substitute(subset),
                             ...) {
  sdata <- data[eval(qsubset, data), ]
  myplot <- xyplot( y ~ x , data=sdata)
  latex(myplot,
        ## caption=RtoLatex(subset.char=deparse(qsubset)),  ## use
either caption or colheads
        colheads=paste("\\Large \\strut",                   ##
Hmisc::latex argument
                       RtoLatex(subset.char=deparse(qsubset))),
        collapse=identity, ## collapse is an argument to microplot()
        x.axis=FALSE, y.axis=FALSE, ## x.axis, y.axis are arguments to
as.includegraphics()
        ...) ## arguments to latex() or as.includegraphics() or microplot()
  }


df <- data.frame(x=1:5, y=1:5)
myplot.tex <- plotSubsetLatex(df, x<1.5 | y>3.5, ## see title "(x <
1.5) | (y > 3.5)" and pts at x=1,4,5.
                              height.panel=3, width.panel=3, rowname=NULL)
myplot.tex$file ## pathname to tex file which contains pathname to
component pdf file
## print.default(myplot.tex) ## pathname to tex file and additional
information about component pdf files
myplot.tex ## displays generated pdf file on screen, and pathname to
generated pdf file

On Mon, Aug 20, 2018 at 10:12 PM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> A generalization of Bert's suggestion is
>
> plotSubset <- function (data, subset, qsubset = substitute(subset))
> {
>     sdata <- data[eval(qsubset, data), ]
>     with(sdata, plot(x, y, main = subsetToPlotmath(expr = qsubset)))
> }
>
>
> subsetToPlotmath <- function(expr) {
>     # Argument 'expr': an expression used as subset argument to subset()
>     # Return: an expression used by plotmath that is more readable to
> non-programming people
>     if (is.call(expr)) {
>         for(i in seq_along(expr)) {
>             expr[[i]] <- subsetToPlotmath(expr[[i]])
>         }
>         if (is.name(funcName <- expr[[1]]) && !is.null(func <-
> env.subsetToPlotmath[[as.character(funcName)]])) {
>             expr <- do.call(func, as.list(expr[-1]))
>         }
>     }
>     expr
> }
> env.subsetToPlotmath <- new.env()
> env.subsetToPlotmath[["&"]] <- function(x, y) substitute(x ~ italic(and) ~
> y)
> env.subsetToPlotmath[["|"]] <- function(x, y) substitute((x) ~ italic(or) ~
> (y)) # internal parens not always needed
> env.subsetToPlotmath[["log10"]] <- function(x)
> substitute(italic(log)[10](x))
> env.subsetToPlotmath[["exp"]] <- function(x) substitute(italic(e)^x)
>
> You can add more conversions to the environment env.subsetToPlotmath.
>
> Try it with
>
>> df <- data.frame(x=1:5, y=1:5)
>> plotSubset(df, x<1.5 | y>3.5) # see title "(x < 1.5) or (y > 3.5)" and
> pts at x=1,4,5.
>
> It doesn't get right the parentheses needed to enforce the order of
> evaluation:
> it always puts parentheses around the arguments to | and never puts them
> around the arguments to &.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Aug 20, 2018 at 4:14 PM, MacQueen, Don via R-help <
> r-help at r-project.org> wrote:
>
>> Thanks Bert!
>>
>> It certainly works for the example (and shows a much deeper understanding
>> of eval, substitute, etc. than I have). But it doesn't appear to generalize
>> very well in the way I need (which of course I didn't think of mentioning
>> until after I sent the email -- sorry).
>>
>> Suppose subs is any expression that would be valid for the subset argument
>> of base::subset, for a given data frame. Then I can extract that subset of
>> the data frame by using
>>    mydf[  with(mydf, eval(subs)) ,  ]
>> (or similar).
>>
>> Then, having plotted some aspect of that subset, I want to annotate the
>> plot with the subset specifications.
>>
>> I've used this approach to  set up a system that helps me to interactively
>> review various subsets of a large set of data. I save the final selected
>> subsetting expressions in some sort of data structure, for later use in
>> preparing a report using rmarkdown.
>>
>> I was hoping to use plotmath to improve the appearance of the annotations
>> -- but I now think it's not worth this kind of effort. I think I'm going to
>> settle for mtext( as.character(subs) ).
>>
>> -Don
>>
>> --
>> Don MacQueen
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> Lab cell 925-724-7509
>>
>>
>>
>> From: Bert Gunter <bgunter.4567 at gmail.com>
>> Date: Monday, August 20, 2018 at 3:38 PM
>> To: "MacQueen, Don" <macqueen1 at llnl.gov>
>> Cc: array R-help <r-help at r-project.org>
>> Subject: Re: [R] plotmath and logical operators?
>>
>> This is clumsy and probably subject to considerable improvement, but does
>> it work for you:
>>
>> left <- quote(x >= 3)
>> right <- quote(y <= 3) ## these can be anything
>>
>> ## the plot:
>> plot(1)
>> eval(substitute(mtext(expression(paste(left, " & ",right))), list(left =
>> left, right = right)))
>>
>> ## Expression evaluation
>> eval(substitute(with(df,left & right), list(left = left, right = right)))
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <
>> r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
>> I would like to use plotmath to annotate a plot with an expression that
>> includes a logical operator.
>>
>> ## works well
>> tmp <- expression(x >= 3)
>> plot(1)
>> mtext(tmp)
>>
>> ## not so well
>> tmp <- expression(x >= 3 &  y <= 3)
>> plot(1)
>> mtext(tmp)
>>
>> Although the text that's displayed makes sense, it won't be obvious to my
>> non-mathematical audience.
>>
>> I'd appreciate suggestions.
>>
>>
>> I've found a work-around that gets the annotation to look right
>>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>>   plot(1)
>>   mtext(tmpw)
>>
>>
>> But it breaks my original purpose, illustrated by this example:
>>
>> df <- data.frame(x=1:5, y=1:5)
>> tmp <- expression(x >= 3 & y <= 3)
>> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>> with(df, eval(tmp))
>> [1] FALSE FALSE  TRUE FALSE FALSE
>> with(df, eval(tmpw))
>> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE"
>> "TRUE  &  FALSE"
>>
>> Thanks
>> -Don
>>
>> --
>> Don MacQueen
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> Lab cell 925-724-7509
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giu@epp@cef@lu @ending from gm@il@com  Tue Aug 21 03:59:49 2018
From: giu@epp@cef@lu @ending from gm@il@com (Giuseppa Cefalu)
Date: Mon, 20 Aug 2018 21:59:49 -0400
Subject: [R] (no subject)
Message-ID: <CACGY-iRm=1LFYzhrKQLdrMJxiE9-hA=2wHN51e7BU9492MuNzA@mail.gmail.com>

Hello,

I have  a list of lists.  The lists in the list of lists are file names.  I
use lapply to read and merge the contents of each list in the list of lists
(3 merged contents in this case  which will be the content of 3 files).
Then, I  have to change the name of the 3 resulting files and finally I
have to write the contents of the files to each file.

 lc <- list("test.txt", "test.txt", "test.txt", "test.txt")
 lc1 <- list("test.txt", "test.txt", "test.txt")
 lc2 <- list("test.txt", "test.txt")
#list of lists.  The lists contain file names
 lc <- list(lc, lc1, lc2)
#new names for the three lists in the list of lists
 new_dataFns <- list("name1", "name2", "name3")
 file_paths <- NULL
 new_path <- NULL
#add the file names to the path and read and merge the contents of each
list in the list of lists
 lapply(
    lc,
    function(lc) {
     filenames <- file.path(dataFnsDir, lc)
     dataList= lapply(filenames, function (x) read.table(file=x,
header=TRUE))
     Reduce(function(x,y) merge(x,y), dataList)
     #   print(dataList)

    }
  )

#add the new name of the file to the path total will be 3
paths/fille_newname.tsv.
 lapply(new_path, function(new_path){new_path <- file.path(getwd(),
new_dataFns)

The statements above work because lc and  new_dataFns are global and I can
pass them to the lapply function

#Finally, I need to write the merged contents to the corresponding file
(path/name.tsv).  I tried the following statement, but this does not work.
How can I write the content to each file? I was trying to use list <-
cbind(dataList, new_path) so that afterwards I can get the merged contents
and the file_name from the list and that way write each merged content to
the corresponding file, but it seems that the dataList and the newPath are
not global and the cbind() function does not work.

	[[alternative HTML version deleted]]


From mi@ojpm @ending from gm@il@com  Tue Aug 21 10:48:54 2018
From: mi@ojpm @ending from gm@il@com (John)
Date: Tue, 21 Aug 2018 16:48:54 +0800
Subject: [R] Time series analysis: Granger causality with error-correction
 term
Message-ID: <CABcx46CpZ3T8c5R965AogkKSa=hgXNNq0fefmofZ8=Ham+sgTw@mail.gmail.com>

Hi,

   Which package/function do you recommend for Granger causality between x
and y with an error correction term?

   In my problem, economic theory maintains that x~ I(1); y~I(1), x-y ~I(0)

\begin{eqnarray}
\Delta x_t = g_0 + \lambda_{x}(x_{t-1}-y_{t-1})+\sum_{k=1}^{n}g_{1k}\Delta
x_{t-s}+\sum_{k=1}^{n}g_{2k}\Delta y_{t-s}+\epsilon_{1t}  \\
\Delta y_t = g_0 + \lambda_{y}(x_{t-1}-y_{t-1})+\sum_{k=1}^{n}g_{3k}\Delta
x_{t-s}+\sum_{k=1}^{n}g_{4k}\Delta y_{t-s}+\epsilon_{2t}
\end{eqnarray}

   I am not sure if it would work if I run Granger causality between \Delta
x and \Delta y, treating the error correction term (x_{t-1}-y_{t-1}) and
exogenous variable.

   Thank you very much!!

John

	[[alternative HTML version deleted]]


From ggrothendieck @ending from gm@il@com  Tue Aug 21 14:53:15 2018
From: ggrothendieck @ending from gm@il@com (Gabor Grothendieck)
Date: Tue, 21 Aug 2018 08:53:15 -0400
Subject: [R] plotmath and logical operators?
In-Reply-To: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
Message-ID: <CAP01uRmJ3Bq2J_xOst=-RD9qv0K9yw=CAuc3_djS445vLA+32g@mail.gmail.com>

Try this:

plot(1)
tmp <- x >= 3 ~ "&" ~ y <= 3
mtext(tmp)
On Mon, Aug 20, 2018 at 5:00 PM MacQueen, Don via R-help
<r-help at r-project.org> wrote:
>
> I would like to use plotmath to annotate a plot with an expression that includes a logical operator.
>
> ## works well
> tmp <- expression(x >= 3)
> plot(1)
> mtext(tmp)
>
> ## not so well
> tmp <- expression(x >= 3 &  y <= 3)
> plot(1)
> mtext(tmp)?
>
> Although the text that's displayed makes sense, it won't be obvious to my non-mathematical audience.
>
> I'd appreciate suggestions.
>
>
> I've found a work-around that gets the annotation to look right
>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>   plot(1)
>   mtext(tmpw)
>
>
> But it breaks my original purpose, illustrated by this example:
>
> df <- data.frame(x=1:5, y=1:5)
> tmp <- expression(x >= 3 & y <= 3)
> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
> with(df, eval(tmp))
> [1] FALSE FALSE  TRUE FALSE FALSE
> with(df, eval(tmpw))
> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE" "TRUE  &  FALSE"
>
> Thanks
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jun@y@n @ending from uconn@edu  Tue Aug 21 12:39:46 2018
From: jun@y@n @ending from uconn@edu (Yan, Jun)
Date: Tue, 21 Aug 2018 10:39:46 +0000
Subject: [R] Seeking nomination for the Statistical Computing and Graphics
 Award
Message-ID: <BL0PR05MB46271C19AF334BD2D354F709F0310@BL0PR05MB4627.namprd05.prod.outlook.com>

(apologies for cross posting)

The Statistical Computing and Graphics Award of the?ASA Sections of Statistical Computing and Statistical Graphics?recognizes an individual or team for innovation in computing, software, or graphics that has had a great impact on statistical practice or research. The past awardees include Bill Cleveland (2016) and Robert Gentleman and Ross Ihaka (2010). The prize carries with it a cash award of $5,000 plus an allowance of up to $1,000 for travel to the next Joint Statistical Meetings (JSM) where the award will be presented.

Qualifications
The prize-winning contribution will have had significant and lasting impacts on statistical computing, software or graphics.

The Awards Committee depends on the American Statistical Association membership to submit nominations. Committee members will review the nominations and make the final determination of who, if any, should receive the award. The award may not be given to a sitting member of the Awards Committee or a sitting member of the Executive Committee of the Section of Statistical Computing or the Section of Statistical Graphics.

Nomination and Award Dates
Nominations are due by November 15, 2018 for an award to?be presented at the JSM in the following year. Nominations should be submitted as a complete packet, consisting of:
- a?nomination letter, no longer than four pages, addressing points in the selection criteria
- nominee's curriculum?vita(e)
- a minimum of 3 (and no more than 4) supporting letters, each no longer than two pages

Selection Process
The Awards Committee will consist of the Chairs and Past Chairs of the Sections on Statistical Computing and Statistical Graphics. The selection process will be handled by the Awards Chair of the Statistical Computing Section and the Statistical Graphics Section. Nominations and questions are to be sent to the e-mail address below.

Jun Yan
Professor
University of Connecticut
jun.yan at uconn.edu



 
???

From @bouelm@k@rim1962 @ending from gm@il@com  Tue Aug 21 17:48:29 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Tue, 21 Aug 2018 11:48:29 -0400
Subject: [R] R Codes for Introduction to Data Mining
Message-ID: <CAE9stmfAyfg=_43JZdjfmdnATK3SSUgEdZ_XeN7FQRfmg9hEjA@mail.gmail.com>

Dear All: good morning


I am going to teach a course title "Introduction to Statistical Data
Mining", and I am using the book titled "*Introduction to Data Mining
(Second Edition)*"  by Kumar and etal.

I am wondering if someone have R codes/functions for examples and exercises
given in this textbook.

I thank you all in advance.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Tue Aug 21 18:07:08 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Tue, 21 Aug 2018 16:07:08 +0000
Subject: [R] R Codes for Introduction to Data Mining
In-Reply-To: <CAE9stmfAyfg=_43JZdjfmdnATK3SSUgEdZ_XeN7FQRfmg9hEjA@mail.gmail.com>
References: <CAE9stmfAyfg=_43JZdjfmdnATK3SSUgEdZ_XeN7FQRfmg9hEjA@mail.gmail.com>
Message-ID: <eef2e28c99a146f5b6f8e19875d4545a@tamu.edu>

There are some materials at

https://www-users.cs.umn.edu/~kumar001/dmbook/index.php

Michael Hahsler has code examples at 

https://mhahsler.github.io/Introduction_to_Data_Mining_R_Examples/
https://github.com/mhahsler/Introduction_to_Data_Mining_R_Examples


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of AbouEl-Makarim Aboueissa
Sent: Tuesday, August 21, 2018 10:48 AM
To: R mailing list <r-help at r-project.org>
Subject: [R] R Codes for Introduction to Data Mining

Dear All: good morning


I am going to teach a course title "Introduction to Statistical Data
Mining", and I am using the book titled "*Introduction to Data Mining
(Second Edition)*"  by Kumar and etal.

I am wondering if someone have R codes/functions for examples and exercises
given in this textbook.

I thank you all in advance.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dc@rl@on @ending from t@mu@edu  Tue Aug 21 18:19:39 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Tue, 21 Aug 2018 16:19:39 +0000
Subject: [R] Transforming data for nice output table
In-Reply-To: <faf43c86-d740-fa42-5b3a-65bb949729cb@sapo.pt>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
 <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>
 <a204d6bf-6bcc-c72a-8393-01c90e452f1d@sapo.pt>
 <faf43c86-d740-fa42-5b3a-65bb949729cb@sapo.pt>
Message-ID: <1f276ca2db634df0b1dc57f3c6c0ab23@tamu.edu>

Another approach to adding GW_Elevation to the year value, but the table is more compact with just the year.

dta <- read.csv("http://doylesdartden.com/R/ExampleData.csv")
Years <- paste("GW_Elevation", dta$Year)
xtabs(GW_Elevation~Location+Years, dta)


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Monday, August 20, 2018 11:39 PM
To: David Doyle <kydaviddoyle at gmail.com>; r-help at r-project.org
Subject: Re: [R] Transforming data for nice output table

Sorry, there is no need to subset the data frame,

reshape2::dcast(dta, etc)

will do the same.

Rui Barradas

On 21/08/2018 05:10, Rui Barradas wrote:
> Hello,
> 
> One of those would be with package reshape2.
> 
> 
> 
> dta <- read.csv( "http://doylesdartden.com/R/ExampleData.csv")
> 
> subdta <- dta[, c("Location", "Year", "GW_Elevation")]
> 
> res <- reshape2::dcast(subdta, Location ~ Year, value.var = "GW_Elevation")
> names(res)[-1] <- paste("GW_Elevation", names(res)[-1], sep = "_")
> head(res)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> On 20/08/2018 21:37, Rui Barradas wrote:
>> Hello,
>>
>> This is a very frequent question.
>> I could rewrite one or two answers taken from StackOverflow:
>>
>> https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format 
>>
>>
>>
>> But there you will have more options.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> On 20/08/2018 20:17, David Doyle wrote:
>>> Hello everyone,
>>>
>>> I'm trying to generate tables of my data out of R for my report.
>>>
>>> My data is setup in the format as follows and the example can be 
>>> found at:
>>> http://doylesdartden.com/R/ExampleData.csv
>>>
>>> Location??????? Date??????? Year????? GW_Elevation
>>> 127(I)??????? 5/14/2006???? 2006?????? 752.46
>>> 119(I)??????? 5/14/2006???? 2006?????? 774.67
>>> 127(I)??????? 6/11/2007???? 2007?????? 752.06
>>> 119(I)??????? 6/11/2007???? 2007?????? 775.57
>>>
>>> I would like to generate a table that showed
>>>
>>> Location??? GW_Elevation 2006??? GW_Elevation 2007??? GW_Elevation 
>>> xxx.....
>>>
>>> 119(I)??????????????????? 774.67????????????????????? 775.57
>>> ?????????? xxxx
>>> 127(I)??????????????????? 752.46????????????????????? 752.06
>>> ?????????? xxxx
>>> XXXX????????????????????????? XX?????????????????????????? XX
>>>
>>> ? Any thoughts on how to transform the data so it would be in this 
>>> format??
>>>
>>> Thank you for your time
>>>
>>> David Doyle
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ---
>> This email has been checked for viruses by AVG.
>> https://www.avg.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From @bouelm@k@rim1962 @ending from gm@il@com  Tue Aug 21 18:20:48 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Tue, 21 Aug 2018 12:20:48 -0400
Subject: [R] R Codes for Introduction to Data Mining
In-Reply-To: <eef2e28c99a146f5b6f8e19875d4545a@tamu.edu>
References: <CAE9stmfAyfg=_43JZdjfmdnATK3SSUgEdZ_XeN7FQRfmg9hEjA@mail.gmail.com>
 <eef2e28c99a146f5b6f8e19875d4545a@tamu.edu>
Message-ID: <CAE9stmdShN7haBF3Fq4PFzuZ+GYNMEvmX3HKOuGxzXqK6TY8_w@mail.gmail.com>

Dear David:

Thank you very much

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Tue, Aug 21, 2018 at 12:07 PM David L Carlson <dcarlson at tamu.edu> wrote:

> There are some materials at
>
> https://www-users.cs.umn.edu/~kumar001/dmbook/index.php
>
> Michael Hahsler has code examples at
>
> https://mhahsler.github.io/Introduction_to_Data_Mining_R_Examples/
> https://github.com/mhahsler/Introduction_to_Data_Mining_R_Examples
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> AbouEl-Makarim Aboueissa
> Sent: Tuesday, August 21, 2018 10:48 AM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] R Codes for Introduction to Data Mining
>
> Dear All: good morning
>
>
> I am going to teach a course title "Introduction to Statistical Data
> Mining", and I am using the book titled "*Introduction to Data Mining
> (Second Edition)*"  by Kumar and etal.
>
> I am wondering if someone have R codes/functions for examples and exercises
> given in this textbook.
>
> I thank you all in advance.
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@uljohn32 @ending from gm@il@com  Wed Aug 22 00:13:52 2018
From: p@uljohn32 @ending from gm@il@com (Paul Johnson)
Date: Tue, 21 Aug 2018 17:13:52 -0500
Subject: [R] Transforming data for nice output table
In-Reply-To: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
Message-ID: <CAErODj83TV6Ux0NT129=ONn72BPR0Q1CkUm81foPgFvVUu9f5A@mail.gmail.com>

On Mon, Aug 20, 2018 at 2:17 PM David Doyle <kydaviddoyle at gmail.com> wrote:
>
> Hello everyone,
>
> I'm trying to generate tables of my data out of R for my report.
>
> My data is setup in the format as follows and the example can be found at:
> http://doylesdartden.com/R/ExampleData.csv
>
> Location        Date        Year      GW_Elevation
> 127(I)        5/14/2006     2006       752.46
> 119(I)        5/14/2006     2006       774.67
> 127(I)        6/11/2007     2007       752.06
> 119(I)        6/11/2007     2007       775.57
>
> I would like to generate a table that showed
>
> Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....
>
> 119(I)                    774.67                      775.57
>           xxxx
> 127(I)                    752.46                      752.06
>           xxxx
> XXXX                          XX                           XX
>
>  Any thoughts on how to transform the data so it would be in this format??
>
> Thank you for your time
>
> David Doyle

Dear David

I'd consider studying R's reshape function, it was intended exactly
for this purpose. No reason to adventure into any user-contributed
tidy places to get this done.

dta <- read.csv("http://doylesdartden.com/R/ExampleData.csv")
dta <- dta[c("Location", "Year", "GW_Elevation")]
dta.wide <- reshape(dta, direction = "wide", idvar = "Location",
v.names = "GW_Elevation", timevar = "Year")
head(dta.wide)

  Location GW_Elevation.2006 GW_Elevation.2007 GW_Elevation.2008
1   127(I)            752.46                NA            757.50
2   119(S)            774.67            778.76            776.40
3   132(I)            759.45            761.68            764.27
4   132(S)            761.77            761.04            765.44
5   111(I)            753.52            763.24            764.24
6   111(S)            766.18            772.84            767.41
  GW_Elevation.2009 GW_Elevation.2010 GW_Elevation.2011 GW_Elevation.2012
1            759.90            756.40            759.05            759.31
2            777.59            777.45            778.21            778.13
3            761.90            764.03            763.63            763.99
4            761.21            763.12            762.69            759.57
5            750.85            764.37            762.99            763.90
6            769.77            767.88            767.95            767.19
  GW_Elevation.2013 GW_Elevation.2014 GW_Elevation.2015 GW_Elevation.2016
1            756.07            756.66            757.72            757.66
2            778.88            778.28            775.16            778.28
3            761.22            762.81            762.36            764.46
4            763.19            763.87            761.94            763.90
5            764.42            761.65            764.02            762.93
6            770.20            767.25            767.74            766.87

The main difference between this and your stated target is that your
target column names have spaces in them, which are forbidden in
column names of data frames. Here R used a period for joining strings.
You can override
that if you want to with the reshape function, but usually I'd let the periods
happen.

If you do want to replace period with spaces, it can be done, but you
break the warranty
on other uses of a data frame. (Could get rid of underscore after GW
in same way)

colnames(dta.wide) <- sub("Elevation.", "Elevation ",
colnames(dta.wide), fixed = TRUE)

I'd not try to use that wide frame for many other purposes because of
the spaces, but it works well if you want to make a pleasant table out
of it. For example, xtable is my favorite:

library(xtable)

xt <- xtable(dta.wide)
print(xt)

The latex from that prints out beautifully in a document. The print
method for xtable has a file parameter if you want to save the file.

Good Luck

pj



>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From p@uljohn32 @ending from gm@il@com  Wed Aug 22 00:45:33 2018
From: p@uljohn32 @ending from gm@il@com (Paul Johnson)
Date: Tue, 21 Aug 2018 17:45:33 -0500
Subject: [R] looking for formula parser that allows coefficients
Message-ID: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>

Can you point me at any packages that allow users to write a
formula with coefficients?

I want to write a data simulator that has a matrix X with lots
of columns, and then users can generate predictive models
by entering a formula that uses some of the variables, allowing
interactions, like

y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2

Currently, in the rockchalk package, I have a function simulates
data (genCorrelatedData2), but my interface to enter the beta
coefficients is poor.  I assumed user would always enter 0's as
place holder for the unused coefficients, and the intercept is
always first. The unnamed vector is too confusing.  I have them specify:

c(2, 1.1, 0, 3, 0, 0, 0.2, ...)

I the documentation I say (ridiculously) it is easy to figure out from
the examples, but it really isnt.
It function prints out the equation it thinks you intended, thats
minimum protection against user error, but still not very good:

dat <- genCorrelatedData2(N = 10, rho = 0.0,
          beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
          means = c(0,0,0), sds = c(1,1,1), stde = 0)
[1] "The equation that was calculated was"
y = 1 + 2*x1 + 1*x2 + 1*x3
 + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
 + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
 + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
 + N(0,0) random error

But still, it is not very good.

As I look at this now, I realize expect just the vech, not the whole vector
of all interaction terms, so it is even more difficult than I thought to get the
correct input.Hence, I'd like to let the user write a formula.

The alternative for the user interface is to have named coefficients.
I can more or less easily allow a named vector for beta

beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)

I could build a formula from that.  That's not too bad. But I still think
it would be cool to allow formula input.

Have you ever seen it done?
pj
-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From jfox @ending from mcm@@ter@c@  Wed Aug 22 01:42:04 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Tue, 21 Aug 2018 23:42:04 +0000
Subject: [R] looking for formula parser that allows coefficients
In-Reply-To: <21802_1534891556_w7LMjuVa021775_CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
References: <21802_1534891556_w7LMjuVa021775_CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368957C3@FHSDB2D11-2.csu.mcmaster.ca>

Dear Paul,

Is it possible that you're overthinking this? That is, to you really need an R model formula or just want to evaluate an arithmetic expression using the columns of X?

If the latter, the following approach may work for you:

> evalFormula <- function(X, expr){
+   if (is.null(colnames(X))) colnames(X) <- paste0("x", 1:ncol(X))
+   with(as.data.frame(X), eval(parse(text=expr)))
+ }

> X <- matrix(1:20, 5, 4)
> X
     [,1] [,2] [,3] [,4]
[1,]    1    6   11   16
[2,]    2    7   12   17
[3,]    3    8   13   18
[4,]    4    9   14   19
[5,]    5   10   15   20

> evalFormula(X, '2 + 3*x1 + 4*x2 + 5*x3 + 6*x1*x2')
[1] 120 180 252 336 432

I hope that this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Johnson
> Sent: Tuesday, August 21, 2018 6:46 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] looking for formula parser that allows coefficients
> 
> Can you point me at any packages that allow users to write a formula with
> coefficients?
> 
> I want to write a data simulator that has a matrix X with lots of columns, and
> then users can generate predictive models by entering a formula that uses
> some of the variables, allowing interactions, like
> 
> y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2
> 
> Currently, in the rockchalk package, I have a function simulates data
> (genCorrelatedData2), but my interface to enter the beta coefficients is poor.
> I assumed user would always enter 0's as place holder for the unused
> coefficients, and the intercept is always first. The unnamed vector is too
> confusing.  I have them specify:
> 
> c(2, 1.1, 0, 3, 0, 0, 0.2, ...)
> 
> I the documentation I say (ridiculously) it is easy to figure out from the
> examples, but it really isnt.
> It function prints out the equation it thinks you intended, thats minimum
> protection against user error, but still not very good:
> 
> dat <- genCorrelatedData2(N = 10, rho = 0.0,
>           beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
>           means = c(0,0,0), sds = c(1,1,1), stde = 0) [1] "The equation that was
> calculated was"
> y = 1 + 2*x1 + 1*x2 + 1*x3
>  + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
>  + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
>  + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
>  + N(0,0) random error
> 
> But still, it is not very good.
> 
> As I look at this now, I realize expect just the vech, not the whole vector of all
> interaction terms, so it is even more difficult than I thought to get the correct
> input.Hence, I'd like to let the user write a formula.
> 
> The alternative for the user interface is to have named coefficients.
> I can more or less easily allow a named vector for beta
> 
> beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)
> 
> I could build a formula from that.  That's not too bad. But I still think it would
> be cool to allow formula input.
> 
> Have you ever seen it done?
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> 
> To write to me directly, please address me at pauljohn at ku.edu.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@eb@@ti@ntello @ending from icocommerci@l@co@uk  Wed Aug 22 00:43:43 2018
From: j@eb@@ti@ntello @ending from icocommerci@l@co@uk (jsebastiantello)
Date: Tue, 21 Aug 2018 22:43:43 +0000
Subject: [R] (no subject)
Message-ID: <9EF8D729-E01C-4558-B010-86FE6149DED6@icocommercial.co.uk>

hi R     https://goo.gl/G8X41r


From erinm@hodge@@ @ending from gm@il@com  Wed Aug 22 03:03:24 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Tue, 21 Aug 2018 19:03:24 -0600
Subject: [R] as.Date() function
In-Reply-To: <2071249222.638416.1534896885296@mail.yahoo.com>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
 <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>
 <20180819201627.Horde.q2d4uhEE8_2mg8Bn_ouZiwV@webmail.philipsmith.ca>
 <2071249222.638416.1534896885296@mail.yahoo.com>
Message-ID: <CACxE24muNKTz4Q4j7cMq7A6wqHORNp291gp=g6h-ooxciF_eSw@mail.gmail.com>

Nice one!


On Tue, Aug 21, 2018 at 6:14 PM John Kane <jrkrideau at yahoo.ca> wrote:

> You loaded "lubridate" so using Erin's approach
>
> library(lubridate)
> st <- c("1961-01","1961-04","1983-02")
> dat1 <- ymd(paste( st, "01",  sep ="-"))
>
>
> On Monday, August 20, 2018, 1:15:56 a.m. EDT, <
> philipsm at cpanel1.stormweb.net> wrote:
>
>
> Thanks Erin and Jim. You have indeed solved my problem.
>
> Philip
>
>
> Quoting Erin Hodgess <erinm.hodgess at gmail.com>:
>
> > Hi Philip:
> >
> > Here is something to consider:
> >
> >> #potential solution:
> >> sta <- paste(st,"-01",sep="")
> >> st1 <- as.Date(sta, format=("%Y-%m-%d"))
> >> print(st1)
> > [1] "1961-01-01" "1961-04-01" "1983-02-01"
> >
> >
> > Hope this helps!
> > Erin
> >
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >
> > On Sun, Aug 19, 2018 at 3:25 PM <philipsm at cpanel1.stormweb.net> wrote:
> >
> >> I am having trouble with what must be a very simple problem. Here is a
> >> reproducible example:
> >>
> >> library(lubridate)
> >> st <- c("1961-01","1961-04","1983-02")
> >> print(st)
> >> #[1] "1961-01" "1961-04" "1983-02"
> >> st1 <- as.Date(st, format=("%Y-%m"))
> >> print(st1)
> >> #[1] NA NA NA
> >>
> >> Why the heck am I getting three NAs instead of three Dates?I have
> >> studied the R documentation for as.Date() and it has not turned on the
> >> light bulb for me.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From reichm@nj @ending from @bcglob@l@net  Wed Aug 22 03:44:00 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Tue, 21 Aug 2018 20:44:00 -0500
Subject: [R] How to manually color specific bars
Message-ID: <000401d439b9$9a0467e0$ce0d37a0$@sbcglobal.net>

R-Help Forum

 

While the following code works fine I need to change (highlight) specific
"bars" within plot 2 (p2). For example I want the bars to be  (lets say)
red, on  1 Aug 2016 and 1 Aug 2017 . What do I need to do?

 

library(ggplot2)

library(reshape2)

library(scales)

library(egg)

#data <- dataset

data <- read.csv("~/R/Data_Files/AreaPlotData.csv", stringsAsFactors=FALSE)

data$Serial <- seq.int(nrow(data))

data$min <- pmin(data$Melbourne,data$Sydney)

data <- melt(data, id.vars=c("Serial","min","Timeline"), value.name="Price")

data$Timeline <- as.Date(data$Timeline, format="%m/%d/%Y")

p1 <- ggplot(data, aes(x = Timeline, y = Price)) +

  geom_line(aes(col = variable)) + geom_ribbon(aes(ymin = min, ymax = Price,
fill = variable), alpha = 0.3) + 

  scale_color_manual(values = c("#144A90","#D81F26")) + 

  scale_fill_manual(values = c("#F7A396","#88CADD")) + 

  theme_get() + theme(legend.position="top", legend.title=element_blank()) +

  scale_x_date(labels=date_format("%b%y"))

 

data2 <- read.csv("~/R/Data_Files/AreaPlotData2.csv",
stringsAsFactors=FALSE)

data2$Timeline <- as.Date(data2$Timeline, format="%m/%d/%Y")

p2 <- ggplot(data2, aes(x = Timeline, y=Port)) + 

  geom_bar(stat = "identity", width = 0.1, color = "blue") +

  scale_y_continuous(name="Port Holdings", limits=c(0, 40))

 

ggarrange(p1, p2, heights = c(2, 0.6),ncol = 1, nrow = 2)

 

Jeff


	[[alternative HTML version deleted]]


From reichm@nj @ending from @bcglob@l@net  Wed Aug 22 04:23:06 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Tue, 21 Aug 2018 21:23:06 -0500
Subject: [R] How to manually color specific bars
In-Reply-To: <000401d439b9$9a0467e0$ce0d37a0$@sbcglobal.net>
References: <000401d439b9$9a0467e0$ce0d37a0$@sbcglobal.net>
Message-ID: <000d01d439bf$10a2aba0$31e802e0$@sbcglobal.net>

Please disregard I simply added a highlight variable and added
  
	scale_fill_manual(values = c("Yes"="red", "No"="grey")) 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
Sent: Tuesday, August 21, 2018 8:44 PM
To: r-help at r-project.org
Subject: [R] How to manually color specific bars

R-Help Forum

While the following code works fine I need to change (highlight) specific
"bars" within plot 2 (p2). For example I want the bars to be  (lets say)
red, on  1 Aug 2016 and 1 Aug 2017 . What do I need to do?

library(ggplot2)
library(reshape2)
library(scales)
library(egg)
#data <- dataset
data <- read.csv("~/R/Data_Files/AreaPlotData.csv", stringsAsFactors=FALSE)
data$Serial <- seq.int(nrow(data))
data$min <- pmin(data$Melbourne,data$Sydney)
data <- melt(data, id.vars=c("Serial","min","Timeline"), value.name="Price")
data$Timeline <- as.Date(data$Timeline, format="%m/%d/%Y")
p1 <- ggplot(data, aes(x = Timeline, y = Price)) +
  geom_line(aes(col = variable)) + geom_ribbon(aes(ymin = min, ymax = Price,
fill = variable), alpha = 0.3) + 
  scale_color_manual(values = c("#144A90","#D81F26")) + 
  scale_fill_manual(values = c("#F7A396","#88CADD")) + 
  theme_get() + theme(legend.position="top", legend.title=element_blank()) +
  scale_x_date(labels=date_format("%b%y"))

data2 <- read.csv("~/R/Data_Files/AreaPlotData2.csv",
stringsAsFactors=FALSE)
data2$Timeline <- as.Date(data2$Timeline, format="%m/%d/%Y")
p2 <- ggplot(data2, aes(x = Timeline, y=Port)) + 
  geom_bar(stat = "identity", width = 0.1, color = "blue") +
  scale_y_continuous(name="Port Holdings", limits=c(0, 40))

ggarrange(p1, p2, heights = c(2, 0.6),ncol = 1, nrow = 2)

Jeff


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jrkride@u @ending from y@hoo@c@  Wed Aug 22 02:14:45 2018
From: jrkride@u @ending from y@hoo@c@ (John Kane)
Date: Wed, 22 Aug 2018 00:14:45 +0000 (UTC)
Subject: [R] as.Date() function
In-Reply-To: <20180819201627.Horde.q2d4uhEE8_2mg8Bn_ouZiwV@webmail.philipsmith.ca>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
 <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>
 <20180819201627.Horde.q2d4uhEE8_2mg8Bn_ouZiwV@webmail.philipsmith.ca>
Message-ID: <2071249222.638416.1534896885296@mail.yahoo.com>

You loaded "lubridate" so using Erin's approach 

library(lubridate)
st <- c("1961-01","1961-04","1983-02")
dat1 <- ymd(paste( st, "01",? sep ="-"))
 

    On Monday, August 20, 2018, 1:15:56 a.m. EDT, <philipsm at cpanel1.stormweb.net> wrote:  
 
 Thanks Erin and Jim. You have indeed solved my problem.

Philip


Quoting Erin Hodgess <erinm.hodgess at gmail.com>:

> Hi Philip:
>
> Here is something to consider:
>
>> #potential solution:
>> sta <- paste(st,"-01",sep="")
>> st1 <- as.Date(sta, format=("%Y-%m-%d"))
>> print(st1)
> [1] "1961-01-01" "1961-04-01" "1983-02-01"
>
>
> Hope this helps!
> Erin
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>
> On Sun, Aug 19, 2018 at 3:25 PM <philipsm at cpanel1.stormweb.net> wrote:
>
>> I am having trouble with what must be a very simple problem. Here is a
>> reproducible example:
>>
>> library(lubridate)
>> st <- c("1961-01","1961-04","1983-02")
>> print(st)
>> #[1] "1961-01" "1961-04" "1983-02"
>> st1 <- as.Date(st, format=("%Y-%m"))
>> print(st1)
>> #[1] NA NA NA
>>
>> Why the heck am I getting three NAs instead of three Dates?I have
>> studied the R documentation for as.Date() and it has not turned on the
>> light bulb for me.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From ggrothendieck @ending from gm@il@com  Wed Aug 22 09:33:53 2018
From: ggrothendieck @ending from gm@il@com (Gabor Grothendieck)
Date: Wed, 22 Aug 2018 03:33:53 -0400
Subject: [R] looking for formula parser that allows coefficients
In-Reply-To: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
References: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
Message-ID: <CAP01uRm41Zy-UamFBYshbdRjA9XwnwafQHszYEbH0FjDjE4xCw@mail.gmail.com>

Some string manipulation can convert the formula to a named vector such as
the one shown at the end of your post.

library(gsubfn)

# input
fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2

pat <- "([+-])? *(\\d\\S*)? *\\*? *([[:alpha:]]\\S*)?"
ch <- format(fo[[3]])
m <- matrix(strapplyc(ch, pat)[[1]], 3)
m <- m[, colSums(m != "") > 0]
m[2, m[2, ] == ""] <- 1
m[3, m[3, ] == ""] <- "(Intercept)"
co <- as.numeric(paste0(m[1, ], m[2, ]))
v <- m[3, ]
setNames(co, v)
## (Intercept)          x1          x3       x1:x3       x2:x2
##         2.0        -1.1         1.0        -1.0         0.2
On Tue, Aug 21, 2018 at 6:46 PM Paul Johnson <pauljohn32 at gmail.com> wrote:
>
> Can you point me at any packages that allow users to write a
> formula with coefficients?
>
> I want to write a data simulator that has a matrix X with lots
> of columns, and then users can generate predictive models
> by entering a formula that uses some of the variables, allowing
> interactions, like
>
> y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2
>
> Currently, in the rockchalk package, I have a function simulates
> data (genCorrelatedData2), but my interface to enter the beta
> coefficients is poor.  I assumed user would always enter 0's as
> place holder for the unused coefficients, and the intercept is
> always first. The unnamed vector is too confusing.  I have them specify:
>
> c(2, 1.1, 0, 3, 0, 0, 0.2, ...)
>
> I the documentation I say (ridiculously) it is easy to figure out from
> the examples, but it really isnt.
> It function prints out the equation it thinks you intended, thats
> minimum protection against user error, but still not very good:
>
> dat <- genCorrelatedData2(N = 10, rho = 0.0,
>           beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
>           means = c(0,0,0), sds = c(1,1,1), stde = 0)
> [1] "The equation that was calculated was"
> y = 1 + 2*x1 + 1*x2 + 1*x3
>  + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
>  + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
>  + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
>  + N(0,0) random error
>
> But still, it is not very good.
>
> As I look at this now, I realize expect just the vech, not the whole vector
> of all interaction terms, so it is even more difficult than I thought to get the
> correct input.Hence, I'd like to let the user write a formula.
>
> The alternative for the user interface is to have named coefficients.
> I can more or less easily allow a named vector for beta
>
> beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)
>
> I could build a formula from that.  That's not too bad. But I still think
> it would be cool to allow formula input.
>
> Have you ever seen it done?
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From c@l@ndr@ @ending from rgzm@de  Wed Aug 22 16:33:53 2018
From: c@l@ndr@ @ending from rgzm@de (Ivan Calandra)
Date: Wed, 22 Aug 2018 16:33:53 +0200
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
Message-ID: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>

Dear useRs,

I have just noticed that when input is only NA with na.rm=TRUE, mean() 
results in NaN, whereas median() and sd() produce NA. Shouldn't it all 
be the same? I think NA makes more sense than NaN in that case.

x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1] 
NAsd(x, na.rm=TRUE) [1] NA

Thanks for any feedback.

Best,
Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From bgunter@4567 @ending from gm@il@com  Wed Aug 22 16:47:44 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 22 Aug 2018 07:47:44 -0700
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
Message-ID: <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>

Actually, the dissonance is a bit more basic.

After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
what you see is actually:

> z <- numeric(0)
> mean(z)
[1] NaN
> median(z)
[1] NA
> sd(z)
[1] NA
> sum(z)
[1] 0
etc.

I imagine that there may be more of these little inconsistencies due to the
organic way R evolved over time. What the conventions should be  can be
purely a matter of personal opinion in the absence of accepted standards.
But I would look to see what accepted standards were, if any, first.

-- Bert


On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:

> Dear useRs,
>
> I have just noticed that when input is only NA with na.rm=TRUE, mean()
> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
> be the same? I think NA makes more sense than NaN in that case.
>
> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
> NAsd(x, na.rm=TRUE) [1] NA
>
> Thanks for any feedback.
>
> Best,
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Wed Aug 22 16:47:55 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 22 Aug 2018 10:47:55 -0400
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
Message-ID: <16dd1b74-983e-7617-17ef-0567d3b6cf66@gmail.com>

On 22/08/2018 10:33 AM, Ivan Calandra wrote:
> Dear useRs,
> 
> I have just noticed that when input is only NA with na.rm=TRUE, mean()
> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
> be the same? I think NA makes more sense than NaN in that case.

The mean can be defined as sum(x)/length(x), so if x is length 0, you 
get 0/0 which is NaN.

median(x) is documented in its help page to give NA for x of length 0.

sd(x) is documented to give an error for such x and NA for length 1, but 
it gives NA for both.

Duncan Murdoch
> 
> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
> NAsd(x, na.rm=TRUE) [1] NA
> 
> Thanks for any feedback.
> 
> Best,
> Ivan
>


From bgunter@4567 @ending from gm@il@com  Wed Aug 22 16:55:29 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 22 Aug 2018 07:55:29 -0700
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
Message-ID: <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>

... And FWIW (not much, I agree), note that if z = numeric(0) and sum(z) =
0, then mean(z) = NaN makes sense, as length(z) = 0, so dividing by 0 gives
NaN. So you can see the sorts of issues you may need to consider.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 22, 2018 at 7:47 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Actually, the dissonance is a bit more basic.
>
> After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
> what you see is actually:
>
> > z <- numeric(0)
> > mean(z)
> [1] NaN
> > median(z)
> [1] NA
> > sd(z)
> [1] NA
> > sum(z)
> [1] 0
> etc.
>
> I imagine that there may be more of these little inconsistencies due to
> the organic way R evolved over time. What the conventions should be  can be
> purely a matter of personal opinion in the absence of accepted standards.
> But I would look to see what accepted standards were, if any, first.
>
> -- Bert
>
>
> On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:
>
>> Dear useRs,
>>
>> I have just noticed that when input is only NA with na.rm=TRUE, mean()
>> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
>> be the same? I think NA makes more sense than NaN in that case.
>>
>> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
>> NAsd(x, na.rm=TRUE) [1] NA
>>
>> Thanks for any feedback.
>>
>> Best,
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Aug 22 17:02:13 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 08:02:13 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
Message-ID: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>

   I've not before created bar charts, only scatter plots and box plots.
Checking in Deepayan's book, searching the web, and looking at ?barchart has
not shown me the how to get the results I need.

   The dataframe looks like this:
> head(stage_heights)
   Year   Med   Max
1 1989 91.17 93.32
2 1990 91.22 93.43
3 1991 91.24 92.89
4 1993 91.14 93.02
5 1994 93.92 95.74
6 1995 94.34 96.85

   I want to show Med and Max heights for each Year with each bar having a
different color (or pattern) and a single x-axis year label.

   Trying to follow the example in ?barchart for a single variable produced this:

> barchart('Year' ~ 'Med', data=stage_height, panel=lattice.getOption('panel.barchart'), default.prepanel=lattice.getOption('prepanel.default.barchart'),box.ratio=2)
Error in eval(substitute(groups), data, environment(formula)) :
   invalid 'envir' argument of type 'closure'
and no plot was displayed.

   I must be missing the obvious and want a pointer to descriptions that
teach me how to produce bar charts.

Rich


From giftedlife2014 @ending from gm@il@com  Wed Aug 22 17:02:59 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 22 Aug 2018 16:02:59 +0100
Subject: [R] Monte Carlo on simple regression
Message-ID: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>

Kind R-users,
I run a simple regression. I am interested in using the Monte Carlo to test
the slope parameter.
Here is what I have done:
d1<-read.table("Lightcor",col.names=c("a"))
d2<-read.table("CRcor",col.names=c("a"))
 Li<-d1$a
CR<-d2$a

 fit<-lm(Li~CR)
 a<-summary(fit)
a gives the slope as 88.15

Problem: I now what to repeat the samples to access this coefficient.
Following one of the related examples I got online, I did (tried to modify):

N <- nrow(Li) # returns the number of observations in the dataset
C <- 50         # desired number of subsamples
S <- 38         # desired sample size

sumb2 <- 0
for (i in 1:C){   # a loop over the number of subsamples
  set.seed(3*i)   # a different seed for each subsample
  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
  mod <- lm(Li~CR,data=subsample)
  #sum b2 for all subsamples:
  sumb2 <- sumb2 + coef(mod)[[2]]
}
print(sumb2/C, digits = 3)

   But when I run the script, I had error message:
Error in 1:N : argument of length 0
My data:
Li        CR
74281 8449
92473 8148
62310 8520
71219 8264
33469 8389
75768 7499
61636 7821
103829 8468
87336 8568
129443 8190
97682 8539
106918 8502
97171 8578
48012 8181
93086 8631
92374 8562
113010 8404
66956 8592
133037 8632
108849 8644
81544 8442
105072 8615
143437 7724
153294 7829
123735 8682
154738 8756
100760 8839
108034 8839
81826 8858
116901 8847
80780 8869
122684 8736
141716 9087
144315 9166
162078 9147
163184 9267
150688 9275
200848 9259
221570 8943
192424 8564
173024 9282
197326 9318
209344 9293
220201 9242
212626 9324
218115 9319
170001 9314
187490 9346
172440 9350
180330 9349
200807 9355
234994 9350
139053 9284
150048 9361
203650 9346
233331 9369
198790 9340
164060 9382
198000 9401
201707 9355
179257 9369
188736 9298
243392 9393
246040 9374
269058 9364
201657 9370
187942 9354
228514 9305
234000 9392
224431 9395
163502 9398
I would be most glad for your great assistance.
Many thanks.
Ogbos

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @ending from me@com  Wed Aug 22 17:24:52 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Wed, 22 Aug 2018 11:24:52 -0400
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
 <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
Message-ID: <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>

Hi,

It might even be worthwhile to review this recent thread on R-Devel:

  https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html

which touches upon a subtly related topic vis-a-vis NaN handling.

Regards,

Marc Schwartz


> On Aug 22, 2018, at 10:55 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ... And FWIW (not much, I agree), note that if z = numeric(0) and sum(z) =
> 0, then mean(z) = NaN makes sense, as length(z) = 0, so dividing by 0 gives
> NaN. So you can see the sorts of issues you may need to consider.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Aug 22, 2018 at 7:47 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> Actually, the dissonance is a bit more basic.
>> 
>> After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
>> what you see is actually:
>> 
>>> z <- numeric(0)
>>> mean(z)
>> [1] NaN
>>> median(z)
>> [1] NA
>>> sd(z)
>> [1] NA
>>> sum(z)
>> [1] 0
>> etc.
>> 
>> I imagine that there may be more of these little inconsistencies due to
>> the organic way R evolved over time. What the conventions should be  can be
>> purely a matter of personal opinion in the absence of accepted standards.
>> But I would look to see what accepted standards were, if any, first.
>> 
>> -- Bert
>> 
>> 
>> On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:
>> 
>>> Dear useRs,
>>> 
>>> I have just noticed that when input is only NA with na.rm=TRUE, mean()
>>> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
>>> be the same? I think NA makes more sense than NaN in that case.
>>> 
>>> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
>>> NAsd(x, na.rm=TRUE) [1] NA
>>> 
>>> Thanks for any feedback.
>>> 
>>> Best,
>>> Ivan
>>> 
>>> --
>>> Dr. Ivan Calandra
>>> TraCEr, laboratory for Traceology and Controlled Experiments
>>> MONREPOS Archaeological Research Centre and
>>> Museum for Human Behavioural Evolution
>>> Schloss Monrepos
>>> 56567 Neuwied, Germany
>>> +49 (0) 2631 9772-243
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Wed Aug 22 17:58:01 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 22 Aug 2018 08:58:01 -0700
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>

No reproducible example (see posting guide below) so minimal help.

Remove the quotes from your formula. Why did you think they should be
there? -- see ?formula.

Read the relevant portions of ?xyplot carefully (again?). You seemed to
have missed:

"*Primary variables:* The x and y variables should both be numeric in xyplot,
and an attempt is made to coerce them if not. However, if either is a
factor, the levels of that factor are used as axis labels. In the other
four functions documented here, [ which includes barchart()]  **exactly one
of x and y should be numeric, and the other a factor or shingle**. Which of
these will happen is determined by the horizontal argument ? if
horizontal=TRUE, then y will be coerced to be a factor or shingle, otherwise
 x. The default value of horizontal is FALSE if x is a factor or shingle,
TRUEotherwise. (The functionality provided by horizontal=FALSE is not
S-compatible.)

So with the default ... horizontal = FALSE, Med would be treated as a
factor, which I think is precisely the opposite of what you want.

Here is a simple example to indicate how things work:

y <- runif(5)
x <- factor(letters[1:5])
barchart(y~x)

As for fiddling with the colors and patterns of the bars -- generally a bad
idea , especially fill patterns, btw -- see the "col" argument of
?panel.barchart, which is always where you should look for such info (i.e.
panel.whatever). I don't know whether you can fool with fill patterns* --
it may depend on your graphics device -- but you can google around or see
what trellis.par.get() has available (which can be specified in the
"par.settings" argument list in the call).

* For why fooling with fill patterns is a bad idea, google "moir? patterns".

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 22, 2018 at 8:13 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    I've not before created bar charts, only scatter plots and box plots.
> Checking in Deepayan's book, searching the web, and looking at ?barchart
> has
> not shown me the how to get the results I need.
>
>    The dataframe looks like this:
> > head(stage_heights)
>    Year   Med   Max
> 1 1989 91.17 93.32
> 2 1990 91.22 93.43
> 3 1991 91.24 92.89
> 4 1993 91.14 93.02
> 5 1994 93.92 95.74
> 6 1995 94.34 96.85
>
>    I want to show Med and Max heights for each Year with each bar having a
> different color (or pattern) and a single x-axis year label.
>
>    Trying to follow the example in ?barchart for a single variable
> produced this:
>
> > barchart('Year' ~ 'Med', data=stage_height,
> panel=lattice.getOption('panel.barchart'),
> default.prepanel=lattice.getOption('prepanel.default.barchart'),box.ratio=2)
> Error in eval(substitute(groups), data, environment(formula)) :
>    invalid 'envir' argument of type 'closure'
> and no plot was displayed.
>
>    I must be missing the obvious and want a pointer to descriptions that
> teach me how to produce bar charts.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Wed Aug 22 18:06:18 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 22 Aug 2018 19:06:18 +0300
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
Message-ID: <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>

Li is defined as d1$a which is a vector. You should use

N <- length(Li)

HTH,
Eric


On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Kind R-users,
> I run a simple regression. I am interested in using the Monte Carlo to test
> the slope parameter.
> Here is what I have done:
> d1<-read.table("Lightcor",col.names=c("a"))
> d2<-read.table("CRcor",col.names=c("a"))
>  Li<-d1$a
> CR<-d2$a
>
>  fit<-lm(Li~CR)
>  a<-summary(fit)
> a gives the slope as 88.15
>
> Problem: I now what to repeat the samples to access this coefficient.
> Following one of the related examples I got online, I did (tried to
> modify):
>
> N <- nrow(Li) # returns the number of observations in the dataset
> C <- 50         # desired number of subsamples
> S <- 38         # desired sample size
>
> sumb2 <- 0
> for (i in 1:C){   # a loop over the number of subsamples
>   set.seed(3*i)   # a different seed for each subsample
>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>   mod <- lm(Li~CR,data=subsample)
>   #sum b2 for all subsamples:
>   sumb2 <- sumb2 + coef(mod)[[2]]
> }
> print(sumb2/C, digits = 3)
>
>    But when I run the script, I had error message:
> Error in 1:N : argument of length 0
> My data:
> Li        CR
> 74281 8449
> 92473 8148
> 62310 8520
> 71219 8264
> 33469 8389
> 75768 7499
> 61636 7821
> 103829 8468
> 87336 8568
> 129443 8190
> 97682 8539
> 106918 8502
> 97171 8578
> 48012 8181
> 93086 8631
> 92374 8562
> 113010 8404
> 66956 8592
> 133037 8632
> 108849 8644
> 81544 8442
> 105072 8615
> 143437 7724
> 153294 7829
> 123735 8682
> 154738 8756
> 100760 8839
> 108034 8839
> 81826 8858
> 116901 8847
> 80780 8869
> 122684 8736
> 141716 9087
> 144315 9166
> 162078 9147
> 163184 9267
> 150688 9275
> 200848 9259
> 221570 8943
> 192424 8564
> 173024 9282
> 197326 9318
> 209344 9293
> 220201 9242
> 212626 9324
> 218115 9319
> 170001 9314
> 187490 9346
> 172440 9350
> 180330 9349
> 200807 9355
> 234994 9350
> 139053 9284
> 150048 9361
> 203650 9346
> 233331 9369
> 198790 9340
> 164060 9382
> 198000 9401
> 201707 9355
> 179257 9369
> 188736 9298
> 243392 9393
> 246040 9374
> 269058 9364
> 201657 9370
> 187942 9354
> 228514 9305
> 234000 9392
> 224431 9395
> 163502 9398
> I would be most glad for your great assistance.
> Many thanks.
> Ogbos
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Aug 22 18:17:26 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 09:17:26 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Bert Gunter wrote:

> No reproducible example (see posting guide below) so minimal help.

Hi Bert,

   I thought the header and six data rows of the dataframe plus the syntax of
the command I used were sufficient. Regardless, here's the dput() output:

structure(list(Year = c(1989L, 1990L, 1991L, 1993L, 1994L, 1995L, 
1996L, 1997L, 1998L, 1999L, 2000L, 2001L, 2002L, 2003L, 2004L, 
2005L, 2006L, 2007L, 2008L, 2009L, 2010L, 2011L, 2012L, 2013L, 
2014L, 2015L, 2016L, 2017L, 2018L), Med = c(91.17, 91.22, 91.24, 
91.14, 93.92, 94.34, 91.32, 91.36, 91.24, 94.33, 94.33, 94, 94.32, 
94.02, 94.19, 94.05, 94.21, 94.21, 94.32, 94.13, 94.27, 94.34, 
94.23, 94.25, 94.15, 94.01, 94.09, 94.31, 94.35), Max = c(93.32, 
93.43, 92.89, 93.02, 95.74, 96.85, 95.86, 94.25, 93.67, 97.42, 
97.42, 94.99, 96.58, 96.57, 96.32, 95.96, 97.4, 97.28, 96.72, 
97.43, 95.95, 97.82, 97, 96.6, 96.24, 96.68, 96.96, 96.39, 96.95
)), class = "data.frame", row.names = c(NA, -29L))


> Remove the quotes from your formula. Why did you think they should be
> there? -- see ?formula.

   A prior attempt seemed to suggest the strings needed to be quoted.

> Read the relevant portions of ?xyplot carefully (again?). You seemed to
> have missed:

   I'm trying to create a barchart, not an xyplot.

> y <- runif(5)
> x <- factor(letters[1:5])
> barchart(y~x)

   Okay. I see one error in my command that's fixed here:

barchart(stage_heights$Med ~ stage_heights$Year, horizontal=FALSE)

> As for fiddling with the colors and patterns of the bars -- generally a bad
> idea , especially fill patterns, btw -- see the "col" argument of
> ?panel.barchart, which is always where you should look for such info (i.e.
> panel.whatever). I don't know whether you can fool with fill patterns* --
> it may depend on your graphics device -- but you can google around or see
> what trellis.par.get() has available (which can be specified in the
> "par.settings" argument list in the call).

   I need pairs of bars, one each for Med and Max for each year. Color or
pattern would distinguish the two.

> * For why fooling with fill patterns is a bad idea, google "moir? patterns".

   I did not think that a solid fill or striped fill would create a moire
pattern on either a computer screen viewing a .pdf file or on the printed
page.

   Correcting the barchard() command fixed the main issue; getting the second
set of bars is still eluding me, but I'll continue working on fixing this.
I'll get the years as the x-axis labels rather than year number in sequence
from 1 to 29.

Thanks,

Rich


From giftedlife2014 @ending from gm@il@com  Wed Aug 22 18:20:25 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 22 Aug 2018 17:20:25 +0100
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
Message-ID: <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>

Hello Eric,
Thanks for this.

I tried it. It went but another problem prevents the code from running.
 source("script.R")
Error in Li[sample(1:N, size = S, replace = TRUE), ] :
  incorrect number of dimensions

The error is coming from the line:
 subsample <- Li[sample(1:N, size=S, replace=TRUE), ]

I tried to replace Li with N but it didn't go. I also tried replacing it
with length(Li). The same error remains.

Thank so much for looking at this again.

Ogbos


On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com> wrote:

> Li is defined as d1$a which is a vector. You should use
>
> N <- length(Li)
>
> HTH,
> Eric
>
>
> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
>
>> Kind R-users,
>> I run a simple regression. I am interested in using the Monte Carlo to
>> test
>> the slope parameter.
>> Here is what I have done:
>> d1<-read.table("Lightcor",col.names=c("a"))
>> d2<-read.table("CRcor",col.names=c("a"))
>>  Li<-d1$a
>> CR<-d2$a
>>
>>  fit<-lm(Li~CR)
>>  a<-summary(fit)
>> a gives the slope as 88.15
>>
>> Problem: I now what to repeat the samples to access this coefficient.
>> Following one of the related examples I got online, I did (tried to
>> modify):
>>
>> N <- nrow(Li) # returns the number of observations in the dataset
>> C <- 50         # desired number of subsamples
>> S <- 38         # desired sample size
>>
>> sumb2 <- 0
>> for (i in 1:C){   # a loop over the number of subsamples
>>   set.seed(3*i)   # a different seed for each subsample
>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>   mod <- lm(Li~CR,data=subsample)
>>   #sum b2 for all subsamples:
>>   sumb2 <- sumb2 + coef(mod)[[2]]
>> }
>> print(sumb2/C, digits = 3)
>>
>>    But when I run the script, I had error message:
>> Error in 1:N : argument of length 0
>> My data:
>> Li        CR
>> 74281 8449
>> 92473 8148
>> 62310 8520
>> 71219 8264
>> 33469 8389
>> 75768 7499
>> 61636 7821
>> 103829 8468
>> 87336 8568
>> 129443 8190
>> 97682 8539
>> 106918 8502
>> 97171 8578
>> 48012 8181
>> 93086 8631
>> 92374 8562
>> 113010 8404
>> 66956 8592
>> 133037 8632
>> 108849 8644
>> 81544 8442
>> 105072 8615
>> 143437 7724
>> 153294 7829
>> 123735 8682
>> 154738 8756
>> 100760 8839
>> 108034 8839
>> 81826 8858
>> 116901 8847
>> 80780 8869
>> 122684 8736
>> 141716 9087
>> 144315 9166
>> 162078 9147
>> 163184 9267
>> 150688 9275
>> 200848 9259
>> 221570 8943
>> 192424 8564
>> 173024 9282
>> 197326 9318
>> 209344 9293
>> 220201 9242
>> 212626 9324
>> 218115 9319
>> 170001 9314
>> 187490 9346
>> 172440 9350
>> 180330 9349
>> 200807 9355
>> 234994 9350
>> 139053 9284
>> 150048 9361
>> 203650 9346
>> 233331 9369
>> 198790 9340
>> 164060 9382
>> 198000 9401
>> 201707 9355
>> 179257 9369
>> 188736 9298
>> 243392 9393
>> 246040 9374
>> 269058 9364
>> 201657 9370
>> 187942 9354
>> 228514 9305
>> 234000 9392
>> 224431 9395
>> 163502 9398
>> I would be most glad for your great assistance.
>> Many thanks.
>> Ogbos
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Wed Aug 22 18:28:44 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 22 Aug 2018 17:28:44 +0100
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
 <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
 <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>
Message-ID: <CAC8ss32LL1oU1h72foH77iJ-siADh40v-1v6Hv2pAh0JS-noHA@mail.gmail.com>

Hello Erick,

Thanks again.
Another line indicated error:

source("script.R")
Error in eval(predvars, data, env) :
  numeric 'envir' arg not of length one
Thank you for additional assitance.
Ogbos



On Wed, Aug 22, 2018 at 5:23 PM Eric Berger <ericjberger at gmail.com> wrote:

> You have an extra comma ... it should be
>
> Li[sample(1:N, size = S, replace = TRUE)]
>
> i.e. no comma after the closing parenthesis
>
>
>
> On Wed, Aug 22, 2018 at 7:20 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
>
>> Hello Eric,
>> Thanks for this.
>>
>> I tried it. It went but another problem prevents the code from running.
>>  source("script.R")
>> Error in Li[sample(1:N, size = S, replace = TRUE), ] :
>>   incorrect number of dimensions
>>
>> The error is coming from the line:
>>  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>
>> I tried to replace Li with N but it didn't go. I also tried replacing it
>> with length(Li). The same error remains.
>>
>> Thank so much for looking at this again.
>>
>> Ogbos
>>
>>
>> On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com>
>> wrote:
>>
>>> Li is defined as d1$a which is a vector. You should use
>>>
>>> N <- length(Li)
>>>
>>> HTH,
>>> Eric
>>>
>>>
>>> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>>> wrote:
>>>
>>>> Kind R-users,
>>>> I run a simple regression. I am interested in using the Monte Carlo to
>>>> test
>>>> the slope parameter.
>>>> Here is what I have done:
>>>> d1<-read.table("Lightcor",col.names=c("a"))
>>>> d2<-read.table("CRcor",col.names=c("a"))
>>>>  Li<-d1$a
>>>> CR<-d2$a
>>>>
>>>>  fit<-lm(Li~CR)
>>>>  a<-summary(fit)
>>>> a gives the slope as 88.15
>>>>
>>>> Problem: I now what to repeat the samples to access this coefficient.
>>>> Following one of the related examples I got online, I did (tried to
>>>> modify):
>>>>
>>>> N <- nrow(Li) # returns the number of observations in the dataset
>>>> C <- 50         # desired number of subsamples
>>>> S <- 38         # desired sample size
>>>>
>>>> sumb2 <- 0
>>>> for (i in 1:C){   # a loop over the number of subsamples
>>>>   set.seed(3*i)   # a different seed for each subsample
>>>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>>   mod <- lm(Li~CR,data=subsample)
>>>>   #sum b2 for all subsamples:
>>>>   sumb2 <- sumb2 + coef(mod)[[2]]
>>>> }
>>>> print(sumb2/C, digits = 3)
>>>>
>>>>    But when I run the script, I had error message:
>>>> Error in 1:N : argument of length 0
>>>> My data:
>>>> Li        CR
>>>> 74281 8449
>>>> 92473 8148
>>>> 62310 8520
>>>> 71219 8264
>>>> 33469 8389
>>>> 75768 7499
>>>> 61636 7821
>>>> 103829 8468
>>>> 87336 8568
>>>> 129443 8190
>>>> 97682 8539
>>>> 106918 8502
>>>> 97171 8578
>>>> 48012 8181
>>>> 93086 8631
>>>> 92374 8562
>>>> 113010 8404
>>>> 66956 8592
>>>> 133037 8632
>>>> 108849 8644
>>>> 81544 8442
>>>> 105072 8615
>>>> 143437 7724
>>>> 153294 7829
>>>> 123735 8682
>>>> 154738 8756
>>>> 100760 8839
>>>> 108034 8839
>>>> 81826 8858
>>>> 116901 8847
>>>> 80780 8869
>>>> 122684 8736
>>>> 141716 9087
>>>> 144315 9166
>>>> 162078 9147
>>>> 163184 9267
>>>> 150688 9275
>>>> 200848 9259
>>>> 221570 8943
>>>> 192424 8564
>>>> 173024 9282
>>>> 197326 9318
>>>> 209344 9293
>>>> 220201 9242
>>>> 212626 9324
>>>> 218115 9319
>>>> 170001 9314
>>>> 187490 9346
>>>> 172440 9350
>>>> 180330 9349
>>>> 200807 9355
>>>> 234994 9350
>>>> 139053 9284
>>>> 150048 9361
>>>> 203650 9346
>>>> 233331 9369
>>>> 198790 9340
>>>> 164060 9382
>>>> 198000 9401
>>>> 201707 9355
>>>> 179257 9369
>>>> 188736 9298
>>>> 243392 9393
>>>> 246040 9374
>>>> 269058 9364
>>>> 201657 9370
>>>> 187942 9354
>>>> 228514 9305
>>>> 234000 9392
>>>> 224431 9395
>>>> 163502 9398
>>>> I would be most glad for your great assistance.
>>>> Many thanks.
>>>> Ogbos
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Wed Aug 22 18:23:28 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 22 Aug 2018 19:23:28 +0300
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
 <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
Message-ID: <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>

You have an extra comma ... it should be

Li[sample(1:N, size = S, replace = TRUE)]

i.e. no comma after the closing parenthesis



On Wed, Aug 22, 2018 at 7:20 PM, Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Hello Eric,
> Thanks for this.
>
> I tried it. It went but another problem prevents the code from running.
>  source("script.R")
> Error in Li[sample(1:N, size = S, replace = TRUE), ] :
>   incorrect number of dimensions
>
> The error is coming from the line:
>  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>
> I tried to replace Li with N but it didn't go. I also tried replacing it
> with length(Li). The same error remains.
>
> Thank so much for looking at this again.
>
> Ogbos
>
>
> On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> Li is defined as d1$a which is a vector. You should use
>>
>> N <- length(Li)
>>
>> HTH,
>> Eric
>>
>>
>> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>>
>>> Kind R-users,
>>> I run a simple regression. I am interested in using the Monte Carlo to
>>> test
>>> the slope parameter.
>>> Here is what I have done:
>>> d1<-read.table("Lightcor",col.names=c("a"))
>>> d2<-read.table("CRcor",col.names=c("a"))
>>>  Li<-d1$a
>>> CR<-d2$a
>>>
>>>  fit<-lm(Li~CR)
>>>  a<-summary(fit)
>>> a gives the slope as 88.15
>>>
>>> Problem: I now what to repeat the samples to access this coefficient.
>>> Following one of the related examples I got online, I did (tried to
>>> modify):
>>>
>>> N <- nrow(Li) # returns the number of observations in the dataset
>>> C <- 50         # desired number of subsamples
>>> S <- 38         # desired sample size
>>>
>>> sumb2 <- 0
>>> for (i in 1:C){   # a loop over the number of subsamples
>>>   set.seed(3*i)   # a different seed for each subsample
>>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>   mod <- lm(Li~CR,data=subsample)
>>>   #sum b2 for all subsamples:
>>>   sumb2 <- sumb2 + coef(mod)[[2]]
>>> }
>>> print(sumb2/C, digits = 3)
>>>
>>>    But when I run the script, I had error message:
>>> Error in 1:N : argument of length 0
>>> My data:
>>> Li        CR
>>> 74281 8449
>>> 92473 8148
>>> 62310 8520
>>> 71219 8264
>>> 33469 8389
>>> 75768 7499
>>> 61636 7821
>>> 103829 8468
>>> 87336 8568
>>> 129443 8190
>>> 97682 8539
>>> 106918 8502
>>> 97171 8578
>>> 48012 8181
>>> 93086 8631
>>> 92374 8562
>>> 113010 8404
>>> 66956 8592
>>> 133037 8632
>>> 108849 8644
>>> 81544 8442
>>> 105072 8615
>>> 143437 7724
>>> 153294 7829
>>> 123735 8682
>>> 154738 8756
>>> 100760 8839
>>> 108034 8839
>>> 81826 8858
>>> 116901 8847
>>> 80780 8869
>>> 122684 8736
>>> 141716 9087
>>> 144315 9166
>>> 162078 9147
>>> 163184 9267
>>> 150688 9275
>>> 200848 9259
>>> 221570 8943
>>> 192424 8564
>>> 173024 9282
>>> 197326 9318
>>> 209344 9293
>>> 220201 9242
>>> 212626 9324
>>> 218115 9319
>>> 170001 9314
>>> 187490 9346
>>> 172440 9350
>>> 180330 9349
>>> 200807 9355
>>> 234994 9350
>>> 139053 9284
>>> 150048 9361
>>> 203650 9346
>>> 233331 9369
>>> 198790 9340
>>> 164060 9382
>>> 198000 9401
>>> 201707 9355
>>> 179257 9369
>>> 188736 9298
>>> 243392 9393
>>> 246040 9374
>>> 269058 9364
>>> 201657 9370
>>> 187942 9354
>>> 228514 9305
>>> 234000 9392
>>> 224431 9395
>>> 163502 9398
>>> I would be most glad for your great assistance.
>>> Many thanks.
>>> Ogbos
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]


From ted@h@rding @ending from wl@ndre@@net  Wed Aug 22 18:41:18 2018
From: ted@h@rding @ending from wl@ndre@@net (Ted Harding)
Date: Wed, 22 Aug 2018 17:41:18 +0100
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
 <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
 <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>
Message-ID: <1534956078.6967.24.camel@deb2.fort.knox.uk>

I think that one can usefully look at this question from the
point of view of what "NaN" and "NA" are abbreviations for
(at any rate, according to the understanding I have adopted
since many years -- maybe over-simplified).

NaN: Mot a Number
NA: Not Available

So NA is typically used for missing values, whereas NaN
represents the reults of numerical calculations which
cannot give a result which is a definite number,

Hence 0/0 is not a number, so NaN; similarly Inf/Inf.

Thus, with your x <- c(NA, NA, NA) mean(x, na.rm=TRUE)
sum(x, na.rm=TRUE) = 0, since the set of values of x
with na.rm=TRUE is empty so the number of elements
in x is 0; hence mean = 0/0 = NaN.

But for median(x, na.rm=TRUE), because there are no available
elements in x with na.rm=TRUE, and the median is found by
searching among available elements for the value which
divides the set of values into two halves, the median
is not available, hence NA.

Best wishes to all,
Ted.

On Wed, 2018-08-22 at 11:24 -0400, Marc Schwartz via R-help wrote:
> Hi,
> 
> It might even be worthwhile to review this recent thread on R-Devel:
> 
>   https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html
> 
> which touches upon a subtly related topic vis-a-vis NaN handling.
> 
> Regards,
> 
> Marc Schwartz
> 
> 
> > On Aug 22, 2018, at 10:55 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > 
> > ... And FWIW (not much, I agree), note that if z = numeric(0) and sum(z) =
> > 0, then mean(z) = NaN makes sense, as length(z) = 0, so dividing by 0 gives
> > NaN. So you can see the sorts of issues you may need to consider.
> > 
> > Bert Gunter
> > 
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > 
> > 
> > On Wed, Aug 22, 2018 at 7:47 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > 
> >> Actually, the dissonance is a bit more basic.
> >> 
> >> After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
> >> what you see is actually:
> >> 
> >>> z <- numeric(0)
> >>> mean(z)
> >> [1] NaN
> >>> median(z)
> >> [1] NA
> >>> sd(z)
> >> [1] NA
> >>> sum(z)
> >> [1] 0
> >> etc.
> >> 
> >> I imagine that there may be more of these little inconsistencies due to
> >> the organic way R evolved over time. What the conventions should be  can be
> >> purely a matter of personal opinion in the absence of accepted standards.
> >> But I would look to see what accepted standards were, if any, first.
> >> 
> >> -- Bert
> >> 
> >> 
> >> On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:
> >> 
> >>> Dear useRs,
> >>> 
> >>> I have just noticed that when input is only NA with na.rm=TRUE, mean()
> >>> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
> >>> be the same? I think NA makes more sense than NaN in that case.
> >>> 
> >>> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
> >>> NAsd(x, na.rm=TRUE) [1] NA
> >>> 
> >>> Thanks for any feedback.
> >>> 
> >>> Best,
> >>> Ivan
> >>> 
> >>> --
> >>> Dr. Ivan Calandra
> >>> TraCEr, laboratory for Traceology and Controlled Experiments
> >>> MONREPOS Archaeological Research Centre and
> >>> Museum for Human Behavioural Evolution
> >>> Schloss Monrepos
> >>> 56567 Neuwied, Germany
> >>> +49 (0) 2631 9772-243
> >>> https://www.researchgate.net/profile/Ivan_Calandra
> >>> 
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>> 
> >> 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ericjberger @ending from gm@il@com  Wed Aug 22 18:44:35 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 22 Aug 2018 19:44:35 +0300
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAC8ss32LL1oU1h72foH77iJ-siADh40v-1v6Hv2pAh0JS-noHA@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
 <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
 <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>
 <CAC8ss32LL1oU1h72foH77iJ-siADh40v-1v6Hv2pAh0JS-noHA@mail.gmail.com>
Message-ID: <CAGgJW77EjgHBrG8i4P82tKfMuU0Zi6LtqYc6yFgpBNhoehi+7w@mail.gmail.com>

Hi Ogbos,
I took a closer look at your code.
Here's a modified version (using dummy data) that seems to do what you want.
Hopefully this will make it clear what you need to to.

nn <- 100
lDf <- data.frame(Li=rnorm(nn),CR=rnorm(nn))

fit<-lm(Li~CR, data=lDf)
a<-summary(fit)

N <- nrow(lDf)
C <- 50         # desired number of subsamples
S <- 38         # desired sample size

sumb2 <- 0
for (i in 1:C){   # a loop over the number of subsamples
  set.seed(3*i)   # a different seed for each subsample
  subsample <- lDf[sample(1:N, size=S, replace=TRUE), ]
  mod <- lm(Li~CR,data=subsample)
  #sum b2 for all subsamples:
  sumb2 <- sumb2 + coef(mod)[[2]]
}
print(sumb2/C, digits = 3)

Best,
Eric



On Wed, Aug 22, 2018 at 7:28 PM, Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Hello Erick,
>
> Thanks again.
> Another line indicated error:
>
> source("script.R")
> Error in eval(predvars, data, env) :
>   numeric 'envir' arg not of length one
> Thank you for additional assitance.
> Ogbos
>
>
>
> On Wed, Aug 22, 2018 at 5:23 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> You have an extra comma ... it should be
>>
>> Li[sample(1:N, size = S, replace = TRUE)]
>>
>> i.e. no comma after the closing parenthesis
>>
>>
>>
>> On Wed, Aug 22, 2018 at 7:20 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>>
>>> Hello Eric,
>>> Thanks for this.
>>>
>>> I tried it. It went but another problem prevents the code from running.
>>>  source("script.R")
>>> Error in Li[sample(1:N, size = S, replace = TRUE), ] :
>>>   incorrect number of dimensions
>>>
>>> The error is coming from the line:
>>>  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>
>>> I tried to replace Li with N but it didn't go. I also tried replacing it
>>> with length(Li). The same error remains.
>>>
>>> Thank so much for looking at this again.
>>>
>>> Ogbos
>>>
>>>
>>> On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com>
>>> wrote:
>>>
>>>> Li is defined as d1$a which is a vector. You should use
>>>>
>>>> N <- length(Li)
>>>>
>>>> HTH,
>>>> Eric
>>>>
>>>>
>>>> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>>>> wrote:
>>>>
>>>>> Kind R-users,
>>>>> I run a simple regression. I am interested in using the Monte Carlo to
>>>>> test
>>>>> the slope parameter.
>>>>> Here is what I have done:
>>>>> d1<-read.table("Lightcor",col.names=c("a"))
>>>>> d2<-read.table("CRcor",col.names=c("a"))
>>>>>  Li<-d1$a
>>>>> CR<-d2$a
>>>>>
>>>>>  fit<-lm(Li~CR)
>>>>>  a<-summary(fit)
>>>>> a gives the slope as 88.15
>>>>>
>>>>> Problem: I now what to repeat the samples to access this coefficient.
>>>>> Following one of the related examples I got online, I did (tried to
>>>>> modify):
>>>>>
>>>>> N <- nrow(Li) # returns the number of observations in the dataset
>>>>> C <- 50         # desired number of subsamples
>>>>> S <- 38         # desired sample size
>>>>>
>>>>> sumb2 <- 0
>>>>> for (i in 1:C){   # a loop over the number of subsamples
>>>>>   set.seed(3*i)   # a different seed for each subsample
>>>>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>>>   mod <- lm(Li~CR,data=subsample)
>>>>>   #sum b2 for all subsamples:
>>>>>   sumb2 <- sumb2 + coef(mod)[[2]]
>>>>> }
>>>>> print(sumb2/C, digits = 3)
>>>>>
>>>>>    But when I run the script, I had error message:
>>>>> Error in 1:N : argument of length 0
>>>>> My data:
>>>>> Li        CR
>>>>> 74281 8449
>>>>> 92473 8148
>>>>> 62310 8520
>>>>> 71219 8264
>>>>> 33469 8389
>>>>> 75768 7499
>>>>> 61636 7821
>>>>> 103829 8468
>>>>> 87336 8568
>>>>> 129443 8190
>>>>> 97682 8539
>>>>> 106918 8502
>>>>> 97171 8578
>>>>> 48012 8181
>>>>> 93086 8631
>>>>> 92374 8562
>>>>> 113010 8404
>>>>> 66956 8592
>>>>> 133037 8632
>>>>> 108849 8644
>>>>> 81544 8442
>>>>> 105072 8615
>>>>> 143437 7724
>>>>> 153294 7829
>>>>> 123735 8682
>>>>> 154738 8756
>>>>> 100760 8839
>>>>> 108034 8839
>>>>> 81826 8858
>>>>> 116901 8847
>>>>> 80780 8869
>>>>> 122684 8736
>>>>> 141716 9087
>>>>> 144315 9166
>>>>> 162078 9147
>>>>> 163184 9267
>>>>> 150688 9275
>>>>> 200848 9259
>>>>> 221570 8943
>>>>> 192424 8564
>>>>> 173024 9282
>>>>> 197326 9318
>>>>> 209344 9293
>>>>> 220201 9242
>>>>> 212626 9324
>>>>> 218115 9319
>>>>> 170001 9314
>>>>> 187490 9346
>>>>> 172440 9350
>>>>> 180330 9349
>>>>> 200807 9355
>>>>> 234994 9350
>>>>> 139053 9284
>>>>> 150048 9361
>>>>> 203650 9346
>>>>> 233331 9369
>>>>> 198790 9340
>>>>> 164060 9382
>>>>> 198000 9401
>>>>> 201707 9355
>>>>> 179257 9369
>>>>> 188736 9298
>>>>> 243392 9393
>>>>> 246040 9374
>>>>> 269058 9364
>>>>> 201657 9370
>>>>> 187942 9354
>>>>> 228514 9305
>>>>> 234000 9392
>>>>> 224431 9395
>>>>> 163502 9398
>>>>> I would be most glad for your great assistance.
>>>>> Many thanks.
>>>>> Ogbos
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Aug 22 19:08:55 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 22 Aug 2018 10:08:55 -0700
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQXZ5cKo=CsrZR2JrtDJ=Y2GsKYnJ38dj6KYsc1snrxEQ@mail.gmail.com>

See inline.

-- Bert



On Wed, Aug 22, 2018 at 9:17 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 22 Aug 2018, Bert Gunter wrote:
>
> > No reproducible example (see posting guide below) so minimal help.
>
> Hi Bert,
>
>    I thought the header and six data rows of the dataframe plus the syntax
> of
> the command I used were sufficient. Regardless, here's the dput() output:
>
> structure(list(Year = c(1989L, 1990L, 1991L, 1993L, 1994L, 1995L,
> 1996L, 1997L, 1998L, 1999L, 2000L, 2001L, 2002L, 2003L, 2004L,
> 2005L, 2006L, 2007L, 2008L, 2009L, 2010L, 2011L, 2012L, 2013L,
> 2014L, 2015L, 2016L, 2017L, 2018L), Med = c(91.17, 91.22, 91.24,
> 91.14, 93.92, 94.34, 91.32, 91.36, 91.24, 94.33, 94.33, 94, 94.32,
> 94.02, 94.19, 94.05, 94.21, 94.21, 94.32, 94.13, 94.27, 94.34,
> 94.23, 94.25, 94.15, 94.01, 94.09, 94.31, 94.35), Max = c(93.32,
> 93.43, 92.89, 93.02, 95.74, 96.85, 95.86, 94.25, 93.67, 97.42,
> 97.42, 94.99, 96.58, 96.57, 96.32, 95.96, 97.4, 97.28, 96.72,
> 97.43, 95.95, 97.82, 97, 96.6, 96.24, 96.68, 96.96, 96.39, 96.95
> )), class = "data.frame", row.names = c(NA, -29L))
>
>
> > Remove the quotes from your formula. Why did you think they should be
> > there? -- see ?formula.
>
>    A prior attempt seemed to suggest the strings needed to be quoted.
>
> > Read the relevant portions of ?xyplot carefully (again?). You seemed to
> > have missed:
>
>    I'm trying to create a barchart, not an xyplot.
>

Please see ?xyplot, where you will also see dotplot, barchart, etc.
documented !

>
> > y <- runif(5)
> > x <- factor(letters[1:5])
> > barchart(y~x)
>
>    Okay. I see one error in my command that's fixed here:
>
> barchart(stage_heights$Med ~ stage_heights$Year, horizontal=FALSE)
>
> > As for fiddling with the colors and patterns of the bars -- generally a
> bad
> > idea , especially fill patterns, btw -- see the "col" argument of
> > ?panel.barchart, which is always where you should look for such info
> (i.e.
> > panel.whatever). I don't know whether you can fool with fill patterns* --
> > it may depend on your graphics device -- but you can google around or see
> > what trellis.par.get() has available (which can be specified in the
> > "par.settings" argument list in the call).
>
>    I need pairs of bars, one each for Med and Max for each year. Color or
> pattern would distinguish the two.
>

?xyplot tells you about the "groups" argument that does exactly this.
Again, please read the relevant sections of ?xyplot carefully.


> > * For why fooling with fill patterns is a bad idea, google "moir?
> patterns".
>
>    I did not think that a solid fill or striped fill would create a moire
> pattern on either a computer screen viewing a .pdf file or on the printed
> page.
>

I agree. But color alone usually is the better classifier and suffices; in
black and white, light gray vs. black would work as well for just two
categories I think.



>
>    Correcting the barchard() command fixed the main issue; getting the
> second
> set of bars is still eluding me, but I'll continue working on fixing this.
> I'll get the years as the x-axis labels rather than year number in sequence
> from 1 to 29.
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Wed Aug 22 19:14:33 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Wed, 22 Aug 2018 18:14:33 +0100
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAGgJW77EjgHBrG8i4P82tKfMuU0Zi6LtqYc6yFgpBNhoehi+7w@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
 <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
 <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>
 <CAC8ss32LL1oU1h72foH77iJ-siADh40v-1v6Hv2pAh0JS-noHA@mail.gmail.com>
 <CAGgJW77EjgHBrG8i4P82tKfMuU0Zi6LtqYc6yFgpBNhoehi+7w@mail.gmail.com>
Message-ID: <CAC8ss30V2CVkAsQ465x-shCuQpDW3CEMH9YchDYSZeDO25Cxfg@mail.gmail.com>

Dear Erick,

This is great!!
Many thanks for resolving the problem.
Ogbos

On Wed, Aug 22, 2018 at 5:44 PM Eric Berger <ericjberger at gmail.com> wrote:

> Hi Ogbos,
> I took a closer look at your code.
> Here's a modified version (using dummy data) that seems to do what you
> want.
> Hopefully this will make it clear what you need to to.
>
> nn <- 100
> lDf <- data.frame(Li=rnorm(nn),CR=rnorm(nn))
>
> fit<-lm(Li~CR, data=lDf)
> a<-summary(fit)
>
> N <- nrow(lDf)
> C <- 50         # desired number of subsamples
> S <- 38         # desired sample size
>
> sumb2 <- 0
> for (i in 1:C){   # a loop over the number of subsamples
>   set.seed(3*i)   # a different seed for each subsample
>   subsample <- lDf[sample(1:N, size=S, replace=TRUE), ]
>   mod <- lm(Li~CR,data=subsample)
>   #sum b2 for all subsamples:
>   sumb2 <- sumb2 + coef(mod)[[2]]
> }
> print(sumb2/C, digits = 3)
>
> Best,
> Eric
>
>
>
> On Wed, Aug 22, 2018 at 7:28 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
>
>> Hello Erick,
>>
>> Thanks again.
>> Another line indicated error:
>>
>> source("script.R")
>> Error in eval(predvars, data, env) :
>>   numeric 'envir' arg not of length one
>> Thank you for additional assitance.
>> Ogbos
>>
>>
>>
>> On Wed, Aug 22, 2018 at 5:23 PM Eric Berger <ericjberger at gmail.com>
>> wrote:
>>
>>> You have an extra comma ... it should be
>>>
>>> Li[sample(1:N, size = S, replace = TRUE)]
>>>
>>> i.e. no comma after the closing parenthesis
>>>
>>>
>>>
>>> On Wed, Aug 22, 2018 at 7:20 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>>> wrote:
>>>
>>>> Hello Eric,
>>>> Thanks for this.
>>>>
>>>> I tried it. It went but another problem prevents the code from
>>>> running.
>>>>  source("script.R")
>>>> Error in Li[sample(1:N, size = S, replace = TRUE), ] :
>>>>   incorrect number of dimensions
>>>>
>>>> The error is coming from the line:
>>>>  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>>
>>>> I tried to replace Li with N but it didn't go. I also tried replacing
>>>> it with length(Li). The same error remains.
>>>>
>>>> Thank so much for looking at this again.
>>>>
>>>> Ogbos
>>>>
>>>>
>>>> On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com>
>>>> wrote:
>>>>
>>>>> Li is defined as d1$a which is a vector. You should use
>>>>>
>>>>> N <- length(Li)
>>>>>
>>>>> HTH,
>>>>> Eric
>>>>>
>>>>>
>>>>> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com
>>>>> > wrote:
>>>>>
>>>>>> Kind R-users,
>>>>>> I run a simple regression. I am interested in using the Monte Carlo
>>>>>> to test
>>>>>> the slope parameter.
>>>>>> Here is what I have done:
>>>>>> d1<-read.table("Lightcor",col.names=c("a"))
>>>>>> d2<-read.table("CRcor",col.names=c("a"))
>>>>>>  Li<-d1$a
>>>>>> CR<-d2$a
>>>>>>
>>>>>>  fit<-lm(Li~CR)
>>>>>>  a<-summary(fit)
>>>>>> a gives the slope as 88.15
>>>>>>
>>>>>> Problem: I now what to repeat the samples to access this coefficient.
>>>>>> Following one of the related examples I got online, I did (tried to
>>>>>> modify):
>>>>>>
>>>>>> N <- nrow(Li) # returns the number of observations in the dataset
>>>>>> C <- 50         # desired number of subsamples
>>>>>> S <- 38         # desired sample size
>>>>>>
>>>>>> sumb2 <- 0
>>>>>> for (i in 1:C){   # a loop over the number of subsamples
>>>>>>   set.seed(3*i)   # a different seed for each subsample
>>>>>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>>>>   mod <- lm(Li~CR,data=subsample)
>>>>>>   #sum b2 for all subsamples:
>>>>>>   sumb2 <- sumb2 + coef(mod)[[2]]
>>>>>> }
>>>>>> print(sumb2/C, digits = 3)
>>>>>>
>>>>>>    But when I run the script, I had error message:
>>>>>> Error in 1:N : argument of length 0
>>>>>> My data:
>>>>>> Li        CR
>>>>>> 74281 8449
>>>>>> 92473 8148
>>>>>> 62310 8520
>>>>>> 71219 8264
>>>>>> 33469 8389
>>>>>> 75768 7499
>>>>>> 61636 7821
>>>>>> 103829 8468
>>>>>> 87336 8568
>>>>>> 129443 8190
>>>>>> 97682 8539
>>>>>> 106918 8502
>>>>>> 97171 8578
>>>>>> 48012 8181
>>>>>> 93086 8631
>>>>>> 92374 8562
>>>>>> 113010 8404
>>>>>> 66956 8592
>>>>>> 133037 8632
>>>>>> 108849 8644
>>>>>> 81544 8442
>>>>>> 105072 8615
>>>>>> 143437 7724
>>>>>> 153294 7829
>>>>>> 123735 8682
>>>>>> 154738 8756
>>>>>> 100760 8839
>>>>>> 108034 8839
>>>>>> 81826 8858
>>>>>> 116901 8847
>>>>>> 80780 8869
>>>>>> 122684 8736
>>>>>> 141716 9087
>>>>>> 144315 9166
>>>>>> 162078 9147
>>>>>> 163184 9267
>>>>>> 150688 9275
>>>>>> 200848 9259
>>>>>> 221570 8943
>>>>>> 192424 8564
>>>>>> 173024 9282
>>>>>> 197326 9318
>>>>>> 209344 9293
>>>>>> 220201 9242
>>>>>> 212626 9324
>>>>>> 218115 9319
>>>>>> 170001 9314
>>>>>> 187490 9346
>>>>>> 172440 9350
>>>>>> 180330 9349
>>>>>> 200807 9355
>>>>>> 234994 9350
>>>>>> 139053 9284
>>>>>> 150048 9361
>>>>>> 203650 9346
>>>>>> 233331 9369
>>>>>> 198790 9340
>>>>>> 164060 9382
>>>>>> 198000 9401
>>>>>> 201707 9355
>>>>>> 179257 9369
>>>>>> 188736 9298
>>>>>> 243392 9393
>>>>>> 246040 9374
>>>>>> 269058 9364
>>>>>> 201657 9370
>>>>>> 187942 9354
>>>>>> 228514 9305
>>>>>> 234000 9392
>>>>>> 224431 9395
>>>>>> 163502 9398
>>>>>> I would be most glad for your great assistance.
>>>>>> Many thanks.
>>>>>> Ogbos
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Aug 22 19:24:01 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 10:24:01 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Rich Shepard wrote:

> Correcting the barchard() command fixed the main issue; getting the second
> set of bars is still eluding me, but I'll continue working on fixing this.
> I'll get the years as the x-axis labels rather than year number in
> sequence from 1 to 29.

   Despite additional reading of barchart() examples and help pages I'm still
missing how to get grouping working and use the years in the dataframe as
labels on the x-axis.

   The most recent command version (on the dput output in my previous
message) is:

med_max <- barchart(stage_heights$Med ~ stage_heights$Year, horizontal=FALSE, col = 'black',
                     main = 'Median and Maximum Stage Heights\nUSGS Gauge',
                     ylab = 'Elevation (masl)', xlab = 'Year', groups=TRUE,
                     beside=TRUE, panel = "panel.superbar", prepanel = "prepanel.superbar",)
print(med_max)

   I don't think that conditioning into a trellis applies to this barchart
and I'm not relating the use of scales and labels in a conditioned plot to
the barchart.

   The above command yields an error and I've not found the explanation for
it:

Error in get(fun, mode = "function", envir = parent.frame()) :
   object 'panel.superbar' of mode 'function' was not found

so I'm definitely not getting the command syntax correct. Help's still
needed.

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Aug 22 19:26:12 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 10:26:12 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbQXZ5cKo=CsrZR2JrtDJ=Y2GsKYnJ38dj6KYsc1snrxEQ@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <CAGxFJbQXZ5cKo=CsrZR2JrtDJ=Y2GsKYnJ38dj6KYsc1snrxEQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808221025420.6107@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Bert Gunter wrote:

> See inline.

Bert,

   Will do. Sent a reply before seeing this. More to follow.

Thanks,

Rich


From bgunter@4567 @ending from gm@il@com  Wed Aug 22 20:05:21 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 22 Aug 2018 11:05:21 -0700
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>

(I know that you said your post may already be "out of date", but ...)

"   Despite additional reading of barchart() examples and help pages I'm
still
missing how to get grouping working and use the years in the dataframe as
labels on the x-axis."

But ?barchart says:
"Formally, if groups is specified, then groups along with subscripts is
passed to the panel function, ..."

which, as I already told you, means you should consult ?panel.barchart . In
particular, the example therein tells you exactly how the "groups" argument
should be specified and how it works (you can change colors via the "col"
argument, of course). Note, in particular, that "groups" must be your
grouping variable, which means, in particular, that you need to reformat
your data frame in what is currently referred to as "tidy" format (aka
"long" format as opposed to "wide") -- one variable per column, one
observation per row.  That is:

Year     Value   Summary.Type
1991    91.24   "Med"
1991    92.89   "Max"
... etc.

.... groups = Summary.Type, ...
in your call will then do the job.

As an aside, this is a good example of why you should adhere to this format
for data analysis in R.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 22, 2018 at 10:34 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 22 Aug 2018, Rich Shepard wrote:
>
> > Correcting the barchard() command fixed the main issue; getting the
> second
> > set of bars is still eluding me, but I'll continue working on fixing
> this.
> > I'll get the years as the x-axis labels rather than year number in
> > sequence from 1 to 29.
>
>    Despite additional reading of barchart() examples and help pages I'm
> still
> missing how to get grouping working and use the years in the dataframe as
> labels on the x-axis.
>
>    The most recent command version (on the dput output in my previous
> message) is:
>
> med_max <- barchart(stage_heights$Med ~ stage_heights$Year,
> horizontal=FALSE, col = 'black',
>                      main = 'Median and Maximum Stage Heights\nUSGS Gauge',
>                      ylab = 'Elevation (masl)', xlab = 'Year', groups=TRUE,
>                      beside=TRUE, panel = "panel.superbar", prepanel =
> "prepanel.superbar",)
> print(med_max)
>
>    I don't think that conditioning into a trellis applies to this barchart
> and I'm not relating the use of scales and labels in a conditioned plot to
> the barchart.
>
>    The above command yields an error and I've not found the explanation for
> it:
>
> Error in get(fun, mode = "function", envir = parent.frame()) :
>    object 'panel.superbar' of mode 'function' was not found
>
> so I'm definitely not getting the command syntax correct. Help's still
> needed.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Aug 22 20:18:34 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 11:18:34 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808221114140.6107@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Bert Gunter wrote:

> (I know that you said your post may already be "out of date", but ...)

Bert,

   Still reading ?xyplot/?barchart.

> But ?barchart says:
> "Formally, if groups is specified, then groups along with subscripts is
> passed to the panel function, ..."
>
> which, as I already told you, means you should consult ?panel.barchart . In
> particular, the example therein tells you exactly how the "groups" argument
> should be specified and how it works (you can change colors via the "col"
> argument, of course). Note, in particular, that "groups" must be your
> grouping variable, which means, in particular, that you need to reformat
> your data frame in what is currently referred to as "tidy" format (aka
> "long" format as opposed to "wide") -- one variable per column, one
> observation per row.  That is:
>
> Year     Value   Summary.Type
> 1991    91.24   "Med"
> 1991    92.89   "Max"
> ... etc.

   I saw this in examples and missed its application to my data. You've
cleared my confusion and now I _do_ understand the need for a separate
grouping column and reshaping to a long format. Thanks for explaining so
effectively.

> As an aside, this is a good example of why you should adhere to this
> format for data analysis in R.

   I've done this with all my other data sets and have no excuse for not
doing so with this one. Mea culpa!

Best regards,

Rich


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Wed Aug 22 23:27:47 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Wed, 22 Aug 2018 17:27:47 -0400
Subject: [R] R package downloading
Message-ID: <CAPQaxLMucmgk8EcB-7Oax24GLPr0Z+wmVQOyfqAquC+WWLDrbw@mail.gmail.com>

Hello all,

  Once the R package TCGAbiolinks.... or biocLite(?TCGAbiolinks?) is done
unpacking, how do I go about apply any particular analysis with it?
Currently, I am unable to access the consule and edit any further. Would I
therefore have to open up a new script?

Spencer Brackett

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Aug 22 23:31:50 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 14:31:50 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Bert Gunter wrote:

> .... groups = Summary.Type, ...
> in your call will then do the job.
>
> As an aside, this is a good example of why you should adhere to this format
> for data analysis in R.

Bert,

   Progress and retreat. I'm putting this aside for a day or so because I
need to provide my client with a draft report and I can add this plot later
when I figure out how to do it correctly.

   More when I have results.

Thanks again,

Rich


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Aug 22 23:42:10 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 22 Aug 2018 14:42:10 -0700
Subject: [R] R package downloading
In-Reply-To: <CAPQaxLMucmgk8EcB-7Oax24GLPr0Z+wmVQOyfqAquC+WWLDrbw@mail.gmail.com>
References: <CAPQaxLMucmgk8EcB-7Oax24GLPr0Z+wmVQOyfqAquC+WWLDrbw@mail.gmail.com>
Message-ID: <CFE6818E-DA71-49BA-B67E-D100A2270E2A@dcn.davis.ca.us>

The Bioconductor project does things their own way. Please use their support channels for help with their packages. https://www.bioconductor.org/help/

On August 22, 2018 2:27:47 PM PDT, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>Hello all,
>
>Once the R package TCGAbiolinks.... or biocLite(?TCGAbiolinks?) is done
>unpacking, how do I go about apply any particular analysis with it?
>Currently, I am unable to access the consule and edit any further.
>Would I
>therefore have to open up a new script?
>
>Spencer Brackett
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@@@pdx @ending from gm@il@com  Thu Aug 23 01:07:02 2018
From: r@@@pdx @ending from gm@il@com (Richard Sherman)
Date: Wed, 22 Aug 2018 16:07:02 -0700
Subject: [R] graphing repeated curves
Message-ID: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>

Hi all,

I have a simple graphing question that is not really a graphing question, but a question about repeating a task.

I?m fiddling with some of McElreath?s Statistical Rethinking, and there?s a graph illustrating extreme overfitting (a number of polynomial terms in x equal to the number of observations), a subject I know well having taught it to grad students for many years.

The plot I want to reproduce has, in effect:

m1 <- lm( y ~ x)
m2 <- lm( y ~ x + x^2)

?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed by some plot() or lines() or ggplot2() call to render the data and fitted curves.

Obviously I don?t want to run such regressions for any real purpose, but I think it might be useful to learn how to do such a thing in R without writing down each lm() call individually. It?s not obvious where I?d want to apply this, but I like learning how to repeat things in a compact way. 

So, something like:

data( mtcars )
d <- mtcars
v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
m1 <- lm( mpg ~ hp  , data = d )

and then somehow use for() with an index or some flavor of apply() with the vector v to repeat this process yielding

m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )

? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6) , data=d )

But finding a way to index these values including not just each value but each value+1 , then value+1 and value+2, and so on escapes me. Obviously I don?t want to include index values below zero. 

===
Richard Sherman
rss.pdx at gmail.com


From drjimlemon @ending from gm@il@com  Thu Aug 23 01:43:09 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 23 Aug 2018 09:43:09 +1000
Subject: [R] graphing repeated curves
In-Reply-To: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
References: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
Message-ID: <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>

Hi Richard,
This may be what you want:

data(mtcars)
m<-list()
for(i in 1:6) {
 rhterms<-paste(paste0("I(hp^",1:i,")"),sep="+")
 lmexp<-paste0("lm(mpg~",rhterms,",mtcars)")
 cat(lmexp,"\n")
 m[[i]]<-eval(parse(text=lmexp))
}
plot(mpg~hp,mtcars,type="n")
for(i in 1:6) abline(m[[i]],col=i)

Jim


On Thu, Aug 23, 2018 at 9:07 AM, Richard Sherman <rss.pdx at gmail.com> wrote:
> Hi all,
>
> I have a simple graphing question that is not really a graphing question, but a question about repeating a task.
>
> I?m fiddling with some of McElreath?s Statistical Rethinking, and there?s a graph illustrating extreme overfitting (a number of polynomial terms in x equal to the number of observations), a subject I know well having taught it to grad students for many years.
>
> The plot I want to reproduce has, in effect:
>
> m1 <- lm( y ~ x)
> m2 <- lm( y ~ x + x^2)
>
> ?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed by some plot() or lines() or ggplot2() call to render the data and fitted curves.
>
> Obviously I don?t want to run such regressions for any real purpose, but I think it might be useful to learn how to do such a thing in R without writing down each lm() call individually. It?s not obvious where I?d want to apply this, but I like learning how to repeat things in a compact way.
>
> So, something like:
>
> data( mtcars )
> d <- mtcars
> v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
> m1 <- lm( mpg ~ hp  , data = d )
>
> and then somehow use for() with an index or some flavor of apply() with the vector v to repeat this process yielding
>
> m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
> m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )
>
> ? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6) , data=d )
>
> But finding a way to index these values including not just each value but each value+1 , then value+1 and value+2, and so on escapes me. Obviously I don?t want to include index values below zero.
>
> ===
> Richard Sherman
> rss.pdx at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox @ending from mcm@@ter@c@  Thu Aug 23 02:29:21 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Thu, 23 Aug 2018 00:29:21 +0000
Subject: [R] graphing repeated curves
In-Reply-To: <787_1534979238_w7MN7IHh021447_DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
References: <787_1534979238_w7MN7IHh021447_DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368962F7@FHSDB2D11-2.csu.mcmaster.ca>

Dear Richard,

How about this:

ord <- order(mtcars$hp)
mtcars$hp <- mtcars$hp[ord]
mtcars$mpg <- mtcars$mpg[ord]
plot(mpg ~ hp, data=mtcars)
for (p in 1:6){
    m <- lm(mpg ~ poly(hp, p), data=mtcars)
    lines(mtcars$hp, fitted(m), lty=p, col=p)
}
legend("topright", legend=1:6, lty=1:6, col=1:6, title="order", inset=0.02)

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Richard
> Sherman
> Sent: Wednesday, August 22, 2018 7:07 PM
> To: r-help at r-project.org
> Subject: [R] graphing repeated curves
> 
> Hi all,
> 
> I have a simple graphing question that is not really a graphing question, but a
> question about repeating a task.
> 
> I?m fiddling with some of McElreath?s Statistical Rethinking, and there?s a
> graph illustrating extreme overfitting (a number of polynomial terms in x
> equal to the number of observations), a subject I know well having taught it to
> grad students for many years.
> 
> The plot I want to reproduce has, in effect:
> 
> m1 <- lm( y ~ x)
> m2 <- lm( y ~ x + x^2)
> 
> ?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed by some
> plot() or lines() or ggplot2() call to render the data and fitted curves.
> 
> Obviously I don?t want to run such regressions for any real purpose, but I think
> it might be useful to learn how to do such a thing in R without writing down
> each lm() call individually. It?s not obvious where I?d want to apply this, but I
> like learning how to repeat things in a compact way.
> 
> So, something like:
> 
> data( mtcars )
> d <- mtcars
> v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
> m1 <- lm( mpg ~ hp  , data = d )
> 
> and then somehow use for() with an index or some flavor of apply() with the
> vector v to repeat this process yielding
> 
> m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
> m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )
> 
> ? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) +
> I(hp^5) + I(hp^6) , data=d )
> 
> But finding a way to index these values including not just each value but each
> value+1 , then value+1 and value+2, and so on escapes me. Obviously I don?t
> want to include index values below zero.
> 
> ===
> Richard Sherman
> rss.pdx at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter@4567 @ending from gm@il@com  Thu Aug 23 02:37:45 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 22 Aug 2018 17:37:45 -0700
Subject: [R] graphing repeated curves
In-Reply-To: <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>
References: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
 <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>
Message-ID: <CAGxFJbTb30ovevhyAzyOzDKD9es1WXqO9Yy_9pSe1o6feCORSQ@mail.gmail.com>

I do not think this does what the OP wants -- it does not produce
polynomials of the form desired.

John Fox's solution using poly() seems to me to be the right approach, but
I will show what I think is a considerably simpler way to build up the
polynomial expressions just as an example of one way to do this sort of
thing in more general circumstances:

fm <- vector("character",6)
fm[1]<- "mpg ~ hp"
for(i in 2:6)fm[i]<- paste0(fm[i-1]," + I(hp^", i,")")
## yielding:
> fm
[1] "mpg ~ hp"
[2] "mpg ~ hp + I(hp^2)"
[3] "mpg ~ hp + I(hp^2) + I(hp^3)"
[4] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4)"
[5] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5)"
[6] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6)"

Although fm is a character vector, the character strings will be
automatically coerced by lm to formulas (see ?lm), so, e.g.

results <- lapply(fm, lm,data = mtcars)

would yield a list of regressions which could then be summarized, plotted
or whatever (again using lapply). e.g.

> results[[3]]

Call:
FUN(formula = X[[i]], data = ..1)

Coefficients:
(Intercept)           hp      I(hp^2)      I(hp^3)
  4.422e+01   -2.945e-01    9.115e-04   -8.701e-07

One could also choose to do the plotting or whatever within the lapply
call, but I prefer to keep things simple if possible.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 22, 2018 at 4:43 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Richard,
> This may be what you want:
>
> data(mtcars)
> m<-list()
> for(i in 1:6) {
>  rhterms<-paste(paste0("I(hp^",1:i,")"),sep="+")
>  lmexp<-paste0("lm(mpg~",rhterms,",mtcars)")
>  cat(lmexp,"\n")
>  m[[i]]<-eval(parse(text=lmexp))
> }
> plot(mpg~hp,mtcars,type="n")
> for(i in 1:6) abline(m[[i]],col=i)
>
> Jim
>
>
> On Thu, Aug 23, 2018 at 9:07 AM, Richard Sherman <rss.pdx at gmail.com>
> wrote:
> > Hi all,
> >
> > I have a simple graphing question that is not really a graphing
> question, but a question about repeating a task.
> >
> > I?m fiddling with some of McElreath?s Statistical Rethinking, and
> there?s a graph illustrating extreme overfitting (a number of polynomial
> terms in x equal to the number of observations), a subject I know well
> having taught it to grad students for many years.
> >
> > The plot I want to reproduce has, in effect:
> >
> > m1 <- lm( y ~ x)
> > m2 <- lm( y ~ x + x^2)
> >
> > ?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed by
> some plot() or lines() or ggplot2() call to render the data and fitted
> curves.
> >
> > Obviously I don?t want to run such regressions for any real purpose, but
> I think it might be useful to learn how to do such a thing in R without
> writing down each lm() call individually. It?s not obvious where I?d want
> to apply this, but I like learning how to repeat things in a compact way.
> >
> > So, something like:
> >
> > data( mtcars )
> > d <- mtcars
> > v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
> > m1 <- lm( mpg ~ hp  , data = d )
> >
> > and then somehow use for() with an index or some flavor of apply() with
> the vector v to repeat this process yielding
> >
> > m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
> > m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )
> >
> > ? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4)
> + I(hp^5) + I(hp^6) , data=d )
> >
> > But finding a way to index these values including not just each value
> but each value+1 , then value+1 and value+2, and so on escapes me.
> Obviously I don?t want to include index values below zero.
> >
> > ===
> > Richard Sherman
> > rss.pdx at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Thu Aug 23 02:56:52 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Thu, 23 Aug 2018 00:56:52 +0000
Subject: [R] graphing repeated curves
In-Reply-To: <789_1534984775_w7N0dYTv015741_CAGxFJbTb30ovevhyAzyOzDKD9es1WXqO9Yy_9pSe1o6feCORSQ@mail.gmail.com>
References: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
 <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>
 <789_1534984775_w7N0dYTv015741_CAGxFJbTb30ovevhyAzyOzDKD9es1WXqO9Yy_9pSe1o6feCORSQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836896327@FHSDB2D11-2.csu.mcmaster.ca>

Dear Bert,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Wednesday, August 22, 2018 8:38 PM
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: rss.pdx at gmail.com; R-help <r-help at r-project.org>
> Subject: Re: [R] graphing repeated curves
> 
> I do not think this does what the OP wants -- it does not produce polynomials
> of the form desired.
> 
> John Fox's solution using poly() seems to me to be the right approach, but I

Actually, I didn't do a good job of graphing the polynomials between the observed x-values. Here's a better solution:

x <- with(mtcars, seq(min(hp), max(hp), length=500))
plot(mpg ~ hp, data=mtcars)
for (p in 1:6){
    m <- lm(mpg ~ poly(hp, p), data=mtcars)
    lines(x, predict(m, newdata=data.frame(hp=x)), lty=p, col=p)
}
legend("top", legend=1:6, lty=1:6, col=1:6, title="order", inset=0.02)

Best,
 John

> will show what I think is a considerably simpler way to build up the
> polynomial expressions just as an example of one way to do this sort of thing
> in more general circumstances:
> 
> fm <- vector("character",6)
> fm[1]<- "mpg ~ hp"
> for(i in 2:6)fm[i]<- paste0(fm[i-1]," + I(hp^", i,")") ## yielding:
> > fm
> [1] "mpg ~ hp"
> [2] "mpg ~ hp + I(hp^2)"
> [3] "mpg ~ hp + I(hp^2) + I(hp^3)"
> [4] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4)"
> [5] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5)"
> [6] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6)"
> 
> Although fm is a character vector, the character strings will be automatically
> coerced by lm to formulas (see ?lm), so, e.g.
> 
> results <- lapply(fm, lm,data = mtcars)
> 
> would yield a list of regressions which could then be summarized, plotted or
> whatever (again using lapply). e.g.
> 
> > results[[3]]
> 
> Call:
> FUN(formula = X[[i]], data = ..1)
> 
> Coefficients:
> (Intercept)           hp      I(hp^2)      I(hp^3)
>   4.422e+01   -2.945e-01    9.115e-04   -8.701e-07
> 
> One could also choose to do the plotting or whatever within the lapply call,
> but I prefer to keep things simple if possible.
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Aug 22, 2018 at 4:43 PM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> 
> > Hi Richard,
> > This may be what you want:
> >
> > data(mtcars)
> > m<-list()
> > for(i in 1:6) {
> >  rhterms<-paste(paste0("I(hp^",1:i,")"),sep="+")
> >  lmexp<-paste0("lm(mpg~",rhterms,",mtcars)")
> >  cat(lmexp,"\n")
> >  m[[i]]<-eval(parse(text=lmexp))
> > }
> > plot(mpg~hp,mtcars,type="n")
> > for(i in 1:6) abline(m[[i]],col=i)
> >
> > Jim
> >
> >
> > On Thu, Aug 23, 2018 at 9:07 AM, Richard Sherman <rss.pdx at gmail.com>
> > wrote:
> > > Hi all,
> > >
> > > I have a simple graphing question that is not really a graphing
> > question, but a question about repeating a task.
> > >
> > > I?m fiddling with some of McElreath?s Statistical Rethinking, and
> > there?s a graph illustrating extreme overfitting (a number of
> > polynomial terms in x equal to the number of observations), a subject
> > I know well having taught it to grad students for many years.
> > >
> > > The plot I want to reproduce has, in effect:
> > >
> > > m1 <- lm( y ~ x)
> > > m2 <- lm( y ~ x + x^2)
> > >
> > > ?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed
> > > by
> > some plot() or lines() or ggplot2() call to render the data and fitted
> > curves.
> > >
> > > Obviously I don?t want to run such regressions for any real purpose,
> > > but
> > I think it might be useful to learn how to do such a thing in R
> > without writing down each lm() call individually. It?s not obvious
> > where I?d want to apply this, but I like learning how to repeat things in a
> compact way.
> > >
> > > So, something like:
> > >
> > > data( mtcars )
> > > d <- mtcars
> > > v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
> > > m1 <- lm( mpg ~ hp  , data = d )
> > >
> > > and then somehow use for() with an index or some flavor of apply()
> > > with
> > the vector v to repeat this process yielding
> > >
> > > m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
> > > m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )
> > >
> > > ? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) +
> > > I(hp^4)
> > + I(hp^5) + I(hp^6) , data=d )
> > >
> > > But finding a way to index these values including not just each
> > > value
> > but each value+1 , then value+1 and value+2, and so on escapes me.
> > Obviously I don?t want to include index values below zero.
> > >
> > > ===
> > > Richard Sherman
> > > rss.pdx at gmail.com
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@@@pdx @ending from gm@il@com  Thu Aug 23 03:09:15 2018
From: r@@@pdx @ending from gm@il@com (Richard Sherman)
Date: Wed, 22 Aug 2018 18:09:15 -0700
Subject: [R] graphing repeated curves
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836896327@FHSDB2D11-2.csu.mcmaster.ca>
References: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
 <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>
 <789_1534984775_w7N0dYTv015741_CAGxFJbTb30ovevhyAzyOzDKD9es1WXqO9Yy_9pSe1o6feCORSQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836896327@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <86A0380F-19EC-4036-9F20-B75576BCC5E9@gmail.com>

These are great, thanks.

I always forget about paste().

===
Richard Sherman
rss.pdx at gmail.com



> On Aug 22, 2018, at 17:56, Fox, John <jfox at mcmaster.ca> wrote:
> 
> fm <- vector("character",6)
> fm[1]<- "mpg ~ hp"
> for(i in 2:6)fm[i]<- paste0(fm[i-1]," + I(hp^", i,")")


From c@l@ndr@ @ending from rgzm@de  Thu Aug 23 08:15:35 2018
From: c@l@ndr@ @ending from rgzm@de (Ivan Calandra)
Date: Thu, 23 Aug 2018 08:15:35 +0200
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <1534956078.6967.24.camel@deb2.fort.knox.uk>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
 <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
 <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>
 <1534956078.6967.24.camel@deb2.fort.knox.uk>
Message-ID: <62dac2e0-9ebc-63d3-ad7b-07535f60909b@rgzm.de>

Thanks all for the enlightenment.

So, it does make sense that mean() produces NaN and median()/sd() NA, 
from a calculation point of view at least.
But I still think it also makes sense that the mean of NA is NA as well, 
be it only for consistency with other functions. That's just my opinion 
of course. I can still convert NaN to NA at the end if I need to.

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 22/08/2018 18:41, Ted Harding wrote:
> I think that one can usefully look at this question from the
> point of view of what "NaN" and "NA" are abbreviations for
> (at any rate, according to the understanding I have adopted
> since many years -- maybe over-simplified).
>
> NaN: Mot a Number
> NA: Not Available
>
> So NA is typically used for missing values, whereas NaN
> represents the reults of numerical calculations which
> cannot give a result which is a definite number,
>
> Hence 0/0 is not a number, so NaN; similarly Inf/Inf.
>
> Thus, with your x <- c(NA, NA, NA) mean(x, na.rm=TRUE)
> sum(x, na.rm=TRUE) = 0, since the set of values of x
> with na.rm=TRUE is empty so the number of elements
> in x is 0; hence mean = 0/0 = NaN.
>
> But for median(x, na.rm=TRUE), because there are no available
> elements in x with na.rm=TRUE, and the median is found by
> searching among available elements for the value which
> divides the set of values into two halves, the median
> is not available, hence NA.
>
> Best wishes to all,
> Ted.
>
> On Wed, 2018-08-22 at 11:24 -0400, Marc Schwartz via R-help wrote:
>> Hi,
>>
>> It might even be worthwhile to review this recent thread on R-Devel:
>>
>>    https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html
>>
>> which touches upon a subtly related topic vis-a-vis NaN handling.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>>> On Aug 22, 2018, at 10:55 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> ... And FWIW (not much, I agree), note that if z = numeric(0) and sum(z) =
>>> 0, then mean(z) = NaN makes sense, as length(z) = 0, so dividing by 0 gives
>>> NaN. So you can see the sorts of issues you may need to consider.
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Wed, Aug 22, 2018 at 7:47 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>>> Actually, the dissonance is a bit more basic.
>>>>
>>>> After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
>>>> what you see is actually:
>>>>
>>>>> z <- numeric(0)
>>>>> mean(z)
>>>> [1] NaN
>>>>> median(z)
>>>> [1] NA
>>>>> sd(z)
>>>> [1] NA
>>>>> sum(z)
>>>> [1] 0
>>>> etc.
>>>>
>>>> I imagine that there may be more of these little inconsistencies due to
>>>> the organic way R evolved over time. What the conventions should be  can be
>>>> purely a matter of personal opinion in the absence of accepted standards.
>>>> But I would look to see what accepted standards were, if any, first.
>>>>
>>>> -- Bert
>>>>
>>>>
>>>> On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:
>>>>
>>>>> Dear useRs,
>>>>>
>>>>> I have just noticed that when input is only NA with na.rm=TRUE, mean()
>>>>> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
>>>>> be the same? I think NA makes more sense than NaN in that case.
>>>>>
>>>>> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
>>>>> NAsd(x, na.rm=TRUE) [1] NA
>>>>>
>>>>> Thanks for any feedback.
>>>>>
>>>>> Best,
>>>>> Ivan
>>>>>
>>>>> --
>>>>> Dr. Ivan Calandra
>>>>> TraCEr, laboratory for Traceology and Controlled Experiments
>>>>> MONREPOS Archaeological Research Centre and
>>>>> Museum for Human Behavioural Evolution
>>>>> Schloss Monrepos
>>>>> 56567 Neuwied, Germany
>>>>> +49 (0) 2631 9772-243
>>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From vidhi@@l@giri @ending from gm@il@com  Thu Aug 23 08:35:11 2018
From: vidhi@@l@giri @ending from gm@il@com (Vidya Alagiriswamy)
Date: Wed, 22 Aug 2018 23:35:11 -0700
Subject: [R] importing .v8x file in R
Message-ID: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>

 HI,

   I am new to R and want to read the data file with extension .v8x. The
file is hints2003.d2006_06_02.public.v8x. Is anyone familiar with this
extension? Please help.

Thanks,
Vidya

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Thu Aug 23 10:31:52 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Thu, 23 Aug 2018 20:31:52 +1200
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <62dac2e0-9ebc-63d3-ad7b-07535f60909b@rgzm.de>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
 <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
 <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>
 <1534956078.6967.24.camel@deb2.fort.knox.uk>
 <62dac2e0-9ebc-63d3-ad7b-07535f60909b@rgzm.de>
Message-ID: <120e7f5c-4f94-8943-c0ae-a920662a6ce6@auckland.ac.nz>


On 08/23/2018 06:15 PM, Ivan Calandra wrote:

> Thanks all for the enlightenment.
> 
> So, it does make sense that mean() produces NaN and median()/sd() NA, 
> from a calculation point of view at least.
> But I still think it also makes sense that the mean of NA is NA as well, 
> be it only for consistency with other functions. That's just my opinion 
> of course. I can still convert NaN to NA at the end if I need to.

But the mean of NA *is* NA!

> x <- NA
> mean(x)
> [1] NA

This is *not* the same scenario as having nothing left after *removing* 
all NAs:

> x <- rep(NA,3)
> mean(x,na.rm=TRUE > [1] NaN

Seems quite consistent/coherent to me.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ruipb@rr@d@@ @ending from @@po@pt  Thu Aug 23 10:35:29 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Thu, 23 Aug 2018 09:35:29 +0100
Subject: [R] importing .v8x file in R
In-Reply-To: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
References: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
Message-ID: <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>

Hello,

Sorry but I don't believe this is a question for r-help.

r-help is meant for questions about R code, you should find out what 
type of file do you have. Maybe open it and see its contents.

There is really nothing we can do.

Rui Barradas

On 23/08/2018 07:35, Vidya Alagiriswamy wrote:
>   HI,
> 
>     I am new to R and want to read the data file with extension .v8x. The
> file is hints2003.d2006_06_02.public.v8x. Is anyone familiar with this
> extension? Please help.
> 
> Thanks,
> Vidya
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com


From r@turner @ending from @uckl@nd@@c@nz  Thu Aug 23 10:39:33 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Thu, 23 Aug 2018 20:39:33 +1200
Subject: [R] importing .v8x file in R
In-Reply-To: <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>
References: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
 <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>
Message-ID: <a7c5cb51-1d19-39bf-caa7-fda093cfa4d6@auckland.ac.nz>

On 08/23/2018 08:35 PM, Rui Barradas wrote:
> Hello,
> 
> Sorry but I don't believe this is a question for r-help.
> 
> r-help is meant for questions about R code, you should find out what 
> type of file do you have. Maybe open it and see its contents.
> 
> There is really nothing we can do.

Indeed.  But the OP could try Googling "v8x file extension".
Psigh!

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @@himk@poor @ending from gm@il@com  Thu Aug 23 11:00:59 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Thu, 23 Aug 2018 14:30:59 +0530
Subject: [R] Unclear about the output from summary of ca.jo from package urca
Message-ID: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>

Dear All,

I am not sure about the summary of the function ca.jo. I have posted my
query here :-

https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r

I did not receive any reply so I am posting my query here.

Many thanks and best regards,
Ashim

	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Thu Aug 23 11:15:19 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Thu, 23 Aug 2018 21:15:19 +1200
Subject: [R] Plots in ioslides and R markdown
Message-ID: <20180823091519.GB13179@slingshot.co.nz>

I'm having difficulty getting plots into ioslides.  It seems to me
that the scale is completely out, but I can't figure out what to do
about it.  Whatever I try, I get the title slide, then a second with a
horizontal line and a vertical line in the bottom right corner.  It
looks like a badly scaled plot about 25 times the size of the plotting
area, so only a fragment is visible.

This is the code I've tried:

---
title: "Barking up the wrong tree"
author: "Patrick Connolly"
date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
output: ioslides_presentation
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(tidy=TRUE,
                      warning=FALSE, 
                      message=FALSE,
                      cache=FALSE,
                      dpi=600)
```

```{r use these functions, echo= FALSE}
  load(".RData") ## code for 6 plotting functions

``
## 6 different Trees

```{r 6 different Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}

###  par(mfrow = c(2, 3))
plot1()
plot2()
plot3()
plot4()
plot5()
plot6()
}
```

If I run the plot functions in the Console, it all works and displays
correctly in Rstudiio's plot panel, even the mfrow bit.  But I haven't
worked out how to include the code into Rmarkdown.  I thought it might
be less taxing to not try putting the 6 plots on the same slide, but
it makes no difference when I commented out the mfrow bit.

I'm not very familiar with the workings of Markdown or Rstudio, but it
does seem strange to me that I need to specifically load the global
environment otherwise it's not visible.  Is that to be expected?

Ideas welcome, particularly about scaling.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From r@turner @ending from @uckl@nd@@c@nz  Thu Aug 23 12:57:35 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Thu, 23 Aug 2018 22:57:35 +1200
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
Message-ID: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>


I *think* that this is an R question (and *not* an RStudio question!)

I have, somewhat against my better judgement, decided to experiment with 
using RStudio.

I downloaded and install RStudio.  Easy-peasy.  Nice lucid instructions.

Then I tried to start RStudio ("rstudio" from the command line)
and got a pop-up window with the error message:

> R shared library (/usr/lib64/R/lib/libR.so) not found. If this
> is a custom build of R, was it built with the --enable-R-shlib option?

Oops, no, I guess it wasn't.  So I carefully did a

     sudo make uninstall
     make clean
     make distclean

and then did

     ./R-3.5.1/configure <various flags>

making sure I added the --enable-R-shlib flag.

Then I did make and sudo make install. It all seemed to go ...
but then I did

     rstudio

again and got the same popup error.

There is indeed *no* libR.so in /usr/lib64/R/lib.

There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals that 
it dates from the my previous install of R-3.5.1 for which I *did not* 
configure with --enable-R-shlib.

Can anyone explain to me WTF is going on?

What should I do?  Just make a symbolic link from /usr/lib/R/lib/libR.so 
to /usr/lib64/R/lib/libR.so?

It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
most recent install of R.

I plead for enlightenment.

cheers,

Rolf Turner

P.S. I'm running Ubuntu 18.04.  And the previous install of R was done 
under Ubuntu 18.04.

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jttkim @ending from googlem@il@com  Thu Aug 23 13:09:46 2018
From: jttkim @ending from googlem@il@com (Jan T Kim)
Date: Thu, 23 Aug 2018 12:09:46 +0100
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
Message-ID: <20180823110945.GS26688@paftolwp3a>

Hi Rolf & All,

I haven't built R in a while, but my general expectation of an
autotools based build & install would be that the default prefix
is /usr/local, rather than /usr. So I'd expect the shared libs
in /usr/local/lib, /usr/local/lib64 etc.

I also have a recollection that I once installed Rstudio for some
MOOC, and ended up putting a symlink in somewhere like /usr/lib* ,
because Rstudio was only available as a binary with the location
of the shared lib hard-baked into it.

Depending on your <various flags> this may be irrelevant, apologies
in that case.

Best regards, Jan


On Thu, Aug 23, 2018 at 10:57:35PM +1200, Rolf Turner wrote:
> 
> I *think* that this is an R question (and *not* an RStudio question!)
> 
> I have, somewhat against my better judgement, decided to experiment with
> using RStudio.
> 
> I downloaded and install RStudio.  Easy-peasy.  Nice lucid instructions.
> 
> Then I tried to start RStudio ("rstudio" from the command line)
> and got a pop-up window with the error message:
> 
> >R shared library (/usr/lib64/R/lib/libR.so) not found. If this
> >is a custom build of R, was it built with the --enable-R-shlib option?
> 
> Oops, no, I guess it wasn't.  So I carefully did a
> 
>     sudo make uninstall
>     make clean
>     make distclean
> 
> and then did
> 
>     ./R-3.5.1/configure <various flags>
> 
> making sure I added the --enable-R-shlib flag.
> 
> Then I did make and sudo make install. It all seemed to go ...
> but then I did
> 
>     rstudio
> 
> again and got the same popup error.
> 
> There is indeed *no* libR.so in /usr/lib64/R/lib.
> 
> There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals that it
> dates from the my previous install of R-3.5.1 for which I *did not*
> configure with --enable-R-shlib.
> 
> Can anyone explain to me WTF is going on?
> 
> What should I do?  Just make a symbolic link from /usr/lib/R/lib/libR.so to
> /usr/lib64/R/lib/libR.so?
> 
> It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
> most recent install of R.
> 
> I plead for enlightenment.
> 
> cheers,
> 
> Rolf Turner
> 
> P.S. I'm running Ubuntu 18.04.  And the previous install of R was done under
> Ubuntu 18.04.
> 
> R. T.
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @ending from @uckl@nd@@c@nz  Thu Aug 23 13:34:38 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Thu, 23 Aug 2018 23:34:38 +1200
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <20180823110945.GS26688@paftolwp3a>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <20180823110945.GS26688@paftolwp3a>
Message-ID: <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>


On 08/23/2018 11:09 PM, Jan T Kim via R-help wrote:

> Hi Rolf & All,
> 
> I haven't built R in a while, but my general expectation of an
> autotools based build & install would be that the default prefix
> is /usr/local, rather than /usr. So I'd expect the shared libs
> in /usr/local/lib, /usr/local/lib64 etc.

I guess I should have said --- I did

     sudo make prefix=/usr install

which puts stuff into /usr rather than into /usr/local.

I forget exactly why I chose (in the dim distant past) to do this ...
I have a vague recollection that my search path was more "comfortable" 
that way.

> I also have a recollection that I once installed Rstudio for some
> MOOC, and ended up putting a symlink in somewhere like /usr/lib* ,
> because Rstudio was only available as a binary with the location
> of the shared lib hard-baked into it.

So it looks like a symlink might be the answer for me.

I would still like to know why /usr/lib/R/lib/libR.so was not refreshed 
on the most recent build, but.

> Depending on your <various flags> this may be irrelevant, apologies
> in that case.

Not to worry.  Thanks for taking an interest.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From berwin@turl@ch @ending from gm@il@com  Thu Aug 23 16:04:42 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Thu, 23 Aug 2018 22:04:42 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
Message-ID: <20180823220442.3370298d@absentia>

G'day Rolf,

On Thu, 23 Aug 2018 22:57:35 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> I *think* that this is an R question (and *not* an RStudio question!)

Others may disagree... :)

> I have, somewhat against my better judgement, decided to experiment
> with using RStudio.

Very good if you are still involved with teaching and need to use the
same environment as your student...  or want to try some new IDE...

If you have a good set-up that works for you, a bit more difficult to
see why you want to change...  RStudio's editor  allegedly has an Emacs
style but I find that style more confusing than helpful... half of the
short-cuts do not seem to work...  

But it is a nice IDE...

> Then I tried to start RStudio ("rstudio" from the command line)
> and got a pop-up window with the error message:
> 
> > R shared library (/usr/lib64/R/lib/libR.so) not found. If this
> > is a custom build of R, was it built with the --enable-R-shlib
> > option?  

Yes, I regularly got that too, until I changed my R installation
scripts ....
 
> Oops, no, I guess it wasn't.  So I carefully did a
> 
>      sudo make uninstall
>      make clean
>      make distclean

To bad that you did this.  There should have been a file called
"config.log" in that directory, and the top lines of that file would
have told you with which option ./configure was called, in particular
whether you had used the --enable-R-shlib flag.

> and then did
> 
>      ./R-3.5.1/configure <various flags>
> 
> making sure I added the --enable-R-shlib flag.

Well, some of the other flags might also be important...

> Then I did make and sudo make install. It all seemed to go ...
> but then I did
> 
>      rstudio
> 
> again and got the same popup error.
> 
> There is indeed *no* libR.so in /usr/lib64/R/lib.

I wonder why rstudio tries to look into /usr/lib64.  AFAICT, rstudio
queries the R that it uses for its home directory and then expects
libR.so to be at a specific location relative to this home directory.
And it expects that the installation does not use sub-architectures,
that is what tripped me up.  

> There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals
> that it dates from the my previous install of R-3.5.1 for which I
> *did not* configure with --enable-R-shlib.

Are you sure?  I am running Ubuntu 18.04 too.  My system
has /usr/lib/libR.so and /usr/lib/R/lib/libR.so, with the former being
a link to the latter.  And these were installed via `r-base-core` which
seems to be a requirement for `ess`.  (The long list of `ess` on
Ubuntu, together with its insistence of installing r-base-core and a
whole bunch of r-cran-* package is IMHO ridiculous.   Nearly bad enough
to make me consider installing ESS from source again.)

So the /usr/lib/R/lib/libR.so could be from r-base-core (if you somehow
installed that package).

Obviously you have sudo rights on your machine, so I would suggest to
try:
	sudo updatedb
	locate libR.so
To see how many libR.so you have installed and where they are
 
> Can anyone explain to me WTF is going on?

Not with much more information, e.g. what those "<various flags>"
to .configure were.  

Also, the great strength of unix system is that you can influence the
behaviour of programs via system variables...  unfortunately that is
also one of its greatest weaknesses when it comes to finding out why
programs do not behaved the way you expect them to work.  Some stray
environment variable might cause all this problem.

> What should I do?  Just make a symbolic link
> from /usr/lib/R/lib/libR.so to /usr/lib64/R/lib/libR.so?

I would not recommend this.  If this file is from another installation,
you are just asking for trouble down the road, which would then be even
harder to debug.

> It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
> most recent install of R.

Me too.  But I think you should never install to this location in the
first place.  AFAICT, /usr/lib/R/lib/libR.so is installed by
r-core-base, so if you install your own version there and then a
"apt-get update" updates r-core-base, you will end up with a broken
system.   

I learned the hard way long time ago not to install any software in
areas where Ubuntu packages are installed.  I restrict myself to
install to /usr/local or /opt (with /opt often being on a separate
partition so that material installed there survive if I have to
install/upgrade Ubuntu from scratch).

> I plead for enlightenment.

Not sure whether my comments were very helpful.  But you should
probably find out why your custom installed version of R tells RStudio
to look at /usr/lib64. A "locate libR.pc" could be helpful.  on my
system this returns /usr/lib/pkgconfig/libR.pc (from r-base-core)
and /opt/R/R-3.5.1/lib/pkgconfig/libR.pc (my installation from source).

Cheers,

	Berwin


From bgunter@4567 @ending from gm@il@com  Thu Aug 23 16:22:35 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 23 Aug 2018 07:22:35 -0700
Subject: [R] Unclear about the output from summary of ca.jo from package
 urca
In-Reply-To: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
References: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
Message-ID: <CAGxFJbTmbYTq_ybXXpbQmvk-N2DZ58KcLmy_T+rTdZ+y5KxoXQ@mail.gmail.com>

This is about statistics , not R programming, and so is off topic here.
Your first port of call for this sort of thing should be the package docs,
**including any references** . There are references given. Have you studied
them??

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 23, 2018 at 2:12 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> I am not sure about the summary of the function ca.jo. I have posted my
> query here :-
>
>
> https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r
>
> I did not receive any reply so I am posting my query here.
>
> Many thanks and best regards,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Aug 23 16:23:32 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 23 Aug 2018 07:23:32 -0700
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180823091519.GB13179@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
Message-ID: <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>

This is not reproducible because you have not provided the plot code or sample data. Output of sessionInfo would probably be appropriate as well.

As to whether needing to load objects is typical... yes, rmarkdown runs from a fresh environment to emphasize reproducibility, but your load command is bypassing that for us.

On August 23, 2018 2:15:19 AM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>I'm having difficulty getting plots into ioslides.  It seems to me
>that the scale is completely out, but I can't figure out what to do
>about it.  Whatever I try, I get the title slide, then a second with a
>horizontal line and a vertical line in the bottom right corner.  It
>looks like a badly scaled plot about 25 times the size of the plotting
>area, so only a fragment is visible.
>
>This is the code I've tried:
>
>---
>title: "Barking up the wrong tree"
>author: "Patrick Connolly"
>date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
>output: ioslides_presentation
>---
>
>```{r global_options, echo=FALSE}
>knitr::opts_chunk$set(tidy=TRUE,
>                      warning=FALSE, 
>                      message=FALSE,
>                      cache=FALSE,
>                      dpi=600)
>```
>
>```{r use these functions, echo= FALSE}
>  load(".RData") ## code for 6 plotting functions
>
>``
>## 6 different Trees
>
>```{r 6 different Trees, echo = FALSE, messages=FALSE, fig.width = 7,
>fig.height = 5}
>
>###  par(mfrow = c(2, 3))
>plot1()
>plot2()
>plot3()
>plot4()
>plot5()
>plot6()
>}
>```
>
>If I run the plot functions in the Console, it all works and displays
>correctly in Rstudiio's plot panel, even the mfrow bit.  But I haven't
>worked out how to include the code into Rmarkdown.  I thought it might
>be less taxing to not try putting the 6 plots on the same slide, but
>it makes no difference when I commented out the mfrow bit.
>
>I'm not very familiar with the workings of Markdown or Rstudio, but it
>does seem strange to me that I need to specifically load the global
>environment otherwise it's not visible.  Is that to be expected?
>
>Ideas welcome, particularly about scaling.

-- 
Sent from my phone. Please excuse my brevity.


From berwin@turl@ch @ending from gm@il@com  Thu Aug 23 16:26:42 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Thu, 23 Aug 2018 22:26:42 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <20180823110945.GS26688@paftolwp3a>
 <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>
Message-ID: <20180823222642.65d6cf1f@absentia>

G'day Rolf,

On Thu, 23 Aug 2018 23:34:38 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> I guess I should have said --- I did
> 
>      sudo make prefix=/usr install
> 
> which puts stuff into /usr rather than into /usr/local.

???

I do not remember ever specifying "prefix=foo" at the make install
stage.  Not for any software that uses autoconf &c.

I thought the prefix should be specified to ./configure and after that
just
	make
	make check
	make install

I am pretty sure that the location of RHOME is set by the path
specified (explicitly or implicitly) to ./configure.  If you then
install R at another location with your construct, some problems seem
to be pre-programmed.  But I could be wrong.
 
> I forget exactly why I chose (in the dim distant past) to do this ...
> I have a vague recollection that my search path was more
> "comfortable" that way.

In my experience this is a false comfort.  Set the search path so
that /opt/bin or /usr/local/bin is early on and finds programs you
install to those location.  

Installing to /usr will sooner or later lead to tears if your program
"conflicts" with some Ubuntu package (which might have been installed
to satisfy the requirement of another package that you needed).  If
that package is update during an "apt-get update", you can end up with
a broken system.  
 
> > I also have a recollection that I once installed Rstudio for some
> > MOOC, and ended up putting a symlink in somewhere like /usr/lib* ,
> > because Rstudio was only available as a binary with the location
> > of the shared lib hard-baked into it.  

The location is only hard-coded in relation to RHOME and with the
assumption that you are not using a sub-architecture on Ubuntu.  AFAIK,
binary Ubuntu distributions of R do not use sub-architectures and there
should be no problem on an Ubuntu system as long as all software is
installed via Ubuntu.  But this is probably a question better discussed
on r-sig-Debian

> So it looks like a symlink might be the answer for me.

Only if you can be sure that that libR.so is compatible with the R
version that you seem to be using.  The official r-base-core package
from Ubuntu seems to be R 3.4.4.  If you added the CRAN repository to
your Ubuntu system, you might have a newer version installed.  But if
your installation is partly a self-compiled R-3.5.1 version that is
then linked to an R 3.4.4 libR.so in /usr/lib/R/lib/ (from
r-cran-base), you are inviting trouble.

Cheers,

	Berwin


From peter@l@ngfelder @ending from gm@il@com  Thu Aug 23 17:45:37 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Thu, 23 Aug 2018 08:45:37 -0700
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <20180823222642.65d6cf1f@absentia>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <20180823110945.GS26688@paftolwp3a>
 <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>
 <20180823222642.65d6cf1f@absentia>
Message-ID: <CA+hbrhX+YvWPAFSJUwgfBsM5YCq1k5ezTtr6OqxaEm7iNMTQLg@mail.gmail.com>

On Thu, Aug 23, 2018 at 7:33 AM Berwin A Turlach
<berwin.turlach at gmail.com> wrote:
>
> G'day Rolf,
>
> On Thu, 23 Aug 2018 23:34:38 +1200
> Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> > I guess I should have said --- I did
> >
> >      sudo make prefix=/usr install
> >
> > which puts stuff into /usr rather than into /usr/local.
>
> ???
>
> I do not remember ever specifying "prefix=foo" at the make install
> stage.  Not for any software that uses autoconf &c.
>
> I thought the prefix should be specified to ./configure and after that
> just
>         make
>         make check
>         make install
>
> I am pretty sure that the location of RHOME is set by the path
> specified (explicitly or implicitly) to ./configure.  If you then
> install R at another location with your construct, some problems seem
> to be pre-programmed.  But I could be wrong.

The manual, specifically

https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installation

documents this way of choosing the installation directory.

Peter


From reichm@nj @ending from @bcglob@l@net  Fri Aug 24 04:38:56 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Thu, 23 Aug 2018 21:38:56 -0500
Subject: [R] How to add a geom_smooth() line
Message-ID: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>

R-help

 

I want to add two smooth lines (geom_smooth()) for each scatter plot.  How
do I do that?

 

ggplot() +

  geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +

  geom_point(data=data, aes(x=timeline, y=launches), color="red") +

  xlab("Deliveries") +

  ylab("Launches") +

  ggtitle("Scatterplot of Launches vs. Deliveries")

 

Jeff


	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Fri Aug 24 06:08:57 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 24 Aug 2018 05:08:57 +0100
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
Message-ID: <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>

Hello,

The trick is to reshape your data from wide to long format.
There are many ways to do this, I will use package reshape2.

Make up a dataset:


library(ggplot2)
library(reshape2)

set.seed(9773)
n <- 20
data <- data.frame(timeline = 1:n,
                    deliveries = log(1:n) + runif(n),
                    launches = (1:n)/4 + runif(n))

# reformat it
long <- melt(data, id.vars = "timeline")
head(long)

# et voila!
ggplot(long, aes(timeline, value, colour = variable)) +
     geom_point() +
     stat_smooth() +
     xlab("Deliveries") +
     ylab("Launches") +
     ggtitle("Scatterplot of Launches vs. Deliveries")


Use the smoothing function of your choice, I left it with the default loess.

Hope this helps,

Rui Barradas


On 24/08/2018 03:38, Jeff Reichman wrote:
> R-help
> 
>   
> 
> I want to add two smooth lines (geom_smooth()) for each scatter plot.  How
> do I do that?
> 
>   
> 
> ggplot() +
> 
>    geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +
> 
>    geom_point(data=data, aes(x=timeline, y=launches), color="red") +
> 
>    xlab("Deliveries") +
> 
>    ylab("Launches") +
> 
>    ggtitle("Scatterplot of Launches vs. Deliveries")
> 
>   
> 
> Jeff
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com


From ruipb@rr@d@@ @ending from @@po@pt  Fri Aug 24 06:14:13 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 24 Aug 2018 05:14:13 +0100
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
 <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>
Message-ID: <68d972be-c638-5f39-4873-2a2c8c8447d2@sapo.pt>

Sorry, should be geom_smooth, not stat_smooth. They both work the same 
way or very close to it.

Rui Barradas

On 24/08/2018 05:08, Rui Barradas wrote:
> Hello,
> 
> The trick is to reshape your data from wide to long format.
> There are many ways to do this, I will use package reshape2.
> 
> Make up a dataset:
> 
> 
> library(ggplot2)
> library(reshape2)
> 
> set.seed(9773)
> n <- 20
> data <- data.frame(timeline = 1:n,
>  ?????????????????? deliveries = log(1:n) + runif(n),
>  ?????????????????? launches = (1:n)/4 + runif(n))
> 
> # reformat it
> long <- melt(data, id.vars = "timeline")
> head(long)
> 
> # et voila!
> ggplot(long, aes(timeline, value, colour = variable)) +
>  ??? geom_point() +
>  ??? stat_smooth() +
>  ??? xlab("Deliveries") +
>  ??? ylab("Launches") +
>  ??? ggtitle("Scatterplot of Launches vs. Deliveries")
> 
> 
> Use the smoothing function of your choice, I left it with the default 
> loess.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> On 24/08/2018 03:38, Jeff Reichman wrote:
>> R-help
>>
>>
>> I want to add two smooth lines (geom_smooth()) for each scatter plot.  
>> How
>> do I do that?
>>
>>
>> ggplot() +
>>
>> ?? geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +
>>
>> ?? geom_point(data=data, aes(x=timeline, y=launches), color="red") +
>>
>> ?? xlab("Deliveries") +
>>
>> ?? ylab("Launches") +
>>
>> ?? ggtitle("Scatterplot of Launches vs. Deliveries")
>>
>>
>> Jeff
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipb@rr@d@@ @ending from @@po@pt  Fri Aug 24 06:31:30 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 24 Aug 2018 05:31:30 +0100
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
 <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>
Message-ID: <dc9ef8f9-ab78-f882-d442-a514ddd3931e@sapo.pt>

Hello,

if you want to fit different models to each of deliveries and launches, 
use the wide format instead:


ggplot(data = data, aes(x = timeline)) +
   geom_point(aes(y = deliveries), color = "blue") +
   geom_smooth(aes(y = deliveries), color = "blue", method = lm, formula 
= y ~ log(x)) +
   geom_point(aes(y = launches), color = "red") +
   geom_smooth(aes(y = launches), color = "red", method = lm, formula = 
y ~ x) +
   xlab("Deliveries") +
   ylab("Launches") +
   ggtitle("Scatterplot of Launches vs. Deliveries")


Hope this helps,

Rui Barradas

On 24/08/2018 05:08, Rui Barradas wrote:
> Hello,
> 
> The trick is to reshape your data from wide to long format.
> There are many ways to do this, I will use package reshape2.
> 
> Make up a dataset:
> 
> 
> library(ggplot2)
> library(reshape2)
> 
> set.seed(9773)
> n <- 20
> data <- data.frame(timeline = 1:n,
>  ?????????????????? deliveries = log(1:n) + runif(n),
>  ?????????????????? launches = (1:n)/4 + runif(n))
> 
> # reformat it
> long <- melt(data, id.vars = "timeline")
> head(long)
> 
> # et voila!
> ggplot(long, aes(timeline, value, colour = variable)) +
>  ??? geom_point() +
>  ??? stat_smooth() +
>  ??? xlab("Deliveries") +
>  ??? ylab("Launches") +
>  ??? ggtitle("Scatterplot of Launches vs. Deliveries")
> 
> 
> Use the smoothing function of your choice, I left it with the default 
> loess.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> On 24/08/2018 03:38, Jeff Reichman wrote:
>> R-help
>>
>>
>> I want to add two smooth lines (geom_smooth()) for each scatter plot.  
>> How
>> do I do that?
>>
>>
>> ggplot() +
>>
>> ?? geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +
>>
>> ?? geom_point(data=data, aes(x=timeline, y=launches), color="red") +
>>
>> ?? xlab("Deliveries") +
>>
>> ?? ylab("Launches") +
>>
>> ?? ggtitle("Scatterplot of Launches vs. Deliveries")
>>
>>
>> Jeff
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @u@@n@eli@@ @ending from m@ine@edu  Fri Aug 24 00:09:47 2018
From: @u@@n@eli@@ @ending from m@ine@edu (Susan Elias)
Date: Thu, 23 Aug 2018 18:09:47 -0400
Subject: [R] How does Markov random field (bs=mrf) in mgvc gam handle
 repeated measures on the spatial units?
Message-ID: <CAKXsTQPROq=Gv5-ZGNCR1DZb1wgbrV5ErgvOkFjOB0QZR8MExw@mail.gmail.com>

Hello R,

I am attempting a spatio-temporal model in mgcv gam.

I am using a factor smooth to define each of 27 areal units in a shapefile
("id") as subjects (essentially) which have undergone 23 repeated
measurements in time ("year").

I am using the Markov random field to define the neighbor relationships of
the area units.

I have combed through Wood (2017) and other resources and have not found an
answer to my question, which is: how is the mrf handling the repeated
measures?  My model is:

model<-gam(response) ~ s(year) +
                       ti(year,id, bs="fs", m=1) +
                       s(id, bs = 'mrf', xt = list(nb = neighbors), k=5),
                       family=tw(), data=data)

Susan

	[[alternative HTML version deleted]]


From rileyfinn3 @ending from gm@il@com  Fri Aug 24 05:23:40 2018
From: rileyfinn3 @ending from gm@il@com (Riley Finn)
Date: Thu, 23 Aug 2018 22:23:40 -0500
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
Message-ID: <CAKg3cnLp2G51HyfS_zoqjcX__yoiJ=6NCqmbraphpOa5LagQKA@mail.gmail.com>

Jeff,

You need to reshape your data frame.  If you use ggplot, you will often
have to present your data in "long format"

Use the reshape2 package.

I made a sample data frame because you didn't provide one.  I also change
your x and y labels because they made no sense.

data <- data.frame(
  timeline = 1:10,
  launches = sample(10:20, 10),
  deliveries = sample(10:20, 10)
)

library(reshape2)
dataNew <- melt(data = data, id.vars = 'timeline',
                variable.name = 'launchOrDelivery')

ggplot(data=dataNew, aes(x=timeline, y=value), color= launchOrDelivery) +
  geom_point(aes(color= launchOrDelivery)) +
  geom_smooth(aes(group = launchOrDelivery, color= launchOrDelivery), se =
FALSE) +
  xlab("timeline") +
  ylab("Launches/Deliveries") +
  ggtitle("Scatterplot of Launches vs. Deliveries")


On Thu, Aug 23, 2018 at 9:39 PM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-help
>
>
>
> I want to add two smooth lines (geom_smooth()) for each scatter plot.  How
> do I do that?
>
>
>
> ggplot() +
>
>   geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +
>
>   geom_point(data=data, aes(x=timeline, y=launches), color="red") +
>
>   xlab("Deliveries") +
>
>   ylab("Launches") +
>
>   ggtitle("Scatterplot of Launches vs. Deliveries")
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From berwin@turl@ch @ending from gm@il@com  Fri Aug 24 11:27:40 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Fri, 24 Aug 2018 17:27:40 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <CA+hbrhX+YvWPAFSJUwgfBsM5YCq1k5ezTtr6OqxaEm7iNMTQLg@mail.gmail.com>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <20180823110945.GS26688@paftolwp3a>
 <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>
 <20180823222642.65d6cf1f@absentia>
 <CA+hbrhX+YvWPAFSJUwgfBsM5YCq1k5ezTtr6OqxaEm7iNMTQLg@mail.gmail.com>
Message-ID: <20180824172740.62fad478@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Peter,

On Thu, 23 Aug 2018 08:45:37 -0700
Peter Langfelder <peter.langfelder at gmail.com> wrote:

> The manual, specifically
> 
> https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installation
> 
> documents this way of choosing the installation directory.

Yes, with the caveat that one needs GNU or Solaris make (which would be
the case on Ubuntu).  So it is hardly the recommended way.  

As I read the R Administration Manual, the recommended way is to specify
the location at which you want to install R via ./configure.

Cheers,

	Berwin


From @@himk@poor @ending from gm@il@com  Fri Aug 24 11:31:12 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Fri, 24 Aug 2018 15:01:12 +0530
Subject: [R] Unclear about the output from summary of ca.jo from package
 urca
In-Reply-To: <CAGxFJbTmbYTq_ybXXpbQmvk-N2DZ58KcLmy_T+rTdZ+y5KxoXQ@mail.gmail.com>
References: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
 <CAGxFJbTmbYTq_ybXXpbQmvk-N2DZ58KcLmy_T+rTdZ+y5KxoXQ@mail.gmail.com>
Message-ID: <CAC8=1erwNmOW0YBqLag+rr71gZVN-4TkTNNT3Nw7=HfuJbZ-rg@mail.gmail.com>

Dear Bert,

I have read some of the references. I do understand what the 2 matrices(
the cointegrating relationships and the alpha / loading matrix which gives
the speed of the mean reversion)  are. What I do not understand is the
format of the output of the package. My main query is that why do we have
.l2 in the cointegrating relationships. They are contemporaneous
relationships , they should not have .l2 in the end. That's my query.

Many thanks,
Ashim

On Thu, Aug 23, 2018 at 7:52 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> This is about statistics , not R programming, and so is off topic here.
> Your first port of call for this sort of thing should be the package docs,
> **including any references** . There are references given. Have you studied
> them??
>
> Cheers,
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Aug 23, 2018 at 2:12 AM Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I am not sure about the summary of the function ca.jo. I have posted my
>> query here :-
>>
>>
>> https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r
>>
>> I did not receive any reply so I am posting my query here.
>>
>> Many thanks and best regards,
>> Ashim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Fri Aug 24 12:02:59 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Fri, 24 Aug 2018 12:02:59 +0200
Subject: [R] Unclear about the output from summary of ca.jo from package
 urca
In-Reply-To: <CAC8=1erwNmOW0YBqLag+rr71gZVN-4TkTNNT3Nw7=HfuJbZ-rg@mail.gmail.com>
References: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
 <CAGxFJbTmbYTq_ybXXpbQmvk-N2DZ58KcLmy_T+rTdZ+y5KxoXQ@mail.gmail.com>
 <CAC8=1erwNmOW0YBqLag+rr71gZVN-4TkTNNT3Nw7=HfuJbZ-rg@mail.gmail.com>
Message-ID: <83C9E217-B785-4226-A9D3-BA2CA52F1BCE@gmail.com>

Well, reading the code is not much harder than reading the papers (not that that helps much, been there...)

I don't actually know the answer, but the notation comes from this bit in ca.jo():

        if (spec == "longrun") {
            ZK <- cbind(x[-c((N - K + 1):N), ], 1)
            Lnotation <- K
        }
        else if (spec == "transitory") {
            ZK <- cbind(x[-N, ], 1)[K:(N - 1), ]
            Lnotation <- 1
        }
        colnames(ZK) <- c(paste(colnames(x), ".l", Lnotation, 
            sep = ""), "constant")

(actually there are several such bits). 

K=2 by default, so you get .l2 for the "longrun" spec and ".l1" for "transitory". So I would guess that studying the two specification formats from the help page might give the solution to the riddle eventually.

(Another issue is that the column names are clearly rubbish, only the row names make sense. The columns are eigenvectors sorted by eigenvalues which has no relation to the input columns. Presumably, they are just an artifact of the matrix operations.)

-pd

> On 24 Aug 2018, at 11:31 , Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> 
> Dear Bert,
> 
> I have read some of the references. I do understand what the 2 matrices(
> the cointegrating relationships and the alpha / loading matrix which gives
> the speed of the mean reversion)  are. What I do not understand is the
> format of the output of the package. My main query is that why do we have
> .l2 in the cointegrating relationships. They are contemporaneous
> relationships , they should not have .l2 in the end. That's my query.
> 
> Many thanks,
> Ashim
> 
> On Thu, Aug 23, 2018 at 7:52 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> This is about statistics , not R programming, and so is off topic here.
>> Your first port of call for this sort of thing should be the package docs,
>> **including any references** . There are references given. Have you studied
>> them??
>> 
>> Cheers,
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Aug 23, 2018 at 2:12 AM Ashim Kapoor <ashimkapoor at gmail.com>
>> wrote:
>> 
>>> Dear All,
>>> 
>>> I am not sure about the summary of the function ca.jo. I have posted my
>>> query here :-
>>> 
>>> 
>>> https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r
>>> 
>>> I did not receive any reply so I am posting my query here.
>>> 
>>> Many thanks and best regards,
>>> Ashim
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From col@vittorio @ending from virgilio@it  Fri Aug 24 12:29:01 2018
From: col@vittorio @ending from virgilio@it (Vittorio Colagrande)
Date: Fri, 24 Aug 2018 12:29:01 +0200
Subject: [R] Algorithm Net Analyte Signal (NAS) in R
Message-ID: <FF1D1AD17EF54C9D938E44CEDDD198C2@user8a7c344e2a>

 Dear R-group
I would like to ask a possible algorithm in R and related documetation for 

the development of analysis "Net Analyte Signal" (NAS) in order to solve 

of problem of spectral interference in Analytical Chemistry. 

 

I will greatly appreciate any clarification you could provide.

Best regards.

Vittorio Colagrande
	[[alternative HTML version deleted]]


From reichm@nj @ending from @bcglob@l@net  Fri Aug 24 13:44:05 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Fri, 24 Aug 2018 06:44:05 -0500
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <CAKg3cnLp2G51HyfS_zoqjcX__yoiJ=6NCqmbraphpOa5LagQKA@mail.gmail.com>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
 <CAKg3cnLp2G51HyfS_zoqjcX__yoiJ=6NCqmbraphpOa5LagQKA@mail.gmail.com>
Message-ID: <000601d43b9f$c35cba60$4a162f20$@sbcglobal.net>

Got it thank you

 

From: Riley Finn <rileyfinn3 at gmail.com> 
Sent: Thursday, August 23, 2018 10:24 PM
To: reichmanj at sbcglobal.net
Cc: R-help at r-project.org
Subject: Re: [R] How to add a geom_smooth() line

 

Jeff,

 

You need to reshape your data frame.  If you use ggplot, you will often have to present your data in "long format"

 

Use the reshape2 package.

 

I made a sample data frame because you didn't provide one.  I also change your x and y labels because they made no sense.  

 

data <- data.frame(
  timeline = 1:10,
  launches = sample(10:20, 10),
  deliveries = sample(10:20, 10)
)

library(reshape2)
dataNew <- melt(data = data, id.vars = 'timeline', 
                variable.name <http://variable.name>  = 'launchOrDelivery')

ggplot(data=dataNew, aes(x=timeline, y=value), color= launchOrDelivery) +
  geom_point(aes(color= launchOrDelivery)) + 
  geom_smooth(aes(group = launchOrDelivery, color= launchOrDelivery), se = FALSE) + 
  xlab("timeline") +
  ylab("Launches/Deliveries") +
  ggtitle("Scatterplot of Launches vs. Deliveries")

 

On Thu, Aug 23, 2018 at 9:39 PM Jeff Reichman <reichmanj at sbcglobalnet <mailto:reichmanj at sbcglobal.net> > wrote:

R-help



I want to add two smooth lines (geom_smooth()) for each scatter plot.  How
do I do that?



ggplot() +

  geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +

  geom_point(data=data, aes(x=timeline, y=launches), color="red") +

  xlab("Deliveries") +

  ylab("Launches") +

  ggtitle("Scatterplot of Launches vs. Deliveries")



Jeff


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From i@t@z@hn @ending from gm@il@com  Fri Aug 24 15:10:34 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Fri, 24 Aug 2018 09:10:34 -0400
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
Message-ID: <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>

On Thu, Aug 23, 2018 at 6:57 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> I *think* that this is an R question (and *not* an RStudio question!)

I think this is actually and Ubuntu question, and probably belongs on
R-sig-debian.

>
> I have, somewhat against my better judgement, decided to experiment with
> using RStudio.
>
> I downloaded and install RStudio.  Easy-peasy.  Nice lucid instructions.
>
> Then I tried to start RStudio ("rstudio" from the command line)
> and got a pop-up window with the error message:
>
> > R shared library (/usr/lib64/R/lib/libR.so) not found. If this
> > is a custom build of R, was it built with the --enable-R-shlib option?
>
> Oops, no, I guess it wasn't.  So I carefully did a
>
>      sudo make uninstall
>      make clean
>      make distclean
>
> and then did
>
>      ./R-3.5.1/configure <various flags>
>
> making sure I added the --enable-R-shlib flag.
>
> Then I did make and sudo make install.

IMO if you are compiling and installing software yourself on Linux
your are Doing It Wrong. Use the package manager, that is what it is
there for.

--Ista

It all seemed to go ...
> but then I did
>
>      rstudio
>
> again and got the same popup error.
>
> There is indeed *no* libR.so in /usr/lib64/R/lib.
>
> There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals that
> it dates from the my previous install of R-3.5.1 for which I *did not*
> configure with --enable-R-shlib.
>
> Can anyone explain to me WTF is going on?
>
> What should I do?  Just make a symbolic link from /usr/lib/R/lib/libR.so
> to /usr/lib64/R/lib/libR.so?
>
> It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
> most recent install of R.
>
> I plead for enlightenment.
>
> cheers,
>
> Rolf Turner
>
> P.S. I'm running Ubuntu 18.04.  And the previous install of R was done
> under Ubuntu 18.04.
>
> R. T.
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bog@@o@chri@tofer @ending from gm@il@com  Fri Aug 24 15:12:16 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Fri, 24 Aug 2018 18:42:16 +0530
Subject: [R] Cant schedule R job using taskscheduleR
Message-ID: <CA+dpOJ=RfRW0eSkvES2vCeR1AuQPrYwdMnwJThqqkvwYyB6Oig@mail.gmail.com>

Hi,

I am trying to schedule an R job using taskscheduler_create() function
available in package taskscheduleR.

Below is my code:

> library(taskscheduleR)
Warning message:
package ?taskscheduleR? was built under R version 3.5.1
> taskscheduler_create(taskname = "ABC", rscript = paste("C:\\ABC.R"),
startdate = format(Sys.Date() + 1, "%d/%m/%Y"), schedule = "WEEKLY",
starttime = "16:30", days = c("MON", "TUE", "WED", "THU", "FRI")[1])
[1] "ERROR: Incorrect Start Date."
attr(,"status")
[1] 16389
Warning message:
In system(cmd, intern = TRUE) :
  running command 'schtasks /Create /TN "ABC" /TR "cmd /c
C:/PROGRA~1/R/R-35~1.0/bin/Rscript.exe \"C:\ABC.R\"  >> \"C:\ABC.log\"
2>&1" /SC WEEKLY /ST 16:30 /SD "25/08/2018" /D MON ' had status 16389


However it fails with stating Incorrect Start Date.

Any help to understand what went wrong?

I am using R in Windows. Below is Session Information :

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
                 LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] taskscheduleR_1.1

loaded via a namespace (and not attached):
[1] compiler_3.5.0    tools_3.5.0       data.table_1.11.4

	[[alternative HTML version deleted]]


From deep@m@hm@ii@c @ending from gm@il@com  Fri Aug 24 15:44:19 2018
From: deep@m@hm@ii@c @ending from gm@il@com (Deepa)
Date: Fri, 24 Aug 2018 19:14:19 +0530
Subject: [R] Multiple counters in a single for loop
Message-ID: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>

Hello,

Is there an option to include multiple counters in a single for loop in R?

For instance, in python there is

for i,j in zip(x,range(0,len(x))):


Any suggestions?

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Aug 24 16:53:10 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 24 Aug 2018 07:53:10 -0700
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180824101317.GC13179@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180824101317.GC13179@slingshot.co.nz>
Message-ID: <9B82F30C-FD82-42A1-97EC-52A9E79478F9@dcn.davis.ca.us>

a) Keep the mailing list in the conversation... someone else may have useful input, and others may benefit from reading the discussion.

b) If the issue can be reproduced on your end with something like a basic plot(mpg~disk, data=mtcars) call, then you should use that instead of your complicated example. If the problem only appears when you use certain plotting functions hidden inside your plot1 through plot6 functions, we can't tell that from here. Sorting that out is part of making your example minimal as the Posting Guide requests.

c) If you can only reproduce with certain data, then you can use dput to give us the necessary data.[1][2] It is up to you to determine what the minimal data needed to demo the problem is, but we don't want to sift through some large data blob only to find out that it was not relevant so you need to do that. 

d) Interactions with data files are hard to make reproducible on someone else's computer... saving data with different filenames will not help fix that problem.

e) Note that this is the R-help mailing list, not the RStudio-help mailing list nor the rmarkdown-package-help mailing list. We can and often do provide help on using contributed packages anyway, but you should be aware that not everyone here uses RStudio so doing your best to provide a reproducible example is in your interest if you want readers to consider your question on topic.

There are many discussions online of how to communicate R examples, such as [1][2][3]. In particular I think [3] is useful because it forces you to confirm that the example will run in a fresh R environment which is the first step to insuring it will run on our computers and we can dig into the problem. in this case you could use it to help confirm that your R code should work for us without the rmarkdown.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On August 24, 2018 3:13:17 AM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>On Thu, 23-Aug-2018 at 07:23AM -0700, Jeff Newmiller wrote:
>
>|> This is not reproducible because you have not provided the plot
>|> code or sample data. Output of sessionInfo would probably be
>|> appropriate as well.
>
>I took it as read that the plotting functions themselves aren't an
>issue since they operate as intended outside of the Rmarkdown
>space. Any function that uses the function plot() successfully will
>do.  I was trying to ascertain how I should be setting up the scaling.
>
>|> As to whether needing to load objects is typical... yes, rmarkdown
>|> runs from a fresh environment to emphasize reproducibility, but
>|> your load command is bypassing that for us.
>
>The objects loaded from .RData took hours of simulating and it's out
>of the question to run them again inside Rmarkdown.  Though the script
>used in the creation of .RData is reproducable, perhaps it would be
>clearer for me to have saved the objects to a file by a different
>name.
>
>Is there a better way to do that??
>
>
>
>|> On August 23, 2018 2:15:19 AM PDT, Patrick Connolly
><p_connolly at slingshot.co.nz> wrote:
>|> >I'm having difficulty getting plots into ioslides.  It seems to me
>|> >that the scale is completely out, but I can't figure out what to do
>|> >about it.  Whatever I try, I get the title slide, then a second
>with a
>|> >horizontal line and a vertical line in the bottom right corner.  It
>|> >looks like a badly scaled plot about 25 times the size of the
>plotting
>|> >area, so only a fragment is visible.
>|> >
>|> >This is the code I've tried:
>|> >
>|> >---
>|> >title: "Barking up the wrong tree"
>|> >author: "Patrick Connolly"
>|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
>|> >output: ioslides_presentation
>|> >---
>|> >
>|> >```{r global_options, echo=FALSE}
>|> >knitr::opts_chunk$set(tidy=TRUE,
>|> >                      warning=FALSE, 
>|> >                      message=FALSE,
>|> >                      cache=FALSE,
>|> >                      dpi=600)
>|> >```
>|> >
>|> >```{r use these functions, echo= FALSE}
>|> >  load(".RData") ## code for 6 plotting functions
>|> >
>|> >``
>|> >## 6 different Trees
>|> >
>|> >```{r 6 different Trees, echo = FALSE, messages=FALSE, fig.width =
>7,
>|> >fig.height = 5}
>|> >
>|> >###  par(mfrow = c(2, 3))
>|> >plot1()
>|> >plot2()
>|> >plot3()
>|> >plot4()
>|> >plot5()
>|> >plot6()
>|> >}
>|> >```
>|> >
>|> >If I run the plot functions in the Console, it all works and
>displays
>|> >correctly in Rstudiio's plot panel, even the mfrow bit.  But I
>haven't
>|> >worked out how to include the code into Rmarkdown.  I thought it
>might
>|> >be less taxing to not try putting the 6 plots on the same slide,
>but
>|> >it makes no difference when I commented out the mfrow bit.
>|> >
>|> >I'm not very familiar with the workings of Markdown or Rstudio, but
>it
>|> >does seem strange to me that I need to specifically load the global
>|> >environment otherwise it's not visible.  Is that to be expected?
>|> >
>|> >Ideas welcome, particularly about scaling.
>|> 
>|> -- 
>|> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Fri Aug 24 17:28:23 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 24 Aug 2018 08:28:23 -0700
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
References: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
Message-ID: <CAGxFJbTUid_QqaVBBjMQGLiMDuRKpD1mPT-A-RAGjkyeddFm7g@mail.gmail.com>

Sort of, but you typically wouldn't need to in R because of vectorization,
which buries the iteration in the underlying C code. Here's an example that
may clarify what I mean:

x <- cbind(1:5,6:10)
x ## a 2 column matrix
## get squares of all elements of x
## method 1
m1 <-x^2

##method 2: square the column vectors
m2 <- x
for (i in 1:2)m2[,i] <- m2[,i]^2
identical(m1,m2)
## of course, one could do this by row vectors, too

## method 3: loop through each element
m3 <- x
ix <- as.matrix(expand.grid(1:5,1:2))
ix
m3[ix]^2 ## matrix indexing of an array. This produces a vector,though.

Note also that there is an "iterators" package in R which implements
python-like iterators.I don't know how efficient it is, however.

My overall advice would be that you should try to program in R's native
paradigms, which emphasize whole object manipulation through vectorization,
rather than trying to use Python's, especially if efficiency is a
consideration. Feel free to ignore of course.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 24, 2018 at 6:44 AM Deepa <deepamahm.iisc at gmail.com> wrote:

> Hello,
>
> Is there an option to include multiple counters in a single for loop in R?
>
> For instance, in python there is
>
> for i,j in zip(x,range(0,len(x))):
>
>
> Any suggestions?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Fri Aug 24 18:00:13 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 24 Aug 2018 16:00:13 +0000
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
References: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
Message-ID: <D7431DA4-8E78-4175-A716-89E997BAD187@llnl.gov>

I don't know of any such option, but it's easy enough to achieve something more or less equivalent.

x <- runif(5)

for (ir in seq(nrow(myi <- cbind(x, 1:length(x))))) {
  i <- myi[ir,1]
  j <- myi[ir,2]
  cat(i,j,'\n')
}

I consider that for() statement to be ugly and unreadable. Normally I would build the matrix myi before constructing the loop, and make other changes for clarity. But in this instance I wanted to make it a one-liner, just to more or less mimic the python.

And having now read Bert's reply, he makes a good point. For many things one might want to do with such a loop, R can do them without an explicit loop.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/24/18, 6:44 AM, "R-help on behalf of Deepa" <r-help-bounces at r-project.org on behalf of deepamahm.iisc at gmail.com> wrote:

    Hello,
    
    Is there an option to include multiple counters in a single for loop in R?
    
    For instance, in python there is
    
    for i,j in zip(x,range(0,len(x))):
    
    
    Any suggestions?
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @mit@c@03 @ending from gm@il@com  Fri Aug 24 18:34:29 2018
From: @mit@c@03 @ending from gm@il@com (Amit Govil)
Date: Sat, 25 Aug 2018 00:34:29 +0800
Subject: [R] Need some help with data-wrangling in R
Message-ID: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>

Hi,

I have log data in which one of the columns have IP ranges and the next
column is corresponding ports. Eg:


IPRange Port
10.78.64.0-10.78.66.255 D, A, C

I need to expand the IPRange column into a list of network blocks till 3rd
octet:

IPRange IP Port
192.100.176.0-192.100.179.255 192.100.176.0/24 A, B, C
192.100.176.0-192.100.179.255 192.100.177.0/24 A, B, C
192.100.176.0-192.100.179.255 192.100.178.0/24 A, B, C
192.100.176.0-192.100.179.255 192.100.179.0/24 A, B, C

How do I do this data transformation in R?

Please assist.

Thanks
Amit

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Aug 24 18:52:55 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 24 Aug 2018 09:52:55 -0700
Subject: [R] Need some help with data-wrangling in R
In-Reply-To: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>
References: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>
Message-ID: <CAGxFJbQOgNDbA-5O8zKnRX6WeJX11yfJurOwzy=iJ7yFtCV74Q@mail.gmail.com>

" list of network blocks till 3rd octet:"

This is incomprehensible to me. If that is so for others, also, I suggest
that you provide a reproducible example (see posting guide) to explain what
you mean.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 24, 2018 at 9:41 AM Amit Govil <amit.cs03 at gmail.com> wrote:

> Hi,
>
> I have log data in which one of the columns have IP ranges and the next
> column is corresponding ports. Eg:
>
>
> IPRange Port
> 10.78.64.0-10.78.66.255 D, A, C
>
> I need to expand the IPRange column into a list of network blocks till 3rd
> octet:
>
> IPRange IP Port
> 192.100.176.0-192.100.179.255 192.100.176.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.177.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.178.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.179.0/24 A, B, C
>
> How do I do this data transformation in R?
>
> Please assist.
>
> Thanks
> Amit
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Fri Aug 24 18:53:57 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 24 Aug 2018 17:53:57 +0100
Subject: [R] Need some help with data-wrangling in R
In-Reply-To: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>
References: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>
Message-ID: <3bc9735a-ddcf-7df8-2052-39b95cfc87fc@sapo.pt>

Hello,

Cross-posting is not very well seen by R-Help. Please wait for an answer 
to one of your posts before posting somewhere else.

https://stackoverflow.com/questions/52008756/how-to-get-a-list-of-ip-addresses-from-an-ip-range-using-r

Rui Barradas

On 24/08/2018 17:34, Amit Govil wrote:
> Hi,
> 
> I have log data in which one of the columns have IP ranges and the next
> column is corresponding ports. Eg:
> 
> 
> IPRange Port
> 10.78.64.0-10.78.66.255 D, A, C
> 
> I need to expand the IPRange column into a list of network blocks till 3rd
> octet:
> 
> IPRange IP Port
> 192.100.176.0-192.100.179.255 192.100.176.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.177.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.178.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.179.0/24 A, B, C
> 
> How do I do this data transformation in R?
> 
> Please assist.
> 
> Thanks
> Amit
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com


From p@ulbern@l07 @ending from gm@il@com  Fri Aug 24 20:57:10 2018
From: p@ulbern@l07 @ending from gm@il@com (Paul Bernal)
Date: Fri, 24 Aug 2018 13:57:10 -0500
Subject: [R] Obtaining Complete Dataset with Imputed Values
Message-ID: <CAMOcQfOFkwSUVhXGCy7-R-3YGLC0swMY-1TjBLTQTR_jpJsgRQ@mail.gmail.com>

Dear friends, hope all is well with you,

I am working with package mi for data inputation. Currently working with R
version 3.5.0 (64-bit).

Say my data is  defined as dat, and I do the following:

datimputations <- mi(dat[2:5], n.iter=50)
completedat <- complete(datimputations)

After using the complete function, I get the following error message:

Error in complete(datimputations, m = 1) : 'data' not of class 'mids'

How can I retrieve the processed dataframe (along with the imputed values)?

Here is my dput() for you to see

> dput(head(dat,100))
structure(list(TransitDate = structure(c(496990800, 499669200,
502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
754722000, 757400400), class = c("POSIXct", "POSIXt"), tzone = ""),
    Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L, 14L, 16L,
    6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L, 10L,
    9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
    7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L,
    5L, 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L,
    9L, 8L, 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L,
    14L, 15L, 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L,
    9L, 12L, 8L, 12L, 10L, 11L, 10L, 9L, 10L), CargoTons = c(154973L,
    129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
    124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L,
    98222L, 54719L, 98470L, 18263L, 104255L, 62869L, 62523L,
    75344L, 81476L, 92818L, 87457L, 85231L, 77897L, 57699L, 96989L,
    109361L, 59799L, 91116L, 82241L, 74251L, 124361L, 68751L,
    61719L, 68017L, 37760L, 32513L, 56359L, 51333L, 80859L, 75852L,
    65760L, 96043L, 38820L, 63202L, 102647L, 49104L, 53482L,
    121305L, 71795L, 76704L, 146097L, 73047L, 68557L, 110642L,
    77616L, 97767L, 52059L, 58658L, 66350L, 69303L, 76013L, 91909L,
    108445L, 94454L, 101249L, 112131L, 56290L, 118342L, 70618L,
    64783L, 112839L, 120506L, 94243L, 130768L, 133643L, 146321L,
    140736L, 147234L, 158953L, 189888L, 93819L, 130021L, 130124L,
    55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
    93713L, 98417L, 97210L, 88464L, 94659L), RcnstPCUMS = c(229914L,
    214547L, 215890L, 158695L, 173125L, 222533L, 212490L, 222125L,
    266913L, 94268L, 112967L, 95480L, 87654L, 108996L, 97973L,
    139247L, 93817L, 133197L, 40020L, 169749L, 102590L, 112121L,
    140241L, 122989L, 144592L, 144979L, 123748L, 123249L, 70081L,
    155218L, 168096L, 104743L, 163384L, 142648L, 129188L, 183170L,
    99299L, 99873L, 111648L, 55890L, 59183L, 95568L, 72550L,
    104562L, 100478L, 92665L, 130625L, 54786L, 105900L, 135833L,
    70932L, 73247L, 149632L, 94317L, 87926L, 181989L, 92778L,
    107097L, 153246L, 105175L, 126393L, 81976L, 95518L, 109019L,
    95370L, 140492L, 125795L, 157978L, 138424L, 138160L, 180320L,
    78757L, 135860L, 85921L, 114847L, 151965L, 152561L, 132841L,
    204839L, 209567L, 224436L, 210209L, 227143L, 245968L, 264969L,
    158648L, 222251L, 194335L, 111618L, 189643L, 137438L, 124953L,
    163155L, 107633L, 164525L, 135102L, 152072L, 126636L, 121008L,
    137824L), TotalToll = c(420742L, 392621L, 395078L, 290411L,
    316818L, 407235L, 388856L, 406488L, 482774L, 172510L, 206729L,
    174728L, 160406L, 199462L, 179290L, 254822L, 171685L, 243750L,
    73236L, 310640L, 187739L, 205181L, 249438L, 225069L, 264603L,
    265311L, 226458L, 225545L, 128248L, 284048L, 296023L, 184934L,
    298992L, 261045L, 236414L, 335201L, 181717L, 182767L, 204315L,
    102278L, 108304L, 174889L, 132766L, 191348L, 183874L, 169576L,
    239043L, 100258L, 212859L, 273024L, 142573L, 147226L, 300760L,
    189577L, 176731L, 365797L, 186483L, 215264L, 308024L, 211401L,
    254049L, 164771L, 191991L, 219128L, 191693L, 282388L, 252847L,
    317535L, 278232L, 277701L, 356022L, 158301L, 273078L, 172701L,
    230842L, 305449L, 306647L, 267010L, 406202L, 421229L, 451116L,
    422520L, 456557L, 494395L, 582202L, 350612L, 491174L, 429480L,
    239858L, 419111L, 303737L, 276146L, 360572L, 237868L, 358627L,
    298575L, 336079L, 279865L, 267427L, 304591L)), row.names = c(NA,
100L), class = "data.frame")

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Aug 24 21:37:59 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 24 Aug 2018 12:37:59 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Rich Shepard wrote:

>  More when I have results.

   Almost there. I've read the auto.key section in ?barchart and looked at
examples from stackoverflow on the web without seeing my syntax errors. I
would like help on two issues:

   1. What I want is to have the legend text in black and the colored
rectangles match the black and grey of the bars. Instead, I get the legend
text colored and have no idea where the default colors in the rectangles got
there.

   2. I've not found how to have the years (rather than the sequence of
years) as the x-axis labels.

   Here are the dput() output and the script:

structure(list(year = c(1989L, 1989L, 1990L, 1990L, 1991L, 1991L, 
1993L, 1993L, 1994L, 1994L, 1995L, 1995L, 1996L, 1996L, 1997L, 
1997L, 1998L, 1998L, 1999L, 1999L, 2000L, 2000L, 2001L, 2001L, 
2002L, 2002L, 2003L, 2003L, 2004L, 2004L, 2005L, 2005L, 2006L, 
2006L, 2007L, 2007L, 2008L, 2008L, 2009L, 2009L, 2010L, 2010L, 
2011L, 2011L, 2012L, 2012L, 2013L, 2013L, 2014L, 2014L, 2015L, 
2015L, 2016L, 2016L, 2017L, 2017L, 2018L, 2018L), value = c(91.17, 
93.32, 91.22, 93.43, 91.24, 92.89, 91.14, 93.02, 93.92, 95.74, 
94.34, 96.85, 91.32, 95.86, 91.36, 94.25, 91.24, 93.67, 94.33, 
97.42, 94.33, 97.42, 94, 94.99, 94.32, 96.58, 94.02, 96.57, 94.19, 
96.32, 94.05, 95.96, 94.21, 97.4, 94.21, 97.28, 94.32, 96.72, 
94.13, 97.43, 94.27, 95.95, 94.34, 97.82, 94.23, 97, 94.25, 96.6, 
94.15, 96.24, 94.01, 96.68, 94.09, 96.96, 94.31, 96.39, 94.35, 
96.95), type = structure(c(2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L), .Label = c("Max", "Med"), class = "factor")), class = "data.frame", row.names = c(NA, 
-58L))

med_max <- barchart(value ~ year, data=stage_heights,
                     panel = lattice.getOption("panel.barchart"),
                     default.prepanel = lattice.getOption("prepanel.default.barchart"),
                     box.ratio = 2, horizontal=FALSE, auto.key=list(space='right',
                                                                    col=c('black', 'grey')),
                     groups=factor(type,labels=c('Median','Maximum')), beside=TRUE,
                     col = c('grey','black'), labels=list(c(1989,1990,1991,1992, 1993,1994,
                                                            1995,1996,1997,1998,1999,2000,2001,
                                                            2002,2003,2004,2005,2006,2007,2008,
                                                            2009,2010,2011,2012,2013,2014,2015,
                                                            2016,2017,2018),
                                                          scales=list(x=list(rot=90)),
                                                          main = 'Median and Maximum Stage Heights',
                                                          ylab = 'Elevation (masl)', xlab = 'Year')
print(med_max)

Rich


From rmh @ending from temple@edu  Fri Aug 24 21:58:15 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Fri, 24 Aug 2018 15:58:15 -0400
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
Message-ID: <CAGx1TMDfE5+5pkVx-kz1Q-N742z2bykH=OdKxKcZ91qSM733Hg@mail.gmail.com>

color for the legend comes from trellis.par.get

You can control that for an individual plot with the par.settings argument.

tmp <- data.frame(y=sample(10),
                  group=rep(c("Median", "Maximum"), each=5),
                  year=factor(rep(1998:1999, length=10)))

barchart(y ~ year, data=tmp, group=group, auto.key=TRUE, main="default legend",
         col = c('grey','black'))

barchart(y ~ year, data=tmp, group=group, auto.key=TRUE, main="what you want",
         par.settings=list(superpose.polygon=list(col=c('grey','black'))))

names(trellis.par.get())
trellis.par.get()$superpose.polygon



On Fri, Aug 24, 2018 at 3:37 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> On Wed, 22 Aug 2018, Rich Shepard wrote:
>
>>  More when I have results.
>
>
>   Almost there. I've read the auto.key section in ?barchart and looked at
> examples from stackoverflow on the web without seeing my syntax errors. I
> would like help on two issues:
>
>   1. What I want is to have the legend text in black and the colored
> rectangles match the black and grey of the bars. Instead, I get the legend
> text colored and have no idea where the default colors in the rectangles got
> there.
>
>   2. I've not found how to have the years (rather than the sequence of
> years) as the x-axis labels.
>
>   Here are the dput() output and the script:
>
> structure(list(year = c(1989L, 1989L, 1990L, 1990L, 1991L, 1991L, 1993L,
> 1993L, 1994L, 1994L, 1995L, 1995L, 1996L, 1996L, 1997L, 1997L, 1998L, 1998L,
> 1999L, 1999L, 2000L, 2000L, 2001L, 2001L, 2002L, 2002L, 2003L, 2003L, 2004L,
> 2004L, 2005L, 2005L, 2006L, 2006L, 2007L, 2007L, 2008L, 2008L, 2009L, 2009L,
> 2010L, 2010L, 2011L, 2011L, 2012L, 2012L, 2013L, 2013L, 2014L, 2014L, 2015L,
> 2015L, 2016L, 2016L, 2017L, 2017L, 2018L, 2018L), value = c(91.17, 93.32,
> 91.22, 93.43, 91.24, 92.89, 91.14, 93.02, 93.92, 95.74, 94.34, 96.85, 91.32,
> 95.86, 91.36, 94.25, 91.24, 93.67, 94.33, 97.42, 94.33, 97.42, 94, 94.99,
> 94.32, 96.58, 94.02, 96.57, 94.19, 96.32, 94.05, 95.96, 94.21, 97.4, 94.21,
> 97.28, 94.32, 96.72, 94.13, 97.43, 94.27, 95.95, 94.34, 97.82, 94.23, 97,
> 94.25, 96.6, 94.15, 96.24, 94.01, 96.68, 94.09, 96.96, 94.31, 96.39, 94.35,
> 96.95), type = structure(c(2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), .Label = c("Max", "Med"), class =
> "factor")), class = "data.frame", row.names = c(NA, -58L))
>
> med_max <- barchart(value ~ year, data=stage_heights,
>                     panel = lattice.getOption("panel.barchart"),
>                     default.prepanel =
> lattice.getOption("prepanel.default.barchart"),
>                     box.ratio = 2, horizontal=FALSE,
> auto.key=list(space='right',
>
> col=c('black', 'grey')),
>                     groups=factor(type,labels=c('Median','Maximum')),
> beside=TRUE,
>                     col = c('grey','black'),
> labels=list(c(1989,1990,1991,1992, 1993,1994,
>
> 1995,1996,1997,1998,1999,2000,2001,
>
> 2002,2003,2004,2005,2006,2007,2008,
>
> 2009,2010,2011,2012,2013,2014,2015,
>                                                            2016,2017,2018),
>
> scales=list(x=list(rot=90)),
>                                                          main = 'Median and
> Maximum Stage Heights',
>                                                          ylab = 'Elevation
> (masl)', xlab = 'Year')
> print(med_max)
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Fri Aug 24 22:16:02 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 24 Aug 2018 13:16:02 -0700
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTKeyhVd1TyZ9WLWg6o6dn-7cnjkW4VEz+EL8mYuRO=Cg@mail.gmail.com>

For the legend, you can use the full "key" argument for more control. The
docs in ?xyplot for "key" Should answer your questions.  "col" controls
text color within the "text" component and rectangle color within the
"rectangle" component , for example. I think this should work as an
alternative to specifying the par.settings components, but I haven't
checked.

For the scales, again, the docs provide the answer:  the "at" and "labels"
components of "x" component of the scales lists can explicitly control the
x -labels, e.g.

scales = list( x = list( at = ..., labels = ...)    etc.

If you are uncomfortable with the R lattice help docs, and you intend to
continue to use lattice plots (a good idea; ggplot is an alternative of
course), Deepayan has written a book that you might wish to get:

http://lmdvr.r-forge.r-project.org/figures/figures.html

There are also numerous web tutorials.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 24, 2018 at 12:38 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 22 Aug 2018, Rich Shepard wrote:
>
> >  More when I have results.
>
>    Almost there. I've read the auto.key section in ?barchart and looked at
> examples from stackoverflow on the web without seeing my syntax errors. I
> would like help on two issues:
>
>    1. What I want is to have the legend text in black and the colored
> rectangles match the black and grey of the bars. Instead, I get the legend
> text colored and have no idea where the default colors in the rectangles
> got
> there.
>
>    2. I've not found how to have the years (rather than the sequence of
> years) as the x-axis labels.
>
>    Here are the dput() output and the script:
>
> structure(list(year = c(1989L, 1989L, 1990L, 1990L, 1991L, 1991L,
> 1993L, 1993L, 1994L, 1994L, 1995L, 1995L, 1996L, 1996L, 1997L,
> 1997L, 1998L, 1998L, 1999L, 1999L, 2000L, 2000L, 2001L, 2001L,
> 2002L, 2002L, 2003L, 2003L, 2004L, 2004L, 2005L, 2005L, 2006L,
> 2006L, 2007L, 2007L, 2008L, 2008L, 2009L, 2009L, 2010L, 2010L,
> 2011L, 2011L, 2012L, 2012L, 2013L, 2013L, 2014L, 2014L, 2015L,
> 2015L, 2016L, 2016L, 2017L, 2017L, 2018L, 2018L), value = c(91.17,
> 93.32, 91.22, 93.43, 91.24, 92.89, 91.14, 93.02, 93.92, 95.74,
> 94.34, 96.85, 91.32, 95.86, 91.36, 94.25, 91.24, 93.67, 94.33,
> 97.42, 94.33, 97.42, 94, 94.99, 94.32, 96.58, 94.02, 96.57, 94.19,
> 96.32, 94.05, 95.96, 94.21, 97.4, 94.21, 97.28, 94.32, 96.72,
> 94.13, 97.43, 94.27, 95.95, 94.34, 97.82, 94.23, 97, 94.25, 96.6,
> 94.15, 96.24, 94.01, 96.68, 94.09, 96.96, 94.31, 96.39, 94.35,
> 96.95), type = structure(c(2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L), .Label = c("Max", "Med"), class = "factor")), class = "data.frame",
> row.names = c(NA,
> -58L))
>
> med_max <- barchart(value ~ year, data=stage_heights,
>                      panel = lattice.getOption("panel.barchart"),
>                      default.prepanel =
> lattice.getOption("prepanel.default.barchart"),
>                      box.ratio = 2, horizontal=FALSE,
> auto.key=list(space='right',
>
> col=c('black', 'grey')),
>                      groups=factor(type,labels=c('Median','Maximum')),
> beside=TRUE,
>                      col = c('grey','black'),
> labels=list(c(1989,1990,1991,1992, 1993,1994,
>
> 1995,1996,1997,1998,1999,2000,2001,
>
> 2002,2003,2004,2005,2006,2007,2008,
>
> 2009,2010,2011,2012,2013,2014,2015,
>
> 2016,2017,2018),
>
> scales=list(x=list(rot=90)),
>                                                           main = 'Median
> and Maximum Stage Heights',
>                                                           ylab =
> 'Elevation (masl)', xlab = 'Year')
> print(med_max)
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From fr@inj @ending from gm@il@com  Fri Aug 24 23:22:09 2018
From: fr@inj @ending from gm@il@com (John C Frain)
Date: Fri, 24 Aug 2018 22:22:09 +0100
Subject: [R] Unclear about the output from summary of ca.jo from package
 urca
In-Reply-To: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
References: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
Message-ID: <CAHrK516-9YYh_n_BKa0wo_XHzuZiV_+ANHKDM-=VfKSYXPX83Q@mail.gmail.com>

I have posted a reply to your original quesstion  on Cross Validated
explaining how the notation arises.
John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


On Thu, 23 Aug 2018 at 10:12, Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> I am not sure about the summary of the function ca.jo. I have posted my
> query here :-
>
>
> https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r
>
> I did not receive any reply so I am posting my query here.
>
> Many thanks and best regards,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Aug 24 23:28:49 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 24 Aug 2018 14:28:49 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbTKeyhVd1TyZ9WLWg6o6dn-7cnjkW4VEz+EL8mYuRO=Cg@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
 <CAGxFJbTKeyhVd1TyZ9WLWg6o6dn-7cnjkW4VEz+EL8mYuRO=Cg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808241422531.19296@salmo.appl-ecosys.com>

On Fri, 24 Aug 2018, Bert Gunter wrote:

> For the legend, you can use the full "key" argument for more control.

Bert,

   This I did.

> For the scales, again, the docs provide the answer:  the "at" and "labels"
> components of "x" component of the scales lists can explicitly control the
> x -labels, e.g.

   A bit of trial-and-error got this working, too. Now the plot command works
as desired:

barchart(value ~ year, data=stage_heights,
                     panel = lattice.getOption("panel.barchart"),
                     default.prepanel = lattice.getOption("prepanel.default.barchart"),
                     box.ratio = 2, horizontal=FALSE, key=list(c(0.2,0.3), columns=2,
                                                               text=list(c('Median','Maximum')),
                                                               rect=list(col=c('black', 'grey'))),
                     groups=factor(type,labels=c('Median','Maximum')), beside=TRUE,
                     col = c('grey','black'), scales=list(x=list(at=rep(1:29),
                                                                 labels=rep(1989:2018),rot=90)),
                     main = 'Median and Maximum Stage Heights',
                     ylab = 'Elevation (masl)', xlab = 'Year')

(Emacs w/ESS does the formatting). I suppose that the Maximum bar is plotted
to the left because alphabetically it preceeds Medium. I can live with this.

   Deepayan's book was one of the first I bought years ago. I've not before
had plots that required more in-depth knowledge of panels, keys, and scales
so I do appreciate your patient mentoring.

Best regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Aug 24 23:31:06 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 24 Aug 2018 14:31:06 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGx1TMDfE5+5pkVx-kz1Q-N742z2bykH=OdKxKcZ91qSM733Hg@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
 <CAGx1TMDfE5+5pkVx-kz1Q-N742z2bykH=OdKxKcZ91qSM733Hg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808241428550.19296@salmo.appl-ecosys.com>

On Fri, 24 Aug 2018, Richard M. Heiberger wrote:

> color for the legend comes from trellis.par.get
> You can control that for an individual plot with the par.settings argument.
> tmp <- data.frame(y=sample(10),
>                  group=rep(c("Median", "Maximum"), each=5),
>                  year=factor(rep(1998:1999, length=10)))
>
> barchart(y ~ year, data=tmp, group=group, auto.key=TRUE, main="default legend",
>         col = c('grey','black'))
>
> barchart(y ~ year, data=tmp, group=group, auto.key=TRUE, main="what you want",
>         par.settings=list(superpose.polygon=list(col=c('grey','black'))))
>
> names(trellis.par.get())
> trellis.par.get()$superpose.polygon

   Thanks, Richard!

   Before venturing into par.settings I worked off of Bert's advice and
careful reading of the ?xyplot details allowed me to fix the two remaining
issues. Your suggestions will definitely be of value when I have other
complex lattice plots to properly display.

Best regards,

Rich


From r@turner @ending from @uckl@nd@@c@nz  Sat Aug 25 01:20:09 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 25 Aug 2018 11:20:09 +1200
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
Message-ID: <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>


See in-line below.

On 08/25/2018 01:10 AM, Ista Zahn wrote:

> On Thu, Aug 23, 2018 at 6:57 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> I *think* that this is an R question (and *not* an RStudio question!)
> 
> I think this is actually and Ubuntu question, and probably belongs on
> R-sig-debian.

Well, it's about installing R --- *could* be independent of OS.

>>
>> I have, somewhat against my better judgement, decided to experiment with
>> using RStudio.
>>
>> I downloaded and install RStudio.  Easy-peasy.  Nice lucid instructions.
>>
>> Then I tried to start RStudio ("rstudio" from the command line)
>> and got a pop-up window with the error message:
>>
>>> R shared library (/usr/lib64/R/lib/libR.so) not found. If this
>>> is a custom build of R, was it built with the --enable-R-shlib option?
>>
>> Oops, no, I guess it wasn't.  So I carefully did a
>>
>>       sudo make uninstall
>>       make clean
>>       make distclean
>>
>> and then did
>>
>>       ./R-3.5.1/configure <various flags>
>>
>> making sure I added the --enable-R-shlib flag.
>>
>> Then I did make and sudo make install.
> 
> IMO if you are compiling and installing software yourself on Linux
> your are Doing It Wrong. Use the package manager, that is what it is
> there for.

I was pretty sure that the foregoing was a complete red herring.  And I 
was right.

I have been told by younger and wiser heads that installing from source 
is The Right Thing to Do.  Moreover I'd always had the impression that 
the version of R provided by the package manager persistently lags one 
or two releases behind the current version.  However, given that the 
suggestion had been made, I decided I'd try it.

The process for installing R using the package manager is far from 
straightforward and few people give clear instructions on this issue.
(Instructions are usually incomplete and full of jargon and acronyms 
that the instructors blithely assume assume that the instructees 
understand.  (They *don't*! In this instance (mirabile dictu!) I managed 
(using Uncle Google) to find very clear and explicit instructions at:

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart

I followed these instructions, and everything went swimmingly.  I indeed 
got the current version of R (3.5.1, "Feather Spray").  So my previous 
impression was incorrect (given that one carefully follows the rather 
complex installation procedures, at least).

Interestingly (???) the "new" R was installed in /usr/bin and not in 
/usr/local/bin.

I then tried issuing the command:

     rstudio

Exactly the same pop-up error.  No help at all, as I expected.

I then tried

     sudo apt install r-base-dev

thinking that this might be needed to get the libR.so created (in the 
right place).  No joy.

I then tried the symlink strategy that I had previously suggested.  No 
joy there either.

Then finally, in desperation, I copied libR.so from /usr/lib/R/lib to
/usr/lib64/R/lib.  Bingo!!!  I can now start Rstudio!!!

It remains mysterious to me why the symlink procedure did not work, 
whereas making a copy of libR.so *did* work.

However I guess this really doesn't matter.  It's now working.

cheers,

Rolf

> --Ista
> 
> It all seemed to go ...
>> but then I did
>>
>>       rstudio
>>
>> again and got the same popup error.
>>
>> There is indeed *no* libR.so in /usr/lib64/R/lib.
>>
>> There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals that
>> it dates from the my previous install of R-3.5.1 for which I *did not*
>> configure with --enable-R-shlib.
>>
>> Can anyone explain to me WTF is going on?
>>
>> What should I do?  Just make a symbolic link from /usr/lib/R/lib/libR.so
>> to /usr/lib64/R/lib/libR.so?
>>
>> It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
>> most recent install of R.
>>
>> I plead for enlightenment.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> P.S. I'm running Ubuntu 18.04.  And the previous install of R was done
>> under Ubuntu 18.04.
>>
>> R. T.
-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From t@n@@@ @ending from gm@il@com  Sat Aug 25 03:28:59 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Fri, 24 Aug 2018 18:28:59 -0700
Subject: [R] installing R 3.5.1
Message-ID: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>

Dear all,

I am trying to install R 3.5.1 on my Ubuntu 14.04 system; however, I am
getting the following message :

sudo apt-get install r-base
[...]
The following packages have unmet dependencies:
 r-base : Depends: r-recommended (= 3.5.1-1trusty) but it is not going to
be installed
E: Unable to correct problems, you have held broken packages.

In the file /etc/apt/sources.list , I have set up :

deb https://cloud.r-project.org/bin/linux/ubuntu trusty/
deb https://cloud.r-project.org/bin/linux/ubuntu trusty-cran35/

Would you please advise, what shall I do next ? Thanks a lot !

-- bogdan

	[[alternative HTML version deleted]]


From ggrothendieck @ending from gm@il@com  Sat Aug 25 04:06:22 2018
From: ggrothendieck @ending from gm@il@com (Gabor Grothendieck)
Date: Fri, 24 Aug 2018 22:06:22 -0400
Subject: [R] looking for formula parser that allows coefficients
In-Reply-To: <CAErODj-DW3AQCH8SHHHaNHAoGMNmnMvi=M0QK2Jm1Dk63ksm4Q@mail.gmail.com>
References: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
 <CAP01uRm41Zy-UamFBYshbdRjA9XwnwafQHszYEbH0FjDjE4xCw@mail.gmail.com>
 <CAErODj-DW3AQCH8SHHHaNHAoGMNmnMvi=M0QK2Jm1Dk63ksm4Q@mail.gmail.com>
Message-ID: <CAP01uRn4OoR0uk0m4oqQc2iOF7BN4PRb7UbrkE+Y5cxZq35Hqw@mail.gmail.com>

Also here is a solution that uses formula processing rather than
string processing.
No packages are used.

Parse <- function(e) {
  if (length(e) == 1) {
    if (is.numeric(e)) return(e)
    else setNames(1, as.character(e))
  } else {
    if (isChar(e[[1]], "*")) {
       x1 <- Recall(e[[2]])
       x2 <- Recall(e[[3]])
       setNames(unname(x1 * x2), paste0(names(x1), names(x2)))
    } else if (isChar(e[[1]], "+")) c(Recall(e[[2]]), Recall(e[[3]]))
    else if (isChar(e[[1]], "-")) {
      if (length(e) == 2) -1 * Recall(e[[2]])
      else c(Recall(e[[2]]), -Recall(e[[3]]))
    } else if (isChar(e[[1]], ":")) setNames(1, paste(e[-1], collapse = ":"))
  }
}

# test
fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2
Parse(fo[[3]])

giving:

         x1    x3 x1:x3 x2:x2
  2.0  -1.1   1.0  -1.0   0.2
On Wed, Aug 22, 2018 at 11:50 AM Paul Johnson <pauljohn32 at gmail.com> wrote:
>
> Thanks as usual.  I owe you more KU decorations soon.
> On Wed, Aug 22, 2018 at 2:34 AM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > Some string manipulation can convert the formula to a named vector such as
> > the one shown at the end of your post.
> >
> > library(gsubfn)
> >
> > # input
> > fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2
> >
> > pat <- "([+-])? *(\\d\\S*)? *\\*? *([[:alpha:]]\\S*)?"
> > ch <- format(fo[[3]])
> > m <- matrix(strapplyc(ch, pat)[[1]], 3)
> > m <- m[, colSums(m != "") > 0]
> > m[2, m[2, ] == ""] <- 1
> > m[3, m[3, ] == ""] <- "(Intercept)"
> > co <- as.numeric(paste0(m[1, ], m[2, ]))
> > v <- m[3, ]
> > setNames(co, v)
> > ## (Intercept)          x1          x3       x1:x3       x2:x2
> > ##         2.0        -1.1         1.0        -1.0         0.2
> > On Tue, Aug 21, 2018 at 6:46 PM Paul Johnson <pauljohn32 at gmail.com> wrote:
> > >
> > > Can you point me at any packages that allow users to write a
> > > formula with coefficients?
> > >
> > > I want to write a data simulator that has a matrix X with lots
> > > of columns, and then users can generate predictive models
> > > by entering a formula that uses some of the variables, allowing
> > > interactions, like
> > >
> > > y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2
> > >
> > > Currently, in the rockchalk package, I have a function simulates
> > > data (genCorrelatedData2), but my interface to enter the beta
> > > coefficients is poor.  I assumed user would always enter 0's as
> > > place holder for the unused coefficients, and the intercept is
> > > always first. The unnamed vector is too confusing.  I have them specify:
> > >
> > > c(2, 1.1, 0, 3, 0, 0, 0.2, ...)
> > >
> > > I the documentation I say (ridiculously) it is easy to figure out from
> > > the examples, but it really isnt.
> > > It function prints out the equation it thinks you intended, thats
> > > minimum protection against user error, but still not very good:
> > >
> > > dat <- genCorrelatedData2(N = 10, rho = 0.0,
> > >           beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
> > >           means = c(0,0,0), sds = c(1,1,1), stde = 0)
> > > [1] "The equation that was calculated was"
> > > y = 1 + 2*x1 + 1*x2 + 1*x3
> > >  + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
> > >  + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
> > >  + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
> > >  + N(0,0) random error
> > >
> > > But still, it is not very good.
> > >
> > > As I look at this now, I realize expect just the vech, not the whole vector
> > > of all interaction terms, so it is even more difficult than I thought to get the
> > > correct input.Hence, I'd like to let the user write a formula.
> > >
> > > The alternative for the user interface is to have named coefficients.
> > > I can more or less easily allow a named vector for beta
> > >
> > > beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)
> > >
> > > I could build a formula from that.  That's not too bad. But I still think
> > > it would be cool to allow formula input.
> > >
> > > Have you ever seen it done?
> > > pj
> > > --
> > > Paul E. Johnson   http://pj.freefaculty.org
> > > Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> > >
> > > To write to me directly, please address me at pauljohn at ku.edu.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
>
>
>
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothendieck @ending from gm@il@com  Sat Aug 25 04:24:55 2018
From: ggrothendieck @ending from gm@il@com (Gabor Grothendieck)
Date: Fri, 24 Aug 2018 22:24:55 -0400
Subject: [R] looking for formula parser that allows coefficients
In-Reply-To: <CAP01uRn4OoR0uk0m4oqQc2iOF7BN4PRb7UbrkE+Y5cxZq35Hqw@mail.gmail.com>
References: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
 <CAP01uRm41Zy-UamFBYshbdRjA9XwnwafQHszYEbH0FjDjE4xCw@mail.gmail.com>
 <CAErODj-DW3AQCH8SHHHaNHAoGMNmnMvi=M0QK2Jm1Dk63ksm4Q@mail.gmail.com>
 <CAP01uRn4OoR0uk0m4oqQc2iOF7BN4PRb7UbrkE+Y5cxZq35Hqw@mail.gmail.com>
Message-ID: <CAP01uRn10CMKtEqgmmw_ogsEZk7OWM3bsPsBK5dvoyFusyJvOA@mail.gmail.com>

The isChar function used in Parse is:

  isChar <- function(e, ch) identical(e, as.symbol(ch))
On Fri, Aug 24, 2018 at 10:06 PM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> Also here is a solution that uses formula processing rather than
> string processing.
> No packages are used.
>
> Parse <- function(e) {
>   if (length(e) == 1) {
>     if (is.numeric(e)) return(e)
>     else setNames(1, as.character(e))
>   } else {
>     if (isChar(e[[1]], "*")) {
>        x1 <- Recall(e[[2]])
>        x2 <- Recall(e[[3]])
>        setNames(unname(x1 * x2), paste0(names(x1), names(x2)))
>     } else if (isChar(e[[1]], "+")) c(Recall(e[[2]]), Recall(e[[3]]))
>     else if (isChar(e[[1]], "-")) {
>       if (length(e) == 2) -1 * Recall(e[[2]])
>       else c(Recall(e[[2]]), -Recall(e[[3]]))
>     } else if (isChar(e[[1]], ":")) setNames(1, paste(e[-1], collapse = ":"))
>   }
> }
>
> # test
> fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2
> Parse(fo[[3]])
>
> giving:
>
>          x1    x3 x1:x3 x2:x2
>   2.0  -1.1   1.0  -1.0   0.2
> On Wed, Aug 22, 2018 at 11:50 AM Paul Johnson <pauljohn32 at gmail.com> wrote:
> >
> > Thanks as usual.  I owe you more KU decorations soon.
> > On Wed, Aug 22, 2018 at 2:34 AM Gabor Grothendieck
> > <ggrothendieck at gmail.com> wrote:
> > >
> > > Some string manipulation can convert the formula to a named vector such as
> > > the one shown at the end of your post.
> > >
> > > library(gsubfn)
> > >
> > > # input
> > > fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2
> > >
> > > pat <- "([+-])? *(\\d\\S*)? *\\*? *([[:alpha:]]\\S*)?"
> > > ch <- format(fo[[3]])
> > > m <- matrix(strapplyc(ch, pat)[[1]], 3)
> > > m <- m[, colSums(m != "") > 0]
> > > m[2, m[2, ] == ""] <- 1
> > > m[3, m[3, ] == ""] <- "(Intercept)"
> > > co <- as.numeric(paste0(m[1, ], m[2, ]))
> > > v <- m[3, ]
> > > setNames(co, v)
> > > ## (Intercept)          x1          x3       x1:x3       x2:x2
> > > ##         2.0        -1.1         1.0        -1.0         0.2
> > > On Tue, Aug 21, 2018 at 6:46 PM Paul Johnson <pauljohn32 at gmail.com> wrote:
> > > >
> > > > Can you point me at any packages that allow users to write a
> > > > formula with coefficients?
> > > >
> > > > I want to write a data simulator that has a matrix X with lots
> > > > of columns, and then users can generate predictive models
> > > > by entering a formula that uses some of the variables, allowing
> > > > interactions, like
> > > >
> > > > y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2
> > > >
> > > > Currently, in the rockchalk package, I have a function simulates
> > > > data (genCorrelatedData2), but my interface to enter the beta
> > > > coefficients is poor.  I assumed user would always enter 0's as
> > > > place holder for the unused coefficients, and the intercept is
> > > > always first. The unnamed vector is too confusing.  I have them specify:
> > > >
> > > > c(2, 1.1, 0, 3, 0, 0, 0.2, ...)
> > > >
> > > > I the documentation I say (ridiculously) it is easy to figure out from
> > > > the examples, but it really isnt.
> > > > It function prints out the equation it thinks you intended, thats
> > > > minimum protection against user error, but still not very good:
> > > >
> > > > dat <- genCorrelatedData2(N = 10, rho = 0.0,
> > > >           beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
> > > >           means = c(0,0,0), sds = c(1,1,1), stde = 0)
> > > > [1] "The equation that was calculated was"
> > > > y = 1 + 2*x1 + 1*x2 + 1*x3
> > > >  + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
> > > >  + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
> > > >  + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
> > > >  + N(0,0) random error
> > > >
> > > > But still, it is not very good.
> > > >
> > > > As I look at this now, I realize expect just the vech, not the whole vector
> > > > of all interaction terms, so it is even more difficult than I thought to get the
> > > > correct input.Hence, I'd like to let the user write a formula.
> > > >
> > > > The alternative for the user interface is to have named coefficients.
> > > > I can more or less easily allow a named vector for beta
> > > >
> > > > beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)
> > > >
> > > > I could build a formula from that.  That's not too bad. But I still think
> > > > it would be cool to allow formula input.
> > > >
> > > > Have you ever seen it done?
> > > > pj
> > > > --
> > > > Paul E. Johnson   http://pj.freefaculty.org
> > > > Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> > > >
> > > > To write to me directly, please address me at pauljohn at ku.edu.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Statistics & Software Consulting
> > > GKX Group, GKX Associates Inc.
> > > tel: 1-877-GKX-GROUP
> > > email: ggrothendieck at gmail.com
> >
> >
> >
> > --
> > Paul E. Johnson   http://pj.freefaculty.org
> > Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> >
> > To write to me directly, please address me at pauljohn at ku.edu.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From p_connolly @ending from @ling@hot@co@nz  Fri Aug 24 12:13:17 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Fri, 24 Aug 2018 22:13:17 +1200
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
Message-ID: <20180824101317.GC13179@slingshot.co.nz>

On Thu, 23-Aug-2018 at 07:23AM -0700, Jeff Newmiller wrote:

|> This is not reproducible because you have not provided the plot
|> code or sample data. Output of sessionInfo would probably be
|> appropriate as well.

I took it as read that the plotting functions themselves aren't an
issue since they operate as intended outside of the Rmarkdown
space. Any function that uses the function plot() successfully will
do.  I was trying to ascertain how I should be setting up the scaling.

|> As to whether needing to load objects is typical... yes, rmarkdown
|> runs from a fresh environment to emphasize reproducibility, but
|> your load command is bypassing that for us.

The objects loaded from .RData took hours of simulating and it's out
of the question to run them again inside Rmarkdown.  Though the script
used in the creation of .RData is reproducable, perhaps it would be
clearer for me to have saved the objects to a file by a different
name.

Is there a better way to do that??



|> On August 23, 2018 2:15:19 AM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
|> >I'm having difficulty getting plots into ioslides.  It seems to me
|> >that the scale is completely out, but I can't figure out what to do
|> >about it.  Whatever I try, I get the title slide, then a second with a
|> >horizontal line and a vertical line in the bottom right corner.  It
|> >looks like a badly scaled plot about 25 times the size of the plotting
|> >area, so only a fragment is visible.
|> >
|> >This is the code I've tried:
|> >
|> >---
|> >title: "Barking up the wrong tree"
|> >author: "Patrick Connolly"
|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
|> >output: ioslides_presentation
|> >---
|> >
|> >```{r global_options, echo=FALSE}
|> >knitr::opts_chunk$set(tidy=TRUE,
|> >                      warning=FALSE, 
|> >                      message=FALSE,
|> >                      cache=FALSE,
|> >                      dpi=600)
|> >```
|> >
|> >```{r use these functions, echo= FALSE}
|> >  load(".RData") ## code for 6 plotting functions
|> >
|> >``
|> >## 6 different Trees
|> >
|> >```{r 6 different Trees, echo = FALSE, messages=FALSE, fig.width = 7,
|> >fig.height = 5}
|> >
|> >###  par(mfrow = c(2, 3))
|> >plot1()
|> >plot2()
|> >plot3()
|> >plot4()
|> >plot5()
|> >plot6()
|> >}
|> >```
|> >
|> >If I run the plot functions in the Console, it all works and displays
|> >correctly in Rstudiio's plot panel, even the mfrow bit.  But I haven't
|> >worked out how to include the code into Rmarkdown.  I thought it might
|> >be less taxing to not try putting the 6 plots on the same slide, but
|> >it makes no difference when I commented out the mfrow bit.
|> >
|> >I'm not very familiar with the workings of Markdown or Rstudio, but it
|> >does seem strange to me that I need to specifically load the global
|> >environment otherwise it's not visible.  Is that to be expected?
|> >
|> >Ideas welcome, particularly about scaling.
|> 
|> -- 
|> Sent from my phone. Please excuse my brevity.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From berwin@turl@ch @ending from gm@il@com  Sat Aug 25 09:51:25 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Sat, 25 Aug 2018 15:51:25 +0800
Subject: [R] installing R 3.5.1
In-Reply-To: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
Message-ID: <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Bogdan,

On Fri, 24 Aug 2018 18:28:59 -0700
Bogdan Tanasa <tanasa at gmail.com> wrote:

> I am trying to install R 3.5.1 on my Ubuntu 14.04 system; however, I
> am getting the following message :
> 
> sudo apt-get install r-base
> [...]
> The following packages have unmet dependencies:
>  r-base : Depends: r-recommended (= 3.5.1-1trusty) but it is not
> going to be installed
> E: Unable to correct problems, you have held broken packages.

For me such problems are usually fixed by specifying the package that
"is not going to be installed" but on which the package I want to
install depends also to apt-get install.

What does
	sudo apt-get install r-base r-recommended
do on your system?

Cheers,

	Berwin


From benoit@v@ill@nt @ending from no-log@org  Sat Aug 25 11:13:49 2018
From: benoit@v@ill@nt @ending from no-log@org (Benoit Vaillant)
Date: Sat, 25 Aug 2018 11:13:49 +0200
Subject: [R] installing R 3.5.1
In-Reply-To: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
Message-ID: <20180825091348.7tidm7fvhiudr35d@auroras.fr>

Hello Bogdan,

This reply is off topic for the list, appologies. This problem is more
r-sig-debian related (see below).

Though Berwin already mentionned a possible solution, here is another.

On Fri, Aug 24, 2018 at 06:28:59PM -0700, Bogdan Tanasa wrote:
> I am trying to install R 3.5.1 on my Ubuntu 14.04 system;

You are trying to install R (latest version) on a system that is
outdated by the latest LTS (16.04) and more than four years old
now. ;-)

If you go to: https://cloud.r-project.org/bin/linux/ubuntu/

You'll get some hints, like:
"R 3.5 packages for Ubuntu on i386 and amd64 are available for most
stable Desktop releases of Ubuntu until their official end of life
date. However, only the latest Long Term Support (LTS) release is
fully supported."

Note the *only the latest LTS* ;-)

You'll also get the r-sig-debian list link to report issues.

> Would you please advise, what shall I do next ? Thanks a lot !

If you have the time, upgrade your LTS by migrating your system from
14.04 to 16.04 and then 18.04 (Bionic Beaver).

Best regards,

-- 
Beno?t

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180825/5b4a7474/attachment.sig>

From p_connolly @ending from @ling@hot@co@nz  Sat Aug 25 12:21:46 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Sat, 25 Aug 2018 22:21:46 +1200
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
Message-ID: <20180825102146.GD13179@slingshot.co.nz>

I've simplified it so that it's reproducible:


---
title: "Barking up the wrong tree"
author: "Patrick Connolly"
date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
output:
  ioslides_presentation: default
  slidy_presentation: default
  beamer_presentation: default
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(tidy=TRUE,
                      warning=FALSE, 
                      message=FALSE,
                      cache=FALSE,
                      dpi = 300)
         
```
## 6 different Regression Trees

```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}

 par(mfrow = c(2, 3))
plot(1:10)
plot(12:4)
plot(seq(0, 800))
plot(-100:-900)
plot(12:50)
plot(90:54)
```

I've tried it on a different machine which gives a slightly more
informative message:

X11 font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12 could not be loaded

That seems to be associated with the Cairo plotting device which isn't
necessary with pdf devices which I normally use, nor, it would seem by
the plot pane in Rstudio.  Consequently, running the plot code itself
works fine, but if is to be incorporated in HTML, we run into the Cairo
issue, Looking into that one, it appears something has been orphaned
for a couple of years.  If anyone has information about that, I'd be
interested.

TIA


-------------

 version 3.5.0 (2018-04-23)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C               LC_TIME=en_NZ.UTF-8       
 [4] LC_COLLATE=en_NZ.UTF-8     LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] utils     stats     grDevices graphics  methods   base     

other attached packages:
[1] sp_1.3-1        lattice_0.20-35

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.17     knitr_1.20       bindr_0.1.1      magrittr_1.5     tidyselect_0.2.4 munsell_0.5.0   
 [7] colorspace_1.3-2 xtable_1.8-2     R6_2.2.2         rlang_0.2.1      stringr_1.3.1    plyr_1.8.4      
[13] dplyr_0.7.6      tools_3.5.0      grid_3.5.0       htmltools_0.3.6  crosstalk_1.0.0  rprojroot_1.3-2 
[19] yaml_2.1.19      leaflet_2.0.1    assertthat_0.2.0 digest_0.6.15    tibble_1.4.2     bindrcpp_0.2.2  
[25] shiny_1.1.0      purrr_0.2.5      later_0.7.3      htmlwidgets_1.2  promises_1.0.1   evaluate_0.10.1 
[31] glue_1.2.0       mime_0.5         rmarkdown_1.10   stringi_1.2.3    compiler_3.5.0   pillar_1.2.3    
[37] backports_1.1.2  scales_0.5.0     httpuv_1.4.4.2   pkgconfig_2.0.1 
> 



On Thu, 23-Aug-2018 at 07:23AM -0700, Jeff Newmiller wrote:

|> This is not reproducible because you have not provided the plot code or sample data. Output of sessionInfo would probably be appropriate as well.
|> 
|> As to whether needing to load objects is typical... yes, rmarkdown runs from a fresh environment to emphasize reproducibility, but your load command is bypassing that for us.
|> 
|> On August 23, 2018 2:15:19 AM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
|> >I'm having difficulty getting plots into ioslides.  

[...]


-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From murdoch@dunc@n @ending from gm@il@com  Sat Aug 25 13:53:31 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sat, 25 Aug 2018 07:53:31 -0400
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180825102146.GD13179@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
Message-ID: <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>

On 25/08/2018 6:21 AM, Patrick Connolly wrote:
> ---
> title: "Barking up the wrong tree"
> author: "Patrick Connolly"
> date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
> output:
>    ioslides_presentation: default
>    slidy_presentation: default
>    beamer_presentation: default
> ---
> 
> ```{r global_options, echo=FALSE}
> knitr::opts_chunk$set(tidy=TRUE,
>                        warning=FALSE,
>                        message=FALSE,
>                        cache=FALSE,
>                        dpi = 300)

Drop the dpi setting and it will work fine.

Duncan Murdoch

>           
> ```
> ## 6 different Regression Trees
> 
> ```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
> 
>   par(mfrow = c(2, 3))
> plot(1:10)
> plot(12:4)
> plot(seq(0, 800))
> plot(-100:-900)
> plot(12:50)
> plot(90:54)
> ```


From edd @ending from debi@n@org  Sat Aug 25 14:45:33 2018
From: edd @ending from debi@n@org (Dirk Eddelbuettel)
Date: Sat, 25 Aug 2018 07:45:33 -0500
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
 <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
Message-ID: <23425.20333.436940.985925@rob.eddelbuettel.com>


Rolf,

I noticed this thread started by you as well as a few of the excellent
follow-ups. While it conclcuded, allow me a few quick comments:

 - Some of us go through some effort to provide R on Ubuntu (and Debian) in a
   reliable and reproducible manner. And it works and is used by many people.

 - The basic r-base (and r-base-core etc) packages work in the distribution,
   but may be older as the distribution is taken as snapshots in time.  Hence
   the Ubuntu mirror via CRAN. That way you get a choice between eg R 3.4.4
   (not that old) and R 3.5.1. (brand new) in the current Ubuntu 18.04.

 - The (short) instructions at CRAN work: add a repo, install from it.
   Neither they nor the longer (more recent) blog post you found (which says
   the same, with more pictures) suggest to link or move libraries around.

 - We even have "proof" in the sense of fully automated build and use
   systems. Docker is just one example.  Eg this Dockerfile build the r-base
   container available as rocker/r-base (as well as the official r-base)
      https://github.com/rocker-org/rocker/blob/master/r-base/Dockerfile
   and eg this one use it and builds on top to generated an RStudio container
      https://github.com/rocker-org/rocker/blob/master/rstudio/testing/Dockerfile 
   Nowhere in either of these "recipes" are library files moved, renamed, or
   otherwise altered.

 - Nobody ever suggested for _any_ Linux distribution to mix its files below
   /usr with your own compilation.  There lies madness, and it may be the
   root cause of the behaviour local to your machine.  Don't do it.

 - Please consider asking Debian and Ubuntu related questions on r-sig-debian.  

Regards, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From @hivipmp82 @ending from gm@il@com  Sat Aug 25 16:00:47 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Sat, 25 Aug 2018 19:30:47 +0530
Subject: [R] NaN in Scoring Sentiment
Message-ID: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>

Hi All- I am running a sentiment scoring model and the code is as below:
sentiments_per_Category <- aggregate(relative_sentiment_frequencies,
                                     by = list(Category =
df$Case.Category), mean)

while i run the head command most of the values are NaN. i then used
complete.cases on my data frame
df[complete.cases(df),]
 but it does not seems to work. Please advice if there is a way to handle
NaN.

Regards, Shivi

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Aug 25 16:21:47 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 25 Aug 2018 07:21:47 -0700
Subject: [R] NaN in Scoring Sentiment
In-Reply-To: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
References: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
Message-ID: <0B0C9A04-27A4-4F4C-A178-BA45110C3506@dcn.davis.ca.us>

Did you keep the resulting complete cases version of df?

dfc <- df[complete.cases(df),]

and then use that as input?

On August 25, 2018 7:00:47 AM PDT, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>Hi All- I am running a sentiment scoring model and the code is as
>below:
>sentiments_per_Category <- aggregate(relative_sentiment_frequencies,
>                                     by = list(Category =
>df$Case.Category), mean)
>
>while i run the head command most of the values are NaN. i then used
>complete.cases on my data frame
>df[complete.cases(df),]
>but it does not seems to work. Please advice if there is a way to
>handle
>NaN.
>
>Regards, Shivi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From t@n@@@ @ending from gm@il@com  Sat Aug 25 16:24:40 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sat, 25 Aug 2018 07:24:40 -0700
Subject: [R] installing R 3.5.1
In-Reply-To: <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
 <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>
Message-ID: <CA+JEM02_tV3qFoNK9AdggePEit7KBnDj1eYiL6AEbRX=bp9ULg@mail.gmail.com>

Dear Berwin, thank you for your help.

On my system, after "sudo apt-get install r-base r-recommended", it says :
[..]
The following packages have unmet dependencies:
 r-recommended : Depends: r-cran-kernsmooth (>= 2.2.14) but it is not going
to be installed
                 Depends: r-cran-mass but it is not going to be installed
                 Depends: r-cran-class but it is not going to be installed
                 Depends: r-cran-nnet but it is not going to be installed
E: Unable to correct problems, you have held broken packages.

Although these packages seem to be well installed ..

On Sat, Aug 25, 2018 at 12:51 AM Berwin A Turlach <berwin.turlach at gmail.com>
wrote:

> G'day Bogdan,
>
> On Fri, 24 Aug 2018 18:28:59 -0700
> Bogdan Tanasa <tanasa at gmail.com> wrote:
>
> > I am trying to install R 3.5.1 on my Ubuntu 14.04 system; however, I
> > am getting the following message :
> >
> > sudo apt-get install r-base
> > [...]
> > The following packages have unmet dependencies:
> >  r-base : Depends: r-recommended (= 3.5.1-1trusty) but it is not
> > going to be installed
> > E: Unable to correct problems, you have held broken packages.
>
> For me such problems are usually fixed by specifying the package that
> "is not going to be installed" but on which the package I want to
> install depends also to apt-get install.
>
> What does
>         sudo apt-get install r-base r-recommended
> do on your system?
>
> Cheers,
>
>         Berwin
>

	[[alternative HTML version deleted]]


From t@n@@@ @ending from gm@il@com  Sat Aug 25 16:27:20 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sat, 25 Aug 2018 07:27:20 -0700
Subject: [R] installing R 3.5.1
Message-ID: <CA+JEM03v-nMsKdzg-R7iEX8maOcL7pyRf8xYgdUh4JQ-eu5yOQ@mail.gmail.com>

Dear Benoit, many thanks for your suggestions. Have a good weekend !

Message: 26
Date: Sat, 25 Aug 2018 11:13:49 +0200
From: Benoit Vaillant <benoit.vaillant at no-log.org>
To: Bogdan Tanasa <tanasa at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] installing R 3.5.1
Message-ID: <20180825091348.7tidm7fvhiudr35d at auroras.fr>
Content-Type: text/plain; charset="iso-8859-15"

Hello Bogdan,

This reply is off topic for the list, appologies. This problem is more
r-sig-debian related (see below).

Though Berwin already mentionned a possible solution, here is another.

On Fri, Aug 24, 2018 at 06:28:59PM -0700, Bogdan Tanasa wrote:
> I am trying to install R 3.5.1 on my Ubuntu 14.04 system;

You are trying to install R (latest version) on a system that is
outdated by the latest LTS (16.04) and more than four years old
now. ;-)

If you go to: https://cloud.r-project.org/bin/linux/ubuntu/

You'll get some hints, like:
"R 3.5 packages for Ubuntu on i386 and amd64 are available for most
stable Desktop releases of Ubuntu until their official end of life
date. However, only the latest Long Term Support (LTS) release is
fully supported."

Note the *only the latest LTS* ;-)

You'll also get the r-sig-debian list link to report issues.

> Would you please advise, what shall I do next ? Thanks a lot !

If you have the time, upgrade your LTS by migrating your system from
14.04 to 16.04 and then 18.04 (Bionic Beaver).

Best regards,

-- 
Beno?t

	[[alternative HTML version deleted]]


From berwin@turl@ch @ending from gm@il@com  Sat Aug 25 16:59:18 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Sat, 25 Aug 2018 22:59:18 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
 <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
Message-ID: <20180825225918.1f91a9cc@absentia>

G'day Rolf,

On Sat, 25 Aug 2018 11:20:09 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> I was pretty sure that the foregoing was a complete red herring.  And
> I was right.

I am not sure whether I agree. :)
 
> I have been told by younger and wiser heads that installing from
> source is The Right Thing to Do. 

Younger heads probably have more time on their hands to play around
with installing from source and debugging when things go wrong.  Wiser
heads probably have figured out how they should do so in the first
place. :)

Seriously, years ago I installed quite a bit of software from source,
also to always have the newest version.  And while I was using Debian
unstable I accepted that from time to time an update would leave me
with a broken system and I would have to spend some time to fix it
again.  Nowadays, I rather spend my time on other things and so am
happy to go with most software with whatever version the package
installer of Ubuntu installs.

The one exception is R, but that is for various good reasons:
  * I want to have the 32 bit and 64 bit architecture installed so
    that I can test my packages on both packages.  
  * I would like to keep old versions around, to test my packages on
    them
  * I like to use the R version that is installed in our computer
    lab when preparing teaching material, and the newest version
    otherwise.

If I ever get the feeling that all these points are easily achievable
with the compiled packages (without having to play around with docker,
sandboxes etc), I would stop compiling R from source.

> Moreover I'd always had the impression that the version of R provided
> by the package manager persistently lags one or two releases behind
> the current version.

From the official repositories, yes.  But CRAN provides since longer
than I can remember up-to-date binary packages for the most common
Linux distributions.  AFAIK, Debian and Ubuntu packages are available
thanks to Dirk Eddelbuettel (initially? mainly?) and others.

> The process for installing R using the package manager is far from 
> straightforward and few people give clear instructions on this issue.

1.) Start a web browser
2.) Go to your favourite CRAN server
3.) Select 'Download R for Linux'
4.) Select the directory "ubuntu/" from the page that is served
5.) Select README.html from the page that is served
6.) Follow the instructions

> (Instructions are usually incomplete and full of jargon and acronyms 
> that the instructors blithely assume assume that the instructees 
> understand.  

I am sure (some) of my students have the same complains about my
lecturing....   

> (They *don't*! In this instance (mirabile dictu!) I managed (using
> Uncle Google) 

You were lucky in this case, usually Uncle Google serves me with
somewhat out-dated (if not wrong) information when I run into a
technical problem with linux.....

> to find very clear and explicit instructions at:
> 
> https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart
> 
> I followed these instructions, and everything went swimmingly. 

You were lucky that you are not sitting behind a firewall (as I seem to
be, not sure whom I have to thank for that).  For me the first step
(installing the GPG key) fails and some further googling was
necessary.  Though, I was working from the CRAN instructions.

> Interestingly (???) the "new" R was installed in /usr/bin and not in 
> /usr/local/bin.

Of course, it is a system Ubuntu package, so it installs to /usr/bin.

> I then tried issuing the command:
> 
>      rstudio
> 
> Exactly the same pop-up error.  No help at all, as I expected.

O.k., as I got a new machine, I installed (X)ubuntu 18.04 from scratch,
no update from an earlier version.  The R version installed from
r-base-core was R 3.4.4.  In a terminal in which I manipulated my PATH
variable so that /usr/bin is early on, I could start R without problem,
and I could start rstudio without problem.

After following the instructions on CRAN and updating my apt
information, I have now R 3.5.1 installed.  And it starts fine from the
command line as does rstudio.  And rstudio starts now with R 3.5.1.

Both these packages work out of the box.  Thus I wonder whether you
have somehow messed up your system during the attempt to install R from
source.  Or have some environment variables set that provide rstudio
with wrong information....

> Then finally, in desperation, I copied libR.so from /usr/lib/R/lib to
> /usr/lib64/R/lib.  Bingo!!!  I can now start Rstudio!!!

I keep wondering why you have a /usr/lib64.

On my Ubuntu boxes, in /usr I have /lib, /lib32 and /libx32, but no
lib64.  As far as I know, Debian/Ubuntu 64bit implementations always
used /usr/lib for its 64 bit libraries and /usr/lib32 for the 32 bit
versions (unlike other distributions who used /usr/lib64 for the former
and /usr/lib for the latter).

In fact, a 'locate /lib64' on my Ubuntu 18.04 system (less than 2 week
old fresh installation) shows:

/lib64
/lib64/ld-linux-x86-64.so.2
/usr/src/linux-headers-4.15.0-32/arch/sh/lib64
/usr/src/linux-headers-4.15.0-32/arch/sh/lib64/Makefile
/usr/src/linux-headers-4.15.0-33/arch/sh/lib64
/usr/src/linux-headers-4.15.0-33/arch/sh/lib64/Makefile

So there seems to be a /lib64, but no /usr/lib64.  How did you get
this?  And why does rstudio think it has to look into that directory?

> It remains mysterious to me why the symlink procedure did not work, 
> whereas making a copy of libR.so *did* work.

Agreed, that is somebody a mystery.

> However I guess this really doesn't matter.  It's now working.

Until it breaks again. :)

I would advise to start at some point with a clean Ubuntu installation,
and then restrict yourself to /usr/local and /opt when installing
software from source.  

Cheers,

	Berwin


From berwin@turl@ch @ending from gm@il@com  Sat Aug 25 17:02:25 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Sat, 25 Aug 2018 23:02:25 +0800
Subject: [R] installing R 3.5.1
In-Reply-To: <CA+JEM02_tV3qFoNK9AdggePEit7KBnDj1eYiL6AEbRX=bp9ULg@mail.gmail.com>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
 <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>
 <CA+JEM02_tV3qFoNK9AdggePEit7KBnDj1eYiL6AEbRX=bp9ULg@mail.gmail.com>
Message-ID: <20180825230225.5b31175e@absentia>

Dear Bogdan,

On Sat, 25 Aug 2018 07:24:40 -0700
Bogdan Tanasa <tanasa at gmail.com> wrote:

> installed E: Unable to correct problems, you have held broken
> packages.

Perhaps this is the problem, did you try "apt-get -f install"?

Cheers,

	Berwin


From t@n@@@ @ending from gm@il@com  Sat Aug 25 18:00:59 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sat, 25 Aug 2018 09:00:59 -0700
Subject: [R] installing R 3.5.1
In-Reply-To: <20180825230225.5b31175e@absentia>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
 <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>
 <CA+JEM02_tV3qFoNK9AdggePEit7KBnDj1eYiL6AEbRX=bp9ULg@mail.gmail.com>
 <20180825230225.5b31175e@absentia>
Message-ID: <CA+JEM02MaMmMRem_cpV-iVE-BS9HJ3LwKU_2yOz2RXw=h9xPiw@mail.gmail.com>

Dear Berwin, thank you very much . I guess that I shall update my Ubuntu OS
;

after "sudo apt-get -f install", I am getting the same message :

The following packages have unmet dependencies:
 r-recommended : Depends: r-cran-kernsmooth (>= 2.2.14) but it is not going
to be installed
                 Depends: r-cran-mass but it is not going to be installed
                 Depends: r-cran-class but it is not going to be installed
                 Depends: r-cran-nnet but it is not going to be installed
E: Unable to correct problems, you have held broken packages.


On Sat, Aug 25, 2018 at 8:02 AM, Berwin A Turlach <berwin.turlach at gmail.com>
wrote:

> Dear Bogdan,
>
> On Sat, 25 Aug 2018 07:24:40 -0700
> Bogdan Tanasa <tanasa at gmail.com> wrote:
>
> > installed E: Unable to correct problems, you have held broken
> > packages.
>
> Perhaps this is the problem, did you try "apt-get -f install"?
>
> Cheers,
>
>         Berwin
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Aug 25 18:57:29 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 25 Aug 2018 09:57:29 -0700
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
References: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
Message-ID: <753893CA-5D0B-4CB6-9EAD-620ADCF07BC8@dcn.davis.ca.us>

look at the map2 function in the purrr package.

On August 24, 2018 6:44:19 AM PDT, Deepa <deepamahm.iisc at gmail.com> wrote:
>Hello,
>
>Is there an option to include multiple counters in a single for loop in
>R?
>
>For instance, in python there is
>
>for i,j in zip(x,range(0,len(x))):
>
>
>Any suggestions?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jeremiejuste m@ili@g off gm@il@com  Sat Aug 25 19:47:21 2018
From: jeremiejuste m@ili@g off gm@il@com (jeremiejuste m@ili@g off gm@il@com)
Date: Sat, 25 Aug 2018 19:47:21 +0200
Subject: [R] Multiple counters in a single for loop
Message-ID: <5b819653.1c69fb81.47916.a598@mx.google.com>

Hello,
I'm aware it is not the answer you are expecting but indexes are not that bad to implement as well.

for ( i in 1:length(var1)){
elem1 <-var1[i]
elem2 <-  var2[i]


}

if you want more abstraction you could then wrap that up in a function

HTHOn 25 Aug 2018 18:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> look at the map2 function in the purrr package. 
>
> On August 24, 2018 6:44:19 AM PDT, Deepa <deepamahm.iisc at gmail.com> wrote: 
> >Hello, 
> > 
> >Is there an option to include multiple counters in a single for loop in 
> >R? 
> > 
> >For instance, in python there is 
> > 
> >for i,j in zip(x,range(0,len(x))): 
> > 
> > 
> >Any suggestions? 
> > 
> > [[alternative HTML version deleted]] 
> > 
> >______________________________________________ 
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> >https://stat.ethz.ch/mailman/listinfo/r-help 
> >PLEASE do read the posting guide 
> >http://www.R-project.org/posting-guide.html 
> >and provide commented, minimal, self-contained, reproducible code. 
>
> -- 
> Sent from my phone. Please excuse my brevity. 
>
> ______________________________________________ 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 

From murdoch@dunc@n @ending from gm@il@com  Sat Aug 25 22:12:32 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sat, 25 Aug 2018 16:12:32 -0400
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <5b819653.1c69fb81.47916.a598@mx.google.com>
References: <5b819653.1c69fb81.47916.a598@mx.google.com>
Message-ID: <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com>

On 25/08/2018 1:47 PM, jeremiejuste at gmail.com wrote:
> Hello,
> I'm aware it is not the answer you are expecting but indexes are not that bad to implement as well.
> 
> for ( i in 1:length(var1)){

This is generally a bad idea:  if length(var1) == 0, it does the wrong 
thing, since 1:0 is c(1L, 0L).  Better to use

for ( i in seq_along(var1) ) {

Duncan Murdoch

> elem1 <-var1[i]
> elem2 <-  var2[i]
> 
> 
> }
> 
> if you want more abstraction you could then wrap that up in a function
> 
> HTHOn 25 Aug 2018 18:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> look at the map2 function in the purrr package.
>>
>> On August 24, 2018 6:44:19 AM PDT, Deepa <deepamahm.iisc at gmail.com> wrote:
>>> Hello,
>>>
>>> Is there an option to include multiple counters in a single for loop in
>>> R?
>>>
>>> For instance, in python there is
>>>
>>> for i,j in zip(x,range(0,len(x))):
>>>
>>>
>>> Any suggestions?
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> -- 
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p_connolly @ending from @ling@hot@co@nz  Sun Aug 26 01:37:02 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Sun, 26 Aug 2018 11:37:02 +1200
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
Message-ID: <20180825233702.GE13179@slingshot.co.nz>

On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:

|> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
|> >---
|> >title: "Barking up the wrong tree"
|> >author: "Patrick Connolly"
|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
|> >output:
|> >   ioslides_presentation: default
|> >   slidy_presentation: default
|> >   beamer_presentation: default
|> >---
|> >
|> >```{r global_options, echo=FALSE}
|> >knitr::opts_chunk$set(tidy=TRUE,
|> >                       warning=FALSE,
|> >                       message=FALSE,
|> >                       cache=FALSE,
|> >                       dpi = 300)
|> 
|> Drop the dpi setting and it will work fine.

Still doesn't avoid what I think is the issue with Cairo

   Error in axis(side = side, at = at, labels = labels, ...) : X11
  font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12
  could not be loaded Calls: <Anonymous> ... plot.default -> localAxis
  -> Axis -> Axis.default -> axis

  Execution halted


For interactive plotting, Rstudio plots those 6 plots on one page so
no issue is apparent, as it will if I use a pdf device within ESS.
However, when plotting interactively in ESS, a basic font is used for
the labels which is OK for preliminary quick look.  No error message
is shown, but I suspect that it is defaulting to a crude font because
the helvetica font is not available.

It appears to me that the font problem doesn't arise with Rstudio
unless the desired output is ioslides.  Which brings us back to the
issue with Cairo.  There are lots of hits when I search for
configuring fonts, Cairo and R but I've not found anything I can use.

I would appreciate pointers where I can find useful information.

Thank you.

|> 
|> Duncan Murdoch
|> 
|> >```
|> >## 6 different Regression Trees
|> >
|> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
|> >
|> >  par(mfrow = c(2, 3))
|> >plot(1:10)
|> >plot(12:4)
|> >plot(seq(0, 800))
|> >plot(-100:-900)
|> >plot(12:50)
|> >plot(90:54)
|> >```

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From murdoch@dunc@n @ending from gm@il@com  Sun Aug 26 02:10:14 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sat, 25 Aug 2018 20:10:14 -0400
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180825233702.GE13179@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
 <20180825233702.GE13179@slingshot.co.nz>
Message-ID: <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>

On 25/08/2018 7:37 PM, Patrick Connolly wrote:
> On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:
> 
> |> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
> |> >---
> |> >title: "Barking up the wrong tree"
> |> >author: "Patrick Connolly"
> |> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
> |> >output:
> |> >   ioslides_presentation: default
> |> >   slidy_presentation: default
> |> >   beamer_presentation: default
> |> >---
> |> >
> |> >```{r global_options, echo=FALSE}
> |> >knitr::opts_chunk$set(tidy=TRUE,
> |> >                       warning=FALSE,
> |> >                       message=FALSE,
> |> >                       cache=FALSE,
> |> >                       dpi = 300)
> |>
> |> Drop the dpi setting and it will work fine.
> 
> Still doesn't avoid what I think is the issue with Cairo
> 
>     Error in axis(side = side, at = at, labels = labels, ...) : X11
>    font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12
>    could not be loaded Calls: <Anonymous> ... plot.default -> localAxis
>    -> Axis -> Axis.default -> axis
> 
>    Execution halted
> 
> 
> For interactive plotting, Rstudio plots those 6 plots on one page so
> no issue is apparent, as it will if I use a pdf device within ESS.

So use RStudio, don't use ESS.

> However, when plotting interactively in ESS, a basic font is used for
> the labels which is OK for preliminary quick look.  No error message
> is shown, but I suspect that it is defaulting to a crude font because
> the helvetica font is not available.
> 
> It appears to me that the font problem doesn't arise with Rstudio
> unless the desired output is ioslides.  Which brings us back to the
> issue with Cairo.  There are lots of hits when I search for
> configuring fonts, Cairo and R but I've not found anything I can use.
> 

I don't see a font problem in MacOS.  I don't think you've stated what 
system you are using (but I may have missed it).

Duncan Murdoch

> I would appreciate pointers where I can find useful information.
> 
> Thank you.
> 
> |>
> |> Duncan Murdoch
> |>
> |> >```
> |> >## 6 different Regression Trees
> |> >
> |> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
> |> >
> |> >  par(mfrow = c(2, 3))
> |> >plot(1:10)
> |> >plot(12:4)
> |> >plot(seq(0, 800))
> |> >plot(-100:-900)
> |> >plot(12:50)
> |> >plot(90:54)
> |> >```
>


From r@turner @ending from @uckl@nd@@c@nz  Sun Aug 26 03:00:34 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 26 Aug 2018 13:00:34 +1200
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <20180825225918.1f91a9cc@absentia>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
 <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
 <20180825225918.1f91a9cc@absentia>
Message-ID: <12ea011e-250e-e8ab-d589-42491b6547b5@auckland.ac.nz>


On 08/26/2018 02:59 AM, Berwin A Turlach wrote:

> G'day Rolf,
> 
> On Sat, 25 Aug 2018 11:20:09 +1200
> Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
>> I was pretty sure that the foregoing was a complete red herring.  And
>> I was right.
> 
> I am not sure whether I agree. :)

Huh?  Black is white and up is down???

I did as advised and it made absolutely no difference.  Ergo  I was right.

<SNIP>

> I keep wondering why you have a /usr/lib64.

<SNIP>

> .... How did you get this? 

I have no idea.  It just seems to be there.  And it seems that rstudio 
thinks that it should be there.

> And why does rstudio think it has to look into that directory?
How would I know?  You would have to ask RStudio, not me.

Anyway, I seem to have (for the time being at least) a working system, 
and I don't feel like wasting any more time on this issue.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From berwin@turl@ch @ending from gm@il@com  Sun Aug 26 07:29:48 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Sun, 26 Aug 2018 13:29:48 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <12ea011e-250e-e8ab-d589-42491b6547b5@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
 <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
 <20180825225918.1f91a9cc@absentia>
 <12ea011e-250e-e8ab-d589-42491b6547b5@auckland.ac.nz>
Message-ID: <20180826132948.65495dfe@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Rolf,

On Sun, 26 Aug 2018 13:00:34 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 08/26/2018 02:59 AM, Berwin A Turlach wrote:
>
> > I am not sure whether I agree. :)  
> 
> Huh?  Black is white and up is down???

Nope, but as I said, on my machine RStudio and the R installed from the
Ubuntu repositories worked out of the box.

After adding the CRAN repositories to my apt configuration and
upgrading R, RStudio and the new R version worked again out of the box.

For the R versions that I compile from source, as I install sub
architectures, I need to install symbol links from where libR.so
actually is to where Rstudio expects them.  And RStudio works out of
the box with all these installation, i.e. it seems to follow symbolic
links.
 
> I did as advised and it made absolutely no difference.  Ergo  I was
> right.

That is your conclusion from the data, are you are perfectly entitled
to it. :)

I still think that this is one of the 5% of the cases where you got
your inference wrong.  Given that for me (and presumably many others
[but I neither follow r-sig-Debian nor the Rstudio forums, so I may
have a biased input]) everything works out of the box, my conclusion
from the data is that you have FUBAR'd your system.

Now, this can be from the way you tried to compile R from source (you
never told us what you exactly specified to ./configure, but we would
also have to know whether you made changes to config.site before
compilation) or it could be from some environment variables (set long
time ago and since forgotten [if so, where is it set ~/.bashrc? ~/.R?). 

> <SNIP>
> 
> > I keep wondering why you have a /usr/lib64.  
> 
> <SNIP>
> 
> > .... How did you get this?   
> 
> I have no idea.  It just seems to be there.  And it seems that
> rstudio thinks that it should be there.

As far as I can tell, RStudio expects libR.so in a certain directory
relative to where the home directory (as reported by R on query) of R.
But RStudio's behaviour can also be influenced by environment variable.
 
So the fact that RStudio keeps looking at /usr/lib64 is for me evidence
that your system is compromised, and that RStudio is not starting the
version of R installed from the Ubuntu package manager.

> Anyway, I seem to have (for the time being at least) a working
> system, and I don't feel like wasting any more time on this issue.

Fair enough, but I am concerned that this issue will raise it head
sooner or later again.  So my final advice is to stick to the old adage
from sports: Never change a winning team.  If you system works for you
know, freeze it.  No more updates/upgrades.   Otherwise, good luck when
you try to update R next....

Cheers,
	
	Berwin


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Aug 26 08:35:03 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 25 Aug 2018 23:35:03 -0700
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
 <20180825233702.GE13179@slingshot.co.nz>
 <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
Message-ID: <7558075D-115E-4B6D-9486-29608FBEF4DC@dcn.davis.ca.us>

a) Duncan, he provided sessionInfo below his reprex.

b) Patrick: you appear to be trying to use a common file to generate multiple output formats. I will caution you that I have found considerable disappointment in trying that, and suggest that you focus your efforts on one output format for each Rmd file.

c) You can add out.width="100%" and out.height="100%" to your chunk to fix the scaling problem. This method is HTML-specific... you would need different strings for LaTeX output.

d) Note that the help files for the rmarkdown output functions are often very interesting. e.g.

?rmarkdown::ioslides_presentation

On August 25, 2018 5:10:14 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 25/08/2018 7:37 PM, Patrick Connolly wrote:
>> On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:
>> 
>> |> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
>> |> >---
>> |> >title: "Barking up the wrong tree"
>> |> >author: "Patrick Connolly"
>> |> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
>> |> >output:
>> |> >   ioslides_presentation: default
>> |> >   slidy_presentation: default
>> |> >   beamer_presentation: default
>> |> >---
>> |> >
>> |> >```{r global_options, echo=FALSE}
>> |> >knitr::opts_chunk$set(tidy=TRUE,
>> |> >                       warning=FALSE,
>> |> >                       message=FALSE,
>> |> >                       cache=FALSE,
>> |> >                       dpi = 300)
>> |>
>> |> Drop the dpi setting and it will work fine.
>> 
>> Still doesn't avoid what I think is the issue with Cairo
>> 
>>     Error in axis(side = side, at = at, labels = labels, ...) : X11
>>    font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size
>12
>>    could not be loaded Calls: <Anonymous> ... plot.default ->
>localAxis
>>    -> Axis -> Axis.default -> axis
>> 
>>    Execution halted
>> 
>> 
>> For interactive plotting, Rstudio plots those 6 plots on one page so
>> no issue is apparent, as it will if I use a pdf device within ESS.
>
>So use RStudio, don't use ESS.
>
>> However, when plotting interactively in ESS, a basic font is used for
>> the labels which is OK for preliminary quick look.  No error message
>> is shown, but I suspect that it is defaulting to a crude font because
>> the helvetica font is not available.
>> 
>> It appears to me that the font problem doesn't arise with Rstudio
>> unless the desired output is ioslides.  Which brings us back to the
>> issue with Cairo.  There are lots of hits when I search for
>> configuring fonts, Cairo and R but I've not found anything I can use.
>> 
>
>I don't see a font problem in MacOS.  I don't think you've stated what 
>system you are using (but I may have missed it).
>
>Duncan Murdoch
>
>> I would appreciate pointers where I can find useful information.
>> 
>> Thank you.
>> 
>> |>
>> |> Duncan Murdoch
>> |>
>> |> >```
>> |> >## 6 different Regression Trees
>> |> >
>> |> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE,
>fig.width = 7, fig.height = 5}
>> |> >
>> |> >  par(mfrow = c(2, 3))
>> |> >plot(1:10)
>> |> >plot(12:4)
>> |> >plot(seq(0, 800))
>> |> >plot(-100:-900)
>> |> >plot(12:50)
>> |> >plot(90:54)
>> |> >```
>> 

-- 
Sent from my phone. Please excuse my brevity.


From jeremieju@te @ending from gm@il@com  Sun Aug 26 09:10:45 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Sun, 26 Aug 2018 09:10:45 +0200
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com> (Duncan
 Murdoch's message of "Sat, 25 Aug 2018 16:12:32 -0400")
References: <5b819653.1c69fb81.47916.a598@mx.google.com>
 <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com>
Message-ID: <87pny5mwlm.fsf@gmail.com>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

>> for ( i in 1:length(var1)){
>
> This is generally a bad idea:  if length(var1) == 0, it does the wrong
> thing, since 1:0 is c(1L, 0L).  Better to use
>
> for ( i in seq_along(var1) ) {
>


granted. One should check the validity of their variables before using
them but I argue that seq_along does not protect you from the
unexpected behaviour.

If the length of var1 should not be 0 so

stopifnot(length(var)==0) 
for ( i in 1:length(var1)){

    elem1 <-var1[i]
    elem2 <-  var2[i]

}


From jeremieju@te @ending from gm@il@com  Sun Aug 26 09:27:01 2018
From: jeremieju@te @ending from gm@il@com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Sun, 26 Aug 2018 09:27:01 +0200
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <87pny5mwlm.fsf@gmail.com>
References: <5b819653.1c69fb81.47916.a598@mx.google.com>
 <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com>
 <87pny5mwlm.fsf@gmail.com>
Message-ID: <CAPHJcdBgYEPUnF8P765CZ4X6TecZZ_v0YWAfZr0oQbK9_1Q37Q@mail.gmail.com>

Of course I meant

>If the length of var1 should not be 0 so

stopifnot(length(var)>0)

On Sun, Aug 26, 2018 at 9:10 AM, Jeremie Juste <jeremiejuste at gmail.com>
wrote:

> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
>
> >> for ( i in 1:length(var1)){
> >
> > This is generally a bad idea:  if length(var1) == 0, it does the wrong
> > thing, since 1:0 is c(1L, 0L).  Better to use
> >
> > for ( i in seq_along(var1) ) {
> >
>
>
> granted. One should check the validity of their variables before using
> them but I argue that seq_along does not protect you from the
> unexpected behaviour.
>
> If the length of var1 should not be 0 so
>
> stopifnot(length(var)==0)
> for ( i in 1:length(var1)){
>
>     elem1 <-var1[i]
>     elem2 <-  var2[i]
>
> }
>



-- 
J?r?mie Juste

	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Sun Aug 26 10:40:32 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Sun, 26 Aug 2018 20:40:32 +1200
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
 <20180825233702.GE13179@slingshot.co.nz>
 <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
Message-ID: <20180826084032.GA6042@slingshot.co.nz>

On Sat, 25-Aug-2018 at 08:10PM -0400, Duncan Murdoch wrote:

|> On 25/08/2018 7:37 PM, Patrick Connolly wrote:
|> >On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:
|> >
|> >|> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
|> >|> >---
|> >|> >title: "Barking up the wrong tree"
|> >|> >author: "Patrick Connolly"
|> >|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
|> >|> >output:
|> >|> >   ioslides_presentation: default
|> >|> >   slidy_presentation: default
|> >|> >   beamer_presentation: default
|> >|> >---
|> >|> >
|> >|> >```{r global_options, echo=FALSE}
|> >|> >knitr::opts_chunk$set(tidy=TRUE,
|> >|> >                       warning=FALSE,
|> >|> >                       message=FALSE,
|> >|> >                       cache=FALSE,
|> >|> >                       dpi = 300)
|> >|>
|> >|> Drop the dpi setting and it will work fine.
|> >
|> >Still doesn't avoid what I think is the issue with Cairo
|> >
|> >    Error in axis(side = side, at = at, labels = labels, ...) : X11
|> >   font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12
|> >   could not be loaded Calls: <Anonymous> ... plot.default -> localAxis
|> >   -> Axis -> Axis.default -> axis
|> >
|> >   Execution halted
|> >
|> >
|> >For interactive plotting, Rstudio plots those 6 plots on one page so
|> >no issue is apparent, as it will if I use a pdf device within ESS.
|> 
|> So use RStudio, don't use ESS.

I'm using Rstudio to try to output ioslides which runs into the font
problem which doesn't arise when plotting to the plot pane.  RStudio's
no advantage when the objective is ioslides.  That observation gives
rise to my hypothesis that to produce ioslides, Cairo is utilized in
ways incomprehensible to me.

|> 
|> >However, when plotting interactively in ESS, a basic font is used for
|> >the labels which is OK for preliminary quick look.  No error message
|> >is shown, but I suspect that it is defaulting to a crude font because
|> >the helvetica font is not available.
|> >
|> >It appears to me that the font problem doesn't arise with Rstudio
|> >unless the desired output is ioslides.  Which brings us back to the
|> >issue with Cairo.  There are lots of hits when I search for
|> >configuring fonts, Cairo and R but I've not found anything I can use.
|> >
|> 
|> I don't see a font problem in MacOS.  I don't think you've stated
|> what system you are using (but I may have missed it).

It has something to do with X11 which I guess MacOS doesn't use.

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
 [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] utils     stats     grDevices graphics  methods   base     

other attached packages:
[1] lattice_0.20-35

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.17     bindr_0.1.1      magrittr_1.5     tidyselect_0.2.4
 [5] munsell_0.5.0    colorspace_1.3-2 xtable_1.8-2     R6_2.2.2        
 [9] rlang_0.2.1      plyr_1.8.4       dplyr_0.7.6      tools_3.5.0     
[13] grid_3.5.0       htmltools_0.3.6  crosstalk_1.0.0  leaflet_2.0.1   
[17] assertthat_0.2.0 digest_0.6.15    tibble_1.4.2     bindrcpp_0.2.2  
[21] shiny_1.1.0      purrr_0.2.5      later_0.7.3      htmlwidgets_1.2 
[25] promises_1.0.1   glue_1.2.0       mime_0.5         compiler_3.5.0  
[29] pillar_1.2.3     scales_0.5.0     httpuv_1.4.4.2   pkgconfig_2.0.1 


|> 
|> Duncan Murdoch
|> 
|> >I would appreciate pointers where I can find useful information.
|> >
|> >Thank you.
|> >
|> >|>
|> >|> Duncan Murdoch
|> >|>
|> >|> >```
|> >|> >## 6 different Regression Trees
|> >|> >
|> >|> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
|> >|> >
|> >|> >  par(mfrow = c(2, 3))
|> >|> >plot(1:10)
|> >|> >plot(12:4)
|> >|> >plot(seq(0, 800))
|> >|> >plot(-100:-900)
|> >|> >plot(12:50)
|> >|> >plot(90:54)
|> >|> >```
|> >

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From murdoch@dunc@n @ending from gm@il@com  Sun Aug 26 12:59:57 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 26 Aug 2018 06:59:57 -0400
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <87pny5mwlm.fsf@gmail.com>
References: <5b819653.1c69fb81.47916.a598@mx.google.com>
 <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com> <87pny5mwlm.fsf@gmail.com>
Message-ID: <57752b2b-c27d-e1fb-c0e0-59abd5321b19@gmail.com>

On 26/08/2018 3:10 AM, Jeremie Juste wrote:
> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
> 
>>> for ( i in 1:length(var1)){
>>
>> This is generally a bad idea:  if length(var1) == 0, it does the wrong
>> thing, since 1:0 is c(1L, 0L).  Better to use
>>
>> for ( i in seq_along(var1) ) {
>>
> 
> 
> granted. One should check the validity of their variables before using
> them but I argue that seq_along does not protect you from the
> unexpected behaviour.

I don't see why you argue that.  seq_along(var1) will give an empty 
vector if var1 is empty, so the loop won't run at all.

> 
> If the length of var1 should not be 0 so
> 
> stopifnot(length(var) > 0)
> for ( i in 1:length(var1)){
> 
>      elem1 <-var1[i]
>      elem2 <-  var2[i]
> 
> }

That's a possibility (I made your >0 correction), but maybe having 
length 0 isn't something that should trigger a fatal error, maybe it's 
just that no elements met some condition.

Duncan Murdoch


From murdoch@dunc@n @ending from gm@il@com  Sun Aug 26 14:09:48 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 26 Aug 2018 08:09:48 -0400
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180826084032.GA6042@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
 <20180825233702.GE13179@slingshot.co.nz>
 <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
 <20180826084032.GA6042@slingshot.co.nz>
Message-ID: <1c32d8ed-eeb3-c7a4-c8bc-e81eabe7df69@gmail.com>

On 26/08/2018 4:40 AM, Patrick Connolly wrote:
> On Sat, 25-Aug-2018 at 08:10PM -0400, Duncan Murdoch wrote:
> 
> |> On 25/08/2018 7:37 PM, Patrick Connolly wrote:
> |> >On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:
> |> >
> |> >|> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
> |> >|> >---
> |> >|> >title: "Barking up the wrong tree"
> |> >|> >author: "Patrick Connolly"
> |> >|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
> |> >|> >output:
> |> >|> >   ioslides_presentation: default
> |> >|> >   slidy_presentation: default
> |> >|> >   beamer_presentation: default
> |> >|> >---
> |> >|> >
> |> >|> >```{r global_options, echo=FALSE}
> |> >|> >knitr::opts_chunk$set(tidy=TRUE,
> |> >|> >                       warning=FALSE,
> |> >|> >                       message=FALSE,
> |> >|> >                       cache=FALSE,
> |> >|> >                       dpi = 300)
> |> >|>
> |> >|> Drop the dpi setting and it will work fine.
> |> >
> |> >Still doesn't avoid what I think is the issue with Cairo
> |> >
> |> >    Error in axis(side = side, at = at, labels = labels, ...) : X11
> |> >   font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12
> |> >   could not be loaded Calls: <Anonymous> ... plot.default -> localAxis
> |> >   -> Axis -> Axis.default -> axis
> |> >
> |> >   Execution halted
> |> >
> |> >
> |> >For interactive plotting, Rstudio plots those 6 plots on one page so
> |> >no issue is apparent, as it will if I use a pdf device within ESS.
> |>
> |> So use RStudio, don't use ESS.
> 
> I'm using Rstudio to try to output ioslides which runs into the font
> problem which doesn't arise when plotting to the plot pane.  RStudio's
> no advantage when the objective is ioslides.  That observation gives
> rise to my hypothesis that to produce ioslides, Cairo is utilized in
> ways incomprehensible to me.

Since that error happens during the axis() call, it's related to the 
graphics device that is being used.  That would be different for an 
ioslides document than it is for interactive display.  On my system (and 
I think on all systems) the png() device is used for ioslides.

If you run debug(png) then rmarkdown::render( <your Rmd file> ), you'll 
see what options are being passed to png.  On my system, it is called 
with no arguments except a filename, so it uses the defaults for all 
other arguments.  That means the "type" argument eventually gets set to 
"quartz".  Yours will be different, but I don't know what it will get. 
Maybe you can choose something different than the default by setting 
options("bitmapType").

Duncan Murdoch
> 
> |>
> |> >However, when plotting interactively in ESS, a basic font is used for
> |> >the labels which is OK for preliminary quick look.  No error message
> |> >is shown, but I suspect that it is defaulting to a crude font because
> |> >the helvetica font is not available.
> |> >
> |> >It appears to me that the font problem doesn't arise with Rstudio
> |> >unless the desired output is ioslides.  Which brings us back to the
> |> >issue with Cairo.  There are lots of hits when I search for
> |> >configuring fonts, Cairo and R but I've not found anything I can use.
> |> >
> |>
> |> I don't see a font problem in MacOS.  I don't think you've stated
> |> what system you are using (but I may have missed it).
> 
> It has something to do with X11 which I guess MacOS doesn't use.
> 
>> sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
> 
> Matrix products: default
> BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
> LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so
> 
> locale:
>   [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>   [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>   [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] utils     stats     grDevices graphics  methods   base
> 
> other attached packages:
> [1] lattice_0.20-35
> 
> loaded via a namespace (and not attached):
>   [1] Rcpp_0.12.17     bindr_0.1.1      magrittr_1.5     tidyselect_0.2.4
>   [5] munsell_0.5.0    colorspace_1.3-2 xtable_1.8-2     R6_2.2.2
>   [9] rlang_0.2.1      plyr_1.8.4       dplyr_0.7.6      tools_3.5.0
> [13] grid_3.5.0       htmltools_0.3.6  crosstalk_1.0.0  leaflet_2.0.1
> [17] assertthat_0.2.0 digest_0.6.15    tibble_1.4.2     bindrcpp_0.2.2
> [21] shiny_1.1.0      purrr_0.2.5      later_0.7.3      htmlwidgets_1.2
> [25] promises_1.0.1   glue_1.2.0       mime_0.5         compiler_3.5.0
> [29] pillar_1.2.3     scales_0.5.0     httpuv_1.4.4.2   pkgconfig_2.0.1
> 
> 
> |>
> |> Duncan Murdoch
> |>
> |> >I would appreciate pointers where I can find useful information.
> |> >
> |> >Thank you.
> |> >
> |> >|>
> |> >|> Duncan Murdoch
> |> >|>
> |> >|> >```
> |> >|> >## 6 different Regression Trees
> |> >|> >
> |> >|> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
> |> >|> >
> |> >|> >  par(mfrow = c(2, 3))
> |> >|> >plot(1:10)
> |> >|> >plot(12:4)
> |> >|> >plot(seq(0, 800))
> |> >|> >plot(-100:-900)
> |> >|> >plot(12:50)
> |> >|> >plot(90:54)
> |> >|> >```
> |> >
>


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Sun Aug 26 23:08:38 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 17:08:38 -0400
Subject: [R] Help with DNA Methylation Analysis
Message-ID: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>

Good evening,

  I am attempting to run the following analysis on TCGA data, however
something is being reported as an error in my arguments... any ideas as to
what is incorrect in the following? Thanks!

1 library(TCGAbiolinks)
2
3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
4 path <? "."
5
6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
level = 3)
7 TCGAdownload(query.met, path = path )
8 met <? TCGAprepare(query = query.met,dir = path,
9                      add.subtype = TRUE, add.clinical = TRUE,
10                    summarizedExperiment = TRUE,
11                      save = TRUE, filename = "lgg_gbm_met.rda")
12
13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform = "IlluminaHiSeq_
RNASeqV2",level = 3)
15
16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
results")
17
18 exp <? TCGAprepare(query = query.exp, dir = path,
19                    summarizedExperiment = TRUE,
20                      add.subtype = TRUE, add.clinical = TRUE,
21                    type = "rsem.genes.normalized_results",
22                      save = T,filename = "lgg_gbm_exp.rda")

To download data on DNA methylation and gene expression?

1 library(summarizedExperiment)
2 # get expression matrix
3 data <? assay(exp)
4
5 # get sample information
6 sample.info <? colData(exp)
7
8 # get genes information
9 genes.info <? rowRanges(exp)

Following stepwise procedure for obtaining GBM and LGG clinical data?

1 # get clinical patient data for GBM samples
2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
3
4 # get clinical patient data for LGG samples
5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
6
7 # Bind the results, as the columns might not be the same,
8 # we will plyr rbind.fill , to have all columns from both files
9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
10
11 # Other clinical files can be downloaded,
12 # Use ?TCGAquery_clinic for more information
13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
14
15 # Also, you can get clinical information from different tumor types.
16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
18    samples = c("TCGA-06-5416-01A-01D-1481-05",
19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))


# Searching idat file for DNA methylation
query <- GDCquery(project = "TCGA-GBM",
                 data.category = "Raw microarray data",
                 data.type = "Raw intensities",
                 experimental.strategy = "Methylation array",
                 legacy = TRUE,
                 file.type = ".idat",
                 platform = "Illumina Human Methylation 450")

**Repeat for LGG**

To access mutational information concerning TMZ methylation?

> mutation <? TCGAquery_maf(tumor = "lgg")
2   Getting maf tables
3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
4   We found these maf files below:
5       MAF.File.Name
6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
7
8   3 LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
9
10       Archive.Name Deploy.Date
11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
  10-DEC-13
12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0   24-DEC-14
13
14   Please, select the line that you want to download: 3

**Repeat this for GBM***

Selecting specified lines to download?

1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)



Downloading data via the Bioconductor package RTCGAtoolbox?

library(RTCGAToolbox)
2
3 # Get the last run dates
4 lastRunDate <? getFirehoseRunningDates()[1]
5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
6
7 # get DNA methylation data, RNAseq2 and clinical data for LGG
8 lgg.data <? getFirehoseData(dataset = "LGG",
9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate = lastRunDate,
10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
11       Mutation = T,
12       fileSizeLimit = 10000)
13
14 # get DNA methylation data, RNAseq2 and clinical data for GBM
15 gbm.data <? getFirehoseData(dataset = "GBM",
16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
18       fileSizeLimit = 10000)
19
20 # To access the data you should use the getData function
21 # or simply access with @ (for example gbm.data at Clinical)
22 gbm.mut <? getData(gbm.data,"Mutations")
23 gbm.clin <? getData(gbm.data,"Clinical")
24 gbm.gistic <? getData(gbm.data,"GISTIC")






Genomic Analysis/Final data extraction:

Enable ?getData? to access the data

Obtaining GISTIC results?

1 # Download GISTIC results
2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
3
4 # get GISTIC results
5 gistic.allbygene <? gistic at GISTIC@AllByGene
6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene

Repeat this procedure to obtain LGG GISTIC results.

***Please ignore the 'non-coded' text as they are procedural
steps/classifications***

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sun Aug 26 23:36:59 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 26 Aug 2018 14:36:59 -0700
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
Message-ID: <CAGxFJbQPXwDMxj9WUcP+Qz8MsFiPZ5uqrezOCcJBQX=DxT+DFg@mail.gmail.com>

You should probably post this on the Bioconductor list rather then here, as
you would more likely find the expertise you seek there. You are using
Bioconductor packages after all.

https://support.bioconductor.org/

Cheers,
Bert


On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Good evening,
>
>   I am attempting to run the following analysis on TCGA data, however
> something is being reported as an error in my arguments... any ideas as to
> what is incorrect in the following? Thanks!
>
> 1 library(TCGAbiolinks)
> 2
> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> 4 path <? "."
> 5
> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
> level = 3)
> 7 TCGAdownload(query.met, path = path )
> 8 met <? TCGAprepare(query = query.met,dir = path,
> 9                      add.subtype = TRUE, add.clinical = TRUE,
> 10                    summarizedExperiment = TRUE,
> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> 12
> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> "IlluminaHiSeq_
> RNASeqV2",level = 3)
> 15
> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> results")
> 17
> 18 exp <? TCGAprepare(query = query.exp, dir = path,
> 19                    summarizedExperiment = TRUE,
> 20                      add.subtype = TRUE, add.clinical = TRUE,
> 21                    type = "rsem.genes.normalized_results",
> 22                      save = T,filename = "lgg_gbm_exp.rda")
>
> To download data on DNA methylation and gene expression?
>
> 1 library(summarizedExperiment)
> 2 # get expression matrix
> 3 data <? assay(exp)
> 4
> 5 # get sample information
> 6 sample.info <? colData(exp)
> 7
> 8 # get genes information
> 9 genes.info <? rowRanges(exp)
>
> Following stepwise procedure for obtaining GBM and LGG clinical data?
>
> 1 # get clinical patient data for GBM samples
> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
> 3
> 4 # get clinical patient data for LGG samples
> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
> 6
> 7 # Bind the results, as the columns might not be the same,
> 8 # we will plyr rbind.fill , to have all columns from both files
> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
> 10
> 11 # Other clinical files can be downloaded,
> 12 # Use ?TCGAquery_clinic for more information
> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
> 14
> 15 # Also, you can get clinical information from different tumor types.
> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>
>
> # Searching idat file for DNA methylation
> query <- GDCquery(project = "TCGA-GBM",
>                  data.category = "Raw microarray data",
>                  data.type = "Raw intensities",
>                  experimental.strategy = "Methylation array",
>                  legacy = TRUE,
>                  file.type = ".idat",
>                  platform = "Illumina Human Methylation 450")
>
> **Repeat for LGG**
>
> To access mutational information concerning TMZ methylation?
>
> > mutation <? TCGAquery_maf(tumor = "lgg")
> 2   Getting maf tables
> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
> 4   We found these maf files below:
> 5       MAF.File.Name
> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
> 7
> 8   3 LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
> 9
> 10       Archive.Name Deploy.Date
> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>   10-DEC-13
> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>  24-DEC-14
> 13
> 14   Please, select the line that you want to download: 3
>
> **Repeat this for GBM***
>
> Selecting specified lines to download?
>
> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>
>
>
> Downloading data via the Bioconductor package RTCGAtoolbox?
>
> library(RTCGAToolbox)
> 2
> 3 # Get the last run dates
> 4 lastRunDate <? getFirehoseRunningDates()[1]
> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
> 6
> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
> 8 lgg.data <? getFirehoseData(dataset = "LGG",
> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate = lastRunDate,
> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
> 11       Mutation = T,
> 12       fileSizeLimit = 10000)
> 13
> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
> 15 gbm.data <? getFirehoseData(dataset = "GBM",
> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
> 18       fileSizeLimit = 10000)
> 19
> 20 # To access the data you should use the getData function
> 21 # or simply access with @ (for example gbm.data at Clinical)
> 22 gbm.mut <? getData(gbm.data,"Mutations")
> 23 gbm.clin <? getData(gbm.data,"Clinical")
> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>
>
>
>
>
>
> Genomic Analysis/Final data extraction:
>
> Enable ?getData? to access the data
>
> Obtaining GISTIC results?
>
> 1 # Download GISTIC results
> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
> 3
> 4 # get GISTIC results
> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>
> Repeat this procedure to obtain LGG GISTIC results.
>
> ***Please ignore the 'non-coded' text as they are procedural
> steps/classifications***
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Sun Aug 26 23:37:45 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 17:37:45 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CAGxFJbQPXwDMxj9WUcP+Qz8MsFiPZ5uqrezOCcJBQX=DxT+DFg@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CAGxFJbQPXwDMxj9WUcP+Qz8MsFiPZ5uqrezOCcJBQX=DxT+DFg@mail.gmail.com>
Message-ID: <CAPQaxLN+=J1ZkTTEJ7EQRotZy3cA7=rkibewzwxjmjLSTfcLPA@mail.gmail.com>

Thanks! Will do.

On Sun, Aug 26, 2018 at 5:37 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> You should probably post this on the Bioconductor list rather then here,
> as you would more likely find the expertise you seek there. You are using
> Bioconductor packages after all.
>
> https://support.bioconductor.org/
>
> Cheers,
> Bert
>
>
> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Good evening,
>>
>>   I am attempting to run the following analysis on TCGA data, however
>> something is being reported as an error in my arguments... any ideas as to
>> what is incorrect in the following? Thanks!
>>
>> 1 library(TCGAbiolinks)
>> 2
>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> 4 path <? "."
>> 5
>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> level = 3)
>> 7 TCGAdownload(query.met, path = path )
>> 8 met <? TCGAprepare(query = query.met,dir = path,
>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>> 10                    summarizedExperiment = TRUE,
>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> 12
>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>> "IlluminaHiSeq_
>> RNASeqV2",level = 3)
>> 15
>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> results")
>> 17
>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> 19                    summarizedExperiment = TRUE,
>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>> 21                    type = "rsem.genes.normalized_results",
>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>
>> To download data on DNA methylation and gene expression?
>>
>> 1 library(summarizedExperiment)
>> 2 # get expression matrix
>> 3 data <? assay(exp)
>> 4
>> 5 # get sample information
>> 6 sample.info <? colData(exp)
>> 7
>> 8 # get genes information
>> 9 genes.info <? rowRanges(exp)
>>
>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>
>> 1 # get clinical patient data for GBM samples
>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>> 3
>> 4 # get clinical patient data for LGG samples
>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>> 6
>> 7 # Bind the results, as the columns might not be the same,
>> 8 # we will plyr rbind.fill , to have all columns from both files
>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>> 10
>> 11 # Other clinical files can be downloaded,
>> 12 # Use ?TCGAquery_clinic for more information
>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>> 14
>> 15 # Also, you can get clinical information from different tumor types.
>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>
>>
>> # Searching idat file for DNA methylation
>> query <- GDCquery(project = "TCGA-GBM",
>>                  data.category = "Raw microarray data",
>>                  data.type = "Raw intensities",
>>                  experimental.strategy = "Methylation array",
>>                  legacy = TRUE,
>>                  file.type = ".idat",
>>                  platform = "Illumina Human Methylation 450")
>>
>> **Repeat for LGG**
>>
>> To access mutational information concerning TMZ methylation?
>>
>> > mutation <? TCGAquery_maf(tumor = "lgg")
>> 2   Getting maf tables
>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>> 4   We found these maf files below:
>> 5       MAF.File.Name
>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>> 7
>> 8   3 LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>> 9
>> 10       Archive.Name Deploy.Date
>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>   10-DEC-13
>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>  24-DEC-14
>> 13
>> 14   Please, select the line that you want to download: 3
>>
>> **Repeat this for GBM***
>>
>> Selecting specified lines to download?
>>
>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>
>>
>>
>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>
>> library(RTCGAToolbox)
>> 2
>> 3 # Get the last run dates
>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>> 6
>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate = lastRunDate,
>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>> 11       Mutation = T,
>> 12       fileSizeLimit = 10000)
>> 13
>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>> 18       fileSizeLimit = 10000)
>> 19
>> 20 # To access the data you should use the getData function
>> 21 # or simply access with @ (for example gbm.data at Clinical)
>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>
>>
>>
>>
>>
>>
>> Genomic Analysis/Final data extraction:
>>
>> Enable ?getData? to access the data
>>
>> Obtaining GISTIC results?
>>
>> 1 # Download GISTIC results
>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>> 3
>> 4 # get GISTIC results
>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>
>> Repeat this procedure to obtain LGG GISTIC results.
>>
>> ***Please ignore the 'non-coded' text as they are procedural
>> steps/classifications***
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Mon Aug 27 02:22:38 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 20:22:38 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
Message-ID: <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>

 Thank you! I will make note of that. Unfortunately, lines 1 and 4 of the
first portion of this analysis appear to be where the error begins... to
which several subsequent lines also come up as ?errored?. Perhaps this is
an issue of the capitalization and/or spacing (something within the text)?
The proposed method for methylation data extraction is based on the first
third of the following TCGA workflow:
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308

Best,

Spencer Brackett












On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com> wrote:

> Hi Spencer.
>
> Should you capitalize the following library import?
>
> library(summarizedExperiment)
>
> In other words, I think that line should be:
>
> library(SummarizedExperiment)
>
> Hope this helps.
>
> ~Caitlin
>
>
>
>
> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Good evening,
>>
>>   I am attempting to run the following analysis on TCGA data, however
>> something is being reported as an error in my arguments... any ideas as to
>> what is incorrect in the following? Thanks!
>>
>> 1 library(TCGAbiolinks)
>> 2
>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> 4 path <? "."
>> 5
>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> level = 3)
>> 7 TCGAdownload(query.met, path = path )
>> 8 met <? TCGAprepare(query = query.met,dir = path,
>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>> 10                    summarizedExperiment = TRUE,
>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> 12
>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>> "IlluminaHiSeq_
>> RNASeqV2",level = 3)
>> 15
>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> results")
>> 17
>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> 19                    summarizedExperiment = TRUE,
>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>> 21                    type = "rsem.genes.normalized_results",
>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>
>> To download data on DNA methylation and gene expression?
>>
>> 1 library(summarizedExperiment)
>> 2 # get expression matrix
>> 3 data <? assay(exp)
>> 4
>> 5 # get sample information
>> 6 sample.info <? colData(exp)
>> 7
>> 8 # get genes information
>> 9 genes.info <? rowRanges(exp)
>>
>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>
>> 1 # get clinical patient data for GBM samples
>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>> 3
>> 4 # get clinical patient data for LGG samples
>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>> 6
>> 7 # Bind the results, as the columns might not be the same,
>> 8 # we will plyr rbind.fill , to have all columns from both files
>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>> 10
>> 11 # Other clinical files can be downloaded,
>> 12 # Use ?TCGAquery_clinic for more information
>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>> 14
>> 15 # Also, you can get clinical information from different tumor types.
>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>
>>
>> # Searching idat file for DNA methylation
>> query <- GDCquery(project = "TCGA-GBM",
>>                  data.category = "Raw microarray data",
>>                  data.type = "Raw intensities",
>>                  experimental.strategy = "Methylation array",
>>                  legacy = TRUE,
>>                  file.type = ".idat",
>>                  platform = "Illumina Human Methylation 450")
>>
>> **Repeat for LGG**
>>
>> To access mutational information concerning TMZ methylation?
>>
>> > mutation <? TCGAquery_maf(tumor = "lgg")
>> 2   Getting maf tables
>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>> 4   We found these maf files below:
>> 5       MAF.File.Name
>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>> 7
>> 8   3 LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>> 9
>> 10       Archive.Name Deploy.Date
>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>   10-DEC-13
>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>  24-DEC-14
>> 13
>> 14   Please, select the line that you want to download: 3
>>
>> **Repeat this for GBM***
>>
>> Selecting specified lines to download?
>>
>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>
>>
>>
>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>
>> library(RTCGAToolbox)
>> 2
>> 3 # Get the last run dates
>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>> 6
>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate = lastRunDate,
>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>> 11       Mutation = T,
>> 12       fileSizeLimit = 10000)
>> 13
>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>> 18       fileSizeLimit = 10000)
>> 19
>> 20 # To access the data you should use the getData function
>> 21 # or simply access with @ (for example gbm.data at Clinical)
>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>
>>
>>
>>
>>
>>
>> Genomic Analysis/Final data extraction:
>>
>> Enable ?getData? to access the data
>>
>> Obtaining GISTIC results?
>>
>> 1 # Download GISTIC results
>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>> 3
>> 4 # get GISTIC results
>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>
>> Repeat this procedure to obtain LGG GISTIC results.
>>
>> ***Please ignore the 'non-coded' text as they are procedural
>> steps/classifications***
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Mon Aug 27 02:34:13 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 20:34:13 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
Message-ID: <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>

Caitlin,

  Forgive me, but I?m not quite sure exactly what your question is asking.
The data is originally from the TCGA and I have it downloaded onto another
R script. I opened a new script to perform the functions I posted to this
forum because I was unable to input any other commands into the console....
due to the fact that the translated data filled the entirety of said
consule. Perhaps overloaded it? Regardless, I was unable to input any
further commands.

-Spencer Brackett


On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com> wrote:

> You're welcome Spencer :)
>
> The 4th line:
>
> path <? "."
>
> refers to the current directory (the dot in other words). Is the data
> stored in the same directory where the code is being run?
>
>
>
> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4 of the
>> first portion of this analysis appear to be where the error begins... to
>> which several subsequent lines also come up as ?errored?. Perhaps this is
>> an issue of the capitalization and/or spacing (something within the text)?
>> The proposed method for methylation data extraction is based on the first
>> third of the following TCGA workflow:
>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308
>>
>> Best,
>>
>> Spencer Brackett
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com> wrote:
>>
>>> Hi Spencer.
>>>
>>> Should you capitalize the following library import?
>>>
>>> library(summarizedExperiment)
>>>
>>> In other words, I think that line should be:
>>>
>>> library(SummarizedExperiment)
>>>
>>> Hope this helps.
>>>
>>> ~Caitlin
>>>
>>>
>>>
>>>
>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>>
>>>> Good evening,
>>>>
>>>>   I am attempting to run the following analysis on TCGA data, however
>>>> something is being reported as an error in my arguments... any ideas as
>>>> to
>>>> what is incorrect in the following? Thanks!
>>>>
>>>> 1 library(TCGAbiolinks)
>>>> 2
>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>>>> 4 path <? "."
>>>> 5
>>>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>>>> level = 3)
>>>> 7 TCGAdownload(query.met, path = path )
>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>> 10                    summarizedExperiment = TRUE,
>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>> 12
>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>> "IlluminaHiSeq_
>>>> RNASeqV2",level = 3)
>>>> 15
>>>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>>>> results")
>>>> 17
>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>> 19                    summarizedExperiment = TRUE,
>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>> 21                    type = "rsem.genes.normalized_results",
>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>
>>>> To download data on DNA methylation and gene expression?
>>>>
>>>> 1 library(summarizedExperiment)
>>>> 2 # get expression matrix
>>>> 3 data <? assay(exp)
>>>> 4
>>>> 5 # get sample information
>>>> 6 sample.info <? colData(exp)
>>>> 7
>>>> 8 # get genes information
>>>> 9 genes.info <? rowRanges(exp)
>>>>
>>>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>>>
>>>> 1 # get clinical patient data for GBM samples
>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>>>> 3
>>>> 4 # get clinical patient data for LGG samples
>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>>>> 6
>>>> 7 # Bind the results, as the columns might not be the same,
>>>> 8 # we will plyr rbind.fill , to have all columns from both files
>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>>>> 10
>>>> 11 # Other clinical files can be downloaded,
>>>> 12 # Use ?TCGAquery_clinic for more information
>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>>>> 14
>>>> 15 # Also, you can get clinical information from different tumor types.
>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>>>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>>>
>>>>
>>>> # Searching idat file for DNA methylation
>>>> query <- GDCquery(project = "TCGA-GBM",
>>>>                  data.category = "Raw microarray data",
>>>>                  data.type = "Raw intensities",
>>>>                  experimental.strategy = "Methylation array",
>>>>                  legacy = TRUE,
>>>>                  file.type = ".idat",
>>>>                  platform = "Illumina Human Methylation 450")
>>>>
>>>> **Repeat for LGG**
>>>>
>>>> To access mutational information concerning TMZ methylation?
>>>>
>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
>>>> 2   Getting maf tables
>>>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>>>> 4   We found these maf files below:
>>>> 5       MAF.File.Name
>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>>>> 7
>>>> 8   3
>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>>>> 9
>>>> 10       Archive.Name Deploy.Date
>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>>>   10-DEC-13
>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>>>  24-DEC-14
>>>> 13
>>>> 14   Please, select the line that you want to download: 3
>>>>
>>>> **Repeat this for GBM***
>>>>
>>>> Selecting specified lines to download?
>>>>
>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>>>
>>>>
>>>>
>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>>>
>>>> library(RTCGAToolbox)
>>>> 2
>>>> 3 # Get the last run dates
>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>>>> 6
>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
>>>> lastRunDate,
>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>>>> 11       Mutation = T,
>>>> 12       fileSizeLimit = 10000)
>>>> 13
>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>>>> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>>>> 18       fileSizeLimit = 10000)
>>>> 19
>>>> 20 # To access the data you should use the getData function
>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Genomic Analysis/Final data extraction:
>>>>
>>>> Enable ?getData? to access the data
>>>>
>>>> Obtaining GISTIC results?
>>>>
>>>> 1 # Download GISTIC results
>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>>>> 3
>>>> 4 # get GISTIC results
>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>>>
>>>> Repeat this procedure to obtain LGG GISTIC results.
>>>>
>>>> ***Please ignore the 'non-coded' text as they are procedural
>>>> steps/classifications***
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From bioprogr@mmer @ending from gm@il@com  Mon Aug 27 02:41:50 2018
From: bioprogr@mmer @ending from gm@il@com (Caitlin)
Date: Sun, 26 Aug 2018 17:41:50 -0700
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
 <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
Message-ID: <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>

No worries Spencer. There is no downloaded data? Nothing is physically
stored on your hard drive? The dot in the path would be interpreted (no pun
intended!) as something like the following:

If the TCGA data was stored in a file named "tcga_data.dat" and it was in a
directory named "C:\spencer", the 4th line of that script would set the
path to "C:\spencer\tcga_data.dat" if you ran the script from that same
folder. If your tcga data is not stored in the same file from which the
script is being ran, it won't find any data to work with. Does this help?


On Sun, Aug 26, 2018 at 5:34 PM Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Caitlin,
>
>   Forgive me, but I?m not quite sure exactly what your question is asking.
> The data is originally from the TCGA and I have it downloaded onto another
> R script. I opened a new script to perform the functions I posted to this
> forum because I was unable to input any other commands into the console....
> due to the fact that the translated data filled the entirety of said
> consule. Perhaps overloaded it? Regardless, I was unable to input any
> further commands.
>
> -Spencer Brackett
>
>
> On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com> wrote:
>
>> You're welcome Spencer :)
>>
>> The 4th line:
>>
>> path <? "."
>>
>> refers to the current directory (the dot in other words). Is the data
>> stored in the same directory where the code is being run?
>>
>>
>>
>> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>>
>>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4 of
>>> the first portion of this analysis appear to be where the error begins...
>>> to which several subsequent lines also come up as ?errored?. Perhaps this
>>> is an issue of the capitalization and/or spacing (something within the
>>> text)? The proposed method for methylation data extraction is based on the
>>> first third of the following TCGA workflow:
>>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308
>>>
>>> Best,
>>>
>>> Spencer Brackett
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com> wrote:
>>>
>>>> Hi Spencer.
>>>>
>>>> Should you capitalize the following library import?
>>>>
>>>> library(summarizedExperiment)
>>>>
>>>> In other words, I think that line should be:
>>>>
>>>> library(SummarizedExperiment)
>>>>
>>>> Hope this helps.
>>>>
>>>> ~Caitlin
>>>>
>>>>
>>>>
>>>>
>>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>
>>>>> Good evening,
>>>>>
>>>>>   I am attempting to run the following analysis on TCGA data, however
>>>>> something is being reported as an error in my arguments... any ideas
>>>>> as to
>>>>> what is incorrect in the following? Thanks!
>>>>>
>>>>> 1 library(TCGAbiolinks)
>>>>> 2
>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>>>>> 4 path <? "."
>>>>> 5
>>>>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>>>>> level = 3)
>>>>> 7 TCGAdownload(query.met, path = path )
>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>>> 10                    summarizedExperiment = TRUE,
>>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>>> 12
>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>>> "IlluminaHiSeq_
>>>>> RNASeqV2",level = 3)
>>>>> 15
>>>>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>>>>> results")
>>>>> 17
>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>>> 19                    summarizedExperiment = TRUE,
>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>>> 21                    type = "rsem.genes.normalized_results",
>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>>
>>>>> To download data on DNA methylation and gene expression?
>>>>>
>>>>> 1 library(summarizedExperiment)
>>>>> 2 # get expression matrix
>>>>> 3 data <? assay(exp)
>>>>> 4
>>>>> 5 # get sample information
>>>>> 6 sample.info <? colData(exp)
>>>>> 7
>>>>> 8 # get genes information
>>>>> 9 genes.info <? rowRanges(exp)
>>>>>
>>>>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>>>>
>>>>> 1 # get clinical patient data for GBM samples
>>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>>>>> 3
>>>>> 4 # get clinical patient data for LGG samples
>>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>>>>> 6
>>>>> 7 # Bind the results, as the columns might not be the same,
>>>>> 8 # we will plyr rbind.fill , to have all columns from both files
>>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>>>>> 10
>>>>> 11 # Other clinical files can be downloaded,
>>>>> 12 # Use ?TCGAquery_clinic for more information
>>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>>>>> 14
>>>>> 15 # Also, you can get clinical information from different tumor types.
>>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>>>>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>>>>
>>>>>
>>>>> # Searching idat file for DNA methylation
>>>>> query <- GDCquery(project = "TCGA-GBM",
>>>>>                  data.category = "Raw microarray data",
>>>>>                  data.type = "Raw intensities",
>>>>>                  experimental.strategy = "Methylation array",
>>>>>                  legacy = TRUE,
>>>>>                  file.type = ".idat",
>>>>>                  platform = "Illumina Human Methylation 450")
>>>>>
>>>>> **Repeat for LGG**
>>>>>
>>>>> To access mutational information concerning TMZ methylation?
>>>>>
>>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
>>>>> 2   Getting maf tables
>>>>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>>>>> 4   We found these maf files below:
>>>>> 5       MAF.File.Name
>>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>>>>> 7
>>>>> 8   3
>>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>>>>> 9
>>>>> 10       Archive.Name Deploy.Date
>>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>>>>   10-DEC-13
>>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>>>>  24-DEC-14
>>>>> 13
>>>>> 14   Please, select the line that you want to download: 3
>>>>>
>>>>> **Repeat this for GBM***
>>>>>
>>>>> Selecting specified lines to download?
>>>>>
>>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>>>>
>>>>>
>>>>>
>>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>>>>
>>>>> library(RTCGAToolbox)
>>>>> 2
>>>>> 3 # Get the last run dates
>>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>>>>> 6
>>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
>>>>> lastRunDate,
>>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>>>>> 11       Mutation = T,
>>>>> 12       fileSizeLimit = 10000)
>>>>> 13
>>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>>>>> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
>>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>>>>> 18       fileSizeLimit = 10000)
>>>>> 19
>>>>> 20 # To access the data you should use the getData function
>>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
>>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Genomic Analysis/Final data extraction:
>>>>>
>>>>> Enable ?getData? to access the data
>>>>>
>>>>> Obtaining GISTIC results?
>>>>>
>>>>> 1 # Download GISTIC results
>>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>>>>> 3
>>>>> 4 # get GISTIC results
>>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>>>>
>>>>> Repeat this procedure to obtain LGG GISTIC results.
>>>>>
>>>>> ***Please ignore the 'non-coded' text as they are procedural
>>>>> steps/classifications***
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Mon Aug 27 02:49:48 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 20:49:48 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
 <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
 <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>
Message-ID: <CAPQaxLOH8TDjhutsh5Ck9oWEz2zeR=_umMjFcYBWvxncL6FJew@mail.gmail.com>

Caitlin,

 Perhaps that is the problem. To be more specific, the data was transferred
from the TCGA database to a CSV file... there are technically two separate
files (CSV) for this analysis.... one for GBM and one for LGG. Both CVS
files were then individually downloaded onto my open R console. Upon
arranging them with the summary () function, the data expanded and took up
the whole console page... even seemingly abrogating the arguments which
allowed for the data to be downloaded onto R in the first place. Are you
suggesting that I would need to utilize a flash drive to successfully
utilize the function you suggested? Or could I perhaps do so with the CSV
field I mentioned? If so, how?

-Spencer B

On Sun, Aug 26, 2018 at 8:42 PM Caitlin <bioprogrammer at gmail.com> wrote:

> No worries Spencer. There is no downloaded data? Nothing is physically
> stored on your hard drive? The dot in the path would be interpreted (no pun
> intended!) as something like the following:
>
> If the TCGA data was stored in a file named "tcga_data.dat" and it was in
> a directory named "C:\spencer", the 4th line of that script would set the
> path to "C:\spencer\tcga_data.dat" if you ran the script from that same
> folder. If your tcga data is not stored in the same file from which the
> script is being ran, it won't find any data to work with. Does this help?
>
>
> On Sun, Aug 26, 2018 at 5:34 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Caitlin,
>>
>>   Forgive me, but I?m not quite sure exactly what your question is
>> asking. The data is originally from the TCGA and I have it downloaded onto
>> another R script. I opened a new script to perform the functions I posted
>> to this forum because I was unable to input any other commands into the
>> console.... due to the fact that the translated data filled the entirety of
>> said consule. Perhaps overloaded it? Regardless, I was unable to input any
>> further commands.
>>
>> -Spencer Brackett
>>
>>
>> On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com> wrote:
>>
>>> You're welcome Spencer :)
>>>
>>> The 4th line:
>>>
>>> path <? "."
>>>
>>> refers to the current directory (the dot in other words). Is the data
>>> stored in the same directory where the code is being run?
>>>
>>>
>>>
>>> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>>
>>>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4 of
>>>> the first portion of this analysis appear to be where the error begins...
>>>> to which several subsequent lines also come up as ?errored?. Perhaps this
>>>> is an issue of the capitalization and/or spacing (something within the
>>>> text)? The proposed method for methylation data extraction is based on the
>>>> first third of the following TCGA workflow:
>>>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308
>>>>
>>>> Best,
>>>>
>>>> Spencer Brackett
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Spencer.
>>>>>
>>>>> Should you capitalize the following library import?
>>>>>
>>>>> library(summarizedExperiment)
>>>>>
>>>>> In other words, I think that line should be:
>>>>>
>>>>> library(SummarizedExperiment)
>>>>>
>>>>> Hope this helps.
>>>>>
>>>>> ~Caitlin
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>
>>>>>> Good evening,
>>>>>>
>>>>>>   I am attempting to run the following analysis on TCGA data, however
>>>>>> something is being reported as an error in my arguments... any ideas
>>>>>> as to
>>>>>> what is incorrect in the following? Thanks!
>>>>>>
>>>>>> 1 library(TCGAbiolinks)
>>>>>> 2
>>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and
>>>>>> GBM.
>>>>>> 4 path <? "."
>>>>>> 5
>>>>>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>>>>>> level = 3)
>>>>>> 7 TCGAdownload(query.met, path = path )
>>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>>>> 10                    summarizedExperiment = TRUE,
>>>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>>>> 12
>>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>>>> "IlluminaHiSeq_
>>>>>> RNASeqV2",level = 3)
>>>>>> 15
>>>>>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>>>>>> results")
>>>>>> 17
>>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>>>> 19                    summarizedExperiment = TRUE,
>>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>>>> 21                    type = "rsem.genes.normalized_results",
>>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>>>
>>>>>> To download data on DNA methylation and gene expression?
>>>>>>
>>>>>> 1 library(summarizedExperiment)
>>>>>> 2 # get expression matrix
>>>>>> 3 data <? assay(exp)
>>>>>> 4
>>>>>> 5 # get sample information
>>>>>> 6 sample.info <? colData(exp)
>>>>>> 7
>>>>>> 8 # get genes information
>>>>>> 9 genes.info <? rowRanges(exp)
>>>>>>
>>>>>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>>>>>
>>>>>> 1 # get clinical patient data for GBM samples
>>>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>>>>>> 3
>>>>>> 4 # get clinical patient data for LGG samples
>>>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>>>>>> 6
>>>>>> 7 # Bind the results, as the columns might not be the same,
>>>>>> 8 # we will plyr rbind.fill , to have all columns from both files
>>>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>>>>>> 10
>>>>>> 11 # Other clinical files can be downloaded,
>>>>>> 12 # Use ?TCGAquery_clinic for more information
>>>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>>>>>> 14
>>>>>> 15 # Also, you can get clinical information from different tumor
>>>>>> types.
>>>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>>>>>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>>>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>>>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>>>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>>>>>
>>>>>>
>>>>>> # Searching idat file for DNA methylation
>>>>>> query <- GDCquery(project = "TCGA-GBM",
>>>>>>                  data.category = "Raw microarray data",
>>>>>>                  data.type = "Raw intensities",
>>>>>>                  experimental.strategy = "Methylation array",
>>>>>>                  legacy = TRUE,
>>>>>>                  file.type = ".idat",
>>>>>>                  platform = "Illumina Human Methylation 450")
>>>>>>
>>>>>> **Repeat for LGG**
>>>>>>
>>>>>> To access mutational information concerning TMZ methylation?
>>>>>>
>>>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
>>>>>> 2   Getting maf tables
>>>>>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>>>>>> 4   We found these maf files below:
>>>>>> 5       MAF.File.Name
>>>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>>>>>> 7
>>>>>> 8   3
>>>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>>>>>> 9
>>>>>> 10       Archive.Name Deploy.Date
>>>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>>>>>   10-DEC-13
>>>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>>>>>  24-DEC-14
>>>>>> 13
>>>>>> 14   Please, select the line that you want to download: 3
>>>>>>
>>>>>> **Repeat this for GBM***
>>>>>>
>>>>>> Selecting specified lines to download?
>>>>>>
>>>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>>>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>>>>>
>>>>>>
>>>>>>
>>>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>>>>>
>>>>>> library(RTCGAToolbox)
>>>>>> 2
>>>>>> 3 # Get the last run dates
>>>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>>>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>>>>>> 6
>>>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>>>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>>>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
>>>>>> lastRunDate,
>>>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>>>>>> 11       Mutation = T,
>>>>>> 12       fileSizeLimit = 10000)
>>>>>> 13
>>>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>>>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>>>>>> 16       runDate = lastDate, gistic2_Date =
>>>>>> getFirehoseAnalyzeDates(1),
>>>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>>>>>> 18       fileSizeLimit = 10000)
>>>>>> 19
>>>>>> 20 # To access the data you should use the getData function
>>>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
>>>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>>>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>>>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Genomic Analysis/Final data extraction:
>>>>>>
>>>>>> Enable ?getData? to access the data
>>>>>>
>>>>>> Obtaining GISTIC results?
>>>>>>
>>>>>> 1 # Download GISTIC results
>>>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>>>>>> 3
>>>>>> 4 # get GISTIC results
>>>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>>>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>>>>>
>>>>>> Repeat this procedure to obtain LGG GISTIC results.
>>>>>>
>>>>>> ***Please ignore the 'non-coded' text as they are procedural
>>>>>> steps/classifications***
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>

	[[alternative HTML version deleted]]


From erinm@hodge@@ @ending from gm@il@com  Mon Aug 27 04:40:15 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Sun, 26 Aug 2018 20:40:15 -0600
Subject: [R] Using a different compiler to create a package with source code
Message-ID: <CACxE24nCQ8AsREWvzZKvtHL=HR8LHC_=NRrryB4Y1NjKaZFMDQ@mail.gmail.com>

Hello!
I need to use the PGI compiler for a new package.  Should I ask here or the
development list, please?

Sorry for the airspace if I'm on the wrong list.

Thanks,
Erin


Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Aug 27 04:44:19 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 26 Aug 2018 19:44:19 -0700
Subject: [R] 
 Using a different compiler to create a package with source code
In-Reply-To: <CACxE24nCQ8AsREWvzZKvtHL=HR8LHC_=NRrryB4Y1NjKaZFMDQ@mail.gmail.com>
References: <CACxE24nCQ8AsREWvzZKvtHL=HR8LHC_=NRrryB4Y1NjKaZFMDQ@mail.gmail.com>
Message-ID: <2233319D-DDE5-4B64-B702-4893BE35B613@dcn.davis.ca.us>

Wrong list, though you will probably need to recompile R itself and every other package you want to use in conjunction with this special package in order to do this... and you may not find many or even any people interested in helping as a result.

On August 26, 2018 7:40:15 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello!
>I need to use the PGI compiler for a new package.  Should I ask here or
>the
>development list, please?
>
>Sorry for the airspace if I'm on the wrong list.
>
>Thanks,
>Erin
>
>
>Erin Hodgess, PhD
>mailto: erinm.hodgess at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From erinm@hodge@@ @ending from gm@il@com  Mon Aug 27 04:45:05 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Sun, 26 Aug 2018 20:45:05 -0600
Subject: [R] 
 Using a different compiler to create a package with source code
In-Reply-To: <2233319D-DDE5-4B64-B702-4893BE35B613@dcn.davis.ca.us>
References: <CACxE24nCQ8AsREWvzZKvtHL=HR8LHC_=NRrryB4Y1NjKaZFMDQ@mail.gmail.com>
 <2233319D-DDE5-4B64-B702-4893BE35B613@dcn.davis.ca.us>
Message-ID: <CACxE24k=2ztX_YA5M0VOWCuQMSHCtSoMTsENyXzi+Gpj1AErfA@mail.gmail.com>

OK.  Thanks for the info!

Sincerely,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Sun, Aug 26, 2018 at 8:44 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Wrong list, though you will probably need to recompile R itself and every
> other package you want to use in conjunction with this special package in
> order to do this... and you may not find many or even any people interested
> in helping as a result.
>
> On August 26, 2018 7:40:15 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >Hello!
> >I need to use the PGI compiler for a new package.  Should I ask here or
> >the
> >development list, please?
> >
> >Sorry for the airspace if I'm on the wrong list.
> >
> >Thanks,
> >Erin
> >
> >
> >Erin Hodgess, PhD
> >mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Mon Aug 27 05:49:23 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 23:49:23 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CABDKo+yuFT=V41jzwyUD9ACskUfhaA9inChZbR+a-O3Cz_PoNQ@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
 <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
 <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>
 <CAPQaxLOH8TDjhutsh5Ck9oWEz2zeR=_umMjFcYBWvxncL6FJew@mail.gmail.com>
 <CABDKo+wmSAMqP=ERvoAz1AZrj0p+jZhhYCoFohNkGcT81Zecvw@mail.gmail.com>
 <CAPQaxLP0LZOsXC4L4WF4DVFC=mvr=cKHs2KQAe0YXWJUHAsDEg@mail.gmail.com>
 <CABDKo+yuFT=V41jzwyUD9ACskUfhaA9inChZbR+a-O3Cz_PoNQ@mail.gmail.com>
Message-ID: <CAPQaxLPC+natdQ=rwfKkmdq=CK=Aw9-M-Nn71=bvDRZaZudyZA@mail.gmail.com>

Hello all,

  To begin my analysis, I downloaded two TCGA datasets (GBM and LGG), both
csv files, onto on r script after loading the cBioLite package. Following
this, I inputted the following argument...

> the_data<-read.csv(file=?c:/file_name.csv,header=TRUE,sep=?,?)

Upon running the line I received this...

+

If continue to press enter, the + sign continues to appear on every
subsequent/new line.

Does anyone know what this is indicative of and how I may continue on with
my analysis

My next step after this would have been the following (the numbers before
each command being line markers; not part of line)..

1 library(TCGAbiolinks)
2
3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
4 path <? "."

Best wishes,

Spencer Brackett

On Sun, Aug 26, 2018 at 9:13 PM Caitlin <bioprogrammer at gmail.com> wrote:

> You're welcome Spencer :)
>
> I hope I was able to help you. If this problem persists, or a new one
> appears, feel free to post or email. You might also like:
>
> https://www.biostars.org/
>
> It is quite similar to StackOverflow but with a biological sciences focus.
>
> Hope this helps!
>
> ~Caitlin
>
>
>
> On Sun, Aug 26, 2018 at 6:02 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Caitlin,
>>
>>  Thanks again! I already have the two files stored in those two CSV files
>> via my desktop, but if tuning those with this function do not work, then I
>> will try it with a flash drive.
>>
>> Best,
>>
>> Spencer Brackett
>>
>> On Sun, Aug 26, 2018 at 8:56 PM Caitlin <bioprogrammer at gmail.com> wrote:
>>
>>> Hmm...could you store each in its own file (a flash drive would be fine)
>>> then use:
>>>
>>> the_data <- read.csv(file="c:/file_name.csv", header=TRUE, sep=",")
>>>
>>> to read each into your script? The data would then exist as a dataframe object that you could then work with.
>>>
>>>
>>> On Sun, Aug 26, 2018 at 5:50 PM Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>>
>>>> Caitlin,
>>>>
>>>>  Perhaps that is the problem. To be more specific, the data was
>>>> transferred from the TCGA database to a CSV file... there are technically
>>>> two separate files (CSV) for this analysis.... one for GBM and one for LGG.
>>>> Both CVS files were then individually downloaded onto my open R console.
>>>> Upon arranging them with the summary () function, the data expanded and
>>>> took up the whole console page... even seemingly abrogating the arguments
>>>> which allowed for the data to be downloaded onto R in the first place. Are
>>>> you suggesting that I would need to utilize a flash drive to successfully
>>>> utilize the function you suggested? Or could I perhaps do so with the CSV
>>>> field I mentioned? If so, how?
>>>>
>>>> -Spencer B
>>>>
>>>> On Sun, Aug 26, 2018 at 8:42 PM Caitlin <bioprogrammer at gmail.com>
>>>> wrote:
>>>>
>>>>> No worries Spencer. There is no downloaded data? Nothing is physically
>>>>> stored on your hard drive? The dot in the path would be interpreted (no pun
>>>>> intended!) as something like the following:
>>>>>
>>>>> If the TCGA data was stored in a file named "tcga_data.dat" and it was
>>>>> in a directory named "C:\spencer", the 4th line of that script would set
>>>>> the path to "C:\spencer\tcga_data.dat" if you ran the script from that same
>>>>> folder. If your tcga data is not stored in the same file from which the
>>>>> script is being ran, it won't find any data to work with. Does this help?
>>>>>
>>>>>
>>>>> On Sun, Aug 26, 2018 at 5:34 PM Spencer Brackett <
>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>
>>>>>> Caitlin,
>>>>>>
>>>>>>   Forgive me, but I?m not quite sure exactly what your question is
>>>>>> asking. The data is originally from the TCGA and I have it downloaded onto
>>>>>> another R script. I opened a new script to perform the functions I posted
>>>>>> to this forum because I was unable to input any other commands into the
>>>>>> console.... due to the fact that the translated data filled the entirety of
>>>>>> said consule. Perhaps overloaded it? Regardless, I was unable to input any
>>>>>> further commands.
>>>>>>
>>>>>> -Spencer Brackett
>>>>>>
>>>>>>
>>>>>> On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> You're welcome Spencer :)
>>>>>>>
>>>>>>> The 4th line:
>>>>>>>
>>>>>>> path <? "."
>>>>>>>
>>>>>>> refers to the current directory (the dot in other words). Is the
>>>>>>> data stored in the same directory where the code is being run?
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>>>
>>>>>>>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4
>>>>>>>> of the first portion of this analysis appear to be where the error
>>>>>>>> begins... to which several subsequent lines also come up as ?errored?.
>>>>>>>> Perhaps this is an issue of the capitalization and/or spacing (something
>>>>>>>> within the text)? The proposed method for methylation data extraction is
>>>>>>>> based on the first third of the following TCGA workflow:
>>>>>>>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308
>>>>>>>>
>>>>>>>> Best,
>>>>>>>>
>>>>>>>> Spencer Brackett
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>> Hi Spencer.
>>>>>>>>>
>>>>>>>>> Should you capitalize the following library import?
>>>>>>>>>
>>>>>>>>> library(summarizedExperiment)
>>>>>>>>>
>>>>>>>>> In other words, I think that line should be:
>>>>>>>>>
>>>>>>>>> library(SummarizedExperiment)
>>>>>>>>>
>>>>>>>>> Hope this helps.
>>>>>>>>>
>>>>>>>>> ~Caitlin
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
>>>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>>>>>
>>>>>>>>>> Good evening,
>>>>>>>>>>
>>>>>>>>>>   I am attempting to run the following analysis on TCGA data,
>>>>>>>>>> however
>>>>>>>>>> something is being reported as an error in my arguments... any
>>>>>>>>>> ideas as to
>>>>>>>>>> what is incorrect in the following? Thanks!
>>>>>>>>>>
>>>>>>>>>> 1 library(TCGAbiolinks)
>>>>>>>>>> 2
>>>>>>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG
>>>>>>>>>> and GBM.
>>>>>>>>>> 4 path <? "."
>>>>>>>>>> 5
>>>>>>>>>> 6 query.met <? TCGAquery(tumor =
>>>>>>>>>> c("LGG","GBM"),"HumanMethylation450",
>>>>>>>>>> level = 3)
>>>>>>>>>> 7 TCGAdownload(query.met, path = path )
>>>>>>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>>>>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>>>>>>>> 10                    summarizedExperiment = TRUE,
>>>>>>>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>>>>>>>> 12
>>>>>>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and
>>>>>>>>>> GBM.
>>>>>>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>>>>>>>> "IlluminaHiSeq_
>>>>>>>>>> RNASeqV2",level = 3)
>>>>>>>>>> 15
>>>>>>>>>> 16 TCGAdownload(query.exp,path = path, type =
>>>>>>>>>> "rsem.genes.normalized_
>>>>>>>>>> results")
>>>>>>>>>> 17
>>>>>>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>>>>>>>> 19                    summarizedExperiment = TRUE,
>>>>>>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>>>>>>>> 21                    type = "rsem.genes.normalized_results",
>>>>>>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>>>>>>>
>>>>>>>>>> To download data on DNA methylation and gene expression?
>>>>>>>>>>
>>>>>>>>>> 1 library(summarizedExperiment)
>>>>>>>>>> 2 # get expression matrix
>>>>>>>>>> 3 data <? assay(exp)
>>>>>>>>>> 4
>>>>>>>>>> 5 # get sample information
>>>>>>>>>> 6 sample.info <? colData(exp)
>>>>>>>>>> 7
>>>>>>>>>> 8 # get genes information
>>>>>>>>>> 9 genes.info <? rowRanges(exp)
>>>>>>>>>>
>>>>>>>>>> Following stepwise procedure for obtaining GBM and LGG clinical
>>>>>>>>>> data?
>>>>>>>>>>
>>>>>>>>>> 1 # get clinical patient data for GBM samples
>>>>>>>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>>>>>>>>>> 3
>>>>>>>>>> 4 # get clinical patient data for LGG samples
>>>>>>>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>>>>>>>>>> 6
>>>>>>>>>> 7 # Bind the results, as the columns might not be the same,
>>>>>>>>>> 8 # we will plyr rbind.fill , to have all columns from both files
>>>>>>>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>>>>>>>>>> 10
>>>>>>>>>> 11 # Other clinical files can be downloaded,
>>>>>>>>>> 12 # Use ?TCGAquery_clinic for more information
>>>>>>>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>>>>>>>>>> 14
>>>>>>>>>> 15 # Also, you can get clinical information from different tumor
>>>>>>>>>> types.
>>>>>>>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>>>>>>>>>> 17 data <? TCGAquery_clinic(clinical_data_type =
>>>>>>>>>> "clinical_patient",
>>>>>>>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>>>>>>>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>>>>>>>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> # Searching idat file for DNA methylation
>>>>>>>>>> query <- GDCquery(project = "TCGA-GBM",
>>>>>>>>>>                  data.category = "Raw microarray data",
>>>>>>>>>>                  data.type = "Raw intensities",
>>>>>>>>>>                  experimental.strategy = "Methylation array",
>>>>>>>>>>                  legacy = TRUE,
>>>>>>>>>>                  file.type = ".idat",
>>>>>>>>>>                  platform = "Illumina Human Methylation 450")
>>>>>>>>>>
>>>>>>>>>> **Repeat for LGG**
>>>>>>>>>>
>>>>>>>>>> To access mutational information concerning TMZ methylation?
>>>>>>>>>>
>>>>>>>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
>>>>>>>>>> 2   Getting maf tables
>>>>>>>>>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>>>>>>>>>> 4   We found these maf files below:
>>>>>>>>>> 5       MAF.File.Name
>>>>>>>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>>>>>>>>>> 7
>>>>>>>>>> 8   3
>>>>>>>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>>>>>>>>>> 9
>>>>>>>>>> 10       Archive.Name Deploy.Date
>>>>>>>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>>>>>>>>>   10-DEC-13
>>>>>>>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>>>>>>>>>  24-DEC-14
>>>>>>>>>> 13
>>>>>>>>>> 14   Please, select the line that you want to download: 3
>>>>>>>>>>
>>>>>>>>>> **Repeat this for GBM***
>>>>>>>>>>
>>>>>>>>>> Selecting specified lines to download?
>>>>>>>>>>
>>>>>>>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>>>>>>>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>>>>>>>>>
>>>>>>>>>> library(RTCGAToolbox)
>>>>>>>>>> 2
>>>>>>>>>> 3 # Get the last run dates
>>>>>>>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>>>>>>>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>>>>>>>>>> 6
>>>>>>>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>>>>>>>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>>>>>>>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
>>>>>>>>>> lastRunDate,
>>>>>>>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic =
>>>>>>>>>> TRUE,
>>>>>>>>>> 11       Mutation = T,
>>>>>>>>>> 12       fileSizeLimit = 10000)
>>>>>>>>>> 13
>>>>>>>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>>>>>>>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>>>>>>>>>> 16       runDate = lastDate, gistic2_Date =
>>>>>>>>>> getFirehoseAnalyzeDates(1),
>>>>>>>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm =
>>>>>>>>>> TRUE,
>>>>>>>>>> 18       fileSizeLimit = 10000)
>>>>>>>>>> 19
>>>>>>>>>> 20 # To access the data you should use the getData function
>>>>>>>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
>>>>>>>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>>>>>>>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>>>>>>>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Genomic Analysis/Final data extraction:
>>>>>>>>>>
>>>>>>>>>> Enable ?getData? to access the data
>>>>>>>>>>
>>>>>>>>>> Obtaining GISTIC results?
>>>>>>>>>>
>>>>>>>>>> 1 # Download GISTIC results
>>>>>>>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>>>>>>>>>> 3
>>>>>>>>>> 4 # get GISTIC results
>>>>>>>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>>>>>>>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>>>>>>>>>
>>>>>>>>>> Repeat this procedure to obtain LGG GISTIC results.
>>>>>>>>>>
>>>>>>>>>> ***Please ignore the 'non-coded' text as they are procedural
>>>>>>>>>> steps/classifications***
>>>>>>>>>>
>>>>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>>>
>>>>>>>>>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Mon Aug 27 08:32:40 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 27 Aug 2018 09:32:40 +0300
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CAPQaxLPC+natdQ=rwfKkmdq=CK=Aw9-M-Nn71=bvDRZaZudyZA@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
 <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
 <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>
 <CAPQaxLOH8TDjhutsh5Ck9oWEz2zeR=_umMjFcYBWvxncL6FJew@mail.gmail.com>
 <CABDKo+wmSAMqP=ERvoAz1AZrj0p+jZhhYCoFohNkGcT81Zecvw@mail.gmail.com>
 <CAPQaxLP0LZOsXC4L4WF4DVFC=mvr=cKHs2KQAe0YXWJUHAsDEg@mail.gmail.com>
 <CABDKo+yuFT=V41jzwyUD9ACskUfhaA9inChZbR+a-O3Cz_PoNQ@mail.gmail.com>
 <CAPQaxLPC+natdQ=rwfKkmdq=CK=Aw9-M-Nn71=bvDRZaZudyZA@mail.gmail.com>
Message-ID: <CAGgJW76vc_TKJrxmxTPDrp03CZqS-vWZxwmZ+JvPPJ2n496v5Q@mail.gmail.com>

Your problem is that the command you entered

> the_data<-read.csv(file=?c:/file_name.csv,header=TRUE,sep=?,?)

is missing a double quote after the .csv. The statement should be

> the_data<-read.csv(file=?c:/file_name.csv",header=TRUE,sep=?,?)

The '+' sign is a prompt from R that indicates it has not yet seen the end
of a statement, and it is expecting you to continue from the previous line.

The explanation: you are supplying the read.csv() function three arguments,
one each for the parameters 'file', 'header' and 'sep'.
The parameters 'file' and 'sep' are expecting strings as arguments, such as
"c:/file_name.csv" or "c:/myspecialdata.csv".
The parameter 'sep' (for separator) indicates that the separator is a comma.
Note that you could also have written

> the_data<-read.csv(file=?c:/file_name.csv")

as the default values for the parameter 'header' is TRUE, and for the
parameter 'sep' is comma.
You can confirm this by looking at the help via

> ?read.csv

HTH,
Eric


On Mon, Aug 27, 2018 at 6:49 AM, Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Hello all,
>
>   To begin my analysis, I downloaded two TCGA datasets (GBM and LGG), both
> csv files, onto on r script after loading the cBioLite package. Following
> this, I inputted the following argument...
>
> > the_data<-read.csv(file=?c:/file_name.csv,header=TRUE,sep=?,?)
>
> Upon running the line I received this...
>
> +
>
> If continue to press enter, the + sign continues to appear on every
> subsequent/new line.
>
> Does anyone know what this is indicative of and how I may continue on with
> my analysis
>
> My next step after this would have been the following (the numbers before
> each command being line markers; not part of line)..
>
> 1 library(TCGAbiolinks)
> 2
> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> 4 path <? "."
>
> Best wishes,
>
> Spencer Brackett
>
> On Sun, Aug 26, 2018 at 9:13 PM Caitlin <bioprogrammer at gmail.com> wrote:
>
> > You're welcome Spencer :)
> >
> > I hope I was able to help you. If this problem persists, or a new one
> > appears, feel free to post or email. You might also like:
> >
> > https://www.biostars.org/
> >
> > It is quite similar to StackOverflow but with a biological sciences
> focus.
> >
> > Hope this helps!
> >
> > ~Caitlin
> >
> >
> >
> > On Sun, Aug 26, 2018 at 6:02 PM Spencer Brackett <
> > spbrackett20 at saintjosephhs.com> wrote:
> >
> >> Caitlin,
> >>
> >>  Thanks again! I already have the two files stored in those two CSV
> files
> >> via my desktop, but if tuning those with this function do not work,
> then I
> >> will try it with a flash drive.
> >>
> >> Best,
> >>
> >> Spencer Brackett
> >>
> >> On Sun, Aug 26, 2018 at 8:56 PM Caitlin <bioprogrammer at gmail.com>
> wrote:
> >>
> >>> Hmm...could you store each in its own file (a flash drive would be
> fine)
> >>> then use:
> >>>
> >>> the_data <- read.csv(file="c:/file_name.csv", header=TRUE, sep=",")
> >>>
> >>> to read each into your script? The data would then exist as a
> dataframe object that you could then work with.
> >>>
> >>>
> >>> On Sun, Aug 26, 2018 at 5:50 PM Spencer Brackett <
> >>> spbrackett20 at saintjosephhs.com> wrote:
> >>>
> >>>> Caitlin,
> >>>>
> >>>>  Perhaps that is the problem. To be more specific, the data was
> >>>> transferred from the TCGA database to a CSV file... there are
> technically
> >>>> two separate files (CSV) for this analysis.... one for GBM and one
> for LGG.
> >>>> Both CVS files were then individually downloaded onto my open R
> console.
> >>>> Upon arranging them with the summary () function, the data expanded
> and
> >>>> took up the whole console page... even seemingly abrogating the
> arguments
> >>>> which allowed for the data to be downloaded onto R in the first
> place. Are
> >>>> you suggesting that I would need to utilize a flash drive to
> successfully
> >>>> utilize the function you suggested? Or could I perhaps do so with the
> CSV
> >>>> field I mentioned? If so, how?
> >>>>
> >>>> -Spencer B
> >>>>
> >>>> On Sun, Aug 26, 2018 at 8:42 PM Caitlin <bioprogrammer at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> No worries Spencer. There is no downloaded data? Nothing is
> physically
> >>>>> stored on your hard drive? The dot in the path would be interpreted
> (no pun
> >>>>> intended!) as something like the following:
> >>>>>
> >>>>> If the TCGA data was stored in a file named "tcga_data.dat" and it
> was
> >>>>> in a directory named "C:\spencer", the 4th line of that script would
> set
> >>>>> the path to "C:\spencer\tcga_data.dat" if you ran the script from
> that same
> >>>>> folder. If your tcga data is not stored in the same file from which
> the
> >>>>> script is being ran, it won't find any data to work with. Does this
> help?
> >>>>>
> >>>>>
> >>>>> On Sun, Aug 26, 2018 at 5:34 PM Spencer Brackett <
> >>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>
> >>>>>> Caitlin,
> >>>>>>
> >>>>>>   Forgive me, but I?m not quite sure exactly what your question is
> >>>>>> asking. The data is originally from the TCGA and I have it
> downloaded onto
> >>>>>> another R script. I opened a new script to perform the functions I
> posted
> >>>>>> to this forum because I was unable to input any other commands into
> the
> >>>>>> console.... due to the fact that the translated data filled the
> entirety of
> >>>>>> said consule. Perhaps overloaded it? Regardless, I was unable to
> input any
> >>>>>> further commands.
> >>>>>>
> >>>>>> -Spencer Brackett
> >>>>>>
> >>>>>>
> >>>>>> On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> You're welcome Spencer :)
> >>>>>>>
> >>>>>>> The 4th line:
> >>>>>>>
> >>>>>>> path <? "."
> >>>>>>>
> >>>>>>> refers to the current directory (the dot in other words). Is the
> >>>>>>> data stored in the same directory where the code is being run?
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
> >>>>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>>>
> >>>>>>>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4
> >>>>>>>> of the first portion of this analysis appear to be where the error
> >>>>>>>> begins... to which several subsequent lines also come up as
> ?errored?.
> >>>>>>>> Perhaps this is an issue of the capitalization and/or spacing
> (something
> >>>>>>>> within the text)? The proposed method for methylation data
> extraction is
> >>>>>>>> based on the first third of the following TCGA workflow:
> >>>>>>>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=
> 0.0715308
> >>>>>>>>
> >>>>>>>> Best,
> >>>>>>>>
> >>>>>>>> Spencer Brackett
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com>
> >>>>>>>> wrote:
> >>>>>>>>
> >>>>>>>>> Hi Spencer.
> >>>>>>>>>
> >>>>>>>>> Should you capitalize the following library import?
> >>>>>>>>>
> >>>>>>>>> library(summarizedExperiment)
> >>>>>>>>>
> >>>>>>>>> In other words, I think that line should be:
> >>>>>>>>>
> >>>>>>>>> library(SummarizedExperiment)
> >>>>>>>>>
> >>>>>>>>> Hope this helps.
> >>>>>>>>>
> >>>>>>>>> ~Caitlin
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
> >>>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>>>>>
> >>>>>>>>>> Good evening,
> >>>>>>>>>>
> >>>>>>>>>>   I am attempting to run the following analysis on TCGA data,
> >>>>>>>>>> however
> >>>>>>>>>> something is being reported as an error in my arguments... any
> >>>>>>>>>> ideas as to
> >>>>>>>>>> what is incorrect in the following? Thanks!
> >>>>>>>>>>
> >>>>>>>>>> 1 library(TCGAbiolinks)
> >>>>>>>>>> 2
> >>>>>>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG
> >>>>>>>>>> and GBM.
> >>>>>>>>>> 4 path <? "."
> >>>>>>>>>> 5
> >>>>>>>>>> 6 query.met <? TCGAquery(tumor =
> >>>>>>>>>> c("LGG","GBM"),"HumanMethylation450",
> >>>>>>>>>> level = 3)
> >>>>>>>>>> 7 TCGAdownload(query.met, path = path )
> >>>>>>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
> >>>>>>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
> >>>>>>>>>> 10                    summarizedExperiment = TRUE,
> >>>>>>>>>> 11                      save = TRUE, filename =
> "lgg_gbm_met.rda")
> >>>>>>>>>> 12
> >>>>>>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG
> and
> >>>>>>>>>> GBM.
> >>>>>>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> >>>>>>>>>> "IlluminaHiSeq_
> >>>>>>>>>> RNASeqV2",level = 3)
> >>>>>>>>>> 15
> >>>>>>>>>> 16 TCGAdownload(query.exp,path = path, type =
> >>>>>>>>>> "rsem.genes.normalized_
> >>>>>>>>>> results")
> >>>>>>>>>> 17
> >>>>>>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
> >>>>>>>>>> 19                    summarizedExperiment = TRUE,
> >>>>>>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
> >>>>>>>>>> 21                    type = "rsem.genes.normalized_results",
> >>>>>>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
> >>>>>>>>>>
> >>>>>>>>>> To download data on DNA methylation and gene expression?
> >>>>>>>>>>
> >>>>>>>>>> 1 library(summarizedExperiment)
> >>>>>>>>>> 2 # get expression matrix
> >>>>>>>>>> 3 data <? assay(exp)
> >>>>>>>>>> 4
> >>>>>>>>>> 5 # get sample information
> >>>>>>>>>> 6 sample.info <? colData(exp)
> >>>>>>>>>> 7
> >>>>>>>>>> 8 # get genes information
> >>>>>>>>>> 9 genes.info <? rowRanges(exp)
> >>>>>>>>>>
> >>>>>>>>>> Following stepwise procedure for obtaining GBM and LGG clinical
> >>>>>>>>>> data?
> >>>>>>>>>>
> >>>>>>>>>> 1 # get clinical patient data for GBM samples
> >>>>>>>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
> >>>>>>>>>> 3
> >>>>>>>>>> 4 # get clinical patient data for LGG samples
> >>>>>>>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
> >>>>>>>>>> 6
> >>>>>>>>>> 7 # Bind the results, as the columns might not be the same,
> >>>>>>>>>> 8 # we will plyr rbind.fill , to have all columns from both
> files
> >>>>>>>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
> >>>>>>>>>> 10
> >>>>>>>>>> 11 # Other clinical files can be downloaded,
> >>>>>>>>>> 12 # Use ?TCGAquery_clinic for more information
> >>>>>>>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","
> clinical_radiation")
> >>>>>>>>>> 14
> >>>>>>>>>> 15 # Also, you can get clinical information from different tumor
> >>>>>>>>>> types.
> >>>>>>>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
> >>>>>>>>>> 17 data <? TCGAquery_clinic(clinical_data_type =
> >>>>>>>>>> "clinical_patient",
> >>>>>>>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
> >>>>>>>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
> >>>>>>>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> # Searching idat file for DNA methylation
> >>>>>>>>>> query <- GDCquery(project = "TCGA-GBM",
> >>>>>>>>>>                  data.category = "Raw microarray data",
> >>>>>>>>>>                  data.type = "Raw intensities",
> >>>>>>>>>>                  experimental.strategy = "Methylation array",
> >>>>>>>>>>                  legacy = TRUE,
> >>>>>>>>>>                  file.type = ".idat",
> >>>>>>>>>>                  platform = "Illumina Human Methylation 450")
> >>>>>>>>>>
> >>>>>>>>>> **Repeat for LGG**
> >>>>>>>>>>
> >>>>>>>>>> To access mutational information concerning TMZ methylation?
> >>>>>>>>>>
> >>>>>>>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
> >>>>>>>>>> 2   Getting maf tables
> >>>>>>>>>> 3   Source: https://wiki.nci.nih.gov/
> display/TCGA/TCGA+MAF+Files
> >>>>>>>>>> 4   We found these maf files below:
> >>>>>>>>>> 5       MAF.File.Name
> >>>>>>>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_
> DNASeq.1.somatic.maf
> >>>>>>>>>> 7
> >>>>>>>>>> 8   3
> >>>>>>>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.
> somatic.maf
> >>>>>>>>>> 9
> >>>>>>>>>> 10       Archive.Name Deploy.Date
> >>>>>>>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_
> DNASeq_automated.Level_2.1.0.0
> >>>>>>>>>>   10-DEC-13
> >>>>>>>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_
> DNASeq_curated.Level_2.1.3.0
> >>>>>>>>>>  24-DEC-14
> >>>>>>>>>> 13
> >>>>>>>>>> 14   Please, select the line that you want to download: 3
> >>>>>>>>>>
> >>>>>>>>>> **Repeat this for GBM***
> >>>>>>>>>>
> >>>>>>>>>> Selecting specified lines to download?
> >>>>>>>>>>
> >>>>>>>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
> >>>>>>>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
> >>>>>>>>>>
> >>>>>>>>>> library(RTCGAToolbox)
> >>>>>>>>>> 2
> >>>>>>>>>> 3 # Get the last run dates
> >>>>>>>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
> >>>>>>>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
> >>>>>>>>>> 6
> >>>>>>>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
> >>>>>>>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
> >>>>>>>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
> >>>>>>>>>> lastRunDate,
> >>>>>>>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic =
> >>>>>>>>>> TRUE,
> >>>>>>>>>> 11       Mutation = T,
> >>>>>>>>>> 12       fileSizeLimit = 10000)
> >>>>>>>>>> 13
> >>>>>>>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
> >>>>>>>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
> >>>>>>>>>> 16       runDate = lastDate, gistic2_Date =
> >>>>>>>>>> getFirehoseAnalyzeDates(1),
> >>>>>>>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm =
> >>>>>>>>>> TRUE,
> >>>>>>>>>> 18       fileSizeLimit = 10000)
> >>>>>>>>>> 19
> >>>>>>>>>> 20 # To access the data you should use the getData function
> >>>>>>>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
> >>>>>>>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
> >>>>>>>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
> >>>>>>>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> Genomic Analysis/Final data extraction:
> >>>>>>>>>>
> >>>>>>>>>> Enable ?getData? to access the data
> >>>>>>>>>>
> >>>>>>>>>> Obtaining GISTIC results?
> >>>>>>>>>>
> >>>>>>>>>> 1 # Download GISTIC results
> >>>>>>>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
> >>>>>>>>>> 3
> >>>>>>>>>> 4 # get GISTIC results
> >>>>>>>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
> >>>>>>>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
> >>>>>>>>>>
> >>>>>>>>>> Repeat this procedure to obtain LGG GISTIC results.
> >>>>>>>>>>
> >>>>>>>>>> ***Please ignore the 'non-coded' text as they are procedural
> >>>>>>>>>> steps/classifications***
> >>>>>>>>>>
> >>>>>>>>>>         [[alternative HTML version deleted]]
> >>>>>>>>>>
> >>>>>>>>>> ______________________________________________
> >>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >>>>>>>>>>
> >>>>>>>>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Mon Aug 27 11:01:40 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 27 Aug 2018 09:01:40 +0000
Subject: [R] NaN in Scoring Sentiment
In-Reply-To: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
References: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
Message-ID: <8444c6baab4642d8bdf8bfcfe4761db3@SRVEXCHCM1302.precheza.cz>

Hi

the output seems to me rather weird. Unles you have NaNs in input data frame you should not get NaN as a result.

Anyway, your aggregate will give you NA or NaN even when there is only one NA or NaN in your input data frame. So I suggest to use

sentiments_per_Category <- aggregate(relative_sentiment_frequencies,                                      by = list(Category = df$Case.Category), mean, na.rm=TRUE)

This should strip all NAs before calculating mean in each category.

Complete cases removes all lines with at least one NA in your data frame, which probably results to empty data frame.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Shivi Bhatia
> Sent: Saturday, August 25, 2018 4:01 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] NaN in Scoring Sentiment
>
> Hi All- I am running a sentiment scoring model and the code is as below:
> sentiments_per_Category <- aggregate(relative_sentiment_frequencies,
>                                      by = list(Category = df$Case.Category), mean)
>
> while i run the head command most of the values are NaN. i then used
> complete.cases on my data frame df[complete.cases(df),]  but it does not seems
> to work. Please advice if there is a way to handle NaN.
>
> Regards, Shivi
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From @hivipmp82 @ending from gm@il@com  Mon Aug 27 12:31:03 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Mon, 27 Aug 2018 10:31:03 +0000 (UTC)
Subject: [R] NaN in Scoring Sentiment
In-Reply-To: <8444c6baab4642d8bdf8bfcfe4761db3@SRVEXCHCM1302.precheza.cz>
References: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
 <8444c6baab4642d8bdf8bfcfe4761db3@SRVEXCHCM1302.precheza.cz>
Message-ID: <304559663.3649674.1535365863210@mail.yahoo.com>

Thanks you Petr. This worked.?
Regards, Shivi?


Sent from Yahoo Mail for iPhone


On Monday, August 27, 2018, 14:31, PIKAL Petr <petr.pikal at precheza.cz> wrote:

Hi

the output seems to me rather weird. Unles you have NaNs in input data frame you should not get NaN as a result.

Anyway, your aggregate will give you NA or NaN even when there is only one NA or NaN in your input data frame. So I suggest to use

sentiments_per_Category <- aggregate(relative_sentiment_frequencies,? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? by = list(Category = df$Case.Category), mean, na.rm=TRUE)

This should strip all NAs before calculating mean in each category.

Complete cases removes all lines with at least one NA in your data frame, which probably results to empty data frame.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Shivi Bhatia
> Sent: Saturday, August 25, 2018 4:01 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] NaN in Scoring Sentiment
>
> Hi All- I am running a sentiment scoring model and the code is as below:
> sentiments_per_Category <- aggregate(relative_sentiment_frequencies,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? by = list(Category = df$Case.Category), mean)
>
> while i run the head command most of the values are NaN. i then used
> complete.cases on my data frame df[complete.cases(df),]? but it does not seems
> to work. Please advice if there is a way to handle NaN.
>
> Regards, Shivi
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/





	[[alternative HTML version deleted]]


From krylov@r00t @ending from gm@il@com  Mon Aug 27 18:25:08 2018
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Mon, 27 Aug 2018 19:25:08 +0300
Subject: [R] "use of NULL environment is defunct" when trying to lock a
 reference class
Message-ID: <20180827192508.325baf02@trisector>

Hi!

I'm trying to create a persistent memoising class with a destructor and
an option to evaluate cache misses in parallel. I want to lock all
its fields because it doesn't make sense to change them after the
filename, the environment object and the function are set in the
object. (I'm not sure whether I should lock the environment field I use
as the hash, though.)

The problem is, I can't figure out how to use class$lock(...) properly:

> test.class <- setRefClass("test", fields=c("field"))
> test.class$lock("field")
Error in .makeDefaultBinding(current at field, current at className, TRUE, environment(current)) :
  use of NULL environment is defunct

By looking at traceback() and source of methods:::.lockRefFields,
I see that environment(zzz at generator$def at fieldPrototypes[["field"]])
is, indeed, NULL.

I'm using R version 3.3.3 (2017-03-06),  version$`svn rev` is "72310".

What am I doing wring?

-- 
Best regards,
Ivan

P.S. Please Cc me in your replies to the list, if possible.


From ericjberger @ending from gm@il@com  Mon Aug 27 20:48:50 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 27 Aug 2018 21:48:50 +0300
Subject: [R] "use of NULL environment is defunct" when trying to lock a
 reference class
In-Reply-To: <20180827192508.325baf02@trisector>
References: <20180827192508.325baf02@trisector>
Message-ID: <CAGgJW75JO4gFyLadqYUN9_Fgcon0w4=MONtYP4v7TUvrEVOwrg@mail.gmail.com>

Hi Ivan,
Unfortunately I cannot answer your question.
However, I do have quite a bit of experience using R's reference classes
and you might want to consider the more recent R6 package.
It provides R6 classes which have advantages over
reference classes.  See for example:

1. Hadley Wickham on R6 (chapter 16 in "Advanced R")
https://adv-r.hadley.nz/r6.html

2. The R6 package documentation which seems to mention 'lock' in quite a
few places
https://cran.r-project.org/web/packages/R6/R6.pdf

HTH,
Eric


On Mon, Aug 27, 2018 at 7:25 PM, Ivan Krylov <krylov.r00t at gmail.com> wrote:

> Hi!
>
> I'm trying to create a persistent memoising class with a destructor and
> an option to evaluate cache misses in parallel. I want to lock all
> its fields because it doesn't make sense to change them after the
> filename, the environment object and the function are set in the
> object. (I'm not sure whether I should lock the environment field I use
> as the hash, though.)
>
> The problem is, I can't figure out how to use class$lock(...) properly:
>
> > test.class <- setRefClass("test", fields=c("field"))
> > test.class$lock("field")
> Error in .makeDefaultBinding(current at field, current at className, TRUE,
> environment(current)) :
>   use of NULL environment is defunct
>
> By looking at traceback() and source of methods:::.lockRefFields,
> I see that environment(zzz at generator$def at fieldPrototypes[["field"]])
> is, indeed, NULL.
>
> I'm using R version 3.3.3 (2017-03-06),  version$`svn rev` is "72310".
>
> What am I doing wring?
>
> --
> Best regards,
> Ivan
>
> P.S. Please Cc me in your replies to the list, if possible.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tully@holme@ @ending from wyo@gov  Mon Aug 27 22:14:03 2018
From: tully@holme@ @ending from wyo@gov (Tully Holmes)
Date: Mon, 27 Aug 2018 14:14:03 -0600
Subject: [R] Warning: unable to access index for repository...
Message-ID: <CAKGhYij=MzTz+V9THKAzLZmw4yc7QYJExYGezp3N1P8vAzgxGg@mail.gmail.com>

Good afternoon,

I'm trying to install a package with the "install.packages" command in
RGUI, and get the following error message:


> install.packages ("tidyverse")
Warning: unable to access index for repository
https://mran.microsoft.com/snapshot/2017-05-01/src/contrib:
  cannot open URL ''
Warning: unable to access index for repository
https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3:
  cannot open URL '
https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3/PACKAGES
'
Warning message:
package ?tidyverse? is not available (for R version 3.3.3)


Is there any documentation available that might document all the
destination IP addresses that are involved when the "install.packages"
command is ran?  Our R server is in a part of the state network that has
limited access to the internet, so I need to have outbound openings made in
the firewall that will let the install.packages command access what it
needs to access .  Earlier I have coordinated with the firewall team to
open ports 80 and 443 outbound from our R server to the 3 IP addresses that
correspond to mran.microsoft.com, cran.microsoft.com, and www.stats.ox.ac.uk.
I looked up these 3 IP addresses at network-tools.com.  I think there might
be additional IP addresses involved, because after these openings were
made, I'm still getting the error message above.

Thanks,

-- 

Tully Holmes

Business Applications Analyst

State of Wyoming

Wyoming Community College Commission

2300 Capitol Ave., 5th Floor, Suite B

Cheyenne, WY 82002

307-777-6832

-- 

E-Mail to and from me, in connection with the transaction 
of public 
business, is subject to the Wyoming Public Records 
Act and may be 
disclosed to third parties.

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Aug 27 22:35:23 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 27 Aug 2018 13:35:23 -0700
Subject: [R] Warning: unable to access index for repository...
In-Reply-To: <CAKGhYij=MzTz+V9THKAzLZmw4yc7QYJExYGezp3N1P8vAzgxGg@mail.gmail.com>
References: <CAKGhYij=MzTz+V9THKAzLZmw4yc7QYJExYGezp3N1P8vAzgxGg@mail.gmail.com>
Message-ID: <CAGxFJbT4HFA=CGE+q-5BJNN9qJtV199vBbW5bh_w=d0WGZW1fA@mail.gmail.com>

The main CRAN repository is at:
https://cran.r-project.org/

A full list of repositories can be found under the "Mirrors" link there.

Cheers,
Bert



On Mon, Aug 27, 2018 at 1:19 PM Tully Holmes <tully.holmes at wyo.gov> wrote:

> Good afternoon,
>
> I'm trying to install a package with the "install.packages" command in
> RGUI, and get the following error message:
>
>
> > install.packages ("tidyverse")
> Warning: unable to access index for repository
> https://mran.microsoft.com/snapshot/2017-05-01/src/contrib:
>   cannot open URL ''
> Warning: unable to access index for repository
> https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3:
>   cannot open URL '
>
> https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3/PACKAGES
> '
> Warning message:
> package ?tidyverse? is not available (for R version 3.3.3)
>
>
> Is there any documentation available that might document all the
> destination IP addresses that are involved when the "install.packages"
> command is ran?  Our R server is in a part of the state network that has
> limited access to the internet, so I need to have outbound openings made in
> the firewall that will let the install.packages command access what it
> needs to access .  Earlier I have coordinated with the firewall team to
> open ports 80 and 443 outbound from our R server to the 3 IP addresses that
> correspond to mran.microsoft.com, cran.microsoft.com, and
> www.stats.ox.ac.uk.
> I looked up these 3 IP addresses at network-tools.com.  I think there
> might
> be additional IP addresses involved, because after these openings were
> made, I'm still getting the error message above.
>
> Thanks,
>
> --
>
> Tully Holmes
>
> Business Applications Analyst
>
> State of Wyoming
>
> Wyoming Community College Commission
>
> 2300 Capitol Ave., 5th Floor, Suite B
>
> Cheyenne, WY 82002
>
> 307-777-6832
>
> --
>
> E-Mail to and from me, in connection with the transaction
> of public
> business, is subject to the Wyoming Public Records
> Act and may be
> disclosed to third parties.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkride@u @ending from y@hoo@c@  Mon Aug 27 22:40:53 2018
From: jrkride@u @ending from y@hoo@c@ (John Kane)
Date: Mon, 27 Aug 2018 20:40:53 +0000 (UTC)
Subject: [R] Cant schedule R job using taskscheduleR
In-Reply-To: <CA+dpOJ=RfRW0eSkvES2vCeR1AuQPrYwdMnwJThqqkvwYyB6Oig@mail.gmail.com>
References: <CA+dpOJ=RfRW0eSkvES2vCeR1AuQPrYwdMnwJThqqkvwYyB6Oig@mail.gmail.com>
Message-ID: <603849833.3481199.1535402453427@mail.yahoo.com>

A quick guess it that your version of R is outdated.sessionInfo()
R version 3.5.0 

package ?taskscheduleR? was built under R version 3.5.1
I don't know if that is the source of the error but I'd suggest updating to 3.5.1 as a first step.
   On Friday, August 24, 2018, 9:12:36 a.m. EDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:  
 
 Hi,

I am trying to schedule an R job using taskscheduler_create() function
available in package taskscheduleR.

Below is my code:

> library(taskscheduleR)
Warning message:
package ?taskscheduleR? was built under R version 3.5.1
> taskscheduler_create(taskname = "ABC", rscript = paste("C:\\ABC.R"),
startdate = format(Sys.Date() + 1, "%d/%m/%Y"), schedule = "WEEKLY",
starttime = "16:30", days = c("MON", "TUE", "WED", "THU", "FRI")[1])
[1] "ERROR: Incorrect Start Date."
attr(,"status")
[1] 16389
Warning message:
In system(cmd, intern = TRUE) :
? running command 'schtasks /Create /TN "ABC" /TR "cmd /c
C:/PROGRA~1/R/R-35~1.0/bin/Rscript.exe \"C:\ABC.R\"? >> \"C:\ABC.log\"
2>&1" /SC WEEKLY /ST 16:30 /SD "25/08/2018" /D MON ' had status 16389


However it fails with stating Incorrect Start Date.

Any help to understand what went wrong?

I am using R in Windows. Below is Session Information :

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United
States.1252? ? LC_MONETARY=English_United States.1252 LC_NUMERIC=C
? ? ? ? ? ? ? ? LC_TIME=English_United States.1252

attached base packages:
[1] stats? ? graphics? grDevices utils? ? datasets? methods? base

other attached packages:
[1] taskscheduleR_1.1

loaded via a namespace (and not attached):
[1] compiler_3.5.0? ? tools_3.5.0? ? ? data.table_1.11.4

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]


From jrkride@u @ending from y@hoo@c@  Mon Aug 27 22:53:08 2018
From: jrkride@u @ending from y@hoo@c@ (John Kane)
Date: Mon, 27 Aug 2018 20:53:08 +0000 (UTC)
Subject: [R] importing .v8x file in R
In-Reply-To: <a7c5cb51-1d19-39bf-caa7-fda093cfa4d6@auckland.ac.nz>
References: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
 <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>
 <a7c5cb51-1d19-39bf-caa7-fda093cfa4d6@auckland.ac.nz>
Message-ID: <819857550.3467885.1535403188592@mail.yahoo.com>

A simple google would have let you here SAS Enterprise Guide Implemented at MDACC.It looks like you have a SAS transport file . Check out the SASxport package. It may do what you want.


| 
| 
|  | 
SAS Enterprise Guide Implemented at MDACC


 |

 |

 |



   On Thursday, August 23, 2018, 4:39:45 a.m. EDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:  
 
 On 08/23/2018 08:35 PM, Rui Barradas wrote:
> Hello,
> 
> Sorry but I don't believe this is a question for r-help.
> 
> r-help is meant for questions about R code, you should find out what 
> type of file do you have. Maybe open it and see its contents.
> 
> There is really nothing we can do.

Indeed.? But the OP could try Googling "v8x file extension".
Psigh!

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From tully@holme@ @ending from wyo@gov  Mon Aug 27 23:55:03 2018
From: tully@holme@ @ending from wyo@gov (Tully Holmes)
Date: Mon, 27 Aug 2018 15:55:03 -0600
Subject: [R] Warning: unable to access index for repository...
In-Reply-To: <CAGxFJbT4HFA=CGE+q-5BJNN9qJtV199vBbW5bh_w=d0WGZW1fA@mail.gmail.com>
References: <CAKGhYij=MzTz+V9THKAzLZmw4yc7QYJExYGezp3N1P8vAzgxGg@mail.gmail.com>
 <CAGxFJbT4HFA=CGE+q-5BJNN9qJtV199vBbW5bh_w=d0WGZW1fA@mail.gmail.com>
Message-ID: <CAKGhYiiuoruWBJxjScqFsjy6Rp_kDcGoWCQsE9ra1k4O19nLtw@mail.gmail.com>

Thanks Bert, I'll reference this repository to determine the firewall rules
we will need.

-- 

Tully Holmes

Business Applications Analyst

State of Wyoming

Wyoming Community College Commission

2300 Capitol Ave., 5th Floor, Suite B

Cheyenne, WY 82002

307-777-6832



On Mon, Aug 27, 2018 at 2:35 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> The main CRAN repository is at:
> https://cran.r-project.org/
>
> A full list of repositories can be found under the "Mirrors" link there.
>
> Cheers,
> Bert
>
>
>
> On Mon, Aug 27, 2018 at 1:19 PM Tully Holmes <tully.holmes at wyo.gov> wrote:
>
>> Good afternoon,
>>
>> I'm trying to install a package with the "install.packages" command in
>> RGUI, and get the following error message:
>>
>>
>> > install.packages ("tidyverse")
>> Warning: unable to access index for repository
>> https://mran.microsoft.com/snapshot/2017-05-01/src/contrib:
>>   cannot open URL ''
>> Warning: unable to access index for repository
>> https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3:
>>   cannot open URL '
>> https://mran.microsoft.com/snapshot/2017-05-01/bin/
>> windows/contrib/3.3/PACKAGES
>> '
>> Warning message:
>> package ?tidyverse? is not available (for R version 3.3.3)
>>
>>
>> Is there any documentation available that might document all the
>> destination IP addresses that are involved when the "install.packages"
>> command is ran?  Our R server is in a part of the state network that has
>> limited access to the internet, so I need to have outbound openings made
>> in
>> the firewall that will let the install.packages command access what it
>> needs to access .  Earlier I have coordinated with the firewall team to
>> open ports 80 and 443 outbound from our R server to the 3 IP addresses
>> that
>> correspond to mran.microsoft.com, cran.microsoft.com, and
>> www.stats.ox.ac.uk.
>> I looked up these 3 IP addresses at network-tools.com.  I think there
>> might
>> be additional IP addresses involved, because after these openings were
>> made, I'm still getting the error message above.
>>
>> Thanks,
>>
>> --
>>
>> Tully Holmes
>>
>> Business Applications Analyst
>>
>> State of Wyoming
>>
>> Wyoming Community College Commission
>>
>> 2300 Capitol Ave., 5th Floor, Suite B
>> <https://maps.google.com/?q=2300+Capitol+Ave.,+5th+Floor,+Suite+B+%0D%0A+%0D%0ACheyenne,+WY+82002&entry=gmail&source=g>
>>
>> Cheyenne, WY 82002
>>
>> 307-777-6832
>>
>> --
>>
>> E-Mail to and from me, in connection with the transaction
>> of public
>> business, is subject to the Wyoming Public Records
>> Act and may be
>> disclosed to third parties.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 

E-Mail to and from me, in connection with the transaction 
of public 
business, is subject to the Wyoming Public Records 
Act and may be 
disclosed to third parties.

	[[alternative HTML version deleted]]


From @hmed@ti@80 @ending from gm@il@com  Tue Aug 28 00:54:04 2018
From: @hmed@ti@80 @ending from gm@il@com (Ahmed Attia)
Date: Mon, 27 Aug 2018 19:54:04 -0300
Subject: [R] r-data partitioning considering two variables (character and
 numeric)
Message-ID: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>

I would like to partition the following dataset (dataGenotype) based
on two variables; Genotype and stand_ID, for example, for Genotype
H13: stand_ID number 7 may go to training and stand_ID number 18 and
21 may go to testing.

Genotype    stand_ID    Inventory_date  stemC   mheight
H13             7        5/18/2006  1940.1075   11.33995
H13             7        11/1/2008  10898.9597  23.20395
H13             7        4/14/2009  12830.1284  23.77395
H13            18        11/3/2005  2726.42 13.4432
H13            18        6/30/2008  12226.1554  24.091967
H13            18        4/14/2009  14141.68    25.0922
H13            21        5/18/2006  4981.7158   15.7173
H13            21        4/14/2009  20327.0667  27.9155
H15            9         3/31/2006  3570.06 14.7898
H15            9         11/1/2008  15138.8383  26.2088
H15            9         4/14/2009  17035.4688  26.8778
H15           20         1/18/2005  3016.881    14.1886
H15           20        10/4/2006   8330.4688   20.19425
H15           20        6/30/2008   13576.5 25.4774
H15           32        2/1/2006    3426.2525   14.31815
U21           3         1/9/2006    3660.416    15.09925
U21           3         6/30/2008   13236.29    24.27634
U21           3         4/14/2009   16124.192   25.79562
U21           67        11/4/2005   2812.8425   13.60485
U21           67        4/14/2009   13468.455   24.6203

And the desired output is the following;

A-training

Genotype    stand_ID    Inventory_date  stemC   mheight
H13            7         5/18/2006  1940.1075   11.33995
H13            7         11/1/2008  10898.9597  23.20395
H13            7         4/14/2009  12830.1284  23.77395
H15            9         3/31/2006  3570.06 14.7898
H15            9         11/1/2008  15138.8383  26.2088
H15            9         4/14/2009  17035.4688  26.8778
U21            67        11/4/2005  2812.8425   13.60485
U21            67        4/14/2009  13468.455   24.6203

B-testing

Genotype    stand_ID    Inventory_date  stemC   mheight
H13             18       11/3/2005  2726.42 13.4432
H13             18       6/30/2008  12226.1554  24.091967
H13             18       4/14/2009  14141.68    25.0922
H13             21       5/18/2006  4981.7158   15.7173
H13             21       4/14/2009  20327.0667  27.9155
H15             20       1/18/2005  3016.881    14.1886
H15             20       10/4/2006  8330.4688   20.19425
H15             20       6/30/2008  13576.5 25.4774
H15             32       2/1/2006   3426.2525   14.31815
U21             3        1/9/2006   3660.416    15.09925
U21             3        6/30/2008  13236.29    24.27634
U21             3        4/14/2009  16124.192   25.79562

I tried the following code;

library(caret)
dataPartitioning <- createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
train = dataGenotype[dataPartitioning,]
test = dataGenotype[-dataPartitioning,]

Also tried

createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)

It did not produce the desired output, the data are partitioned within
the stand_ID. For example, one row of stand_ID 7 goes to training and
two rows of stand_ID 7 go to testing. How can I partition the data by
Genotype and stand_ID together?.



Ahmed Attia


From bgunter@4567 @ending from gm@il@com  Tue Aug 28 01:09:03 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 27 Aug 2018 16:09:03 -0700
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
Message-ID: <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>

Just partition the unique stand_ID's and select on them using %in% , say:

id <- unique(dataGenotype$stand_ID)
tst <- sample(id, floor(length(id)/2))
wh <- dataGenotype$stand_ID %in% tst ## logical vector
test<- dataGenotype[wh,]
train <- dataGenotype[!wh,]

There are a million variations on this theme I'm sure.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 27, 2018 at 3:54 PM Ahmed Attia <ahmedatia80 at gmail.com> wrote:

> I would like to partition the following dataset (dataGenotype) based
> on two variables; Genotype and stand_ID, for example, for Genotype
> H13: stand_ID number 7 may go to training and stand_ID number 18 and
> 21 may go to testing.
>
> Genotype    stand_ID    Inventory_date  stemC   mheight
> H13             7        5/18/2006  1940.1075   11.33995
> H13             7        11/1/2008  10898.9597  23.20395
> H13             7        4/14/2009  12830.1284  23.77395
> H13            18        11/3/2005  2726.42 13.4432
> H13            18        6/30/2008  12226.1554  24.091967
> H13            18        4/14/2009  14141.68    25.0922
> H13            21        5/18/2006  4981.7158   15.7173
> H13            21        4/14/2009  20327.0667  27.9155
> H15            9         3/31/2006  3570.06 14.7898
> H15            9         11/1/2008  15138.8383  26.2088
> H15            9         4/14/2009  17035.4688  26.8778
> H15           20         1/18/2005  3016.881    14.1886
> H15           20        10/4/2006   8330.4688   20.19425
> H15           20        6/30/2008   13576.5 25.4774
> H15           32        2/1/2006    3426.2525   14.31815
> U21           3         1/9/2006    3660.416    15.09925
> U21           3         6/30/2008   13236.29    24.27634
> U21           3         4/14/2009   16124.192   25.79562
> U21           67        11/4/2005   2812.8425   13.60485
> U21           67        4/14/2009   13468.455   24.6203
>
> And the desired output is the following;
>
> A-training
>
> Genotype    stand_ID    Inventory_date  stemC   mheight
> H13            7         5/18/2006  1940.1075   11.33995
> H13            7         11/1/2008  10898.9597  23.20395
> H13            7         4/14/2009  12830.1284  23.77395
> H15            9         3/31/2006  3570.06 14.7898
> H15            9         11/1/2008  15138.8383  26.2088
> H15            9         4/14/2009  17035.4688  26.8778
> U21            67        11/4/2005  2812.8425   13.60485
> U21            67        4/14/2009  13468.455   24.6203
>
> B-testing
>
> Genotype    stand_ID    Inventory_date  stemC   mheight
> H13             18       11/3/2005  2726.42 13.4432
> H13             18       6/30/2008  12226.1554  24.091967
> H13             18       4/14/2009  14141.68    25.0922
> H13             21       5/18/2006  4981.7158   15.7173
> H13             21       4/14/2009  20327.0667  27.9155
> H15             20       1/18/2005  3016.881    14.1886
> H15             20       10/4/2006  8330.4688   20.19425
> H15             20       6/30/2008  13576.5 25.4774
> H15             32       2/1/2006   3426.2525   14.31815
> U21             3        1/9/2006   3660.416    15.09925
> U21             3        6/30/2008  13236.29    24.27634
> U21             3        4/14/2009  16124.192   25.79562
>
> I tried the following code;
>
> library(caret)
> dataPartitioning <-
> createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
> train = dataGenotype[dataPartitioning,]
> test = dataGenotype[-dataPartitioning,]
>
> Also tried
>
> createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
>
> It did not produce the desired output, the data are partitioned within
> the stand_ID. For example, one row of stand_ID 7 goes to training and
> two rows of stand_ID 7 go to testing. How can I partition the data by
> Genotype and stand_ID together?.
>
>
>
> Ahmed Attia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Tue Aug 28 01:10:43 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 27 Aug 2018 23:10:43 +0000
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
Message-ID: <AB76DEC9-603A-4796-994C-619669ED2FD0@llnl.gov>

You could start with split()

grp <- rep('', nrow(mydata) )
grp[mydata$stand_ID %in% c(7,9,67)] <- 'A-training'
grp[mydata$stand_ID %in% c(3,18,20,21,32)] <- 'B-testing'

split(mydata, grp)

or perhaps

grp <- ifelse(  mydata$stand_ID %in% c(7,9,67) , 'A-training', 'B-testing' )
split(mydata, grp)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/27/18, 3:54 PM, "R-help on behalf of Ahmed Attia" <r-help-bounces at r-project.org on behalf of ahmedatia80 at gmail.com> wrote:

    I would like to partition the following dataset (dataGenotype) based
    on two variables; Genotype and stand_ID, for example, for Genotype
    H13: stand_ID number 7 may go to training and stand_ID number 18 and
    21 may go to testing.
    
    Genotype    stand_ID    Inventory_date  stemC   mheight
    H13             7        5/18/2006  1940.1075   11.33995
    H13             7        11/1/2008  10898.9597  23.20395
    H13             7        4/14/2009  12830.1284  23.77395
    H13            18        11/3/2005  2726.42 13.4432
    H13            18        6/30/2008  12226.1554  24.091967
    H13            18        4/14/2009  14141.68    25.0922
    H13            21        5/18/2006  4981.7158   15.7173
    H13            21        4/14/2009  20327.0667  27.9155
    H15            9         3/31/2006  3570.06 14.7898
    H15            9         11/1/2008  15138.8383  26.2088
    H15            9         4/14/2009  17035.4688  26.8778
    H15           20         1/18/2005  3016.881    14.1886
    H15           20        10/4/2006   8330.4688   20.19425
    H15           20        6/30/2008   13576.5 25.4774
    H15           32        2/1/2006    3426.2525   14.31815
    U21           3         1/9/2006    3660.416    15.09925
    U21           3         6/30/2008   13236.29    24.27634
    U21           3         4/14/2009   16124.192   25.79562
    U21           67        11/4/2005   2812.8425   13.60485
    U21           67        4/14/2009   13468.455   24.6203
    
    And the desired output is the following;
    
    A-training
    
    Genotype    stand_ID    Inventory_date  stemC   mheight
    H13            7         5/18/2006  1940.1075   11.33995
    H13            7         11/1/2008  10898.9597  23.20395
    H13            7         4/14/2009  12830.1284  23.77395
    H15            9         3/31/2006  3570.06 14.7898
    H15            9         11/1/2008  15138.8383  26.2088
    H15            9         4/14/2009  17035.4688  26.8778
    U21            67        11/4/2005  2812.8425   13.60485
    U21            67        4/14/2009  13468.455   24.6203
    
    B-testing
    
    Genotype    stand_ID    Inventory_date  stemC   mheight
    H13             18       11/3/2005  2726.42 13.4432
    H13             18       6/30/2008  12226.1554  24.091967
    H13             18       4/14/2009  14141.68    25.0922
    H13             21       5/18/2006  4981.7158   15.7173
    H13             21       4/14/2009  20327.0667  27.9155
    H15             20       1/18/2005  3016.881    14.1886
    H15             20       10/4/2006  8330.4688   20.19425
    H15             20       6/30/2008  13576.5 25.4774
    H15             32       2/1/2006   3426.2525   14.31815
    U21             3        1/9/2006   3660.416    15.09925
    U21             3        6/30/2008  13236.29    24.27634
    U21             3        4/14/2009  16124.192   25.79562
    
    I tried the following code;
    
    library(caret)
    dataPartitioning <- createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
    train = dataGenotype[dataPartitioning,]
    test = dataGenotype[-dataPartitioning,]
    
    Also tried
    
    createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
    
    It did not produce the desired output, the data are partitioned within
    the stand_ID. For example, one row of stand_ID 7 goes to training and
    two rows of stand_ID 7 go to testing. How can I partition the data by
    Genotype and stand_ID together?.
    
    
    
    Ahmed Attia
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @ending from llnl@gov  Tue Aug 28 01:14:45 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 27 Aug 2018 23:14:45 +0000
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <AB76DEC9-603A-4796-994C-619669ED2FD0@llnl.gov>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
 <AB76DEC9-603A-4796-994C-619669ED2FD0@llnl.gov>
Message-ID: <2A3BA850-7CAC-4D8A-83A8-33A61F0AB003@llnl.gov>

And yes, I ignored Genotype, but for the example data none of the stand_ID values are present in more than one Genotype, so it doesn't matter. If that's not true in general, then constructing the grp variable is a little more complex, but the principle is the same.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/27/18, 4:10 PM, "R-help on behalf of MacQueen, Don via R-help" <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

    You could start with split()
    
    grp <- rep('', nrow(mydata) )
    grp[mydata$stand_ID %in% c(7,9,67)] <- 'A-training'
    grp[mydata$stand_ID %in% c(3,18,20,21,32)] <- 'B-testing'
    
    split(mydata, grp)
    
    or perhaps
    
    grp <- ifelse(  mydata$stand_ID %in% c(7,9,67) , 'A-training', 'B-testing' )
    split(mydata, grp)
    
    -Don
    
    --
    Don MacQueen
    Lawrence Livermore National Laboratory
    7000 East Ave., L-627
    Livermore, CA 94550
    925-423-1062
    Lab cell 925-724-7509
     
     
    
    On 8/27/18, 3:54 PM, "R-help on behalf of Ahmed Attia" <r-help-bounces at r-project.org on behalf of ahmedatia80 at gmail.com> wrote:
    
        I would like to partition the following dataset (dataGenotype) based
        on two variables; Genotype and stand_ID, for example, for Genotype
        H13: stand_ID number 7 may go to training and stand_ID number 18 and
        21 may go to testing.
        
        Genotype    stand_ID    Inventory_date  stemC   mheight
        H13             7        5/18/2006  1940.1075   11.33995
        H13             7        11/1/2008  10898.9597  23.20395
        H13             7        4/14/2009  12830.1284  23.77395
        H13            18        11/3/2005  2726.42 13.4432
        H13            18        6/30/2008  12226.1554  24.091967
        H13            18        4/14/2009  14141.68    25.0922
        H13            21        5/18/2006  4981.7158   15.7173
        H13            21        4/14/2009  20327.0667  27.9155
        H15            9         3/31/2006  3570.06 14.7898
        H15            9         11/1/2008  15138.8383  26.2088
        H15            9         4/14/2009  17035.4688  26.8778
        H15           20         1/18/2005  3016.881    14.1886
        H15           20        10/4/2006   8330.4688   20.19425
        H15           20        6/30/2008   13576.5 25.4774
        H15           32        2/1/2006    3426.2525   14.31815
        U21           3         1/9/2006    3660.416    15.09925
        U21           3         6/30/2008   13236.29    24.27634
        U21           3         4/14/2009   16124.192   25.79562
        U21           67        11/4/2005   2812.8425   13.60485
        U21           67        4/14/2009   13468.455   24.6203
        
        And the desired output is the following;
        
        A-training
        
        Genotype    stand_ID    Inventory_date  stemC   mheight
        H13            7         5/18/2006  1940.1075   11.33995
        H13            7         11/1/2008  10898.9597  23.20395
        H13            7         4/14/2009  12830.1284  23.77395
        H15            9         3/31/2006  3570.06 14.7898
        H15            9         11/1/2008  15138.8383  26.2088
        H15            9         4/14/2009  17035.4688  26.8778
        U21            67        11/4/2005  2812.8425   13.60485
        U21            67        4/14/2009  13468.455   24.6203
        
        B-testing
        
        Genotype    stand_ID    Inventory_date  stemC   mheight
        H13             18       11/3/2005  2726.42 13.4432
        H13             18       6/30/2008  12226.1554  24.091967
        H13             18       4/14/2009  14141.68    25.0922
        H13             21       5/18/2006  4981.7158   15.7173
        H13             21       4/14/2009  20327.0667  27.9155
        H15             20       1/18/2005  3016.881    14.1886
        H15             20       10/4/2006  8330.4688   20.19425
        H15             20       6/30/2008  13576.5 25.4774
        H15             32       2/1/2006   3426.2525   14.31815
        U21             3        1/9/2006   3660.416    15.09925
        U21             3        6/30/2008  13236.29    24.27634
        U21             3        4/14/2009  16124.192   25.79562
        
        I tried the following code;
        
        library(caret)
        dataPartitioning <- createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
        train = dataGenotype[dataPartitioning,]
        test = dataGenotype[-dataPartitioning,]
        
        Also tried
        
        createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
        
        It did not produce the desired output, the data are partitioned within
        the stand_ID. For example, one row of stand_ID 7 goes to training and
        two rows of stand_ID 7 go to testing. How can I partition the data by
        Genotype and stand_ID together?.
        
        
        
        Ahmed Attia
        
        ______________________________________________
        R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
        https://stat.ethz.ch/mailman/listinfo/r-help
        PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
        and provide commented, minimal, self-contained, reproducible code.
        
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @ending from gm@il@com  Tue Aug 28 01:50:47 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 27 Aug 2018 16:50:47 -0700
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
 <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>
Message-ID: <CAGxFJbQJau0JdkvPmcGwL4+6q_-Lj3zDqtFB0du_F3fok_V-hw@mail.gmail.com>

Sorry, my bad -- careless reading: you need to do the partitioning within
genotype.
Something like:

by(dataGenotype, dataGenotype$Genotype, function(x){

  u <- unique(x$standID)

   tst <- x$x2 %in% sample(u, floor(length(u)/2))

   list(test = x[tst,], train = x[!tst,]

   })


This will give a list each component of which will split the Genotype into
test and train dataframe subsets by ID. These lists of data frames can then
be recombined into a single test and train dataframe by, e.g. an
appropriate rbind() call.


HOWEVER, note that you will need to modify this function to decide what to
do if/when there is only one ID in a Genotype, as Don MacQueen already
pointed out.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 27, 2018 at 4:09 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Just partition the unique stand_ID's and select on them using %in% , say:
>
> id <- unique(dataGenotype$stand_ID)
> tst <- sample(id, floor(length(id)/2))
> wh <- dataGenotype$stand_ID %in% tst ## logical vector
> test<- dataGenotype[wh,]
> train <- dataGenotype[!wh,]
>
> There are a million variations on this theme I'm sure.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 27, 2018 at 3:54 PM Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>
>> I would like to partition the following dataset (dataGenotype) based
>> on two variables; Genotype and stand_ID, for example, for Genotype
>> H13: stand_ID number 7 may go to training and stand_ID number 18 and
>> 21 may go to testing.
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13             7        5/18/2006  1940.1075   11.33995
>> H13             7        11/1/2008  10898.9597  23.20395
>> H13             7        4/14/2009  12830.1284  23.77395
>> H13            18        11/3/2005  2726.42 13.4432
>> H13            18        6/30/2008  12226.1554  24.091967
>> H13            18        4/14/2009  14141.68    25.0922
>> H13            21        5/18/2006  4981.7158   15.7173
>> H13            21        4/14/2009  20327.0667  27.9155
>> H15            9         3/31/2006  3570.06 14.7898
>> H15            9         11/1/2008  15138.8383  26.2088
>> H15            9         4/14/2009  17035.4688  26.8778
>> H15           20         1/18/2005  3016.881    14.1886
>> H15           20        10/4/2006   8330.4688   20.19425
>> H15           20        6/30/2008   13576.5 25.4774
>> H15           32        2/1/2006    3426.2525   14.31815
>> U21           3         1/9/2006    3660.416    15.09925
>> U21           3         6/30/2008   13236.29    24.27634
>> U21           3         4/14/2009   16124.192   25.79562
>> U21           67        11/4/2005   2812.8425   13.60485
>> U21           67        4/14/2009   13468.455   24.6203
>>
>> And the desired output is the following;
>>
>> A-training
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13            7         5/18/2006  1940.1075   11.33995
>> H13            7         11/1/2008  10898.9597  23.20395
>> H13            7         4/14/2009  12830.1284  23.77395
>> H15            9         3/31/2006  3570.06 14.7898
>> H15            9         11/1/2008  15138.8383  26.2088
>> H15            9         4/14/2009  17035.4688  26.8778
>> U21            67        11/4/2005  2812.8425   13.60485
>> U21            67        4/14/2009  13468.455   24.6203
>>
>> B-testing
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13             18       11/3/2005  2726.42 13.4432
>> H13             18       6/30/2008  12226.1554  24.091967
>> H13             18       4/14/2009  14141.68    25.0922
>> H13             21       5/18/2006  4981.7158   15.7173
>> H13             21       4/14/2009  20327.0667  27.9155
>> H15             20       1/18/2005  3016.881    14.1886
>> H15             20       10/4/2006  8330.4688   20.19425
>> H15             20       6/30/2008  13576.5 25.4774
>> H15             32       2/1/2006   3426.2525   14.31815
>> U21             3        1/9/2006   3660.416    15.09925
>> U21             3        6/30/2008  13236.29    24.27634
>> U21             3        4/14/2009  16124.192   25.79562
>>
>> I tried the following code;
>>
>> library(caret)
>> dataPartitioning <-
>> createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
>> train = dataGenotype[dataPartitioning,]
>> test = dataGenotype[-dataPartitioning,]
>>
>> Also tried
>>
>> createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
>>
>> It did not produce the desired output, the data are partitioned within
>> the stand_ID. For example, one row of stand_ID 7 goes to training and
>> two rows of stand_ID 7 go to testing. How can I partition the data by
>> Genotype and stand_ID together?.
>>
>>
>>
>> Ahmed Attia
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @hmed@ti@80 @ending from gm@il@com  Tue Aug 28 02:46:33 2018
From: @hmed@ti@80 @ending from gm@il@com (Ahmed Attia)
Date: Mon, 27 Aug 2018 21:46:33 -0300
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
 <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>
Message-ID: <CAG6S0OkBZmrkejifbjfb65eNbE4gKJH=gLKM3DT74vN_h_7VoQ@mail.gmail.com>

Thanks Bert, worked nicely. Yes, genotypes with only one ID will be
eliminated before partitioning the data.


Best regards

Ahmed Attia






On Mon, Aug 27, 2018 at 8:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Just partition the unique stand_ID's and select on them using %in% , say:
>
> id <- unique(dataGenotype$stand_ID)
> tst <- sample(id, floor(length(id)/2))
> wh <- dataGenotype$stand_ID %in% tst ## logical vector
> test<- dataGenotype[wh,]
> train <- dataGenotype[!wh,]
>
> There are a million variations on this theme I'm sure.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 27, 2018 at 3:54 PM Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>>
>> I would like to partition the following dataset (dataGenotype) based
>> on two variables; Genotype and stand_ID, for example, for Genotype
>> H13: stand_ID number 7 may go to training and stand_ID number 18 and
>> 21 may go to testing.
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13             7        5/18/2006  1940.1075   11.33995
>> H13             7        11/1/2008  10898.9597  23.20395
>> H13             7        4/14/2009  12830.1284  23.77395
>> H13            18        11/3/2005  2726.42 13.4432
>> H13            18        6/30/2008  12226.1554  24.091967
>> H13            18        4/14/2009  14141.68    25.0922
>> H13            21        5/18/2006  4981.7158   15.7173
>> H13            21        4/14/2009  20327.0667  27.9155
>> H15            9         3/31/2006  3570.06 14.7898
>> H15            9         11/1/2008  15138.8383  26.2088
>> H15            9         4/14/2009  17035.4688  26.8778
>> H15           20         1/18/2005  3016.881    14.1886
>> H15           20        10/4/2006   8330.4688   20.19425
>> H15           20        6/30/2008   13576.5 25.4774
>> H15           32        2/1/2006    3426.2525   14.31815
>> U21           3         1/9/2006    3660.416    15.09925
>> U21           3         6/30/2008   13236.29    24.27634
>> U21           3         4/14/2009   16124.192   25.79562
>> U21           67        11/4/2005   2812.8425   13.60485
>> U21           67        4/14/2009   13468.455   24.6203
>>
>> And the desired output is the following;
>>
>> A-training
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13            7         5/18/2006  1940.1075   11.33995
>> H13            7         11/1/2008  10898.9597  23.20395
>> H13            7         4/14/2009  12830.1284  23.77395
>> H15            9         3/31/2006  3570.06 14.7898
>> H15            9         11/1/2008  15138.8383  26.2088
>> H15            9         4/14/2009  17035.4688  26.8778
>> U21            67        11/4/2005  2812.8425   13.60485
>> U21            67        4/14/2009  13468.455   24.6203
>>
>> B-testing
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13             18       11/3/2005  2726.42 13.4432
>> H13             18       6/30/2008  12226.1554  24.091967
>> H13             18       4/14/2009  14141.68    25.0922
>> H13             21       5/18/2006  4981.7158   15.7173
>> H13             21       4/14/2009  20327.0667  27.9155
>> H15             20       1/18/2005  3016.881    14.1886
>> H15             20       10/4/2006  8330.4688   20.19425
>> H15             20       6/30/2008  13576.5 25.4774
>> H15             32       2/1/2006   3426.2525   14.31815
>> U21             3        1/9/2006   3660.416    15.09925
>> U21             3        6/30/2008  13236.29    24.27634
>> U21             3        4/14/2009  16124.192   25.79562
>>
>> I tried the following code;
>>
>> library(caret)
>> dataPartitioning <-
>> createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
>> train = dataGenotype[dataPartitioning,]
>> test = dataGenotype[-dataPartitioning,]
>>
>> Also tried
>>
>> createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
>>
>> It did not produce the desired output, the data are partitioned within
>> the stand_ID. For example, one row of stand_ID 7 goes to training and
>> two rows of stand_ID 7 go to testing. How can I partition the data by
>> Genotype and stand_ID together?.
>>
>>
>>
>> Ahmed Attia
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From vidhi@@l@giri @ending from gm@il@com  Tue Aug 28 01:51:42 2018
From: vidhi@@l@giri @ending from gm@il@com (Vidya Alagiriswamy)
Date: Mon, 27 Aug 2018 16:51:42 -0700
Subject: [R] importing .v8x file in R
In-Reply-To: <819857550.3467885.1535403188592@mail.yahoo.com>
References: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
 <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>
 <a7c5cb51-1d19-39bf-caa7-fda093cfa4d6@auckland.ac.nz>
 <819857550.3467885.1535403188592@mail.yahoo.com>
Message-ID: <047ACB2C-E289-4A56-AF89-705A111D225C@gmail.com>

Thank you. Will take look.

Sent from my iPhone

> On Aug 27, 2018, at 1:53 PM, John Kane <jrkrideau at yahoo.ca> wrote:
> 
> A simple google would have let you here SAS Enterprise Guide Implemented at MDACC.
> It looks like you have a SAS transport file . Check out the SASxport package. It may do what you want.
> 
> SAS Enterprise Guide Implemented at MDACC
> 
> 
> On Thursday, August 23, 2018, 4:39:45 a.m. EDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 08/23/2018 08:35 PM, Rui Barradas wrote:
> > Hello,
> > 
> > Sorry but I don't believe this is a question for r-help.
> > 
> > r-help is meant for questions about R code, you should find out what 
> > type of file do you have. Maybe open it and see its contents.
> > 
> > There is really nothing we can do.
> 
> Indeed.  But the OP could try Googling "v8x file extension".
> Psigh!
> 
> cheers,
> 
> Rolf
> 
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Tue Aug 28 13:26:14 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Tue, 28 Aug 2018 11:26:14 +0000
Subject: [R] installing R in ubuntu
Message-ID: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                              I am trying to install R in ubuntu AWS instance....

While getting help from google, I came across something called GPG key. How to get the GPG key for an AWS ubuntu  instance? More over, what is a GPG key?

Any general help on installing R in ubuntu AWS instance?

very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Tue Aug 28 15:13:31 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Tue, 28 Aug 2018 15:13:31 +0200
Subject: [R] installing R in ubuntu
In-Reply-To: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <1A3EA26D-B035-413D-A7D4-C66807DC3B4D@gmail.com>

It's a digital signature (GNU Privacy Guard). Typically to allow you to verify that the stuff you install is what it says that it is.

However, you are not likely to get more informative answers than that in this forum. Possible better is the R-SIG-debian lists or forums specifically for AWS. (& it is not like googling for "GPG AWS" draws a complete blank.)

-pd


> On 28 Aug 2018, at 13:26 , akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> dear members,
>                              I am trying to install R in ubuntu AWS instance....
> 
> While getting help from google, I came across something called GPG key. How to get the GPG key for an AWS ubuntu  instance? More over, what is a GPG key?
> 
> Any general help on installing R in ubuntu AWS instance?
> 
> very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rm@h@rp @ending from me@com  Tue Aug 28 20:00:43 2018
From: rm@h@rp @ending from me@com (R. Mark Sharp)
Date: Tue, 28 Aug 2018 13:00:43 -0500
Subject: [R] Writing .nc files
In-Reply-To: <3D8D75DC-B773-44A8-92A3-81403F065A4C@me.com>
References: <CAON01EbSs=z6Gd6vPaa9aQReiJTwi6rqHyKBFJ71Wo+bT=yh+g@mail.gmail.com>
 <144921FD-954D-4B92-BF6C-261DECB2535A@me.com>
 <CAON01Ebn+Anh3O-Ux059F4WcUtfE7n5D40x8kJ2nb9kYkohWJw@mail.gmail.com>
 <3D8D75DC-B773-44A8-92A3-81403F065A4C@me.com>
Message-ID: <18943960-4420-41E9-A894-6E8E9CB78FF4@me.com>

Marco,

Always post to the r-help list to have a better chance of finding someone that can help.

There is a very nice tutorial that you should have found. See http://geog.uoregon.edu/bartlein/courses/geog490/week04-netCDF.html#create-and-write-a-netcdf-file

Mark
R. Mark Sharp, Ph.D.
Data Scientist and Biomedical Statistical Consultant
7526 Meadow Green St.
San Antonio, TX 78251
mobile: 210-218-2868
rmsharp at me.com











> On Aug 28, 2018, at 8:26 AM, R. Mark Sharp <rmsharp at me.com> wrote:
> 
> Marco,
> 
> You will need to ask the list. I have never worked with .nc files.
> 
> Most are wanting to go the other direction .nc to .csv or dataframe. Google search with ?.nc file in r?.
> 
> R. Mark Sharp, Ph.D.
> Data Scientist and Biomedical Statistical Consultant
> 7526 Meadow Green St.
> San Antonio, TX 78251
> mobile: 210-218-2868
> rmsharp at me.com
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>> On Aug 27, 2018, at 10:12 AM, Marco Antonio P?rez <marko.luna13 at gmail.com> wrote:
>> 
>> Hello Mark:
>> 
>> I appreciate your sopport in this subject. But now, I need your help again, please. 
>> I wondering if you know how to transform a .csv file to .nc file_
>> 
>> Thanks a lot!!
>> 
>> 2018-08-10 17:08 GMT-03:00 R. Mark Sharp <rmsharp at me.com>:
>> Marco,
>> 
>> The error message indicates that nlon*nlat is 420 and that 1378620/420 has a remainder. For the matrix to form, all rows have to be complete. 
>> 
>> I am guessing you have at least one value incorrect among nlon, nlat, t or the length of fulldatav.
>> 
>> Mark
>> R. Mark Sharp, Ph.D.
>> Data Scientist and Biomedical Statistical Consultant
>> 7526 Meadow Green St.
>> San Antonio, TX 78251
>> mobile: 210-218-2868
>> rmsharp at me.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>>> On Aug 10, 2018, at 10:00 AM, Marco Antonio P?rez <marko.luna13 at gmail.com> wrote:
>>> 
>>> I am trying to write a function to make a matrix of precipitation with
>>> this secuencie;
>>> ######## PRIMER PERIODO
>>> cordex1 <-
>>> nc_open("pr_CAM-44i_ICHEC-EC-EARTH_rcp45_r12i1p1_SMHI-RCA4_v1_mon_200601-201012.nc")
>>> fullmon1<-ncvar_get(cordex1,"pr")
>>> lat<-ncvar_get(cordex1,"lat", start=c(35.5),count=c(20))
>>> lon <-ncvar_get(cordex1,"lon", start=c(125),count=c(21.5))
>>> t <- ncvar_get(cordex1,"time")
>>> nlon <- dim(lon)
>>> nlat <- dim(lat)
>>> nt <- dim(t)
>>> fulldatav <- as.vector(fullmon1)
>>> fulldata <- matrix(fulldatav, nrow=nlon*nlat, ncol=nt)
>>> lonlat <- expand.grid(lon,lat)
>>> df_cordex1<- data.frame(lonlat,fulldata)
>>> 
>>> but with the expresion  fulldata <- matrix(fulldatav, nrow=nlon*nlat,
>>> ncol=nt) this error appears
>>> Warning message:
>>> In matrix(fulldatav, nrow = nlon * nlat, ncol = nt) :
>>> data length [1378620] is not a sub-multiple or multiple of the number of
>>> rows [420]
>>> 
>>> Somebody help me!!!
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 


From krylov@r00t @ending from gm@il@com  Tue Aug 28 22:49:17 2018
From: krylov@r00t @ending from gm@il@com (Ivan Krylov)
Date: Tue, 28 Aug 2018 23:49:17 +0300
Subject: [R] "use of NULL environment is defunct" when trying to lock a
 reference class
In-Reply-To: <CAGgJW75JO4gFyLadqYUN9_Fgcon0w4=MONtYP4v7TUvrEVOwrg@mail.gmail.com>
References: <20180827192508.325baf02@trisector>
 <CAGgJW75JO4gFyLadqYUN9_Fgcon0w4=MONtYP4v7TUvrEVOwrg@mail.gmail.com>
Message-ID: <20180828234917.7544886d@trisector>

Hi Eric,

Thank you for your answer!

On Mon, 27 Aug 2018 21:48:50 +0300
Eric Berger <ericjberger at gmail.com> wrote:

> you might want to consider the more recent R6 package

Indeed, R6 has private fields which fits my idea of an object with
mutable state even better.

My original problem seems to be solved and I'm posting my code (CC0) in
case someone else needs it as a reference:

require(digest); require(R6)
memoised <- R6Class(
	"memoised", lock_objects=T, lock_class=T, cloneable=F,
	private=list(fun=NULL, storage=NULL, cache=NULL),
	public=list(
		initialize=function(fun, storage) { # constructor
			private$fun <- fun
			private$storage <- storage
			private$cache <- tryCatch(
				{
					load(storage)
					cache
				}, error = function(e) {
					new.env(T, emptyenv())
				}
			)
		},
		eval=function(...) { # behave as cached fun
			hash <- digest(list(...), algo="sha1")
			if (exists(hash, private$cache)) return(get(hash, private$cache))
			val <- private$fun(...)
			assign(hash, val, private$cache)
			val
		},
		par.eval=function(args, cl) { # args is list of argument lists
			# hash all because we'll need them later
			hashes <- lapply(args, digest, algo="sha1")
			# indices of not yet evaluated in the original args array
			missing <- Filter(function(i) !exists(hashes[[i]], private$cache), seq_along(args))
			# evaluate and save them
			values <- parLapply(cl, args[missing], function(l) do.call(private$fun,l))
			private$cache[hashes[missing]] <- values
			# get all requested hashes
			private$cache[hashes]
		},
		finalize=function() { # destructor
			cache <- private$cache # must have known name for restore
			save(cache, file=private$storage)
		}
	)
)

It's still a mystery why did setRefClass refuse to lock my class, but
at least it's not blocking my progress.

-- 
Best regards,
Ivan


From r@turner @ending from @uckl@nd@@c@nz  Wed Aug 29 00:11:12 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 29 Aug 2018 10:11:12 +1200
Subject: [R] [FORGED]  installing R in ubuntu
In-Reply-To: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <9dae54da-b21c-6973-909e-3d701ef11436@auckland.ac.nz>

On 08/28/2018 11:26 PM, akshay kulkarni wrote:
> dear members,
>                                I am trying to install R in ubuntu AWS instance....
> 
> While getting help from google, I came across something called GPG key. How to get the GPG key for an AWS ubuntu  instance? More over, what is a GPG key?
> 
> Any general help on installing R in ubuntu AWS instance?
> 
> very many thanks for your time and effort...

You may find the following link helpful.  I did.

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From g@ll@i@@f@nny @ending from gm@il@com  Wed Aug 29 15:19:34 2018
From: g@ll@i@@f@nny @ending from gm@il@com (Fanny Gallais)
Date: Wed, 29 Aug 2018 15:19:34 +0200
Subject: [R] Estimate parameters differential equations system
Message-ID: <CANSOPkWhUaPMi-JM38qxwCtPVndjzZT8AyPbf+LBkJJy-zqB6Q@mail.gmail.com>

Dear R users,



I am working on a simple mathematical model made of two ordinary
differential equations:



dx/dt=-mx-d1(x-c)

dy/dt=mx-d2y



I would like to fit this model to my data and estimate the corresponding
parameters. The thing is I only have observed data for y, x is unknown. Is
it possible to do this in R?



Thank you for your help

Fanny

	[[alternative HTML version deleted]]


From prof@@mit@mitt@l m@ili@g off gm@il@com  Wed Aug 29 13:18:32 2018
From: prof@@mit@mitt@l m@ili@g off gm@il@com (prof@@mit@mitt@l m@ili@g off gm@il@com)
Date: Wed, 29 Aug 2018 16:48:32 +0530
Subject: [R] Bitbucket code
Message-ID: <447701d43f8a$07241930$156c4b90$@gmail.com>

I installed a local zip file a few days ago and the package was recently
modified on bitbucket , with a stable zip version not yet available.

 

How many days does it usually take to get a stable zip version. How can I
`devtools` it from the bitbucket the fastest way? I have my own sourcetree
and the author has created in cloud.

 

 

 

BR

Amit

 

Listusers, 

Early answers help everyone.  Please acknowledge when you receive a useful
reply.

 

 

 


	[[alternative HTML version deleted]]


From prof@@mit@mitt@l m@ili@g off gm@il@com  Wed Aug 29 13:24:41 2018
From: prof@@mit@mitt@l m@ili@g off gm@il@com (prof@@mit@mitt@l m@ili@g off gm@il@com)
Date: Wed, 29 Aug 2018 16:54:41 +0530
Subject: [R] Bitbucket code
In-Reply-To: <447701d43f8a$07241930$156c4b90$@gmail.com>
References: <447701d43f8a$07241930$156c4b90$@gmail.com>
Message-ID: <00eb01d43f8a$e3759e40$aa60dac0$@gmail.com>

 

I installed a local zip file a few days ago and the package was recently
modified on bitbucket , with a stable zip version not yet available.  I have
tried using `remotes` but `RTOOLS` is not updated for 3.5.1

 

Should I use my clone to install into R, I do not think I can install the
whole package using `source()`

 

How should this be done fast and quick?

 

 

How many days does it usually take to get a stable zip version. How can I
`devtools` it from the bitbucket the fastest way? I have my own sourcetree
and the author has created in cloud.

 

 

 

BR

Amit

 

Listusers, 

Early answers help everyone.  Please acknowledge when you receive a useful
reply.

 

 

 


	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @ending from me@com  Wed Aug 29 16:25:27 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Wed, 29 Aug 2018 10:25:27 -0400
Subject: [R] Bitbucket code
In-Reply-To: <447701d43f8a$07241930$156c4b90$@gmail.com>
References: <447701d43f8a$07241930$156c4b90$@gmail.com>
Message-ID: <D72DA336-D5EF-44DD-85B6-0E62F8F3773C@me.com>


> On Aug 29, 2018, at 7:18 AM, prof.amit.mittal at gmail.com wrote:
> 
> I installed a local zip file a few days ago and the package was recently
> modified on bitbucket , with a stable zip version not yet available.
> 
> How many days does it usually take to get a stable zip version. How can I
> `devtools` it from the bitbucket the fastest way? I have my own sourcetree
> and the author has created in cloud.
> 
> 
> BR
> 
> Amit
> 


Hi,

No need to post twice.

I don't use Bitbucket, but it looks like the devtools package has a install_bitbucket() function, so perhaps that will do what you want.

In terms of making a stable archive file available, that will be entirely up to the package maintainer and when/how they choose to make that available (e.g. via CRAN or other vehicles).

Regards,

Marc Schwartz


From prof@@mit@mitt@l @ending from gm@il@com  Wed Aug 29 16:31:20 2018
From: prof@@mit@mitt@l @ending from gm@il@com (Amit Mittal)
Date: Wed, 29 Aug 2018 14:31:20 +0000
Subject: [R] Bitbucket code
In-Reply-To: <D72DA336-D5EF-44DD-85B6-0E62F8F3773C@me.com>
References: <447701d43f8a$07241930$156c4b90$@gmail.com>,
 <D72DA336-D5EF-44DD-85B6-0E62F8F3773C@me.com>
Message-ID: <DM6PR01MB41079586796CE83CD4EE84F1FC090@DM6PR01MB4107.prod.exchangelabs.com>

I stumbled upon `remotes` and that is based on `devtools` but it fails because RTOOLS haven't been upgraded for 3.5.1

Sorry about posting twice and I am pretty sure I added this detail in another msg which will also be released by the moderator q yet :x

------------
Amit Mittal


Sent from my Outlook for Android
https://aka.ms/ghei36

________________________________
From: Marc Schwartz <marc_schwartz at me.com>
Sent: Wednesday, August 29, 2018 7:55:27 PM
To: prof.amit.mittal at gmail.com
Cc: R-help
Subject: Re: [R] Bitbucket code


> On Aug 29, 2018, at 7:18 AM, prof.amit.mittal at gmail.com wrote:
>
> I installed a local zip file a few days ago and the package was recently
> modified on bitbucket , with a stable zip version not yet available.
>
> How many days does it usually take to get a stable zip version. How can I
> `devtools` it from the bitbucket the fastest way? I have my own sourcetree
> and the author has created in cloud.
>
>
> BR
>
> Amit
>


Hi,

No need to post twice.

I don't use Bitbucket, but it looks like the devtools package has a install_bitbucket() function, so perhaps that will do what you want.

In terms of making a stable archive file available, that will be entirely up to the package maintainer and when/how they choose to make that available (e.g. via CRAN or other vehicles).

Regards,

Marc Schwartz



	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Thu Aug 30 00:06:13 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Wed, 29 Aug 2018 18:06:13 -0400
Subject: [R] TCGA biolinks, DNA methylation
Message-ID: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>

Good evening R users,

  I am attempting to carry out DNA methylation analysis on two separate CSV
files (LGG and GBM), which I have downloaded onto my R console. To set the
path<-"." to be indicative of one or both of the csv files, I utilized the
following functions and received the errors shown. How do I set the "." so
that I can begin analysis on my files?

> the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
Error: unexpected string constant in "the_data
<-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
Error: unexpected string constant in
"the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""

This is the preliminary portion of the analysis I am trying to run, which I
am referring to:

1 library(TCGAbiolinks)
2
3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
4 path <? "."
5
6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
level = 3)
7 TCGAdownload(query.met, path = path )
8 met <? TCGAprepare(query = query.met,dir = path,
9                      add.subtype = TRUE, add.clinical = TRUE,
10                    summarizedExperiment = TRUE,
11                      save = TRUE, filename = "lgg_gbm_met.rda")
12
13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform = "IlluminaHiSeq_
RNASeqV2",level = 3)
15
16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
results")
17
18 exp <? TCGAprepare(query = query.exp, dir = path,
19                    summarizedExperiment = TRUE,
20                      add.subtype = TRUE, add.clinical = TRUE,
21                    type = "rsem.genes.normalized_results",
22                      save = T,filename = "lgg_gbm_exp.rda")

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Thu Aug 30 00:34:06 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Wed, 29 Aug 2018 18:34:06 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
Message-ID: <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>

Hi,

If you had an actual gene analysis question I'd suggest the
BioConductor email list, but you have a plain old ordinary typo:

 the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")

You're missing the = after the argument sep

 the_data <- read.csv(file = "LGG_clinical_drug.csv", header = TRUE, sep = ",")

Using more spaces in your code would make that typo easier to spot.

Sarah
On Wed, Aug 29, 2018 at 6:06 PM Spencer Brackett
<spbrackett20 at saintjosephhs.com> wrote:
>
> Good evening R users,
>
>   I am attempting to carry out DNA methylation analysis on two separate CSV
> files (LGG and GBM), which I have downloaded onto my R console. To set the
> path<-"." to be indicative of one or both of the csv files, I utilized the
> following functions and received the errors shown. How do I set the "." so
> that I can begin analysis on my files?
>
> > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
> Error: unexpected string constant in "the_data
> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
> Error: unexpected string constant in
> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>
> This is the preliminary portion of the analysis I am trying to run, which I
> am referring to:
>
> 1 library(TCGAbiolinks)
> 2
> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> 4 path <? "."
> 5
> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
> level = 3)
> 7 TCGAdownload(query.met, path = path )
> 8 met <? TCGAprepare(query = query.met,dir = path,
> 9                      add.subtype = TRUE, add.clinical = TRUE,
> 10                    summarizedExperiment = TRUE,
> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> 12
> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform = "IlluminaHiSeq_
> RNASeqV2",level = 3)
> 15
> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> results")
> 17
> 18 exp <? TCGAprepare(query = query.exp, dir = path,
> 19                    summarizedExperiment = TRUE,
> 20                      add.subtype = TRUE, add.clinical = TRUE,
> 21                    type = "rsem.genes.normalized_results",
> 22                      save = T,filename = "lgg_gbm_exp.rda")
>
> Many thanks,
>
> Spencer Brackett
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Thu Aug 30 00:58:34 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Wed, 29 Aug 2018 18:58:34 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
Message-ID: <CAPQaxLPdeGESo-2AYmpxab88xFsFkRYJCzeNWyyrP86dFDKL0w@mail.gmail.com>

  Thank you! The line however was still found to be errored after I fixed
the mistake. Is there anything else I can do to maybe set the ?.? As an
object?

Spencer

On Wed, Aug 29, 2018 at 6:34 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> If you had an actual gene analysis question I'd suggest the
> BioConductor email list, but you have a plain old ordinary typo:
>
>  the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>
> You're missing the = after the argument sep
>
>  the_data <- read.csv(file = "LGG_clinical_drug.csv", header = TRUE, sep =
> ",")
>
> Using more spaces in your code would make that typo easier to spot.
>
> Sarah
> On Wed, Aug 29, 2018 at 6:06 PM Spencer Brackett
> <spbrackett20 at saintjosephhs.com> wrote:
> >
> > Good evening R users,
> >
> >   I am attempting to carry out DNA methylation analysis on two separate
> CSV
> > files (LGG and GBM), which I have downloaded onto my R console. To set
> the
> > path<-"." to be indicative of one or both of the csv files, I utilized
> the
> > following functions and received the errors shown. How do I set the "."
> so
> > that I can begin analysis on my files?
> >
> > > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
> > Error: unexpected string constant in "the_data
> > <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> > > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
> > Error: unexpected string constant in
> > "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
> >
> > This is the preliminary portion of the analysis I am trying to run,
> which I
> > am referring to:
> >
> > 1 library(TCGAbiolinks)
> > 2
> > 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> > 4 path <? "."
> > 5
> > 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
> > level = 3)
> > 7 TCGAdownload(query.met, path = path )
> > 8 met <? TCGAprepare(query = query.met,dir = path,
> > 9                      add.subtype = TRUE, add.clinical = TRUE,
> > 10                    summarizedExperiment = TRUE,
> > 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> > 12
> > 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
> > 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> "IlluminaHiSeq_
> > RNASeqV2",level = 3)
> > 15
> > 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> > results")
> > 17
> > 18 exp <? TCGAprepare(query = query.exp, dir = path,
> > 19                    summarizedExperiment = TRUE,
> > 20                      add.subtype = TRUE, add.clinical = TRUE,
> > 21                    type = "rsem.genes.normalized_results",
> > 22                      save = T,filename = "lgg_gbm_exp.rda")
> >
> > Many thanks,
> >
> > Spencer Brackett
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Thu Aug 30 01:06:39 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 29 Aug 2018 16:06:39 -0700
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
Message-ID: <CAGxFJbQaNYF_9Le18q2AksWcW3jHKiHRkxCEnsUXHeeBG5PP3w@mail.gmail.com>

As an aside, the sep = "," can be omitted, as that's the default anyway.

In his response to Sarah, the OP gave us only "the line was found to be
errored," which of course is useless. Perhaps if he provided explicit
information on what the call and the error was...

-- Bert



On Wed, Aug 29, 2018 at 3:34 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> If you had an actual gene analysis question I'd suggest the
> BioConductor email list, but you have a plain old ordinary typo:
>
>  the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>
> You're missing the = after the argument sep
>
>  the_data <- read.csv(file = "LGG_clinical_drug.csv", header = TRUE, sep =
> ",")
>
> Using more spaces in your code would make that typo easier to spot.
>
> Sarah
> On Wed, Aug 29, 2018 at 6:06 PM Spencer Brackett
> <spbrackett20 at saintjosephhs.com> wrote:
> >
> > Good evening R users,
> >
> >   I am attempting to carry out DNA methylation analysis on two separate
> CSV
> > files (LGG and GBM), which I have downloaded onto my R console. To set
> the
> > path<-"." to be indicative of one or both of the csv files, I utilized
> the
> > following functions and received the errors shown. How do I set the "."
> so
> > that I can begin analysis on my files?
> >
> > > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
> > Error: unexpected string constant in "the_data
> > <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> > > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
> > Error: unexpected string constant in
> > "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
> >
> > This is the preliminary portion of the analysis I am trying to run,
> which I
> > am referring to:
> >
> > 1 library(TCGAbiolinks)
> > 2
> > 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> > 4 path <? "."
> > 5
> > 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
> > level = 3)
> > 7 TCGAdownload(query.met, path = path )
> > 8 met <? TCGAprepare(query = query.met,dir = path,
> > 9                      add.subtype = TRUE, add.clinical = TRUE,
> > 10                    summarizedExperiment = TRUE,
> > 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> > 12
> > 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
> > 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> "IlluminaHiSeq_
> > RNASeqV2",level = 3)
> > 15
> > 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> > results")
> > 17
> > 18 exp <? TCGAprepare(query = query.exp, dir = path,
> > 19                    summarizedExperiment = TRUE,
> > 20                      add.subtype = TRUE, add.clinical = TRUE,
> > 21                    type = "rsem.genes.normalized_results",
> > 22                      save = T,filename = "lgg_gbm_exp.rda")
> >
> > Many thanks,
> >
> > Spencer Brackett
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Thu Aug 30 01:07:19 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Wed, 29 Aug 2018 19:07:19 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLPdeGESo-2AYmpxab88xFsFkRYJCzeNWyyrP86dFDKL0w@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
 <CAPQaxLPdeGESo-2AYmpxab88xFsFkRYJCzeNWyyrP86dFDKL0w@mail.gmail.com>
Message-ID: <CAM_vju=nSdoC5gEPuA8yOTTDhXfq5js5bWZr_OXFT03Z_xK6BQ@mail.gmail.com>

On Wed, Aug 29, 2018 at 6:58 PM Spencer Brackett
<spbrackett20 at saintjosephhs.com> wrote:
>
>   Thank you! The line however was still found to be errored after I fixed the mistake. Is there anything else I can do to maybe set the ?.? As an object?

But presumably with a different error, which you don't tell us.

The "." doesn't appear anywhere in the read.csv() command that you
initially reported an error in.
All a path of "." means is "look in the current directory." So later
in your download commands, files should be saved to the current
working directory. But that doesn't have anything to do with your
current csv file.

What does

getwd()

tell you? If it is NOT the same directory that contains
LGG_clinical_drug.csv then you need to tell read.csv() where to look
for it.

the_data <- read.csv(file = "path/to/file/LGG_clinical_drug.csv",
header = TRUE, sep = ",")

with whatever the actual path is.

If that's NOT the problem, or it still doesn't work, you'll need to
tell us more information. Like what the error message is, what getwd()
returns, and where the file actually is on your system.

The read.csv() commands don't seem to have anything at all to do with
the remaining part of the sample analysis you're trying to run


> Spencer
>
> On Wed, Aug 29, 2018 at 6:34 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> If you had an actual gene analysis question I'd suggest the
>> BioConductor email list, but you have a plain old ordinary typo:
>>
>>  the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>>
>> You're missing the = after the argument sep
>>
>>  the_data <- read.csv(file = "LGG_clinical_drug.csv", header = TRUE, sep = ",")
>>
>> Using more spaces in your code would make that typo easier to spot.
>>
>> Sarah
>> On Wed, Aug 29, 2018 at 6:06 PM Spencer Brackett
>> <spbrackett20 at saintjosephhs.com> wrote:
>> >
>> > Good evening R users,
>> >
>> >   I am attempting to carry out DNA methylation analysis on two separate CSV
>> > files (LGG and GBM), which I have downloaded onto my R console. To set the
>> > path<-"." to be indicative of one or both of the csv files, I utilized the
>> > following functions and received the errors shown. How do I set the "." so
>> > that I can begin analysis on my files?
>> >
>> > > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>> > Error: unexpected string constant in "the_data
>> > <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>> > > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>> > Error: unexpected string constant in
>> > "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>> >
>> > This is the preliminary portion of the analysis I am trying to run, which I
>> > am referring to:
>> >
>> > 1 library(TCGAbiolinks)
>> > 2
>> > 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> > 4 path <? "."
>> > 5
>> > 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> > level = 3)
>> > 7 TCGAdownload(query.met, path = path )
>> > 8 met <? TCGAprepare(query = query.met,dir = path,
>> > 9                      add.subtype = TRUE, add.clinical = TRUE,
>> > 10                    summarizedExperiment = TRUE,
>> > 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> > 12
>> > 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> > 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform = "IlluminaHiSeq_
>> > RNASeqV2",level = 3)
>> > 15
>> > 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> > results")
>> > 17
>> > 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> > 19                    summarizedExperiment = TRUE,
>> > 20                      add.subtype = TRUE, add.clinical = TRUE,
>> > 21                    type = "rsem.genes.normalized_results",
>> > 22                      save = T,filename = "lgg_gbm_exp.rda")
>> >
>> > Many thanks,
>> >
>> > Spencer Brackett
>> >
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org


From pd@lgd @ending from gm@il@com  Thu Aug 30 10:48:10 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Thu, 30 Aug 2018 10:48:10 +0200
Subject: [R] Estimate parameters differential equations system
In-Reply-To: <CANSOPkWhUaPMi-JM38qxwCtPVndjzZT8AyPbf+LBkJJy-zqB6Q@mail.gmail.com>
References: <CANSOPkWhUaPMi-JM38qxwCtPVndjzZT8AyPbf+LBkJJy-zqB6Q@mail.gmail.com>
Message-ID: <39D9F9FA-6506-4AB1-B098-738FBDF2F1D6@gmail.com>

If you can solve the system and the parameters are identifiable from the y component, then I would think that nls() can do it. However, beware unidentifiablity: If x stays constant at its equilibrium value of (er...) d1*c/(m+d1), then even knowing x won't allow you to tease out c, d1, and m; and not knowing x you can't separate m from x in the mx term in dy/dt. So it likely depends on the exact experiment, especially the initial conditions of the system whether you can estimate things or not.

-pd

> On 29 Aug 2018, at 15:19 , Fanny Gallais <gallais.fanny at gmail.com> wrote:
> 
> Dear R users,
> 
> 
> 
> I am working on a simple mathematical model made of two ordinary
> differential equations:
> 
> 
> 
> dx/dt=-mx-d1(x-c)
> 
> dy/dt=mx-d2y
> 
> 
> 
> I would like to fit this model to my data and estimate the corresponding
> parameters. The thing is I only have observed data for y, x is unknown. Is
> it possible to do this in R?
> 
> 
> 
> Thank you for your help
> 
> Fanny
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Bill@Poling @ending from zeli@@com  Thu Aug 30 14:41:37 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 30 Aug 2018 12:41:37 +0000
Subject: [R] Obtaining Complete Dataset with Imputed Values
In-Reply-To: <CAMOcQfOFkwSUVhXGCy7-R-3YGLC0swMY-1TjBLTQTR_jpJsgRQ@mail.gmail.com>
References: <CAMOcQfOFkwSUVhXGCy7-R-3YGLC0swMY-1TjBLTQTR_jpJsgRQ@mail.gmail.com>
Message-ID: <BN7PR02MB5073FD3BECD27322684988B7EA080@BN7PR02MB5073.namprd02.prod.outlook.com>

Good morning Paul.

I am unfamiliar with the package you are using but I have been working through the tutorial for this purpose using finalfit, if that is any help.

Cheers

WHP

http://www.datasurg.net/2018/08/29/five-steps-for-missing-data-with-finalfit/


From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
Sent: Friday, August 24, 2018 2:57 PM
To: r-help at r-project.org
Subject: [R] Obtaining Complete Dataset with Imputed Values

Dear friends, hope all is well with you,

I am working with package mi for data inputation. Currently working with R
version 3.5.0 (64-bit).

Say my data is defined as dat, and I do the following:

datimputations <- mi(dat[2:5], n.iter=50)
completedat <- complete(datimputations)

After using the complete function, I get the following error message:

Error in complete(datimputations, m = 1) : 'data' not of class 'mids'

How can I retrieve the processed dataframe (along with the imputed values)?

Here is my dput() for you to see

> dput(head(dat,100))
structure(list(TransitDate = structure(c(496990800, 499669200,
502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
754722000, 757400400), class = c("POSIXct", "POSIXt"), tzone = ""),
Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L, 14L, 16L,
6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L, 10L,
9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L,
5L, 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L,
9L, 8L, 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L,
14L, 15L, 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L,
9L, 12L, 8L, 12L, 10L, 11L, 10L, 9L, 10L), CargoTons = c(154973L,
129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L,
98222L, 54719L, 98470L, 18263L, 104255L, 62869L, 62523L,
75344L, 81476L, 92818L, 87457L, 85231L, 77897L, 57699L, 96989L,
109361L, 59799L, 91116L, 82241L, 74251L, 124361L, 68751L,
61719L, 68017L, 37760L, 32513L, 56359L, 51333L, 80859L, 75852L,
65760L, 96043L, 38820L, 63202L, 102647L, 49104L, 53482L,
121305L, 71795L, 76704L, 146097L, 73047L, 68557L, 110642L,
77616L, 97767L, 52059L, 58658L, 66350L, 69303L, 76013L, 91909L,
108445L, 94454L, 101249L, 112131L, 56290L, 118342L, 70618L,
64783L, 112839L, 120506L, 94243L, 130768L, 133643L, 146321L,
140736L, 147234L, 158953L, 189888L, 93819L, 130021L, 130124L,
55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
93713L, 98417L, 97210L, 88464L, 94659L), RcnstPCUMS = c(229914L,
214547L, 215890L, 158695L, 173125L, 222533L, 212490L, 222125L,
266913L, 94268L, 112967L, 95480L, 87654L, 108996L, 97973L,
139247L, 93817L, 133197L, 40020L, 169749L, 102590L, 112121L,
140241L, 122989L, 144592L, 144979L, 123748L, 123249L, 70081L,
155218L, 168096L, 104743L, 163384L, 142648L, 129188L, 183170L,
99299L, 99873L, 111648L, 55890L, 59183L, 95568L, 72550L,
104562L, 100478L, 92665L, 130625L, 54786L, 105900L, 135833L,
70932L, 73247L, 149632L, 94317L, 87926L, 181989L, 92778L,
107097L, 153246L, 105175L, 126393L, 81976L, 95518L, 109019L,
95370L, 140492L, 125795L, 157978L, 138424L, 138160L, 180320L,
78757L, 135860L, 85921L, 114847L, 151965L, 152561L, 132841L,
204839L, 209567L, 224436L, 210209L, 227143L, 245968L, 264969L,
158648L, 222251L, 194335L, 111618L, 189643L, 137438L, 124953L,
163155L, 107633L, 164525L, 135102L, 152072L, 126636L, 121008L,
137824L), TotalToll = c(420742L, 392621L, 395078L, 290411L,
316818L, 407235L, 388856L, 406488L, 482774L, 172510L, 206729L,
174728L, 160406L, 199462L, 179290L, 254822L, 171685L, 243750L,
73236L, 310640L, 187739L, 205181L, 249438L, 225069L, 264603L,
265311L, 226458L, 225545L, 128248L, 284048L, 296023L, 184934L,
298992L, 261045L, 236414L, 335201L, 181717L, 182767L, 204315L,
102278L, 108304L, 174889L, 132766L, 191348L, 183874L, 169576L,
239043L, 100258L, 212859L, 273024L, 142573L, 147226L, 300760L,
189577L, 176731L, 365797L, 186483L, 215264L, 308024L, 211401L,
254049L, 164771L, 191991L, 219128L, 191693L, 282388L, 252847L,
317535L, 278232L, 277701L, 356022L, 158301L, 273078L, 172701L,
230842L, 305449L, 306647L, 267010L, 406202L, 421229L, 451116L,
422520L, 456557L, 494395L, 582202L, 350612L, 491174L, 429480L,
239858L, 419111L, 303737L, 276146L, 360572L, 237868L, 358627L,
298575L, 336079L, 279865L, 267427L, 304591L)), row.names = c(NA,
100L), class = "data.frame")

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From jfox @ending from mcm@@ter@c@  Thu Aug 30 16:18:30 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Thu, 30 Aug 2018 14:18:30 +0000
Subject: [R] Obtaining Complete Dataset with Imputed Values
In-Reply-To: <24780_1535632920_w7UCfxIP009372_BN7PR02MB5073FD3BECD27322684988B7EA080@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <CAMOcQfOFkwSUVhXGCy7-R-3YGLC0swMY-1TjBLTQTR_jpJsgRQ@mail.gmail.com>
 <24780_1535632920_w7UCfxIP009372_BN7PR02MB5073FD3BECD27322684988B7EA080@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A550E@FHSDB2D11-2.csu.mcmaster.ca>

Dear Paul and WHP,

My guess: Paul apparently has loaded the mice package after the mi package. Both packages have complete() functions, but for objects of different classes -- "mids" in the case of mice. Consquently, complete() in the mice package is shadowing complete() in the mi package.

The solution is not to load both packages unless you actually need to, load mi after mice (though then other similar problems might surface), or invoke mi::complete()  explicitly.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bill Poling
> Sent: Thursday, August 30, 2018 8:42 AM
> To: Paul Bernal <paulbernal07 at gmail.com>; r-help at r-project.org
> Subject: Re: [R] Obtaining Complete Dataset with Imputed Values
> 
> Good morning Paul.
> 
> I am unfamiliar with the package you are using but I have been working
> through the tutorial for this purpose using finalfit, if that is any help.
> 
> Cheers
> 
> WHP
> 
> http://www.datasurg.net/2018/08/29/five-steps-for-missing-data-with-
> finalfit/
> 
> 
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
> Sent: Friday, August 24, 2018 2:57 PM
> To: r-help at r-project.org
> Subject: [R] Obtaining Complete Dataset with Imputed Values
> 
> Dear friends, hope all is well with you,
> 
> I am working with package mi for data inputation. Currently working with R
> version 3.5.0 (64-bit).
> 
> Say my data is defined as dat, and I do the following:
> 
> datimputations <- mi(dat[2:5], n.iter=50) completedat <-
> complete(datimputations)
> 
> After using the complete function, I get the following error message:
> 
> Error in complete(datimputations, m = 1) : 'data' not of class 'mids'
> 
> How can I retrieve the processed dataframe (along with the imputed values)?
> 
> Here is my dput() for you to see
> 
> > dput(head(dat,100))
> structure(list(TransitDate = structure(c(496990800, 499669200, 502261200,
> 504939600, 507618000, 510037200, 512715600, 515307600, 517986000,
> 520578000, 523256400, 525934800, 528526800, 531205200, 533797200,
> 536475600, 539154000, 541573200, 544251600, 546843600, 549522000,
> 552114000, 554792400, 557470800, 560062800, 562741200, 565333200,
> 568011600, 570690000, 573195600, 575874000, 578466000, 581144400,
> 583736400, 586414800, 589093200, 591685200, 594363600, 596955600,
> 599634000, 602312400, 604731600, 607410000, 610002000, 612680400,
> 615272400, 617950800, 620629200, 623221200, 625899600, 628491600,
> 631170000, 633848400, 636267600, 638946000, 641538000, 644216400,
> 646808400, 649486800, 652165200, 654757200, 657435600, 660027600,
> 662706000, 665384400, 667803600, 670482000, 673074000, 675752400,
> 678344400, 681022800, 683701200, 686293200, 688971600, 691563600,
> 694242000, 696920400, 699426000, 702104400, 704696400, 707371200,
> 709963200, 712641600, 715320000, 717912000, 720590400, 723182400,
> 725860800, 728539200, 730958400, 733636800, 736232400, 738910800,
> 741502800, 744181200, 746859600, 749451600, 752130000, 754722000,
> 757400400), class = c("POSIXct", "POSIXt"), tzone = ""), Transits = c(14L, 14L,
> 13L, 10L, 11L, 14L, 14L, 14L, 16L, 6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L,
> 8L, 10L, 9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L, 7L, 7L, 8L, 4L,
> 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L, 5L, 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L,
> 5L, 6L, 7L, 6L, 9L, 8L, 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L, 14L, 15L,
> 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L, 9L, 12L, 8L, 12L, 10L, 11L, 10L,
> 9L, 10L), CargoTons = c(154973L, 129636L, 136884L, 86348L, 109907L,
> 154506L, 144083L, 152794L, 124861L, 60330L, 65221L, 61718L, 53997L,
> 83536L, 63218L, 98222L, 54719L, 98470L, 18263L, 104255L, 62869L, 62523L,
> 75344L, 81476L, 92818L, 87457L, 85231L, 77897L, 57699L, 96989L, 109361L,
> 59799L, 91116L, 82241L, 74251L, 124361L, 68751L, 61719L, 68017L, 37760L,
> 32513L, 56359L, 51333L, 80859L, 75852L, 65760L, 96043L, 38820L, 63202L,
> 102647L, 49104L, 53482L, 121305L, 71795L, 76704L, 146097L, 73047L,
> 68557L, 110642L, 77616L, 97767L, 52059L, 58658L, 66350L, 69303L, 76013L,
> 91909L, 108445L, 94454L, 101249L, 112131L, 56290L, 118342L, 70618L,
> 64783L, 112839L, 120506L, 94243L, 130768L, 133643L, 146321L, 140736L,
> 147234L, 158953L, 189888L, 93819L, 130021L, 130124L, 55088L, 114783L,
> 95184L, 82205L, 80321L, 65422L, 98933L, 93713L, 98417L, 97210L, 88464L,
> 94659L), RcnstPCUMS = c(229914L, 214547L, 215890L, 158695L, 173125L,
> 222533L, 212490L, 222125L, 266913L, 94268L, 112967L, 95480L, 87654L,
> 108996L, 97973L, 139247L, 93817L, 133197L, 40020L, 169749L, 102590L,
> 112121L, 140241L, 122989L, 144592L, 144979L, 123748L, 123249L, 70081L,
> 155218L, 168096L, 104743L, 163384L, 142648L, 129188L, 183170L, 99299L,
> 99873L, 111648L, 55890L, 59183L, 95568L, 72550L, 104562L, 100478L,
> 92665L, 130625L, 54786L, 105900L, 135833L, 70932L, 73247L, 149632L,
> 94317L, 87926L, 181989L, 92778L, 107097L, 153246L, 105175L, 126393L,
> 81976L, 95518L, 109019L, 95370L, 140492L, 125795L, 157978L, 138424L,
> 138160L, 180320L, 78757L, 135860L, 85921L, 114847L, 151965L, 152561L,
> 132841L, 204839L, 209567L, 224436L, 210209L, 227143L, 245968L, 264969L,
> 158648L, 222251L, 194335L, 111618L, 189643L, 137438L, 124953L, 163155L,
> 107633L, 164525L, 135102L, 152072L, 126636L, 121008L, 137824L), TotalToll
> = c(420742L, 392621L, 395078L, 290411L, 316818L, 407235L, 388856L,
> 406488L, 482774L, 172510L, 206729L, 174728L, 160406L, 199462L, 179290L,
> 254822L, 171685L, 243750L, 73236L, 310640L, 187739L, 205181L, 249438L,
> 225069L, 264603L, 265311L, 226458L, 225545L, 128248L, 284048L, 296023L,
> 184934L, 298992L, 261045L, 236414L, 335201L, 181717L, 182767L, 204315L,
> 102278L, 108304L, 174889L, 132766L, 191348L, 183874L, 169576L, 239043L,
> 100258L, 212859L, 273024L, 142573L, 147226L, 300760L, 189577L, 176731L,
> 365797L, 186483L, 215264L, 308024L, 211401L, 254049L, 164771L, 191991L,
> 219128L, 191693L, 282388L, 252847L, 317535L, 278232L, 277701L, 356022L,
> 158301L, 273078L, 172701L, 230842L, 305449L, 306647L, 267010L, 406202L,
> 421229L, 451116L, 422520L, 456557L, 494395L, 582202L, 350612L, 491174L,
> 429480L, 239858L, 419111L, 303737L, 276146L, 360572L, 237868L, 358627L,
> 298575L, 336079L, 279865L, 267427L, 304591L)), row.names = c(NA, 100L),
> class = "data.frame")
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-
> help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From orchidn @ending from live@com  Thu Aug 30 18:46:40 2018
From: orchidn @ending from live@com (dani)
Date: Thu, 30 Aug 2018 16:46:40 +0000
Subject: [R] standardized regression coefficients in GAM
Message-ID: <BYAPR06MB38320BDE72A62F65A4D9E5B5D6080@BYAPR06MB3832.namprd06.prod.outlook.com>

Hello everyone,


I was wondering if anyone can help me calculate standardized regression coefficients from a GAM model.

I have some dummy and some continuous covariates in my GAM model. I know I could standardize only the continuous covariates and re-run the model to get the standardized coefficients. Can anyone help with some R code to create the standardized coefficients after obtaining a GAM model based on unstandardized coefficients?


Also, on a separate note, what do I do with the dummy covariates - should I just include them as they are in the model with standardized variables? I do not see how I can standardize dummy variables.


Thank you!

Best,

Dani

<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Thu Aug 30 20:37:17 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Thu, 30 Aug 2018 18:37:17 +0000
Subject: [R] standardized regression coefficients in GAM
In-Reply-To: <2250_1535647791_w7UGnopD005648_BYAPR06MB38320BDE72A62F65A4D9E5B5D6080@BYAPR06MB3832.namprd06.prod.outlook.com>
References: <2250_1535647791_w7UGnopD005648_BYAPR06MB38320BDE72A62F65A4D9E5B5D6080@BYAPR06MB3832.namprd06.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A5784@FHSDB2D11-2.csu.mcmaster.ca>

Dear Dani,

I'll address your questions briefly below. They aren't unique to GAMs.

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of dani
> Sent: Thursday, August 30, 2018 12:47 PM
> To: r-help at r-project.org
> Subject: [R] standardized regression coefficients in GAM
> 
> Hello everyone,
> 
> 
> I was wondering if anyone can help me calculate standardized regression
> coefficients from a GAM model.
> 
> I have some dummy and some continuous covariates in my GAM model. I
> know I could standardize only the continuous covariates and re-run the model
> to get the standardized coefficients. Can anyone help with some R code to
> create the standardized coefficients after obtaining a GAM model based on
> unstandardized coefficients?

Why one would want to do this isn't clear to me, but you can just multiply each such coefficient by the standard deviation of the corresponding X and divide by the standard deviation of Y.

> 
> 
> Also, on a separate note, what do I do with the dummy covariates - should I
> just include them as they are in the model with standardized variables? I do
> not see how I can standardize dummy variables.

Standardizing dummy regressors is nonsense, so don't do it. If there are interaction regressors in your model, don't standardize those either.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> 
> 
> Thank you!
> 
> Best,
> 
> Dani
> 
> <http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From orchidn @ending from live@com  Thu Aug 30 20:43:28 2018
From: orchidn @ending from live@com (dani)
Date: Thu, 30 Aug 2018 18:43:28 +0000
Subject: [R] standardized regression coefficients in GAM
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8368A5784@FHSDB2D11-2.csu.mcmaster.ca>
References: <2250_1535647791_w7UGnopD005648_BYAPR06MB38320BDE72A62F65A4D9E5B5D6080@BYAPR06MB3832.namprd06.prod.outlook.com>,
 <ACD1644AA6C67E4FBD0C350625508EC8368A5784@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <BYAPR06MB3832B6A24706E379A8E5D241D6080@BYAPR06MB3832.namprd06.prod.outlook.com>

Dear Dr Fox,


Thank you so much for your response! I will report the results of the regression models only based on unstandardized coefficients then, it seems to be best.


Thanks for taking the time to respond and clarify this issue for me!

Best regards,

Dani


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Fox, John <jfox at mcmaster.ca>
Sent: Thursday, August 30, 2018 11:37 AM
To: dani
Cc: r-help at r-project.org
Subject: RE: standardized regression coefficients in GAM

Dear Dani,

I'll address your questions briefly below. They aren't unique to GAMs.

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of dani
> Sent: Thursday, August 30, 2018 12:47 PM
> To: r-help at r-project.org
> Subject: [R] standardized regression coefficients in GAM
>
> Hello everyone,
>
>
> I was wondering if anyone can help me calculate standardized regression
> coefficients from a GAM model.
>
> I have some dummy and some continuous covariates in my GAM model. I
> know I could standardize only the continuous covariates and re-run the model
> to get the standardized coefficients. Can anyone help with some R code to
> create the standardized coefficients after obtaining a GAM model based on
> unstandardized coefficients?

Why one would want to do this isn't clear to me, but you can just multiply each such coefficient by the standard deviation of the corresponding X and divide by the standard deviation of Y.

>
>
> Also, on a separate note, what do I do with the dummy covariates - should I
> just include them as they are in the model with standardized variables? I do
> not see how I can standardize dummy variables.

Standardizing dummy regressors is nonsense, so don't do it. If there are interaction regressors in your model, don't standardize those either.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



>
>
> Thank you!
>
> Best,
>
> Dani
>
> <http://aka.ms/weboutlook>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From k@belimef@ne @ending from y@hoo@co@uk  Thu Aug 30 23:39:48 2018
From: k@belimef@ne @ending from y@hoo@co@uk (KABELI MEFANE)
Date: Thu, 30 Aug 2018 21:39:48 +0000 (UTC)
Subject: [R] R code for parameter estimates
References: <966262583.1956370.1535665188559.ref@mail.yahoo.com>
Message-ID: <966262583.1956370.1535665188559@mail.yahoo.com>

Hello R -helpers


Can you please be kind enough to help me the R code for GEV parameter estimates using Bayes, I have done them using MLE and it would really be nice to compare. I am trying to model rainfall data, i have used sevaral distributions such as lognormal, Burr, Pearson, GEV but the three parameter lognormal and log Pearson were a hustle due to the shift parameter. NowI want to use Bayes.

Best Regards
Kabeli Mefane

?Tell me and I'll forget; show me and I may remember; involve me and I'll understand.?

	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Fri Aug 31 02:53:38 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Thu, 30 Aug 2018 20:53:38 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
Message-ID: <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>

Hello again,

My apologies for the delayed response... computer troubles. In reference to
Ms. Goslee's and Mr. Barry's query, the following is the error code
received after I inputted my R command

 the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
Error: unexpected string constant in
"the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""

Given this, should I proceed with implementing the path<getwd() ,since I
am, as he suggested trying to set the variable *path* to my working
directory with path<-"."

Mr. Mittal also recommended importing with r studio, which I shall try in
the meantime.

Many thanks,

Spencer Brackett


On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <prof.amit.mittal at gmail.com>
wrote:

> Use r studio and import from the menu. Read_csv has changed
>
> Also you can see any format problems
>
> On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Good evening R users,
>>
>>   I am attempting to carry out DNA methylation analysis on two separate
>> CSV
>> files (LGG and GBM), which I have downloaded onto my R console. To set the
>> path<-"." to be indicative of one or both of the csv files, I utilized the
>> following functions and received the errors shown. How do I set the "." so
>> that I can begin analysis on my files?
>>
>> > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>> Error: unexpected string constant in "the_data
>> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>> Error: unexpected string constant in
>> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>>
>> This is the preliminary portion of the analysis I am trying to run, which
>> I
>> am referring to:
>>
>> 1 library(TCGAbiolinks)
>> 2
>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> 4 path <? "."
>> 5
>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> level = 3)
>> 7 TCGAdownload(query.met, path = path )
>> 8 met <? TCGAprepare(query = query.met,dir = path,
>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>> 10                    summarizedExperiment = TRUE,
>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> 12
>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>> "IlluminaHiSeq_
>> RNASeqV2",level = 3)
>> 15
>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> results")
>> 17
>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> 19                    summarizedExperiment = TRUE,
>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>> 21                    type = "rsem.genes.normalized_results",
>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>
>> Many thanks,
>>
>> Spencer Brackett
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @ending from @@intjo@ephh@@com  Fri Aug 31 03:05:17 2018
From: @pbr@ckett20 @ending from @@intjo@ephh@@com (Spencer Brackett)
Date: Thu, 30 Aug 2018 21:05:17 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
 <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>
 <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
Message-ID: <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>

My apologies... the following is what I received from the correction

 the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep=",")
Warning messages:
1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
  line 3 appears to contain embedded nulls
2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
  line 4 appears to contain embedded nulls
3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
  line 5 appears to contain embedded nulls
4: In scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :
  embedded nul(s) found in input
>


On Thu, Aug 30, 2018 at 8:57 PM Patrick Barry <pdbarry at alaska.edu> wrote:

> You still haven't fixed the first thing both Sarah and I pointed out. You
> are lacking an = between sep and ","
>
> the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>
> should be
>
> the_data <- read.csv(file = "GBM_clinical_drug.csv", header = TRUE, *sep
> = ","*)
>
> as Sarah pointed out, you should use spaces to help make these errors more
> obvious.
>
> On Thu, Aug 30, 2018 at 4:53 PM, Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Hello again,
>>
>> My apologies for the delayed response... computer troubles. In reference
>> to
>> Ms. Goslee's and Mr. Barry's query, the following is the error code
>> received after I inputted my R command
>>
>>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>> Error: unexpected string constant in
>> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""
>>
>> Given this, should I proceed with implementing the path<getwd() ,since I
>> am, as he suggested trying to set the variable *path* to my working
>> directory with path<-"."
>>
>> Mr. Mittal also recommended importing with r studio, which I shall try in
>> the meantime.
>>
>> Many thanks,
>>
>> Spencer Brackett
>>
>>
>> On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <prof.amit.mittal at gmail.com>
>> wrote:
>>
>> > Use r studio and import from the menu. Read_csv has changed
>> >
>> > Also you can see any format problems
>> >
>> > On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
>> > spbrackett20 at saintjosephhs.com> wrote:
>> >
>> >> Good evening R users,
>> >>
>> >>   I am attempting to carry out DNA methylation analysis on two separate
>> >> CSV
>> >> files (LGG and GBM), which I have downloaded onto my R console. To set
>> the
>> >> path<-"." to be indicative of one or both of the csv files, I utilized
>> the
>> >> following functions and received the errors shown. How do I set the
>> "." so
>> >> that I can begin analysis on my files?
>> >>
>> >> > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>> >> Error: unexpected string constant in "the_data
>> >> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>> >> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>> >> Error: unexpected string constant in
>> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>> >>
>> >> This is the preliminary portion of the analysis I am trying to run,
>> which
>> >> I
>> >> am referring to:
>> >>
>> >> 1 library(TCGAbiolinks)
>> >> 2
>> >> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> >> 4 path <? "."
>> >> 5
>> >> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> >> level = 3)
>> >> 7 TCGAdownload(query.met, path = path )
>> >> 8 met <? TCGAprepare(query = query.met,dir = path,
>> >> 9                      add.subtype = TRUE, add.clinical = TRUE,
>> >> 10                    summarizedExperiment = TRUE,
>> >> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> >> 12
>> >> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> >> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>> >> "IlluminaHiSeq_
>> >> RNASeqV2",level = 3)
>> >> 15
>> >> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> >> results")
>> >> 17
>> >> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> >> 19                    summarizedExperiment = TRUE,
>> >> 20                      add.subtype = TRUE, add.clinical = TRUE,
>> >> 21                    type = "rsem.genes.normalized_results",
>> >> 22                      save = T,filename = "lgg_gbm_exp.rda")
>> >>
>> >> Many thanks,
>> >>
>> >> Spencer Brackett
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Aug 31 04:20:40 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 30 Aug 2018 19:20:40 -0700
Subject: [R] R code for parameter estimates
In-Reply-To: <966262583.1956370.1535665188559@mail.yahoo.com>
References: <966262583.1956370.1535665188559.ref@mail.yahoo.com>
 <966262583.1956370.1535665188559@mail.yahoo.com>
Message-ID: <CAGxFJbR7w1RaAb5=4dZ47k2=BrVvFjadx5HATaw-WxETQsOmpg@mail.gmail.com>

As you have completely failed to follow procedures described in the posting
guide linked below, your post is unlikely to receive any response.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 30, 2018 at 3:08 PM KABELI MEFANE via R-help <
r-help at r-project.org> wrote:

> Hello R -helpers
>
>
> Can you please be kind enough to help me the R code for GEV parameter
> estimates using Bayes, I have done them using MLE and it would really be
> nice to compare. I am trying to model rainfall data, i have used sevaral
> distributions such as lognormal, Burr, Pearson, GEV but the three parameter
> lognormal and log Pearson were a hustle due to the shift parameter. NowI
> want to use Bayes.
>
> Best Regards
> Kabeli Mefane
>
> ?Tell me and I'll forget; show me and I may remember; involve me and I'll
> understand.?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Fri Aug 31 13:03:00 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Fri, 31 Aug 2018 13:03:00 +0200
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
 <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>
 <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
 <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
Message-ID: <34AA2079-B7A4-4DC1-8CFF-EE271C843DD0@gmail.com>

At this point, it seems pretty clear that the issue is in the data file itself. Possibilities are that it is either not a CSV file to begin with or in some exotic encoding (utf-16?). 

You probably need to look at the file in a text editor to see whether the context makes sense as comma-separated variables. 

Also, perhaps review the download mechanism --- recently I have found several students shooting themselves in the foot by downloading .csv files, having them automatically  opened by Excel and the save them _in_ Excel, garbling the file in the process.

-pd

> On 31 Aug 2018, at 03:05 , Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> My apologies... the following is what I received from the correction
> 
> the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep=",")
> Warning messages:
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>  line 3 appears to contain embedded nulls
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>  line 4 appears to contain embedded nulls
> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>  line 5 appears to contain embedded nulls
> 4: In scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :
>  embedded nul(s) found in input
>> 
> 
> 
> On Thu, Aug 30, 2018 at 8:57 PM Patrick Barry <pdbarry at alaska.edu> wrote:
> 
>> You still haven't fixed the first thing both Sarah and I pointed out. You
>> are lacking an = between sep and ","
>> 
>> the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>> 
>> should be
>> 
>> the_data <- read.csv(file = "GBM_clinical_drug.csv", header = TRUE, *sep
>> = ","*)
>> 
>> as Sarah pointed out, you should use spaces to help make these errors more
>> obvious.
>> 
>> On Thu, Aug 30, 2018 at 4:53 PM, Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>> 
>>> Hello again,
>>> 
>>> My apologies for the delayed response... computer troubles. In reference
>>> to
>>> Ms. Goslee's and Mr. Barry's query, the following is the error code
>>> received after I inputted my R command
>>> 
>>> the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>>> Error: unexpected string constant in
>>> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""
>>> 
>>> Given this, should I proceed with implementing the path<getwd() ,since I
>>> am, as he suggested trying to set the variable *path* to my working
>>> directory with path<-"."
>>> 
>>> Mr. Mittal also recommended importing with r studio, which I shall try in
>>> the meantime.
>>> 
>>> Many thanks,
>>> 
>>> Spencer Brackett
>>> 
>>> 
>>> On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <prof.amit.mittal at gmail.com>
>>> wrote:
>>> 
>>>> Use r studio and import from the menu. Read_csv has changed
>>>> 
>>>> Also you can see any format problems
>>>> 
>>>> On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>> 
>>>>> Good evening R users,
>>>>> 
>>>>>  I am attempting to carry out DNA methylation analysis on two separate
>>>>> CSV
>>>>> files (LGG and GBM), which I have downloaded onto my R console. To set
>>> the
>>>>> path<-"." to be indicative of one or both of the csv files, I utilized
>>> the
>>>>> following functions and received the errors shown. How do I set the
>>> "." so
>>>>> that I can begin analysis on my files?
>>>>> 
>>>>>> the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>>>>> Error: unexpected string constant in "the_data
>>>>> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>>>>>> the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>>>>> Error: unexpected string constant in
>>>>> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>>>>> 
>>>>> This is the preliminary portion of the analysis I am trying to run,
>>> which
>>>>> I
>>>>> am referring to:
>>>>> 
>>>>> 1 library(TCGAbiolinks)
>>>>> 2
>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>>>>> 4 path <? "."
>>>>> 5
>>>>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>>>>> level = 3)
>>>>> 7 TCGAdownload(query.met, path = path )
>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>>> 10                    summarizedExperiment = TRUE,
>>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>>> 12
>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>>> "IlluminaHiSeq_
>>>>> RNASeqV2",level = 3)
>>>>> 15
>>>>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>>>>> results")
>>>>> 17
>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>>> 19                    summarizedExperiment = TRUE,
>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>>> 21                    type = "rsem.genes.normalized_results",
>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>> 
>>>>> Many thanks,
>>>>> 
>>>>> Spencer Brackett
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From nichol@@@wr@y @ending from ntlworld@com  Fri Aug 31 13:42:19 2018
From: nichol@@@wr@y @ending from ntlworld@com (Nick Wray)
Date: Fri, 31 Aug 2018 12:42:19 +0100 (BST)
Subject: [R] Main label on Cullen and Frey
Message-ID: <2040384799.899784.1535715740012@mail2.virginmedia.com>

Hello   Does anyone know how to modify the main label when you plot a Cullen & Frey (sounds like an Oxford gentleman's outfitters - statistically significant waistcoats a speciality) diagram from the "descdist" function?  I've tried setting a variable to the descdist(data) but it just returns the summary statistics.

Thanks

Nick Wray
	[[alternative HTML version deleted]]


From nichol@@@wr@y @ending from ntlworld@com  Fri Aug 31 16:40:55 2018
From: nichol@@@wr@y @ending from ntlworld@com (Nick Wray)
Date: Fri, 31 Aug 2018 15:40:55 +0100 (BST)
Subject: [R] Resetting bin size in histogram having already changed to
 relative frequencies
Message-ID: <1389669594.915788.1535726455670@mail2.virginmedia.com>

Hello again.  I am trying to alter the bin size on a histogram where I have reset the vertical axis to relative frequency, rather than absolute.  Beneath is a simple example (not my real data) of this:

xvals<-rnorm(1000,0,1)
xvals
hist(xvals)
h<-hist(xvals,plot=F)

h
h$counts
h$counts<-h$counts/sum(h$counts)
h$counts
plot(h,freq=T,ylab="Relative Frequency")


This gives me a plot with bin sizes of 0.5 and the relative frequency, but I cannot reset the bin size as well.  I don't know whether the only way to do it is to reset all the h$mids etc as well but this seems horrendously complicated and I wonder whether I am missing something simple

Any ideas I would be thankful for   Nick Wray

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Aug 31 16:48:52 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 31 Aug 2018 07:48:52 -0700
Subject: [R] Resetting bin size in histogram having already changed to
 relative frequencies
In-Reply-To: <1389669594.915788.1535726455670@mail2.virginmedia.com>
References: <1389669594.915788.1535726455670@mail2.virginmedia.com>
Message-ID: <CAGxFJbQNSxnSzy3SNWuQnw6UJS8-pRvxA_WX-K7AKBLb+=PJPg@mail.gmail.com>

Consult the docs, please. ?hist and the "breaks" argument. Also note the
"freq" argument, which means you should not be computing relative
frequencies manually.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 31, 2018 at 7:42 AM Nick Wray via R-help <r-help at r-project.org>
wrote:

> Hello again.  I am trying to alter the bin size on a histogram where I
> have reset the vertical axis to relative frequency, rather than absolute.
> Beneath is a simple example (not my real data) of this:
>
> xvals<-rnorm(1000,0,1)
> xvals
> hist(xvals)
> h<-hist(xvals,plot=F)
>
> h
> h$counts
> h$counts<-h$counts/sum(h$counts)
> h$counts
> plot(h,freq=T,ylab="Relative Frequency")
>
>
> This gives me a plot with bin sizes of 0.5 and the relative frequency, but
> I cannot reset the bin size as well.  I don't know whether the only way to
> do it is to reset all the h$mids etc as well but this seems horrendously
> complicated and I wonder whether I am missing something simple
>
> Any ideas I would be thankful for   Nick Wray
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Fri Aug 31 17:12:20 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 31 Aug 2018 08:12:20 -0700
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
 <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>
 <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
 <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
Message-ID: <CAF8bMcbCFbVbdgDbqbisyKZ+fYnBmW8ybSQD4mMym8Rgaa_9qg@mail.gmail.com>

Try adding fileEncoding="UTF-16" to your read.csv() call.  Many Windows
programs write UTF-16 files by default.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Aug 30, 2018 at 6:05 PM, Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> My apologies... the following is what I received from the correction
>
>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep=",")
> Warning messages:
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   line 3 appears to contain embedded nulls
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   line 4 appears to contain embedded nulls
> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   line 5 appears to contain embedded nulls
> 4: In scan(file = file, what = what, sep = sep, quote = quote, dec = dec,
> :
>   embedded nul(s) found in input
> >
>
>
> On Thu, Aug 30, 2018 at 8:57 PM Patrick Barry <pdbarry at alaska.edu> wrote:
>
> > You still haven't fixed the first thing both Sarah and I pointed out. You
> > are lacking an = between sep and ","
> >
> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
> >
> > should be
> >
> > the_data <- read.csv(file = "GBM_clinical_drug.csv", header = TRUE, *sep
> > = ","*)
> >
> > as Sarah pointed out, you should use spaces to help make these errors
> more
> > obvious.
> >
> > On Thu, Aug 30, 2018 at 4:53 PM, Spencer Brackett <
> > spbrackett20 at saintjosephhs.com> wrote:
> >
> >> Hello again,
> >>
> >> My apologies for the delayed response... computer troubles. In reference
> >> to
> >> Ms. Goslee's and Mr. Barry's query, the following is the error code
> >> received after I inputted my R command
> >>
> >>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
> >> Error: unexpected string constant in
> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""
> >>
> >> Given this, should I proceed with implementing the path<getwd() ,since I
> >> am, as he suggested trying to set the variable *path* to my working
> >> directory with path<-"."
> >>
> >> Mr. Mittal also recommended importing with r studio, which I shall try
> in
> >> the meantime.
> >>
> >> Many thanks,
> >>
> >> Spencer Brackett
> >>
> >>
> >> On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <
> prof.amit.mittal at gmail.com>
> >> wrote:
> >>
> >> > Use r studio and import from the menu. Read_csv has changed
> >> >
> >> > Also you can see any format problems
> >> >
> >> > On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
> >> > spbrackett20 at saintjosephhs.com> wrote:
> >> >
> >> >> Good evening R users,
> >> >>
> >> >>   I am attempting to carry out DNA methylation analysis on two
> separate
> >> >> CSV
> >> >> files (LGG and GBM), which I have downloaded onto my R console. To
> set
> >> the
> >> >> path<-"." to be indicative of one or both of the csv files, I
> utilized
> >> the
> >> >> following functions and received the errors shown. How do I set the
> >> "." so
> >> >> that I can begin analysis on my files?
> >> >>
> >> >> > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
> >> >> Error: unexpected string constant in "the_data
> >> >> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> >> >> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
> >> >> Error: unexpected string constant in
> >> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
> >> >>
> >> >> This is the preliminary portion of the analysis I am trying to run,
> >> which
> >> >> I
> >> >> am referring to:
> >> >>
> >> >> 1 library(TCGAbiolinks)
> >> >> 2
> >> >> 3 # Download the DNA methylation data: HumanMethylation450 LGG and
> GBM.
> >> >> 4 path <? "."
> >> >> 5
> >> >> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"
> HumanMethylation450",
> >> >> level = 3)
> >> >> 7 TCGAdownload(query.met, path = path )
> >> >> 8 met <? TCGAprepare(query = query.met,dir = path,
> >> >> 9                      add.subtype = TRUE, add.clinical = TRUE,
> >> >> 10                    summarizedExperiment = TRUE,
> >> >> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> >> >> 12
> >> >> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and
> GBM.
> >> >> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> >> >> "IlluminaHiSeq_
> >> >> RNASeqV2",level = 3)
> >> >> 15
> >> >> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> >> >> results")
> >> >> 17
> >> >> 18 exp <? TCGAprepare(query = query.exp, dir = path,
> >> >> 19                    summarizedExperiment = TRUE,
> >> >> 20                      add.subtype = TRUE, add.clinical = TRUE,
> >> >> 21                    type = "rsem.genes.normalized_results",
> >> >> 22                      save = T,filename = "lgg_gbm_exp.rda")
> >> >>
> >> >> Many thanks,
> >> >>
> >> >> Spencer Brackett
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug  1 00:04:05 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 1 Aug 2018 08:04:05 +1000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
Message-ID: <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>

Hi Diego,
I think the error is due to NA values in your data file. If I extend
your example and run it, I get no errors:

MyData<-read.table(text="103001930 103001580 103001530
1998-10-01 00:00:00 0.6 0 0
1998-10-01 01:00:00 0.2 0.2 0.2
1998-10-01 02:00:00 0.6 0.2 0.4
1998-10-01 03:00:00 0 0 0.6
1998-10-01 04:00:00 0 0 0
1998-10-01 05:00:00 0 0 0
1998-10-01 06:00:00 0 0 0
1998-10-01 07:00:00 0.2 0 0
1998-10-01 08:00:00 0.6 0 0
1998-10-01 09:00:00 0.2 0.2 0.2
1998-10-01 10:00:00 0.6 0.2 0.4
1998-10-01 11:00:00 0 0 0.6
1998-10-01 12:00:00 0 0 0
1998-10-01 13:00:00 0 0 0
1998-10-01 14:00:00 0 0 0
1998-10-01 15:00:00 0.2 0 0
1998-10-01 16:00:00 0.6 0 0
1998-10-01 17:00:00 0.2 0.2 0.2
1998-10-01 18:00:00 0.6 0.2 0.4
1998-10-01 19:00:00 0 0 0.6
1998-10-01 20:00:00 0 0 0
1998-10-01 21:00:00 0 0 0
1998-10-01 22:00:00 0 0 0
1998-10-01 23:00:00 0.2 0 0
1998-10-02 00:00:00 0.6 0 0
1998-10-02 01:00:00 0.2 0.2 0.2
1998-10-02 02:00:00 0.6 0.2 0.4
1998-10-02 03:00:00 0 0 0.6
1998-10-02 04:00:00 0 0 0
1998-10-02 05:00:00 0 0 0
1998-10-02 06:00:00 0 0 0
1998-10-02 07:00:00 0.2 0 0
1998-10-02 08:00:00 0.6 0 0
1998-10-02 09:00:00 0.2 0.2 0.2
1998-10-02 10:00:00 0.6 0.2 0.4
1998-10-02 11:00:00 0 0 0.6
1998-10-02 12:00:00 0 0 0
1998-10-02 13:00:00 0 0 0
1998-10-02 14:00:00 0 0 0
1998-10-02 15:00:00 0.2 0 0
1998-10-02 16:00:00 0.6 0 0
1998-10-02 17:00:00 0.2 0.2 0.2
1998-10-02 18:00:00 0.6 0.2 0.4
1998-10-02 19:00:00 0 0 0.6
1998-10-02 20:00:00 0 0 0
1998-10-02 21:00:00 0 0 0
1998-10-02 22:00:00 0 0 0
1998-10-02 23:00:00 0.2 0 0",
skip=1,stringsAsFactors=FALSE)
names(MyData)<-c("date","time","st1","st2","st3")
MyData$datetime<-strptime(paste(MyData$date,MyData$time),
 format="%Y-%m-%d %H:%M:%S")
MyData$datetime
st1_daily<-by(MyData$st1,MyData$date,mean)
st2_daily<-by(MyData$st2,MyData$date,mean)
st3_daily<-by(MyData$st3,MyData$date,mean)
st1_daily
st2_daily
st3_daily

Try adding na.rm=TRUE to the "by" calls:

st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)

Jim

On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani <diego.avesani at gmail.com> wrote:
> Dear all,
>
> I have still problem with date.
> Could you please tel me how to use POSIXct.
> Indeed I have found this command:
> timeAverage, but I am not able to convert MyDate to properly date.
>
> Thank a lot
> I hope to no bother you, at least too much
>
>
> Diego
>
>
> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com> wrote:
>>
>> Dear Jim, Dear all,
>>
>> thanks a lot.
>>
>> Unfortunately, I get the following error:
>>
>>
>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L, 925L,  :
>>   arguments must have same length
>>
>>
>> This is particularly strange. indeed, if I apply
>>
>>
>> mean(MyData$str1,na.rm=TRUE)
>>
>>
>> it works
>>
>>
>> Sorry, I have to learn a lot.
>> You are really boosting me
>>
>> Diego
>>
>>
>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Diego,
>>> One way you can get daily means is:
>>>
>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>>>
>>> Jim
>>>
>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani <diego.avesani at gmail.com>
>>> wrote:
>>> > Dear all,
>>> > I have found the error, my fault. Sorry.
>>> > There was an extra come in the headers line.
>>> > Thanks again.
>>> >
>>> > If I can I would like to ask you another questions about the imported
>>> > data.
>>> > I would like to compute the daily average of the different date.
>>> > Basically I
>>> > have hourly data, I would like to ave the daily mean of them.
>>> >
>>> > Is there some special commands?
>>> >
>>> > Thanks a lot.
>>> >
>>> >
>>> > Diego
>>> >
>>> >
>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
>>> > wrote:
>>> >>
>>> >> Dear all,
>>> >> I move to csv file because originally the date where in csv file.
>>> >> In addition, due to the fact that, as you told me, read.csv is a
>>> >> special
>>> >> case of read.table, I prefer start to learn from the simplest one.
>>> >> After that, I will try also the *.txt format.
>>> >>
>>> >> with read.csv, something strange happened:
>>> >>
>>> >> This us now the file:
>>> >>
>>> >> date,st1,st2,st3,
>>> >> 10/1/1998 0:00,0.6,0,0
>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>>> >> 10/1/1998 3:00,0,0,0.6
>>> >> 10/1/1998 4:00,0,0,0
>>> >> 10/1/1998 5:00,0,0,0
>>> >> 10/1/1998 6:00,0,0,0
>>> >> 10/1/1998 7:00,0.2,0,0
>>> >> 10/1/1998 8:00,0.6,0.2,0
>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>>> >> 10/1/1998 10:00,0,0.4,0.2
>>> >>
>>> >> When I apply:
>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>> >>
>>> >> this is the results:
>>> >>
>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>>> >>
>>> >> I do not understand why.
>>> >> Something wrong with date?
>>> >>
>>> >> really really thanks,
>>> >> I appreciate a lot all your helps.
>>> >>
>>> >> Diedro
>>> >>
>>> >>
>>> >> Diego
>>> >>
>>> >>
>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>>> >>>
>>> >>> Or, without removing the first line
>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>>> >>>
>>> >>> Another alternative,
>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>>> >>> since the dates appear to be in the default format.
>>> >>> (I generally prefer to work with datetimes in POSIXct class rather
>>> >>> than
>>> >>> POSIXlt class)
>>> >>>
>>> >>> -Don
>>> >>>
>>> >>> --
>>> >>> Don MacQueen
>>> >>> Lawrence Livermore National Laboratory
>>> >>> 7000 East Ave., L-627
>>> >>> Livermore, CA 94550
>>> >>> 925-423-1062
>>> >>> Lab cell 925-724-7509
>>> >>>
>>> >>>
>>> >>>
>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>>> >>> <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com>
>>> >>> wrote:
>>> >>>
>>> >>>     Hi Diego,
>>> >>>     You may have to do some conversion as you have three fields in
>>> >>> the
>>> >>>     first line using the default space separator and five fields in
>>> >>>     subsequent lines. If the first line doesn't contain any important
>>> >>> data
>>> >>>     you can just delete it or replace it with a meaningful header
>>> >>> line
>>> >>>     with five fields and save the file under another name.
>>> >>>
>>> >>>     It looks as thought you have date-time as two fields. If so, you
>>> >>> can
>>> >>>     just read the first field if you only want the date:
>>> >>>
>>> >>>     # assume you have removed the first line
>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>> >>>
>>> >>>     If you want the date/time:
>>> >>>
>>> >>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>>> >>> %H:%M:%S")
>>> >>>
>>> >>>     Jim
>>> >>>
>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>>> >>> <diego.avesani at gmail.com> wrote:
>>> >>>     > Dear all,
>>> >>>     >
>>> >>>     > I am dealing with the reading of a *.txt file.
>>> >>>     > The txt file the following shape:
>>> >>>     >
>>> >>>     > 103001930 103001580 103001530
>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>>> >>>     > 1998-10-01 04:00:00 0 0 0
>>> >>>     > 1998-10-01 05:00:00 0 0 0
>>> >>>     > 1998-10-01 06:00:00 0 0 0
>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>>> >>>     >
>>> >>>     > If it is possible I have a coupe of questions, which will sound
>>> >>> stupid but
>>> >>>     > they are important to me in order to understand ho R deal with
>>> >>> file
>>> >>> or date.
>>> >>>     >
>>> >>>     > 1) Do I have to convert it to a *csv file?
>>> >>>     > 2) Can a deal with space and not ","
>>> >>>     > 3) How can I read date?
>>> >>>     >
>>> >>>     > thanks a lot to all of you,
>>> >>>     > Thanks
>>> >>>     >
>>> >>>     >
>>> >>>     > Diego
>>> >>>     >
>>> >>>     >         [[alternative HTML version deleted]]
>>> >>>     >
>>> >>>     > ______________________________________________
>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> >>> see
>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>     > PLEASE do read the posting guide
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>>     > and provide commented, minimal, self-contained, reproducible
>>> >>> code.
>>> >>>
>>> >>>     ______________________________________________
>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>     PLEASE do read the posting guide
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>>     and provide commented, minimal, self-contained, reproducible
>>> >>> code.
>>> >>>
>>> >>>
>>> >>
>>> >
>>
>>
>



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug  1 01:01:48 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 31 Jul 2018 16:01:48 -0700
Subject: [R] read txt file - date - no space
In-Reply-To: <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
Message-ID: <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>

... and the most common source of NA values in time data is wrong timezones. You really need to make sure the timezone that is assumed when the character data are converted to POSIXt agrees with the data. In most cases the easiest way to insure this is to use

Sys.setenv(TZ="US/Pacific")

or whatever timezone from

OlsonNames()

corresponds with your data. Execute this setenv function before the strptime or as.POSIXct() function call.

You can use 

MyData[ is.na(MyData$datetime), ]

to see which records are failing to convert time.

[1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1

On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Diego,
>I think the error is due to NA values in your data file. If I extend
>your example and run it, I get no errors:
>
>MyData<-read.table(text="103001930 103001580 103001530
>1998-10-01 00:00:00 0.6 0 0
>1998-10-01 01:00:00 0.2 0.2 0.2
>1998-10-01 02:00:00 0.6 0.2 0.4
>1998-10-01 03:00:00 0 0 0.6
>1998-10-01 04:00:00 0 0 0
>1998-10-01 05:00:00 0 0 0
>1998-10-01 06:00:00 0 0 0
>1998-10-01 07:00:00 0.2 0 0
>1998-10-01 08:00:00 0.6 0 0
>1998-10-01 09:00:00 0.2 0.2 0.2
>1998-10-01 10:00:00 0.6 0.2 0.4
>1998-10-01 11:00:00 0 0 0.6
>1998-10-01 12:00:00 0 0 0
>1998-10-01 13:00:00 0 0 0
>1998-10-01 14:00:00 0 0 0
>1998-10-01 15:00:00 0.2 0 0
>1998-10-01 16:00:00 0.6 0 0
>1998-10-01 17:00:00 0.2 0.2 0.2
>1998-10-01 18:00:00 0.6 0.2 0.4
>1998-10-01 19:00:00 0 0 0.6
>1998-10-01 20:00:00 0 0 0
>1998-10-01 21:00:00 0 0 0
>1998-10-01 22:00:00 0 0 0
>1998-10-01 23:00:00 0.2 0 0
>1998-10-02 00:00:00 0.6 0 0
>1998-10-02 01:00:00 0.2 0.2 0.2
>1998-10-02 02:00:00 0.6 0.2 0.4
>1998-10-02 03:00:00 0 0 0.6
>1998-10-02 04:00:00 0 0 0
>1998-10-02 05:00:00 0 0 0
>1998-10-02 06:00:00 0 0 0
>1998-10-02 07:00:00 0.2 0 0
>1998-10-02 08:00:00 0.6 0 0
>1998-10-02 09:00:00 0.2 0.2 0.2
>1998-10-02 10:00:00 0.6 0.2 0.4
>1998-10-02 11:00:00 0 0 0.6
>1998-10-02 12:00:00 0 0 0
>1998-10-02 13:00:00 0 0 0
>1998-10-02 14:00:00 0 0 0
>1998-10-02 15:00:00 0.2 0 0
>1998-10-02 16:00:00 0.6 0 0
>1998-10-02 17:00:00 0.2 0.2 0.2
>1998-10-02 18:00:00 0.6 0.2 0.4
>1998-10-02 19:00:00 0 0 0.6
>1998-10-02 20:00:00 0 0 0
>1998-10-02 21:00:00 0 0 0
>1998-10-02 22:00:00 0 0 0
>1998-10-02 23:00:00 0.2 0 0",
>skip=1,stringsAsFactors=FALSE)
>names(MyData)<-c("date","time","st1","st2","st3")
>MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> format="%Y-%m-%d %H:%M:%S")
>MyData$datetime
>st1_daily<-by(MyData$st1,MyData$date,mean)
>st2_daily<-by(MyData$st2,MyData$date,mean)
>st3_daily<-by(MyData$st3,MyData$date,mean)
>st1_daily
>st2_daily
>st3_daily
>
>Try adding na.rm=TRUE to the "by" calls:
>
>st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
>st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
>st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
>
>Jim
>
>On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
><diego.avesani at gmail.com> wrote:
>> Dear all,
>>
>> I have still problem with date.
>> Could you please tel me how to use POSIXct.
>> Indeed I have found this command:
>> timeAverage, but I am not able to convert MyDate to properly date.
>>
>> Thank a lot
>> I hope to no bother you, at least too much
>>
>>
>> Diego
>>
>>
>> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
>wrote:
>>>
>>> Dear Jim, Dear all,
>>>
>>> thanks a lot.
>>>
>>> Unfortunately, I get the following error:
>>>
>>>
>>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
>925L,  :
>>>   arguments must have same length
>>>
>>>
>>> This is particularly strange. indeed, if I apply
>>>
>>>
>>> mean(MyData$str1,na.rm=TRUE)
>>>
>>>
>>> it works
>>>
>>>
>>> Sorry, I have to learn a lot.
>>> You are really boosting me
>>>
>>> Diego
>>>
>>>
>>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>
>>>> Hi Diego,
>>>> One way you can get daily means is:
>>>>
>>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>>>>
>>>> Jim
>>>>
>>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
><diego.avesani at gmail.com>
>>>> wrote:
>>>> > Dear all,
>>>> > I have found the error, my fault. Sorry.
>>>> > There was an extra come in the headers line.
>>>> > Thanks again.
>>>> >
>>>> > If I can I would like to ask you another questions about the
>imported
>>>> > data.
>>>> > I would like to compute the daily average of the different date.
>>>> > Basically I
>>>> > have hourly data, I would like to ave the daily mean of them.
>>>> >
>>>> > Is there some special commands?
>>>> >
>>>> > Thanks a lot.
>>>> >
>>>> >
>>>> > Diego
>>>> >
>>>> >
>>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
>>>> > wrote:
>>>> >>
>>>> >> Dear all,
>>>> >> I move to csv file because originally the date where in csv
>file.
>>>> >> In addition, due to the fact that, as you told me, read.csv is a
>>>> >> special
>>>> >> case of read.table, I prefer start to learn from the simplest
>one.
>>>> >> After that, I will try also the *.txt format.
>>>> >>
>>>> >> with read.csv, something strange happened:
>>>> >>
>>>> >> This us now the file:
>>>> >>
>>>> >> date,st1,st2,st3,
>>>> >> 10/1/1998 0:00,0.6,0,0
>>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>>>> >> 10/1/1998 3:00,0,0,0.6
>>>> >> 10/1/1998 4:00,0,0,0
>>>> >> 10/1/1998 5:00,0,0,0
>>>> >> 10/1/1998 6:00,0,0,0
>>>> >> 10/1/1998 7:00,0.2,0,0
>>>> >> 10/1/1998 8:00,0.6,0.2,0
>>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>>>> >> 10/1/1998 10:00,0,0.4,0.2
>>>> >>
>>>> >> When I apply:
>>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>>> >>
>>>> >> this is the results:
>>>> >>
>>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>>>> >>
>>>> >> I do not understand why.
>>>> >> Something wrong with date?
>>>> >>
>>>> >> really really thanks,
>>>> >> I appreciate a lot all your helps.
>>>> >>
>>>> >> Diedro
>>>> >>
>>>> >>
>>>> >> Diego
>>>> >>
>>>> >>
>>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
>wrote:
>>>> >>>
>>>> >>> Or, without removing the first line
>>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>>>> >>>
>>>> >>> Another alternative,
>>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>>>> >>> since the dates appear to be in the default format.
>>>> >>> (I generally prefer to work with datetimes in POSIXct class
>rather
>>>> >>> than
>>>> >>> POSIXlt class)
>>>> >>>
>>>> >>> -Don
>>>> >>>
>>>> >>> --
>>>> >>> Don MacQueen
>>>> >>> Lawrence Livermore National Laboratory
>>>> >>> 7000 East Ave., L-627
>>>> >>> Livermore, CA 94550
>>>> >>> 925-423-1062
>>>> >>> Lab cell 925-724-7509
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>>>> >>> <r-help-bounces at r-project.org on behalf of
>drjimlemon at gmail.com>
>>>> >>> wrote:
>>>> >>>
>>>> >>>     Hi Diego,
>>>> >>>     You may have to do some conversion as you have three fields
>in
>>>> >>> the
>>>> >>>     first line using the default space separator and five
>fields in
>>>> >>>     subsequent lines. If the first line doesn't contain any
>important
>>>> >>> data
>>>> >>>     you can just delete it or replace it with a meaningful
>header
>>>> >>> line
>>>> >>>     with five fields and save the file under another name.
>>>> >>>
>>>> >>>     It looks as thought you have date-time as two fields. If
>so, you
>>>> >>> can
>>>> >>>     just read the first field if you only want the date:
>>>> >>>
>>>> >>>     # assume you have removed the first line
>>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>>> >>>
>>>> >>>     If you want the date/time:
>>>> >>>
>>>> >>>    
>dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>>>> >>> %H:%M:%S")
>>>> >>>
>>>> >>>     Jim
>>>> >>>
>>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>>>> >>> <diego.avesani at gmail.com> wrote:
>>>> >>>     > Dear all,
>>>> >>>     >
>>>> >>>     > I am dealing with the reading of a *.txt file.
>>>> >>>     > The txt file the following shape:
>>>> >>>     >
>>>> >>>     > 103001930 103001580 103001530
>>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>>>> >>>     > 1998-10-01 04:00:00 0 0 0
>>>> >>>     > 1998-10-01 05:00:00 0 0 0
>>>> >>>     > 1998-10-01 06:00:00 0 0 0
>>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>>>> >>>     >
>>>> >>>     > If it is possible I have a coupe of questions, which will
>sound
>>>> >>> stupid but
>>>> >>>     > they are important to me in order to understand ho R deal
>with
>>>> >>> file
>>>> >>> or date.
>>>> >>>     >
>>>> >>>     > 1) Do I have to convert it to a *csv file?
>>>> >>>     > 2) Can a deal with space and not ","
>>>> >>>     > 3) How can I read date?
>>>> >>>     >
>>>> >>>     > thanks a lot to all of you,
>>>> >>>     > Thanks
>>>> >>>     >
>>>> >>>     >
>>>> >>>     > Diego
>>>> >>>     >
>>>> >>>     >         [[alternative HTML version deleted]]
>>>> >>>     >
>>>> >>>     > ______________________________________________
>>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more,
>>>> >>> see
>>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>     > PLEASE do read the posting guide
>>>> >>> http://www.R-project.org/posting-guide.html
>>>> >>>     > and provide commented, minimal, self-contained,
>reproducible
>>>> >>> code.
>>>> >>>
>>>> >>>     ______________________________________________
>>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more, see
>>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>     PLEASE do read the posting guide
>>>> >>> http://www.R-project.org/posting-guide.html
>>>> >>>     and provide commented, minimal, self-contained,
>reproducible
>>>> >>> code.
>>>> >>>
>>>> >>>
>>>> >>
>>>> >
>>>
>>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From @tyen @end|ng |rom ntu@edu@tw  Wed Aug  1 08:35:21 2018
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Wed, 1 Aug 2018 14:35:21 +0800
Subject: [R] Problem with Rtools version 3.5.0.4
In-Reply-To: <f0bbfe43-f123-7939-251e-dac280331408@gmail.com>
References: <f0bbfe43-f123-7939-251e-dac280331408@gmail.com>
Message-ID: <cf7eb226-f447-1079-547b-5334ab4a9b36@ntu.edu.tw>

I am trying to build an R package with Rtools version 3.5.0.4 along with 
R-3.5.1
using the following? sequence of commands:

File -> Open Project -> Build -> Build Binary Package

I received the following error message:

zip I/O error: No such file or directory
zip error: Temporary file failure (Y:/ziPu2G1b)
running 'zip' failed

I then removed Rtools version 3.5.0.4 and installed Rtools version 3.4. 
It worked. What am I missing? Or, shall I wait till the next version of 
Rtools?

Full log file below.

==> Rcmd.exe INSTALL --build --preclean yenlib3

* installing to library 'C:/Users/syen01/Documents/R/win-library/3.5'
* installing *source* package 'yenlib3' ...
** R
** data
*** moving datasets to lazyload DB
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
 ? converting help for package 'yenlib3'
 ??? finding HTML links ... done
 ??? aids??????????????????????????????????? html
 ??? all.variables?????????????????????????? html
 ??? ate.boprobit??????????????????????????? html
(list truncated)
 ??? ate.boprobitE0????????????????????????? html
 ??? zxcombined????????????????????????????? html
** building package indices
** testing if installed package can be loaded
*** arch - i386
*** arch - x64
* MD5 sums
zip I/O error: No such file or directory
zip error: Temporary file failure (Y:/ziPu2G1b)
running 'zip' failed
* DONE (yenlib3)
In R CMD INSTALL

Binary package written to Y:/
-- 

styen at ntu.edu.tw (S.T. Yen)


	[[alternative HTML version deleted]]



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Wed Aug  1 08:54:38 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Wed, 1 Aug 2018 08:54:38 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
Message-ID: <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>

Dear all,
I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
all again in order to understand.
If I could I would like to start again, without mixing strategy and waiting
for your advice.

I am really appreciate you help, really really.
Here my new file, a *.csv file (buy the way, it is possible to attach it in
the mailing list?)

date,str1,str2,str3
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0


I read it as:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

at this point I would like to have the daily mean.
What would you suggest?

Really Really thanks,
You are my lifesaver

Thanks



Diego


On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> ... and the most common source of NA values in time data is wrong
> timezones. You really need to make sure the timezone that is assumed when
> the character data are converted to POSIXt agrees with the data. In most
> cases the easiest way to insure this is to use
>
> Sys.setenv(TZ="US/Pacific")
>
> or whatever timezone from
>
> OlsonNames()
>
> corresponds with your data. Execute this setenv function before the
> strptime or as.POSIXct() function call.
>
> You can use
>
> MyData[ is.na(MyData$datetime), ]
>
> to see which records are failing to convert time.
>
> [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>
> On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> >Hi Diego,
> >I think the error is due to NA values in your data file. If I extend
> >your example and run it, I get no errors:
> >
> >MyData<-read.table(text="103001930 103001580 103001530
> >1998-10-01 00:00:00 0.6 0 0
> >1998-10-01 01:00:00 0.2 0.2 0.2
> >1998-10-01 02:00:00 0.6 0.2 0.4
> >1998-10-01 03:00:00 0 0 0.6
> >1998-10-01 04:00:00 0 0 0
> >1998-10-01 05:00:00 0 0 0
> >1998-10-01 06:00:00 0 0 0
> >1998-10-01 07:00:00 0.2 0 0
> >1998-10-01 08:00:00 0.6 0 0
> >1998-10-01 09:00:00 0.2 0.2 0.2
> >1998-10-01 10:00:00 0.6 0.2 0.4
> >1998-10-01 11:00:00 0 0 0.6
> >1998-10-01 12:00:00 0 0 0
> >1998-10-01 13:00:00 0 0 0
> >1998-10-01 14:00:00 0 0 0
> >1998-10-01 15:00:00 0.2 0 0
> >1998-10-01 16:00:00 0.6 0 0
> >1998-10-01 17:00:00 0.2 0.2 0.2
> >1998-10-01 18:00:00 0.6 0.2 0.4
> >1998-10-01 19:00:00 0 0 0.6
> >1998-10-01 20:00:00 0 0 0
> >1998-10-01 21:00:00 0 0 0
> >1998-10-01 22:00:00 0 0 0
> >1998-10-01 23:00:00 0.2 0 0
> >1998-10-02 00:00:00 0.6 0 0
> >1998-10-02 01:00:00 0.2 0.2 0.2
> >1998-10-02 02:00:00 0.6 0.2 0.4
> >1998-10-02 03:00:00 0 0 0.6
> >1998-10-02 04:00:00 0 0 0
> >1998-10-02 05:00:00 0 0 0
> >1998-10-02 06:00:00 0 0 0
> >1998-10-02 07:00:00 0.2 0 0
> >1998-10-02 08:00:00 0.6 0 0
> >1998-10-02 09:00:00 0.2 0.2 0.2
> >1998-10-02 10:00:00 0.6 0.2 0.4
> >1998-10-02 11:00:00 0 0 0.6
> >1998-10-02 12:00:00 0 0 0
> >1998-10-02 13:00:00 0 0 0
> >1998-10-02 14:00:00 0 0 0
> >1998-10-02 15:00:00 0.2 0 0
> >1998-10-02 16:00:00 0.6 0 0
> >1998-10-02 17:00:00 0.2 0.2 0.2
> >1998-10-02 18:00:00 0.6 0.2 0.4
> >1998-10-02 19:00:00 0 0 0.6
> >1998-10-02 20:00:00 0 0 0
> >1998-10-02 21:00:00 0 0 0
> >1998-10-02 22:00:00 0 0 0
> >1998-10-02 23:00:00 0.2 0 0",
> >skip=1,stringsAsFactors=FALSE)
> >names(MyData)<-c("date","time","st1","st2","st3")
> >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > format="%Y-%m-%d %H:%M:%S")
> >MyData$datetime
> >st1_daily<-by(MyData$st1,MyData$date,mean)
> >st2_daily<-by(MyData$st2,MyData$date,mean)
> >st3_daily<-by(MyData$st3,MyData$date,mean)
> >st1_daily
> >st2_daily
> >st3_daily
> >
> >Try adding na.rm=TRUE to the "by" calls:
> >
> >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> >
> >Jim
> >
> >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> ><diego.avesani at gmail.com> wrote:
> >> Dear all,
> >>
> >> I have still problem with date.
> >> Could you please tel me how to use POSIXct.
> >> Indeed I have found this command:
> >> timeAverage, but I am not able to convert MyDate to properly date.
> >>
> >> Thank a lot
> >> I hope to no bother you, at least too much
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> >wrote:
> >>>
> >>> Dear Jim, Dear all,
> >>>
> >>> thanks a lot.
> >>>
> >>> Unfortunately, I get the following error:
> >>>
> >>>
> >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> >925L,  :
> >>>   arguments must have same length
> >>>
> >>>
> >>> This is particularly strange. indeed, if I apply
> >>>
> >>>
> >>> mean(MyData$str1,na.rm=TRUE)
> >>>
> >>>
> >>> it works
> >>>
> >>>
> >>> Sorry, I have to learn a lot.
> >>> You are really boosting me
> >>>
> >>> Diego
> >>>
> >>>
> >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>>>
> >>>> Hi Diego,
> >>>> One way you can get daily means is:
> >>>>
> >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> >>>>
> >>>> Jim
> >>>>
> >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> ><diego.avesani at gmail.com>
> >>>> wrote:
> >>>> > Dear all,
> >>>> > I have found the error, my fault. Sorry.
> >>>> > There was an extra come in the headers line.
> >>>> > Thanks again.
> >>>> >
> >>>> > If I can I would like to ask you another questions about the
> >imported
> >>>> > data.
> >>>> > I would like to compute the daily average of the different date.
> >>>> > Basically I
> >>>> > have hourly data, I would like to ave the daily mean of them.
> >>>> >
> >>>> > Is there some special commands?
> >>>> >
> >>>> > Thanks a lot.
> >>>> >
> >>>> >
> >>>> > Diego
> >>>> >
> >>>> >
> >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
> >>>> > wrote:
> >>>> >>
> >>>> >> Dear all,
> >>>> >> I move to csv file because originally the date where in csv
> >file.
> >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> >>>> >> special
> >>>> >> case of read.table, I prefer start to learn from the simplest
> >one.
> >>>> >> After that, I will try also the *.txt format.
> >>>> >>
> >>>> >> with read.csv, something strange happened:
> >>>> >>
> >>>> >> This us now the file:
> >>>> >>
> >>>> >> date,st1,st2,st3,
> >>>> >> 10/1/1998 0:00,0.6,0,0
> >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> >>>> >> 10/1/1998 3:00,0,0,0.6
> >>>> >> 10/1/1998 4:00,0,0,0
> >>>> >> 10/1/1998 5:00,0,0,0
> >>>> >> 10/1/1998 6:00,0,0,0
> >>>> >> 10/1/1998 7:00,0.2,0,0
> >>>> >> 10/1/1998 8:00,0.6,0.2,0
> >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> >>>> >> 10/1/1998 10:00,0,0.4,0.2
> >>>> >>
> >>>> >> When I apply:
> >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>>> >>
> >>>> >> this is the results:
> >>>> >>
> >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>>> >>
> >>>> >> I do not understand why.
> >>>> >> Something wrong with date?
> >>>> >>
> >>>> >> really really thanks,
> >>>> >> I appreciate a lot all your helps.
> >>>> >>
> >>>> >> Diedro
> >>>> >>
> >>>> >>
> >>>> >> Diego
> >>>> >>
> >>>> >>
> >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> >wrote:
> >>>> >>>
> >>>> >>> Or, without removing the first line
> >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>> >>>
> >>>> >>> Another alternative,
> >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>>> >>> since the dates appear to be in the default format.
> >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> >rather
> >>>> >>> than
> >>>> >>> POSIXlt class)
> >>>> >>>
> >>>> >>> -Don
> >>>> >>>
> >>>> >>> --
> >>>> >>> Don MacQueen
> >>>> >>> Lawrence Livermore National Laboratory
> >>>> >>> 7000 East Ave., L-627
> >>>> >>> Livermore, CA 94550
> >>>> >>> 925-423-1062
> >>>> >>> Lab cell 925-724-7509
> >>>> >>>
> >>>> >>>
> >>>> >>>
> >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>>> >>> <r-help-bounces at r-project.org on behalf of
> >drjimlemon at gmail.com>
> >>>> >>> wrote:
> >>>> >>>
> >>>> >>>     Hi Diego,
> >>>> >>>     You may have to do some conversion as you have three fields
> >in
> >>>> >>> the
> >>>> >>>     first line using the default space separator and five
> >fields in
> >>>> >>>     subsequent lines. If the first line doesn't contain any
> >important
> >>>> >>> data
> >>>> >>>     you can just delete it or replace it with a meaningful
> >header
> >>>> >>> line
> >>>> >>>     with five fields and save the file under another name.
> >>>> >>>
> >>>> >>>     It looks as thought you have date-time as two fields. If
> >so, you
> >>>> >>> can
> >>>> >>>     just read the first field if you only want the date:
> >>>> >>>
> >>>> >>>     # assume you have removed the first line
> >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>> >>>
> >>>> >>>     If you want the date/time:
> >>>> >>>
> >>>> >>>
> >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>>> >>> %H:%M:%S")
> >>>> >>>
> >>>> >>>     Jim
> >>>> >>>
> >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>>> >>> <diego.avesani at gmail.com> wrote:
> >>>> >>>     > Dear all,
> >>>> >>>     >
> >>>> >>>     > I am dealing with the reading of a *.txt file.
> >>>> >>>     > The txt file the following shape:
> >>>> >>>     >
> >>>> >>>     > 103001930 103001580 103001530
> >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>> >>>     >
> >>>> >>>     > If it is possible I have a coupe of questions, which will
> >sound
> >>>> >>> stupid but
> >>>> >>>     > they are important to me in order to understand ho R deal
> >with
> >>>> >>> file
> >>>> >>> or date.
> >>>> >>>     >
> >>>> >>>     > 1) Do I have to convert it to a *csv file?
> >>>> >>>     > 2) Can a deal with space and not ","
> >>>> >>>     > 3) How can I read date?
> >>>> >>>     >
> >>>> >>>     > thanks a lot to all of you,
> >>>> >>>     > Thanks
> >>>> >>>     >
> >>>> >>>     >
> >>>> >>>     > Diego
> >>>> >>>     >
> >>>> >>>     >         [[alternative HTML version deleted]]
> >>>> >>>     >
> >>>> >>>     > ______________________________________________
> >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more,
> >>>> >>> see
> >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     > PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     > and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>     ______________________________________________
> >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more, see
> >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>
> >>>> >>
> >>>> >
> >>>
> >>>
> >>
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Wed Aug  1 13:58:59 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 1 Aug 2018 11:58:59 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
Message-ID: <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>

Hi

I did not get through all answers you already got and you probably obtained similar advice as mine.

# read data (if you have csv file just use read.csv)
> test<-read.table("clipboard", header=T, sep=",")

# control your object(s)
> str(test)
'data.frame':   8 obs. of  4 variables:
 $ date: Factor w/ 8 levels "10/1/1998 0:00",..: 1 2 3 4 5 6 7 8
 $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2
 $ str2: num  0 0.2 0.2 0 0 0 0 0
 $ str3: num  0 0.2 0.4 0.6 0 0 0 0

#if it is OK change first column to real date by POSIXct
test$date<-as.POSIXct(test$date, format="%d/%m/%Y %H:%M")

#attach lubridate
> library(lubridate)

# aggregate your object(s) and use lubridate function

> aggregate(test[,-1], list(day(test$date)), mean)
  Group.1 str1 str2 str3
1      10  0.2 0.05 0.15

# or format function

> aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
     Group.1 str1 str2 str3
1 1998-01-10  0.2 0.05 0.15

If it does not work with your data you should post at least result of

str(yourdata)

or preferably

dput(yourdata[1:20,])

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Diego Avesani
> Sent: Wednesday, August 1, 2018 8:55 AM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] read txt file - date - no space
>
> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat all again
> in order to understand.
> If I could I would like to start again, without mixing strategy and waiting for
> your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in the
> mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed
> > when the character data are converted to POSIXt agrees with the data.
> > In most cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani
> > >>>> > <diego.avesani at gmail.com>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is
> > >>>> >> a special case of read.table, I prefer start to learn from the
> > >>>> >> simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
> > >>>> >>> skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > >drjimlemon at gmail.com>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three
> > >>>> >>> fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which
> > >>>> >>> will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R
> > >>>> >>> deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From d|ego@@ve@@n| @end|ng |rom gm@||@com  Wed Aug  1 14:29:53 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Wed, 1 Aug 2018 14:29:53 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>

Dear Pikal, Deal all,

again really thank.

it seems not working.
Some specifications: My non data are -999, but I could change it.

My final results is:

1        1  -55.86242 -55.84764660 -277.4775
2        2  -55.47554 -94.58921682 -277.4845
3        3  -55.47095 -99.20239198 -277.4709
4        4  -55.46470 -55.45952932 -392.9071
5        5  -55.43335 -55.40171682 -388.4110
6        6  -55.40108 -55.37399691 -332.9068
7        7  -55.39201 -55.35156250 -332.8902
8        8 -110.87184   0.16136188 -281.8230
9        9 -110.95077 -55.63856096 -332.9564
10      10 -157.64430  -0.06602705 -315.3840
11      11 -105.06157   0.11507675 -315.4152
12      12  -70.08677 -52.54501096 -316.7247


So it is not correct.
For example for the first day in my csv I would have expected 0.167.

I am going to post what you have suggested:

for  str(MyData)

'data.frame': 160008 obs. of  4 variables:
 $ date: POSIXct, format: "1998-01-10 00:00:00" "1998-01-10 01:00:00"
"1998-01-10 02:00:00" "1998-01-10 03:00:00" ...
 $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
 $ str2: num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
 $ str3: num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...

unfortunately, I am not able to post

dput(str[1:20,])

it gives me

Error in str[1:20, ] : object of type 'closure' is not subsettable


Thanks again,
I hope that what I posted could be enough in order to help me.



Diego


On 1 August 2018 at 13:58, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> I did not get through all answers you already got and you probably
> obtained similar advice as mine.
>
> # read data (if you have csv file just use read.csv)
> > test<-read.table("clipboard", header=T, sep=",")
>
> # control your object(s)
> > str(test)
> 'data.frame':   8 obs. of  4 variables:
>  $ date: Factor w/ 8 levels "10/1/1998 0:00",..: 1 2 3 4 5 6 7 8
>  $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2
>  $ str2: num  0 0.2 0.2 0 0 0 0 0
>  $ str3: num  0 0.2 0.4 0.6 0 0 0 0
>
> #if it is OK change first column to real date by POSIXct
> test$date<-as.POSIXct(test$date, format="%d/%m/%Y %H:%M")
>
> #attach lubridate
> > library(lubridate)
>
> # aggregate your object(s) and use lubridate function
>
> > aggregate(test[,-1], list(day(test$date)), mean)
>   Group.1 str1 str2 str3
> 1      10  0.2 0.05 0.15
>
> # or format function
>
> > aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
>      Group.1 str1 str2 str3
> 1 1998-01-10  0.2 0.05 0.15
>
> If it does not work with your data you should post at least result of
>
> str(yourdata)
>
> or preferably
>
> dput(yourdata[1:20,])
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Diego Avesani
> > Sent: Wednesday, August 1, 2018 8:55 AM
> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] read txt file - date - no space
> >
> > Dear all,
> > I am sorry, I did a lot of confusion. I am sorry, I have to relax and
> stat all again
> > in order to understand.
> > If I could I would like to start again, without mixing strategy and
> waiting for
> > your advice.
> >
> > I am really appreciate you help, really really.
> > Here my new file, a *.csv file (buy the way, it is possible to attach it
> in the
> > mailing list?)
> >
> > date,str1,str2,str3
> > 10/1/1998 0:00,0.6,0,0
> > 10/1/1998 1:00,0.2,0.2,0.2
> > 10/1/1998 2:00,0.6,0.2,0.4
> > 10/1/1998 3:00,0,0,0.6
> > 10/1/1998 4:00,0,0,0
> > 10/1/1998 5:00,0,0,0
> > 10/1/1998 6:00,0,0,0
> > 10/1/1998 7:00,0.2,0,0
> >
> >
> > I read it as:
> > MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >
> > at this point I would like to have the daily mean.
> > What would you suggest?
> >
> > Really Really thanks,
> > You are my lifesaver
> >
> > Thanks
> >
> >
> >
> > Diego
> >
> >
> > On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > > ... and the most common source of NA values in time data is wrong
> > > timezones. You really need to make sure the timezone that is assumed
> > > when the character data are converted to POSIXt agrees with the data.
> > > In most cases the easiest way to insure this is to use
> > >
> > > Sys.setenv(TZ="US/Pacific")
> > >
> > > or whatever timezone from
> > >
> > > OlsonNames()
> > >
> > > corresponds with your data. Execute this setenv function before the
> > > strptime or as.POSIXct() function call.
> > >
> > > You can use
> > >
> > > MyData[ is.na(MyData$datetime), ]
> > >
> > > to see which records are failing to convert time.
> > >
> > > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> > >
> > > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
> > wrote:
> > > >Hi Diego,
> > > >I think the error is due to NA values in your data file. If I extend
> > > >your example and run it, I get no errors:
> > > >
> > > >MyData<-read.table(text="103001930 103001580 103001530
> > > >1998-10-01 00:00:00 0.6 0 0
> > > >1998-10-01 01:00:00 0.2 0.2 0.2
> > > >1998-10-01 02:00:00 0.6 0.2 0.4
> > > >1998-10-01 03:00:00 0 0 0.6
> > > >1998-10-01 04:00:00 0 0 0
> > > >1998-10-01 05:00:00 0 0 0
> > > >1998-10-01 06:00:00 0 0 0
> > > >1998-10-01 07:00:00 0.2 0 0
> > > >1998-10-01 08:00:00 0.6 0 0
> > > >1998-10-01 09:00:00 0.2 0.2 0.2
> > > >1998-10-01 10:00:00 0.6 0.2 0.4
> > > >1998-10-01 11:00:00 0 0 0.6
> > > >1998-10-01 12:00:00 0 0 0
> > > >1998-10-01 13:00:00 0 0 0
> > > >1998-10-01 14:00:00 0 0 0
> > > >1998-10-01 15:00:00 0.2 0 0
> > > >1998-10-01 16:00:00 0.6 0 0
> > > >1998-10-01 17:00:00 0.2 0.2 0.2
> > > >1998-10-01 18:00:00 0.6 0.2 0.4
> > > >1998-10-01 19:00:00 0 0 0.6
> > > >1998-10-01 20:00:00 0 0 0
> > > >1998-10-01 21:00:00 0 0 0
> > > >1998-10-01 22:00:00 0 0 0
> > > >1998-10-01 23:00:00 0.2 0 0
> > > >1998-10-02 00:00:00 0.6 0 0
> > > >1998-10-02 01:00:00 0.2 0.2 0.2
> > > >1998-10-02 02:00:00 0.6 0.2 0.4
> > > >1998-10-02 03:00:00 0 0 0.6
> > > >1998-10-02 04:00:00 0 0 0
> > > >1998-10-02 05:00:00 0 0 0
> > > >1998-10-02 06:00:00 0 0 0
> > > >1998-10-02 07:00:00 0.2 0 0
> > > >1998-10-02 08:00:00 0.6 0 0
> > > >1998-10-02 09:00:00 0.2 0.2 0.2
> > > >1998-10-02 10:00:00 0.6 0.2 0.4
> > > >1998-10-02 11:00:00 0 0 0.6
> > > >1998-10-02 12:00:00 0 0 0
> > > >1998-10-02 13:00:00 0 0 0
> > > >1998-10-02 14:00:00 0 0 0
> > > >1998-10-02 15:00:00 0.2 0 0
> > > >1998-10-02 16:00:00 0.6 0 0
> > > >1998-10-02 17:00:00 0.2 0.2 0.2
> > > >1998-10-02 18:00:00 0.6 0.2 0.4
> > > >1998-10-02 19:00:00 0 0 0.6
> > > >1998-10-02 20:00:00 0 0 0
> > > >1998-10-02 21:00:00 0 0 0
> > > >1998-10-02 22:00:00 0 0 0
> > > >1998-10-02 23:00:00 0.2 0 0",
> > > >skip=1,stringsAsFactors=FALSE)
> > > >names(MyData)<-c("date","time","st1","st2","st3")
> > > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > > format="%Y-%m-%d %H:%M:%S")
> > > >MyData$datetime
> > > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > > >st1_daily
> > > >st2_daily
> > > >st3_daily
> > > >
> > > >Try adding na.rm=TRUE to the "by" calls:
> > > >
> > > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > > >
> > > >Jim
> > > >
> > > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > > ><diego.avesani at gmail.com> wrote:
> > > >> Dear all,
> > > >>
> > > >> I have still problem with date.
> > > >> Could you please tel me how to use POSIXct.
> > > >> Indeed I have found this command:
> > > >> timeAverage, but I am not able to convert MyDate to properly date.
> > > >>
> > > >> Thank a lot
> > > >> I hope to no bother you, at least too much
> > > >>
> > > >>
> > > >> Diego
> > > >>
> > > >>
> > > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > > >wrote:
> > > >>>
> > > >>> Dear Jim, Dear all,
> > > >>>
> > > >>> thanks a lot.
> > > >>>
> > > >>> Unfortunately, I get the following error:
> > > >>>
> > > >>>
> > > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > > >925L,  :
> > > >>>   arguments must have same length
> > > >>>
> > > >>>
> > > >>> This is particularly strange. indeed, if I apply
> > > >>>
> > > >>>
> > > >>> mean(MyData$str1,na.rm=TRUE)
> > > >>>
> > > >>>
> > > >>> it works
> > > >>>
> > > >>>
> > > >>> Sorry, I have to learn a lot.
> > > >>> You are really boosting me
> > > >>>
> > > >>> Diego
> > > >>>
> > > >>>
> > > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >>>>
> > > >>>> Hi Diego,
> > > >>>> One way you can get daily means is:
> > > >>>>
> > > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > > >>>>
> > > >>>> Jim
> > > >>>>
> > > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > > ><diego.avesani at gmail.com>
> > > >>>> wrote:
> > > >>>> > Dear all,
> > > >>>> > I have found the error, my fault. Sorry.
> > > >>>> > There was an extra come in the headers line.
> > > >>>> > Thanks again.
> > > >>>> >
> > > >>>> > If I can I would like to ask you another questions about the
> > > >imported
> > > >>>> > data.
> > > >>>> > I would like to compute the daily average of the different date.
> > > >>>> > Basically I
> > > >>>> > have hourly data, I would like to ave the daily mean of them.
> > > >>>> >
> > > >>>> > Is there some special commands?
> > > >>>> >
> > > >>>> > Thanks a lot.
> > > >>>> >
> > > >>>> >
> > > >>>> > Diego
> > > >>>> >
> > > >>>> >
> > > >>>> > On 31 July 2018 at 10:40, Diego Avesani
> > > >>>> > <diego.avesani at gmail.com>
> > > >>>> > wrote:
> > > >>>> >>
> > > >>>> >> Dear all,
> > > >>>> >> I move to csv file because originally the date where in csv
> > > >file.
> > > >>>> >> In addition, due to the fact that, as you told me, read.csv is
> > > >>>> >> a special case of read.table, I prefer start to learn from the
> > > >>>> >> simplest
> > > >one.
> > > >>>> >> After that, I will try also the *.txt format.
> > > >>>> >>
> > > >>>> >> with read.csv, something strange happened:
> > > >>>> >>
> > > >>>> >> This us now the file:
> > > >>>> >>
> > > >>>> >> date,st1,st2,st3,
> > > >>>> >> 10/1/1998 0:00,0.6,0,0
> > > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > > >>>> >> 10/1/1998 3:00,0,0,0.6
> > > >>>> >> 10/1/1998 4:00,0,0,0
> > > >>>> >> 10/1/1998 5:00,0,0,0
> > > >>>> >> 10/1/1998 6:00,0,0,0
> > > >>>> >> 10/1/1998 7:00,0.2,0,0
> > > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > > >>>> >>
> > > >>>> >> When I apply:
> > > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > > >>>> >>
> > > >>>> >> this is the results:
> > > >>>> >>
> > > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > > >>>> >>
> > > >>>> >> I do not understand why.
> > > >>>> >> Something wrong with date?
> > > >>>> >>
> > > >>>> >> really really thanks,
> > > >>>> >> I appreciate a lot all your helps.
> > > >>>> >>
> > > >>>> >> Diedro
> > > >>>> >>
> > > >>>> >>
> > > >>>> >> Diego
> > > >>>> >>
> > > >>>> >>
> > > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > > >wrote:
> > > >>>> >>>
> > > >>>> >>> Or, without removing the first line
> > > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
> > > >>>> >>> skip=1)
> > > >>>> >>>
> > > >>>> >>> Another alternative,
> > > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > > >>>> >>> since the dates appear to be in the default format.
> > > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > > >rather
> > > >>>> >>> than
> > > >>>> >>> POSIXlt class)
> > > >>>> >>>
> > > >>>> >>> -Don
> > > >>>> >>>
> > > >>>> >>> --
> > > >>>> >>> Don MacQueen
> > > >>>> >>> Lawrence Livermore National Laboratory
> > > >>>> >>> 7000 East Ave., L-627
> > > >>>> >>> Livermore, CA 94550
> > > >>>> >>> 925-423-1062
> > > >>>> >>> Lab cell 925-724-7509
> > > >>>> >>>
> > > >>>> >>>
> > > >>>> >>>
> > > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > > >drjimlemon at gmail.com>
> > > >>>> >>> wrote:
> > > >>>> >>>
> > > >>>> >>>     Hi Diego,
> > > >>>> >>>     You may have to do some conversion as you have three
> > > >>>> >>> fields
> > > >in
> > > >>>> >>> the
> > > >>>> >>>     first line using the default space separator and five
> > > >fields in
> > > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > > >important
> > > >>>> >>> data
> > > >>>> >>>     you can just delete it or replace it with a meaningful
> > > >header
> > > >>>> >>> line
> > > >>>> >>>     with five fields and save the file under another name.
> > > >>>> >>>
> > > >>>> >>>     It looks as thought you have date-time as two fields. If
> > > >so, you
> > > >>>> >>> can
> > > >>>> >>>     just read the first field if you only want the date:
> > > >>>> >>>
> > > >>>> >>>     # assume you have removed the first line
> > > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > > >>>> >>>
> > > >>>> >>>     If you want the date/time:
> > > >>>> >>>
> > > >>>> >>>
> > > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > > >>>> >>> %H:%M:%S")
> > > >>>> >>>
> > > >>>> >>>     Jim
> > > >>>> >>>
> > > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > > >>>> >>> <diego.avesani at gmail.com> wrote:
> > > >>>> >>>     > Dear all,
> > > >>>> >>>     >
> > > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > > >>>> >>>     > The txt file the following shape:
> > > >>>> >>>     >
> > > >>>> >>>     > 103001930 103001580 103001530
> > > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > > >>>> >>>     >
> > > >>>> >>>     > If it is possible I have a coupe of questions, which
> > > >>>> >>> will
> > > >sound
> > > >>>> >>> stupid but
> > > >>>> >>>     > they are important to me in order to understand ho R
> > > >>>> >>> deal
> > > >with
> > > >>>> >>> file
> > > >>>> >>> or date.
> > > >>>> >>>     >
> > > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > > >>>> >>>     > 2) Can a deal with space and not ","
> > > >>>> >>>     > 3) How can I read date?
> > > >>>> >>>     >
> > > >>>> >>>     > thanks a lot to all of you,
> > > >>>> >>>     > Thanks
> > > >>>> >>>     >
> > > >>>> >>>     >
> > > >>>> >>>     > Diego
> > > >>>> >>>     >
> > > >>>> >>>     >         [[alternative HTML version deleted]]
> > > >>>> >>>     >
> > > >>>> >>>     > ______________________________________________
> > > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > > >more,
> > > >>>> >>> see
> > > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>> >>>     > PLEASE do read the posting guide
> > > >>>> >>> http://www.R-project.org/posting-guide.html
> > > >>>> >>>     > and provide commented, minimal, self-contained,
> > > >reproducible
> > > >>>> >>> code.
> > > >>>> >>>
> > > >>>> >>>     ______________________________________________
> > > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > > >more, see
> > > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>> >>>     PLEASE do read the posting guide
> > > >>>> >>> http://www.R-project.org/posting-guide.html
> > > >>>> >>>     and provide commented, minimal, self-contained,
> > > >reproducible
> > > >>>> >>> code.
> > > >>>> >>>
> > > >>>> >>>
> > > >>>> >>
> > > >>>> >
> > > >>>
> > > >>>
> > > >>
> > > >
> > > >______________________________________________
> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > >PLEASE do read the posting guide
> > > >http://www.R-project.org/posting-guide.html
> > > >and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Sent from my phone. Please excuse my brevity.
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> zasady-ochrany-osobnich-udaju/ | Information about processing and
> protection of business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

	[[alternative HTML version deleted]]



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Wed Aug  1 14:37:55 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Wed, 1 Aug 2018 14:37:55 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>
Message-ID: <CAG8o1y65ccvCpRQ8QvmC=vDgVhzD2acB6xb+f0NVEkPsuEhmsA@mail.gmail.com>

Dear Pikal, DEar all,

I do not if it could help:
if I print MyData%date, I get (at some point)

[281] "1998-12-10 16:00:00 CET"  "1998-12-10 17:00:00 CET"
"1998-12-10 18:00:00 CET"  "1998-12-10 19:00:00 CET"
 [285] "1998-12-10 20:00:00 CET"  "1998-12-10 21:00:00 CET"
"1998-12-10 22:00:00 CET"  "1998-12-10 23:00:00 CET"
 [289] NA                         NA                         NA
                 NA
 [293] NA                         NA                         NA
                 NA
 [297] NA                         NA                         NA
                 NA


Again Thanks

Diego


On 1 August 2018 at 14:29, Diego Avesani <diego.avesani at gmail.com> wrote:

> Dear Pikal, Deal all,
>
> again really thank.
>
> it seems not working.
> Some specifications: My non data are -999, but I could change it.
>
> My final results is:
>
> 1        1  -55.86242 -55.84764660 -277.4775
> 2        2  -55.47554 -94.58921682 -277.4845
> 3        3  -55.47095 -99.20239198 -277.4709
> 4        4  -55.46470 -55.45952932 -392.9071
> 5        5  -55.43335 -55.40171682 -388.4110
> 6        6  -55.40108 -55.37399691 -332.9068
> 7        7  -55.39201 -55.35156250 -332.8902
> 8        8 -110.87184   0.16136188 -281.8230
> 9        9 -110.95077 -55.63856096 -332.9564
> 10      10 -157.64430  -0.06602705 -315.3840
> 11      11 -105.06157   0.11507675 -315.4152
> 12      12  -70.08677 -52.54501096 -316.7247
>
>
> So it is not correct.
> For example for the first day in my csv I would have expected 0.167.
>
> I am going to post what you have suggested:
>
> for  str(MyData)
>
> 'data.frame': 160008 obs. of  4 variables:
>  $ date: POSIXct, format: "1998-01-10 00:00:00" "1998-01-10 01:00:00"
> "1998-01-10 02:00:00" "1998-01-10 03:00:00" ...
>  $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
>  $ str2: num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
>  $ str3: num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...
>
> unfortunately, I am not able to post
>
> dput(str[1:20,])
>
> it gives me
>
> Error in str[1:20, ] : object of type 'closure' is not subsettable
>
>
> Thanks again,
> I hope that what I posted could be enough in order to help me.
>
>
>
> Diego
>
>
> On 1 August 2018 at 13:58, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> I did not get through all answers you already got and you probably
>> obtained similar advice as mine.
>>
>> # read data (if you have csv file just use read.csv)
>> > test<-read.table("clipboard", header=T, sep=",")
>>
>> # control your object(s)
>> > str(test)
>> 'data.frame':   8 obs. of  4 variables:
>>  $ date: Factor w/ 8 levels "10/1/1998 0:00",..: 1 2 3 4 5 6 7 8
>>  $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2
>>  $ str2: num  0 0.2 0.2 0 0 0 0 0
>>  $ str3: num  0 0.2 0.4 0.6 0 0 0 0
>>
>> #if it is OK change first column to real date by POSIXct
>> test$date<-as.POSIXct(test$date, format="%d/%m/%Y %H:%M")
>>
>> #attach lubridate
>> > library(lubridate)
>>
>> # aggregate your object(s) and use lubridate function
>>
>> > aggregate(test[,-1], list(day(test$date)), mean)
>>   Group.1 str1 str2 str3
>> 1      10  0.2 0.05 0.15
>>
>> # or format function
>>
>> > aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
>>      Group.1 str1 str2 str3
>> 1 1998-01-10  0.2 0.05 0.15
>>
>> If it does not work with your data you should post at least result of
>>
>> str(yourdata)
>>
>> or preferably
>>
>> dput(yourdata[1:20,])
>>
>> Cheers
>> Petr
>>
>>
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Diego Avesani
>> > Sent: Wednesday, August 1, 2018 8:55 AM
>> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > Cc: r-help mailing list <r-help at r-project.org>
>> > Subject: Re: [R] read txt file - date - no space
>> >
>> > Dear all,
>> > I am sorry, I did a lot of confusion. I am sorry, I have to relax and
>> stat all again
>> > in order to understand.
>> > If I could I would like to start again, without mixing strategy and
>> waiting for
>> > your advice.
>> >
>> > I am really appreciate you help, really really.
>> > Here my new file, a *.csv file (buy the way, it is possible to attach
>> it in the
>> > mailing list?)
>> >
>> > date,str1,str2,str3
>> > 10/1/1998 0:00,0.6,0,0
>> > 10/1/1998 1:00,0.2,0.2,0.2
>> > 10/1/1998 2:00,0.6,0.2,0.4
>> > 10/1/1998 3:00,0,0,0.6
>> > 10/1/1998 4:00,0,0,0
>> > 10/1/1998 5:00,0,0,0
>> > 10/1/1998 6:00,0,0,0
>> > 10/1/1998 7:00,0.2,0,0
>> >
>> >
>> > I read it as:
>> > MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>> >
>> > at this point I would like to have the daily mean.
>> > What would you suggest?
>> >
>> > Really Really thanks,
>> > You are my lifesaver
>> >
>> > Thanks
>> >
>> >
>> >
>> > Diego
>> >
>> >
>> > On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> >
>> > > ... and the most common source of NA values in time data is wrong
>> > > timezones. You really need to make sure the timezone that is assumed
>> > > when the character data are converted to POSIXt agrees with the data.
>> > > In most cases the easiest way to insure this is to use
>> > >
>> > > Sys.setenv(TZ="US/Pacific")
>> > >
>> > > or whatever timezone from
>> > >
>> > > OlsonNames()
>> > >
>> > > corresponds with your data. Execute this setenv function before the
>> > > strptime or as.POSIXct() function call.
>> > >
>> > > You can use
>> > >
>> > > MyData[ is.na(MyData$datetime), ]
>> > >
>> > > to see which records are failing to convert time.
>> > >
>> > > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>> > >
>> > > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
>> > wrote:
>> > > >Hi Diego,
>> > > >I think the error is due to NA values in your data file. If I extend
>> > > >your example and run it, I get no errors:
>> > > >
>> > > >MyData<-read.table(text="103001930 103001580 103001530
>> > > >1998-10-01 00:00:00 0.6 0 0
>> > > >1998-10-01 01:00:00 0.2 0.2 0.2
>> > > >1998-10-01 02:00:00 0.6 0.2 0.4
>> > > >1998-10-01 03:00:00 0 0 0.6
>> > > >1998-10-01 04:00:00 0 0 0
>> > > >1998-10-01 05:00:00 0 0 0
>> > > >1998-10-01 06:00:00 0 0 0
>> > > >1998-10-01 07:00:00 0.2 0 0
>> > > >1998-10-01 08:00:00 0.6 0 0
>> > > >1998-10-01 09:00:00 0.2 0.2 0.2
>> > > >1998-10-01 10:00:00 0.6 0.2 0.4
>> > > >1998-10-01 11:00:00 0 0 0.6
>> > > >1998-10-01 12:00:00 0 0 0
>> > > >1998-10-01 13:00:00 0 0 0
>> > > >1998-10-01 14:00:00 0 0 0
>> > > >1998-10-01 15:00:00 0.2 0 0
>> > > >1998-10-01 16:00:00 0.6 0 0
>> > > >1998-10-01 17:00:00 0.2 0.2 0.2
>> > > >1998-10-01 18:00:00 0.6 0.2 0.4
>> > > >1998-10-01 19:00:00 0 0 0.6
>> > > >1998-10-01 20:00:00 0 0 0
>> > > >1998-10-01 21:00:00 0 0 0
>> > > >1998-10-01 22:00:00 0 0 0
>> > > >1998-10-01 23:00:00 0.2 0 0
>> > > >1998-10-02 00:00:00 0.6 0 0
>> > > >1998-10-02 01:00:00 0.2 0.2 0.2
>> > > >1998-10-02 02:00:00 0.6 0.2 0.4
>> > > >1998-10-02 03:00:00 0 0 0.6
>> > > >1998-10-02 04:00:00 0 0 0
>> > > >1998-10-02 05:00:00 0 0 0
>> > > >1998-10-02 06:00:00 0 0 0
>> > > >1998-10-02 07:00:00 0.2 0 0
>> > > >1998-10-02 08:00:00 0.6 0 0
>> > > >1998-10-02 09:00:00 0.2 0.2 0.2
>> > > >1998-10-02 10:00:00 0.6 0.2 0.4
>> > > >1998-10-02 11:00:00 0 0 0.6
>> > > >1998-10-02 12:00:00 0 0 0
>> > > >1998-10-02 13:00:00 0 0 0
>> > > >1998-10-02 14:00:00 0 0 0
>> > > >1998-10-02 15:00:00 0.2 0 0
>> > > >1998-10-02 16:00:00 0.6 0 0
>> > > >1998-10-02 17:00:00 0.2 0.2 0.2
>> > > >1998-10-02 18:00:00 0.6 0.2 0.4
>> > > >1998-10-02 19:00:00 0 0 0.6
>> > > >1998-10-02 20:00:00 0 0 0
>> > > >1998-10-02 21:00:00 0 0 0
>> > > >1998-10-02 22:00:00 0 0 0
>> > > >1998-10-02 23:00:00 0.2 0 0",
>> > > >skip=1,stringsAsFactors=FALSE)
>> > > >names(MyData)<-c("date","time","st1","st2","st3")
>> > > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
>> > > > format="%Y-%m-%d %H:%M:%S")
>> > > >MyData$datetime
>> > > >st1_daily<-by(MyData$st1,MyData$date,mean)
>> > > >st2_daily<-by(MyData$st2,MyData$date,mean)
>> > > >st3_daily<-by(MyData$st3,MyData$date,mean)
>> > > >st1_daily
>> > > >st2_daily
>> > > >st3_daily
>> > > >
>> > > >Try adding na.rm=TRUE to the "by" calls:
>> > > >
>> > > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
>> > > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
>> > > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
>> > > >
>> > > >Jim
>> > > >
>> > > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
>> > > ><diego.avesani at gmail.com> wrote:
>> > > >> Dear all,
>> > > >>
>> > > >> I have still problem with date.
>> > > >> Could you please tel me how to use POSIXct.
>> > > >> Indeed I have found this command:
>> > > >> timeAverage, but I am not able to convert MyDate to properly date.
>> > > >>
>> > > >> Thank a lot
>> > > >> I hope to no bother you, at least too much
>> > > >>
>> > > >>
>> > > >> Diego
>> > > >>
>> > > >>
>> > > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
>> > > >wrote:
>> > > >>>
>> > > >>> Dear Jim, Dear all,
>> > > >>>
>> > > >>> thanks a lot.
>> > > >>>
>> > > >>> Unfortunately, I get the following error:
>> > > >>>
>> > > >>>
>> > > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>> > > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
>> > > >925L,  :
>> > > >>>   arguments must have same length
>> > > >>>
>> > > >>>
>> > > >>> This is particularly strange. indeed, if I apply
>> > > >>>
>> > > >>>
>> > > >>> mean(MyData$str1,na.rm=TRUE)
>> > > >>>
>> > > >>>
>> > > >>> it works
>> > > >>>
>> > > >>>
>> > > >>> Sorry, I have to learn a lot.
>> > > >>> You are really boosting me
>> > > >>>
>> > > >>> Diego
>> > > >>>
>> > > >>>
>> > > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>> > > >>>>
>> > > >>>> Hi Diego,
>> > > >>>> One way you can get daily means is:
>> > > >>>>
>> > > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>> > > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>> > > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>> > > >>>>
>> > > >>>> Jim
>> > > >>>>
>> > > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
>> > > ><diego.avesani at gmail.com>
>> > > >>>> wrote:
>> > > >>>> > Dear all,
>> > > >>>> > I have found the error, my fault. Sorry.
>> > > >>>> > There was an extra come in the headers line.
>> > > >>>> > Thanks again.
>> > > >>>> >
>> > > >>>> > If I can I would like to ask you another questions about the
>> > > >imported
>> > > >>>> > data.
>> > > >>>> > I would like to compute the daily average of the different
>> date.
>> > > >>>> > Basically I
>> > > >>>> > have hourly data, I would like to ave the daily mean of them.
>> > > >>>> >
>> > > >>>> > Is there some special commands?
>> > > >>>> >
>> > > >>>> > Thanks a lot.
>> > > >>>> >
>> > > >>>> >
>> > > >>>> > Diego
>> > > >>>> >
>> > > >>>> >
>> > > >>>> > On 31 July 2018 at 10:40, Diego Avesani
>> > > >>>> > <diego.avesani at gmail.com>
>> > > >>>> > wrote:
>> > > >>>> >>
>> > > >>>> >> Dear all,
>> > > >>>> >> I move to csv file because originally the date where in csv
>> > > >file.
>> > > >>>> >> In addition, due to the fact that, as you told me, read.csv is
>> > > >>>> >> a special case of read.table, I prefer start to learn from the
>> > > >>>> >> simplest
>> > > >one.
>> > > >>>> >> After that, I will try also the *.txt format.
>> > > >>>> >>
>> > > >>>> >> with read.csv, something strange happened:
>> > > >>>> >>
>> > > >>>> >> This us now the file:
>> > > >>>> >>
>> > > >>>> >> date,st1,st2,st3,
>> > > >>>> >> 10/1/1998 0:00,0.6,0,0
>> > > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>> > > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>> > > >>>> >> 10/1/1998 3:00,0,0,0.6
>> > > >>>> >> 10/1/1998 4:00,0,0,0
>> > > >>>> >> 10/1/1998 5:00,0,0,0
>> > > >>>> >> 10/1/1998 6:00,0,0,0
>> > > >>>> >> 10/1/1998 7:00,0.2,0,0
>> > > >>>> >> 10/1/1998 8:00,0.6,0.2,0
>> > > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>> > > >>>> >> 10/1/1998 10:00,0,0.4,0.2
>> > > >>>> >>
>> > > >>>> >> When I apply:
>> > > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>> > > >>>> >>
>> > > >>>> >> this is the results:
>> > > >>>> >>
>> > > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>> > > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>> > > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>> > > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>> > > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>> > > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>> > > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>> > > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>> > > >>>> >>
>> > > >>>> >> I do not understand why.
>> > > >>>> >> Something wrong with date?
>> > > >>>> >>
>> > > >>>> >> really really thanks,
>> > > >>>> >> I appreciate a lot all your helps.
>> > > >>>> >>
>> > > >>>> >> Diedro
>> > > >>>> >>
>> > > >>>> >>
>> > > >>>> >> Diego
>> > > >>>> >>
>> > > >>>> >>
>> > > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
>> > > >wrote:
>> > > >>>> >>>
>> > > >>>> >>> Or, without removing the first line
>> > > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
>> > > >>>> >>> skip=1)
>> > > >>>> >>>
>> > > >>>> >>> Another alternative,
>> > > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>> > > >>>> >>> since the dates appear to be in the default format.
>> > > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
>> > > >rather
>> > > >>>> >>> than
>> > > >>>> >>> POSIXlt class)
>> > > >>>> >>>
>> > > >>>> >>> -Don
>> > > >>>> >>>
>> > > >>>> >>> --
>> > > >>>> >>> Don MacQueen
>> > > >>>> >>> Lawrence Livermore National Laboratory
>> > > >>>> >>> 7000 East Ave., L-627
>> > > >>>> >>> Livermore, CA 94550
>> > > >>>> >>> 925-423-1062
>> > > >>>> >>> Lab cell 925-724-7509
>> > > >>>> >>>
>> > > >>>> >>>
>> > > >>>> >>>
>> > > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>> > > >>>> >>> <r-help-bounces at r-project.org on behalf of
>> > > >drjimlemon at gmail.com>
>> > > >>>> >>> wrote:
>> > > >>>> >>>
>> > > >>>> >>>     Hi Diego,
>> > > >>>> >>>     You may have to do some conversion as you have three
>> > > >>>> >>> fields
>> > > >in
>> > > >>>> >>> the
>> > > >>>> >>>     first line using the default space separator and five
>> > > >fields in
>> > > >>>> >>>     subsequent lines. If the first line doesn't contain any
>> > > >important
>> > > >>>> >>> data
>> > > >>>> >>>     you can just delete it or replace it with a meaningful
>> > > >header
>> > > >>>> >>> line
>> > > >>>> >>>     with five fields and save the file under another name.
>> > > >>>> >>>
>> > > >>>> >>>     It looks as thought you have date-time as two fields. If
>> > > >so, you
>> > > >>>> >>> can
>> > > >>>> >>>     just read the first field if you only want the date:
>> > > >>>> >>>
>> > > >>>> >>>     # assume you have removed the first line
>> > > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>> > > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>> > > >>>> >>>
>> > > >>>> >>>     If you want the date/time:
>> > > >>>> >>>
>> > > >>>> >>>
>> > > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>> > > >>>> >>> %H:%M:%S")
>> > > >>>> >>>
>> > > >>>> >>>     Jim
>> > > >>>> >>>
>> > > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>> > > >>>> >>> <diego.avesani at gmail.com> wrote:
>> > > >>>> >>>     > Dear all,
>> > > >>>> >>>     >
>> > > >>>> >>>     > I am dealing with the reading of a *.txt file.
>> > > >>>> >>>     > The txt file the following shape:
>> > > >>>> >>>     >
>> > > >>>> >>>     > 103001930 103001580 103001530
>> > > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>> > > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>> > > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>> > > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>> > > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
>> > > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
>> > > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
>> > > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>> > > >>>> >>>     >
>> > > >>>> >>>     > If it is possible I have a coupe of questions, which
>> > > >>>> >>> will
>> > > >sound
>> > > >>>> >>> stupid but
>> > > >>>> >>>     > they are important to me in order to understand ho R
>> > > >>>> >>> deal
>> > > >with
>> > > >>>> >>> file
>> > > >>>> >>> or date.
>> > > >>>> >>>     >
>> > > >>>> >>>     > 1) Do I have to convert it to a *csv file?
>> > > >>>> >>>     > 2) Can a deal with space and not ","
>> > > >>>> >>>     > 3) How can I read date?
>> > > >>>> >>>     >
>> > > >>>> >>>     > thanks a lot to all of you,
>> > > >>>> >>>     > Thanks
>> > > >>>> >>>     >
>> > > >>>> >>>     >
>> > > >>>> >>>     > Diego
>> > > >>>> >>>     >
>> > > >>>> >>>     >         [[alternative HTML version deleted]]
>> > > >>>> >>>     >
>> > > >>>> >>>     > ______________________________________________
>> > > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE
>> and
>> > > >more,
>> > > >>>> >>> see
>> > > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >>>> >>>     > PLEASE do read the posting guide
>> > > >>>> >>> http://www.R-project.org/posting-guide.html
>> > > >>>> >>>     > and provide commented, minimal, self-contained,
>> > > >reproducible
>> > > >>>> >>> code.
>> > > >>>> >>>
>> > > >>>> >>>     ______________________________________________
>> > > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> > > >more, see
>> > > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >>>> >>>     PLEASE do read the posting guide
>> > > >>>> >>> http://www.R-project.org/posting-guide.html
>> > > >>>> >>>     and provide commented, minimal, self-contained,
>> > > >reproducible
>> > > >>>> >>> code.
>> > > >>>> >>>
>> > > >>>> >>>
>> > > >>>> >>
>> > > >>>> >
>> > > >>>
>> > > >>>
>> > > >>
>> > > >
>> > > >______________________________________________
>> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >PLEASE do read the posting guide
>> > > >http://www.R-project.org/posting-guide.html
>> > > >and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > > --
>> > > Sent from my phone. Please excuse my brevity.
>> > >
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady
>> -ochrany-osobnich-udaju/ | Information about processing and protection
>> of business partner?s personal data are available on website:
>> https://www.precheza.cz/en/personal-data-protection-principles/
>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>> documents attached to it may be confidential and are subject to the legally
>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>
>>
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Wed Aug  1 15:09:18 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 1 Aug 2018 13:09:18 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <9fb07206dab14492acb6c2aa56c9d6a4@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y5TW5t=TsTF6rGz=_MTcaTMtzE3nPUKNPoSHNiUWY-hSQ@mail.gmail.com>
Message-ID: <38987a7e64a945f0b164783a6cf717d7@SRVEXCHCM1302.precheza.cz>

Hi

see in line

From: Diego Avesani <diego.avesani at gmail.com>
Sent: Wednesday, August 1, 2018 2:30 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] read txt file - date - no space

Dear Pikal, Deal all,

again really thank.

it seems not working.
Some specifications: My non data are -999, but I could change it.

You must change it to NA. How the poor R should know that -999 is missing and not a real value.

something like

Mydata[Mydata== -999] <- NA

should do it.

My final results is:


1        1  -55.86242 -55.84764660 -277.4775

2        2  -55.47554 -94.58921682 -277.4845

3        3  -55.47095 -99.20239198 -277.4709

4        4  -55.46470 -55.45952932 -392.9071

5        5  -55.43335 -55.40171682 -388.4110

6        6  -55.40108 -55.37399691 -332.9068

7        7  -55.39201 -55.35156250 -332.8902

8        8 -110.87184   0.16136188 -281.8230

9        9 -110.95077 -55.63856096 -332.9564

10      10 -157.64430  -0.06602705 -315.3840

11      11 -105.06157   0.11507675 -315.4152

12      12  -70.08677 -52.54501096 -316.7247

So it is not correct.
For example for the first day in my csv I would have expected 0.167.

I am going to post what you have suggested:

for  str(MyData)

Your data seems to be OK, so after you change your -999 to NA everything should be OK.

'data.frame':                 160008 obs. of  4 variables:
 $ date: POSIXct, format: "1998-01-10 00:00:00" "1998-01-10 01:00:00" "1998-01-10 02:00:00" "1998-01-10 03:00:00" ...
 $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
 $ str2: num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
 $ str3: num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...

unfortunately, I am not able to post

dput(str[1:20,])

it gives me

Error in str[1:20, ] : object of type 'closure' is not subsettable



dput(MyData[1:20,])



I would recommend you to spend some time reading R-intro which should be located in doc/manual folder of your installation. It could help you in many situations.



Cheers

Petr


Thanks again,
I hope that what I posted could be enough in order to help me.



Diego

On 1 August 2018 at 13:58, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

I did not get through all answers you already got and you probably obtained similar advice as mine.

# read data (if you have csv file just use read.csv)
> test<-read.table("clipboard", header=T, sep=",")

# control your object(s)
> str(test)
'data.frame':   8 obs. of  4 variables:
 $ date: Factor w/ 8 levels "10/1/1998 0:00",..: 1 2 3 4 5 6 7 8
 $ str1: num  0.6 0.2 0.6 0 0 0 0 0.2
 $ str2: num  0 0.2 0.2 0 0 0 0 0
 $ str3: num  0 0.2 0.4 0.6 0 0 0 0

#if it is OK change first column to real date by POSIXct
test$date<-as.POSIXct(test$date, format="%d/%m/%Y %H:%M")

#attach lubridate
> library(lubridate)

# aggregate your object(s) and use lubridate function

> aggregate(test[,-1], list(day(test$date)), mean)
  Group.1 str1 str2 str3
1      10  0.2 0.05 0.15

# or format function

> aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
     Group.1 str1 str2 str3
1 1998-01-10  0.2 0.05 0.15

If it does not work with your data you should post at least result of

str(yourdata)

or preferably

dput(yourdata[1:20,])

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Diego Avesani
> Sent: Wednesday, August 1, 2018 8:55 AM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>
> Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] read txt file - date - no space
>
> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat all again
> in order to understand.
> If I could I would like to start again, without mixing strategy and waiting for
> your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in the
> mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed
> > when the character data are converted to POSIXt agrees with the data.
> > In most cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na<http://is.na>(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani
> > >>>> > <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is
> > >>>> >> a special case of read.table, I prefer start to learn from the
> > >>>> >> simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
> > >>>> >>> skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of
> > >drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three
> > >>>> >>> fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which
> > >>>> >>> will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R
> > >>>> >>> deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From jho|tm@n @end|ng |rom gm@||@com  Wed Aug  1 17:01:17 2018
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Wed, 1 Aug 2018 08:01:17 -0700
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
Message-ID: <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>

Try this:

> library(lubridate)
> library(tidyverse)
> input <- read.csv(text = "date,str1,str2,str3
+ 10/1/1998 0:00,0.6,0,0
+                   10/1/1998 1:00,0.2,0.2,0.2
+                   10/1/1998 2:00,0.6,0.2,0.4
+                   10/1/1998 3:00,0,0,0.6
+                   10/1/1998 4:00,0,0,0
+                   10/1/1998 5:00,0,0,0
+                   10/1/1998 6:00,0,0,0
+                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
> # convert the date and add the "day" so summarize
> input <- input %>%
+   mutate(date = mdy_hm(date),
+          day = floor_date(date, unit = 'day')
+   )
>
> by_day <- input %>%
+   group_by(day) %>%
+   summarise(m_s1 = mean(str1),
+             m_s2 = mean(str2),
+             m_s3 = mean(str3)
+   )
>
> by_day
# A tibble: 1 x 4
  day                  m_s1   m_s2  m_s3
  <dttm>              <dbl>  <dbl> <dbl>
1 1998-10-01 00:00:00 0.200 0.0500 0.150

Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
wrote:

> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
> all again in order to understand.
> If I could I would like to start again, without mixing strategy and waiting
> for your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in
> the mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed when
> > the character data are converted to POSIXt agrees with the data. In most
> > cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> > >>>> >> special
> > >>>> >> case of read.table, I prefer start to learn from the simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > >drjimlemon at gmail.com>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @||ve@tr|@c@@@|| @end|ng |rom gm@||@com  Wed Aug  1 17:40:54 2018
From: @||ve@tr|@c@@@|| @end|ng |rom gm@||@com (Edoardo Silvestri)
Date: Wed, 1 Aug 2018 17:40:54 +0200
Subject: [R] New post for Rhelp
Message-ID: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>

I have a database based on hourly data and I need to forecast next 24h of a
single variable. I was thinking about applying an ARIMA model with some
exogenous variables but I don't succeed to configure the hourly frequency,
estimate ARIMA parameters, pdq ( exists some tests to check which
parameters are better for the model?) and the structure of the model in its
easy form because I would also like to introduce some seasonality form by
analyzing some variables I highlighted some daily and weekly behaviours
similar.



I recognize that it could be quite difficult the problem but if you have
also some useful links or some codes that can help me, please send me.

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug  1 21:51:49 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 1 Aug 2018 12:51:49 -0700
Subject: [R] New post for Rhelp
In-Reply-To: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>
References: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>
Message-ID: <CAGxFJbQDpANZJwoyk-NG1CU4KFV59p_S5nJcXUUbNSxuZpuaNA@mail.gmail.com>

Statistics issues are generally off topic here; and we generally prefer
posters to show us their own efforts rather than expecting us to solve the
problem for them.

However, this CRAN time series task view may be useful to you:

https://cran.r-project.org/web/views/TimeSeries.html

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 1, 2018 at 8:40 AM, Edoardo Silvestri <
silvestri.casali at gmail.com> wrote:

> I have a database based on hourly data and I need to forecast next 24h of a
> single variable. I was thinking about applying an ARIMA model with some
> exogenous variables but I don't succeed to configure the hourly frequency,
> estimate ARIMA parameters, pdq ( exists some tests to check which
> parameters are better for the model?) and the structure of the model in its
> easy form because I would also like to introduce some seasonality form by
> analyzing some variables I highlighted some daily and weekly behaviours
> similar.
>
>
>
> I recognize that it could be quite difficult the problem but if you have
> also some useful links or some codes that can help me, please send me.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From rod@@t@||ord @end|ng |rom gm@||@com  Thu Aug  2 03:20:04 2018
From: rod@@t@||ord @end|ng |rom gm@||@com (R Stafford)
Date: Wed, 1 Aug 2018 21:20:04 -0400
Subject: [R] Combinations of true/false values where one pair is mutually
 exclusive
Message-ID: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>

I have 6 variables, (A,B,C,D,E,F) that can either pass or fail (i.e., true
or false).
I can get a table of all pass/fail combinations with this:

scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"), F =
c("pass", "fail"))

But I have the extra condition that if E is true, then F must be false, and
vice versa, so what I don't know is how to get all combinations when E and F
are mutually exclusive.

	[[alternative HTML version deleted]]



From chk@tr @end|ng |rom un||e@|t  Thu Aug  2 04:01:24 2018
From: chk@tr @end|ng |rom un||e@|t (Saptorshee Kanto Chakraborty)
Date: Thu, 2 Aug 2018 04:01:24 +0200
Subject: [R] CODE HELP
Message-ID: <CAAr3ZhjhfE8ED+EwZeUOmM6gd8vcoKoZrWdswe-CVE3MXvF8oA@mail.gmail.com>

Hello,

I am interested to apply an econometric technique of  Latent Variable
framework on Environmental Kuznets Curve for 164 countries for a span of 25
years.

The methodology and the code are from Simulation exercise from an
unpublished paper "Two Examples of Convex-Programming-Based
High-Dimensional Econometric Estimators" in R. Is it somehow possible to
apply it to my data.


I am attaching the codes

Thanking You

-- 
Saptorshee Chakraborty

Personal Website: http://saptorshee.weebly.com/


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug  2 07:20:37 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 2 Aug 2018 15:20:37 +1000
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
Message-ID: <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>

Hi Rod,
How about this?

scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"))
scenarios$F<-ifelse(scenarios$E=="pass","fail","pass")

Jim



On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com> wrote:
> I have 6 variables, (A,B,C,D,E,F) that can either pass or fail (i.e., true
> or false).
> I can get a table of all pass/fail combinations with this:
>
> scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
> c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"), F =
> c("pass", "fail"))
>
> But I have the extra condition that if E is true, then F must be false, and
> vice versa, so what I don't know is how to get all combinations when E and F
> are mutually exclusive.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jwd @end|ng |rom @urewe@t@net  Thu Aug  2 07:35:07 2018
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 1 Aug 2018 22:35:07 -0700
Subject: [R] New post for Rhelp
In-Reply-To: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>
References: <CAEv8TnR=mHqYvS9z2VRTq3d6nZOaQS4ge3AUeRz6BEWMyU=8Jw@mail.gmail.com>
Message-ID: <20180801223507.505eba68@Draco.localdomain>

On Wed, 1 Aug 2018 17:40:54 +0200
Edoardo Silvestri <silvestri.casali at gmail.com> wrote:

> I have a database based on hourly data and I need to forecast next
> 24h of a single variable. I was thinking about applying an ARIMA
> model with some exogenous variables but I don't succeed to configure
> the hourly frequency, estimate ARIMA parameters, pdq ( exists some
> tests to check which parameters are better for the model?) and the
> structure of the model in its easy form because I would also like to
> introduce some seasonality form by analyzing some variables I
> highlighted some daily and weekly behaviours similar.
> 
> 
> 
> I recognize that it could be quite difficult the problem but if you
> have also some useful links or some codes that can help me, please
> send me.
> 
You are talking about analyzing data in a regular time series.  R has
wide ranging time series analysis packages.  I would suggest starting
with the basic package that comes with an R download and reading the
basic information associated with it.  You could also checkout Venables
and Ripley, _Modern Applied Statistics with S [which R is a dialect
of].  If this is a homework question, hit the books.

JWDougherty



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Thu Aug  2 08:55:34 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Thu, 2 Aug 2018 08:55:34 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
Message-ID: <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>

Dear

I have check the one of the line that gives me problem. I mean, which give
NA after R processing. I think that is similar to the others:

10/12/1998 10:00,0,0,0
10/12/1998 11:00,0,0,0
10/12/1998 12:00,0,0,0
10/12/1998 13:00,0,0,0
10/12/1998 14:00,0,0,0
10/12/1998 15:00,0,0,0
10/12/1998 16:00,0,0,0
10/12/1998 17:00,0,0,0

@jim: It seems that you suggestion is focus on reading data from the
terminal. It is possible to apply it to a *.csv file?

@Pikal: Could it be that there are some date conversion error?

Thanks again,
Diego


Diego


On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com> wrote:

>
> Try this:
>
> > library(lubridate)
> > library(tidyverse)
> > input <- read.csv(text = "date,str1,str2,str3
> + 10/1/1998 0:00,0.6,0,0
> +                   10/1/1998 1:00,0.2,0.2,0.2
> +                   10/1/1998 2:00,0.6,0.2,0.4
> +                   10/1/1998 3:00,0,0,0.6
> +                   10/1/1998 4:00,0,0,0
> +                   10/1/1998 5:00,0,0,0
> +                   10/1/1998 6:00,0,0,0
> +                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
> > # convert the date and add the "day" so summarize
> > input <- input %>%
> +   mutate(date = mdy_hm(date),
> +          day = floor_date(date, unit = 'day')
> +   )
> >
> > by_day <- input %>%
> +   group_by(day) %>%
> +   summarise(m_s1 = mean(str1),
> +             m_s2 = mean(str2),
> +             m_s3 = mean(str3)
> +   )
> >
> > by_day
> # A tibble: 1 x 4
>   day                  m_s1   m_s2  m_s3
>   <dttm>              <dbl>  <dbl> <dbl>
> 1 1998-10-01 00:00:00 0.200 0.0500 0.150
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve?Tell me what you want to
> do, not how you want to do it.*
>
>
> On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
> wrote:
>
>> Dear all,
>> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
>> all again in order to understand.
>> If I could I would like to start again, without mixing strategy and
>> waiting
>> for your advice.
>>
>> I am really appreciate you help, really really.
>> Here my new file, a *.csv file (buy the way, it is possible to attach it
>> in
>> the mailing list?)
>>
>> date,str1,str2,str3
>> 10/1/1998 0:00,0.6,0,0
>> 10/1/1998 1:00,0.2,0.2,0.2
>> 10/1/1998 2:00,0.6,0.2,0.4
>> 10/1/1998 3:00,0,0,0.6
>> 10/1/1998 4:00,0,0,0
>> 10/1/1998 5:00,0,0,0
>> 10/1/1998 6:00,0,0,0
>> 10/1/1998 7:00,0.2,0,0
>>
>>
>> I read it as:
>> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>
>> at this point I would like to have the daily mean.
>> What would you suggest?
>>
>> Really Really thanks,
>> You are my lifesaver
>>
>> Thanks
>>
>>
>>
>> Diego
>>
>>
>> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>> > ... and the most common source of NA values in time data is wrong
>> > timezones. You really need to make sure the timezone that is assumed
>> when
>> > the character data are converted to POSIXt agrees with the data. In most
>> > cases the easiest way to insure this is to use
>> >
>> > Sys.setenv(TZ="US/Pacific")
>> >
>> > or whatever timezone from
>> >
>> > OlsonNames()
>> >
>> > corresponds with your data. Execute this setenv function before the
>> > strptime or as.POSIXct() function call.
>> >
>> > You can use
>> >
>> > MyData[ is.na(MyData$datetime), ]
>> >
>> > to see which records are failing to convert time.
>> >
>> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>> >
>> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>> > >Hi Diego,
>> > >I think the error is due to NA values in your data file. If I extend
>> > >your example and run it, I get no errors:
>> > >
>> > >MyData<-read.table(text="103001930 103001580 103001530
>> > >1998-10-01 00:00:00 0.6 0 0
>> > >1998-10-01 01:00:00 0.2 0.2 0.2
>> > >1998-10-01 02:00:00 0.6 0.2 0.4
>> > >1998-10-01 03:00:00 0 0 0.6
>> > >1998-10-01 04:00:00 0 0 0
>> > >1998-10-01 05:00:00 0 0 0
>> > >1998-10-01 06:00:00 0 0 0
>> > >1998-10-01 07:00:00 0.2 0 0
>> > >1998-10-01 08:00:00 0.6 0 0
>> > >1998-10-01 09:00:00 0.2 0.2 0.2
>> > >1998-10-01 10:00:00 0.6 0.2 0.4
>> > >1998-10-01 11:00:00 0 0 0.6
>> > >1998-10-01 12:00:00 0 0 0
>> > >1998-10-01 13:00:00 0 0 0
>> > >1998-10-01 14:00:00 0 0 0
>> > >1998-10-01 15:00:00 0.2 0 0
>> > >1998-10-01 16:00:00 0.6 0 0
>> > >1998-10-01 17:00:00 0.2 0.2 0.2
>> > >1998-10-01 18:00:00 0.6 0.2 0.4
>> > >1998-10-01 19:00:00 0 0 0.6
>> > >1998-10-01 20:00:00 0 0 0
>> > >1998-10-01 21:00:00 0 0 0
>> > >1998-10-01 22:00:00 0 0 0
>> > >1998-10-01 23:00:00 0.2 0 0
>> > >1998-10-02 00:00:00 0.6 0 0
>> > >1998-10-02 01:00:00 0.2 0.2 0.2
>> > >1998-10-02 02:00:00 0.6 0.2 0.4
>> > >1998-10-02 03:00:00 0 0 0.6
>> > >1998-10-02 04:00:00 0 0 0
>> > >1998-10-02 05:00:00 0 0 0
>> > >1998-10-02 06:00:00 0 0 0
>> > >1998-10-02 07:00:00 0.2 0 0
>> > >1998-10-02 08:00:00 0.6 0 0
>> > >1998-10-02 09:00:00 0.2 0.2 0.2
>> > >1998-10-02 10:00:00 0.6 0.2 0.4
>> > >1998-10-02 11:00:00 0 0 0.6
>> > >1998-10-02 12:00:00 0 0 0
>> > >1998-10-02 13:00:00 0 0 0
>> > >1998-10-02 14:00:00 0 0 0
>> > >1998-10-02 15:00:00 0.2 0 0
>> > >1998-10-02 16:00:00 0.6 0 0
>> > >1998-10-02 17:00:00 0.2 0.2 0.2
>> > >1998-10-02 18:00:00 0.6 0.2 0.4
>> > >1998-10-02 19:00:00 0 0 0.6
>> > >1998-10-02 20:00:00 0 0 0
>> > >1998-10-02 21:00:00 0 0 0
>> > >1998-10-02 22:00:00 0 0 0
>> > >1998-10-02 23:00:00 0.2 0 0",
>> > >skip=1,stringsAsFactors=FALSE)
>> > >names(MyData)<-c("date","time","st1","st2","st3")
>> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
>> > > format="%Y-%m-%d %H:%M:%S")
>> > >MyData$datetime
>> > >st1_daily<-by(MyData$st1,MyData$date,mean)
>> > >st2_daily<-by(MyData$st2,MyData$date,mean)
>> > >st3_daily<-by(MyData$st3,MyData$date,mean)
>> > >st1_daily
>> > >st2_daily
>> > >st3_daily
>> > >
>> > >Try adding na.rm=TRUE to the "by" calls:
>> > >
>> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
>> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
>> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
>> > >
>> > >Jim
>> > >
>> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
>> > ><diego.avesani at gmail.com> wrote:
>> > >> Dear all,
>> > >>
>> > >> I have still problem with date.
>> > >> Could you please tel me how to use POSIXct.
>> > >> Indeed I have found this command:
>> > >> timeAverage, but I am not able to convert MyDate to properly date.
>> > >>
>> > >> Thank a lot
>> > >> I hope to no bother you, at least too much
>> > >>
>> > >>
>> > >> Diego
>> > >>
>> > >>
>> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
>> > >wrote:
>> > >>>
>> > >>> Dear Jim, Dear all,
>> > >>>
>> > >>> thanks a lot.
>> > >>>
>> > >>> Unfortunately, I get the following error:
>> > >>>
>> > >>>
>> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
>> > >925L,  :
>> > >>>   arguments must have same length
>> > >>>
>> > >>>
>> > >>> This is particularly strange. indeed, if I apply
>> > >>>
>> > >>>
>> > >>> mean(MyData$str1,na.rm=TRUE)
>> > >>>
>> > >>>
>> > >>> it works
>> > >>>
>> > >>>
>> > >>> Sorry, I have to learn a lot.
>> > >>> You are really boosting me
>> > >>>
>> > >>> Diego
>> > >>>
>> > >>>
>> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>> > >>>>
>> > >>>> Hi Diego,
>> > >>>> One way you can get daily means is:
>> > >>>>
>> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>> > >>>>
>> > >>>> Jim
>> > >>>>
>> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
>> > ><diego.avesani at gmail.com>
>> > >>>> wrote:
>> > >>>> > Dear all,
>> > >>>> > I have found the error, my fault. Sorry.
>> > >>>> > There was an extra come in the headers line.
>> > >>>> > Thanks again.
>> > >>>> >
>> > >>>> > If I can I would like to ask you another questions about the
>> > >imported
>> > >>>> > data.
>> > >>>> > I would like to compute the daily average of the different date.
>> > >>>> > Basically I
>> > >>>> > have hourly data, I would like to ave the daily mean of them.
>> > >>>> >
>> > >>>> > Is there some special commands?
>> > >>>> >
>> > >>>> > Thanks a lot.
>> > >>>> >
>> > >>>> >
>> > >>>> > Diego
>> > >>>> >
>> > >>>> >
>> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com
>> >
>> > >>>> > wrote:
>> > >>>> >>
>> > >>>> >> Dear all,
>> > >>>> >> I move to csv file because originally the date where in csv
>> > >file.
>> > >>>> >> In addition, due to the fact that, as you told me, read.csv is a
>> > >>>> >> special
>> > >>>> >> case of read.table, I prefer start to learn from the simplest
>> > >one.
>> > >>>> >> After that, I will try also the *.txt format.
>> > >>>> >>
>> > >>>> >> with read.csv, something strange happened:
>> > >>>> >>
>> > >>>> >> This us now the file:
>> > >>>> >>
>> > >>>> >> date,st1,st2,st3,
>> > >>>> >> 10/1/1998 0:00,0.6,0,0
>> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>> > >>>> >> 10/1/1998 3:00,0,0,0.6
>> > >>>> >> 10/1/1998 4:00,0,0,0
>> > >>>> >> 10/1/1998 5:00,0,0,0
>> > >>>> >> 10/1/1998 6:00,0,0,0
>> > >>>> >> 10/1/1998 7:00,0.2,0,0
>> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
>> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
>> > >>>> >>
>> > >>>> >> When I apply:
>> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>> > >>>> >>
>> > >>>> >> this is the results:
>> > >>>> >>
>> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>> > >>>> >>
>> > >>>> >> I do not understand why.
>> > >>>> >> Something wrong with date?
>> > >>>> >>
>> > >>>> >> really really thanks,
>> > >>>> >> I appreciate a lot all your helps.
>> > >>>> >>
>> > >>>> >> Diedro
>> > >>>> >>
>> > >>>> >>
>> > >>>> >> Diego
>> > >>>> >>
>> > >>>> >>
>> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
>> > >wrote:
>> > >>>> >>>
>> > >>>> >>> Or, without removing the first line
>> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>> > >>>> >>>
>> > >>>> >>> Another alternative,
>> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>> > >>>> >>> since the dates appear to be in the default format.
>> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
>> > >rather
>> > >>>> >>> than
>> > >>>> >>> POSIXlt class)
>> > >>>> >>>
>> > >>>> >>> -Don
>> > >>>> >>>
>> > >>>> >>> --
>> > >>>> >>> Don MacQueen
>> > >>>> >>> Lawrence Livermore National Laboratory
>> > >>>> >>> 7000 East Ave., L-627
>> > >>>> >>> Livermore, CA 94550
>> > >>>> >>> 925-423-1062
>> > >>>> >>> Lab cell 925-724-7509
>> > >>>> >>>
>> > >>>> >>>
>> > >>>> >>>
>> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>> > >>>> >>> <r-help-bounces at r-project.org on behalf of
>> > >drjimlemon at gmail.com>
>> > >>>> >>> wrote:
>> > >>>> >>>
>> > >>>> >>>     Hi Diego,
>> > >>>> >>>     You may have to do some conversion as you have three fields
>> > >in
>> > >>>> >>> the
>> > >>>> >>>     first line using the default space separator and five
>> > >fields in
>> > >>>> >>>     subsequent lines. If the first line doesn't contain any
>> > >important
>> > >>>> >>> data
>> > >>>> >>>     you can just delete it or replace it with a meaningful
>> > >header
>> > >>>> >>> line
>> > >>>> >>>     with five fields and save the file under another name.
>> > >>>> >>>
>> > >>>> >>>     It looks as thought you have date-time as two fields. If
>> > >so, you
>> > >>>> >>> can
>> > >>>> >>>     just read the first field if you only want the date:
>> > >>>> >>>
>> > >>>> >>>     # assume you have removed the first line
>> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>> > >>>> >>>
>> > >>>> >>>     If you want the date/time:
>> > >>>> >>>
>> > >>>> >>>
>> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>> > >>>> >>> %H:%M:%S")
>> > >>>> >>>
>> > >>>> >>>     Jim
>> > >>>> >>>
>> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>> > >>>> >>> <diego.avesani at gmail.com> wrote:
>> > >>>> >>>     > Dear all,
>> > >>>> >>>     >
>> > >>>> >>>     > I am dealing with the reading of a *.txt file.
>> > >>>> >>>     > The txt file the following shape:
>> > >>>> >>>     >
>> > >>>> >>>     > 103001930 103001580 103001530
>> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
>> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
>> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
>> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>> > >>>> >>>     >
>> > >>>> >>>     > If it is possible I have a coupe of questions, which will
>> > >sound
>> > >>>> >>> stupid but
>> > >>>> >>>     > they are important to me in order to understand ho R deal
>> > >with
>> > >>>> >>> file
>> > >>>> >>> or date.
>> > >>>> >>>     >
>> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
>> > >>>> >>>     > 2) Can a deal with space and not ","
>> > >>>> >>>     > 3) How can I read date?
>> > >>>> >>>     >
>> > >>>> >>>     > thanks a lot to all of you,
>> > >>>> >>>     > Thanks
>> > >>>> >>>     >
>> > >>>> >>>     >
>> > >>>> >>>     > Diego
>> > >>>> >>>     >
>> > >>>> >>>     >         [[alternative HTML version deleted]]
>> > >>>> >>>     >
>> > >>>> >>>     > ______________________________________________
>> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> > >more,
>> > >>>> >>> see
>> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>> >>>     > PLEASE do read the posting guide
>> > >>>> >>> http://www.R-project.org/posting-guide.html
>> > >>>> >>>     > and provide commented, minimal, self-contained,
>> > >reproducible
>> > >>>> >>> code.
>> > >>>> >>>
>> > >>>> >>>     ______________________________________________
>> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> > >more, see
>> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>> >>>     PLEASE do read the posting guide
>> > >>>> >>> http://www.R-project.org/posting-guide.html
>> > >>>> >>>     and provide commented, minimal, self-contained,
>> > >reproducible
>> > >>>> >>> code.
>> > >>>> >>>
>> > >>>> >>>
>> > >>>> >>
>> > >>>> >
>> > >>>
>> > >>>
>> > >>
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Aug  2 09:32:38 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Aug 2018 07:32:38 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
Message-ID: <8a286c58191c4dfebcd7e1fb60db9bca@SRVEXCHCM1302.precheza.cz>

Hi

see in line (and please do not post HTML formated messages, it could be scrammbled)

From: Diego Avesani <diego.avesani at gmail.com>
Sent: Thursday, August 2, 2018 8:56 AM
To: jim holtman <jholtman at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] read txt file - date - no space

Dear

I have check the one of the line that gives me problem. I mean, which give NA after R processing. I think that is similar to the others:

You should stop **thinking** and instead do real inspection of ?offending? values.

10/12/1998 10:00,0,0,0
10/12/1998 11:00,0,0,0
10/12/1998 12:00,0,0,0
10/12/1998 13:00,0,0,0
10/12/1998 14:00,0,0,0
10/12/1998 15:00,0,0,0
10/12/1998 16:00,0,0,0
10/12/1998 17:00,0,0,0

These lines do not pose any problem with formating.

>  test<-read.table("clipboard", sep=",")
> str(test)
'data.frame':   8 obs. of  4 variables:
$ V1: Factor w/ 8 levels "10/12/1998 10:00",..: 1 2 3 4 5 6 7 8
$ V2: int  0 0 0 0 0 0 0 0
$ V3: int  0 0 0 0 0 0 0 0
$ V4: int  0 0 0 0 0 0 0 0
> as.POSIXct(test$V1, format="%d/%m/%Y %H:%M")
[1] "1998-12-10 10:00:00 CET" "1998-12-10 11:00:00 CET"
[3] "1998-12-10 12:00:00 CET" "1998-12-10 13:00:00 CET"
[5] "1998-12-10 14:00:00 CET" "1998-12-10 15:00:00 CET"
[7] "1998-12-10 16:00:00 CET" "1998-12-10 17:00:00 CET"


@jim: It seems that you suggestion is focus on reading data from the terminal. It is possible to apply it to a *.csv file?

@Pikal: Could it be that there are some date conversion error?

Well, your str(MyData) result suggest, that conversion from character to POSIX was done correctly (at least partly).

However NAs in date column you posted in second mail suggest, that some values in the input are probably formated differently and they are changed to NA during POSIX conversion.

You could check which values are problematic if instead directly changing date column to POSIX you put a new column to you data with converted POSIX values

So read your data from csv file and change date to POSIX but store it in different column of data frame.

MyData$date2 <- as.POSIXct(MyData$date, format="%d/%m/%Y %H:%M")

and check which values in your original file are formated differently.

something like
MyData$date[is.na(MyData$date2)]

However your (very basic) questions suggest, that you have only minor understanding what are R objects, how to check, inspect and manipulate them. You could do a big favour to yourself going through basic documentation as I suggested before.

Cheers
Petr

Thanks again,
Diego


Diego

On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com<mailto:jholtman at gmail.com>> wrote:

Try this:

> library(lubridate)
> library(tidyverse)
> input <- read.csv(text = "date,str1,str2,str3
+ 10/1/1998 0:00,0.6,0,0
+                   10/1/1998 1:00,0.2,0.2,0.2
+                   10/1/1998 2:00,0.6,0.2,0.4
+                   10/1/1998 3:00,0,0,0.6
+                   10/1/1998 4:00,0,0,0
+                   10/1/1998 5:00,0,0,0
+                   10/1/1998 6:00,0,0,0
+                   10/1/1998 7:00,0.2,0,0", as.is<http://as.is> = TRUE)
> # convert the date and add the "day" so summarize
> input <- input %>%
+   mutate(date = mdy_hm(date),
+          day = floor_date(date, unit = 'day')
+   )
>
> by_day <- input %>%
+   group_by(day) %>%
+   summarise(m_s1 = mean(str1),
+             m_s2 = mean(str2),
+             m_s3 = mean(str3)
+   )
>
> by_day
# A tibble: 1 x 4
  day                  m_s1   m_s2  m_s3
  <dttm>              <dbl>  <dbl> <dbl>
1 1998-10-01 00:00:00 0.200 0.0500 0.150

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear all,
I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
all again in order to understand.
If I could I would like to start again, without mixing strategy and waiting
for your advice.

I am really appreciate you help, really really.
Here my new file, a *.csv file (buy the way, it is possible to attach it in
the mailing list?)

date,str1,str2,str3
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0


I read it as:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

at this point I would like to have the daily mean.
What would you suggest?

Really Really thanks,
You are my lifesaver

Thanks



Diego


On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:

> ... and the most common source of NA values in time data is wrong
> timezones. You really need to make sure the timezone that is assumed when
> the character data are converted to POSIXt agrees with the data. In most
> cases the easiest way to insure this is to use
>
> Sys.setenv(TZ="US/Pacific")
>
> or whatever timezone from
>
> OlsonNames()
>
> corresponds with your data. Execute this setenv function before the
> strptime or as.POSIXct() function call.
>
> You can use
>
> MyData[ is.na<http://is.na>(MyData$datetime), ]
>
> to see which records are failing to convert time.
>
> [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>
> On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >Hi Diego,
> >I think the error is due to NA values in your data file. If I extend
> >your example and run it, I get no errors:
> >
> >MyData<-read.table(text="103001930 103001580 103001530
> >1998-10-01 00:00:00 0.6 0 0
> >1998-10-01 01:00:00 0.2 0.2 0.2
> >1998-10-01 02:00:00 0.6 0.2 0.4
> >1998-10-01 03:00:00 0 0 0.6
> >1998-10-01 04:00:00 0 0 0
> >1998-10-01 05:00:00 0 0 0
> >1998-10-01 06:00:00 0 0 0
> >1998-10-01 07:00:00 0.2 0 0
> >1998-10-01 08:00:00 0.6 0 0
> >1998-10-01 09:00:00 0.2 0.2 0.2
> >1998-10-01 10:00:00 0.6 0.2 0.4
> >1998-10-01 11:00:00 0 0 0.6
> >1998-10-01 12:00:00 0 0 0
> >1998-10-01 13:00:00 0 0 0
> >1998-10-01 14:00:00 0 0 0
> >1998-10-01 15:00:00 0.2 0 0
> >1998-10-01 16:00:00 0.6 0 0
> >1998-10-01 17:00:00 0.2 0.2 0.2
> >1998-10-01 18:00:00 0.6 0.2 0.4
> >1998-10-01 19:00:00 0 0 0.6
> >1998-10-01 20:00:00 0 0 0
> >1998-10-01 21:00:00 0 0 0
> >1998-10-01 22:00:00 0 0 0
> >1998-10-01 23:00:00 0.2 0 0
> >1998-10-02 00:00:00 0.6 0 0
> >1998-10-02 01:00:00 0.2 0.2 0.2
> >1998-10-02 02:00:00 0.6 0.2 0.4
> >1998-10-02 03:00:00 0 0 0.6
> >1998-10-02 04:00:00 0 0 0
> >1998-10-02 05:00:00 0 0 0
> >1998-10-02 06:00:00 0 0 0
> >1998-10-02 07:00:00 0.2 0 0
> >1998-10-02 08:00:00 0.6 0 0
> >1998-10-02 09:00:00 0.2 0.2 0.2
> >1998-10-02 10:00:00 0.6 0.2 0.4
> >1998-10-02 11:00:00 0 0 0.6
> >1998-10-02 12:00:00 0 0 0
> >1998-10-02 13:00:00 0 0 0
> >1998-10-02 14:00:00 0 0 0
> >1998-10-02 15:00:00 0.2 0 0
> >1998-10-02 16:00:00 0.6 0 0
> >1998-10-02 17:00:00 0.2 0.2 0.2
> >1998-10-02 18:00:00 0.6 0.2 0.4
> >1998-10-02 19:00:00 0 0 0.6
> >1998-10-02 20:00:00 0 0 0
> >1998-10-02 21:00:00 0 0 0
> >1998-10-02 22:00:00 0 0 0
> >1998-10-02 23:00:00 0.2 0 0",
> >skip=1,stringsAsFactors=FALSE)
> >names(MyData)<-c("date","time","st1","st2","st3")
> >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > format="%Y-%m-%d %H:%M:%S")
> >MyData$datetime
> >st1_daily<-by(MyData$st1,MyData$date,mean)
> >st2_daily<-by(MyData$st2,MyData$date,mean)
> >st3_daily<-by(MyData$st3,MyData$date,mean)
> >st1_daily
> >st2_daily
> >st3_daily
> >
> >Try adding na.rm=TRUE to the "by" calls:
> >
> >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> >
> >Jim
> >
> >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >> Dear all,
> >>
> >> I have still problem with date.
> >> Could you please tel me how to use POSIXct.
> >> Indeed I have found this command:
> >> timeAverage, but I am not able to convert MyDate to properly date.
> >>
> >> Thank a lot
> >> I hope to no bother you, at least too much
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >wrote:
> >>>
> >>> Dear Jim, Dear all,
> >>>
> >>> thanks a lot.
> >>>
> >>> Unfortunately, I get the following error:
> >>>
> >>>
> >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> >925L,  :
> >>>   arguments must have same length
> >>>
> >>>
> >>> This is particularly strange. indeed, if I apply
> >>>
> >>>
> >>> mean(MyData$str1,na.rm=TRUE)
> >>>
> >>>
> >>> it works
> >>>
> >>>
> >>> Sorry, I have to learn a lot.
> >>> You are really boosting me
> >>>
> >>> Diego
> >>>
> >>>
> >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >>>>
> >>>> Hi Diego,
> >>>> One way you can get daily means is:
> >>>>
> >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> >>>>
> >>>> Jim
> >>>>
> >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> wrote:
> >>>> > Dear all,
> >>>> > I have found the error, my fault. Sorry.
> >>>> > There was an extra come in the headers line.
> >>>> > Thanks again.
> >>>> >
> >>>> > If I can I would like to ask you another questions about the
> >imported
> >>>> > data.
> >>>> > I would like to compute the daily average of the different date.
> >>>> > Basically I
> >>>> > have hourly data, I would like to ave the daily mean of them.
> >>>> >
> >>>> > Is there some special commands?
> >>>> >
> >>>> > Thanks a lot.
> >>>> >
> >>>> >
> >>>> > Diego
> >>>> >
> >>>> >
> >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> > wrote:
> >>>> >>
> >>>> >> Dear all,
> >>>> >> I move to csv file because originally the date where in csv
> >file.
> >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> >>>> >> special
> >>>> >> case of read.table, I prefer start to learn from the simplest
> >one.
> >>>> >> After that, I will try also the *.txt format.
> >>>> >>
> >>>> >> with read.csv, something strange happened:
> >>>> >>
> >>>> >> This us now the file:
> >>>> >>
> >>>> >> date,st1,st2,st3,
> >>>> >> 10/1/1998 0:00,0.6,0,0
> >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> >>>> >> 10/1/1998 3:00,0,0,0.6
> >>>> >> 10/1/1998 4:00,0,0,0
> >>>> >> 10/1/1998 5:00,0,0,0
> >>>> >> 10/1/1998 6:00,0,0,0
> >>>> >> 10/1/1998 7:00,0.2,0,0
> >>>> >> 10/1/1998 8:00,0.6,0.2,0
> >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> >>>> >> 10/1/1998 10:00,0,0.4,0.2
> >>>> >>
> >>>> >> When I apply:
> >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>>> >>
> >>>> >> this is the results:
> >>>> >>
> >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>>> >>
> >>>> >> I do not understand why.
> >>>> >> Something wrong with date?
> >>>> >>
> >>>> >> really really thanks,
> >>>> >> I appreciate a lot all your helps.
> >>>> >>
> >>>> >> Diedro
> >>>> >>
> >>>> >>
> >>>> >> Diego
> >>>> >>
> >>>> >>
> >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>
> >wrote:
> >>>> >>>
> >>>> >>> Or, without removing the first line
> >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>> >>>
> >>>> >>> Another alternative,
> >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>>> >>> since the dates appear to be in the default format.
> >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> >rather
> >>>> >>> than
> >>>> >>> POSIXlt class)
> >>>> >>>
> >>>> >>> -Don
> >>>> >>>
> >>>> >>> --
> >>>> >>> Don MacQueen
> >>>> >>> Lawrence Livermore National Laboratory
> >>>> >>> 7000 East Ave., L-627
> >>>> >>> Livermore, CA 94550
> >>>> >>> 925-423-1062
> >>>> >>> Lab cell 925-724-7509
> >>>> >>>
> >>>> >>>
> >>>> >>>
> >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>>> >>> <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of
> >drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> >>>> >>> wrote:
> >>>> >>>
> >>>> >>>     Hi Diego,
> >>>> >>>     You may have to do some conversion as you have three fields
> >in
> >>>> >>> the
> >>>> >>>     first line using the default space separator and five
> >fields in
> >>>> >>>     subsequent lines. If the first line doesn't contain any
> >important
> >>>> >>> data
> >>>> >>>     you can just delete it or replace it with a meaningful
> >header
> >>>> >>> line
> >>>> >>>     with five fields and save the file under another name.
> >>>> >>>
> >>>> >>>     It looks as thought you have date-time as two fields. If
> >so, you
> >>>> >>> can
> >>>> >>>     just read the first field if you only want the date:
> >>>> >>>
> >>>> >>>     # assume you have removed the first line
> >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>> >>>
> >>>> >>>     If you want the date/time:
> >>>> >>>
> >>>> >>>
> >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>>> >>> %H:%M:%S")
> >>>> >>>
> >>>> >>>     Jim
> >>>> >>>
> >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>>> >>> <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >>>> >>>     > Dear all,
> >>>> >>>     >
> >>>> >>>     > I am dealing with the reading of a *.txt file.
> >>>> >>>     > The txt file the following shape:
> >>>> >>>     >
> >>>> >>>     > 103001930 103001580 103001530
> >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>> >>>     >
> >>>> >>>     > If it is possible I have a coupe of questions, which will
> >sound
> >>>> >>> stupid but
> >>>> >>>     > they are important to me in order to understand ho R deal
> >with
> >>>> >>> file
> >>>> >>> or date.
> >>>> >>>     >
> >>>> >>>     > 1) Do I have to convert it to a *csv file?
> >>>> >>>     > 2) Can a deal with space and not ","
> >>>> >>>     > 3) How can I read date?
> >>>> >>>     >
> >>>> >>>     > thanks a lot to all of you,
> >>>> >>>     > Thanks
> >>>> >>>     >
> >>>> >>>     >
> >>>> >>>     > Diego
> >>>> >>>     >
> >>>> >>>     >         [[alternative HTML version deleted]]
> >>>> >>>     >
> >>>> >>>     > ______________________________________________
> >>>> >>>     > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more,
> >>>> >>> see
> >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     > PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     > and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>     ______________________________________________
> >>>> >>>     R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more, see
> >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>
> >>>> >>
> >>>> >
> >>>
> >>>
> >>
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From d|ego@@ve@@n| @end|ng |rom gm@||@com  Thu Aug  2 09:30:53 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Thu, 2 Aug 2018 09:30:53 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
Message-ID: <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>

Dear all,

I have found and error in the date conversion. Now it looks like:

MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
# change date to real
MyData$date<-as.POSIXct(MyData$date, format="%*m*/%*d*/%Y %H:%M")

After that I apply the PIKAL's suggestions:

aggregate(MyData[,-1], list(day(MyData$date)), mean)

And this is the final results:

 1 -82.43636 -46.12437 -319.2710
2        2 -82.06105 -45.74184 -319.2696
3        3 -82.05527 -45.52650 -319.2416
4        4 -82.03535 -47.59191 -319.2275
5        5 -77.44928 -50.05953 -320.5798
...
31    -86.10234 -47.06247 -340.0968

However, it is not correct.
This because I have not made myself clear about my purpose. As I told you
some days ago, I have a *.csv file with hourly data from 10/21/1998
to 12/31/2016. I would like to compute the daily means. Basically, I would
like to have the mean of the hourly date for each day from 10/21/1998
to 12/31/2016 and not 31 values.

Really really thanks again,
Diego


Diego


On 2 August 2018 at 08:55, Diego Avesani <diego.avesani at gmail.com> wrote:

> Dear
>
> I have check the one of the line that gives me problem. I mean, which give
> NA after R processing. I think that is similar to the others:
>
> 10/12/1998 10:00,0,0,0
> 10/12/1998 11:00,0,0,0
> 10/12/1998 12:00,0,0,0
> 10/12/1998 13:00,0,0,0
> 10/12/1998 14:00,0,0,0
> 10/12/1998 15:00,0,0,0
> 10/12/1998 16:00,0,0,0
> 10/12/1998 17:00,0,0,0
>
> @jim: It seems that you suggestion is focus on reading data from the
> terminal. It is possible to apply it to a *.csv file?
>
> @Pikal: Could it be that there are some date conversion error?
>
> Thanks again,
> Diego
>
>
> Diego
>
>
> On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com> wrote:
>
>>
>> Try this:
>>
>> > library(lubridate)
>> > library(tidyverse)
>> > input <- read.csv(text = "date,str1,str2,str3
>> + 10/1/1998 0:00,0.6,0,0
>> +                   10/1/1998 1:00,0.2,0.2,0.2
>> +                   10/1/1998 2:00,0.6,0.2,0.4
>> +                   10/1/1998 3:00,0,0,0.6
>> +                   10/1/1998 4:00,0,0,0
>> +                   10/1/1998 5:00,0,0,0
>> +                   10/1/1998 6:00,0,0,0
>> +                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
>> > # convert the date and add the "day" so summarize
>> > input <- input %>%
>> +   mutate(date = mdy_hm(date),
>> +          day = floor_date(date, unit = 'day')
>> +   )
>> >
>> > by_day <- input %>%
>> +   group_by(day) %>%
>> +   summarise(m_s1 = mean(str1),
>> +             m_s2 = mean(str2),
>> +             m_s3 = mean(str3)
>> +   )
>> >
>> > by_day
>> # A tibble: 1 x 4
>>   day                  m_s1   m_s2  m_s3
>>   <dttm>              <dbl>  <dbl> <dbl>
>> 1 1998-10-01 00:00:00 0.200 0.0500 0.150
>>
>> Jim Holtman
>> *Data Munger Guru*
>>
>>
>> *What is the problem that you are trying to solve?Tell me what you want
>> to do, not how you want to do it.*
>>
>>
>> On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
>> wrote:
>>
>>> Dear all,
>>> I am sorry, I did a lot of confusion. I am sorry, I have to relax and
>>> stat
>>> all again in order to understand.
>>> If I could I would like to start again, without mixing strategy and
>>> waiting
>>> for your advice.
>>>
>>> I am really appreciate you help, really really.
>>> Here my new file, a *.csv file (buy the way, it is possible to attach it
>>> in
>>> the mailing list?)
>>>
>>> date,str1,str2,str3
>>> 10/1/1998 0:00,0.6,0,0
>>> 10/1/1998 1:00,0.2,0.2,0.2
>>> 10/1/1998 2:00,0.6,0.2,0.4
>>> 10/1/1998 3:00,0,0,0.6
>>> 10/1/1998 4:00,0,0,0
>>> 10/1/1998 5:00,0,0,0
>>> 10/1/1998 6:00,0,0,0
>>> 10/1/1998 7:00,0.2,0,0
>>>
>>>
>>> I read it as:
>>> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>>
>>> at this point I would like to have the daily mean.
>>> What would you suggest?
>>>
>>> Really Really thanks,
>>> You are my lifesaver
>>>
>>> Thanks
>>>
>>>
>>>
>>> Diego
>>>
>>>
>>> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>> > ... and the most common source of NA values in time data is wrong
>>> > timezones. You really need to make sure the timezone that is assumed
>>> when
>>> > the character data are converted to POSIXt agrees with the data. In
>>> most
>>> > cases the easiest way to insure this is to use
>>> >
>>> > Sys.setenv(TZ="US/Pacific")
>>> >
>>> > or whatever timezone from
>>> >
>>> > OlsonNames()
>>> >
>>> > corresponds with your data. Execute this setenv function before the
>>> > strptime or as.POSIXct() function call.
>>> >
>>> > You can use
>>> >
>>> > MyData[ is.na(MyData$datetime), ]
>>> >
>>> > to see which records are failing to convert time.
>>> >
>>> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>>> >
>>> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>> > >Hi Diego,
>>> > >I think the error is due to NA values in your data file. If I extend
>>> > >your example and run it, I get no errors:
>>> > >
>>> > >MyData<-read.table(text="103001930 103001580 103001530
>>> > >1998-10-01 00:00:00 0.6 0 0
>>> > >1998-10-01 01:00:00 0.2 0.2 0.2
>>> > >1998-10-01 02:00:00 0.6 0.2 0.4
>>> > >1998-10-01 03:00:00 0 0 0.6
>>> > >1998-10-01 04:00:00 0 0 0
>>> > >1998-10-01 05:00:00 0 0 0
>>> > >1998-10-01 06:00:00 0 0 0
>>> > >1998-10-01 07:00:00 0.2 0 0
>>> > >1998-10-01 08:00:00 0.6 0 0
>>> > >1998-10-01 09:00:00 0.2 0.2 0.2
>>> > >1998-10-01 10:00:00 0.6 0.2 0.4
>>> > >1998-10-01 11:00:00 0 0 0.6
>>> > >1998-10-01 12:00:00 0 0 0
>>> > >1998-10-01 13:00:00 0 0 0
>>> > >1998-10-01 14:00:00 0 0 0
>>> > >1998-10-01 15:00:00 0.2 0 0
>>> > >1998-10-01 16:00:00 0.6 0 0
>>> > >1998-10-01 17:00:00 0.2 0.2 0.2
>>> > >1998-10-01 18:00:00 0.6 0.2 0.4
>>> > >1998-10-01 19:00:00 0 0 0.6
>>> > >1998-10-01 20:00:00 0 0 0
>>> > >1998-10-01 21:00:00 0 0 0
>>> > >1998-10-01 22:00:00 0 0 0
>>> > >1998-10-01 23:00:00 0.2 0 0
>>> > >1998-10-02 00:00:00 0.6 0 0
>>> > >1998-10-02 01:00:00 0.2 0.2 0.2
>>> > >1998-10-02 02:00:00 0.6 0.2 0.4
>>> > >1998-10-02 03:00:00 0 0 0.6
>>> > >1998-10-02 04:00:00 0 0 0
>>> > >1998-10-02 05:00:00 0 0 0
>>> > >1998-10-02 06:00:00 0 0 0
>>> > >1998-10-02 07:00:00 0.2 0 0
>>> > >1998-10-02 08:00:00 0.6 0 0
>>> > >1998-10-02 09:00:00 0.2 0.2 0.2
>>> > >1998-10-02 10:00:00 0.6 0.2 0.4
>>> > >1998-10-02 11:00:00 0 0 0.6
>>> > >1998-10-02 12:00:00 0 0 0
>>> > >1998-10-02 13:00:00 0 0 0
>>> > >1998-10-02 14:00:00 0 0 0
>>> > >1998-10-02 15:00:00 0.2 0 0
>>> > >1998-10-02 16:00:00 0.6 0 0
>>> > >1998-10-02 17:00:00 0.2 0.2 0.2
>>> > >1998-10-02 18:00:00 0.6 0.2 0.4
>>> > >1998-10-02 19:00:00 0 0 0.6
>>> > >1998-10-02 20:00:00 0 0 0
>>> > >1998-10-02 21:00:00 0 0 0
>>> > >1998-10-02 22:00:00 0 0 0
>>> > >1998-10-02 23:00:00 0.2 0 0",
>>> > >skip=1,stringsAsFactors=FALSE)
>>> > >names(MyData)<-c("date","time","st1","st2","st3")
>>> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
>>> > > format="%Y-%m-%d %H:%M:%S")
>>> > >MyData$datetime
>>> > >st1_daily<-by(MyData$st1,MyData$date,mean)
>>> > >st2_daily<-by(MyData$st2,MyData$date,mean)
>>> > >st3_daily<-by(MyData$st3,MyData$date,mean)
>>> > >st1_daily
>>> > >st2_daily
>>> > >st3_daily
>>> > >
>>> > >Try adding na.rm=TRUE to the "by" calls:
>>> > >
>>> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
>>> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
>>> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
>>> > >
>>> > >Jim
>>> > >
>>> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
>>> > ><diego.avesani at gmail.com> wrote:
>>> > >> Dear all,
>>> > >>
>>> > >> I have still problem with date.
>>> > >> Could you please tel me how to use POSIXct.
>>> > >> Indeed I have found this command:
>>> > >> timeAverage, but I am not able to convert MyDate to properly date.
>>> > >>
>>> > >> Thank a lot
>>> > >> I hope to no bother you, at least too much
>>> > >>
>>> > >>
>>> > >> Diego
>>> > >>
>>> > >>
>>> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
>>> > >wrote:
>>> > >>>
>>> > >>> Dear Jim, Dear all,
>>> > >>>
>>> > >>> thanks a lot.
>>> > >>>
>>> > >>> Unfortunately, I get the following error:
>>> > >>>
>>> > >>>
>>> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
>>> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
>>> > >925L,  :
>>> > >>>   arguments must have same length
>>> > >>>
>>> > >>>
>>> > >>> This is particularly strange. indeed, if I apply
>>> > >>>
>>> > >>>
>>> > >>> mean(MyData$str1,na.rm=TRUE)
>>> > >>>
>>> > >>>
>>> > >>> it works
>>> > >>>
>>> > >>>
>>> > >>> Sorry, I have to learn a lot.
>>> > >>> You are really boosting me
>>> > >>>
>>> > >>> Diego
>>> > >>>
>>> > >>>
>>> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> > >>>>
>>> > >>>> Hi Diego,
>>> > >>>> One way you can get daily means is:
>>> > >>>>
>>> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
>>> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
>>> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
>>> > >>>>
>>> > >>>> Jim
>>> > >>>>
>>> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
>>> > ><diego.avesani at gmail.com>
>>> > >>>> wrote:
>>> > >>>> > Dear all,
>>> > >>>> > I have found the error, my fault. Sorry.
>>> > >>>> > There was an extra come in the headers line.
>>> > >>>> > Thanks again.
>>> > >>>> >
>>> > >>>> > If I can I would like to ask you another questions about the
>>> > >imported
>>> > >>>> > data.
>>> > >>>> > I would like to compute the daily average of the different date.
>>> > >>>> > Basically I
>>> > >>>> > have hourly data, I would like to ave the daily mean of them.
>>> > >>>> >
>>> > >>>> > Is there some special commands?
>>> > >>>> >
>>> > >>>> > Thanks a lot.
>>> > >>>> >
>>> > >>>> >
>>> > >>>> > Diego
>>> > >>>> >
>>> > >>>> >
>>> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <
>>> diego.avesani at gmail.com>
>>> > >>>> > wrote:
>>> > >>>> >>
>>> > >>>> >> Dear all,
>>> > >>>> >> I move to csv file because originally the date where in csv
>>> > >file.
>>> > >>>> >> In addition, due to the fact that, as you told me, read.csv is
>>> a
>>> > >>>> >> special
>>> > >>>> >> case of read.table, I prefer start to learn from the simplest
>>> > >one.
>>> > >>>> >> After that, I will try also the *.txt format.
>>> > >>>> >>
>>> > >>>> >> with read.csv, something strange happened:
>>> > >>>> >>
>>> > >>>> >> This us now the file:
>>> > >>>> >>
>>> > >>>> >> date,st1,st2,st3,
>>> > >>>> >> 10/1/1998 0:00,0.6,0,0
>>> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
>>> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
>>> > >>>> >> 10/1/1998 3:00,0,0,0.6
>>> > >>>> >> 10/1/1998 4:00,0,0,0
>>> > >>>> >> 10/1/1998 5:00,0,0,0
>>> > >>>> >> 10/1/1998 6:00,0,0,0
>>> > >>>> >> 10/1/1998 7:00,0.2,0,0
>>> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
>>> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
>>> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
>>> > >>>> >>
>>> > >>>> >> When I apply:
>>> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>> > >>>> >>
>>> > >>>> >> this is the results:
>>> > >>>> >>
>>> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>>> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>>> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>>> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>>> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>>> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>>> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>>> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>>> > >>>> >>
>>> > >>>> >> I do not understand why.
>>> > >>>> >> Something wrong with date?
>>> > >>>> >>
>>> > >>>> >> really really thanks,
>>> > >>>> >> I appreciate a lot all your helps.
>>> > >>>> >>
>>> > >>>> >> Diedro
>>> > >>>> >>
>>> > >>>> >>
>>> > >>>> >> Diego
>>> > >>>> >>
>>> > >>>> >>
>>> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
>>> > >wrote:
>>> > >>>> >>>
>>> > >>>> >>> Or, without removing the first line
>>> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE,
>>> skip=1)
>>> > >>>> >>>
>>> > >>>> >>> Another alternative,
>>> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>>> > >>>> >>> since the dates appear to be in the default format.
>>> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
>>> > >rather
>>> > >>>> >>> than
>>> > >>>> >>> POSIXlt class)
>>> > >>>> >>>
>>> > >>>> >>> -Don
>>> > >>>> >>>
>>> > >>>> >>> --
>>> > >>>> >>> Don MacQueen
>>> > >>>> >>> Lawrence Livermore National Laboratory
>>> > >>>> >>> 7000 East Ave., L-627
>>> > >>>> >>> Livermore, CA 94550
>>> > >>>> >>> 925-423-1062
>>> > >>>> >>> Lab cell 925-724-7509
>>> > >>>> >>>
>>> > >>>> >>>
>>> > >>>> >>>
>>> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>>> > >>>> >>> <r-help-bounces at r-project.org on behalf of
>>> > >drjimlemon at gmail.com>
>>> > >>>> >>> wrote:
>>> > >>>> >>>
>>> > >>>> >>>     Hi Diego,
>>> > >>>> >>>     You may have to do some conversion as you have three
>>> fields
>>> > >in
>>> > >>>> >>> the
>>> > >>>> >>>     first line using the default space separator and five
>>> > >fields in
>>> > >>>> >>>     subsequent lines. If the first line doesn't contain any
>>> > >important
>>> > >>>> >>> data
>>> > >>>> >>>     you can just delete it or replace it with a meaningful
>>> > >header
>>> > >>>> >>> line
>>> > >>>> >>>     with five fields and save the file under another name.
>>> > >>>> >>>
>>> > >>>> >>>     It looks as thought you have date-time as two fields. If
>>> > >so, you
>>> > >>>> >>> can
>>> > >>>> >>>     just read the first field if you only want the date:
>>> > >>>> >>>
>>> > >>>> >>>     # assume you have removed the first line
>>> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>> > >>>> >>>
>>> > >>>> >>>     If you want the date/time:
>>> > >>>> >>>
>>> > >>>> >>>
>>> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>>> > >>>> >>> %H:%M:%S")
>>> > >>>> >>>
>>> > >>>> >>>     Jim
>>> > >>>> >>>
>>> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>>> > >>>> >>> <diego.avesani at gmail.com> wrote:
>>> > >>>> >>>     > Dear all,
>>> > >>>> >>>     >
>>> > >>>> >>>     > I am dealing with the reading of a *.txt file.
>>> > >>>> >>>     > The txt file the following shape:
>>> > >>>> >>>     >
>>> > >>>> >>>     > 103001930 103001580 103001530
>>> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>>> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>>> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
>>> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
>>> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
>>> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>>> > >>>> >>>     >
>>> > >>>> >>>     > If it is possible I have a coupe of questions, which
>>> will
>>> > >sound
>>> > >>>> >>> stupid but
>>> > >>>> >>>     > they are important to me in order to understand ho R
>>> deal
>>> > >with
>>> > >>>> >>> file
>>> > >>>> >>> or date.
>>> > >>>> >>>     >
>>> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
>>> > >>>> >>>     > 2) Can a deal with space and not ","
>>> > >>>> >>>     > 3) How can I read date?
>>> > >>>> >>>     >
>>> > >>>> >>>     > thanks a lot to all of you,
>>> > >>>> >>>     > Thanks
>>> > >>>> >>>     >
>>> > >>>> >>>     >
>>> > >>>> >>>     > Diego
>>> > >>>> >>>     >
>>> > >>>> >>>     >         [[alternative HTML version deleted]]
>>> > >>>> >>>     >
>>> > >>>> >>>     > ______________________________________________
>>> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>> > >more,
>>> > >>>> >>> see
>>> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>>> >>>     > PLEASE do read the posting guide
>>> > >>>> >>> http://www.R-project.org/posting-guide.html
>>> > >>>> >>>     > and provide commented, minimal, self-contained,
>>> > >reproducible
>>> > >>>> >>> code.
>>> > >>>> >>>
>>> > >>>> >>>     ______________________________________________
>>> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>> > >more, see
>>> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>>> >>>     PLEASE do read the posting guide
>>> > >>>> >>> http://www.R-project.org/posting-guide.html
>>> > >>>> >>>     and provide commented, minimal, self-contained,
>>> > >reproducible
>>> > >>>> >>> code.
>>> > >>>> >>>
>>> > >>>> >>>
>>> > >>>> >>
>>> > >>>> >
>>> > >>>
>>> > >>>
>>> > >>
>>> > >
>>> > >______________________________________________
>>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >PLEASE do read the posting guide
>>> > >http://www.R-project.org/posting-guide.html
>>> > >and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > --
>>> > Sent from my phone. Please excuse my brevity.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Aug  2 09:56:54 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Aug 2018 07:56:54 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
 <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>
Message-ID: <7cc52fbb86b84fe3bd9234906559d145@SRVEXCHCM1302.precheza.cz>

Well,

you followed my advice only partly. Did you get rid of your silly -999 values before averaging? Probably not.
Did you tried aggregating by slightly longer construction
aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
which keeps difference in month and year? Probably not.

We do not have your data, we do not know what exactly you want to do so it is really difficult to give you a help.

If I calculate correctly there are 24 hour in one day and you have data for 18 years which gives me approximately 158000 distinct values.

I can get either 18 values (averaging years) or aproximately 6600 values (averaging days).

So my advice is:

Read your data to R
Change date column to POSIX but store it in different column
Change NA values from -999 to real NA values
Check dimension of your data ?dim
Check structure of your data ?str
Check if all dates are changed to POSIX correctly, are some of them NA?
Aggregate your values (not by lubridate function day) and store them in another object

Cheers
Petr


From: Diego Avesani <diego.avesani at gmail.com>
Sent: Thursday, August 2, 2018 9:31 AM
To: jim holtman <jholtman at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] read txt file - date - no space

Dear all,

I have found and error in the date conversion. Now it looks like:

MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
# change date to real
MyData$date<-as.POSIXct(MyData$date, format="%m/%d/%Y %H:%M")

After that I apply the PIKAL's suggestions:

aggregate(MyData[,-1], list(day(MyData$date)), mean)

And this is the final results:

 1 -82.43636 -46.12437 -319.2710
2        2 -82.06105 -45.74184 -319.2696
3        3 -82.05527 -45.52650 -319.2416
4        4 -82.03535 -47.59191 -319.2275
5        5 -77.44928 -50.05953 -320.5798
...
31    -86.10234 -47.06247 -340.0968

However, it is not correct.
This because I have not made myself clear about my purpose. As I told you some days ago, I have a *.csv file with hourly data from 10/21/1998 to 12/31/2016. I would like to compute the daily means. Basically, I would like to have the mean of the hourly date for each day from 10/21/1998 to 12/31/2016 and not 31 values.

Really really thanks again,
Diego


Diego

On 2 August 2018 at 08:55, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear

I have check the one of the line that gives me problem. I mean, which give NA after R processing. I think that is similar to the others:

10/12/1998 10:00,0,0,0
10/12/1998 11:00,0,0,0
10/12/1998 12:00,0,0,0
10/12/1998 13:00,0,0,0
10/12/1998 14:00,0,0,0
10/12/1998 15:00,0,0,0
10/12/1998 16:00,0,0,0
10/12/1998 17:00,0,0,0

@jim: It seems that you suggestion is focus on reading data from the terminal. It is possible to apply it to a *.csv file?

@Pikal: Could it be that there are some date conversion error?

Thanks again,
Diego


Diego

On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com<mailto:jholtman at gmail.com>> wrote:

Try this:

> library(lubridate)
> library(tidyverse)
> input <- read.csv(text = "date,str1,str2,str3
+ 10/1/1998 0:00,0.6,0,0
+                   10/1/1998 1:00,0.2,0.2,0.2
+                   10/1/1998 2:00,0.6,0.2,0.4
+                   10/1/1998 3:00,0,0,0.6
+                   10/1/1998 4:00,0,0,0
+                   10/1/1998 5:00,0,0,0
+                   10/1/1998 6:00,0,0,0
+                   10/1/1998 7:00,0.2,0,0", as.is<http://as.is> = TRUE)
> # convert the date and add the "day" so summarize
> input <- input %>%
+   mutate(date = mdy_hm(date),
+          day = floor_date(date, unit = 'day')
+   )
>
> by_day <- input %>%
+   group_by(day) %>%
+   summarise(m_s1 = mean(str1),
+             m_s2 = mean(str2),
+             m_s3 = mean(str3)
+   )
>
> by_day
# A tibble: 1 x 4
  day                  m_s1   m_s2  m_s3
  <dttm>              <dbl>  <dbl> <dbl>
1 1998-10-01 00:00:00 0.200 0.0500 0.150

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear all,
I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
all again in order to understand.
If I could I would like to start again, without mixing strategy and waiting
for your advice.

I am really appreciate you help, really really.
Here my new file, a *.csv file (buy the way, it is possible to attach it in
the mailing list?)

date,str1,str2,str3
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0


I read it as:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

at this point I would like to have the daily mean.
What would you suggest?

Really Really thanks,
You are my lifesaver

Thanks



Diego


On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:

> ... and the most common source of NA values in time data is wrong
> timezones. You really need to make sure the timezone that is assumed when
> the character data are converted to POSIXt agrees with the data. In most
> cases the easiest way to insure this is to use
>
> Sys.setenv(TZ="US/Pacific")
>
> or whatever timezone from
>
> OlsonNames()
>
> corresponds with your data. Execute this setenv function before the
> strptime or as.POSIXct() function call.
>
> You can use
>
> MyData[ is.na<http://is.na>(MyData$datetime), ]
>
> to see which records are failing to convert time.
>
> [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>
> On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >Hi Diego,
> >I think the error is due to NA values in your data file. If I extend
> >your example and run it, I get no errors:
> >
> >MyData<-read.table(text="103001930 103001580 103001530
> >1998-10-01 00:00:00 0.6 0 0
> >1998-10-01 01:00:00 0.2 0.2 0.2
> >1998-10-01 02:00:00 0.6 0.2 0.4
> >1998-10-01 03:00:00 0 0 0.6
> >1998-10-01 04:00:00 0 0 0
> >1998-10-01 05:00:00 0 0 0
> >1998-10-01 06:00:00 0 0 0
> >1998-10-01 07:00:00 0.2 0 0
> >1998-10-01 08:00:00 0.6 0 0
> >1998-10-01 09:00:00 0.2 0.2 0.2
> >1998-10-01 10:00:00 0.6 0.2 0.4
> >1998-10-01 11:00:00 0 0 0.6
> >1998-10-01 12:00:00 0 0 0
> >1998-10-01 13:00:00 0 0 0
> >1998-10-01 14:00:00 0 0 0
> >1998-10-01 15:00:00 0.2 0 0
> >1998-10-01 16:00:00 0.6 0 0
> >1998-10-01 17:00:00 0.2 0.2 0.2
> >1998-10-01 18:00:00 0.6 0.2 0.4
> >1998-10-01 19:00:00 0 0 0.6
> >1998-10-01 20:00:00 0 0 0
> >1998-10-01 21:00:00 0 0 0
> >1998-10-01 22:00:00 0 0 0
> >1998-10-01 23:00:00 0.2 0 0
> >1998-10-02 00:00:00 0.6 0 0
> >1998-10-02 01:00:00 0.2 0.2 0.2
> >1998-10-02 02:00:00 0.6 0.2 0.4
> >1998-10-02 03:00:00 0 0 0.6
> >1998-10-02 04:00:00 0 0 0
> >1998-10-02 05:00:00 0 0 0
> >1998-10-02 06:00:00 0 0 0
> >1998-10-02 07:00:00 0.2 0 0
> >1998-10-02 08:00:00 0.6 0 0
> >1998-10-02 09:00:00 0.2 0.2 0.2
> >1998-10-02 10:00:00 0.6 0.2 0.4
> >1998-10-02 11:00:00 0 0 0.6
> >1998-10-02 12:00:00 0 0 0
> >1998-10-02 13:00:00 0 0 0
> >1998-10-02 14:00:00 0 0 0
> >1998-10-02 15:00:00 0.2 0 0
> >1998-10-02 16:00:00 0.6 0 0
> >1998-10-02 17:00:00 0.2 0.2 0.2
> >1998-10-02 18:00:00 0.6 0.2 0.4
> >1998-10-02 19:00:00 0 0 0.6
> >1998-10-02 20:00:00 0 0 0
> >1998-10-02 21:00:00 0 0 0
> >1998-10-02 22:00:00 0 0 0
> >1998-10-02 23:00:00 0.2 0 0",
> >skip=1,stringsAsFactors=FALSE)
> >names(MyData)<-c("date","time","st1","st2","st3")
> >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > format="%Y-%m-%d %H:%M:%S")
> >MyData$datetime
> >st1_daily<-by(MyData$st1,MyData$date,mean)
> >st2_daily<-by(MyData$st2,MyData$date,mean)
> >st3_daily<-by(MyData$st3,MyData$date,mean)
> >st1_daily
> >st2_daily
> >st3_daily
> >
> >Try adding na.rm=TRUE to the "by" calls:
> >
> >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> >
> >Jim
> >
> >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >> Dear all,
> >>
> >> I have still problem with date.
> >> Could you please tel me how to use POSIXct.
> >> Indeed I have found this command:
> >> timeAverage, but I am not able to convert MyDate to properly date.
> >>
> >> Thank a lot
> >> I hope to no bother you, at least too much
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >wrote:
> >>>
> >>> Dear Jim, Dear all,
> >>>
> >>> thanks a lot.
> >>>
> >>> Unfortunately, I get the following error:
> >>>
> >>>
> >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> >925L,  :
> >>>   arguments must have same length
> >>>
> >>>
> >>> This is particularly strange. indeed, if I apply
> >>>
> >>>
> >>> mean(MyData$str1,na.rm=TRUE)
> >>>
> >>>
> >>> it works
> >>>
> >>>
> >>> Sorry, I have to learn a lot.
> >>> You are really boosting me
> >>>
> >>> Diego
> >>>
> >>>
> >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >>>>
> >>>> Hi Diego,
> >>>> One way you can get daily means is:
> >>>>
> >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> >>>>
> >>>> Jim
> >>>>
> >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> wrote:
> >>>> > Dear all,
> >>>> > I have found the error, my fault. Sorry.
> >>>> > There was an extra come in the headers line.
> >>>> > Thanks again.
> >>>> >
> >>>> > If I can I would like to ask you another questions about the
> >imported
> >>>> > data.
> >>>> > I would like to compute the daily average of the different date.
> >>>> > Basically I
> >>>> > have hourly data, I would like to ave the daily mean of them.
> >>>> >
> >>>> > Is there some special commands?
> >>>> >
> >>>> > Thanks a lot.
> >>>> >
> >>>> >
> >>>> > Diego
> >>>> >
> >>>> >
> >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> > wrote:
> >>>> >>
> >>>> >> Dear all,
> >>>> >> I move to csv file because originally the date where in csv
> >file.
> >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> >>>> >> special
> >>>> >> case of read.table, I prefer start to learn from the simplest
> >one.
> >>>> >> After that, I will try also the *.txt format.
> >>>> >>
> >>>> >> with read.csv, something strange happened:
> >>>> >>
> >>>> >> This us now the file:
> >>>> >>
> >>>> >> date,st1,st2,st3,
> >>>> >> 10/1/1998 0:00,0.6,0,0
> >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> >>>> >> 10/1/1998 3:00,0,0,0.6
> >>>> >> 10/1/1998 4:00,0,0,0
> >>>> >> 10/1/1998 5:00,0,0,0
> >>>> >> 10/1/1998 6:00,0,0,0
> >>>> >> 10/1/1998 7:00,0.2,0,0
> >>>> >> 10/1/1998 8:00,0.6,0.2,0
> >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> >>>> >> 10/1/1998 10:00,0,0.4,0.2
> >>>> >>
> >>>> >> When I apply:
> >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>>> >>
> >>>> >> this is the results:
> >>>> >>
> >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>>> >>
> >>>> >> I do not understand why.
> >>>> >> Something wrong with date?
> >>>> >>
> >>>> >> really really thanks,
> >>>> >> I appreciate a lot all your helps.
> >>>> >>
> >>>> >> Diedro
> >>>> >>
> >>>> >>
> >>>> >> Diego
> >>>> >>
> >>>> >>
> >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>
> >wrote:
> >>>> >>>
> >>>> >>> Or, without removing the first line
> >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>> >>>
> >>>> >>> Another alternative,
> >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>>> >>> since the dates appear to be in the default format.
> >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> >rather
> >>>> >>> than
> >>>> >>> POSIXlt class)
> >>>> >>>
> >>>> >>> -Don
> >>>> >>>
> >>>> >>> --
> >>>> >>> Don MacQueen
> >>>> >>> Lawrence Livermore National Laboratory
> >>>> >>> 7000 East Ave., L-627
> >>>> >>> Livermore, CA 94550
> >>>> >>> 925-423-1062
> >>>> >>> Lab cell 925-724-7509
> >>>> >>>
> >>>> >>>
> >>>> >>>
> >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>>> >>> <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of
> >drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> >>>> >>> wrote:
> >>>> >>>
> >>>> >>>     Hi Diego,
> >>>> >>>     You may have to do some conversion as you have three fields
> >in
> >>>> >>> the
> >>>> >>>     first line using the default space separator and five
> >fields in
> >>>> >>>     subsequent lines. If the first line doesn't contain any
> >important
> >>>> >>> data
> >>>> >>>     you can just delete it or replace it with a meaningful
> >header
> >>>> >>> line
> >>>> >>>     with five fields and save the file under another name.
> >>>> >>>
> >>>> >>>     It looks as thought you have date-time as two fields. If
> >so, you
> >>>> >>> can
> >>>> >>>     just read the first field if you only want the date:
> >>>> >>>
> >>>> >>>     # assume you have removed the first line
> >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>> >>>
> >>>> >>>     If you want the date/time:
> >>>> >>>
> >>>> >>>
> >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>>> >>> %H:%M:%S")
> >>>> >>>
> >>>> >>>     Jim
> >>>> >>>
> >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>>> >>> <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >>>> >>>     > Dear all,
> >>>> >>>     >
> >>>> >>>     > I am dealing with the reading of a *.txt file.
> >>>> >>>     > The txt file the following shape:
> >>>> >>>     >
> >>>> >>>     > 103001930 103001580 103001530
> >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>> >>>     >
> >>>> >>>     > If it is possible I have a coupe of questions, which will
> >sound
> >>>> >>> stupid but
> >>>> >>>     > they are important to me in order to understand ho R deal
> >with
> >>>> >>> file
> >>>> >>> or date.
> >>>> >>>     >
> >>>> >>>     > 1) Do I have to convert it to a *csv file?
> >>>> >>>     > 2) Can a deal with space and not ","
> >>>> >>>     > 3) How can I read date?
> >>>> >>>     >
> >>>> >>>     > thanks a lot to all of you,
> >>>> >>>     > Thanks
> >>>> >>>     >
> >>>> >>>     >
> >>>> >>>     > Diego
> >>>> >>>     >
> >>>> >>>     >         [[alternative HTML version deleted]]
> >>>> >>>     >
> >>>> >>>     > ______________________________________________
> >>>> >>>     > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more,
> >>>> >>> see
> >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     > PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     > and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>     ______________________________________________
> >>>> >>>     R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more, see
> >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>
> >>>> >>
> >>>> >
> >>>
> >>>
> >>
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From d|ego@@ve@@n| @end|ng |rom gm@||@com  Thu Aug  2 10:00:27 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Thu, 2 Aug 2018 10:00:27 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <8a286c58191c4dfebcd7e1fb60db9bca@SRVEXCHCM1302.precheza.cz>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
 <8a286c58191c4dfebcd7e1fb60db9bca@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAG8o1y7MTYCZnd8P-S2YDunbZL3M3tSfosSVa18aDwyP+H_PQw@mail.gmail.com>

Dear PIKAL, Dear all,

thanks again a lot.
I have finally understood what "in line" means.
I would definitely read some "R-intro" and in this moment I am reading a
R-tutorial.
I would not post formatted messages.

I would ask if it is possible to have some final suggestions:
- how to have daily mean;
- how to deal with NA;

Indeed, after changing the ate format I get

   Group.1      str1      str2      str3
1        1 -82.43636 -46.12437 -319.2710
2        2 -82.06105 -45.74184 -319.2696
3        3 -82.05527 -45.52650 -319.2416
4        4 -82.03535 -47.59191 -319.2275
...
31      31 -86.10234 -47.06247 -340.0968

As I said in the previously this is not correct.
This because I have not made myself clear about my purpose. As I told you
some days ago, I have a *.csv file with hourly data from 10/21/1998 to
12/31/2016.
I would like to compute the daily means.
Basically, I would like to have the mean of the hourly date for each day
from 10/21/1998 to 12/31/2016 and not 31 values.

I really really thank, especially for you patience.
I am leaning a lot,
Again thanks

Diego


On 2 August 2018 at 09:32, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> see in line (and please do not post HTML formated messages, it could be
> scrammbled)
>
>
>
> *From:* Diego Avesani <diego.avesani at gmail.com>
> *Sent:* Thursday, August 2, 2018 8:56 AM
> *To:* jim holtman <jholtman at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz
> >
> *Cc:* R mailing list <r-help at r-project.org>
> *Subject:* Re: [R] read txt file - date - no space
>
>
>
> Dear
>
>
>
> I have check the one of the line that gives me problem. I mean, which give
> NA after R processing. I think that is similar to the others:
>
>
>
> You should stop **thinking** and instead do real inspection of ?offending?
> values.
>
>
>
> 10/12/1998 10:00,0,0,0
>
> 10/12/1998 11:00,0,0,0
>
> 10/12/1998 12:00,0,0,0
>
> 10/12/1998 13:00,0,0,0
>
> 10/12/1998 14:00,0,0,0
>
> 10/12/1998 15:00,0,0,0
>
> 10/12/1998 16:00,0,0,0
>
> 10/12/1998 17:00,0,0,0
>
>
>
> These lines do not pose any problem with formating.
>
>
>
> >  test<-read.table("clipboard", sep=",")
>
> > str(test)
>
> 'data.frame':   8 obs. of  4 variables:
>
> $ V1: Factor w/ 8 levels "10/12/1998 10:00",..: 1 2 3 4 5 6 7 8
>
> $ V2: int  0 0 0 0 0 0 0 0
>
> $ V3: int  0 0 0 0 0 0 0 0
>
> $ V4: int  0 0 0 0 0 0 0 0
>
> > as.POSIXct(test$V1, format="%d/%m/%Y %H:%M")
>
> [1] "1998-12-10 10:00:00 CET" "1998-12-10 11:00:00 CET"
>
> [3] "1998-12-10 12:00:00 CET" "1998-12-10 13:00:00 CET"
>
> [5] "1998-12-10 14:00:00 CET" "1998-12-10 15:00:00 CET"
>
> [7] "1998-12-10 16:00:00 CET" "1998-12-10 17:00:00 CET"
>
>
>
>
>
> @jim: It seems that you suggestion is focus on reading data from the
> terminal. It is possible to apply it to a *.csv file?
>
>
>
> @Pikal: Could it be that there are some date conversion error?
>
>
>
> Well, your str(MyData) result suggest, that conversion from character to
> POSIX was done correctly (at least partly).
>
>
>
> However NAs in date column you posted in second mail suggest, that some
> values in the input are probably formated differently and they are changed
> to NA during POSIX conversion.
>
>
>
> You could check which values are problematic if instead directly changing
> date column to POSIX you put a new column to you data with converted POSIX
> values
>
>
>
> So read your data from csv file and change date to POSIX but store it in
> different column of data frame.
>
>
>
> MyData$date2 <- as.POSIXct(MyData$date, format="%d/%m/%Y %H:%M")
>
>
>
> and check which values in your original file are formated differently.
>
>
>
> something like
>
> MyData$date[is.na(MyData$date2)]
>
>
>
> However your (very basic) questions suggest, that you have only minor
> understanding what are R objects, how to check, inspect and manipulate
> them. You could do a big favour to yourself going through basic
> documentation as I suggested before.
>
>
>
> Cheers
>
> Petr
>
>
>
> Thanks again,
>
> Diego
>
>
>
>
> Diego
>
>
>
> On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com> wrote:
>
>
> Try this:
>
>
>
> > library(lubridate)
>
> > library(tidyverse)
>
> > input <- read.csv(text = "date,str1,str2,str3
>
> + 10/1/1998 0:00,0.6,0,0
>
> +                   10/1/1998 1:00,0.2,0.2,0.2
>
> +                   10/1/1998 2:00,0.6,0.2,0.4
>
> +                   10/1/1998 3:00,0,0,0.6
>
> +                   10/1/1998 4:00,0,0,0
>
> +                   10/1/1998 5:00,0,0,0
>
> +                   10/1/1998 6:00,0,0,0
>
> +                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
>
> > # convert the date and add the "day" so summarize
>
> > input <- input %>%
>
> +   mutate(date = mdy_hm(date),
>
> +          day = floor_date(date, unit = 'day')
>
> +   )
>
> >
>
> > by_day <- input %>%
>
> +   group_by(day) %>%
>
> +   summarise(m_s1 = mean(str1),
>
> +             m_s2 = mean(str2),
>
> +             m_s3 = mean(str3)
>
> +   )
>
> >
>
> > by_day
>
> # A tibble: 1 x 4
>
>   day                  m_s1   m_s2  m_s3
>
>   <dttm>              <dbl>  <dbl> <dbl>
>
> 1 1998-10-01 00:00:00 0.200 0.0500 0.150
>
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve? Tell me what you want
> to do, not how you want to do it.*
>
>
>
>
>
> On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
> wrote:
>
> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
> all again in order to understand.
> If I could I would like to start again, without mixing strategy and waiting
> for your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in
> the mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed when
> > the character data are converted to POSIXt agrees with the data. In most
> > cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> > >>>> >> special
> > >>>> >> case of read.table, I prefer start to learn from the simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > >drjimlemon at gmail.com>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> *Osobn? ?daje: *Informace o zpracov?n? a ochran? osobn?ch ?daj?
> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: *https://www.precheza.cz/zasady-ochrany-osobnich-udaju/
> <https://www.precheza.cz/zasady-ochrany-osobnich-udaju/>* | Information
> about processing and protection of business partner?s personal data are
> available on website: *https://www.precheza.cz/en/personal-data-protection-principles/
> <https://www.precheza.cz/en/personal-data-protection-principles/>*
>
> *D?v?rnost: *Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: *https://www.precheza.cz/01-dovetek/
> <https://www.precheza.cz/01-dovetek/>* | This email and any documents
> attached to it may be confidential and are subject to the legally binding
> disclaimer: *https://www.precheza.cz/en/01-disclaimer/
> <https://www.precheza.cz/en/01-disclaimer/>*
>
>
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Thu Aug  2 10:22:31 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 2 Aug 2018 11:22:31 +0300
Subject: [R] CODE HELP
In-Reply-To: <CAAr3ZhjhfE8ED+EwZeUOmM6gd8vcoKoZrWdswe-CVE3MXvF8oA@mail.gmail.com>
References: <CAAr3ZhjhfE8ED+EwZeUOmM6gd8vcoKoZrWdswe-CVE3MXvF8oA@mail.gmail.com>
Message-ID: <CAGgJW75YCXaJXoResfpJcOu4EBFxBmfHXR=bAeoToQpbCwrxSw@mail.gmail.com>

Hi Saptorshee,
Two comments:
1. no attachments made it through to the list. You probably need to include
the code directly in your email, and send your email as plain text
(otherwise information gets stripped)
2. for anyone interested in following up on Saptorshee's question, I
searched for the paper "Two Examples ..." and found that it is available
for download from https://arxiv.org/pdf/1806.10423.pdf. (It looks quite
interesting with a lot of discussion regarding various optimization
packages and their current status regarding availability from R.)

Best,
Eric


On Thu, Aug 2, 2018 at 5:01 AM, Saptorshee Kanto Chakraborty <
chkstr at unife.it> wrote:

> Hello,
>
> I am interested to apply an econometric technique of  Latent Variable
> framework on Environmental Kuznets Curve for 164 countries for a span of 25
> years.
>
> The methodology and the code are from Simulation exercise from an
> unpublished paper "Two Examples of Convex-Programming-Based
> High-Dimensional Econometric Estimators" in R. Is it somehow possible to
> apply it to my data.
>
>
> I am attaching the codes
>
> Thanking You
>
> --
> Saptorshee Chakraborty
>
> Personal Website: http://saptorshee.weebly.com/
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m|@ojpm @end|ng |rom gm@||@com  Thu Aug  2 10:30:44 2018
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 2 Aug 2018 16:30:44 +0800
Subject: [R] F-test where the coefficients in the H_0 is nonzero
Message-ID: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>

Hi,

   I try to run the regression
   y = beta_0 + beta_1 x
   and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
   I believe I can run the regression
   (y-x) = beta_0 +beta_1? x
   and do the regular F-test (using lm functio) where the hypothesized
coefficients are all zero.

   Is there any function in R that deal with the case where the
coefficients are nonzero?

John

	[[alternative HTML version deleted]]



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Thu Aug  2 10:53:22 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Thu, 2 Aug 2018 10:53:22 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <4fd59c09ca87481198eb0a6f338db729@SRVEXCHCM1302.precheza.cz>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
 <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>
 <7cc52fbb86b84fe3bd9234906559d145@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y6YtK9uhDxsnEPNsnQ5WPQUsaffpjG9uVKrPWBFUh4BAQ@mail.gmail.com>
 <4fd59c09ca87481198eb0a6f338db729@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAG8o1y7r=t9oRH-gYcfF8RuwKQx9VNkc3vV=AEQB-pCb18Vn1w@mail.gmail.com>

Dear Petr,

I have read the file:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

I have used  POSIXct to convert properly the date
MyData$date2<-as.POSIXct(MyData$date, format="%m/%d/%Y %H:%M")
creating a second field inside MyDate.

I have converted the -999 to NA:
MyData[MyData== -999] <- NA

dim(MyData):
160008      5
And this is clear because I have 160008 days and 5 field:
date2,date,str1,str2,str3

I have chech the structure of my data:
str(MyData)

'data.frame': 160008 obs. of  5 variables:
 $ date : Factor w/ 160008 levels "10/10/1998 0:00",..: 913 914 925 930 931
932 933 934 935 936 ...
 $ str1 : num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
 $ str2 : num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
 $ str3 : num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...
 $ date2: POSIXct, format: "1998-10-01 00:00:00" "1998-10-01 01:00:00"
"1998-10-01 02:00:00" "1998-10-01 03:00:00" ...

Almost everything is clear:
str1,str2,str3 are mumbers,
date2 are date in the format according to POSIXct: Y-m-d h:m:s
date has 160008 Factor, i.e. 160008  factors which are the number of
category.
I do not understand "913 914 925 930" are the possibilitiues in levels?

I have no NA in date2:

which(MyData$date2 == NA)
integer(0)

as well in date.

At this point I have applied:

daily_mean1<-aggregate(MyData$str1, list(format(MyData$date, "%Y-%m-%d")),
mean)

which seems to be correct:
I have

dim(daily_mean1):
6667    2
str(daily_mean1)
'data.frame': 6667 obs. of  2 variables:
 $ Group.1: chr  "1998-10-01" "1998-10-02" "1998-10-03" "1998-10-04" ...
 $ x      : num  0.1667 0.0583 0.0417 0.3417 0.3333 ...

Really Really thanks:
You not only taught me R  but also how to dealwith learning.

Can I ask you anover question about aggregate?

Again thanks

Diego


On 2 August 2018 at 10:10, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> *From:* Diego Avesani <diego.avesani at gmail.com>
> *Sent:* Thursday, August 2, 2018 10:03 AM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Subject:* Re: [R] read txt file - date - no space
>
>
>
> Thanks,
>
> I have just send you a e-mail, before reading this one.
>
> Let's me read your last mail and go carefully through it.
>
>
>
> Thanks again, really really,
>
> I mean it
>
>
>
> P.S.
>
> Do you wand my *.csv file?
>
>
>
> Not necessarily, you should better learn things yourself if you really
> want to use R. Only if after you tested all suggested ways and did not get
> desired result.
>
>
>
> Cheers
>
> Petr
>
>
>
>
> Diego
>
>
>
> On 2 August 2018 at 09:56, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Well,
>
>
>
> you followed my advice only partly. Did you get rid of your silly -999
> values before averaging? Probably not.
>
> Did you tried aggregating by slightly longer construction
>
> aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
>
> which keeps difference in month and year? Probably not.
>
>
>
> We do not have your data, we do not know what exactly you want to do so it
> is really difficult to give you a help.
>
>
>
> If I calculate correctly there are 24 hour in one day and you have data
> for 18 years which gives me approximately 158000 distinct values.
>
>
>
> I can get either 18 values (averaging years) or aproximately 6600 values
> (averaging days).
>
>
>
> So my advice is:
>
>
>
> Read your data to R
>
> Change date column to POSIX but store it in different column
>
> Change NA values from -999 to real NA values
>
> Check dimension of your data ?dim
>
> Check structure of your data ?str
>
> Check if all dates are changed to POSIX correctly, are some of them NA?
>
> Aggregate your values (not by lubridate function day) and store them in
> another object
>
>
>
> Cheers
>
> Petr
>
>
>
>
>
> *From:* Diego Avesani <diego.avesani at gmail.com>
> *Sent:* Thursday, August 2, 2018 9:31 AM
> *To:* jim holtman <jholtman at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz
> >
> *Cc:* R mailing list <r-help at r-project.org>
> *Subject:* Re: [R] read txt file - date - no space
>
>
>
> Dear all,
>
>
>
> I have found and error in the date conversion. Now it looks like:
>
>
>
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> # change date to real
>
> MyData$date<-as.POSIXct(MyData$date, format="%*m*/%*d*/%Y %H:%M")
>
>
>
> After that I apply the PIKAL's suggestions:
>
>
>
> aggregate(MyData[,-1], list(day(MyData$date)), mean)
>
>
>
> And this is the final results:
>
>
>
>  1 -82.43636 -46.12437 -319.2710
>
> 2        2 -82.06105 -45.74184 -319.2696
>
> 3        3 -82.05527 -45.52650 -319.2416
>
> 4        4 -82.03535 -47.59191 -319.2275
>
> 5        5 -77.44928 -50.05953 -320.5798
>
> ...
>
> 31    -86.10234 -47.06247 -340.0968
>
>
>
> However, it is not correct.
>
> This because I have not made myself clear about my purpose. As I told you
> some days ago, I have a *.csv file with hourly data from 10/21/1998
> to 12/31/2016. I would like to compute the daily means. Basically, I would
> like to have the mean of the hourly date for each day from 10/21/1998
> to 12/31/2016 and not 31 values.
>
>
>
> Really really thanks again,
>
> Diego
>
>
>
>
> Diego
>
>
>
> On 2 August 2018 at 08:55, Diego Avesani <diego.avesani at gmail.com> wrote:
>
> Dear
>
>
>
> I have check the one of the line that gives me problem. I mean, which give
> NA after R processing. I think that is similar to the others:
>
>
>
> 10/12/1998 10:00,0,0,0
>
> 10/12/1998 11:00,0,0,0
>
> 10/12/1998 12:00,0,0,0
>
> 10/12/1998 13:00,0,0,0
>
> 10/12/1998 14:00,0,0,0
>
> 10/12/1998 15:00,0,0,0
>
> 10/12/1998 16:00,0,0,0
>
> 10/12/1998 17:00,0,0,0
>
>
>
> @jim: It seems that you suggestion is focus on reading data from the
> terminal. It is possible to apply it to a *.csv file?
>
>
>
> @Pikal: Could it be that there are some date conversion error?
>
>
>
> Thanks again,
>
> Diego
>
>
>
>
> Diego
>
>
>
> On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com> wrote:
>
>
> Try this:
>
>
>
> > library(lubridate)
>
> > library(tidyverse)
>
> > input <- read.csv(text = "date,str1,str2,str3
>
> + 10/1/1998 0:00,0.6,0,0
>
> +                   10/1/1998 1:00,0.2,0.2,0.2
>
> +                   10/1/1998 2:00,0.6,0.2,0.4
>
> +                   10/1/1998 3:00,0,0,0.6
>
> +                   10/1/1998 4:00,0,0,0
>
> +                   10/1/1998 5:00,0,0,0
>
> +                   10/1/1998 6:00,0,0,0
>
> +                   10/1/1998 7:00,0.2,0,0", as.is = TRUE)
>
> > # convert the date and add the "day" so summarize
>
> > input <- input %>%
>
> +   mutate(date = mdy_hm(date),
>
> +          day = floor_date(date, unit = 'day')
>
> +   )
>
> >
>
> > by_day <- input %>%
>
> +   group_by(day) %>%
>
> +   summarise(m_s1 = mean(str1),
>
> +             m_s2 = mean(str2),
>
> +             m_s3 = mean(str3)
>
> +   )
>
> >
>
> > by_day
>
> # A tibble: 1 x 4
>
>   day                  m_s1   m_s2  m_s3
>
>   <dttm>              <dbl>  <dbl> <dbl>
>
> 1 1998-10-01 00:00:00 0.200 0.0500 0.150
>
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve? Tell me what you want
> to do, not how you want to do it.*
>
>
>
>
>
> On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com>
> wrote:
>
> Dear all,
> I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
> all again in order to understand.
> If I could I would like to start again, without mixing strategy and waiting
> for your advice.
>
> I am really appreciate you help, really really.
> Here my new file, a *.csv file (buy the way, it is possible to attach it in
> the mailing list?)
>
> date,str1,str2,str3
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
>
>
> I read it as:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> at this point I would like to have the daily mean.
> What would you suggest?
>
> Really Really thanks,
> You are my lifesaver
>
> Thanks
>
>
>
> Diego
>
>
> On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > ... and the most common source of NA values in time data is wrong
> > timezones. You really need to make sure the timezone that is assumed when
> > the character data are converted to POSIXt agrees with the data. In most
> > cases the easiest way to insure this is to use
> >
> > Sys.setenv(TZ="US/Pacific")
> >
> > or whatever timezone from
> >
> > OlsonNames()
> >
> > corresponds with your data. Execute this setenv function before the
> > strptime or as.POSIXct() function call.
> >
> > You can use
> >
> > MyData[ is.na(MyData$datetime), ]
> >
> > to see which records are failing to convert time.
> >
> > [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
> >
> > On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >Hi Diego,
> > >I think the error is due to NA values in your data file. If I extend
> > >your example and run it, I get no errors:
> > >
> > >MyData<-read.table(text="103001930 103001580 103001530
> > >1998-10-01 00:00:00 0.6 0 0
> > >1998-10-01 01:00:00 0.2 0.2 0.2
> > >1998-10-01 02:00:00 0.6 0.2 0.4
> > >1998-10-01 03:00:00 0 0 0.6
> > >1998-10-01 04:00:00 0 0 0
> > >1998-10-01 05:00:00 0 0 0
> > >1998-10-01 06:00:00 0 0 0
> > >1998-10-01 07:00:00 0.2 0 0
> > >1998-10-01 08:00:00 0.6 0 0
> > >1998-10-01 09:00:00 0.2 0.2 0.2
> > >1998-10-01 10:00:00 0.6 0.2 0.4
> > >1998-10-01 11:00:00 0 0 0.6
> > >1998-10-01 12:00:00 0 0 0
> > >1998-10-01 13:00:00 0 0 0
> > >1998-10-01 14:00:00 0 0 0
> > >1998-10-01 15:00:00 0.2 0 0
> > >1998-10-01 16:00:00 0.6 0 0
> > >1998-10-01 17:00:00 0.2 0.2 0.2
> > >1998-10-01 18:00:00 0.6 0.2 0.4
> > >1998-10-01 19:00:00 0 0 0.6
> > >1998-10-01 20:00:00 0 0 0
> > >1998-10-01 21:00:00 0 0 0
> > >1998-10-01 22:00:00 0 0 0
> > >1998-10-01 23:00:00 0.2 0 0
> > >1998-10-02 00:00:00 0.6 0 0
> > >1998-10-02 01:00:00 0.2 0.2 0.2
> > >1998-10-02 02:00:00 0.6 0.2 0.4
> > >1998-10-02 03:00:00 0 0 0.6
> > >1998-10-02 04:00:00 0 0 0
> > >1998-10-02 05:00:00 0 0 0
> > >1998-10-02 06:00:00 0 0 0
> > >1998-10-02 07:00:00 0.2 0 0
> > >1998-10-02 08:00:00 0.6 0 0
> > >1998-10-02 09:00:00 0.2 0.2 0.2
> > >1998-10-02 10:00:00 0.6 0.2 0.4
> > >1998-10-02 11:00:00 0 0 0.6
> > >1998-10-02 12:00:00 0 0 0
> > >1998-10-02 13:00:00 0 0 0
> > >1998-10-02 14:00:00 0 0 0
> > >1998-10-02 15:00:00 0.2 0 0
> > >1998-10-02 16:00:00 0.6 0 0
> > >1998-10-02 17:00:00 0.2 0.2 0.2
> > >1998-10-02 18:00:00 0.6 0.2 0.4
> > >1998-10-02 19:00:00 0 0 0.6
> > >1998-10-02 20:00:00 0 0 0
> > >1998-10-02 21:00:00 0 0 0
> > >1998-10-02 22:00:00 0 0 0
> > >1998-10-02 23:00:00 0.2 0 0",
> > >skip=1,stringsAsFactors=FALSE)
> > >names(MyData)<-c("date","time","st1","st2","st3")
> > >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > > format="%Y-%m-%d %H:%M:%S")
> > >MyData$datetime
> > >st1_daily<-by(MyData$st1,MyData$date,mean)
> > >st2_daily<-by(MyData$st2,MyData$date,mean)
> > >st3_daily<-by(MyData$st3,MyData$date,mean)
> > >st1_daily
> > >st2_daily
> > >st3_daily
> > >
> > >Try adding na.rm=TRUE to the "by" calls:
> > >
> > >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> > >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> > >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> > >
> > >Jim
> > >
> > >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> > ><diego.avesani at gmail.com> wrote:
> > >> Dear all,
> > >>
> > >> I have still problem with date.
> > >> Could you please tel me how to use POSIXct.
> > >> Indeed I have found this command:
> > >> timeAverage, but I am not able to convert MyDate to properly date.
> > >>
> > >> Thank a lot
> > >> I hope to no bother you, at least too much
> > >>
> > >>
> > >> Diego
> > >>
> > >>
> > >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com>
> > >wrote:
> > >>>
> > >>> Dear Jim, Dear all,
> > >>>
> > >>> thanks a lot.
> > >>>
> > >>> Unfortunately, I get the following error:
> > >>>
> > >>>
> > >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> > >925L,  :
> > >>>   arguments must have same length
> > >>>
> > >>>
> > >>> This is particularly strange. indeed, if I apply
> > >>>
> > >>>
> > >>> mean(MyData$str1,na.rm=TRUE)
> > >>>
> > >>>
> > >>> it works
> > >>>
> > >>>
> > >>> Sorry, I have to learn a lot.
> > >>> You are really boosting me
> > >>>
> > >>> Diego
> > >>>
> > >>>
> > >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>> Hi Diego,
> > >>>> One way you can get daily means is:
> > >>>>
> > >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> > >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> > >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> > >>>>
> > >>>> Jim
> > >>>>
> > >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> > ><diego.avesani at gmail.com>
> > >>>> wrote:
> > >>>> > Dear all,
> > >>>> > I have found the error, my fault. Sorry.
> > >>>> > There was an extra come in the headers line.
> > >>>> > Thanks again.
> > >>>> >
> > >>>> > If I can I would like to ask you another questions about the
> > >imported
> > >>>> > data.
> > >>>> > I would like to compute the daily average of the different date.
> > >>>> > Basically I
> > >>>> > have hourly data, I would like to ave the daily mean of them.
> > >>>> >
> > >>>> > Is there some special commands?
> > >>>> >
> > >>>> > Thanks a lot.
> > >>>> >
> > >>>> >
> > >>>> > Diego
> > >>>> >
> > >>>> >
> > >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
> > >>>> > wrote:
> > >>>> >>
> > >>>> >> Dear all,
> > >>>> >> I move to csv file because originally the date where in csv
> > >file.
> > >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> > >>>> >> special
> > >>>> >> case of read.table, I prefer start to learn from the simplest
> > >one.
> > >>>> >> After that, I will try also the *.txt format.
> > >>>> >>
> > >>>> >> with read.csv, something strange happened:
> > >>>> >>
> > >>>> >> This us now the file:
> > >>>> >>
> > >>>> >> date,st1,st2,st3,
> > >>>> >> 10/1/1998 0:00,0.6,0,0
> > >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> > >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> > >>>> >> 10/1/1998 3:00,0,0,0.6
> > >>>> >> 10/1/1998 4:00,0,0,0
> > >>>> >> 10/1/1998 5:00,0,0,0
> > >>>> >> 10/1/1998 6:00,0,0,0
> > >>>> >> 10/1/1998 7:00,0.2,0,0
> > >>>> >> 10/1/1998 8:00,0.6,0.2,0
> > >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> > >>>> >> 10/1/1998 10:00,0,0.4,0.2
> > >>>> >>
> > >>>> >> When I apply:
> > >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> > >>>> >>
> > >>>> >> this is the results:
> > >>>> >>
> > >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> > >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> > >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> > >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> > >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> > >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> > >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> > >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> > >>>> >>
> > >>>> >> I do not understand why.
> > >>>> >> Something wrong with date?
> > >>>> >>
> > >>>> >> really really thanks,
> > >>>> >> I appreciate a lot all your helps.
> > >>>> >>
> > >>>> >> Diedro
> > >>>> >>
> > >>>> >>
> > >>>> >> Diego
> > >>>> >>
> > >>>> >>
> > >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov>
> > >wrote:
> > >>>> >>>
> > >>>> >>> Or, without removing the first line
> > >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> > >>>> >>>
> > >>>> >>> Another alternative,
> > >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> > >>>> >>> since the dates appear to be in the default format.
> > >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> > >rather
> > >>>> >>> than
> > >>>> >>> POSIXlt class)
> > >>>> >>>
> > >>>> >>> -Don
> > >>>> >>>
> > >>>> >>> --
> > >>>> >>> Don MacQueen
> > >>>> >>> Lawrence Livermore National Laboratory
> > >>>> >>> 7000 East Ave., L-627
> > >>>> >>> Livermore, CA 94550
> > >>>> >>> 925-423-1062
> > >>>> >>> Lab cell 925-724-7509
> > >>>> >>>
> > >>>> >>>
> > >>>> >>>
> > >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> > >>>> >>> <r-help-bounces at r-project.org on behalf of
> > >drjimlemon at gmail.com>
> > >>>> >>> wrote:
> > >>>> >>>
> > >>>> >>>     Hi Diego,
> > >>>> >>>     You may have to do some conversion as you have three fields
> > >in
> > >>>> >>> the
> > >>>> >>>     first line using the default space separator and five
> > >fields in
> > >>>> >>>     subsequent lines. If the first line doesn't contain any
> > >important
> > >>>> >>> data
> > >>>> >>>     you can just delete it or replace it with a meaningful
> > >header
> > >>>> >>> line
> > >>>> >>>     with five fields and save the file under another name.
> > >>>> >>>
> > >>>> >>>     It looks as thought you have date-time as two fields. If
> > >so, you
> > >>>> >>> can
> > >>>> >>>     just read the first field if you only want the date:
> > >>>> >>>
> > >>>> >>>     # assume you have removed the first line
> > >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> > >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> > >>>> >>>
> > >>>> >>>     If you want the date/time:
> > >>>> >>>
> > >>>> >>>
> > >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> > >>>> >>> %H:%M:%S")
> > >>>> >>>
> > >>>> >>>     Jim
> > >>>> >>>
> > >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> > >>>> >>> <diego.avesani at gmail.com> wrote:
> > >>>> >>>     > Dear all,
> > >>>> >>>     >
> > >>>> >>>     > I am dealing with the reading of a *.txt file.
> > >>>> >>>     > The txt file the following shape:
> > >>>> >>>     >
> > >>>> >>>     > 103001930 103001580 103001530
> > >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> > >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> > >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> > >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> > >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> > >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> > >>>> >>>     >
> > >>>> >>>     > If it is possible I have a coupe of questions, which will
> > >sound
> > >>>> >>> stupid but
> > >>>> >>>     > they are important to me in order to understand ho R deal
> > >with
> > >>>> >>> file
> > >>>> >>> or date.
> > >>>> >>>     >
> > >>>> >>>     > 1) Do I have to convert it to a *csv file?
> > >>>> >>>     > 2) Can a deal with space and not ","
> > >>>> >>>     > 3) How can I read date?
> > >>>> >>>     >
> > >>>> >>>     > thanks a lot to all of you,
> > >>>> >>>     > Thanks
> > >>>> >>>     >
> > >>>> >>>     >
> > >>>> >>>     > Diego
> > >>>> >>>     >
> > >>>> >>>     >         [[alternative HTML version deleted]]
> > >>>> >>>     >
> > >>>> >>>     > ______________________________________________
> > >>>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more,
> > >>>> >>> see
> > >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     > PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     > and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>     ______________________________________________
> > >>>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > >more, see
> > >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> >>>     PLEASE do read the posting guide
> > >>>> >>> http://www.R-project.org/posting-guide.html
> > >>>> >>>     and provide commented, minimal, self-contained,
> > >reproducible
> > >>>> >>> code.
> > >>>> >>>
> > >>>> >>>
> > >>>> >>
> > >>>> >
> > >>>
> > >>>
> > >>
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> *Osobn? ?daje: *Informace o zpracov?n? a ochran? osobn?ch ?daj?
> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: *https://www.precheza.cz/zasady-ochrany-osobnich-udaju/
> <https://www.precheza.cz/zasady-ochrany-osobnich-udaju/>* | Information
> about processing and protection of business partner?s personal data are
> available on website: *https://www.precheza.cz/en/personal-data-protection-principles/
> <https://www.precheza.cz/en/personal-data-protection-principles/>*
>
> *D?v?rnost: *Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: *https://www.precheza.cz/01-dovetek/
> <https://www.precheza.cz/01-dovetek/>* | This email and any documents
> attached to it may be confidential and are subject to the legally binding
> disclaimer: *https://www.precheza.cz/en/01-disclaimer/
> <https://www.precheza.cz/en/01-disclaimer/>*
>
>
>
>
>

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Thu Aug  2 11:06:15 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 2 Aug 2018 11:06:15 +0200
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
Message-ID: <97AED34A-EBD9-47C2-8C39-CF149EC0C3E0@gmail.com>

This should do it:

> x <- rnorm(10)
> y <- x+rnorm(10)
> fit1 <- lm(y~x)
> fit2 <- lm(y~-1 + offset(0 + 1 * x))
> anova(fit2, fit1)
Analysis of Variance Table

Model 1: y ~ -1 + offset(0 + 1 * x)
Model 2: y ~ x
  Res.Df     RSS Df Sum of Sq      F Pr(>F)
1     10 10.6381                           
2      8  7.8096  2    2.8285 1.4487 0.2904


> On 2 Aug 2018, at 10:30 , John <miaojpm at gmail.com> wrote:
> 
> Hi,
> 
>   I try to run the regression
>   y = beta_0 + beta_1 x
>   and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
>   I believe I can run the regression
>   (y-x) = beta_0 +beta_1? x
>   and do the regular F-test (using lm functio) where the hypothesized
> coefficients are all zero.
> 
>   Is there any function in R that deal with the case where the
> coefficients are nonzero?
> 
> John
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Aug  2 11:09:16 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Aug 2018 09:09:16 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y7r=t9oRH-gYcfF8RuwKQx9VNkc3vV=AEQB-pCb18Vn1w@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
 <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>
 <CA+8X3fWxLNvmxtgkeYa62bRJXwP-Qu2HSZLCs=AjQQeOPhpZEw@mail.gmail.com>
 <DA608609-DCD9-41B2-A561-EC419CC9B8ED@dcn.davis.ca.us>
 <CAG8o1y6LmXu42+AvWPmfDxB0nkAi01PJynnwFedwM0zOc-6cVw@mail.gmail.com>
 <CAAxdm-5rNfu-+zE2PNkpudM33-coJBaiCrChWuDePtZfFerAjw@mail.gmail.com>
 <CAG8o1y6KBTib-iNrk-e41oU1VnGKYh2Arbfh79euUXZ-YR8FHQ@mail.gmail.com>
 <CAG8o1y4zrHoVVNP891C0B_5goms8+_1ZL=sis=tsaBU4tx_KYA@mail.gmail.com>
 <7cc52fbb86b84fe3bd9234906559d145@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y6YtK9uhDxsnEPNsnQ5WPQUsaffpjG9uVKrPWBFUh4BAQ@mail.gmail.com>
 <4fd59c09ca87481198eb0a6f338db729@SRVEXCHCM1302.precheza.cz>
 <CAG8o1y7r=t9oRH-gYcfF8RuwKQx9VNkc3vV=AEQB-pCb18Vn1w@mail.gmail.com>
Message-ID: <d9d6dad0c1374038a8c986b80b59fe65@SRVEXCHCM1302.precheza.cz>

Hi

Good that you have finally got desired result.
Regarding aggregate, you could consult help page

?aggregate

It has many good examples how to use it.

and for understanding factors

?factor is your friend and/or pages 16+ from R intro.

Cheers
Petr

From: Diego Avesani <diego.avesani at gmail.com>
Sent: Thursday, August 2, 2018 10:53 AM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] read txt file - date - no space


Dear Petr,

I have read the file:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

I have used  POSIXct to convert properly the date
MyData$date2<-as.POSIXct(MyData$date, format="%m/%d/%Y %H:%M")
creating a second field inside MyDate.

I have converted the -999 to NA:
MyData[MyData== -999] <- NA

dim(MyData):
160008      5
And this is clear because I have 160008 days and 5 field:
date2,date,str1,str2,str3

I have chech the structure of my data:
str(MyData)

'data.frame':   160008 obs. of  5 variables:
 $ date : Factor w/ 160008 levels "10/10/1998 0:00",..: 913 914 925 930 931 932 933 934 935 936 ...
 $ str1 : num  0.6 0.2 0.6 0 0 0 0 0.2 0.6 0.2 ...
 $ str2 : num  0 0.2 0.2 0 0 0 0 0 0.2 0.4 ...
 $ str3 : num  0 0.2 0.4 0.6 0 0 0 0 0 0.4 ...
 $ date2: POSIXct, format: "1998-10-01 00:00:00" "1998-10-01 01:00:00" "1998-10-01 02:00:00" "1998-10-01 03:00:00" ...

Almost everything is clear:
str1,str2,str3 are mumbers,
date2 are date in the format according to POSIXct: Y-m-d h:m:s
date has 160008 Factor, i.e. 160008  factors which are the number of category.
I do not understand "913 914 925 930" are the possibilitiues in levels?

I have no NA in date2:

which(MyData$date2 == NA)
integer(0)

as well in date.

At this point I have applied:

daily_mean1<-aggregate(MyData$str1, list(format(MyData$date, "%Y-%m-%d")), mean)

which seems to be correct:
I have

dim(daily_mean1):
6667    2
str(daily_mean1)
'data.frame':   6667 obs. of  2 variables:
 $ Group.1: chr  "1998-10-01" "1998-10-02" "1998-10-03" "1998-10-04" ...
 $ x      : num  0.1667 0.0583 0.0417 0.3417 0.3333 ...

Really Really thanks:
You not only taught me R  but also how to dealwith learning.

Can I ask you anover question about aggregate?

Again thanks

Diego

On 2 August 2018 at 10:10, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

From: Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
Sent: Thursday, August 2, 2018 10:03 AM
To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Subject: Re: [R] read txt file - date - no space

Thanks,
I have just send you a e-mail, before reading this one.
Let's me read your last mail and go carefully through it.

Thanks again, really really,
I mean it

P.S.
Do you wand my *.csv file?

Not necessarily, you should better learn things yourself if you really want to use R. Only if after you tested all suggested ways and did not get desired result.

Cheers
Petr


Diego

On 2 August 2018 at 09:56, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Well,

you followed my advice only partly. Did you get rid of your silly -999 values before averaging? Probably not.
Did you tried aggregating by slightly longer construction
aggregate(test[,-1], list(format(test$date, "%Y-%m-%d")), mean)
which keeps difference in month and year? Probably not.

We do not have your data, we do not know what exactly you want to do so it is really difficult to give you a help.

If I calculate correctly there are 24 hour in one day and you have data for 18 years which gives me approximately 158000 distinct values.

I can get either 18 values (averaging years) or aproximately 6600 values (averaging days).

So my advice is:

Read your data to R
Change date column to POSIX but store it in different column
Change NA values from -999 to real NA values
Check dimension of your data ?dim
Check structure of your data ?str
Check if all dates are changed to POSIX correctly, are some of them NA?
Aggregate your values (not by lubridate function day) and store them in another object

Cheers
Petr


From: Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
Sent: Thursday, August 2, 2018 9:31 AM
To: jim holtman <jholtman at gmail.com<mailto:jholtman at gmail.com>>; PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Cc: R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] read txt file - date - no space

Dear all,

I have found and error in the date conversion. Now it looks like:

MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
# change date to real
MyData$date<-as.POSIXct(MyData$date, format="%m/%d/%Y %H:%M")

After that I apply the PIKAL's suggestions:

aggregate(MyData[,-1], list(day(MyData$date)), mean)

And this is the final results:

 1 -82.43636 -46.12437 -319.2710
2        2 -82.06105 -45.74184 -319.2696
3        3 -82.05527 -45.52650 -319.2416
4        4 -82.03535 -47.59191 -319.2275
5        5 -77.44928 -50.05953 -320.5798
...
31    -86.10234 -47.06247 -340.0968

However, it is not correct.
This because I have not made myself clear about my purpose. As I told you some days ago, I have a *.csv file with hourly data from 10/21/1998 to 12/31/2016. I would like to compute the daily means. Basically, I would like to have the mean of the hourly date for each day from 10/21/1998 to 12/31/2016 and not 31 values.

Really really thanks again,
Diego


Diego

On 2 August 2018 at 08:55, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear

I have check the one of the line that gives me problem. I mean, which give NA after R processing. I think that is similar to the others:

10/12/1998 10:00,0,0,0
10/12/1998 11:00,0,0,0
10/12/1998 12:00,0,0,0
10/12/1998 13:00,0,0,0
10/12/1998 14:00,0,0,0
10/12/1998 15:00,0,0,0
10/12/1998 16:00,0,0,0
10/12/1998 17:00,0,0,0

@jim: It seems that you suggestion is focus on reading data from the terminal. It is possible to apply it to a *.csv file?

@Pikal: Could it be that there are some date conversion error?

Thanks again,
Diego


Diego

On 1 August 2018 at 17:01, jim holtman <jholtman at gmail.com<mailto:jholtman at gmail.com>> wrote:

Try this:

> library(lubridate)
> library(tidyverse)
> input <- read.csv(text = "date,str1,str2,str3
+ 10/1/1998 0:00,0.6,0,0
+                   10/1/1998 1:00,0.2,0.2,0.2
+                   10/1/1998 2:00,0.6,0.2,0.4
+                   10/1/1998 3:00,0,0,0.6
+                   10/1/1998 4:00,0,0,0
+                   10/1/1998 5:00,0,0,0
+                   10/1/1998 6:00,0,0,0
+                   10/1/1998 7:00,0.2,0,0", as.is<http://as.is> = TRUE)
> # convert the date and add the "day" so summarize
> input <- input %>%
+   mutate(date = mdy_hm(date),
+          day = floor_date(date, unit = 'day')
+   )
>
> by_day <- input %>%
+   group_by(day) %>%
+   summarise(m_s1 = mean(str1),
+             m_s2 = mean(str2),
+             m_s3 = mean(str3)
+   )
>
> by_day
# A tibble: 1 x 4
  day                  m_s1   m_s2  m_s3
  <dttm>              <dbl>  <dbl> <dbl>
1 1998-10-01 00:00:00 0.200 0.0500 0.150

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Jul 31, 2018 at 11:54 PM Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
Dear all,
I am sorry, I did a lot of confusion. I am sorry, I have to relax and stat
all again in order to understand.
If I could I would like to start again, without mixing strategy and waiting
for your advice.

I am really appreciate you help, really really.
Here my new file, a *.csv file (buy the way, it is possible to attach it in
the mailing list?)

date,str1,str2,str3
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0


I read it as:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

at this point I would like to have the daily mean.
What would you suggest?

Really Really thanks,
You are my lifesaver

Thanks



Diego


On 1 August 2018 at 01:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:

> ... and the most common source of NA values in time data is wrong
> timezones. You really need to make sure the timezone that is assumed when
> the character data are converted to POSIXt agrees with the data. In most
> cases the easiest way to insure this is to use
>
> Sys.setenv(TZ="US/Pacific")
>
> or whatever timezone from
>
> OlsonNames()
>
> corresponds with your data. Execute this setenv function before the
> strptime or as.POSIXct() function call.
>
> You can use
>
> MyData[ is.na<http://is.na>(MyData$datetime), ]
>
> to see which records are failing to convert time.
>
> [1] https://github.com/jdnewmil/eci298sp2016/blob/master/QuickHowto1
>
> On July 31, 2018 3:04:05 PM PDT, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >Hi Diego,
> >I think the error is due to NA values in your data file. If I extend
> >your example and run it, I get no errors:
> >
> >MyData<-read.table(text="103001930 103001580 103001530
> >1998-10-01 00:00:00 0.6 0 0
> >1998-10-01 01:00:00 0.2 0.2 0.2
> >1998-10-01 02:00:00 0.6 0.2 0.4
> >1998-10-01 03:00:00 0 0 0.6
> >1998-10-01 04:00:00 0 0 0
> >1998-10-01 05:00:00 0 0 0
> >1998-10-01 06:00:00 0 0 0
> >1998-10-01 07:00:00 0.2 0 0
> >1998-10-01 08:00:00 0.6 0 0
> >1998-10-01 09:00:00 0.2 0.2 0.2
> >1998-10-01 10:00:00 0.6 0.2 0.4
> >1998-10-01 11:00:00 0 0 0.6
> >1998-10-01 12:00:00 0 0 0
> >1998-10-01 13:00:00 0 0 0
> >1998-10-01 14:00:00 0 0 0
> >1998-10-01 15:00:00 0.2 0 0
> >1998-10-01 16:00:00 0.6 0 0
> >1998-10-01 17:00:00 0.2 0.2 0.2
> >1998-10-01 18:00:00 0.6 0.2 0.4
> >1998-10-01 19:00:00 0 0 0.6
> >1998-10-01 20:00:00 0 0 0
> >1998-10-01 21:00:00 0 0 0
> >1998-10-01 22:00:00 0 0 0
> >1998-10-01 23:00:00 0.2 0 0
> >1998-10-02 00:00:00 0.6 0 0
> >1998-10-02 01:00:00 0.2 0.2 0.2
> >1998-10-02 02:00:00 0.6 0.2 0.4
> >1998-10-02 03:00:00 0 0 0.6
> >1998-10-02 04:00:00 0 0 0
> >1998-10-02 05:00:00 0 0 0
> >1998-10-02 06:00:00 0 0 0
> >1998-10-02 07:00:00 0.2 0 0
> >1998-10-02 08:00:00 0.6 0 0
> >1998-10-02 09:00:00 0.2 0.2 0.2
> >1998-10-02 10:00:00 0.6 0.2 0.4
> >1998-10-02 11:00:00 0 0 0.6
> >1998-10-02 12:00:00 0 0 0
> >1998-10-02 13:00:00 0 0 0
> >1998-10-02 14:00:00 0 0 0
> >1998-10-02 15:00:00 0.2 0 0
> >1998-10-02 16:00:00 0.6 0 0
> >1998-10-02 17:00:00 0.2 0.2 0.2
> >1998-10-02 18:00:00 0.6 0.2 0.4
> >1998-10-02 19:00:00 0 0 0.6
> >1998-10-02 20:00:00 0 0 0
> >1998-10-02 21:00:00 0 0 0
> >1998-10-02 22:00:00 0 0 0
> >1998-10-02 23:00:00 0.2 0 0",
> >skip=1,stringsAsFactors=FALSE)
> >names(MyData)<-c("date","time","st1","st2","st3")
> >MyData$datetime<-strptime(paste(MyData$date,MyData$time),
> > format="%Y-%m-%d %H:%M:%S")
> >MyData$datetime
> >st1_daily<-by(MyData$st1,MyData$date,mean)
> >st2_daily<-by(MyData$st2,MyData$date,mean)
> >st3_daily<-by(MyData$st3,MyData$date,mean)
> >st1_daily
> >st2_daily
> >st3_daily
> >
> >Try adding na.rm=TRUE to the "by" calls:
> >
> >st1_daily<-by(MyData$st1,MyData$date,mean,na.rm=TRUE)
> >st2_daily<-by(MyData$st2,MyData$date,mean,na.rm=TRUE)
> >st3_daily<-by(MyData$st3,MyData$date,mean,na.rm=TRUE)
> >
> >Jim
> >
> >On Tue, Jul 31, 2018 at 11:11 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >> Dear all,
> >>
> >> I have still problem with date.
> >> Could you please tel me how to use POSIXct.
> >> Indeed I have found this command:
> >> timeAverage, but I am not able to convert MyDate to properly date.
> >>
> >> Thank a lot
> >> I hope to no bother you, at least too much
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >wrote:
> >>>
> >>> Dear Jim, Dear all,
> >>>
> >>> thanks a lot.
> >>>
> >>> Unfortunately, I get the following error:
> >>>
> >>>
> >>>  st1_daily<-by(MyData$st1,MyData$date,mean)
> >>> Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L,
> >925L,  :
> >>>   arguments must have same length
> >>>
> >>>
> >>> This is particularly strange. indeed, if I apply
> >>>
> >>>
> >>> mean(MyData$str1,na.rm=TRUE)
> >>>
> >>>
> >>> it works
> >>>
> >>>
> >>> Sorry, I have to learn a lot.
> >>> You are really boosting me
> >>>
> >>> Diego
> >>>
> >>>
> >>> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>> wrote:
> >>>>
> >>>> Hi Diego,
> >>>> One way you can get daily means is:
> >>>>
> >>>> st1_daily<-by(MyData$st1,MyData$date,mean)
> >>>> st2_daily<-by(MyData$st2,MyData$date,mean)
> >>>> st3_daily<-by(MyData$st3,MyData$date,mean)
> >>>>
> >>>> Jim
> >>>>
> >>>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani
> ><diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> wrote:
> >>>> > Dear all,
> >>>> > I have found the error, my fault. Sorry.
> >>>> > There was an extra come in the headers line.
> >>>> > Thanks again.
> >>>> >
> >>>> > If I can I would like to ask you another questions about the
> >imported
> >>>> > data.
> >>>> > I would like to compute the daily average of the different date.
> >>>> > Basically I
> >>>> > have hourly data, I would like to ave the daily mean of them.
> >>>> >
> >>>> > Is there some special commands?
> >>>> >
> >>>> > Thanks a lot.
> >>>> >
> >>>> >
> >>>> > Diego
> >>>> >
> >>>> >
> >>>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>>
> >>>> > wrote:
> >>>> >>
> >>>> >> Dear all,
> >>>> >> I move to csv file because originally the date where in csv
> >file.
> >>>> >> In addition, due to the fact that, as you told me, read.csv is a
> >>>> >> special
> >>>> >> case of read.table, I prefer start to learn from the simplest
> >one.
> >>>> >> After that, I will try also the *.txt format.
> >>>> >>
> >>>> >> with read.csv, something strange happened:
> >>>> >>
> >>>> >> This us now the file:
> >>>> >>
> >>>> >> date,st1,st2,st3,
> >>>> >> 10/1/1998 0:00,0.6,0,0
> >>>> >> 10/1/1998 1:00,0.2,0.2,0.2
> >>>> >> 10/1/1998 2:00,0.6,0.2,0.4
> >>>> >> 10/1/1998 3:00,0,0,0.6
> >>>> >> 10/1/1998 4:00,0,0,0
> >>>> >> 10/1/1998 5:00,0,0,0
> >>>> >> 10/1/1998 6:00,0,0,0
> >>>> >> 10/1/1998 7:00,0.2,0,0
> >>>> >> 10/1/1998 8:00,0.6,0.2,0
> >>>> >> 10/1/1998 9:00,0.2,0.4,0.4
> >>>> >> 10/1/1998 10:00,0,0.4,0.2
> >>>> >>
> >>>> >> When I apply:
> >>>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>>> >>
> >>>> >> this is the results:
> >>>> >>
> >>>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >>>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >>>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >>>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >>>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >>>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >>>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >>>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>>> >>
> >>>> >> I do not understand why.
> >>>> >> Something wrong with date?
> >>>> >>
> >>>> >> really really thanks,
> >>>> >> I appreciate a lot all your helps.
> >>>> >>
> >>>> >> Diedro
> >>>> >>
> >>>> >>
> >>>> >> Diego
> >>>> >>
> >>>> >>
> >>>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>
> >wrote:
> >>>> >>>
> >>>> >>> Or, without removing the first line
> >>>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>> >>>
> >>>> >>> Another alternative,
> >>>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>>> >>> since the dates appear to be in the default format.
> >>>> >>> (I generally prefer to work with datetimes in POSIXct class
> >rather
> >>>> >>> than
> >>>> >>> POSIXlt class)
> >>>> >>>
> >>>> >>> -Don
> >>>> >>>
> >>>> >>> --
> >>>> >>> Don MacQueen
> >>>> >>> Lawrence Livermore National Laboratory
> >>>> >>> 7000 East Ave., L-627
> >>>> >>> Livermore, CA 94550
> >>>> >>> 925-423-1062
> >>>> >>> Lab cell 925-724-7509
> >>>> >>>
> >>>> >>>
> >>>> >>>
> >>>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>>> >>> <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of
> >drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
> >>>> >>> wrote:
> >>>> >>>
> >>>> >>>     Hi Diego,
> >>>> >>>     You may have to do some conversion as you have three fields
> >in
> >>>> >>> the
> >>>> >>>     first line using the default space separator and five
> >fields in
> >>>> >>>     subsequent lines. If the first line doesn't contain any
> >important
> >>>> >>> data
> >>>> >>>     you can just delete it or replace it with a meaningful
> >header
> >>>> >>> line
> >>>> >>>     with five fields and save the file under another name.
> >>>> >>>
> >>>> >>>     It looks as thought you have date-time as two fields. If
> >so, you
> >>>> >>> can
> >>>> >>>     just read the first field if you only want the date:
> >>>> >>>
> >>>> >>>     # assume you have removed the first line
> >>>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>> >>>
> >>>> >>>     If you want the date/time:
> >>>> >>>
> >>>> >>>
> >dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>>> >>> %H:%M:%S")
> >>>> >>>
> >>>> >>>     Jim
> >>>> >>>
> >>>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>>> >>> <diego.avesani at gmail.com<mailto:diego.avesani at gmail.com>> wrote:
> >>>> >>>     > Dear all,
> >>>> >>>     >
> >>>> >>>     > I am dealing with the reading of a *.txt file.
> >>>> >>>     > The txt file the following shape:
> >>>> >>>     >
> >>>> >>>     > 103001930 103001580 103001530
> >>>> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>> >>>     >
> >>>> >>>     > If it is possible I have a coupe of questions, which will
> >sound
> >>>> >>> stupid but
> >>>> >>>     > they are important to me in order to understand ho R deal
> >with
> >>>> >>> file
> >>>> >>> or date.
> >>>> >>>     >
> >>>> >>>     > 1) Do I have to convert it to a *csv file?
> >>>> >>>     > 2) Can a deal with space and not ","
> >>>> >>>     > 3) How can I read date?
> >>>> >>>     >
> >>>> >>>     > thanks a lot to all of you,
> >>>> >>>     > Thanks
> >>>> >>>     >
> >>>> >>>     >
> >>>> >>>     > Diego
> >>>> >>>     >
> >>>> >>>     >         [[alternative HTML version deleted]]
> >>>> >>>     >
> >>>> >>>     > ______________________________________________
> >>>> >>>     > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more,
> >>>> >>> see
> >>>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     > PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     > and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>     ______________________________________________
> >>>> >>>     R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
> >more, see
> >>>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>     PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>>     and provide commented, minimal, self-contained,
> >reproducible
> >>>> >>> code.
> >>>> >>>
> >>>> >>>
> >>>> >>
> >>>> >
> >>>
> >>>
> >>
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/




	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Thu Aug  2 11:33:20 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Thu, 2 Aug 2018 09:33:20 +0000
Subject: [R] inconsistency in forecast package....
Message-ID: <SL2P216MB0091CE3772EA1B4B540B6F38C82C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                           I am using R to do my research for Day Trading in INDIA. I have a list of 206 stocks to work with.

I have extracted a parameter of a stock based on the OHLC data of the stock. It includes values both less than and greater than 1 ( It basically is a ratio). I am using forecast package to predict the value of the parameter for the next day.

However, the value of the parameter is greater than 1 for all stocks! Actually, according to statistics, half of the stocks should have value less than 1 and half greater than 1.

Is this because of  a one odd day or is there some techniques of properly handling the forecast package?

very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From Kev|n@F|@ment @end|ng |rom pm|@com  Thu Aug  2 10:45:25 2018
From: Kev|n@F|@ment @end|ng |rom pm|@com (Flament, Kevin)
Date: Thu, 2 Aug 2018 08:45:25 +0000
Subject: [R] Philip Morris International - Windows10 migration assessment
Message-ID: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>

Dear R Project team,

I am representing the System Toxicology department of Philip Morris International in the scope of a Windows 10 migration project.
This project is currently at the end of the assessment phase. We would require an answer to this email by the end of this week.

I would like to ask you some questions related to the following software we are using at PMI :

R for Windows 3.0.2
R for Windows 3.1.2

Are all of those software compatible with Windows 10 Enterprise (version 10.0.16299 build 16299)?
Are all of those software compatible with Windows 10 LTSC (version 14393.2399)?
Are those software compatible with a 32 and/or 64 bit version of Windows 10?
Are those application dependent on MS Office?
Have those applications any pre-requisites? Such as Java, .Net, Oracle.

If the software are not compatible, do you have a new version of this software compatible with the mentioned version of Windows 10?
What would be the cost of such migration (instrument replacement if necessary, licence cost, ...)?

If the software are not compatible and a new version is not yet available, could you give me an estimation for the future release availability?

Best Regards,

Kevin Flament

Data & Systems Specialist
PMI Science and Innovation
Quai Jeanrenaud 3
2000 Neuch?tel

	[[alternative HTML version deleted]]



From S@E|||@on @end|ng |rom LGCGroup@com  Thu Aug  2 13:26:44 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Thu, 2 Aug 2018 11:26:44 +0000
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
Message-ID: <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>

> On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
> wrote:
> > But I have the extra condition that if E is true, then F must be false, and
> > vice versa, 

Question: Does 'vice versa' mean 
a) "if E is False, F must be True"
or
b) "if F is True, E must be False"?
... which are not the same.

b) (and mutual exclusivity in general) does not rule out the condition "E False, F False", which would not be addressed by the 
pass/fail equivalent equivalent of F <- !E




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From S@E|||@on @end|ng |rom LGCGroup@com  Thu Aug  2 13:32:42 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Thu, 2 Aug 2018 11:32:42 +0000
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
Message-ID: <cdf35fd4267b47dbb9b872684d2aa378@GBDCVPEXC04.corp.lgc-group.com>

Suggest you take a look at the R website at www.r-project.org; the most important answers are evident there.

If you 'require' more authoritative answers within a particular timescale, I suggest you engage an R consultant and pay for them. This is a voluntary list.


S Ellison
 

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Flament,
> Kevin
> Sent: 02 August 2018 09:45
> To: r-help at R-project.org
> Subject: [R] Philip Morris International - Windows10 migration assessment
> 
> Dear R Project team,
> 
> I am representing the System Toxicology department of Philip Morris
> International in the scope of a Windows 10 migration project.
> This project is currently at the end of the assessment phase. We would
> require an answer to this email by the end of this week.
> 
> I would like to ask you some questions related to the following software we
> are using at PMI :
> 
> R for Windows 3.0.2
> R for Windows 3.1.2
> 
> Are all of those software compatible with Windows 10 Enterprise (version
> 10.0.16299 build 16299)?
> Are all of those software compatible with Windows 10 LTSC (version
> 14393.2399)?
> Are those software compatible with a 32 and/or 64 bit version of Windows
> 10?
> Are those application dependent on MS Office?
> Have those applications any pre-requisites? Such as Java, .Net, Oracle.
> 
> If the software are not compatible, do you have a new version of this
> software compatible with the mentioned version of Windows 10?
> What would be the cost of such migration (instrument replacement if
> necessary, licence cost, ...)?
> 
> If the software are not compatible and a new version is not yet available,
> could you give me an estimation for the future release availability?
> 
> Best Regards,
> 
> Kevin Flament
> 
> Data & Systems Specialist
> PMI Science and Innovation
> Quai Jeanrenaud 3
> 2000 Neuch?tel
> 
> 	[[alternative HTML version deleted]]



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From chk@tr @end|ng |rom un||e@|t  Thu Aug  2 13:43:28 2018
From: chk@tr @end|ng |rom un||e@|t (Saptorshee Kanto Chakraborty)
Date: Thu, 2 Aug 2018 13:43:28 +0200
Subject: [R] CODE HELP
In-Reply-To: <CAGgJW75YCXaJXoResfpJcOu4EBFxBmfHXR=bAeoToQpbCwrxSw@mail.gmail.com>
References: <CAAr3ZhjhfE8ED+EwZeUOmM6gd8vcoKoZrWdswe-CVE3MXvF8oA@mail.gmail.com>
 <CAGgJW75YCXaJXoResfpJcOu4EBFxBmfHXR=bAeoToQpbCwrxSw@mail.gmail.com>
Message-ID: <CAAr3ZhiF1X-MDX48PeZBZe_0seZ=TYybr5kCHMV859PeWpV1fg@mail.gmail.com>

Hello,

Thank you for replying. I am sorry te codes were not attached, I did attach
them but I think it got blocked due to some filters. I am pasting the link
for the codes:
https://github.com/zhentaoshi/convex_prog_in_econometrics/tree/master/C-Lasso/PLS_static

The authors never replied I have contacted them twice, I think they are
very busy.

Any help will be useful.

On Thu, 2 Aug 2018 at 10:22, Eric Berger <ericjberger at gmail.com> wrote:

> Hi Saptorshee,
> Two comments:
> 1. no attachments made it through to the list. You probably need to
> include the code directly in your email, and send your email as plain text
> (otherwise information gets stripped)
> 2. for anyone interested in following up on Saptorshee's question, I
> searched for the paper "Two Examples ..." and found that it is available
> for download from https://arxiv.org/pdf/1806.10423.pdf. (It looks quite
> interesting with a lot of discussion regarding various optimization
> packages and their current status regarding availability from R.)
>
> Best,
> Eric
>
>
> On Thu, Aug 2, 2018 at 5:01 AM, Saptorshee Kanto Chakraborty <
> chkstr at unife.it> wrote:
>
>> Hello,
>>
>> I am interested to apply an econometric technique of  Latent Variable
>> framework on Environmental Kuznets Curve for 164 countries for a span of
>> 25
>> years.
>>
>> The methodology and the code are from Simulation exercise from an
>> unpublished paper "Two Examples of Convex-Programming-Based
>> High-Dimensional Econometric Estimators" in R. Is it somehow possible to
>> apply it to my data.
>>
>>
>> I am attaching the codes
>>
>> Thanking You
>>
>> --
>> Saptorshee Chakraborty
>>
>> Personal Website: http://saptorshee.weebly.com/
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

-- 
Saptorshee Chakraborty

Personal Website: http://saptorshee.weebly.com/

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Thu Aug  2 14:23:33 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Aug 2018 12:23:33 +0000
Subject: [R] how to allign data
Message-ID: <41e5dda4b6a84bda9c0896c4bc6bcf3b@SRVEXCHCM1302.precheza.cz>

Dear all

Before I start to reinvent wheel I would like to ask you if you have some easy solution for aligning data

I have something like this
x<-1:100
set.seed(42)
y1<-c(runif(20)+1, 1.2*x[1:80]+runif(80))
y2<-c(runif(40)+1, 1.2*x[1:60]+runif(60))

plot(x,y1)
points(x,y2, col=2)

with y increase starting at various x.

I would like to allign data so that the increase starts at the same x point, something like

plot(x,y1)
points(x[-(1:20)]-20,y2[-(1:20)], col=2)

I consider using strucchange or segmented packages to find break(s) and "shift" x values according to this break. But maybe somebody already did similar task (aligning several vectors according to some common breakpoint) and could offer better or simpler solution.

Best regards.
Petr
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug  2 16:54:54 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 2 Aug 2018 07:54:54 -0700
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
Message-ID: <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>

R is free and open source. Your queries are inappropriate for this list,
which is about help for programming in R.  Please go here and follow the
relevant links to answer your questions:

https://www.r-project.org/

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 2, 2018 at 1:45 AM, Flament, Kevin <Kevin.Flament at pmi.com>
wrote:

> Dear R Project team,
>
> I am representing the System Toxicology department of Philip Morris
> International in the scope of a Windows 10 migration project.
> This project is currently at the end of the assessment phase. We would
> require an answer to this email by the end of this week.
>
> I would like to ask you some questions related to the following software
> we are using at PMI :
>
> R for Windows 3.0.2
> R for Windows 3.1.2
>
> Are all of those software compatible with Windows 10 Enterprise (version
> 10.0.16299 build 16299)?
> Are all of those software compatible with Windows 10 LTSC (version
> 14393.2399)?
> Are those software compatible with a 32 and/or 64 bit version of Windows
> 10?
> Are those application dependent on MS Office?
> Have those applications any pre-requisites? Such as Java, .Net, Oracle.
>
> If the software are not compatible, do you have a new version of this
> software compatible with the mentioned version of Windows 10?
> What would be the cost of such migration (instrument replacement if
> necessary, licence cost, ...)?
>
> If the software are not compatible and a new version is not yet available,
> could you give me an estimation for the future release availability?
>
> Best Regards,
>
> Kevin Flament
>
> Data & Systems Specialist
> PMI Science and Innovation
> Quai Jeanrenaud 3
> 2000 Neuch?tel
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From rod@@t@||ord @end|ng |rom gm@||@com  Thu Aug  2 17:41:36 2018
From: rod@@t@||ord @end|ng |rom gm@||@com (R Stafford)
Date: Thu, 2 Aug 2018 11:41:36 -0400
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>

Thank you for pointing that out, I realize not only did I use the wrong
language but I did not describe the situation accurately.  I do need to
address the situation where both variables E and F actually pass, that is
the majority case, one or the other can fail, but there can never be a
situation where E and F both fail.  I do not know a specific term for that
situation, but you are correct that mutual exclusivity is wrong.   While I
can generate a list of all possible combinations with the expand.grid
function (which I am not committed to by the way), it would be very helpful
if I could exclude the combinations where E and F both fail.  I am not sure
where to go from here, but the solution does not have to be elegant or even
efficient because I do not need to scale higher than 6 variables.



On Thu, Aug 2, 2018 at 7:26 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
> > wrote:
> > > But I have the extra condition that if E is true, then F must be
> false, and
> > > vice versa,
>
> Question: Does 'vice versa' mean
> a) "if E is False, F must be True"
> or
> b) "if F is True, E must be False"?
> ... which are not the same.
>
> b) (and mutual exclusivity in general) does not rule out the condition "E
> False, F False", which would not be addressed by the
> pass/fail equivalent equivalent of F <- !E
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:13}}



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Aug  2 17:52:57 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 2 Aug 2018 15:52:57 +0000
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
 <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
Message-ID: <34DFD051-2E07-4D0D-9924-1E56FAEB471E@llnl.gov>

From what I can tell, the simplest way is to
   First generate all the combinations
   Then exclude those you don't want.

Here's an example, with only three variables (D, E, and F), that excludes those where E and F both fail

> tmp <- c('p','f')
> X <- expand.grid(D=tmp, E=tmp, F=tmp)
> X <- subset(X, !(E=='f' & F=='f'))
> X
  D E F
1 p p p
2 f p p
3 p f p
4 f f p
5 p p f
6 f p f


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/2/18, 8:41 AM, "R-help on behalf of R Stafford" <r-help-bounces at r-project.org on behalf of rod.stafford at gmail.com> wrote:

    Thank you for pointing that out, I realize not only did I use the wrong
    language but I did not describe the situation accurately.  I do need to
    address the situation where both variables E and F actually pass, that is
    the majority case, one or the other can fail, but there can never be a
    situation where E and F both fail.  I do not know a specific term for that
    situation, but you are correct that mutual exclusivity is wrong.   While I
    can generate a list of all possible combinations with the expand.grid
    function (which I am not committed to by the way), it would be very helpful
    if I could exclude the combinations where E and F both fail.  I am not sure
    where to go from here, but the solution does not have to be elegant or even
    efficient because I do not need to scale higher than 6 variables.
    
    
    
    On Thu, Aug 2, 2018 at 7:26 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
    
    > > On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
    > > wrote:
    > > > But I have the extra condition that if E is true, then F must be
    > false, and
    > > > vice versa,
    >
    > Question: Does 'vice versa' mean
    > a) "if E is False, F must be True"
    > or
    > b) "if F is True, E must be False"?
    > ... which are not the same.
    >
    > b) (and mutual exclusivity in general) does not rule out the condition "E
    > False, F False", which would not be addressed by the
    > pass/fail equivalent equivalent of F <- !E
    >
    >
    >
    >
    > *******************************************************************
    > This email and any attachments are confidential. Any u...{{dropped:13}}
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Aug  2 17:57:24 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 2 Aug 2018 11:57:24 -0400
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
 <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
Message-ID: <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>

Given that clarification, I'd just generate the full set and remove
the ones you aren't interested in, as in:


scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"), F =
c("pass", "fail"))


scenarios <- subset(scenarios, !(E == "fail" & F == "fail))

Sarah

On Thu, Aug 2, 2018 at 11:41 AM, R Stafford <rod.stafford at gmail.com> wrote:
> Thank you for pointing that out, I realize not only did I use the wrong
> language but I did not describe the situation accurately.  I do need to
> address the situation where both variables E and F actually pass, that is
> the majority case, one or the other can fail, but there can never be a
> situation where E and F both fail.  I do not know a specific term for that
> situation, but you are correct that mutual exclusivity is wrong.   While I
> can generate a list of all possible combinations with the expand.grid
> function (which I am not committed to by the way), it would be very helpful
> if I could exclude the combinations where E and F both fail.  I am not sure
> where to go from here, but the solution does not have to be elegant or even
> efficient because I do not need to scale higher than 6 variables.
>
>
>
> On Thu, Aug 2, 2018 at 7:26 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>
>> > On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
>> > wrote:
>> > > But I have the extra condition that if E is true, then F must be
>> false, and
>> > > vice versa,
>>
>> Question: Does 'vice versa' mean
>> a) "if E is False, F must be True"
>> or
>> b) "if F is True, E must be False"?
>> ... which are not the same.
>>
>> b) (and mutual exclusivity in general) does not rule out the condition "E
>> False, F False", which would not be addressed by the
>> pass/fail equivalent equivalent of F <- !E
>>
>>
>>



From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug  2 19:11:03 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 2 Aug 2018 10:11:03 -0700
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
 <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
 <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>
Message-ID: <CAGxFJbQj5BaggSS9LysSb-a58ectvsuc=LJ_C3HRPLTJfdUqpA@mail.gmail.com>

Logic:

!(E == "fail" & F == "fail)   <==>

(E == "pass" | F == "pass")


-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 2, 2018 at 8:57 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Given that clarification, I'd just generate the full set and remove
> the ones you aren't interested in, as in:
>
>
> scenarios <- expand.grid(A = c("pass", "fail"), B = c("pass", "fail"), C =
> c("pass", "fail"), D = c("pass", "fail"), E = c("pass", "fail"), F =
> c("pass", "fail"))
>
>
> scenarios <- subset(scenarios, !(E == "fail" & F == "fail))
>
> Sarah
>
> On Thu, Aug 2, 2018 at 11:41 AM, R Stafford <rod.stafford at gmail.com>
> wrote:
> > Thank you for pointing that out, I realize not only did I use the wrong
> > language but I did not describe the situation accurately.  I do need to
> > address the situation where both variables E and F actually pass, that is
> > the majority case, one or the other can fail, but there can never be a
> > situation where E and F both fail.  I do not know a specific term for
> that
> > situation, but you are correct that mutual exclusivity is wrong.   While
> I
> > can generate a list of all possible combinations with the expand.grid
> > function (which I am not committed to by the way), it would be very
> helpful
> > if I could exclude the combinations where E and F both fail.  I am not
> sure
> > where to go from here, but the solution does not have to be elegant or
> even
> > efficient because I do not need to scale higher than 6 variables.
> >
> >
> >
> > On Thu, Aug 2, 2018 at 7:26 AM, S Ellison <S.Ellison at lgcgroup.com>
> wrote:
> >
> >> > On Thu, Aug 2, 2018 at 11:20 AM, R Stafford <rod.stafford at gmail.com>
> >> > wrote:
> >> > > But I have the extra condition that if E is true, then F must be
> >> false, and
> >> > > vice versa,
> >>
> >> Question: Does 'vice versa' mean
> >> a) "if E is False, F must be True"
> >> or
> >> b) "if F is True, E must be False"?
> >> ... which are not the same.
> >>
> >> b) (and mutual exclusivity in general) does not rule out the condition
> "E
> >> False, F False", which would not be addressed by the
> >> pass/fail equivalent equivalent of F <- !E
> >>
> >>
> >>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From motyoc@k@ @end|ng |rom y@hoo@com  Thu Aug  2 21:00:08 2018
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Thu, 2 Aug 2018 19:00:08 +0000 (UTC)
Subject: [R] kSamples ad.test question
References: <2131690356.1175565.1533236408682.ref@mail.yahoo.com>
Message-ID: <2131690356.1175565.1533236408682@mail.yahoo.com>

Dear All,

once we run the following code, the results of the test will give us the expected obvious, samples are?from the common distribution...


library(kSamples)

u1 <- sample(rnorm(500,10,1),20,replace = TRUE)
u2 <- sample(rnorm(500,10,1),20,replace = TRUE)
u3 <- sample(rnorm(500,10,1),20,replace = TRUE)
u4 <- sample(rnorm(500,10,1),20,replace = TRUE)
u5 <- sample(rnorm(500,10,1),20,replace = TRUE)

ad.test(u1, u2, u3,u4,u5, method = "exact", dist = FALSE, Nsim = 1000)

next, if I change "u5" to:

u5 <- sample(rnorm(500,20,1),20,replace = TRUE)

the results of the test again gives us what we expect, ie samples are not from the common distribution.... my question is: would you know of a way to be able to automatically select out or identify? "u5", the distribution that is "responsible"? for the results generated showing that the?samples are?not?from the common distribution??

much appreciate your help,


Andras?



From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug  2 21:37:53 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 2 Aug 2018 12:37:53 -0700
Subject: [R] kSamples ad.test question
In-Reply-To: <2131690356.1175565.1533236408682@mail.yahoo.com>
References: <2131690356.1175565.1533236408682.ref@mail.yahoo.com>
 <2131690356.1175565.1533236408682@mail.yahoo.com>
Message-ID: <CAGxFJbS=XF2fJmGxLMqf5FPd9b+9Eaj4oHDCT4tYa5KFQkV9Zg@mail.gmail.com>

You may get a response here, but as this is primarily a statistical
question, not a question about R programming, so it is off topic here. I
would suggest that you post this on stats.stackexchange.com or other
statistics site instead. There is a large literature on this sort of thing .

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 2, 2018 at 12:00 PM, Andras Farkas via R-help <
r-help at r-project.org> wrote:

> Dear All,
>
> once we run the following code, the results of the test will give us the
> expected obvious, samples are from the common distribution...
>
>
> library(kSamples)
>
> u1 <- sample(rnorm(500,10,1),20,replace = TRUE)
> u2 <- sample(rnorm(500,10,1),20,replace = TRUE)
> u3 <- sample(rnorm(500,10,1),20,replace = TRUE)
> u4 <- sample(rnorm(500,10,1),20,replace = TRUE)
> u5 <- sample(rnorm(500,10,1),20,replace = TRUE)
>
> ad.test(u1, u2, u3,u4,u5, method = "exact", dist = FALSE, Nsim = 1000)
>
> next, if I change "u5" to:
>
> u5 <- sample(rnorm(500,20,1),20,replace = TRUE)
>
> the results of the test again gives us what we expect, ie samples are not
> from the common distribution.... my question is: would you know of a way to
> be able to automatically select out or identify  "u5", the distribution
> that is "responsible"  for the results generated showing that the samples
> are not from the common distribution?
>
> much appreciate your help,
>
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Fri Aug  3 00:32:18 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 3 Aug 2018 08:32:18 +1000
Subject: [R] how to allign data
In-Reply-To: <41e5dda4b6a84bda9c0896c4bc6bcf3b@SRVEXCHCM1302.precheza.cz>
References: <41e5dda4b6a84bda9c0896c4bc6bcf3b@SRVEXCHCM1302.precheza.cz>
Message-ID: <CA+8X3fV_joQ95iqfM7tGDEwQUX91XEAOoZfyxtx1nhAPYqg9Dw@mail.gmail.com>

Hi Petr,
I recently had to align the minima of deceleration events to form an
aggregate "braking profile" for different locations. It seems as
though you are looking for something like:

find_increase<-function(x,surround=10) {
 inc_index<-which.max(diff(x))
 indices<-(inc_index-surround):(inc_index+surround)
 nneg<-sum(indices < 1)
 # pad both ends with NA if needed
 newx<-x[1:max(indices)]
 if(nneg > 0) newx<-c(rep(NA,nneg),newx)
 return(newx)
}

Jim

On Thu, Aug 2, 2018 at 10:23 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> Before I start to reinvent wheel I would like to ask you if you have some easy solution for aligning data
>
> I have something like this
> x<-1:100
> set.seed(42)
> y1<-c(runif(20)+1, 1.2*x[1:80]+runif(80))
> y2<-c(runif(40)+1, 1.2*x[1:60]+runif(60))
>
> plot(x,y1)
> points(x,y2, col=2)
>
> with y increase starting at various x.
>
> I would like to allign data so that the increase starts at the same x point, something like
>
> plot(x,y1)
> points(x[-(1:20)]-20,y2[-(1:20)], col=2)
>
> I consider using strucchange or segmented packages to find break(s) and "shift" x values according to this break. But maybe somebody already did similar task (aligning several vectors according to some common breakpoint) and could offer better or simpler solution.
>
> Best regards.
> Petr
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From cjgroen|ng @end|ng |rom gm@||@com  Fri Aug  3 04:11:07 2018
From: cjgroen|ng @end|ng |rom gm@||@com (cjg15)
Date: Thu, 2 Aug 2018 22:11:07 -0400
Subject: [R] Rendo and dataMultilevelIV
Message-ID: <CAFM=56cW2jwit3ehn3OQrspzEt7Z74dOaQwOGdHzYdjQQEiGxA@mail.gmail.com>

Hi - Does anyone know what the variables CID and SID are in the
dataMultilevelIV dataset?

The example from page 18-19 of
https://cran.r-project.org/web/packages/REndo/REndo.pdf has

formula1 <- y ~ X11 + X12 + X13 + X14 + X15 + X21 + X22 + X23 + X24 + X31 +
X32 + X33 + (1 + X11 | CID) + (1|SID)

what exactly are the (1 + X11|CID) and (1|SID) terms?

does (1|SID) mean random intercepts for SID, and SID is student ID?

Thanks in advance, Chris

	[[alternative HTML version deleted]]



From j@n@@nn@ert @end|ng |rom u@ntwerpen@be  Fri Aug  3 07:54:36 2018
From: j@n@@nn@ert @end|ng |rom u@ntwerpen@be (Annaert Jan)
Date: Fri, 3 Aug 2018 05:54:36 +0000
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
Message-ID: <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>

You can easily test linear restrictions using the function linearHypothesis() from the car package.
There are several ways to set up the null hypothesis, but a straightforward one here is:
 
> library(car)
> x <- rnorm(10)
> y <- x+rnorm(10)
> linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
Linear hypothesis test

Hypothesis:
(Intercept) = 0
x = 1

Model 1: restricted model
Model 2: y ~ x

  Res.Df     RSS Df Sum of Sq      F Pr(>F)
1     10 10.6218                           
2      8  9.0001  2    1.6217 0.7207 0.5155


Jan

From: R-help <r-help-bounces at r-project.org> on behalf of John <miaojpm at gmail.com>
Date: Thursday, 2 August 2018 at 10:44
To: r-help <r-help at r-project.org>
Subject: [R] F-test where the coefficients in the H_0 is nonzero

Hi,

?? I try to run the regression
?? y = beta_0 + beta_1 x
?? and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
?? I believe I can run the regression
?? (y-x) = beta_0 +beta_1? x
?? and do the regular F-test (using lm functio) where the hypothesized
coefficients are all zero.

?? Is there any function in R that deal with the case where the
coefficients are nonzero?

John

	[[alternative HTML version deleted]]

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From djnord|und @end|ng |rom gm@||@com  Fri Aug  3 08:20:52 2018
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Thu, 2 Aug 2018 23:20:52 -0700
Subject: [R] Rendo and dataMultilevelIV
In-Reply-To: <CAFM=56cW2jwit3ehn3OQrspzEt7Z74dOaQwOGdHzYdjQQEiGxA@mail.gmail.com>
References: <CAFM=56cW2jwit3ehn3OQrspzEt7Z74dOaQwOGdHzYdjQQEiGxA@mail.gmail.com>
Message-ID: <4b5fb2c5-9f6d-9d85-70cf-f522db288aef@gmail.com>

On 8/2/2018 7:11 PM, cjg15 wrote:
> Hi - Does anyone know what the variables CID and SID are in the
> dataMultilevelIV dataset?
> 
> The example from page 18-19 of
> https://cran.r-project.org/web/packages/REndo/REndo.pdf has
> 
> formula1 <- y ~ X11 + X12 + X13 + X14 + X15 + X21 + X22 + X23 + X24 + X31 +
> X32 + X33 + (1 + X11 | CID) + (1|SID)
> 
> what exactly are the (1 + X11|CID) and (1|SID) terms?
> 
> does (1|SID) mean random intercepts for SID, and SID is student ID?
> 
> Thanks in advance, Chris
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Did you read pages 9-10 of the document you provided a link to above 
(which describes the dataMultilevelIV dataset)?


Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA



From R@|ner @end|ng |rom krug@@de  Fri Aug  3 09:03:43 2018
From: R@|ner @end|ng |rom krug@@de (Rainer Krug)
Date: Fri, 3 Aug 2018 09:03:43 +0200
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
 <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>
Message-ID: <C42F8302-FA61-4C1B-9C1A-33AC3708676E@krugs.de>

Let?s not alienate the business users!

I agree that this is not the right / best forum to ask these type of questions, but where is? I would suggest to at least point them to the right resources. and not say that there questions are inappropriate here.

Actually, if I as a private user would ask that question, I guess I would get an answer here.

So please - not alienate the business users.

Cheers and good luck with Windows,

Rainer




> On 2 Aug 2018, at 16:54, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> R is free and open source. Your queries are inappropriate for this list,
> which is about help for programming in R.  Please go here and follow the
> relevant links to answer your questions:
> 
> https://www.r-project.org/
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Thu, Aug 2, 2018 at 1:45 AM, Flament, Kevin <Kevin.Flament at pmi.com>
> wrote:
> 
>> Dear R Project team,
>> 
>> I am representing the System Toxicology department of Philip Morris
>> International in the scope of a Windows 10 migration project.
>> This project is currently at the end of the assessment phase. We would
>> require an answer to this email by the end of this week.
>> 
>> I would like to ask you some questions related to the following software
>> we are using at PMI :
>> 
>> R for Windows 3.0.2
>> R for Windows 3.1.2
>> 
>> Are all of those software compatible with Windows 10 Enterprise (version
>> 10.0.16299 build 16299)?
>> Are all of those software compatible with Windows 10 LTSC (version
>> 14393.2399)?
>> Are those software compatible with a 32 and/or 64 bit version of Windows
>> 10?
>> Are those application dependent on MS Office?
>> Have those applications any pre-requisites? Such as Java, .Net, Oracle.
>> 
>> If the software are not compatible, do you have a new version of this
>> software compatible with the mentioned version of Windows 10?
>> What would be the cost of such migration (instrument replacement if
>> necessary, licence cost, ...)?
>> 
>> If the software are not compatible and a new version is not yet available,
>> could you give me an estimation for the future release availability?
>> 
>> Best Regards,
>> 
>> Kevin Flament
>> 
>> Data & Systems Specialist
>> PMI Science and Innovation
>> Quai Jeanrenaud 3
>> 2000 Neuch?tel
>> 
>>        [[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180803/ab615859/attachment-0002.sig>

From |eeth0323 @end|ng |rom vm@-@o|ut|on@@com  Fri Aug  3 05:07:28 2018
From: |eeth0323 @end|ng |rom vm@-@o|ut|on@@com (=?ks_c_5601-1987?B?wMzFwsjx?=)
Date: Fri, 3 Aug 2018 03:07:28 +0000
Subject: [R] Questions for Licensing
Message-ID: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>

To whom it may concern,

I am very new to GNU GPL License and I have no idea how using GPL licensed software can affect the software that my company has developed.

My company develops and distributes S/W to clients. Our product is a proprietary software under EULA license.
When we sell our products and sign contracts we do not open the source code of our products to our clients. Although we do provide documents for methods, property, fields with definition and sample codes.

Since our product is mainly used for simulation, scheduling and analyzation, we are considering to use R for creating data visualization.
We would also like to deliver our product including R as bundle to customers.
So basically, the product components would be looking like the one attached to this mail.

Red box : Overall package of our product to be delivered to our customers.
Blue box: Components of our company developed programs.
Blue color filled box : Our company?s main program and class library Dlls.
R link module : Functions defined to connect and communicate with R through R.Net
Interface : R.Net or something similar to play the same role. If needed, develop our own interface to call R libraries.
R scripts : R scripts to process result data from our engine, convert it using the R engine and finally display the visualized data through our product.
R Engine : R controls and DLLs

We are not planning to modify any part of the libraries of R.
Also the engine of our product will not be directly calling R controls but through R.Net as an interface to communicate with R.

Now the questions I would like to ask are the following :

1.   R is licensed under GPL2/GPL3 and R.Net is licensed under BDS. In case we sell the content of the blue box (shown above), do we need to provide the source code for our entire product because we are using GPL licensed S/W?

2.   One our components from our product will be referring to DLLs provided from R.Net such as R link module in this case. In this scenario, do we need to provide the source code for the R-link Module?


3.   Instead of using R.Net, in case we develop our own DLLs to directly communicate with R (without R modification), do we need to provide the source code for our entire product?


5.   Are we allowed to deliver our products as a package as in the Red box? (Sell our products including R)
A. If not, which of components are we allowed to sell as a package to our customers.
B.  If we sell our products including R installation, do we need to open our product?s source code?


Last but not least, we would like to know a way how we could use R and treat as an individual license so it does not violate our EULA license and for us not to open any part of source code of our products.
The end-users of our customers are developers and analysts. I?m pretty sure analysts would not request for open source but developers would.
We just want to avoid a situation in which our product accidentally falls under the GPL license because of our use of R and us therefore having to provide the source code for our product.

Thank you for your precious time reading this mail and any advices and information you provide will be a great help to me.

Best regards,
Tae Hee, Lee
Junior Engineer
Technical Supports
VMS-Solutions Co.,Ltd, South Korea


-------------- next part --------------
A non-text attachment was scrubbed...
Name: ProductComponentGroup.png
Type: image/png
Size: 72144 bytes
Desc: ProductComponentGroup.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180803/1ba0750c/attachment-0002.png>

From pd@|gd @end|ng |rom gm@||@com  Fri Aug  3 09:54:07 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 3 Aug 2018 09:54:07 +0200
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
Message-ID: <EAD84A10-9C8C-4419-8831-701DAAE31B52@gmail.com>

It is difficult to answer such questions authoritatively, but

- we have, to my recollection, no reports of major incompatibility with Windows 10

- however, the version numbers of R increase with .1 per year, and we are currently at 3.5.1, so your versions are 4 and 5 years out of date. Most users are upgraded at least annually, so problems with older versions could go undetected

- there is no external cost of migrating to a newer version. R is free software. Rolling it out within an organization could require some manpower, as could sorting out changed behaviour of R and its add-on packages. It should be fairly easy to do a test install of 3.5.1 and run it by your user base to see whether there are issues. 

- R works cross-platform and has no specific dependency on MS Office products

- R can interact with Java, but Java is not generally a prerequisite. You may want to check whether your users use packages with Java dependencies

- Peter Dalgaard

> On 2 Aug 2018, at 10:45 , Flament, Kevin <Kevin.Flament at pmi.com> wrote:
> 
> Dear R Project team,
> 
> I am representing the System Toxicology department of Philip Morris International in the scope of a Windows 10 migration project.
> This project is currently at the end of the assessment phase. We would require an answer to this email by the end of this week.
> 
> I would like to ask you some questions related to the following software we are using at PMI :
> 
> R for Windows 3.0.2
> R for Windows 3.1.2
> 
> Are all of those software compatible with Windows 10 Enterprise (version 10.0.16299 build 16299)?
> Are all of those software compatible with Windows 10 LTSC (version 14393.2399)?
> Are those software compatible with a 32 and/or 64 bit version of Windows 10?
> Are those application dependent on MS Office?
> Have those applications any pre-requisites? Such as Java, .Net, Oracle.
> 
> If the software are not compatible, do you have a new version of this software compatible with the mentioned version of Windows 10?
> What would be the cost of such migration (instrument replacement if necessary, licence cost, ...)?
> 
> If the software are not compatible and a new version is not yet available, could you give me an estimation for the future release availability?
> 
> Best Regards,
> 
> Kevin Flament
> 
> Data & Systems Specialist
> PMI Science and Innovation
> Quai Jeanrenaud 3
> 2000 Neuch?tel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Aug  3 10:25:07 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 3 Aug 2018 20:25:07 +1200
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <C42F8302-FA61-4C1B-9C1A-33AC3708676E@krugs.de>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
 <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>
 <C42F8302-FA61-4C1B-9C1A-33AC3708676E@krugs.de>
Message-ID: <4723b4d8-225c-ae3a-e429-ee5623c50188@auckland.ac.nz>

On 03/08/18 19:03, Rainer Krug wrote:
> Let?s not alienate the business users!
> 
> I agree that this is not the right / best forum to ask these type of questions, but where is? I would suggest to at least point them to the right resources. and not say that there questions are inappropriate here.
> 
> Actually, if I as a private user would ask that question, I guess I would get an answer here.
> 
> So please - not alienate the business users.
> 
> Cheers and good luck with Windows.

On the contrary, I would say that one has a moral obligation to alienate 
tobacco companies.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From S@E|||@on @end|ng |rom LGCGroup@com  Fri Aug  3 12:46:50 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Fri, 3 Aug 2018 10:46:50 +0000
Subject: [R] 
 Combinations of true/false values where one pair is mutually
 exclusive
In-Reply-To: <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>
References: <CAG6pTpVAqZ9K6rPt270H73mmoNzk8Lx7rd9dZYRXEQXLWs0Agg@mail.gmail.com>
 <CA+8X3fWyCGyXzg6ao1WVmUbMEuZ-xoGbW96pJz9QinjYBXyhuw@mail.gmail.com>
 <aed8ef634d714dac85dba5495b10c052@GBDCVPEXC04.corp.lgc-group.com>
 <CAG6pTpX4Fsvm0B9uqfCutc8DL0NjX8n828u9=nGPtoeextsJ4g@mail.gmail.com>
 <CAM_vju==AGLzMjXRbOEXP9gWucBnchgwT5FA-YjvOFR5wjEjXw@mail.gmail.com>
Message-ID: <60d0eee9c6a44804b79f77cd060cbcd5@GBDCVPEXC04.corp.lgc-group.com>

> Given that clarification, I'd just generate the full set and remove
> the ones you aren't interested in, as in:
I'd agree; that is probably the most efficient thing to do with only half a dozen binary variables and a single condition.

A way of going about it for a more complex case might be to generate a single dummy variable encoding the special case combinations in the expand.grid step, and then decode that. For example (using this case):

allowed.EF <- data.frame(E=c("pass", "pass", "fail"), F=c("pass", "fail", "pass" ))

AtoEF <- expand.grid(A=c("pass", "fail"),B=c("pass", "fail"), C=c("pass", "fail"), D=c("pass", "fail"), EF=1:3 )

AtoF <- cbind(AtoEF[1:4], allowed.EF[AtoEF$EF,])

#Which gives the same combinations as Sarah's complete/subset method, albeit in a different order and with silly row names.




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From S@E|||@on @end|ng |rom LGCGroup@com  Fri Aug  3 13:04:10 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Fri, 3 Aug 2018 11:04:10 +0000
Subject: [R] Questions for Licensing
In-Reply-To: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>
References: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>
Message-ID: <0357062e62d24f07a72e2fce79fce4cb@GBDCVPEXC04.corp.lgc-group.com>

> I am very new to GNU GPL License and I have no idea how using GPL licensed
> software can affect the software that my company has developed.
Short answer: in that situation, consult a qualified legal expert under contract to give you advice.

Nothing less  will be of any use in defending your business.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From petr@p|k@| @end|ng |rom prechez@@cz  Fri Aug  3 13:34:34 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 3 Aug 2018 11:34:34 +0000
Subject: [R] how to allign data
In-Reply-To: <CA+8X3fV_joQ95iqfM7tGDEwQUX91XEAOoZfyxtx1nhAPYqg9Dw@mail.gmail.com>
References: <41e5dda4b6a84bda9c0896c4bc6bcf3b@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fV_joQ95iqfM7tGDEwQUX91XEAOoZfyxtx1nhAPYqg9Dw@mail.gmail.com>
Message-ID: <eb934025d57d451c89cb3bfe7cc86c83@SRVEXCHCM1302.precheza.cz>

Hi Jim

Thanks for your function, however I either do not understand its purpose or I did not explained my aim correctly.

with segmented package I could find x value for break in slope
fit<-lm(y1~x)
segmented(fit, seg.Z=~x)
Estimated Break-Point(s):
psi1.x
 20.77
fit<-lm(y2~x)
segmented(fit, seg.Z=~x)
Estimated Break-Point(s):
psi1.x
 40.99

After that I need to allign both y1 and y2 to common x, for which I could use the difference in estimated beakpoints for each y, which is
> round(40.99-20.77)
[1] 20

and use this difference for aligning data

plot(x,y1)
points(x[-(1:(psi20)]-20,y2[-(1:20)], col=2)

But this seems to me rather complicated so I just asked if there is some shorter and less tedious option.

Actually I cannot decipher how your function could help me to plot y1 and y2 and starting to increase at the same point.

Cheers
Petr

> -----Original Message-----
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Friday, August 3, 2018 12:32 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] how to allign data
>
> Hi Petr,
> I recently had to align the minima of deceleration events to form an
> aggregate "braking profile" for different locations. It seems as
> though you are looking for something like:
>
> find_increase<-function(x,surround=10) {
>  inc_index<-which.max(diff(x))
>  indices<-(inc_index-surround):(inc_index+surround)
>  nneg<-sum(indices < 1)
>  # pad both ends with NA if needed
>  newx<-x[1:max(indices)]
>  if(nneg > 0) newx<-c(rep(NA,nneg),newx)
>  return(newx)
> }
>
> Jim
>
> On Thu, Aug 2, 2018 at 10:23 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > Dear all
> >
> > Before I start to reinvent wheel I would like to ask you if you have some easy
> solution for aligning data
> >
> > I have something like this
> > x<-1:100
> > set.seed(42)
> > y1<-c(runif(20)+1, 1.2*x[1:80]+runif(80))
> > y2<-c(runif(40)+1, 1.2*x[1:60]+runif(60))
> >
> > plot(x,y1)
> > points(x,y2, col=2)
> >
> > with y increase starting at various x.
> >
> > I would like to allign data so that the increase starts at the same x point,
> something like
> >
> > plot(x,y1)
> > points(x[-(1:20)]-20,y2[-(1:20)], col=2)
> >
> > I consider using strucchange or segmented packages to find break(s) and
> "shift" x values according to this break. But maybe somebody already did
> similar task (aligning several vectors according to some common breakpoint)
> and could offer better or simpler solution.
> >
> > Best regards.
> > Petr
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-
> ochrany-osobnich-udaju/ | Information about processing and protection of
> business partner?s personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Aug  3 13:44:17 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 03 Aug 2018 07:44:17 -0400
Subject: [R] Questions for Licensing
In-Reply-To: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>
References: <PS1PR02MB1404D0E5A71CA9F7EFD280F5E8230@PS1PR02MB1404.apcprd02.prod.outlook.com>
Message-ID: <725F442C-F765-42D1-8134-D4CD8997B732@me.com>

Hi,

As was mentioned in another reply, you will not get formal legal advice here, as none of us are intellectual property (IP) lawyers, and there can even be country specific issues when it comes to such things, based upon local laws and legal precedents that may be relevant.

That being said, on an informal basis, you should at least review the GPL FAQ:

  https://www.gnu.org/licenses/gpl-faq.en.html

to begin to educate yourself on key issues, which really come down to whether or not, your proprietary application can be considered a "derivative work" and therefore be impacted by the so-called "viral" implications of the GPL.

Given the liability risks (legal and financial) that your company faces if you "get it wrong", you need to seek out local legal expertise, specifically with IP related issues, and get a formal legal opinion and guidance.

Regards,

Marc Schwartz


> On Aug 2, 2018, at 11:07 PM, ??? <leeth0323 at vms-solutions.com> wrote:
> 
> To whom it may concern,
> 
> I am very new to GNU GPL License and I have no idea how using GPL licensed software can affect the software that my company has developed.
> 
> My company develops and distributes S/W to clients. Our product is a proprietary software under EULA license.
> When we sell our products and sign contracts we do not open the source code of our products to our clients. Although we do provide documents for methods, property, fields with definition and sample codes.
> 
> Since our product is mainly used for simulation, scheduling and analyzation, we are considering to use R for creating data visualization.
> We would also like to deliver our product including R as bundle to customers.
> So basically, the product components would be looking like the one attached to this mail.
> 
> Red box : Overall package of our product to be delivered to our customers.
> Blue box: Components of our company developed programs.
> Blue color filled box : Our company?s main program and class library Dlls.
> R link module : Functions defined to connect and communicate with R through R.Net
> Interface : R.Net or something similar to play the same role. If needed, develop our own interface to call R libraries.
> R scripts : R scripts to process result data from our engine, convert it using the R engine and finally display the visualized data through our product.
> R Engine : R controls and DLLs
> 
> We are not planning to modify any part of the libraries of R.
> Also the engine of our product will not be directly calling R controls but through R.Net as an interface to communicate with R.
> 
> Now the questions I would like to ask are the following :
> 
> 1.   R is licensed under GPL2/GPL3 and R.Net is licensed under BDS. In case we sell the content of the blue box (shown above), do we need to provide the source code for our entire product because we are using GPL licensed S/W?
> 
> 2.   One our components from our product will be referring to DLLs provided from R.Net such as R link module in this case. In this scenario, do we need to provide the source code for the R-link Module?
> 
> 
> 3.   Instead of using R.Net, in case we develop our own DLLs to directly communicate with R (without R modification), do we need to provide the source code for our entire product?
> 
> 
> 5.   Are we allowed to deliver our products as a package as in the Red box? (Sell our products including R)
> A. If not, which of components are we allowed to sell as a package to our customers.
> B.  If we sell our products including R installation, do we need to open our product?s source code?
> 
> 
> Last but not least, we would like to know a way how we could use R and treat as an individual license so it does not violate our EULA license and for us not to open any part of source code of our products.
> The end-users of our customers are developers and analysts. I?m pretty sure analysts would not request for open source but developers would.
> We just want to avoid a situation in which our product accidentally falls under the GPL license because of our use of R and us therefore having to provide the source code for our product.
> 
> Thank you for your precious time reading this mail and any advices and information you provide will be a great help to me.
> 
> Best regards,
> Tae Hee, Lee
> Junior Engineer
> Technical Supports
> VMS-Solutions Co.,Ltd, South Korea



From er|cjberger @end|ng |rom gm@||@com  Fri Aug  3 13:57:39 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 3 Aug 2018 14:57:39 +0300
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <4723b4d8-225c-ae3a-e429-ee5623c50188@auckland.ac.nz>
References: <45cb14a9ceb5461487f15259f1c804d0@PMICHLAUEXM284.PMINTL.NET>
 <CAGxFJbRqqrVNgJfoPVrKtB2=E=N7YSdb2EK+RGDA5WLf+j0t8w@mail.gmail.com>
 <C42F8302-FA61-4C1B-9C1A-33AC3708676E@krugs.de>
 <4723b4d8-225c-ae3a-e429-ee5623c50188@auckland.ac.nz>
Message-ID: <CAGgJW75ZR+8NRF_V4mhxSb1sXMi0ozMJ3wDQS11AmjdpF+e7tA@mail.gmail.com>

Hi Kevin,
For what it's worth I use R on Windows 10 Pro with the 16299 build (and
also with a later build on a different Windows 10 Pro computer.)
I also use R on Linux machines (specifically Ubuntu).
I use 64 bit versions but both 32bit and 64bit version are available.
As Peter wrote previously, R itself has no dependency on MS Office products.
However there are thousands of R packages freely downloadable (e.g. from
CRAN but also from other sources.)
Some of these packages may have explicit dependencies on commercial
packages.
(e.g. Rmosek is a free package that makes it easy to access the commercial
optimization software mosek.)
Peter also wrote that the latest release of R is version 3.5.1 which makes
your referenced versions quite old.
As far as I know it is generally possible to install any version of R (even
multiple versions of R) on your computer.
For example, when R 3.5.0 was released recently some users experienced some
glitches (some of which have presumably been fixed in 3.5.1.)
Personally I am staying with R 3.4.2 for a while longer.

If PMI requires "commercial" support and has the budget for it, you might
consider contacting Rstudio.com which produces some of the major
software tools used by the R community - Rstudio and Shiny and additional R
packages. They provide both free and commercial versions of
RStudio and Shiny and should have a lot of experience dealing with
corporate customers. Also by supporting them PMI would be indirectly
supporting
the R community at large which greatly benefits from the work they do.

I hope that helps.

Regards,

Eric Berger



On Fri, Aug 3, 2018 at 11:25 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 03/08/18 19:03, Rainer Krug wrote:
>
>> Let?s not alienate the business users!
>>
>> I agree that this is not the right / best forum to ask these type of
>> questions, but where is? I would suggest to at least point them to the
>> right resources. and not say that there questions are inappropriate here.
>>
>> Actually, if I as a private user would ask that question, I guess I would
>> get an answer here.
>>
>> So please - not alienate the business users.
>>
>> Cheers and good luck with Windows.
>>
>
> On the contrary, I would say that one has a moral obligation to alienate
> tobacco companies.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From c||ve||@t@ @end|ng |rom goog|em@||@com  Fri Aug  3 21:47:01 2018
From: c||ve||@t@ @end|ng |rom goog|em@||@com (Clive Nicholas)
Date: Fri, 3 Aug 2018 20:47:01 +0100
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
Message-ID: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>

On 03/08/18 19:03, Rainer Krug wrote:
> Let?s not alienate the business users!
>
> I agree that this is not the right / best forum to ask these type of
questions, but where is? I would suggest to at least point them to the
right resources. and not say that there questions are inappropriate here.
>
> Actually, if I as a private user would ask that question, I guess I would
get an answer here.
>
> So please - not alienate the business users.
>
> Cheers and good luck with Windows.

On the contrary, I would say that one has a moral obligation to alienate
tobacco companies.

cheers,

Rolf Turner

-- 

And I'm down with this moral sentiment 10,000%.

I frankly couldn't believe what I was reading whilst perusing the digest,
and from whom. This smug bloke thinks he can land his 14-ton todger onto
the list, demand answers by a fixed deadline, and all in the service of
doing his bit to help replace the 7 million tobacco users who die every
year - according to the World Health Organisation - with preferably new,
young customers for the likes of PMI to sell their cancer sticks.

Disgusting. *Absolutely* disgusting! What on Bod's Earth are we doing
helping these people? They should be nowhere near this list. Do you hear
that, Philip Morris Angel of Death? I sincerely hope you crash and burn.

-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

	[[alternative HTML version deleted]]



From |nterzone @end|ng |rom gm@||@com  Sat Aug  4 00:07:51 2018
From: |nterzone @end|ng |rom gm@||@com (Dylan Distasio)
Date: Fri, 3 Aug 2018 18:07:51 -0400
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
References: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
Message-ID: <CAJrqPH9k=vWV9=5ojTgdwkNHYfd3WwKNpsOz_WXLEeAt1n4u+g@mail.gmail.com>

Nice virtue signalling, feel better now?

On Fri, Aug 3, 2018, 3:47 PM Clive Nicholas via R-help <r-help at r-project.org>
wrote:

> On 03/08/18 19:03, Rainer Krug wrote:
> > Let?s not alienate the business users!
> >
> > I agree that this is not the right / best forum to ask these type of
> questions, but where is? I would suggest to at least point them to the
> right resources. and not say that there questions are inappropriate here.
> >
> > Actually, if I as a private user would ask that question, I guess I would
> get an answer here.
> >
> > So please - not alienate the business users.
> >
> > Cheers and good luck with Windows.
>
> On the contrary, I would say that one has a moral obligation to alienate
> tobacco companies.
>
> cheers,
>
> Rolf Turner
>
> --
>
> And I'm down with this moral sentiment 10,000%.
>
> I frankly couldn't believe what I was reading whilst perusing the digest,
> and from whom. This smug bloke thinks he can land his 14-ton todger onto
> the list, demand answers by a fixed deadline, and all in the service of
> doing his bit to help replace the 7 million tobacco users who die every
> year - according to the World Health Organisation - with preferably new,
> young customers for the likes of PMI to sell their cancer sticks.
>
> Disgusting. *Absolutely* disgusting! What on Bod's Earth are we doing
> helping these people? They should be nowhere near this list. Do you hear
> that, Philip Morris Angel of Death? I sincerely hope you crash and burn.
>
> --
> Clive Nicholas
>
> "My colleagues in the social sciences talk a great deal about methodology.
> I prefer to call it style." -- Freeman J. Dyson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug  4 00:58:48 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 4 Aug 2018 10:58:48 +1200
Subject: [R] 
 [FORGED] Re: Philip Morris International - Windows10 migration
 assessment
In-Reply-To: <CAJrqPH9k=vWV9=5ojTgdwkNHYfd3WwKNpsOz_WXLEeAt1n4u+g@mail.gmail.com>
References: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
 <CAJrqPH9k=vWV9=5ojTgdwkNHYfd3WwKNpsOz_WXLEeAt1n4u+g@mail.gmail.com>
Message-ID: <3024e898-f009-24ba-7c6a-6c805116c3b4@auckland.ac.nz>


On 04/08/18 10:07, Dylan Distasio wrote:

> Nice virtue signalling, feel better now?

I was going to respond to this, but then I thought that it would be 
better to heed the ancient wisdom: "Do not feed the trolls."

cheers,

Rolf Turner

> 
> On Fri, Aug 3, 2018, 3:47 PM Clive Nicholas via R-help <r-help at r-project.org>
> wrote:
> 
>> On 03/08/18 19:03, Rainer Krug wrote:
>>> Let?s not alienate the business users!
>>>
>>> I agree that this is not the right / best forum to ask these type of
>> questions, but where is? I would suggest to at least point them to the
>> right resources. and not say that there questions are inappropriate here.
>>>
>>> Actually, if I as a private user would ask that question, I guess I would
>> get an answer here.
>>>
>>> So please - not alienate the business users.
>>>
>>> Cheers and good luck with Windows.
>>
>> On the contrary, I would say that one has a moral obligation to alienate
>> tobacco companies.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>>
>> And I'm down with this moral sentiment 10,000%.
>>
>> I frankly couldn't believe what I was reading whilst perusing the digest,
>> and from whom. This smug bloke thinks he can land his 14-ton todger onto
>> the list, demand answers by a fixed deadline, and all in the service of
>> doing his bit to help replace the 7 million tobacco users who die every
>> year - according to the World Health Organisation - with preferably new,
>> young customers for the likes of PMI to sell their cancer sticks.
>>
>> Disgusting. *Absolutely* disgusting! What on Bod's Earth are we doing
>> helping these people? They should be nowhere near this list. Do you hear
>> that, Philip Morris Angel of Death? I sincerely hope you crash and burn.
>>
>> --
>> Clive Nicholas
>>
>> "My colleagues in the social sciences talk a great deal about methodology.
>> I prefer to call it style." -- Freeman J. Dyson



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug  4 07:52:37 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 4 Aug 2018 17:52:37 +1200
Subject: [R] A slightly unorthodox matrix product.
Message-ID: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>


Can anyone think of a sexy way of forming following "product"?

Given matrices A and B, both with m rows, form a 3 dimensional array C 
such that:

     C[i,j,k] = A[i,j]*B[i,k]

I *think* that the following does what I want.  (I keep confusing 
myself, so I'm not sure!)

library(abind)
xxx <- lapply(1:nrow(a),function(i,a,b){a[i,]%o%b[i,]},a=A,b=B)
do.call(abind,c(xxx,list(along=3)))

Is there a cleverer way?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From euthym|o@@k@k@@v|k|@ @end|ng |rom gm@||@com  Fri Aug  3 23:29:46 2018
From: euthym|o@@k@k@@v|k|@ @end|ng |rom gm@||@com (euthymios kasvikis)
Date: Sat, 4 Aug 2018 00:29:46 +0300
Subject: [R] Perform GEE regression in R with multiple dependent variables
Message-ID: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>

Im trying to perform generalized estimating equation (GEE) on the (sample)
dataset below with R and I would like some little guidance. First of all I
will describe my dataset. As you can see below it includes 5 variables.
Country_ID shows the country of the politician, Ideo_Ordinal his poltical
belief from 1 to 7 (far left to far right). Then we have measurements
regarding three characteristics. I would like to run an analysis based on
the country and the political beliefs of every politician (dependent
variables) in relation with the 3 characteristics. I have used the geepack
package using:

library(geepack)

        samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
sample$Ideo_Ordinal,
                                       corstr = "independence"))) %>%
          rownames_to_column() %>%
          mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
                 upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
                 df=1,
                 ExpBeta = exp(Estimate)) %>%       # Transformed estimate
          mutate(lWald=exp(lowerWald),              # Upper transformed
                 uWald=exp(upperWald))              # Lower transformed
        samplem

I would like to know if it is valid to add in this method the Country_ID
simultaneously with Ideo_Ordinal and how to do it.

Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
    3             1            3      0.250895132  0.155238716  0.128683755
    5             1            3     -0.117725000 -0.336256435 -0.203137879
    7             1            3      0.269509029 -0.260728261  0.086819555
    9             1            6      0.108873496  0.175528190  0.182884928
    14            1            3      0.173129951  0.054468468  0.155030794
    15            1            6     -0.312088872 -0.414358301 -0.212599946
    17            1            3     -0.297647658 -0.096523143 -0.228533352
    18            1            3     -0.020389157 -0.210180866 -0.046687695
    20            1            3     -0.523432382 -0.125114982 -0.431070629
    21            1            1      0.040304508  0.022743463  0.233657881
    22            1            3      0.253695988 -0.330825166  0.101122320
    23            1            3     -0.478673895 -0.421801231 -0.422894791
    27            1            6     -0.040856419 -0.566728704 -0.136069484
    28            1            3      0.240040249 -0.398404825  0.135603114
    29            1            6     -0.207631653 -0.005347621 -0.294935155
    30            1            3      0.458042533  0.462935386  0.586244831
    31            1            3     -0.259850232 -0.233074787 -0.092249465
    33            1            3      0.002164223 -0.637668706 -0.267158031
    34            1            6      0.050991955 -0.098030021 -0.043826848
    36            1            3     -0.338052871 -0.168894328 -0.230198200
    38            1            3      0.174382347  0.023807812  0.192963609
    41            2            3     -0.227322148 -0.010016330 -0.095576329
    42            2            3     -0.267514920  0.066108837 -0.218979873
    43            2            3      0.421277754  0.385223920  0.421274111
    44            2            3     -0.399592341 -0.498154998 -0.320402699
    45            2            1      0.162038344  0.328116118  0.104105963
    47            2            3     -0.080755709  0.003080287 -0.043568723
    48            2            3      0.059474124 -0.447305420  0.003988071
    49            2            3     -0.219773040 -0.312902659 -0.239057883
    51            2            3      0.438659431  0.364042111  0.393014172
    52            2            3     -0.088560903 -0.490889275 -0.006041054
    53            2            3     -0.122612591  0.074438944  0.103722836
    54            2            3     -0.450586055 -0.304253061 -0.132365179
    55            2            6     -0.710545197 -0.451329850 -0.764201786
    56            2            3      0.330718447  0.335460128  0.429173481
    57            2            3      0.442508023  0.297522144  0.407155726
    60            2            3      0.060797815 -0.096516876 -0.012802977
    61            2            3     -0.250757764 -0.113219864 -0.215345379
    62            2            1      0.153654345 -0.089615287  0.118626045
    65            2            3      0.042969508 -0.486999608 -0.080829636
    66            3            3      0.158337022  0.208229002  0.241607154
    67            3            3      0.220237408  0.397914524  0.262207709
    69            3            3      0.200558577  0.244419633  0.301732113
    71            3            3      0.690244689  0.772692418  0.625921098
    72            3            3      0.189810070  0.377774321  0.293988340
    73            3            3     -0.385724422 -0.262131032 -0.373159652
    74            3            3     -0.124095769 -0.109816334 -0.127157915
    75            3            1      0.173299879  0.453592671  0.325357383
    76            3            3     -0.598215129 -0.643286651 -0.423824759
    77            3            3     -0.420558406 -0.361763025 -0.465612116
    78            3            3     -0.176788569 -0.305506924 -0.203730879
    80            3            3     -0.114790731  0.262392918  0.061382073
    81            3            3     -0.274904173 -0.342603918 -0.302761994
    82            3            3     -0.146902101 -0.059558818 -0.120550957
    84            3            3      0.038303792 -0.139833875  0.170005914
    85            3            3     -0.220212221 -0.541399757 -0.555201764
    87            3            3      0.255300386  0.179484246  0.421428096
    88            3            6     -0.548823069 -0.405541620 -0.322935805

	[[alternative HTML version deleted]]



From bkok@@| @end|ng |rom gm@||@com  Fri Aug  3 23:46:32 2018
From: bkok@@| @end|ng |rom gm@||@com (=?UTF-8?B?QsO8bGVudCBLw7Zrc2Fs?=)
Date: Fri, 3 Aug 2018 23:46:32 +0200
Subject: [R] 
 Philip Morris International - Windows10 migration assessment
In-Reply-To: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
References: <CAHs5aThcCZnP-dPXJ1FbZLw=kLFp5YU2HweFvu2t+vz9HiimBQ@mail.gmail.com>
Message-ID: <CAGze6DmKCcq-Dj6CX+KK65YgUaqoAEMg4ZNuh+xgtJMdarWP3Q@mail.gmail.com>

Well said Clive. Thanks.

Bulent

On Fri, Aug 3, 2018, 21:47 Clive Nicholas via R-help <r-help at r-project.org>
wrote:

> On 03/08/18 19:03, Rainer Krug wrote:
> > Let?s not alienate the business users!
> >
> > I agree that this is not the right / best forum to ask these type of
> questions, but where is? I would suggest to at least point them to the
> right resources. and not say that there questions are inappropriate here.
> >
> > Actually, if I as a private user would ask that question, I guess I would
> get an answer here.
> >
> > So please - not alienate the business users.
> >
> > Cheers and good luck with Windows.
>
> On the contrary, I would say that one has a moral obligation to alienate
> tobacco companies.
>
> cheers,
>
> Rolf Turner
>
> --
>
> And I'm down with this moral sentiment 10,000%.
>
> I frankly couldn't believe what I was reading whilst perusing the digest,
> and from whom. This smug bloke thinks he can land his 14-ton todger onto
> the list, demand answers by a fixed deadline, and all in the service of
> doing his bit to help replace the 7 million tobacco users who die every
> year - according to the World Health Organisation - with preferably new,
> young customers for the likes of PMI to sell their cancer sticks.
>
> Disgusting. *Absolutely* disgusting! What on Bod's Earth are we doing
> helping these people? They should be nowhere near this list. Do you hear
> that, Philip Morris Angel of Death? I sincerely hope you crash and burn.
>
> --
> Clive Nicholas
>
> "My colleagues in the social sciences talk a great deal about methodology.
> I prefer to call it style." -- Freeman J. Dyson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Sat Aug  4 19:01:02 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 4 Aug 2018 20:01:02 +0300
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
Message-ID: <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>

Hi Rolf,
A few edits because (i) nrow(a) should be nrow(A) and (ii) you have
calculated C[j,k,i] = A[i,j]*B[i,k], (iii) minor style change on lapply.

library(abind)
xxx <- lapply(1:nrow(A),function(i){A[i,]%o%B[i,]})
yyy <- do.call(abind,c(xxx,list(along=3)))
zzz <- aperm(yyy,c(3,1,2))

HTH,
Eric


On Sat, Aug 4, 2018 at 8:52 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> Can anyone think of a sexy way of forming following "product"?
>
> Given matrices A and B, both with m rows, form a 3 dimensional array C
> such that:
>
>     C[i,j,k] = A[i,j]*B[i,k]
>
> I *think* that the following does what I want.  (I keep confusing myself,
> so I'm not sure!)
>
> library(abind)
> xxx <- lapply(1:nrow(a),function(i,a,b){a[i,]%o%b[i,]},a=A,b=B)
> do.call(abind,c(xxx,list(along=3)))
>
> Is there a cleverer way?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From ccberry @end|ng |rom uc@d@edu  Sat Aug  4 19:34:26 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Sat, 4 Aug 2018 17:34:26 +0000
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
Message-ID: <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>



> On Aug 4, 2018, at 10:01 AM, Eric Berger <ericjberger at gmail.com> wrote:
> 
> Hi Rolf,
> A few edits because (i) nrow(a) should be nrow(A) and (ii) you have
> calculated C[j,k,i] = A[i,j]*B[i,k], (iii) minor style change on lapply.
> 
> library(abind)
> xxx <- lapply(1:nrow(A),function(i){A[i,]%o%B[i,]})
> yyy <- do.call(abind,c(xxx,list(along=3)))

Or use the simplify="array" gambit in sapply:

yyy <- sapply(1:nrow(A), function(i) A[i,] %o% B[i,], simplify="array")

> zzz <- aperm(yyy,c(3,1,2))
> 

HTH, 

Chuck



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  4 20:43:16 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 4 Aug 2018 11:43:16 -0700 (PDT)
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
Message-ID: <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>

Sometimes a good old for loop performs best, even if it doesn't look sexy:

########
A <- matrix( 1:12, nrow = 3 )
B <- matrix( 1:15, nrow = 3 )

library(abind)
# Eric
ans1 <- function( a, b ) {
   xxx <- lapply( seq.int( nrow( A ) )
                , function( i ) {
                     A[ i, ] %o% B[ i, ]
                  }
                )
   yyy <- do.call( abind, c( xxx, list( along = 3 ) ) )
   zzz <- aperm( yyy, c( 3, 1, 2 ) )
   zzz
}
# Charles
ans1b <- function( a, b ) {
   xxx <- lapply( seq.int( nrow( A ) )
                , function( i ) {
                     A[ i, ] %o% B[ i, ]
                  }
                )
   yyy <- sapply( seq.int( nrow( a ) )
                , function( i ) a[ i, ] %o% b[ i, ]
                , simplify = "array"
                )
   zzz <- aperm( yyy, c( 3, 1, 2 ) )
   zzz
}
# Jeff #1
ans2 <- function( a, b ) {
   zzz <- array( rep( NA, nrow( a ) * ncol( a ) * ncol( b ) )
               , dim = c( nrow( a ), ncol( a ), ncol( b ) )
               )
   jseq <- seq.int( ncol( a ) )
   kseq <- seq.int( ncol( b ) )
   for ( i in seq.int( nrow( a ) ) ) {
     zzz[ i, jseq, kseq ] <- outer( a[ i, ], b[ i, ] )
   }
   zzz
}
# Jeff #2
ans3 <- function( a, b ) {
   idxs <- expand.grid( i = seq.int( nrow( a ) )
                      , j = seq.int( ncol( a ) )
                      , k = seq.int( ncol( b ) )
                      )
   ij <- as.matrix( idxs[ , c( "i", "j" ) ] )
   ik <- as.matrix( idxs[ , c( "i", "k" ) ] )
   array( a[ ij ] * b[ ik ]
        , dim = c( nrow( a ), ncol( a ), ncol( b ) )
        )
}

library(microbenchmark)

microbenchmark( res1 <- ans1( A, B )
               , res1b <- ans1b( A, B )
               , res2 <- ans2( A, B )
               , res3 <- ans3( A, B )
               )
#> Unit: microseconds
#>                  expr     min       lq      mean   median       uq
#>    res1 <- ans1(A, B) 660.489 688.3460 4199.5385 742.5505 805.1860
#>  res1b <- ans1b(A, B) 224.436 236.2250  427.4806 246.3240 269.6425
#>    res2 <- ans2(A, B)  91.538  96.9075  287.9596 102.0335 110.8825
#>    res3 <- ans3(A, B) 508.642 528.9700  860.6295 563.5470 619.5285
#>        max neval
#>  344769.27   100
#>   17062.63   100
#>   18212.11   100
#>   23041.89   100
all( res1 == res2 )
#> [1] TRUE
all( res1 == res1b )
#> [1] TRUE
all( res1 == res3 )
#> [1] TRUE
res3
#> , , 1
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]    1    4    7   10
#> [2,]    4   10   16   22
#> [3,]    9   18   27   36
#>
#> , , 2
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]    4   16   28   40
#> [2,]   10   25   40   55
#> [3,]   18   36   54   72
#>
#> , , 3
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]    7   28   49   70
#> [2,]   16   40   64   88
#> [3,]   27   54   81  108
#>
#> , , 4
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]   10   40   70  100
#> [2,]   22   55   88  121
#> [3,]   36   72  108  144
#>
#> , , 5
#>
#>      [,1] [,2] [,3] [,4]
#> [1,]   13   52   91  130
#> [2,]   28   70  112  154
#> [3,]   45   90  135  180

#' Created on 2018-08-04 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
########

On Sat, 4 Aug 2018, Berry, Charles wrote:

>
>
>> On Aug 4, 2018, at 10:01 AM, Eric Berger <ericjberger at gmail.com> wrote:
>>
>> Hi Rolf,
>> A few edits because (i) nrow(a) should be nrow(A) and (ii) you have
>> calculated C[j,k,i] = A[i,j]*B[i,k], (iii) minor style change on lapply.
>>
>> library(abind)
>> xxx <- lapply(1:nrow(A),function(i){A[i,]%o%B[i,]})
>> yyy <- do.call(abind,c(xxx,list(along=3)))
>
> Or use the simplify="array" gambit in sapply:
>
> yyy <- sapply(1:nrow(A), function(i) A[i,] %o% B[i,], simplify="array")
>
>> zzz <- aperm(yyy,c(3,1,2))
>>
>
> HTH,
>
> Chuck
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From ccberry @end|ng |rom uc@d@edu  Sat Aug  4 21:31:31 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Sat, 4 Aug 2018 19:31:31 +0000
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
 <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
Message-ID: <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>



> On Aug 4, 2018, at 11:43 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Sometimes a good old for loop performs best, even if it doesn't look sexy:
> 
> 

Fair enough, but a vectorized solution beats them all (see below).

Also,

[SNIP]


> # Charles
> ans1b <- function( a, b )
> {

The lapply you put here was from Eric's solution:

>  xxx <- lapply( seq.int( nrow( A ) )
>               , function( i ) {
>                    A[ i, ] %o% B[ i, ]
>                 }


This is what I had in mind:

ans1b.corrected <- function( a, b ) {
  yyy <- sapply( seq.int( nrow( a ) )
                 , function( i ) a[ i, ] %o% b[ i, ]
                 , simplify = "array"
  )
  zzz <- aperm( yyy, c( 3, 1, 2 ) )
  zzz
}

On my system it is slower than a for loop but a lot faster than your benchmark showed with the superfluous code from Eric's solution.

For speed, a vectorized solution is faster than a for loop by a factor of 3 on my laptop:

ans0 <- function(A,B){
  nca <- ncol(A)
  ncb <- ncol(B)
  j.index <- rep(1:nca, times = ncb)
  k.index <- rep(1:nca, each = ncb)
  res <- array(A[, j.index] * B[, k.index], c(nrow(A), nca, ncb))
  res
  }


> microbenchmark(
+   res0 <- ans0(A, B),
+   res1 <- ans1(A, B),
+   res1b <- ans1b.corrected(A, B),
+   res2 <- ans2(A, B),
+   res3 <- ans3(A, B)
+ )
Unit: microseconds
                           expr     min       lq      mean   median       uq     max neval   cld
             res0 <- ans0(A, B)  13.281  18.4960  21.52723  19.9905  23.4750  61.556   100 a    
             res1 <- ans1(A, B) 353.121 369.8635 409.77788 381.5840 444.3290 701.256   100     e
 res1b <- ans1b.corrected(A, B)  82.816  89.4185 101.52321  95.4275 107.1700 217.357   100   c  
             res2 <- ans2(A, B)  49.674  54.4825  61.78278  58.7540  65.5265 172.625   100  b   
             res3 <- ans3(A, B) 317.772 342.4220 392.25065 360.4675 436.2125 602.346   100    d 
> 


FWIW, if there are dimnames on A and B, sapply( row names(A), ..., simplify="array") preserves them without further ado.

Chuck


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  4 21:59:15 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 4 Aug 2018 12:59:15 -0700 (PDT)
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
 <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
 <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>
Message-ID: <alpine.BSF.2.00.1808041249340.89457@pedal.dcn.davis.ca.us>

Sorry I missed your intent on the sapply.

Slick work on the vectorizing, but for the future reference it was 
slightly buggy:

#######
A <- matrix( 1:12, nrow = 3 )
B <- matrix( 1:15, nrow = 3 )

# for loop
ans2 <- function( a, b ) {
   zzz <- array( rep( NA, nrow( a ) * ncol( a ) * ncol( b ) )
               , dim = c( nrow( a ), ncol( a ), ncol( b ) )
               )
   jseq <- seq.int( ncol( a ) )
   kseq <- seq.int( ncol( b ) )
   for ( i in seq.int( nrow( a ) ) ) {
     zzz[ i, jseq, kseq ] <- outer( a[ i, ], b[ i, ] )
   }
   zzz
}

# fast but buggy
ans0 <- function( A, B ) {
   nca <- ncol( A )
   ncb <- ncol( B )
   j.index <- rep( seq.int( nca ), times = ncb)
   k.index <- rep( seq.int( nca ), each = ncb)
   res <- array( A[ , j.index ] * B[ , k.index ]
               , c( nrow( A ), nca, ncb )
               )
   res
   }

# bugfixed
ans0b <- function( A, B ) {
   nca <- ncol( A )
   ncb <- ncol( B )
   j.index <- rep( seq.int( nca ), times = ncb )
   k.index <- rep( seq.int( ncb ), each = nca )
   res <- array( A[ , j.index ] * B[ , k.index ]
               , c( nrow( A ), nca, ncb )
               )
   res
   }

library(microbenchmark)

microbenchmark( res2 <- ans2( A, B )
               , res0b <- ans0b( A, B )
               , res0 <- ans0( A, B )
               )
#> Unit: microseconds
#>                  expr    min      lq     mean  median      uq      max
#>    res2 <- ans2(A, B) 84.987 87.8185 270.2153 96.4315 99.4175 17531.77
#>  res0b <- ans0b(A, B) 17.940 19.2055 126.8974 20.8800 22.2865 10616.36
#>    res0 <- ans0(A, B) 18.041 19.1670 126.1183 20.5530 21.9545 10532.44
#>  neval
#>    100
#>    100
#>    100
all( res2 == res0 )
#> [1] FALSE
all( res2 == res0b )
#> [1] TRUE

#' Created on 2018-08-04 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
#######

On Sat, 4 Aug 2018, Berry, Charles wrote:

>
>
>> On Aug 4, 2018, at 11:43 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Sometimes a good old for loop performs best, even if it doesn't look sexy:
>>
>>
>
> Fair enough, but a vectorized solution beats them all (see below).
>
> Also,
>
> [SNIP]
>
>
>> # Charles
>> ans1b <- function( a, b )
>> {
>
> The lapply you put here was from Eric's solution:
>
>>  xxx <- lapply( seq.int( nrow( A ) )
>>               , function( i ) {
>>                    A[ i, ] %o% B[ i, ]
>>                 }
>
>
> This is what I had in mind:
>
> ans1b.corrected <- function( a, b ) {
>  yyy <- sapply( seq.int( nrow( a ) )
>                 , function( i ) a[ i, ] %o% b[ i, ]
>                 , simplify = "array"
>  )
>  zzz <- aperm( yyy, c( 3, 1, 2 ) )
>  zzz
> }
>
> On my system it is slower than a for loop but a lot faster than your benchmark showed with the superfluous code from Eric's solution.
>
> For speed, a vectorized solution is faster than a for loop by a factor of 3 on my laptop:
>
> ans0 <- function(A,B){
>  nca <- ncol(A)
>  ncb <- ncol(B)
>  j.index <- rep(1:nca, times = ncb)
>  k.index <- rep(1:nca, each = ncb)
>  res <- array(A[, j.index] * B[, k.index], c(nrow(A), nca, ncb))
>  res
>  }
>
>
>> microbenchmark(
> +   res0 <- ans0(A, B),
> +   res1 <- ans1(A, B),
> +   res1b <- ans1b.corrected(A, B),
> +   res2 <- ans2(A, B),
> +   res3 <- ans3(A, B)
> + )
> Unit: microseconds
>                           expr     min       lq      mean   median       uq     max neval   cld
>             res0 <- ans0(A, B)  13.281  18.4960  21.52723  19.9905  23.4750  61.556   100 a
>             res1 <- ans1(A, B) 353.121 369.8635 409.77788 381.5840 444.3290 701.256   100     e
> res1b <- ans1b.corrected(A, B)  82.816  89.4185 101.52321  95.4275 107.1700 217.357   100   c
>             res2 <- ans2(A, B)  49.674  54.4825  61.78278  58.7540  65.5265 172.625   100  b
>             res3 <- ans3(A, B) 317.772 342.4220 392.25065 360.4675 436.2125 602.346   100    d
>>
>
>
> FWIW, if there are dimnames on A and B, sapply( row names(A), ..., simplify="array") preserves them without further ado.
>
> Chuck
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From ccberry @end|ng |rom uc@d@edu  Sat Aug  4 21:59:45 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Sat, 4 Aug 2018 19:59:45 +0000
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <alpine.BSF.2.00.1808041249340.89457@pedal.dcn.davis.ca.us>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
 <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
 <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>
 <alpine.BSF.2.00.1808041249340.89457@pedal.dcn.davis.ca.us>
Message-ID: <32F4EDE4-FE5D-4AF0-8FDF-8281A7F67401@ucsd.edu>



> On Aug 4, 2018, at 12:59 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
...

> Slick work on the vectorizing, but for the future reference it was slightly buggy:
> 

Thanks for catching that!

Chuck



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  5 01:21:17 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 5 Aug 2018 11:21:17 +1200
Subject: [R] [FORGED] Re:  A slightly unorthodox matrix product.
In-Reply-To: <32F4EDE4-FE5D-4AF0-8FDF-8281A7F67401@ucsd.edu>
References: <e0073e07-31b3-20df-c20d-6c565c857554@auckland.ac.nz>
 <CAGgJW74L4wJxym5MPz0ZmK5BoXuw1yqnOuJ5y1vm=3XzJhJ-7w@mail.gmail.com>
 <55D898C9-B89E-4BB9-899E-C6E1B04AEA99@ucsd.edu>
 <alpine.BSF.2.00.1808041139080.89457@pedal.dcn.davis.ca.us>
 <F34AD066-6D0B-4F81-8F13-51046CFB78C4@ucsd.edu>
 <alpine.BSF.2.00.1808041249340.89457@pedal.dcn.davis.ca.us>
 <32F4EDE4-FE5D-4AF0-8FDF-8281A7F67401@ucsd.edu>
Message-ID: <f95a5ac9-19a6-3159-e414-aa38a7b2bddc@auckland.ac.nz>



Thanks to Eric Berger, Jeff Newmiller and Chuck Berry for their help 
with this.  Thanks especially to Eric for catching the bugs in my 
proposed solution.  I can *never* keep the indexing straight in 
multidimensional arrays!  It's tough being a <expletive deleted>-wit!

I wouldn't have figured out the "ans0b" solution in a million years.

Thanks again.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  5 07:23:40 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 5 Aug 2018 17:23:40 +1200
Subject: [R] A slightly unorthodox matrix product.
In-Reply-To: <CABoW5_Vusxxr=Fxtq7qcA-BwDB_70fm1s3NzvxRO_bgWkk66hg@mail.gmail.com>
References: <CABoW5_Vusxxr=Fxtq7qcA-BwDB_70fm1s3NzvxRO_bgWkk66hg@mail.gmail.com>
Message-ID: <3f5166d9-4ae6-99fd-aede-b2f5c3d2632c@auckland.ac.nz>

On 05/08/18 16:41, Thomas Jagger wrote:
>  > Date: Sat, 4 Aug 2018 17:52:37 +1200
>  >
>  > From: Rolf Turner <r.turner at auckland.ac.nz 
> <mailto:r.turner at auckland.ac.nz>>
>  > To: r-help <r-help at r-project.org <mailto:r-help at r-project.org>>
>  > Subject: [R] A slightly unorthodox matrix product.
>  > Message-ID: <e0073e07-31b3-20df-c20d-6c565c857554 at auckland.ac.nz 
> <mailto:e0073e07-31b3-20df-c20d-6c565c857554 at auckland.ac.nz>>
>  > Content-Type: text/plain; charset="utf-8"; Format="flowed"
>  >
>  >
>  > Can anyone think of a sexy way of forming following "product"?
>  >
>  > Given matrices A and B, both with m rows, form a 3 dimensional array C
>  > such that:
>  >
>  > ? ? ?C[i,j,k] = A[i,j]*B[i,k]
>  >
>  > I *think* that the following does what I want. ?(I keep confusing
>  > myself, so I'm not sure!)
>  >
>  > library(abind)
>  > xxx <- lapply(1:nrow(a),function(i,a,b){a[i,]%o%b[i,]},a=A,b=B)
>  > do.call(abind,c(xxx,list(along=3)))
>  >
>  > Is there a cleverer way?
>  >
>  > cheers,
>  >
>  > Rolf Turner
>  >
>  > --
>  > Technical Editor ANZJS
>  > Department of Statistics
>  > University of Auckland
>  > Phone: +64-9-373-7599 ext. 88276
> 
> Dear Rolf,
> Try the following:
> 
> B<-matrix(1:12,3,4)
> 
> C<-as.vector(A[,rep(seq(ncol(A)),ncol(B))])*as.vector(B[,rep(seq(ncol(B)),each=ncol(A))])
> dim(C) <- c(nrow(A),ncol(A),ncol(B))
> 
> #test it on column 2 should return true
> all(C[,,2]==A*B[,rep(2,ncol(A))])
> #on all columns (sapply returns 9 rows with 3 columns all values are TRUE)
> 
> all( sapply(seq(ncol(C)),function(i) (C[,,i]==A*B[,rep(i,ncol(A))]) ) )
> 
> Note that it creates the final array by taking advantage of the 
> column-major ordering in R.
> Initially, we create a vector by multiplying elementwise the 2 vectors 
> internally associated with each matrix,
> finally,? we generate our? 3D array by adding the dimensions attribute, 
> a vector of 3? elements.
> 
> This method should be fairly fast since we are using internal R matrix 
> addressing, and not multiple function calls required by lapply ().
> I hope this helps

Neat, and much better than anything I could have thought of.  However
microbenchmark() indicates that the Chuck Berry/Jeff Newmiller solution 
is about twice as fast.  Not that this speed difference is Any Big Deal, 
but.

Thanks for taking an interest in this obscure query of mine.

cheers,

Rolf
-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From thj@gger @end|ng |rom gm@||@com  Sun Aug  5 06:41:22 2018
From: thj@gger @end|ng |rom gm@||@com (Thomas Jagger)
Date: Sat, 4 Aug 2018 22:41:22 -0600
Subject: [R] A slightly unorthodox matrix product.
Message-ID: <CABoW5_Vusxxr=Fxtq7qcA-BwDB_70fm1s3NzvxRO_bgWkk66hg@mail.gmail.com>

> Date: Sat, 4 Aug 2018 17:52:37 +1200
>
> From: Rolf Turner <r.turner at auckland.ac.nz>
> To: r-help <r-help at r-project.org>
> Subject: [R] A slightly unorthodox matrix product.
> Message-ID: <e0073e07-31b3-20df-c20d-6c565c857554 at auckland.ac.nz>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
>
> Can anyone think of a sexy way of forming following "product"?
>
> Given matrices A and B, both with m rows, form a 3 dimensional array C
> such that:
>
>      C[i,j,k] = A[i,j]*B[i,k]
>
> I *think* that the following does what I want.  (I keep confusing
> myself, so I'm not sure!)
>
> library(abind)
> xxx <- lapply(1:nrow(a),function(i,a,b){a[i,]%o%b[i,]},a=A,b=B)
> do.call(abind,c(xxx,list(along=3)))
>
> Is there a cleverer way?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276

Dear Rolf,
Try the following:

B<-matrix(1:12,3,4)

C<-as.vector(A[,rep(seq(ncol(A)),ncol(B))])*as.vector(B[,rep(seq(ncol(B)),each=ncol(A))])
dim(C) <- c(nrow(A),ncol(A),ncol(B))

#test it on column 2 should return true
all(C[,,2]==A*B[,rep(2,ncol(A))])
#on all columns (sapply returns 9 rows with 3 columns all values are TRUE)

all( sapply(seq(ncol(C)),function(i) (C[,,i]==A*B[,rep(i,ncol(A))]) ) )

Note that it creates the final array by taking advantage of the
column-major ordering in R.
Initially, we create a vector by multiplying elementwise the 2 vectors
internally associated with each matrix,
finally,  we generate our  3D array by adding the dimensions attribute, a
vector of 3  elements.

This method should be fairly fast since we are using internal R matrix
addressing, and not multiple function calls required by lapply ().
I hope this helps
Thomas Jagger

	[[alternative HTML version deleted]]



From j@zh@o @end|ng |rom ye@h@net  Sun Aug  5 14:36:21 2018
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Sun, 5 Aug 2018 20:36:21 +0800 (CST)
Subject: [R] MASS::boxcox "object not found"
Message-ID: <6ed54e57.1067.1650a16a89d.Coremail.jszhao@yeah.net>

Hi there,

I wrote a function that wraps MASS::boxcox as:

bc <- function(vec) {
   lam <- boxcox(lm(vec ~ 1))
   lam <- lam$x[which.max(lam$y)]
   (vec^lam - 1)/lam
}

When I invoke it as:

> x <- runif(20)
> bc(x)
Error in eval(predvars, data, env) : object 'vec' not found

I have googled, and rewrote the above function as:

bc <- function(vec) {
   dat <<- data.frame(vec = vec)
   lam <- boxcox(lm(vec ~ 1, dat))
   lam <- lam$x[which.max(lam$y)]
   rm(dat, envir = .GlobalEnv)
   (vec^lam - 1)/lam
}

It works. But, I am wondering why MASS::boxcox have to wrap in such way that have to use the data in .GlobalEnv.

Best,
Jinsong
	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sun Aug  5 15:04:12 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 5 Aug 2018 18:34:12 +0530
Subject: [R] Adding % sign to ticks in persp()
Message-ID: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>

Hi,

Is there any way to add styles to the tick marks in persp() function?

For eample I want to add '%' suffix to the z-axis tick marks.in below plot :

x <- seq(-10, 10, length= 30)
y <- x
f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
z <- outer(x, y, f)
z[is.na(z)] <- 1
op <- par(bg = "white")
persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
ticktype = "detailed")

	[[alternative HTML version deleted]]



From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Sun Aug  5 23:24:17 2018
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Mon, 6 Aug 2018 09:24:17 +1200
Subject: [R] [FORGED]  Adding % sign to ticks in persp()
In-Reply-To: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>
References: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>
Message-ID: <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>

Hi

Not in the persp() function itself, but the following code converts the 
persp() output to 'grid' output then modifies the labels to add 
percentage signs ...

x <- seq(-10, 10, length= 30)
y <- x
f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
z <- outer(x, y, f)
z[is.na(z)] <- 1
op <- par(bg = "white")
persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
       ticktype = "detailed")

library(gridGraphics)
grid.echo()
labelGrobs <- grid.grep("z-axis-labels", grep=TRUE, global=TRUE)
addPercent <- function(x) {
     lab <- grid.get(x)
     grid.edit(x, label=paste0(lab$label, "%"), redraw=FALSE)
}
lapply(labelGrobs, addPercent)
grid.refresh()

... is that what you meant?  The positioning of the labels relative to 
the tick marks is imperfect and could perhaps be improved by also 
editing the 'cex' for the labels, but hopefully this gets close enough 
to be useful.

Paul

On 06/08/18 01:04, Christofer Bogaso wrote:
> Hi,
> 
> Is there any way to add styles to the tick marks in persp() function?
> 
> For eample I want to add '%' suffix to the z-axis tick marks.in below plot :
> 
> x <- seq(-10, 10, length= 30)
> y <- x
> f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
> z <- outer(x, y, f)
> z[is.na(z)] <- 1
> op <- par(bg = "white")
> persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
> ticktype = "detailed")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From du|c@|m@ @end|ng |rom b|gpond@com  Mon Aug  6 06:29:07 2018
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Mon, 6 Aug 2018 14:29:07 +1000
Subject: [R] 
 Perform GEE regression in R with multiple dependent variables
In-Reply-To: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
References: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
Message-ID: <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>

Hi

Please read the geepack manual carefully.
GEE ordinal regression is not simple.
You need to format your data and do not use sample as a storage name. It is
the name of a function

dta is storage
dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal))
 
m0 <-
ordgee(Ideo_Ordinal ~ Machiavellianism+Psychopathy+Narcissism ,data = dta,
id = Country_ID,
       corstr = "independence")

You need to see if the model is appropriate first and whether the sandwich
errors are right before you go further

If this is your data you may not get credible results.
You need to read up on the requirements of GEEs and  ordinal GEEs in
particular
There are a number of packages with different data requirements and methods 
If you have repeated measurements   repolr; ?multgee (just from memory)
Small sample sizes are a problem there are a number of packages dealing with
this but you will have to see which is best for you
Many do not offer a method for ordinal or multinomial GEE.
One further question to ask  population specific or subject specific  ie to
GEE or not to GEE


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of euthymios
kasvikis
Sent: Saturday, 4 August 2018 07:30
To: r-help at r-project.org
Subject: [R] Perform GEE regression in R with multiple dependent variables

Im trying to perform generalized estimating equation (GEE) on the (sample)
dataset below with R and I would like some little guidance. First of all I
will describe my dataset. As you can see below it includes 5 variables.
Country_ID shows the country of the politician, Ideo_Ordinal his poltical
belief from 1 to 7 (far left to far right). Then we have measurements
regarding three characteristics. I would like to run an analysis based on
the country and the political beliefs of every politician (dependent
variables) in relation with the 3 characteristics. I have used the geepack
package using:

library(geepack)

        samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
sample$Ideo_Ordinal,
                                       corstr = "independence"))) %>%
          rownames_to_column() %>%
          mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
                 upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
                 df=1,
                 ExpBeta = exp(Estimate)) %>%       # Transformed estimate
          mutate(lWald=exp(lowerWald),              # Upper transformed
                 uWald=exp(upperWald))              # Lower transformed
        samplem

I would like to know if it is valid to add in this method the Country_ID
simultaneously with Ideo_Ordinal and how to do it.

Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
    3             1            3      0.250895132  0.155238716  0.128683755
    5             1            3     -0.117725000 -0.336256435 -0.203137879
    7             1            3      0.269509029 -0.260728261  0.086819555
    9             1            6      0.108873496  0.175528190  0.182884928
    14            1            3      0.173129951  0.054468468  0.155030794
    15            1            6     -0.312088872 -0.414358301 -0.212599946
    17            1            3     -0.297647658 -0.096523143 -0.228533352
    18            1            3     -0.020389157 -0.210180866 -0.046687695
    20            1            3     -0.523432382 -0.125114982 -0.431070629
    21            1            1      0.040304508  0.022743463  0.233657881
    22            1            3      0.253695988 -0.330825166  0.101122320
    23            1            3     -0.478673895 -0.421801231 -0.422894791
    27            1            6     -0.040856419 -0.566728704 -0.136069484
    28            1            3      0.240040249 -0.398404825  0.135603114
    29            1            6     -0.207631653 -0.005347621 -0.294935155
    30            1            3      0.458042533  0.462935386  0.586244831
    31            1            3     -0.259850232 -0.233074787 -0.092249465
    33            1            3      0.002164223 -0.637668706 -0.267158031
    34            1            6      0.050991955 -0.098030021 -0.043826848
    36            1            3     -0.338052871 -0.168894328 -0.230198200
    38            1            3      0.174382347  0.023807812  0.192963609
    41            2            3     -0.227322148 -0.010016330 -0.095576329
    42            2            3     -0.267514920  0.066108837 -0.218979873
    43            2            3      0.421277754  0.385223920  0.421274111
    44            2            3     -0.399592341 -0.498154998 -0.320402699
    45            2            1      0.162038344  0.328116118  0.104105963
    47            2            3     -0.080755709  0.003080287 -0.043568723
    48            2            3      0.059474124 -0.447305420  0.003988071
    49            2            3     -0.219773040 -0.312902659 -0.239057883
    51            2            3      0.438659431  0.364042111  0.393014172
    52            2            3     -0.088560903 -0.490889275 -0.006041054
    53            2            3     -0.122612591  0.074438944  0.103722836
    54            2            3     -0.450586055 -0.304253061 -0.132365179
    55            2            6     -0.710545197 -0.451329850 -0.764201786
    56            2            3      0.330718447  0.335460128  0.429173481
    57            2            3      0.442508023  0.297522144  0.407155726
    60            2            3      0.060797815 -0.096516876 -0.012802977
    61            2            3     -0.250757764 -0.113219864 -0.215345379
    62            2            1      0.153654345 -0.089615287  0.118626045
    65            2            3      0.042969508 -0.486999608 -0.080829636
    66            3            3      0.158337022  0.208229002  0.241607154
    67            3            3      0.220237408  0.397914524  0.262207709
    69            3            3      0.200558577  0.244419633  0.301732113
    71            3            3      0.690244689  0.772692418  0.625921098
    72            3            3      0.189810070  0.377774321  0.293988340
    73            3            3     -0.385724422 -0.262131032 -0.373159652
    74            3            3     -0.124095769 -0.109816334 -0.127157915
    75            3            1      0.173299879  0.453592671  0.325357383
    76            3            3     -0.598215129 -0.643286651 -0.423824759
    77            3            3     -0.420558406 -0.361763025 -0.465612116
    78            3            3     -0.176788569 -0.305506924 -0.203730879
    80            3            3     -0.114790731  0.262392918  0.061382073
    81            3            3     -0.274904173 -0.342603918 -0.302761994
    82            3            3     -0.146902101 -0.059558818 -0.120550957
    84            3            3      0.038303792 -0.139833875  0.170005914
    85            3            3     -0.220212221 -0.541399757 -0.555201764
    87            3            3      0.255300386  0.179484246  0.421428096
    88            3            6     -0.548823069 -0.405541620 -0.322935805

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Aug  6 07:33:59 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 6 Aug 2018 11:03:59 +0530
Subject: [R] [FORGED]  Adding % sign to ticks in persp()
In-Reply-To: <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>
References: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>
 <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>
Message-ID: <CA+dpOJkjLvr1G5SjGWsWe4-TZWDoOD9qsjUyUPznMQW==wBDrQ@mail.gmail.com>

Awesome, thanks!

On Mon, Aug 6, 2018 at 2:54 AM Paul Murrell <paul at stat.auckland.ac.nz>
wrote:

> Hi
>
> Not in the persp() function itself, but the following code converts the
> persp() output to 'grid' output then modifies the labels to add
> percentage signs ...
>
> x <- seq(-10, 10, length= 30)
> y <- x
> f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
> z <- outer(x, y, f)
> z[is.na(z)] <- 1
> op <- par(bg = "white")
> persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
>        ticktype = "detailed")
>
> library(gridGraphics)
> grid.echo()
> labelGrobs <- grid.grep("z-axis-labels", grep=TRUE, global=TRUE)
> addPercent <- function(x) {
>      lab <- grid.get(x)
>      grid.edit(x, label=paste0(lab$label, "%"), redraw=FALSE)
> }
> lapply(labelGrobs, addPercent)
> grid.refresh()
>
> ... is that what you meant?  The positioning of the labels relative to
> the tick marks is imperfect and could perhaps be improved by also
> editing the 'cex' for the labels, but hopefully this gets close enough
> to be useful.
>
> Paul
>
> On 06/08/18 01:04, Christofer Bogaso wrote:
> > Hi,
> >
> > Is there any way to add styles to the tick marks in persp() function?
> >
> > For eample I want to add '%' suffix to the z-axis tick marks.in below
> plot :
> >
> > x <- seq(-10, 10, length= 30)
> > y <- x
> > f <- function(x, y) { r <- sqrt(x^2+y^2); 10 * sin(r)/r }
> > z <- outer(x, y, f)
> > z[is.na(z)] <- 1
> > op <- par(bg = "white")
> > persp(x, y, z, theta = 30, phi = 30, expand = 0.5, col = "lightblue",
> > ticktype = "detailed")
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>

	[[alternative HTML version deleted]]



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Mon Aug  6 11:02:23 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Mon, 6 Aug 2018 12:02:23 +0300
Subject: [R] loop over matrix: subscript out of bounds
Message-ID: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>

I have a basic for loop with a simple matrix. The code is doing what it is
supposed to do, but I'm still wondering the error "subscript out of
bounds". What would be a smoother way to code such a basic for loop?

myMatrix <- matrix(0,5,12)
for(i in 1:nrow(myMatrix)) {
  for(i in 1:ncol(myMatrix)) {
    myMatrix[i,i] = -1
    myMatrix[i,i+1] = 1
}}
print(myMatrix)

Thanks in advance!

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Mon Aug  6 11:24:14 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 6 Aug 2018 12:24:14 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
Message-ID: <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>

Both loops are on 'i', which is a bad idea. :-)
Also myMatrix[i,i+1] will be out-of-bounds if i = ncol(myMatrix)


On Mon, Aug 6, 2018 at 12:02 PM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
wrote:

> I have a basic for loop with a simple matrix. The code is doing what it is
> supposed to do, but I'm still wondering the error "subscript out of
> bounds". What would be a smoother way to code such a basic for loop?
>
> myMatrix <- matrix(0,5,12)
> for(i in 1:nrow(myMatrix)) {
>   for(i in 1:ncol(myMatrix)) {
>     myMatrix[i,i] = -1
>     myMatrix[i,i+1] = 1
> }}
> print(myMatrix)
>
> Thanks in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From e@ @end|ng |rom enr|co@chum@nn@net  Mon Aug  6 13:23:48 2018
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Mon, 06 Aug 2018 13:23:48 +0200
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
Message-ID: <20180806132348.Horde.Lrxdz_1YNo5hSjZmHWsQWi-@webmail.your-server.de>


Quoting Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>:

> I have a basic for loop with a simple matrix. The code is doing what it is
> supposed to do, but I'm still wondering the error "subscript out of
> bounds". What would be a smoother way to code such a basic for loop?
>
> myMatrix <- matrix(0,5,12)
> for(i in 1:nrow(myMatrix)) {
>   for(i in 1:ncol(myMatrix)) {
>     myMatrix[i,i] = -1
>     myMatrix[i,i+1] = 1
> }}
> print(myMatrix)
>
> Thanks in advance!
>

Perhaps you do not need loops at all?

     myMatrix <- matrix(0, 5, 12)
     diag(myMatrix) <- -1
     diag(myMatrix[, -1]) <- 1

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  6 12:58:44 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 6 Aug 2018 11:58:44 +0100
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
Message-ID: <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>

Hello,

Eric is right but...

You have two assignments. The second sets a value that will be 
overwritten is the next iteration by myMatrix[i,i] = -1 when 'i' becomes 
the next value.

If you fix the second index and use 'j', you might as well do

myMatrix[] = -1
myMatrix[, ncol(myMatrix)] = 1

Hope this helps,

Rui Barradas

?s 10:24 de 06/08/2018, Eric Berger escreveu:
> Both loops are on 'i', which is a bad idea. :-)
> Also myMatrix[i,i+1] will be out-of-bounds if i = ncol(myMatrix)
> 
> 
> On Mon, Aug 6, 2018 at 12:02 PM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> wrote:
> 
>> I have a basic for loop with a simple matrix. The code is doing what it is
>> supposed to do, but I'm still wondering the error "subscript out of
>> bounds". What would be a smoother way to code such a basic for loop?
>>
>> myMatrix <- matrix(0,5,12)
>> for(i in 1:nrow(myMatrix)) {
>>    for(i in 1:ncol(myMatrix)) {
>>      myMatrix[i,i] = -1
>>      myMatrix[i,i+1] = 1
>> }}
>> print(myMatrix)
>>
>> Thanks in advance!
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From euthym|o@@k@k@@v|k|@ @end|ng |rom gm@||@com  Mon Aug  6 17:00:30 2018
From: euthym|o@@k@k@@v|k|@ @end|ng |rom gm@||@com (euthymios kasvikis)
Date: Mon, 6 Aug 2018 18:00:30 +0300
Subject: [R] 
 Perform GEE regression in R with multiple dependent variables
In-Reply-To: <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>
References: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
 <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>
Message-ID: <CABNxSU2d0hwv+vN8YuecS3TPvhA--_hF+R_bv+MGmBYGKSYp6g@mail.gmail.com>

First of all thanks for your advice. So suppose that I would like to use
the multgee package. The model would be like:
library(multgee)
fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism,
data=RightWomen,
                    id= ordered(factor(Country_ID)))
summary(fitord)

???? ???, 6 ??? 2018 ???? 7:29 ?.?., ?/? Duncan Mackay <dulcalma at bigpond.com>
??????:

> Hi
>
> Please read the geepack manual carefully.
> GEE ordinal regression is not simple.
> You need to format your data and do not use sample as a storage name. It is
> the name of a function
>
> dta is storage
> dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal))
>
> m0 <-
> ordgee(Ideo_Ordinal ~ Machiavellianism+Psychopathy+Narcissism ,data = dta,
> id = Country_ID,
>        corstr = "independence")
>
> You need to see if the model is appropriate first and whether the sandwich
> errors are right before you go further
>
> If this is your data you may not get credible results.
> You need to read up on the requirements of GEEs and  ordinal GEEs in
> particular
> There are a number of packages with different data requirements and
> methods
> If you have repeated measurements   repolr; ?multgee (just from memory)
> Small sample sizes are a problem there are a number of packages dealing
> with
> this but you will have to see which is best for you
> Many do not offer a method for ordinal or multinomial GEE.
> One further question to ask  population specific or subject specific  ie to
> GEE or not to GEE
>
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2350
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of euthymios
> kasvikis
> Sent: Saturday, 4 August 2018 07:30
> To: r-help at r-project.org
> Subject: [R] Perform GEE regression in R with multiple dependent variables
>
> Im trying to perform generalized estimating equation (GEE) on the (sample)
> dataset below with R and I would like some little guidance. First of all I
> will describe my dataset. As you can see below it includes 5 variables.
> Country_ID shows the country of the politician, Ideo_Ordinal his poltical
> belief from 1 to 7 (far left to far right). Then we have measurements
> regarding three characteristics. I would like to run an analysis based on
> the country and the political beliefs of every politician (dependent
> variables) in relation with the 3 characteristics. I have used the geepack
> package using:
>
> library(geepack)
>
>         samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
> ~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
> sample$Ideo_Ordinal,
>                                        corstr = "independence"))) %>%
>           rownames_to_column() %>%
>           mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
>                  upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
>                  df=1,
>                  ExpBeta = exp(Estimate)) %>%       # Transformed estimate
>           mutate(lWald=exp(lowerWald),              # Upper transformed
>                  uWald=exp(upperWald))              # Lower transformed
>         samplem
>
> I would like to know if it is valid to add in this method the Country_ID
> simultaneously with Ideo_Ordinal and how to do it.
>
> Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
>     3             1            3      0.250895132  0.155238716  0.128683755
>     5             1            3     -0.117725000 -0.336256435 -0.203137879
>     7             1            3      0.269509029 -0.260728261  0.086819555
>     9             1            6      0.108873496  0.175528190  0.182884928
>     14            1            3      0.173129951  0.054468468  0.155030794
>     15            1            6     -0.312088872 -0.414358301 -0.212599946
>     17            1            3     -0.297647658 -0.096523143 -0.228533352
>     18            1            3     -0.020389157 -0.210180866 -0.046687695
>     20            1            3     -0.523432382 -0.125114982 -0.431070629
>     21            1            1      0.040304508  0.022743463  0.233657881
>     22            1            3      0.253695988 -0.330825166  0.101122320
>     23            1            3     -0.478673895 -0.421801231 -0.422894791
>     27            1            6     -0.040856419 -0.566728704 -0.136069484
>     28            1            3      0.240040249 -0.398404825  0.135603114
>     29            1            6     -0.207631653 -0.005347621 -0.294935155
>     30            1            3      0.458042533  0.462935386  0.586244831
>     31            1            3     -0.259850232 -0.233074787 -0.092249465
>     33            1            3      0.002164223 -0.637668706 -0.267158031
>     34            1            6      0.050991955 -0.098030021 -0.043826848
>     36            1            3     -0.338052871 -0.168894328 -0.230198200
>     38            1            3      0.174382347  0.023807812  0.192963609
>     41            2            3     -0.227322148 -0.010016330 -0.095576329
>     42            2            3     -0.267514920  0.066108837 -0.218979873
>     43            2            3      0.421277754  0.385223920  0.421274111
>     44            2            3     -0.399592341 -0.498154998 -0.320402699
>     45            2            1      0.162038344  0.328116118  0.104105963
>     47            2            3     -0.080755709  0.003080287 -0.043568723
>     48            2            3      0.059474124 -0.447305420  0.003988071
>     49            2            3     -0.219773040 -0.312902659 -0.239057883
>     51            2            3      0.438659431  0.364042111  0.393014172
>     52            2            3     -0.088560903 -0.490889275 -0.006041054
>     53            2            3     -0.122612591  0.074438944  0.103722836
>     54            2            3     -0.450586055 -0.304253061 -0.132365179
>     55            2            6     -0.710545197 -0.451329850 -0.764201786
>     56            2            3      0.330718447  0.335460128  0.429173481
>     57            2            3      0.442508023  0.297522144  0.407155726
>     60            2            3      0.060797815 -0.096516876 -0.012802977
>     61            2            3     -0.250757764 -0.113219864 -0.215345379
>     62            2            1      0.153654345 -0.089615287  0.118626045
>     65            2            3      0.042969508 -0.486999608 -0.080829636
>     66            3            3      0.158337022  0.208229002  0.241607154
>     67            3            3      0.220237408  0.397914524  0.262207709
>     69            3            3      0.200558577  0.244419633  0.301732113
>     71            3            3      0.690244689  0.772692418  0.625921098
>     72            3            3      0.189810070  0.377774321  0.293988340
>     73            3            3     -0.385724422 -0.262131032 -0.373159652
>     74            3            3     -0.124095769 -0.109816334 -0.127157915
>     75            3            1      0.173299879  0.453592671  0.325357383
>     76            3            3     -0.598215129 -0.643286651 -0.423824759
>     77            3            3     -0.420558406 -0.361763025 -0.465612116
>     78            3            3     -0.176788569 -0.305506924 -0.203730879
>     80            3            3     -0.114790731  0.262392918  0.061382073
>     81            3            3     -0.274904173 -0.342603918 -0.302761994
>     82            3            3     -0.146902101 -0.059558818 -0.120550957
>     84            3            3      0.038303792 -0.139833875  0.170005914
>     85            3            3     -0.220212221 -0.541399757 -0.555201764
>     87            3            3      0.255300386  0.179484246  0.421428096
>     88            3            6     -0.548823069 -0.405541620 -0.322935805
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From S@E|||@on @end|ng |rom LGCGroup@com  Mon Aug  6 17:18:18 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Mon, 6 Aug 2018 15:18:18 +0000
Subject: [R] [FORGED]  Adding % sign to ticks in persp()
In-Reply-To: <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>
References: <CA+dpOJmMTe+8CbB-z+OZ4uedu-gFxDBF6rA1wmcpQ-Ynd6xkcA@mail.gmail.com>
 <60bec249-747d-c393-a4e8-1386964f80c4@stat.auckland.ac.nz>
Message-ID: <3fe0f752751a4edb8bc1ec423268dde2@GBDCVPEXC08.corp.lgc-group.com>

Another possible approach, using the transformation returned by persp() to locate axes explicitly and using base graphics to place labels etc, is given at 
http://entrenchant.blogspot.com/2014/03/custom-tick-labels-in-r-perspective.html


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Murrell
> Sent: 05 August 2018 22:24
> To: Christofer Bogaso; r-help
> Subject: Re: [R] [FORGED] Adding % sign to ticks in persp()
> 
> Hi
> 
> Not in the persp() function itself, but the following code converts the
> persp() output to 'grid' output then modifies the labels to add
> percentage signs ...
> 


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From B|||@Po||ng @end|ng |rom ze||@@com  Mon Aug  6 17:31:44 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Mon, 6 Aug 2018 15:31:44 +0000
Subject: [R] help with read function in Azure Data Lake Remote environment
Message-ID: <CY1PR0201MB18346E3267AB8466D6CA0BD0EA200@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi,

Locally I am using windows:
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Locally on my laptop using RStudio I normally set my working directory and read in my csv files.

setwd("C:/WHP/Appeals")

getwd()#-----------------------------Check to verify

read.csv("WHP_EditAppealRev_Tmp V1.csv",nrows=1, head=FALSE)#N=61 columns

appdf1 <- fread("WHP_EditAppealRev_Tmp V1.csv",select=c(5,9,10,11,14,15,16,17,18,25,31,28,32,42,45,46,47,48,49,53,54,58,59,61),header=TRUE, stringsAsFactors=TRUE)

This all works fine locally.

Now I am working in RStudio in a Remote desk top AZURE Data Lake environment (DSVM) however the remote file path out there is does not appear to be that different.

Remotley I am using windows:
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows Server >= 2012 x64 (build 9200)

setwd("C:/Users/sysAdmin/Documents/WHP/NJDemo082018")
getwd()#-----------------------------Check to verify

The directory gets set but the csv does not get read for some reason?

read.csv("C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv",nrows=1, head=FALSE)#N= columns
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv': No such file or directory

demo1 <- fread("C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv",select=c(1,2,3),header=TRUE, stringsAsFactors=TRUE)
Error in fread("C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv",  :
  File 'C:/Users/sysAdmin/Documents/WHP/NJDemo082018/TestDemoV1.csv' does not exist; getwd()=='C:/Users/sysAdmin/Documents/WHP/NJDemo082018'.
Include correct full path, or one or more spaces to consider the input a system command.

I have tried moving the csv file further forward to the root C: but still no luck?

read.csv("C:/TestDemoV1.csv",nrows=1, head=FALSE)#N= columns
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'C:/TestDemoV1.csv': No such file or directory


Any suggestions would be appreciated, thank you.

WHP


Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug  6 19:26:17 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 6 Aug 2018 10:26:17 -0700 (PDT)
Subject: [R] MASS::boxcox "object not found"
In-Reply-To: <6ed54e57.1067.1650a16a89d.Coremail.jszhao@yeah.net>
References: <6ed54e57.1067.1650a16a89d.Coremail.jszhao@yeah.net>
Message-ID: <alpine.BSF.2.00.1808061011230.91548@pedal.dcn.davis.ca.us>

It is rarely a good idea to invoke lm without providing the inputs in a 
data frame through the data argument. In this case, just making that 
change is insufficient though... the boxcox.lm function calls the update 
function, which re-retreives the data in a new context. The workaround is 
to supply the data= argument to boxplot which will pass it on to the 
update function to keep the data visible in the updated lm model.  None of 
this seemed obvious to me from the boxplot help, but I think I would 
regard using the data= argument to boxplot as being about as essential as 
it is in lm, because the alternative is to assume that all the data are 
as-named in the global environment (x is different than vec).

#######
library(MASS)
bc <- function(vec) {
    dta <- data.frame( vec = vec ) # Rarely a good idea to call "lm"
                                   # without the data argument.
    model <- lm( vec ~ 1, data = dta )
    lam <- boxcox( model, data=dta )
    lam <- lam$x[which.max(lam$y)]
    (vec^lam - 1)/lam
}
x <- runif(20)
bc(x)

#' ![](https://i.imgur.com/lhKymfQ.png)

#'     #>  [1] -0.92115159 -0.21776512 -1.20946708 -0.16700312 -0.76096811
#'     #>  [6] -0.12208801 -0.61723623 -0.78302973 -0.62455538 -1.40636663
#'     #> [11] -0.52627869 -0.09377700 -1.02867887 -0.68288810 -0.93872856
#'     #> [16] -0.17005783 -0.01754519 -0.83549564 -0.35399612 -1.34878425

#' Created on 2018-08-06 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).

#######

On Sun, 5 Aug 2018, Jinsong Zhao wrote:

> Hi there,
>
> I wrote a function that wraps MASS::boxcox as:
>
> bc <- function(vec) {
>   lam <- boxcox(lm(vec ~ 1))
>   lam <- lam$x[which.max(lam$y)]
>   (vec^lam - 1)/lam
> }
>
> When I invoke it as:
>
>> x <- runif(20)
>> bc(x)
> Error in eval(predvars, data, env) : object 'vec' not found
>
> I have googled, and rewrote the above function as:
>
> bc <- function(vec) {
>   dat <<- data.frame(vec = vec)
>   lam <- boxcox(lm(vec ~ 1, dat))
>   lam <- lam$x[which.max(lam$y)]
>   rm(dat, envir = .GlobalEnv)
>   (vec^lam - 1)/lam
> }
>
> It works. But, I am wondering why MASS::boxcox have to wrap in such way that have to use the data in .GlobalEnv.
>
> Best,
> Jinsong
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From euthym|o@@k@k@@v|k|@ @end|ng |rom gm@||@com  Mon Aug  6 18:21:44 2018
From: euthym|o@@k@k@@v|k|@ @end|ng |rom gm@||@com (euthymios kasvikis)
Date: Mon, 6 Aug 2018 19:21:44 +0300
Subject: [R] 
 Perform GEE regression in R with multiple dependent variables
In-Reply-To: <CABNxSU2d0hwv+vN8YuecS3TPvhA--_hF+R_bv+MGmBYGKSYp6g@mail.gmail.com>
References: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
 <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>
 <CABNxSU2d0hwv+vN8YuecS3TPvhA--_hF+R_bv+MGmBYGKSYp6g@mail.gmail.com>
Message-ID: <CABNxSU0D29NXmAoNzw7gU95+tPFb=XvYA6gYUyNiS6VQ209egQ@mail.gmail.com>

Or
library(multgee)
fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism,
data=RightWomen,
                    id= Politician_ID,repeated=Country_ID)
summary(fitord)

Should I use dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal)) ?


???? ???, 6 ??? 2018 ???? 6:00 ?.?., ?/? euthymios kasvikis <
euthymios.k.kasvikis at gmail.com> ??????:

> First of all thanks for your advice. So suppose that I would like to use
> the multgee package. The model would be like:
> library(multgee)
> fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism,
> data=RightWomen,
>                     id= ordered(factor(Country_ID)))
> summary(fitord)
>
> ???? ???, 6 ??? 2018 ???? 7:29 ?.?., ?/? Duncan Mackay <
> dulcalma at bigpond.com> ??????:
>
>> Hi
>>
>> Please read the geepack manual carefully.
>> GEE ordinal regression is not simple.
>> You need to format your data and do not use sample as a storage name. It
>> is
>> the name of a function
>>
>> dta is storage
>> dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal))
>>
>> m0 <-
>> ordgee(Ideo_Ordinal ~ Machiavellianism+Psychopathy+Narcissism ,data = dta,
>> id = Country_ID,
>>        corstr = "independence")
>>
>> You need to see if the model is appropriate first and whether the sandwich
>> errors are right before you go further
>>
>> If this is your data you may not get credible results.
>> You need to read up on the requirements of GEEs and  ordinal GEEs in
>> particular
>> There are a number of packages with different data requirements and
>> methods
>> If you have repeated measurements   repolr; ?multgee (just from memory)
>> Small sample sizes are a problem there are a number of packages dealing
>> with
>> this but you will have to see which is best for you
>> Many do not offer a method for ordinal or multinomial GEE.
>> One further question to ask  population specific or subject specific  ie
>> to
>> GEE or not to GEE
>>
>>
>> Regards
>>
>> Duncan
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2350
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of euthymios
>> kasvikis
>> Sent: Saturday, 4 August 2018 07:30
>> To: r-help at r-project.org
>> Subject: [R] Perform GEE regression in R with multiple dependent variables
>>
>> Im trying to perform generalized estimating equation (GEE) on the (sample)
>> dataset below with R and I would like some little guidance. First of all I
>> will describe my dataset. As you can see below it includes 5 variables.
>> Country_ID shows the country of the politician, Ideo_Ordinal his poltical
>> belief from 1 to 7 (far left to far right). Then we have measurements
>> regarding three characteristics. I would like to run an analysis based on
>> the country and the political beliefs of every politician (dependent
>> variables) in relation with the 3 characteristics. I have used the geepack
>> package using:
>>
>> library(geepack)
>>
>>         samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
>> ~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
>> sample$Ideo_Ordinal,
>>                                        corstr = "independence"))) %>%
>>           rownames_to_column() %>%
>>           mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
>>                  upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
>>                  df=1,
>>                  ExpBeta = exp(Estimate)) %>%       # Transformed estimate
>>           mutate(lWald=exp(lowerWald),              # Upper transformed
>>                  uWald=exp(upperWald))              # Lower transformed
>>         samplem
>>
>> I would like to know if it is valid to add in this method the Country_ID
>> simultaneously with Ideo_Ordinal and how to do it.
>>
>> Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
>>     3             1            3      0.250895132  0.155238716
>> 0.128683755
>>     5             1            3     -0.117725000 -0.336256435
>> -0.203137879
>>     7             1            3      0.269509029 -0.260728261
>> 0.086819555
>>     9             1            6      0.108873496  0.175528190
>> 0.182884928
>>     14            1            3      0.173129951  0.054468468
>> 0.155030794
>>     15            1            6     -0.312088872 -0.414358301
>> -0.212599946
>>     17            1            3     -0.297647658 -0.096523143
>> -0.228533352
>>     18            1            3     -0.020389157 -0.210180866
>> -0.046687695
>>     20            1            3     -0.523432382 -0.125114982
>> -0.431070629
>>     21            1            1      0.040304508  0.022743463
>> 0.233657881
>>     22            1            3      0.253695988 -0.330825166
>> 0.101122320
>>     23            1            3     -0.478673895 -0.421801231
>> -0.422894791
>>     27            1            6     -0.040856419 -0.566728704
>> -0.136069484
>>     28            1            3      0.240040249 -0.398404825
>> 0.135603114
>>     29            1            6     -0.207631653 -0.005347621
>> -0.294935155
>>     30            1            3      0.458042533  0.462935386
>> 0.586244831
>>     31            1            3     -0.259850232 -0.233074787
>> -0.092249465
>>     33            1            3      0.002164223 -0.637668706
>> -0.267158031
>>     34            1            6      0.050991955 -0.098030021
>> -0.043826848
>>     36            1            3     -0.338052871 -0.168894328
>> -0.230198200
>>     38            1            3      0.174382347  0.023807812
>> 0.192963609
>>     41            2            3     -0.227322148 -0.010016330
>> -0.095576329
>>     42            2            3     -0.267514920  0.066108837
>> -0.218979873
>>     43            2            3      0.421277754  0.385223920
>> 0.421274111
>>     44            2            3     -0.399592341 -0.498154998
>> -0.320402699
>>     45            2            1      0.162038344  0.328116118
>> 0.104105963
>>     47            2            3     -0.080755709  0.003080287
>> -0.043568723
>>     48            2            3      0.059474124 -0.447305420
>> 0.003988071
>>     49            2            3     -0.219773040 -0.312902659
>> -0.239057883
>>     51            2            3      0.438659431  0.364042111
>> 0.393014172
>>     52            2            3     -0.088560903 -0.490889275
>> -0.006041054
>>     53            2            3     -0.122612591  0.074438944
>> 0.103722836
>>     54            2            3     -0.450586055 -0.304253061
>> -0.132365179
>>     55            2            6     -0.710545197 -0.451329850
>> -0.764201786
>>     56            2            3      0.330718447  0.335460128
>> 0.429173481
>>     57            2            3      0.442508023  0.297522144
>> 0.407155726
>>     60            2            3      0.060797815 -0.096516876
>> -0.012802977
>>     61            2            3     -0.250757764 -0.113219864
>> -0.215345379
>>     62            2            1      0.153654345 -0.089615287
>> 0.118626045
>>     65            2            3      0.042969508 -0.486999608
>> -0.080829636
>>     66            3            3      0.158337022  0.208229002
>> 0.241607154
>>     67            3            3      0.220237408  0.397914524
>> 0.262207709
>>     69            3            3      0.200558577  0.244419633
>> 0.301732113
>>     71            3            3      0.690244689  0.772692418
>> 0.625921098
>>     72            3            3      0.189810070  0.377774321
>> 0.293988340
>>     73            3            3     -0.385724422 -0.262131032
>> -0.373159652
>>     74            3            3     -0.124095769 -0.109816334
>> -0.127157915
>>     75            3            1      0.173299879  0.453592671
>> 0.325357383
>>     76            3            3     -0.598215129 -0.643286651
>> -0.423824759
>>     77            3            3     -0.420558406 -0.361763025
>> -0.465612116
>>     78            3            3     -0.176788569 -0.305506924
>> -0.203730879
>>     80            3            3     -0.114790731  0.262392918
>> 0.061382073
>>     81            3            3     -0.274904173 -0.342603918
>> -0.302761994
>>     82            3            3     -0.146902101 -0.059558818
>> -0.120550957
>>     84            3            3      0.038303792 -0.139833875
>> 0.170005914
>>     85            3            3     -0.220212221 -0.541399757
>> -0.555201764
>>     87            3            3      0.255300386  0.179484246
>> 0.421428096
>>     88            3            6     -0.548823069 -0.405541620
>> -0.322935805
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]



From du|c@|m@ @end|ng |rom b|gpond@com  Tue Aug  7 06:16:19 2018
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Tue, 7 Aug 2018 14:16:19 +1000
Subject: [R] 
 Perform GEE regression in R with multiple dependent variables
In-Reply-To: <CABNxSU0D29NXmAoNzw7gU95+tPFb=XvYA6gYUyNiS6VQ209egQ@mail.gmail.com>
References: <CABNxSU0TWmnXFtSjGPiAGNaAYPUjAUgoub229uXV2GSu-u3RMw@mail.gmail.com>
 <002901d42d3e$041f4f10$0c5ded30$@bigpond.com>
 <CABNxSU2d0hwv+vN8YuecS3TPvhA--_hF+R_bv+MGmBYGKSYp6g@mail.gmail.com>
 <CABNxSU0D29NXmAoNzw7gU95+tPFb=XvYA6gYUyNiS6VQ209egQ@mail.gmail.com>
Message-ID: <000b01d42e05$64785970$2d690c50$@bigpond.com>

It is quite a while (years) since I used multgee.

There are several papers published by Agresti and ?Touloumis et al   1 in Biometrics in 2013  and another in JSS. I am unable to reference  them at the moment; you need to read them.

 

I cannot remember how the dependent variable (y) is formatted: ordered or numerical see package help.

 

The repeated argument is for longitudinal/ repeated measurements:

Country_ID if is refers to countries is therefore an x  variable (factor) 

 

How you set up you model depends on what your model is testing.

 

Remember ordinal GEE in unlike normal modelling

 

Regards

 

Duncan

 

From: euthymios kasvikis [mailto:euthymios.k.kasvikis at gmail.com] 
Sent: Tuesday, 7 August 2018 02:22
To: dulcalma at bigpond.com
Cc: r-help at r-project.org
Subject: Re: [R] Perform GEE regression in R with multiple dependent variables

 

Or 

library(multgee)

fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism, data=RightWomen,

                    id= Politician_ID,repeated=Country_ID)

summary(fitord)

 

Should I use dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal)) ?

 

 

???? ???, 6 ??? 2018 ???? 6:00 ?.?., ?/? euthymios kasvikis <euthymios.k.kasvikis at gmail.com> ??????:

First of all thanks for your advice. So suppose that I would like to use the multgee package. The model would be like: 

library(multgee)

fitord <- ordLORgee(Ideo_Ordinal~ Machiavellianism+Psychopathy+Narcissism, data=RightWomen,

                    id= ordered(factor(Country_ID)))

summary(fitord)

 

???? ???, 6 ??? 2018 ???? 7:29 ?.?., ?/? Duncan Mackay <dulcalma at bigpond.com> ??????:

Hi

Please read the geepack manual carefully.
GEE ordinal regression is not simple.
You need to format your data and do not use sample as a storage name. It is
the name of a function

dta is storage
dta$Ideo_Ordinal <- ordered(factor(dta$Ideo_Ordinal))

m0 <-
ordgee(Ideo_Ordinal ~ Machiavellianism+Psychopathy+Narcissism ,data = dta,
id = Country_ID,
       corstr = "independence")

You need to see if the model is appropriate first and whether the sandwich
errors are right before you go further

If this is your data you may not get credible results.
You need to read up on the requirements of GEEs and  ordinal GEEs in
particular
There are a number of packages with different data requirements and methods 
If you have repeated measurements   repolr; ?multgee (just from memory)
Small sample sizes are a problem there are a number of packages dealing with
this but you will have to see which is best for you
Many do not offer a method for ordinal or multinomial GEE.
One further question to ask  population specific or subject specific  ie to
GEE or not to GEE


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of euthymios
kasvikis
Sent: Saturday, 4 August 2018 07:30
To: r-help at r-project.org
Subject: [R] Perform GEE regression in R with multiple dependent variables

Im trying to perform generalized estimating equation (GEE) on the (sample)
dataset below with R and I would like some little guidance. First of all I
will describe my dataset. As you can see below it includes 5 variables.
Country_ID shows the country of the politician, Ideo_Ordinal his poltical
belief from 1 to 7 (far left to far right). Then we have measurements
regarding three characteristics. I would like to run an analysis based on
the country and the political beliefs of every politician (dependent
variables) in relation with the 3 characteristics. I have used the geepack
package using:

library(geepack)

        samplem<-coef(summary(geeglm(sample$Ideo_Ordinal
~Machiavellianism+Psychopathy+Narcissism ,data = sample, id =
sample$Ideo_Ordinal,
                                       corstr = "independence"))) %>%
          rownames_to_column() %>%
          mutate(lowerWald = Estimate-1.96*Std.err, # Lower Wald CI
                 upperWald=Estimate+1.96*Std.err,   # Upper Wald CI
                 df=1,
                 ExpBeta = exp(Estimate)) %>%       # Transformed estimate
          mutate(lWald=exp(lowerWald),              # Upper transformed
                 uWald=exp(upperWald))              # Lower transformed
        samplem

I would like to know if it is valid to add in this method the Country_ID
simultaneously with Ideo_Ordinal and how to do it.

Country_ID Ideo_Ordinal Machiavellianism   Narcissism  Psychopathy
    3             1            3      0.250895132  0.155238716  0.128683755
    5             1            3     -0.117725000 -0.336256435 -0.203137879
    7             1            3      0.269509029 -0.260728261  0.086819555
    9             1            6      0.108873496  0.175528190  0.182884928
    14            1            3      0.173129951  0.054468468  0.155030794
    15            1            6     -0.312088872 -0.414358301 -0.212599946
    17            1            3     -0.297647658 -0.096523143 -0.228533352
    18            1            3     -0.020389157 -0.210180866 -0.046687695
    20            1            3     -0.523432382 -0.125114982 -0.431070629
    21            1            1      0.040304508  0.022743463  0.233657881
    22            1            3      0.253695988 -0.330825166  0.101122320
    23            1            3     -0.478673895 -0.421801231 -0.422894791
    27            1            6     -0.040856419 -0.566728704 -0.136069484
    28            1            3      0.240040249 -0.398404825  0.135603114
    29            1            6     -0.207631653 -0.005347621 -0.294935155
    30            1            3      0.458042533  0.462935386  0.586244831
    31            1            3     -0.259850232 -0.233074787 -0.092249465
    33            1            3      0.002164223 -0.637668706 -0.267158031
    34            1            6      0.050991955 -0.098030021 -0.043826848
    36            1            3     -0.338052871 -0.168894328 -0.230198200
    38            1            3      0.174382347  0.023807812  0.192963609
    41            2            3     -0.227322148 -0.010016330 -0.095576329
    42            2            3     -0.267514920  0.066108837 -0.218979873
    43            2            3      0.421277754  0.385223920  0.421274111
    44            2            3     -0.399592341 -0.498154998 -0.320402699
    45            2            1      0.162038344  0.328116118  0.104105963
    47            2            3     -0.080755709  0.003080287 -0.043568723
    48            2            3      0.059474124 -0.447305420  0.003988071
    49            2            3     -0.219773040 -0.312902659 -0.239057883
    51            2            3      0.438659431  0.364042111  0.393014172
    52            2            3     -0.088560903 -0.490889275 -0.006041054
    53            2            3     -0.122612591  0.074438944  0.103722836
    54            2            3     -0.450586055 -0.304253061 -0.132365179
    55            2            6     -0.710545197 -0.451329850 -0.764201786
    56            2            3      0.330718447  0.335460128  0.429173481
    57            2            3      0.442508023  0.297522144  0.407155726
    60            2            3      0.060797815 -0.096516876 -0.012802977
    61            2            3     -0.250757764 -0.113219864 -0.215345379
    62            2            1      0.153654345 -0.089615287  0.118626045
    65            2            3      0.042969508 -0.486999608 -0.080829636
    66            3            3      0.158337022  0.208229002  0.241607154
    67            3            3      0.220237408  0.397914524  0.262207709
    69            3            3      0.200558577  0.244419633  0.301732113
    71            3            3      0.690244689  0.772692418  0.625921098
    72            3            3      0.189810070  0.377774321  0.293988340
    73            3            3     -0.385724422 -0.262131032 -0.373159652
    74            3            3     -0.124095769 -0.109816334 -0.127157915
    75            3            1      0.173299879  0.453592671  0.325357383
    76            3            3     -0.598215129 -0.643286651 -0.423824759
    77            3            3     -0.420558406 -0.361763025 -0.465612116
    78            3            3     -0.176788569 -0.305506924 -0.203730879
    80            3            3     -0.114790731  0.262392918  0.061382073
    81            3            3     -0.274904173 -0.342603918 -0.302761994
    82            3            3     -0.146902101 -0.059558818 -0.120550957
    84            3            3      0.038303792 -0.139833875  0.170005914
    85            3            3     -0.220212221 -0.541399757 -0.555201764
    87            3            3      0.255300386  0.179484246  0.421428096
    88            3            6     -0.548823069 -0.405541620 -0.322935805

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]



From kenneth@b@rnhoorn @end|ng |rom te|enet@be  Mon Aug  6 20:18:38 2018
From: kenneth@b@rnhoorn @end|ng |rom te|enet@be (kenneth Barnhoorn)
Date: Mon, 6 Aug 2018 20:18:38 +0200
Subject: [R] linear regression
Message-ID: <D0B03FB6-08D7-45CB-9D53-DD4EC3EAD4DA@telenet.be>

I have a problem with a linear regression output. 

In January I made an analysis of some data and received an certain output, if I run the same code now I don?t receive the same output and I don?t see why. It is important to know the country, so I would like to see the country names behind the coefficient names like in January? 

January:




Now: 



From y@@@@_m@||k@ @end|ng |rom y@hoo@|r  Tue Aug  7 07:51:12 2018
From: y@@@@_m@||k@ @end|ng |rom y@hoo@|r (malika yassa)
Date: Tue, 7 Aug 2018 05:51:12 +0000 (UTC)
Subject: [R] (no subject)
References: <18410916.4678238.1533621072638.ref@mail.yahoo.com>
Message-ID: <18410916.4678238.1533621072638@mail.yahoo.com>

hellothis is my programmeyou can help me, i cann't found a solution for H? and this? function i calculate for all value for x1thank you 


x<-rexp(N,2)

z<-rnorm(0,1,n)

g<rexp(2,n)

h=max(x)-min(x)

n1=n^0.17

h1=h/n1

k=2

x1<-seq(from=-2,to=2,by=0.1)

s[i]=(x[i]+x[i+1])/2

for(i in 1:N)

fkS<-function(m,k){fkm=-m*(abs(Z-m)<k)+k*(Z-m>=k)-k*(Z-m<=-k)}

k1<-function(u,x1){-1/(2*pi)exp((x1-u)/h1}

for (i in 1:n)

{k1(u,x1)=integrate(-1/(2*pi)exp((x1-u)/h1,lower=s[i-1],upper=s[i])}

?

?

H<-function(u,x1)

for (i in 1:n)

{H(u,x1)=sum(g[i]*fkS*integrate(k1,lower=s[i-1],upper=s[i])

}


	[[alternative HTML version deleted]]



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Tue Aug  7 09:36:10 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 7 Aug 2018 10:36:10 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
Message-ID: <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>

Thanks for help!

However, changing the index from i to j for the column vector changes the
output. I would like the matrix to be the following:

-1 1 0 0 0 0 0
0 -1 1 0 0 0 0
0 0 -1 1 0 0 0
.....
etc.

How to code it?

Best,
Maija


>> myMatrix <- matrix(0,5,12)
>> for(i in 1:nrow(myMatrix)) {
>>    for(i in 1:ncol(myMatrix)) {
>>      myMatrix[i,i] = -1
>>      myMatrix[i,i+1] = 1
>> }}
>> print(myMatrix)



ma 6. elok. 2018 klo 13.58 Rui Barradas (ruipbarradas at sapo.pt) kirjoitti:

> Hello,
>
> Eric is right but...
>
> You have two assignments. The second sets a value that will be
> overwritten is the next iteration by myMatrix[i,i] = -1 when 'i' becomes
> the next value.
>
> If you fix the second index and use 'j', you might as well do
>
> myMatrix[] = -1
> myMatrix[, ncol(myMatrix)] = 1
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 10:24 de 06/08/2018, Eric Berger escreveu:
> > Both loops are on 'i', which is a bad idea. :-)
> > Also myMatrix[i,i+1] will be out-of-bounds if i = ncol(myMatrix)
> >
> >
> > On Mon, Aug 6, 2018 at 12:02 PM, Maija Sirkj?rvi <
> maija.sirkjarvi at gmail.com>
> > wrote:
> >
> >> I have a basic for loop with a simple matrix. The code is doing what it
> is
> >> supposed to do, but I'm still wondering the error "subscript out of
> >> bounds". What would be a smoother way to code such a basic for loop?
> >>
> >> myMatrix <- matrix(0,5,12)
> >> for(i in 1:nrow(myMatrix)) {
> >>    for(i in 1:ncol(myMatrix)) {
> >>      myMatrix[i,i] = -1
> >>      myMatrix[i,i+1] = 1
> >> }}
> >> print(myMatrix)
> >>
> >> Thanks in advance!
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Aug  7 09:47:18 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 7 Aug 2018 09:47:18 +0200
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
Message-ID: <23401.20102.253070.593345@stat.math.ethz.ch>


> Thanks for help!
> However, changing the index from i to j for the column vector changes the
> output. I would like the matrix to be the following:

> -1 1 0 0 0 0 0
> 0 -1 1 0 0 0 0
> 0 0 -1 1 0 0 0
> .....
> etc.

> How to code it?

as Enrico Schumann showed you:  Without any loop, a very nice
R-ish way (see his message)!

Martin

> Best,
> Maija



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Tue Aug  7 10:20:04 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 7 Aug 2018 11:20:04 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <23401.20102.253070.593345@stat.math.ethz.ch>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
Message-ID: <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>

Thanks, but I didn't quite get it. And I don't get it running as it should.

ti 7. elok. 2018 klo 10.47 Martin Maechler (maechler at stat.math.ethz.ch)
kirjoitti:

>
> > Thanks for help!
> > However, changing the index from i to j for the column vector changes the
> > output. I would like the matrix to be the following:
>
> > -1 1 0 0 0 0 0
> > 0 -1 1 0 0 0 0
> > 0 0 -1 1 0 0 0
> > .....
> > etc.
>
> > How to code it?
>
> as Enrico Schumann showed you:  Without any loop, a very nice
> R-ish way (see his message)!
>
> Martin
>
> > Best,
> > Maija
>
>

	[[alternative HTML version deleted]]



From jwd @end|ng |rom @urewe@t@net  Tue Aug  7 10:38:22 2018
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Tue, 7 Aug 2018 01:38:22 -0700
Subject: [R] linear regression
In-Reply-To: <D0B03FB6-08D7-45CB-9D53-DD4EC3EAD4DA@telenet.be>
References: <D0B03FB6-08D7-45CB-9D53-DD4EC3EAD4DA@telenet.be>
Message-ID: <20180807013822.2cd8e967@Draco.localdomain>

On Mon, 6 Aug 2018 20:18:38 +0200
kenneth Barnhoorn <kenneth.barnhoorn at telenet.be> wrote:

Your examples did not appear.  Remember to use plain text rather
than html.

JWDougherty

> I have a problem with a linear regression output. 
> 
> In January I made an analysis of some data and received an certain
> output, if I run the same code now I don?t receive the same output
> and I don?t see why. It is important to know the country, so I would
> like to see the country names behind the coefficient names like in
> January? 
> 
> January:
> 
> 
> 
> 
> Now: 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.
> 



From drj|m|emon @end|ng |rom gm@||@com  Tue Aug  7 11:13:03 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 7 Aug 2018 19:13:03 +1000
Subject: [R] linear regression
In-Reply-To: <20180807013822.2cd8e967@Draco.localdomain>
References: <D0B03FB6-08D7-45CB-9D53-DD4EC3EAD4DA@telenet.be>
 <20180807013822.2cd8e967@Draco.localdomain>
Message-ID: <CA+8X3fU09ou2tK7cH9_mBu_40PYN3GbfuTQMNa2cpeHaahSADQ@mail.gmail.com>

Hi Kenneth,
My guess is that you have tried to send screenshots of your output and
these were blocked. Try to cut and paste the output into your message.

Jim


On Tue, Aug 7, 2018 at 6:38 PM, John <jwd at surewest.net> wrote:
> On Mon, 6 Aug 2018 20:18:38 +0200
> kenneth Barnhoorn <kenneth.barnhoorn at telenet.be> wrote:
>
> Your examples did not appear.  Remember to use plain text rather
> than html.
>
> JWDougherty
>
>> I have a problem with a linear regression output.
>>
>> In January I made an analysis of some data and received an certain
>> output, if I run the same code now I don?t receive the same output
>> and I don?t see why. It is important to know the country, so I would
>> like to see the country names behind the coefficient names like in
>> January?
>>
>> January:
>>
>>
>>
>>
>> Now:
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @k@h@y_e4 @end|ng |rom hotm@||@com  Tue Aug  7 11:38:15 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Tue, 7 Aug 2018 09:38:15 +0000
Subject: [R] installing R in Amazon linux AMI
Message-ID: <SL2P216MB009118AE60FC40C66C01E61AC8270@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am using R in AWS. I am currently using RHEL AMI in ec2 instance. I want to shift to Amazon LINUX AMI to lower costs.

How do you install R in Amazon lINUX AMI? I have searched the web, and , to my disappointment have not found any articles on how to install R in Amazon linux AMI, as is there for RED HAT AMI.

Any help?

Very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug  7 16:37:27 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 7 Aug 2018 15:37:27 +0100
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
Message-ID: <5B69AEA7.70408@sapo.pt>

Hello,

If it is not running as you want it, you should say what went wrong.
Post the code that you have tried and the expected output, please.
(In fact, the lack of expected output was the reason why my suggestion 
was completely off target.)

Rui Barradas

On 07/08/2018 09:20, Maija Sirkj?rvi wrote:
> Thanks, but I didn't quite get it. And I don't get it running as it should.
>
> ti 7. elok. 2018 klo 10.47 Martin Maechler (maechler at stat.math.ethz.ch
> <mailto:maechler at stat.math.ethz.ch>) kirjoitti:
>
>
>      > Thanks for help!
>      > However, changing the index from i to j for the column vector
>     changes the
>      > output. I would like the matrix to be the following:
>
>      > -1 1 0 0 0 0 0
>      > 0 -1 1 0 0 0 0
>      > 0 0 -1 1 0 0 0
>      > .....
>      > etc.
>
>      > How to code it?
>
>     as Enrico Schumann showed you:  Without any loop, a very nice
>     R-ish way (see his message)!
>
>     Martin
>
>      > Best,
>      > Maija
>



From @||ve@tr|@c@@@|| @end|ng |rom gm@||@com  Tue Aug  7 16:47:40 2018
From: @||ve@tr|@c@@@|| @end|ng |rom gm@||@com (Edoardo Silvestri)
Date: Tue, 7 Aug 2018 16:47:40 +0200
Subject: [R] Lag function
Message-ID: <CAEv8TnR2B02aWbcb=XD_DQ=c5Eo2Ln9z5aRORXcH2Cfd3nsDQQ@mail.gmail.com>

I have an hourly database and I defined a variable as follows:
time<-ts(data$variable, frequency=24)

If i need to create the variables with one day lag, the corresponding
command is lag(time,24)?

Thank you

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug  7 19:13:28 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 7 Aug 2018 10:13:28 -0700
Subject: [R] Lag function
In-Reply-To: <CAEv8TnR2B02aWbcb=XD_DQ=c5Eo2Ln9z5aRORXcH2Cfd3nsDQQ@mail.gmail.com>
References: <CAEv8TnR2B02aWbcb=XD_DQ=c5Eo2Ln9z5aRORXcH2Cfd3nsDQQ@mail.gmail.com>
Message-ID: <CAGxFJbTpO1=wSCGK8UycsmsAshYsLsswQXagVeNbdOfnLNaTUg@mail.gmail.com>

Well, maybe. Whether it's +24 or -24 depends on what you mean by "one day
lag." I suspect you mean -24, but perhaps this will help you decide:

test <- ts(1:72, frequency = 24)
plot(lag(test,24))
plot(lag(test,-24))

Note that the +24 moves the time base back 24 observable units (= hours)
and -24 moves it forward 24 hours. This means that the day 2 observations
are those from day 1, etc., which is usually what is wanted for lag. But
you decide.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 7, 2018 at 7:47 AM, Edoardo Silvestri <
silvestri.casali at gmail.com> wrote:

> I have an hourly database and I defined a variable as follows:
> time<-ts(data$variable, frequency=24)
>
> If i need to create the variables with one day lag, the corresponding
> command is lag(time,24)?
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Wed Aug  8 03:06:07 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 8 Aug 2018 11:06:07 +1000
Subject: [R] (no subject)
In-Reply-To: <18410916.4678238.1533621072638@mail.yahoo.com>
References: <18410916.4678238.1533621072638.ref@mail.yahoo.com>
 <18410916.4678238.1533621072638@mail.yahoo.com>
Message-ID: <CA+8X3fWP6f+co3RHs_RdwQ24ucXOCHaA7r=TbwdUUxUm2TPZ4Q@mail.gmail.com>

Hi malika,
You don't seem to have defined your functions correctly. For example:

H<-function(u,x1)

would define an empty function H if that command worked, but it doesn't

Jim


On Tue, Aug 7, 2018 at 3:51 PM, malika yassa via R-help
<r-help at r-project.org> wrote:
> hellothis is my programmeyou can help me, i cann't found a solution for H  and this  function i calculate for all value for x1thank you
>
>
> x<-rexp(N,2)
>
> z<-rnorm(0,1,n)
>
> g<rexp(2,n)
>
> h=max(x)-min(x)
>
> n1=n^0.17
>
> h1=h/n1
>
> k=2
>
> x1<-seq(from=-2,to=2,by=0.1)
>
> s[i]=(x[i]+x[i+1])/2
>
> for(i in 1:N)
>
> fkS<-function(m,k){fkm=-m*(abs(Z-m)<k)+k*(Z-m>=k)-k*(Z-m<=-k)}
>
> k1<-function(u,x1){-1/(2*pi)exp((x1-u)/h1}
>
> for (i in 1:n)
>
> {k1(u,x1)=integrate(-1/(2*pi)exp((x1-u)/h1,lower=s[i-1],upper=s[i])}
>
>
>
>
>
> H<-function(u,x1)
>
> for (i in 1:n)
>
> {H(u,x1)=sum(g[i]*fkS*integrate(k1,lower=s[i-1],upper=s[i])
>
> }
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From joh@nn@-@chw@rz @end|ng |rom gmx@de  Wed Aug  8 09:08:09 2018
From: joh@nn@-@chw@rz @end|ng |rom gmx@de (Johanna Schwarz)
Date: Wed, 8 Aug 2018 09:08:09 +0200
Subject: [R] Submit your own R package - @examples
Message-ID: <003401d42ee6$90521040$b0f630c0$@gmx.de>

Dear community, 

I am trying to submit my first R package to CRAN and stumbled upon the
following problem:

Most of my methods, are not exported to the namespace using the @examples
options.

Will I have to provide @examples for these methods in the documentation? If
yes, I have the problem that when I run the @examples for the method that is
not exported, I receive the error 

Error in foo() : could not find function "foo"

Execution halted

 

What am I missing? Will I even have to provide examples to pass the CRAN
tests?

 

Thank you in advance for your help,

schwart

 


	[[alternative HTML version deleted]]



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Wed Aug  8 11:40:59 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Wed, 8 Aug 2018 12:40:59 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <5B69AEA7.70408@sapo.pt>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
Message-ID: <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>

Thanks!

If I do it like this:

myMatrix <- matrix(0,5,5*2-3)
print(myMatrix)
for(i in 2:nrow(myMatrix))
  for(j in 2:ncol(myMatrix))
    myMatrix[i-1,j-1] = -1
    myMatrix[i-1,j] = 1
print(myMatrix)

I get the following result:

   [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]   -1   -1   -1   -1   -1   -1    0
[2,]   -1   -1   -1   -1   -1   -1    0
[3,]   -1   -1   -1   -1   -1   -1    0
[4,]   -1   -1   -1   -1   -1   -1    1
[5,]    0    0    0    0    0    0    0

However. The result that I would need to get would be like this:

   [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]   -1   1   0   0   0   0    0
[2,]   0   -1   1   0   0   0    0
[3,]   0   0   -1   1   0   0    0
[4,]   0   0   0   -1   1   0    0
[5,]    0    0    0    0    -1  1    0

I'd rather not create symmetric matrices as I would really like to learn
how to do this thing "the hard way" as I find matrix iteration to be quite
a basic procedure in everything I'm trying to do.

Thanks again!
Maija




ti 7. elok. 2018 klo 17.37 Rui Barradas (ruipbarradas at sapo.pt) kirjoitti:

> Hello,
>
> If it is not running as you want it, you should say what went wrong.
> Post the code that you have tried and the expected output, please.
> (In fact, the lack of expected output was the reason why my suggestion
> was completely off target.)
>
> Rui Barradas
>
> On 07/08/2018 09:20, Maija Sirkj?rvi wrote:
> > Thanks, but I didn't quite get it. And I don't get it running as it
> should.
> >
> > ti 7. elok. 2018 klo 10.47 Martin Maechler (maechler at stat.math.ethz.ch
> > <mailto:maechler at stat.math.ethz.ch>) kirjoitti:
> >
> >
> >      > Thanks for help!
> >      > However, changing the index from i to j for the column vector
> >     changes the
> >      > output. I would like the matrix to be the following:
> >
> >      > -1 1 0 0 0 0 0
> >      > 0 -1 1 0 0 0 0
> >      > 0 0 -1 1 0 0 0
> >      > .....
> >      > etc.
> >
> >      > How to code it?
> >
> >     as Enrico Schumann showed you:  Without any loop, a very nice
> >     R-ish way (see his message)!
> >
> >     Martin
> >
> >      > Best,
> >      > Maija
> >
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Wed Aug  8 11:53:32 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 8 Aug 2018 12:53:32 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
Message-ID: <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>

You only need one "for loop"

for(i in 2:nrow(myMatrix)) {
   myMatrix[i-1,i-1] = -1
   myMatrix[i-1,i] = 1
}

HTH,
Eric


On Wed, Aug 8, 2018 at 12:40 PM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
wrote:

> Thanks!
>
> If I do it like this:
>
> myMatrix <- matrix(0,5,5*2-3)
> print(myMatrix)
> for(i in 2:nrow(myMatrix))
>   for(j in 2:ncol(myMatrix))
>     myMatrix[i-1,j-1] = -1
>     myMatrix[i-1,j] = 1
> print(myMatrix)
>
> I get the following result:
>
>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]   -1   -1   -1   -1   -1   -1    0
> [2,]   -1   -1   -1   -1   -1   -1    0
> [3,]   -1   -1   -1   -1   -1   -1    0
> [4,]   -1   -1   -1   -1   -1   -1    1
> [5,]    0    0    0    0    0    0    0
>
> However. The result that I would need to get would be like this:
>
>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]   -1   1   0   0   0   0    0
> [2,]   0   -1   1   0   0   0    0
> [3,]   0   0   -1   1   0   0    0
> [4,]   0   0   0   -1   1   0    0
> [5,]    0    0    0    0    -1  1    0
>
> I'd rather not create symmetric matrices as I would really like to learn
> how to do this thing "the hard way" as I find matrix iteration to be quite
> a basic procedure in everything I'm trying to do.
>
> Thanks again!
> Maija
>
>
>
>
> ti 7. elok. 2018 klo 17.37 Rui Barradas (ruipbarradas at sapo.pt) kirjoitti:
>
> > Hello,
> >
> > If it is not running as you want it, you should say what went wrong.
> > Post the code that you have tried and the expected output, please.
> > (In fact, the lack of expected output was the reason why my suggestion
> > was completely off target.)
> >
> > Rui Barradas
> >
> > On 07/08/2018 09:20, Maija Sirkj?rvi wrote:
> > > Thanks, but I didn't quite get it. And I don't get it running as it
> > should.
> > >
> > > ti 7. elok. 2018 klo 10.47 Martin Maechler (maechler at stat.math.ethz.ch
> > > <mailto:maechler at stat.math.ethz.ch>) kirjoitti:
> > >
> > >
> > >      > Thanks for help!
> > >      > However, changing the index from i to j for the column vector
> > >     changes the
> > >      > output. I would like the matrix to be the following:
> > >
> > >      > -1 1 0 0 0 0 0
> > >      > 0 -1 1 0 0 0 0
> > >      > 0 0 -1 1 0 0 0
> > >      > .....
> > >      > etc.
> > >
> > >      > How to code it?
> > >
> > >     as Enrico Schumann showed you:  Without any loop, a very nice
> > >     R-ish way (see his message)!
> > >
> > >     Martin
> > >
> > >      > Best,
> > >      > Maija
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Wed Aug  8 12:03:11 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Wed, 8 Aug 2018 13:03:11 +0300
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
 <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
Message-ID: <CAJxz9NZZjTusrGW2vj7wSjuNHvjQ-zpDkHBwg82N2HonZJypkg@mail.gmail.com>

Thanks a lot ! That's it!

Maija

ke 8. elok. 2018 klo 12.53 Eric Berger (ericjberger at gmail.com) kirjoitti:

> You only need one "for loop"
>
> for(i in 2:nrow(myMatrix)) {
>    myMatrix[i-1,i-1] = -1
>    myMatrix[i-1,i] = 1
> }
>
> HTH,
> Eric
>
>
> On Wed, Aug 8, 2018 at 12:40 PM, Maija Sirkj?rvi <
> maija.sirkjarvi at gmail.com> wrote:
>
>> Thanks!
>>
>> If I do it like this:
>>
>> myMatrix <- matrix(0,5,5*2-3)
>> print(myMatrix)
>> for(i in 2:nrow(myMatrix))
>>   for(j in 2:ncol(myMatrix))
>>     myMatrix[i-1,j-1] = -1
>>     myMatrix[i-1,j] = 1
>> print(myMatrix)
>>
>> I get the following result:
>>
>>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
>> [1,]   -1   -1   -1   -1   -1   -1    0
>> [2,]   -1   -1   -1   -1   -1   -1    0
>> [3,]   -1   -1   -1   -1   -1   -1    0
>> [4,]   -1   -1   -1   -1   -1   -1    1
>> [5,]    0    0    0    0    0    0    0
>>
>> However. The result that I would need to get would be like this:
>>
>>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
>> [1,]   -1   1   0   0   0   0    0
>> [2,]   0   -1   1   0   0   0    0
>> [3,]   0   0   -1   1   0   0    0
>> [4,]   0   0   0   -1   1   0    0
>> [5,]    0    0    0    0    -1  1    0
>>
>> I'd rather not create symmetric matrices as I would really like to learn
>> how to do this thing "the hard way" as I find matrix iteration to be quite
>> a basic procedure in everything I'm trying to do.
>>
>> Thanks again!
>> Maija
>>
>>
>>
>>
>> ti 7. elok. 2018 klo 17.37 Rui Barradas (ruipbarradas at sapo.pt) kirjoitti:
>>
>> > Hello,
>> >
>> > If it is not running as you want it, you should say what went wrong.
>> > Post the code that you have tried and the expected output, please.
>> > (In fact, the lack of expected output was the reason why my suggestion
>> > was completely off target.)
>> >
>> > Rui Barradas
>> >
>> > On 07/08/2018 09:20, Maija Sirkj?rvi wrote:
>> > > Thanks, but I didn't quite get it. And I don't get it running as it
>> > should.
>> > >
>> > > ti 7. elok. 2018 klo 10.47 Martin Maechler (
>> maechler at stat.math.ethz.ch
>> > > <mailto:maechler at stat.math.ethz.ch>) kirjoitti:
>> > >
>> > >
>> > >      > Thanks for help!
>> > >      > However, changing the index from i to j for the column vector
>> > >     changes the
>> > >      > output. I would like the matrix to be the following:
>> > >
>> > >      > -1 1 0 0 0 0 0
>> > >      > 0 -1 1 0 0 0 0
>> > >      > 0 0 -1 1 0 0 0
>> > >      > .....
>> > >      > etc.
>> > >
>> > >      > How to code it?
>> > >
>> > >     as Enrico Schumann showed you:  Without any loop, a very nice
>> > >     R-ish way (see his message)!
>> > >
>> > >     Martin
>> > >
>> > >      > Best,
>> > >      > Maija
>> > >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Aug  8 13:09:01 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 8 Aug 2018 13:09:01 +0200
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
 <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
Message-ID: <23402.53069.24933.691484@stat.math.ethz.ch>

>>>>> Eric Berger    on Wed, 8 Aug 2018 12:53:32 +0300 writes:

> You only need one "for loop"
> for(i in 2:nrow(myMatrix)) {
>    myMatrix[i-1,i-1] = -1
>    myMatrix[i-1,i] = 1
> }
> 
> HTH,
> Eric

and why are you not using Enrico Schumann's even nicer solution
(from August 6) that I had mentioned too ?
Here's the link to it in the (official) R-help archives:
 https://stat.ethz.ch/pipermail/r-help/2018-August/455673.html

Maija said
> Thanks, but I didn't quite get it. And I don't get it running as it should.

and actually she is right that that version does not work for
all dimensions of 'myMatrix' -- it does need  ncol(.) >= 3
but neither does the above solution -- it only works for nrow(.) >= 2

Here's a function version of Enrico's that does work in all cases(!)
without a for loop -- including examples (as comments)

mkMat <- function(n=5, m=7) {
    M <- matrix(0, n,m)
    diag(M) <- -1
    ## this fails when m == ncol(M) <= 2, and ', drop=FALSE' does *not* help :
    ## diag(M[, -1]) <- 1
    ## diag(M[, -1, drop=FALSE]) <- 1
    ## This *does* work:
    M[col(M) - row(M) == 1L] <- 1

    M
}
mkMat()
##      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
## [1,]   -1    1    0    0    0    0    0
## [2,]    0   -1    1    0    0    0    0
## [3,]    0    0   -1    1    0    0    0
## [4,]    0    0    0   -1    1    0    0
## [5,]    0    0    0    0   -1    1    0
mkMat(3,5)
##      [,1] [,2] [,3] [,4] [,5]
## [1,]   -1    1    0    0    0
## [2,]    0   -1    1    0    0
## [3,]    0    0   -1    1    0
mkMat(5,3)
##      [,1] [,2] [,3]
## [1,]   -1    1    0
## [2,]    0   -1    1
## [3,]    0    0   -1
## [4,]    0    0    0
## [5,]    0    0    0

## Show that all small (m,n) work:
for(m in 0:3)
    for(n in 0:3) {
        cat(sprintf("(%d,%d):\n", n,m)); print(mkMat(n,m))
    }

## (output not shown here)


> 
> On Wed, Aug 8, 2018 at 12:40 PM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> wrote:
> 
> >   [.............]
> >   [.............]

> > However. The result that I would need to get would be like this:
> >
> >     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> > [1,]  -1    1    0    0    0    0    0
> > [2,]   0   -1    1    0    0    0    0
> > [3,]   0    0   -1    1    0    0    0
> > [4,]   0    0    0   -1    1    0    0
> > [5,]   0    0    0    0   -1    1    0



From S@E|||@on @end|ng |rom LGCGroup@com  Wed Aug  8 13:59:42 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Wed, 8 Aug 2018 11:59:42 +0000
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <23402.53069.24933.691484@stat.math.ethz.ch>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
 <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
 <23402.53069.24933.691484@stat.math.ethz.ch>
Message-ID: <0d7366e7965c471dbea4a9100cef391c@GBDCVPEXC08.corp.lgc-group.com>

 
> >>>>> Eric Berger    on Wed, 8 Aug 2018 12:53:32 +0300 writes:
> 
> > You only need one "for loop"
> > for(i in 2:nrow(myMatrix)) {
> >    myMatrix[i-1,i-1] = -1
> >    myMatrix[i-1,i] = 1
> > }

Or none, with matrix-based array indexing and explicit control of the indices to prevent overrun in :

mkMat <- function(n=5, m=7) {
   M <- matrix(0, n,m)
   i <- 1:min(n,m)
   j <- i[i<m]
   M[ cbind(i,i) ] <- -1
   M[ cbind(j, j+1) ] <- 1
   M
}




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From S@E|||@on @end|ng |rom LGCGroup@com  Wed Aug  8 14:24:46 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Wed, 8 Aug 2018 12:24:46 +0000
Subject: [R] Submit your own R package - @examples
In-Reply-To: <003401d42ee6$90521040$b0f630c0$@gmx.de>
References: <003401d42ee6$90521040$b0f630c0$@gmx.de>
Message-ID: <de52b1f08bec4ad0bce1c0cac22fbc33@GBDCVPEXC08.corp.lgc-group.com>

> Most of my methods, are not exported to the namespace using the
> @examples
> options.

Joanna,
You normally need to export _all_ the objects/functions that you expect users to be able to run.
And if you are giving an example of a function, it seems likely that you expect users to use it, so it needs to be exported.

But it looks like you're using Roxygen and if I'm reading the documentation correctly, @examples doesn't export anything at all. @export does that. See https://cran.r-project.org/web/packages/roxygen2/vignettes/namespace.html

This is also a development question: maybe try the R-package-devel or R-devel lists?

Steve Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Aug  8 15:49:18 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 8 Aug 2018 13:49:18 +0000
Subject: [R] Help with finalfit and knitr
Message-ID: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi using some of my own data I am trying to reproduce examples from this tutorial:

https://cran.r-project.org/web/packages/finalfit/vignettes/finalfit_basics.html

Here are my sys info:
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows Server >= 2012 x64 (build 9200)

Here is my data structure:
str(df6)
# 'data.frame': 78407 obs. of  6 variables:
#   $ ProductName    : Factor w/ 2 levels "Editing","OON": 2 2 2 2 2 2 2 2 2 2 ...
# $ RevCodeCats    : Factor w/ 20 levels "BHAccomodations",..: 10 10 12 12 8 8 12 20 8 19 ...
# $ AgeCat         : Factor w/ 10 levels "[>80]","[0-5]",..: 9 9 5 5 7 4 7 7 7 9 ...
# $ PatientGender  : Factor w/ 3 levels "F","M","U": 2 2 2 2 2 1 1 1 1 1 ...
# $ AcceptedSavings: num  0 0 0 0 48.9 ...
# $ BinaryAccSav   : Factor w/ 2 levels "0","1": 1 1 1 1 2 2 2 2 2 2 ...

Here is my call:

explanatory = c("ProductName", "AgeCat", "PatientGender")
dependent = "BinaryAccSav" #------------------------------------------------------- AcceptedSavings 1=Y 0=N
df6 %>%  finalfit(dependent, explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

Here is the error:
#Error: unexpected symbol in " df6 %>%  finalfit(dependent, explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr"

The error is identifying the knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r")) as the problem

I believe I have copied the procedure correctly from the tutorial and replaced the tutorial variables with mine.

Libraries I believe are necessary:
library("knitr", lib.loc="~/R/win-library/3.5")
library("rmarkdown", lib.loc="~/R/win-library/3.5")
library("htmlTable", lib.loc="~/R/win-library/3.5")

And I see --Warning in install.packages :  package 'kable' is not available (for R version 3.5.1) which I believe is my problem?


  1.  can my hunch be validated by someone please?
  2.  Is there a solution for this?
  3.  or do I contact the package authors directly?

Thank you all!

WHP


Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug  8 16:21:19 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 8 Aug 2018 07:21:19 -0700
Subject: [R] Submit your own R package - @examples
In-Reply-To: <003401d42ee6$90521040$b0f630c0$@gmx.de>
References: <003401d42ee6$90521040$b0f630c0$@gmx.de>
Message-ID: <CAGxFJbQ093sqm=_tbSySGg+KBArgQ9+G1w2YNTu7za5apL9UPg@mail.gmail.com>

This should be posted on the r-package-devel list rather than here:

https://stat.ethz.ch/mailman/listinfo/r-package-devel

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 8, 2018 at 12:08 AM, Johanna Schwarz <johanna-schwarz at gmx.de>
wrote:

> Dear community,
>
> I am trying to submit my first R package to CRAN and stumbled upon the
> following problem:
>
> Most of my methods, are not exported to the namespace using the @examples
> options.
>
> Will I have to provide @examples for these methods in the documentation? If
> yes, I have the problem that when I run the @examples for the method that
> is
> not exported, I receive the error
>
> Error in foo() : could not find function "foo"
>
> Execution halted
>
>
>
> What am I missing? Will I even have to provide examples to pass the CRAN
> tests?
>
>
>
> Thank you in advance for your help,
>
> schwart
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug  8 17:06:48 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Aug 2018 08:06:48 -0700
Subject: [R] Help with finalfit and knitr
In-Reply-To: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>

R syntax does not allow for objects to be plopped next to each other separated by a space. There should be a newline after the t1 variable. This kind of problem plagues people copying HTML into emails on this mailing list (losing newlines), and was probably introduced into your code during a copy-paste as well.

There is no package called "kable"... that is a function in the knitr package.

My advice is to enter one line of each example at a time and study what it does before proceeding to the next line. Copying whole swathes of code and marveling at the result is exhilarating but ultimately leaves you handicapped in creating your own code.

On August 8, 2018 6:49:18 AM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Hi using some of my own data I am trying to reproduce examples from
>this tutorial:
>
>https://cran.r-project.org/web/packages/finalfit/vignettes/finalfit_basics.html
>
>Here are my sys info:
>R version 3.5.1 (2018-07-02)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows Server >= 2012 x64 (build 9200)
>
>Here is my data structure:
>str(df6)
># 'data.frame': 78407 obs. of  6 variables:
>#   $ ProductName    : Factor w/ 2 levels "Editing","OON": 2 2 2 2 2 2
>2 2 2 2 ...
># $ RevCodeCats    : Factor w/ 20 levels "BHAccomodations",..: 10 10 12
>12 8 8 12 20 8 19 ...
># $ AgeCat         : Factor w/ 10 levels "[>80]","[0-5]",..: 9 9 5 5 7
>4 7 7 7 9 ...
># $ PatientGender  : Factor w/ 3 levels "F","M","U": 2 2 2 2 2 1 1 1 1
>1 ...
># $ AcceptedSavings: num  0 0 0 0 48.9 ...
># $ BinaryAccSav   : Factor w/ 2 levels "0","1": 1 1 1 1 2 2 2 2 2 2
>...
>
>Here is my call:
>
>explanatory = c("ProductName", "AgeCat", "PatientGender")
>dependent = "BinaryAccSav"
>#-------------------------------------------------------
>AcceptedSavings 1=Y 0=N
>df6 %>%  finalfit(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE) -> t1 knitr::kable(t1, row.names=FALSE,
>align=c("l", "l", "r", "r", "r"))
>
>Here is the error:
>#Error: unexpected symbol in " df6 %>%  finalfit(dependent,
>explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr"
>
>The error is identifying the knitr::kable(t1, row.names=FALSE,
>align=c("l", "l", "r", "r", "r")) as the problem
>
>I believe I have copied the procedure correctly from the tutorial and
>replaced the tutorial variables with mine.
>
>Libraries I believe are necessary:
>library("knitr", lib.loc="~/R/win-library/3.5")
>library("rmarkdown", lib.loc="~/R/win-library/3.5")
>library("htmlTable", lib.loc="~/R/win-library/3.5")
>
>And I see --Warning in install.packages :  package 'kable' is not
>available (for R version 3.5.1) which I believe is my problem?
>
>
>  1.  can my hunch be validated by someone please?
>  2.  Is there a solution for this?
>  3.  or do I contact the package authors directly?
>
>Thank you all!
>
>WHP
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:15}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug  8 17:21:05 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 8 Aug 2018 08:21:05 -0700
Subject: [R] Fwd:  Help with finalfit and knitr
In-Reply-To: <CAGxFJbQC3m8-x9gX9c=1kKFMqDH3c5wbzL35Dvxa6-LgHnR8oA@mail.gmail.com>
References: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>
 <CAGxFJbQC3m8-x9gX9c=1kKFMqDH3c5wbzL35Dvxa6-LgHnR8oA@mail.gmail.com>
Message-ID: <CAGxFJbTOMvi=C50mrHFO7YVGRr7sZBbWhEKgv374OATZREwKRA@mail.gmail.com>

(From Jeff Newmiller)


"My advice is to enter one line of each example at a time and study what it
does before proceeding to the next line. Copying whole swathes of code and
marveling at the result is exhilarating but ultimately leaves you
handicapped in creating your own code."

Fortune nomination!

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 8, 2018 at 8:06 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> R syntax does not allow for objects to be plopped next to each other
> separated by a space. There should be a newline after the t1 variable. This
> kind of problem plagues people copying HTML into emails on this mailing
> list (losing newlines), and was probably introduced into your code during a
> copy-paste as well.
>
> There is no package called "kable"... that is a function in the knitr
> package.
>
> My advice is to enter one line of each example at a time and study what it
> does before proceeding to the next line. Copying whole swathes of code and
> marveling at the result is exhilarating but ultimately leaves you
> handicapped in creating your own code.
>
> On August 8, 2018 6:49:18 AM PDT, Bill Poling <Bill.Poling at zelis.com>
> wrote:
> >Hi using some of my own data I am trying to reproduce examples from
> >this tutorial:
> >
> >https://cran.r-project.org/web/packages/finalfit/vignettes/
> finalfit_basics.html
> >
> >Here are my sys info:
> >R version 3.5.1 (2018-07-02)
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >Running under: Windows Server >= 2012 x64 (build 9200)
> >
> >Here is my data structure:
> >str(df6)
> ># 'data.frame': 78407 obs. of  6 variables:
> >#   $ ProductName    : Factor w/ 2 levels "Editing","OON": 2 2 2 2 2 2
> >2 2 2 2 ...
> ># $ RevCodeCats    : Factor w/ 20 levels "BHAccomodations",..: 10 10 12
> >12 8 8 12 20 8 19 ...
> ># $ AgeCat         : Factor w/ 10 levels "[>80]","[0-5]",..: 9 9 5 5 7
> >4 7 7 7 9 ...
> ># $ PatientGender  : Factor w/ 3 levels "F","M","U": 2 2 2 2 2 1 1 1 1
> >1 ...
> ># $ AcceptedSavings: num  0 0 0 0 48.9 ...
> ># $ BinaryAccSav   : Factor w/ 2 levels "0","1": 1 1 1 1 2 2 2 2 2 2
> >...
> >
> >Here is my call:
> >
> >explanatory = c("ProductName", "AgeCat", "PatientGender")
> >dependent = "BinaryAccSav"
> >#-------------------------------------------------------
> >AcceptedSavings 1=Y 0=N
> >df6 %>%  finalfit(dependent, explanatory, p=TRUE,
> >add_dependent_label=TRUE) -> t1 knitr::kable(t1, row.names=FALSE,
> >align=c("l", "l", "r", "r", "r"))
> >
> >Here is the error:
> >#Error: unexpected symbol in " df6 %>%  finalfit(dependent,
> >explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr"
> >
> >The error is identifying the knitr::kable(t1, row.names=FALSE,
> >align=c("l", "l", "r", "r", "r")) as the problem
> >
> >I believe I have copied the procedure correctly from the tutorial and
> >replaced the tutorial variables with mine.
> >
> >Libraries I believe are necessary:
> >library("knitr", lib.loc="~/R/win-library/3.5")
> >library("rmarkdown", lib.loc="~/R/win-library/3.5")
> >library("htmlTable", lib.loc="~/R/win-library/3.5")
> >
> >And I see --Warning in install.packages :  package 'kable' is not
> >available (for R version 3.5.1) which I believe is my problem?
> >
> >
> >  1.  can my hunch be validated by someone please?
> >  2.  Is there a solution for this?
> >  3.  or do I contact the package authors directly?
> >
> >Thank you all!
> >
> >WHP
> >
> >
> >Confidentiality Notice This message is sent from Zelis.
> >...{{dropped:15}}
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From L@urence@C|@rk @end|ng |rom he@|thm@n|td@com  Wed Aug  8 17:09:35 2018
From: L@urence@C|@rk @end|ng |rom he@|thm@n|td@com (Laurence Clark)
Date: Wed, 8 Aug 2018 15:09:35 +0000
Subject: [R] security using R at work
Message-ID: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>

Hello all,

I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.

My question is:

If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security. Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?

Thank you

Laurence


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Laurence Clark
Business Data Analyst
Account Management
Health Management Ltd

Mobile: 		07584 556498
Switchboard: 	0845 504 1000
Email: 		Laurence.Clark at healthmanltd.com
Web: 		www.healthmanagement.co.uk

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ, United Kingdom.</font> 
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


#####################################################################################
Scanned by MailMarshal - M86 Security's comprehensive email content security solution. 
Download a free evaluation of MailMarshal at www.m86security.com
#####################################################################################



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Aug  8 17:56:38 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 8 Aug 2018 17:56:38 +0200
Subject: [R] Fwd:  Help with finalfit and knitr
In-Reply-To: <CAGxFJbTOMvi=C50mrHFO7YVGRr7sZBbWhEKgv374OATZREwKRA@mail.gmail.com>
References: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>
 <CAGxFJbQC3m8-x9gX9c=1kKFMqDH3c5wbzL35Dvxa6-LgHnR8oA@mail.gmail.com>
 <CAGxFJbTOMvi=C50mrHFO7YVGRr7sZBbWhEKgv374OATZREwKRA@mail.gmail.com>
Message-ID: <23403.4790.687877.63875@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Wed, 8 Aug 2018 08:21:05 -0700 writes:

    > (From Jeff Newmiller) "My advice is to enter one line of
    > each example at a time and study what it does before
    > proceeding to the next line. Copying whole swathes of code
    > and marveling at the result is exhilarating but ultimately
    > leaves you handicapped in creating your own code."

    > Fortune nomination!

seconded!
Martin

    > Cheers, Bert

    > Bert Gunter



From b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk  Wed Aug  8 18:10:30 2018
From: b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk (Barry Rowlingson)
Date: Wed, 8 Aug 2018 17:10:30 +0100
Subject: [R] security using R at work
In-Reply-To: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
References: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
Message-ID: <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>

On Wed, Aug 8, 2018 at 4:09 PM, Laurence Clark
<Laurence.Clark at healthmanltd.com> wrote:
> Hello all,
>
> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>
> My question is:
>
> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security.

> Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?

You are talking mostly to statisticians here, and if p>0 then there's
"a chance". I'd say yes, there's a chance, but its pretty small, and
would only occur through stupidity, accident or malice.

 In the ordinary course of things your data will be on your hard disk,
or on your corporate network drives, and only exist between your
corporate network server and your PC's memory. R will load the data
into that memory, do stuff with it in that memory, and write results
back to hard disk. Nothing leaves the network this way.

However... R has facilities for talking to the internet. You can save
data to google docs spreadsheets, for example, but you'd have to be
signed in to google, and have to type something like:

 > writeGoogleDoc(my_data, "secretdata.xls")

that covers "stupid". You should know that google docs are on google's
servers, and google's servers aren't on your network, and your secret
data shouldn't go on google's servers.

Accidents happen. You might be working on non-secret data which you
want to save to google docs, and accidentally save "data1" which is
secret instead of "data2" which is okay to be public. Oops. You sent
it to google. Accidents happen.

"malice" would be if someone had put code into R or an add-on package
that you use that sends your data over the network without you
knowing. For example maybe every time you fit a linear model with:

 lm(age~beauty, data=people)

R could be transmitting the data to hackers. But the chance of this is
very small, and I don't think any malicious code has ever been
discovered in R or the 12000 add-on packages downloadable from CRAN.
Doesn't mean it hasn't been discovered yet or won't be in the future.

It used to be said that the only machine safe from hackers was one
unplugged from the network. But now hackers can get to your machine
via malicious USB sticks, keyboard loggers, and various other nasties.
The only machine safe from hackers is one with the power off. But take
the power plug out because a wake-on-lan packet could switch your
machine on remotely....

Barry







> Thank you
>
> Laurence
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> Laurence Clark
> Business Data Analyst
> Account Management
> Health Management Ltd
>
> Mobile:                 07584 556498
> Switchboard:    0845 504 1000
> Email:          Laurence.Clark at healthmanltd.com
> Web:            www.healthmanagement.co.uk
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ, United Kingdom.</font>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> #####################################################################################
> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
> Download a free evaluation of MailMarshal at www.m86security.com
> #####################################################################################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Aug  8 18:17:16 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 8 Aug 2018 09:17:16 -0700 (PDT)
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <alpine.LNX.2.20.1808080912520.1236@salmo.appl-ecosys.com>

On Wed, 8 Aug 2018, Laurence Clark wrote:

> I want to download R and use it for work purposes. I hope to use it to
> analyse very sensitive data from our clients.

Laurence,

   Good choice.

> My question is:
>
> If I install R on my work network computer, will the data ever leave our
> network? I need to know if the data goes anywhere other than our network,
> because this could compromise it's security. Is there is any chance the
> data could go to a server owned by 'R' or anything else that's not
> immediately obvious, but constitutes the data leaving our network?

   Your sensitive data are no more, and no less, secure than any other data
on your desktop computer or the company's network. Assuming company
personnel and payroll data are on your local network, and proposals written
with Microsoft's tools are happily created by employees, then your client
data are equally secure (or at risk) regardless of the application used on
them. This is a network security issue, not an R issue.

Rich



From d@v|d@m| @end|ng |rom m|cro@o|t@com  Wed Aug  8 18:35:55 2018
From: d@v|d@m| @end|ng |rom m|cro@o|t@com (David Smith (CDA))
Date: Wed, 8 Aug 2018 16:35:55 +0000
Subject: [R] Revolutions blog: July 2018 roundup
Message-ID: <DM5PR2101MB10486A1008E5DE26BA43BE9BC8260@DM5PR2101MB1048.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of July:

R package authors validate quality and security for their packages with the
Linux Foundation's CII Best Practices Badge Program:
http://blog.revolutionanalytics.com/2018/07/cii-certification-for-r-packages.html

R scripts to generate images in the style of famous artworks, like Mondrian's:
http://blog.revolutionanalytics.com/2018/07/art-with-code.html

A 6-minute video tour of the AI and Machine Learning services in Azure,
including R:
http://blog.revolutionanalytics.com/2018/07/a-quick-tour-of-ai-services-in-azure.html

The July roundup of AI, Machine Learning and Data Science news:
http://blog.revolutionanalytics.com/2018/07/ai-roundup-july-2018.html

An R package used to tile hexagons, used to create a striking banner of hex
stickers for useR!2018:
http://blog.revolutionanalytics.com/2018/07/user-2017-hexwall.html

Highlights and links to videos from the useR!2018 conference:
http://blog.revolutionanalytics.com/2018/07/user-2018-recap.html

Video and R scripts from my workshop on creating an app to detect images of
hotdogs: http://blog.revolutionanalytics.com/2018/07/r-for-ai-video.html

Microsoft has released a number of open data sets produced from its research
programs: http://blog.revolutionanalytics.com/2018/07/msr-open-data.html

R 3.5.1 has been released:
http://blog.revolutionanalytics.com/2018/07/r-351-update-now-available-.html

And some general interest stories (not necessarily related to R):

* An app to visualize the distribution of street orientations in cities:
  http://blog.revolutionanalytics.com/2018/07/because-its-friday-urban-planning-fight.html

* A TED talk explores the link between spoken language and the way we think:
  http://blog.revolutionanalytics.com/2018/07/because-its-friday-language-and-thought.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Aug  8 18:35:57 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 8 Aug 2018 16:35:57 +0000
Subject: [R] Help with finalfit and knitr
In-Reply-To: <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>
References: <CY1PR0201MB18346F742D2C71EBE05E44B9EA260@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CE0A53BB-02F0-4A85-BFB5-20E1813E81A0@dcn.davis.ca.us>
Message-ID: <CY1PR0201MB183443FCB40C6EAA676B4D0CEA260@CY1PR0201MB1834.namprd02.prod.outlook.com>

Wow, thank you Jeff, that?s got it!

explanatory = c("ProductName", "AgeCat", "PatientGender","RevCodeCats")
 View(explanatory)
dependent = "BinaryAccSav" # ---------------------------------------------------- AcceptedSavings AcceptedSavings 1=Y 0=N
View(dependent)
df6 %>% summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE) -> t1
View(t1)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

WHP


From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Wednesday, August 08, 2018 11:07 AM
To: r-help at r-project.org; Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with finalfit and knitr

R syntax does not allow for objects to be plopped next to each other separated by a space. There should be a newline after the t1 variable. This kind of problem plagues people copying HTML into emails on this mailing list (losing newlines), and was probably introduced into your code during a copy-paste as well.

There is no package called "kable"... that is a function in the knitr package.

My advice is to enter one line of each example at a time and study what it does before proceeding to the next line. Copying whole swathes of code and marveling at the result is exhilarating but ultimately leaves you handicapped in creating your own code.

On August 8, 2018 6:49:18 AM PDT, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>Hi using some of my own data I am trying to reproduce examples from
>this tutorial:
>
>https://cran.r-project.org/web/packages/finalfit/vignettes/finalfit_basics.html<https://cran.r-project.org/web/packages/finalfit/vignettes/finalfit_basics.html>
>
>Here are my sys info:
>R version 3.5.1 (2018-07-02)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows Server >= 2012 x64 (build 9200)
>
>Here is my data structure:
>str(df6)
># 'data.frame': 78407 obs. of 6 variables:
># $ ProductName : Factor w/ 2 levels "Editing","OON": 2 2 2 2 2 2
>2 2 2 2 ...
># $ RevCodeCats : Factor w/ 20 levels "BHAccomodations",..: 10 10 12
>12 8 8 12 20 8 19 ...
># $ AgeCat : Factor w/ 10 levels "[>80]","[0-5]",..: 9 9 5 5 7
>4 7 7 7 9 ...
># $ PatientGender : Factor w/ 3 levels "F","M","U": 2 2 2 2 2 1 1 1 1
>1 ...
># $ AcceptedSavings: num 0 0 0 0 48.9 ...
># $ BinaryAccSav : Factor w/ 2 levels "0","1": 1 1 1 1 2 2 2 2 2 2
>...
>
>Here is my call:
>
>explanatory = c("ProductName", "AgeCat", "PatientGender")
>dependent = "BinaryAccSav"
>#-------------------------------------------------------
>AcceptedSavings 1=Y 0=N
>df6 %>% finalfit(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE) -> t1 knitr::kable(t1, row.names=FALSE,
>align=c("l", "l", "r", "r", "r"))
>
>Here is the error:
>#Error: unexpected symbol in " df6 %>% finalfit(dependent,
>explanatory, p=TRUE, add_dependent_label=TRUE) -> t1 knitr"
>
>The error is identifying the knitr::kable(t1, row.names=FALSE,
>align=c("l", "l", "r", "r", "r")) as the problem
>
>I believe I have copied the procedure correctly from the tutorial and
>replaced the tutorial variables with mine.
>
>Libraries I believe are necessary:
>library("knitr", lib.loc="~/R/win-library/3.5")
>library("rmarkdown", lib.loc="~/R/win-library/3.5")
>library("htmlTable", lib.loc="~/R/win-library/3.5")
>
>And I see --Warning in install.packages : package 'kable' is not
>available (for R version 3.5.1) which I believe is my problem?
>
>
> 1. can my hunch be validated by someone please?
> 2. Is there a solution for this?
> 3. or do I contact the package authors directly?
>
>Thank you all!
>
>WHP
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:15}}
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Aug  8 18:52:07 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 8 Aug 2018 17:52:07 +0100
Subject: [R] loop over matrix: subscript out of bounds
In-Reply-To: <0d7366e7965c471dbea4a9100cef391c@GBDCVPEXC08.corp.lgc-group.com>
References: <CAJxz9NYGErgC9PMDk0Y_0c=9RwNk9RF3SXxNdPr-C0iB4G7K2Q@mail.gmail.com>
 <CAGgJW76uZnvjkm64hxREmayPAZmHjNmdExRY_oi7nHt2XrT_+w@mail.gmail.com>
 <03585e4c-abfd-9044-94ae-4e37d69880c5@sapo.pt>
 <CAJxz9NYtp0mgQuJrJQ79NtXdkcLh9WMfwmF8swns=zOySLiEDQ@mail.gmail.com>
 <23401.20102.253070.593345@stat.math.ethz.ch>
 <CAJxz9NapLW-hjNxs2sOB5QeGt7rYw4zQkEwz5_ag43_EZJ56fw@mail.gmail.com>
 <5B69AEA7.70408@sapo.pt>
 <CAJxz9NZQRfxgsdRTO1B9DFSxN4KyTygFgtWfAmKqLZu+rMTYBQ@mail.gmail.com>
 <CAGgJW75rbYjfW4yMf-T7cY2ZOJQLoo+B-i5ZxkJd0DGDhf2_zA@mail.gmail.com>
 <23402.53069.24933.691484@stat.math.ethz.ch>
 <0d7366e7965c471dbea4a9100cef391c@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <5B6B1FB7.2070309@sapo.pt>

Hello,

There are now three solutions to the OP's problem.
I have timed them and the results depend on the matrix size.

The solution I thought would be better, Enrico's diag(), is in fact the 
slowest. As for the other two, Eric's for loop is 50% fastest than the 
matrix index for small matrices but its relative performance degrades as 
the matrix becomes bigger and bigger.


library(microbenchmark)

#Enrico Schumann
mkMat_diag <- function(nr = 5, nc = 7) {
     M <- matrix(0, nr, nc)
     diag(M) <- -1
     diag(M[, -1]) <- 1
     M
}

#Eric Berger
mkMat_loop <- function(nr = 5, nc = 7) {
     M <- matrix(0, nr, nc)
     for(i in 2:nrow(M)) {
        M[i - 1, i - 1] <- -1
        M[i - 1, i] <- 1
     }
     M
}


#S.Ellison
mkMat_index <- function(nr = 5, nc = 7) {
    M <- matrix(0, nr, nc)
    i <- 1:min(nr, nc)
    j <- i[i < nc]
    M[ cbind(i, i) ] <- -1
    M[ cbind(j, j + 1) ] <- 1
    M
}



microbenchmark(
     loop = mkMat_loop(),
     index = mkMat_index(),
     diag = mkMat_diag(),
     times = 1e3
)


microbenchmark(
     loop = mkMat_loop(50, 70),
     index = mkMat_index(50, 70),
     diag = mkMat_diag(50, 70)
)


microbenchmark(
     loop = mkMat_loop(500, 700),
     index = mkMat_index(500, 700),
     diag = mkMat_diag(500, 700)
)


Hope this helps,

Rui Barradas

On 08/08/2018 12:59, S Ellison wrote:
>
>>>>>>> Eric Berger    on Wed, 8 Aug 2018 12:53:32 +0300 writes:
>>
>>> You only need one "for loop"
>>> for(i in 2:nrow(myMatrix)) {
>>>     myMatrix[i-1,i-1] = -1
>>>     myMatrix[i-1,i] = 1
>>> }
>
> Or none, with matrix-based array indexing and explicit control of the indices to prevent overrun in :
>
> mkMat <- function(n=5, m=7) {
>     M <- matrix(0, n,m)
>     i <- 1:min(n,m)
>     j <- i[i<m]
>     M[ cbind(i,i) ] <- -1
>     M[ cbind(j, j+1) ] <- 1
>     M
> }
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From r@herry8 @end|ng |rom comc@@t@net  Wed Aug  8 18:40:25 2018
From: r@herry8 @end|ng |rom comc@@t@net (rsherry8)
Date: Wed, 8 Aug 2018 12:40:25 -0400
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <5B6B1CF9.3090005@comcast.net>

I consider R to be secure. It is possible, but very unlikely, that there 
are some back door traps in R where somebody could access your data. 
There is no software that is 100% secure and R is not 100% secure.

Bob

On 8/8/2018 11:09 AM, Laurence Clark wrote:
> Hello all,
>
> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>
> My question is:
>
> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security. Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?
>
> Thank you
>
> Laurence
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> Laurence Clark
> Business Data Analyst
> Account Management
> Health Management Ltd
>
> Mobile: 		07584 556498
> Switchboard: 	0845 504 1000
> Email: 		Laurence.Clark at healthmanltd.com
> Web: 		www.healthmanagement.co.uk
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ, United Kingdom.</font>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> #####################################################################################
> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
> Download a free evaluation of MailMarshal at www.m86security.com
> #####################################################################################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From |r@nc|@@bo@teng @end|ng |rom ver@@ntphy@|c@@com  Thu Aug  9 00:42:04 2018
From: |r@nc|@@bo@teng @end|ng |rom ver@@ntphy@|c@@com (Francis Boateng)
Date: Wed, 8 Aug 2018 22:42:04 +0000
Subject: [R] exponential day
Message-ID: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>

Hi,
Please, how can I determine parameters from exponential equation
Example one:  y = a*exp(-b*x);  how do I determine ?a? and ?b?, as well as R-square from data sets. And also fitting y = a*exp(-b*x) into the data sets
Assuming data sets
A = (0,2,4,6,8,10)
B = (1,0.8,0.6,0.4,0.2,0.1)

Thanks
Francis


Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]



From R@|ner @end|ng |rom krug@@de  Thu Aug  9 09:17:06 2018
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Thu, 9 Aug 2018 09:17:06 +0200
Subject: [R] security using R at work
In-Reply-To: <5B6B1CF9.3090005@comcast.net>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
 <5B6B1CF9.3090005@comcast.net>
Message-ID: <80F1EB77-A6B0-4B42-9459-93958E7FC41C@krugs.de>

This can likely be answered for R itself, but R itself (without additional packages) is very limited. As soon as you install packages, it all depends on the package you install and if you trust the authors of these packages.

As far as I know, there is no code checking for security on CRAN (please correct me if I am wrong!).

The advantage of R and open source: you can always look into the source code and see yourself.

And as this can be done, and R is not written by a single person or company, the likelihood of a backdoor in R is very very low (lower than in many commercial products I would say).

Cheers,

Rainer


> On 8 Aug 2018, at 18:40, rsherry8 <rsherry8 at comcast.net> wrote:
> 
> I consider R to be secure. It is possible, but very unlikely, that there are some back door traps in R where somebody could access your data. There is no software that is 100% secure and R is not 100% secure.
> 
> Bob
> 
> On 8/8/2018 11:09 AM, Laurence Clark wrote:
>> Hello all,
>> 
>> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>> 
>> My question is:
>> 
>> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security. Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?
>> 
>> Thank you
>> 
>> Laurence
>> 
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> Laurence Clark
>> Business Data Analyst
>> Account Management
>> Health Management Ltd
>> 
>> Mobile: 		07584 556498
>> Switchboard: 	0845 504 1000
>> Email: 		Laurence.Clark at healthmanltd.com
>> Web: 		www.healthmanagement.co.uk
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester,
> Leicestershire, LE19 1WZ, United Kingdom.</font>
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> 
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> 
>> 
>> #####################################################################################
>> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
>> Download a free evaluation of MailMarshal at www.m86security.com
>> #####################################################################################
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180809/84663dec/attachment-0002.sig>

From R@|ner @end|ng |rom krug@@de  Thu Aug  9 09:19:23 2018
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Thu, 9 Aug 2018 09:19:23 +0200
Subject: [R] security using R at work
In-Reply-To: <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>
References: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>
Message-ID: <5ABC8474-E080-438A-8D9D-6E7B69F5F438@krugs.de>

I can not agree more, Barry. Very nicely put.

Rainer


> On 8 Aug 2018, at 18:10, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> 
> On Wed, Aug 8, 2018 at 4:09 PM, Laurence Clark
> <Laurence.Clark at healthmanltd.com> wrote:
>> Hello all,
>> 
>> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>> 
>> My question is:
>> 
>> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security.
> 
>> Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?
> 
> You are talking mostly to statisticians here, and if p>0 then there's
> "a chance". I'd say yes, there's a chance, but its pretty small, and
> would only occur through stupidity, accident or malice.
> 
> In the ordinary course of things your data will be on your hard disk,
> or on your corporate network drives, and only exist between your
> corporate network server and your PC's memory. R will load the data
> into that memory, do stuff with it in that memory, and write results
> back to hard disk. Nothing leaves the network this way.
> 
> However... R has facilities for talking to the internet. You can save
> data to google docs spreadsheets, for example, but you'd have to be
> signed in to google, and have to type something like:
> 
>> writeGoogleDoc(my_data, "secretdata.xls")
> 
> that covers "stupid". You should know that google docs are on google's
> servers, and google's servers aren't on your network, and your secret
> data shouldn't go on google's servers.
> 
> Accidents happen. You might be working on non-secret data which you
> want to save to google docs, and accidentally save "data1" which is
> secret instead of "data2" which is okay to be public. Oops. You sent
> it to google. Accidents happen.
> 
> "malice" would be if someone had put code into R or an add-on package
> that you use that sends your data over the network without you
> knowing. For example maybe every time you fit a linear model with:
> 
> lm(age~beauty, data=people)
> 
> R could be transmitting the data to hackers. But the chance of this is
> very small, and I don't think any malicious code has ever been
> discovered in R or the 12000 add-on packages downloadable from CRAN.
> Doesn't mean it hasn't been discovered yet or won't be in the future.
> 
> It used to be said that the only machine safe from hackers was one
> unplugged from the network. But now hackers can get to your machine
> via malicious USB sticks, keyboard loggers, and various other nasties.
> The only machine safe from hackers is one with the power off. But take
> the power plug out because a wake-on-lan packet could switch your
> machine on remotely....
> 
> Barry
> 
> 
> 
> 
> 
> 
> 
>> Thank you
>> 
>> Laurence
>> 
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> Laurence Clark
>> Business Data Analyst
>> Account Management
>> Health Management Ltd
>> 
>> Mobile:                 07584 556498
>> Switchboard:    0845 504 1000
>> Email:          Laurence.Clark at healthmanltd.com
>> Web:            www.healthmanagement.co.uk
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester,
>  Leicestershire, LE19 1WZ, United Kingdom.</font>
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> 
>> 
>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> 
>> 
>> #####################################################################################
>> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
>> Download a free evaluation of MailMarshal at www.m86security.com
>> #####################################################################################
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180809/cf997365/attachment-0002.sig>

From m@rc_grt @end|ng |rom y@hoo@|r  Thu Aug  9 09:57:48 2018
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Thu, 9 Aug 2018 09:57:48 +0200
Subject: [R] sub/grep question: extract year
Message-ID: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>

Hi everybody,

I have some questions about the way that sub is working. I hope that 
someone has the answer:

1/ Why the second example does not return an empty string ? There is no 
match.

subtext <- "-1980-"
sub(".*(1980).*", "\\1", subtext) # return 1980
sub(".*(1981).*", "\\1", subtext) # return -1980-

2/ Based on sub documentation, it replaces the first occurence of a 
pattern: why it does not return 1980 ?

subtext <- " 1980 1981 "
sub(".*(198[01]).*", "\\1", subtext) # return 1981

3/ I want extract year from text; I use:

subtext <- "bla 1980 bla"
sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) # 
return 1980
subtext <- "bla 2010 bla"
sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) # 
return 2010

but

subtext <- "bla 1010 bla"
sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) # 
return 1010

I would like exclude the case 1010 and other like this.

The solution would be:

18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]

Is there a solution to write such a pattern in grep ?

Thanks a lot

Marc



From rhe|p @end|ng |rom eoo@@dd@@n|  Thu Aug  9 10:14:01 2018
From: rhe|p @end|ng |rom eoo@@dd@@n| (Jan van der Laan)
Date: Thu, 9 Aug 2018 10:14:01 +0200
Subject: [R] security using R at work
In-Reply-To: <5ABC8474-E080-438A-8D9D-6E7B69F5F438@krugs.de>
References: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>
 <5ABC8474-E080-438A-8D9D-6E7B69F5F438@krugs.de>
Message-ID: <bed18a4a-c40c-06c2-e6b5-ae86de697080@eoos.dds.nl>

You can also inadvertently transmit data to the internet using a package 
without being obviously 'stupid', e.g. by using a package that uses an 
external service for data processing. For example, some javascript 
visualisation libs can do that (not sure if those wrapped in R-packages 
do), or, for example, a geocoding service.

Not having an (outgoing) internet connection at least helps against 
mistakes like this (and probably against many untargeted attacks). If it 
is allowed to have the sensitive data on that computer, using R on that 
computer is probably not going to make is less safe.

Jan


On 09-08-18 09:19, Rainer M Krug wrote:
> I can not agree more, Barry. Very nicely put.
> 
> Rainer
> 
> 
>> On 8 Aug 2018, at 18:10, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
>>
>> On Wed, Aug 8, 2018 at 4:09 PM, Laurence Clark
>> <Laurence.Clark at healthmanltd.com> wrote:
>>> Hello all,
>>>
>>> I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.
>>>
>>> My question is:
>>>
>>> If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security.
>>
>>> Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?
>>
>> You are talking mostly to statisticians here, and if p>0 then there's
>> "a chance". I'd say yes, there's a chance, but its pretty small, and
>> would only occur through stupidity, accident or malice.
>>
>> In the ordinary course of things your data will be on your hard disk,
>> or on your corporate network drives, and only exist between your
>> corporate network server and your PC's memory. R will load the data
>> into that memory, do stuff with it in that memory, and write results
>> back to hard disk. Nothing leaves the network this way.
>>
>> However... R has facilities for talking to the internet. You can save
>> data to google docs spreadsheets, for example, but you'd have to be
>> signed in to google, and have to type something like:
>>
>>> writeGoogleDoc(my_data, "secretdata.xls")
>>
>> that covers "stupid". You should know that google docs are on google's
>> servers, and google's servers aren't on your network, and your secret
>> data shouldn't go on google's servers.
>>
>> Accidents happen. You might be working on non-secret data which you
>> want to save to google docs, and accidentally save "data1" which is
>> secret instead of "data2" which is okay to be public. Oops. You sent
>> it to google. Accidents happen.
>>
>> "malice" would be if someone had put code into R or an add-on package
>> that you use that sends your data over the network without you
>> knowing. For example maybe every time you fit a linear model with:
>>
>> lm(age~beauty, data=people)
>>
>> R could be transmitting the data to hackers. But the chance of this is
>> very small, and I don't think any malicious code has ever been
>> discovered in R or the 12000 add-on packages downloadable from CRAN.
>> Doesn't mean it hasn't been discovered yet or won't be in the future.
>>
>> It used to be said that the only machine safe from hackers was one
>> unplugged from the network. But now hackers can get to your machine
>> via malicious USB sticks, keyboard loggers, and various other nasties.
>> The only machine safe from hackers is one with the power off. But take
>> the power plug out because a wake-on-lan packet could switch your
>> machine on remotely....
>>
>> Barry
>>
>>
>>
>>
>>
>>
>>
>>> Thank you
>>>
>>> Laurence
>>>
>>>
>>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>> Laurence Clark
>>> Business Data Analyst
>>> Account Management
>>> Health Management Ltd
>>>
>>> Mobile:                 07584 556498
>>> Switchboard:    0845 504 1000
>>> Email:          Laurence.Clark at healthmanltd.com
>>> Web:            www.healthmanagement.co.uk
>>>
>>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester,
>>   Leicestershire, LE19 1WZ, United Kingdom.</font>
>>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>
>>>
>>> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>
>>>
>>> #####################################################################################
>>> Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
>>> Download a free evaluation of MailMarshal at www.m86security.com
>>> #####################################################################################
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
> 
> University of Z?rich
> 
> Cell:       +41 (0)78 630 66 57
> email:      Rainer at krugs.de
> Skype:      RMkrug
> 
> PGP: 0x0F52F982
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

From b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk  Thu Aug  9 10:25:03 2018
From: b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk (Barry Rowlingson)
Date: Thu, 9 Aug 2018 09:25:03 +0100
Subject: [R] security using R at work
In-Reply-To: <c8f6ca37d73f4b2bbfb64478775a6b08@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
References: <9331aa81dd1f417d80b6a56488082398@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczOevHn3Mu-4A2qWfr5DiXL_gCwdS_cbEgkPpP0LW2M+RA@mail.gmail.com>
 <5ABC8474-E080-438A-8D9D-6E7B69F5F438@krugs.de>
 <c8f6ca37d73f4b2bbfb64478775a6b08@LNXP265MB1290.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CANVKczOoKLWm9GB+NGcFUpn=oZGXrYoxYp=Z61TRVwuyJ1nMig@mail.gmail.com>

On Thu, Aug 9, 2018 at 9:14 AM, Jan van der Laan <rhelp at eoos.dds.nl> wrote:
> You can also inadvertently transmit data to the internet using a package
> without being obviously 'stupid', e.g. by using a package that uses an
> external service for data processing. For example, some javascript
> visualisation libs can do that (not sure if those wrapped in R-packages
> do), or, for example, a geocoding service.

 Ooh yes, that's probably a whole new category.  Maybe "Unwittingly"
describes this - it could be the users fault for not reading or
understanding the documentation or the package authors fault for not
documenting the network activity properly. Leave that one to the
lawyers to decide.

Barry



From po|@@on200 @end|ng |rom goog|em@||@com  Thu Aug  9 10:44:31 2018
From: po|@@on200 @end|ng |rom goog|em@||@com (john matthew)
Date: Thu, 9 Aug 2018 09:44:31 +0100
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <CA+b7HP1q4juNNXJ0JOR-g1+NjiDt4PrqMLjHUmHtn=q3_wszMA@mail.gmail.com>

Hello Laurence.
Taking a pragmatic approach.

If the data is so valuable and secret but also needs some analysis in R,
here is suggested steps to minimise security risks.

1. Plan the analysis up front, what exactly what you want and the outcomes.
2. Take a laptop with Internet, install R and all packages needed for the
planned analysis.
3. Unplug ethernet and turn off blue tooth and wifi. So no internet access
at all.
4. Bring your secret data via USB or cd.
5. Perform the R analysis and export reports and figures etc to safe place.
6. Delete R, the data and all packages from laptop before using online
again.

A bit extreme and may still be some risk but its minimal as the analysis
was done offline, and you removed R etc after. But now have a set of R
results.

Just an idea.

John.


On 8 Aug 2018 16:53, "Laurence Clark" <Laurence.Clark at healthmanltd.com>
wrote:

> Hello all,
>
> I want to download R and use it for work purposes. I hope to use it to
> analyse very sensitive data from our clients.
>
> My question is:
>
> If I install R on my work network computer, will the data ever leave our
> network? I need to know if the data goes anywhere other than our network,
> because this could compromise it's security. Is there is any chance the
> data could go to a server owned by 'R' or anything else that's not
> immediately obvious, but constitutes the data leaving our network?
>
> Thank you
>
> Laurence
>
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
> Laurence Clark
> Business Data Analyst
> Account Management
> Health Management Ltd
>
> Mobile:                 07584 556498
> Switchboard:    0845 504 1000
> Email:          Laurence.Clark at healthmanltd.com
> Web:            www.healthmanagement.co.uk
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole
> use of the intended recipients and may contain confidential and privileged
> information or otherwise be protected by law. Any unauthorised review, use,
> disclosure or distribution is prohibited. If you are not the intended
> recipient, please contact the sender, and destroy all copies and the
> original message.<BR><BR>MAXIMUS People Services Limited is registered in
> England and Wales (registered number: 03752300); registered office: 202 -
> 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health
> and Disability Assessments Ltd (registered number: 9072343) and Health
> Management Ltd (registered number: 4369949) are registered in England and
> Wales. The registered office for each is Ash House, The Broyle, Ringmer,
> East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in
> England and Wales (registered number: 09457025); registered office: 18c
> Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ,
> United Kingdom.</font>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
>
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
>
>
> ############################################################
> #########################
> Scanned by MailMarshal - M86 Security's comprehensive email content
> security solution.
> Download a free evaluation of MailMarshal at www.m86security.com
> ############################################################
> #########################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m|@ojpm @end|ng |rom gm@||@com  Thu Aug  9 10:58:14 2018
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 9 Aug 2018 16:58:14 +0800
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
 <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
Message-ID: <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>

Hi,

   I try to run the same f-test by lm (with summary) and the function
"linearHypothesis" in car package. Why are the results (p-values for the
f-test) different?


> df1<-data.frame(x=c(2,3,4), y=c(7,6,8))
> lm1<-lm(y~x, df1)
> lm1

Call:
lm(formula = y ~ x, data = df1)

Coefficients:
(Intercept)            x
        5.5          0.5

> summary(lm1)

Call:
lm(formula = y ~ x, data = df1)

Residuals:
   1    2    3
 0.5 -1.0  0.5

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)    5.500      2.693   2.043    0.290
x              0.500      0.866   0.577    0.667

Residual standard error: 1.225 on 1 degrees of freedom
Multiple R-squared:   0.25, Adjusted R-squared:   -0.5
F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667

> linearHypothesis(lm1, c("(Intercept)=0", "x=0"))
Linear hypothesis test

Hypothesis:
(Intercept) = 0
x = 0

Model 1: restricted model
Model 2: y ~ x

  Res.Df   RSS Df Sum of Sq      F Pr(>F)
1      3 149.0
2      1   1.5  2     147.5 49.167 0.1003

2018-08-03 13:54 GMT+08:00 Annaert Jan <jan.annaert at uantwerpen.be>:

> You can easily test linear restrictions using the function
> linearHypothesis() from the car package.
> There are several ways to set up the null hypothesis, but a
> straightforward one here is:
>
> > library(car)
> > x <- rnorm(10)
> > y <- x+rnorm(10)
> > linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
> Linear hypothesis test
>
> Hypothesis:
> (Intercept) = 0
> x = 1
>
> Model 1: restricted model
> Model 2: y ~ x
>
>   Res.Df     RSS Df Sum of Sq      F Pr(>F)
> 1     10 10.6218
> 2      8  9.0001  2    1.6217 0.7207 0.5155
>
>
> Jan
>
> From: R-help <r-help-bounces at r-project.org> on behalf of John <
> miaojpm at gmail.com>
> Date: Thursday, 2 August 2018 at 10:44
> To: r-help <r-help at r-project.org>
> Subject: [R] F-test where the coefficients in the H_0 is nonzero
>
> Hi,
>
>    I try to run the regression
>    y = beta_0 + beta_1 x
>    and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
>    I believe I can run the regression
>    (y-x) = beta_0 +beta_1? x
>    and do the regular F-test (using lm functio) where the hypothesized
> coefficients are all zero.
>
>    Is there any function in R that deal with the case where the
> coefficients are nonzero?
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]



From m@rk|eed@2 @end|ng |rom gm@||@com  Thu Aug  9 11:10:27 2018
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Thu, 9 Aug 2018 05:10:27 -0400
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
 <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
 <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
Message-ID: <CAHz+bWYsk5_QikbM5P_2S9mrSCBtDwH6xAgLs-tMLtG+8Ua__w@mail.gmail.com>

Hi: the F-test is a joint hypothesis ( I never used that function from the
car package but it sounds like it is )  and the t-statistics
that come  out of a  regression are "conditional" in the sense that they
test the significance of one coefficient given the other so you wouldn't
expect the two outputs to be the same.




On Thu, Aug 9, 2018 at 4:58 AM, John <miaojpm at gmail.com> wrote:

> Hi,
>
>    I try to run the same f-test by lm (with summary) and the function
> "linearHypothesis" in car package. Why are the results (p-values for the
> f-test) different?
>
>
> > df1<-data.frame(x=c(2,3,4), y=c(7,6,8))
> > lm1<-lm(y~x, df1)
> > lm1
>
> Call:
> lm(formula = y ~ x, data = df1)
>
> Coefficients:
> (Intercept)            x
>         5.5          0.5
>
> > summary(lm1)
>
> Call:
> lm(formula = y ~ x, data = df1)
>
> Residuals:
>    1    2    3
>  0.5 -1.0  0.5
>
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)    5.500      2.693   2.043    0.290
> x              0.500      0.866   0.577    0.667
>
> Residual standard error: 1.225 on 1 degrees of freedom
> Multiple R-squared:   0.25, Adjusted R-squared:   -0.5
> F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667
>
> > linearHypothesis(lm1, c("(Intercept)=0", "x=0"))
> Linear hypothesis test
>
> Hypothesis:
> (Intercept) = 0
> x = 0
>
> Model 1: restricted model
> Model 2: y ~ x
>
>   Res.Df   RSS Df Sum of Sq      F Pr(>F)
> 1      3 149.0
> 2      1   1.5  2     147.5 49.167 0.1003
>
> 2018-08-03 13:54 GMT+08:00 Annaert Jan <jan.annaert at uantwerpen.be>:
>
> > You can easily test linear restrictions using the function
> > linearHypothesis() from the car package.
> > There are several ways to set up the null hypothesis, but a
> > straightforward one here is:
> >
> > > library(car)
> > > x <- rnorm(10)
> > > y <- x+rnorm(10)
> > > linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
> > Linear hypothesis test
> >
> > Hypothesis:
> > (Intercept) = 0
> > x = 1
> >
> > Model 1: restricted model
> > Model 2: y ~ x
> >
> >   Res.Df     RSS Df Sum of Sq      F Pr(>F)
> > 1     10 10.6218
> > 2      8  9.0001  2    1.6217 0.7207 0.5155
> >
> >
> > Jan
> >
> > From: R-help <r-help-bounces at r-project.org> on behalf of John <
> > miaojpm at gmail.com>
> > Date: Thursday, 2 August 2018 at 10:44
> > To: r-help <r-help at r-project.org>
> > Subject: [R] F-test where the coefficients in the H_0 is nonzero
> >
> > Hi,
> >
> >    I try to run the regression
> >    y = beta_0 + beta_1 x
> >    and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
> >    I believe I can run the regression
> >    (y-x) = beta_0 +beta_1? x
> >    and do the regular F-test (using lm functio) where the hypothesized
> > coefficients are all zero.
> >
> >    Is there any function in R that deal with the case where the
> > coefficients are nonzero?
> >
> > John
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@rc_grt @end|ng |rom y@hoo@|r  Thu Aug  9 11:19:51 2018
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Thu, 9 Aug 2018 11:19:51 +0200
Subject: [R] sub/grep question: extract year
In-Reply-To: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
References: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
Message-ID: <2c6cfa13-34e7-b327-2617-9c74ab25e45e@yahoo.fr>

I answer myself to the third point:
This pattern is better to get a year:

pattern.year <- ".*\\b(18|19|20)([0-9][0-9])\\b.*"

subtext <- "bla 1880 bla"
sub(pattern.year, "\\1\\2", subtext) # return 1880
subtext <- "bla 1980 bla"
sub(pattern.year, "\\1\\2", subtext) # return 1980
subtext <- "bla 2010 bla"
sub(pattern.year, "\\1\\2", subtext) # return 2010
subtext <- "bla 1010 bla"
sub(pattern.year, "\\1\\2", subtext) # return bla 1010 bla
subtext <- "bla 3010 bla"
sub(pattern.year, "\\1\\2", subtext) # return bla 3010 bla

Marc


Le 09/08/2018 ? 09:57, Marc Girondot via R-help a ?crit?:
> Hi everybody,
>
> I have some questions about the way that sub is working. I hope that 
> someone has the answer:
>
> 1/ Why the second example does not return an empty string ? There is 
> no match.
>
> subtext <- "-1980-"
> sub(".*(1980).*", "\\1", subtext) # return 1980
> sub(".*(1981).*", "\\1", subtext) # return -1980-
>
> 2/ Based on sub documentation, it replaces the first occurence of a 
> pattern: why it does not return 1980 ?
>
> subtext <- " 1980 1981 "
> sub(".*(198[01]).*", "\\1", subtext) # return 1981
>
> 3/ I want extract year from text; I use:
>
> subtext <- "bla 1980 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 1980
> subtext <- "bla 2010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 2010
>
> but
>
> subtext <- "bla 1010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 1010
>
> I would like exclude the case 1010 and other like this.
>
> The solution would be:
>
> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>
> Is there a solution to write such a pattern in grep ?
>
> Thanks a lot
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From po|@@on200 @end|ng |rom goog|em@||@com  Thu Aug  9 11:36:36 2018
From: po|@@on200 @end|ng |rom goog|em@||@com (john matthew)
Date: Thu, 9 Aug 2018 10:36:36 +0100
Subject: [R] sub/grep question: extract year
In-Reply-To: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
References: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
Message-ID: <CA+b7HP27j0uHjRdfPNnRSyDYqCp6a23wKe39uGWLaUc5a=P8FQ@mail.gmail.com>

Hi Marc.
For question 1.
I know in Perl that regular expressions when captured can be saved if not
overwritten. \\1 is the capture variable in your R examples.

So the 2nd regular expression does not match but \\1 still has 1980
captured from the previous expression, hence the result.

Maybe if you restart R and try your 2nd expression first, \\1 will be empty
or no match result.

Just speculation :)

John


On 9 Aug 2018 08:58, "Marc Girondot via R-help" <r-help at r-project.org>
wrote:

> Hi everybody,
>
> I have some questions about the way that sub is working. I hope that
> someone has the answer:
>
> 1/ Why the second example does not return an empty string ? There is no
> match.
>
> subtext <- "-1980-"
> sub(".*(1980).*", "\\1", subtext) # return 1980
> sub(".*(1981).*", "\\1", subtext) # return -1980-
>
> 2/ Based on sub documentation, it replaces the first occurence of a
> pattern: why it does not return 1980 ?
>
> subtext <- " 1980 1981 "
> sub(".*(198[01]).*", "\\1", subtext) # return 1981
>
> 3/ I want extract year from text; I use:
>
> subtext <- "bla 1980 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
> return 1980
> subtext <- "bla 2010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
> return 2010
>
> but
>
> subtext <- "bla 1010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
> return 1010
>
> I would like exclude the case 1010 and other like this.
>
> The solution would be:
>
> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>
> Is there a solution to write such a pattern in grep ?
>
> Thanks a lot
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@yur@t@de @end|ng |rom gm@||@com  Thu Aug  9 08:20:06 2018
From: m@yur@t@de @end|ng |rom gm@||@com (Mayur Tade)
Date: Thu, 9 Aug 2018 11:50:06 +0530
Subject: [R] error with the expand.grid command
Message-ID: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>

 hello sir...
i am trying to extract the chlorophyll data of particular lat and lon from
the world chlorophyll data from the netcdf file in R. as i am new to R i am
facing the problem related to it when i am trying expand.grid command it is
showing me this message.....message is followed.....its my kind request
please help me with the same
ttt<-expand.grid(lon,lat,time)
Error in paste0(nmc[i], "=", if (is.numeric(x)) format(x) else x) :
  cannot coerce type 'closure' to vector of type 'character'

here is the print of my netcdf file for you kind information.....follow...

> print(tt)
File E:\chlorophyll data research student..mayur
t..KUFOS\1997\ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_
GEO_PML_OCx-199709-fv3.1.nc
<http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
(NC_FORMAT_NETCDF4_CLASSIC):

     9 variables (excluding dimension variables):
        float MERIS_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the number of observations from the MERIS
sensor contributing to this bin cell
            number_of_files_composited: 19
        float MODISA_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the number of observations from the MODIS
(Aqua) sensor contributing to this bin cell
            number_of_files_composited: 19
        float SeaWiFS_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the number of observations from the SeaWiFS
(GAC and LAC) sensor contributing to this bin cell
            number_of_files_composited: 19
        float VIIRS_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the number of observations from the VIIRS
sensor contributing to this bin cell
            number_of_files_composited: 19
        float chlor_a[lon,lat,time]
            _FillValue: 9.96920996838687e+36
            long_name: Chlorophyll-a concentration in seawater (not
log-transformed), generated by SeaDAS using a blended combination of OCI
(OC4v6 + Hu's CI), OC3 and OC5, depending on water class memberships
            units: milligram m-3
            ancillary_variables: chlor_a_log10_rmsd chlor_a_log10_bias
            grid_mapping: crs
            standard_name: mass_concentration_of_chlorophyll_a_in_sea_water
            units_nonstandard: mg m^-3
            parameter_vocab_uri:
http://vocab.nerc.ac.uk/collection/P04/current/
        float chlor_a_log10_bias[lon,lat,time]
            _FillValue: 9.96920996838687e+36
            long_name: Bias of log10-transformed chlorophyll-a concentration
in seawater.
            grid_mapping: crs
            rel: uncertainty
            comment: Uncertainty lookups derived from file:
/data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
cci_chla_bias.dat
            ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
        float chlor_a_log10_rmsd[lon,lat,time]
            _FillValue: 9.96920996838687e+36
            long_name: Root-mean-square-difference of log10-transformed
chlorophyll-a concentration in seawater.
            grid_mapping: crs
            rel: uncertainty
            comment: Uncertainty lookups derived from file:
/data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
cci_chla_rmsd.dat
            ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
        int crs[time]
            grid_mapping_name: latitude_longitude
        float total_nobs_sum[lon,lat,time]
            _FillValue: 0
            long_name: Count of the total number of observations
contributing to this bin cell
            number_of_files_composited: 19

     3 dimensions:
        time  Size:1
            axis: T
            standard_name: time
            units: days since 1970-01-01 00:00:00
        lat  Size:4320
            units: degrees_north
            long_name: latitude
            standard_name: latitude
            valid_min: -89.9791641235352
            valid_max: 89.9791641235352
            axis: Y
        lon  Size:8640
            units: degrees_east
            long_name: longitude
            standard_name: longitude
            valid_min: -179.97917175293
            valid_max: 179.97917175293
            axis: X

    47 global attributes:
        Metadata_Conventions: Unidata Dataset Discovery v1.0
        cdm_data_type: Grid
        comment: See summary attribute
        creator_email: help at esa-oceancolour-cci.org
        creator_name: Plymouth Marine Laboratory
        creator_url: http://esa-oceancolour-cci.org
        geospatial_lat_max: 90
        geospatial_lat_min: -90
        geospatial_lat_resolution: .04166666666666666666
        geospatial_lat_units: decimal degrees north
        geospatial_lon_max: 180
        geospatial_lon_min: -180
        geospatial_lon_resolution: .04166666666666666666
        geospatial_lon_units: decimal degrees east
        geospatial_vertical_max: 0
        geospatial_vertical_min: 0
        institution: Plymouth Marine Laboratory
        keywords: satellite,observation,ocean,ocean colour
        keywords_vocabulary: none
        license: ESA CCI Data Policy: free and open access.  When
referencing, please use: Ocean Colour Climate Change Initiative dataset,
Version <Version Number>, European Space Agency, available online at
http://www.esa-oceancolour-cci.org.  We would also appreciate being notified
of publications so that we can list them on the project website at
http://www.esa-oceancolour-cci.org/?q=publications
        naming_authority: uk.ac.pml
        number_of_optical_water_types: 14
        platform: Orbview-2,Aqua,Envisat,Suomi-NPP
        processing_level: Level-3
        project: Climate Change Initiative - European Space Agency
        references: http://www.esa-oceancolour-cci.org/
        sensor: SeaWiFS,MODIS,MERIS,VIIRS
        source: NASA SeaWiFS L2 R2014.0 LAC and GAC, MODIS-Aqua L1A, MERIS
L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L2 R2014.0.1 (data
identical to R2014.0.2)
        spatial_resolution: 4km nominal at equator
        standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata
Conventions Version 1.6
        title: ESA CCI Ocean Colour Product
        number_of_files_composited: 19
        creation_date: Tue Aug 23 09:00:23 2016
        date_created: Tue Aug 23 09:00:23 2016
        time_coverage_resolution: P1M
        time_coverage_duration: P1M
        start_date: 01-SEP-1997 00:00:00.000000
        stop_date: 30-SEP-1997 23:59:00.000000
        time_coverage_start: 199709010000Z
        time_coverage_end: 199709302359Z
        netcdf_file_type: NETCDF4_CLASSIC
        history: Source data were:
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970904-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970904-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970906-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970906-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970909-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970909-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970910-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970910-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970915-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970915-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970916-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970916-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970918-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970918-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970919-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970919-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970920-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970920-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970921-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970921-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970922-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970922-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970923-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970923-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970924-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970924-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970925-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970925-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970926-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970926-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970927-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970927-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970928-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970928-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970929-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970929-fv3.1.nc/>
,
ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
OCx_QAA-19970930-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970930-fv3.1.nc/>
;
netcdf_compositor_cci composites  Rrs_412, Rrs_443, Rrs_490, Rrs_510,
Rrs_555, Rrs_670, water_class1, water_class2, water_class3, water_class4,
water_class5, water_class6, water_class7, water_class8, water_class9,
water_class10, water_class11, water_class12, water_class13, water_class14,
atot_412, atot_443, atot_490, atot_510, atot_555, atot_670, aph_412,
aph_443, aph_490, aph_510, aph_555, aph_670, adg_412, adg_443, adg_490,
adg_510, adg_555, adg_670, bbp_412, bbp_443, bbp_490, bbp_510, bbp_555,
bbp_670, chlor_a, kd_490, chlor_a_log10_bias, Rrs_412_bias, Rrs_443_bias,
Rrs_490_bias, Rrs_510_bias, Rrs_555_bias, Rrs_670_bias, aph_412_bias,
aph_443_bias, aph_490_bias, aph_510_bias, aph_555_bias, aph_670_bias,
adg_412_bias, adg_443_bias, adg_490_bias, adg_510_bias, adg_555_bias,
adg_670_bias, kd_490_bias with --mean,  chlor_a_log10_rmsd, Rrs_412_rmsd,
Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_555_rmsd, Rrs_670_rmsd,
aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_555_rmsd,
aph_670_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd,
adg_555_rmsd, adg_670_rmsd, kd_490_rmsd with --root-mean-square, and
SeaWiFS_nobs, MODISA_nobs, MERIS_nobs, VIIRS_nobs, total_nobs - with --total
1471940520 Subsetted from
standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_
MONTHLY_4km_GEO_PML_OCx_QAA-199709-fv3.1.nc
<http://esacci-oc-l3s-oc_products-merged-1m_monthly_4km_geo_pml_ocx_qaa-199709-fv3.1.nc/>
to only include variables
MERIS_nobs_sum,MODISA_nobs_sum,SeaWiFS_nobs_sum,VIIRS_
nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,
crs,lat,lon,time,total_nobs_sum
        Conventions: CF-1.6
        product_version: 3.1
        summary: Data products generated by the Ocean Colour component of
the European Space Agency Climate Change Initiative project. These files are
daily composites of merged sensor (MERIS, MODIS Aqua, SeaWiFS LAC & GAC,
VIIRS) products.  MODIS Aqua and MERIS were band-shifted and bias-corrected
to SeaWiFS bands and values using a temporally and spatially varying scheme
based on the overlap years of 2003-2007.  VIIRS was band-shifted and
bias-corrected in a second stage against the MODIS Rrs that had already been
corrected to SeaWiFS levels, for the overlap period 2012-2013.  VIIRS and
SeaWiFS Rrs were derived from standard NASA L2 products; MERIS and MODIS
from a combination of NASA's l2gen (for basic sensor geometry corrections,
etc) and HYGEOS Polymer v3.5 (for atmospheric correction).  The Rrs were
binned to a sinusoidal 4km level-3 grid, and later to 4km geographic
projection, by Brockmann Consult's BEAM.  Derived products were generally
computed with the standard SeaDAS algorithms.  QAA IOPs were derived using
the standard SeaDAS algorithm but with a modified backscattering table to
match that used in the bandshifting.  The final chlorophyll is a combination
of OC4, Hu's CI and OC5, depending on the water class memberships.
Uncertainty estimates were added using the fuzzy water classifier and
uncertainty estimation algorithm of Tim Moore as documented in Jackson et al
(2017).
        tracking_id: 659b397a-953c-4814-a3e2-460d6218fcfa
        id:
ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-199709-fv3.1.nc
<http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>

	[[alternative HTML version deleted]]



From K@th@r|n@@Fr|t@ch @end|ng |rom nn|@co@uk  Thu Aug  9 10:24:15 2018
From: K@th@r|n@@Fr|t@ch @end|ng |rom nn|@co@uk (Fritsch, Katharina (NNL))
Date: Thu, 9 Aug 2018 08:24:15 +0000
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <1B674C66F0DD4343BA5DD0C025217F9F02270AAD@CSSPWD2PRAP1147.SSA-Intra.net>

Hiya,
I work in a very security conscious organisation and we happily use R. The average user can only use R via RStudio Server, with a limited number of packages available, so that adds an additional level of control.
That said, are you sure that the sentence 'a few people on a mailing list said it would be alright' is going to convince your IT department of the harmlessness of R?
Cheers,
Katharina.

--

Dr Katharina Fritsch B.Sc. M.Sc. MRSC
Chemical Modeller, Chemical and Process Modelling


E.
katharina.fritsch at nnl.co.uk
T.
+44 (0)1925 289387
@uknnl

National Nuclear Laboratory Limited, 5th Floor, Chadwick House,
Birchwood Park, Warrington, WA3 6AE, UK

www.nnl.co.uk


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Laurence Clark
Sent: 08 August 2018 16:10
To: 'r-help at r-project.org'
Subject: [R] security using R at work

Hello all,

I want to download R and use it for work purposes. I hope to use it to analyse very sensitive data from our clients.

My question is:

If I install R on my work network computer, will the data ever leave our network? I need to know if the data goes anywhere other than our network, because this could compromise it's security. Is there is any chance the data could go to a server owned by 'R' or anything else that's not immediately obvious, but constitutes the data leaving our network?

Thank you

Laurence


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Laurence Clark
Business Data Analyst
Account Management
Health Management Ltd

Mobile:                 07584 556498
Switchboard:    0845 504 1000
Email:          Laurence.Clark at healthmanltd.com
Web:            BLOCKEDhealthmanagement[.]co[.]ukBLOCKED

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole use of the intended recipients and may contain confidential and privileged information or otherwise be protected by law. Any unauthorised review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender, and destroy all copies and the original message.<BR><BR>MAXIMUS People Services Limited is registered in England and Wales (registered number: 03752300); registered office: 202 - 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health and Disability Assessments Ltd (registered number: 9072343) and Health Management Ltd (registered number: 4369949) are registered in England and Wales. The registered office for each is Ash House, The Broyle, Ringmer, East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in England and Wales (registered number: 09457025); registered office: 18c Meridian East, Meridian Business Park, Leicester, Leicestershire, LE19 1WZ, United Kingdom.</font>
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


#####################################################################################
Scanned by MailMarshal - M86 Security's comprehensive email content security solution.
Download a free evaluation of MailMarshal at BLOCKEDm86security[.]comBLOCKED
#####################################################################################

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
BLOCKEDstat[.]ethz[.]ch/mailman/listinfo/r-helpBLOCKED
PLEASE do read the posting guide BLOCKEDR-project[.]org/posting-guide[.]htmlBLOCKED
and provide commented, minimal, self-contained, reproducible code.
*****************************************************************************
This message was received by the Cloud Security Email Gateway

and was checked for Viruses and SPAM by the Cloud Security Email Management Service.
Please forward any suspicious or unwanted emails to "Spam Helpdesk"
*****************************************************************************


This e-mail is from National Nuclear Laboratory Limited ("NNL"). This e-mail and any attachments are intended for the addressee and may also be legally privileged. If you are not the intended recipient please do not print, re-transmit, store or act in reliance on it or any attachments. Instead, please e-mail it back to the sender and then immediately permanently delete it.

National Nuclear Laboratory Limited (Company number 3857752) Registered in England and Wales. Registered office: Chadwick House, Warrington Road, Birchwood Park, Warrington, WA3 6AE.



From m@rc@g|rondot @end|ng |rom u-p@ud@|r  Thu Aug  9 11:17:28 2018
From: m@rc@g|rondot @end|ng |rom u-p@ud@|r (Marc Girondot)
Date: Thu, 9 Aug 2018 11:17:28 +0200
Subject: [R] sub/grep question: extract year
In-Reply-To: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
References: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
Message-ID: <43e498eb-21e7-605a-f58c-dc66fec49fb2@u-psud.fr>

I answer myself to the third point:
This pattern is better :

pattern.year <- ".*\\b(18|19|20)([0-9][0-9])\\b.*"

subtext <- "bla 1880 bla"
sub(pattern.year, "\\1\\2", subtext) # return 1880
subtext <- "bla 1980 bla"
sub(pattern.year, "\\1\\2", subtext) # return 1980
subtext <- "bla 2010 bla"
sub(pattern.year, "\\1\\2", subtext) # return 2010
subtext <- "bla 1010 bla"
sub(pattern.year, "\\1\\2", subtext) # return bla 1010 bla
subtext <- "bla 3010 bla"
sub(pattern.year, "\\1\\2", subtext) # return bla 3010 bla

Marc

Le 09/08/2018 ? 09:57, Marc Girondot via R-help a ?crit?:
> Hi everybody,
>
> I have some questions about the way that sub is working. I hope that 
> someone has the answer:
>
> 1/ Why the second example does not return an empty string ? There is 
> no match.
>
> subtext <- "-1980-"
> sub(".*(1980).*", "\\1", subtext) # return 1980
> sub(".*(1981).*", "\\1", subtext) # return -1980-
>
> 2/ Based on sub documentation, it replaces the first occurence of a 
> pattern: why it does not return 1980 ?
>
> subtext <- " 1980 1981 "
> sub(".*(198[01]).*", "\\1", subtext) # return 1981
>
> 3/ I want extract year from text; I use:
>
> subtext <- "bla 1980 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 1980
> subtext <- "bla 2010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 2010
>
> but
>
> subtext <- "bla 1010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) 
> # return 1010
>
> I would like exclude the case 1010 and other like this.
>
> The solution would be:
>
> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>
> Is there a solution to write such a pattern in grep ?
>
> Thanks a lot
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
__________________________________________________________
Marc Girondot, Pr

Laboratoire Ecologie, Syst?matique et Evolution
Equipe de Conservation des Populations et des Communaut?s
CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
B?timent 362
91405 Orsay Cedex, France

Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
e-mail: marc.girondot at u-psud.fr
Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
Skype: girondot



From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Thu Aug  9 11:32:36 2018
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Thu, 9 Aug 2018 11:32:36 +0200 (CEST)
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
 <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
 <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1808091129010.22455@paninaro>

On Thu, 9 Aug 2018, John wrote:

> Hi,
>
>   I try to run the same f-test by lm (with summary) and the function
> "linearHypothesis" in car package. Why are the results (p-values for the
> f-test) different?

The standard F test in the summary output tests the hypothesis that all 
coefficients _except the intercept_ are zero. Thus, all of these are the 
same:

summary(lm1)
## ...
## F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667

linearHypothesis(lm1, "x = 0")
## ...
##   Res.Df RSS Df Sum of Sq      F Pr(>F)
## 1      2 2.0
## 2      1 1.5  1       0.5 0.3333 0.6667

lm0 <- lm(y ~ 1, data = df1)
anova(lm0, lm1)
## ...
##   Res.Df RSS Df Sum of Sq      F Pr(>F)
## 1      2 2.0
## 2      1 1.5  1       0.5 0.3333 0.6667


>
>> df1<-data.frame(x=c(2,3,4), y=c(7,6,8))
>> lm1<-lm(y~x, df1)
>> lm1
>
> Call:
> lm(formula = y ~ x, data = df1)
>
> Coefficients:
> (Intercept)            x
>        5.5          0.5
>
>> summary(lm1)
>
> Call:
> lm(formula = y ~ x, data = df1)
>
> Residuals:
>   1    2    3
> 0.5 -1.0  0.5
>
> Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
> (Intercept)    5.500      2.693   2.043    0.290
> x              0.500      0.866   0.577    0.667
>
> Residual standard error: 1.225 on 1 degrees of freedom
> Multiple R-squared:   0.25, Adjusted R-squared:   -0.5
> F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667
>
>> linearHypothesis(lm1, c("(Intercept)=0", "x=0"))
> Linear hypothesis test
>
> Hypothesis:
> (Intercept) = 0
> x = 0
>
> Model 1: restricted model
> Model 2: y ~ x
>
>  Res.Df   RSS Df Sum of Sq      F Pr(>F)
> 1      3 149.0
> 2      1   1.5  2     147.5 49.167 0.1003
>
> 2018-08-03 13:54 GMT+08:00 Annaert Jan <jan.annaert at uantwerpen.be>:
>
>> You can easily test linear restrictions using the function
>> linearHypothesis() from the car package.
>> There are several ways to set up the null hypothesis, but a
>> straightforward one here is:
>>
>>> library(car)
>>> x <- rnorm(10)
>>> y <- x+rnorm(10)
>>> linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
>> Linear hypothesis test
>>
>> Hypothesis:
>> (Intercept) = 0
>> x = 1
>>
>> Model 1: restricted model
>> Model 2: y ~ x
>>
>>   Res.Df     RSS Df Sum of Sq      F Pr(>F)
>> 1     10 10.6218
>> 2      8  9.0001  2    1.6217 0.7207 0.5155
>>
>>
>> Jan
>>
>> From: R-help <r-help-bounces at r-project.org> on behalf of John <
>> miaojpm at gmail.com>
>> Date: Thursday, 2 August 2018 at 10:44
>> To: r-help <r-help at r-project.org>
>> Subject: [R] F-test where the coefficients in the H_0 is nonzero
>>
>> Hi,
>>
>>    I try to run the regression
>>    y = beta_0 + beta_1 x
>>    and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
>>    I believe I can run the regression
>>    (y-x) = beta_0 +beta_1? x
>>    and do the regular F-test (using lm functio) where the hypothesized
>> coefficients are all zero.
>>
>>    Is there any function in R that deal with the case where the
>> coefficients are nonzero?
>>
>> John
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From po|@@on200 @end|ng |rom goog|em@||@com  Thu Aug  9 11:40:12 2018
From: po|@@on200 @end|ng |rom goog|em@||@com (john matthew)
Date: Thu, 9 Aug 2018 10:40:12 +0100
Subject: [R] sub/grep question: extract year
In-Reply-To: <CA+b7HP27j0uHjRdfPNnRSyDYqCp6a23wKe39uGWLaUc5a=P8FQ@mail.gmail.com>
References: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
 <CA+b7HP27j0uHjRdfPNnRSyDYqCp6a23wKe39uGWLaUc5a=P8FQ@mail.gmail.com>
Message-ID: <CA+b7HP1yNnif7jDaYwFL8E+9vAc9jqRTRHFTmJ7DEsUQOPHn3A@mail.gmail.com>

So there is probably a command that resets the capture variables as I call
them. No doubt someone will write what it is.

On 9 Aug 2018 10:36, "john matthew" <poisson200 at googlemail.com> wrote:

> Hi Marc.
> For question 1.
> I know in Perl that regular expressions when captured can be saved if not
> overwritten. \\1 is the capture variable in your R examples.
>
> So the 2nd regular expression does not match but \\1 still has 1980
> captured from the previous expression, hence the result.
>
> Maybe if you restart R and try your 2nd expression first, \\1 will be
> empty or no match result.
>
> Just speculation :)
>
> John
>
>
> On 9 Aug 2018 08:58, "Marc Girondot via R-help" <r-help at r-project.org>
> wrote:
>
>> Hi everybody,
>>
>> I have some questions about the way that sub is working. I hope that
>> someone has the answer:
>>
>> 1/ Why the second example does not return an empty string ? There is no
>> match.
>>
>> subtext <- "-1980-"
>> sub(".*(1980).*", "\\1", subtext) # return 1980
>> sub(".*(1981).*", "\\1", subtext) # return -1980-
>>
>> 2/ Based on sub documentation, it replaces the first occurence of a
>> pattern: why it does not return 1980 ?
>>
>> subtext <- " 1980 1981 "
>> sub(".*(198[01]).*", "\\1", subtext) # return 1981
>>
>> 3/ I want extract year from text; I use:
>>
>> subtext <- "bla 1980 bla"
>> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
>> return 1980
>> subtext <- "bla 2010 bla"
>> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
>> return 2010
>>
>> but
>>
>> subtext <- "bla 1010 bla"
>> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1", subtext) #
>> return 1010
>>
>> I would like exclude the case 1010 and other like this.
>>
>> The solution would be:
>>
>> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>>
>> Is there a solution to write such a pattern in grep ?
>>
>> Thanks a lot
>>
>> Marc
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Thu Aug  9 11:45:58 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 9 Aug 2018 11:45:58 +0200
Subject: [R] F-test where the coefficients in the H_0 is nonzero
In-Reply-To: <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
References: <CABcx46CAFoe4J_iqTWD2vY8Fk6E_ip5_PZ+=+zhTxukdPy+wcw@mail.gmail.com>
 <ADAB9CB4-ACB2-48C0-BE8E-87ADCE13351A@ua.ac.be>
 <CABcx46CQds=8=7bzeP8wvTTx+Gq2TX4FLCv-NweJumUKkwNsvw@mail.gmail.com>
Message-ID: <96DA15B2-46DA-43B7-9B34-211C67DD3C0B@gmail.com>

The null hypothesis is different (and the different numerator Df is the givaway).

> lm0 <- lm(y~-1, df1)
> anova(lm0,lm1)
Analysis of Variance Table

Model 1: y ~ -1
Model 2: y ~ x
  Res.Df   RSS Df Sum of Sq      F Pr(>F)
1      3 149.0                           
2      1   1.5  2     147.5 49.167 0.1003

-pd

> On 9 Aug 2018, at 10:58 , John <miaojpm at gmail.com> wrote:
> 
> Hi,
> 
>   I try to run the same f-test by lm (with summary) and the function
> "linearHypothesis" in car package. Why are the results (p-values for the
> f-test) different?
> 
> 
>> df1<-data.frame(x=c(2,3,4), y=c(7,6,8))
>> lm1<-lm(y~x, df1)
>> lm1
> 
> Call:
> lm(formula = y ~ x, data = df1)
> 
> Coefficients:
> (Intercept)            x
>        5.5          0.5
> 
>> summary(lm1)
> 
> Call:
> lm(formula = y ~ x, data = df1)
> 
> Residuals:
>   1    2    3
> 0.5 -1.0  0.5
> 
> Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
> (Intercept)    5.500      2.693   2.043    0.290
> x              0.500      0.866   0.577    0.667
> 
> Residual standard error: 1.225 on 1 degrees of freedom
> Multiple R-squared:   0.25, Adjusted R-squared:   -0.5
> F-statistic: 0.3333 on 1 and 1 DF,  p-value: 0.6667
> 
>> linearHypothesis(lm1, c("(Intercept)=0", "x=0"))
> Linear hypothesis test
> 
> Hypothesis:
> (Intercept) = 0
> x = 0
> 
> Model 1: restricted model
> Model 2: y ~ x
> 
>  Res.Df   RSS Df Sum of Sq      F Pr(>F)
> 1      3 149.0
> 2      1   1.5  2     147.5 49.167 0.1003
> 
> 2018-08-03 13:54 GMT+08:00 Annaert Jan <jan.annaert at uantwerpen.be>:
> 
>> You can easily test linear restrictions using the function
>> linearHypothesis() from the car package.
>> There are several ways to set up the null hypothesis, but a
>> straightforward one here is:
>> 
>>> library(car)
>>> x <- rnorm(10)
>>> y <- x+rnorm(10)
>>> linearHypothesis(lm(y~x), c("(Intercept)=0", "x=1"))
>> Linear hypothesis test
>> 
>> Hypothesis:
>> (Intercept) = 0
>> x = 1
>> 
>> Model 1: restricted model
>> Model 2: y ~ x
>> 
>>  Res.Df     RSS Df Sum of Sq      F Pr(>F)
>> 1     10 10.6218
>> 2      8  9.0001  2    1.6217 0.7207 0.5155
>> 
>> 
>> Jan
>> 
>> From: R-help <r-help-bounces at r-project.org> on behalf of John <
>> miaojpm at gmail.com>
>> Date: Thursday, 2 August 2018 at 10:44
>> To: r-help <r-help at r-project.org>
>> Subject: [R] F-test where the coefficients in the H_0 is nonzero
>> 
>> Hi,
>> 
>>   I try to run the regression
>>   y = beta_0 + beta_1 x
>>   and test H_0: (beta_0, beta_1) =(0,1) against H_1: H_0 is false
>>   I believe I can run the regression
>>   (y-x) = beta_0 +beta_1? x
>>   and do the regular F-test (using lm functio) where the hypothesized
>> coefficients are all zero.
>> 
>>   Is there any function in R that deal with the case where the
>> coefficients are nonzero?
>> 
>> John
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From po|@@on200 @end|ng |rom goog|em@||@com  Thu Aug  9 12:05:40 2018
From: po|@@on200 @end|ng |rom goog|em@||@com (john matthew)
Date: Thu, 9 Aug 2018 11:05:40 +0100
Subject: [R] security using R at work
In-Reply-To: <1B674C66F0DD4343BA5DD0C025217F9F02270AAD@CSSPWD2PRAP1147.SSA-Intra.net>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
 <1B674C66F0DD4343BA5DD0C025217F9F02270AAD@CSSPWD2PRAP1147.SSA-Intra.net>
Message-ID: <CA+b7HP3xPsxn3ZRrhDH8k-fBmKcd1gCTsjmH96EthA+716G5-g@mail.gmail.com>

Hi Katherina.
Good point you make. What makes your IT department happy with the use of R
studio server? What are the safe packages?

Can I trust your answer? :)
John.



On 9 Aug 2018 10:38, "Fritsch, Katharina (NNL) via R-help" <
r-help at r-project.org> wrote:

> Hiya,
> I work in a very security conscious organisation and we happily use R. The
> average user can only use R via RStudio Server, with a limited number of
> packages available, so that adds an additional level of control.
> That said, are you sure that the sentence 'a few people on a mailing list
> said it would be alright' is going to convince your IT department of the
> harmlessness of R?
> Cheers,
> Katharina.
>
> --
>
> Dr Katharina Fritsch B.Sc. M.Sc. MRSC
> Chemical Modeller, Chemical and Process Modelling
>
>
> E.
> katharina.fritsch at nnl.co.uk
> T.
> +44 (0)1925 289387
> @uknnl
>
> National Nuclear Laboratory Limited, 5th Floor, Chadwick House,
> Birchwood Park, Warrington, WA3 6AE, UK
>
> www.nnl.co.uk
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Laurence
> Clark
> Sent: 08 August 2018 16:10
> To: 'r-help at r-project.org'
> Subject: [R] security using R at work
>
> Hello all,
>
> I want to download R and use it for work purposes. I hope to use it to
> analyse very sensitive data from our clients.
>
> My question is:
>
> If I install R on my work network computer, will the data ever leave our
> network? I need to know if the data goes anywhere other than our network,
> because this could compromise it's security. Is there is any chance the
> data could go to a server owned by 'R' or anything else that's not
> immediately obvious, but constitutes the data leaving our network?
>
> Thank you
>
> Laurence
>
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
> Laurence Clark
> Business Data Analyst
> Account Management
> Health Management Ltd
>
> Mobile:                 07584 556498
> Switchboard:    0845 504 1000
> Email:          Laurence.Clark at healthmanltd.com
> Web:            BLOCKEDhealthmanagement[.]co[.]ukBLOCKED
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
> CONFIDENTIALITY NOTICE: This email, including attachments, is for the sole
> use of the intended recipients and may contain confidential and privileged
> information or otherwise be protected by law. Any unauthorised review, use,
> disclosure or distribution is prohibited. If you are not the intended
> recipient, please contact the sender, and destroy all copies and the
> original message.<BR><BR>MAXIMUS People Services Limited is registered in
> England and Wales (registered number: 03752300); registered office: 202 -
> 206 Union Street, London, SE1 0LX, United Kingdom. The Centre for Health
> and Disability Assessments Ltd (registered number: 9072343) and Health
> Management Ltd (registered number: 4369949) are registered in England and
> Wales. The registered office for each is Ash House, The Broyle, Ringmer,
> East Sussex, BN8 5NN, United Kingdom. Remploy Limited is registered in
> England and Wales (registered number: 09457025); registered office: 18c
> Meridian East, Meridian Business Park, Leicester, L
>  eicestershire, LE19 1WZ, United Kingdom.</font>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
>
>
> ------------------------------------------------------------
> ------------------------------------------------------------
> ----------------------------------------------------------
>
>
> ############################################################
> #########################
> Scanned by MailMarshal - M86 Security's comprehensive email content
> security solution.
> Download a free evaluation of MailMarshal at BLOCKEDm86security[.]
> comBLOCKED
> ############################################################
> #########################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> BLOCKEDstat[.]ethz[.]ch/mailman/listinfo/r-helpBLOCKED
> PLEASE do read the posting guide BLOCKEDR-project[.]org/
> posting-guide[.]htmlBLOCKED
> and provide commented, minimal, self-contained, reproducible code.
> ************************************************************
> *****************
> This message was received by the Cloud Security Email Gateway
>
> and was checked for Viruses and SPAM by the Cloud Security Email
> Management Service.
> Please forward any suspicious or unwanted emails to "Spam Helpdesk"
> ************************************************************
> *****************
>
>
> This e-mail is from National Nuclear Laboratory Limited ("NNL"). This
> e-mail and any attachments are intended for the addressee and may also be
> legally privileged. If you are not the intended recipient please do not
> print, re-transmit, store or act in reliance on it or any attachments.
> Instead, please e-mail it back to the sender and then immediately
> permanently delete it.
>
> National Nuclear Laboratory Limited (Company number 3857752) Registered in
> England and Wales. Registered office: Chadwick House, Warrington Road,
> Birchwood Park, Warrington, WA3 6AE.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From e@ @end|ng |rom enr|co@chum@nn@net  Thu Aug  9 12:14:52 2018
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 09 Aug 2018 12:14:52 +0200
Subject: [R] sub/grep question: extract year
In-Reply-To: <1ba34951-8805-0cdd-0b05-8716438e35b0@yahoo.fr>
Message-ID: <20180809121452.Horde.uxO51lQThuuhDXBPVsVAIMH@webmail.your-server.de>


Quoting Marc Girondot via R-help <r-help at r-project.org>:

> Hi everybody,
>
> I have some questions about the way that sub is working. I hope that  
> someone has the answer:
>
> 1/ Why the second example does not return an empty string ? There is  
> no match.
>
> subtext <- "-1980-"
> sub(".*(1980).*", "\\1", subtext) # return 1980
> sub(".*(1981).*", "\\1", subtext) # return -1980-

This is as documented in ?sub:
    "Elements of character vectors x which are not
     substituted will be returned unchanged"

> 2/ Based on sub documentation, it replaces the first occurence of a  
> pattern: why it does not return 1980 ?
>
> subtext <- " 1980 1981 "
> sub(".*(198[01]).*", "\\1", subtext) # return 1981

Because the pattern matches the whole string,
not just the year:

     regexpr(".*(198[01]).*", subtext)
     ## [1] 1
     ## attr(,"match.length")
     ## [1] 11
     ## attr(,"useBytes")
     ## [1] TRUE

 From this match, the RE engine will give you the last backreference-match,
which is "1981". If you want to _extract_ the first year, use a  
non-greedy RE instead:

     sub(".*?(198[01]).*", "\\1", subtext)
     ## [1] "1980"

I say _extract_ because you may _replace_ the pattern, as expected:

     sub("198[01]", "YYYY", subtext)
     ## [1] " YYYY 1981 "

That is because the pattern does not match the whole string.
Perhaps this example makes it clearer:

     test <- "1 2 3 4 5"
     sub("([0-9])", "\\1\\1", test)
     ## [1] "11 2 3 4 5"
     sub(".*([0-9]).*", "\\1\\1", test)
     ## [1] "55"
     sub(".*?([0-9]).*", "\\1\\1", test)
     ## [1] "11"



> 3/ I want extract year from text; I use:
>
> subtext <- "bla 1980 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1",  
> subtext) # return 1980
> subtext <- "bla 2010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1",  
> subtext) # return 2010
>
> but
>
> subtext <- "bla 1010 bla"
> sub(".*[ \\.\\(-]([12][01289][0-9][0-9])[ \\.\\)-].*", "\\1",  
> subtext) # return 1010
>
> I would like exclude the case 1010 and other like this.
>
> The solution would be:
>
> 18[0-9][0-9] or 19[0-9][0-9] or 200[0-9] or 201[0-9]
>
> Is there a solution to write such a pattern in grep ?

You answered this yourself, I think.


> Thanks a lot
>
> Marc
>


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net



From S@E|||@on @end|ng |rom LGCGroup@com  Thu Aug  9 13:56:11 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Thu, 9 Aug 2018 11:56:11 +0000
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <998a40ef9cfe4b5a876fce9f4f441a58@GBDCVPEXC08.corp.lgc-group.com>

> If I install R on my work network computer, will the data ever leave our
> network? 
As far as I know, if you run R locally (and not, say, on an amazon EC2 instance) your data - indeed anything about you or your machine - will only leave your desktop if you download and run an R package that transfers data intentionally. I don't know of _any_, but there are 10000 or so out there and I've probably used less than a hundred of them over the last decade. 
Other than malice, I can't imagine why an R package would upload data to anywhere else, but I suppose it's conceivable that someone has a server farm out there for doing parallel MCMC and has written a package to access it, and that might be a use-case for data upload. Again, I don't know of one.

But here are three things that don't depend on a mailing list opinion.
a) If you are genuinely concerned, airgap. Only run sensitive data on machines that are not connected to the outside world. Install any necessary packages from local .zip on USB drives or something.

b) Install something like wireshark and test for unexpected outgoing traffic on a dummy data set before applying the package to anything sensitive.

c) Have your IT department mark R as an unauthorised package (in your machine's firewall/security package) for TCP/IP transport so that R cannot talk to the internet.*

*That is a pain as the ability to download packages on demand is really helpful. However, it does mean that you can restrict _just_ R and does not require an airgap.



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From S@E|||@on @end|ng |rom LGCGroup@com  Thu Aug  9 14:11:31 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Thu, 9 Aug 2018 12:11:31 +0000
Subject: [R] exponential day
In-Reply-To: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
References: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
Message-ID: <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>

> Please, how can I determine parameters from exponential equation Example
> one:  y = a*exp(-b*x);  how do I determine  a  and  b , as well as R-square
> from data sets. And also fitting y = a*exp(-b*x) into the data sets Assuming
> data sets A = (0,2,4,6,8,10) B = (1,0.8,0.6,0.4,0.2,0.1)

For least squares fitting, you could take logs and do a simple linear fit, if the resduals are reasonably homoscedastic in the log domain (or if you can sort the weighting out properly).

For non-linear least squares, look at ?nlm, ?nls or (if you want to roll your own) ?optim

For max likelihood, maybe nlme in the nlme package.

For other ideas, look up 'non-linear fitting with R' on any search engine, or check the R Task Views

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From btupper @end|ng |rom b|ge|ow@org  Thu Aug  9 14:32:50 2018
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 9 Aug 2018 08:32:50 -0400
Subject: [R] error with the expand.grid command
In-Reply-To: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>
References: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>
Message-ID: <A25D3183-897C-48C4-8F49-DCBDB6C3B7AB@bigelow.org>

Hello,

You will have much better success if you subscribe and post to the R-sig-geo mailing list rather than the R-help mailing list.  You can subscribe to that list here... https://www.r-project.org/mail.html <https://www.r-project.org/mail.html>

If you are open to other suggestions, here are a couple of other tips to help you get help.

Change your email client to send plain text rather than richly formatted messages.  Using richly formatted text will often result in a garbled message and always results in this little gem you can see a the bottom of your message...

> [[alternative HTML version deleted]]


More specifically to your problem, there isn't anyway for others to help you since we could not access your data (like the NCDF file) and variables (like lon, lat, time, tt and ttt).  Anything you can do to make the issue super easy for someone to help means you are more likely to get the help you seek.  There are some really nice tutorials on how to ask a question on a help list that will most likely score you the help you seek.  Here's an example... https://www.r-project.org/posting-guide.html <https://www.r-project.org/posting-guide.html> but there are more out there on the world wild web.

Best of luck and see you over on R-sig-geo!

Ben

> On Aug 9, 2018, at 2:20 AM, Mayur Tade <mayur.tade at gmail.com> wrote:
> 
> hello sir...
> i am trying to extract the chlorophyll data of particular lat and lon from
> the world chlorophyll data from the netcdf file in R. as i am new to R i am
> facing the problem related to it when i am trying expand.grid command it is
> showing me this message.....message is followed.....its my kind request
> please help me with the same
> ttt<-expand.grid(lon,lat,time)
> Error in paste0(nmc[i], "=", if (is.numeric(x)) format(x) else x) :
>  cannot coerce type 'closure' to vector of type 'character'
> 
> here is the print of my netcdf file for you kind information.....follow...
> 
>> print(tt)
> File E:\chlorophyll data research student..mayur
> t..KUFOS\1997\ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_
> GEO_PML_OCx-199709-fv3.1.nc
> <http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
> (NC_FORMAT_NETCDF4_CLASSIC):
> 
>     9 variables (excluding dimension variables):
>        float MERIS_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the number of observations from the MERIS
> sensor contributing to this bin cell
>            number_of_files_composited: 19
>        float MODISA_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the number of observations from the MODIS
> (Aqua) sensor contributing to this bin cell
>            number_of_files_composited: 19
>        float SeaWiFS_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the number of observations from the SeaWiFS
> (GAC and LAC) sensor contributing to this bin cell
>            number_of_files_composited: 19
>        float VIIRS_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the number of observations from the VIIRS
> sensor contributing to this bin cell
>            number_of_files_composited: 19
>        float chlor_a[lon,lat,time]
>            _FillValue: 9.96920996838687e+36
>            long_name: Chlorophyll-a concentration in seawater (not
> log-transformed), generated by SeaDAS using a blended combination of OCI
> (OC4v6 + Hu's CI), OC3 and OC5, depending on water class memberships
>            units: milligram m-3
>            ancillary_variables: chlor_a_log10_rmsd chlor_a_log10_bias
>            grid_mapping: crs
>            standard_name: mass_concentration_of_chlorophyll_a_in_sea_water
>            units_nonstandard: mg m^-3
>            parameter_vocab_uri:
> http://vocab.nerc.ac.uk/collection/P04/current/
>        float chlor_a_log10_bias[lon,lat,time]
>            _FillValue: 9.96920996838687e+36
>            long_name: Bias of log10-transformed chlorophyll-a concentration
> in seawater.
>            grid_mapping: crs
>            rel: uncertainty
>            comment: Uncertainty lookups derived from file:
> /data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
> cci_chla_bias.dat
>            ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
>        float chlor_a_log10_rmsd[lon,lat,time]
>            _FillValue: 9.96920996838687e+36
>            long_name: Root-mean-square-difference of log10-transformed
> chlorophyll-a concentration in seawater.
>            grid_mapping: crs
>            rel: uncertainty
>            comment: Uncertainty lookups derived from file:
> /data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
> cci_chla_rmsd.dat
>            ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
>        int crs[time]
>            grid_mapping_name: latitude_longitude
>        float total_nobs_sum[lon,lat,time]
>            _FillValue: 0
>            long_name: Count of the total number of observations
> contributing to this bin cell
>            number_of_files_composited: 19
> 
>     3 dimensions:
>        time  Size:1
>            axis: T
>            standard_name: time
>            units: days since 1970-01-01 00:00:00
>        lat  Size:4320
>            units: degrees_north
>            long_name: latitude
>            standard_name: latitude
>            valid_min: -89.9791641235352
>            valid_max: 89.9791641235352
>            axis: Y
>        lon  Size:8640
>            units: degrees_east
>            long_name: longitude
>            standard_name: longitude
>            valid_min: -179.97917175293
>            valid_max: 179.97917175293
>            axis: X
> 
>    47 global attributes:
>        Metadata_Conventions: Unidata Dataset Discovery v1.0
>        cdm_data_type: Grid
>        comment: See summary attribute
>        creator_email: help at esa-oceancolour-cci.org
>        creator_name: Plymouth Marine Laboratory
>        creator_url: http://esa-oceancolour-cci.org
>        geospatial_lat_max: 90
>        geospatial_lat_min: -90
>        geospatial_lat_resolution: .04166666666666666666
>        geospatial_lat_units: decimal degrees north
>        geospatial_lon_max: 180
>        geospatial_lon_min: -180
>        geospatial_lon_resolution: .04166666666666666666
>        geospatial_lon_units: decimal degrees east
>        geospatial_vertical_max: 0
>        geospatial_vertical_min: 0
>        institution: Plymouth Marine Laboratory
>        keywords: satellite,observation,ocean,ocean colour
>        keywords_vocabulary: none
>        license: ESA CCI Data Policy: free and open access.  When
> referencing, please use: Ocean Colour Climate Change Initiative dataset,
> Version <Version Number>, European Space Agency, available online at
> http://www.esa-oceancolour-cci.org.  We would also appreciate being notified
> of publications so that we can list them on the project website at
> http://www.esa-oceancolour-cci.org/?q=publications
>        naming_authority: uk.ac.pml
>        number_of_optical_water_types: 14
>        platform: Orbview-2,Aqua,Envisat,Suomi-NPP
>        processing_level: Level-3
>        project: Climate Change Initiative - European Space Agency
>        references: http://www.esa-oceancolour-cci.org/
>        sensor: SeaWiFS,MODIS,MERIS,VIIRS
>        source: NASA SeaWiFS L2 R2014.0 LAC and GAC, MODIS-Aqua L1A, MERIS
> L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L2 R2014.0.1 (data
> identical to R2014.0.2)
>        spatial_resolution: 4km nominal at equator
>        standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata
> Conventions Version 1.6
>        title: ESA CCI Ocean Colour Product
>        number_of_files_composited: 19
>        creation_date: Tue Aug 23 09:00:23 2016
>        date_created: Tue Aug 23 09:00:23 2016
>        time_coverage_resolution: P1M
>        time_coverage_duration: P1M
>        start_date: 01-SEP-1997 00:00:00.000000
>        stop_date: 30-SEP-1997 23:59:00.000000
>        time_coverage_start: 199709010000Z
>        time_coverage_end: 199709302359Z
>        netcdf_file_type: NETCDF4_CLASSIC
>        history: Source data were:
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970904-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970904-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970906-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970906-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970909-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970909-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970910-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970910-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970915-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970915-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970916-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970916-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970918-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970918-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970919-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970919-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970920-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970920-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970921-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970921-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970922-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970922-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970923-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970923-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970924-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970924-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970925-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970925-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970926-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970926-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970927-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970927-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970928-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970928-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970929-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970929-fv3.1.nc/>
> ,
> ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
> OCx_QAA-19970930-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970930-fv3.1.nc/>
> ;
> netcdf_compositor_cci composites  Rrs_412, Rrs_443, Rrs_490, Rrs_510,
> Rrs_555, Rrs_670, water_class1, water_class2, water_class3, water_class4,
> water_class5, water_class6, water_class7, water_class8, water_class9,
> water_class10, water_class11, water_class12, water_class13, water_class14,
> atot_412, atot_443, atot_490, atot_510, atot_555, atot_670, aph_412,
> aph_443, aph_490, aph_510, aph_555, aph_670, adg_412, adg_443, adg_490,
> adg_510, adg_555, adg_670, bbp_412, bbp_443, bbp_490, bbp_510, bbp_555,
> bbp_670, chlor_a, kd_490, chlor_a_log10_bias, Rrs_412_bias, Rrs_443_bias,
> Rrs_490_bias, Rrs_510_bias, Rrs_555_bias, Rrs_670_bias, aph_412_bias,
> aph_443_bias, aph_490_bias, aph_510_bias, aph_555_bias, aph_670_bias,
> adg_412_bias, adg_443_bias, adg_490_bias, adg_510_bias, adg_555_bias,
> adg_670_bias, kd_490_bias with --mean,  chlor_a_log10_rmsd, Rrs_412_rmsd,
> Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_555_rmsd, Rrs_670_rmsd,
> aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_555_rmsd,
> aph_670_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd,
> adg_555_rmsd, adg_670_rmsd, kd_490_rmsd with --root-mean-square, and
> SeaWiFS_nobs, MODISA_nobs, MERIS_nobs, VIIRS_nobs, total_nobs - with --total
> 1471940520 Subsetted from
> standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_
> MONTHLY_4km_GEO_PML_OCx_QAA-199709-fv3.1.nc
> <http://esacci-oc-l3s-oc_products-merged-1m_monthly_4km_geo_pml_ocx_qaa-199709-fv3.1.nc/>
> to only include variables
> MERIS_nobs_sum,MODISA_nobs_sum,SeaWiFS_nobs_sum,VIIRS_
> nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,
> crs,lat,lon,time,total_nobs_sum
>        Conventions: CF-1.6
>        product_version: 3.1
>        summary: Data products generated by the Ocean Colour component of
> the European Space Agency Climate Change Initiative project. These files are
> daily composites of merged sensor (MERIS, MODIS Aqua, SeaWiFS LAC & GAC,
> VIIRS) products.  MODIS Aqua and MERIS were band-shifted and bias-corrected
> to SeaWiFS bands and values using a temporally and spatially varying scheme
> based on the overlap years of 2003-2007.  VIIRS was band-shifted and
> bias-corrected in a second stage against the MODIS Rrs that had already been
> corrected to SeaWiFS levels, for the overlap period 2012-2013.  VIIRS and
> SeaWiFS Rrs were derived from standard NASA L2 products; MERIS and MODIS
> from a combination of NASA's l2gen (for basic sensor geometry corrections,
> etc) and HYGEOS Polymer v3.5 (for atmospheric correction).  The Rrs were
> binned to a sinusoidal 4km level-3 grid, and later to 4km geographic
> projection, by Brockmann Consult's BEAM.  Derived products were generally
> computed with the standard SeaDAS algorithms.  QAA IOPs were derived using
> the standard SeaDAS algorithm but with a modified backscattering table to
> match that used in the bandshifting.  The final chlorophyll is a combination
> of OC4, Hu's CI and OC5, depending on the water class memberships.
> Uncertainty estimates were added using the fuzzy water classifier and
> uncertainty estimation algorithm of Tim Moore as documented in Jackson et al
> (2017).
>        tracking_id: 659b397a-953c-4814-a3e2-460d6218fcfa
>        id:
> ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-199709-fv3.1.nc
> <http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]



From b@h@mev|k @end|ng |rom u@|t@u|o@no  Thu Aug  9 15:21:05 2018
From: b@h@mev|k @end|ng |rom u@|t@u|o@no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Thu, 09 Aug 2018 15:21:05 +0200
Subject: [R] security using R at work
In-Reply-To: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
 (Laurence Clark's message of "Wed, 8 Aug 2018 15:09:35 +0000")
References: <2BEF6B4D731C4E4E89C0972751D24519340B6783@HMLEXMAIL01.hml.local>
Message-ID: <s3szhxvd6bi.fsf@varelg.uio.no>

The section I'm working in runs a facility for sensitive research data
(https://www.uio.no/english/services/it/research/sensitive-data/).  Our
users use R (along with other analysis software).  We don't consider R
safe or unsafe, but have designed the services so that it should not be
possible (or at least very difficult) for sensitive information to leak
out of the network.

I would say that your best bet is to expect all analysis software to
have security holes or be compromised, and design your setup/network
around that assumption.

-- 
Regards,
Bj?rn-Helge Mevik

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 832 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180809/3c512239/attachment-0002.sig>

From k@n@g|@n@tt@@|o @end|ng |rom gm@||@com  Thu Aug  9 16:22:55 2018
From: k@n@g|@n@tt@@|o @end|ng |rom gm@||@com (Kan Z. Gianattasio)
Date: Thu, 9 Aug 2018 10:22:55 -0400
Subject: [R] Warnings using SuperLearner?
Message-ID: <CAOBENzeSXQitCEGmRnu6tV24CagjxG_BQrNcBkLwbcmxD6Wn-g@mail.gmail.com>

 Hello,

I'm using the CV.SuperLearner to model a binary outcome using a set of
predictors, specifying family=binomial(), method = "method.AUC", and
SL.library = c("SL.glmnet", "SL.glm", "SL.randomForest", "SL.gam",
"SL.polymars", "SL.mean").

I'm getting a number of warning messages (copied below), and have not been
able to find anything about what they imply, or how to address them. Any
insight would be greatly appreciated.

Thank you in advance!

---

I get the following warnings as the models are being run (many times over):

step half ouch...
step half ouch...
warning - model size was reduced
warning - model size was reduced
step half ouch...
step half ouch...
step half ouch...
step half ouch...
warning - model size was reduced
step half ouch...
warning - model size was reduced

At the very end, I'm also getting the following:

1: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
2: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
3: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
4: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
5: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
6: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH
7: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
  optim didn't converge when estimating the super learner coefficients,
reason (see ?optim):  52  optim message:  ERROR:
ABNORMAL_TERMINATION_IN_LNSRCH

	[[alternative HTML version deleted]]



From @||ve@tr|@c@@@|| @end|ng |rom gm@||@com  Thu Aug  9 16:51:19 2018
From: @||ve@tr|@c@@@|| @end|ng |rom gm@||@com (Edoardo Silvestri)
Date: Thu, 9 Aug 2018 16:51:19 +0200
Subject: [R] Plot function: hourly data and x-axis
Message-ID: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>

Hi all,
I have a little problem with plot function..
I have an hourly dataset and I would like plot a variable with x-axis based
on daily or monthly frequency, just to have a better visualization and
avoid on x-axis all hours of the dataset.

Do you know what is the solution?
Thanks
Edo

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Aug  9 18:39:54 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 9 Aug 2018 16:39:54 +0000
Subject: [R] Plot function: hourly data and x-axis
In-Reply-To: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>
References: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>
Message-ID: <C5CACF0D-3DC6-403F-BBD3-FE6D0BED1F67@llnl.gov>

Normally, one turns off the x-axis tick marks and labels by supplying   xaxt='n'  in the plot() call, and then adds a customized x-axis using the axis() function.

But without more information, little help can be provided (a vague question receives a vague answer).

I'd suggest reviewing the posting guide and other advice shown at the bottom of every email sent by R-help.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/9/18, 7:51 AM, "R-help on behalf of Edoardo Silvestri" <r-help-bounces at r-project.org on behalf of silvestri.casali at gmail.com> wrote:

    Hi all,
    I have a little problem with plot function..
    I have an hourly dataset and I would like plot a variable with x-axis based
    on daily or monthly frequency, just to have a better visualization and
    avoid on x-axis all hours of the dataset.
    
    Do you know what is the solution?
    Thanks
    Edo
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @end|ng |rom ||n|@gov  Thu Aug  9 18:45:32 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 9 Aug 2018 16:45:32 +0000
Subject: [R] error with the expand.grid command
In-Reply-To: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>
References: <CAOP_hSgmdutmYpykuBvKF7-MuTQh9-ZNYkbvJ+dYn_ESW6hWAA@mail.gmail.com>
Message-ID: <B8AD139A-1A29-4B37-9225-FF5EF1DF0B6B@llnl.gov>

In my experience, error messages that reference a closure usually mean that you have supplied a function where you aren't supposed to.

In this case, I'd look and see if lon, lat, or time is a function (by accident, of course).

More specifically, right now in one of my R sessions, I get:

> class(time)
[1] "function"
> find('time')
[1] "package:stats"

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/8/18, 11:20 PM, "R-help on behalf of Mayur Tade" <r-help-bounces at r-project.org on behalf of mayur.tade at gmail.com> wrote:

     hello sir...
    i am trying to extract the chlorophyll data of particular lat and lon from
    the world chlorophyll data from the netcdf file in R. as i am new to R i am
    facing the problem related to it when i am trying expand.grid command it is
    showing me this message.....message is followed.....its my kind request
    please help me with the same
    ttt<-expand.grid(lon,lat,time)
    Error in paste0(nmc[i], "=", if (is.numeric(x)) format(x) else x) :
      cannot coerce type 'closure' to vector of type 'character'
    
    here is the print of my netcdf file for you kind information.....follow...
    
    > print(tt)
    File E:\chlorophyll data research student..mayur
    t..KUFOS\1997\ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_
    GEO_PML_OCx-199709-fv3.1.nc
    <http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
    (NC_FORMAT_NETCDF4_CLASSIC):
    
         9 variables (excluding dimension variables):
            float MERIS_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the number of observations from the MERIS
    sensor contributing to this bin cell
                number_of_files_composited: 19
            float MODISA_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the number of observations from the MODIS
    (Aqua) sensor contributing to this bin cell
                number_of_files_composited: 19
            float SeaWiFS_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the number of observations from the SeaWiFS
    (GAC and LAC) sensor contributing to this bin cell
                number_of_files_composited: 19
            float VIIRS_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the number of observations from the VIIRS
    sensor contributing to this bin cell
                number_of_files_composited: 19
            float chlor_a[lon,lat,time]
                _FillValue: 9.96920996838687e+36
                long_name: Chlorophyll-a concentration in seawater (not
    log-transformed), generated by SeaDAS using a blended combination of OCI
    (OC4v6 + Hu's CI), OC3 and OC5, depending on water class memberships
                units: milligram m-3
                ancillary_variables: chlor_a_log10_rmsd chlor_a_log10_bias
                grid_mapping: crs
                standard_name: mass_concentration_of_chlorophyll_a_in_sea_water
                units_nonstandard: mg m^-3
                parameter_vocab_uri:
    http://vocab.nerc.ac.uk/collection/P04/current/
            float chlor_a_log10_bias[lon,lat,time]
                _FillValue: 9.96920996838687e+36
                long_name: Bias of log10-transformed chlorophyll-a concentration
    in seawater.
                grid_mapping: crs
                rel: uncertainty
                comment: Uncertainty lookups derived from file:
    /data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
    cci_chla_bias.dat
                ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
            float chlor_a_log10_rmsd[lon,lat,time]
                _FillValue: 9.96920996838687e+36
                long_name: Root-mean-square-difference of log10-transformed
    chlorophyll-a concentration in seawater.
                grid_mapping: crs
                rel: uncertainty
                comment: Uncertainty lookups derived from file:
    /data/datasets/CCI/v3.1-production/stage09b-uncertainty_tables/chlor_a/
    cci_chla_rmsd.dat
                ref: http://www.esa-oceancolour-cci.org/?q=webfm_send/581
            int crs[time]
                grid_mapping_name: latitude_longitude
            float total_nobs_sum[lon,lat,time]
                _FillValue: 0
                long_name: Count of the total number of observations
    contributing to this bin cell
                number_of_files_composited: 19
    
         3 dimensions:
            time  Size:1
                axis: T
                standard_name: time
                units: days since 1970-01-01 00:00:00
            lat  Size:4320
                units: degrees_north
                long_name: latitude
                standard_name: latitude
                valid_min: -89.9791641235352
                valid_max: 89.9791641235352
                axis: Y
            lon  Size:8640
                units: degrees_east
                long_name: longitude
                standard_name: longitude
                valid_min: -179.97917175293
                valid_max: 179.97917175293
                axis: X
    
        47 global attributes:
            Metadata_Conventions: Unidata Dataset Discovery v1.0
            cdm_data_type: Grid
            comment: See summary attribute
            creator_email: help at esa-oceancolour-cci.org
            creator_name: Plymouth Marine Laboratory
            creator_url: http://esa-oceancolour-cci.org
            geospatial_lat_max: 90
            geospatial_lat_min: -90
            geospatial_lat_resolution: .04166666666666666666
            geospatial_lat_units: decimal degrees north
            geospatial_lon_max: 180
            geospatial_lon_min: -180
            geospatial_lon_resolution: .04166666666666666666
            geospatial_lon_units: decimal degrees east
            geospatial_vertical_max: 0
            geospatial_vertical_min: 0
            institution: Plymouth Marine Laboratory
            keywords: satellite,observation,ocean,ocean colour
            keywords_vocabulary: none
            license: ESA CCI Data Policy: free and open access.  When
    referencing, please use: Ocean Colour Climate Change Initiative dataset,
    Version <Version Number>, European Space Agency, available online at
    http://www.esa-oceancolour-cci.org.  We would also appreciate being notified
    of publications so that we can list them on the project website at
    http://www.esa-oceancolour-cci.org/?q=publications
            naming_authority: uk.ac.pml
            number_of_optical_water_types: 14
            platform: Orbview-2,Aqua,Envisat,Suomi-NPP
            processing_level: Level-3
            project: Climate Change Initiative - European Space Agency
            references: http://www.esa-oceancolour-cci.org/
            sensor: SeaWiFS,MODIS,MERIS,VIIRS
            source: NASA SeaWiFS L2 R2014.0 LAC and GAC, MODIS-Aqua L1A, MERIS
    L1B 3rd reprocessing inc OCL corrections, NASA VIIRS L2 R2014.0.1 (data
    identical to R2014.0.2)
            spatial_resolution: 4km nominal at equator
            standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata
    Conventions Version 1.6
            title: ESA CCI Ocean Colour Product
            number_of_files_composited: 19
            creation_date: Tue Aug 23 09:00:23 2016
            date_created: Tue Aug 23 09:00:23 2016
            time_coverage_resolution: P1M
            time_coverage_duration: P1M
            start_date: 01-SEP-1997 00:00:00.000000
            stop_date: 30-SEP-1997 23:59:00.000000
            time_coverage_start: 199709010000Z
            time_coverage_end: 199709302359Z
            netcdf_file_type: NETCDF4_CLASSIC
            history: Source data were:
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970904-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970904-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970906-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970906-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970909-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970909-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970910-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970910-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970915-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970915-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970916-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970916-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970918-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970918-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970919-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970919-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970920-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970920-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970921-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970921-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970922-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970922-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970923-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970923-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970924-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970924-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970925-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970925-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970926-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970926-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970927-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970927-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970928-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970928-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970929-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970929-fv3.1.nc/>
    ,
    ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1D_DAILY_4km_GEO_PML_
    OCx_QAA-19970930-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1d_daily_4km_geo_pml_ocx_qaa-19970930-fv3.1.nc/>
    ;
    netcdf_compositor_cci composites  Rrs_412, Rrs_443, Rrs_490, Rrs_510,
    Rrs_555, Rrs_670, water_class1, water_class2, water_class3, water_class4,
    water_class5, water_class6, water_class7, water_class8, water_class9,
    water_class10, water_class11, water_class12, water_class13, water_class14,
    atot_412, atot_443, atot_490, atot_510, atot_555, atot_670, aph_412,
    aph_443, aph_490, aph_510, aph_555, aph_670, adg_412, adg_443, adg_490,
    adg_510, adg_555, adg_670, bbp_412, bbp_443, bbp_490, bbp_510, bbp_555,
    bbp_670, chlor_a, kd_490, chlor_a_log10_bias, Rrs_412_bias, Rrs_443_bias,
    Rrs_490_bias, Rrs_510_bias, Rrs_555_bias, Rrs_670_bias, aph_412_bias,
    aph_443_bias, aph_490_bias, aph_510_bias, aph_555_bias, aph_670_bias,
    adg_412_bias, adg_443_bias, adg_490_bias, adg_510_bias, adg_555_bias,
    adg_670_bias, kd_490_bias with --mean,  chlor_a_log10_rmsd, Rrs_412_rmsd,
    Rrs_443_rmsd, Rrs_490_rmsd, Rrs_510_rmsd, Rrs_555_rmsd, Rrs_670_rmsd,
    aph_412_rmsd, aph_443_rmsd, aph_490_rmsd, aph_510_rmsd, aph_555_rmsd,
    aph_670_rmsd, adg_412_rmsd, adg_443_rmsd, adg_490_rmsd, adg_510_rmsd,
    adg_555_rmsd, adg_670_rmsd, kd_490_rmsd with --root-mean-square, and
    SeaWiFS_nobs, MODISA_nobs, MERIS_nobs, VIIRS_nobs, total_nobs - with --total
    1471940520 Subsetted from
    standardised_geo/ESACCI-OC-L3S-OC_PRODUCTS-MERGED-1M_
    MONTHLY_4km_GEO_PML_OCx_QAA-199709-fv3.1.nc
    <http://esacci-oc-l3s-oc_products-merged-1m_monthly_4km_geo_pml_ocx_qaa-199709-fv3.1.nc/>
    to only include variables
    MERIS_nobs_sum,MODISA_nobs_sum,SeaWiFS_nobs_sum,VIIRS_
    nobs_sum,chlor_a,chlor_a_log10_bias,chlor_a_log10_rmsd,
    crs,lat,lon,time,total_nobs_sum
            Conventions: CF-1.6
            product_version: 3.1
            summary: Data products generated by the Ocean Colour component of
    the European Space Agency Climate Change Initiative project. These files are
    daily composites of merged sensor (MERIS, MODIS Aqua, SeaWiFS LAC & GAC,
    VIIRS) products.  MODIS Aqua and MERIS were band-shifted and bias-corrected
    to SeaWiFS bands and values using a temporally and spatially varying scheme
    based on the overlap years of 2003-2007.  VIIRS was band-shifted and
    bias-corrected in a second stage against the MODIS Rrs that had already been
    corrected to SeaWiFS levels, for the overlap period 2012-2013.  VIIRS and
    SeaWiFS Rrs were derived from standard NASA L2 products; MERIS and MODIS
    from a combination of NASA's l2gen (for basic sensor geometry corrections,
    etc) and HYGEOS Polymer v3.5 (for atmospheric correction).  The Rrs were
    binned to a sinusoidal 4km level-3 grid, and later to 4km geographic
    projection, by Brockmann Consult's BEAM.  Derived products were generally
    computed with the standard SeaDAS algorithms.  QAA IOPs were derived using
    the standard SeaDAS algorithm but with a modified backscattering table to
    match that used in the bandshifting.  The final chlorophyll is a combination
    of OC4, Hu's CI and OC5, depending on the water class memberships.
    Uncertainty estimates were added using the fuzzy water classifier and
    uncertainty estimation algorithm of Tim Moore as documented in Jackson et al
    (2017).
            tracking_id: 659b397a-953c-4814-a3e2-460d6218fcfa
            id:
    ESACCI-OC-L3S-CHLOR_A-MERGED-1M_MONTHLY_4km_GEO_PML_OCx-199709-fv3.1.nc
    <http://esacci-oc-l3s-chlor_a-merged-1m_monthly_4km_geo_pml_ocx-199709-fv3.1.nc/>
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug  9 18:52:55 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 9 Aug 2018 09:52:55 -0700
Subject: [R] Warnings using SuperLearner?
In-Reply-To: <CAOBENzeSXQitCEGmRnu6tV24CagjxG_BQrNcBkLwbcmxD6Wn-g@mail.gmail.com>
References: <CAOBENzeSXQitCEGmRnu6tV24CagjxG_BQrNcBkLwbcmxD6Wn-g@mail.gmail.com>
Message-ID: <CAGxFJbQ2u2CTWfYdEF4vicaW7AWhU71W0Pv0M-K5Pa-u+UU13g@mail.gmail.com>

A guess:

It sounds like you are overspecifying models leading to numerical issues
during the various optimizations being performed. Try simplifying your
model (reducing the number of predictors).  Without more details on your
data and model, it may be difficult to diagnose beyond such a guess, though
there are certainy wiser folks than I out there.

Also, this is a plain text maiing list. Please post in plain text, not HTML.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 9, 2018 at 7:22 AM, Kan Z. Gianattasio <
kan.gianattasio at gmail.com> wrote:

>  Hello,
>
> I'm using the CV.SuperLearner to model a binary outcome using a set of
> predictors, specifying family=binomial(), method = "method.AUC", and
> SL.library = c("SL.glmnet", "SL.glm", "SL.randomForest", "SL.gam",
> "SL.polymars", "SL.mean").
>
> I'm getting a number of warning messages (copied below), and have not been
> able to find anything about what they imply, or how to address them. Any
> insight would be greatly appreciated.
>
> Thank you in advance!
>
> ---
>
> I get the following warnings as the models are being run (many times over):
>
> step half ouch...
> step half ouch...
> warning - model size was reduced
> warning - model size was reduced
> step half ouch...
> step half ouch...
> step half ouch...
> step half ouch...
> warning - model size was reduced
> step half ouch...
> warning - model size was reduced
>
> At the very end, I'm also getting the following:
>
> 1: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 2: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 3: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 4: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 5: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 6: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> 7: In method$computeCoef(Z = Z, Y = Y, libraryNames = libraryNames,  :
>   optim didn't converge when estimating the super learner coefficients,
> reason (see ?optim):  52  optim message:  ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Aug  9 19:23:43 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 09 Aug 2018 10:23:43 -0700
Subject: [R] Plot function: hourly data and x-axis
In-Reply-To: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>
References: <CAEv8TnR5kP8LS-WEC4NkNzE9sMxTZtigjg1_qBZ-egGwvTjG_w@mail.gmail.com>
Message-ID: <54A20E35-750B-469B-9A1A-6047F0098B29@dcn.davis.ca.us>

Pre-process your data into per-day or per-month records, then plot it. There are many ways to do this... for example, base R has the aggregate function, and the dplyr package has the group_by/summarise functions, and the data.table package can do this as well (read the vignettes).

All of these techniques require that you learn how to deal with timestamps using one or more of the time classes. The most common of these can be introduced by reading

?DateTimeClasses

and/or reading some of the fine blogs online regarding this topic. Note that the trunc.POSIXt function offers one way to identify which time interval each record of your data belongs to.

If you need more assistance, read the Posting Guide and create a reproducible example similar to the data you are working with, and be sure to post it using plain text so it does not get corrupted in the mailing list.

On August 9, 2018 7:51:19 AM PDT, Edoardo Silvestri <silvestri.casali at gmail.com> wrote:
>Hi all,
>I have a little problem with plot function..
>I have an hourly dataset and I would like plot a variable with x-axis
>based
>on daily or monthly frequency, just to have a better visualization and
>avoid on x-axis all hours of the dataset.
>
>Do you know what is the solution?
>Thanks
>Edo
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From @@m@hkow73 @end|ng |rom gm@||@com  Thu Aug  9 20:08:12 2018
From: @@m@hkow73 @end|ng |rom gm@||@com (Ekow Asmah)
Date: Thu, 9 Aug 2018 19:08:12 +0100
Subject: [R] Assistance needed to run bootstrapping using benchmarking
 package
Message-ID: <CAPh=1bzf4niR_dodPE0rgd3DBV3Up_nmKK+vJtBbs+iiB4NYCA@mail.gmail.com>

Hello everyone. I am trying to run bootstrapping with DEA's directional
distance function using benchmarking Package. i have tried all i could but
without success. the actual problem is with the following commands:
1. dhat <- dea.direct(...)
2. Bm[i,] <- dea.direct (.....)
The details of the commands and the data are attached to this mail. Please
help me out

the error message is at the ending part of the commands

-- 
Emmanuel E. Asmah
Lecturer
Cape Coast Technical University
Cape Coast, Ghana
0233 -244759147
 easmah at cpoly.edu.gh
asmahkow73 at gmail.com
asmahkow at hahoo.com

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: BENCH 1.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180809/4fdbb4e1/attachment-0002.txt>

From r@herry8 @end|ng |rom comc@@t@net  Thu Aug  9 19:12:45 2018
From: r@herry8 @end|ng |rom comc@@t@net (rsherry8)
Date: Thu, 9 Aug 2018 13:12:45 -0400
Subject: [R] Trying to Generalize a Function in R
Message-ID: <5B6C760D.5050404@comcast.net>


I wrote the following function:

# This method gets historical stock data for the stock Avalon Bay whose 
symbol is AVB.
getReturns <- function(norm = FALSE)
{
     library(quantmod)

     getSymbols("AVB", src = "yahoo", from = start, to = end)
     length = length(  AVB$AVB.Close )
     close = as.numeric( AVB$AVB.Close )
     cat( "length = ", length(close ), "\n" )
     for( i in 1:length-1 )
         diff[i] = ((close[i+1] - close[i]) ) / close[i]
     u = mean(diff)
     stdDev = sd(diff)
     cat( "stdDev = ", stdDev, "\n" )

     if ( norm == TRUE ) {
         diff = (diff - u)
         diff = diff / stdDev
     }
     return (diff)
}

I would like to generalize it to work for any stock by passing in the 
stock symbol. So the header for the
function would be:

getReturns <- function(symbol, norm = FALSE)

Now how do I update this line:
     length = length(  AVB$AVB.Close )
This statement will not work:
     length = length(  symbol$AVB.Close )
because the name that holds the closing price is a function of the stock 
symbol.

Thanks,
Bob



From peter@|@ng|e|der @end|ng |rom gm@||@com  Thu Aug  9 21:46:01 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 9 Aug 2018 12:46:01 -0700
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <5B6C760D.5050404@comcast.net>
References: <5B6C760D.5050404@comcast.net>
Message-ID: <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>

If I understand it correctly, the function getSymbols creates a
variable with the name being the stock symbol. Then use the function
get(symbol) to retrieve the value of the variable whose name is
contained in the character string `symbol'. Assign that to a variable
(e.g. AVB). You may also have to modify the names of the components
you retrieve from the list AVB. For that, you can use
AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
something like AVB[[paste0(symbol, ".Close"]] to generalize the
retrieval of list components.

HTH,

Peter
On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>
>
> I wrote the following function:
>
> # This method gets historical stock data for the stock Avalon Bay whose
> symbol is AVB.
> getReturns <- function(norm = FALSE)
> {
>      library(quantmod)
>
>      getSymbols("AVB", src = "yahoo", from = start, to = end)
>      length = length(  AVB$AVB.Close )
>      close = as.numeric( AVB$AVB.Close )
>      cat( "length = ", length(close ), "\n" )
>      for( i in 1:length-1 )
>          diff[i] = ((close[i+1] - close[i]) ) / close[i]
>      u = mean(diff)
>      stdDev = sd(diff)
>      cat( "stdDev = ", stdDev, "\n" )
>
>      if ( norm == TRUE ) {
>          diff = (diff - u)
>          diff = diff / stdDev
>      }
>      return (diff)
> }
>
> I would like to generalize it to work for any stock by passing in the
> stock symbol. So the header for the
> function would be:
>
> getReturns <- function(symbol, norm = FALSE)
>
> Now how do I update this line:
>      length = length(  AVB$AVB.Close )
> This statement will not work:
>      length = length(  symbol$AVB.Close )
> because the name that holds the closing price is a function of the stock
> symbol.
>
> Thanks,
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@|| @end|ng |rom @|ex@ndr@thorn@com  Thu Aug  9 17:36:23 2018
From: m@|| @end|ng |rom @|ex@ndr@thorn@com (Alexandra Thorn)
Date: Thu, 9 Aug 2018 11:36:23 -0400
Subject: [R] Help reinstalling rgdal (Ubuntu 16.04)
Message-ID: <20180809113623.71e49ae7@athorn-Lemur-Ultra>

Hi all,

Following some updates to R that I received via Synaptic Package
Manager on Ubuntu 16.04 (looks like I now have R 3.4.4-1xenial0), I
have been unable to reinstall rgdal, and I need help.

Initially I was getting error messages about dependencies on GDAL
1.11.4, but after following instructions to install GDAL from source
(into my /usr/local directory) I'm now getting a different set of error
messages (see the output error messages posted below my signature).  

I can't tell if this means that I've made a mistake installing GDAL or
if there's some other problem with my setup/configuration.  I really
need rgdal for the analyses I do in R and could use some help figuring
this out.

Thanks,
Alex

> install.packages("rgdal")
Installing package into ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4?
(as ?lib? is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/rgdal_1.3-4.tar.gz'
Content type 'application/x-gzip' length 1664774 bytes (1.6 MB)
==================================================
downloaded 1.6 MB

* installing *source* package ?rgdal? ...
** package ?rgdal? successfully unpacked and MD5 sums checked
configure: R_HOME: /usr/lib/R
configure: CC: gcc -std=gnu99
configure: CXX: g++
configure: C++11 support available
configure: rgdal: 1.3-4
checking for /usr/bin/svnversion... no
configure: svn revision: 766
checking for gdal-config... /usr/local/bin/gdal-config
checking gdal-config usability... yes
configure: GDAL: 2.3.1
checking C++11 support for GDAL >= 2.3.0... yes
checking GDAL version >= 1.11.4... yes
checking gdal: linking with --libs only... no
checking gdal: linking with --libs and --dep-libs... no
In file included from /usr/local/include/gdal.h:45:0,
                 from gdal_test.cc:1:
/usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
  newer. #    error Must have C++11 or newer.
      ^
In file included from /usr/local/include/gdal.h:49:0,
                 from gdal_test.cc:1:
/usr/local/include/cpl_minixml.h:202:47: error: expected template-name
  before '<' token class CPLXMLTreeCloser: public
  std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
/usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
  token /usr/local/include/cpl_minixml.h:202:47: error: expected
  unqualified-id before '<' token In file included
  from /usr/local/include/ogr_api.h:45:0,
  from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
/usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
  line /usr/local/include/ogr_core.h:79:28: error: expected declaration
  before end of line In file included
  from /usr/local/include/gdal.h:45:0, from gdal_test.cc:1:
/usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
  newer. #    error Must have C++11 or newer.
      ^
In file included from /usr/local/include/gdal.h:49:0,
                 from gdal_test.cc:1:
/usr/local/include/cpl_minixml.h:202:47: error: expected template-name
  before '<' token class CPLXMLTreeCloser: public
  std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
/usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
  token /usr/local/include/cpl_minixml.h:202:47: error: expected
  unqualified-id before '<' token In file included
  from /usr/local/include/ogr_api.h:45:0,
  from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
/usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
  line /usr/local/include/ogr_core.h:79:28: error: expected declaration
  before end of line configure: Install failure: compilation and/or
  linkage problems. configure: error: GDALAllRegister not found in
  libgdal. ERROR: configuration failed for package ?rgdal?
* removing ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4/rgdal?

The downloaded source packages are in
	?/tmp/RtmpeuSDnj/downloaded_packages?
Warning message:
In install.packages("rgdal") :
  installation of package ?rgdal? had non-zero exit status
> 



From r@herry8 @end|ng |rom comc@@t@net  Thu Aug  9 23:24:17 2018
From: r@herry8 @end|ng |rom comc@@t@net (rsherry8)
Date: Thu, 9 Aug 2018 17:24:17 -0400
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
Message-ID: <5B6CB101.3000008@comcast.net>

Peter,

Thanks for the response. I tired the following command:
     AVB[["AVB.Close"]]
and I got:
     Error in AVB[["AVB.Close"]] : subscript out of bounds
Are you assuming that AVB is a data frame? I do not think AVB is a data 
frame. Is there a way
for me to check?
Thanks,
Bob

On 8/9/2018 3:46 PM, Peter Langfelder wrote:
> If I understand it correctly, the function getSymbols creates a
> variable with the name being the stock symbol. Then use the function
> get(symbol) to retrieve the value of the variable whose name is
> contained in the character string `symbol'. Assign that to a variable
> (e.g. AVB). You may also have to modify the names of the components
> you retrieve from the list AVB. For that, you can use
> AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
> something like AVB[[paste0(symbol, ".Close"]] to generalize the
> retrieval of list components.
>
> HTH,
>
> Peter
> On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>
>> I wrote the following function:
>>
>> # This method gets historical stock data for the stock Avalon Bay whose
>> symbol is AVB.
>> getReturns <- function(norm = FALSE)
>> {
>>       library(quantmod)
>>
>>       getSymbols("AVB", src = "yahoo", from = start, to = end)
>>       length = length(  AVB$AVB.Close )
>>       close = as.numeric( AVB$AVB.Close )
>>       cat( "length = ", length(close ), "\n" )
>>       for( i in 1:length-1 )
>>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>       u = mean(diff)
>>       stdDev = sd(diff)
>>       cat( "stdDev = ", stdDev, "\n" )
>>
>>       if ( norm == TRUE ) {
>>           diff = (diff - u)
>>           diff = diff / stdDev
>>       }
>>       return (diff)
>> }
>>
>> I would like to generalize it to work for any stock by passing in the
>> stock symbol. So the header for the
>> function would be:
>>
>> getReturns <- function(symbol, norm = FALSE)
>>
>> Now how do I update this line:
>>       length = length(  AVB$AVB.Close )
>> This statement will not work:
>>       length = length(  symbol$AVB.Close )
>> because the name that holds the closing price is a function of the stock
>> symbol.
>>
>> Thanks,
>> Bob
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From r@herry8 @end|ng |rom comc@@t@net  Thu Aug  9 23:25:05 2018
From: r@herry8 @end|ng |rom comc@@t@net (rsherry8)
Date: Thu, 9 Aug 2018 17:25:05 -0400
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
Message-ID: <5B6CB131.4010408@comcast.net>

Duncan,

Thanks for the response. I tired the following:
     >  series <- getSymbols("AVB", src = "yahoo", from = start, to = end)
     > series[0]
         character(0)
     > nrow( series )
         NULL
nrow( series ) returned NULL. I do not understand why. I am thinking 
that there should be an R command to
tell me about the structure of series. I tried: typeof( series ) and 
got: "character". Is there a better command for
me to use other than typeof?

I also tried this command:
     c1 <- as.numeric(series[, paste0(symbol, ".Close")])
where symbol held the value "AVB" and I got:
     Error in series[, paste0(symbol, ".Close")] :
     incorrect number of dimensions

Please help.
Thanks,
Bob

On 8/9/2018 3:46 PM, Peter Langfelder wrote:
> If I understand it correctly, the function getSymbols creates a
> variable with the name being the stock symbol. Then use the function
> get(symbol) to retrieve the value of the variable whose name is
> contained in the character string `symbol'. Assign that to a variable
> (e.g. AVB). You may also have to modify the names of the components
> you retrieve from the list AVB. For that, you can use
> AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
> something like AVB[[paste0(symbol, ".Close"]] to generalize the
> retrieval of list components.
>
> HTH,
>
> Peter
> On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>
>> I wrote the following function:
>>
>> # This method gets historical stock data for the stock Avalon Bay whose
>> symbol is AVB.
>> getReturns <- function(norm = FALSE)
>> {
>>       library(quantmod)
>>
>>       getSymbols("AVB", src = "yahoo", from = start, to = end)
>>       length = length(  AVB$AVB.Close )
>>       close = as.numeric( AVB$AVB.Close )
>>       cat( "length = ", length(close ), "\n" )
>>       for( i in 1:length-1 )
>>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>       u = mean(diff)
>>       stdDev = sd(diff)
>>       cat( "stdDev = ", stdDev, "\n" )
>>
>>       if ( norm == TRUE ) {
>>           diff = (diff - u)
>>           diff = diff / stdDev
>>       }
>>       return (diff)
>> }
>>
>> I would like to generalize it to work for any stock by passing in the
>> stock symbol. So the header for the
>> function would be:
>>
>> getReturns <- function(symbol, norm = FALSE)
>>
>> Now how do I update this line:
>>       length = length(  AVB$AVB.Close )
>> This statement will not work:
>>       length = length(  symbol$AVB.Close )
>> because the name that holds the closing price is a function of the stock
>> symbol.
>>
>> Thanks,
>> Bob
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From peter@|@ng|e|der @end|ng |rom gm@||@com  Thu Aug  9 23:29:37 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 9 Aug 2018 14:29:37 -0700
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <5B6CB101.3000008@comcast.net>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
 <5B6CB101.3000008@comcast.net>
Message-ID: <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>

Well, your function uses AVB$AVB.Close, so I assumed AVB is a list (a
data frame can be thought of as a special list). What do you get when
you type class(AVB)?

Peter
On Thu, Aug 9, 2018 at 2:24 PM rsherry8 <rsherry8 at comcast.net> wrote:
>
> Peter,
>
> Thanks for the response. I tired the following command:
>      AVB[["AVB.Close"]]
> and I got:
>      Error in AVB[["AVB.Close"]] : subscript out of bounds
> Are you assuming that AVB is a data frame? I do not think AVB is a data
> frame. Is there a way
> for me to check?
> Thanks,
> Bob
>
> On 8/9/2018 3:46 PM, Peter Langfelder wrote:
> > If I understand it correctly, the function getSymbols creates a
> > variable with the name being the stock symbol. Then use the function
> > get(symbol) to retrieve the value of the variable whose name is
> > contained in the character string `symbol'. Assign that to a variable
> > (e.g. AVB). You may also have to modify the names of the components
> > you retrieve from the list AVB. For that, you can use
> > AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
> > something like AVB[[paste0(symbol, ".Close"]] to generalize the
> > retrieval of list components.
> >
> > HTH,
> >
> > Peter
> > On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
> >>
> >> I wrote the following function:
> >>
> >> # This method gets historical stock data for the stock Avalon Bay whose
> >> symbol is AVB.
> >> getReturns <- function(norm = FALSE)
> >> {
> >>       library(quantmod)
> >>
> >>       getSymbols("AVB", src = "yahoo", from = start, to = end)
> >>       length = length(  AVB$AVB.Close )
> >>       close = as.numeric( AVB$AVB.Close )
> >>       cat( "length = ", length(close ), "\n" )
> >>       for( i in 1:length-1 )
> >>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
> >>       u = mean(diff)
> >>       stdDev = sd(diff)
> >>       cat( "stdDev = ", stdDev, "\n" )
> >>
> >>       if ( norm == TRUE ) {
> >>           diff = (diff - u)
> >>           diff = diff / stdDev
> >>       }
> >>       return (diff)
> >> }
> >>
> >> I would like to generalize it to work for any stock by passing in the
> >> stock symbol. So the header for the
> >> function would be:
> >>
> >> getReturns <- function(symbol, norm = FALSE)
> >>
> >> Now how do I update this line:
> >>       length = length(  AVB$AVB.Close )
> >> This statement will not work:
> >>       length = length(  symbol$AVB.Close )
> >> because the name that holds the closing price is a function of the stock
> >> symbol.
> >>
> >> Thanks,
> >> Bob
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>



From drj|m|emon @end|ng |rom gm@||@com  Fri Aug 10 00:11:09 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 10 Aug 2018 08:11:09 +1000
Subject: [R] Help reinstalling rgdal (Ubuntu 16.04)
In-Reply-To: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
References: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
Message-ID: <CA+8X3fUa=q43VNz-DQW1d10krSF7nPALpeay3zmx_jU0JnSJcw@mail.gmail.com>

Hi Alex,
I don't use Ubuntu, but if I saw that error message I would upgrade my
C++ compiler and try again. With luck, this is what caused the cascade
of errors beneath it.

Jim

On Fri, Aug 10, 2018 at 1:36 AM, Alexandra Thorn
<mail at alexandrathorn.com> wrote:
> Hi all,
>
> Following some updates to R that I received via Synaptic Package
> Manager on Ubuntu 16.04 (looks like I now have R 3.4.4-1xenial0), I
> have been unable to reinstall rgdal, and I need help.
>
> Initially I was getting error messages about dependencies on GDAL
> 1.11.4, but after following instructions to install GDAL from source
> (into my /usr/local directory) I'm now getting a different set of error
> messages (see the output error messages posted below my signature).
>
> I can't tell if this means that I've made a mistake installing GDAL or
> if there's some other problem with my setup/configuration.  I really
> need rgdal for the analyses I do in R and could use some help figuring
> this out.
>
> Thanks,
> Alex
>
>> install.packages("rgdal")
> Installing package into ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4?
> (as ?lib? is unspecified)
> trying URL 'https://cloud.r-project.org/src/contrib/rgdal_1.3-4.tar.gz'
> Content type 'application/x-gzip' length 1664774 bytes (1.6 MB)
> ==================================================
> downloaded 1.6 MB
>
> * installing *source* package ?rgdal? ...
> ** package ?rgdal? successfully unpacked and MD5 sums checked
> configure: R_HOME: /usr/lib/R
> configure: CC: gcc -std=gnu99
> configure: CXX: g++
> configure: C++11 support available
> configure: rgdal: 1.3-4
> checking for /usr/bin/svnversion... no
> configure: svn revision: 766
> checking for gdal-config... /usr/local/bin/gdal-config
> checking gdal-config usability... yes
> configure: GDAL: 2.3.1
> checking C++11 support for GDAL >= 2.3.0... yes
> checking GDAL version >= 1.11.4... yes
> checking gdal: linking with --libs only... no
> checking gdal: linking with --libs and --dep-libs... no
> In file included from /usr/local/include/gdal.h:45:0,
>                  from gdal_test.cc:1:
> /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>   newer. #    error Must have C++11 or newer.
>       ^
> In file included from /usr/local/include/gdal.h:49:0,
>                  from gdal_test.cc:1:
> /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
>   before '<' token class CPLXMLTreeCloser: public
>   std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
> /usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
>   token /usr/local/include/cpl_minixml.h:202:47: error: expected
>   unqualified-id before '<' token In file included
>   from /usr/local/include/ogr_api.h:45:0,
>   from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
> /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
>   line /usr/local/include/ogr_core.h:79:28: error: expected declaration
>   before end of line In file included
>   from /usr/local/include/gdal.h:45:0, from gdal_test.cc:1:
> /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>   newer. #    error Must have C++11 or newer.
>       ^
> In file included from /usr/local/include/gdal.h:49:0,
>                  from gdal_test.cc:1:
> /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
>   before '<' token class CPLXMLTreeCloser: public
>   std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
> /usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
>   token /usr/local/include/cpl_minixml.h:202:47: error: expected
>   unqualified-id before '<' token In file included
>   from /usr/local/include/ogr_api.h:45:0,
>   from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
> /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
>   line /usr/local/include/ogr_core.h:79:28: error: expected declaration
>   before end of line configure: Install failure: compilation and/or
>   linkage problems. configure: error: GDALAllRegister not found in
>   libgdal. ERROR: configuration failed for package ?rgdal?
> * removing ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4/rgdal?
>
> The downloaded source packages are in
>         ?/tmp/RtmpeuSDnj/downloaded_packages?
> Warning message:
> In install.packages("rgdal") :
>   installation of package ?rgdal? had non-zero exit status
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Aug 10 00:13:38 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 9 Aug 2018 22:13:38 +0000
Subject: [R] Help reinstalling rgdal (Ubuntu 16.04)
In-Reply-To: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
References: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
Message-ID: <FDA106CA-4AF9-449C-93C7-609FFAE3B20A@llnl.gov>

There are quite a few messages on R-sig-geo about installing rgdal on Ubuntu. Maybe one of them contains your solution?
(I use Mac, so can't help directly)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/9/18, 8:36 AM, "R-help on behalf of Alexandra Thorn" <r-help-bounces at r-project.org on behalf of mail at alexandrathorn.com> wrote:

    Hi all,
    
    Following some updates to R that I received via Synaptic Package
    Manager on Ubuntu 16.04 (looks like I now have R 3.4.4-1xenial0), I
    have been unable to reinstall rgdal, and I need help.
    
    Initially I was getting error messages about dependencies on GDAL
    1.11.4, but after following instructions to install GDAL from source
    (into my /usr/local directory) I'm now getting a different set of error
    messages (see the output error messages posted below my signature).  
    
    I can't tell if this means that I've made a mistake installing GDAL or
    if there's some other problem with my setup/configuration.  I really
    need rgdal for the analyses I do in R and could use some help figuring
    this out.
    
    Thanks,
    Alex
    
    > install.packages("rgdal")
    Installing package into ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4?
    (as ?lib? is unspecified)
    trying URL 'https://cloud.r-project.org/src/contrib/rgdal_1.3-4.tar.gz'
    Content type 'application/x-gzip' length 1664774 bytes (1.6 MB)
    ==================================================
    downloaded 1.6 MB
    
    * installing *source* package ?rgdal? ...
    ** package ?rgdal? successfully unpacked and MD5 sums checked
    configure: R_HOME: /usr/lib/R
    configure: CC: gcc -std=gnu99
    configure: CXX: g++
    configure: C++11 support available
    configure: rgdal: 1.3-4
    checking for /usr/bin/svnversion... no
    configure: svn revision: 766
    checking for gdal-config... /usr/local/bin/gdal-config
    checking gdal-config usability... yes
    configure: GDAL: 2.3.1
    checking C++11 support for GDAL >= 2.3.0... yes
    checking GDAL version >= 1.11.4... yes
    checking gdal: linking with --libs only... no
    checking gdal: linking with --libs and --dep-libs... no
    In file included from /usr/local/include/gdal.h:45:0,
                     from gdal_test.cc:1:
    /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
      newer. #    error Must have C++11 or newer.
          ^
    In file included from /usr/local/include/gdal.h:49:0,
                     from gdal_test.cc:1:
    /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
      before '<' token class CPLXMLTreeCloser: public
      std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
    /usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
      token /usr/local/include/cpl_minixml.h:202:47: error: expected
      unqualified-id before '<' token In file included
      from /usr/local/include/ogr_api.h:45:0,
      from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
    /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
      line /usr/local/include/ogr_core.h:79:28: error: expected declaration
      before end of line In file included
      from /usr/local/include/gdal.h:45:0, from gdal_test.cc:1:
    /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
      newer. #    error Must have C++11 or newer.
          ^
    In file included from /usr/local/include/gdal.h:49:0,
                     from gdal_test.cc:1:
    /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
      before '<' token class CPLXMLTreeCloser: public
      std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
    /usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
      token /usr/local/include/cpl_minixml.h:202:47: error: expected
      unqualified-id before '<' token In file included
      from /usr/local/include/ogr_api.h:45:0,
      from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
    /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
      line /usr/local/include/ogr_core.h:79:28: error: expected declaration
      before end of line configure: Install failure: compilation and/or
      linkage problems. configure: error: GDALAllRegister not found in
      libgdal. ERROR: configuration failed for package ?rgdal?
    * removing ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4/rgdal?
    
    The downloaded source packages are in
    	?/tmp/RtmpeuSDnj/downloaded_packages?
    Warning message:
    In install.packages("rgdal") :
      installation of package ?rgdal? had non-zero exit status
    > 
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r@herry8 @end|ng |rom comc@@t@net  Fri Aug 10 00:18:40 2018
From: r@herry8 @end|ng |rom comc@@t@net (rsherry8)
Date: Thu, 9 Aug 2018 18:18:40 -0400
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
 <5B6CB101.3000008@comcast.net>
 <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>
Message-ID: <5B6CBDC0.2070206@comcast.net>

Peter,

Here is the R command and its output that you requested:

 > class(AVB)
[1] "xts" "zoo"

Bob
On 8/9/2018 5:29 PM, Peter Langfelder wrote:
> Well, your function uses AVB$AVB.Close, so I assumed AVB is a list (a
> data frame can be thought of as a special list). What do you get when
> you type class(AVB)?
>
> Peter
> On Thu, Aug 9, 2018 at 2:24 PM rsherry8 <rsherry8 at comcast.net> wrote:
>> Peter,
>>
>> Thanks for the response. I tired the following command:
>>       AVB[["AVB.Close"]]
>> and I got:
>>       Error in AVB[["AVB.Close"]] : subscript out of bounds
>> Are you assuming that AVB is a data frame? I do not think AVB is a data
>> frame. Is there a way
>> for me to check?
>> Thanks,
>> Bob
>>
>> On 8/9/2018 3:46 PM, Peter Langfelder wrote:
>>> If I understand it correctly, the function getSymbols creates a
>>> variable with the name being the stock symbol. Then use the function
>>> get(symbol) to retrieve the value of the variable whose name is
>>> contained in the character string `symbol'. Assign that to a variable
>>> (e.g. AVB). You may also have to modify the names of the components
>>> you retrieve from the list AVB. For that, you can use
>>> AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
>>> something like AVB[[paste0(symbol, ".Close"]] to generalize the
>>> retrieval of list components.
>>>
>>> HTH,
>>>
>>> Peter
>>> On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>> I wrote the following function:
>>>>
>>>> # This method gets historical stock data for the stock Avalon Bay whose
>>>> symbol is AVB.
>>>> getReturns <- function(norm = FALSE)
>>>> {
>>>>        library(quantmod)
>>>>
>>>>        getSymbols("AVB", src = "yahoo", from = start, to = end)
>>>>        length = length(  AVB$AVB.Close )
>>>>        close = as.numeric( AVB$AVB.Close )
>>>>        cat( "length = ", length(close ), "\n" )
>>>>        for( i in 1:length-1 )
>>>>            diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>>>        u = mean(diff)
>>>>        stdDev = sd(diff)
>>>>        cat( "stdDev = ", stdDev, "\n" )
>>>>
>>>>        if ( norm == TRUE ) {
>>>>            diff = (diff - u)
>>>>            diff = diff / stdDev
>>>>        }
>>>>        return (diff)
>>>> }
>>>>
>>>> I would like to generalize it to work for any stock by passing in the
>>>> stock symbol. So the header for the
>>>> function would be:
>>>>
>>>> getReturns <- function(symbol, norm = FALSE)
>>>>
>>>> Now how do I update this line:
>>>>        length = length(  AVB$AVB.Close )
>>>> This statement will not work:
>>>>        length = length(  symbol$AVB.Close )
>>>> because the name that holds the closing price is a function of the stock
>>>> symbol.
>>>>
>>>> Thanks,
>>>> Bob
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 10 00:40:47 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 9 Aug 2018 15:40:47 -0700
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
 <5B6CB101.3000008@comcast.net>
 <CA+hbrhX2v1xJ7gHc+jd6TFxMOeGMYq7MQUJpLAbPdAptMZx7LQ@mail.gmail.com>
Message-ID: <CAGxFJbTXnygOdHnCYRWEoZ5W1dwFu+dfH=OGcBFrjCD5iLaX8A@mail.gmail.com>

" I am thinking that there should be an R command to
tell me about the structure of series"

?str
## perhaps also/instead
?summary

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Aug 9, 2018 at 2:29 PM, Peter Langfelder <peter.langfelder at gmail.com
> wrote:

> Well, your function uses AVB$AVB.Close, so I assumed AVB is a list (a
> data frame can be thought of as a special list). What do you get when
> you type class(AVB)?
>
> Peter
> On Thu, Aug 9, 2018 at 2:24 PM rsherry8 <rsherry8 at comcast.net> wrote:
> >
> > Peter,
> >
> > Thanks for the response. I tired the following command:
> >      AVB[["AVB.Close"]]
> > and I got:
> >      Error in AVB[["AVB.Close"]] : subscript out of bounds
> > Are you assuming that AVB is a data frame? I do not think AVB is a data
> > frame. Is there a way
> > for me to check?
> > Thanks,
> > Bob
> >
> > On 8/9/2018 3:46 PM, Peter Langfelder wrote:
> > > If I understand it correctly, the function getSymbols creates a
> > > variable with the name being the stock symbol. Then use the function
> > > get(symbol) to retrieve the value of the variable whose name is
> > > contained in the character string `symbol'. Assign that to a variable
> > > (e.g. AVB). You may also have to modify the names of the components
> > > you retrieve from the list AVB. For that, you can use
> > > AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
> > > something like AVB[[paste0(symbol, ".Close"]] to generalize the
> > > retrieval of list components.
> > >
> > > HTH,
> > >
> > > Peter
> > > On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
> > >>
> > >> I wrote the following function:
> > >>
> > >> # This method gets historical stock data for the stock Avalon Bay
> whose
> > >> symbol is AVB.
> > >> getReturns <- function(norm = FALSE)
> > >> {
> > >>       library(quantmod)
> > >>
> > >>       getSymbols("AVB", src = "yahoo", from = start, to = end)
> > >>       length = length(  AVB$AVB.Close )
> > >>       close = as.numeric( AVB$AVB.Close )
> > >>       cat( "length = ", length(close ), "\n" )
> > >>       for( i in 1:length-1 )
> > >>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
> > >>       u = mean(diff)
> > >>       stdDev = sd(diff)
> > >>       cat( "stdDev = ", stdDev, "\n" )
> > >>
> > >>       if ( norm == TRUE ) {
> > >>           diff = (diff - u)
> > >>           diff = diff / stdDev
> > >>       }
> > >>       return (diff)
> > >> }
> > >>
> > >> I would like to generalize it to work for any stock by passing in the
> > >> stock symbol. So the header for the
> > >> function would be:
> > >>
> > >> getReturns <- function(symbol, norm = FALSE)
> > >>
> > >> Now how do I update this line:
> > >>       length = length(  AVB$AVB.Close )
> > >> This statement will not work:
> > >>       length = length(  symbol$AVB.Close )
> > >> because the name that holds the closing price is a function of the
> stock
> > >> symbol.
> > >>
> > >> Thanks,
> > >> Bob
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Fri Aug 10 01:15:58 2018
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Thu, 9 Aug 2018 18:15:58 -0500
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <5B6CB101.3000008@comcast.net>
References: <5B6C760D.5050404@comcast.net>
 <CA+hbrhX_+_7Jv1dEjBTRm72NanWojpBuzODF=KUmKw3kNbHDJw@mail.gmail.com>
 <5B6CB101.3000008@comcast.net>
Message-ID: <CAPPM_gR+B5f46pat2KDSzy4LehQ+ywPGCoN2tBefEtpU9yjuXA@mail.gmail.com>

Peter was on the right track.  getSymbols() allows you to specify that
you want the value returned as an object instead of load()ed by
setting auto.assign = FALSE.

I've also made other changes to your function:
- Use requireNamespace() so you don't alter the search() path
- Use TTR::ROC() to calculate returns, instead of a loop
- Use more meaningful names for the mean and standard deviation objects
- Use isTRUE() to ensure 'norm' is 'TRUE' and not '1' or '"true"' or
anything else that could be coerced to TRUE

getReturns <-
function(symbol,
         start = "2015-01-01",
         end = Sys.Date(),
         norm = FALSE)
{
    stopifnot(requireNamespace("quantmod"))

    Data <- quantmod::getSymbols(symbol, src = "yahoo",
      from = start, to = end, auto.assign = FALSE)
    cat("length = ", NROW(Data), "\n")
    ret <- TTR::ROC(quantmod::Cl(Data), type = "discrete")
    mu <- mean(ret, na.rm = TRUE)
    sigma <- sd(ret, na.rm = TRUE)
    cat("stdDev = ", sigma, "\n")

    if (isTRUE(norm)) {
        ret <- (ret - mu)
        ret <- ret / sigma
    }
    return(ret)
}

x <- getReturns("IBM")
length =  907
stdDev =  0.01245428
head(x)
              IBM.Close
2015-01-02           NA
2015-01-05 -0.015734932
2015-01-06 -0.021565971
2015-01-07 -0.006535554
2015-01-08  0.021734892
2015-01-09  0.004355530


On Thu, Aug 9, 2018 at 4:24 PM, rsherry8 <rsherry8 at comcast.net> wrote:
> Peter,
>
> Thanks for the response. I tired the following command:
>     AVB[["AVB.Close"]]
> and I got:
>     Error in AVB[["AVB.Close"]] : subscript out of bounds
> Are you assuming that AVB is a data frame? I do not think AVB is a data
> frame. Is there a way
> for me to check?
> Thanks,
> Bob
>
>
> On 8/9/2018 3:46 PM, Peter Langfelder wrote:
>>
>> If I understand it correctly, the function getSymbols creates a
>> variable with the name being the stock symbol. Then use the function
>> get(symbol) to retrieve the value of the variable whose name is
>> contained in the character string `symbol'. Assign that to a variable
>> (e.g. AVB). You may also have to modify the names of the components
>> you retrieve from the list AVB. For that, you can use
>> AVB[["AVB.Close"]] instead of AVB$AVB.Close. You can them use
>> something like AVB[[paste0(symbol, ".Close"]] to generalize the
>> retrieval of list components.
>>
>> HTH,
>>
>> Peter
>> On Thu, Aug 9, 2018 at 12:40 PM rsherry8 <rsherry8 at comcast.net> wrote:
>>>
>>>
>>> I wrote the following function:
>>>
>>> # This method gets historical stock data for the stock Avalon Bay whose
>>> symbol is AVB.
>>> getReturns <- function(norm = FALSE)
>>> {
>>>       library(quantmod)
>>>
>>>       getSymbols("AVB", src = "yahoo", from = start, to = end)
>>>       length = length(  AVB$AVB.Close )
>>>       close = as.numeric( AVB$AVB.Close )
>>>       cat( "length = ", length(close ), "\n" )
>>>       for( i in 1:length-1 )
>>>           diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>>       u = mean(diff)
>>>       stdDev = sd(diff)
>>>       cat( "stdDev = ", stdDev, "\n" )
>>>
>>>       if ( norm == TRUE ) {
>>>           diff = (diff - u)
>>>           diff = diff / stdDev
>>>       }
>>>       return (diff)
>>> }
>>>
>>> I would like to generalize it to work for any stock by passing in the
>>> stock symbol. So the header for the
>>> function would be:
>>>
>>> getReturns <- function(symbol, norm = FALSE)
>>>
>>> Now how do I update this line:
>>>       length = length(  AVB$AVB.Close )
>>> This statement will not work:
>>>       length = length(  symbol$AVB.Close )
>>> because the name that holds the closing price is a function of the stock
>>> symbol.
>>>
>>> Thanks,
>>> Bob
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2018 | www.rinfinance.com



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 10 03:19:49 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 09 Aug 2018 18:19:49 -0700
Subject: [R] Help reinstalling rgdal (Ubuntu 16.04)
In-Reply-To: <FDA106CA-4AF9-449C-93C7-609FFAE3B20A@llnl.gov>
References: <20180809113623.71e49ae7@athorn-Lemur-Ultra>
 <FDA106CA-4AF9-449C-93C7-609FFAE3B20A@llnl.gov>
Message-ID: <B288ADA5-7C74-4184-9AA0-AD1D63F50E16@dcn.davis.ca.us>

Or ask on R-sig-debian...

On August 9, 2018 3:13:38 PM PDT, "MacQueen, Don via R-help" <r-help at r-project.org> wrote:
>There are quite a few messages on R-sig-geo about installing rgdal on
>Ubuntu. Maybe one of them contains your solution?
>(I use Mac, so can't help directly)
>
>-Don
>
>--
>Don MacQueen
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>Lab cell 925-724-7509
> 
> 
>
>?On 8/9/18, 8:36 AM, "R-help on behalf of Alexandra Thorn"
><r-help-bounces at r-project.org on behalf of mail at alexandrathorn.com>
>wrote:
>
>    Hi all,
>    
>    Following some updates to R that I received via Synaptic Package
>    Manager on Ubuntu 16.04 (looks like I now have R 3.4.4-1xenial0), I
>    have been unable to reinstall rgdal, and I need help.
>    
>    Initially I was getting error messages about dependencies on GDAL
>   1.11.4, but after following instructions to install GDAL from source
>(into my /usr/local directory) I'm now getting a different set of error
>  messages (see the output error messages posted below my signature).  
>    
> I can't tell if this means that I've made a mistake installing GDAL or
>   if there's some other problem with my setup/configuration.  I really
> need rgdal for the analyses I do in R and could use some help figuring
>    this out.
>    
>    Thanks,
>    Alex
>    
>    > install.packages("rgdal")
>Installing package into
>?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4?
>    (as ?lib? is unspecified)
>trying URL 'https://cloud.r-project.org/src/contrib/rgdal_1.3-4.tar.gz'
>    Content type 'application/x-gzip' length 1664774 bytes (1.6 MB)
>    ==================================================
>    downloaded 1.6 MB
>    
>    * installing *source* package ?rgdal? ...
>    ** package ?rgdal? successfully unpacked and MD5 sums checked
>    configure: R_HOME: /usr/lib/R
>    configure: CC: gcc -std=gnu99
>    configure: CXX: g++
>    configure: C++11 support available
>    configure: rgdal: 1.3-4
>    checking for /usr/bin/svnversion... no
>    configure: svn revision: 766
>    checking for gdal-config... /usr/local/bin/gdal-config
>    checking gdal-config usability... yes
>    configure: GDAL: 2.3.1
>    checking C++11 support for GDAL >= 2.3.0... yes
>    checking GDAL version >= 1.11.4... yes
>    checking gdal: linking with --libs only... no
>    checking gdal: linking with --libs and --dep-libs... no
>    In file included from /usr/local/include/gdal.h:45:0,
>                     from gdal_test.cc:1:
>  /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>      newer. #    error Must have C++11 or newer.
>          ^
>    In file included from /usr/local/include/gdal.h:49:0,
>                     from gdal_test.cc:1:
> /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
>      before '<' token class CPLXMLTreeCloser: public
>      std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
>/usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
>      token /usr/local/include/cpl_minixml.h:202:47: error: expected
>      unqualified-id before '<' token In file included
>      from /usr/local/include/ogr_api.h:45:0,
>      from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
> /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
>  line /usr/local/include/ogr_core.h:79:28: error: expected declaration
>      before end of line In file included
>      from /usr/local/include/gdal.h:45:0, from gdal_test.cc:1:
>  /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>      newer. #    error Must have C++11 or newer.
>          ^
>    In file included from /usr/local/include/gdal.h:49:0,
>                     from gdal_test.cc:1:
> /usr/local/include/cpl_minixml.h:202:47: error: expected template-name
>      before '<' token class CPLXMLTreeCloser: public
>      std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter> ^
>/usr/local/include/cpl_minixml.h:202:47: error: expected '{' before '<'
>      token /usr/local/include/cpl_minixml.h:202:47: error: expected
>      unqualified-id before '<' token In file included
>      from /usr/local/include/ogr_api.h:45:0,
>      from /usr/local/include/gdal.h:50, from gdal_test.cc:1:
> /usr/local/include/ogr_core.h:79:28: error: expected '}' before end of
>  line /usr/local/include/ogr_core.h:79:28: error: expected declaration
>      before end of line configure: Install failure: compilation and/or
>      linkage problems. configure: error: GDALAllRegister not found in
>      libgdal. ERROR: configuration failed for package ?rgdal?
>    * removing ?/home/athorn/R/x86_64-pc-linux-gnu-library/3.4/rgdal?
>    
>    The downloaded source packages are in
>    	?/tmp/RtmpeuSDnj/downloaded_packages?
>    Warning message:
>    In install.packages("rgdal") :
>      installation of package ?rgdal? had non-zero exit status
>    > 
>    
>    ______________________________________________
>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
>    
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From m|@ojpm @end|ng |rom gm@||@com  Fri Aug 10 10:59:45 2018
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Fri, 10 Aug 2018 16:59:45 +0800
Subject: [R] The auto.arima function in forecast package
Message-ID: <CABcx46ARs7rCdBS4FgQz25Eeh0euSf9-WGrz3r8dTXgWFw9c-g@mail.gmail.com>

Hi,

   I am wondering if I am doing correctly, but my auto.arima usually (if
not always) give me (0,1,0), whatever portion of the series I take. In the
following instances, only the last one yields ARIMA(0,1,1), and all the
other cases yield ARIMA(0,1,0). I would like to do forecast based on ARIMA.
The forecast with ARIMA(0,1,0) is exactly the random walk forecast for any
forecasting horizon h, so it does not make much sense.... Am I doing
anything wrong? Is the data very unusual?

   The length of the df_arima sequence is 68. My data is seasonally
adjusted, so I use seasonal = FALSE.

> auto.arima(df_arima, d=1, ic="aic", seasonal = FALSE)
Series: df_arima
ARIMA(0,1,0)

sigma^2 estimated as 0.9323:  log likelihood=-221.43
AIC=444.85   AICc=444.88   BIC=447.93

> auto.arima(df_arima[2:30], d=1, ic="aic", seasonal = FALSE)
Series: df_arima[2:30]
ARIMA(0,1,0)

sigma^2 estimated as 1.486:  log likelihood=-45.28
AIC=92.56   AICc=92.71   BIC=93.89
> auto.arima(df_arima[30:50], d=1, ic="aic", seasonal = FALSE)
Series: df_arima[30:50]
ARIMA(0,1,0)

sigma^2 estimated as 2.065:  log likelihood=-35.63
AIC=73.26   AICc=73.48   BIC=74.25
> auto.arima(df_arima[30:65], d=1, ic="aic", seasonal = FALSE)
Series: df_arima[30:65]
ARIMA(0,1,1)

Coefficients:
         ma1
      0.3684
s.e.  0.1591

sigma^2 estimated as 1.328:  log likelihood=-54.19
AIC=112.39   AICc=112.76   BIC=115.5


> dput(df_arima)
c(0.206955966502065, 0.572310398166964, 0.730924932354315,
1.41842200551883,
3.46103800972619, 3.61249423115895, 5.82223437508589, 4.16838241173942,
3.41346768155648, 0.862064978610255, 0.998745364906517, 0.519274399474301,
-1.11283353732583, -0.735660435061958, -0.780332562883557,
0.835729609943847,
2.72188993637388, 2.28434816118952, 1.89419627788212, 0.808622045623819,
0.628929267637468, -0.605142332415043, -1.50590253313166,
-0.288872689519148,
0.779724144195981, 1.77156391706856, 1.54853781756041, 3.31419159924959,
1.93558418905826, 1.2733744986462, 1.08821585241274, 2.62853576193935,
3.73925259835317, 4.36605858718784, 4.94030870469473, 4.95025405015856,
3.62293670685028, 2.66083271862916, 2.63088962945459, 2.64079870265661,
2.24308372288402, 4.60965981893589, 5.61665338477875, 4.13854855208327,
2.74923595127379, 1.95704807193253, 1.39700634338462, -3.2051540517546,
-4.14645815871689, -3.55954963127346, -2.75935917560429, -2.35979888878128,
-1.60997264659325, 0.107359485533354, 0.452171464181572, 1.83710430300006,
2.05388942618911, 1.42071194194746, 0.62281728667859, 0.66619920044817,
1.91899026506288, 0.876017396693274, 0.767997179685187, 0.960763098531148,
1.07168884361519, 1.7179971391635, 0.916107067445848, 0.488814956401007,
0.445930327726551, 0.700746383716555, 1.85843822164806, 0.892473264860727,
0.614568090119794, 2.4071141581713, 1.95656784524512, 1.97416030945137,
1.50143287537079, 2.16462319254254, 2.07797672518777, 0.272208427739407,
0.798064671535004, 0.754477049206304, 1.15345347401843, 1.2569270188491,
1.04667488857908, 1.61549969176582, 1.61397592409376, 2.15802281566817,
1.77514416862246, 1.37441120562698, 2.02489513295532, 2.58699935920175,
2.75245197313523, 2.23920076522477, 1.5517277192193, 2.1968256454034,
2.56612088350139, 1.58214013021238, 0.224868329892303, 0, 0.75815516785358,
0.306075421735685, -0.911618439021877, -0.851059960629386,
0.920475843398605,
0.204019124781452, 0.265049070791767, 0.693380201646732, 1.76190014304951,
1.7409678665274, 2.30875574967095, 3.1616985460498, 3.03416937102321,
2.51100317138793, 1.74651451299397, 2.1955027765292, 0.885663954102278,
0.42162278205693, -0.919995110735239, -1.09905745071531, -2.68791519080633,
-3.351439, -2.10834457783508, -2.20921682103322, -0.74375338663687,
-0.402576080931594, 1.20253696682322, 1.49061195023896, 0.526155117506621,
1.48289074384766, 0.627624111314717, 0.262639414167709, 0.101025401449073,
0.667507628973207, 0.86863891914688, 0.603620359927048, 1.53734977063493,
1.63989774985629, 2.06996035293847, 1.23150306020205, 1.00602988533123,
1.46753831297777, 1.28396719372157, 1.22372099999999, 0.42010456383097,
1.68739489046037, 1.0009947634714, 0.218850966640427, 0.218698677177565,
0.457733617597422, 1.42090579656218, 0.436897503947153, 1.05592733175737,
1.67544706250284, 2.69758588203255, 2.87640149597799, 2.13003529065778,
2.42946437023286, 2.32608159085508, 1.97956200691809, 0.274402066259904
)

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Aug 10 15:48:25 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 10 Aug 2018 06:48:25 -0700 (PDT)
Subject: [R] Resolving installed package updates warning
Message-ID: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>

   Updating installed packages ends with a warning:

Warning message:
In install.packages(update[instlib == l, "Package"], l, contriburl = contriburl,  :
   installation of package ?rgdal? had non-zero exit status

   What steps should I take to correct this?

Rich



From m@rko@|un@13 @end|ng |rom gm@||@com  Fri Aug 10 16:00:33 2018
From: m@rko@|un@13 @end|ng |rom gm@||@com (=?UTF-8?Q?Marco_Antonio_P=C3=A9rez?=)
Date: Fri, 10 Aug 2018 11:00:33 -0300
Subject: [R] help
Message-ID: <CAON01EbSs=z6Gd6vPaa9aQReiJTwi6rqHyKBFJ71Wo+bT=yh+g@mail.gmail.com>

 I am trying to write a function to make a matrix of precipitation with
this secuencie;
######## PRIMER PERIODO
cordex1 <-
nc_open("pr_CAM-44i_ICHEC-EC-EARTH_rcp45_r12i1p1_SMHI-RCA4_v1_mon_200601-201012.nc")
fullmon1<-ncvar_get(cordex1,"pr")
lat<-ncvar_get(cordex1,"lat", start=c(35.5),count=c(20))
lon <-ncvar_get(cordex1,"lon", start=c(125),count=c(21.5))
t <- ncvar_get(cordex1,"time")
nlon <- dim(lon)
nlat <- dim(lat)
nt <- dim(t)
fulldatav <- as.vector(fullmon1)
fulldata <- matrix(fulldatav, nrow=nlon*nlat, ncol=nt)
lonlat <- expand.grid(lon,lat)
df_cordex1<- data.frame(lonlat,fulldata)

but with the expresion  fulldata <- matrix(fulldatav, nrow=nlon*nlat,
ncol=nt) this error appears
Warning message:
In matrix(fulldatav, nrow = nlon * nlat, ncol = nt) :
  data length [1378620] is not a sub-multiple or multiple of the number of
rows [420]

Somebody help me!!!

	[[alternative HTML version deleted]]



From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Fri Aug 10 17:22:12 2018
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Fri, 10 Aug 2018 15:22:12 +0000
Subject: [R] Fast matrix multiplication
Message-ID: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>

Hi,

I would like to compute:  A %*% B %*% t(A)



A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).



Here is a sample code.



M <- 10000

N <- 100

A <- matrix(rnorm(M*N), M, N)

B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric positive-definite matrix



# method 1

system.time(D <- A %*% B %*% t(A))



# I can obtain speedup by using a Cholesky decomposition of B

# method 2

system.time({

C <- t(chol(B))

E <- tcrossprod(A%*%C)

})



all.equal(D, E)



I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.



Thanks,

Ravi



	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Aug 10 18:15:37 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 10 Aug 2018 16:15:37 +0000
Subject: [R] Resolving installed package updates warning
In-Reply-To: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
Message-ID: <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>

I would start by trying to install rgdal by itself, rather than as part of a "batch" update. As in

  Install.packages('rgdal')

 My expectation is that you will see a more complete error message specific to rgdal, which presumably will provide a clue or pointer.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/10/18, 6:48 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       Updating installed packages ends with a warning:
    
    Warning message:
    In install.packages(update[instlib == l, "Package"], l, contriburl = contriburl,  :
       installation of package ?rgdal? had non-zero exit status
    
       What steps should I take to correct this?
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From |@t@z@hn @end|ng |rom gm@||@com  Fri Aug 10 18:19:57 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Fri, 10 Aug 2018 12:19:57 -0400
Subject: [R] Fast matrix multiplication
In-Reply-To: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
Message-ID: <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>

Hi Ravi,

You can achieve substantial speed up by using a faster BLAS (e.g.,
OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6
year old, but 8 core) system your example takes 3.9 seconds with using
the reference BLAS and only 0.9 seconds using OpenBLAS.

Best,
Ista
On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Hi,
>
> I would like to compute:  A %*% B %*% t(A)
>
>
>
> A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
>
>
>
> Here is a sample code.
>
>
>
> M <- 10000
>
> N <- 100
>
> A <- matrix(rnorm(M*N), M, N)
>
> B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric positive-definite matrix
>
>
>
> # method 1
>
> system.time(D <- A %*% B %*% t(A))
>
>
>
> # I can obtain speedup by using a Cholesky decomposition of B
>
> # method 2
>
> system.time({
>
> C <- t(chol(B))
>
> E <- tcrossprod(A%*%C)
>
> })
>
>
>
> all.equal(D, E)
>
>
>
> I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
>
>
>
> Thanks,
>
> Ravi
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From HDor@n @end|ng |rom @|r@org  Fri Aug 10 18:22:42 2018
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Fri, 10 Aug 2018 16:22:42 +0000
Subject: [R] Fast matrix multiplication
Message-ID: <D79333E7.529D3%hdoran@air.org>

Yeah, you might not be able to go much faster here unless A has some
specialized structure that you can take advantage of (e.g., sparsity)?

On 8/10/18, 11:22 AM, "Ravi Varadhan" <ravi.varadhan at jhu.edu> wrote:

>Hi,
>
>I would like to compute:  A %*% B %*% t(A)
>
>
>
>A is a mxn matrix and B is an nxn symmetric, positive-definite matrix,
>where m is large relative to n (e.g., m=50,000 and n=100).
>
>
>
>Here is a sample code.
>
>
>
>M <- 10000
>
>N <- 100
>
>A <- matrix(rnorm(M*N), M, N)
>
>B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric
>positive-definite matrix
>
>
>
># method 1
>
>system.time(D <- A %*% B %*% t(A))
>
>
>
># I can obtain speedup by using a Cholesky decomposition of B
>
># method 2
>
>system.time({
>
>C <- t(chol(B))
>
>E <- tcrossprod(A%*%C)
>
>})
>
>
>
>all.equal(D, E)
>
>
>
>I am wondering how to obtain more substantial speedup.  Any suggestions
>would be greatly appreciated.
>
>
>
>Thanks,
>
>Ravi
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>



From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Fri Aug 10 18:48:14 2018
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Fri, 10 Aug 2018 16:48:14 +0000
Subject: [R] cumulate of snow cumulates from daily values of different
 automatic stations for some time intervals
Message-ID: <8B435C9568170B469AE31E8891E8CC4F54CCBF0B@ESINO.regionemarche.intra>

Dear R-list users,
I have 10 data frames (called df1, df2, ... df10), where each of them contains snow data from an automatic meteorological station (obviously each station has a different station code).
Here is an example of df1:

station_code date_factor date_POSIX snow
217 1999-12-15 1999-12-15  0
217 1999-12-16 1999-12-16  0
217 1999-12-17 1999-12-17 38
217 1999-12-18 1999-12-18 31
217 1999-12-19 1999-12-19 21
217 1999-12-20 1999-12-20 12
217 1999-12-21 1999-12-21 42
217 1999-12-22 1999-12-22 61
217 1999-12-23 1999-12-23 57
217 1999-12-24 1999-12-24 48
...

where
> sapply(df1, class)
$station_code
[1] "numeric"

$date_factor
[1] "factor"

$date_POSIX
[1] "POSIXct" "POSIXt"

$snow
[1] "integer"

Given a series of max three intervals (example with two intervals: from 1st to 12th of January 2000 and from 23rd to 28th of March 2000), I need to evaluate for each station the total snow cumulate for all the intervals selected, and finally create a data frame where for each line there is the station code and the snow cumulate. It should be like

station_code total_snow_cumulate
217 125
218 80
...

Could somebody show me a direction for an efficient solution?

Thank you for your attention and your help
Stefano


         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Aug 10 18:53:54 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 10 Aug 2018 09:53:54 -0700 (PDT)
Subject: [R] Resolving installed package updates warning
In-Reply-To: <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
 <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
Message-ID: <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>

On Fri, 10 Aug 2018, MacQueen, Don wrote:

> I would start by trying to install rgdal by itself, rather than as part of
> a "batch" update. As in
>
>  Install.packages('rgdal')

Don,

   rgdal was supposed to be installed, but you have a valid point.

> My expectation is that you will see a more complete error message specific
> to rgdal, which presumably will provide a clue or pointer.

   Boy howdy! This is interesting:

* installing *source* package ?rgdal? ...
** package ?rgdal? successfully unpacked and MD5 sums checked
configure: R_HOME: /usr/lib/R
configure: CC: gcc
configure: CXX: g++
configure: C++11 support available
configure: rgdal: 1.3-4
checking for /usr/bin/svnversion... yes
configure: svn revision: 766
checking for gdal-config... /usr/bin/gdal-config
checking gdal-config usability... yes
configure: GDAL: 2.3.0
checking C++11 support for GDAL >= 2.3.0... yes
checking GDAL version >= 1.11.4... yes
checking gdal: linking with --libs only... no
checking gdal: linking with --libs and --dep-libs... no
In file included from /usr/include/gdal.h:45:0,
                  from gdal_test.cc:1:
/usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
  #    error Must have C++11 or newer.
       ^
In file included from /usr/include/gdal.h:49:0,
                  from gdal_test.cc:1:
/usr/include/cpl_minixml.h:202:47: error: expected template-name before '<' token
  class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter>
                                                ^
/usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
/usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before '<' token
In file included from /usr/include/ogr_api.h:45:0,
                  from /usr/include/gdal.h:50,
                  from gdal_test.cc:1:
/usr/include/ogr_core.h:79:28: error: expected '}' before end of line
/usr/include/ogr_core.h:79:28: error: expected declaration before end of line
In file included from /usr/include/gdal.h:45:0,
                  from gdal_test.cc:1:
/usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
  #    error Must have C++11 or newer.
       ^
In file included from /usr/include/gdal.h:49:0,
                  from gdal_test.cc:1:
/usr/include/cpl_minixml.h:202:47: error: expected template-name before '<' token
  class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter>
                                                ^
/usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
/usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before '<' token
In file included from /usr/include/ogr_api.h:45:0,
                  from /usr/include/gdal.h:50,
                  from gdal_test.cc:1:
/usr/include/ogr_core.h:79:28: error: expected '}' before end of line
/usr/include/ogr_core.h:79:28: error: expected declaration before end of line
configure: Install failure: compilation and/or linkage problems.
configure: error: GDALAllRegister not found in libgdal.
ERROR: configuration failed for package ?rgdal?
* removing ?/usr/lib/R/library/rgdal?
* restoring previous ?/usr/lib/R/library/rgdal?

The downloaded source packages are in
 	?/tmp/RtmpVGIz3Q/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("rgdal") :
   installation of package ?rgdal? had non-zero exit status

   Installed here are:
gcc-5.5.0-i586-1_slack14.2
gcc-g++-5.5.0-i586-1_slack14.2
gcc-gfortran-5.5.0-i586-1_slack14.2
gcc-gnat-5.5.0-i586-1_slack14.2
gcc-go-5.5.0-i586-1_slack14.2
gcc-java-5.5.0-i586-1_slack14.2
gcc-objc-5.5.0-i586-1_slack14.2
gccmakedep-1.0.3-noarch-1

and

gdal-2.3.0-i586-1_SBo

   What's C++11?

Rich



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Aug 10 19:19:45 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 10 Aug 2018 17:19:45 +0000
Subject: [R] Resolving installed package updates warning
In-Reply-To: <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
 <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
 <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
Message-ID: <AF50F4B7-DA00-4536-9CDA-FF03908F5A7F@llnl.gov>

Rich,

C++11 is a programming language.

Interestingly, someone else asked for help yesterday with exactly the same error message for rgdal. The subject line was

  "Help reinstalling rgdal (Ubuntu 16.04)"

The suggestions were to visit the mailing lists R-sig-geo and/or R-sig-debian.

It's puzzling to me that the output first says
   configure: C++11 support available
and then later says
  /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.

Maybe the C+11 on the system needs to be a newer version...but this level is pretty much over my head.

I wouldn't even look at the other error messages until that one has been solved.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/10/18, 9:53 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Fri, 10 Aug 2018, MacQueen, Don wrote:
    
    > I would start by trying to install rgdal by itself, rather than as part of
    > a "batch" update. As in
    >
    >  Install.packages('rgdal')
    
    Don,
    
       rgdal was supposed to be installed, but you have a valid point.
    
    > My expectation is that you will see a more complete error message specific
    > to rgdal, which presumably will provide a clue or pointer.
    
       Boy howdy! This is interesting:
    
    * installing *source* package ?rgdal? ...
    ** package ?rgdal? successfully unpacked and MD5 sums checked
    configure: R_HOME: /usr/lib/R
    configure: CC: gcc
    configure: CXX: g++
    configure: C++11 support available
    configure: rgdal: 1.3-4
    checking for /usr/bin/svnversion... yes
    configure: svn revision: 766
    checking for gdal-config... /usr/bin/gdal-config
    checking gdal-config usability... yes
    configure: GDAL: 2.3.0
    checking C++11 support for GDAL >= 2.3.0... yes
    checking GDAL version >= 1.11.4... yes
    checking gdal: linking with --libs only... no
    checking gdal: linking with --libs and --dep-libs... no
    In file included from /usr/include/gdal.h:45:0,
                      from gdal_test.cc:1:
    /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
      #    error Must have C++11 or newer.
           ^
    In file included from /usr/include/gdal.h:49:0,
                      from gdal_test.cc:1:
    /usr/include/cpl_minixml.h:202:47: error: expected template-name before '<' token
      class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter>
                                                    ^
    /usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
    /usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before '<' token
    In file included from /usr/include/ogr_api.h:45:0,
                      from /usr/include/gdal.h:50,
                      from gdal_test.cc:1:
    /usr/include/ogr_core.h:79:28: error: expected '}' before end of line
    /usr/include/ogr_core.h:79:28: error: expected declaration before end of line
    In file included from /usr/include/gdal.h:45:0,
                      from gdal_test.cc:1:
    /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
      #    error Must have C++11 or newer.
           ^
    In file included from /usr/include/gdal.h:49:0,
                      from gdal_test.cc:1:
    /usr/include/cpl_minixml.h:202:47: error: expected template-name before '<' token
      class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode, CPLXMLTreeCloserDeleter>
                                                    ^
    /usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
    /usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before '<' token
    In file included from /usr/include/ogr_api.h:45:0,
                      from /usr/include/gdal.h:50,
                      from gdal_test.cc:1:
    /usr/include/ogr_core.h:79:28: error: expected '}' before end of line
    /usr/include/ogr_core.h:79:28: error: expected declaration before end of line
    configure: Install failure: compilation and/or linkage problems.
    configure: error: GDALAllRegister not found in libgdal.
    ERROR: configuration failed for package ?rgdal?
    * removing ?/usr/lib/R/library/rgdal?
    * restoring previous ?/usr/lib/R/library/rgdal?
    
    The downloaded source packages are in
     	?/tmp/RtmpVGIz3Q/downloaded_packages?
    Updating HTML index of packages in '.Library'
    Making 'packages.html' ... done
    Warning message:
    In install.packages("rgdal") :
       installation of package ?rgdal? had non-zero exit status
    
       Installed here are:
    gcc-5.5.0-i586-1_slack14.2
    gcc-g++-5.5.0-i586-1_slack14.2
    gcc-gfortran-5.5.0-i586-1_slack14.2
    gcc-gnat-5.5.0-i586-1_slack14.2
    gcc-go-5.5.0-i586-1_slack14.2
    gcc-java-5.5.0-i586-1_slack14.2
    gcc-objc-5.5.0-i586-1_slack14.2
    gccmakedep-1.0.3-noarch-1
    
    and
    
    gdal-2.3.0-i586-1_SBo
    
       What's C++11?
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 10 19:20:58 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 10 Aug 2018 10:20:58 -0700
Subject: [R] Resolving installed package updates warning
In-Reply-To: <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
 <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
 <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSX7y3c2w8Vmh8s+sqU0Y_gEMw7JP6JeYj2sNruWmAkeg@mail.gmail.com>

  What's C++11?

Google it!

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Aug 10, 2018 at 9:53 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 10 Aug 2018, MacQueen, Don wrote:
>
> I would start by trying to install rgdal by itself, rather than as part of
>> a "batch" update. As in
>>
>>  Install.packages('rgdal')
>>
>
> Don,
>
>   rgdal was supposed to be installed, but you have a valid point.
>
> My expectation is that you will see a more complete error message specific
>> to rgdal, which presumably will provide a clue or pointer.
>>
>
>   Boy howdy! This is interesting:
>
> * installing *source* package ?rgdal? ...
> ** package ?rgdal? successfully unpacked and MD5 sums checked
> configure: R_HOME: /usr/lib/R
> configure: CC: gcc
> configure: CXX: g++
> configure: C++11 support available
> configure: rgdal: 1.3-4
> checking for /usr/bin/svnversion... yes
> configure: svn revision: 766
> checking for gdal-config... /usr/bin/gdal-config
> checking gdal-config usability... yes
> configure: GDAL: 2.3.0
> checking C++11 support for GDAL >= 2.3.0... yes
> checking GDAL version >= 1.11.4... yes
> checking gdal: linking with --libs only... no
> checking gdal: linking with --libs and --dep-libs... no
> In file included from /usr/include/gdal.h:45:0,
>                  from gdal_test.cc:1:
> /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
>  #    error Must have C++11 or newer.
>       ^
> In file included from /usr/include/gdal.h:49:0,
>                  from gdal_test.cc:1:
> /usr/include/cpl_minixml.h:202:47: error: expected template-name before
> '<' token
>  class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode,
> CPLXMLTreeCloserDeleter>
>                                                ^
> /usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
> /usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before
> '<' token
> In file included from /usr/include/ogr_api.h:45:0,
>                  from /usr/include/gdal.h:50,
>                  from gdal_test.cc:1:
> /usr/include/ogr_core.h:79:28: error: expected '}' before end of line
> /usr/include/ogr_core.h:79:28: error: expected declaration before end of
> line
> In file included from /usr/include/gdal.h:45:0,
>                  from gdal_test.cc:1:
> /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
>  #    error Must have C++11 or newer.
>       ^
> In file included from /usr/include/gdal.h:49:0,
>                  from gdal_test.cc:1:
> /usr/include/cpl_minixml.h:202:47: error: expected template-name before
> '<' token
>  class CPLXMLTreeCloser: public std::unique_ptr<CPLXMLNode,
> CPLXMLTreeCloserDeleter>
>                                                ^
> /usr/include/cpl_minixml.h:202:47: error: expected '{' before '<' token
> /usr/include/cpl_minixml.h:202:47: error: expected unqualified-id before
> '<' token
> In file included from /usr/include/ogr_api.h:45:0,
>                  from /usr/include/gdal.h:50,
>                  from gdal_test.cc:1:
> /usr/include/ogr_core.h:79:28: error: expected '}' before end of line
> /usr/include/ogr_core.h:79:28: error: expected declaration before end of
> line
> configure: Install failure: compilation and/or linkage problems.
> configure: error: GDALAllRegister not found in libgdal.
> ERROR: configuration failed for package ?rgdal?
> * removing ?/usr/lib/R/library/rgdal?
> * restoring previous ?/usr/lib/R/library/rgdal?
>
> The downloaded source packages are in
>         ?/tmp/RtmpVGIz3Q/downloaded_packages?
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("rgdal") :
>   installation of package ?rgdal? had non-zero exit status
>
>   Installed here are:
> gcc-5.5.0-i586-1_slack14.2
> gcc-g++-5.5.0-i586-1_slack14.2
> gcc-gfortran-5.5.0-i586-1_slack14.2
> gcc-gnat-5.5.0-i586-1_slack14.2
> gcc-go-5.5.0-i586-1_slack14.2
> gcc-java-5.5.0-i586-1_slack14.2
> gcc-objc-5.5.0-i586-1_slack14.2
> gccmakedep-1.0.3-noarch-1
>
> and
>
> gdal-2.3.0-i586-1_SBo
>
>   What's C++11?
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@herry8 @end|ng |rom comc@@t@net  Fri Aug 10 19:32:33 2018
From: r@herry8 @end|ng |rom comc@@t@net (rsherry8)
Date: Fri, 10 Aug 2018 13:32:33 -0400
Subject: [R] Trying to Generalize a Function in R
In-Reply-To: <e6ac255f-5ffa-6b4d-1943-bd85a5f66e3b@gmail.com>
References: <5B6C760D.5050404@comcast.net>
 <7dabb432-627a-a943-9c5c-f7b12d680b25@gmail.com>
 <5B6CAA92.8050806@comcast.net>
 <8bfc1997-c6ad-1600-f8be-1e28127ecfea@gmail.com> <5B6CBE70.409@comcast.net>
 <e6ac255f-5ffa-6b4d-1943-bd85a5f66e3b@gmail.com>
Message-ID: <5B6DCC31.4080109@comcast.net>

Duncan,

Since you asked, here is an updated version of my function.

# This method gets the Data.
getReturns1 <- function(symbol, norm = FALSE)
{
     library(quantmod)

     series = getSymbols(symbol, src = "yahoo", from = start, to = end, 
auto.assign = FALSE)
     length <- nrow(  series )
     close <- as.numeric(series[, paste0(symbol, ".Close")])
     cat( "length = ", length(close ), "\n" )
     diff = seq(1:(length-1))
     for( i in 1:length-1 )
         diff[i] = ((close[i+1] - close[i]) ) / close[i]
     u = mean(diff)
     stdDev = sd(diff)
     cat( "stdDev = ", stdDev, "\n" )

     if ( norm == TRUE ) {
         diff = (diff - u)
         diff = diff / stdDev
     }
     cat( "length = ", length(diff ), "\n" )

     return (diff)
}

I believe it is now working correctly. I did add the following statement:
         diff = seq(1:(length-1))
I thank you for your help. I also think the version of the function
posted by Joshua Ulrich is better. I found his post to be very educational.

Bob

On 8/9/2018 6:48 PM, Duncan Murdoch wrote:
> On 09/08/2018 6:21 PM, rsherry8 wrote:
>> Duncan,
>>
>> You are right and when I run with auto.assign=FALSE it works.
>
> You should post your working version of the function to the mailing list.
>
> Duncan Murdoch
>
>>
>> Thank you very much,
>> Bob
>>
>> On 8/9/2018 6:11 PM, Duncan Murdoch wrote:
>>> On 09/08/2018 4:56 PM, rsherry8 wrote:
>>>> Duncan,
>>>>
>>>> Thanks for the response. I tired the following:
>>>>        >  series <- getSymbols("AVB", src = "yahoo", from = start, to
>>>> = end)
>>>
>>> You missed the auto.assign=FALSE argument.
>>>
>>>>        > series[0]
>>>>            character(0)
>>>>        > nrow( series )
>>>>            NULL
>>>> nrow( series ) returned NULL. I do not understand why. I am thinking
>>>> that there should be an R command to
>>>> tell me about the structure of series. I tried: typeof( series ) and
>>>> got: "character". Is there a better command for
>>>> me to use other than typeof?
>>>
>>> Won't help here, but often str() is more informative than typeof().
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> I also tried this command:
>>>>        c1 <- as.numeric(series[, paste0(symbol, ".Close")])
>>>> where symbol held the value "AVB" and I got:
>>>>        Error in series[, paste0(symbol, ".Close")] :
>>>>        incorrect number of dimensions
>>>>
>>>> Please help.
>>>> Thanks,
>>>> Bob
>>>>
>>>> On 8/9/2018 3:51 PM, Duncan Murdoch wrote:
>>>>> On 09/08/2018 1:12 PM, rsherry8 wrote:
>>>>>>
>>>>>> I wrote the following function:
>>>>>>
>>>>>> # This method gets historical stock data for the stock Avalon Bay
>>>>>> whose
>>>>>> symbol is AVB.
>>>>>> getReturns <- function(norm = FALSE)
>>>>>> {
>>>>>>         library(quantmod)
>>>>>>
>>>>>>         getSymbols("AVB", src = "yahoo", from = start, to = end)
>>>>>>         length = length(  AVB$AVB.Close )
>>>>>>         close = as.numeric( AVB$AVB.Close )
>>>>>>         cat( "length = ", length(close ), "\n" )
>>>>>>         for( i in 1:length-1 )
>>>>>>             diff[i] = ((close[i+1] - close[i]) ) / close[i]
>>>>>>         u = mean(diff)
>>>>>>         stdDev = sd(diff)
>>>>>>         cat( "stdDev = ", stdDev, "\n" )
>>>>>>
>>>>>>         if ( norm == TRUE ) {
>>>>>>             diff = (diff - u)
>>>>>>             diff = diff / stdDev
>>>>>>         }
>>>>>>         return (diff)
>>>>>> }
>>>>>>
>>>>>> I would like to generalize it to work for any stock by passing in 
>>>>>> the
>>>>>> stock symbol. So the header for the
>>>>>> function would be:
>>>>>>
>>>>>> getReturns <- function(symbol, norm = FALSE)
>>>>>
>>>>> The quantmod function getSymbols has arguments auto.assign which
>>>>> defaults to TRUE.  Set it to FALSE, and then keep the result of the
>>>>> call, instead of assuming that a variable named AVB has been created.
>>>>>
>>>>> That is,
>>>>>
>>>>>          series <- getSymbols(symbol, src = "yahoo", from = start, 
>>>>> to =
>>>>> end, auto.assign = FALSE)
>>>>>          length <- nrow(  series )
>>>>>
>>>>> It will still name the columns according to the symbol, so you would
>>>>> also need
>>>>>
>>>>>         close <- as.numeric(series[, paste0(symbol, ".Close")])
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>>
>>>>>> Now how do I update this line:
>>>>>>         length = length(  AVB$AVB.Close )
>>>>>> This statement will not work:
>>>>>>         length = length(  symbol$AVB.Close )
>>>>>> because the name that holds the closing price is a function of the
>>>>>> stock
>>>>>> symbol.
>>>>>>
>>>>>> Thanks,
>>>>>> Bob
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>>
>>
>
>



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Aug 10 20:08:57 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 10 Aug 2018 11:08:57 -0700 (PDT)
Subject: [R] Resolving installed package updates warning
In-Reply-To: <AF50F4B7-DA00-4536-9CDA-FF03908F5A7F@llnl.gov>
References: <alpine.LNX.2.20.1808100646280.6491@salmo.appl-ecosys.com>
 <0D2CD5C1-CB69-44F3-9951-2DA436E78C5A@llnl.gov>
 <alpine.LNX.2.20.1808100949130.14707@salmo.appl-ecosys.com>
 <AF50F4B7-DA00-4536-9CDA-FF03908F5A7F@llnl.gov>
Message-ID: <alpine.LNX.2.20.1808101104590.14707@salmo.appl-ecosys.com>

On Fri, 10 Aug 2018, MacQueen, Don wrote:

> C++11 is a programming language.

Don,

   That's what I assumed; a version of c++, which is installed here by
default. Perhaps not that verision, but ...

>   configure: C++11 support available
> and then later says
>  /usr/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.

>    configure: CXX: g++
>    configure: C++11 support available
>    checking C++11 support for GDAL >= 2.3.0... yes
>    checking GDAL version >= 1.11.4... yes

   Since the configuration finds C++11 support available and a sufficiently
current version of gdal the warning/errors make no sense to me.

   FWIW, there's no issue compiling/using gdal on slackware; I've done so for
many years.

Rich



From rm@h@rp @end|ng |rom me@com  Fri Aug 10 22:08:24 2018
From: rm@h@rp @end|ng |rom me@com (R. Mark Sharp)
Date: Fri, 10 Aug 2018 16:08:24 -0400
Subject: [R] help
In-Reply-To: <CAON01EbSs=z6Gd6vPaa9aQReiJTwi6rqHyKBFJ71Wo+bT=yh+g@mail.gmail.com>
References: <CAON01EbSs=z6Gd6vPaa9aQReiJTwi6rqHyKBFJ71Wo+bT=yh+g@mail.gmail.com>
Message-ID: <144921FD-954D-4B92-BF6C-261DECB2535A@me.com>

Marco,

The error message indicates that nlon*nlat is 420 and that 1378620/420 has a remainder. For the matrix to form, all rows have to be complete. 

I am guessing you have at least one value incorrect among nlon, nlat, t or the length of fulldatav.

Mark
R. Mark Sharp, Ph.D.
Data Scientist and Biomedical Statistical Consultant
7526 Meadow Green St.
San Antonio, TX 78251
mobile: 210-218-2868
rmsharp at me.com











> On Aug 10, 2018, at 10:00 AM, Marco Antonio P?rez <marko.luna13 at gmail.com> wrote:
> 
> I am trying to write a function to make a matrix of precipitation with
> this secuencie;
> ######## PRIMER PERIODO
> cordex1 <-
> nc_open("pr_CAM-44i_ICHEC-EC-EARTH_rcp45_r12i1p1_SMHI-RCA4_v1_mon_200601-201012.nc")
> fullmon1<-ncvar_get(cordex1,"pr")
> lat<-ncvar_get(cordex1,"lat", start=c(35.5),count=c(20))
> lon <-ncvar_get(cordex1,"lon", start=c(125),count=c(21.5))
> t <- ncvar_get(cordex1,"time")
> nlon <- dim(lon)
> nlat <- dim(lat)
> nt <- dim(t)
> fulldatav <- as.vector(fullmon1)
> fulldata <- matrix(fulldatav, nrow=nlon*nlat, ncol=nt)
> lonlat <- expand.grid(lon,lat)
> df_cordex1<- data.frame(lonlat,fulldata)
> 
> but with the expresion  fulldata <- matrix(fulldatav, nrow=nlon*nlat,
> ncol=nt) this error appears
> Warning message:
> In matrix(fulldatav, nrow = nlon * nlat, ncol = nt) :
>  data length [1378620] is not a sub-multiple or multiple of the number of
> rows [420]
> 
> Somebody help me!!!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @h|v|pmp82 @end|ng |rom gm@||@com  Sat Aug 11 17:55:41 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Sat, 11 Aug 2018 21:25:41 +0530
Subject: [R] Assistance on Installing Rattle
Message-ID: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>

Hi,

Need assistance on installing Rattle.

I have followed the instructions on https://rattle.togaware.com/
but still facing error installing the package.
ERROR: dependency 'RGtk2' is not available for package 'rattle'.
Have tried installing RGt2 from multiple sources and its still failing.

One of the suggestion on stack overflow was to downgrade the R version here
:
https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
Request assistance.

Regards, Shivi

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Sat Aug 11 18:08:49 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 11 Aug 2018 19:08:49 +0300
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
Message-ID: <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>

Hi Shivi,
I have no experience with the rattle package but I just installed it with
no problem.
I am using a Windows 10 machine with R version 3.4.2.

I suggest you provide additional information so that others may have ideas.
e.g. your operating system version and output from sessionInfo() (in R)

Best,
Eric


On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Hi,
>
> Need assistance on installing Rattle.
>
> I have followed the instructions on https://rattle.togaware.com/
> but still facing error installing the package.
> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
> Have tried installing RGt2 from multiple sources and its still failing.
>
> One of the suggestion on stack overflow was to downgrade the R version here
> :
> https://stackoverflow.com/questions/24913643/downgrade-
> r-version-no-issues-with-bioconductor-installation
> Request assistance.
>
> Regards, Shivi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From |@r|dcher @end|ng |rom gm@||@com  Sat Aug 11 10:47:54 2018
From: |@r|dcher @end|ng |rom gm@||@com (Farid Ch)
Date: Sat, 11 Aug 2018 08:47:54 +0000
Subject: [R] source script file that contains Unicode non-English characters
Message-ID: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>

Hi all,

Please check the attached file.

Thanks
Farid




From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 11 23:12:43 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 12 Aug 2018 09:12:43 +1200
Subject: [R] Mysterious seg fault.
Message-ID: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>


I am getting a seg fault from a package that I am working on, and I am 
totally flummoxed by it.  The fault presumably arises from dynamically
loaded Fortran code, but I'm damned if I can see where the error lies.

In an effort to diagnose the problem I created a "non-package" version 
of the code.  That is, I copied all the *.R files and *.f file into a
new directory.  In that directory I created a *.so file using
R CMD SHLIB.

In the R code I removed all the "PACKAGE=" lines from the calls to
.Fortran() and put in appropriate dyn.load() calls.

I then started R in this new "clean" directory and sourced all of the
*.R files.

I then issued the command that produces the seg fault when run under the 
aegis of the package.  The command ran without a murmur of complaint.
WTF?

Can anyone suggest a reason why a seg fault might arise when the code is 
run in the context of a package, but not when it is run in "standalone 
mode"?

I have checked and rechecked my init.c file --- which is the only thing 
that I can think of that might create a difference --- and cannot find 
any discrepancy between the declarations in the init.c file and the 
Fortran code.

The package is a bit complicated, so giving more detail would be 
cumbersome.  Also I have no idea what aspects of detail would be 
relevant.  If anyone would like more info, feel free to ask.

I would really appreciate it if someone could give me some suggestions
before I go *completely* mad!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From gor@n@bro@trom @end|ng |rom umu@@e  Sat Aug 11 23:52:01 2018
From: gor@n@bro@trom @end|ng |rom umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Sat, 11 Aug 2018 23:52:01 +0200
Subject: [R] Mysterious seg fault.
In-Reply-To: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
Message-ID: <06ccac94-300b-7497-3b61-2e898001c62b@umu.se>

Rolf,

have you tried to run R with a debugger, as in

$ R -d gdb

the gnu debugger?

G,

On 2018-08-11 23:12, Rolf Turner wrote:
> 
> I am getting a seg fault from a package that I am working on, and I am 
> totally flummoxed by it.? The fault presumably arises from dynamically
> loaded Fortran code, but I'm damned if I can see where the error lies.
> 
> In an effort to diagnose the problem I created a "non-package" version 
> of the code.? That is, I copied all the *.R files and *.f file into a
> new directory.? In that directory I created a *.so file using
> R CMD SHLIB.
> 
> In the R code I removed all the "PACKAGE=" lines from the calls to
> .Fortran() and put in appropriate dyn.load() calls.
> 
> I then started R in this new "clean" directory and sourced all of the
> *.R files.
> 
> I then issued the command that produces the seg fault when run under the 
> aegis of the package.? The command ran without a murmur of complaint.
> WTF?
> 
> Can anyone suggest a reason why a seg fault might arise when the code is 
> run in the context of a package, but not when it is run in "standalone 
> mode"?
> 
> I have checked and rechecked my init.c file --- which is the only thing 
> that I can think of that might create a difference --- and cannot find 
> any discrepancy between the declarations in the init.c file and the 
> Fortran code.
> 
> The package is a bit complicated, so giving more detail would be 
> cumbersome.? Also I have no idea what aspects of detail would be 
> relevant.? If anyone would like more info, feel free to ask.
> 
> I would really appreciate it if someone could give me some suggestions
> before I go *completely* mad!
> 
> cheers,
> 
> Rolf Turner
>



From drj|m|emon @end|ng |rom gm@||@com  Sun Aug 12 01:51:43 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 12 Aug 2018 09:51:43 +1000
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
Message-ID: <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>

Hi Farid,
Whatever you attached has not gotten through.

Jim

On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
> Hi all,
>
> Please check the attached file.
>
> Thanks
> Farid
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From peter@|@ng|e|der @end|ng |rom gm@||@com  Sun Aug 12 04:13:38 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Sat, 11 Aug 2018 19:13:38 -0700
Subject: [R] Mysterious seg fault.
In-Reply-To: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
Message-ID: <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>

Segfaults are not always repeatable. You may have an undefined pointer that
sometime points into unreachable or unallocated memory, causing a segfault,
and sometimes may point into valid memory, without causing a segfault.

You may want to read
https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Checking-memory-access
for tips on how to diagnose such problems.

HTH,

Peter

On Sat, Aug 11, 2018 at 2:13 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> I am getting a seg fault from a package that I am working on, and I am
> totally flummoxed by it.  The fault presumably arises from dynamically
> loaded Fortran code, but I'm damned if I can see where the error lies.
>
> In an effort to diagnose the problem I created a "non-package" version
> of the code.  That is, I copied all the *.R files and *.f file into a
> new directory.  In that directory I created a *.so file using
> R CMD SHLIB.
>
> In the R code I removed all the "PACKAGE=" lines from the calls to
> .Fortran() and put in appropriate dyn.load() calls.
>
> I then started R in this new "clean" directory and sourced all of the
> *.R files.
>
> I then issued the command that produces the seg fault when run under the
> aegis of the package.  The command ran without a murmur of complaint.
> WTF?
>
> Can anyone suggest a reason why a seg fault might arise when the code is
> run in the context of a package, but not when it is run in "standalone
> mode"?
>
> I have checked and rechecked my init.c file --- which is the only thing
> that I can think of that might create a difference --- and cannot find
> any discrepancy between the declarations in the init.c file and the
> Fortran code.
>
> The package is a bit complicated, so giving more detail would be
> cumbersome.  Also I have no idea what aspects of detail would be
> relevant.  If anyone would like more info, feel free to ask.
>
> I would really appreciate it if someone could give me some suggestions
> before I go *completely* mad!
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug 12 04:54:52 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 11 Aug 2018 19:54:52 -0700
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
Message-ID: <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>

... and read the Posting Guide... only a few file types will ever make it through the mailing list so repeatedly sending files not among those few types would just be frustrating for everyone.

On August 11, 2018 4:51:43 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Farid,
>Whatever you attached has not gotten through.
>
>Jim
>
>On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
>> Hi all,
>>
>> Please check the attached file.
>>
>> Thanks
>> Farid
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From er|cjberger @end|ng |rom gm@||@com  Sun Aug 12 07:42:41 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 12 Aug 2018 08:42:41 +0300
Subject: [R] Mysterious seg fault.
In-Reply-To: <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
Message-ID: <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>

Hi Rolf,
When faced with such a situation I take the following approach which often
helps.
Use the same setup that caused the seg fault (you need a reproducible
problem.)
Start your R session using valgrind. e.g. in linux I do:

$ valgrind R

Assuming that a seg fault still occurs then valgrind should provide info as
to where.

HTH,
Eric


On Sun, Aug 12, 2018 at 5:13 AM, Peter Langfelder <
peter.langfelder at gmail.com> wrote:

> Segfaults are not always repeatable. You may have an undefined pointer that
> sometime points into unreachable or unallocated memory, causing a segfault,
> and sometimes may point into valid memory, without causing a segfault.
>
> You may want to read
> https://cran.r-project.org/doc/manuals/r-release/R-exts.
> html#Checking-memory-access
> for tips on how to diagnose such problems.
>
> HTH,
>
> Peter
>
> On Sat, Aug 11, 2018 at 2:13 PM Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
>
> >
> > I am getting a seg fault from a package that I am working on, and I am
> > totally flummoxed by it.  The fault presumably arises from dynamically
> > loaded Fortran code, but I'm damned if I can see where the error lies.
> >
> > In an effort to diagnose the problem I created a "non-package" version
> > of the code.  That is, I copied all the *.R files and *.f file into a
> > new directory.  In that directory I created a *.so file using
> > R CMD SHLIB.
> >
> > In the R code I removed all the "PACKAGE=" lines from the calls to
> > .Fortran() and put in appropriate dyn.load() calls.
> >
> > I then started R in this new "clean" directory and sourced all of the
> > *.R files.
> >
> > I then issued the command that produces the seg fault when run under the
> > aegis of the package.  The command ran without a murmur of complaint.
> > WTF?
> >
> > Can anyone suggest a reason why a seg fault might arise when the code is
> > run in the context of a package, but not when it is run in "standalone
> > mode"?
> >
> > I have checked and rechecked my init.c file --- which is the only thing
> > that I can think of that might create a difference --- and cannot find
> > any discrepancy between the declarations in the init.c file and the
> > Fortran code.
> >
> > The package is a bit complicated, so giving more detail would be
> > cumbersome.  Also I have no idea what aspects of detail would be
> > relevant.  If anyone would like more info, feel free to ask.
> >
> > I would really appreciate it if someone could give me some suggestions
> > before I go *completely* mad!
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug 12 08:32:09 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 12 Aug 2018 18:32:09 +1200
Subject: [R] Mysterious seg fault.
In-Reply-To: <06ccac94-300b-7497-3b61-2e898001c62b@umu.se>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <06ccac94-300b-7497-3b61-2e898001c62b@umu.se>
Message-ID: <f66fd810-8066-f6dd-6bf7-5ae89ea32ecd@auckland.ac.nz>

On 12/08/18 09:52, G?ran Brostr?m wrote:
> Rolf,
> 
> have you tried to run R with a debugger, as in
> 
> $ R -d gdb
> 
> the gnu debugger?


No, I haven't.  Did not know about the gnu debugger.  I shall 
investigate.  Thanks

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From |@r|dcher @end|ng |rom gm@||@com  Sun Aug 12 09:09:22 2018
From: |@r|dcher @end|ng |rom gm@||@com (Faridedin Cheraghi)
Date: Sun, 12 Aug 2018 11:39:22 +0430
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
Message-ID: <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>

It was actually a .rmd file so you can get the coloring of the bug report
in your text editor. I changed the format to .txt.

-Farid

On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> ... and read the Posting Guide... only a few file types will ever make it
> through the mailing list so repeatedly sending files not among those few
> types would just be frustrating for everyone.
>
> On August 11, 2018 4:51:43 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> >Hi Farid,
> >Whatever you attached has not gotten through.
> >
> >Jim
> >
> >On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
> >> Hi all,
> >>
> >> Please check the attached file.
> >>
> >> Thanks
> >> Farid
> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: bug-source-unicode.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180812/db68446e/attachment-0002.txt>

From @h|v|pmp82 @end|ng |rom gm@||@com  Sun Aug 12 12:49:18 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Sun, 12 Aug 2018 16:19:18 +0530
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
Message-ID: <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>

Hi Eric,

Thank you for the reply. I am adding the session details below, hope it
helps:
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default
locale:
[1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
LC_MONETARY=English_India.1252
[4] LC_NUMERIC=C                   LC_TIME=English_India.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Thanks.

On Sat, Aug 11, 2018 at 9:38 PM Eric Berger <ericjberger at gmail.com> wrote:

> Hi Shivi,
> I have no experience with the rattle package but I just installed it with
> no problem.
> I am using a Windows 10 machine with R version 3.4.2.
>
> I suggest you provide additional information so that others may have ideas.
> e.g. your operating system version and output from sessionInfo() (in R)
>
> Best,
> Eric
>
>
> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
>
>> Hi,
>>
>> Need assistance on installing Rattle.
>>
>> I have followed the instructions on https://rattle.togaware.com/
>> but still facing error installing the package.
>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
>> Have tried installing RGt2 from multiple sources and its still failing.
>>
>> One of the suggestion on stack overflow was to downgrade the R version
>> here
>> :
>>
>> https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>> Request assistance.
>>
>> Regards, Shivi
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sun Aug 12 15:50:48 2018
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 12 Aug 2018 14:50:48 +0100
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
Message-ID: <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>

Dear Shivi

What error message do you get when you try to install RGtk2?

Michael

On 12/08/2018 11:49, Shivi Bhatia wrote:
> Hi Eric,
> 
> Thank you for the reply. I am adding the session details below, hope it
> helps:
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> Matrix products: default
> locale:
> [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
> LC_MONETARY=English_India.1252
> [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> Thanks.
> 
> On Sat, Aug 11, 2018 at 9:38 PM Eric Berger <ericjberger at gmail.com> wrote:
> 
>> Hi Shivi,
>> I have no experience with the rattle package but I just installed it with
>> no problem.
>> I am using a Windows 10 machine with R version 3.4.2.
>>
>> I suggest you provide additional information so that others may have ideas.
>> e.g. your operating system version and output from sessionInfo() (in R)
>>
>> Best,
>> Eric
>>
>>
>> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia <shivipmp82 at gmail.com>
>> wrote:
>>
>>> Hi,
>>>
>>> Need assistance on installing Rattle.
>>>
>>> I have followed the instructions on https://rattle.togaware.com/
>>> but still facing error installing the package.
>>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
>>> Have tried installing RGt2 from multiple sources and its still failing.
>>>
>>> One of the suggestion on stack overflow was to downgrade the R version
>>> here
>>> :
>>>
>>> https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>>> Request assistance.
>>>
>>> Regards, Shivi
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug 12 17:30:47 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 12 Aug 2018 11:30:47 -0400
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
Message-ID: <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>

On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
> It was actually a .rmd file so you can get the coloring of the bug report
> in your text editor. I changed the format to .txt.

When I run your script on a Mac (in a UTF-8 locale), all lines work as 
expected.  I'm guessing you are working on Windows, in a non-UTF-8 locale?

Posting sessionInfo() would be helpful.

Duncan Murdoch

> 
> -Farid
> 
> On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> ... and read the Posting Guide... only a few file types will ever make it
>> through the mailing list so repeatedly sending files not among those few
>> types would just be frustrating for everyone.
>>
>> On August 11, 2018 4:51:43 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> Hi Farid,
>>> Whatever you attached has not gotten through.
>>>
>>> Jim
>>>
>>> On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
>>>> Hi all,
>>>>
>>>> Please check the attached file.
>>>>
>>>> Thanks
>>>> Farid
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From |@r|dcher @end|ng |rom gm@||@com  Sun Aug 12 17:48:20 2018
From: |@r|dcher @end|ng |rom gm@||@com (Faridedin Cheraghi)
Date: Sun, 12 Aug 2018 20:18:20 +0430
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
Message-ID: <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>

that's right and I don't want to change my locale. my sessionInfo() :

R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

thanks

On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
>
>> It was actually a .rmd file so you can get the coloring of the bug report
>> in your text editor. I changed the format to .txt.
>>
>
> When I run your script on a Mac (in a UTF-8 locale), all lines work as
> expected.  I'm guessing you are working on Windows, in a non-UTF-8 locale?
>
> Posting sessionInfo() would be helpful.
>
> Duncan Murdoch
>
>
>
>> -Farid
>>
>> On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us
>> >
>> wrote:
>>
>> ... and read the Posting Guide... only a few file types will ever make it
>>> through the mailing list so repeatedly sending files not among those few
>>> types would just be frustrating for everyone.
>>>
>>> On August 11, 2018 4:51:43 PM PDT, Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>>
>>>> Hi Farid,
>>>> Whatever you attached has not gotten through.
>>>>
>>>> Jim
>>>>
>>>> On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch <faridcher at gmail.com> wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> Please check the attached file.
>>>>>
>>>>> Thanks
>>>>> Farid
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>>
>>>> http://www.R-project.org/posting-guide.html
>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug 12 18:33:14 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 12 Aug 2018 12:33:14 -0400
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
 <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
Message-ID: <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>

On 12/08/2018 11:48 AM, Faridedin Cheraghi wrote:
> that's right and I don't want to change my locale. my sessionInfo() :

I think it could be another manifestation of a known bug on Windows, 
where strings are converted from UTF-8 to the current locale and back to 
UTF-8, a lossy conversion.  This has been present for many years, and 
requires a lot of internal changes to fix, so I wouldn't hold your 
breath waiting for a fix.

I believe the "right" fix is for R to always convert strings to UTF-8 
internally.  This wasn't possible when the internationalization code was 
added many years ago because not all platforms supported UTF-8.  It 
would be a lot of work now, and since it isn't needed now on the 
platforms most developers use, it's not receiving a lot of attention.

Your workaround

file(script,
      encoding = "UTF-8") %T>%
      source() %>%
      close()   # works fine

is a nice way to avoid this problem.

Duncan Murdoch

> 
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
> 
> thanks
> 
> On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
> 
>         It was actually a .rmd file so you can get the coloring of the
>         bug report
>         in your text editor. I changed the format to .txt.
> 
> 
>     When I run your script on a Mac (in a UTF-8 locale), all lines work
>     as expected.? I'm guessing you are working on Windows, in a
>     non-UTF-8 locale?
> 
>     Posting sessionInfo() would be helpful.
> 
>     Duncan Murdoch
> 
> 
> 
>         -Farid
> 
>         On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller
>         <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>
>         wrote:
> 
>             ... and read the Posting Guide... only a few file types will
>             ever make it
>             through the mailing list so repeatedly sending files not
>             among those few
>             types would just be frustrating for everyone.
> 
>             On August 11, 2018 4:51:43 PM PDT, Jim Lemon
>             <drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>> wrote:
> 
>                 Hi Farid,
>                 Whatever you attached has not gotten through.
> 
>                 Jim
> 
>                 On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch
>                 <faridcher at gmail.com <mailto:faridcher at gmail.com>> wrote:
> 
>                     Hi all,
> 
>                     Please check the attached file.
> 
>                     Thanks
>                     Farid
> 
> 
>                     ______________________________________________
>                     R-help at r-project.org <mailto:R-help at r-project.org>
>                     mailing list -- To UNSUBSCRIBE and more, see
>                     https://stat.ethz.ch/mailman/listinfo/r-help
>                     <https://stat.ethz.ch/mailman/listinfo/r-help>
>                     PLEASE do read the posting guide
> 
>                 http://www.R-project.org/posting-guide.html
>                 <http://www.R-project.org/posting-guide.html>
> 
>                     and provide commented, minimal, self-contained,
>                     reproducible code.
> 
> 
>                 ______________________________________________
>                 R-help at r-project.org <mailto:R-help at r-project.org>
>                 mailing list -- To UNSUBSCRIBE and more, see
>                 https://stat.ethz.ch/mailman/listinfo/r-help
>                 <https://stat.ethz.ch/mailman/listinfo/r-help>
>                 PLEASE do read the posting guide
>                 http://www.R-project.org/posting-guide.html
>                 <http://www.R-project.org/posting-guide.html>
>                 and provide commented, minimal, self-contained,
>                 reproducible code.
> 
> 
>             --
>             Sent from my phone. Please excuse my brevity.
> 
> 
> 
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
> 
> 
>



From peter@c@rbonetto @end|ng |rom gm@||@com  Sun Aug 12 16:49:10 2018
From: peter@c@rbonetto @end|ng |rom gm@||@com (Peter Carbonetto)
Date: Sun, 12 Aug 2018 09:49:10 -0500
Subject: [R] Fast matrix multiplication
Message-ID: <CAPvCojL19g6mQy7YrF8iN4h5pcoXwHxzBDuZ3aWKGZcBaFGGGw@mail.gmail.com>

Hi Ravi,

Like Ista, I have also had success in using R with OpenBLAS on our Linux
compute cluster.

This will involve installing R from source. If you'd like, I can send you
the configure settings I used, as well as the environment settings used to
control OpenBLAS multithreading. The CRAN site also has some good
documentation of this.

Note that I had issues using the latest version of OpenBLAS (0.3.x) with R
3.5.1. I'm not sure if you would have the same issues as me, but to be safe
I would suggest using OpenBLAS 0.2.x instead.

Peter

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug 13 00:32:04 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 13 Aug 2018 10:32:04 +1200
Subject: [R] Mysterious seg fault.
In-Reply-To: <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
Message-ID: <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>


On 12/08/18 17:42, Eric Berger wrote:

> Hi Rolf,
> When faced with such a situation I take the following approach which 
> often helps.
> Use the same setup that caused the seg fault (you need a reproducible 
> problem.)
> Start your R session using valgrind. e.g. in linux I do:
> 
> $ valgrind R
> 
> Assuming that a seg fault still occurs then valgrind should provide info 
> as to where.
> 
> HTH

Well, it probably *would* help if I weren't such a thicko.

The story so far:  I have managed to install valgrind (downloaded a 
tarball and installed from source).  Seemed to go OK, but:

* when I type "valgrind" I get "command not found"
* however valgrind is in /usr/local/bin (I did "configure" with
   prefix="/usr/local" so this is as it should be)
* /usr/local/bin/valgrind is executable
* /usr/local/bin is in my path

So how in god's name can the command not be found?  And why do these 
things always happen to *me*???

I can work around this problem by giving the full path name, however.

So I did:

/usr/local/bin/valgrind R

and got a lot of (mysterious to me) output:

> /usr/local/bin/valgrind R
> ==18051== Memcheck, a memory error detector
> ==18051== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
> ==18051== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
> ==18051== Command: /usr/local/bin/R
> ==18051== 
> ==18051== Invalid free() / delete / delete[] / realloc()
> ==18051==    at 0x4C2ECF0: free (vg_replace_malloc.c:530)
> ==18051==    by 0x45E280: ??? (in /bin/bash)
> ==18051==    by 0x45E42F: run_unwind_frame (in /bin/bash)
> ==18051==    by 0x47B714: parse_and_execute (in /bin/bash)
> ==18051==    by 0x47B102: ??? (in /bin/bash)
> ==18051==    by 0x47B35C: source_file (in /bin/bash)
> ==18051==    by 0x4849C7: source_builtin (in /bin/bash)
> ==18051==    by 0x43378D: ??? (in /bin/bash)
> ==18051==    by 0x43592C: ??? (in /bin/bash)
> ==18051==    by 0x4369C7: execute_command_internal (in /bin/bash)
> ==18051==    by 0x43851D: execute_command (in /bin/bash)
> ==18051==    by 0x42139D: reader_loop (in /bin/bash)
> ==18051==  Address 0x4241008 is in the brk data segment 0x4228000-0x4246fff
> ==18051== 
> ==18051== Invalid free() / delete / delete[] / realloc()
> ==18051==    at 0x4C2ECF0: free (vg_replace_malloc.c:530)
> ==18051==    by 0x45E280: ??? (in /bin/bash)
> ==18051==    by 0x45E42F: run_unwind_frame (in /bin/bash)
> ==18051==    by 0x4849D3: source_builtin (in /bin/bash)
> ==18051==    by 0x43378D: ??? (in /bin/bash)
> ==18051==    by 0x43592C: ??? (in /bin/bash)
> ==18051==    by 0x4369C7: execute_command_internal (in /bin/bash)
> ==18051==    by 0x43851D: execute_command (in /bin/bash)
> ==18051==    by 0x42139D: reader_loop (in /bin/bash)
> ==18051==    by 0x41FDB0: main (in /bin/bash)
> ==18051==  Address 0x4240708 is in the brk data segment 0x4228000-0x4246fff
> ==18051== 
> 

Not at all clear to me what to make of this.  Does it indicate problems 
or memory leaks in my installation of R?  Anyhow, things then proceed in 
an expected manner:

> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>   Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> Loading required package: misc
> [Previously saved workspace restored]

I then loaded the problematic package and issued the problematic command:

> > library(hmm.discnp)
> hmm.discnp 2.0-9
> 
>      This package has changed SUBSTANTIALLY from its 
>      previous release.  Read the documentation 
>      carefully.  Note in particular that the meaning of 
>      the argument "nsim" of the function rhmm() has 
>      changed, and a new argument "ylengths" now plays 
>      essentially the role previously played by 
>      "nsim".
> 
> > xxx <- get.hgl(p3,2,yyy)
> 
>  *** caught segfault ***
> address (nil), cause 'unknown'
> Segmentation fault (core dumped)

Nothing informative.  Is there something else I should be doing?

Sorry for being a nuisance, but I am at a loss.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From drj|m|emon @end|ng |rom gm@||@com  Mon Aug 13 01:55:28 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 13 Aug 2018 09:55:28 +1000
Subject: [R] cumulate of snow cumulates from daily values of different
 automatic stations for some time intervals
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F54CCBF0B@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F54CCBF0B@ESINO.regionemarche.intra>
Message-ID: <CA+8X3fUpyN9X6qZwjxdxaokAfo1QjtNZWxpSOOO3nDanKpVJ7g@mail.gmail.com>

Hi Stefano,
This was such a stinker of a problem that I just had to crack it:

# create some data the lazy man's way
year_dates<-c(paste(2000,rep("01",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("02",29),formatC(1:29,width=2,flag=0),sep="-"),
 paste(2000,rep("03",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("04",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("05",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("06",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("07",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("08",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("09",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("10",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("11",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("12",31),formatC(1:31,width=2,flag=0),sep="-"))

df1<-data.frame(station_code=rep(217,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df2<-data.frame(station_code=rep(218,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df3<-data.frame(station_code=rep(219,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df4<-data.frame(station_code=rep(220,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df5<-data.frame(station_code=rep(221,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df6<-data.frame(station_code=rep(222,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df7<-data.frame(station_code=rep(223,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df8<-data.frame(station_code=rep(224,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df9<-data.frame(station_code=rep(225,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df10<-data.frame(station_code=rep(226,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))

snow_list<-list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

for(station in 1:10)
 snow_list[[station]]$doy<-1:length(snow_list[[station]]$date_POSIX)

select_days<-c(1:12,83:88)

cum_snow<-function(x,which_days) {
 return(list(x$station_code[1],sum(x$snow[which_days])))
}

cum_list<-lapply(lapply(snow_list,cum_snow,select_days),unlist)

snow_totals<-data.frame(station_code=NULL,snow_cumulate=NULL)

for(station in 1:10) snow_totals<-rbind(snow_totals,cum_list[[station]])

names(snow_totals)<-c("station_code","snow_cumulate")

Jim


On Sat, Aug 11, 2018 at 2:48 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-list users,
> I have 10 data frames (called df1, df2, ... df10), where each of them contains snow data from an automatic meteorological station (obviously each station has a different station code).
> Here is an example of df1:
>
> station_code date_factor date_POSIX snow
> 217 1999-12-15 1999-12-15  0
> 217 1999-12-16 1999-12-16  0
> 217 1999-12-17 1999-12-17 38
> 217 1999-12-18 1999-12-18 31
> 217 1999-12-19 1999-12-19 21
> 217 1999-12-20 1999-12-20 12
> 217 1999-12-21 1999-12-21 42
> 217 1999-12-22 1999-12-22 61
> 217 1999-12-23 1999-12-23 57
> 217 1999-12-24 1999-12-24 48
> ...
>
> where
>> sapply(df1, class)
> $station_code
> [1] "numeric"
>
> $date_factor
> [1] "factor"
>
> $date_POSIX
> [1] "POSIXct" "POSIXt"
>
> $snow
> [1] "integer"
>
> Given a series of max three intervals (example with two intervals: from 1st to 12th of January 2000 and from 23rd to 28th of March 2000), I need to evaluate for each station the total snow cumulate for all the intervals selected, and finally create a data frame where for each line there is the station code and the snow cumulate. It should be like
>
> station_code total_snow_cumulate
> 217 125
> 218 80
> ...
>
> Could somebody show me a direction for an efficient solution?
>
> Thank you for your attention and your help
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug 13 02:03:58 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 12 Aug 2018 20:03:58 -0400
Subject: [R] Mysterious seg fault.
In-Reply-To: <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
Message-ID: <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>

On 12/08/2018 6:32 PM, Rolf Turner wrote:
> 
> On 12/08/18 17:42, Eric Berger wrote:
> 
>> Hi Rolf,
>> When faced with such a situation I take the following approach which
>> often helps.
>> Use the same setup that caused the seg fault (you need a reproducible
>> problem.)
>> Start your R session using valgrind. e.g. in linux I do:
>>
>> $ valgrind R
>>
>> Assuming that a seg fault still occurs then valgrind should provide info
>> as to where.
>>
>> HTH
> 
> Well, it probably *would* help if I weren't such a thicko.
> 
> The story so far:  I have managed to install valgrind (downloaded a
> tarball and installed from source).  Seemed to go OK, but:
> 
> * when I type "valgrind" I get "command not found"
> * however valgrind is in /usr/local/bin (I did "configure" with
>     prefix="/usr/local" so this is as it should be)
> * /usr/local/bin/valgrind is executable
> * /usr/local/bin is in my path
> 
> So how in god's name can the command not be found?  And why do these
> things always happen to *me*???
> 
> I can work around this problem by giving the full path name, however.
> 
> So I did:
> 
> /usr/local/bin/valgrind R

I believe on your system R is a script, so you can't run valgrind this 
way.  It's just debugging bash, not R.  You need to use

R -d valgrind

(though with your weird path problems, you might need a fully qualified 
/usr/local/bin/valgrind there).

You run gdb the same way:

R -d gdb

and then give the command "r" to gdb to start R.  It will give a report 
when you get the segfault.  I don't know which report will be more 
informative.

Duncan Murdoch

> 
> and got a lot of (mysterious to me) output:
> 
>> /usr/local/bin/valgrind R
>> ==18051== Memcheck, a memory error detector
>> ==18051== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
>> ==18051== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
>> ==18051== Command: /usr/local/bin/R
>> ==18051==
>> ==18051== Invalid free() / delete / delete[] / realloc()
>> ==18051==    at 0x4C2ECF0: free (vg_replace_malloc.c:530)
>> ==18051==    by 0x45E280: ??? (in /bin/bash)
>> ==18051==    by 0x45E42F: run_unwind_frame (in /bin/bash)
>> ==18051==    by 0x47B714: parse_and_execute (in /bin/bash)
>> ==18051==    by 0x47B102: ??? (in /bin/bash)
>> ==18051==    by 0x47B35C: source_file (in /bin/bash)
>> ==18051==    by 0x4849C7: source_builtin (in /bin/bash)
>> ==18051==    by 0x43378D: ??? (in /bin/bash)
>> ==18051==    by 0x43592C: ??? (in /bin/bash)
>> ==18051==    by 0x4369C7: execute_command_internal (in /bin/bash)
>> ==18051==    by 0x43851D: execute_command (in /bin/bash)
>> ==18051==    by 0x42139D: reader_loop (in /bin/bash)
>> ==18051==  Address 0x4241008 is in the brk data segment 0x4228000-0x4246fff
>> ==18051==
>> ==18051== Invalid free() / delete / delete[] / realloc()
>> ==18051==    at 0x4C2ECF0: free (vg_replace_malloc.c:530)
>> ==18051==    by 0x45E280: ??? (in /bin/bash)
>> ==18051==    by 0x45E42F: run_unwind_frame (in /bin/bash)
>> ==18051==    by 0x4849D3: source_builtin (in /bin/bash)
>> ==18051==    by 0x43378D: ??? (in /bin/bash)
>> ==18051==    by 0x43592C: ??? (in /bin/bash)
>> ==18051==    by 0x4369C7: execute_command_internal (in /bin/bash)
>> ==18051==    by 0x43851D: execute_command (in /bin/bash)
>> ==18051==    by 0x42139D: reader_loop (in /bin/bash)
>> ==18051==    by 0x41FDB0: main (in /bin/bash)
>> ==18051==  Address 0x4240708 is in the brk data segment 0x4228000-0x4246fff
>> ==18051==
>>
> 
> Not at all clear to me what to make of this.  Does it indicate problems
> or memory leaks in my installation of R?  Anyhow, things then proceed in
> an expected manner:
> 
>> R version 3.5.1 (2018-07-02) -- "Feather Spray"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>    Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> Loading required package: misc
>> [Previously saved workspace restored]
> 
> I then loaded the problematic package and issued the problematic command:
> 
>>> library(hmm.discnp)
>> hmm.discnp 2.0-9
>>
>>       This package has changed SUBSTANTIALLY from its
>>       previous release.  Read the documentation
>>       carefully.  Note in particular that the meaning of
>>       the argument "nsim" of the function rhmm() has
>>       changed, and a new argument "ylengths" now plays
>>       essentially the role previously played by
>>       "nsim".
>>
>>> xxx <- get.hgl(p3,2,yyy)
>>
>>   *** caught segfault ***
>> address (nil), cause 'unknown'
>> Segmentation fault (core dumped)
> 
> Nothing informative.  Is there something else I should be doing?
> 
> Sorry for being a nuisance, but I am at a loss.
> 
> cheers,
> 
> Rolf
>



From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug 13 03:29:39 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 13 Aug 2018 13:29:39 +1200
Subject: [R] Mysterious seg fault.
In-Reply-To: <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
Message-ID: <32f9ace9-58b5-1480-211e-fb8e5ec7eb68@auckland.ac.nz>

On 13/08/18 12:03, Duncan Murdoch wrote:

<SNIP>

>> So I did:
>>
>> /usr/local/bin/valgrind R
> 
> I believe on your system R is a script, so you can't run valgrind this 
> way.? It's just debugging bash, not R.? You need to use
> 
> R -d valgrind
> 
> (though with your weird path problems, you might need a fully qualified 
> /usr/local/bin/valgrind there).
> 
> You run gdb the same way:
> 
> R -d gdb
> 
> and then give the command "r" to gdb to start R.? It will give a report 
> when you get the segfault.? I don't know which report will be more 
> informative.

<SNIP>

Thanks Duncan.  I did as you said with valgrind and got output that is 
probably more relevant.  However it is still opaque to me.  I have no 
idea how to use it to track down the error that I am making in the code.

> xxx <- get.hgl(p3,2,yyy)
> ==20088== Invalid read of size 8
> ==20088==    at 0x5116CD: Rf_allocVector3 (memory.c:2539)
> ==20088==    by 0x4B40FF: Rf_allocVector (Rinlinedfuns.h:577)
> ==20088==    by 0x4B40FF: do_missing (envir.c:2265)
> ==20088==    by 0x4CA383: bcEval (eval.c:6801)
> ==20088==    by 0x4D99EF: Rf_eval (eval.c:624)
> ==20088==    by 0x4DB172: R_execClosure (eval.c:1773)
> ==20088==    by 0x4D0E6E: bcEval (eval.c:6749)
> ==20088==    by 0x4D99EF: Rf_eval (eval.c:624)
> ==20088==    by 0x4DB172: R_execClosure (eval.c:1773)
> ==20088==    by 0x4D0E6E: bcEval (eval.c:6749)
> ==20088==    by 0x4D99EF: Rf_eval (eval.c:624)
> ==20088==    by 0x4DB172: R_execClosure (eval.c:1773)
> ==20088==    by 0x4D99A1: Rf_eval (eval.c:747)
> ==20088==  Address 0x3fca86ccfb7de9cc is not stack'd, malloc'd or (recently) free'd
> ==20088== 
> 
>  *** caught segfault ***
> address (nil), cause 'unknown'
> ==20088== Invalid read of size 8
> ==20088==    at 0x511B23: Rf_allocVector3 (memory.c:2691)
> ==20088==    by 0x49137A: Rf_allocVector (Rinlinedfuns.h:577)
> ==20088==    by 0x49137A: deparse1WithCutoff (deparse.c:268)
> ==20088==    by 0x492EAF: Rf_deparse1m (deparse.c:197)
> ==20088==    by 0x4BA99C: R_GetTraceback (errors.c:1409)
> ==20088==    by 0x5053CE: sigactionSegv (main.c:592)
> ==20088==    by 0x6CA738F: ??? (in /lib/x86_64-linux-gnu/libpthread-2.23.so)
> ==20088==    by 0x5116CC: Rf_allocVector3 (memory.c:2539)
> ==20088==  Address 0x3fca86ccfb7de9cc is not stack'd, malloc'd or (recently) free'd
> ==20088== 
> ==20088== 
> ==20088== Process terminating with default action of signal 11 (SIGSEGV)
> ==20088==  General Protection Fault
> ==20088==    at 0x511B23: Rf_allocVector3 (memory.c:2691)
> ==20088==    by 0x49137A: Rf_allocVector (Rinlinedfuns.h:577)
> ==20088==    by 0x49137A: deparse1WithCutoff (deparse.c:268)
> ==20088==    by 0x492EAF: Rf_deparse1m (deparse.c:197)
> ==20088==    by 0x4BA99C: R_GetTraceback (errors.c:1409)
> ==20088==    by 0x5053CE: sigactionSegv (main.c:592)
> ==20088==    by 0x6CA738F: ??? (in /lib/x86_64-linux-gnu/libpthread-2.23.so)
> ==20088==    by 0x5116CC: Rf_allocVector3 (memory.c:2539)
> ==20088== 
> ==20088== HEAP SUMMARY:
> ==20088==     in use at exit: 210,111,063 bytes in 57,981 blocks
> ==20088==   total heap usage: 106,693 allocs, 48,712 frees, 349,208,345 bytes allocated
> ==20088== 
> ==20088== LEAK SUMMARY:
> ==20088==    definitely lost: 0 bytes in 0 blocks
> ==20088==    indirectly lost: 0 bytes in 0 blocks
> ==20088==      possibly lost: 0 bytes in 0 blocks
> ==20088==    still reachable: 210,111,063 bytes in 57,981 blocks
> ==20088==                       of which reachable via heuristic:
> ==20088==                         newarray           : 4,264 bytes in 1 blocks
> ==20088==         suppressed: 0 bytes in 0 blocks
> ==20088== Rerun with --leak-check=full to see details of leaked memory
> ==20088== 
> ==20088== For counts of detected and suppressed errors, rerun with: -v
> ==20088== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)
> Segmentation fault (core dumped)

Doesn't mean a thing to me, I'm afraid.  Does it mean anything to you?
I have not (yet) "rerun with: -v".  I suspect that this would not help.

I guess I'll try to get gdb going next, and see if that provides more 
lucid output.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug 13 03:51:24 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 13 Aug 2018 13:51:24 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
Message-ID: <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>


OK everybody!  You can relax.  :-) I managed to spot the loony.  After 
mucking around with valgrind, and before trying gdb, I had one more look 
at my code and *finally* saw the stupid thing that I had been doing.

In the call to .Fortran() I had a line

     nphi=as.integer(nphi),

but "nphi" was nowhere defined (!!!) in the R code.  The name "nphi" 
appeared as an argument in the Fortran subroutine in question, but was 
nowhere actually *used*!!!

It seems that passing a non-existent value as an argument to a Fortran 
subroutine can *sometimes* confuse it.  Understandably.

I think that this "nphi" was a left-over from an earlier version of the 
code.  I must have changed the code so that nphi was no longer needed, 
but then forgot to remove it from some places.  Psigh!  I hate myself 
sometimes.

Anyhow, thanks to all those who took the time and made the effort to try 
to help me.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From deep@m@hm@||@c @end|ng |rom gm@||@com  Mon Aug 13 07:10:10 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa Maheshvare)
Date: Mon, 13 Aug 2018 10:40:10 +0530
Subject: [R] searching for a specific row name in R
Message-ID: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>

Hello Everyone,

I have a 1000 x 20 matrix. The second column of the matrix has the names of identifiers. How do I check when a certain identifier is present in the set of 1000 identifier names present in the second column. For instance, let the names of identifiers be A1,A2,...A1000. I want to check whether A501 is present .How can this be checked?

Any help will be highly appreciated.


	[[alternative HTML version deleted]]



From @|k@u||m @end|ng |rom |@@tm@||@|m  Mon Aug 13 09:09:23 2018
From: @|k@u||m @end|ng |rom |@@tm@||@|m (Albrecht Kauffmann)
Date: Mon, 13 Aug 2018 09:09:23 +0200
Subject: [R] searching for a specific row name in R
In-Reply-To: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
Message-ID: <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>

Hello Deepa,

sum(x[,2] == "A501")
or
which(x[,2] == "A501")
.
Best,
Albrecht


-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
> Hello Everyone,
> 
> I have a 1000 x 20 matrix. The second column of the matrix has the names 
> of identifiers. How do I check when a certain identifier is present in 
> the set of 1000 identifier names present in the second column. For 
> instance, let the names of identifiers be A1,A2,...A1000. I want to 
> check whether A501 is present .How can this be checked?
> 
> Any help will be highly appreciated.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Aug 13 10:45:42 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 13 Aug 2018 10:45:42 +0200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
Message-ID: <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>

On Mon, Aug 13, 2018 at 3:51 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> OK everybody!  You can relax.  :-) I managed to spot the loony.  After
> mucking around with valgrind, and before trying gdb, I had one more look
> at my code and *finally* saw the stupid thing that I had been doing.
>
> In the call to .Fortran() I had a line
>
>      nphi=as.integer(nphi),
>
> but "nphi" was nowhere defined (!!!) in the R code.  The name "nphi"
> appeared as an argument in the Fortran subroutine in question, but was
> nowhere actually *used*!!!

Didn't R CMD check pick this up, that is, didn't it report that 'nphi'
is a "global" variable?

/Henrik

>
> It seems that passing a non-existent value as an argument to a Fortran
> subroutine can *sometimes* confuse it.  Understandably.
>
> I think that this "nphi" was a left-over from an earlier version of the
> code.  I must have changed the code so that nphi was no longer needed,
> but then forgot to remove it from some places.  Psigh!  I hate myself
> sometimes.
>
> Anyhow, thanks to all those who took the time and made the effort to try
> to help me.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug 13 11:54:06 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 13 Aug 2018 21:54:06 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
Message-ID: <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>


On 13/08/18 20:45, Henrik Bengtsson wrote:

> On Mon, Aug 13, 2018 at 3:51 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> OK everybody!  You can relax.  :-) I managed to spot the loony.  After
>> mucking around with valgrind, and before trying gdb, I had one more look
>> at my code and *finally* saw the stupid thing that I had been doing.
>>
>> In the call to .Fortran() I had a line
>>
>>       nphi=as.integer(nphi),
>>
>> but "nphi" was nowhere defined (!!!) in the R code.  The name "nphi"
>> appeared as an argument in the Fortran subroutine in question, but was
>> nowhere actually *used*!!!
> 
> Didn't R CMD check pick this up, that is, didn't it report that 'nphi'
> is a "global" variable?

No it didn't.  The name only appears in the call to .Fortran().  I think 
if it appeared in a call to an ordinary garden-variety R function then a 
warning would have been issued.

Such a lapse would be hard for R CMD check to pick up.  E.g

    nphi=integer(1),

would be OK in a call to .Fortran (which would allow a value of nphi, 
calculated within the called subroutine, to be *returned*) whereas

    nphi=as.integer(nphi),

causes trouble when nphi has never been defined (as I found out after a 
great expenditure of time and torn-out hair).  In the former instance it 
doesn't matter an FTCF whether nphi has been defined or not.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From pd@|gd @end|ng |rom gm@||@com  Mon Aug 13 13:39:30 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 13 Aug 2018 13:39:30 +0200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
Message-ID: <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>

It's odd, possibly a bug, that you don't get 

Error: object 'nphi' not found

but I can't offhand see where the evaluation of args to .C/.Fortran is supposed to take place.

-pd

> On 13 Aug 2018, at 11:54 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 13/08/18 20:45, Henrik Bengtsson wrote:
> 
>> On Mon, Aug 13, 2018 at 3:51 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> 
>>> 
>>> OK everybody!  You can relax.  :-) I managed to spot the loony.  After
>>> mucking around with valgrind, and before trying gdb, I had one more look
>>> at my code and *finally* saw the stupid thing that I had been doing.
>>> 
>>> In the call to .Fortran() I had a line
>>> 
>>>      nphi=as.integer(nphi),
>>> 
>>> but "nphi" was nowhere defined (!!!) in the R code.  The name "nphi"
>>> appeared as an argument in the Fortran subroutine in question, but was
>>> nowhere actually *used*!!!
>> Didn't R CMD check pick this up, that is, didn't it report that 'nphi'
>> is a "global" variable?
> 
> No it didn't.  The name only appears in the call to .Fortran().  I think if it appeared in a call to an ordinary garden-variety R function then a warning would have been issued.
> 
> Such a lapse would be hard for R CMD check to pick up.  E.g
> 
>   nphi=integer(1),
> 
> would be OK in a call to .Fortran (which would allow a value of nphi, calculated within the called subroutine, to be *returned*) whereas
> 
>   nphi=as.integer(nphi),
> 
> causes trouble when nphi has never been defined (as I found out after a great expenditure of time and torn-out hair).  In the former instance it doesn't matter an FTCF whether nphi has been defined or not.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From chr|@@@ @end|ng |rom med@um|ch@edu  Mon Aug 13 14:27:53 2018
From: chr|@@@ @end|ng |rom med@um|ch@edu (Andrews, Chris)
Date: Mon, 13 Aug 2018 12:27:53 +0000
Subject: [R] Typo in print.aov
Message-ID: <cc3652e5c58d48a0bd63757e0bb9e7df@med.umich.edu>


While looking at the code of print.aov for a different reason, I noticed that 'coefficient' was spelled with 3 'f's in one location.  Perhaps this is on purpose but in another location it has just 2 'f's.  This has not caused me any problem (that I know of) but I found it curious.

Chris



R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)




> getAnywhere(print.aov)
A single object matching 'print.aov' was found
It was found in the following places
  registered S3 method for print from namespace stats
  namespace:stats
with value

function (x, intercept = FALSE, tol = sqrt(.Machine$double.eps), 
    ...) 
{
    if (!is.null(cl <- x$call)) {
        cat("Call:\n   ")
        dput(cl, control = NULL)
    }
    qrx <- if (x$rank) 
        qr(x)
    asgn <- x$assign[qrx$pivot[1L:x$rank]]
    effects <- x$effects
    if (!is.null(effects)) 
        effects <- as.matrix(effects)[seq_along(asgn), , drop = FALSE]
    rdf <- x$df.residual
    resid <- as.matrix(x$residuals)
    wt <- x$weights
    if (!is.null(wt)) 
        resid <- resid * sqrt(wt)
    RSS <- colSums(resid^2)
    uasgn <- unique(asgn)
    nmeffect <- c("(Intercept)", attr(x$terms, "term.labels"))[1 + 
        uasgn]
    nterms <- length(uasgn)
    nresp <- NCOL(effects)
    df <- numeric(nterms)
    ss <- matrix(NA, nterms, nresp)
    if (nterms) {
        for (i in seq(nterms)) {
            ai <- asgn == uasgn[i]
            df[i] <- sum(ai)
            ef <- effects[ai, , drop = FALSE]
            ss[i, ] <- if (sum(ai) > 1) 
                colSums(ef^2)
            else ef^2
        }
        keep <- df > 0L
        if (!intercept && uasgn[1L] == 0) 
            keep[1L] <- FALSE
        nmeffect <- nmeffect[keep]
        df <- df[keep]
        ss <- ss[keep, , drop = FALSE]
        nterms <- length(df)
    }
    cat("\nTerms:\n")
    if (nterms == 0L) {
        if (rdf > 0L) {
            ss <- RSS
            ssp <- sapply(ss, format)
            if (!is.matrix(ssp)) 
                ssp <- t(ssp)
            tmp <- as.matrix(c(ssp, format(rdf)))
            if (length(ss) > 1L) {
                rn <- colnames(x$fitted.values)
                if (is.null(rn)) 
                  rn <- paste("resp", seq_along(ss))
            }
            else rn <- "Sum of Squares"
            dimnames(tmp) <- list(c(rn, "Deg. of Freedom"), "Residuals")
            print(tmp, quote = FALSE, right = TRUE)
            cat("\n")
            rs <- sqrt(RSS/rdf)
            cat(if (length(rs) > 1L) 
                "Residual standard errors:"
            else "Residual standard error:", sapply(rs, format))
            cat("\n")
        }
        else print(matrix(0, 2L, 1L, dimnames = list(c("Sum of Squares", 
            "Deg. of Freedom"), "<empty>")))
    }
    else {
        if (rdf > 0L) {
            nterms <- nterms + 1L
            df <- c(df, rdf)
            ss <- rbind(ss, RSS)
            nmeffect <- c(nmeffect, "Residuals")
        }
        ssp <- apply(zapsmall(ss), 2L, format)
        tmp <- t(cbind(ssp, format(df)))
        if (ncol(effects) > 1L) {
            rn <- colnames(x$coeffficients) ###############************ <------- HERE
            if (is.null(rn)) 
                rn <- paste("resp", seq(ncol(effects)))
        }
        else rn <- "Sum of Squares"
        dimnames(tmp) <- list(c(rn, "Deg. of Freedom"), nmeffect)
        print(tmp, quote = FALSE, right = TRUE)
        rank <- x$rank
        cat("\n")
        if (rdf > 0L) {
            rs <- sqrt(RSS/rdf)
            cat(if (length(rs) > 1L) 
                "Residual standard errors:"
            else "Residual standard error:", sapply(rs, format))
            cat("\n")
        }
        coef <- as.matrix(x$coefficients)[, 1L]  ################## ************ <- NOT HERE
        R <- qrx$qr
        R <- R[1L:min(dim(R)), , drop = FALSE]
        R[lower.tri(R)] <- 0
        if (rank < (nc <- length(coef))) {
            cat(paste(nc - rank, "out of", nc, "effects not estimable\n"))
            R <- R[, 1L:rank, drop = FALSE]
        }
        d2 <- sum(abs(diag(R)))
        diag(R) <- 0
        if (sum(abs(R))/d2 > tol) 
            cat("Estimated effects may be unbalanced\n")
        else cat("Estimated effects are balanced\n")
        if (nzchar(mess <- naprint(x$na.action))) 
            cat(mess, "\n", sep = "")
    }
    invisible(x)
}
<bytecode: 0x0000000014c90ca0>
<environment: namespace:stats>


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 



From m@cqueen1 @end|ng |rom ||n|@gov  Mon Aug 13 16:48:50 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 13 Aug 2018 14:48:50 +0000
Subject: [R] searching for a specific row name in R
In-Reply-To: <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
Message-ID: <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>

Or to return a logical value, i.e., TRUE if the column contains the value, FALSE if it does not:

  any( x[,2] == 'A501' )

-Don
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:

    Hello Deepa,
    
    sum(x[,2] == "A501")
    or
    which(x[,2] == "A501")
    .
    Best,
    Albrecht
    
    
    -- 
      Albrecht Kauffmann
      alkauffm at fastmail.fm
    
    Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
    > Hello Everyone,
    > 
    > I have a 1000 x 20 matrix. The second column of the matrix has the names 
    > of identifiers. How do I check when a certain identifier is present in 
    > the set of 1000 identifier names present in the second column. For 
    > instance, let the names of identifiers be A1,A2,...A1000. I want to 
    > check whether A501 is present .How can this be checked?
    > 
    > Any help will be highly appreciated.
    > 
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @h|v|pmp82 @end|ng |rom gm@||@com  Mon Aug 13 17:07:07 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Mon, 13 Aug 2018 20:37:07 +0530
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
 <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
Message-ID: <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>

Hi Michael,

I was able to install RGtk2 from install.packages("
https://cran.r-project.org/bin/windows/contrib/3.3/RGtk2_2.20.31.zip",
repos=NULL) but after installing this and trying to install rattle i get
this error:
Error : package 'RGtk2' was installed by an R version with different
internals; it needs to be reinstalled for use with this R version
ERROR: lazy loading failed for package 'rattle'

I tried installing rattle from install.packages("rattle", repos="
https://rattle.togaware.com", type="source").

Regards, Shivi


On Sun, Aug 12, 2018 at 7:20 PM Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Dear Shivi
>
> What error message do you get when you try to install RGtk2?
>
> Michael
>
> On 12/08/2018 11:49, Shivi Bhatia wrote:
> > Hi Eric,
> >
> > Thank you for the reply. I am adding the session details below, hope it
> > helps:
> > R version 3.5.1 (2018-07-02)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows >= 8 x64 (build 9200)
> >
> > Matrix products: default
> > locale:
> > [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
> > LC_MONETARY=English_India.1252
> > [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > Thanks.
> >
> > On Sat, Aug 11, 2018 at 9:38 PM Eric Berger <ericjberger at gmail.com>
> wrote:
> >
> >> Hi Shivi,
> >> I have no experience with the rattle package but I just installed it
> with
> >> no problem.
> >> I am using a Windows 10 machine with R version 3.4.2.
> >>
> >> I suggest you provide additional information so that others may have
> ideas.
> >> e.g. your operating system version and output from sessionInfo() (in R)
> >>
> >> Best,
> >> Eric
> >>
> >>
> >> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia <shivipmp82 at gmail.com>
> >> wrote:
> >>
> >>> Hi,
> >>>
> >>> Need assistance on installing Rattle.
> >>>
> >>> I have followed the instructions on https://rattle.togaware.com/
> >>> but still facing error installing the package.
> >>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
> >>> Have tried installing RGt2 from multiple sources and its still failing.
> >>>
> >>> One of the suggestion on stack overflow was to downgrade the R version
> >>> here
> >>> :
> >>>
> >>>
> https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
> >>> Request assistance.
> >>>
> >>> Regards, Shivi
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Mon Aug 13 18:11:02 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 13 Aug 2018 18:11:02 +0200
Subject: [R] Typo in print.aov
In-Reply-To: <cc3652e5c58d48a0bd63757e0bb9e7df@med.umich.edu>
References: <cc3652e5c58d48a0bd63757e0bb9e7df@med.umich.edu>
Message-ID: <9EE2B66A-9205-4961-A052-B4B650C90C22@gmail.com>

That's a bug... no other place in the sources has "coeffficients". The net result is that the NULL case is used even when colnames _are_ present. It does make a difference, e.g. to examples(manova). I am fixing this in r-devel since the urgency must be rather low.

- Peter D.

> On 13 Aug 2018, at 14:27 , Andrews, Chris <chrisaa at med.umich.edu> wrote:
> 
> 
> While looking at the code of print.aov for a different reason, I noticed that 'coefficient' was spelled with 3 'f's in one location.  Perhaps this is on purpose but in another location it has just 2 'f's.  This has not caused me any problem (that I know of) but I found it curious.
> 
> Chris
> 
> 
> 
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> 
> 
> 
>> getAnywhere(print.aov)
> A single object matching 'print.aov' was found
> It was found in the following places
>  registered S3 method for print from namespace stats
>  namespace:stats
> with value
> 
> function (x, intercept = FALSE, tol = sqrt(.Machine$double.eps), 
>    ...) 
> {
>    if (!is.null(cl <- x$call)) {
>        cat("Call:\n   ")
>        dput(cl, control = NULL)
>    }
>    qrx <- if (x$rank) 
>        qr(x)
>    asgn <- x$assign[qrx$pivot[1L:x$rank]]
>    effects <- x$effects
>    if (!is.null(effects)) 
>        effects <- as.matrix(effects)[seq_along(asgn), , drop = FALSE]
>    rdf <- x$df.residual
>    resid <- as.matrix(x$residuals)
>    wt <- x$weights
>    if (!is.null(wt)) 
>        resid <- resid * sqrt(wt)
>    RSS <- colSums(resid^2)
>    uasgn <- unique(asgn)
>    nmeffect <- c("(Intercept)", attr(x$terms, "term.labels"))[1 + 
>        uasgn]
>    nterms <- length(uasgn)
>    nresp <- NCOL(effects)
>    df <- numeric(nterms)
>    ss <- matrix(NA, nterms, nresp)
>    if (nterms) {
>        for (i in seq(nterms)) {
>            ai <- asgn == uasgn[i]
>            df[i] <- sum(ai)
>            ef <- effects[ai, , drop = FALSE]
>            ss[i, ] <- if (sum(ai) > 1) 
>                colSums(ef^2)
>            else ef^2
>        }
>        keep <- df > 0L
>        if (!intercept && uasgn[1L] == 0) 
>            keep[1L] <- FALSE
>        nmeffect <- nmeffect[keep]
>        df <- df[keep]
>        ss <- ss[keep, , drop = FALSE]
>        nterms <- length(df)
>    }
>    cat("\nTerms:\n")
>    if (nterms == 0L) {
>        if (rdf > 0L) {
>            ss <- RSS
>            ssp <- sapply(ss, format)
>            if (!is.matrix(ssp)) 
>                ssp <- t(ssp)
>            tmp <- as.matrix(c(ssp, format(rdf)))
>            if (length(ss) > 1L) {
>                rn <- colnames(x$fitted.values)
>                if (is.null(rn)) 
>                  rn <- paste("resp", seq_along(ss))
>            }
>            else rn <- "Sum of Squares"
>            dimnames(tmp) <- list(c(rn, "Deg. of Freedom"), "Residuals")
>            print(tmp, quote = FALSE, right = TRUE)
>            cat("\n")
>            rs <- sqrt(RSS/rdf)
>            cat(if (length(rs) > 1L) 
>                "Residual standard errors:"
>            else "Residual standard error:", sapply(rs, format))
>            cat("\n")
>        }
>        else print(matrix(0, 2L, 1L, dimnames = list(c("Sum of Squares", 
>            "Deg. of Freedom"), "<empty>")))
>    }
>    else {
>        if (rdf > 0L) {
>            nterms <- nterms + 1L
>            df <- c(df, rdf)
>            ss <- rbind(ss, RSS)
>            nmeffect <- c(nmeffect, "Residuals")
>        }
>        ssp <- apply(zapsmall(ss), 2L, format)
>        tmp <- t(cbind(ssp, format(df)))
>        if (ncol(effects) > 1L) {
>            rn <- colnames(x$coeffficients) ###############************ <------- HERE
>            if (is.null(rn)) 
>                rn <- paste("resp", seq(ncol(effects)))
>        }
>        else rn <- "Sum of Squares"
>        dimnames(tmp) <- list(c(rn, "Deg. of Freedom"), nmeffect)
>        print(tmp, quote = FALSE, right = TRUE)
>        rank <- x$rank
>        cat("\n")
>        if (rdf > 0L) {
>            rs <- sqrt(RSS/rdf)
>            cat(if (length(rs) > 1L) 
>                "Residual standard errors:"
>            else "Residual standard error:", sapply(rs, format))
>            cat("\n")
>        }
>        coef <- as.matrix(x$coefficients)[, 1L]  ################## ************ <- NOT HERE
>        R <- qrx$qr
>        R <- R[1L:min(dim(R)), , drop = FALSE]
>        R[lower.tri(R)] <- 0
>        if (rank < (nc <- length(coef))) {
>            cat(paste(nc - rank, "out of", nc, "effects not estimable\n"))
>            R <- R[, 1L:rank, drop = FALSE]
>        }
>        d2 <- sum(abs(diag(R)))
>        diag(R) <- 0
>        if (sum(abs(R))/d2 > tol) 
>            cat("Estimated effects may be unbalanced\n")
>        else cat("Estimated effects are balanced\n")
>        if (nzchar(mess <- naprint(x$na.action))) 
>            cat(mess, "\n", sep = "")
>    }
>    invisible(x)
> }
> <bytecode: 0x0000000014c90ca0>
> <environment: namespace:stats>
> 
> 
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Aug 13 18:26:38 2018
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 13 Aug 2018 17:26:38 +0100
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
 <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
 <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>
Message-ID: <3d221e3e-52f0-fffe-f70d-31e43845fc57@dewey.myzen.co.uk>

Dear Shivi

You are running R 3.5.1 according to your session info. Why are you 
installing a version for R 3.3? Note that the up-to-date version depends 
on R > 3.4.0 so it is no surprise that you get problems.

Michael

On 13/08/2018 16:07, Shivi Bhatia wrote:
> Hi Michael,
> 
> I was able to install RGtk2 
> from?install.packages("https://cran.r-project.org/bin/windows/contrib/3.3/RGtk2_2.20.31.zip", 
> repos=NULL) but after installing this and trying to install rattle i get 
> this error:
> Error : package 'RGtk2' was installed by an R version with different 
> internals; it needs to be reinstalled for use with this R version
> ERROR: lazy loading failed for package 'rattle'
> 
> I tried installing rattle from?install.packages("rattle", 
> repos="https://rattle.togaware.com", type="source").
> 
> Regards, Shivi
> 
> 
> On Sun, Aug 12, 2018 at 7:20 PM Michael Dewey <lists at dewey.myzen.co.uk 
> <mailto:lists at dewey.myzen.co.uk>> wrote:
> 
>     Dear Shivi
> 
>     What error message do you get when you try to install RGtk2?
> 
>     Michael
> 
>     On 12/08/2018 11:49, Shivi Bhatia wrote:
>      > Hi Eric,
>      >
>      > Thank you for the reply. I am adding the session details below,
>     hope it
>      > helps:
>      > R version 3.5.1 (2018-07-02)
>      > Platform: x86_64-w64-mingw32/x64 (64-bit)
>      > Running under: Windows >= 8 x64 (build 9200)
>      >
>      > Matrix products: default
>      > locale:
>      > [1] LC_COLLATE=English_India.1252? LC_CTYPE=English_India.1252
>      > LC_MONETARY=English_India.1252
>      > [4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ?LC_TIME=English_India.1252
>      >
>      > attached base packages:
>      > [1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
>      >
>      > Thanks.
>      >
>      > On Sat, Aug 11, 2018 at 9:38 PM Eric Berger
>     <ericjberger at gmail.com <mailto:ericjberger at gmail.com>> wrote:
>      >
>      >> Hi Shivi,
>      >> I have no experience with the rattle package but I just
>     installed it with
>      >> no problem.
>      >> I am using a Windows 10 machine with R version 3.4.2.
>      >>
>      >> I suggest you provide additional information so that others may
>     have ideas.
>      >> e.g. your operating system version and output from sessionInfo()
>     (in R)
>      >>
>      >> Best,
>      >> Eric
>      >>
>      >>
>      >> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia
>     <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>>
>      >> wrote:
>      >>
>      >>> Hi,
>      >>>
>      >>> Need assistance on installing Rattle.
>      >>>
>      >>> I have followed the instructions on https://rattle.togaware.com/
>      >>> but still facing error installing the package.
>      >>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
>      >>> Have tried installing RGt2 from multiple sources and its still
>     failing.
>      >>>
>      >>> One of the suggestion on stack overflow was to downgrade the R
>     version
>      >>> here
>      >>> :
>      >>>
>      >>>
>     https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>      >>> Request assistance.
>      >>>
>      >>> Regards, Shivi
>      >>>
>      >>>? ? ? ? ? [[alternative HTML version deleted]]
>      >>>
>      >>> ______________________________________________
>      >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >>> PLEASE do read the posting guide
>      >>> http://www.R-project.org/posting-guide.html
>      >>> and provide commented, minimal, self-contained, reproducible code.
>      >>>
>      >>
>      >>
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
> 
>     -- 
>     Michael
>     http://www.dewey.myzen.co.uk/home.html
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



From |@t@z@hn @end|ng |rom gm@||@com  Mon Aug 13 21:17:54 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Mon, 13 Aug 2018 15:17:54 -0400
Subject: [R] Fast matrix multiplication
In-Reply-To: <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
 <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
Message-ID: <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>

On Mon, Aug 13, 2018 at 2:41 PM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Hi Ista,
> Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?

Not sure. If you want an easy way I would use MRO. More info at
https://mran.microsoft.com/rro#intelmkl1

--Ista

> Thanks,
> Ravi
>
> -----Original Message-----
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Friday, August 10, 2018 12:20 PM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] Fast matrix multiplication
>
>
> Hi Ravi,
>
> You can achieve substantial speed up by using a faster BLAS (e.g., OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6 year old, but 8 core) system your example takes 3.9 seconds with using the reference BLAS and only 0.9 seconds using OpenBLAS.
>
> Best,
> Ista
> On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> >
> > Hi,
> >
> > I would like to compute:  A %*% B %*% t(A)
> >
> >
> >
> > A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
> >
> >
> >
> > Here is a sample code.
> >
> >
> >
> > M <- 10000
> >
> > N <- 100
> >
> > A <- matrix(rnorm(M*N), M, N)
> >
> > B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric
> > positive-definite matrix
> >
> >
> >
> > # method 1
> >
> > system.time(D <- A %*% B %*% t(A))
> >
> >
> >
> > # I can obtain speedup by using a Cholesky decomposition of B
> >
> > # method 2
> >
> > system.time({
> >
> > C <- t(chol(B))
> >
> > E <- tcrossprod(A%*%C)
> >
> > })
> >
> >
> >
> > all.equal(D, E)
> >
> >
> >
> > I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
> >
> >
> >
> > Thanks,
> >
> > Ravi
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



From peter@|@ng|e|der @end|ng |rom gm@||@com  Mon Aug 13 21:34:59 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Mon, 13 Aug 2018 12:34:59 -0700
Subject: [R] Fast matrix multiplication
In-Reply-To: <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
 <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
 <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
Message-ID: <CA+hbrhUPrWMkA6SAukZeCLt50SCZmkPctEgOV+mE7bB3D2kSnQ@mail.gmail.com>

On Mon, Aug 13, 2018 at 12:18 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Mon, Aug 13, 2018 at 2:41 PM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> >
> > Hi Ista,
> > Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?
>
> Not sure. If you want an easy way I would use MRO. More info at
> https://mran.microsoft.com/rro#intelmkl1

OpenBLAS is provided as a binary for Windows, see http://www.openblas.net/ .

You may need to compile R from source though, unless you can use an
equivalent of the linux trick to replace libRblas.so with a symlink to
the compiled openBLAS library.

Peter



From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Aug 14 01:16:09 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 14 Aug 2018 11:16:09 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
Message-ID: <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>

On 13/08/18 23:39, peter dalgaard wrote:
> It's odd, possibly a bug, that you don't get
> 
> Error: object 'nphi' not found
> 
> but I can't offhand see where the evaluation of args to .C/.Fortran is supposed to take place.

If it is indeed a bug then it would be nice an it were fixed.  If that 
is possible.  Way beyond my level of comprehension but.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From deep@m@hm@||@c @end|ng |rom gm@||@com  Tue Aug 14 05:36:00 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa)
Date: Tue, 14 Aug 2018 09:06:00 +0530
Subject: [R] searching for a specific row name in R
In-Reply-To: <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
Message-ID: <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>

Hi Don,

When there is a list of identifier names that I want to check, the only way
is to loop over each entry stored in the list of identifier names or is
there is there any other shortcut?

Many thanks for the response?

On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Or to return a logical value, i.e., TRUE if the column contains the value,
> FALSE if it does not:
>
>   any( x[,2] == 'A501' )
>
> -Don
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
> r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
>
>     Hello Deepa,
>
>     sum(x[,2] == "A501")
>     or
>     which(x[,2] == "A501")
>     .
>     Best,
>     Albrecht
>
>
>     --
>       Albrecht Kauffmann
>       alkauffm at fastmail.fm
>
>     Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
>     > Hello Everyone,
>     >
>     > I have a 1000 x 20 matrix. The second column of the matrix has the
> names
>     > of identifiers. How do I check when a certain identifier is present
> in
>     > the set of 1000 identifier names present in the second column. For
>     > instance, let the names of identifiers be A1,A2,...A1000. I want to
>     > check whether A501 is present .How can this be checked?
>     >
>     > Any help will be highly appreciated.
>     >
>     >
>     >   [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]



From bor|@@@te|pe @end|ng |rom utoronto@c@  Tue Aug 14 05:46:05 2018
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 13 Aug 2018 23:46:05 -0400
Subject: [R] searching for a specific row name in R
In-Reply-To: <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
Message-ID: <11492AAE-6888-4D90-B408-F020FAD5DFC3@utoronto.ca>

Use the %in% operator:

help('%in%')

e.g.

R > c("d", "v", "4", "s") %in% letters
[1]  TRUE  TRUE FALSE  TRUE


B.


> On 2018-08-13, at 23:36, Deepa <deepamahm.iisc at gmail.com> wrote:
> 
> Hi Don,
> 
> When there is a list of identifier names that I want to check, the only way
> is to loop over each entry stored in the list of identifier names or is
> there is there any other shortcut?
> 
> Many thanks for the response?
> 
> On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
>> Or to return a logical value, i.e., TRUE if the column contains the value,
>> FALSE if it does not:
>> 
>>  any( x[,2] == 'A501' )
>> 
>> -Don
>> --
>> Don MacQueen
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> Lab cell 925-724-7509
>> 
>> 
>> 
>> ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
>> r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
>> 
>>    Hello Deepa,
>> 
>>    sum(x[,2] == "A501")
>>    or
>>    which(x[,2] == "A501")
>>    .
>>    Best,
>>    Albrecht
>> 
>> 
>>    --
>>      Albrecht Kauffmann
>>      alkauffm at fastmail.fm
>> 
>>    Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
>>> Hello Everyone,
>>> 
>>> I have a 1000 x 20 matrix. The second column of the matrix has the
>> names
>>> of identifiers. How do I check when a certain identifier is present
>> in
>>> the set of 1000 identifier names present in the second column. For
>>> instance, let the names of identifiers be A1,A2,...A1000. I want to
>>> check whether A501 is present .How can this be checked?
>>> 
>>> Any help will be highly appreciated.
>>> 
>>> 
>>>  [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>    ______________________________________________
>>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>    PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>    and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From deep@m@hm@||@c @end|ng |rom gm@||@com  Tue Aug 14 06:16:15 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa)
Date: Tue, 14 Aug 2018 09:46:15 +0530
Subject: [R] searching for a specific row name in R
In-Reply-To: <11492AAE-6888-4D90-B408-F020FAD5DFC3@utoronto.ca>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
 <11492AAE-6888-4D90-B408-F020FAD5DFC3@utoronto.ca>
Message-ID: <CAGchuN5A4=mdGbynBZf4Mk3256rB5c07Htw9OR28fpM09Dd1Lg@mail.gmail.com>

I have a hundred identifier names that I want to check from the second
column of a matrix with 6000 entries in the column.
Instead of using  R > c("d", "v", "4", "s") %in% letters , is there an
alternative?

I have the hundred identifier names that are of my interest stored in an
array.




On Tue, Aug 14, 2018 at 9:16 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Use the %in% operator:
>
> help('%in%')
>
> e.g.
>
> R > c("d", "v", "4", "s") %in% letters
> [1]  TRUE  TRUE FALSE  TRUE
>
>
> B.
>
>
> > On 2018-08-13, at 23:36, Deepa <deepamahm.iisc at gmail.com> wrote:
> >
> > Hi Don,
> >
> > When there is a list of identifier names that I want to check, the only
> way
> > is to loop over each entry stored in the list of identifier names or is
> > there is there any other shortcut?
> >
> > Many thanks for the response?
> >
> > On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov>
> wrote:
> >
> >> Or to return a logical value, i.e., TRUE if the column contains the
> value,
> >> FALSE if it does not:
> >>
> >>  any( x[,2] == 'A501' )
> >>
> >> -Don
> >> --
> >> Don MacQueen
> >> Lawrence Livermore National Laboratory
> >> 7000 East Ave., L-627
> >> Livermore, CA 94550
> >> 925-423-1062
> >> Lab cell 925-724-7509
> >>
> >>
> >>
> >> ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
> >> r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
> >>
> >>    Hello Deepa,
> >>
> >>    sum(x[,2] == "A501")
> >>    or
> >>    which(x[,2] == "A501")
> >>    .
> >>    Best,
> >>    Albrecht
> >>
> >>
> >>    --
> >>      Albrecht Kauffmann
> >>      alkauffm at fastmail.fm
> >>
> >>    Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
> >>> Hello Everyone,
> >>>
> >>> I have a 1000 x 20 matrix. The second column of the matrix has the
> >> names
> >>> of identifiers. How do I check when a certain identifier is present
> >> in
> >>> the set of 1000 identifier names present in the second column. For
> >>> instance, let the names of identifiers be A1,A2,...A1000. I want to
> >>> check whether A501 is present .How can this be checked?
> >>>
> >>> Any help will be highly appreciated.
> >>>
> >>>
> >>>  [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>    ______________________________________________
> >>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>    https://stat.ethz.ch/mailman/listinfo/r-help
> >>    PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>    and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 14 06:18:06 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 13 Aug 2018 21:18:06 -0700
Subject: [R] searching for a specific row name in R
In-Reply-To: <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
Message-ID: <CAGxFJbRQ=5Hn_E7PG+6xHVE01FJJuZGr7YZ3BXoxS3SqBbBpcw@mail.gmail.com>

These seem to be basic R questions. You should spend time with an R
tutorial or two for this sort of thing. This list is here to help, but you
also need to do homework on your own if you have not already done so.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Aug 13, 2018 at 8:36 PM, Deepa <deepamahm.iisc at gmail.com> wrote:

> Hi Don,
>
> When there is a list of identifier names that I want to check, the only way
> is to loop over each entry stored in the list of identifier names or is
> there is there any other shortcut?
>
> Many thanks for the response?
>
> On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>
> > Or to return a logical value, i.e., TRUE if the column contains the
> value,
> > FALSE if it does not:
> >
> >   any( x[,2] == 'A501' )
> >
> > -Don
> > --
> > Don MacQueen
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> > Lab cell 925-724-7509
> >
> >
> >
> > ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
> > r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
> >
> >     Hello Deepa,
> >
> >     sum(x[,2] == "A501")
> >     or
> >     which(x[,2] == "A501")
> >     .
> >     Best,
> >     Albrecht
> >
> >
> >     --
> >       Albrecht Kauffmann
> >       alkauffm at fastmail.fm
> >
> >     Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
> >     > Hello Everyone,
> >     >
> >     > I have a 1000 x 20 matrix. The second column of the matrix has the
> > names
> >     > of identifiers. How do I check when a certain identifier is present
> > in
> >     > the set of 1000 identifier names present in the second column. For
> >     > instance, let the names of identifiers be A1,A2,...A1000. I want to
> >     > check whether A501 is present .How can this be checked?
> >     >
> >     > Any help will be highly appreciated.
> >     >
> >     >
> >     >   [[alternative HTML version deleted]]
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >
> >     ______________________________________________
> >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m|ch@|@burd@ @end|ng |rom centrum@cz  Tue Aug 14 08:44:51 2018
From: m|ch@|@burd@ @end|ng |rom centrum@cz (Michal Burda)
Date: Tue, 14 Aug 2018 08:44:51 +0200
Subject: [R] Makefile generator - please comment
Message-ID: <CAP4zaHNhvA+XWbirUfGJryxh1u7exUVjZ-=JPAP4CX9m8R1ZUg@mail.gmail.com>

Dear R users,

I would like to ask you for comments on whether you find interesting a
package that would help you generate Makefiles for R analytical projects. I
am developing it for some time mainly for myself and now try to decide
whether it is worth an effort to continue and enhance it for wider
audience. Install the most recent version from github, if you wish:

devtools::install_github("beerda/rmake")

The use of the package is very simple. You write your rules as a pipe
similar to Magrittr's operator:

library(rmake)
job <- 'input.csv' %>>% rRule('preprocess.R') %>>% 'data.rds' %>>%
markdownRule('report.Rmd') %>>% 'report.pdf'
makefile(job, 'Makefile')

Thats it. This piece of code generates a complete Makefile that runs
preprocess.R, which reads input.csv and writes data.rds, and then compiles
a markdown report.Rmd, which depends on data.rds, and creates a final
report.pdf. (Of course more complicated pipelines are possible as well as
define dependencies programmatically, also some other features are
implemented already, you can imagine...) I ask the community of whether you
find it useful and whether it is good idea to continue in development of
such package. Recently, some other build tools appeared for R, which seem
very interesting, but which I am not so much experienced with (e.g.
"drake"). There are also some other projects with similar purpose, but they
seem more or less abandoned. Any comments are welcome.

Thanks, in advance.

Best regards,

Michal Burda

	[[alternative HTML version deleted]]



From cke||ey @end|ng |rom @|r@org  Mon Aug 13 19:18:16 2018
From: cke||ey @end|ng |rom @|r@org (Kelley, Claire)
Date: Mon, 13 Aug 2018 17:18:16 +0000
Subject: [R] Cannot set correct miktex path for pdflatex
Message-ID: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>

Hi all,

I am having a problem in R where R is finding an old non existent version of miktex rather than the new version. This occurs despite having set the path to the correct location.

For example in bash if I look for the location of pdflatex:

$ which pdflatex
/c/Program Files/MiKTeX 2.9/miktex/bin/x64/pdflatex


It points to the correct MikTex installation.

However in R:

Sys.which("pdflatex")
                                                pdflatex
C:\\PROGRA~1\\MIKTEX~1.9\\miktex\\bin\\x64\\pdflatex.exe"

Points to the old  (1.9) version of Miktex.

This is my session info:

R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.1

Any thoughts?

I have unsuccessfully tried:


  1.  Adding correct MikTex path to my Renviorn.site. this adds MikTex to my path and I can see the addition, but doesn?t fix the problem
  2.  Adding MikTex path to my $PATH variable. This lets bash find the right version of miktex but doesn?t help in R
  3.  Making sure I only have on version of MIktex. I don?t have tiny tex installed (nor can I because I need the full MIkTex for other work) .


Best,
Claire

	[[alternative HTML version deleted]]


From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Mon Aug 13 20:41:57 2018
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Mon, 13 Aug 2018 18:41:57 +0000
Subject: [R] Fast matrix multiplication
In-Reply-To: <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
Message-ID: <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>

Hi Ista,
Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?
Thanks,
Ravi

-----Original Message-----
From: Ista Zahn <istazahn at gmail.com> 
Sent: Friday, August 10, 2018 12:20 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: r-help at r-project.org
Subject: Re: [R] Fast matrix multiplication


Hi Ravi,

You can achieve substantial speed up by using a faster BLAS (e.g., OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6 year old, but 8 core) system your example takes 3.9 seconds with using the reference BLAS and only 0.9 seconds using OpenBLAS.

Best,
Ista
On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Hi,
>
> I would like to compute:  A %*% B %*% t(A)
>
>
>
> A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
>
>
>
> Here is a sample code.
>
>
>
> M <- 10000
>
> N <- 100
>
> A <- matrix(rnorm(M*N), M, N)
>
> B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric 
> positive-definite matrix
>
>
>
> # method 1
>
> system.time(D <- A %*% B %*% t(A))
>
>
>
> # I can obtain speedup by using a Cholesky decomposition of B
>
> # method 2
>
> system.time({
>
> C <- t(chol(B))
>
> E <- tcrossprod(A%*%C)
>
> })
>
>
>
> all.equal(D, E)
>
>
>
> I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
>
>
>
> Thanks,
>
> Ravi
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @h|v|pmp82 @end|ng |rom gm@||@com  Mon Aug 13 20:47:39 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Mon, 13 Aug 2018 18:47:39 +0000 (UTC)
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <3d221e3e-52f0-fffe-f70d-31e43845fc57@dewey.myzen.co.uk>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
 <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
 <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>
 <3d221e3e-52f0-fffe-f70d-31e43845fc57@dewey.myzen.co.uk>
Message-ID: <630087097.36649.1534186059024@mail.yahoo.com>

Hi Michael?Thank you for the reply.I have been looking for 3.5.1 version of this package but I cannot find one, would you recommend downgrading my current R version.?Would there be some or any other compatibly issue - please advice.?
Thank you, Shivi?


Sent from Yahoo Mail for iPhone


On Monday, August 13, 2018, 21:56, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

Dear Shivi

You are running R 3.5.1 according to your session info. Why are you 
installing a version for R 3.3? Note that the up-to-date version depends 
on R > 3.4.0 so it is no surprise that you get problems.

Michael

On 13/08/2018 16:07, Shivi Bhatia wrote:
> Hi Michael,
> 
> I was able to install RGtk2 
> from?install.packages("https://cran.r-project.org/bin/windows/contrib/3.3/RGtk2_2.20.31.zip", 
> repos=NULL) but after installing this and trying to install rattle i get 
> this error:
> Error : package 'RGtk2' was installed by an R version with different 
> internals; it needs to be reinstalled for use with this R version
> ERROR: lazy loading failed for package 'rattle'
> 
> I tried installing rattle from?install.packages("rattle", 
> repos="https://rattle.togaware.com", type="source").
> 
> Regards, Shivi
> 
> 
> On Sun, Aug 12, 2018 at 7:20 PM Michael Dewey <lists at dewey.myzen.co.uk 
> <mailto:lists at dewey.myzen.co.uk>> wrote:
> 
>? ? Dear Shivi
> 
>? ? What error message do you get when you try to install RGtk2?
> 
>? ? Michael
> 
>? ? On 12/08/2018 11:49, Shivi Bhatia wrote:
>? ? ? > Hi Eric,
>? ? ? >
>? ? ? > Thank you for the reply. I am adding the session details below,
>? ? hope it
>? ? ? > helps:
>? ? ? > R version 3.5.1 (2018-07-02)
>? ? ? > Platform: x86_64-w64-mingw32/x64 (64-bit)
>? ? ? > Running under: Windows >= 8 x64 (build 9200)
>? ? ? >
>? ? ? > Matrix products: default
>? ? ? > locale:
>? ? ? > [1] LC_COLLATE=English_India.1252? LC_CTYPE=English_India.1252
>? ? ? > LC_MONETARY=English_India.1252
>? ? ? > [4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ?LC_TIME=English_India.1252
>? ? ? >
>? ? ? > attached base packages:
>? ? ? > [1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
>? ? ? >
>? ? ? > Thanks.
>? ? ? >
>? ? ? > On Sat, Aug 11, 2018 at 9:38 PM Eric Berger
>? ? <ericjberger at gmail.com <mailto:ericjberger at gmail.com>> wrote:
>? ? ? >
>? ? ? >> Hi Shivi,
>? ? ? >> I have no experience with the rattle package but I just
>? ? installed it with
>? ? ? >> no problem.
>? ? ? >> I am using a Windows 10 machine with R version 3.4.2.
>? ? ? >>
>? ? ? >> I suggest you provide additional information so that others may
>? ? have ideas.
>? ? ? >> e.g. your operating system version and output from sessionInfo()
>? ? (in R)
>? ? ? >>
>? ? ? >> Best,
>? ? ? >> Eric
>? ? ? >>
>? ? ? >>
>? ? ? >> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia
>? ? <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>>
>? ? ? >> wrote:
>? ? ? >>
>? ? ? >>> Hi,
>? ? ? >>>
>? ? ? >>> Need assistance on installing Rattle.
>? ? ? >>>
>? ? ? >>> I have followed the instructions on https://rattle.togaware.com/
>? ? ? >>> but still facing error installing the package.
>? ? ? >>> ERROR: dependency 'RGtk2' is not available for package 'rattle'.
>? ? ? >>> Have tried installing RGt2 from multiple sources and its still
>? ? failing.
>? ? ? >>>
>? ? ? >>> One of the suggestion on stack overflow was to downgrade the R
>? ? version
>? ? ? >>> here
>? ? ? >>> :
>? ? ? >>>
>? ? ? >>>
>? ? https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>? ? ? >>> Request assistance.
>? ? ? >>>
>? ? ? >>> Regards, Shivi
>? ? ? >>>
>? ? ? >>>? ? ? ? ? [[alternative HTML version deleted]]
>? ? ? >>>
>? ? ? >>> ______________________________________________
>? ? ? >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>? ? -- To UNSUBSCRIBE and more, see
>? ? ? >>> https://stat.ethz.ch/mailman/listinfo/r-help
>? ? ? >>> PLEASE do read the posting guide
>? ? ? >>> http://www.R-project.org/posting-guide.html
>? ? ? >>> and provide commented, minimal, self-contained, reproducible code.
>? ? ? >>>
>? ? ? >>
>? ? ? >>
>? ? ? >
>? ? ? >? ? ? ?[[alternative HTML version deleted]]
>? ? ? >
>? ? ? > ______________________________________________
>? ? ? > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>? ? -- To UNSUBSCRIBE and more, see
>? ? ? > https://stat.ethz.ch/mailman/listinfo/r-help
>? ? ? > PLEASE do read the posting guide
>? ? http://www.R-project.org/posting-guide.html
>? ? ? > and provide commented, minimal, self-contained, reproducible code.
>? ? ? >
> 
>? ? -- 
>? ? Michael
>? ? http://www.dewey.myzen.co.uk/home.html
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html




	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Tue Aug 14 09:49:16 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 14 Aug 2018 10:49:16 +0300
Subject: [R] Cannot set correct miktex path for pdflatex
In-Reply-To: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>
References: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>
Message-ID: <CAGgJW74V+fWR7-rwPSJXHPxe15sAGK-5cdr5M-sJxad-KcbijQ@mail.gmail.com>

Hi Claire,
In Unix (linux) the 'which' command is documented as searching for the
command according to the PATH environment variable.
The different results from
$ which
and
> Sys.which()
would point to the fact that the PATH variable is different in the two
cases.

Compare:
$ echo $PATH

versus

Sys.getenv("PATH")

HTH,
Eric




On Mon, Aug 13, 2018 at 8:18 PM, Kelley, Claire <ckelley at air.org> wrote:

> Hi all,
>
> I am having a problem in R where R is finding an old non existent version
> of miktex rather than the new version. This occurs despite having set the
> path to the correct location.
>
> For example in bash if I look for the location of pdflatex:
>
> $ which pdflatex
> /c/Program Files/MiKTeX 2.9/miktex/bin/x64/pdflatex
>
>
> It points to the correct MikTex installation.
>
> However in R:
>
> Sys.which("pdflatex")
>                                                 pdflatex
> C:\\PROGRA~1\\MIKTEX~1.9\\miktex\\bin\\x64\\pdflatex.exe"
>
> Points to the old  (1.9) version of Miktex.
>
> This is my session info:
>
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.1
>
> Any thoughts?
>
> I have unsuccessfully tried:
>
>
>   1.  Adding correct MikTex path to my Renviorn.site. this adds MikTex to
> my path and I can see the addition, but doesn?t fix the problem
>   2.  Adding MikTex path to my $PATH variable. This lets bash find the
> right version of miktex but doesn?t help in R
>   3.  Making sure I only have on version of MIktex. I don?t have tiny tex
> installed (nor can I because I need the full MIkTex for other work) .
>
>
> Best,
> Claire
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Tue Aug 14 01:13:50 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Mon, 13 Aug 2018 19:13:50 -0400
Subject: [R] Request for help with R program
Message-ID: <CAPQaxLOAYS0q7-wzQ30Df6SL6JkuospJMY7Gvh-SLpvbRqRWcQ@mail.gmail.com>

Good evening,

  I am a high school research student who is partnering with Baylor
University (TX) on a Genomic research project, and was seeking to use the R
program to analysis our data? which is from GDC database. R-3.5.1 is
currently downloaded onto my Windows PC and I am looking to download the
CGDS and GAIA packages, and then to subsequently downloaded and analyze the
Genomic data we have extracted via the R packages. I attempted to utilize
the various help utilities you provide, but I am rather inexperienced with
computer programming and the R program as a whole. Therefore, I am
requesting a screen sharing session and/or phone or email correspondence
with one of your associates so to achieve my goals. Such would be very
helpful to my and my mentors work, and our pending publication.

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]



From @purd|e@@ @end|ng |rom gm@||@com  Tue Aug 14 05:16:08 2018
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Tue, 14 Aug 2018 15:16:08 +1200
Subject: [R] Prevent Printing Function's Environment
Message-ID: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>

Hi All

When you print a function constructed within a function, R prints it's
environment.
For example:

> myfunction = function ()
+ {   f = function () NULL
+     attributes (f) = list (class="myfunction", myattribute=1)
+     f
+ }

> myfunction.f = myfunction ()

> myfunction.f
function ()
NULL
<environment: 0x03fcbc30>
attr(,"class")
[1] "myfunction"
attr(,"myattribute")
[1] 1

One way to prevent this is to set the function's environment to the global
environment.
But I was wondering if there's a way to stop R from printing the
environment without changing the environment?


kind regards
Abs

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 14 10:34:40 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 14 Aug 2018 09:34:40 +0100
Subject: [R] Prevent Printing Function's Environment
In-Reply-To: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>
References: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>
Message-ID: <ff749e3e-5467-a3a7-8d7f-89073be90fae@sapo.pt>

Hello,

I am not sure I understand the question.
You say that

One way to prevent this [to print the attributes] is to set the 
function's environment to the global environment.

But this is not true, just see the example below, where I set the 
function's environment to .GlobalEnv


myfunction2 = function (){
   f = function () NULL
   attributes (f) = list (class="myfunction2", myattribute2=1)
   environment(f) <- .GlobalEnv
   f
}

myfunction2.f = myfunction2 ()

myfunction2.f
#function ()
#  NULL
#attr(,"class")
#[1] "myfunction2"
#attr(,"myattribute2")
#[1] 1

environment(myfunction2.f)
#<environment: R_GlobalEnv>


When you run the function's name, the function's definition is printed, 
all of it. If you want to print its return value you have to call it 
with the parenthesis:

myfunction2.f()    # My function
#NULL

myfunction.f()     # Your function
#NULL


If you want to print the body of the function, use, well, body().

body(myfunction.f)
#NULL


Hope this helps,

Rui Barradas
?s 04:16 de 14/08/2018, Abs Spurdle escreveu:
> Hi All
> 
> When you print a function constructed within a function, R prints it's
> environment.
> For example:
> 
>> myfunction = function ()
> + {   f = function () NULL
> +     attributes (f) = list (class="myfunction", myattribute=1)
> +     f
> + }
> 
>> myfunction.f = myfunction ()
> 
>> myfunction.f
> function ()
> NULL
> <environment: 0x03fcbc30>
> attr(,"class")
> [1] "myfunction"
> attr(,"myattribute")
> [1] 1
> 
> One way to prevent this is to set the function's environment to the global
> environment.
> But I was wondering if there's a way to stop R from printing the
> environment without changing the environment?
> 
> 
> kind regards
> Abs
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Aug 14 10:58:45 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 14 Aug 2018 10:58:45 +0200
Subject: [R] Prevent Printing Function's Environment
In-Reply-To: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>
References: <CAB8pepx4mQPwaHzQ9HMh_6R6Qfge17ZxZLRLreCamewat8ck9Q@mail.gmail.com>
Message-ID: <23410.39365.388183.563907@stat.math.ethz.ch>

>>>>> Abs Spurdle 
>>>>>     on Tue, 14 Aug 2018 15:16:08 +1200 writes:

    > Hi All

    > When you print a function constructed within a function, R
    > prints it's environment.  For example:

     > > myfunction = function ()
     > + {   f = function () NULL
     > +     attributes (f) = list (class="myfunction", myattribute=1)
     > +     f
     > + }

     > > myfunction.f = myfunction ()

     > > myfunction.f
     > function ()
     > NULL
     > <environment: 0x03fcbc30>
     > attr(,"class")
     > [1] "myfunction"
     > attr(,"myattribute")
     > [1] 1

     > One way to prevent this is to set the function's environment to the global
     > environment.
     > But I was wondering if there's a way to stop R from printing the
     > environment without changing the environment?

Probably, not the way you want, but if you need it e.g., for
didactical reasons, here's a way that may be didactically
relevant in it self:

  > ls.str
  function (pos = -1, name, envir, all.names = FALSE, pattern, 
      mode = "any") 
  {
      if (missing(envir)) 
	  envir <- as.environment(pos)
      nms <- ls(name, envir = envir, all.names = all.names, pattern = pattern)
      r <- unlist(lapply(nms, function(n) exists(n, envir = envir, 
	  mode = mode, inherits = FALSE)))
      structure(nms[r], envir = envir, mode = mode, class = "ls_str")
  }
  <bytecode: 0xb222858>
  <environment: namespace:utils>

so, I want to suppress the last two lines that are printed.
That's a piece of cake if you know  capture.output() :

  > P2 <- function(.) writeLines(head(capture.output(.), -2))
  > P2(ls.str)
  function (pos = -1, name, envir, all.names = FALSE, pattern, 
      mode = "any") 
  {
      if (missing(envir)) 
	  envir <- as.environment(pos)
      nms <- ls(name, envir = envir, all.names = all.names, pattern = pattern)
      r <- unlist(lapply(nms, function(n) exists(n, envir = envir, 
	  mode = mode, inherits = FALSE)))
      structure(nms[r], envir = envir, mode = mode, class = "ls_str")
  }
  >



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 14 10:20:35 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 14 Aug 2018 09:20:35 +0100
Subject: [R] searching for a specific row name in R
In-Reply-To: <CAGchuN5A4=mdGbynBZf4Mk3256rB5c07Htw9OR28fpM09Dd1Lg@mail.gmail.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
 <11492AAE-6888-4D90-B408-F020FAD5DFC3@utoronto.ca>
 <CAGchuN5A4=mdGbynBZf4Mk3256rB5c07Htw9OR28fpM09Dd1Lg@mail.gmail.com>
Message-ID: <53204ebd-0403-f5bd-9eee-c1beff3caf24@sapo.pt>

Hello,

If you have one hundred identifier names that you want to check the 
result of

id %in% column

will have length 100, the same as length(id).
If you want a shorter result you can do

which(id %in% column)

This will give you only the TRUE values.

Hope this helps,

Rui Barradas


?s 05:16 de 14/08/2018, Deepa escreveu:
> I have a hundred identifier names that I want to check from the second
> column of a matrix with 6000 entries in the column.
> Instead of using  R > c("d", "v", "4", "s") %in% letters , is there an
> alternative?
> 
> I have the hundred identifier names that are of my interest stored in an
> array.
> 
> 
> 
> 
> On Tue, Aug 14, 2018 at 9:16 AM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> 
>> Use the %in% operator:
>>
>> help('%in%')
>>
>> e.g.
>>
>> R > c("d", "v", "4", "s") %in% letters
>> [1]  TRUE  TRUE FALSE  TRUE
>>
>>
>> B.
>>
>>
>>> On 2018-08-13, at 23:36, Deepa <deepamahm.iisc at gmail.com> wrote:
>>>
>>> Hi Don,
>>>
>>> When there is a list of identifier names that I want to check, the only
>> way
>>> is to loop over each entry stored in the list of identifier names or is
>>> there is there any other shortcut?
>>>
>>> Many thanks for the response?
>>>
>>> On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov>
>> wrote:
>>>
>>>> Or to return a logical value, i.e., TRUE if the column contains the
>> value,
>>>> FALSE if it does not:
>>>>
>>>>   any( x[,2] == 'A501' )
>>>>
>>>> -Don
>>>> --
>>>> Don MacQueen
>>>> Lawrence Livermore National Laboratory
>>>> 7000 East Ave., L-627
>>>> Livermore, CA 94550
>>>> 925-423-1062
>>>> Lab cell 925-724-7509
>>>>
>>>>
>>>>
>>>> ?On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <
>>>> r-help-bounces at r-project.org on behalf of alkauffm at fastmail.fm> wrote:
>>>>
>>>>     Hello Deepa,
>>>>
>>>>     sum(x[,2] == "A501")
>>>>     or
>>>>     which(x[,2] == "A501")
>>>>     .
>>>>     Best,
>>>>     Albrecht
>>>>
>>>>
>>>>     --
>>>>       Albrecht Kauffmann
>>>>       alkauffm at fastmail.fm
>>>>
>>>>     Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
>>>>> Hello Everyone,
>>>>>
>>>>> I have a 1000 x 20 matrix. The second column of the matrix has the
>>>> names
>>>>> of identifiers. How do I check when a certain identifier is present
>>>> in
>>>>> the set of 1000 identifier names present in the second column. For
>>>>> instance, let the names of identifiers be A1,A2,...A1000. I want to
>>>>> check whether A501 is present .How can this be checked?
>>>>>
>>>>> Any help will be highly appreciated.
>>>>>
>>>>>
>>>>>   [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>     ______________________________________________
>>>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>>     PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>>     and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Aug 14 12:28:37 2018
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 14 Aug 2018 11:28:37 +0100
Subject: [R] Assistance on Installing Rattle
In-Reply-To: <630087097.36649.1534186059024@mail.yahoo.com>
References: <CAB=p7SrMfxJU=xueAhhoXTL_MjwgAndwVQ8g3WH3TasmjqGW2A@mail.gmail.com>
 <CAGgJW76Mt4THjf737+uTryrh_wVF-JXcGWfwOJMHZtUta54nFw@mail.gmail.com>
 <CAB=p7SrTSYSGSNzzsQ_y7V2wmLoh9At3b0iNGTed4P_LmOO60w@mail.gmail.com>
 <0b89c9d1-949b-a78a-1d6f-558df6bc0bbe@dewey.myzen.co.uk>
 <CAB=p7Sqm=dKODdofxGT_HjxmN6j6MTWWFx1NaubjKG87+7sxzg@mail.gmail.com>
 <3d221e3e-52f0-fffe-f70d-31e43845fc57@dewey.myzen.co.uk>
 <630087097.36649.1534186059024@mail.yahoo.com>
Message-ID: <db3b8bf6-b720-0ad7-7e17-3a4807c979c1@dewey.myzen.co.uk>

Dear Shivi

The current version is on CRAN so why not use that?

install.packages("RGtk2")

should install version 2.30.35
If it does not then try another mirror

Michael

On 13/08/2018 19:47, Shivi Bhatia wrote:
> Hi Michael
> Thank you for the reply.
> I have been looking for 3.5.1 version of this package but I cannot find 
> one, would you recommend downgrading my current R version.
> Would there be some or any other compatibly issue - please advice.
> 
> Thank you, Shivi
> 
> 
> Sent from Yahoo Mail for iPhone <https://overview.mail.yahoo.com/?.src=iOS>
> 
> On Monday, August 13, 2018, 21:56, Michael Dewey 
> <lists at dewey.myzen.co.uk> wrote:
> 
>     Dear Shivi
> 
>     You are running R 3.5.1 according to your session info. Why are you
>     installing a version for R 3.3? Note that the up-to-date version
>     depends
>     on R > 3.4.0 so it is no surprise that you get problems.
> 
>     Michael
> 
>     On 13/08/2018 16:07, Shivi Bhatia wrote:
>      > Hi Michael,
>      >
>      > I was able to install RGtk2
>      >
>     from?install.packages("https://cran.r-project.org/bin/windows/contrib/3.3/RGtk2_2.20.31.zip",
> 
>      > repos=NULL) but after installing this and trying to install
>     rattle i get
>      > this error:
>      > Error : package 'RGtk2' was installed by an R version with different
>      > internals; it needs to be reinstalled for use with this R version
>      > ERROR: lazy loading failed for package 'rattle'
>      >
>      > I tried installing rattle from?install.packages("rattle",
>      > repos="https://rattle.togaware.com", type="source").
>      >
>      > Regards, Shivi
>      >
>      >
>      > On Sun, Aug 12, 2018 at 7:20 PM Michael Dewey
>     <lists at dewey.myzen.co.uk <mailto:lists at dewey.myzen.co.uk>
>      > <mailto:lists at dewey.myzen.co.uk
>     <mailto:lists at dewey.myzen.co.uk>>> wrote:
>      >
>      >? ? Dear Shivi
>      >
>      >? ? What error message do you get when you try to install RGtk2?
>      >
>      >? ? Michael
>      >
>      >? ? On 12/08/2018 11:49, Shivi Bhatia wrote:
>      >? ? ? > Hi Eric,
>      >? ? ? >
>      >? ? ? > Thank you for the reply. I am adding the session details
>     below,
>      >? ? hope it
>      >? ? ? > helps:
>      >? ? ? > R version 3.5.1 (2018-07-02)
>      >? ? ? > Platform: x86_64-w64-mingw32/x64 (64-bit)
>      >? ? ? > Running under: Windows >= 8 x64 (build 9200)
>      >? ? ? >
>      >? ? ? > Matrix products: default
>      >? ? ? > locale:
>      >? ? ? > [1] LC_COLLATE=English_India.1252? LC_CTYPE=English_India.1252
>      >? ? ? > LC_MONETARY=English_India.1252
>      >? ? ? > [4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ?LC_TIME=English_India.1252
>      >? ? ? >
>      >? ? ? > attached base packages:
>      >? ? ? > [1] stats? ? ?graphics? grDevices utils? ? ?datasets 
>     methods? ?base
>      >? ? ? >
>      >? ? ? > Thanks.
>      >? ? ? >
>      >? ? ? > On Sat, Aug 11, 2018 at 9:38 PM Eric Berger
>      >? ? <ericjberger at gmail.com <mailto:ericjberger at gmail.com>
>     <mailto:ericjberger at gmail.com <mailto:ericjberger at gmail.com>>> wrote:
>      >? ? ? >
>      >? ? ? >> Hi Shivi,
>      >? ? ? >> I have no experience with the rattle package but I just
>      >? ? installed it with
>      >? ? ? >> no problem.
>      >? ? ? >> I am using a Windows 10 machine with R version 3.4.2.
>      >? ? ? >>
>      >? ? ? >> I suggest you provide additional information so that
>     others may
>      >? ? have ideas.
>      >? ? ? >> e.g. your operating system version and output from
>     sessionInfo()
>      >? ? (in R)
>      >? ? ? >>
>      >? ? ? >> Best,
>      >? ? ? >> Eric
>      >? ? ? >>
>      >? ? ? >>
>      >? ? ? >> On Sat, Aug 11, 2018 at 6:55 PM, Shivi Bhatia
>      >? ? <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>
>     <mailto:shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>>>
>      >? ? ? >> wrote:
>      >? ? ? >>
>      >? ? ? >>> Hi,
>      >? ? ? >>>
>      >? ? ? >>> Need assistance on installing Rattle.
>      >? ? ? >>>
>      >? ? ? >>> I have followed the instructions on
>     https://rattle.togaware.com/
>      >? ? ? >>> but still facing error installing the package.
>      >? ? ? >>> ERROR: dependency 'RGtk2' is not available for package
>     'rattle'.
>      >? ? ? >>> Have tried installing RGt2 from multiple sources and its
>     still
>      >? ? failing.
>      >? ? ? >>>
>      >? ? ? >>> One of the suggestion on stack overflow was to downgrade
>     the R
>      >? ? version
>      >? ? ? >>> here
>      >? ? ? >>> :
>      >? ? ? >>>
>      >? ? ? >>>
>      >
>     https://stackoverflow.com/questions/24913643/downgrade-r-version-no-issues-with-bioconductor-installation
>      >? ? ? >>> Request assistance.
>      >? ? ? >>>
>      >? ? ? >>> Regards, Shivi
>      >? ? ? >>>
>      >? ? ? >>>? ? ? ? ? [[alternative HTML version deleted]]
>      >? ? ? >>>
>      >? ? ? >>> ______________________________________________
>      >? ? ? >>> R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list
>      >? ? -- To UNSUBSCRIBE and more, see
>      >? ? ? >>> https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? >>> PLEASE do read the posting guide
>      >? ? ? >>> http://www.R-project.org/posting-guide.html
>      >? ? ? >>> and provide commented, minimal, self-contained,
>     reproducible code.
>      >? ? ? >>>
>      >? ? ? >>
>      >? ? ? >>
>      >? ? ? >
>      >? ? ? >? ? ? ?[[alternative HTML version deleted]]
>      >? ? ? >
>      >? ? ? > ______________________________________________
>      >? ? ? > R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list
>      >? ? -- To UNSUBSCRIBE and more, see
>      >? ? ? > https://stat.ethz.ch/mailman/listinfo/r-help
>      >? ? ? > PLEASE do read the posting guide
>      > http://www.R-project.org/posting-guide.html
>      >? ? ? > and provide commented, minimal, self-contained,
>     reproducible code.
>      >? ? ? >
>      >
>      >? ? --
>      >? ? Michael
>      > http://www.dewey.myzen.co.uk/home.html
> 
>      >
> 
>     -- 
>     Michael
>     http://www.dewey.myzen.co.uk/home.html
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



From pd@|gd @end|ng |rom gm@||@com  Tue Aug 14 13:01:39 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 14 Aug 2018 13:01:39 +0200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
Message-ID: <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>

Hmm, 

> .Fortran(stats:::C_setsmu, as.integer(0))
[[1]]
[1] 0

> .Fortran(stats:::C_setsmu, as.integer(fumble))
Error: object 'fumble' not found
> .Fortran(stats:::C_setsmu, fumble=as.integer(fumble))
Error: object 'fumble' not found
> .Fortran(stats:::C_setsmu, nphi=as.integer(nphi))
Error: object 'nphi' not found

so I think we need an alternative hypothesis about what went wrong for you... 

If nphi was NULL from the outset, that could explain things.

-pd


> On 14 Aug 2018, at 01:16 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 13/08/18 23:39, peter dalgaard wrote:
>> It's odd, possibly a bug, that you don't get
>> Error: object 'nphi' not found
>> but I can't offhand see where the evaluation of args to .C/.Fortran is supposed to take place.
> 
> If it is indeed a bug then it would be nice an it were fixed.  If that is possible.  Way beyond my level of comprehension but.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From |@t@z@hn @end|ng |rom gm@||@com  Tue Aug 14 15:46:35 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Tue, 14 Aug 2018 09:46:35 -0400
Subject: [R] Fast matrix multiplication
In-Reply-To: <54d4ce0aa9cc4a92bb0a534f734586c5@jhu.edu>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
 <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
 <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
 <54d4ce0aa9cc4a92bb0a534f734586c5@jhu.edu>
Message-ID: <CA+vqiLFVyHhHX+WDmXpBZkz3XiBQ9nwn_0g_vLSpRoxV8nyXtg@mail.gmail.com>

On Tue, Aug 14, 2018 at 9:41 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Does Microsoft open R come with pre-compiled BLAS that is optimized for matrix computations?

Yes, see https://mran.microsoft.com/rro#intelmkl1 for details.

--Ista

>
> Thanks,
> Ravi
>
> -----Original Message-----
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Monday, August 13, 2018 3:18 PM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] Fast matrix multiplication
>
>
> On Mon, Aug 13, 2018 at 2:41 PM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> >
> > Hi Ista,
> > Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?
>
> Not sure. If you want an easy way I would use MRO. More info at
> https://mran.microsoft.com/rro#intelmkl1
>
> --Ista
>
> > Thanks,
> > Ravi
> >
> > -----Original Message-----
> > From: Ista Zahn <istazahn at gmail.com>
> > Sent: Friday, August 10, 2018 12:20 PM
> > To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Fast matrix multiplication
> >
> >
> > Hi Ravi,
> >
> > You can achieve substantial speed up by using a faster BLAS (e.g., OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6 year old, but 8 core) system your example takes 3.9 seconds with using the reference BLAS and only 0.9 seconds using OpenBLAS.
> >
> > Best,
> > Ista
> > On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> > >
> > > Hi,
> > >
> > > I would like to compute:  A %*% B %*% t(A)
> > >
> > >
> > >
> > > A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
> > >
> > >
> > >
> > > Here is a sample code.
> > >
> > >
> > >
> > > M <- 10000
> > >
> > > N <- 100
> > >
> > > A <- matrix(rnorm(M*N), M, N)
> > >
> > > B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric
> > > positive-definite matrix
> > >
> > >
> > >
> > > # method 1
> > >
> > > system.time(D <- A %*% B %*% t(A))
> > >
> > >
> > >
> > > # I can obtain speedup by using a Cholesky decomposition of B
> > >
> > > # method 2
> > >
> > > system.time({
> > >
> > > C <- t(chol(B))
> > >
> > > E <- tcrossprod(A%*%C)
> > >
> > > })
> > >
> > >
> > >
> > > all.equal(D, E)
> > >
> > >
> > >
> > > I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
> > >
> > >
> > >
> > > Thanks,
> > >
> > > Ravi
> > >
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>



From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Tue Aug 14 15:41:36 2018
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Tue, 14 Aug 2018 13:41:36 +0000
Subject: [R] Fast matrix multiplication
In-Reply-To: <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
References: <6621daa5b470485eb0aac67d3ca778ef@jhu.edu>
 <CA+vqiLF4Pn5UV9jB2bGBSivNo5ePW2R+GyVmSC4r7cd7gLZ_DQ@mail.gmail.com>
 <3fc785fb7ef1490ba08a25db0cf399d0@jhu.edu>
 <CA+vqiLHD_Dp-k7Vh64mXyxdWN_zj42yeC35t8Um4Jrr6d_+XyQ@mail.gmail.com>
Message-ID: <54d4ce0aa9cc4a92bb0a534f734586c5@jhu.edu>

Does Microsoft open R come with pre-compiled BLAS that is optimized for matrix computations?

Thanks,
Ravi

-----Original Message-----
From: Ista Zahn <istazahn at gmail.com> 
Sent: Monday, August 13, 2018 3:18 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: r-help at r-project.org
Subject: Re: [R] Fast matrix multiplication


On Mon, Aug 13, 2018 at 2:41 PM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>
> Hi Ista,
> Thank you for the response.  I use Windows.  Is there a pre-compiled version of openBLAS for windows that would make it easy for me to use it?

Not sure. If you want an easy way I would use MRO. More info at
https://mran.microsoft.com/rro#intelmkl1

--Ista

> Thanks,
> Ravi
>
> -----Original Message-----
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Friday, August 10, 2018 12:20 PM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] Fast matrix multiplication
>
>
> Hi Ravi,
>
> You can achieve substantial speed up by using a faster BLAS (e.g., OpenBLAS or MKL), especially on systems with multiple CPUs. On my (6 year old, but 8 core) system your example takes 3.9 seconds with using the reference BLAS and only 0.9 seconds using OpenBLAS.
>
> Best,
> Ista
> On Fri, Aug 10, 2018 at 11:46 AM Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> >
> > Hi,
> >
> > I would like to compute:  A %*% B %*% t(A)
> >
> >
> >
> > A is a mxn matrix and B is an nxn symmetric, positive-definite matrix, where m is large relative to n (e.g., m=50,000 and n=100).
> >
> >
> >
> > Here is a sample code.
> >
> >
> >
> > M <- 10000
> >
> > N <- 100
> >
> > A <- matrix(rnorm(M*N), M, N)
> >
> > B <- crossprod(matrix(rnorm(N*N), N, N)) # creating a symmetric 
> > positive-definite matrix
> >
> >
> >
> > # method 1
> >
> > system.time(D <- A %*% B %*% t(A))
> >
> >
> >
> > # I can obtain speedup by using a Cholesky decomposition of B
> >
> > # method 2
> >
> > system.time({
> >
> > C <- t(chol(B))
> >
> > E <- tcrossprod(A%*%C)
> >
> > })
> >
> >
> >
> > all.equal(D, E)
> >
> >
> >
> > I am wondering how to obtain more substantial speedup.  Any suggestions would be greatly appreciated.
> >
> >
> >
> > Thanks,
> >
> > Ravi
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From rmh @end|ng |rom temp|e@edu  Tue Aug 14 17:03:47 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 14 Aug 2018 11:03:47 -0400
Subject: [R] Cannot set correct miktex path for pdflatex
In-Reply-To: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>
References: <7B286890-A924-40EE-8D81-A1382C12AE5A@air.org>
Message-ID: <CAGx1TMBUKR=QV6ENzzrqxwT+3MD9YZ-k=yZZGRX+b_BveZa4+w@mail.gmail.com>

You are getting the correct version.  R is using the 8.3 version of the path.
MS DOS often can't handle long MS Windows pathnames, particularly with
blank space characters.
MS therefore provides an 8.3 equivalent for all long names.

C:\>dir /x prog*
dir /x prog*
 Volume in drive C has no label.
 Volume Serial Number is 188D-5BB8

 Directory of C:\

12/03/2017  03:39 PM    <DIR>          PROGRA~1     Program Files
05/17/2018  03:02 AM    <DIR>          PROGRA~2     Program Files (x86)
               0 File(s)              0 bytes
               2 Dir(s)   1,257,172,992 bytes free

C:\>dir /x progra~1\Miktex*
dir /x progra~1\Miktex*
 Volume in drive C has no label.
 Volume Serial Number is 188D-5BB8

 Directory of C:\progra~1

12/18/2015  09:50 PM    <DIR>          MIKTEX~1.9   MiKTeX 2.9
               0 File(s)              0 bytes
               1 Dir(s)   1,257,172,992 bytes free

C:\>
C:\>dir /?
dir /?
Displays a list of files and subdirectories in a directory.

DIR [drive:][path][filename] [/A[[:]attributes]] [/B] [/C] [/D] [/L] [/N]
  [/O[[:]sortorder]] [/P] [/Q] [/R] [/S] [/T[[:]timefield]] [/W] [/X] [/4]

  [drive:][path][filename]
              Specifies drive, directory, and/or files to list.

  /A          Displays files with specified attributes.
  attributes   D  Directories                R  Read-only files
               H  Hidden files               A  Files ready for archiving
               S  System files               I  Not content indexed files
               L  Reparse Points             -  Prefix meaning not
  /B          Uses bare format (no heading information or summary).
  /C          Display the thousand separator in file sizes.  This is the
              default.  Use /-C to disable display of separator.
  /D          Same as wide but files are list sorted by column.
  /L          Uses lowercase.
  /N          New long list format where filenames are on the far right.
  /O          List by files in sorted order.
  sortorder    N  By name (alphabetic)       S  By size (smallest first)
               E  By extension (alphabetic)  D  By date/time (oldest first)
               G  Group directories first    -  Prefix to reverse order
  /P          Pauses after each screenful of information.
  /Q          Display the owner of the file.
  /R          Display alternate data streams of the file.
  /S          Displays files in specified directory and all subdirectories.
  /T          Controls which time field displayed or used for sorting
  timefield   C  Creation
              A  Last Access
              W  Last Written
  /W          Uses wide list format.
  /X          This displays the short names generated for non-8dot3 file
              names.  The format is that of /N with the short name inserted
              before the long name. If no short name is present, blanks are
              displayed in its place.
  /4          Displays four-digit years

Switches may be preset in the DIRCMD environment variable.  Override
preset switches by prefixing any switch with - (hyphen)--for example, /-W.

On Mon, Aug 13, 2018 at 1:18 PM, Kelley, Claire <ckelley at air.org> wrote:
> Hi all,
>
> I am having a problem in R where R is finding an old non existent version of miktex rather than the new version. This occurs despite having set the path to the correct location.
>
> For example in bash if I look for the location of pdflatex:
>
> $ which pdflatex
> /c/Program Files/MiKTeX 2.9/miktex/bin/x64/pdflatex
>
>
> It points to the correct MikTex installation.
>
> However in R:
>
> Sys.which("pdflatex")
>                                                 pdflatex
> C:\\PROGRA~1\\MIKTEX~1.9\\miktex\\bin\\x64\\pdflatex.exe"
>
> Points to the old  (1.9) version of Miktex.
>
> This is my session info:
>
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.1
>
> Any thoughts?
>
> I have unsuccessfully tried:
>
>
>   1.  Adding correct MikTex path to my Renviorn.site. this adds MikTex to my path and I can see the addition, but doesn?t fix the problem
>   2.  Adding MikTex path to my $PATH variable. This lets bash find the right version of miktex but doesn?t help in R
>   3.  Making sure I only have on version of MIktex. I don?t have tiny tex installed (nor can I because I need the full MIkTex for other work) .
>
>
> Best,
> Claire
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 14 17:12:02 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 14 Aug 2018 08:12:02 -0700
Subject: [R] Request for help with R program
In-Reply-To: <CAPQaxLOAYS0q7-wzQ30Df6SL6JkuospJMY7Gvh-SLpvbRqRWcQ@mail.gmail.com>
References: <CAPQaxLOAYS0q7-wzQ30Df6SL6JkuospJMY7Gvh-SLpvbRqRWcQ@mail.gmail.com>
Message-ID: <CAGxFJbQcW0rV0Sdjp8fKsSC0A4s2k2g7tCX87r072eyBVT3ngg@mail.gmail.com>

R has no "associates". It is open source software with many users and
developers with varying skill levels and interests.

I think you are in over your head ("inexperienced in computer programming")
and should seek local resources at Baylor to help you. This list probably
cannot provide the level of assistance you seek.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Aug 13, 2018 at 4:13 PM, Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Good evening,
>
>   I am a high school research student who is partnering with Baylor
> University (TX) on a Genomic research project, and was seeking to use the R
> program to analysis our data? which is from GDC database. R-3.5.1 is
> currently downloaded onto my Windows PC and I am looking to download the
> CGDS and GAIA packages, and then to subsequently downloaded and analyze the
> Genomic data we have extracted via the R packages. I attempted to utilize
> the various help utilities you provide, but I am rather inexperienced with
> computer programming and the R program as a whole. Therefore, I am
> requesting a screen sharing session and/or phone or email correspondence
> with one of your associates so to achieve my goals. Such would be very
> helpful to my and my mentors work, and our pending publication.
>
> Many thanks,
>
> Spencer Brackett
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Tue Aug 14 21:46:48 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Tue, 14 Aug 2018 12:46:48 -0700
Subject: [R] Changing PDF orientation midstream
Message-ID: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>

Hi, I'm wondering whether it is possible to change the orientation of the PDF in the middle of the document. In other words, pages 1,2,3 - portrait, pages 4,5 - landscape, etc. 

This is how I call it -

pdf (file, paper="US") or USr for landscape 


Thanks!



From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 14 22:20:26 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 14 Aug 2018 13:20:26 -0700
Subject: [R] Changing PDF orientation midstream
In-Reply-To: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>
References: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>
Message-ID: <CAGxFJbTcUwKrPR83nfOFzHrfYQrJ-myTu53k37iTS-e73S3vog@mail.gmail.com>

1. Probably not. But I'm no pdf expert.

2. This adobe thread may be relevant:

https://forums.adobe.com/thread/1091826

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 14, 2018 at 12:46 PM, Stats Student <stats.student4647 at gmail.com
> wrote:

> Hi, I'm wondering whether it is possible to change the orientation of the
> PDF in the middle of the document. In other words, pages 1,2,3 - portrait,
> pages 4,5 - landscape, etc.
>
> This is how I call it -
>
> pdf (file, paper="US") or USr for landscape
>
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From pro|jcn@@h @end|ng |rom gm@||@com  Tue Aug 14 22:27:54 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Tue, 14 Aug 2018 16:27:54 -0400
Subject: [R] Changing PDF orientation midstream
In-Reply-To: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>
References: <dacfeb3e-37e8-4c78-9a48-8d6f0192b435@gmail.com>
Message-ID: <d25fe17e-a1e0-65a5-7720-9a7d5d7dcc4a@gmail.com>

Not an R issue, but for linux users pdf-shuffler is a great tool

JN

On 2018-08-14 03:46 PM, Stats Student wrote:
> Hi, I'm wondering whether it is possible to change the orientation of the PDF in the middle of the document. In other words, pages 1,2,3 - portrait, pages 4,5 - landscape, etc. 
> 
> This is how I call it -
> 
> pdf (file, paper="US") or USr for landscape 
> 
> 
> Thanks!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From cdeterm@njr @end|ng |rom gm@||@com  Tue Aug 14 22:43:12 2018
From: cdeterm@njr @end|ng |rom gm@||@com (Charles Determan)
Date: Tue, 14 Aug 2018 15:43:12 -0500
Subject: [R] FPMC?
Message-ID: <CAKxd1KN+Fmn47Z-PvuEnuixM4yarXSYXZ791Gddw3wKUSHfw=g@mail.gmail.com>

Greetings R users,

I recently came across an interesting paper regarding recommender systems.
The particular method defined in the manuscript was Factorizing
Personalized Markov Chains.  You can find the article in question here (
http://www.ra.ethz.ch/cdstore/www2010/www/p811.pdf).  I am curious if
anyone here has ever come across anything like this before in the R
community.  I have found multiple packages on Markov Chains but nothing
with respect to combining them with matrix factorization.  I will continue
to search around but thought I would pose the question here as well.

Regards,
Charles

	[[alternative HTML version deleted]]



From tmg1970 @end|ng |rom gm@||@com  Tue Aug 14 17:48:54 2018
From: tmg1970 @end|ng |rom gm@||@com (Tania Morgado Garcia)
Date: Tue, 14 Aug 2018 10:48:54 -0500
Subject: [R] Spline function
Message-ID: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>

 Hello everyone. I'm new to R and I'm using spline functions. With the
command splinefun (x, y) I get the function of interpolating the values x
and y. Later, I can evaluate that function for values of x by obtaining the
respective values of y. The point is that I need the inverse operation,
with the function, for a value of Y I need to know the value of x. Could
you please help me?
A cordial greeting

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 15 00:22:38 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 14 Aug 2018 15:22:38 -0700
Subject: [R] Spline function
In-Reply-To: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
References: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
Message-ID: <CAGxFJbQTGK3gHYOBQfooYyY8h4scEY7ick0gRYR0zeVK-MGf5A@mail.gmail.com>

If I understand correctly, not in general possible.

Suppose for a bunch of different x's the y's are all constant =0. What x
would correspond to y = 1.

Or suppose (x,y) pairs trace a sine function over several periods. Then
there is no unique x corresponding to y = .5, say.

Perhaps if you more explicitly specified the nature of your problem (e.g.
is y monotonic in x?) some assistance might be provided.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Aug 14, 2018 at 8:48 AM, Tania Morgado Garcia <tmg1970 at gmail.com>
wrote:

>  Hello everyone. I'm new to R and I'm using spline functions. With the
> command splinefun (x, y) I get the function of interpolating the values x
> and y. Later, I can evaluate that function for values of x by obtaining the
> respective values of y. The point is that I need the inverse operation,
> with the function, for a value of Y I need to know the value of x. Could
> you please help me?
> A cordial greeting
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From 538280 @end|ng |rom gm@||@com  Wed Aug 15 00:33:58 2018
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Tue, 14 Aug 2018 16:33:58 -0600
Subject: [R] Spline function
In-Reply-To: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
References: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
Message-ID: <CAFEqCdyL_o-89yVyiJJLB1qpcNm0LSGHdcfOr1SXhW5ZqE5=eA@mail.gmail.com>

The uniroot function can be used to find a value in a specified
interval, if it exists.
On Tue, Aug 14, 2018 at 3:30 PM Tania Morgado Garcia <tmg1970 at gmail.com> wrote:
>
>  Hello everyone. I'm new to R and I'm using spline functions. With the
> command splinefun (x, y) I get the function of interpolating the values x
> and y. Later, I can evaluate that function for values of x by obtaining the
> respective values of y. The point is that I need the inverse operation,
> with the function, for a value of Y I need to know the value of x. Could
> you please help me?
> A cordial greeting
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com



From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Aug 15 00:40:58 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 15 Aug 2018 10:40:58 +1200
Subject: [R] [FORGED]  Spline function
In-Reply-To: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
References: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
Message-ID: <04e90632-25a3-6726-5f83-401c6e86b6ea@auckland.ac.nz>


On 15/08/18 03:48, Tania Morgado Garcia wrote:

>   Hello everyone. I'm new to R and I'm using spline functions. With the
> command splinefun (x, y) I get the function of interpolating the values x
> and y. Later, I can evaluate that function for values of x by obtaining the
> respective values of y. The point is that I need the inverse operation,
> with the function, for a value of Y I need to know the value of x. Could
> you please help me?

Your question is ill-posed.  There could easily be multiple x values 
corresponding to a single y value, unless the spline function is monotone.

If you can specify an interval which encloses the x value that you are 
trying to and over which the spline function is monotone, then uniroot() 
might provide what you want.

Something like:

    spf <- splinefun(x,y)
    uniroot(f=function(x){spf-y0},interval=c(a,b))

where y0 is the y value for which you want the corresponding x value,
where spf() is monotone on [a,b], and where there *exists* an x value 
between a and b such that spf(x) = y0.

Good luck.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Aug 15 01:12:00 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 15 Aug 2018 11:12:00 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
 <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
Message-ID: <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>

On 14/08/18 23:01, peter dalgaard wrote:
> Hmm,
> 
>> .Fortran(stats:::C_setsmu, as.integer(0))
> [[1]]
> [1] 0
> 
>> .Fortran(stats:::C_setsmu, as.integer(fumble))
> Error: object 'fumble' not found
>> .Fortran(stats:::C_setsmu, fumble=as.integer(fumble))
> Error: object 'fumble' not found
>> .Fortran(stats:::C_setsmu, nphi=as.integer(nphi))
> Error: object 'nphi' not found
> 
> so I think we need an alternative hypothesis about what went wrong for you...
> 
> If nphi was NULL from the outset, that could explain things.

No, I never set nphi to NULL.

I put the code back to the way it was previously, just now, and tried 
again. Now I get "object 'nphi' not found".

There is no explanation other than gremlins and the malevolence that the 
computer gods hold towards me.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Aug 15 01:35:08 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 14 Aug 2018 19:35:08 -0400
Subject: [R] Spline function
In-Reply-To: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
References: <CAGObTgoswDbimGHvNfAa26-xah-05iYLPnD4MD+2TVuvQER6PA@mail.gmail.com>
Message-ID: <561b4d57-350d-3e30-12f5-4881d6038f2e@gmail.com>

On 14/08/2018 11:48 AM, Tania Morgado Garcia wrote:
>   Hello everyone. I'm new to R and I'm using spline functions. With the
> command splinefun (x, y) I get the function of interpolating the values x
> and y. Later, I can evaluate that function for values of x by obtaining the
> respective values of y. The point is that I need the inverse operation,
> with the function, for a value of Y I need to know the value of x. Could
> you please help me?

Others have pointed out uniroot().  One other possibility:  maybe you 
don't need both the function and its inverse, or an approximate inverse 
is good enough.  In either of those cases, just swap x and y in the call 
to splinefun(), and you'll get a new function mapping y values to the 
corresponding x values.  (You'll get nonsense or an error in cases where 
this mapping is not unique.)  It won't match the inverse of the original 
spline interpolator except at observed (x,y) pairs, but will usually be 
close, especially if the functions are pretty smooth.

Duncan Murdoch



From rmh @end|ng |rom temp|e@edu  Wed Aug 15 03:00:41 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 14 Aug 2018 21:00:41 -0400
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
 <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
 <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>
Message-ID: <CAGx1TMDq5QTcQ7pK3Z3EghSS9s9mCEvcd-+vcMvYcqcNtqSG3Q@mail.gmail.com>

There is no explanation other than gremlins and the malevolence that
the computer gods hold towards me.

fortune nomination.

On Tue, Aug 14, 2018 at 7:12 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 14/08/18 23:01, peter dalgaard wrote:
>>
>> Hmm,
>>
>>> .Fortran(stats:::C_setsmu, as.integer(0))
>>
>> [[1]]
>> [1] 0
>>
>>> .Fortran(stats:::C_setsmu, as.integer(fumble))
>>
>> Error: object 'fumble' not found
>>>
>>> .Fortran(stats:::C_setsmu, fumble=as.integer(fumble))
>>
>> Error: object 'fumble' not found
>>>
>>> .Fortran(stats:::C_setsmu, nphi=as.integer(nphi))
>>
>> Error: object 'nphi' not found
>>
>> so I think we need an alternative hypothesis about what went wrong for
>> you...
>>
>> If nphi was NULL from the outset, that could explain things.
>
>
> No, I never set nphi to NULL.
>
> I put the code back to the way it was previously, just now, and tried again.
> Now I get "object 'nphi' not found".
>
> There is no explanation other than gremlins and the malevolence that the
> computer gods hold towards me.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Aug 15 04:58:32 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 15 Aug 2018 14:58:32 +1200
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <CAGx1TMDq5QTcQ7pK3Z3EghSS9s9mCEvcd-+vcMvYcqcNtqSG3Q@mail.gmail.com>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <CA+hbrhXgzQJxiY18zHfHeUj9bGhY8yhJTN+XMQVG1ke6jjt6cg@mail.gmail.com>
 <CAGgJW77eb_y8bn1mX9Vw+8cg8gM6SexEGkyrQbpyfV8xCx8-+Q@mail.gmail.com>
 <e6fd5191-69e7-5d01-1929-f0ca4b16d18a@auckland.ac.nz>
 <40098e07-e1df-46de-43bb-66f6e53f7252@gmail.com>
 <e792e467-db78-36a8-9625-92a0b8d14837@auckland.ac.nz>
 <CAFDcVCQE-V8umXbgVdodj=zEMM7TihRckCHgf-WHwCrNa24YoQ@mail.gmail.com>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
 <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
 <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>
 <CAGx1TMDq5QTcQ7pK3Z3EghSS9s9mCEvcd-+vcMvYcqcNtqSG3Q@mail.gmail.com>
Message-ID: <e2644b3e-ca15-fc84-5cac-1a21ec24fcf9@auckland.ac.nz>

On 15/08/18 13:00, Richard M. Heiberger wrote:
> There is no explanation other than gremlins and the malevolence that
> the computer gods hold towards me.
> 
> fortune nomination.

I demur.  I already have a fortune with gremlins in it attributed to me
(fortune(213)).

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From chr|@ho|d @end|ng |rom p@yctc@org  Wed Aug 15 08:40:14 2018
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Wed, 15 Aug 2018 07:40:14 +0100 (BST)
Subject: [R] Mysterious seg fault --- SOLVED
In-Reply-To: <e2644b3e-ca15-fc84-5cac-1a21ec24fcf9@auckland.ac.nz>
References: <d017bace-edef-3097-bcfa-f6b733803636@auckland.ac.nz>
 <8e341661-fa31-6280-28d6-33b36e6daa13@auckland.ac.nz>
 <57732538-A39F-4784-B8EB-BAB4BE86196B@gmail.com>
 <a7f9b379-64b2-5f95-7007-8470dbf3b029@auckland.ac.nz>
 <6F90D55E-D435-4384-BDEA-9E127356AE7E@gmail.com>
 <c1fb35cd-6e88-74de-bf27-8efaee0f9171@auckland.ac.nz>
 <CAGx1TMDq5QTcQ7pK3Z3EghSS9s9mCEvcd-+vcMvYcqcNtqSG3Q@mail.gmail.com>
 <e2644b3e-ca15-fc84-5cac-1a21ec24fcf9@auckland.ac.nz>
Message-ID: <1891588009.1366220.1534315214354.JavaMail.zimbra@psyctc.org>

Ah, if I'd had a fortune for every time I invoked the wrath of the IT gods and the malicious work of their gremlins, I'd be an obscenely wealthy person by now.

More seriously, I can't tell you how much I appreciate the joyous flickers of humour here, amidst all the pain and suffering (yes, I may be projecting a bit here), and the welcome, vital, but often humiliating genius many contributors bring as it underlines how low my statistical and computing IQ is. 

I have Rolf as #1 for self-deprecating humour on r-help.  Keep rescuing my sense of humour on my gremlin-beset days please Rolf, all!

Chris

----- Original Message -----
> From: "Rolf Turner" <r.turner at auckland.ac.nz>
> To: "Richard M. Heiberger" <rmh at temple.edu>
> Cc: r-help at r-project.org, "Achim Zeileis" <Achim.Zeileis at uibk.ac.at>, "peter dalgaard" <pdalgd at gmail.com>, "Henrik
> Bengtsson" <henrik.bengtsson at gmail.com>
> Sent: Wednesday, 15 August, 2018 04:58:32
> Subject: Re: [R] Mysterious seg fault --- SOLVED

> On 15/08/18 13:00, Richard M. Heiberger wrote:
>> There is no explanation other than gremlins and the malevolence that
>> the computer gods hold towards me.
>> 
>> fortune nomination.
> 
> I demur.  I already have a fortune with gremlins in it attributed to me
> (fortune(213)).
> 
> cheers,
> 
> Rolf
> 
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Wed Aug 15 16:21:55 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Wed, 15 Aug 2018 07:21:55 -0700
Subject: [R] Ordering of facet_wrap() panels
Message-ID: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>

Hi, I am generating multiple charts with facet_wrap() and what what I see, R/ggplot sorts the panels by the facet variable. So adding an index to the facet variable (1 - bucket, 2 - bucket, etc) does solve the sorting issue but it's ugly. 

I also read this post which, if I understand correctly, claims that ggplot should be using the initial ordering of the data for ordering the charts (instead of ordering the data itself). 

https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/

Wondering if anyone knows how to direct ggplot use the initial sorting of the data to order the panels. 

Thank you.



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 15 16:50:49 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Aug 2018 07:50:49 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
Message-ID: <CAGxFJbSGTPxSMKbo9SNbggMZN+LhGnHrvi31pFUEcFjp5xjBrA@mail.gmail.com>

See ?factor.

You can either use ?ordered to create an ordered factor to sort the levels
as you desire or sort them with factor(). e.g.

> f <- factor(letters[3:1])
> f
[1] c b a
Levels: a b c   ## default ordering

> f <- factor(f, levels = letters[3:1])
> f
[1] c b a
Levels: c b a  ## explicit ordering

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 15, 2018 at 7:21 AM, Stats Student <stats.student4647 at gmail.com>
wrote:

> Hi, I am generating multiple charts with facet_wrap() and what what I see,
> R/ggplot sorts the panels by the facet variable. So adding an index to the
> facet variable (1 - bucket, 2 - bucket, etc) does solve the sorting issue
> but it's ugly.
>
> I also read this post which, if I understand correctly, claims that ggplot
> should be using the initial ordering of the data for ordering the charts
> (instead of ordering the data itself).
>
> https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/
>
> Wondering if anyone knows how to direct ggplot use the initial sorting of
> the data to order the panels.
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 15 18:23:42 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Aug 2018 09:23:42 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <CAMZO7wL5CChzQ_g0BUeJQBW_7V3VWzKo8mwuoYODPVVAwDU1mw@mail.gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
 <CAGxFJbSGTPxSMKbo9SNbggMZN+LhGnHrvi31pFUEcFjp5xjBrA@mail.gmail.com>
 <CAMZO7wL5CChzQ_g0BUeJQBW_7V3VWzKo8mwuoYODPVVAwDU1mw@mail.gmail.com>
Message-ID: <CAGxFJbQcAGzCtXYfDXmyy4HS9PGD_Cuf-ML=dUr=toYOY5fwNg@mail.gmail.com>

1. Unless there is good reason to keep a reply private, always cc the list.
This allows more brains, possible corrections, etc.

2. Have you read ?factor and ?unique ? Always study the docs carefully.
They are generally terse but complete, especially the base docs, and you
can often find your answers there.

3. Your "solution" may work in this case, but if I understand correctly
what you're after,  won't in general. unique() gives the unique values in
the order they appear, which may not be the order you want:

## want ordering to be "a" < "b" < "c"

> f <- rep(letters[3:1],2)

> factor(f, levels = unique(f))
[1] c b a c b a
Levels: c b a  ## not your desired order

Again, please consult the docs and perhaps a tutorial or two as necessary.

-- Bert



On Wed, Aug 15, 2018 at 8:22 AM, Stats Student <stats.student4647 at gmail.com>
wrote:

> Many thanks, Bert.
>
> I did -
>
> facet_wrap(~factor(var, levels=unique (var))
>
> And it seems to be working fine.
> Do you see any issues with this?
>
> I'm fairly new to R so want to make sure I'm not doing something stupid.
>
> Thanks again.
>
> On Wed, Aug 15, 2018, 7:50 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> See ?factor.
>>
>> You can either use ?ordered to create an ordered factor to sort the
>> levels as you desire or sort them with factor(). e.g.
>>
>> > f <- factor(letters[3:1])
>> > f
>> [1] c b a
>> Levels: a b c   ## default ordering
>>
>> > f <- factor(f, levels = letters[3:1])
>> > f
>> [1] c b a
>> Levels: c b a  ## explicit ordering
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Wed, Aug 15, 2018 at 7:21 AM, Stats Student <
>> stats.student4647 at gmail.com> wrote:
>>
>>> Hi, I am generating multiple charts with facet_wrap() and what what I
>>> see, R/ggplot sorts the panels by the facet variable. So adding an index to
>>> the facet variable (1 - bucket, 2 - bucket, etc) does solve the sorting
>>> issue but it's ugly.
>>>
>>> I also read this post which, if I understand correctly, claims that
>>> ggplot should be using the initial ordering of the data for ordering the
>>> charts (instead of ordering the data itself).
>>>
>>> https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/
>>>
>>> Wondering if anyone knows how to direct ggplot use the initial sorting
>>> of the data to order the panels.
>>>
>>> Thank you.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]



From |r@nc|@@bo@teng @end|ng |rom ver@@ntphy@|c@@com  Wed Aug 15 19:17:14 2018
From: |r@nc|@@bo@teng @end|ng |rom ver@@ntphy@|c@@com (Francis Boateng)
Date: Wed, 15 Aug 2018 17:17:14 +0000
Subject: [R] exponential day
In-Reply-To: <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>
References: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
 <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <SN2PR17MB0717E59E1C00C9D0677FA3608F3F0@SN2PR17MB0717.namprd17.prod.outlook.com>

Thanks Ellison, I will try it. 

Francis


-----Original Message-----
From: S Ellison <S.Ellison at LGCGroup.com> 
Sent: Thursday, August 9, 2018 8:12 AM
To: Francis Boateng <francis.boateng at versantphysics.com>; r-help at r-project.org
Subject: RE: exponential day

> Please, how can I determine parameters from exponential equation 
> Example
> one:  y = a*exp(-b*x);  how do I determine  a  and  b , as well as 
> R-square from data sets. And also fitting y = a*exp(-b*x) into the 
> data sets Assuming data sets A = (0,2,4,6,8,10) B = 
> (1,0.8,0.6,0.4,0.2,0.1)

For least squares fitting, you could take logs and do a simple linear fit, if the resduals are reasonably homoscedastic in the log domain (or if you can sort the weighting out properly).

For non-linear least squares, look at ?nlm, ?nls or (if you want to roll your own) ?optim

For max likelihood, maybe nlme in the nlme package.

For other ideas, look up 'non-linear fitting with R' on any search engine, or check the R Task Views

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or disclosure other than by the intended recipient is unauthorised. If you have received this message in error, please notify the sender immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 15 20:04:36 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Aug 2018 11:04:36 -0700
Subject: [R] exponential day
In-Reply-To: <SN2PR17MB0717E59E1C00C9D0677FA3608F3F0@SN2PR17MB0717.namprd17.prod.outlook.com>
References: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
 <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>
 <SN2PR17MB0717E59E1C00C9D0677FA3608F3F0@SN2PR17MB0717.namprd17.prod.outlook.com>
Message-ID: <CAGxFJbRBoq+ffRGeZ+r3tf9x045sD19muD3N4oSNazpvFZh=dg@mail.gmail.com>

Please note that R^2 for nonlinear models is nonsense.

Search on "R^2 in nonlinear models" for details, e.g.

http://statisticsbyjim.com/regression/r-squared-invalid-nonlinear-regression/

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 15, 2018 at 10:54 AM Francis Boateng <
francis.boateng at versantphysics.com> wrote:

> Thanks Ellison, I will try it.
>
> Francis
>
>
> -----Original Message-----
> From: S Ellison <S.Ellison at LGCGroup.com>
> Sent: Thursday, August 9, 2018 8:12 AM
> To: Francis Boateng <francis.boateng at versantphysics.com>;
> r-help at r-project.org
> Subject: RE: exponential day
>
> > Please, how can I determine parameters from exponential equation
> > Example
> > one:  y = a*exp(-b*x);  how do I determine  a  and  b , as well as
> > R-square from data sets. And also fitting y = a*exp(-b*x) into the
> > data sets Assuming data sets A = (0,2,4,6,8,10) B =
> > (1,0.8,0.6,0.4,0.2,0.1)
>
> For least squares fitting, you could take logs and do a simple linear fit,
> if the resduals are reasonably homoscedastic in the log domain (or if you
> can sort the weighting out properly).
>
> For non-linear least squares, look at ?nlm, ?nls or (if you want to roll
> your own) ?optim
>
> For max likelihood, maybe nlme in the nlme package.
>
> For other ideas, look up 'non-linear fitting with R' on any search engine,
> or check the R Task Views
>
> S Ellison
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:18}}



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Wed Aug 15 20:07:39 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Wed, 15 Aug 2018 14:07:39 -0400
Subject: [R] Problem with loaded R packages
Message-ID: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>

Good afternoon,

  I am trying to load the two R packages CGSDR and GAIA which I have
successfully installed onto my R program. Following installation of the two
packages, I proceeded upon recommendation to load both packages via the
library function. Therefore I inputed following...

library(cgdsr)
library(gaia)

This was successfull. Then did the following

source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf

This Bioconductorlink was reported to contain an error and was not loaded
successfully.

Any ideas of what exactly I am doing wrong in my lines?

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]



From m@rc_@chw@rtz @end|ng |rom me@com  Wed Aug 15 20:33:25 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 15 Aug 2018 14:33:25 -0400
Subject: [R] Problem with loaded R packages
In-Reply-To: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
References: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
Message-ID: <D817FF91-4A51-47FC-8412-8F61747497AC@me.com>

Hi,

The ?source function is intended to read a plain text R source code file into the R console, not a PDF file.

Even if source() could read in a PDF file, you have a typo in the URL, which is CRAN, not BioConductor, and which should be:

  https://cran.r-project.org/web/packages/cgdsr/vignettes/cgdsr.pdf

Regards,

Marc Schwartz

> On Aug 15, 2018, at 2:07 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> Good afternoon,
> 
>  I am trying to load the two R packages CGSDR and GAIA which I have
> successfully installed onto my R program. Following installation of the two
> packages, I proceeded upon recommendation to load both packages via the
> library function. Therefore I inputed following...
> 
> library(cgdsr)
> library(gaia)
> 
> This was successfull. Then did the following
> 
> source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf
> 
> This Bioconductorlink was reported to contain an error and was not loaded
> successfully.
> 
> Any ideas of what exactly I am doing wrong in my lines?
> 
> Many thanks,
> 
> Spencer Brackett
> 
> 	[[alternative HTML version deleted]]



From m@rc_@chw@rtz @end|ng |rom me@com  Wed Aug 15 20:52:44 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 15 Aug 2018 14:52:44 -0400
Subject: [R] Problem with loaded R packages
In-Reply-To: <CAPQaxLOexhvqGiBEaf8pU5tJ=EO-JKpCMdZRaJz0C6LHYFnMJA@mail.gmail.com>
References: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
 <D817FF91-4A51-47FC-8412-8F61747497AC@me.com>
 <CAPQaxLOexhvqGiBEaf8pU5tJ=EO-JKpCMdZRaJz0C6LHYFnMJA@mail.gmail.com>
Message-ID: <7590F990-933F-47BA-BC33-CC4C98E1E8B9@me.com>

Hi Spencer,

Please be sure to use reply-all to keep the thread on the list and in the list archives for the future benefit of others. It also allows others to participate with additional information, if needed.

You have already loaded the packages by using the two library() function calls as you have below.

Beyond that, if there are examples from the package vignettes that you want to run, just copy and paste the relevant code from the PDF file, within whatever application you use to view it, into the R console.

Each package also has it's own documentation as well, describing the functions, their arguments, any included datasets, and typically some examples. You can bring up the main package help index by using, for example:

  help(package = "cgdsr")
 
Regards,

Marc


> On Aug 15, 2018, at 2:41 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> Mr. Schwartz, 
> 
>   I see. Thank you for the correction! Is there any other line which I could input to load the two packages in question?
> 
> Many thanks, 
> 
> Spencer Brackett 
> 
> On Wed, Aug 15, 2018 at 2:33 PM Marc Schwartz <marc_schwartz at me.com> wrote:
> Hi,
> 
> The ?source function is intended to read a plain text R source code file into the R console, not a PDF file.
> 
> Even if source() could read in a PDF file, you have a typo in the URL, which is CRAN, not BioConductor, and which should be:
> 
>   https://cran.r-project.org/web/packages/cgdsr/vignettes/cgdsr.pdf
> 
> Regards,
> 
> Marc Schwartz
> 
> > On Aug 15, 2018, at 2:07 PM, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> > 
> > Good afternoon,
> > 
> >  I am trying to load the two R packages CGSDR and GAIA which I have
> > successfully installed onto my R program. Following installation of the two
> > packages, I proceeded upon recommendation to load both packages via the
> > library function. Therefore I inputed following...
> > 
> > library(cgdsr)
> > library(gaia)
> > 
> > This was successfull. Then did the following
> > 
> > source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf
> > 
> > This Bioconductorlink was reported to contain an error and was not loaded
> > successfully.
> > 
> > Any ideas of what exactly I am doing wrong in my lines?
> > 
> > Many thanks,
> > 
> > Spencer Brackett
> > 
> >       [[alternative HTML version deleted]]
> 



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Wed Aug 15 21:06:10 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Wed, 15 Aug 2018 15:06:10 -0400
Subject: [R] Problem with loaded R packages
In-Reply-To: <581DFE3D-BCF5-4250-B581-8909E14F513E@dcn.davis.ca.us>
References: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
 <581DFE3D-BCF5-4250-B581-8909E14F513E@dcn.davis.ca.us>
Message-ID: <CAPQaxLNo2NGRGNA18fqea4BQpUAGS9LPgFc9RfY4nVLrZpxpaw@mail.gmail.com>

 Many thanks! I will look into apply the advice given.

-Spencer Brackett

On Wed, Aug 15, 2018 at 3:03 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> a) Raw URL text is not legal in R code. URLs MUST ALWAYS be enclosed in
> single (') or double (") quotes in R.
>
> b) The source function expects to go where you tell it to go and retrieve
> text composed of R statements. A PDF is a binary file... even if it
> happened to contain some R code that you could read with your PDF viewer it
> would be inaccessible to the R interpreter because it is not in a text file.
>
> c) I can't really tell where you are headed with this code you gave us...
> if you want to read the vignette you could use your web browser to download
> that PDF and use your viewer to open it. If you want to run any of the code
> shown in it you can copy it to the console interactively.
>
> d) The Bioconductor project has a different mailing list... for questions
> not generically about R you should look at
> https://www.bioconductor.org/help/support
>
> On August 15, 2018 11:07:39 AM PDT, Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
> >Good afternoon,
> >
> >  I am trying to load the two R packages CGSDR and GAIA which I have
> >successfully installed onto my R program. Following installation of the
> >two
> >packages, I proceeded upon recommendation to load both packages via the
> >library function. Therefore I inputed following...
> >
> >library(cgdsr)
> >library(gaia)
> >
> >This was successfull. Then did the following
> >
> >source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf
> >
> >This Bioconductorlink was reported to contain an error and was not
> >loaded
> >successfully.
> >
> >Any ideas of what exactly I am doing wrong in my lines?
> >
> >Many thanks,
> >
> >Spencer Brackett
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug 15 21:03:26 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 15 Aug 2018 12:03:26 -0700
Subject: [R] Problem with loaded R packages
In-Reply-To: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
References: <CAPQaxLPV4YCuP6GVz9-p=3CyKuaueXfSWFXLVW94Y7nXYgULyw@mail.gmail.com>
Message-ID: <581DFE3D-BCF5-4250-B581-8909E14F513E@dcn.davis.ca.us>

a) Raw URL text is not legal in R code. URLs MUST ALWAYS be enclosed in single (') or double (") quotes in R.

b) The source function expects to go where you tell it to go and retrieve text composed of R statements. A PDF is a binary file... even if it happened to contain some R code that you could read with your PDF viewer it would be inaccessible to the R interpreter because it is not in a text file.

c) I can't really tell where you are headed with this code you gave us... if you want to read the vignette you could use your web browser to download that PDF and use your viewer to open it. If you want to run any of the code shown in it you can copy it to the console interactively.

d) The Bioconductor project has a different mailing list... for questions not generically about R you should look at https://www.bioconductor.org/help/support

On August 15, 2018 11:07:39 AM PDT, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>Good afternoon,
>
>  I am trying to load the two R packages CGSDR and GAIA which I have
>successfully installed onto my R program. Following installation of the
>two
>packages, I proceeded upon recommendation to load both packages via the
>library function. Therefore I inputed following...
>
>library(cgdsr)
>library(gaia)
>
>This was successfull. Then did the following
>
>source(https://cran.r-project.org/web/packages/cgdsr/vingnettes/cgdsr.pdf
>
>This Bioconductorlink was reported to contain an error and was not
>loaded
>successfully.
>
>Any ideas of what exactly I am doing wrong in my lines?
>
>Many thanks,
>
>Spencer Brackett
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From pro|jcn@@h @end|ng |rom gm@||@com  Wed Aug 15 22:11:13 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Wed, 15 Aug 2018 16:11:13 -0400
Subject: [R] exponential day
In-Reply-To: <CAGxFJbRBoq+ffRGeZ+r3tf9x045sD19muD3N4oSNazpvFZh=dg@mail.gmail.com>
References: <SN2PR17MB0717AEBC0E78591BF523DFBD8F260@SN2PR17MB0717.namprd17.prod.outlook.com>
 <310f2f579bbe412494d76eb84a569dd7@GBDCVPEXC08.corp.lgc-group.com>
 <SN2PR17MB0717E59E1C00C9D0677FA3608F3F0@SN2PR17MB0717.namprd17.prod.outlook.com>
 <CAGxFJbRBoq+ffRGeZ+r3tf9x045sD19muD3N4oSNazpvFZh=dg@mail.gmail.com>
Message-ID: <4d5aae69-d630-8290-4d11-bb564c17ad26@gmail.com>

Since I'm associated with a lot of nonlinear modeling software, including nlsr and (now
deprecated) nlmrt, I'll perhaps seem an odd person to say that I calculate an R^2 quite
regularly for all sorts of models. I find it useful to know if my nonlinear models do
poorly compared to the model that is simply the mean of the data.

The big issue, of course, is to get across to people that all their linear model ideas
about this quantity -- and we need some other name here -- are indeed rubbish in this
context. All I'm doing is comparing two models in a very crude way. Useful? Sometimes,
esp. if the result is a negative number (i.e., a nonlinear model is less effective in
approximating data than a single value).  Is it important? No. We only want to avoid
using bad models, and this is a quick and dirty flag.

Best, JN


On 2018-08-15 02:04 PM, Bert Gunter wrote:
> Please note that R^2 for nonlinear models is nonsense.
> 
> Search on "R^2 in nonlinear models" for details, e.g.
> 
> http://statisticsbyjim.com/regression/r-squared-invalid-nonlinear-regression/
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Aug 15, 2018 at 10:54 AM Francis Boateng <
> francis.boateng at versantphysics.com> wrote:
> 
>> Thanks Ellison, I will try it.
>>
>> Francis
>>
>>
>> -----Original Message-----
>> From: S Ellison <S.Ellison at LGCGroup.com>
>> Sent: Thursday, August 9, 2018 8:12 AM
>> To: Francis Boateng <francis.boateng at versantphysics.com>;
>> r-help at r-project.org
>> Subject: RE: exponential day
>>
>>> Please, how can I determine parameters from exponential equation
>>> Example
>>> one:  y = a*exp(-b*x);  how do I determine  a  and  b , as well as
>>> R-square from data sets. And also fitting y = a*exp(-b*x) into the
>>> data sets Assuming data sets A = (0,2,4,6,8,10) B =
>>> (1,0.8,0.6,0.4,0.2,0.1)
>>
>> For least squares fitting, you could take logs and do a simple linear fit,
>> if the resduals are reasonably homoscedastic in the log domain (or if you
>> can sort the weighting out properly).
>>
>> For non-linear least squares, look at ?nlm, ?nls or (if you want to roll
>> your own) ?optim
>>
>> For max likelihood, maybe nlme in the nlme package.
>>
>> For other ideas, look up 'non-linear fitting with R' on any search engine,
>> or check the R Task Views
>>
>> S Ellison
>>
>>
>>
>> *******************************************************************
>> This email and any attachments are confidential. Any u...{{dropped:18}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jwd @end|ng |rom @urewe@t@net  Wed Aug 15 23:57:52 2018
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 15 Aug 2018 14:57:52 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
Message-ID: <20180815145752.0124f307@Draco.localdomain>

On Wed, 15 Aug 2018 07:21:55 -0700
Stats Student <stats.student4647 at gmail.com> wrote:

> Hi, I am generating multiple charts with facet_wrap() and what what I
> see, R/ggplot sorts the panels by the facet variable. So adding an
> index to the facet variable (1 - bucket, 2 - bucket, etc) does solve
> the sorting issue but it's ugly. 
> 
You should also be looking at the ggplot help mailing list.  Since you
did not supply an example of your code it is not possible to really see
if anything in it might be overriding ggplot's normal behavior.

JDougherty



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Aug 16 01:38:58 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Wed, 15 Aug 2018 23:38:58 +0000
Subject: [R] searching for a specific row name in R
In-Reply-To: <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
References: <5b7112af.1c69fb81.b4ca8.2b0e@mx.google.com>
 <1534144163.672121.1472092568.57C327B9@webmail.messagingengine.com>
 <EF30A90C-7A94-4C72-A20F-0E159A8F933B@llnl.gov>
 <CAGchuN43nct+33t4Lpn1e3TL5Qz7tOUkp-Bf1Me-LWdeO02fXg@mail.gmail.com>
Message-ID: <2FE3B7C3-F127-4B71-A9F4-5DD368DE37AD@llnl.gov>

It depends on what you want to check. There are a lot of things you can check without looping.

For example, if you want to check whether all of the first letters of the identifier names are "A", you could do
  table( substr(idnames,1,1))
to show you all of the first letters, and how many there are of each.

Like Bert said, some tutorials would be good. Even better would be to find someone nearby who knows R really well. I think R is probably difficult to learn all on one's own.

Small suggestion: be careful about using the word "list" in statements like "a list of identifier names".  It's ok in ordinary English, but in R a "list" is a special kind of data structure. Better to say "a vector of identifier names".

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Deepa <deepamahm.iisc at gmail.com>
Date: Monday, August 13, 2018 at 8:36 PM
To: "MacQueen, Don" <macqueen1 at llnl.gov>, array R-help <r-help at r-project.org>
Subject: Re: [R] searching for a specific row name in R

Hi Don,

When there is a list of identifier names that I want to check, the only way is to loop over each entry stored in the list of identifier names or is there is there any other shortcut?

Many thanks for the response?

On Mon, Aug 13, 2018 at 8:18 PM, MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>> wrote:
Or to return a logical value, i.e., TRUE if the column contains the value, FALSE if it does not:

  any( x[,2] == 'A501' )

-Don
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



On 8/13/18, 12:09 AM, "R-help on behalf of Albrecht Kauffmann" <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of alkauffm at fastmail.fm<mailto:alkauffm at fastmail.fm>> wrote:

    Hello Deepa,

    sum(x[,2] == "A501")
    or
    which(x[,2] == "A501")
    .
    Best,
    Albrecht


    --
      Albrecht Kauffmann
      alkauffm at fastmail.fm<mailto:alkauffm at fastmail.fm>

    Am Mo, 13. Aug 2018, um 07:10, schrieb Deepa Maheshvare:
    > Hello Everyone,
    >
    > I have a 1000 x 20 matrix. The second column of the matrix has the names
    > of identifiers. How do I check when a certain identifier is present in
    > the set of 1000 identifier names present in the second column. For
    > instance, let the names of identifiers be A1,A2,...A1000. I want to
    > check whether A501 is present .How can this be checked?
    >
    > Any help will be highly appreciated.
    >
    >
    >   [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.

    ______________________________________________
    R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Wed Aug 15 21:18:12 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Wed, 15 Aug 2018 12:18:12 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <CAGxFJbQcAGzCtXYfDXmyy4HS9PGD_Cuf-ML=dUr=toYOY5fwNg@mail.gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
 <CAGxFJbSGTPxSMKbo9SNbggMZN+LhGnHrvi31pFUEcFjp5xjBrA@mail.gmail.com>
 <CAMZO7wL5CChzQ_g0BUeJQBW_7V3VWzKo8mwuoYODPVVAwDU1mw@mail.gmail.com>
 <CAGxFJbQcAGzCtXYfDXmyy4HS9PGD_Cuf-ML=dUr=toYOY5fwNg@mail.gmail.com>
Message-ID: <43b623e6-de96-4dda-abb3-a97e4392baeb@gmail.com>

Understood. Will review the docs again. 

My data is from an external source which, among other things, ensures that it's sorted correctly. I was asking for a way to have ggplot use the ordering in place, instead of re-ordering everything. Apologies if it wasn't clear from the original post. 

Anyway, if the data is correctly presorted, unique should work ok, I think. 




On Aug 15, 2018, 9:23 AM, at 9:23 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>1. Unless there is good reason to keep a reply private, always cc the
>list.
>This allows more brains, possible corrections, etc.
>
>2. Have you read ?factor and ?unique ? Always study the docs carefully.
>They are generally terse but complete, especially the base docs, and
>you
>can often find your answers there.
>
>3. Your "solution" may work in this case, but if I understand correctly
>what you're after,  won't in general. unique() gives the unique values
>in
>the order they appear, which may not be the order you want:
>
>## want ordering to be "a" < "b" < "c"
>
>> f <- rep(letters[3:1],2)
>
>> factor(f, levels = unique(f))
>[1] c b a c b a
>Levels: c b a  ## not your desired order
>
>Again, please consult the docs and perhaps a tutorial or two as
>necessary.
>
>-- Bert
>
>
>
>On Wed, Aug 15, 2018 at 8:22 AM, Stats Student
><stats.student4647 at gmail.com>
>wrote:
>
>> Many thanks, Bert.
>>
>> I did -
>>
>> facet_wrap(~factor(var, levels=unique (var))
>>
>> And it seems to be working fine.
>> Do you see any issues with this?
>>
>> I'm fairly new to R so want to make sure I'm not doing something
>stupid.
>>
>> Thanks again.
>>
>> On Wed, Aug 15, 2018, 7:50 AM Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>>
>>> See ?factor.
>>>
>>> You can either use ?ordered to create an ordered factor to sort the
>>> levels as you desire or sort them with factor(). e.g.
>>>
>>> > f <- factor(letters[3:1])
>>> > f
>>> [1] c b a
>>> Levels: a b c   ## default ordering
>>>
>>> > f <- factor(f, levels = letters[3:1])
>>> > f
>>> [1] c b a
>>> Levels: c b a  ## explicit ordering
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming
>along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>> On Wed, Aug 15, 2018 at 7:21 AM, Stats Student <
>>> stats.student4647 at gmail.com> wrote:
>>>
>>>> Hi, I am generating multiple charts with facet_wrap() and what what
>I
>>>> see, R/ggplot sorts the panels by the facet variable. So adding an
>index to
>>>> the facet variable (1 - bucket, 2 - bucket, etc) does solve the
>sorting
>>>> issue but it's ugly.
>>>>
>>>> I also read this post which, if I understand correctly, claims that
>>>> ggplot should be using the initial ordering of the data for
>ordering the
>>>> charts (instead of ordering the data itself).
>>>>
>>>> https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/
>>>>
>>>> Wondering if anyone knows how to direct ggplot use the initial
>sorting
>>>> of the data to order the panels.
>>>>
>>>> Thank you.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>



From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Thu Aug 16 12:33:28 2018
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Thu, 16 Aug 2018 10:33:28 +0000
Subject: [R] cumulate of snow cumulates from daily values of different
 automatic stations for some time intervals
In-Reply-To: <CA+8X3fUpyN9X6qZwjxdxaokAfo1QjtNZWxpSOOO3nDanKpVJ7g@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F54CCBF0B@ESINO.regionemarche.intra>,
 <CA+8X3fUpyN9X6qZwjxdxaokAfo1QjtNZWxpSOOO3nDanKpVJ7g@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F54CCDC0A@ESINO.regionemarche.intra>

Hi Jim.
Thank you for your help. I found very useful cum_snow and cum_list, but I decided to manage the list and dates in a different way.
First of all I decided to deal with a unique data frame (called df_CFS) where I attached all the 10 data frames, and instead to build a list with the 10 different data frames I created a list with the 10 station codes (217, 2018, ...):

list_station_code <- list(217, 218, 219, ...)

For managing dates, I created a vector of length 6. This is an example

my_date <- c("1999-12-17-00-00", "2000-01-07-00-00", "2000-01-10-00-00", "2000-01-15-00-00", NA, NA)

and then I created three functions based on the non NA elements of my_date:

sum_prec1 <- function(x, init_day1_POSIX, fin_day1_POSIX) {
  sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day1_POSIX & df_CFS$data_POSIX <= fin_day1_POSIX], na.rm=T)
}

sum_prec2 <- function(x, init_day1_POSIX, fin_day1_POSIX, init_day2_POSIX, fin_day2_POSIX) {
print("sum_prec2")
  sum1 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day1_POSIX & df_CFS$data_POSIX <= fin_day1_POSIX], na.rm=T)
  sum2 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day2_POSIX & df_CFS$data_POSIX <= fin_day2_POSIX], na.rm=T)
  sum <- sum1 + sum2
}

sum_prec3 <- function(x, init_day1_POSIX, fin_day1_POSIX, init_day2_POSIX, fin_day2_POSIX, init_day3_POSIX, fin_day3_POSIX) {
print("sum_prec3")
  sum1 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day1_POSIX & df_CFS$data_POSIX <= fin_day1_POSIX], na.rm=T)
  sum2 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day2_POSIX & df_CFS$data_POSIX <= fin_day2_POSIX], na.rm=T)
  sum3 <- sum(df_CFS$Hn[df_CFS$Codice_sensore==x & df_CFS$data_POSIX >= init_day3_POSIX & df_CFS$data_POSIX <= fin_day3_POSIX], na.rm=T)
  sum <- sum1 + sum2 + sum3
}

Finally

  my_date_POSIX <- as.POSIXct(my_date), format="%Y-%m-%d-%H-%M")
  my_date_POSIX <- my_dates[!is.na(my_date_POSIX)]
  if (length(my_date_POSIX)==2) my_output <- lapply(list_station_code, sum_prec1, my_date_POSIX[[1]], my_date_POSIX[[2]])
  else if (length(my_date_POSIX)==4) my_output <- lapply(list_station_code, sum_prec2, my_date_POSIX[[1]], my_date_POSIX[[2]], my_date_POSIX[[3]], my_date_POSIX[[4]])
  else if (length(my_dates)==6) my_output <- lapply(list_station_code, sum_prec3, my_date_POSIX[[1]], my_date_POSIX[[2]], my_date_POSIX[[3]], my_date_POSIX[[4]], my_date_POSIX[[5]], my_date_POSIX[[6]])

  df_snow_totals <- data.frame("station_code" = c(217, 218, 219))
  df_snow_totals$Cumulata <- as.vector(my_output)
  df_snow_totals$Cumulata <- as.numeric(as.character(unlist(df_snow_totals$Cumulata)))



It works.
Thank you for your help
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------
________________________________________
Da: Jim Lemon [drjimlemon at gmail.com]
Inviato: luned? 13 agosto 2018 1.55
A: Stefano Sofia
Cc: r-help at r-project.org
Oggetto: Re: [R] cumulate of snow cumulates from daily values of different automatic stations for some time intervals

Hi Stefano,
This was such a stinker of a problem that I just had to crack it:

# create some data the lazy man's way
year_dates<-c(paste(2000,rep("01",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("02",29),formatC(1:29,width=2,flag=0),sep="-"),
 paste(2000,rep("03",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("04",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("05",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("06",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("07",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("08",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("09",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("10",31),formatC(1:31,width=2,flag=0),sep="-"),
 paste(2000,rep("11",30),formatC(1:30,width=2,flag=0),sep="-"),
 paste(2000,rep("12",31),formatC(1:31,width=2,flag=0),sep="-"))

df1<-data.frame(station_code=rep(217,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df2<-data.frame(station_code=rep(218,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df3<-data.frame(station_code=rep(219,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df4<-data.frame(station_code=rep(220,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df5<-data.frame(station_code=rep(221,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df6<-data.frame(station_code=rep(222,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df7<-data.frame(station_code=rep(223,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df8<-data.frame(station_code=rep(224,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df9<-data.frame(station_code=rep(225,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))
df10<-data.frame(station_code=rep(226,366),
 date_factor=year_dates,date_POSIX=year_dates,
 snow=c(sample(0:70,31),sample(0:50,29),sample(0:10,31,TRUE),rep(0,214),
 sample(0:20,30,TRUE),sample(0:60,31)))

snow_list<-list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

for(station in 1:10)
 snow_list[[station]]$doy<-1:length(snow_list[[station]]$date_POSIX)

select_days<-c(1:12,83:88)

cum_snow<-function(x,which_days) {
 return(list(x$station_code[1],sum(x$snow[which_days])))
}

cum_list<-lapply(lapply(snow_list,cum_snow,select_days),unlist)

snow_totals<-data.frame(station_code=NULL,snow_cumulate=NULL)

for(station in 1:10) snow_totals<-rbind(snow_totals,cum_list[[station]])

names(snow_totals)<-c("station_code","snow_cumulate")

Jim


On Sat, Aug 11, 2018 at 2:48 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-list users,
> I have 10 data frames (called df1, df2, ... df10), where each of them contains snow data from an automatic meteorological station (obviously each station has a different station code).
> Here is an example of df1:
>
> station_code date_factor date_POSIX snow
> 217 1999-12-15 1999-12-15  0
> 217 1999-12-16 1999-12-16  0
> 217 1999-12-17 1999-12-17 38
> 217 1999-12-18 1999-12-18 31
> 217 1999-12-19 1999-12-19 21
> 217 1999-12-20 1999-12-20 12
> 217 1999-12-21 1999-12-21 42
> 217 1999-12-22 1999-12-22 61
> 217 1999-12-23 1999-12-23 57
> 217 1999-12-24 1999-12-24 48
> ...
>
> where
>> sapply(df1, class)
> $station_code
> [1] "numeric"
>
> $date_factor
> [1] "factor"
>
> $date_POSIX
> [1] "POSIXct" "POSIXt"
>
> $snow
> [1] "integer"
>
> Given a series of max three intervals (example with two intervals: from 1st to 12th of January 2000 and from 23rd to 28th of March 2000), I need to evaluate for each station the total snow cumulate for all the intervals selected, and finally create a data frame where for each line there is the station code and the snow cumulate. It should be like
>
> station_code total_snow_cumulate
> 217 125
> 218 80
> ...
>
> Could somebody show me a direction for an efficient solution?
>
> Thank you for your attention and your help
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> and provide commented, minimal, self-contained, reproducible code.

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.



From roy@mende|@@ohn @end|ng |rom no@@@gov  Thu Aug 16 22:01:13 2018
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 16 Aug 2018 13:01:13 -0700
Subject: [R] How deep into function calls does trycatch() work
Message-ID: <BEDFD820-13C1-4FCA-BB22-72B114F57B9D@noaa.gov>

Hi All:

I am using another package in a project I have. Because of that,  I have no control on how that package behaves or what it returns.  This package has a function foo()  that calls httr::GET(),  and if it gets an error from httr::GET() it calls the following routine:


err_handle2 <- function(x) {
  if (x$status_code > 201) {
    tt <- content(x, "text")
    mssg <- xml_text(xml_find_all(read_html(tt), "//h1"))
    stop(paste0(mssg, collapse = "\n\n"), call. = FALSE)
  }
}

My question is if I embed my call to foo() in try...catch will that override the stop() call or am I a goner, or is there another way to override it,  given that I can't change the code to err_handle2().

Thanks,

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.



From peter@|@ng|e|der @end|ng |rom gm@||@com  Thu Aug 16 22:09:32 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 16 Aug 2018 13:09:32 -0700
Subject: [R] How deep into function calls does trycatch() work
In-Reply-To: <BEDFD820-13C1-4FCA-BB22-72B114F57B9D@noaa.gov>
References: <BEDFD820-13C1-4FCA-BB22-72B114F57B9D@noaa.gov>
Message-ID: <CA+hbrhUqTUfEYLDFwcjsJqbx1mLjq5WPeZhOQtT5HbNce_rXMQ@mail.gmail.com>

AFAIK a try or tryCatch will intercept the error thrown by stop(). Why
not try it and see if it works?

Peter
On Thu, Aug 16, 2018 at 1:05 PM Roy Mendelssohn - NOAA Federal via
R-help <r-help at r-project.org> wrote:
>
> Hi All:
>
> I am using another package in a project I have. Because of that,  I have no control on how that package behaves or what it returns.  This package has a function foo()  that calls httr::GET(),  and if it gets an error from httr::GET() it calls the following routine:
>
>
> err_handle2 <- function(x) {
>   if (x$status_code > 201) {
>     tt <- content(x, "text")
>     mssg <- xml_text(xml_find_all(read_html(tt), "//h1"))
>     stop(paste0(mssg, collapse = "\n\n"), call. = FALSE)
>   }
> }
>
> My question is if I embed my call to foo() in try...catch will that override the stop() call or am I a goner, or is there another way to override it,  given that I can't change the code to err_handle2().
>
> Thanks,
>
> -Roy
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Aug 17 01:44:04 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 16 Aug 2018 23:44:04 +0000
Subject: [R] Using rmarkdown with many plots created in a loop
Message-ID: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>

I would appreciate some suggestions of a good way to prepare a report using rmarkdown,
in which I loop through subsets of a data set, creating a plot of each subset, and interspersing
among the figures some text relevant to each figure.

One way is to have an R script write the rmd file, then render it.
It works, but it's cumbersome and difficult to get the rmd syntax correct.
I would very much appreciate suggestions for a better way.

Reproducible example below.

Thanks
-Don


Example data (other data structures could be used), and an example using this approach.

myd <- lapply( 1:3,
              function(i) list(df=data.frame(x=1:5, y=rnorm(5)),
                               comment=paste('Data', LETTERS[i]))
              )

Example interactive review (details would change depending on data structure)
(I would typically insert pauses when working interactively)

for (i in 1:3) {
  cat(paste('Figure',i,'shows',myd[[i]]$comment),'\n')
  with(myd[[i]]$df , plot(x,y))
  mtext(myd[[i]]$comment)
  mtext( paste(nrow(myd[[i]]$df),'points'), adj=1)
}?

Note that along with the data I've saved some comments relevant to each subset.
I've calculated them in the example data, but in general they could be completely
arbitrary and come from anywhere.

Now I'd like to get the same plots and comments into a report prepared using rmarkdown.
Here's one way, having the loop create an rmd file, then rendering it.

### example script begins
library(rmarkdown)

myf <- 'myd.rmd'
sink(myf)
cat('---
title: Example
---

Here are some figures with a comment appearing before each.\n\n'
)
sink()

for (i in 1:3) {
  cat(paste('Figure',i,'comment:',myd[[i]]$comment),'\n', file=myf, append=TRUE)

  cat("
```{r  echo=FALSE, fig.cap='",paste('fig',i),"caption.'}
  with(myd[[",i,"]]$df , plot(x,y))
  mtext(myd[[",i,"]]$comment)
  mtext( paste(nrow(myd[[",i,"]]$df),'points'), adj=1)
```
", file=myf, append=TRUE)
   
}

cat('Done with report\n', file=myf, append=TRUE)

render(myf)

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Aug 16 15:44:45 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 16 Aug 2018 06:44:45 -0700
Subject: [R] Ordering of facet_wrap() panels
In-Reply-To: <43b623e6-de96-4dda-abb3-a97e4392baeb@gmail.com>
References: <271eb112-3fd5-4cf2-9c34-b00c58a5e502@gmail.com>
 <CAGxFJbSGTPxSMKbo9SNbggMZN+LhGnHrvi31pFUEcFjp5xjBrA@mail.gmail.com>
 <CAMZO7wL5CChzQ_g0BUeJQBW_7V3VWzKo8mwuoYODPVVAwDU1mw@mail.gmail.com>
 <CAGxFJbQcAGzCtXYfDXmyy4HS9PGD_Cuf-ML=dUr=toYOY5fwNg@mail.gmail.com>
 <43b623e6-de96-4dda-abb3-a97e4392baeb@gmail.com>
Message-ID: <87786C9B-7F5F-427B-B843-E260109B2582@dcn.davis.ca.us>

The result does NOT depend on whether or how the data itself are sorted, but rather on how the levels of the factors in the data are sorted. Best results will be obtained if you modify the data frame factors before giving the data frame to ggplot. Doing so will allow all of the ggplot functions to work on a consistent set of data columns.

Some example ways to change the ordering:

factor(f, levels = sort(unique(f))) #alpha
factor(f, levels = unique(f)) #as first encountered in data
factor(f, levels = c("b","a","c")) #explicit
factor(f, levels = c("b","a","c"), labels=c("Ok","Best","Other") "#presentation coding

If for some reason you don't want to modify your original data, make a temporary copy of your data frame and set the appropriate factor levels for your presentation. However, it will then be up to you to avoid making substantive changes to the data records between multiple plots (views of the data).

On August 15, 2018 12:18:12 PM PDT, Stats Student <stats.student4647 at gmail.com> wrote:
>Understood. Will review the docs again. 
>
>My data is from an external source which, among other things, ensures
>that it's sorted correctly. I was asking for a way to have ggplot use
>the ordering in place, instead of re-ordering everything. Apologies if
>it wasn't clear from the original post. 
>
>Anyway, if the data is correctly presorted, unique should work ok, I
>think. 
>
>
>
>
>On Aug 15, 2018, 9:23 AM, at 9:23 AM, Bert Gunter
><bgunter.4567 at gmail.com> wrote:
>>1. Unless there is good reason to keep a reply private, always cc the
>>list.
>>This allows more brains, possible corrections, etc.
>>
>>2. Have you read ?factor and ?unique ? Always study the docs
>carefully.
>>They are generally terse but complete, especially the base docs, and
>>you
>>can often find your answers there.
>>
>>3. Your "solution" may work in this case, but if I understand
>correctly
>>what you're after,  won't in general. unique() gives the unique values
>>in
>>the order they appear, which may not be the order you want:
>>
>>## want ordering to be "a" < "b" < "c"
>>
>>> f <- rep(letters[3:1],2)
>>
>>> factor(f, levels = unique(f))
>>[1] c b a c b a
>>Levels: c b a  ## not your desired order
>>
>>Again, please consult the docs and perhaps a tutorial or two as
>>necessary.
>>
>>-- Bert
>>
>>
>>
>>On Wed, Aug 15, 2018 at 8:22 AM, Stats Student
>><stats.student4647 at gmail.com>
>>wrote:
>>
>>> Many thanks, Bert.
>>>
>>> I did -
>>>
>>> facet_wrap(~factor(var, levels=unique (var))
>>>
>>> And it seems to be working fine.
>>> Do you see any issues with this?
>>>
>>> I'm fairly new to R so want to make sure I'm not doing something
>>stupid.
>>>
>>> Thanks again.
>>>
>>> On Wed, Aug 15, 2018, 7:50 AM Bert Gunter <bgunter.4567 at gmail.com>
>>wrote:
>>>
>>>> See ?factor.
>>>>
>>>> You can either use ?ordered to create an ordered factor to sort the
>>>> levels as you desire or sort them with factor(). e.g.
>>>>
>>>> > f <- factor(letters[3:1])
>>>> > f
>>>> [1] c b a
>>>> Levels: a b c   ## default ordering
>>>>
>>>> > f <- factor(f, levels = letters[3:1])
>>>> > f
>>>> [1] c b a
>>>> Levels: c b a  ## explicit ordering
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming
>>along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>> On Wed, Aug 15, 2018 at 7:21 AM, Stats Student <
>>>> stats.student4647 at gmail.com> wrote:
>>>>
>>>>> Hi, I am generating multiple charts with facet_wrap() and what
>what
>>I
>>>>> see, R/ggplot sorts the panels by the facet variable. So adding an
>>index to
>>>>> the facet variable (1 - bucket, 2 - bucket, etc) does solve the
>>sorting
>>>>> issue but it's ugly.
>>>>>
>>>>> I also read this post which, if I understand correctly, claims
>that
>>>>> ggplot should be using the initial ordering of the data for
>>ordering the
>>>>> charts (instead of ordering the data itself).
>>>>>
>>>>> https://mvuorre.github.io/post/2016/order-ggplot-panel-plots/
>>>>>
>>>>> Wondering if anyone knows how to direct ggplot use the initial
>>sorting
>>>>> of the data to order the panels.
>>>>>
>>>>> Thank you.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From citc m@iii@g oii disroot@org  Fri Aug 17 13:55:43 2018
From: citc m@iii@g oii disroot@org (citc m@iii@g oii disroot@org)
Date: Fri, 17 Aug 2018 11:55:43 +0000
Subject: [R] bar plot add space to group data
Message-ID: <0283514711d8183ac79b865fd07f041d@disroot.org>

R-users,

Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.

barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
years<-c(2014,2015,2016,2017,2018)
mtext(years, side=1, at=c(5, 12, 19, 26, 33))
R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))

	[[alternative HTML version deleted]]



From cry@n @end|ng |rom b|ngh@mton@edu  Fri Aug 17 15:19:53 2018
From: cry@n @end|ng |rom b|ngh@mton@edu (Chris Ryan)
Date: Fri, 17 Aug 2018 09:19:53 -0400
Subject: [R] bar plot add space to group data
In-Reply-To: <0283514711d8183ac79b865fd07f041d@disroot.org>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
Message-ID: <A1BC743A-62DC-4B44-934A-F0601A2349C9@binghamton.edu>

Using the lattice package would provide an easy way to distinguish years, by putting them in different panels. Lattice would also help avoid some other features of this graph that, in my opinion, are suboptimal. See Tufte or Cleveland. 

Chris Ryan
-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.

On August 17, 2018 7:55:43 AM EDT, citc at disroot.org wrote:
>R-users,
>
>Can someone please advise how to improve the code below that was used
>to produce the graph shown at the following hyperlink
>(https://chemistryinthecity.neocities.org/content/entry1808.html#17)?
>The request is to add space between the annual data groups.
>
>barplot(gceac[,3], xlab='year', ylab='percentage of each grade',
>col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen',
>'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40,
>y = 30, title='grades'), main='A-level grades, chemistry', beside=T,
>space=c(0,2), ylim=c(0,30))
>years<-c(2014,2015,2016,2017,2018)
>mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>R-users, Can someone please advise how to improve the code below that
>was used to produce the graph shown at the following hyperlink
>(https://chemistryinthecity.neocities.org/content/entry1808.html#17)?
>The request is to add space between the annual data groups. 
>barplot(gceac[,3], xlab='year', ylab='percentage of each grade',
>col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen',
>'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40,
>y = 30, title='grades'), main='A-level grades, chemistry', beside=T,
>space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018)
>mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From |@r|dcher @end|ng |rom gm@||@com  Fri Aug 17 16:07:59 2018
From: |@r|dcher @end|ng |rom gm@||@com (Faridedin Cheraghi)
Date: Fri, 17 Aug 2018 18:37:59 +0430
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
 <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
 <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>
Message-ID: <CAJTBV4ULDuRNuvK5pADmXjKOLKa4VxDPHAtFG_gMvH3XLe9w3w@mail.gmail.com>

Dear Duncan,

thanks for your feedback on this. Even though most developers are not in
Windows (which I doubt it), there are a huge number of people who use R on
Windows and I am one of them who seriously work with R. Following my own
workaround to this bug, now I hit another issue with another workaround
when trying to render the Farsi Unicode characters. While these workarounds
work in ad hoc, they are not appealing in all scenarios;I hit other
problems related to this bug, e.g., when documenting a package with
Roxygen2 package.

Please see the attached files (r scripts) for the complete bug report.

thanks
Farid

On Sun, Aug 12, 2018 at 9:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 12/08/2018 11:48 AM, Faridedin Cheraghi wrote:
>
>> that's right and I don't want to change my locale. my sessionInfo() :
>>
>
> I think it could be another manifestation of a known bug on Windows, where
> strings are converted from UTF-8 to the current locale and back to UTF-8, a
> lossy conversion.  This has been present for many years, and requires a lot
> of internal changes to fix, so I wouldn't hold your breath waiting for a
> fix.
>
> I believe the "right" fix is for R to always convert strings to UTF-8
> internally.  This wasn't possible when the internationalization code was
> added many years ago because not all platforms supported UTF-8.  It would
> be a lot of work now, and since it isn't needed now on the platforms most
> developers use, it's not receiving a lot of attention.
>
> Your workaround
>
> file(script,
>      encoding = "UTF-8") %T>%
>      source() %>%
>      close()   # works fine
>
> is a nice way to avoid this problem.
>
> Duncan Murdoch
>
>
>> R version 3.5.1 (2018-07-02)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> thanks
>>
>> On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
>>
>>         It was actually a .rmd file so you can get the coloring of the
>>         bug report
>>         in your text editor. I changed the format to .txt.
>>
>>
>>     When I run your script on a Mac (in a UTF-8 locale), all lines work
>>     as expected.  I'm guessing you are working on Windows, in a
>>     non-UTF-8 locale?
>>
>>     Posting sessionInfo() would be helpful.
>>
>>     Duncan Murdoch
>>
>>
>>
>>         -Farid
>>
>>         On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller
>>         <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>
>>         wrote:
>>
>>             ... and read the Posting Guide... only a few file types will
>>             ever make it
>>             through the mailing list so repeatedly sending files not
>>             among those few
>>             types would just be frustrating for everyone.
>>
>>             On August 11, 2018 4:51:43 PM PDT, Jim Lemon
>>             <drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>> wrote:
>>
>>                 Hi Farid,
>>                 Whatever you attached has not gotten through.
>>
>>                 Jim
>>
>>                 On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch
>>                 <faridcher at gmail.com <mailto:faridcher at gmail.com>> wrote:
>>
>>                     Hi all,
>>
>>                     Please check the attached file.
>>
>>                     Thanks
>>                     Farid
>>
>>
>>                     ______________________________________________
>>                     R-help at r-project.org <mailto:R-help at r-project.org>
>>                     mailing list -- To UNSUBSCRIBE and more, see
>>                     https://stat.ethz.ch/mailman/listinfo/r-help
>>                     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                     PLEASE do read the posting guide
>>
>>                 http://www.R-project.org/posting-guide.html
>>                 <http://www.R-project.org/posting-guide.html>
>>
>>                     and provide commented, minimal, self-contained,
>>                     reproducible code.
>>
>>
>>                 ______________________________________________
>>                 R-help at r-project.org <mailto:R-help at r-project.org>
>>                 mailing list -- To UNSUBSCRIBE and more, see
>>                 https://stat.ethz.ch/mailman/listinfo/r-help
>>                 <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                 PLEASE do read the posting guide
>>                 http://www.R-project.org/posting-guide.html
>>                 <http://www.R-project.org/posting-guide.html>
>>                 and provide commented, minimal, self-contained,
>>                 reproducible code.
>>
>>
>>             --
>>             Sent from my phone. Please excuse my brevity.
>>
>>
>>
>>             ______________________________________________
>>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>             list -- To UNSUBSCRIBE and more, see
>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>             PLEASE do read the posting guide
>>             http://www.R-project.org/posting-guide.html
>>             <http://www.R-project.org/posting-guide.html>
>>             and provide commented, minimal, self-contained, reproducible
>>             code.
>>
>>
>>
>>
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: bug01_right.png
Type: image/png
Size: 3913 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180817/0f754c29/attachment-0004.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: bug01_wrong.png
Type: image/png
Size: 6462 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180817/0f754c29/attachment-0005.png>

From dc@r|@on @end|ng |rom t@mu@edu  Fri Aug 17 16:37:28 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Fri, 17 Aug 2018 14:37:28 +0000
Subject: [R] bar plot add space to group data
In-Reply-To: <0283514711d8183ac79b865fd07f041d@disroot.org>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
Message-ID: <ef12bce1db1c412e8c02a2b6e26c879e@tamu.edu>

Notice below that your message is substantially scrambled. R-Help is a plain text only list so you should set your email client to produce plain text messages. 

The best place to start is with the manual page for the barplot() function:

?barplot or help(barplot)

You will find the description of the space= argument useful.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of citc at disroot.org
Sent: Friday, August 17, 2018 6:56 AM
To: r-help at r-project.org
Subject: [R] bar plot add space to group data

R-users,

Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.

barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
years<-c(2014,2015,2016,2017,2018)
mtext(years, side=1, at=c(5, 12, 19, 26, 33)) R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From j@p@rk4 @end|ng |rom u|c@edu  Fri Aug 17 19:34:07 2018
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Fri, 17 Aug 2018 17:34:07 +0000
Subject: [R] CARET NN Too Much Output Even with Trace=False
Message-ID: <SN6PR05MB4816206A6C9610E1F707C4FAFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>

Hi R Helpers,


I am using the Neural Net build in the CARET package and it produces a large amount of output that I don't need to see and interferes with my ability to get to the output that I want to see.  I am using the nnet.trace=FALSE setting, but still getting a disproportionate amount of output from this one procedure.


Is there another option setting that will turn off this output?


Reproducible example is below.  It has a little extra complication in it because I hacked it from a post.  Let me know if I need to do anything to it to make it more use-able.


Many thanks.

--John Sparks


library('caret')
set.seed(1)

data<-read.csv(url('https://datahack-prod.s3.ap-south-1.amazonaws.com/train_file/train_u6lujuX_CVtuZ9i.csv'))

#Imputing missing values using median
preProcValues <- preProcess(data, method = c("medianImpute","center","scale"))
library('RANN')
data_processed <- predict(preProcValues, data)
index <- createDataPartition(data_processed$Loan_Status, p=0.75, list=FALSE)
trainSet <- data_processed[ index,]
testSet <- data_processed[-index,]
fitControl <- trainControl(method = "cv",number = 5,savePredictions = 'final',classProbs = T)

trainSet<-subset(trainSet,select=-c(Loan_ID))
outcomeName<-"Loan_Status"
predictors<-names(trainSet)[!names(trainSet) %in% outcomeName]

NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',trControl=fitControl,tuneLength=5,nnet.trace=FALSE)



	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Fri Aug 17 19:45:28 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 17 Aug 2018 10:45:28 -0700
Subject: [R] CARET NN Too Much Output Even with Trace=False
In-Reply-To: <SN6PR05MB4816206A6C9610E1F707C4FAFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>
References: <SN6PR05MB4816206A6C9610E1F707C4FAFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>
Message-ID: <CAF8bMca8LjrspqHrv+GzZqzbLGRbNO59y_VCr3bmZk1epoutoA@mail.gmail.com>

You can use capture.output to store all that tracing information in a
character vector instead of having it printed.  You can look at it to
diagnose problems or just throw it away.

NN.text  <-
capture.output(NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',trControl=fitControl,tuneLength=5,nnet.trace=FALSE))

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 17, 2018 at 10:34 AM, Sparks, John <jspark4 at uic.edu> wrote:

> Hi R Helpers,
>
>
> I am using the Neural Net build in the CARET package and it produces a
> large amount of output that I don't need to see and interferes with my
> ability to get to the output that I want to see.  I am using the
> nnet.trace=FALSE setting, but still getting a disproportionate amount of
> output from this one procedure.
>
>
> Is there another option setting that will turn off this output?
>
>
> Reproducible example is below.  It has a little extra complication in it
> because I hacked it from a post.  Let me know if I need to do anything to
> it to make it more use-able.
>
>
> Many thanks.
>
> --John Sparks
>
>
> library('caret')
> set.seed(1)
>
> data<-read.csv(url('https://datahack-prod.s3.ap-south-1.
> amazonaws.com/train_file/train_u6lujuX_CVtuZ9i.csv'))
>
> #Imputing missing values using median
> preProcValues <- preProcess(data, method = c("medianImpute","center","
> scale"))
> library('RANN')
> data_processed <- predict(preProcValues, data)
> index <- createDataPartition(data_processed$Loan_Status, p=0.75,
> list=FALSE)
> trainSet <- data_processed[ index,]
> testSet <- data_processed[-index,]
> fitControl <- trainControl(method = "cv",number = 5,savePredictions =
> 'final',classProbs = T)
>
> trainSet<-subset(trainSet,select=-c(Loan_ID))
> outcomeName<-"Loan_Status"
> predictors<-names(trainSet)[!names(trainSet) %in% outcomeName]
>
> NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',
> trControl=fitControl,tuneLength=5,nnet.trace=FALSE)
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From j@p@rk4 @end|ng |rom u|c@edu  Fri Aug 17 19:51:05 2018
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Fri, 17 Aug 2018 17:51:05 +0000
Subject: [R] CARET NN Too Much Output Even with Trace=False
In-Reply-To: <CAF8bMca8LjrspqHrv+GzZqzbLGRbNO59y_VCr3bmZk1epoutoA@mail.gmail.com>
References: <SN6PR05MB4816206A6C9610E1F707C4FAFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>,
 <CAF8bMca8LjrspqHrv+GzZqzbLGRbNO59y_VCr3bmZk1epoutoA@mail.gmail.com>
Message-ID: <SN6PR05MB481641D65683484F3D9F628BFA3D0@SN6PR05MB4816.namprd05.prod.outlook.com>

Terrific!  Thanks for the speedy and informative reply.


--JJS


________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: Friday, August 17, 2018 12:45 PM
To: Sparks, John
Cc: r-help at r-project.org
Subject: Re: [R] CARET NN Too Much Output Even with Trace=False

You can use capture.output to store all that tracing information in a character vector instead of having it printed.  You can look at it to diagnose problems or just throw it away.

NN.text  <- capture.output(NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',trControl=fitControl,tuneLength=5,nnet.trace=FALSE))

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Fri, Aug 17, 2018 at 10:34 AM, Sparks, John <jspark4 at uic.edu<mailto:jspark4 at uic.edu>> wrote:
Hi R Helpers,


I am using the Neural Net build in the CARET package and it produces a large amount of output that I don't need to see and interferes with my ability to get to the output that I want to see.  I am using the nnet.trace=FALSE setting, but still getting a disproportionate amount of output from this one procedure.


Is there another option setting that will turn off this output?


Reproducible example is below.  It has a little extra complication in it because I hacked it from a post.  Let me know if I need to do anything to it to make it more use-able.


Many thanks.

--John Sparks


library('caret')
set.seed(1)

data<-read.csv(url('https://datahack-prod.s3.ap-south-1.amazonaws.com/train_file/train_u6lujuX_CVtuZ9i.csv'))

#Imputing missing values using median
preProcValues <- preProcess(data, method = c("medianImpute","center","scale"))
library('RANN')
data_processed <- predict(preProcValues, data)
index <- createDataPartition(data_processed$Loan_Status, p=0.75, list=FALSE)
trainSet <- data_processed[ index,]
testSet <- data_processed[-index,]
fitControl <- trainControl(method = "cv",number = 5,savePredictions = 'final',classProbs = T)

trainSet<-subset(trainSet,select=-c(Loan_ID))
outcomeName<-"Loan_Status"
predictors<-names(trainSet)[!names(trainSet) %in% outcomeName]

NN<-train(trainSet[,predictors],trainSet[,outcomeName],method='nnet',trControl=fitControl,tuneLength=5,nnet.trace=FALSE)



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]



From ghk18 @end|ng |rom @c@r|etm@||@rutger@@edu  Fri Aug 17 21:27:05 2018
From: ghk18 @end|ng |rom @c@r|etm@||@rutger@@edu (GALIB KHAN)
Date: Fri, 17 Aug 2018 14:27:05 -0500
Subject: [R] RuGarch issue
Message-ID: <CAKGtyOmmnHJTTg9Aib9_Nhew-rfZJVF-vh0XYxN2kcrFvfDLEg@mail.gmail.com>

Sup guys,

Got an interesting issue with the rugarch package.

I noticed that when I changed the order of the external regressors, there
are different values for the robust coefficient matrix. The values should be
the same (according to the ordering of the variables). However, I am getting
drastically different results. At that time the model was arma(2,2) +
garch(1,0).

Is this considered a normal behavior of the rugarch package? I assume that
when you change the ordering of the external regressors the output should be
exactly the same....digit by digit.

I confirmed this issue by creating a generic script that can be tested by
anyone. Has anybody faced this issue before or is there post that describes
the issue that I am facing?

  Maybe I am going insane...for now I will look further into the
documentation that our Alexios has provided

Thanks!
  library(rugarch)


set.seed(1)

x1 <- rnorm(1000,5,1)
x2 <- rnorm(1000,3,3)

y    <- .5*(x1*x2) + rnorm(1000,1,3)
dat  <- data.frame(x1,x2,y)

var1 <- c("x1","x2")
var2 <- c("x2","x1")

# setbounds(spec)<-list(vxreg1=c(-1,1))
model_maker <- function(x_name){
  temp <- dat[,c("y",x_name)]

  spec <- ugarchspec(variance.model      = list(model = "sGARCH",
                                                garchOrder = c(1,0)),

                     mean.model          = list(armaOrder = c(2,2),
                                                external.regressors =
as.matrix(temp[,x_name]),
                                                include.mean= T),

                     distribution.model  = "std")

  fit         <- ugarchfit(spec = spec, data = as.matrix(temp$y),solver =
"hybrid")
  return(fit at fit$robust.matcoef)}

model_maker(var1)
model_maker(var2)

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug 17 22:57:54 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 17 Aug 2018 16:57:54 -0400
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <CAJTBV4ULDuRNuvK5pADmXjKOLKa4VxDPHAtFG_gMvH3XLe9w3w@mail.gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
 <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
 <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>
 <CAJTBV4ULDuRNuvK5pADmXjKOLKa4VxDPHAtFG_gMvH3XLe9w3w@mail.gmail.com>
Message-ID: <8e7ca2ae-1e7e-83f2-1d5e-a6bb780af55d@gmail.com>

On 17/08/2018 10:07 AM, Faridedin Cheraghi wrote:
> Dear Duncan,
> 
> thanks for your feedback on this. Even though most developers are not in 
> Windows (which I doubt it),

I'm talking about the R Core developers.  I used to be one, but have 
retired from that role.

  there are a huge number of people who use R
> on Windows and I am one of them who seriously work with R.

Indeed, Microsoft promotes R, and they have a lot of developers; they 
just don't contribute much to R.  Honestly I'd suggest that if you are 
serious about working with languages not supported in the default code 
page, you should switch platforms.

> Following my 
> own workaround to this bug, now?I hit another issue with another 
> workaround when trying to render the Farsi Unicode characters. While 
> these workarounds work in ad hoc, they are not appealing in all 
> scenarios;I hit other problems related to this bug, e.g., when 
> documenting a package with Roxygen2 package.
> 
> Please see the attached files (r scripts) for the complete bug report.

If you think this is a new bug, you should report it to the bug tracking 
system (which requires you to be registered first).  Posting it to me or 
to R-help will probably not result in any action on it.  Posting it to 
the bug page will at least result in a fairly permanent record.

Duncan Murdoch
> 
> thanks
> Farid
> 
> On Sun, Aug 12, 2018 at 9:03 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 12/08/2018 11:48 AM, Faridedin Cheraghi wrote:
> 
>         that's right and I don't want to change my locale. my
>         sessionInfo() :
> 
> 
>     I think it could be another manifestation of a known bug on Windows,
>     where strings are converted from UTF-8 to the current locale and
>     back to UTF-8, a lossy conversion.? This has been present for many
>     years, and requires a lot of internal changes to fix, so I wouldn't
>     hold your breath waiting for a fix.
> 
>     I believe the "right" fix is for R to always convert strings to
>     UTF-8 internally.? This wasn't possible when the
>     internationalization code was added many years ago because not all
>     platforms supported UTF-8.? It would be a lot of work now, and since
>     it isn't needed now on the platforms most developers use, it's not
>     receiving a lot of attention.
> 
>     Your workaround
> 
>     file(script,
>      ? ? ?encoding = "UTF-8") %T>%
>      ? ? ?source() %>%
>      ? ? ?close()? ?# works fine
> 
>     is a nice way to avoid this problem.
> 
>     Duncan Murdoch
> 
> 
>         R version 3.5.1 (2018-07-02)
>         Platform: x86_64-w64-mingw32/x64 (64-bit)
>         Running under: Windows >= 8 x64 (build 9200)
> 
>         Matrix products: default
> 
>         locale:
>         [1] LC_COLLATE=English_United States.1252
>         [2] LC_CTYPE=English_United States.1252
>         [3] LC_MONETARY=English_United States.1252
>         [4] LC_NUMERIC=C
>         [5] LC_TIME=English_United States.1252
> 
>         attached base packages:
>         [1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
> 
>         thanks
> 
>         On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch
>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>         <mailto:murdoch.duncan at gmail.com
>         <mailto:murdoch.duncan at gmail.com>>> wrote:
> 
>          ? ? On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
> 
>          ? ? ? ? It was actually a .rmd file so you can get the coloring
>         of the
>          ? ? ? ? bug report
>          ? ? ? ? in your text editor. I changed the format to .txt.
> 
> 
>          ? ? When I run your script on a Mac (in a UTF-8 locale), all
>         lines work
>          ? ? as expected.? I'm guessing you are working on Windows, in a
>          ? ? non-UTF-8 locale?
> 
>          ? ? Posting sessionInfo() would be helpful.
> 
>          ? ? Duncan Murdoch
> 
> 
> 
>          ? ? ? ? -Farid
> 
>          ? ? ? ? On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller
>          ? ? ? ? <jdnewmil at dcn.davis.ca.us
>         <mailto:jdnewmil at dcn.davis.ca.us>
>         <mailto:jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>>
>          ? ? ? ? wrote:
> 
>          ? ? ? ? ? ? ... and read the Posting Guide... only a few file
>         types will
>          ? ? ? ? ? ? ever make it
>          ? ? ? ? ? ? through the mailing list so repeatedly sending
>         files not
>          ? ? ? ? ? ? among those few
>          ? ? ? ? ? ? types would just be frustrating for everyone.
> 
>          ? ? ? ? ? ? On August 11, 2018 4:51:43 PM PDT, Jim Lemon
>          ? ? ? ? ? ? <drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>         <mailto:drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>>> wrote:
> 
>          ? ? ? ? ? ? ? ? Hi Farid,
>          ? ? ? ? ? ? ? ? Whatever you attached has not gotten through.
> 
>          ? ? ? ? ? ? ? ? Jim
> 
>          ? ? ? ? ? ? ? ? On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch
>          ? ? ? ? ? ? ? ? <faridcher at gmail.com
>         <mailto:faridcher at gmail.com> <mailto:faridcher at gmail.com
>         <mailto:faridcher at gmail.com>>> wrote:
> 
>          ? ? ? ? ? ? ? ? ? ? Hi all,
> 
>          ? ? ? ? ? ? ? ? ? ? Please check the attached file.
> 
>          ? ? ? ? ? ? ? ? ? ? Thanks
>          ? ? ? ? ? ? ? ? ? ? Farid
> 
> 
>          ? ? ? ? ? ? ? ? ? ? ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>          ? ? ? ? ? ? ? ? ? ? mailing list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>                             
>         <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>          ? ? ? ? ? ? ? ? ? ? PLEASE do read the posting guide
> 
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>          ? ? ? ? ? ? ? ? <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
> 
>          ? ? ? ? ? ? ? ? ? ? and provide commented, minimal, self-contained,
>          ? ? ? ? ? ? ? ? ? ? reproducible code.
> 
> 
>          ? ? ? ? ? ? ? ? ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>          ? ? ? ? ? ? ? ? mailing list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>          ? ? ? ? ? ? ? ? <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>          ? ? ? ? ? ? ? ? PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>          ? ? ? ? ? ? ? ? <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>          ? ? ? ? ? ? ? ? and provide commented, minimal, self-contained,
>          ? ? ? ? ? ? ? ? reproducible code.
> 
> 
>          ? ? ? ? ? ? --
>          ? ? ? ? ? ? Sent from my phone. Please excuse my brevity.
> 
> 
> 
>          ? ? ? ? ? ? ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing
>          ? ? ? ? ? ? list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>          ? ? ? ? ? ? <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>          ? ? ? ? ? ? PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>          ? ? ? ? ? ? <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>          ? ? ? ? ? ? and provide commented, minimal, self-contained,
>         reproducible
>          ? ? ? ? ? ? code.
> 
> 
> 
> 
>



From phiiipsm m@iii@g oii cp@@ei1@stormweb@@et  Fri Aug 17 22:06:41 2018
From: phiiipsm m@iii@g oii cp@@ei1@stormweb@@et (phiiipsm m@iii@g oii cp@@ei1@stormweb@@et)
Date: Fri, 17 Aug 2018 16:06:41 -0400
Subject: [R] Finding and changing .Rprofile
Message-ID: <20180817160641.Horde.WjbChzhPRGG_mctw3k74ENm@webmail.philipsmith.ca>

I would like to change my .Rprofile file, but I cannot find it. I use  
a Mac Pro and RStudio. I believe the file is a hidden file and I have  
checked for it accordingly. I can not find it with a Spotlight search.  
It is not in my "default working directory". Is that the same thing as  
my "home directory"? I believe I can put a new .Rprofile file in any  
project directory, but that is not what I want to do. I want a  
.Rprofile file that will apply automatically whenever I start working  
on another project. Was one installed automatically when I installed R  
and RStudio many months ago and if so, where can I find it? If it was  
not installed automatically and I have to create my own, where should  
I put it?



From z267xu @end|ng |rom uw@ter|oo@c@  Fri Aug 17 23:32:07 2018
From: z267xu @end|ng |rom uw@ter|oo@c@ (Zehao Xu)
Date: Fri, 17 Aug 2018 21:32:07 +0000
Subject: [R] How to rotate label in tcltk R
Message-ID: <9d0c17f29c10498e8fa4eb7c0499aacd@uwaterloo.ca>

Dear sir (ma'am)

I just start the tcltk in R. I face a problem, how to rotate the labels in tcltk? I post the example on https://stackoverflow.com/questions/51825771/how-to-rotate-labels-in-tcltk.


Thank you

Z Xu



	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Aug 18 00:08:19 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 17 Aug 2018 15:08:19 -0700 (PDT)
Subject: [R] Understanding read.csv error message
Message-ID: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>

   I have a data file, 'precip_projected.csv,' that starts like this:

name,easting,northing,elev,sampdate,prcp
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02

   There are a bunch of NAs in the data file.

   The command to read it produces an error:

rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)

Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
   replacement has 0 rows, data has 113569

   Is the error generated by finding a date that looks like the number zero
or by a prcp value of zero?

   BTW, I get the same error if I specify stringsAsFactors = F.

TIA,

Rich



From m@rc_@chw@rtz @end|ng |rom me@com  Sat Aug 18 00:17:57 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 17 Aug 2018 18:17:57 -0400
Subject: [R] Finding and changing .Rprofile
In-Reply-To: <20180817160641.Horde.WjbChzhPRGG_mctw3k74ENm@webmail.philipsmith.ca>
References: <20180817160641.Horde.WjbChzhPRGG_mctw3k74ENm@webmail.philipsmith.ca>
Message-ID: <93B2254D-438F-460B-8A12-65CC3D1B2C7C@me.com>


> On Aug 17, 2018, at 4:06 PM, philipsm at cpanel1.stormweb.net wrote:
> 
> I would like to change my .Rprofile file, but I cannot find it. I use a Mac Pro and RStudio. I believe the file is a hidden file and I have checked for it accordingly. I can not find it with a Spotlight search. It is not in my "default working directory". Is that the same thing as my "home directory"? I believe I can put a new .Rprofile file in any project directory, but that is not what I want to do. I want a .Rprofile file that will apply automatically whenever I start working on another project. Was one installed automatically when I installed R and RStudio many months ago and if so, where can I find it? If it was not installed automatically and I have to create my own, where should I put it?


Hi, 

As an FYI, there is a dedicated R list for macOS users:

  https://stat.ethz.ch/mailman/listinfo/r-sig-mac

which should be used for macOS specific questions vis-a-vis R.

The default .Rprofile is stored in your user home folder, which is /Users/YourUserName/.Rprofile or abbreviated as ~/.Rprofile.

As you note, because it is a hidden file, with a leading '.', Finder and Spotlight will not show it by default.

You can change that behavior relative to hidden files, by opening a Terminal and using the following command:

  defaults write com.apple.finder AppleShowAllFiles TRUE

then restart Finder, by using Alt-RightClick on the Finder icon in the dock and selecting Relaunch. You can reverse that behavior by changing the TRUE to FALSE in the above command.

If you don't want to make that global change, you can use the following command in a Terminal session:

  open -a Textedit ~/.Rprofile

That will bring up the Textedit editor application with the file loaded. You can then edit the file content and save it. 

Whichever way you edit the file, be sure to restart any R sessions you have running, so that future R sessions will pick up the changes.

Making the change to that file will generally affect all R sessions for your user profile.

I don't use RStudio, so it may have other relevant features, and they have their own support lists linked on their site.

Regards,

Marc Schwartz



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 18 00:22:45 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 18 Aug 2018 10:22:45 +1200
Subject: [R] bar plot add space to group data
In-Reply-To: <ef12bce1db1c412e8c02a2b6e26c879e@tamu.edu>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <ef12bce1db1c412e8c02a2b6e26c879e@tamu.edu>
Message-ID: <56e7fda9-284c-b16c-e3e5-f8460c34747c@auckland.ac.nz>


On 18/08/18 02:37, David L Carlson wrote:

> Notice below that your message is substantially scrambled. R-Help is a
> plain text only list so you should set your email client to produce plain text messages.
> 
> The best place to start is with the manual page for the barplot() function:
> 
> ?barplot or help(barplot)
> 
> You will find the description of the space= argument useful.

<SNIP>

If one struggles through the garbled html bumff, one sees that the OP 
*did* indeed use the "space=" argument.  However it does not appear to 
have had the desired effect, and I cannot see why.  Since the OP did not 
supply the data, I cannot experiment.

Perhaps someone else will have some insight.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From m@cqueen1 @end|ng |rom ||n|@gov  Sat Aug 18 02:03:25 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Sat, 18 Aug 2018 00:03:25 +0000
Subject: [R] Understanding read.csv error message
In-Reply-To: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
Message-ID: <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>

Hi Rich,

It's not obvious what would be causing that error from read.csv. But here's what I would probably try:

Add quote='"" to your arguments. The default is to use surround text strings with double quotes, but your file doesn't.

Copy the first few rows into another file and try it. If it succeeds, that would suggest something later on in the file is causing the problem.

The argument sep=','   is redundant for read.csv. In other words, it sets sep for you. I'd try switching to the more general read.table.

Are the NAs in the file indicated by NA between a pair of commas? Or do you have successive commas with nothing between them for NA? Not sure what difference it will make, but it might affect what args you pass to read.table.

Are you absolutely sure there are never any commas in the name?

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/17/18, 3:08 PM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       I have a data file, 'precip_projected.csv,' that starts like this:
    
    name,easting,northing,elev,sampdate,prcp
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
    Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02
    
       There are a bunch of NAs in the data file.
    
       The command to read it produces an error:
    
    rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)
    
    Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
       replacement has 0 rows, data has 113569
    
       Is the error generated by finding a date that looks like the number zero
    or by a prcp value of zero?
    
       BTW, I get the same error if I specify stringsAsFactors = F.
    
    TIA,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @end|ng |rom ||n|@gov  Sat Aug 18 02:07:56 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Sat, 18 Aug 2018 00:07:56 +0000
Subject: [R] Understanding read.csv error message
In-Reply-To: <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
 <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>
Message-ID: <732F05DD-7FCF-4509-8502-C58DDF33B273@llnl.gov>

small typo in previous: should be
  quote=""
(I left behind a single quote by mistake)

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/17/18, 5:03 PM, "R-help on behalf of MacQueen, Don via R-help" <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

    Hi Rich,
    
    It's not obvious what would be causing that error from read.csv. But here's what I would probably try:
    
    Add quote='"" to your arguments. The default is to use surround text strings with double quotes, but your file doesn't.
    
    Copy the first few rows into another file and try it. If it succeeds, that would suggest something later on in the file is causing the problem.
    
    The argument sep=','   is redundant for read.csv. In other words, it sets sep for you. I'd try switching to the more general read.table.
    
    Are the NAs in the file indicated by NA between a pair of commas? Or do you have successive commas with nothing between them for NA? Not sure what difference it will make, but it might affect what args you pass to read.table.
    
    Are you absolutely sure there are never any commas in the name?
    
    -Don
    
    --
    Don MacQueen
    Lawrence Livermore National Laboratory
    7000 East Ave., L-627
    Livermore, CA 94550
    925-423-1062
    Lab cell 925-724-7509
     
     
    
    On 8/17/18, 3:08 PM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:
    
           I have a data file, 'precip_projected.csv,' that starts like this:
        
        name,easting,northing,elev,sampdate,prcp
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
        Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02
        
           There are a bunch of NAs in the data file.
        
           The command to read it produces an error:
        
        rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)
        
        Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
           replacement has 0 rows, data has 113569
        
           Is the error generated by finding a date that looks like the number zero
        or by a prcp value of zero?
        
           BTW, I get the same error if I specify stringsAsFactors = F.
        
        TIA,
        
        Rich
        
        ______________________________________________
        R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
        https://stat.ethz.ch/mailman/listinfo/r-help
        PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
        and provide commented, minimal, self-contained, reproducible code.
        
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From phiiipsm m@iii@g oii cp@@ei1@stormweb@@et  Sat Aug 18 01:55:55 2018
From: phiiipsm m@iii@g oii cp@@ei1@stormweb@@et (phiiipsm m@iii@g oii cp@@ei1@stormweb@@et)
Date: Fri, 17 Aug 2018 19:55:55 -0400
Subject: [R] Finding and changing .Rprofile
In-Reply-To: <93B2254D-438F-460B-8A12-65CC3D1B2C7C@me.com>
References: <20180817160641.Horde.WjbChzhPRGG_mctw3k74ENm@webmail.philipsmith.ca>
 <93B2254D-438F-460B-8A12-65CC3D1B2C7C@me.com>
Message-ID: <20180817195555.Horde.SFShsFKx05HL5opVSej9nam@webmail.philipsmith.ca>

Thanks!


Quoting Marc Schwartz <marc_schwartz at me.com>:

>> On Aug 17, 2018, at 4:06 PM, philipsm at cpanel1.stormweb.net wrote:
>>
>> I would like to change my .Rprofile file, but I cannot find it. I  
>> use a Mac Pro and RStudio. I believe the file is a hidden file and  
>> I have checked for it accordingly. I can not find it with a  
>> Spotlight search. It is not in my "default working directory". Is  
>> that the same thing as my "home directory"? I believe I can put a  
>> new .Rprofile file in any project directory, but that is not what I  
>> want to do. I want a .Rprofile file that will apply automatically  
>> whenever I start working on another project. Was one installed  
>> automatically when I installed R and RStudio many months ago and if  
>> so, where can I find it? If it was not installed automatically and  
>> I have to create my own, where should I put it?
>
>
> Hi,
>
> As an FYI, there is a dedicated R list for macOS users:
>
>   https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>
> which should be used for macOS specific questions vis-a-vis R.
>
> The default .Rprofile is stored in your user home folder, which is  
> /Users/YourUserName/.Rprofile or abbreviated as ~/.Rprofile.
>
> As you note, because it is a hidden file, with a leading '.', Finder  
> and Spotlight will not show it by default.
>
> You can change that behavior relative to hidden files, by opening a  
> Terminal and using the following command:
>
>   defaults write com.apple.finder AppleShowAllFiles TRUE
>
> then restart Finder, by using Alt-RightClick on the Finder icon in  
> the dock and selecting Relaunch. You can reverse that behavior by  
> changing the TRUE to FALSE in the above command.
>
> If you don't want to make that global change, you can use the  
> following command in a Terminal session:
>
>   open -a Textedit ~/.Rprofile
>
> That will bring up the Textedit editor application with the file  
> loaded. You can then edit the file content and save it.
>
> Whichever way you edit the file, be sure to restart any R sessions  
> you have running, so that future R sessions will pick up the changes.
>
> Making the change to that file will generally affect all R sessions  
> for your user profile.
>
> I don't use RStudio, so it may have other relevant features, and  
> they have their own support lists linked on their site.
>
> Regards,
>
> Marc Schwartz



From ghk18 @end|ng |rom @c@r|etm@||@rutger@@edu  Sat Aug 18 04:19:09 2018
From: ghk18 @end|ng |rom @c@r|etm@||@rutger@@edu (GALIB KHAN)
Date: Fri, 17 Aug 2018 21:19:09 -0500
Subject: [R] RuGarch issue
In-Reply-To: <CAKGtyOmmnHJTTg9Aib9_Nhew-rfZJVF-vh0XYxN2kcrFvfDLEg@mail.gmail.com>
References: <CAKGtyOmmnHJTTg9Aib9_Nhew-rfZJVF-vh0XYxN2kcrFvfDLEg@mail.gmail.com>
Message-ID: <CAKGtyOmKsBf7mYhycjf2YHbpSVx0X6kOv8s5mwWzfMakRK7g7A@mail.gmail.com>

this post has been submitted to r-sig-finance

Galib Khan
Rutgers Business School '18
Business Analytics and Information Technology
(609) 412-3654

On Fri, Aug 17, 2018 at 2:27 PM, GALIB KHAN <ghk18 at scarletmail.rutgers.edu>
wrote:

> Sup guys,
>
> Got an interesting issue with the rugarch package.
>
> I noticed that when I changed the order of the external regressors, there
> are different values for the robust coefficient matrix. The values should
> be
> the same (according to the ordering of the variables). However, I am
> getting
> drastically different results. At that time the model was arma(2,2) +
> garch(1,0).
>
> Is this considered a normal behavior of the rugarch package? I assume that
> when you change the ordering of the external regressors the output should
> be
> exactly the same....digit by digit.
>
> I confirmed this issue by creating a generic script that can be tested by
> anyone. Has anybody faced this issue before or is there post that describes
> the issue that I am facing?
>
>   Maybe I am going insane...for now I will look further into the
> documentation that our Alexios has provided
>
> Thanks!
>   library(rugarch)
>
>
> set.seed(1)
>
> x1 <- rnorm(1000,5,1)
> x2 <- rnorm(1000,3,3)
>
> y    <- .5*(x1*x2) + rnorm(1000,1,3)
> dat  <- data.frame(x1,x2,y)
>
> var1 <- c("x1","x2")
> var2 <- c("x2","x1")
>
> # setbounds(spec)<-list(vxreg1=c(-1,1))
> model_maker <- function(x_name){
>   temp <- dat[,c("y",x_name)]
>
>   spec <- ugarchspec(variance.model      = list(model = "sGARCH",
>                                                 garchOrder = c(1,0)),
>
>                      mean.model          = list(armaOrder = c(2,2),
>                                                 external.regressors =
> as.matrix(temp[,x_name]),
>                                                 include.mean= T),
>
>                      distribution.model  = "std")
>
>   fit         <- ugarchfit(spec = spec, data = as.matrix(temp$y),solver =
> "hybrid")
>   return(fit at fit$robust.matcoef)}
>
> model_maker(var1)
> model_maker(var2)
>

	[[alternative HTML version deleted]]



From |@r|dcher @end|ng |rom gm@||@com  Sat Aug 18 10:15:26 2018
From: |@r|dcher @end|ng |rom gm@||@com (Faridedin Cheraghi)
Date: Sat, 18 Aug 2018 12:45:26 +0430
Subject: [R] 
 source script file that contains Unicode non-English characters
In-Reply-To: <8e7ca2ae-1e7e-83f2-1d5e-a6bb780af55d@gmail.com>
References: <BN6PR18MB0948AE89407948FE7703EBA2F53B0@BN6PR18MB0948.namprd18.prod.outlook.com>
 <CA+8X3fUx6gLKiaKfp4xXz-nw_ZwqmU8L9Ph8CysXcQkPkGK94Q@mail.gmail.com>
 <A2BDC059-F76B-41E4-B745-6D37299703F1@dcn.davis.ca.us>
 <CAJTBV4UmoR6sYHjkFWOBoucQskQs7VQp5saQUAwR4C6fmnJnsA@mail.gmail.com>
 <64144f28-05b9-8d36-2a3f-641828ca7b12@gmail.com>
 <CAJTBV4WqVQo4v6Vxh39yOL+4H5CdmEAxYO5ar1OJ7RicK73xOQ@mail.gmail.com>
 <b37de0d7-5609-d8e6-c9ec-044cde53ec91@gmail.com>
 <CAJTBV4ULDuRNuvK5pADmXjKOLKa4VxDPHAtFG_gMvH3XLe9w3w@mail.gmail.com>
 <8e7ca2ae-1e7e-83f2-1d5e-a6bb780af55d@gmail.com>
Message-ID: <CAJTBV4U2EQ89n=0nfJPmTssfRNH_+9_0Q-Tr6+=z-SWOU_CN3Q@mail.gmail.com>

Dear Duncan,

thanks again for your response.

>  I'm talking about the R Core developers.

Now it make sense. Those [R Core] are the key words that were omitted in
your original email.

> If you think this is a new bug, you should report it to the bug tracking
system (which requires you to be registered first).  Posting it to me or to
R-help will probably not result in any action on it.  Posting it to the bug
page will at least result in a fairly permanent record.

I already did. Deepayan told me to post it here first to make sure it is
"really" a bug.

Farid.

On Sat, Aug 18, 2018 at 1:27 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 17/08/2018 10:07 AM, Faridedin Cheraghi wrote:
>
>> Dear Duncan,
>>
>> thanks for your feedback on this. Even though most developers are not in
>> Windows (which I doubt it),
>>
>
> I'm talking about the R Core developers.  I used to be one, but have
> retired from that role.
>
>  there are a huge number of people who use R
>
>> on Windows and I am one of them who seriously work with R.
>>
>
> Indeed, Microsoft promotes R, and they have a lot of developers; they just
> don't contribute much to R.  Honestly I'd suggest that if you are serious
> about working with languages not supported in the default code page, you
> should switch platforms.
>
> Following my own workaround to this bug, now I hit another issue with
>> another workaround when trying to render the Farsi Unicode characters.
>> While these workarounds work in ad hoc, they are not appealing in all
>> scenarios;I hit other problems related to this bug, e.g., when documenting
>> a package with Roxygen2 package.
>>
>> Please see the attached files (r scripts) for the complete bug report.
>>
>
> If you think this is a new bug, you should report it to the bug tracking
> system (which requires you to be registered first).  Posting it to me or to
> R-help will probably not result in any action on it.  Posting it to the bug
> page will at least result in a fairly permanent record.
>
> Duncan Murdoch
>
>>
>> thanks
>> Farid
>>
>>
>> On Sun, Aug 12, 2018 at 9:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 12/08/2018 11:48 AM, Faridedin Cheraghi wrote:
>>
>>         that's right and I don't want to change my locale. my
>>         sessionInfo() :
>>
>>
>>     I think it could be another manifestation of a known bug on Windows,
>>     where strings are converted from UTF-8 to the current locale and
>>     back to UTF-8, a lossy conversion.  This has been present for many
>>     years, and requires a lot of internal changes to fix, so I wouldn't
>>     hold your breath waiting for a fix.
>>
>>     I believe the "right" fix is for R to always convert strings to
>>     UTF-8 internally.  This wasn't possible when the
>>     internationalization code was added many years ago because not all
>>     platforms supported UTF-8.  It would be a lot of work now, and since
>>     it isn't needed now on the platforms most developers use, it's not
>>     receiving a lot of attention.
>>
>>     Your workaround
>>
>>     file(script,
>>           encoding = "UTF-8") %T>%
>>           source() %>%
>>           close()   # works fine
>>
>>     is a nice way to avoid this problem.
>>
>>     Duncan Murdoch
>>
>>
>>         R version 3.5.1 (2018-07-02)
>>         Platform: x86_64-w64-mingw32/x64 (64-bit)
>>         Running under: Windows >= 8 x64 (build 9200)
>>
>>         Matrix products: default
>>
>>         locale:
>>         [1] LC_COLLATE=English_United States.1252
>>         [2] LC_CTYPE=English_United States.1252
>>         [3] LC_MONETARY=English_United States.1252
>>         [4] LC_NUMERIC=C
>>         [5] LC_TIME=English_United States.1252
>>
>>         attached base packages:
>>         [1] stats     graphics  grDevices utils     datasets  methods
>>  base
>>
>>         thanks
>>
>>         On Sun, Aug 12, 2018 at 8:00 PM, Duncan Murdoch
>>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>>         <mailto:murdoch.duncan at gmail.com
>>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>>
>>              On 12/08/2018 3:09 AM, Faridedin Cheraghi wrote:
>>
>>                  It was actually a .rmd file so you can get the coloring
>>         of the
>>                  bug report
>>                  in your text editor. I changed the format to .txt.
>>
>>
>>              When I run your script on a Mac (in a UTF-8 locale), all
>>         lines work
>>              as expected.  I'm guessing you are working on Windows, in a
>>              non-UTF-8 locale?
>>
>>              Posting sessionInfo() would be helpful.
>>
>>              Duncan Murdoch
>>
>>
>>
>>                  -Farid
>>
>>                  On Sun, Aug 12, 2018 at 7:24 AM, Jeff Newmiller
>>                  <jdnewmil at dcn.davis.ca.us
>>         <mailto:jdnewmil at dcn.davis.ca.us>
>>         <mailto:jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us
>> >>>
>>                  wrote:
>>
>>                      ... and read the Posting Guide... only a few file
>>         types will
>>                      ever make it
>>                      through the mailing list so repeatedly sending
>>         files not
>>                      among those few
>>                      types would just be frustrating for everyone.
>>
>>                      On August 11, 2018 4:51:43 PM PDT, Jim Lemon
>>                      <drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>>         <mailto:drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>>>
>> wrote:
>>
>>                          Hi Farid,
>>                          Whatever you attached has not gotten through.
>>
>>                          Jim
>>
>>                          On Sat, Aug 11, 2018 at 6:47 PM, Farid Ch
>>                          <faridcher at gmail.com
>>         <mailto:faridcher at gmail.com> <mailto:faridcher at gmail.com
>>         <mailto:faridcher at gmail.com>>> wrote:
>>
>>                              Hi all,
>>
>>                              Please check the attached file.
>>
>>                              Thanks
>>                              Farid
>>
>>
>>                              ______________________________
>> ________________
>>         R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>                              mailing list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                                     <https://stat.ethz.ch/mailman/
>> listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>                              PLEASE do read the posting guide
>>
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>                          <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>
>>                              and provide commented, minimal,
>> self-contained,
>>                              reproducible code.
>>
>>
>>                          ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>                          mailing list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                          <https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>                          PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>                          <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>                          and provide commented, minimal, self-contained,
>>                          reproducible code.
>>
>>
>>                      --
>>                      Sent from my phone. Please excuse my brevity.
>>
>>
>>
>>                      ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>> mailing
>>                      list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                      <https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>                      PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>                      <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>                      and provide commented, minimal, self-contained,
>>         reproducible
>>                      code.
>>
>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Sat Aug 18 10:45:51 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 18 Aug 2018 18:45:51 +1000
Subject: [R] bar plot add space to group data
In-Reply-To: <0283514711d8183ac79b865fd07f041d@disroot.org>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
Message-ID: <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>

Hi citc,
Try this:

geac<-matrix(c(9,9,8,8,8,23,23,23,23,22,27,27,27,25,24,
 19,19,19,20,20,17,17,17,18,19,8,8,8,9,9,2,2,3,3,3),ncol=5,byrow=TRUE)
library(plotrix)
barp(geac,names.arg=2014:2018,main="A level grades chemistry",
 xlab="Year",ylab="Percentage of each grade",ylim=c(0,30),
 col=c("white","lightblue","blue","orange","green","red","pink"))

Jim

On Fri, Aug 17, 2018 at 9:55 PM,  <citc at disroot.org> wrote:
> R-users,
>
> Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.
>
> barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
> years<-c(2014,2015,2016,2017,2018)
> mtext(years, side=1, at=c(5, 12, 19, 26, 33))
> R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From pd@|gd @end|ng |rom gm@||@com  Sat Aug 18 10:47:19 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 18 Aug 2018 10:47:19 +0200
Subject: [R] How to rotate label in tcltk R
In-Reply-To: <9d0c17f29c10498e8fa4eb7c0499aacd@uwaterloo.ca>
References: <9d0c17f29c10498e8fa4eb7c0499aacd@uwaterloo.ca>
Message-ID: <A232D4DB-8987-4C5D-AD8B-2395D9D8F96D@gmail.com>

I don't think labels as such can be rotated. Newer versions of Tk allows rotation in canvases but this was implemented some years after the tcltk package was developed, so some assembly may be required. If you can extrapolate from Python, there may be some relevant ideas in this post:

https://stackoverflow.com/questions/38008389/is-it-possible-to-have-a-vertical-oriented-button-in-tkinter

> On 17 Aug 2018, at 23:32 , Zehao Xu <z267xu at uwaterloo.ca> wrote:
> 
> Dear sir (ma'am)
> 
> I just start the tcltk in R. I face a problem, how to rotate the labels in tcltk? I post the example on https://stackoverflow.com/questions/51825771/how-to-rotate-labels-in-tcltk.
> 
> 
> Thank you
> 
> Z Xu
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From pd@|gd @end|ng |rom gm@||@com  Sat Aug 18 11:05:52 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 18 Aug 2018 11:05:52 +0200
Subject: [R] Understanding read.csv error message
In-Reply-To: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
Message-ID: <23F65233-CFA9-4A6C-B818-79D315B56FF7@gmail.com>

What Don said, and also notice that the error is not about anything having value 0, it is about replacing something with something of _length_ 0. It is not obvious where that happens, sometimes a traceback() can give a clue, but probably Don is right that the issue is that there is something not quite CSV in the file. 

One further idea is to read using colClasses="character" and see if that actually gives you 6 columns and then afterwards try and convert each column to the appropriate type.

-pd

> On 18 Aug 2018, at 00:08 , Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I have a data file, 'precip_projected.csv,' that starts like this:
> 
> name,easting,northing,elev,sampdate,prcp
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02
> 
>  There are a bunch of NAs in the data file.
> 
>  The command to read it produces an error:
> 
> rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)
> 
> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>  replacement has 0 rows, data has 113569
> 
>  Is the error generated by finding a date that looks like the number zero
> or by a prcp value of zero?
> 
>  BTW, I get the same error if I specify stringsAsFactors = F.
> 
> TIA,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From btupper @end|ng |rom b|ge|ow@org  Sat Aug 18 14:00:16 2018
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Sat, 18 Aug 2018 08:00:16 -0400
Subject: [R] Understanding read.csv error message
In-Reply-To: <23F65233-CFA9-4A6C-B818-79D315B56FF7@gmail.com>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
 <23F65233-CFA9-4A6C-B818-79D315B56FF7@gmail.com>
Message-ID: <78649DDA-F9EB-4A83-B8F5-F324394CD8E0@bigelow.org>

Hi,

I would be tempted, as a start, to read the entire file in as rows of text, split each line by the expected delimiter, and then count the number of elements each split line yields.  Once you know each row splits into the expected number of 

txt <- "name,easting,northing,elev,sampdate,prcp
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02"

txtCon <- textConnection(txt)
x <- readLines(txtCon)
close(txtCon)

n <- sapply(strsplit(x, ",", fixed = TRUE), length)
table(n)

If any have a different length then investigate that/those line(s).  If they all have the same length then it likely isn't about the delimiter.

Cheers,
Ben


 
> On Aug 18, 2018, at 5:05 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> What Don said, and also notice that the error is not about anything having value 0, it is about replacing something with something of _length_ 0. It is not obvious where that happens, sometimes a traceback() can give a clue, but probably Don is right that the issue is that there is something not quite CSV in the file. 
> 
> One further idea is to read using colClasses="character" and see if that actually gives you 6 columns and then afterwards try and convert each column to the appropriate type.
> 
> -pd
> 
>> On 18 Aug 2018, at 00:08 , Rich Shepard <rshepard at appl-ecosys.com> wrote:
>> 
>> I have a data file, 'precip_projected.csv,' that starts like this:
>> 
>> name,easting,northing,elev,sampdate,prcp
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-01,0.59
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-02,0.08
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-03,0.1
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-04,0
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-05,0
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-06,0.02
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-07,0.05
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-08,0.1
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-09,0
>> Headworks Portland Water,2370575.38427211,199337.634652112,228,2005-01-10,0.02
>> 
>> There are a bunch of NAs in the data file.
>> 
>> The command to read it produces an error:
>> 
>> rainfall <- read.csv('../data/precipitation/precip_projected.csv', header = T, sep = ',', as.is = T)
>> 
>> Error in `$<-.data.frame`(`*tmp*`, date, value = numeric(0)) :
>> replacement has 0 rows, data has 113569
>> 
>> Is the error generated by finding a date that looks like the number zero
>> or by a prcp value of zero?
>> 
>> BTW, I get the same error if I specify stringsAsFactors = F.
>> 
>> TIA,
>> 
>> Rich
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Aug 18 17:00:00 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 18 Aug 2018 08:00:00 -0700 (PDT)
Subject: [R] Understanding read.csv error message [FIXED]
In-Reply-To: <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>
References: <alpine.LNX.2.20.1808171457450.12645@salmo.appl-ecosys.com>
 <C614868E-2F14-46F2-968A-0A50E60DCD7C@llnl.gov>
Message-ID: <alpine.LNX.2.20.1808180755290.21447@salmo.appl-ecosys.com>

On Sat, 18 Aug 2018, MacQueen, Don wrote:

> It's not obvious what would be causing that error from read.csv. But
> here's what I would probably try:

> I'd try switching to the more general read.table.

Don/Peter,

   I found the problem: it was in the following line in the script which
referenced 'date' rather than 'sampdate'.

   Single or double quotes make no difference within the script.

   I have a vague recollection from long ago that read.table() is a better
choice than read.csv(). I don't recall the details why, but I did change the
function to read.table(), fixed the column name, and have only the labeling
of the xyploy() left to fix.

Thanks very much, both of you,

Rich



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Sat Aug 18 23:20:19 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sat, 18 Aug 2018 16:20:19 -0500
Subject: [R] Converting chr to num
Message-ID: <000001d43739$450cb030$cf261090$@sbcglobal.net>

R-Help Forum

 

How do I convert a chr variable that contains percentages to an integer

 

Example 12.6% (chr) to 12.6 (int)

 

Jeff


	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug 18 23:32:41 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 18 Aug 2018 22:32:41 +0100
Subject: [R] Converting chr to num
In-Reply-To: <000001d43739$450cb030$cf261090$@sbcglobal.net>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
Message-ID: <f12cc9f8-b96d-513e-e356-f16881fdf036@sapo.pt>

Hello,

You have to get rid of the percent sign first. This can be done with ?sub

x <- "12.6%"
y <- sub("%$", "", x)
z <- as.numeric(y)

1) The dollar sign means "end of string". See ?regexpr.
2) You can all of that in one code line, no need to create y.

z <- as.numeric(sub("%$", "", x))


Hope this helps,

Rui Barradas

On 18/08/2018 22:20, Jeff Reichman wrote:
> R-Help Forum
> 
>   
> 
> How do I convert a chr variable that contains percentages to an integer
> 
>   
> 
> Example 12.6% (chr) to 12.6 (int)
> 
>   
> 
> Jeff
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Sun Aug 19 00:02:53 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sat, 18 Aug 2018 17:02:53 -0500
Subject: [R] Converting chr to num
In-Reply-To: <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
Message-ID: <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>

Given it?s a variable would I just change the 12.6 in as.numeric(gsub(pattern = "%","","12.6%"))

To the variable name say ? as.numeric(gsub(pattern = "%","",df$variable))

 

 

From: GALIB KHAN <ghk18 at scarletmail.rutgers.edu> 
Sent: Saturday, August 18, 2018 4:23 PM
To: reichmanj at sbcglobal.net
Cc: r-help at r-project.org
Subject: Re: [R] Converting chr to num

 

Hey there,

 

as.numeric(gsub(pattern = "%","","12.6%"))

 

On Sat, Aug 18, 2018 at 4:20 PM, Jeff Reichman <reichmanj at sbcglobal.net <mailto:reichmanj at sbcglobal.net> > wrote:

R-Help Forum



How do I convert a chr variable that contains percentages to an integer



Example 12.6% (chr) to 12.6 (int)



Jeff


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Sun Aug 19 00:52:15 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 18 Aug 2018 15:52:15 -0700
Subject: [R] Converting chr to num
In-Reply-To: <000001d43739$450cb030$cf261090$@sbcglobal.net>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
Message-ID: <CAGxFJbQ9DS_0a3bTNLO9LO4RPNzaA4BVsaiV-jCzHkYw-jybLQ@mail.gmail.com>

ummmm.... 12.6 is not an integer.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 18, 2018 at 2:20 PM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-Help Forum
>
>
>
> How do I convert a chr variable that contains percentages to an integer
>
>
>
> Example 12.6% (chr) to 12.6 (int)
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From ghk18 @end|ng |rom @c@r|etm@||@rutger@@edu  Sat Aug 18 23:22:36 2018
From: ghk18 @end|ng |rom @c@r|etm@||@rutger@@edu (GALIB KHAN)
Date: Sat, 18 Aug 2018 16:22:36 -0500
Subject: [R] Converting chr to num
In-Reply-To: <000001d43739$450cb030$cf261090$@sbcglobal.net>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
Message-ID: <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>

Hey there,

as.numeric(gsub(pattern = "%","","12.6%"))

On Sat, Aug 18, 2018 at 4:20 PM, Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-Help Forum
>
>
>
> How do I convert a chr variable that contains percentages to an integer
>
>
>
> Example 12.6% (chr) to 12.6 (int)
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From ghk18 @end|ng |rom @c@r|etm@||@rutger@@edu  Sun Aug 19 00:08:21 2018
From: ghk18 @end|ng |rom @c@r|etm@||@rutger@@edu (GALIB KHAN)
Date: Sat, 18 Aug 2018 17:08:21 -0500
Subject: [R] Converting chr to num
In-Reply-To: <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
Message-ID: <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>

So running the code in my head....as long as that column's data type is a
vector of characters then it should work.


Did you try it out?

On Sat, Aug 18, 2018, 5:02 PM Jeff Reichman <reichmanj at sbcglobal.net> wrote:

> Given it?s a variable would I just change the 12.6 in
> as.numeric(gsub(pattern = "%","","12.6%"))
>
> To the variable name say ? as.numeric(gsub(pattern = "%","",df$variable))
>
>
>
>
>
> *From:* GALIB KHAN <ghk18 at scarletmail.rutgers.edu>
> *Sent:* Saturday, August 18, 2018 4:23 PM
> *To:* reichmanj at sbcglobal.net
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] Converting chr to num
>
>
>
> Hey there,
>
>
>
> as.numeric(gsub(pattern = "%","","12.6%"))
>
>
>
> On Sat, Aug 18, 2018 at 4:20 PM, Jeff Reichman <reichmanj at sbcglobal.net>
> wrote:
>
> R-Help Forum
>
>
>
> How do I convert a chr variable that contains percentages to an integer
>
>
>
> Example 12.6% (chr) to 12.6 (int)
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug 19 01:52:50 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 19 Aug 2018 11:52:50 +1200
Subject: [R] [FORGED] Re:  bar plot add space to group data
In-Reply-To: <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
Message-ID: <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>


Jim:

(a) There's no legend.

(b) I am still curious as to why the OP's code didn't work, in that
the "space=c(0,2)" argument seemed to have no effect.

cheers,

Rolf

On 18/08/18 20:45, Jim Lemon wrote:
> Hi citc,
> Try this:
> 
> geac<-matrix(c(9,9,8,8,8,23,23,23,23,22,27,27,27,25,24,
>   19,19,19,20,20,17,17,17,18,19,8,8,8,9,9,2,2,3,3,3),ncol=5,byrow=TRUE)
> library(plotrix)
> barp(geac,names.arg=2014:2018,main="A level grades chemistry",
>   xlab="Year",ylab="Percentage of each grade",ylim=c(0,30),
>   col=c("white","lightblue","blue","orange","green","red","pink"))
> 
> Jim
> 
> On Fri, Aug 17, 2018 at 9:55 PM,  <citc at disroot.org> wrote:
>> R-users,
>>
>> Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.
>>
>> barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
>> years<-c(2014,2015,2016,2017,2018)
>> mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>> R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))



From drj|m|emon @end|ng |rom gm@||@com  Sun Aug 19 06:12:35 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 19 Aug 2018 14:12:35 +1000
Subject: [R] [FORGED] Re:  bar plot add space to group data
In-Reply-To: <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
Message-ID: <CA+8X3fVTeJx6szP8DqdGOuKKitN+g8uQGadwzgo2Vz-=Cs9Q9Q@mail.gmail.com>

Hi Rolf,
That's what comes of being in a hurry.

legend(4.1,30,c("A+","A","B","C","D","E","U"),
 fill=c("white","lightblue","blue","orange","green","red","pink"))

and I thank you for alerting me to the fact that the legend arguments
in barp don't position the legend properly. I'll fix it.

Jim


On Sun, Aug 19, 2018 at 9:52 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> Jim:
>
> (a) There's no legend.
>
> (b) I am still curious as to why the OP's code didn't work, in that
> the "space=c(0,2)" argument seemed to have no effect.
>
> cheers,
>
> Rolf
>
> On 18/08/18 20:45, Jim Lemon wrote:
>>
>> Hi citc,
>> Try this:
>>
>> geac<-matrix(c(9,9,8,8,8,23,23,23,23,22,27,27,27,25,24,
>>   19,19,19,20,20,17,17,17,18,19,8,8,8,9,9,2,2,3,3,3),ncol=5,byrow=TRUE)
>> library(plotrix)
>> barp(geac,names.arg=2014:2018,main="A level grades chemistry",
>>   xlab="Year",ylab="Percentage of each grade",ylim=c(0,30),
>>   col=c("white","lightblue","blue","orange","green","red","pink"))
>>
>> Jim
>>
>> On Fri, Aug 17, 2018 at 9:55 PM,  <citc at disroot.org> wrote:
>>>
>>> R-users,
>>>
>>> Can someone please advise how to improve the code below that was used to
>>> produce the graph shown at the following hyperlink
>>> (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The
>>> request is to add space between the annual data groups.
>>>
>>> barplot(gceac[,3], xlab='year', ylab='percentage of each grade',
>>> col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen',
>>> 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y =
>>> 30, title='grades'), main='A-level grades, chemistry', beside=T,
>>> space=c(0,2), ylim=c(0,30))
>>> years<-c(2014,2015,2016,2017,2018)
>>> mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>>> R-users, Can someone please advise how to improve the code below that was
>>> used to produce the graph shown at the following hyperlink
>>> (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The
>>> request is to add space between the annual data groups.  barplot(gceac[,3],
>>> xlab='year', ylab='percentage of each grade', col=c('aliceblue',
>>> 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'),
>>> legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'),
>>> main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
>>> years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26,
>>> 33))



From peter@|@ng|e|der @end|ng |rom gm@||@com  Sun Aug 19 06:58:04 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Sat, 18 Aug 2018 21:58:04 -0700
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
Message-ID: <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>

My guess is that space has no effect because (1) the first element is
zero and (2) the code in OP's message has
barplot(gceac[,3], ...

i.e. barplot does not see a matrix, only a vector.

To the OP, try formatting the data to be plotted as a matrix, not as a
vector, then the space argument should be useful to add space between
groups.

Peter


On Sat, Aug 18, 2018 at 4:53 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Jim:
>
> (a) There's no legend.
>
> (b) I am still curious as to why the OP's code didn't work, in that
> the "space=c(0,2)" argument seemed to have no effect.
>
> cheers,
>
> Rolf
>
> On 18/08/18 20:45, Jim Lemon wrote:
> > Hi citc,
> > Try this:
> >
> > geac<-matrix(c(9,9,8,8,8,23,23,23,23,22,27,27,27,25,24,
> >   19,19,19,20,20,17,17,17,18,19,8,8,8,9,9,2,2,3,3,3),ncol=5,byrow=TRUE)
> > library(plotrix)
> > barp(geac,names.arg=2014:2018,main="A level grades chemistry",
> >   xlab="Year",ylab="Percentage of each grade",ylim=c(0,30),
> >   col=c("white","lightblue","blue","orange","green","red","pink"))
> >
> > Jim
> >
> > On Fri, Aug 17, 2018 at 9:55 PM,  <citc at disroot.org> wrote:
> >> R-users,
> >>
> >> Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.
> >>
> >> barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30))
> >> years<-c(2014,2015,2016,2017,2018)
> >> mtext(years, side=1, at=c(5, 12, 19, 26, 33))
> >> R-users, Can someone please advise how to improve the code below that was used to produce the graph shown at the following hyperlink (https://chemistryinthecity.neocities.org/content/entry1808.html#17)? The request is to add space between the annual data groups.  barplot(gceac[,3], xlab='year', ylab='percentage of each grade', col=c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 'firebrick', 'violet'), legend=gceac[1:7,2], args.legend = list(x = 40, y = 30, title='grades'), main='A-level grades, chemistry', beside=T, space=c(0,2), ylim=c(0,30)) years<-c(2014,2015,2016,2017,2018) mtext(years, side=1, at=c(5, 12, 19, 26, 33))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug 19 07:06:23 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 19 Aug 2018 06:06:23 +0100
Subject: [R] Converting chr to num
In-Reply-To: <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
 <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
Message-ID: <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>

Hello,

It also works with class "factor":

df <- data.frame(variable = c("12.6%", "30.9%", "61.4%"))
class(df$variable)
#[1] "factor"

as.numeric(gsub(pattern = "%", "", df$variable))
#[1] 12.6 30.9 61.4


This is because sub() and gsub() return a character vector and the 
instruction becomes an equivalent of what the help page ?factor 
documents in section Warning:

To transform a factor f to approximately its original numeric values, 
as.numeric(levels(f))[f] is recommended and slightly more efficient than 
as.numeric(as.character(f)).


Also, I would still prefer

as.numeric(sub(pattern = "%$","",df$variable))
#[1] 12.6 30.9 61.4

The pattern is more strict and there is no need to search&replace 
multiple occurrences of '%'.



Hope this helps,

Rui Barradas

On 18/08/2018 23:08, GALIB KHAN wrote:
> So running the code in my head....as long as that column's data type is a
> vector of characters then it should work.
> 
> 
> Did you try it out?
> 
> On Sat, Aug 18, 2018, 5:02 PM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> 
>> Given it?s a variable would I just change the 12.6 in
>> as.numeric(gsub(pattern = "%","","12.6%"))
>>
>> To the variable name say ? as.numeric(gsub(pattern = "%","",df$variable))
>>
>>
>>
>>
>>
>> *From:* GALIB KHAN <ghk18 at scarletmail.rutgers.edu>
>> *Sent:* Saturday, August 18, 2018 4:23 PM
>> *To:* reichmanj at sbcglobal.net
>> *Cc:* r-help at r-project.org
>> *Subject:* Re: [R] Converting chr to num
>>
>>
>>
>> Hey there,
>>
>>
>>
>> as.numeric(gsub(pattern = "%","","12.6%"))
>>
>>
>>
>> On Sat, Aug 18, 2018 at 4:20 PM, Jeff Reichman <reichmanj at sbcglobal.net>
>> wrote:
>>
>> R-Help Forum
>>
>>
>>
>> How do I convert a chr variable that contains percentages to an integer
>>
>>
>>
>> Example 12.6% (chr) to 12.6 (int)
>>
>>
>>
>> Jeff
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug 19 07:06:50 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 19 Aug 2018 17:06:50 +1200
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
 <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
Message-ID: <708a6692-61d2-8554-07a4-5d780b33e130@auckland.ac.nz>


On 19/08/18 16:58, Peter Langfelder wrote:

> My guess is that space has no effect because (1) the first element is
> zero and (2) the code in OP's message has
> barplot(gceac[,3], ...
> 
> i.e. barplot does not see a matrix, only a vector.
> 
> To the OP, try formatting the data to be plotted as a matrix, not as a
> vector, then the space argument should be useful to add space between
> groups.

Thanks Peter.  That would appear to be a sound analysis.  Thanks for the 
insight.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug 19 07:08:30 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 19 Aug 2018 17:08:30 +1200
Subject: [R] [FORGED] Re:  bar plot add space to group data
In-Reply-To: <CA+8X3fVTeJx6szP8DqdGOuKKitN+g8uQGadwzgo2Vz-=Cs9Q9Q@mail.gmail.com>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
 <CA+8X3fVTeJx6szP8DqdGOuKKitN+g8uQGadwzgo2Vz-=Cs9Q9Q@mail.gmail.com>
Message-ID: <c4c86059-c912-c929-89fc-430742c769e2@auckland.ac.nz>

On 19/08/18 16:12, Jim Lemon wrote:
> Hi Rolf,
> That's what comes of being in a hurry.
> 
> legend(4.1,30,c("A+","A","B","C","D","E","U"),
>   fill=c("white","lightblue","blue","orange","green","red","pink"))
> 
> and I thank you for alerting me to the fact that the legend arguments
> in barp don't position the legend properly. I'll fix it.

And I wasn't even aware that I was doing any alerting! :-)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From citc m@iii@g oii disroot@org  Sun Aug 19 16:12:55 2018
From: citc m@iii@g oii disroot@org (citc m@iii@g oii disroot@org)
Date: Sun, 19 Aug 2018 14:12:55 +0000
Subject: [R] bar plot add space to group data
In-Reply-To: <56e7fda9-284c-b16c-e3e5-f8460c34747c@auckland.ac.nz>
References: <56e7fda9-284c-b16c-e3e5-f8460c34747c@auckland.ac.nz>
 <0283514711d8183ac79b865fd07f041d@disroot.org>
 <ef12bce1db1c412e8c02a2b6e26c879e@tamu.edu>
Message-ID: <9f8092b4050c440332652a2a0726ec22@disroot.org>

August 17, 2018 10:24 PM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:

> On 18/08/18 02:37, David L Carlson wrote:
> 
>> Notice below that your message is substantially scrambled. R-Help is a
>> plain text only list so you should set your email client to produce plain text messages.

Apologies, forgot to change the default settings of the web-mail.

> 
> If one struggles through the garbled html bumff, one sees that the OP *did* indeed use the "space="
> argument. However it does not appear to have had the desired effect, and I cannot see why. Since
> the OP did not supply the data, I cannot experiment.
>

csv data below:

year,grade,percentage
2014,A*,9
2014,A,23
2014,B,27
2014,C,19
2014,D,13
2014,E,7
2014,U,2
2015,A*,9
2015,A,23
2015,B,27
2015,C,19
2015,D,13
2015,E,7
2015,U,2
2016,A*,8
2016,A,23
2016,B,27
2016,C,19
2016,D,13
2016,E,7
2016,U,3
2017,A*,8
2017,A,23
2017,B,24
2017,C,20
2017,D,14
2017,E,8
2017,U,3
2018,A*,8
2018,A,22
2018,B,23
2018,C,20
2018,D,15
2018,E,8
2018,U,3



From citc m@iii@g oii disroot@org  Sun Aug 19 16:15:20 2018
From: citc m@iii@g oii disroot@org (citc m@iii@g oii disroot@org)
Date: Sun, 19 Aug 2018 14:15:20 +0000
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
References: <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
 <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
Message-ID: <f8f036333a82d6544d3be71e9436d160@disroot.org>

August 19, 2018 4:58 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:

> To the OP, try formatting the data to be plotted as a matrix, not as a
> vector

CSV data provided in a previous message; is not the data formatted as a matrix?



From peter@|@ng|e|der @end|ng |rom gm@||@com  Sun Aug 19 17:51:13 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Sun, 19 Aug 2018 08:51:13 -0700
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <f8f036333a82d6544d3be71e9436d160@disroot.org>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
 <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
 <f8f036333a82d6544d3be71e9436d160@disroot.org>
Message-ID: <CA+hbrhVs31LSDMAErgAX5pHWSOC3Xy3WB10_aJ5ue3wk40SRZQ@mail.gmail.com>

On Sun, Aug 19, 2018 at 7:15 AM <citc at disroot.org> wrote:
>
> August 19, 2018 4:58 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:
>
> > To the OP, try formatting the data to be plotted as a matrix, not as a
> > vector
>
> CSV data provided in a previous message; is not the data formatted as a matrix?

I meant the data you give to barplot - your code supplies only the
third column of the data frame, so barplot only sees a vector. I would
try something like

plotData = do.call(cbind, tapply(csv.data$percentage, csv.data$year, identity))

barplot(plotData, <rest of your argument>)

Peter



From j@kper|k@d|oggb@n @end|ng |rom @tudent@@jku@t@@c@ke  Sun Aug 19 18:33:02 2018
From: j@kper|k@d|oggb@n @end|ng |rom @tudent@@jku@t@@c@ke (Dioggban Jakperik)
Date: Sun, 19 Aug 2018 19:33:02 +0300
Subject: [R] Computing the density of a median
Message-ID: <CANbn+9CL7zgn9Xnui43pEYYkPaAB030fkQCGP7UM_CaFR6SywQ@mail.gmail.com>

I have the following function

kdenor <- function(aa,q=NULL){
a=sample(aa,500,replace=F)
ab=quantile(a, p=0.75)-quantile(a, p=0.25)
h=(0.9*min(var(a),ab))/(1.34*n^(1/5))

if(is.null(q)) {
q = seq(min(a)-3*h, max(a)+3*h, length.out=length(a))
}
nx = length(a)
nq = length(q)
xmat = matrix(q,nq,nx) - matrix(a,nq,nx,byrow=TRUE)
denall= dnorm(xmat/h)/h
denhat = apply(denall,1,mean)

f<-denhat
f1<-median(f)
#das<-list(x=q, y=denhat, h=h)
#return(das)
}

f1<-kdenor(aa)

My interest is to obtain the estimate of the density at the median of the
sample data.
But the output of the current function  doesn't provide the correct result.
Kindly help.
Regards.


-- 
Jakperik Dioggban (Student, PAUISTI)
PhD Mathematics (Statistics Option)
Determination is Key to Success

	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Sun Aug 19 20:10:29 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Sun, 19 Aug 2018 18:10:29 +0000
Subject: [R] [FORGED] Re: bar plot add space to group data
In-Reply-To: <CA+hbrhVs31LSDMAErgAX5pHWSOC3Xy3WB10_aJ5ue3wk40SRZQ@mail.gmail.com>
References: <0283514711d8183ac79b865fd07f041d@disroot.org>
 <CA+8X3fX6_VZzgUbxAQHm_fk9D_iKu0kn8JSVECW7Tg+7LL8XJg@mail.gmail.com>
 <7136d23d-da40-c618-5ab6-074da1bf233a@auckland.ac.nz>
 <CA+hbrhUuR4usyOhRoOkQ+Q8yCN363xc07NhZeSXe0dZHObgrZA@mail.gmail.com>
 <f8f036333a82d6544d3be71e9436d160@disroot.org>
 <CA+hbrhVs31LSDMAErgAX5pHWSOC3Xy3WB10_aJ5ue3wk40SRZQ@mail.gmail.com>
Message-ID: <6804ee0d924644fd83f9e6e7b0cdd2e7@tamu.edu>

Actually the data you provided are a data frame and not a matrix as R uses the term. Two columns of gceac are numeric and one is a factor. If we read your data with read.csv() we get:

> str(gceac)
'data.frame':   35 obs. of  3 variables:
 $ year      : int  2014 2014 2014 2014 2014 2014 2014 2015 2015 2015 ...
 $ grade     : Factor w/ 7 levels "A","A*","B","C",..: 2 1 3 4 5 6 7 2 1 3 ...
 $ percentage: int  9 23 27 19 13 7 2 9 23 27 ...

Now we see problem in grade column. Your plot has A* before A, but the factor is created alphabetically so A comes before A*. We can fix that

> gceac$grade <- factor(gceac$grade, levels=c("A*", "A", "B", "C", "D",
     "E", "U"))

> levels(gceac$grade)
[1] "A*" "A"  "B"  "C"  "D"  "E"  "U"

Now you need a matrix for the barplot. That is simple with xtabs()

> gceac.mat <- xtabs(percentage~grade+year, gceac)
> gceac.mat
     year
grade 2014 2015 2016 2017 2018
   A*    9    9    8    8    8
   A    23   23   23   23   22
   B    27   27   27   24   23
   C    19   19   19   20   20
   D    13   13   13   14   15
   E     7    7    7    8    8
   U     2    2    3    3    3

Now we can build your bar plot using almost the same command you used:

> clrs <- c('aliceblue', 'aquamarine', 'blue', 'chocolate', 'darkgreen', 
+      'firebrick', 'violet')
> barplot(gceac.mat, xlab='year', ylab='percentage of each grade', 
+      col=clrs, legend=TRUE, args.legend = list("topright",
+      title='grades'), main='A-level grades, chemistry', beside=T,
+      space=c(0, 1), ylim=c(0,35))

I defined clrs so that the barplot() function would be easier to read, but it works the same your way. Now we just need legend=TRUE and we can position the legend in the top right with the args.legend= argument. The legend overlaps the bars a bit so I increased the y-axis to 35. A .png file is attached.


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Langfelder
Sent: Sunday, August 19, 2018 10:51 AM
To: citc at disroot.org
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] [FORGED] Re: bar plot add space to group data

On Sun, Aug 19, 2018 at 7:15 AM <citc at disroot.org> wrote:
>
> August 19, 2018 4:58 AM, "Peter Langfelder" <peter.langfelder at gmail.com> wrote:
>
> > To the OP, try formatting the data to be plotted as a matrix, not as a
> > vector
>
> CSV data provided in a previous message; is not the data formatted as a matrix?

I meant the data you give to barplot - your code supplies only the
third column of the data frame, so barplot only sees a vector. I would
try something like

plotData = do.call(cbind, tapply(csv.data$percentage, csv.data$year, identity))

barplot(plotData, <rest of your argument>)

Peter

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: BarPlot.png
Type: image/png
Size: 8565 bytes
Desc: BarPlot.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180819/784c7f8c/attachment-0002.png>

From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Sun Aug 19 21:11:44 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 19 Aug 2018 15:11:44 -0400
Subject: [R] Request for R Assistance: Downloading Data
Message-ID: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>

 Good evening,

  I am attempting to download Genomic data from the GDC onto R for analysis
and am experiencing some difficulty. I have downloaded the GDC data into an
Excel, CSV, and notepad (.txt) file and implemented what I believe to be
the proper arguments, with every attempting failing to properly load the
data onto R. The following is the various attempts I made in trying to take
one of these files (a translated version of the GDC data) and load it into R
.

> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?LGG Drug (CSV).csv? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
(CSV).csv",header=TRUE,sep=",")
Error: unexpected symbol in "LGG Drug"
> LGG Drug<-read.table("C:
Error: unexpected symbol in "LGG Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in " GBM Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
:
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
wrap).txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"

Any insight into what perhaps I am inputting that is causes this
reoccurring error? Any suggestions as to another procedure for moving
forward would be greatly appreciated!

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Aug 19 21:19:06 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 19 Aug 2018 12:19:06 -0700 (PDT)
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808191214080.8446@salmo.appl-ecosys.com>

On Sun, 19 Aug 2018, Spencer Brackett wrote:

> I am attempting to download Genomic data from the GDC onto R for analysis
> and am experiencing some difficulty. I have downloaded the GDC data into an
> Excel, CSV, and notepad (.txt) file and implemented what I believe to be
> the proper arguments, with every attempting failing to properly load the
> data onto R.

Spencer,

   Looks like you want to read the data into an R dataframe; I assume that's
the format for geonomic data as it is for environmental data.

>> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")

   Instead, try

mydata <- read.csv("lgg_drug.csv", header = TRUE, stringsAsFactors = FALSE)

Note: this assumes the data file has column headers. And, you can use your
.txt file with the read.table() function.

> Any insight into what perhaps I am inputting that is causes this
> reoccurring error? Any suggestions as to another procedure for moving
> forward would be greatly appreciated!

   How much about R have you read/learned? Taking a couple of steps back
might be well worth your while.

Regards,

Rich



From dc@r|@on @end|ng |rom t@mu@edu  Sun Aug 19 21:20:13 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Sun, 19 Aug 2018 19:20:13 +0000
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
Message-ID: <3534f9ed7ba44c40a0051579f78898ed@tamu.edu>

The load() function is only used for binary files that R creates with the save() function.

You are trying to assign the data to an object (variable) called LGG Drug. R does not allow spaces in variable names. You could try LGGDrug, LGG_Drug, or LGG.Drug. Same issue with GBM Drug. 

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Spencer Brackett
Sent: Sunday, August 19, 2018 2:12 PM
To: r-help at r-project.org
Subject: [R] Request for R Assistance: Downloading Data

 Good evening,

  I am attempting to download Genomic data from the GDC onto R for analysis
and am experiencing some difficulty. I have downloaded the GDC data into an
Excel, CSV, and notepad (.txt) file and implemented what I believe to be
the proper arguments, with every attempting failing to properly load the
data onto R. The following is the various attempts I made in trying to take
one of these files (a translated version of the GDC data) and load it into R
.

> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?LGG Drug (CSV).csv? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
(CSV).csv",header=TRUE,sep=",")
Error: unexpected symbol in "LGG Drug"
> LGG Drug<-read.table("C:
Error: unexpected symbol in "LGG Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in " GBM Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
:
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
wrap).txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"

Any insight into what perhaps I am inputting that is causes this
reoccurring error? Any suggestions as to another procedure for moving
forward would be greatly appreciated!

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From j@p@rk4 @end|ng |rom u|c@edu  Sun Aug 19 21:16:14 2018
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Sun, 19 Aug 2018 19:16:14 +0000
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
Message-ID: <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>

Just a hunch, but I would recommend simplifying your filename:  remove the (CSV) portion.  It could be confusing in R read syntax.  Create a filename with no unnecessary punctuation and no blank spaces.


--John Sparks


________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Spencer Brackett <spbrackett20 at saintjosephhs.com>
Sent: Sunday, August 19, 2018 2:11 PM
To: r-help at r-project.org
Subject: [R] Request for R Assistance: Downloading Data

Good evening,

  I am attempting to download Genomic data from the GDC onto R for analysis
and am experiencing some difficulty. I have downloaded the GDC data into an
Excel, CSV, and notepad (.txt) file and implemented what I believe to be
the proper arguments, with every attempting failing to properly load the
data onto R. The following is the various attempts I made in trying to take
one of these files (a translated version of the GDC data) and load it into R
.

> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?LGG Drug (CSV).csv? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
(CSV).csv",header=TRUE,sep=",")
Error: unexpected symbol in "LGG Drug"
> LGG Drug<-read.table("C:
Error: unexpected symbol in "LGG Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in "GBM Drug"
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"
>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
GBM.txt",header=TRUE,sep="\t")
Error: unexpected symbol in " GBM Drug"
> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
:
  bad restore file magic number (file may be corrupted) -- no data loaded
In addition: Warning message:
file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
  Use of save versions prior to 2 is deprecated
> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
wrap).txt",header=TRUE,sep="")
Error: unexpected symbol in "GBM Drug"

Any insight into what perhaps I am inputting that is causes this
reoccurring error? Any suggestions as to another procedure for moving
forward would be greatly appreciated!

Many thanks,

Spencer Brackett

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
R-help -- Main R Mailing List: Primary help - Homepage - SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R, enhancements and patches to the source code and documentation of R, comparison and compatibility with S and S-plus, and for the posting of nice examples and benchmarks.



PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From er|nm@hodge@@ @end|ng |rom gm@||@com  Sun Aug 19 22:28:49 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sun, 19 Aug 2018 14:28:49 -0600
Subject: [R] learning tidyverse
Message-ID: <CACxE24nvUsjcxVcL7E26MUAmB3Fv1mRYNV-31oEXwOXOGxX0Ng@mail.gmail.com>

Hello everyone!

Could anyone recommend a good way to learn about tidyverse, please?  Is
there a book, please?

Thanks,
Erin



Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]



From |@t@z@hn @end|ng |rom gm@||@com  Sun Aug 19 22:41:59 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Sun, 19 Aug 2018 16:41:59 -0400
Subject: [R] learning tidyverse
In-Reply-To: <CACxE24nvUsjcxVcL7E26MUAmB3Fv1mRYNV-31oEXwOXOGxX0Ng@mail.gmail.com>
References: <CACxE24nvUsjcxVcL7E26MUAmB3Fv1mRYNV-31oEXwOXOGxX0Ng@mail.gmail.com>
Message-ID: <CA+vqiLFVSocCjo77qY+zf58ZXD9_11ApN9E5Z5CK1vpmMT6b+w@mail.gmail.com>

https://www.tidyverse.org/learn/
On Sun, Aug 19, 2018 at 4:29 PM Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> Hello everyone!
>
> Could anyone recommend a good way to learn about tidyverse, please?  Is
> there a book, please?
>
> Thanks,
> Erin
>
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From er|nm@hodge@@ @end|ng |rom gm@||@com  Sun Aug 19 22:43:38 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sun, 19 Aug 2018 14:43:38 -0600
Subject: [R] learning tidyverse
In-Reply-To: <CA+vqiLFVSocCjo77qY+zf58ZXD9_11ApN9E5Z5CK1vpmMT6b+w@mail.gmail.com>
References: <CACxE24nvUsjcxVcL7E26MUAmB3Fv1mRYNV-31oEXwOXOGxX0Ng@mail.gmail.com>
 <CA+vqiLFVSocCjo77qY+zf58ZXD9_11ApN9E5Z5CK1vpmMT6b+w@mail.gmail.com>
Message-ID: <CACxE24nhaCCt6kUuPiU8y+NV4LEcXuC4F6DAN4vJZNm9hsmT5w@mail.gmail.com>

Thanks so much!!!!

e

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Sun, Aug 19, 2018 at 2:42 PM Ista Zahn <istazahn at gmail.com> wrote:

> https://www.tidyverse.org/learn/
> On Sun, Aug 19, 2018 at 4:29 PM Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >
> > Hello everyone!
> >
> > Could anyone recommend a good way to learn about tidyverse, please?  Is
> > there a book, please?
> >
> > Thanks,
> > Erin
> >
> >
> >
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From phiiipsm m@iii@g oii cp@@ei1@stormweb@@et  Sun Aug 19 23:20:29 2018
From: phiiipsm m@iii@g oii cp@@ei1@stormweb@@et (phiiipsm m@iii@g oii cp@@ei1@stormweb@@et)
Date: Sun, 19 Aug 2018 17:20:29 -0400
Subject: [R] as.Date() function
Message-ID: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>

I am having trouble with what must be a very simple problem. Here is a  
reproducible example:

library(lubridate)
st <- c("1961-01","1961-04","1983-02")
print(st)
#[1] "1961-01" "1961-04" "1983-02"
st1 <- as.Date(st, format=("%Y-%m"))
print(st1)
#[1] NA NA NA

Why the heck am I getting three NAs instead of three Dates?I have  
studied the R documentation for as.Date() and it has not turned on the  
light bulb for me.



From chem@ @end|ng |rom r|nzew|nd@org  Sun Aug 19 23:30:34 2018
From: chem@ @end|ng |rom r|nzew|nd@org (=?iso-8859-1?Q?Jos=E9_Mar=EDa?= Mateos)
Date: Sun, 19 Aug 2018 17:30:34 -0400
Subject: [R] as.Date() function
In-Reply-To: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
Message-ID: <20180819213034.GC5241@equipaje>

On Sun, Aug 19, 2018 at 05:20:29PM -0400, philipsm at cpanel1.stormweb.net wrote:
> Why the heck am I getting three NAs instead of three Dates?I have
> studied the R documentation for as.Date() and it has not turned on
> the light bulb for me.

I haven't encountered this problem before, but in my mind, if you want a 
date, you'll also need to specify the day. Only year and month won't cut 
it.

Cheers,

-- 
Jos? Mar?a (Chema) Mateos
https://rinzewind.org/blog-es || https://rinzewind.org/blog-en



From er|nm@hodge@@ @end|ng |rom gm@||@com  Sun Aug 19 23:34:33 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sun, 19 Aug 2018 15:34:33 -0600
Subject: [R] as.Date() function
In-Reply-To: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
Message-ID: <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>

Hi Philip:

Here is something to consider:

> #potential solution:
> sta <- paste(st,"-01",sep="")
> st1 <- as.Date(sta, format=("%Y-%m-%d"))
> print(st1)
[1] "1961-01-01" "1961-04-01" "1983-02-01"


Hope this helps!
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Sun, Aug 19, 2018 at 3:25 PM <philipsm at cpanel1.stormweb.net> wrote:

> I am having trouble with what must be a very simple problem. Here is a
> reproducible example:
>
> library(lubridate)
> st <- c("1961-01","1961-04","1983-02")
> print(st)
> #[1] "1961-01" "1961-04" "1983-02"
> st1 <- as.Date(st, format=("%Y-%m"))
> print(st1)
> #[1] NA NA NA
>
> Why the heck am I getting three NAs instead of three Dates?I have
> studied the R documentation for as.Date() and it has not turned on the
> light bulb for me.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug 19 23:38:40 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 19 Aug 2018 14:38:40 -0700
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
 <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
Message-ID: <9154F32C-253C-4061-8858-C6F6BB877726@dcn.davis.ca.us>

I think this hunch is off the mark... the file name is fine as it is... if anything will confuse R it would be that the data inside the file are not what was expected.

If in fact the file is csv formatted then the function to read it would be read.csv [1] or read.table [2]. Read the help pages for these functions and read the R Data Import/Export documentation [3].

[1] ?read.csv at R console
[2] ?read.table many of the options for this function will work for read.csv.
[3] https://cran.r-project.org/doc/manuals/r-release/R-data.html

On August 19, 2018 12:16:14 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>Just a hunch, but I would recommend simplifying your filename:  remove
>the (CSV) portion.  It could be confusing in R read syntax.  Create a
>filename with no unnecessary punctuation and no blank spaces.
>
>
>--John Sparks
>
>
>________________________________
>From: R-help <r-help-bounces at r-project.org> on behalf of Spencer
>Brackett <spbrackett20 at saintjosephhs.com>
>Sent: Sunday, August 19, 2018 2:11 PM
>To: r-help at r-project.org
>Subject: [R] Request for R Assistance: Downloading Data
>
>Good evening,
>
>I am attempting to download Genomic data from the GDC onto R for
>analysis
>and am experiencing some difficulty. I have downloaded the GDC data
>into an
>Excel, CSV, and notepad (.txt) file and implemented what I believe to
>be
>the proper arguments, with every attempting failing to properly load
>the
>data onto R. The following is the various attempts I made in trying to
>take
>one of these files (a translated version of the GDC data) and load it
>into R
>.
>
>> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
>Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?LGG Drug (CSV).csv? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
>(CSV).csv",header=TRUE,sep=",")
>Error: unexpected symbol in "LGG Drug"
>> LGG Drug<-read.table("C:
>Error: unexpected symbol in "LGG Drug"
>> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
>Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="\t")
>Error: unexpected symbol in "GBM Drug"
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="\t")
>Error: unexpected symbol in " GBM Drug"
>> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
>Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
>wrap).txt")
>:
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM(word
>wrap).txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>
>Any insight into what perhaps I am inputting that is causes this
>reoccurring error? Any suggestions as to another procedure for moving
>forward would be greatly appreciated!
>
>Many thanks,
>
>Spencer Brackett
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>R-help -- Main R Mailing List: Primary help - Homepage -
>SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
>stat.ethz.ch
>The main R mailing list, for announcements about the development of R
>and the availability of new code, questions and answers about problems
>and solutions using R, enhancements and patches to the source code and
>documentation of R, comparison and compatibility with S and S-plus, and
>for the posting of nice examples and benchmarks.
>
>
>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.



From j@p@rk4 @end|ng |rom u|c@edu  Sun Aug 19 23:43:43 2018
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Sun, 19 Aug 2018 21:43:43 +0000
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <9154F32C-253C-4061-8858-C6F6BB877726@dcn.davis.ca.us>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
 <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>,
 <9154F32C-253C-4061-8858-C6F6BB877726@dcn.davis.ca.us>
Message-ID: <SN6PR05MB4816150D27E8995E51B0A6F8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>

I agree with Jeff.  The data type is the problem.  I wrote what I wrote without looking at the problem very carefully.


--JJS


________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Sunday, August 19, 2018 4:38 PM
To: r-help at r-project.org; Sparks, John; Spencer Brackett; r-help at r-project.org
Subject: Re: [R] Request for R Assistance: Downloading Data

I think this hunch is off the mark... the file name is fine as it is... if anything will confuse R it would be that the data inside the file are not what was expected.

If in fact the file is csv formatted then the function to read it would be read.csv [1] or read.table [2]. Read the help pages for these functions and read the R Data Import/Export documentation [3].

[1] ?read.csv at R console
[2] ?read.table many of the options for this function will work for read.csv.
[3] https://cran.r-project.org/doc/manuals/r-release/R-data.html
R Data Import/Export<https://cran.r-project.org/doc/manuals/r-release/R-data.html>
cran.r-project.org
1.1 Imports. The easiest form of data to import into R is a simple text file, and this will often be acceptable for problems of small or medium scale.




On August 19, 2018 12:16:14 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>Just a hunch, but I would recommend simplifying your filename:  remove
>the (CSV) portion.  It could be confusing in R read syntax.  Create a
>filename with no unnecessary punctuation and no blank spaces.
>
>
>--John Sparks
>
>
>________________________________
>From: R-help <r-help-bounces at r-project.org> on behalf of Spencer
>Brackett <spbrackett20 at saintjosephhs.com>
>Sent: Sunday, August 19, 2018 2:11 PM
>To: r-help at r-project.org
>Subject: [R] Request for R Assistance: Downloading Data
>
>Good evening,
>
>I am attempting to download Genomic data from the GDC onto R for
>analysis
>and am experiencing some difficulty. I have downloaded the GDC data
>into an
>Excel, CSV, and notepad (.txt) file and implemented what I believe to
>be
>the proper arguments, with every attempting failing to properly load
>the
>data onto R. The following is the various attempts I made in trying to
>take
>one of these files (a translated version of the GDC data) and load it
>into R
>.
>
>> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
>Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?LGG Drug (CSV).csv? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
>(CSV).csv",header=TRUE,sep=",")
>Error: unexpected symbol in "LGG Drug"
>> LGG Drug<-read.table("C:
>Error: unexpected symbol in "LGG Drug"
>> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
>Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="\t")
>Error: unexpected symbol in "GBM Drug"
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM.txt",header=TRUE,sep="\t")
>Error: unexpected symbol in " GBM Drug"
>> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
>Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
>wrap).txt")
>:
>bad restore file magic number (file may be corrupted) -- no data loaded
>In addition: Warning message:
>file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
>  Use of save versions prior to 2 is deprecated
>> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
>GBM(word
>wrap).txt",header=TRUE,sep="")
>Error: unexpected symbol in "GBM Drug"
>
>Any insight into what perhaps I am inputting that is causes this
>reoccurring error? Any suggestions as to another procedure for moving
>forward would be greatly appreciated!
>
>Many thanks,
>
>Spencer Brackett
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>R-help -- Main R Mailing List: Primary help - Homepage -
>SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
>stat.ethz.ch
>The main R mailing list, for announcements about the development of R
>and the availability of new code, questions and answers about problems
>and solutions using R, enhancements and patches to the source code and
>documentation of R, comparison and compatibility with S and S-plus, and
>for the posting of nice examples and benchmarks.
>
>
>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug 20 01:14:06 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 20 Aug 2018 09:14:06 +1000
Subject: [R] as.Date() function
In-Reply-To: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
Message-ID: <CA+8X3fWcbJecxOmNja+pdtHL9H_mjEE2p6Nron8xdgte5pZgyQ@mail.gmail.com>

Hi Phillip,
Jose has the correct answer. You probably missed this sentence in the
"Note" section of the help page:

"If the date string does not specify the date completely, the returned
answer may be system-specific."

In your case, the function throws up its hands and returns NA as you
haven't specified a date.

Jim

On Mon, Aug 20, 2018 at 7:20 AM,  <philipsm at cpanel1.stormweb.net> wrote:
> I am having trouble with what must be a very simple problem. Here is a
> reproducible example:
>
> library(lubridate)
> st <- c("1961-01","1961-04","1983-02")
> print(st)
> #[1] "1961-01" "1961-04" "1983-02"
> st1 <- as.Date(st, format=("%Y-%m"))
> print(st1)
> #[1] NA NA NA
>
> Why the heck am I getting three NAs instead of three Dates?I have studied
> the R documentation for as.Date() and it has not turned on the light bulb
> for me.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From djnord|und @end|ng |rom gm@||@com  Mon Aug 20 02:08:21 2018
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Sun, 19 Aug 2018 17:08:21 -0700
Subject: [R] Converting chr to num
In-Reply-To: <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
 <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
 <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>
Message-ID: <b123a1a4-0f7c-6242-549c-c6be1572c503@gmail.com>

See comment inline below:

On 8/18/2018 10:06 PM, Rui Barradas wrote:
> Hello,
> 
> It also works with class "factor":
> 
> df <- data.frame(variable = c("12.6%", "30.9%", "61.4%"))
> class(df$variable)
> #[1] "factor"
> 
> as.numeric(gsub(pattern = "%", "", df$variable))
> #[1] 12.6 30.9 61.4
> 
> 
> This is because sub() and gsub() return a character vector and the 
> instruction becomes an equivalent of what the help page ?factor 
> documents in section Warning:
> 
> To transform a factor f to approximately its original numeric values, 
> as.numeric(levels(f))[f] is recommended and slightly more efficient than 
> as.numeric(as.character(f)).
> 
> 
> Also, I would still prefer
> 
> as.numeric(sub(pattern = "%$","",df$variable))
> #[1] 12.6 30.9 61.4
> 
> The pattern is more strict and there is no need to search&replace 
> multiple occurrences of '%'.

The pattern is more strict, and that could cause the conversion to fail 
if the process that created the strings resulted in trailing spaces. 
Without the '$' the conversion succeeds.

df <- data.frame(variable = c("12.6% ", "30.9%", "61.4%"))
as.numeric(sub('%$', '', df$variable))
[1]   NA 30.9 61.4
Warning message:
NAs introduced by coercion


<<<snip>>>


Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA



From phiiipsm m@iii@g oii cp@@ei1@stormweb@@et  Mon Aug 20 02:16:27 2018
From: phiiipsm m@iii@g oii cp@@ei1@stormweb@@et (phiiipsm m@iii@g oii cp@@ei1@stormweb@@et)
Date: Sun, 19 Aug 2018 20:16:27 -0400
Subject: [R] as.Date() function
In-Reply-To: <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
 <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>
Message-ID: <20180819201627.Horde.q2d4uhEE8_2mg8Bn_ouZiwV@webmail.philipsmith.ca>

Thanks Erin and Jim. You have indeed solved my problem.

Philip


Quoting Erin Hodgess <erinm.hodgess at gmail.com>:

> Hi Philip:
>
> Here is something to consider:
>
>> #potential solution:
>> sta <- paste(st,"-01",sep="")
>> st1 <- as.Date(sta, format=("%Y-%m-%d"))
>> print(st1)
> [1] "1961-01-01" "1961-04-01" "1983-02-01"
>
>
> Hope this helps!
> Erin
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>
> On Sun, Aug 19, 2018 at 3:25 PM <philipsm at cpanel1.stormweb.net> wrote:
>
>> I am having trouble with what must be a very simple problem. Here is a
>> reproducible example:
>>
>> library(lubridate)
>> st <- c("1961-01","1961-04","1983-02")
>> print(st)
>> #[1] "1961-01" "1961-04" "1983-02"
>> st1 <- as.Date(st, format=("%Y-%m"))
>> print(st1)
>> #[1] NA NA NA
>>
>> Why the heck am I getting three NAs instead of three Dates?I have
>> studied the R documentation for as.Date() and it has not turned on the
>> light bulb for me.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug 20 07:26:19 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Aug 2018 06:26:19 +0100
Subject: [R] Converting chr to num
In-Reply-To: <b123a1a4-0f7c-6242-549c-c6be1572c503@gmail.com>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
 <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
 <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>
 <b123a1a4-0f7c-6242-549c-c6be1572c503@gmail.com>
Message-ID: <311a6e24-a37d-46bd-7e1b-4d377a6fad3e@sapo.pt>

Hello,

Inline.

On 20/08/2018 01:08, Daniel Nordlund wrote:
> See comment inline below:
> 
> On 8/18/2018 10:06 PM, Rui Barradas wrote:
>> Hello,
>>
>> It also works with class "factor":
>>
>> df <- data.frame(variable = c("12.6%", "30.9%", "61.4%"))
>> class(df$variable)
>> #[1] "factor"
>>
>> as.numeric(gsub(pattern = "%", "", df$variable))
>> #[1] 12.6 30.9 61.4
>>
>>
>> This is because sub() and gsub() return a character vector and the 
>> instruction becomes an equivalent of what the help page ?factor 
>> documents in section Warning:
>>
>> To transform a factor f to approximately its original numeric values, 
>> as.numeric(levels(f))[f] is recommended and slightly more efficient 
>> than as.numeric(as.character(f)).
>>
>>
>> Also, I would still prefer
>>
>> as.numeric(sub(pattern = "%$","",df$variable))
>> #[1] 12.6 30.9 61.4
>>
>> The pattern is more strict and there is no need to search&replace 
>> multiple occurrences of '%'.
> 
> The pattern is more strict, and that could cause the conversion to fail 
> if the process that created the strings resulted in trailing spaces. 

That's true, and I had thought of that but it wasn't in the OP's problem 
description.
The '$' could still be used with something like "%\\s*$":

as.numeric(sub('%\\s*$', '', df$variable))
#[1] 12.6 30.9 61.4


Rui Barradas


> Without the '$' the conversion succeeds.
> 
> df <- data.frame(variable = c("12.6% ", "30.9%", "61.4%"))
> as.numeric(sub('%$', '', df$variable))
> [1]?? NA 30.9 61.4
> Warning message:
> NAs introduced by coercion
> 
> 
> <<<snip>>>
> 
> 
> Dan
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com



From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Mon Aug 20 07:39:20 2018
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Mon, 20 Aug 2018 00:39:20 -0500
Subject: [R] Converting chr to num
In-Reply-To: <311a6e24-a37d-46bd-7e1b-4d377a6fad3e@sapo.pt>
References: <000001d43739$450cb030$cf261090$@sbcglobal.net>
 <CAKGtyO=MnTdcgg1CgDHHU+ZwoB+neinv3sg3nFO1wBhLQD=y3g@mail.gmail.com>
 <000201d4373f$36e4d220$a4ae7660$@sbcglobal.net>
 <CAKGtyOkLqz+m5RH_1VOuaY6QZFcML=_ryKRbadmX6p4_UK_4Ww@mail.gmail.com>
 <0bb649a2-ada3-ceba-d445-d7356baf2950@sapo.pt>
 <b123a1a4-0f7c-6242-549c-c6be1572c503@gmail.com>
 <311a6e24-a37d-46bd-7e1b-4d377a6fad3e@sapo.pt>
Message-ID: <5f3458ae-2a32-1690-8961-42cd8ae710dc@effectivedefense.org>

 ????? Have you considered "Ecfun::asNumericChar" (and 
"Ecfun::asNumericDF")?


DF <- data.frame(variable = c("12.6% ", "30.9%", "61.4%", "1"))
Ecfun::asNumericChar(DF$variable)
[1] 0.126 0.309 0.614 1.000


 ????? If you read the documentation including the examples, you will 
see that many of these issues and others are handled automatically in 
the way that I thought was the most sensible.? If you disagree, we can 
discuss other examples and perhaps modify the code for those functions.


 ????? Spencer Graves


On 2018-08-20 00:26, Rui Barradas wrote:
> Hello,
>
> Inline.
>
> On 20/08/2018 01:08, Daniel Nordlund wrote:
>> See comment inline below:
>>
>> On 8/18/2018 10:06 PM, Rui Barradas wrote:
>>> Hello,
>>>
>>> It also works with class "factor":
>>>
>>> df <- data.frame(variable = c("12.6%", "30.9%", "61.4%"))
>>> class(df$variable)
>>> #[1] "factor"
>>>
>>> as.numeric(gsub(pattern = "%", "", df$variable))
>>> #[1] 12.6 30.9 61.4
>>>
>>>
>>> This is because sub() and gsub() return a character vector and the 
>>> instruction becomes an equivalent of what the help page ?factor 
>>> documents in section Warning:
>>>
>>> To transform a factor f to approximately its original numeric 
>>> values, as.numeric(levels(f))[f] is recommended and slightly more 
>>> efficient than as.numeric(as.character(f)).
>>>
>>>
>>> Also, I would still prefer
>>>
>>> as.numeric(sub(pattern = "%$","",df$variable))
>>> #[1] 12.6 30.9 61.4
>>>
>>> The pattern is more strict and there is no need to search&replace 
>>> multiple occurrences of '%'.
>>
>> The pattern is more strict, and that could cause the conversion to 
>> fail if the process that created the strings resulted in trailing 
>> spaces. 
>
> That's true, and I had thought of that but it wasn't in the OP's 
> problem description.
> The '$' could still be used with something like "%\\s*$":
>
> as.numeric(sub('%\\s*$', '', df$variable))
> #[1] 12.6 30.9 61.4
>
>
> Rui Barradas
>
>
>> Without the '$' the conversion succeeds.
>>
>> df <- data.frame(variable = c("12.6% ", "30.9%", "61.4%"))
>> as.numeric(sub('%$', '', df$variable))
>> [1]?? NA 30.9 61.4
>> Warning message:
>> NAs introduced by coercion
>>
>>
>> <<<snip>>>
>>
>>
>> Dan
>>
>
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Aug 20 13:36:38 2018
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 20 Aug 2018 13:36:38 +0200
Subject: [R] Using rmarkdown with many plots created in a loop
In-Reply-To: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>
References: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>
Message-ID: <CAJuCY5wrwGaRwHsiK+6kDxphQL_2+3yCVxumyZWFT2sPQ_ZrCw@mail.gmail.com>

Dear Don,

Have a look at the knit_expand() function. Then you can create two Rmd
files. One main file and one template file for the subsets. knit_expand()
will find and replace anything between double curly brackets ("{{x}}" in
the example below) with the value of the variable.

The main file:

---
title: "main"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
```

```{r}
mydf <- data.frame(
  id = 1:4,
  x = rnorm(100),
  y = rnorm(100)
)
```

```{r}
rmd <- sapply(
  1:4,
  function(x) {
    knit_expand("child.Rmd", x = x)
  }
)
rmd <- paste(rmd, collapse = "\n")
cat(rmd)
```
```{r results = "asis"}
rendered <- knit(text = rmd, quiet = TRUE)
cat(rendered, sep = "\n")
```


The child.Rmd file

## ID {{x}}

```{r, fig.cap = "The caption: ID = {{x}}", echo = FALSE}
i <- {{x}}
detail <- subset(mydf, id == i)
plot(x ~ y, data = detail)
```

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-08-17 1:44 GMT+02:00 MacQueen, Don via R-help <r-help at r-project.org>:

> I would appreciate some suggestions of a good way to prepare a report
> using rmarkdown,
> in which I loop through subsets of a data set, creating a plot of each
> subset, and interspersing
> among the figures some text relevant to each figure.
>
> One way is to have an R script write the rmd file, then render it.
> It works, but it's cumbersome and difficult to get the rmd syntax correct.
> I would very much appreciate suggestions for a better way.
>
> Reproducible example below.
>
> Thanks
> -Don
>
>
> Example data (other data structures could be used), and an example using
> this approach.
>
> myd <- lapply( 1:3,
>               function(i) list(df=data.frame(x=1:5, y=rnorm(5)),
>                                comment=paste('Data', LETTERS[i]))
>               )
>
> Example interactive review (details would change depending on data
> structure)
> (I would typically insert pauses when working interactively)
>
> for (i in 1:3) {
>   cat(paste('Figure',i,'shows',myd[[i]]$comment),'\n')
>   with(myd[[i]]$df , plot(x,y))
>   mtext(myd[[i]]$comment)
>   mtext( paste(nrow(myd[[i]]$df),'points'), adj=1)
> }?
>
> Note that along with the data I've saved some comments relevant to each
> subset.
> I've calculated them in the example data, but in general they could be
> completely
> arbitrary and come from anywhere.
>
> Now I'd like to get the same plots and comments into a report prepared
> using rmarkdown.
> Here's one way, having the loop create an rmd file, then rendering it.
>
> ### example script begins
> library(rmarkdown)
>
> myf <- 'myd.rmd'
> sink(myf)
> cat('---
> title: Example
> ---
>
> Here are some figures with a comment appearing before each.\n\n'
> )
> sink()
>
> for (i in 1:3) {
>   cat(paste('Figure',i,'comment:',myd[[i]]$comment),'\n', file=myf,
> append=TRUE)
>
>   cat("
> ```{r  echo=FALSE, fig.cap='",paste('fig',i),"caption.'}
>   with(myd[[",i,"]]$df , plot(x,y))
>   mtext(myd[[",i,"]]$comment)
>   mtext( paste(nrow(myd[[",i,"]]$df),'points'), adj=1)
> ```
> ", file=myf, append=TRUE)
>
> }
>
> cat('Done with report\n', file=myf, append=TRUE)
>
> render(myf)
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From rmh @end|ng |rom temp|e@edu  Mon Aug 20 15:45:33 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Mon, 20 Aug 2018 09:45:33 -0400
Subject: [R] Using rmarkdown with many plots created in a loop
In-Reply-To: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>
References: <7613B466-1C59-4EAB-87EA-00214A3ABF49@llnl.gov>
Message-ID: <CAGx1TMBEA7PDNQ9O1QkXtfpuqLd4y4r4+rF2tc2T2pSR8+0BRQ@mail.gmail.com>

## Don,

## This is how I would approach the task of a set of coordinated plots.
## I would place individual plots inside a table.  The rows would index the
## datasets and there would be one or more data or description columns
## in addition to the column containing the graphs.

## I use the microplot package that I placed on CRAN about two years ago.

## install.packages("microplot") ## if necessary


library(microplot)
latexSetOptions()

## I normally use lattice.  microplot also works with ggplot or base graphics
library(lattice)

## I placed your data into a single data.frame
myd <- lapply( 1:3,
              function(i) list(df=data.frame(x=1:5, y=rnorm(5)),
                               comment=paste('Data', LETTERS[i]))
              )

mydf <- cbind(group=rep(c("A", "B", "C"), each=5),
              rbind(myd[[1]]$df, myd[[2]]$df, myd[[3]]$df))
mydf


## construct a lattice with multiple panels
my.lattice <-
  xyplot(y ~ x | group, data=mydf,
         layout=c(1,3), as.table=TRUE, col="black",
         scales=list(alternating=FALSE),
         ylab=list(rot=1))
my.lattice


## microplot provides latex.trellis, which is a method for Hmisc::latex

## simplest display
latex(my.lattice)

## now with comments and optional additional arguments
mycomments <-
  c("Interesting Comment",
    "Full \\LaTeX\\ with an equation $e^{-x^2}$",
    "\\begin{tabular}{l}$\\frac{dy}{dx}$ \\\\is interesting \\\\and
has multiple lines\\end{tabular}")

latex(my.lattice,
      title="Dataset",
      height.panel=1, width.panel=1.5, ## inches
      height.x.axis=.38, width.y.axis=.45,
      graph.header="xyplot(y ~ x | group)",
      dataobject=mycomments,
      colheads=c("Comments", "", "", "xyplot( y \\~{} x )"),
      caption="Very Interesting Caption",
      caption.loc="bottom",
      arraystretch=1.5)

## microplot produces MS Word tables as well as LaTeX tables.
## microplot works with  ?Sweave?, ?knitr?, ?emacs? ?orgmode?, and ?rmarkdown?

## Start with ?microplot-package
## and look at the demos and examples and vignette.

## Rich

On Thu, Aug 16, 2018 at 7:44 PM, MacQueen, Don via R-help
<r-help at r-project.org> wrote:
> I would appreciate some suggestions of a good way to prepare a report using rmarkdown,
> in which I loop through subsets of a data set, creating a plot of each subset, and interspersing
> among the figures some text relevant to each figure.
>
> One way is to have an R script write the rmd file, then render it.
> It works, but it's cumbersome and difficult to get the rmd syntax correct.
> I would very much appreciate suggestions for a better way.
>
> Reproducible example below.
>
> Thanks
> -Don
>
>
> Example data (other data structures could be used), and an example using this approach.
>
> myd <- lapply( 1:3,
>               function(i) list(df=data.frame(x=1:5, y=rnorm(5)),
>                                comment=paste('Data', LETTERS[i]))
>               )
>
> Example interactive review (details would change depending on data structure)
> (I would typically insert pauses when working interactively)
>
> for (i in 1:3) {
>   cat(paste('Figure',i,'shows',myd[[i]]$comment),'\n')
>   with(myd[[i]]$df , plot(x,y))
>   mtext(myd[[i]]$comment)
>   mtext( paste(nrow(myd[[i]]$df),'points'), adj=1)
> }?
>
> Note that along with the data I've saved some comments relevant to each subset.
> I've calculated them in the example data, but in general they could be completely
> arbitrary and come from anywhere.
>
> Now I'd like to get the same plots and comments into a report prepared using rmarkdown.
> Here's one way, having the loop create an rmd file, then rendering it.
>
> ### example script begins
> library(rmarkdown)
>
> myf <- 'myd.rmd'
> sink(myf)
> cat('---
> title: Example
> ---
>
> Here are some figures with a comment appearing before each.\n\n'
> )
> sink()
>
> for (i in 1:3) {
>   cat(paste('Figure',i,'comment:',myd[[i]]$comment),'\n', file=myf, append=TRUE)
>
>   cat("
> ```{r  echo=FALSE, fig.cap='",paste('fig',i),"caption.'}
>   with(myd[[",i,"]]$df , plot(x,y))
>   mtext(myd[[",i,"]]$comment)
>   mtext( paste(nrow(myd[[",i,"]]$df),'points'), adj=1)
> ```
> ", file=myf, append=TRUE)
>
> }
>
> cat('Done with report\n', file=myf, append=TRUE)
>
> render(myf)
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From kyd@v|ddoy|e @end|ng |rom gm@||@com  Mon Aug 20 21:17:13 2018
From: kyd@v|ddoy|e @end|ng |rom gm@||@com (David Doyle)
Date: Mon, 20 Aug 2018 14:17:13 -0500
Subject: [R] Transforming data for nice output table
Message-ID: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>

Hello everyone,

I'm trying to generate tables of my data out of R for my report.

My data is setup in the format as follows and the example can be found at:
http://doylesdartden.com/R/ExampleData.csv

Location        Date        Year      GW_Elevation
127(I)        5/14/2006     2006       752.46
119(I)        5/14/2006     2006       774.67
127(I)        6/11/2007     2007       752.06
119(I)        6/11/2007     2007       775.57

I would like to generate a table that showed

Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....

119(I)                    774.67                      775.57
          xxxx
127(I)                    752.46                      752.06
          xxxx
XXXX                          XX                           XX

 Any thoughts on how to transform the data so it would be in this format??

Thank you for your time

David Doyle

	[[alternative HTML version deleted]]



From @he@cott @end|ng |rom pennmed|c|ne@upenn@edu  Mon Aug 20 21:42:22 2018
From: @he@cott @end|ng |rom pennmed|c|ne@upenn@edu (Scott Sherrill-Mix)
Date: Mon, 20 Aug 2018 15:42:22 -0400
Subject: [R] download.file() problems with binary files containing EOF byte
 in Windows
In-Reply-To: <CAKwTkR2pin3HZVtwO8MvZ0phsE6Q3YYDdX=3+DZ-y7=8qdPECg@mail.gmail.com>
References: <CAKwTkR2pin3HZVtwO8MvZ0phsE6Q3YYDdX=3+DZ-y7=8qdPECg@mail.gmail.com>
Message-ID: <CAKwTkR3G-DAUCoA84+idEQphsZgewPqCPQtiVXD+SAObn8wBQg@mail.gmail.com>

Hello,
I'm trying to get a package to pass win-builder and have been having a
bit of trouble with Windows R and binary files (in my case a small
.tar.gz used in testing). After a little debugging, I think I've
narrowed it down to download.file() truncating files to the first '1a'
byte (often used for EOF but I think a valid byte inside gzip files)
on downloads from local "file://xxx". I'm trying to figure out if this
is a known "feature" of Windows that I should just avoid or does this
seem like a bug?

For example:

#write a file starting with byte 1a (decimal 26)
writeBin(26:100,'tmp.bin',size=1)
download.file('file://tmp.bin','download.bin')
file.size('tmp.bin')
file.size('download.bin')

On Windows (session info below), I get file sizes of 75 and 0 and on
Linux I get 75 and 75.

As a more real world example, if I download.file() on a .gz file then
a remote download seems to return different size files from a local
download. For example for a gz file from a google hit about gzip
(http://commandlinefanatic.com/cgi-bin/showarticle.cgi?article=art053):

download.file('http://commandlinefanatic.com/gunzip.c.gz','gunzip.c.gz')
download.file('file://gunzip.c.gz','dl.gz')
file.size('gunzip.c.gz')
file.size('dl.gz')

I get a 4704 byte file for the remote download and 360 for the local
download in Windows (versus 4704 and 4704 on Linux). Note that the
361st byte is 1a:

readBin('gunzip.c.gz','raw',361)

The various download.file options don't seem to fix this with the same 360 bytes
for:

download.file('file://gunzip.c.gz','dl.gz',mode='wb')
file.size('dl.gz')
download.file('file://gunzip.c.gz','dl.gz',mode='wb',method='internal')
file.size('dl.gz')

It looks like the 'auto' and 'internal' methods both resolve to the
'wininet' method on Windows and mode is automatically set to 'wb' for
gz files so maybe not surprising those don't change things.

Thanks,
Scott

## Windows sessionInfo():
R version 3.5.1 (2018-07-02)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 8.1 x64 (build 9600)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_3.5.1


## Linux sessionInfo():
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.5 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.4



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug 20 22:37:12 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Aug 2018 21:37:12 +0100
Subject: [R] Transforming data for nice output table
In-Reply-To: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
Message-ID: <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>

Hello,

This is a very frequent question.
I could rewrite one or two answers taken from StackOverflow:

https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format


But there you will have more options.


Hope this helps,

Rui Barradas

On 20/08/2018 20:17, David Doyle wrote:
> Hello everyone,
> 
> I'm trying to generate tables of my data out of R for my report.
> 
> My data is setup in the format as follows and the example can be found at:
> http://doylesdartden.com/R/ExampleData.csv
> 
> Location        Date        Year      GW_Elevation
> 127(I)        5/14/2006     2006       752.46
> 119(I)        5/14/2006     2006       774.67
> 127(I)        6/11/2007     2007       752.06
> 119(I)        6/11/2007     2007       775.57
> 
> I would like to generate a table that showed
> 
> Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....
> 
> 119(I)                    774.67                      775.57
>            xxxx
> 127(I)                    752.46                      752.06
>            xxxx
> XXXX                          XX                           XX
> 
>   Any thoughts on how to transform the data so it would be in this format??
> 
> Thank you for your time
> 
> David Doyle
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com



From m@cqueen1 @end|ng |rom ||n|@gov  Mon Aug 20 22:53:39 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 20 Aug 2018 20:53:39 +0000
Subject: [R] plotmath and logical operators?
Message-ID: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>

I would like to use plotmath to annotate a plot with an expression that includes a logical operator.

## works well
tmp <- expression(x >= 3)
plot(1)
mtext(tmp)

## not so well
tmp <- expression(x >= 3 &  y <= 3)
plot(1)
mtext(tmp)?

Although the text that's displayed makes sense, it won't be obvious to my non-mathematical audience.

I'd appreciate suggestions.


I've found a work-around that gets the annotation to look right
  tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
  plot(1)
  mtext(tmpw)


But it breaks my original purpose, illustrated by this example:

df <- data.frame(x=1:5, y=1:5)
tmp <- expression(x >= 3 & y <= 3)
tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
with(df, eval(tmp))
[1] FALSE FALSE  TRUE FALSE FALSE
with(df, eval(tmpw))
[1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE" "TRUE  &  FALSE"

Thanks
-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Aug 20 23:04:58 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Mon, 20 Aug 2018 17:04:58 -0400
Subject: [R] Request for R Assistance: Downloading Data
In-Reply-To: <SN6PR05MB4816150D27E8995E51B0A6F8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
References: <CAPQaxLNyZEJ3+v8odm3S_4K4PEUjUm3m3uYLPzRb3SR7LM=8PQ@mail.gmail.com>
 <SN6PR05MB4816053FA7BC444750490FD8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
 <9154F32C-253C-4061-8858-C6F6BB877726@dcn.davis.ca.us>
 <SN6PR05MB4816150D27E8995E51B0A6F8FA330@SN6PR05MB4816.namprd05.prod.outlook.com>
Message-ID: <CAPQaxLN=mudVDk+7MuqAiHYq+aiQqEsjLe75p8S8KbRSd62d2A@mail.gmail.com>

 Please ignore my last post/inquiry... I have solved the problem. Thanks
again for the help!

On Sun, Aug 19, 2018 at 5:43 PM Sparks, John <jspark4 at uic.edu> wrote:

> I agree with Jeff.  The data type is the problem.  I wrote what I wrote
> without looking at the problem very carefully.
>
>
> --JJS
>
>
> ------------------------------
> *From:* Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> *Sent:* Sunday, August 19, 2018 4:38 PM
> *To:* r-help at r-project.org; Sparks, John; Spencer Brackett;
> r-help at r-project.org
> *Subject:* Re: [R] Request for R Assistance: Downloading Data
>
> I think this hunch is off the mark... the file name is fine as it is... if
> anything will confuse R it would be that the data inside the file are not
> what was expected.
>
> If in fact the file is csv formatted then the function to read it would be
> read.csv [1] or read.table [2]. Read the help pages for these functions and
> read the R Data Import/Export documentation [3].
>
> [1] ?read.csv at R console
> [2] ?read.table many of the options for this function will work for
> read.csv.
> [3] https://cran.r-project.org/doc/manuals/r-release/R-data.html
> R Data Import/Export
> <https://cran.r-project.org/doc/manuals/r-release/R-data.html>
> cran.r-project.org
> 1.1 Imports. The easiest form of data to import into R is a simple text
> file, and this will often be acceptable for problems of small or medium
> scale.
>
>
>
> On August 19, 2018 12:16:14 PM PDT, "Sparks, John" <jspark4 at uic.edu>
> wrote:
> >Just a hunch, but I would recommend simplifying your filename:  remove
> >the (CSV) portion.  It could be confusing in R read syntax.  Create a
> >filename with no unnecessary punctuation and no blank spaces.
> >
> >
> >--John Sparks
> >
> >
> >________________________________
> >From: R-help <r-help-bounces at r-project.org> on behalf of Spencer
> >Brackett <spbrackett20 at saintjosephhs.com>
> >Sent: Sunday, August 19, 2018 2:11 PM
> >To: r-help at r-project.org
> >Subject: [R] Request for R Assistance: Downloading Data
> >
> >Good evening,
> >
> >I am attempting to download Genomic data from the GDC onto R for
> >analysis
> >and am experiencing some difficulty. I have downloaded the GDC data
> >into an
> >Excel, CSV, and notepad (.txt) file and implemented what I believe to
> >be
> >the proper arguments, with every attempting failing to properly load
> >the
> >data onto R. The following is the various attempts I made in trying to
> >take
> >one of these files (a translated version of the GDC data) and load it
> >into R
> >.
> >
> >> load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv")
> >Error in load("C:\\Users\\Spencer\\Desktop\\LGG Drug (CSV).csv") :
> >bad restore file magic number (file may be corrupted) -- no data loaded
> >In addition: Warning message:
> >file ?LGG Drug (CSV).csv? has magic number 'MANIF'
> >  Use of save versions prior to 2 is deprecated
> >> LGG Drug<-read.table("C:\\Users\\Spencer\\Desktop\\LGG Drug
> >(CSV).csv",header=TRUE,sep=",")
> >Error: unexpected symbol in "LGG Drug"
> >> LGG Drug<-read.table("C:
> >Error: unexpected symbol in "LGG Drug"
> >> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt")
> >Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM.txt") :
> >bad restore file magic number (file may be corrupted) -- no data loaded
> >In addition: Warning message:
> >file ?DRUG TRIAL GBM.txt? has magic number 'MANIF'
> >  Use of save versions prior to 2 is deprecated
> >> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM.txt",header=TRUE,sep="")
> >Error: unexpected symbol in "GBM Drug"
> >> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM.txt",header=TRUE,sep="\t")
> >Error: unexpected symbol in "GBM Drug"
> >> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM.txt",header=TRUE,sep="")
> >Error: unexpected symbol in "GBM Drug"
> >>  GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM.txt",header=TRUE,sep="\t")
> >Error: unexpected symbol in " GBM Drug"
> >> load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word wrap).txt")
> >Error in load("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL GBM(word
> >wrap).txt")
> >:
> >bad restore file magic number (file may be corrupted) -- no data loaded
> >In addition: Warning message:
> >file ?DRUG TRIAL GBM(word wrap).txt? has magic number 'MANIF'
> >  Use of save versions prior to 2 is deprecated
> >> GBM Drug<-read.table("C:\\Users\\Spencer\\Desktop\\DRUG TRIAL
> >GBM(word
> >wrap).txt",header=TRUE,sep="")
> >Error: unexpected symbol in "GBM Drug"
> >
> >Any insight into what perhaps I am inputting that is causes this
> >reoccurring error? Any suggestions as to another procedure for moving
> >forward would be greatly appreciated!
> >
> >Many thanks,
> >
> >Spencer Brackett
> >
> >        [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >R-help -- Main R Mailing List: Primary help - Homepage -
> >SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
> >stat.ethz.ch
> >The main R mailing list, for announcements about the development of R
> >and the availability of new code, questions and answers about problems
> >and solutions using R, enhancements and patches to the source code and
> >documentation of R, comparison and compatibility with S and S-plus, and
> >for the posting of nice examples and benchmarks.
> >
> >
> >
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From j@kper|k@d|oggb@n @end|ng |rom @tudent@@jku@t@@c@ke  Mon Aug 20 23:49:59 2018
From: j@kper|k@d|oggb@n @end|ng |rom @tudent@@jku@t@@c@ke (Dioggban Jakperik)
Date: Tue, 21 Aug 2018 00:49:59 +0300
Subject: [R] Fwd: Computing the density of a median
In-Reply-To: <CANbn+9CL7zgn9Xnui43pEYYkPaAB030fkQCGP7UM_CaFR6SywQ@mail.gmail.com>
References: <CANbn+9CL7zgn9Xnui43pEYYkPaAB030fkQCGP7UM_CaFR6SywQ@mail.gmail.com>
Message-ID: <CANbn+9DsS3Q0mUFq6otBc9LKLXAkSj-sTs8QXPp4y-6MpH-mMA@mail.gmail.com>

Dear all,


I have the following function

kdenor <- function(aa,q=NULL){
a=sample(aa,500,replace=F)
ab=quantile(a, p=0.75)-quantile(a, p=0.25)
h=(0.9*min(var(a),ab))/(1.34*n^(1/5))

if(is.null(q)) {
q = seq(min(a)-3*h, max(a)+3*h, length.out=length(a))
}
nx = length(a)
nq = length(q)
xmat = matrix(q,nq,nx) - matrix(a,nq,nx,byrow=TRUE)
denall= dnorm(xmat/h)/h
denhat = apply(denall,1,mean)

f<-denhat
f1<-median(f)
#das<-list(x=q, y=denhat, h=h)
#return(das)
}

f1<-kdenor(aa)

My interest is to obtain the estimate of the density at the median of the
sample data.
But the output of the current function  doesn't provide the correct result.
Kindly help.
Regards.


-- 
Jakperik Dioggban (Student, PAUISTI)
PhD Mathematics (Statistics Option)
Determination is Key to Success



-- 
Jakperik Dioggban (Student, PAUISTI)
PhD Mathematics (Statistics Option)
Determination is Key to Success

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Tue Aug 21 00:27:19 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 21 Aug 2018 08:27:19 +1000
Subject: [R] Transforming data for nice output table
In-Reply-To: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
Message-ID: <CA+8X3fWOkfSxOgRCoFZBYifJg6wMrGiY1sXQy7W+V-nhHqfqVg@mail.gmail.com>

Hi David,
As you want the _values_ of Year from the initial data frame appended
to the _names_ of GW_Elevation, you can't do it the easy way:

dddf<-read.table(text="Location        Date        Year      GW_Elevation
127(I)        5/14/2006     2006       752.46
119(I)        5/14/2006     2006       774.67
127(I)        6/11/2007     2007       752.06
119(I)        6/11/2007     2007       775.57",
header=TRUE)
library(prettyR)
# easy part
sdddf<-stretch_df(dddf[c(1,3,4)],"Location",c("Year","GW_Elevation"))
sdddf

This only works for a data frame with the structure and names of the initial one

# hard part
sdddf_dim<-dim(sdddf)
nyears<-(sdddf_dim[2] - 1)/2
fsdddf<-sdddf[,c(1,1:nyears+nyears+1)]
names(fsdddf)<-c("Location",paste("GW_Elevation",unique(dddf$Year),sep="_"))
fsdddf

I would strongly suggest being happy with the easy way, because if the
order of years isn't ascending, the hard way won't work.

Jim

On Tue, Aug 21, 2018 at 5:17 AM, David Doyle <kydaviddoyle at gmail.com> wrote:
> Hello everyone,
>
> I'm trying to generate tables of my data out of R for my report.
>
> My data is setup in the format as follows and the example can be found at:
> http://doylesdartden.com/R/ExampleData.csv
>
> Location        Date        Year      GW_Elevation
> 127(I)        5/14/2006     2006       752.46
> 119(I)        5/14/2006     2006       774.67
> 127(I)        6/11/2007     2007       752.06
> 119(I)        6/11/2007     2007       775.57
>
> I would like to generate a table that showed
>
> Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....
>
> 119(I)                    774.67                      775.57
>           xxxx
> 127(I)                    752.46                      752.06
>           xxxx
> XXXX                          XX                           XX
>
>  Any thoughts on how to transform the data so it would be in this format??
>
> Thank you for your time
>
> David Doyle
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 21 00:37:53 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 20 Aug 2018 15:37:53 -0700
Subject: [R] plotmath and logical operators?
In-Reply-To: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
Message-ID: <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>

This is clumsy and probably subject to considerable improvement, but does
it work for you:

left <- quote(x >= 3)
right <- quote(y <= 3) ## these can be anything

## the plot:
plot(1)
eval(substitute(mtext(expression(paste(left, " & ",right))), list(left =
left, right = right)))

## Expression evaluation
eval(substitute(with(df,left & right), list(left = left, right = right)))

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <
r-help at r-project.org> wrote:

> I would like to use plotmath to annotate a plot with an expression that
> includes a logical operator.
>
> ## works well
> tmp <- expression(x >= 3)
> plot(1)
> mtext(tmp)
>
> ## not so well
> tmp <- expression(x >= 3 &  y <= 3)
> plot(1)
> mtext(tmp)?
>
> Although the text that's displayed makes sense, it won't be obvious to my
> non-mathematical audience.
>
> I'd appreciate suggestions.
>
>
> I've found a work-around that gets the annotation to look right
>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>   plot(1)
>   mtext(tmpw)
>
>
> But it breaks my original purpose, illustrated by this example:
>
> df <- data.frame(x=1:5, y=1:5)
> tmp <- expression(x >= 3 & y <= 3)
> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
> with(df, eval(tmp))
> [1] FALSE FALSE  TRUE FALSE FALSE
> with(df, eval(tmpw))
> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE"
> "TRUE  &  FALSE"
>
> Thanks
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Aug 21 01:05:03 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 20 Aug 2018 16:05:03 -0700 (PDT)
Subject: [R] Transforming data for nice output table
In-Reply-To: <CA+8X3fWOkfSxOgRCoFZBYifJg6wMrGiY1sXQy7W+V-nhHqfqVg@mail.gmail.com>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
 <CA+8X3fWOkfSxOgRCoFZBYifJg6wMrGiY1sXQy7W+V-nhHqfqVg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1808201557520.25042@pedal.dcn.davis.ca.us>

If departing from base R into contributed territory, tidyr::spread is 
well-suited to this.

library(dplyr)
library(tidyr)
dta <- read.csv( "http://doylesdartden.com/R/ExampleData.csv"
                , header = TRUE
                , as.is = TRUE
                )
result <- (   dta # starting with your data...
           # keep only relevant columns
           %>% select( Location, Year, GW_Elevation )
           # make the key column look like your desired column names
           %>% mutate( Year = sprintf( "GW_Elevation %d", Year ) )
           # spread the "long" data out "wide"
           %>% spread( Year, GW_Elevation )
           )

On Tue, 21 Aug 2018, Jim Lemon wrote:

> Hi David,
> As you want the _values_ of Year from the initial data frame appended
> to the _names_ of GW_Elevation, you can't do it the easy way:
>
> dddf<-read.table(text="Location        Date        Year      GW_Elevation
> 127(I)        5/14/2006     2006       752.46
> 119(I)        5/14/2006     2006       774.67
> 127(I)        6/11/2007     2007       752.06
> 119(I)        6/11/2007     2007       775.57",
> header=TRUE)
> library(prettyR)
> # easy part
> sdddf<-stretch_df(dddf[c(1,3,4)],"Location",c("Year","GW_Elevation"))
> sdddf
>
> This only works for a data frame with the structure and names of the initial one
>
> # hard part
> sdddf_dim<-dim(sdddf)
> nyears<-(sdddf_dim[2] - 1)/2
> fsdddf<-sdddf[,c(1,1:nyears+nyears+1)]
> names(fsdddf)<-c("Location",paste("GW_Elevation",unique(dddf$Year),sep="_"))
> fsdddf
>
> I would strongly suggest being happy with the easy way, because if the
> order of years isn't ascending, the hard way won't work.
>
> Jim
>
> On Tue, Aug 21, 2018 at 5:17 AM, David Doyle <kydaviddoyle at gmail.com> wrote:
>> Hello everyone,
>>
>> I'm trying to generate tables of my data out of R for my report.
>>
>> My data is setup in the format as follows and the example can be found at:
>> http://doylesdartden.com/R/ExampleData.csv
>>
>> Location        Date        Year      GW_Elevation
>> 127(I)        5/14/2006     2006       752.46
>> 119(I)        5/14/2006     2006       774.67
>> 127(I)        6/11/2007     2007       752.06
>> 119(I)        6/11/2007     2007       775.57
>>
>> I would like to generate a table that showed
>>
>> Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....
>>
>> 119(I)                    774.67                      775.57
>>           xxxx
>> 127(I)                    752.46                      752.06
>>           xxxx
>> XXXX                          XX                           XX
>>
>>  Any thoughts on how to transform the data so it would be in this format??
>>
>> Thank you for your time
>>
>> David Doyle
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From m@cqueen1 @end|ng |rom ||n|@gov  Tue Aug 21 01:14:06 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 20 Aug 2018 23:14:06 +0000
Subject: [R] plotmath and logical operators?
In-Reply-To: <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
 <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
Message-ID: <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>

Thanks Bert!

It certainly works for the example (and shows a much deeper understanding of eval, substitute, etc. than I have). But it doesn't appear to generalize very well in the way I need (which of course I didn't think of mentioning until after I sent the email -- sorry).

Suppose subs is any expression that would be valid for the subset argument of base::subset, for a given data frame. Then I can extract that subset of the data frame by using
   mydf[  with(mydf, eval(subs)) ,  ]
(or similar).

Then, having plotted some aspect of that subset, I want to annotate the plot with the subset specifications.

I've used this approach to  set up a system that helps me to interactively review various subsets of a large set of data. I save the final selected subsetting expressions in some sort of data structure, for later use in preparing a report using rmarkdown.

I was hoping to use plotmath to improve the appearance of the annotations -- but I now think it's not worth this kind of effort. I think I'm going to settle for mtext( as.character(subs) ).

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Monday, August 20, 2018 at 3:38 PM
To: "MacQueen, Don" <macqueen1 at llnl.gov>
Cc: array R-help <r-help at r-project.org>
Subject: Re: [R] plotmath and logical operators?

This is clumsy and probably subject to considerable improvement, but does it work for you:

left <- quote(x >= 3)
right <- quote(y <= 3) ## these can be anything

## the plot:
plot(1)
eval(substitute(mtext(expression(paste(left, " & ",right))), list(left = left, right = right)))

## Expression evaluation
eval(substitute(with(df,left & right), list(left = left, right = right)))
Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
I would like to use plotmath to annotate a plot with an expression that includes a logical operator.

## works well
tmp <- expression(x >= 3)
plot(1)
mtext(tmp)

## not so well
tmp <- expression(x >= 3 &  y <= 3)
plot(1)
mtext(tmp)

Although the text that's displayed makes sense, it won't be obvious to my non-mathematical audience.

I'd appreciate suggestions.


I've found a work-around that gets the annotation to look right
  tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
  plot(1)
  mtext(tmpw)


But it breaks my original purpose, illustrated by this example:

df <- data.frame(x=1:5, y=1:5)
tmp <- expression(x >= 3 & y <= 3)
tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
with(df, eval(tmp))
[1] FALSE FALSE  TRUE FALSE FALSE
with(df, eval(tmpw))
[1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE" "TRUE  &  FALSE"

Thanks
-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 21 01:52:48 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 20 Aug 2018 16:52:48 -0700
Subject: [R] plotmath and logical operators?
In-Reply-To: <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
 <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
 <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
Message-ID: <CAGxFJbT3AY25L_C30t2QmbESdavqsRkGcJJWK6dTGWkNYWYAHA@mail.gmail.com>

As I understand it, the problem is:

"A mathematical expression must obey the normal rules of syntax for
any *R* expression,
but it is interpreted according to very different rules than for normal *R*
expressions."

I believe this means that you cannot do what you wanted to using plotmath.

Cheers,
Bert


On Mon, Aug 20, 2018 at 4:14 PM MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Thanks Bert!
>
>
>
> It certainly works for the example (and shows a much deeper understanding
> of eval, substitute, etc. than I have). But it doesn't appear to generalize
> very well in the way I need (which of course I didn't think of mentioning
> until after I sent the email -- sorry).
>
>
>
> Suppose subs is any expression that would be valid for the subset argument
> of base::subset, for a given data frame. Then I can extract that subset of
> the data frame by using
>
>    mydf[  with(mydf, eval(subs)) ,  ]
>
> (or similar).
>
>
>
> Then, having plotted some aspect of that subset, I want to annotate the
> plot with the subset specifications.
>
>
>
> I've used this approach to  set up a system that helps me to interactively
> review various subsets of a large set of data. I save the final selected
> subsetting expressions in some sort of data structure, for later use in
> preparing a report using rmarkdown.
>
>
>
> I was hoping to use plotmath to improve the appearance of the annotations
> -- but I now think it's not worth this kind of effort. I think I'm going to
> settle for mtext( as.character(subs) ).
>
>
>
> -Don
>
>
>
> --
>
> Don MacQueen
>
> Lawrence Livermore National Laboratory
>
> 7000 East Ave., L-627
>
> Livermore, CA 94550
>
> 925-423-1062
>
> Lab cell 925-724-7509
>
>
>
>
>
>
>
> *From: *Bert Gunter <bgunter.4567 at gmail.com>
> *Date: *Monday, August 20, 2018 at 3:38 PM
> *To: *"MacQueen, Don" <macqueen1 at llnl.gov>
> *Cc: *array R-help <r-help at r-project.org>
> *Subject: *Re: [R] plotmath and logical operators?
>
>
>
> This is clumsy and probably subject to considerable improvement, but does
> it work for you:
>
>
>
> left <- quote(x >= 3)
> right <- quote(y <= 3) ## these can be anything
>
>
>
> ## the plot:
>
> plot(1)
>
> eval(substitute(mtext(expression(paste(left, " & ",right))), list(left =
> left, right = right)))
>
>
>
> ## Expression evaluation
>
> eval(substitute(with(df,left & right), list(left = left, right = right)))
>
> Cheers,
>
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
>
>
> On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <
> r-help at r-project.org> wrote:
>
> I would like to use plotmath to annotate a plot with an expression that
> includes a logical operator.
>
> ## works well
> tmp <- expression(x >= 3)
> plot(1)
> mtext(tmp)
>
> ## not so well
> tmp <- expression(x >= 3 &  y <= 3)
> plot(1)
> mtext(tmp)
>
> Although the text that's displayed makes sense, it won't be obvious to my
> non-mathematical audience.
>
> I'd appreciate suggestions.
>
>
> I've found a work-around that gets the annotation to look right
>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>   plot(1)
>   mtext(tmpw)
>
>
> But it breaks my original purpose, illustrated by this example:
>
> df <- data.frame(x=1:5, y=1:5)
> tmp <- expression(x >= 3 & y <= 3)
> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
> with(df, eval(tmp))
> [1] FALSE FALSE  TRUE FALSE FALSE
> with(df, eval(tmpw))
> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE"
> "TRUE  &  FALSE"
>
> Thanks
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Tue Aug 21 04:12:43 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 20 Aug 2018 19:12:43 -0700
Subject: [R] plotmath and logical operators?
In-Reply-To: <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
 <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
 <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
Message-ID: <CAF8bMcY057MeBdmYgnMmNv0a81YFcjyHQXgVjyRVkkzX3at9Bw@mail.gmail.com>

A generalization of Bert's suggestion is

plotSubset <- function (data, subset, qsubset = substitute(subset))
{
    sdata <- data[eval(qsubset, data), ]
    with(sdata, plot(x, y, main = subsetToPlotmath(expr = qsubset)))
}


subsetToPlotmath <- function(expr) {
    # Argument 'expr': an expression used as subset argument to subset()
    # Return: an expression used by plotmath that is more readable to
non-programming people
    if (is.call(expr)) {
        for(i in seq_along(expr)) {
            expr[[i]] <- subsetToPlotmath(expr[[i]])
        }
        if (is.name(funcName <- expr[[1]]) && !is.null(func <-
env.subsetToPlotmath[[as.character(funcName)]])) {
            expr <- do.call(func, as.list(expr[-1]))
        }
    }
    expr
}
env.subsetToPlotmath <- new.env()
env.subsetToPlotmath[["&"]] <- function(x, y) substitute(x ~ italic(and) ~
y)
env.subsetToPlotmath[["|"]] <- function(x, y) substitute((x) ~ italic(or) ~
(y)) # internal parens not always needed
env.subsetToPlotmath[["log10"]] <- function(x)
substitute(italic(log)[10](x))
env.subsetToPlotmath[["exp"]] <- function(x) substitute(italic(e)^x)

You can add more conversions to the environment env.subsetToPlotmath.

Try it with

> df <- data.frame(x=1:5, y=1:5)
> plotSubset(df, x<1.5 | y>3.5) # see title "(x < 1.5) or (y > 3.5)" and
pts at x=1,4,5.

It doesn't get right the parentheses needed to enforce the order of
evaluation:
it always puts parentheses around the arguments to | and never puts them
around the arguments to &.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Aug 20, 2018 at 4:14 PM, MacQueen, Don via R-help <
r-help at r-project.org> wrote:

> Thanks Bert!
>
> It certainly works for the example (and shows a much deeper understanding
> of eval, substitute, etc. than I have). But it doesn't appear to generalize
> very well in the way I need (which of course I didn't think of mentioning
> until after I sent the email -- sorry).
>
> Suppose subs is any expression that would be valid for the subset argument
> of base::subset, for a given data frame. Then I can extract that subset of
> the data frame by using
>    mydf[  with(mydf, eval(subs)) ,  ]
> (or similar).
>
> Then, having plotted some aspect of that subset, I want to annotate the
> plot with the subset specifications.
>
> I've used this approach to  set up a system that helps me to interactively
> review various subsets of a large set of data. I save the final selected
> subsetting expressions in some sort of data structure, for later use in
> preparing a report using rmarkdown.
>
> I was hoping to use plotmath to improve the appearance of the annotations
> -- but I now think it's not worth this kind of effort. I think I'm going to
> settle for mtext( as.character(subs) ).
>
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Date: Monday, August 20, 2018 at 3:38 PM
> To: "MacQueen, Don" <macqueen1 at llnl.gov>
> Cc: array R-help <r-help at r-project.org>
> Subject: Re: [R] plotmath and logical operators?
>
> This is clumsy and probably subject to considerable improvement, but does
> it work for you:
>
> left <- quote(x >= 3)
> right <- quote(y <= 3) ## these can be anything
>
> ## the plot:
> plot(1)
> eval(substitute(mtext(expression(paste(left, " & ",right))), list(left =
> left, right = right)))
>
> ## Expression evaluation
> eval(substitute(with(df,left & right), list(left = left, right = right)))
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <
> r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
> I would like to use plotmath to annotate a plot with an expression that
> includes a logical operator.
>
> ## works well
> tmp <- expression(x >= 3)
> plot(1)
> mtext(tmp)
>
> ## not so well
> tmp <- expression(x >= 3 &  y <= 3)
> plot(1)
> mtext(tmp)
>
> Although the text that's displayed makes sense, it won't be obvious to my
> non-mathematical audience.
>
> I'd appreciate suggestions.
>
>
> I've found a work-around that gets the annotation to look right
>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>   plot(1)
>   mtext(tmpw)
>
>
> But it breaks my original purpose, illustrated by this example:
>
> df <- data.frame(x=1:5, y=1:5)
> tmp <- expression(x >= 3 & y <= 3)
> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
> with(df, eval(tmp))
> [1] FALSE FALSE  TRUE FALSE FALSE
> with(df, eval(tmpw))
> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE"
> "TRUE  &  FALSE"
>
> Thanks
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 21 06:10:52 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 21 Aug 2018 05:10:52 +0100
Subject: [R] Transforming data for nice output table
In-Reply-To: <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
 <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>
Message-ID: <a204d6bf-6bcc-c72a-8393-01c90e452f1d@sapo.pt>

Hello,

One of those would be with package reshape2.



dta <- read.csv( "http://doylesdartden.com/R/ExampleData.csv")

subdta <- dta[, c("Location", "Year", "GW_Elevation")]

res <- reshape2::dcast(subdta, Location ~ Year, value.var = "GW_Elevation")
names(res)[-1] <- paste("GW_Elevation", names(res)[-1], sep = "_")
head(res)


Hope this helps,

Rui Barradas

On 20/08/2018 21:37, Rui Barradas wrote:
> Hello,
> 
> This is a very frequent question.
> I could rewrite one or two answers taken from StackOverflow:
> 
> https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format 
> 
> 
> 
> But there you will have more options.
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> On 20/08/2018 20:17, David Doyle wrote:
>> Hello everyone,
>>
>> I'm trying to generate tables of my data out of R for my report.
>>
>> My data is setup in the format as follows and the example can be found 
>> at:
>> http://doylesdartden.com/R/ExampleData.csv
>>
>> Location??????? Date??????? Year????? GW_Elevation
>> 127(I)??????? 5/14/2006???? 2006?????? 752.46
>> 119(I)??????? 5/14/2006???? 2006?????? 774.67
>> 127(I)??????? 6/11/2007???? 2007?????? 752.06
>> 119(I)??????? 6/11/2007???? 2007?????? 775.57
>>
>> I would like to generate a table that showed
>>
>> Location??? GW_Elevation 2006??? GW_Elevation 2007??? GW_Elevation 
>> xxx.....
>>
>> 119(I)??????????????????? 774.67????????????????????? 775.57
>> ?????????? xxxx
>> 127(I)??????????????????? 752.46????????????????????? 752.06
>> ?????????? xxxx
>> XXXX????????????????????????? XX?????????????????????????? XX
>>
>> ? Any thoughts on how to transform the data so it would be in this 
>> format??
>>
>> Thank you for your time
>>
>> David Doyle
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 21 06:39:03 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 21 Aug 2018 05:39:03 +0100
Subject: [R] Transforming data for nice output table
In-Reply-To: <a204d6bf-6bcc-c72a-8393-01c90e452f1d@sapo.pt>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
 <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>
 <a204d6bf-6bcc-c72a-8393-01c90e452f1d@sapo.pt>
Message-ID: <faf43c86-d740-fa42-5b3a-65bb949729cb@sapo.pt>

Sorry, there is no need to subset the data frame,

reshape2::dcast(dta, etc)

will do the same.

Rui Barradas

On 21/08/2018 05:10, Rui Barradas wrote:
> Hello,
> 
> One of those would be with package reshape2.
> 
> 
> 
> dta <- read.csv( "http://doylesdartden.com/R/ExampleData.csv")
> 
> subdta <- dta[, c("Location", "Year", "GW_Elevation")]
> 
> res <- reshape2::dcast(subdta, Location ~ Year, value.var = "GW_Elevation")
> names(res)[-1] <- paste("GW_Elevation", names(res)[-1], sep = "_")
> head(res)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> On 20/08/2018 21:37, Rui Barradas wrote:
>> Hello,
>>
>> This is a very frequent question.
>> I could rewrite one or two answers taken from StackOverflow:
>>
>> https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format 
>>
>>
>>
>> But there you will have more options.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> On 20/08/2018 20:17, David Doyle wrote:
>>> Hello everyone,
>>>
>>> I'm trying to generate tables of my data out of R for my report.
>>>
>>> My data is setup in the format as follows and the example can be 
>>> found at:
>>> http://doylesdartden.com/R/ExampleData.csv
>>>
>>> Location??????? Date??????? Year????? GW_Elevation
>>> 127(I)??????? 5/14/2006???? 2006?????? 752.46
>>> 119(I)??????? 5/14/2006???? 2006?????? 774.67
>>> 127(I)??????? 6/11/2007???? 2007?????? 752.06
>>> 119(I)??????? 6/11/2007???? 2007?????? 775.57
>>>
>>> I would like to generate a table that showed
>>>
>>> Location??? GW_Elevation 2006??? GW_Elevation 2007??? GW_Elevation 
>>> xxx.....
>>>
>>> 119(I)??????????????????? 774.67????????????????????? 775.57
>>> ?????????? xxxx
>>> 127(I)??????????????????? 752.46????????????????????? 752.06
>>> ?????????? xxxx
>>> XXXX????????????????????????? XX?????????????????????????? XX
>>>
>>> ? Any thoughts on how to transform the data so it would be in this 
>>> format??
>>>
>>> Thank you for your time
>>>
>>> David Doyle
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ---
>> This email has been checked for viruses by AVG.
>> https://www.avg.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From rmh @end|ng |rom temp|e@edu  Tue Aug 21 06:39:17 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 21 Aug 2018 00:39:17 -0400
Subject: [R] plotmath and logical operators?
In-Reply-To: <CAF8bMcY057MeBdmYgnMmNv0a81YFcjyHQXgVjyRVkkzX3at9Bw@mail.gmail.com>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
 <CAGxFJbR1yHF=Zn9DtaRcQA0yKBi66oq3yw=S1W1rj77fnfN0Vw@mail.gmail.com>
 <C5078BE2-C2D8-489E-91A2-CF44C61FBF21@llnl.gov>
 <CAF8bMcY057MeBdmYgnMmNv0a81YFcjyHQXgVjyRVkkzX3at9Bw@mail.gmail.com>
Message-ID: <CAGx1TMCDX+X5ieObyNy8iecL_9nDpP2mZsOV1sgsrp-q8qR6gQ@mail.gmail.com>

## I would use microplot in this situation.
## This example produces a pdf file containing the graph.

library(lattice)
library(microplot)

## Hmisc options for pdflatex
## graphics files are .pdf
latexSetOptions()

RtoLatex <- function(subset , subset.char=substitute(subset)) {
  ## you might need some gsub calls in here
  paste0("$", subset.char, "$")
}

plotSubsetLatex <- function (data, subset, qsubset = substitute(subset),
                             ...) {
  sdata <- data[eval(qsubset, data), ]
  myplot <- xyplot( y ~ x , data=sdata)
  latex(myplot,
        ## caption=RtoLatex(subset.char=deparse(qsubset)),  ## use
either caption or colheads
        colheads=paste("\\Large \\strut",                   ##
Hmisc::latex argument
                       RtoLatex(subset.char=deparse(qsubset))),
        collapse=identity, ## collapse is an argument to microplot()
        x.axis=FALSE, y.axis=FALSE, ## x.axis, y.axis are arguments to
as.includegraphics()
        ...) ## arguments to latex() or as.includegraphics() or microplot()
  }


df <- data.frame(x=1:5, y=1:5)
myplot.tex <- plotSubsetLatex(df, x<1.5 | y>3.5, ## see title "(x <
1.5) | (y > 3.5)" and pts at x=1,4,5.
                              height.panel=3, width.panel=3, rowname=NULL)
myplot.tex$file ## pathname to tex file which contains pathname to
component pdf file
## print.default(myplot.tex) ## pathname to tex file and additional
information about component pdf files
myplot.tex ## displays generated pdf file on screen, and pathname to
generated pdf file

On Mon, Aug 20, 2018 at 10:12 PM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> A generalization of Bert's suggestion is
>
> plotSubset <- function (data, subset, qsubset = substitute(subset))
> {
>     sdata <- data[eval(qsubset, data), ]
>     with(sdata, plot(x, y, main = subsetToPlotmath(expr = qsubset)))
> }
>
>
> subsetToPlotmath <- function(expr) {
>     # Argument 'expr': an expression used as subset argument to subset()
>     # Return: an expression used by plotmath that is more readable to
> non-programming people
>     if (is.call(expr)) {
>         for(i in seq_along(expr)) {
>             expr[[i]] <- subsetToPlotmath(expr[[i]])
>         }
>         if (is.name(funcName <- expr[[1]]) && !is.null(func <-
> env.subsetToPlotmath[[as.character(funcName)]])) {
>             expr <- do.call(func, as.list(expr[-1]))
>         }
>     }
>     expr
> }
> env.subsetToPlotmath <- new.env()
> env.subsetToPlotmath[["&"]] <- function(x, y) substitute(x ~ italic(and) ~
> y)
> env.subsetToPlotmath[["|"]] <- function(x, y) substitute((x) ~ italic(or) ~
> (y)) # internal parens not always needed
> env.subsetToPlotmath[["log10"]] <- function(x)
> substitute(italic(log)[10](x))
> env.subsetToPlotmath[["exp"]] <- function(x) substitute(italic(e)^x)
>
> You can add more conversions to the environment env.subsetToPlotmath.
>
> Try it with
>
>> df <- data.frame(x=1:5, y=1:5)
>> plotSubset(df, x<1.5 | y>3.5) # see title "(x < 1.5) or (y > 3.5)" and
> pts at x=1,4,5.
>
> It doesn't get right the parentheses needed to enforce the order of
> evaluation:
> it always puts parentheses around the arguments to | and never puts them
> around the arguments to &.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Aug 20, 2018 at 4:14 PM, MacQueen, Don via R-help <
> r-help at r-project.org> wrote:
>
>> Thanks Bert!
>>
>> It certainly works for the example (and shows a much deeper understanding
>> of eval, substitute, etc. than I have). But it doesn't appear to generalize
>> very well in the way I need (which of course I didn't think of mentioning
>> until after I sent the email -- sorry).
>>
>> Suppose subs is any expression that would be valid for the subset argument
>> of base::subset, for a given data frame. Then I can extract that subset of
>> the data frame by using
>>    mydf[  with(mydf, eval(subs)) ,  ]
>> (or similar).
>>
>> Then, having plotted some aspect of that subset, I want to annotate the
>> plot with the subset specifications.
>>
>> I've used this approach to  set up a system that helps me to interactively
>> review various subsets of a large set of data. I save the final selected
>> subsetting expressions in some sort of data structure, for later use in
>> preparing a report using rmarkdown.
>>
>> I was hoping to use plotmath to improve the appearance of the annotations
>> -- but I now think it's not worth this kind of effort. I think I'm going to
>> settle for mtext( as.character(subs) ).
>>
>> -Don
>>
>> --
>> Don MacQueen
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> Lab cell 925-724-7509
>>
>>
>>
>> From: Bert Gunter <bgunter.4567 at gmail.com>
>> Date: Monday, August 20, 2018 at 3:38 PM
>> To: "MacQueen, Don" <macqueen1 at llnl.gov>
>> Cc: array R-help <r-help at r-project.org>
>> Subject: Re: [R] plotmath and logical operators?
>>
>> This is clumsy and probably subject to considerable improvement, but does
>> it work for you:
>>
>> left <- quote(x >= 3)
>> right <- quote(y <= 3) ## these can be anything
>>
>> ## the plot:
>> plot(1)
>> eval(substitute(mtext(expression(paste(left, " & ",right))), list(left =
>> left, right = right)))
>>
>> ## Expression evaluation
>> eval(substitute(with(df,left & right), list(left = left, right = right)))
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Aug 20, 2018 at 2:00 PM MacQueen, Don via R-help <
>> r-help at r-project.org<mailto:r-help at r-project.org>> wrote:
>> I would like to use plotmath to annotate a plot with an expression that
>> includes a logical operator.
>>
>> ## works well
>> tmp <- expression(x >= 3)
>> plot(1)
>> mtext(tmp)
>>
>> ## not so well
>> tmp <- expression(x >= 3 &  y <= 3)
>> plot(1)
>> mtext(tmp)
>>
>> Although the text that's displayed makes sense, it won't be obvious to my
>> non-mathematical audience.
>>
>> I'd appreciate suggestions.
>>
>>
>> I've found a work-around that gets the annotation to look right
>>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>>   plot(1)
>>   mtext(tmpw)
>>
>>
>> But it breaks my original purpose, illustrated by this example:
>>
>> df <- data.frame(x=1:5, y=1:5)
>> tmp <- expression(x >= 3 & y <= 3)
>> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>> with(df, eval(tmp))
>> [1] FALSE FALSE  TRUE FALSE FALSE
>> with(df, eval(tmpw))
>> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE"
>> "TRUE  &  FALSE"
>>
>> Thanks
>> -Don
>>
>> --
>> Don MacQueen
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> Lab cell 925-724-7509
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From g|u@epp@ce|@|u @end|ng |rom gm@||@com  Tue Aug 21 03:59:49 2018
From: g|u@epp@ce|@|u @end|ng |rom gm@||@com (Giuseppa Cefalu)
Date: Mon, 20 Aug 2018 21:59:49 -0400
Subject: [R] (no subject)
Message-ID: <CACGY-iRm=1LFYzhrKQLdrMJxiE9-hA=2wHN51e7BU9492MuNzA@mail.gmail.com>

Hello,

I have  a list of lists.  The lists in the list of lists are file names.  I
use lapply to read and merge the contents of each list in the list of lists
(3 merged contents in this case  which will be the content of 3 files).
Then, I  have to change the name of the 3 resulting files and finally I
have to write the contents of the files to each file.

 lc <- list("test.txt", "test.txt", "test.txt", "test.txt")
 lc1 <- list("test.txt", "test.txt", "test.txt")
 lc2 <- list("test.txt", "test.txt")
#list of lists.  The lists contain file names
 lc <- list(lc, lc1, lc2)
#new names for the three lists in the list of lists
 new_dataFns <- list("name1", "name2", "name3")
 file_paths <- NULL
 new_path <- NULL
#add the file names to the path and read and merge the contents of each
list in the list of lists
 lapply(
    lc,
    function(lc) {
     filenames <- file.path(dataFnsDir, lc)
     dataList= lapply(filenames, function (x) read.table(file=x,
header=TRUE))
     Reduce(function(x,y) merge(x,y), dataList)
     #   print(dataList)

    }
  )

#add the new name of the file to the path total will be 3
paths/fille_newname.tsv.
 lapply(new_path, function(new_path){new_path <- file.path(getwd(),
new_dataFns)

The statements above work because lc and  new_dataFns are global and I can
pass them to the lapply function

#Finally, I need to write the merged contents to the corresponding file
(path/name.tsv).  I tried the following statement, but this does not work.
How can I write the content to each file? I was trying to use list <-
cbind(dataList, new_path) so that afterwards I can get the merged contents
and the file_name from the list and that way write each merged content to
the corresponding file, but it seems that the dataList and the newPath are
not global and the cbind() function does not work.

	[[alternative HTML version deleted]]



From m|@ojpm @end|ng |rom gm@||@com  Tue Aug 21 10:48:54 2018
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Tue, 21 Aug 2018 16:48:54 +0800
Subject: [R] Time series analysis: Granger causality with error-correction
 term
Message-ID: <CABcx46CpZ3T8c5R965AogkKSa=hgXNNq0fefmofZ8=Ham+sgTw@mail.gmail.com>

Hi,

   Which package/function do you recommend for Granger causality between x
and y with an error correction term?

   In my problem, economic theory maintains that x~ I(1); y~I(1), x-y ~I(0)

\begin{eqnarray}
\Delta x_t = g_0 + \lambda_{x}(x_{t-1}-y_{t-1})+\sum_{k=1}^{n}g_{1k}\Delta
x_{t-s}+\sum_{k=1}^{n}g_{2k}\Delta y_{t-s}+\epsilon_{1t}  \\
\Delta y_t = g_0 + \lambda_{y}(x_{t-1}-y_{t-1})+\sum_{k=1}^{n}g_{3k}\Delta
x_{t-s}+\sum_{k=1}^{n}g_{4k}\Delta y_{t-s}+\epsilon_{2t}
\end{eqnarray}

   I am not sure if it would work if I run Granger causality between \Delta
x and \Delta y, treating the error correction term (x_{t-1}-y_{t-1}) and
exogenous variable.

   Thank you very much!!

John

	[[alternative HTML version deleted]]



From ggrothend|eck @end|ng |rom gm@||@com  Tue Aug 21 14:53:15 2018
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Tue, 21 Aug 2018 08:53:15 -0400
Subject: [R] plotmath and logical operators?
In-Reply-To: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
References: <8CEE053E-FB13-4195-BFA4-DD2FEA566CEC@llnl.gov>
Message-ID: <CAP01uRmJ3Bq2J_xOst=-RD9qv0K9yw=CAuc3_djS445vLA+32g@mail.gmail.com>

Try this:

plot(1)
tmp <- x >= 3 ~ "&" ~ y <= 3
mtext(tmp)
On Mon, Aug 20, 2018 at 5:00 PM MacQueen, Don via R-help
<r-help at r-project.org> wrote:
>
> I would like to use plotmath to annotate a plot with an expression that includes a logical operator.
>
> ## works well
> tmp <- expression(x >= 3)
> plot(1)
> mtext(tmp)
>
> ## not so well
> tmp <- expression(x >= 3 &  y <= 3)
> plot(1)
> mtext(tmp)?
>
> Although the text that's displayed makes sense, it won't be obvious to my non-mathematical audience.
>
> I'd appreciate suggestions.
>
>
> I've found a work-around that gets the annotation to look right
>   tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
>   plot(1)
>   mtext(tmpw)
>
>
> But it breaks my original purpose, illustrated by this example:
>
> df <- data.frame(x=1:5, y=1:5)
> tmp <- expression(x >= 3 & y <= 3)
> tmpw <- expression(paste( x >= 3, " & ", y <= 3) )
> with(df, eval(tmp))
> [1] FALSE FALSE  TRUE FALSE FALSE
> with(df, eval(tmpw))
> [1] "FALSE  &  TRUE" "FALSE  &  TRUE" "TRUE  &  TRUE"  "TRUE  &  FALSE" "TRUE  &  FALSE"
>
> Thanks
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From jun@y@n @end|ng |rom uconn@edu  Tue Aug 21 12:39:46 2018
From: jun@y@n @end|ng |rom uconn@edu (Yan, Jun)
Date: Tue, 21 Aug 2018 10:39:46 +0000
Subject: [R] Seeking nomination for the Statistical Computing and Graphics
 Award
Message-ID: <BL0PR05MB46271C19AF334BD2D354F709F0310@BL0PR05MB4627.namprd05.prod.outlook.com>

(apologies for cross posting)

The Statistical Computing and Graphics Award of the?ASA Sections of Statistical Computing and Statistical Graphics?recognizes an individual or team for innovation in computing, software, or graphics that has had a great impact on statistical practice or research. The past awardees include Bill Cleveland (2016) and Robert Gentleman and Ross Ihaka (2010). The prize carries with it a cash award of $5,000 plus an allowance of up to $1,000 for travel to the next Joint Statistical Meetings (JSM) where the award will be presented.

Qualifications
The prize-winning contribution will have had significant and lasting impacts on statistical computing, software or graphics.

The Awards Committee depends on the American Statistical Association membership to submit nominations. Committee members will review the nominations and make the final determination of who, if any, should receive the award. The award may not be given to a sitting member of the Awards Committee or a sitting member of the Executive Committee of the Section of Statistical Computing or the Section of Statistical Graphics.

Nomination and Award Dates
Nominations are due by November 15, 2018 for an award to?be presented at the JSM in the following year. Nominations should be submitted as a complete packet, consisting of:
- a?nomination letter, no longer than four pages, addressing points in the selection criteria
- nominee's curriculum?vita(e)
- a minimum of 3 (and no more than 4) supporting letters, each no longer than two pages

Selection Process
The Awards Committee will consist of the Chairs and Past Chairs of the Sections on Statistical Computing and Statistical Graphics. The selection process will be handled by the Awards Chair of the Statistical Computing Section and the Statistical Graphics Section. Nominations and questions are to be sent to the e-mail address below.

Jun Yan
Professor
University of Connecticut
jun.yan at uconn.edu



 
???


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Aug 21 17:48:29 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 21 Aug 2018 11:48:29 -0400
Subject: [R] R Codes for Introduction to Data Mining
Message-ID: <CAE9stmfAyfg=_43JZdjfmdnATK3SSUgEdZ_XeN7FQRfmg9hEjA@mail.gmail.com>

Dear All: good morning


I am going to teach a course title "Introduction to Statistical Data
Mining", and I am using the book titled "*Introduction to Data Mining
(Second Edition)*"  by Kumar and etal.

I am wondering if someone have R codes/functions for examples and exercises
given in this textbook.

I thank you all in advance.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Tue Aug 21 18:07:08 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Tue, 21 Aug 2018 16:07:08 +0000
Subject: [R] R Codes for Introduction to Data Mining
In-Reply-To: <CAE9stmfAyfg=_43JZdjfmdnATK3SSUgEdZ_XeN7FQRfmg9hEjA@mail.gmail.com>
References: <CAE9stmfAyfg=_43JZdjfmdnATK3SSUgEdZ_XeN7FQRfmg9hEjA@mail.gmail.com>
Message-ID: <eef2e28c99a146f5b6f8e19875d4545a@tamu.edu>

There are some materials at

https://www-users.cs.umn.edu/~kumar001/dmbook/index.php

Michael Hahsler has code examples at 

https://mhahsler.github.io/Introduction_to_Data_Mining_R_Examples/
https://github.com/mhahsler/Introduction_to_Data_Mining_R_Examples


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of AbouEl-Makarim Aboueissa
Sent: Tuesday, August 21, 2018 10:48 AM
To: R mailing list <r-help at r-project.org>
Subject: [R] R Codes for Introduction to Data Mining

Dear All: good morning


I am going to teach a course title "Introduction to Statistical Data
Mining", and I am using the book titled "*Introduction to Data Mining
(Second Edition)*"  by Kumar and etal.

I am wondering if someone have R codes/functions for examples and exercises
given in this textbook.

I thank you all in advance.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dc@r|@on @end|ng |rom t@mu@edu  Tue Aug 21 18:19:39 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Tue, 21 Aug 2018 16:19:39 +0000
Subject: [R] Transforming data for nice output table
In-Reply-To: <faf43c86-d740-fa42-5b3a-65bb949729cb@sapo.pt>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
 <3f3bce47-9816-c514-0c0b-da1cbfe366b6@sapo.pt>
 <a204d6bf-6bcc-c72a-8393-01c90e452f1d@sapo.pt>
 <faf43c86-d740-fa42-5b3a-65bb949729cb@sapo.pt>
Message-ID: <1f276ca2db634df0b1dc57f3c6c0ab23@tamu.edu>

Another approach to adding GW_Elevation to the year value, but the table is more compact with just the year.

dta <- read.csv("http://doylesdartden.com/R/ExampleData.csv")
Years <- paste("GW_Elevation", dta$Year)
xtabs(GW_Elevation~Location+Years, dta)


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Monday, August 20, 2018 11:39 PM
To: David Doyle <kydaviddoyle at gmail.com>; r-help at r-project.org
Subject: Re: [R] Transforming data for nice output table

Sorry, there is no need to subset the data frame,

reshape2::dcast(dta, etc)

will do the same.

Rui Barradas

On 21/08/2018 05:10, Rui Barradas wrote:
> Hello,
> 
> One of those would be with package reshape2.
> 
> 
> 
> dta <- read.csv( "http://doylesdartden.com/R/ExampleData.csv")
> 
> subdta <- dta[, c("Location", "Year", "GW_Elevation")]
> 
> res <- reshape2::dcast(subdta, Location ~ Year, value.var = "GW_Elevation")
> names(res)[-1] <- paste("GW_Elevation", names(res)[-1], sep = "_")
> head(res)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> On 20/08/2018 21:37, Rui Barradas wrote:
>> Hello,
>>
>> This is a very frequent question.
>> I could rewrite one or two answers taken from StackOverflow:
>>
>> https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format 
>>
>>
>>
>> But there you will have more options.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> On 20/08/2018 20:17, David Doyle wrote:
>>> Hello everyone,
>>>
>>> I'm trying to generate tables of my data out of R for my report.
>>>
>>> My data is setup in the format as follows and the example can be 
>>> found at:
>>> http://doylesdartden.com/R/ExampleData.csv
>>>
>>> Location??????? Date??????? Year????? GW_Elevation
>>> 127(I)??????? 5/14/2006???? 2006?????? 752.46
>>> 119(I)??????? 5/14/2006???? 2006?????? 774.67
>>> 127(I)??????? 6/11/2007???? 2007?????? 752.06
>>> 119(I)??????? 6/11/2007???? 2007?????? 775.57
>>>
>>> I would like to generate a table that showed
>>>
>>> Location??? GW_Elevation 2006??? GW_Elevation 2007??? GW_Elevation 
>>> xxx.....
>>>
>>> 119(I)??????????????????? 774.67????????????????????? 775.57
>>> ?????????? xxxx
>>> 127(I)??????????????????? 752.46????????????????????? 752.06
>>> ?????????? xxxx
>>> XXXX????????????????????????? XX?????????????????????????? XX
>>>
>>> ? Any thoughts on how to transform the data so it would be in this 
>>> format??
>>>
>>> Thank you for your time
>>>
>>> David Doyle
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ---
>> This email has been checked for viruses by AVG.
>> https://www.avg.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Aug 21 18:20:48 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 21 Aug 2018 12:20:48 -0400
Subject: [R] R Codes for Introduction to Data Mining
In-Reply-To: <eef2e28c99a146f5b6f8e19875d4545a@tamu.edu>
References: <CAE9stmfAyfg=_43JZdjfmdnATK3SSUgEdZ_XeN7FQRfmg9hEjA@mail.gmail.com>
 <eef2e28c99a146f5b6f8e19875d4545a@tamu.edu>
Message-ID: <CAE9stmdShN7haBF3Fq4PFzuZ+GYNMEvmX3HKOuGxzXqK6TY8_w@mail.gmail.com>

Dear David:

Thank you very much

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Tue, Aug 21, 2018 at 12:07 PM David L Carlson <dcarlson at tamu.edu> wrote:

> There are some materials at
>
> https://www-users.cs.umn.edu/~kumar001/dmbook/index.php
>
> Michael Hahsler has code examples at
>
> https://mhahsler.github.io/Introduction_to_Data_Mining_R_Examples/
> https://github.com/mhahsler/Introduction_to_Data_Mining_R_Examples
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> AbouEl-Makarim Aboueissa
> Sent: Tuesday, August 21, 2018 10:48 AM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] R Codes for Introduction to Data Mining
>
> Dear All: good morning
>
>
> I am going to teach a course title "Introduction to Statistical Data
> Mining", and I am using the book titled "*Introduction to Data Mining
> (Second Edition)*"  by Kumar and etal.
>
> I am wondering if someone have R codes/functions for examples and exercises
> given in this textbook.
>
> I thank you all in advance.
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From p@u|john32 @end|ng |rom gm@||@com  Wed Aug 22 00:13:52 2018
From: p@u|john32 @end|ng |rom gm@||@com (Paul Johnson)
Date: Tue, 21 Aug 2018 17:13:52 -0500
Subject: [R] Transforming data for nice output table
In-Reply-To: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
References: <CACftpvpXBHTmW62nhHw+LQHnAj884xmY_PgCz7zz3nQ--0y+1w@mail.gmail.com>
Message-ID: <CAErODj83TV6Ux0NT129=ONn72BPR0Q1CkUm81foPgFvVUu9f5A@mail.gmail.com>

On Mon, Aug 20, 2018 at 2:17 PM David Doyle <kydaviddoyle at gmail.com> wrote:
>
> Hello everyone,
>
> I'm trying to generate tables of my data out of R for my report.
>
> My data is setup in the format as follows and the example can be found at:
> http://doylesdartden.com/R/ExampleData.csv
>
> Location        Date        Year      GW_Elevation
> 127(I)        5/14/2006     2006       752.46
> 119(I)        5/14/2006     2006       774.67
> 127(I)        6/11/2007     2007       752.06
> 119(I)        6/11/2007     2007       775.57
>
> I would like to generate a table that showed
>
> Location    GW_Elevation 2006    GW_Elevation 2007    GW_Elevation xxx.....
>
> 119(I)                    774.67                      775.57
>           xxxx
> 127(I)                    752.46                      752.06
>           xxxx
> XXXX                          XX                           XX
>
>  Any thoughts on how to transform the data so it would be in this format??
>
> Thank you for your time
>
> David Doyle

Dear David

I'd consider studying R's reshape function, it was intended exactly
for this purpose. No reason to adventure into any user-contributed
tidy places to get this done.

dta <- read.csv("http://doylesdartden.com/R/ExampleData.csv")
dta <- dta[c("Location", "Year", "GW_Elevation")]
dta.wide <- reshape(dta, direction = "wide", idvar = "Location",
v.names = "GW_Elevation", timevar = "Year")
head(dta.wide)

  Location GW_Elevation.2006 GW_Elevation.2007 GW_Elevation.2008
1   127(I)            752.46                NA            757.50
2   119(S)            774.67            778.76            776.40
3   132(I)            759.45            761.68            764.27
4   132(S)            761.77            761.04            765.44
5   111(I)            753.52            763.24            764.24
6   111(S)            766.18            772.84            767.41
  GW_Elevation.2009 GW_Elevation.2010 GW_Elevation.2011 GW_Elevation.2012
1            759.90            756.40            759.05            759.31
2            777.59            777.45            778.21            778.13
3            761.90            764.03            763.63            763.99
4            761.21            763.12            762.69            759.57
5            750.85            764.37            762.99            763.90
6            769.77            767.88            767.95            767.19
  GW_Elevation.2013 GW_Elevation.2014 GW_Elevation.2015 GW_Elevation.2016
1            756.07            756.66            757.72            757.66
2            778.88            778.28            775.16            778.28
3            761.22            762.81            762.36            764.46
4            763.19            763.87            761.94            763.90
5            764.42            761.65            764.02            762.93
6            770.20            767.25            767.74            766.87

The main difference between this and your stated target is that your
target column names have spaces in them, which are forbidden in
column names of data frames. Here R used a period for joining strings.
You can override
that if you want to with the reshape function, but usually I'd let the periods
happen.

If you do want to replace period with spaces, it can be done, but you
break the warranty
on other uses of a data frame. (Could get rid of underscore after GW
in same way)

colnames(dta.wide) <- sub("Elevation.", "Elevation ",
colnames(dta.wide), fixed = TRUE)

I'd not try to use that wide frame for many other purposes because of
the spaces, but it works well if you want to make a pleasant table out
of it. For example, xtable is my favorite:

library(xtable)

xt <- xtable(dta.wide)
print(xt)

The latex from that prints out beautifully in a document. The print
method for xtable has a file parameter if you want to save the file.

Good Luck

pj



>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.



From p@u|john32 @end|ng |rom gm@||@com  Wed Aug 22 00:45:33 2018
From: p@u|john32 @end|ng |rom gm@||@com (Paul Johnson)
Date: Tue, 21 Aug 2018 17:45:33 -0500
Subject: [R] looking for formula parser that allows coefficients
Message-ID: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>

Can you point me at any packages that allow users to write a
formula with coefficients?

I want to write a data simulator that has a matrix X with lots
of columns, and then users can generate predictive models
by entering a formula that uses some of the variables, allowing
interactions, like

y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2

Currently, in the rockchalk package, I have a function simulates
data (genCorrelatedData2), but my interface to enter the beta
coefficients is poor.  I assumed user would always enter 0's as
place holder for the unused coefficients, and the intercept is
always first. The unnamed vector is too confusing.  I have them specify:

c(2, 1.1, 0, 3, 0, 0, 0.2, ...)

I the documentation I say (ridiculously) it is easy to figure out from
the examples, but it really isnt.
It function prints out the equation it thinks you intended, thats
minimum protection against user error, but still not very good:

dat <- genCorrelatedData2(N = 10, rho = 0.0,
          beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
          means = c(0,0,0), sds = c(1,1,1), stde = 0)
[1] "The equation that was calculated was"
y = 1 + 2*x1 + 1*x2 + 1*x3
 + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
 + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
 + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
 + N(0,0) random error

But still, it is not very good.

As I look at this now, I realize expect just the vech, not the whole vector
of all interaction terms, so it is even more difficult than I thought to get the
correct input.Hence, I'd like to let the user write a formula.

The alternative for the user interface is to have named coefficients.
I can more or less easily allow a named vector for beta

beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)

I could build a formula from that.  That's not too bad. But I still think
it would be cool to allow formula input.

Have you ever seen it done?
pj
-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.



From j|ox @end|ng |rom mcm@@ter@c@  Wed Aug 22 01:42:04 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 21 Aug 2018 23:42:04 +0000
Subject: [R] looking for formula parser that allows coefficients
In-Reply-To: <21802_1534891556_w7LMjuVa021775_CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
References: <21802_1534891556_w7LMjuVa021775_CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368957C3@FHSDB2D11-2.csu.mcmaster.ca>

Dear Paul,

Is it possible that you're overthinking this? That is, to you really need an R model formula or just want to evaluate an arithmetic expression using the columns of X?

If the latter, the following approach may work for you:

> evalFormula <- function(X, expr){
+   if (is.null(colnames(X))) colnames(X) <- paste0("x", 1:ncol(X))
+   with(as.data.frame(X), eval(parse(text=expr)))
+ }

> X <- matrix(1:20, 5, 4)
> X
     [,1] [,2] [,3] [,4]
[1,]    1    6   11   16
[2,]    2    7   12   17
[3,]    3    8   13   18
[4,]    4    9   14   19
[5,]    5   10   15   20

> evalFormula(X, '2 + 3*x1 + 4*x2 + 5*x3 + 6*x1*x2')
[1] 120 180 252 336 432

I hope that this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Johnson
> Sent: Tuesday, August 21, 2018 6:46 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] looking for formula parser that allows coefficients
> 
> Can you point me at any packages that allow users to write a formula with
> coefficients?
> 
> I want to write a data simulator that has a matrix X with lots of columns, and
> then users can generate predictive models by entering a formula that uses
> some of the variables, allowing interactions, like
> 
> y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2
> 
> Currently, in the rockchalk package, I have a function simulates data
> (genCorrelatedData2), but my interface to enter the beta coefficients is poor.
> I assumed user would always enter 0's as place holder for the unused
> coefficients, and the intercept is always first. The unnamed vector is too
> confusing.  I have them specify:
> 
> c(2, 1.1, 0, 3, 0, 0, 0.2, ...)
> 
> I the documentation I say (ridiculously) it is easy to figure out from the
> examples, but it really isnt.
> It function prints out the equation it thinks you intended, thats minimum
> protection against user error, but still not very good:
> 
> dat <- genCorrelatedData2(N = 10, rho = 0.0,
>           beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
>           means = c(0,0,0), sds = c(1,1,1), stde = 0) [1] "The equation that was
> calculated was"
> y = 1 + 2*x1 + 1*x2 + 1*x3
>  + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
>  + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
>  + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
>  + N(0,0) random error
> 
> But still, it is not very good.
> 
> As I look at this now, I realize expect just the vech, not the whole vector of all
> interaction terms, so it is even more difficult than I thought to get the correct
> input.Hence, I'd like to let the user write a formula.
> 
> The alternative for the user interface is to have named coefficients.
> I can more or less easily allow a named vector for beta
> 
> beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)
> 
> I could build a formula from that.  That's not too bad. But I still think it would
> be cool to allow formula input.
> 
> Have you ever seen it done?
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> 
> To write to me directly, please address me at pauljohn at ku.edu.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From j@eb@@t|@nte||o @end|ng |rom |cocommerc|@|@co@uk  Wed Aug 22 00:43:43 2018
From: j@eb@@t|@nte||o @end|ng |rom |cocommerc|@|@co@uk (jsebastiantello)
Date: Tue, 21 Aug 2018 22:43:43 +0000
Subject: [R] (no subject)
Message-ID: <9EF8D729-E01C-4558-B010-86FE6149DED6@icocommercial.co.uk>

hi R     https://goo.gl/G8X41r



From er|nm@hodge@@ @end|ng |rom gm@||@com  Wed Aug 22 03:03:24 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Tue, 21 Aug 2018 19:03:24 -0600
Subject: [R] as.Date() function
In-Reply-To: <2071249222.638416.1534896885296@mail.yahoo.com>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
 <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>
 <20180819201627.Horde.q2d4uhEE8_2mg8Bn_ouZiwV@webmail.philipsmith.ca>
 <2071249222.638416.1534896885296@mail.yahoo.com>
Message-ID: <CACxE24muNKTz4Q4j7cMq7A6wqHORNp291gp=g6h-ooxciF_eSw@mail.gmail.com>

Nice one!


On Tue, Aug 21, 2018 at 6:14 PM John Kane <jrkrideau at yahoo.ca> wrote:

> You loaded "lubridate" so using Erin's approach
>
> library(lubridate)
> st <- c("1961-01","1961-04","1983-02")
> dat1 <- ymd(paste( st, "01",  sep ="-"))
>
>
> On Monday, August 20, 2018, 1:15:56 a.m. EDT, <
> philipsm at cpanel1.stormweb.net> wrote:
>
>
> Thanks Erin and Jim. You have indeed solved my problem.
>
> Philip
>
>
> Quoting Erin Hodgess <erinm.hodgess at gmail.com>:
>
> > Hi Philip:
> >
> > Here is something to consider:
> >
> >> #potential solution:
> >> sta <- paste(st,"-01",sep="")
> >> st1 <- as.Date(sta, format=("%Y-%m-%d"))
> >> print(st1)
> > [1] "1961-01-01" "1961-04-01" "1983-02-01"
> >
> >
> > Hope this helps!
> > Erin
> >
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >
> > On Sun, Aug 19, 2018 at 3:25 PM <philipsm at cpanel1.stormweb.net> wrote:
> >
> >> I am having trouble with what must be a very simple problem. Here is a
> >> reproducible example:
> >>
> >> library(lubridate)
> >> st <- c("1961-01","1961-04","1983-02")
> >> print(st)
> >> #[1] "1961-01" "1961-04" "1983-02"
> >> st1 <- as.Date(st, format=("%Y-%m"))
> >> print(st1)
> >> #[1] NA NA NA
> >>
> >> Why the heck am I getting three NAs instead of three Dates?I have
> >> studied the R documentation for as.Date() and it has not turned on the
> >> light bulb for me.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Aug 22 03:44:00 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Tue, 21 Aug 2018 20:44:00 -0500
Subject: [R] How to manually color specific bars
Message-ID: <000401d439b9$9a0467e0$ce0d37a0$@sbcglobal.net>

R-Help Forum

 

While the following code works fine I need to change (highlight) specific
"bars" within plot 2 (p2). For example I want the bars to be  (lets say)
red, on  1 Aug 2016 and 1 Aug 2017 . What do I need to do?

 

library(ggplot2)

library(reshape2)

library(scales)

library(egg)

#data <- dataset

data <- read.csv("~/R/Data_Files/AreaPlotData.csv", stringsAsFactors=FALSE)

data$Serial <- seq.int(nrow(data))

data$min <- pmin(data$Melbourne,data$Sydney)

data <- melt(data, id.vars=c("Serial","min","Timeline"), value.name="Price")

data$Timeline <- as.Date(data$Timeline, format="%m/%d/%Y")

p1 <- ggplot(data, aes(x = Timeline, y = Price)) +

  geom_line(aes(col = variable)) + geom_ribbon(aes(ymin = min, ymax = Price,
fill = variable), alpha = 0.3) + 

  scale_color_manual(values = c("#144A90","#D81F26")) + 

  scale_fill_manual(values = c("#F7A396","#88CADD")) + 

  theme_get() + theme(legend.position="top", legend.title=element_blank()) +

  scale_x_date(labels=date_format("%b%y"))

 

data2 <- read.csv("~/R/Data_Files/AreaPlotData2.csv",
stringsAsFactors=FALSE)

data2$Timeline <- as.Date(data2$Timeline, format="%m/%d/%Y")

p2 <- ggplot(data2, aes(x = Timeline, y=Port)) + 

  geom_bar(stat = "identity", width = 0.1, color = "blue") +

  scale_y_continuous(name="Port Holdings", limits=c(0, 40))

 

ggarrange(p1, p2, heights = c(2, 0.6),ncol = 1, nrow = 2)

 

Jeff


	[[alternative HTML version deleted]]



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Aug 22 04:23:06 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Tue, 21 Aug 2018 21:23:06 -0500
Subject: [R] How to manually color specific bars
In-Reply-To: <000401d439b9$9a0467e0$ce0d37a0$@sbcglobal.net>
References: <000401d439b9$9a0467e0$ce0d37a0$@sbcglobal.net>
Message-ID: <000d01d439bf$10a2aba0$31e802e0$@sbcglobal.net>

Please disregard I simply added a highlight variable and added
  
	scale_fill_manual(values = c("Yes"="red", "No"="grey")) 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
Sent: Tuesday, August 21, 2018 8:44 PM
To: r-help at r-project.org
Subject: [R] How to manually color specific bars

R-Help Forum

While the following code works fine I need to change (highlight) specific
"bars" within plot 2 (p2). For example I want the bars to be  (lets say)
red, on  1 Aug 2016 and 1 Aug 2017 . What do I need to do?

library(ggplot2)
library(reshape2)
library(scales)
library(egg)
#data <- dataset
data <- read.csv("~/R/Data_Files/AreaPlotData.csv", stringsAsFactors=FALSE)
data$Serial <- seq.int(nrow(data))
data$min <- pmin(data$Melbourne,data$Sydney)
data <- melt(data, id.vars=c("Serial","min","Timeline"), value.name="Price")
data$Timeline <- as.Date(data$Timeline, format="%m/%d/%Y")
p1 <- ggplot(data, aes(x = Timeline, y = Price)) +
  geom_line(aes(col = variable)) + geom_ribbon(aes(ymin = min, ymax = Price,
fill = variable), alpha = 0.3) + 
  scale_color_manual(values = c("#144A90","#D81F26")) + 
  scale_fill_manual(values = c("#F7A396","#88CADD")) + 
  theme_get() + theme(legend.position="top", legend.title=element_blank()) +
  scale_x_date(labels=date_format("%b%y"))

data2 <- read.csv("~/R/Data_Files/AreaPlotData2.csv",
stringsAsFactors=FALSE)
data2$Timeline <- as.Date(data2$Timeline, format="%m/%d/%Y")
p2 <- ggplot(data2, aes(x = Timeline, y=Port)) + 
  geom_bar(stat = "identity", width = 0.1, color = "blue") +
  scale_y_continuous(name="Port Holdings", limits=c(0, 40))

ggarrange(p1, p2, heights = c(2, 0.6),ncol = 1, nrow = 2)

Jeff


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkr|de@u @end|ng |rom y@hoo@c@  Wed Aug 22 02:14:45 2018
From: jrkr|de@u @end|ng |rom y@hoo@c@ (John Kane)
Date: Wed, 22 Aug 2018 00:14:45 +0000 (UTC)
Subject: [R] as.Date() function
In-Reply-To: <20180819201627.Horde.q2d4uhEE8_2mg8Bn_ouZiwV@webmail.philipsmith.ca>
References: <20180819172029.Horde.RA8533Ax9gJKO58sYgGFIz9@webmail.philipsmith.ca>
 <CACxE24kAdFK1xp-5qRn4jojUzTb=_R199JsnjPBekYs268fzvw@mail.gmail.com>
 <20180819201627.Horde.q2d4uhEE8_2mg8Bn_ouZiwV@webmail.philipsmith.ca>
Message-ID: <2071249222.638416.1534896885296@mail.yahoo.com>

You loaded "lubridate" so using Erin's approach 

library(lubridate)
st <- c("1961-01","1961-04","1983-02")
dat1 <- ymd(paste( st, "01",? sep ="-"))
 

    On Monday, August 20, 2018, 1:15:56 a.m. EDT, <philipsm at cpanel1.stormweb.net> wrote:  
 
 Thanks Erin and Jim. You have indeed solved my problem.

Philip


Quoting Erin Hodgess <erinm.hodgess at gmail.com>:

> Hi Philip:
>
> Here is something to consider:
>
>> #potential solution:
>> sta <- paste(st,"-01",sep="")
>> st1 <- as.Date(sta, format=("%Y-%m-%d"))
>> print(st1)
> [1] "1961-01-01" "1961-04-01" "1983-02-01"
>
>
> Hope this helps!
> Erin
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>
> On Sun, Aug 19, 2018 at 3:25 PM <philipsm at cpanel1.stormweb.net> wrote:
>
>> I am having trouble with what must be a very simple problem. Here is a
>> reproducible example:
>>
>> library(lubridate)
>> st <- c("1961-01","1961-04","1983-02")
>> print(st)
>> #[1] "1961-01" "1961-04" "1983-02"
>> st1 <- as.Date(st, format=("%Y-%m"))
>> print(st1)
>> #[1] NA NA NA
>>
>> Why the heck am I getting three NAs instead of three Dates?I have
>> studied the R documentation for as.Date() and it has not turned on the
>> light bulb for me.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]



From ggrothend|eck @end|ng |rom gm@||@com  Wed Aug 22 09:33:53 2018
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Wed, 22 Aug 2018 03:33:53 -0400
Subject: [R] looking for formula parser that allows coefficients
In-Reply-To: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
References: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
Message-ID: <CAP01uRm41Zy-UamFBYshbdRjA9XwnwafQHszYEbH0FjDjE4xCw@mail.gmail.com>

Some string manipulation can convert the formula to a named vector such as
the one shown at the end of your post.

library(gsubfn)

# input
fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2

pat <- "([+-])? *(\\d\\S*)? *\\*? *([[:alpha:]]\\S*)?"
ch <- format(fo[[3]])
m <- matrix(strapplyc(ch, pat)[[1]], 3)
m <- m[, colSums(m != "") > 0]
m[2, m[2, ] == ""] <- 1
m[3, m[3, ] == ""] <- "(Intercept)"
co <- as.numeric(paste0(m[1, ], m[2, ]))
v <- m[3, ]
setNames(co, v)
## (Intercept)          x1          x3       x1:x3       x2:x2
##         2.0        -1.1         1.0        -1.0         0.2
On Tue, Aug 21, 2018 at 6:46 PM Paul Johnson <pauljohn32 at gmail.com> wrote:
>
> Can you point me at any packages that allow users to write a
> formula with coefficients?
>
> I want to write a data simulator that has a matrix X with lots
> of columns, and then users can generate predictive models
> by entering a formula that uses some of the variables, allowing
> interactions, like
>
> y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2
>
> Currently, in the rockchalk package, I have a function simulates
> data (genCorrelatedData2), but my interface to enter the beta
> coefficients is poor.  I assumed user would always enter 0's as
> place holder for the unused coefficients, and the intercept is
> always first. The unnamed vector is too confusing.  I have them specify:
>
> c(2, 1.1, 0, 3, 0, 0, 0.2, ...)
>
> I the documentation I say (ridiculously) it is easy to figure out from
> the examples, but it really isnt.
> It function prints out the equation it thinks you intended, thats
> minimum protection against user error, but still not very good:
>
> dat <- genCorrelatedData2(N = 10, rho = 0.0,
>           beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
>           means = c(0,0,0), sds = c(1,1,1), stde = 0)
> [1] "The equation that was calculated was"
> y = 1 + 2*x1 + 1*x2 + 1*x3
>  + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
>  + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
>  + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
>  + N(0,0) random error
>
> But still, it is not very good.
>
> As I look at this now, I realize expect just the vech, not the whole vector
> of all interaction terms, so it is even more difficult than I thought to get the
> correct input.Hence, I'd like to let the user write a formula.
>
> The alternative for the user interface is to have named coefficients.
> I can more or less easily allow a named vector for beta
>
> beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)
>
> I could build a formula from that.  That's not too bad. But I still think
> it would be cool to allow formula input.
>
> Have you ever seen it done?
> pj
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From c@|@ndr@ @end|ng |rom rgzm@de  Wed Aug 22 16:33:53 2018
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 22 Aug 2018 16:33:53 +0200
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
Message-ID: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>

Dear useRs,

I have just noticed that when input is only NA with na.rm=TRUE, mean() 
results in NaN, whereas median() and sd() produce NA. Shouldn't it all 
be the same? I think NA makes more sense than NaN in that case.

x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1] 
NAsd(x, na.rm=TRUE) [1] NA

Thanks for any feedback.

Best,
Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 22 16:47:44 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Aug 2018 07:47:44 -0700
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
Message-ID: <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>

Actually, the dissonance is a bit more basic.

After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
what you see is actually:

> z <- numeric(0)
> mean(z)
[1] NaN
> median(z)
[1] NA
> sd(z)
[1] NA
> sum(z)
[1] 0
etc.

I imagine that there may be more of these little inconsistencies due to the
organic way R evolved over time. What the conventions should be  can be
purely a matter of personal opinion in the absence of accepted standards.
But I would look to see what accepted standards were, if any, first.

-- Bert


On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:

> Dear useRs,
>
> I have just noticed that when input is only NA with na.rm=TRUE, mean()
> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
> be the same? I think NA makes more sense than NaN in that case.
>
> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
> NAsd(x, na.rm=TRUE) [1] NA
>
> Thanks for any feedback.
>
> Best,
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Aug 22 16:47:55 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 22 Aug 2018 10:47:55 -0400
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
Message-ID: <16dd1b74-983e-7617-17ef-0567d3b6cf66@gmail.com>

On 22/08/2018 10:33 AM, Ivan Calandra wrote:
> Dear useRs,
> 
> I have just noticed that when input is only NA with na.rm=TRUE, mean()
> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
> be the same? I think NA makes more sense than NaN in that case.

The mean can be defined as sum(x)/length(x), so if x is length 0, you 
get 0/0 which is NaN.

median(x) is documented in its help page to give NA for x of length 0.

sd(x) is documented to give an error for such x and NA for length 1, but 
it gives NA for both.

Duncan Murdoch
> 
> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
> NAsd(x, na.rm=TRUE) [1] NA
> 
> Thanks for any feedback.
> 
> Best,
> Ivan
>



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 22 16:55:29 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Aug 2018 07:55:29 -0700
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
Message-ID: <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>

... And FWIW (not much, I agree), note that if z = numeric(0) and sum(z) =
0, then mean(z) = NaN makes sense, as length(z) = 0, so dividing by 0 gives
NaN. So you can see the sorts of issues you may need to consider.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 22, 2018 at 7:47 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Actually, the dissonance is a bit more basic.
>
> After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
> what you see is actually:
>
> > z <- numeric(0)
> > mean(z)
> [1] NaN
> > median(z)
> [1] NA
> > sd(z)
> [1] NA
> > sum(z)
> [1] 0
> etc.
>
> I imagine that there may be more of these little inconsistencies due to
> the organic way R evolved over time. What the conventions should be  can be
> purely a matter of personal opinion in the absence of accepted standards.
> But I would look to see what accepted standards were, if any, first.
>
> -- Bert
>
>
> On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:
>
>> Dear useRs,
>>
>> I have just noticed that when input is only NA with na.rm=TRUE, mean()
>> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
>> be the same? I think NA makes more sense than NaN in that case.
>>
>> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
>> NAsd(x, na.rm=TRUE) [1] NA
>>
>> Thanks for any feedback.
>>
>> Best,
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Aug 22 17:02:13 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 08:02:13 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
Message-ID: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>

   I've not before created bar charts, only scatter plots and box plots.
Checking in Deepayan's book, searching the web, and looking at ?barchart has
not shown me the how to get the results I need.

   The dataframe looks like this:
> head(stage_heights)
   Year   Med   Max
1 1989 91.17 93.32
2 1990 91.22 93.43
3 1991 91.24 92.89
4 1993 91.14 93.02
5 1994 93.92 95.74
6 1995 94.34 96.85

   I want to show Med and Max heights for each Year with each bar having a
different color (or pattern) and a single x-axis year label.

   Trying to follow the example in ?barchart for a single variable produced this:

> barchart('Year' ~ 'Med', data=stage_height, panel=lattice.getOption('panel.barchart'), default.prepanel=lattice.getOption('prepanel.default.barchart'),box.ratio=2)
Error in eval(substitute(groups), data, environment(formula)) :
   invalid 'envir' argument of type 'closure'
and no plot was displayed.

   I must be missing the obvious and want a pointer to descriptions that
teach me how to produce bar charts.

Rich



From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Aug 22 17:02:59 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 22 Aug 2018 16:02:59 +0100
Subject: [R] Monte Carlo on simple regression
Message-ID: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>

Kind R-users,
I run a simple regression. I am interested in using the Monte Carlo to test
the slope parameter.
Here is what I have done:
d1<-read.table("Lightcor",col.names=c("a"))
d2<-read.table("CRcor",col.names=c("a"))
 Li<-d1$a
CR<-d2$a

 fit<-lm(Li~CR)
 a<-summary(fit)
a gives the slope as 88.15

Problem: I now what to repeat the samples to access this coefficient.
Following one of the related examples I got online, I did (tried to modify):

N <- nrow(Li) # returns the number of observations in the dataset
C <- 50         # desired number of subsamples
S <- 38         # desired sample size

sumb2 <- 0
for (i in 1:C){   # a loop over the number of subsamples
  set.seed(3*i)   # a different seed for each subsample
  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
  mod <- lm(Li~CR,data=subsample)
  #sum b2 for all subsamples:
  sumb2 <- sumb2 + coef(mod)[[2]]
}
print(sumb2/C, digits = 3)

   But when I run the script, I had error message:
Error in 1:N : argument of length 0
My data:
Li        CR
74281 8449
92473 8148
62310 8520
71219 8264
33469 8389
75768 7499
61636 7821
103829 8468
87336 8568
129443 8190
97682 8539
106918 8502
97171 8578
48012 8181
93086 8631
92374 8562
113010 8404
66956 8592
133037 8632
108849 8644
81544 8442
105072 8615
143437 7724
153294 7829
123735 8682
154738 8756
100760 8839
108034 8839
81826 8858
116901 8847
80780 8869
122684 8736
141716 9087
144315 9166
162078 9147
163184 9267
150688 9275
200848 9259
221570 8943
192424 8564
173024 9282
197326 9318
209344 9293
220201 9242
212626 9324
218115 9319
170001 9314
187490 9346
172440 9350
180330 9349
200807 9355
234994 9350
139053 9284
150048 9361
203650 9346
233331 9369
198790 9340
164060 9382
198000 9401
201707 9355
179257 9369
188736 9298
243392 9393
246040 9374
269058 9364
201657 9370
187942 9354
228514 9305
234000 9392
224431 9395
163502 9398
I would be most glad for your great assistance.
Many thanks.
Ogbos

	[[alternative HTML version deleted]]



From m@rc_@chw@rtz @end|ng |rom me@com  Wed Aug 22 17:24:52 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 22 Aug 2018 11:24:52 -0400
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
 <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
Message-ID: <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>

Hi,

It might even be worthwhile to review this recent thread on R-Devel:

  https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html

which touches upon a subtly related topic vis-a-vis NaN handling.

Regards,

Marc Schwartz


> On Aug 22, 2018, at 10:55 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ... And FWIW (not much, I agree), note that if z = numeric(0) and sum(z) =
> 0, then mean(z) = NaN makes sense, as length(z) = 0, so dividing by 0 gives
> NaN. So you can see the sorts of issues you may need to consider.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Aug 22, 2018 at 7:47 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> Actually, the dissonance is a bit more basic.
>> 
>> After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
>> what you see is actually:
>> 
>>> z <- numeric(0)
>>> mean(z)
>> [1] NaN
>>> median(z)
>> [1] NA
>>> sd(z)
>> [1] NA
>>> sum(z)
>> [1] 0
>> etc.
>> 
>> I imagine that there may be more of these little inconsistencies due to
>> the organic way R evolved over time. What the conventions should be  can be
>> purely a matter of personal opinion in the absence of accepted standards.
>> But I would look to see what accepted standards were, if any, first.
>> 
>> -- Bert
>> 
>> 
>> On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:
>> 
>>> Dear useRs,
>>> 
>>> I have just noticed that when input is only NA with na.rm=TRUE, mean()
>>> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
>>> be the same? I think NA makes more sense than NaN in that case.
>>> 
>>> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
>>> NAsd(x, na.rm=TRUE) [1] NA
>>> 
>>> Thanks for any feedback.
>>> 
>>> Best,
>>> Ivan
>>> 
>>> --
>>> Dr. Ivan Calandra
>>> TraCEr, laboratory for Traceology and Controlled Experiments
>>> MONREPOS Archaeological Research Centre and
>>> Museum for Human Behavioural Evolution
>>> Schloss Monrepos
>>> 56567 Neuwied, Germany
>>> +49 (0) 2631 9772-243
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 22 17:58:01 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Aug 2018 08:58:01 -0700
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>

No reproducible example (see posting guide below) so minimal help.

Remove the quotes from your formula. Why did you think they should be
there? -- see ?formula.

Read the relevant portions of ?xyplot carefully (again?). You seemed to
have missed:

"*Primary variables:* The x and y variables should both be numeric in xyplot,
and an attempt is made to coerce them if not. However, if either is a
factor, the levels of that factor are used as axis labels. In the other
four functions documented here, [ which includes barchart()]  **exactly one
of x and y should be numeric, and the other a factor or shingle**. Which of
these will happen is determined by the horizontal argument ? if
horizontal=TRUE, then y will be coerced to be a factor or shingle, otherwise
 x. The default value of horizontal is FALSE if x is a factor or shingle,
TRUEotherwise. (The functionality provided by horizontal=FALSE is not
S-compatible.)

So with the default ... horizontal = FALSE, Med would be treated as a
factor, which I think is precisely the opposite of what you want.

Here is a simple example to indicate how things work:

y <- runif(5)
x <- factor(letters[1:5])
barchart(y~x)

As for fiddling with the colors and patterns of the bars -- generally a bad
idea , especially fill patterns, btw -- see the "col" argument of
?panel.barchart, which is always where you should look for such info (i.e.
panel.whatever). I don't know whether you can fool with fill patterns* --
it may depend on your graphics device -- but you can google around or see
what trellis.par.get() has available (which can be specified in the
"par.settings" argument list in the call).

* For why fooling with fill patterns is a bad idea, google "moir? patterns".

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 22, 2018 at 8:13 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    I've not before created bar charts, only scatter plots and box plots.
> Checking in Deepayan's book, searching the web, and looking at ?barchart
> has
> not shown me the how to get the results I need.
>
>    The dataframe looks like this:
> > head(stage_heights)
>    Year   Med   Max
> 1 1989 91.17 93.32
> 2 1990 91.22 93.43
> 3 1991 91.24 92.89
> 4 1993 91.14 93.02
> 5 1994 93.92 95.74
> 6 1995 94.34 96.85
>
>    I want to show Med and Max heights for each Year with each bar having a
> different color (or pattern) and a single x-axis year label.
>
>    Trying to follow the example in ?barchart for a single variable
> produced this:
>
> > barchart('Year' ~ 'Med', data=stage_height,
> panel=lattice.getOption('panel.barchart'),
> default.prepanel=lattice.getOption('prepanel.default.barchart'),box.ratio=2)
> Error in eval(substitute(groups), data, environment(formula)) :
>    invalid 'envir' argument of type 'closure'
> and no plot was displayed.
>
>    I must be missing the obvious and want a pointer to descriptions that
> teach me how to produce bar charts.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Wed Aug 22 18:06:18 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 22 Aug 2018 19:06:18 +0300
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
Message-ID: <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>

Li is defined as d1$a which is a vector. You should use

N <- length(Li)

HTH,
Eric


On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Kind R-users,
> I run a simple regression. I am interested in using the Monte Carlo to test
> the slope parameter.
> Here is what I have done:
> d1<-read.table("Lightcor",col.names=c("a"))
> d2<-read.table("CRcor",col.names=c("a"))
>  Li<-d1$a
> CR<-d2$a
>
>  fit<-lm(Li~CR)
>  a<-summary(fit)
> a gives the slope as 88.15
>
> Problem: I now what to repeat the samples to access this coefficient.
> Following one of the related examples I got online, I did (tried to
> modify):
>
> N <- nrow(Li) # returns the number of observations in the dataset
> C <- 50         # desired number of subsamples
> S <- 38         # desired sample size
>
> sumb2 <- 0
> for (i in 1:C){   # a loop over the number of subsamples
>   set.seed(3*i)   # a different seed for each subsample
>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>   mod <- lm(Li~CR,data=subsample)
>   #sum b2 for all subsamples:
>   sumb2 <- sumb2 + coef(mod)[[2]]
> }
> print(sumb2/C, digits = 3)
>
>    But when I run the script, I had error message:
> Error in 1:N : argument of length 0
> My data:
> Li        CR
> 74281 8449
> 92473 8148
> 62310 8520
> 71219 8264
> 33469 8389
> 75768 7499
> 61636 7821
> 103829 8468
> 87336 8568
> 129443 8190
> 97682 8539
> 106918 8502
> 97171 8578
> 48012 8181
> 93086 8631
> 92374 8562
> 113010 8404
> 66956 8592
> 133037 8632
> 108849 8644
> 81544 8442
> 105072 8615
> 143437 7724
> 153294 7829
> 123735 8682
> 154738 8756
> 100760 8839
> 108034 8839
> 81826 8858
> 116901 8847
> 80780 8869
> 122684 8736
> 141716 9087
> 144315 9166
> 162078 9147
> 163184 9267
> 150688 9275
> 200848 9259
> 221570 8943
> 192424 8564
> 173024 9282
> 197326 9318
> 209344 9293
> 220201 9242
> 212626 9324
> 218115 9319
> 170001 9314
> 187490 9346
> 172440 9350
> 180330 9349
> 200807 9355
> 234994 9350
> 139053 9284
> 150048 9361
> 203650 9346
> 233331 9369
> 198790 9340
> 164060 9382
> 198000 9401
> 201707 9355
> 179257 9369
> 188736 9298
> 243392 9393
> 246040 9374
> 269058 9364
> 201657 9370
> 187942 9354
> 228514 9305
> 234000 9392
> 224431 9395
> 163502 9398
> I would be most glad for your great assistance.
> Many thanks.
> Ogbos
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Aug 22 18:17:26 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 09:17:26 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Bert Gunter wrote:

> No reproducible example (see posting guide below) so minimal help.

Hi Bert,

   I thought the header and six data rows of the dataframe plus the syntax of
the command I used were sufficient. Regardless, here's the dput() output:

structure(list(Year = c(1989L, 1990L, 1991L, 1993L, 1994L, 1995L, 
1996L, 1997L, 1998L, 1999L, 2000L, 2001L, 2002L, 2003L, 2004L, 
2005L, 2006L, 2007L, 2008L, 2009L, 2010L, 2011L, 2012L, 2013L, 
2014L, 2015L, 2016L, 2017L, 2018L), Med = c(91.17, 91.22, 91.24, 
91.14, 93.92, 94.34, 91.32, 91.36, 91.24, 94.33, 94.33, 94, 94.32, 
94.02, 94.19, 94.05, 94.21, 94.21, 94.32, 94.13, 94.27, 94.34, 
94.23, 94.25, 94.15, 94.01, 94.09, 94.31, 94.35), Max = c(93.32, 
93.43, 92.89, 93.02, 95.74, 96.85, 95.86, 94.25, 93.67, 97.42, 
97.42, 94.99, 96.58, 96.57, 96.32, 95.96, 97.4, 97.28, 96.72, 
97.43, 95.95, 97.82, 97, 96.6, 96.24, 96.68, 96.96, 96.39, 96.95
)), class = "data.frame", row.names = c(NA, -29L))


> Remove the quotes from your formula. Why did you think they should be
> there? -- see ?formula.

   A prior attempt seemed to suggest the strings needed to be quoted.

> Read the relevant portions of ?xyplot carefully (again?). You seemed to
> have missed:

   I'm trying to create a barchart, not an xyplot.

> y <- runif(5)
> x <- factor(letters[1:5])
> barchart(y~x)

   Okay. I see one error in my command that's fixed here:

barchart(stage_heights$Med ~ stage_heights$Year, horizontal=FALSE)

> As for fiddling with the colors and patterns of the bars -- generally a bad
> idea , especially fill patterns, btw -- see the "col" argument of
> ?panel.barchart, which is always where you should look for such info (i.e.
> panel.whatever). I don't know whether you can fool with fill patterns* --
> it may depend on your graphics device -- but you can google around or see
> what trellis.par.get() has available (which can be specified in the
> "par.settings" argument list in the call).

   I need pairs of bars, one each for Med and Max for each year. Color or
pattern would distinguish the two.

> * For why fooling with fill patterns is a bad idea, google "moir? patterns".

   I did not think that a solid fill or striped fill would create a moire
pattern on either a computer screen viewing a .pdf file or on the printed
page.

   Correcting the barchard() command fixed the main issue; getting the second
set of bars is still eluding me, but I'll continue working on fixing this.
I'll get the years as the x-axis labels rather than year number in sequence
from 1 to 29.

Thanks,

Rich



From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Aug 22 18:20:25 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 22 Aug 2018 17:20:25 +0100
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
Message-ID: <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>

Hello Eric,
Thanks for this.

I tried it. It went but another problem prevents the code from running.
 source("script.R")
Error in Li[sample(1:N, size = S, replace = TRUE), ] :
  incorrect number of dimensions

The error is coming from the line:
 subsample <- Li[sample(1:N, size=S, replace=TRUE), ]

I tried to replace Li with N but it didn't go. I also tried replacing it
with length(Li). The same error remains.

Thank so much for looking at this again.

Ogbos


On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com> wrote:

> Li is defined as d1$a which is a vector. You should use
>
> N <- length(Li)
>
> HTH,
> Eric
>
>
> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
>
>> Kind R-users,
>> I run a simple regression. I am interested in using the Monte Carlo to
>> test
>> the slope parameter.
>> Here is what I have done:
>> d1<-read.table("Lightcor",col.names=c("a"))
>> d2<-read.table("CRcor",col.names=c("a"))
>>  Li<-d1$a
>> CR<-d2$a
>>
>>  fit<-lm(Li~CR)
>>  a<-summary(fit)
>> a gives the slope as 88.15
>>
>> Problem: I now what to repeat the samples to access this coefficient.
>> Following one of the related examples I got online, I did (tried to
>> modify):
>>
>> N <- nrow(Li) # returns the number of observations in the dataset
>> C <- 50         # desired number of subsamples
>> S <- 38         # desired sample size
>>
>> sumb2 <- 0
>> for (i in 1:C){   # a loop over the number of subsamples
>>   set.seed(3*i)   # a different seed for each subsample
>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>   mod <- lm(Li~CR,data=subsample)
>>   #sum b2 for all subsamples:
>>   sumb2 <- sumb2 + coef(mod)[[2]]
>> }
>> print(sumb2/C, digits = 3)
>>
>>    But when I run the script, I had error message:
>> Error in 1:N : argument of length 0
>> My data:
>> Li        CR
>> 74281 8449
>> 92473 8148
>> 62310 8520
>> 71219 8264
>> 33469 8389
>> 75768 7499
>> 61636 7821
>> 103829 8468
>> 87336 8568
>> 129443 8190
>> 97682 8539
>> 106918 8502
>> 97171 8578
>> 48012 8181
>> 93086 8631
>> 92374 8562
>> 113010 8404
>> 66956 8592
>> 133037 8632
>> 108849 8644
>> 81544 8442
>> 105072 8615
>> 143437 7724
>> 153294 7829
>> 123735 8682
>> 154738 8756
>> 100760 8839
>> 108034 8839
>> 81826 8858
>> 116901 8847
>> 80780 8869
>> 122684 8736
>> 141716 9087
>> 144315 9166
>> 162078 9147
>> 163184 9267
>> 150688 9275
>> 200848 9259
>> 221570 8943
>> 192424 8564
>> 173024 9282
>> 197326 9318
>> 209344 9293
>> 220201 9242
>> 212626 9324
>> 218115 9319
>> 170001 9314
>> 187490 9346
>> 172440 9350
>> 180330 9349
>> 200807 9355
>> 234994 9350
>> 139053 9284
>> 150048 9361
>> 203650 9346
>> 233331 9369
>> 198790 9340
>> 164060 9382
>> 198000 9401
>> 201707 9355
>> 179257 9369
>> 188736 9298
>> 243392 9393
>> 246040 9374
>> 269058 9364
>> 201657 9370
>> 187942 9354
>> 228514 9305
>> 234000 9392
>> 224431 9395
>> 163502 9398
>> I would be most glad for your great assistance.
>> Many thanks.
>> Ogbos
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Aug 22 18:28:44 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 22 Aug 2018 17:28:44 +0100
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
 <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
 <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>
Message-ID: <CAC8ss32LL1oU1h72foH77iJ-siADh40v-1v6Hv2pAh0JS-noHA@mail.gmail.com>

Hello Erick,

Thanks again.
Another line indicated error:

source("script.R")
Error in eval(predvars, data, env) :
  numeric 'envir' arg not of length one
Thank you for additional assitance.
Ogbos



On Wed, Aug 22, 2018 at 5:23 PM Eric Berger <ericjberger at gmail.com> wrote:

> You have an extra comma ... it should be
>
> Li[sample(1:N, size = S, replace = TRUE)]
>
> i.e. no comma after the closing parenthesis
>
>
>
> On Wed, Aug 22, 2018 at 7:20 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
>
>> Hello Eric,
>> Thanks for this.
>>
>> I tried it. It went but another problem prevents the code from running.
>>  source("script.R")
>> Error in Li[sample(1:N, size = S, replace = TRUE), ] :
>>   incorrect number of dimensions
>>
>> The error is coming from the line:
>>  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>
>> I tried to replace Li with N but it didn't go. I also tried replacing it
>> with length(Li). The same error remains.
>>
>> Thank so much for looking at this again.
>>
>> Ogbos
>>
>>
>> On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com>
>> wrote:
>>
>>> Li is defined as d1$a which is a vector. You should use
>>>
>>> N <- length(Li)
>>>
>>> HTH,
>>> Eric
>>>
>>>
>>> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>>> wrote:
>>>
>>>> Kind R-users,
>>>> I run a simple regression. I am interested in using the Monte Carlo to
>>>> test
>>>> the slope parameter.
>>>> Here is what I have done:
>>>> d1<-read.table("Lightcor",col.names=c("a"))
>>>> d2<-read.table("CRcor",col.names=c("a"))
>>>>  Li<-d1$a
>>>> CR<-d2$a
>>>>
>>>>  fit<-lm(Li~CR)
>>>>  a<-summary(fit)
>>>> a gives the slope as 88.15
>>>>
>>>> Problem: I now what to repeat the samples to access this coefficient.
>>>> Following one of the related examples I got online, I did (tried to
>>>> modify):
>>>>
>>>> N <- nrow(Li) # returns the number of observations in the dataset
>>>> C <- 50         # desired number of subsamples
>>>> S <- 38         # desired sample size
>>>>
>>>> sumb2 <- 0
>>>> for (i in 1:C){   # a loop over the number of subsamples
>>>>   set.seed(3*i)   # a different seed for each subsample
>>>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>>   mod <- lm(Li~CR,data=subsample)
>>>>   #sum b2 for all subsamples:
>>>>   sumb2 <- sumb2 + coef(mod)[[2]]
>>>> }
>>>> print(sumb2/C, digits = 3)
>>>>
>>>>    But when I run the script, I had error message:
>>>> Error in 1:N : argument of length 0
>>>> My data:
>>>> Li        CR
>>>> 74281 8449
>>>> 92473 8148
>>>> 62310 8520
>>>> 71219 8264
>>>> 33469 8389
>>>> 75768 7499
>>>> 61636 7821
>>>> 103829 8468
>>>> 87336 8568
>>>> 129443 8190
>>>> 97682 8539
>>>> 106918 8502
>>>> 97171 8578
>>>> 48012 8181
>>>> 93086 8631
>>>> 92374 8562
>>>> 113010 8404
>>>> 66956 8592
>>>> 133037 8632
>>>> 108849 8644
>>>> 81544 8442
>>>> 105072 8615
>>>> 143437 7724
>>>> 153294 7829
>>>> 123735 8682
>>>> 154738 8756
>>>> 100760 8839
>>>> 108034 8839
>>>> 81826 8858
>>>> 116901 8847
>>>> 80780 8869
>>>> 122684 8736
>>>> 141716 9087
>>>> 144315 9166
>>>> 162078 9147
>>>> 163184 9267
>>>> 150688 9275
>>>> 200848 9259
>>>> 221570 8943
>>>> 192424 8564
>>>> 173024 9282
>>>> 197326 9318
>>>> 209344 9293
>>>> 220201 9242
>>>> 212626 9324
>>>> 218115 9319
>>>> 170001 9314
>>>> 187490 9346
>>>> 172440 9350
>>>> 180330 9349
>>>> 200807 9355
>>>> 234994 9350
>>>> 139053 9284
>>>> 150048 9361
>>>> 203650 9346
>>>> 233331 9369
>>>> 198790 9340
>>>> 164060 9382
>>>> 198000 9401
>>>> 201707 9355
>>>> 179257 9369
>>>> 188736 9298
>>>> 243392 9393
>>>> 246040 9374
>>>> 269058 9364
>>>> 201657 9370
>>>> 187942 9354
>>>> 228514 9305
>>>> 234000 9392
>>>> 224431 9395
>>>> 163502 9398
>>>> I would be most glad for your great assistance.
>>>> Many thanks.
>>>> Ogbos
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Wed Aug 22 18:23:28 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 22 Aug 2018 19:23:28 +0300
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
 <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
Message-ID: <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>

You have an extra comma ... it should be

Li[sample(1:N, size = S, replace = TRUE)]

i.e. no comma after the closing parenthesis



On Wed, Aug 22, 2018 at 7:20 PM, Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Hello Eric,
> Thanks for this.
>
> I tried it. It went but another problem prevents the code from running.
>  source("script.R")
> Error in Li[sample(1:N, size = S, replace = TRUE), ] :
>   incorrect number of dimensions
>
> The error is coming from the line:
>  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>
> I tried to replace Li with N but it didn't go. I also tried replacing it
> with length(Li). The same error remains.
>
> Thank so much for looking at this again.
>
> Ogbos
>
>
> On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> Li is defined as d1$a which is a vector. You should use
>>
>> N <- length(Li)
>>
>> HTH,
>> Eric
>>
>>
>> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>>
>>> Kind R-users,
>>> I run a simple regression. I am interested in using the Monte Carlo to
>>> test
>>> the slope parameter.
>>> Here is what I have done:
>>> d1<-read.table("Lightcor",col.names=c("a"))
>>> d2<-read.table("CRcor",col.names=c("a"))
>>>  Li<-d1$a
>>> CR<-d2$a
>>>
>>>  fit<-lm(Li~CR)
>>>  a<-summary(fit)
>>> a gives the slope as 88.15
>>>
>>> Problem: I now what to repeat the samples to access this coefficient.
>>> Following one of the related examples I got online, I did (tried to
>>> modify):
>>>
>>> N <- nrow(Li) # returns the number of observations in the dataset
>>> C <- 50         # desired number of subsamples
>>> S <- 38         # desired sample size
>>>
>>> sumb2 <- 0
>>> for (i in 1:C){   # a loop over the number of subsamples
>>>   set.seed(3*i)   # a different seed for each subsample
>>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>   mod <- lm(Li~CR,data=subsample)
>>>   #sum b2 for all subsamples:
>>>   sumb2 <- sumb2 + coef(mod)[[2]]
>>> }
>>> print(sumb2/C, digits = 3)
>>>
>>>    But when I run the script, I had error message:
>>> Error in 1:N : argument of length 0
>>> My data:
>>> Li        CR
>>> 74281 8449
>>> 92473 8148
>>> 62310 8520
>>> 71219 8264
>>> 33469 8389
>>> 75768 7499
>>> 61636 7821
>>> 103829 8468
>>> 87336 8568
>>> 129443 8190
>>> 97682 8539
>>> 106918 8502
>>> 97171 8578
>>> 48012 8181
>>> 93086 8631
>>> 92374 8562
>>> 113010 8404
>>> 66956 8592
>>> 133037 8632
>>> 108849 8644
>>> 81544 8442
>>> 105072 8615
>>> 143437 7724
>>> 153294 7829
>>> 123735 8682
>>> 154738 8756
>>> 100760 8839
>>> 108034 8839
>>> 81826 8858
>>> 116901 8847
>>> 80780 8869
>>> 122684 8736
>>> 141716 9087
>>> 144315 9166
>>> 162078 9147
>>> 163184 9267
>>> 150688 9275
>>> 200848 9259
>>> 221570 8943
>>> 192424 8564
>>> 173024 9282
>>> 197326 9318
>>> 209344 9293
>>> 220201 9242
>>> 212626 9324
>>> 218115 9319
>>> 170001 9314
>>> 187490 9346
>>> 172440 9350
>>> 180330 9349
>>> 200807 9355
>>> 234994 9350
>>> 139053 9284
>>> 150048 9361
>>> 203650 9346
>>> 233331 9369
>>> 198790 9340
>>> 164060 9382
>>> 198000 9401
>>> 201707 9355
>>> 179257 9369
>>> 188736 9298
>>> 243392 9393
>>> 246040 9374
>>> 269058 9364
>>> 201657 9370
>>> 187942 9354
>>> 228514 9305
>>> 234000 9392
>>> 224431 9395
>>> 163502 9398
>>> I would be most glad for your great assistance.
>>> Many thanks.
>>> Ogbos
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]



From ted@h@rd|ng @end|ng |rom w|@ndre@@net  Wed Aug 22 18:41:18 2018
From: ted@h@rd|ng @end|ng |rom w|@ndre@@net (Ted Harding)
Date: Wed, 22 Aug 2018 17:41:18 +0100
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
 <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
 <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>
Message-ID: <1534956078.6967.24.camel@deb2.fort.knox.uk>

I think that one can usefully look at this question from the
point of view of what "NaN" and "NA" are abbreviations for
(at any rate, according to the understanding I have adopted
since many years -- maybe over-simplified).

NaN: Mot a Number
NA: Not Available

So NA is typically used for missing values, whereas NaN
represents the reults of numerical calculations which
cannot give a result which is a definite number,

Hence 0/0 is not a number, so NaN; similarly Inf/Inf.

Thus, with your x <- c(NA, NA, NA) mean(x, na.rm=TRUE)
sum(x, na.rm=TRUE) = 0, since the set of values of x
with na.rm=TRUE is empty so the number of elements
in x is 0; hence mean = 0/0 = NaN.

But for median(x, na.rm=TRUE), because there are no available
elements in x with na.rm=TRUE, and the median is found by
searching among available elements for the value which
divides the set of values into two halves, the median
is not available, hence NA.

Best wishes to all,
Ted.

On Wed, 2018-08-22 at 11:24 -0400, Marc Schwartz via R-help wrote:
> Hi,
> 
> It might even be worthwhile to review this recent thread on R-Devel:
> 
>   https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html
> 
> which touches upon a subtly related topic vis-a-vis NaN handling.
> 
> Regards,
> 
> Marc Schwartz
> 
> 
> > On Aug 22, 2018, at 10:55 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > 
> > ... And FWIW (not much, I agree), note that if z = numeric(0) and sum(z) =
> > 0, then mean(z) = NaN makes sense, as length(z) = 0, so dividing by 0 gives
> > NaN. So you can see the sorts of issues you may need to consider.
> > 
> > Bert Gunter
> > 
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > 
> > 
> > On Wed, Aug 22, 2018 at 7:47 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > 
> >> Actually, the dissonance is a bit more basic.
> >> 
> >> After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
> >> what you see is actually:
> >> 
> >>> z <- numeric(0)
> >>> mean(z)
> >> [1] NaN
> >>> median(z)
> >> [1] NA
> >>> sd(z)
> >> [1] NA
> >>> sum(z)
> >> [1] 0
> >> etc.
> >> 
> >> I imagine that there may be more of these little inconsistencies due to
> >> the organic way R evolved over time. What the conventions should be  can be
> >> purely a matter of personal opinion in the absence of accepted standards.
> >> But I would look to see what accepted standards were, if any, first.
> >> 
> >> -- Bert
> >> 
> >> 
> >> On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:
> >> 
> >>> Dear useRs,
> >>> 
> >>> I have just noticed that when input is only NA with na.rm=TRUE, mean()
> >>> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
> >>> be the same? I think NA makes more sense than NaN in that case.
> >>> 
> >>> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
> >>> NAsd(x, na.rm=TRUE) [1] NA
> >>> 
> >>> Thanks for any feedback.
> >>> 
> >>> Best,
> >>> Ivan
> >>> 
> >>> --
> >>> Dr. Ivan Calandra
> >>> TraCEr, laboratory for Traceology and Controlled Experiments
> >>> MONREPOS Archaeological Research Centre and
> >>> Museum for Human Behavioural Evolution
> >>> Schloss Monrepos
> >>> 56567 Neuwied, Germany
> >>> +49 (0) 2631 9772-243
> >>> https://www.researchgate.net/profile/Ivan_Calandra
> >>> 
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>> 
> >> 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From er|cjberger @end|ng |rom gm@||@com  Wed Aug 22 18:44:35 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 22 Aug 2018 19:44:35 +0300
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAC8ss32LL1oU1h72foH77iJ-siADh40v-1v6Hv2pAh0JS-noHA@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
 <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
 <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>
 <CAC8ss32LL1oU1h72foH77iJ-siADh40v-1v6Hv2pAh0JS-noHA@mail.gmail.com>
Message-ID: <CAGgJW77EjgHBrG8i4P82tKfMuU0Zi6LtqYc6yFgpBNhoehi+7w@mail.gmail.com>

Hi Ogbos,
I took a closer look at your code.
Here's a modified version (using dummy data) that seems to do what you want.
Hopefully this will make it clear what you need to to.

nn <- 100
lDf <- data.frame(Li=rnorm(nn),CR=rnorm(nn))

fit<-lm(Li~CR, data=lDf)
a<-summary(fit)

N <- nrow(lDf)
C <- 50         # desired number of subsamples
S <- 38         # desired sample size

sumb2 <- 0
for (i in 1:C){   # a loop over the number of subsamples
  set.seed(3*i)   # a different seed for each subsample
  subsample <- lDf[sample(1:N, size=S, replace=TRUE), ]
  mod <- lm(Li~CR,data=subsample)
  #sum b2 for all subsamples:
  sumb2 <- sumb2 + coef(mod)[[2]]
}
print(sumb2/C, digits = 3)

Best,
Eric



On Wed, Aug 22, 2018 at 7:28 PM, Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Hello Erick,
>
> Thanks again.
> Another line indicated error:
>
> source("script.R")
> Error in eval(predvars, data, env) :
>   numeric 'envir' arg not of length one
> Thank you for additional assitance.
> Ogbos
>
>
>
> On Wed, Aug 22, 2018 at 5:23 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> You have an extra comma ... it should be
>>
>> Li[sample(1:N, size = S, replace = TRUE)]
>>
>> i.e. no comma after the closing parenthesis
>>
>>
>>
>> On Wed, Aug 22, 2018 at 7:20 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>>
>>> Hello Eric,
>>> Thanks for this.
>>>
>>> I tried it. It went but another problem prevents the code from running.
>>>  source("script.R")
>>> Error in Li[sample(1:N, size = S, replace = TRUE), ] :
>>>   incorrect number of dimensions
>>>
>>> The error is coming from the line:
>>>  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>
>>> I tried to replace Li with N but it didn't go. I also tried replacing it
>>> with length(Li). The same error remains.
>>>
>>> Thank so much for looking at this again.
>>>
>>> Ogbos
>>>
>>>
>>> On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com>
>>> wrote:
>>>
>>>> Li is defined as d1$a which is a vector. You should use
>>>>
>>>> N <- length(Li)
>>>>
>>>> HTH,
>>>> Eric
>>>>
>>>>
>>>> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>>>> wrote:
>>>>
>>>>> Kind R-users,
>>>>> I run a simple regression. I am interested in using the Monte Carlo to
>>>>> test
>>>>> the slope parameter.
>>>>> Here is what I have done:
>>>>> d1<-read.table("Lightcor",col.names=c("a"))
>>>>> d2<-read.table("CRcor",col.names=c("a"))
>>>>>  Li<-d1$a
>>>>> CR<-d2$a
>>>>>
>>>>>  fit<-lm(Li~CR)
>>>>>  a<-summary(fit)
>>>>> a gives the slope as 88.15
>>>>>
>>>>> Problem: I now what to repeat the samples to access this coefficient.
>>>>> Following one of the related examples I got online, I did (tried to
>>>>> modify):
>>>>>
>>>>> N <- nrow(Li) # returns the number of observations in the dataset
>>>>> C <- 50         # desired number of subsamples
>>>>> S <- 38         # desired sample size
>>>>>
>>>>> sumb2 <- 0
>>>>> for (i in 1:C){   # a loop over the number of subsamples
>>>>>   set.seed(3*i)   # a different seed for each subsample
>>>>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>>>   mod <- lm(Li~CR,data=subsample)
>>>>>   #sum b2 for all subsamples:
>>>>>   sumb2 <- sumb2 + coef(mod)[[2]]
>>>>> }
>>>>> print(sumb2/C, digits = 3)
>>>>>
>>>>>    But when I run the script, I had error message:
>>>>> Error in 1:N : argument of length 0
>>>>> My data:
>>>>> Li        CR
>>>>> 74281 8449
>>>>> 92473 8148
>>>>> 62310 8520
>>>>> 71219 8264
>>>>> 33469 8389
>>>>> 75768 7499
>>>>> 61636 7821
>>>>> 103829 8468
>>>>> 87336 8568
>>>>> 129443 8190
>>>>> 97682 8539
>>>>> 106918 8502
>>>>> 97171 8578
>>>>> 48012 8181
>>>>> 93086 8631
>>>>> 92374 8562
>>>>> 113010 8404
>>>>> 66956 8592
>>>>> 133037 8632
>>>>> 108849 8644
>>>>> 81544 8442
>>>>> 105072 8615
>>>>> 143437 7724
>>>>> 153294 7829
>>>>> 123735 8682
>>>>> 154738 8756
>>>>> 100760 8839
>>>>> 108034 8839
>>>>> 81826 8858
>>>>> 116901 8847
>>>>> 80780 8869
>>>>> 122684 8736
>>>>> 141716 9087
>>>>> 144315 9166
>>>>> 162078 9147
>>>>> 163184 9267
>>>>> 150688 9275
>>>>> 200848 9259
>>>>> 221570 8943
>>>>> 192424 8564
>>>>> 173024 9282
>>>>> 197326 9318
>>>>> 209344 9293
>>>>> 220201 9242
>>>>> 212626 9324
>>>>> 218115 9319
>>>>> 170001 9314
>>>>> 187490 9346
>>>>> 172440 9350
>>>>> 180330 9349
>>>>> 200807 9355
>>>>> 234994 9350
>>>>> 139053 9284
>>>>> 150048 9361
>>>>> 203650 9346
>>>>> 233331 9369
>>>>> 198790 9340
>>>>> 164060 9382
>>>>> 198000 9401
>>>>> 201707 9355
>>>>> 179257 9369
>>>>> 188736 9298
>>>>> 243392 9393
>>>>> 246040 9374
>>>>> 269058 9364
>>>>> 201657 9370
>>>>> 187942 9354
>>>>> 228514 9305
>>>>> 234000 9392
>>>>> 224431 9395
>>>>> 163502 9398
>>>>> I would be most glad for your great assistance.
>>>>> Many thanks.
>>>>> Ogbos
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 22 19:08:55 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Aug 2018 10:08:55 -0700
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQXZ5cKo=CsrZR2JrtDJ=Y2GsKYnJ38dj6KYsc1snrxEQ@mail.gmail.com>

See inline.

-- Bert



On Wed, Aug 22, 2018 at 9:17 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 22 Aug 2018, Bert Gunter wrote:
>
> > No reproducible example (see posting guide below) so minimal help.
>
> Hi Bert,
>
>    I thought the header and six data rows of the dataframe plus the syntax
> of
> the command I used were sufficient. Regardless, here's the dput() output:
>
> structure(list(Year = c(1989L, 1990L, 1991L, 1993L, 1994L, 1995L,
> 1996L, 1997L, 1998L, 1999L, 2000L, 2001L, 2002L, 2003L, 2004L,
> 2005L, 2006L, 2007L, 2008L, 2009L, 2010L, 2011L, 2012L, 2013L,
> 2014L, 2015L, 2016L, 2017L, 2018L), Med = c(91.17, 91.22, 91.24,
> 91.14, 93.92, 94.34, 91.32, 91.36, 91.24, 94.33, 94.33, 94, 94.32,
> 94.02, 94.19, 94.05, 94.21, 94.21, 94.32, 94.13, 94.27, 94.34,
> 94.23, 94.25, 94.15, 94.01, 94.09, 94.31, 94.35), Max = c(93.32,
> 93.43, 92.89, 93.02, 95.74, 96.85, 95.86, 94.25, 93.67, 97.42,
> 97.42, 94.99, 96.58, 96.57, 96.32, 95.96, 97.4, 97.28, 96.72,
> 97.43, 95.95, 97.82, 97, 96.6, 96.24, 96.68, 96.96, 96.39, 96.95
> )), class = "data.frame", row.names = c(NA, -29L))
>
>
> > Remove the quotes from your formula. Why did you think they should be
> > there? -- see ?formula.
>
>    A prior attempt seemed to suggest the strings needed to be quoted.
>
> > Read the relevant portions of ?xyplot carefully (again?). You seemed to
> > have missed:
>
>    I'm trying to create a barchart, not an xyplot.
>

Please see ?xyplot, where you will also see dotplot, barchart, etc.
documented !

>
> > y <- runif(5)
> > x <- factor(letters[1:5])
> > barchart(y~x)
>
>    Okay. I see one error in my command that's fixed here:
>
> barchart(stage_heights$Med ~ stage_heights$Year, horizontal=FALSE)
>
> > As for fiddling with the colors and patterns of the bars -- generally a
> bad
> > idea , especially fill patterns, btw -- see the "col" argument of
> > ?panel.barchart, which is always where you should look for such info
> (i.e.
> > panel.whatever). I don't know whether you can fool with fill patterns* --
> > it may depend on your graphics device -- but you can google around or see
> > what trellis.par.get() has available (which can be specified in the
> > "par.settings" argument list in the call).
>
>    I need pairs of bars, one each for Med and Max for each year. Color or
> pattern would distinguish the two.
>

?xyplot tells you about the "groups" argument that does exactly this.
Again, please read the relevant sections of ?xyplot carefully.


> > * For why fooling with fill patterns is a bad idea, google "moir?
> patterns".
>
>    I did not think that a solid fill or striped fill would create a moire
> pattern on either a computer screen viewing a .pdf file or on the printed
> page.
>

I agree. But color alone usually is the better classifier and suffices; in
black and white, light gray vs. black would work as well for just two
categories I think.



>
>    Correcting the barchard() command fixed the main issue; getting the
> second
> set of bars is still eluding me, but I'll continue working on fixing this.
> I'll get the years as the x-axis labels rather than year number in sequence
> from 1 to 29.
>
> Thanks,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Aug 22 19:14:33 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 22 Aug 2018 18:14:33 +0100
Subject: [R] Monte Carlo on simple regression
In-Reply-To: <CAGgJW77EjgHBrG8i4P82tKfMuU0Zi6LtqYc6yFgpBNhoehi+7w@mail.gmail.com>
References: <CAC8ss33Sf1LQDzeR_y8Ai+vtSr82-VBKdXT4kROzFAc0yp+HbA@mail.gmail.com>
 <CAGgJW748wYemHLG1970jvJ3g9-TTA8hkQ9GRW7SoP-WzBOv2TA@mail.gmail.com>
 <CAC8ss324Ga0NN3m0NhRJYu7D_wtpVp_3Rw_DKzu_1z_L-eeTqg@mail.gmail.com>
 <CAGgJW77Yq9_XEfA3D7bi14YbH1EpM2Z5oHQpPH=t3sZxegF5ww@mail.gmail.com>
 <CAC8ss32LL1oU1h72foH77iJ-siADh40v-1v6Hv2pAh0JS-noHA@mail.gmail.com>
 <CAGgJW77EjgHBrG8i4P82tKfMuU0Zi6LtqYc6yFgpBNhoehi+7w@mail.gmail.com>
Message-ID: <CAC8ss30V2CVkAsQ465x-shCuQpDW3CEMH9YchDYSZeDO25Cxfg@mail.gmail.com>

Dear Erick,

This is great!!
Many thanks for resolving the problem.
Ogbos

On Wed, Aug 22, 2018 at 5:44 PM Eric Berger <ericjberger at gmail.com> wrote:

> Hi Ogbos,
> I took a closer look at your code.
> Here's a modified version (using dummy data) that seems to do what you
> want.
> Hopefully this will make it clear what you need to to.
>
> nn <- 100
> lDf <- data.frame(Li=rnorm(nn),CR=rnorm(nn))
>
> fit<-lm(Li~CR, data=lDf)
> a<-summary(fit)
>
> N <- nrow(lDf)
> C <- 50         # desired number of subsamples
> S <- 38         # desired sample size
>
> sumb2 <- 0
> for (i in 1:C){   # a loop over the number of subsamples
>   set.seed(3*i)   # a different seed for each subsample
>   subsample <- lDf[sample(1:N, size=S, replace=TRUE), ]
>   mod <- lm(Li~CR,data=subsample)
>   #sum b2 for all subsamples:
>   sumb2 <- sumb2 + coef(mod)[[2]]
> }
> print(sumb2/C, digits = 3)
>
> Best,
> Eric
>
>
>
> On Wed, Aug 22, 2018 at 7:28 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
>
>> Hello Erick,
>>
>> Thanks again.
>> Another line indicated error:
>>
>> source("script.R")
>> Error in eval(predvars, data, env) :
>>   numeric 'envir' arg not of length one
>> Thank you for additional assitance.
>> Ogbos
>>
>>
>>
>> On Wed, Aug 22, 2018 at 5:23 PM Eric Berger <ericjberger at gmail.com>
>> wrote:
>>
>>> You have an extra comma ... it should be
>>>
>>> Li[sample(1:N, size = S, replace = TRUE)]
>>>
>>> i.e. no comma after the closing parenthesis
>>>
>>>
>>>
>>> On Wed, Aug 22, 2018 at 7:20 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>>> wrote:
>>>
>>>> Hello Eric,
>>>> Thanks for this.
>>>>
>>>> I tried it. It went but another problem prevents the code from
>>>> running.
>>>>  source("script.R")
>>>> Error in Li[sample(1:N, size = S, replace = TRUE), ] :
>>>>   incorrect number of dimensions
>>>>
>>>> The error is coming from the line:
>>>>  subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>>
>>>> I tried to replace Li with N but it didn't go. I also tried replacing
>>>> it with length(Li). The same error remains.
>>>>
>>>> Thank so much for looking at this again.
>>>>
>>>> Ogbos
>>>>
>>>>
>>>> On Wed, Aug 22, 2018 at 5:06 PM Eric Berger <ericjberger at gmail.com>
>>>> wrote:
>>>>
>>>>> Li is defined as d1$a which is a vector. You should use
>>>>>
>>>>> N <- length(Li)
>>>>>
>>>>> HTH,
>>>>> Eric
>>>>>
>>>>>
>>>>> On Wed, Aug 22, 2018 at 6:02 PM, Ogbos Okike <giftedlife2014 at gmail.com
>>>>> > wrote:
>>>>>
>>>>>> Kind R-users,
>>>>>> I run a simple regression. I am interested in using the Monte Carlo
>>>>>> to test
>>>>>> the slope parameter.
>>>>>> Here is what I have done:
>>>>>> d1<-read.table("Lightcor",col.names=c("a"))
>>>>>> d2<-read.table("CRcor",col.names=c("a"))
>>>>>>  Li<-d1$a
>>>>>> CR<-d2$a
>>>>>>
>>>>>>  fit<-lm(Li~CR)
>>>>>>  a<-summary(fit)
>>>>>> a gives the slope as 88.15
>>>>>>
>>>>>> Problem: I now what to repeat the samples to access this coefficient.
>>>>>> Following one of the related examples I got online, I did (tried to
>>>>>> modify):
>>>>>>
>>>>>> N <- nrow(Li) # returns the number of observations in the dataset
>>>>>> C <- 50         # desired number of subsamples
>>>>>> S <- 38         # desired sample size
>>>>>>
>>>>>> sumb2 <- 0
>>>>>> for (i in 1:C){   # a loop over the number of subsamples
>>>>>>   set.seed(3*i)   # a different seed for each subsample
>>>>>>   subsample <- Li[sample(1:N, size=S, replace=TRUE), ]
>>>>>>   mod <- lm(Li~CR,data=subsample)
>>>>>>   #sum b2 for all subsamples:
>>>>>>   sumb2 <- sumb2 + coef(mod)[[2]]
>>>>>> }
>>>>>> print(sumb2/C, digits = 3)
>>>>>>
>>>>>>    But when I run the script, I had error message:
>>>>>> Error in 1:N : argument of length 0
>>>>>> My data:
>>>>>> Li        CR
>>>>>> 74281 8449
>>>>>> 92473 8148
>>>>>> 62310 8520
>>>>>> 71219 8264
>>>>>> 33469 8389
>>>>>> 75768 7499
>>>>>> 61636 7821
>>>>>> 103829 8468
>>>>>> 87336 8568
>>>>>> 129443 8190
>>>>>> 97682 8539
>>>>>> 106918 8502
>>>>>> 97171 8578
>>>>>> 48012 8181
>>>>>> 93086 8631
>>>>>> 92374 8562
>>>>>> 113010 8404
>>>>>> 66956 8592
>>>>>> 133037 8632
>>>>>> 108849 8644
>>>>>> 81544 8442
>>>>>> 105072 8615
>>>>>> 143437 7724
>>>>>> 153294 7829
>>>>>> 123735 8682
>>>>>> 154738 8756
>>>>>> 100760 8839
>>>>>> 108034 8839
>>>>>> 81826 8858
>>>>>> 116901 8847
>>>>>> 80780 8869
>>>>>> 122684 8736
>>>>>> 141716 9087
>>>>>> 144315 9166
>>>>>> 162078 9147
>>>>>> 163184 9267
>>>>>> 150688 9275
>>>>>> 200848 9259
>>>>>> 221570 8943
>>>>>> 192424 8564
>>>>>> 173024 9282
>>>>>> 197326 9318
>>>>>> 209344 9293
>>>>>> 220201 9242
>>>>>> 212626 9324
>>>>>> 218115 9319
>>>>>> 170001 9314
>>>>>> 187490 9346
>>>>>> 172440 9350
>>>>>> 180330 9349
>>>>>> 200807 9355
>>>>>> 234994 9350
>>>>>> 139053 9284
>>>>>> 150048 9361
>>>>>> 203650 9346
>>>>>> 233331 9369
>>>>>> 198790 9340
>>>>>> 164060 9382
>>>>>> 198000 9401
>>>>>> 201707 9355
>>>>>> 179257 9369
>>>>>> 188736 9298
>>>>>> 243392 9393
>>>>>> 246040 9374
>>>>>> 269058 9364
>>>>>> 201657 9370
>>>>>> 187942 9354
>>>>>> 228514 9305
>>>>>> 234000 9392
>>>>>> 224431 9395
>>>>>> 163502 9398
>>>>>> I would be most glad for your great assistance.
>>>>>> Many thanks.
>>>>>> Ogbos
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Aug 22 19:24:01 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 10:24:01 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Rich Shepard wrote:

> Correcting the barchard() command fixed the main issue; getting the second
> set of bars is still eluding me, but I'll continue working on fixing this.
> I'll get the years as the x-axis labels rather than year number in
> sequence from 1 to 29.

   Despite additional reading of barchart() examples and help pages I'm still
missing how to get grouping working and use the years in the dataframe as
labels on the x-axis.

   The most recent command version (on the dput output in my previous
message) is:

med_max <- barchart(stage_heights$Med ~ stage_heights$Year, horizontal=FALSE, col = 'black',
                     main = 'Median and Maximum Stage Heights\nUSGS Gauge',
                     ylab = 'Elevation (masl)', xlab = 'Year', groups=TRUE,
                     beside=TRUE, panel = "panel.superbar", prepanel = "prepanel.superbar",)
print(med_max)

   I don't think that conditioning into a trellis applies to this barchart
and I'm not relating the use of scales and labels in a conditioned plot to
the barchart.

   The above command yields an error and I've not found the explanation for
it:

Error in get(fun, mode = "function", envir = parent.frame()) :
   object 'panel.superbar' of mode 'function' was not found

so I'm definitely not getting the command syntax correct. Help's still
needed.

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Aug 22 19:26:12 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 10:26:12 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbQXZ5cKo=CsrZR2JrtDJ=Y2GsKYnJ38dj6KYsc1snrxEQ@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <CAGxFJbQXZ5cKo=CsrZR2JrtDJ=Y2GsKYnJ38dj6KYsc1snrxEQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808221025420.6107@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Bert Gunter wrote:

> See inline.

Bert,

   Will do. Sent a reply before seeing this. More to follow.

Thanks,

Rich



From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 22 20:05:21 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Aug 2018 11:05:21 -0700
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>

(I know that you said your post may already be "out of date", but ...)

"   Despite additional reading of barchart() examples and help pages I'm
still
missing how to get grouping working and use the years in the dataframe as
labels on the x-axis."

But ?barchart says:
"Formally, if groups is specified, then groups along with subscripts is
passed to the panel function, ..."

which, as I already told you, means you should consult ?panel.barchart . In
particular, the example therein tells you exactly how the "groups" argument
should be specified and how it works (you can change colors via the "col"
argument, of course). Note, in particular, that "groups" must be your
grouping variable, which means, in particular, that you need to reformat
your data frame in what is currently referred to as "tidy" format (aka
"long" format as opposed to "wide") -- one variable per column, one
observation per row.  That is:

Year     Value   Summary.Type
1991    91.24   "Med"
1991    92.89   "Max"
... etc.

.... groups = Summary.Type, ...
in your call will then do the job.

As an aside, this is a good example of why you should adhere to this format
for data analysis in R.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 22, 2018 at 10:34 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 22 Aug 2018, Rich Shepard wrote:
>
> > Correcting the barchard() command fixed the main issue; getting the
> second
> > set of bars is still eluding me, but I'll continue working on fixing
> this.
> > I'll get the years as the x-axis labels rather than year number in
> > sequence from 1 to 29.
>
>    Despite additional reading of barchart() examples and help pages I'm
> still
> missing how to get grouping working and use the years in the dataframe as
> labels on the x-axis.
>
>    The most recent command version (on the dput output in my previous
> message) is:
>
> med_max <- barchart(stage_heights$Med ~ stage_heights$Year,
> horizontal=FALSE, col = 'black',
>                      main = 'Median and Maximum Stage Heights\nUSGS Gauge',
>                      ylab = 'Elevation (masl)', xlab = 'Year', groups=TRUE,
>                      beside=TRUE, panel = "panel.superbar", prepanel =
> "prepanel.superbar",)
> print(med_max)
>
>    I don't think that conditioning into a trellis applies to this barchart
> and I'm not relating the use of scales and labels in a conditioned plot to
> the barchart.
>
>    The above command yields an error and I've not found the explanation for
> it:
>
> Error in get(fun, mode = "function", envir = parent.frame()) :
>    object 'panel.superbar' of mode 'function' was not found
>
> so I'm definitely not getting the command syntax correct. Help's still
> needed.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Aug 22 20:18:34 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 11:18:34 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808221114140.6107@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Bert Gunter wrote:

> (I know that you said your post may already be "out of date", but ...)

Bert,

   Still reading ?xyplot/?barchart.

> But ?barchart says:
> "Formally, if groups is specified, then groups along with subscripts is
> passed to the panel function, ..."
>
> which, as I already told you, means you should consult ?panel.barchart . In
> particular, the example therein tells you exactly how the "groups" argument
> should be specified and how it works (you can change colors via the "col"
> argument, of course). Note, in particular, that "groups" must be your
> grouping variable, which means, in particular, that you need to reformat
> your data frame in what is currently referred to as "tidy" format (aka
> "long" format as opposed to "wide") -- one variable per column, one
> observation per row.  That is:
>
> Year     Value   Summary.Type
> 1991    91.24   "Med"
> 1991    92.89   "Max"
> ... etc.

   I saw this in examples and missed its application to my data. You've
cleared my confusion and now I _do_ understand the need for a separate
grouping column and reshaping to a long format. Thanks for explaining so
effectively.

> As an aside, this is a good example of why you should adhere to this
> format for data analysis in R.

   I've done this with all my other data sets and have no excuse for not
doing so with this one. Mea culpa!

Best regards,

Rich



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Wed Aug 22 23:27:47 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Wed, 22 Aug 2018 17:27:47 -0400
Subject: [R] R package downloading
Message-ID: <CAPQaxLMucmgk8EcB-7Oax24GLPr0Z+wmVQOyfqAquC+WWLDrbw@mail.gmail.com>

Hello all,

  Once the R package TCGAbiolinks.... or biocLite(?TCGAbiolinks?) is done
unpacking, how do I go about apply any particular analysis with it?
Currently, I am unable to access the consule and edit any further. Would I
therefore have to open up a new script?

Spencer Brackett

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Aug 22 23:31:50 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 22 Aug 2018 14:31:50 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Bert Gunter wrote:

> .... groups = Summary.Type, ...
> in your call will then do the job.
>
> As an aside, this is a good example of why you should adhere to this format
> for data analysis in R.

Bert,

   Progress and retreat. I'm putting this aside for a day or so because I
need to provide my client with a draft report and I can add this plot later
when I figure out how to do it correctly.

   More when I have results.

Thanks again,

Rich



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug 22 23:42:10 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 22 Aug 2018 14:42:10 -0700
Subject: [R] R package downloading
In-Reply-To: <CAPQaxLMucmgk8EcB-7Oax24GLPr0Z+wmVQOyfqAquC+WWLDrbw@mail.gmail.com>
References: <CAPQaxLMucmgk8EcB-7Oax24GLPr0Z+wmVQOyfqAquC+WWLDrbw@mail.gmail.com>
Message-ID: <CFE6818E-DA71-49BA-B67E-D100A2270E2A@dcn.davis.ca.us>

The Bioconductor project does things their own way. Please use their support channels for help with their packages. https://www.bioconductor.org/help/

On August 22, 2018 2:27:47 PM PDT, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>Hello all,
>
>Once the R package TCGAbiolinks.... or biocLite(?TCGAbiolinks?) is done
>unpacking, how do I go about apply any particular analysis with it?
>Currently, I am unable to access the consule and edit any further.
>Would I
>therefore have to open up a new script?
>
>Spencer Brackett
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From r@@@pdx @end|ng |rom gm@||@com  Thu Aug 23 01:07:02 2018
From: r@@@pdx @end|ng |rom gm@||@com (Richard Sherman)
Date: Wed, 22 Aug 2018 16:07:02 -0700
Subject: [R] graphing repeated curves
Message-ID: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>

Hi all,

I have a simple graphing question that is not really a graphing question, but a question about repeating a task.

I?m fiddling with some of McElreath?s Statistical Rethinking, and there?s a graph illustrating extreme overfitting (a number of polynomial terms in x equal to the number of observations), a subject I know well having taught it to grad students for many years.

The plot I want to reproduce has, in effect:

m1 <- lm( y ~ x)
m2 <- lm( y ~ x + x^2)

?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed by some plot() or lines() or ggplot2() call to render the data and fitted curves.

Obviously I don?t want to run such regressions for any real purpose, but I think it might be useful to learn how to do such a thing in R without writing down each lm() call individually. It?s not obvious where I?d want to apply this, but I like learning how to repeat things in a compact way. 

So, something like:

data( mtcars )
d <- mtcars
v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
m1 <- lm( mpg ~ hp  , data = d )

and then somehow use for() with an index or some flavor of apply() with the vector v to repeat this process yielding

m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )

? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6) , data=d )

But finding a way to index these values including not just each value but each value+1 , then value+1 and value+2, and so on escapes me. Obviously I don?t want to include index values below zero. 

===
Richard Sherman
rss.pdx at gmail.com



From drj|m|emon @end|ng |rom gm@||@com  Thu Aug 23 01:43:09 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 23 Aug 2018 09:43:09 +1000
Subject: [R] graphing repeated curves
In-Reply-To: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
References: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
Message-ID: <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>

Hi Richard,
This may be what you want:

data(mtcars)
m<-list()
for(i in 1:6) {
 rhterms<-paste(paste0("I(hp^",1:i,")"),sep="+")
 lmexp<-paste0("lm(mpg~",rhterms,",mtcars)")
 cat(lmexp,"\n")
 m[[i]]<-eval(parse(text=lmexp))
}
plot(mpg~hp,mtcars,type="n")
for(i in 1:6) abline(m[[i]],col=i)

Jim


On Thu, Aug 23, 2018 at 9:07 AM, Richard Sherman <rss.pdx at gmail.com> wrote:
> Hi all,
>
> I have a simple graphing question that is not really a graphing question, but a question about repeating a task.
>
> I?m fiddling with some of McElreath?s Statistical Rethinking, and there?s a graph illustrating extreme overfitting (a number of polynomial terms in x equal to the number of observations), a subject I know well having taught it to grad students for many years.
>
> The plot I want to reproduce has, in effect:
>
> m1 <- lm( y ~ x)
> m2 <- lm( y ~ x + x^2)
>
> ?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed by some plot() or lines() or ggplot2() call to render the data and fitted curves.
>
> Obviously I don?t want to run such regressions for any real purpose, but I think it might be useful to learn how to do such a thing in R without writing down each lm() call individually. It?s not obvious where I?d want to apply this, but I like learning how to repeat things in a compact way.
>
> So, something like:
>
> data( mtcars )
> d <- mtcars
> v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
> m1 <- lm( mpg ~ hp  , data = d )
>
> and then somehow use for() with an index or some flavor of apply() with the vector v to repeat this process yielding
>
> m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
> m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )
>
> ? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6) , data=d )
>
> But finding a way to index these values including not just each value but each value+1 , then value+1 and value+2, and so on escapes me. Obviously I don?t want to include index values below zero.
>
> ===
> Richard Sherman
> rss.pdx at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From j|ox @end|ng |rom mcm@@ter@c@  Thu Aug 23 02:29:21 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 23 Aug 2018 00:29:21 +0000
Subject: [R] graphing repeated curves
In-Reply-To: <787_1534979238_w7MN7IHh021447_DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
References: <787_1534979238_w7MN7IHh021447_DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368962F7@FHSDB2D11-2.csu.mcmaster.ca>

Dear Richard,

How about this:

ord <- order(mtcars$hp)
mtcars$hp <- mtcars$hp[ord]
mtcars$mpg <- mtcars$mpg[ord]
plot(mpg ~ hp, data=mtcars)
for (p in 1:6){
    m <- lm(mpg ~ poly(hp, p), data=mtcars)
    lines(mtcars$hp, fitted(m), lty=p, col=p)
}
legend("topright", legend=1:6, lty=1:6, col=1:6, title="order", inset=0.02)

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Richard
> Sherman
> Sent: Wednesday, August 22, 2018 7:07 PM
> To: r-help at r-project.org
> Subject: [R] graphing repeated curves
> 
> Hi all,
> 
> I have a simple graphing question that is not really a graphing question, but a
> question about repeating a task.
> 
> I?m fiddling with some of McElreath?s Statistical Rethinking, and there?s a
> graph illustrating extreme overfitting (a number of polynomial terms in x
> equal to the number of observations), a subject I know well having taught it to
> grad students for many years.
> 
> The plot I want to reproduce has, in effect:
> 
> m1 <- lm( y ~ x)
> m2 <- lm( y ~ x + x^2)
> 
> ?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed by some
> plot() or lines() or ggplot2() call to render the data and fitted curves.
> 
> Obviously I don?t want to run such regressions for any real purpose, but I think
> it might be useful to learn how to do such a thing in R without writing down
> each lm() call individually. It?s not obvious where I?d want to apply this, but I
> like learning how to repeat things in a compact way.
> 
> So, something like:
> 
> data( mtcars )
> d <- mtcars
> v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
> m1 <- lm( mpg ~ hp  , data = d )
> 
> and then somehow use for() with an index or some flavor of apply() with the
> vector v to repeat this process yielding
> 
> m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
> m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )
> 
> ? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) +
> I(hp^5) + I(hp^6) , data=d )
> 
> But finding a way to index these values including not just each value but each
> value+1 , then value+1 and value+2, and so on escapes me. Obviously I don?t
> want to include index values below zero.
> 
> ===
> Richard Sherman
> rss.pdx at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug 23 02:37:45 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Aug 2018 17:37:45 -0700
Subject: [R] graphing repeated curves
In-Reply-To: <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>
References: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
 <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>
Message-ID: <CAGxFJbTb30ovevhyAzyOzDKD9es1WXqO9Yy_9pSe1o6feCORSQ@mail.gmail.com>

I do not think this does what the OP wants -- it does not produce
polynomials of the form desired.

John Fox's solution using poly() seems to me to be the right approach, but
I will show what I think is a considerably simpler way to build up the
polynomial expressions just as an example of one way to do this sort of
thing in more general circumstances:

fm <- vector("character",6)
fm[1]<- "mpg ~ hp"
for(i in 2:6)fm[i]<- paste0(fm[i-1]," + I(hp^", i,")")
## yielding:
> fm
[1] "mpg ~ hp"
[2] "mpg ~ hp + I(hp^2)"
[3] "mpg ~ hp + I(hp^2) + I(hp^3)"
[4] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4)"
[5] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5)"
[6] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6)"

Although fm is a character vector, the character strings will be
automatically coerced by lm to formulas (see ?lm), so, e.g.

results <- lapply(fm, lm,data = mtcars)

would yield a list of regressions which could then be summarized, plotted
or whatever (again using lapply). e.g.

> results[[3]]

Call:
FUN(formula = X[[i]], data = ..1)

Coefficients:
(Intercept)           hp      I(hp^2)      I(hp^3)
  4.422e+01   -2.945e-01    9.115e-04   -8.701e-07

One could also choose to do the plotting or whatever within the lapply
call, but I prefer to keep things simple if possible.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 22, 2018 at 4:43 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Richard,
> This may be what you want:
>
> data(mtcars)
> m<-list()
> for(i in 1:6) {
>  rhterms<-paste(paste0("I(hp^",1:i,")"),sep="+")
>  lmexp<-paste0("lm(mpg~",rhterms,",mtcars)")
>  cat(lmexp,"\n")
>  m[[i]]<-eval(parse(text=lmexp))
> }
> plot(mpg~hp,mtcars,type="n")
> for(i in 1:6) abline(m[[i]],col=i)
>
> Jim
>
>
> On Thu, Aug 23, 2018 at 9:07 AM, Richard Sherman <rss.pdx at gmail.com>
> wrote:
> > Hi all,
> >
> > I have a simple graphing question that is not really a graphing
> question, but a question about repeating a task.
> >
> > I?m fiddling with some of McElreath?s Statistical Rethinking, and
> there?s a graph illustrating extreme overfitting (a number of polynomial
> terms in x equal to the number of observations), a subject I know well
> having taught it to grad students for many years.
> >
> > The plot I want to reproduce has, in effect:
> >
> > m1 <- lm( y ~ x)
> > m2 <- lm( y ~ x + x^2)
> >
> > ?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed by
> some plot() or lines() or ggplot2() call to render the data and fitted
> curves.
> >
> > Obviously I don?t want to run such regressions for any real purpose, but
> I think it might be useful to learn how to do such a thing in R without
> writing down each lm() call individually. It?s not obvious where I?d want
> to apply this, but I like learning how to repeat things in a compact way.
> >
> > So, something like:
> >
> > data( mtcars )
> > d <- mtcars
> > v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
> > m1 <- lm( mpg ~ hp  , data = d )
> >
> > and then somehow use for() with an index or some flavor of apply() with
> the vector v to repeat this process yielding
> >
> > m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
> > m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )
> >
> > ? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4)
> + I(hp^5) + I(hp^6) , data=d )
> >
> > But finding a way to index these values including not just each value
> but each value+1 , then value+1 and value+2, and so on escapes me.
> Obviously I don?t want to include index values below zero.
> >
> > ===
> > Richard Sherman
> > rss.pdx at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From j|ox @end|ng |rom mcm@@ter@c@  Thu Aug 23 02:56:52 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 23 Aug 2018 00:56:52 +0000
Subject: [R] graphing repeated curves
In-Reply-To: <789_1534984775_w7N0dYTv015741_CAGxFJbTb30ovevhyAzyOzDKD9es1WXqO9Yy_9pSe1o6feCORSQ@mail.gmail.com>
References: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
 <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>
 <789_1534984775_w7N0dYTv015741_CAGxFJbTb30ovevhyAzyOzDKD9es1WXqO9Yy_9pSe1o6feCORSQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836896327@FHSDB2D11-2.csu.mcmaster.ca>

Dear Bert,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Wednesday, August 22, 2018 8:38 PM
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: rss.pdx at gmail.com; R-help <r-help at r-project.org>
> Subject: Re: [R] graphing repeated curves
> 
> I do not think this does what the OP wants -- it does not produce polynomials
> of the form desired.
> 
> John Fox's solution using poly() seems to me to be the right approach, but I

Actually, I didn't do a good job of graphing the polynomials between the observed x-values. Here's a better solution:

x <- with(mtcars, seq(min(hp), max(hp), length=500))
plot(mpg ~ hp, data=mtcars)
for (p in 1:6){
    m <- lm(mpg ~ poly(hp, p), data=mtcars)
    lines(x, predict(m, newdata=data.frame(hp=x)), lty=p, col=p)
}
legend("top", legend=1:6, lty=1:6, col=1:6, title="order", inset=0.02)

Best,
 John

> will show what I think is a considerably simpler way to build up the
> polynomial expressions just as an example of one way to do this sort of thing
> in more general circumstances:
> 
> fm <- vector("character",6)
> fm[1]<- "mpg ~ hp"
> for(i in 2:6)fm[i]<- paste0(fm[i-1]," + I(hp^", i,")") ## yielding:
> > fm
> [1] "mpg ~ hp"
> [2] "mpg ~ hp + I(hp^2)"
> [3] "mpg ~ hp + I(hp^2) + I(hp^3)"
> [4] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4)"
> [5] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5)"
> [6] "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6)"
> 
> Although fm is a character vector, the character strings will be automatically
> coerced by lm to formulas (see ?lm), so, e.g.
> 
> results <- lapply(fm, lm,data = mtcars)
> 
> would yield a list of regressions which could then be summarized, plotted or
> whatever (again using lapply). e.g.
> 
> > results[[3]]
> 
> Call:
> FUN(formula = X[[i]], data = ..1)
> 
> Coefficients:
> (Intercept)           hp      I(hp^2)      I(hp^3)
>   4.422e+01   -2.945e-01    9.115e-04   -8.701e-07
> 
> One could also choose to do the plotting or whatever within the lapply call,
> but I prefer to keep things simple if possible.
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Aug 22, 2018 at 4:43 PM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> 
> > Hi Richard,
> > This may be what you want:
> >
> > data(mtcars)
> > m<-list()
> > for(i in 1:6) {
> >  rhterms<-paste(paste0("I(hp^",1:i,")"),sep="+")
> >  lmexp<-paste0("lm(mpg~",rhterms,",mtcars)")
> >  cat(lmexp,"\n")
> >  m[[i]]<-eval(parse(text=lmexp))
> > }
> > plot(mpg~hp,mtcars,type="n")
> > for(i in 1:6) abline(m[[i]],col=i)
> >
> > Jim
> >
> >
> > On Thu, Aug 23, 2018 at 9:07 AM, Richard Sherman <rss.pdx at gmail.com>
> > wrote:
> > > Hi all,
> > >
> > > I have a simple graphing question that is not really a graphing
> > question, but a question about repeating a task.
> > >
> > > I?m fiddling with some of McElreath?s Statistical Rethinking, and
> > there?s a graph illustrating extreme overfitting (a number of
> > polynomial terms in x equal to the number of observations), a subject
> > I know well having taught it to grad students for many years.
> > >
> > > The plot I want to reproduce has, in effect:
> > >
> > > m1 <- lm( y ~ x)
> > > m2 <- lm( y ~ x + x^2)
> > >
> > > ?etc., through lm( y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 ), followed
> > > by
> > some plot() or lines() or ggplot2() call to render the data and fitted
> > curves.
> > >
> > > Obviously I don?t want to run such regressions for any real purpose,
> > > but
> > I think it might be useful to learn how to do such a thing in R
> > without writing down each lm() call individually. It?s not obvious
> > where I?d want to apply this, but I like learning how to repeat things in a
> compact way.
> > >
> > > So, something like:
> > >
> > > data( mtcars )
> > > d <- mtcars
> > > v <- c( 1 , 2 , 3 , 4 , 5 , 6  )
> > > m1 <- lm( mpg ~ hp  , data = d )
> > >
> > > and then somehow use for() with an index or some flavor of apply()
> > > with
> > the vector v to repeat this process yielding
> > >
> > > m2 <- lm( mpg ~ hp + I( hp ^2 ) , data=d)
> > > m3 <- lm( mpg ~ hp + I( hp^2 ) + I(hp^3) , data=d )
> > >
> > > ? and the rest through m6 <- lm( mpg ~ hp + I(hp^2) + I(hp^3) +
> > > I(hp^4)
> > + I(hp^5) + I(hp^6) , data=d )
> > >
> > > But finding a way to index these values including not just each
> > > value
> > but each value+1 , then value+1 and value+2, and so on escapes me.
> > Obviously I don?t want to include index values below zero.
> > >
> > > ===
> > > Richard Sherman
> > > rss.pdx at gmail.com
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@@@pdx @end|ng |rom gm@||@com  Thu Aug 23 03:09:15 2018
From: r@@@pdx @end|ng |rom gm@||@com (Richard Sherman)
Date: Wed, 22 Aug 2018 18:09:15 -0700
Subject: [R] graphing repeated curves
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836896327@FHSDB2D11-2.csu.mcmaster.ca>
References: <DD2E93C6-265D-44E4-8912-03A9540A44D3@gmail.com>
 <CA+8X3fXz383eL8hLA_O4f2wLPSANVdLCV+HRV_jdMeK6MRfFCw@mail.gmail.com>
 <789_1534984775_w7N0dYTv015741_CAGxFJbTb30ovevhyAzyOzDKD9es1WXqO9Yy_9pSe1o6feCORSQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836896327@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <86A0380F-19EC-4036-9F20-B75576BCC5E9@gmail.com>

These are great, thanks.

I always forget about paste().

===
Richard Sherman
rss.pdx at gmail.com



> On Aug 22, 2018, at 17:56, Fox, John <jfox at mcmaster.ca> wrote:
> 
> fm <- vector("character",6)
> fm[1]<- "mpg ~ hp"
> for(i in 2:6)fm[i]<- paste0(fm[i-1]," + I(hp^", i,")")



From c@|@ndr@ @end|ng |rom rgzm@de  Thu Aug 23 08:15:35 2018
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 23 Aug 2018 08:15:35 +0200
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <1534956078.6967.24.camel@deb2.fort.knox.uk>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
 <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
 <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>
 <1534956078.6967.24.camel@deb2.fort.knox.uk>
Message-ID: <62dac2e0-9ebc-63d3-ad7b-07535f60909b@rgzm.de>

Thanks all for the enlightenment.

So, it does make sense that mean() produces NaN and median()/sd() NA, 
from a calculation point of view at least.
But I still think it also makes sense that the mean of NA is NA as well, 
be it only for consistency with other functions. That's just my opinion 
of course. I can still convert NaN to NA at the end if I need to.

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 22/08/2018 18:41, Ted Harding wrote:
> I think that one can usefully look at this question from the
> point of view of what "NaN" and "NA" are abbreviations for
> (at any rate, according to the understanding I have adopted
> since many years -- maybe over-simplified).
>
> NaN: Mot a Number
> NA: Not Available
>
> So NA is typically used for missing values, whereas NaN
> represents the reults of numerical calculations which
> cannot give a result which is a definite number,
>
> Hence 0/0 is not a number, so NaN; similarly Inf/Inf.
>
> Thus, with your x <- c(NA, NA, NA) mean(x, na.rm=TRUE)
> sum(x, na.rm=TRUE) = 0, since the set of values of x
> with na.rm=TRUE is empty so the number of elements
> in x is 0; hence mean = 0/0 = NaN.
>
> But for median(x, na.rm=TRUE), because there are no available
> elements in x with na.rm=TRUE, and the median is found by
> searching among available elements for the value which
> divides the set of values into two halves, the median
> is not available, hence NA.
>
> Best wishes to all,
> Ted.
>
> On Wed, 2018-08-22 at 11:24 -0400, Marc Schwartz via R-help wrote:
>> Hi,
>>
>> It might even be worthwhile to review this recent thread on R-Devel:
>>
>>    https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html
>>
>> which touches upon a subtly related topic vis-a-vis NaN handling.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>>> On Aug 22, 2018, at 10:55 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> ... And FWIW (not much, I agree), note that if z = numeric(0) and sum(z) =
>>> 0, then mean(z) = NaN makes sense, as length(z) = 0, so dividing by 0 gives
>>> NaN. So you can see the sorts of issues you may need to consider.
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Wed, Aug 22, 2018 at 7:47 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>>> Actually, the dissonance is a bit more basic.
>>>>
>>>> After xxx(...., na.rm=TRUE) with all NA's in ... you have numeric(0). So
>>>> what you see is actually:
>>>>
>>>>> z <- numeric(0)
>>>>> mean(z)
>>>> [1] NaN
>>>>> median(z)
>>>> [1] NA
>>>>> sd(z)
>>>> [1] NA
>>>>> sum(z)
>>>> [1] 0
>>>> etc.
>>>>
>>>> I imagine that there may be more of these little inconsistencies due to
>>>> the organic way R evolved over time. What the conventions should be  can be
>>>> purely a matter of personal opinion in the absence of accepted standards.
>>>> But I would look to see what accepted standards were, if any, first.
>>>>
>>>> -- Bert
>>>>
>>>>
>>>> On Wed, Aug 22, 2018 at 7:34 AM Ivan Calandra <calandra at rgzm.de> wrote:
>>>>
>>>>> Dear useRs,
>>>>>
>>>>> I have just noticed that when input is only NA with na.rm=TRUE, mean()
>>>>> results in NaN, whereas median() and sd() produce NA. Shouldn't it all
>>>>> be the same? I think NA makes more sense than NaN in that case.
>>>>>
>>>>> x <- c(NA, NA, NA) mean(x, na.rm=TRUE) [1] NaN median(x, na.rm=TRUE) [1]
>>>>> NAsd(x, na.rm=TRUE) [1] NA
>>>>>
>>>>> Thanks for any feedback.
>>>>>
>>>>> Best,
>>>>> Ivan
>>>>>
>>>>> --
>>>>> Dr. Ivan Calandra
>>>>> TraCEr, laboratory for Traceology and Controlled Experiments
>>>>> MONREPOS Archaeological Research Centre and
>>>>> Museum for Human Behavioural Evolution
>>>>> Schloss Monrepos
>>>>> 56567 Neuwied, Germany
>>>>> +49 (0) 2631 9772-243
>>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>



From v|dh|@@|@g|r| @end|ng |rom gm@||@com  Thu Aug 23 08:35:11 2018
From: v|dh|@@|@g|r| @end|ng |rom gm@||@com (Vidya Alagiriswamy)
Date: Wed, 22 Aug 2018 23:35:11 -0700
Subject: [R] importing .v8x file in R
Message-ID: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>

 HI,

   I am new to R and want to read the data file with extension .v8x. The
file is hints2003.d2006_06_02.public.v8x. Is anyone familiar with this
extension? Please help.

Thanks,
Vidya

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Aug 23 10:31:52 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 23 Aug 2018 20:31:52 +1200
Subject: [R] differing behavior of mean(), median() and sd() with na.rm
In-Reply-To: <62dac2e0-9ebc-63d3-ad7b-07535f60909b@rgzm.de>
References: <82eb3f0c-4ce8-7adb-7fbc-2ff3238a0da6@rgzm.de>
 <CAGxFJbT=Mpz8WAKsaP5AQciZ0NReao=UWF_JhiwuNoZqRbAt-Q@mail.gmail.com>
 <CAGxFJbQH2Ce=0FOpB1g7tgTE0fBeEnVwUR5QJ8NA7gdS+tdhDg@mail.gmail.com>
 <EDB12D28-59D9-4FEE-BE86-3996A9B53A39@me.com>
 <1534956078.6967.24.camel@deb2.fort.knox.uk>
 <62dac2e0-9ebc-63d3-ad7b-07535f60909b@rgzm.de>
Message-ID: <120e7f5c-4f94-8943-c0ae-a920662a6ce6@auckland.ac.nz>


On 08/23/2018 06:15 PM, Ivan Calandra wrote:

> Thanks all for the enlightenment.
> 
> So, it does make sense that mean() produces NaN and median()/sd() NA, 
> from a calculation point of view at least.
> But I still think it also makes sense that the mean of NA is NA as well, 
> be it only for consistency with other functions. That's just my opinion 
> of course. I can still convert NaN to NA at the end if I need to.

But the mean of NA *is* NA!

> x <- NA
> mean(x)
> [1] NA

This is *not* the same scenario as having nothing left after *removing* 
all NAs:

> x <- rep(NA,3)
> mean(x,na.rm=TRUE > [1] NaN

Seems quite consistent/coherent to me.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 23 10:35:29 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 23 Aug 2018 09:35:29 +0100
Subject: [R] importing .v8x file in R
In-Reply-To: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
References: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
Message-ID: <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>

Hello,

Sorry but I don't believe this is a question for r-help.

r-help is meant for questions about R code, you should find out what 
type of file do you have. Maybe open it and see its contents.

There is really nothing we can do.

Rui Barradas

On 23/08/2018 07:35, Vidya Alagiriswamy wrote:
>   HI,
> 
>     I am new to R and want to read the data file with extension .v8x. The
> file is hints2003.d2006_06_02.public.v8x. Is anyone familiar with this
> extension? Please help.
> 
> Thanks,
> Vidya
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com



From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Aug 23 10:39:33 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 23 Aug 2018 20:39:33 +1200
Subject: [R] importing .v8x file in R
In-Reply-To: <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>
References: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
 <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>
Message-ID: <a7c5cb51-1d19-39bf-caa7-fda093cfa4d6@auckland.ac.nz>

On 08/23/2018 08:35 PM, Rui Barradas wrote:
> Hello,
> 
> Sorry but I don't believe this is a question for r-help.
> 
> r-help is meant for questions about R code, you should find out what 
> type of file do you have. Maybe open it and see its contents.
> 
> There is really nothing we can do.

Indeed.  But the OP could try Googling "v8x file extension".
Psigh!

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From @@h|mk@poor @end|ng |rom gm@||@com  Thu Aug 23 11:00:59 2018
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 23 Aug 2018 14:30:59 +0530
Subject: [R] Unclear about the output from summary of ca.jo from package urca
Message-ID: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>

Dear All,

I am not sure about the summary of the function ca.jo. I have posted my
query here :-

https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r

I did not receive any reply so I am posting my query here.

Many thanks and best regards,
Ashim

	[[alternative HTML version deleted]]



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Thu Aug 23 11:15:19 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Thu, 23 Aug 2018 21:15:19 +1200
Subject: [R] Plots in ioslides and R markdown
Message-ID: <20180823091519.GB13179@slingshot.co.nz>

I'm having difficulty getting plots into ioslides.  It seems to me
that the scale is completely out, but I can't figure out what to do
about it.  Whatever I try, I get the title slide, then a second with a
horizontal line and a vertical line in the bottom right corner.  It
looks like a badly scaled plot about 25 times the size of the plotting
area, so only a fragment is visible.

This is the code I've tried:

---
title: "Barking up the wrong tree"
author: "Patrick Connolly"
date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
output: ioslides_presentation
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(tidy=TRUE,
                      warning=FALSE, 
                      message=FALSE,
                      cache=FALSE,
                      dpi=600)
```

```{r use these functions, echo= FALSE}
  load(".RData") ## code for 6 plotting functions

``
## 6 different Trees

```{r 6 different Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}

###  par(mfrow = c(2, 3))
plot1()
plot2()
plot3()
plot4()
plot5()
plot6()
}
```

If I run the plot functions in the Console, it all works and displays
correctly in Rstudiio's plot panel, even the mfrow bit.  But I haven't
worked out how to include the code into Rmarkdown.  I thought it might
be less taxing to not try putting the 6 plots on the same slide, but
it makes no difference when I commented out the mfrow bit.

I'm not very familiar with the workings of Markdown or Rstudio, but it
does seem strange to me that I need to specifically load the global
environment otherwise it's not visible.  Is that to be expected?

Ideas welcome, particularly about scaling.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Aug 23 12:57:35 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 23 Aug 2018 22:57:35 +1200
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
Message-ID: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>


I *think* that this is an R question (and *not* an RStudio question!)

I have, somewhat against my better judgement, decided to experiment with 
using RStudio.

I downloaded and install RStudio.  Easy-peasy.  Nice lucid instructions.

Then I tried to start RStudio ("rstudio" from the command line)
and got a pop-up window with the error message:

> R shared library (/usr/lib64/R/lib/libR.so) not found. If this
> is a custom build of R, was it built with the --enable-R-shlib option?

Oops, no, I guess it wasn't.  So I carefully did a

     sudo make uninstall
     make clean
     make distclean

and then did

     ./R-3.5.1/configure <various flags>

making sure I added the --enable-R-shlib flag.

Then I did make and sudo make install. It all seemed to go ...
but then I did

     rstudio

again and got the same popup error.

There is indeed *no* libR.so in /usr/lib64/R/lib.

There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals that 
it dates from the my previous install of R-3.5.1 for which I *did not* 
configure with --enable-R-shlib.

Can anyone explain to me WTF is going on?

What should I do?  Just make a symbolic link from /usr/lib/R/lib/libR.so 
to /usr/lib64/R/lib/libR.so?

It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
most recent install of R.

I plead for enlightenment.

cheers,

Rolf Turner

P.S. I'm running Ubuntu 18.04.  And the previous install of R was done 
under Ubuntu 18.04.

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From jttk|m @end|ng |rom goog|em@||@com  Thu Aug 23 13:09:46 2018
From: jttk|m @end|ng |rom goog|em@||@com (Jan T Kim)
Date: Thu, 23 Aug 2018 12:09:46 +0100
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
Message-ID: <20180823110945.GS26688@paftolwp3a>

Hi Rolf & All,

I haven't built R in a while, but my general expectation of an
autotools based build & install would be that the default prefix
is /usr/local, rather than /usr. So I'd expect the shared libs
in /usr/local/lib, /usr/local/lib64 etc.

I also have a recollection that I once installed Rstudio for some
MOOC, and ended up putting a symlink in somewhere like /usr/lib* ,
because Rstudio was only available as a binary with the location
of the shared lib hard-baked into it.

Depending on your <various flags> this may be irrelevant, apologies
in that case.

Best regards, Jan


On Thu, Aug 23, 2018 at 10:57:35PM +1200, Rolf Turner wrote:
> 
> I *think* that this is an R question (and *not* an RStudio question!)
> 
> I have, somewhat against my better judgement, decided to experiment with
> using RStudio.
> 
> I downloaded and install RStudio.  Easy-peasy.  Nice lucid instructions.
> 
> Then I tried to start RStudio ("rstudio" from the command line)
> and got a pop-up window with the error message:
> 
> >R shared library (/usr/lib64/R/lib/libR.so) not found. If this
> >is a custom build of R, was it built with the --enable-R-shlib option?
> 
> Oops, no, I guess it wasn't.  So I carefully did a
> 
>     sudo make uninstall
>     make clean
>     make distclean
> 
> and then did
> 
>     ./R-3.5.1/configure <various flags>
> 
> making sure I added the --enable-R-shlib flag.
> 
> Then I did make and sudo make install. It all seemed to go ...
> but then I did
> 
>     rstudio
> 
> again and got the same popup error.
> 
> There is indeed *no* libR.so in /usr/lib64/R/lib.
> 
> There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals that it
> dates from the my previous install of R-3.5.1 for which I *did not*
> configure with --enable-R-shlib.
> 
> Can anyone explain to me WTF is going on?
> 
> What should I do?  Just make a symbolic link from /usr/lib/R/lib/libR.so to
> /usr/lib64/R/lib/libR.so?
> 
> It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
> most recent install of R.
> 
> I plead for enlightenment.
> 
> cheers,
> 
> Rolf Turner
> 
> P.S. I'm running Ubuntu 18.04.  And the previous install of R was done under
> Ubuntu 18.04.
> 
> R. T.
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Aug 23 13:34:38 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 23 Aug 2018 23:34:38 +1200
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <20180823110945.GS26688@paftolwp3a>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <20180823110945.GS26688@paftolwp3a>
Message-ID: <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>


On 08/23/2018 11:09 PM, Jan T Kim via R-help wrote:

> Hi Rolf & All,
> 
> I haven't built R in a while, but my general expectation of an
> autotools based build & install would be that the default prefix
> is /usr/local, rather than /usr. So I'd expect the shared libs
> in /usr/local/lib, /usr/local/lib64 etc.

I guess I should have said --- I did

     sudo make prefix=/usr install

which puts stuff into /usr rather than into /usr/local.

I forget exactly why I chose (in the dim distant past) to do this ...
I have a vague recollection that my search path was more "comfortable" 
that way.

> I also have a recollection that I once installed Rstudio for some
> MOOC, and ended up putting a symlink in somewhere like /usr/lib* ,
> because Rstudio was only available as a binary with the location
> of the shared lib hard-baked into it.

So it looks like a symlink might be the answer for me.

I would still like to know why /usr/lib/R/lib/libR.so was not refreshed 
on the most recent build, but.

> Depending on your <various flags> this may be irrelevant, apologies
> in that case.

Not to worry.  Thanks for taking an interest.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From berw|n@tur|@ch @end|ng |rom gm@||@com  Thu Aug 23 16:04:42 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Thu, 23 Aug 2018 22:04:42 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
Message-ID: <20180823220442.3370298d@absentia>

G'day Rolf,

On Thu, 23 Aug 2018 22:57:35 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> I *think* that this is an R question (and *not* an RStudio question!)

Others may disagree... :)

> I have, somewhat against my better judgement, decided to experiment
> with using RStudio.

Very good if you are still involved with teaching and need to use the
same environment as your student...  or want to try some new IDE...

If you have a good set-up that works for you, a bit more difficult to
see why you want to change...  RStudio's editor  allegedly has an Emacs
style but I find that style more confusing than helpful... half of the
short-cuts do not seem to work...  

But it is a nice IDE...

> Then I tried to start RStudio ("rstudio" from the command line)
> and got a pop-up window with the error message:
> 
> > R shared library (/usr/lib64/R/lib/libR.so) not found. If this
> > is a custom build of R, was it built with the --enable-R-shlib
> > option?  

Yes, I regularly got that too, until I changed my R installation
scripts ....
 
> Oops, no, I guess it wasn't.  So I carefully did a
> 
>      sudo make uninstall
>      make clean
>      make distclean

To bad that you did this.  There should have been a file called
"config.log" in that directory, and the top lines of that file would
have told you with which option ./configure was called, in particular
whether you had used the --enable-R-shlib flag.

> and then did
> 
>      ./R-3.5.1/configure <various flags>
> 
> making sure I added the --enable-R-shlib flag.

Well, some of the other flags might also be important...

> Then I did make and sudo make install. It all seemed to go ...
> but then I did
> 
>      rstudio
> 
> again and got the same popup error.
> 
> There is indeed *no* libR.so in /usr/lib64/R/lib.

I wonder why rstudio tries to look into /usr/lib64.  AFAICT, rstudio
queries the R that it uses for its home directory and then expects
libR.so to be at a specific location relative to this home directory.
And it expects that the installation does not use sub-architectures,
that is what tripped me up.  

> There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals
> that it dates from the my previous install of R-3.5.1 for which I
> *did not* configure with --enable-R-shlib.

Are you sure?  I am running Ubuntu 18.04 too.  My system
has /usr/lib/libR.so and /usr/lib/R/lib/libR.so, with the former being
a link to the latter.  And these were installed via `r-base-core` which
seems to be a requirement for `ess`.  (The long list of `ess` on
Ubuntu, together with its insistence of installing r-base-core and a
whole bunch of r-cran-* package is IMHO ridiculous.   Nearly bad enough
to make me consider installing ESS from source again.)

So the /usr/lib/R/lib/libR.so could be from r-base-core (if you somehow
installed that package).

Obviously you have sudo rights on your machine, so I would suggest to
try:
	sudo updatedb
	locate libR.so
To see how many libR.so you have installed and where they are
 
> Can anyone explain to me WTF is going on?

Not with much more information, e.g. what those "<various flags>"
to .configure were.  

Also, the great strength of unix system is that you can influence the
behaviour of programs via system variables...  unfortunately that is
also one of its greatest weaknesses when it comes to finding out why
programs do not behaved the way you expect them to work.  Some stray
environment variable might cause all this problem.

> What should I do?  Just make a symbolic link
> from /usr/lib/R/lib/libR.so to /usr/lib64/R/lib/libR.so?

I would not recommend this.  If this file is from another installation,
you are just asking for trouble down the road, which would then be even
harder to debug.

> It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
> most recent install of R.

Me too.  But I think you should never install to this location in the
first place.  AFAICT, /usr/lib/R/lib/libR.so is installed by
r-core-base, so if you install your own version there and then a
"apt-get update" updates r-core-base, you will end up with a broken
system.   

I learned the hard way long time ago not to install any software in
areas where Ubuntu packages are installed.  I restrict myself to
install to /usr/local or /opt (with /opt often being on a separate
partition so that material installed there survive if I have to
install/upgrade Ubuntu from scratch).

> I plead for enlightenment.

Not sure whether my comments were very helpful.  But you should
probably find out why your custom installed version of R tells RStudio
to look at /usr/lib64. A "locate libR.pc" could be helpful.  on my
system this returns /usr/lib/pkgconfig/libR.pc (from r-base-core)
and /opt/R/R-3.5.1/lib/pkgconfig/libR.pc (my installation from source).

Cheers,

	Berwin



From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug 23 16:22:35 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 23 Aug 2018 07:22:35 -0700
Subject: [R] Unclear about the output from summary of ca.jo from package
 urca
In-Reply-To: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
References: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
Message-ID: <CAGxFJbTmbYTq_ybXXpbQmvk-N2DZ58KcLmy_T+rTdZ+y5KxoXQ@mail.gmail.com>

This is about statistics , not R programming, and so is off topic here.
Your first port of call for this sort of thing should be the package docs,
**including any references** . There are references given. Have you studied
them??

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 23, 2018 at 2:12 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> I am not sure about the summary of the function ca.jo. I have posted my
> query here :-
>
>
> https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r
>
> I did not receive any reply so I am posting my query here.
>
> Many thanks and best regards,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Aug 23 16:23:32 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 23 Aug 2018 07:23:32 -0700
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180823091519.GB13179@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
Message-ID: <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>

This is not reproducible because you have not provided the plot code or sample data. Output of sessionInfo would probably be appropriate as well.

As to whether needing to load objects is typical... yes, rmarkdown runs from a fresh environment to emphasize reproducibility, but your load command is bypassing that for us.

On August 23, 2018 2:15:19 AM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>I'm having difficulty getting plots into ioslides.  It seems to me
>that the scale is completely out, but I can't figure out what to do
>about it.  Whatever I try, I get the title slide, then a second with a
>horizontal line and a vertical line in the bottom right corner.  It
>looks like a badly scaled plot about 25 times the size of the plotting
>area, so only a fragment is visible.
>
>This is the code I've tried:
>
>---
>title: "Barking up the wrong tree"
>author: "Patrick Connolly"
>date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
>output: ioslides_presentation
>---
>
>```{r global_options, echo=FALSE}
>knitr::opts_chunk$set(tidy=TRUE,
>                      warning=FALSE, 
>                      message=FALSE,
>                      cache=FALSE,
>                      dpi=600)
>```
>
>```{r use these functions, echo= FALSE}
>  load(".RData") ## code for 6 plotting functions
>
>``
>## 6 different Trees
>
>```{r 6 different Trees, echo = FALSE, messages=FALSE, fig.width = 7,
>fig.height = 5}
>
>###  par(mfrow = c(2, 3))
>plot1()
>plot2()
>plot3()
>plot4()
>plot5()
>plot6()
>}
>```
>
>If I run the plot functions in the Console, it all works and displays
>correctly in Rstudiio's plot panel, even the mfrow bit.  But I haven't
>worked out how to include the code into Rmarkdown.  I thought it might
>be less taxing to not try putting the 6 plots on the same slide, but
>it makes no difference when I commented out the mfrow bit.
>
>I'm not very familiar with the workings of Markdown or Rstudio, but it
>does seem strange to me that I need to specifically load the global
>environment otherwise it's not visible.  Is that to be expected?
>
>Ideas welcome, particularly about scaling.

-- 
Sent from my phone. Please excuse my brevity.



From berw|n@tur|@ch @end|ng |rom gm@||@com  Thu Aug 23 16:26:42 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Thu, 23 Aug 2018 22:26:42 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <20180823110945.GS26688@paftolwp3a>
 <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>
Message-ID: <20180823222642.65d6cf1f@absentia>

G'day Rolf,

On Thu, 23 Aug 2018 23:34:38 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> I guess I should have said --- I did
> 
>      sudo make prefix=/usr install
> 
> which puts stuff into /usr rather than into /usr/local.

???

I do not remember ever specifying "prefix=foo" at the make install
stage.  Not for any software that uses autoconf &c.

I thought the prefix should be specified to ./configure and after that
just
	make
	make check
	make install

I am pretty sure that the location of RHOME is set by the path
specified (explicitly or implicitly) to ./configure.  If you then
install R at another location with your construct, some problems seem
to be pre-programmed.  But I could be wrong.
 
> I forget exactly why I chose (in the dim distant past) to do this ...
> I have a vague recollection that my search path was more
> "comfortable" that way.

In my experience this is a false comfort.  Set the search path so
that /opt/bin or /usr/local/bin is early on and finds programs you
install to those location.  

Installing to /usr will sooner or later lead to tears if your program
"conflicts" with some Ubuntu package (which might have been installed
to satisfy the requirement of another package that you needed).  If
that package is update during an "apt-get update", you can end up with
a broken system.  
 
> > I also have a recollection that I once installed Rstudio for some
> > MOOC, and ended up putting a symlink in somewhere like /usr/lib* ,
> > because Rstudio was only available as a binary with the location
> > of the shared lib hard-baked into it.  

The location is only hard-coded in relation to RHOME and with the
assumption that you are not using a sub-architecture on Ubuntu.  AFAIK,
binary Ubuntu distributions of R do not use sub-architectures and there
should be no problem on an Ubuntu system as long as all software is
installed via Ubuntu.  But this is probably a question better discussed
on r-sig-Debian

> So it looks like a symlink might be the answer for me.

Only if you can be sure that that libR.so is compatible with the R
version that you seem to be using.  The official r-base-core package
from Ubuntu seems to be R 3.4.4.  If you added the CRAN repository to
your Ubuntu system, you might have a newer version installed.  But if
your installation is partly a self-compiled R-3.5.1 version that is
then linked to an R 3.4.4 libR.so in /usr/lib/R/lib/ (from
r-cran-base), you are inviting trouble.

Cheers,

	Berwin



From peter@|@ng|e|der @end|ng |rom gm@||@com  Thu Aug 23 17:45:37 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 23 Aug 2018 08:45:37 -0700
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <20180823222642.65d6cf1f@absentia>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <20180823110945.GS26688@paftolwp3a>
 <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>
 <20180823222642.65d6cf1f@absentia>
Message-ID: <CA+hbrhX+YvWPAFSJUwgfBsM5YCq1k5ezTtr6OqxaEm7iNMTQLg@mail.gmail.com>

On Thu, Aug 23, 2018 at 7:33 AM Berwin A Turlach
<berwin.turlach at gmail.com> wrote:
>
> G'day Rolf,
>
> On Thu, 23 Aug 2018 23:34:38 +1200
> Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> > I guess I should have said --- I did
> >
> >      sudo make prefix=/usr install
> >
> > which puts stuff into /usr rather than into /usr/local.
>
> ???
>
> I do not remember ever specifying "prefix=foo" at the make install
> stage.  Not for any software that uses autoconf &c.
>
> I thought the prefix should be specified to ./configure and after that
> just
>         make
>         make check
>         make install
>
> I am pretty sure that the location of RHOME is set by the path
> specified (explicitly or implicitly) to ./configure.  If you then
> install R at another location with your construct, some problems seem
> to be pre-programmed.  But I could be wrong.

The manual, specifically

https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installation

documents this way of choosing the installation directory.

Peter



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Aug 24 04:38:56 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 23 Aug 2018 21:38:56 -0500
Subject: [R] How to add a geom_smooth() line
Message-ID: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>

R-help

 

I want to add two smooth lines (geom_smooth()) for each scatter plot.  How
do I do that?

 

ggplot() +

  geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +

  geom_point(data=data, aes(x=timeline, y=launches), color="red") +

  xlab("Deliveries") +

  ylab("Launches") +

  ggtitle("Scatterplot of Launches vs. Deliveries")

 

Jeff


	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug 24 06:08:57 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 24 Aug 2018 05:08:57 +0100
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
Message-ID: <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>

Hello,

The trick is to reshape your data from wide to long format.
There are many ways to do this, I will use package reshape2.

Make up a dataset:


library(ggplot2)
library(reshape2)

set.seed(9773)
n <- 20
data <- data.frame(timeline = 1:n,
                    deliveries = log(1:n) + runif(n),
                    launches = (1:n)/4 + runif(n))

# reformat it
long <- melt(data, id.vars = "timeline")
head(long)

# et voila!
ggplot(long, aes(timeline, value, colour = variable)) +
     geom_point() +
     stat_smooth() +
     xlab("Deliveries") +
     ylab("Launches") +
     ggtitle("Scatterplot of Launches vs. Deliveries")


Use the smoothing function of your choice, I left it with the default loess.

Hope this helps,

Rui Barradas


On 24/08/2018 03:38, Jeff Reichman wrote:
> R-help
> 
>   
> 
> I want to add two smooth lines (geom_smooth()) for each scatter plot.  How
> do I do that?
> 
>   
> 
> ggplot() +
> 
>    geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +
> 
>    geom_point(data=data, aes(x=timeline, y=launches), color="red") +
> 
>    xlab("Deliveries") +
> 
>    ylab("Launches") +
> 
>    ggtitle("Scatterplot of Launches vs. Deliveries")
> 
>   
> 
> Jeff
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug 24 06:14:13 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 24 Aug 2018 05:14:13 +0100
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
 <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>
Message-ID: <68d972be-c638-5f39-4873-2a2c8c8447d2@sapo.pt>

Sorry, should be geom_smooth, not stat_smooth. They both work the same 
way or very close to it.

Rui Barradas

On 24/08/2018 05:08, Rui Barradas wrote:
> Hello,
> 
> The trick is to reshape your data from wide to long format.
> There are many ways to do this, I will use package reshape2.
> 
> Make up a dataset:
> 
> 
> library(ggplot2)
> library(reshape2)
> 
> set.seed(9773)
> n <- 20
> data <- data.frame(timeline = 1:n,
>  ?????????????????? deliveries = log(1:n) + runif(n),
>  ?????????????????? launches = (1:n)/4 + runif(n))
> 
> # reformat it
> long <- melt(data, id.vars = "timeline")
> head(long)
> 
> # et voila!
> ggplot(long, aes(timeline, value, colour = variable)) +
>  ??? geom_point() +
>  ??? stat_smooth() +
>  ??? xlab("Deliveries") +
>  ??? ylab("Launches") +
>  ??? ggtitle("Scatterplot of Launches vs. Deliveries")
> 
> 
> Use the smoothing function of your choice, I left it with the default 
> loess.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> On 24/08/2018 03:38, Jeff Reichman wrote:
>> R-help
>>
>>
>> I want to add two smooth lines (geom_smooth()) for each scatter plot.  
>> How
>> do I do that?
>>
>>
>> ggplot() +
>>
>> ?? geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +
>>
>> ?? geom_point(data=data, aes(x=timeline, y=launches), color="red") +
>>
>> ?? xlab("Deliveries") +
>>
>> ?? ylab("Launches") +
>>
>> ?? ggtitle("Scatterplot of Launches vs. Deliveries")
>>
>>
>> Jeff
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug 24 06:31:30 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 24 Aug 2018 05:31:30 +0100
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
 <bfdbe92c-a2ff-0709-5bfe-ebabf9800f05@sapo.pt>
Message-ID: <dc9ef8f9-ab78-f882-d442-a514ddd3931e@sapo.pt>

Hello,

if you want to fit different models to each of deliveries and launches, 
use the wide format instead:


ggplot(data = data, aes(x = timeline)) +
   geom_point(aes(y = deliveries), color = "blue") +
   geom_smooth(aes(y = deliveries), color = "blue", method = lm, formula 
= y ~ log(x)) +
   geom_point(aes(y = launches), color = "red") +
   geom_smooth(aes(y = launches), color = "red", method = lm, formula = 
y ~ x) +
   xlab("Deliveries") +
   ylab("Launches") +
   ggtitle("Scatterplot of Launches vs. Deliveries")


Hope this helps,

Rui Barradas

On 24/08/2018 05:08, Rui Barradas wrote:
> Hello,
> 
> The trick is to reshape your data from wide to long format.
> There are many ways to do this, I will use package reshape2.
> 
> Make up a dataset:
> 
> 
> library(ggplot2)
> library(reshape2)
> 
> set.seed(9773)
> n <- 20
> data <- data.frame(timeline = 1:n,
>  ?????????????????? deliveries = log(1:n) + runif(n),
>  ?????????????????? launches = (1:n)/4 + runif(n))
> 
> # reformat it
> long <- melt(data, id.vars = "timeline")
> head(long)
> 
> # et voila!
> ggplot(long, aes(timeline, value, colour = variable)) +
>  ??? geom_point() +
>  ??? stat_smooth() +
>  ??? xlab("Deliveries") +
>  ??? ylab("Launches") +
>  ??? ggtitle("Scatterplot of Launches vs. Deliveries")
> 
> 
> Use the smoothing function of your choice, I left it with the default 
> loess.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> On 24/08/2018 03:38, Jeff Reichman wrote:
>> R-help
>>
>>
>> I want to add two smooth lines (geom_smooth()) for each scatter plot.  
>> How
>> do I do that?
>>
>>
>> ggplot() +
>>
>> ?? geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +
>>
>> ?? geom_point(data=data, aes(x=timeline, y=launches), color="red") +
>>
>> ?? xlab("Deliveries") +
>>
>> ?? ylab("Launches") +
>>
>> ?? ggtitle("Scatterplot of Launches vs. Deliveries")
>>
>>
>> Jeff
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @u@@n@e||@@ @end|ng |rom m@|ne@edu  Fri Aug 24 00:09:47 2018
From: @u@@n@e||@@ @end|ng |rom m@|ne@edu (Susan Elias)
Date: Thu, 23 Aug 2018 18:09:47 -0400
Subject: [R] How does Markov random field (bs=mrf) in mgvc gam handle
 repeated measures on the spatial units?
Message-ID: <CAKXsTQPROq=Gv5-ZGNCR1DZb1wgbrV5ErgvOkFjOB0QZR8MExw@mail.gmail.com>

Hello R,

I am attempting a spatio-temporal model in mgcv gam.

I am using a factor smooth to define each of 27 areal units in a shapefile
("id") as subjects (essentially) which have undergone 23 repeated
measurements in time ("year").

I am using the Markov random field to define the neighbor relationships of
the area units.

I have combed through Wood (2017) and other resources and have not found an
answer to my question, which is: how is the mrf handling the repeated
measures?  My model is:

model<-gam(response) ~ s(year) +
                       ti(year,id, bs="fs", m=1) +
                       s(id, bs = 'mrf', xt = list(nb = neighbors), k=5),
                       family=tw(), data=data)

Susan

	[[alternative HTML version deleted]]



From r||ey||nn3 @end|ng |rom gm@||@com  Fri Aug 24 05:23:40 2018
From: r||ey||nn3 @end|ng |rom gm@||@com (Riley Finn)
Date: Thu, 23 Aug 2018 22:23:40 -0500
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
Message-ID: <CAKg3cnLp2G51HyfS_zoqjcX__yoiJ=6NCqmbraphpOa5LagQKA@mail.gmail.com>

Jeff,

You need to reshape your data frame.  If you use ggplot, you will often
have to present your data in "long format"

Use the reshape2 package.

I made a sample data frame because you didn't provide one.  I also change
your x and y labels because they made no sense.

data <- data.frame(
  timeline = 1:10,
  launches = sample(10:20, 10),
  deliveries = sample(10:20, 10)
)

library(reshape2)
dataNew <- melt(data = data, id.vars = 'timeline',
                variable.name = 'launchOrDelivery')

ggplot(data=dataNew, aes(x=timeline, y=value), color= launchOrDelivery) +
  geom_point(aes(color= launchOrDelivery)) +
  geom_smooth(aes(group = launchOrDelivery, color= launchOrDelivery), se =
FALSE) +
  xlab("timeline") +
  ylab("Launches/Deliveries") +
  ggtitle("Scatterplot of Launches vs. Deliveries")


On Thu, Aug 23, 2018 at 9:39 PM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-help
>
>
>
> I want to add two smooth lines (geom_smooth()) for each scatter plot.  How
> do I do that?
>
>
>
> ggplot() +
>
>   geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +
>
>   geom_point(data=data, aes(x=timeline, y=launches), color="red") +
>
>   xlab("Deliveries") +
>
>   ylab("Launches") +
>
>   ggtitle("Scatterplot of Launches vs. Deliveries")
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From berw|n@tur|@ch @end|ng |rom gm@||@com  Fri Aug 24 11:27:40 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Fri, 24 Aug 2018 17:27:40 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <CA+hbrhX+YvWPAFSJUwgfBsM5YCq1k5ezTtr6OqxaEm7iNMTQLg@mail.gmail.com>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <20180823110945.GS26688@paftolwp3a>
 <ca201f40-a595-988f-737f-804452c357c5@auckland.ac.nz>
 <20180823222642.65d6cf1f@absentia>
 <CA+hbrhX+YvWPAFSJUwgfBsM5YCq1k5ezTtr6OqxaEm7iNMTQLg@mail.gmail.com>
Message-ID: <20180824172740.62fad478@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Peter,

On Thu, 23 Aug 2018 08:45:37 -0700
Peter Langfelder <peter.langfelder at gmail.com> wrote:

> The manual, specifically
> 
> https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installation
> 
> documents this way of choosing the installation directory.

Yes, with the caveat that one needs GNU or Solaris make (which would be
the case on Ubuntu).  So it is hardly the recommended way.  

As I read the R Administration Manual, the recommended way is to specify
the location at which you want to install R via ./configure.

Cheers,

	Berwin



From @@h|mk@poor @end|ng |rom gm@||@com  Fri Aug 24 11:31:12 2018
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Fri, 24 Aug 2018 15:01:12 +0530
Subject: [R] Unclear about the output from summary of ca.jo from package
 urca
In-Reply-To: <CAGxFJbTmbYTq_ybXXpbQmvk-N2DZ58KcLmy_T+rTdZ+y5KxoXQ@mail.gmail.com>
References: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
 <CAGxFJbTmbYTq_ybXXpbQmvk-N2DZ58KcLmy_T+rTdZ+y5KxoXQ@mail.gmail.com>
Message-ID: <CAC8=1erwNmOW0YBqLag+rr71gZVN-4TkTNNT3Nw7=HfuJbZ-rg@mail.gmail.com>

Dear Bert,

I have read some of the references. I do understand what the 2 matrices(
the cointegrating relationships and the alpha / loading matrix which gives
the speed of the mean reversion)  are. What I do not understand is the
format of the output of the package. My main query is that why do we have
.l2 in the cointegrating relationships. They are contemporaneous
relationships , they should not have .l2 in the end. That's my query.

Many thanks,
Ashim

On Thu, Aug 23, 2018 at 7:52 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> This is about statistics , not R programming, and so is off topic here.
> Your first port of call for this sort of thing should be the package docs,
> **including any references** . There are references given. Have you studied
> them??
>
> Cheers,
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Aug 23, 2018 at 2:12 AM Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I am not sure about the summary of the function ca.jo. I have posted my
>> query here :-
>>
>>
>> https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r
>>
>> I did not receive any reply so I am posting my query here.
>>
>> Many thanks and best regards,
>> Ashim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Fri Aug 24 12:02:59 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 24 Aug 2018 12:02:59 +0200
Subject: [R] Unclear about the output from summary of ca.jo from package
 urca
In-Reply-To: <CAC8=1erwNmOW0YBqLag+rr71gZVN-4TkTNNT3Nw7=HfuJbZ-rg@mail.gmail.com>
References: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
 <CAGxFJbTmbYTq_ybXXpbQmvk-N2DZ58KcLmy_T+rTdZ+y5KxoXQ@mail.gmail.com>
 <CAC8=1erwNmOW0YBqLag+rr71gZVN-4TkTNNT3Nw7=HfuJbZ-rg@mail.gmail.com>
Message-ID: <83C9E217-B785-4226-A9D3-BA2CA52F1BCE@gmail.com>

Well, reading the code is not much harder than reading the papers (not that that helps much, been there...)

I don't actually know the answer, but the notation comes from this bit in ca.jo():

        if (spec == "longrun") {
            ZK <- cbind(x[-c((N - K + 1):N), ], 1)
            Lnotation <- K
        }
        else if (spec == "transitory") {
            ZK <- cbind(x[-N, ], 1)[K:(N - 1), ]
            Lnotation <- 1
        }
        colnames(ZK) <- c(paste(colnames(x), ".l", Lnotation, 
            sep = ""), "constant")

(actually there are several such bits). 

K=2 by default, so you get .l2 for the "longrun" spec and ".l1" for "transitory". So I would guess that studying the two specification formats from the help page might give the solution to the riddle eventually.

(Another issue is that the column names are clearly rubbish, only the row names make sense. The columns are eigenvectors sorted by eigenvalues which has no relation to the input columns. Presumably, they are just an artifact of the matrix operations.)

-pd

> On 24 Aug 2018, at 11:31 , Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> 
> Dear Bert,
> 
> I have read some of the references. I do understand what the 2 matrices(
> the cointegrating relationships and the alpha / loading matrix which gives
> the speed of the mean reversion)  are. What I do not understand is the
> format of the output of the package. My main query is that why do we have
> .l2 in the cointegrating relationships. They are contemporaneous
> relationships , they should not have .l2 in the end. That's my query.
> 
> Many thanks,
> Ashim
> 
> On Thu, Aug 23, 2018 at 7:52 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> This is about statistics , not R programming, and so is off topic here.
>> Your first port of call for this sort of thing should be the package docs,
>> **including any references** . There are references given. Have you studied
>> them??
>> 
>> Cheers,
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Aug 23, 2018 at 2:12 AM Ashim Kapoor <ashimkapoor at gmail.com>
>> wrote:
>> 
>>> Dear All,
>>> 
>>> I am not sure about the summary of the function ca.jo. I have posted my
>>> query here :-
>>> 
>>> 
>>> https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r
>>> 
>>> I did not receive any reply so I am posting my query here.
>>> 
>>> Many thanks and best regards,
>>> Ashim
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From co|@v|ttor|o @end|ng |rom v|rg|||o@|t  Fri Aug 24 12:29:01 2018
From: co|@v|ttor|o @end|ng |rom v|rg|||o@|t (Vittorio Colagrande)
Date: Fri, 24 Aug 2018 12:29:01 +0200
Subject: [R] Algorithm Net Analyte Signal (NAS) in R
Message-ID: <FF1D1AD17EF54C9D938E44CEDDD198C2@user8a7c344e2a>

 Dear R-group
I would like to ask a possible algorithm in R and related documetation for 

the development of analysis "Net Analyte Signal" (NAS) in order to solve 

of problem of spectral interference in Analytical Chemistry. 

 

I will greatly appreciate any clarification you could provide.

Best regards.

Vittorio Colagrande
	[[alternative HTML version deleted]]



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Aug 24 13:44:05 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Fri, 24 Aug 2018 06:44:05 -0500
Subject: [R] How to add a geom_smooth() line
In-Reply-To: <CAKg3cnLp2G51HyfS_zoqjcX__yoiJ=6NCqmbraphpOa5LagQKA@mail.gmail.com>
References: <001201d43b53$9bc30280$d3490780$@sbcglobal.net>
 <CAKg3cnLp2G51HyfS_zoqjcX__yoiJ=6NCqmbraphpOa5LagQKA@mail.gmail.com>
Message-ID: <000601d43b9f$c35cba60$4a162f20$@sbcglobal.net>

Got it thank you

 

From: Riley Finn <rileyfinn3 at gmail.com> 
Sent: Thursday, August 23, 2018 10:24 PM
To: reichmanj at sbcglobal.net
Cc: R-help at r-project.org
Subject: Re: [R] How to add a geom_smooth() line

 

Jeff,

 

You need to reshape your data frame.  If you use ggplot, you will often have to present your data in "long format"

 

Use the reshape2 package.

 

I made a sample data frame because you didn't provide one.  I also change your x and y labels because they made no sense.  

 

data <- data.frame(
  timeline = 1:10,
  launches = sample(10:20, 10),
  deliveries = sample(10:20, 10)
)

library(reshape2)
dataNew <- melt(data = data, id.vars = 'timeline', 
                variable.name <http://variable.name>  = 'launchOrDelivery')

ggplot(data=dataNew, aes(x=timeline, y=value), color= launchOrDelivery) +
  geom_point(aes(color= launchOrDelivery)) + 
  geom_smooth(aes(group = launchOrDelivery, color= launchOrDelivery), se = FALSE) + 
  xlab("timeline") +
  ylab("Launches/Deliveries") +
  ggtitle("Scatterplot of Launches vs. Deliveries")

 

On Thu, Aug 23, 2018 at 9:39 PM Jeff Reichman <reichmanj at sbcglobalnet <mailto:reichmanj at sbcglobal.net> > wrote:

R-help



I want to add two smooth lines (geom_smooth()) for each scatter plot.  How
do I do that?



ggplot() +

  geom_point(data=data, aes(x=timeline, y=deliveries), color="blue") +

  geom_point(data=data, aes(x=timeline, y=launches), color="red") +

  xlab("Deliveries") +

  ylab("Launches") +

  ggtitle("Scatterplot of Launches vs. Deliveries")



Jeff


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]



From |@t@z@hn @end|ng |rom gm@||@com  Fri Aug 24 15:10:34 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Fri, 24 Aug 2018 09:10:34 -0400
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
Message-ID: <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>

On Thu, Aug 23, 2018 at 6:57 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> I *think* that this is an R question (and *not* an RStudio question!)

I think this is actually and Ubuntu question, and probably belongs on
R-sig-debian.

>
> I have, somewhat against my better judgement, decided to experiment with
> using RStudio.
>
> I downloaded and install RStudio.  Easy-peasy.  Nice lucid instructions.
>
> Then I tried to start RStudio ("rstudio" from the command line)
> and got a pop-up window with the error message:
>
> > R shared library (/usr/lib64/R/lib/libR.so) not found. If this
> > is a custom build of R, was it built with the --enable-R-shlib option?
>
> Oops, no, I guess it wasn't.  So I carefully did a
>
>      sudo make uninstall
>      make clean
>      make distclean
>
> and then did
>
>      ./R-3.5.1/configure <various flags>
>
> making sure I added the --enable-R-shlib flag.
>
> Then I did make and sudo make install.

IMO if you are compiling and installing software yourself on Linux
your are Doing It Wrong. Use the package manager, that is what it is
there for.

--Ista

It all seemed to go ...
> but then I did
>
>      rstudio
>
> again and got the same popup error.
>
> There is indeed *no* libR.so in /usr/lib64/R/lib.
>
> There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals that
> it dates from the my previous install of R-3.5.1 for which I *did not*
> configure with --enable-R-shlib.
>
> Can anyone explain to me WTF is going on?
>
> What should I do?  Just make a symbolic link from /usr/lib/R/lib/libR.so
> to /usr/lib64/R/lib/libR.so?
>
> It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
> most recent install of R.
>
> I plead for enlightenment.
>
> cheers,
>
> Rolf Turner
>
> P.S. I'm running Ubuntu 18.04.  And the previous install of R was done
> under Ubuntu 18.04.
>
> R. T.
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Fri Aug 24 15:12:16 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Fri, 24 Aug 2018 18:42:16 +0530
Subject: [R] Cant schedule R job using taskscheduleR
Message-ID: <CA+dpOJ=RfRW0eSkvES2vCeR1AuQPrYwdMnwJThqqkvwYyB6Oig@mail.gmail.com>

Hi,

I am trying to schedule an R job using taskscheduler_create() function
available in package taskscheduleR.

Below is my code:

> library(taskscheduleR)
Warning message:
package ?taskscheduleR? was built under R version 3.5.1
> taskscheduler_create(taskname = "ABC", rscript = paste("C:\\ABC.R"),
startdate = format(Sys.Date() + 1, "%d/%m/%Y"), schedule = "WEEKLY",
starttime = "16:30", days = c("MON", "TUE", "WED", "THU", "FRI")[1])
[1] "ERROR: Incorrect Start Date."
attr(,"status")
[1] 16389
Warning message:
In system(cmd, intern = TRUE) :
  running command 'schtasks /Create /TN "ABC" /TR "cmd /c
C:/PROGRA~1/R/R-35~1.0/bin/Rscript.exe \"C:\ABC.R\"  >> \"C:\ABC.log\"
2>&1" /SC WEEKLY /ST 16:30 /SD "25/08/2018" /D MON ' had status 16389


However it fails with stating Incorrect Start Date.

Any help to understand what went wrong?

I am using R in Windows. Below is Session Information :

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
                 LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] taskscheduleR_1.1

loaded via a namespace (and not attached):
[1] compiler_3.5.0    tools_3.5.0       data.table_1.11.4

	[[alternative HTML version deleted]]



From deep@m@hm@||@c @end|ng |rom gm@||@com  Fri Aug 24 15:44:19 2018
From: deep@m@hm@||@c @end|ng |rom gm@||@com (Deepa)
Date: Fri, 24 Aug 2018 19:14:19 +0530
Subject: [R] Multiple counters in a single for loop
Message-ID: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>

Hello,

Is there an option to include multiple counters in a single for loop in R?

For instance, in python there is

for i,j in zip(x,range(0,len(x))):


Any suggestions?

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 24 16:53:10 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 24 Aug 2018 07:53:10 -0700
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180824101317.GC13179@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180824101317.GC13179@slingshot.co.nz>
Message-ID: <9B82F30C-FD82-42A1-97EC-52A9E79478F9@dcn.davis.ca.us>

a) Keep the mailing list in the conversation... someone else may have useful input, and others may benefit from reading the discussion.

b) If the issue can be reproduced on your end with something like a basic plot(mpg~disk, data=mtcars) call, then you should use that instead of your complicated example. If the problem only appears when you use certain plotting functions hidden inside your plot1 through plot6 functions, we can't tell that from here. Sorting that out is part of making your example minimal as the Posting Guide requests.

c) If you can only reproduce with certain data, then you can use dput to give us the necessary data.[1][2] It is up to you to determine what the minimal data needed to demo the problem is, but we don't want to sift through some large data blob only to find out that it was not relevant so you need to do that. 

d) Interactions with data files are hard to make reproducible on someone else's computer... saving data with different filenames will not help fix that problem.

e) Note that this is the R-help mailing list, not the RStudio-help mailing list nor the rmarkdown-package-help mailing list. We can and often do provide help on using contributed packages anyway, but you should be aware that not everyone here uses RStudio so doing your best to provide a reproducible example is in your interest if you want readers to consider your question on topic.

There are many discussions online of how to communicate R examples, such as [1][2][3]. In particular I think [3] is useful because it forces you to confirm that the example will run in a fresh R environment which is the first step to insuring it will run on our computers and we can dig into the problem. in this case you could use it to help confirm that your R code should work for us without the rmarkdown.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On August 24, 2018 3:13:17 AM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>On Thu, 23-Aug-2018 at 07:23AM -0700, Jeff Newmiller wrote:
>
>|> This is not reproducible because you have not provided the plot
>|> code or sample data. Output of sessionInfo would probably be
>|> appropriate as well.
>
>I took it as read that the plotting functions themselves aren't an
>issue since they operate as intended outside of the Rmarkdown
>space. Any function that uses the function plot() successfully will
>do.  I was trying to ascertain how I should be setting up the scaling.
>
>|> As to whether needing to load objects is typical... yes, rmarkdown
>|> runs from a fresh environment to emphasize reproducibility, but
>|> your load command is bypassing that for us.
>
>The objects loaded from .RData took hours of simulating and it's out
>of the question to run them again inside Rmarkdown.  Though the script
>used in the creation of .RData is reproducable, perhaps it would be
>clearer for me to have saved the objects to a file by a different
>name.
>
>Is there a better way to do that??
>
>
>
>|> On August 23, 2018 2:15:19 AM PDT, Patrick Connolly
><p_connolly at slingshot.co.nz> wrote:
>|> >I'm having difficulty getting plots into ioslides.  It seems to me
>|> >that the scale is completely out, but I can't figure out what to do
>|> >about it.  Whatever I try, I get the title slide, then a second
>with a
>|> >horizontal line and a vertical line in the bottom right corner.  It
>|> >looks like a badly scaled plot about 25 times the size of the
>plotting
>|> >area, so only a fragment is visible.
>|> >
>|> >This is the code I've tried:
>|> >
>|> >---
>|> >title: "Barking up the wrong tree"
>|> >author: "Patrick Connolly"
>|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
>|> >output: ioslides_presentation
>|> >---
>|> >
>|> >```{r global_options, echo=FALSE}
>|> >knitr::opts_chunk$set(tidy=TRUE,
>|> >                      warning=FALSE, 
>|> >                      message=FALSE,
>|> >                      cache=FALSE,
>|> >                      dpi=600)
>|> >```
>|> >
>|> >```{r use these functions, echo= FALSE}
>|> >  load(".RData") ## code for 6 plotting functions
>|> >
>|> >``
>|> >## 6 different Trees
>|> >
>|> >```{r 6 different Trees, echo = FALSE, messages=FALSE, fig.width =
>7,
>|> >fig.height = 5}
>|> >
>|> >###  par(mfrow = c(2, 3))
>|> >plot1()
>|> >plot2()
>|> >plot3()
>|> >plot4()
>|> >plot5()
>|> >plot6()
>|> >}
>|> >```
>|> >
>|> >If I run the plot functions in the Console, it all works and
>displays
>|> >correctly in Rstudiio's plot panel, even the mfrow bit.  But I
>haven't
>|> >worked out how to include the code into Rmarkdown.  I thought it
>might
>|> >be less taxing to not try putting the 6 plots on the same slide,
>but
>|> >it makes no difference when I commented out the mfrow bit.
>|> >
>|> >I'm not very familiar with the workings of Markdown or Rstudio, but
>it
>|> >does seem strange to me that I need to specifically load the global
>|> >environment otherwise it's not visible.  Is that to be expected?
>|> >
>|> >Ideas welcome, particularly about scaling.
>|> 
>|> -- 
>|> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 24 17:28:23 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Aug 2018 08:28:23 -0700
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
References: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
Message-ID: <CAGxFJbTUid_QqaVBBjMQGLiMDuRKpD1mPT-A-RAGjkyeddFm7g@mail.gmail.com>

Sort of, but you typically wouldn't need to in R because of vectorization,
which buries the iteration in the underlying C code. Here's an example that
may clarify what I mean:

x <- cbind(1:5,6:10)
x ## a 2 column matrix
## get squares of all elements of x
## method 1
m1 <-x^2

##method 2: square the column vectors
m2 <- x
for (i in 1:2)m2[,i] <- m2[,i]^2
identical(m1,m2)
## of course, one could do this by row vectors, too

## method 3: loop through each element
m3 <- x
ix <- as.matrix(expand.grid(1:5,1:2))
ix
m3[ix]^2 ## matrix indexing of an array. This produces a vector,though.

Note also that there is an "iterators" package in R which implements
python-like iterators.I don't know how efficient it is, however.

My overall advice would be that you should try to program in R's native
paradigms, which emphasize whole object manipulation through vectorization,
rather than trying to use Python's, especially if efficiency is a
consideration. Feel free to ignore of course.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 24, 2018 at 6:44 AM Deepa <deepamahm.iisc at gmail.com> wrote:

> Hello,
>
> Is there an option to include multiple counters in a single for loop in R?
>
> For instance, in python there is
>
> for i,j in zip(x,range(0,len(x))):
>
>
> Any suggestions?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Aug 24 18:00:13 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 24 Aug 2018 16:00:13 +0000
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
References: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
Message-ID: <D7431DA4-8E78-4175-A716-89E997BAD187@llnl.gov>

I don't know of any such option, but it's easy enough to achieve something more or less equivalent.

x <- runif(5)

for (ir in seq(nrow(myi <- cbind(x, 1:length(x))))) {
  i <- myi[ir,1]
  j <- myi[ir,2]
  cat(i,j,'\n')
}

I consider that for() statement to be ugly and unreadable. Normally I would build the matrix myi before constructing the loop, and make other changes for clarity. But in this instance I wanted to make it a one-liner, just to more or less mimic the python.

And having now read Bert's reply, he makes a good point. For many things one might want to do with such a loop, R can do them without an explicit loop.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/24/18, 6:44 AM, "R-help on behalf of Deepa" <r-help-bounces at r-project.org on behalf of deepamahm.iisc at gmail.com> wrote:

    Hello,
    
    Is there an option to include multiple counters in a single for loop in R?
    
    For instance, in python there is
    
    for i,j in zip(x,range(0,len(x))):
    
    
    Any suggestions?
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @m|t@c@03 @end|ng |rom gm@||@com  Fri Aug 24 18:34:29 2018
From: @m|t@c@03 @end|ng |rom gm@||@com (Amit Govil)
Date: Sat, 25 Aug 2018 00:34:29 +0800
Subject: [R] Need some help with data-wrangling in R
Message-ID: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>

Hi,

I have log data in which one of the columns have IP ranges and the next
column is corresponding ports. Eg:


IPRange Port
10.78.64.0-10.78.66.255 D, A, C

I need to expand the IPRange column into a list of network blocks till 3rd
octet:

IPRange IP Port
192.100.176.0-192.100.179.255 192.100.176.0/24 A, B, C
192.100.176.0-192.100.179.255 192.100.177.0/24 A, B, C
192.100.176.0-192.100.179.255 192.100.178.0/24 A, B, C
192.100.176.0-192.100.179.255 192.100.179.0/24 A, B, C

How do I do this data transformation in R?

Please assist.

Thanks
Amit

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 24 18:52:55 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Aug 2018 09:52:55 -0700
Subject: [R] Need some help with data-wrangling in R
In-Reply-To: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>
References: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>
Message-ID: <CAGxFJbQOgNDbA-5O8zKnRX6WeJX11yfJurOwzy=iJ7yFtCV74Q@mail.gmail.com>

" list of network blocks till 3rd octet:"

This is incomprehensible to me. If that is so for others, also, I suggest
that you provide a reproducible example (see posting guide) to explain what
you mean.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 24, 2018 at 9:41 AM Amit Govil <amit.cs03 at gmail.com> wrote:

> Hi,
>
> I have log data in which one of the columns have IP ranges and the next
> column is corresponding ports. Eg:
>
>
> IPRange Port
> 10.78.64.0-10.78.66.255 D, A, C
>
> I need to expand the IPRange column into a list of network blocks till 3rd
> octet:
>
> IPRange IP Port
> 192.100.176.0-192.100.179.255 192.100.176.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.177.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.178.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.179.0/24 A, B, C
>
> How do I do this data transformation in R?
>
> Please assist.
>
> Thanks
> Amit
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug 24 18:53:57 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 24 Aug 2018 17:53:57 +0100
Subject: [R] Need some help with data-wrangling in R
In-Reply-To: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>
References: <CAPf9UMoxNJYcnB8N7zsKLfNvg+tE0mz59s21YN9XykZZ9egp1A@mail.gmail.com>
Message-ID: <3bc9735a-ddcf-7df8-2052-39b95cfc87fc@sapo.pt>

Hello,

Cross-posting is not very well seen by R-Help. Please wait for an answer 
to one of your posts before posting somewhere else.

https://stackoverflow.com/questions/52008756/how-to-get-a-list-of-ip-addresses-from-an-ip-range-using-r

Rui Barradas

On 24/08/2018 17:34, Amit Govil wrote:
> Hi,
> 
> I have log data in which one of the columns have IP ranges and the next
> column is corresponding ports. Eg:
> 
> 
> IPRange Port
> 10.78.64.0-10.78.66.255 D, A, C
> 
> I need to expand the IPRange column into a list of network blocks till 3rd
> octet:
> 
> IPRange IP Port
> 192.100.176.0-192.100.179.255 192.100.176.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.177.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.178.0/24 A, B, C
> 192.100.176.0-192.100.179.255 192.100.179.0/24 A, B, C
> 
> How do I do this data transformation in R?
> 
> Please assist.
> 
> Thanks
> Amit
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

---
This email has been checked for viruses by AVG.
https://www.avg.com



From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Aug 24 20:57:10 2018
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 24 Aug 2018 13:57:10 -0500
Subject: [R] Obtaining Complete Dataset with Imputed Values
Message-ID: <CAMOcQfOFkwSUVhXGCy7-R-3YGLC0swMY-1TjBLTQTR_jpJsgRQ@mail.gmail.com>

Dear friends, hope all is well with you,

I am working with package mi for data inputation. Currently working with R
version 3.5.0 (64-bit).

Say my data is  defined as dat, and I do the following:

datimputations <- mi(dat[2:5], n.iter=50)
completedat <- complete(datimputations)

After using the complete function, I get the following error message:

Error in complete(datimputations, m = 1) : 'data' not of class 'mids'

How can I retrieve the processed dataframe (along with the imputed values)?

Here is my dput() for you to see

> dput(head(dat,100))
structure(list(TransitDate = structure(c(496990800, 499669200,
502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
754722000, 757400400), class = c("POSIXct", "POSIXt"), tzone = ""),
    Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L, 14L, 16L,
    6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L, 10L,
    9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
    7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L,
    5L, 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L,
    9L, 8L, 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L,
    14L, 15L, 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L,
    9L, 12L, 8L, 12L, 10L, 11L, 10L, 9L, 10L), CargoTons = c(154973L,
    129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
    124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L,
    98222L, 54719L, 98470L, 18263L, 104255L, 62869L, 62523L,
    75344L, 81476L, 92818L, 87457L, 85231L, 77897L, 57699L, 96989L,
    109361L, 59799L, 91116L, 82241L, 74251L, 124361L, 68751L,
    61719L, 68017L, 37760L, 32513L, 56359L, 51333L, 80859L, 75852L,
    65760L, 96043L, 38820L, 63202L, 102647L, 49104L, 53482L,
    121305L, 71795L, 76704L, 146097L, 73047L, 68557L, 110642L,
    77616L, 97767L, 52059L, 58658L, 66350L, 69303L, 76013L, 91909L,
    108445L, 94454L, 101249L, 112131L, 56290L, 118342L, 70618L,
    64783L, 112839L, 120506L, 94243L, 130768L, 133643L, 146321L,
    140736L, 147234L, 158953L, 189888L, 93819L, 130021L, 130124L,
    55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
    93713L, 98417L, 97210L, 88464L, 94659L), RcnstPCUMS = c(229914L,
    214547L, 215890L, 158695L, 173125L, 222533L, 212490L, 222125L,
    266913L, 94268L, 112967L, 95480L, 87654L, 108996L, 97973L,
    139247L, 93817L, 133197L, 40020L, 169749L, 102590L, 112121L,
    140241L, 122989L, 144592L, 144979L, 123748L, 123249L, 70081L,
    155218L, 168096L, 104743L, 163384L, 142648L, 129188L, 183170L,
    99299L, 99873L, 111648L, 55890L, 59183L, 95568L, 72550L,
    104562L, 100478L, 92665L, 130625L, 54786L, 105900L, 135833L,
    70932L, 73247L, 149632L, 94317L, 87926L, 181989L, 92778L,
    107097L, 153246L, 105175L, 126393L, 81976L, 95518L, 109019L,
    95370L, 140492L, 125795L, 157978L, 138424L, 138160L, 180320L,
    78757L, 135860L, 85921L, 114847L, 151965L, 152561L, 132841L,
    204839L, 209567L, 224436L, 210209L, 227143L, 245968L, 264969L,
    158648L, 222251L, 194335L, 111618L, 189643L, 137438L, 124953L,
    163155L, 107633L, 164525L, 135102L, 152072L, 126636L, 121008L,
    137824L), TotalToll = c(420742L, 392621L, 395078L, 290411L,
    316818L, 407235L, 388856L, 406488L, 482774L, 172510L, 206729L,
    174728L, 160406L, 199462L, 179290L, 254822L, 171685L, 243750L,
    73236L, 310640L, 187739L, 205181L, 249438L, 225069L, 264603L,
    265311L, 226458L, 225545L, 128248L, 284048L, 296023L, 184934L,
    298992L, 261045L, 236414L, 335201L, 181717L, 182767L, 204315L,
    102278L, 108304L, 174889L, 132766L, 191348L, 183874L, 169576L,
    239043L, 100258L, 212859L, 273024L, 142573L, 147226L, 300760L,
    189577L, 176731L, 365797L, 186483L, 215264L, 308024L, 211401L,
    254049L, 164771L, 191991L, 219128L, 191693L, 282388L, 252847L,
    317535L, 278232L, 277701L, 356022L, 158301L, 273078L, 172701L,
    230842L, 305449L, 306647L, 267010L, 406202L, 421229L, 451116L,
    422520L, 456557L, 494395L, 582202L, 350612L, 491174L, 429480L,
    239858L, 419111L, 303737L, 276146L, 360572L, 237868L, 358627L,
    298575L, 336079L, 279865L, 267427L, 304591L)), row.names = c(NA,
100L), class = "data.frame")

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Aug 24 21:37:59 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 24 Aug 2018 12:37:59 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>

On Wed, 22 Aug 2018, Rich Shepard wrote:

>  More when I have results.

   Almost there. I've read the auto.key section in ?barchart and looked at
examples from stackoverflow on the web without seeing my syntax errors. I
would like help on two issues:

   1. What I want is to have the legend text in black and the colored
rectangles match the black and grey of the bars. Instead, I get the legend
text colored and have no idea where the default colors in the rectangles got
there.

   2. I've not found how to have the years (rather than the sequence of
years) as the x-axis labels.

   Here are the dput() output and the script:

structure(list(year = c(1989L, 1989L, 1990L, 1990L, 1991L, 1991L, 
1993L, 1993L, 1994L, 1994L, 1995L, 1995L, 1996L, 1996L, 1997L, 
1997L, 1998L, 1998L, 1999L, 1999L, 2000L, 2000L, 2001L, 2001L, 
2002L, 2002L, 2003L, 2003L, 2004L, 2004L, 2005L, 2005L, 2006L, 
2006L, 2007L, 2007L, 2008L, 2008L, 2009L, 2009L, 2010L, 2010L, 
2011L, 2011L, 2012L, 2012L, 2013L, 2013L, 2014L, 2014L, 2015L, 
2015L, 2016L, 2016L, 2017L, 2017L, 2018L, 2018L), value = c(91.17, 
93.32, 91.22, 93.43, 91.24, 92.89, 91.14, 93.02, 93.92, 95.74, 
94.34, 96.85, 91.32, 95.86, 91.36, 94.25, 91.24, 93.67, 94.33, 
97.42, 94.33, 97.42, 94, 94.99, 94.32, 96.58, 94.02, 96.57, 94.19, 
96.32, 94.05, 95.96, 94.21, 97.4, 94.21, 97.28, 94.32, 96.72, 
94.13, 97.43, 94.27, 95.95, 94.34, 97.82, 94.23, 97, 94.25, 96.6, 
94.15, 96.24, 94.01, 96.68, 94.09, 96.96, 94.31, 96.39, 94.35, 
96.95), type = structure(c(2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
1L), .Label = c("Max", "Med"), class = "factor")), class = "data.frame", row.names = c(NA, 
-58L))

med_max <- barchart(value ~ year, data=stage_heights,
                     panel = lattice.getOption("panel.barchart"),
                     default.prepanel = lattice.getOption("prepanel.default.barchart"),
                     box.ratio = 2, horizontal=FALSE, auto.key=list(space='right',
                                                                    col=c('black', 'grey')),
                     groups=factor(type,labels=c('Median','Maximum')), beside=TRUE,
                     col = c('grey','black'), labels=list(c(1989,1990,1991,1992, 1993,1994,
                                                            1995,1996,1997,1998,1999,2000,2001,
                                                            2002,2003,2004,2005,2006,2007,2008,
                                                            2009,2010,2011,2012,2013,2014,2015,
                                                            2016,2017,2018),
                                                          scales=list(x=list(rot=90)),
                                                          main = 'Median and Maximum Stage Heights',
                                                          ylab = 'Elevation (masl)', xlab = 'Year')
print(med_max)

Rich



From rmh @end|ng |rom temp|e@edu  Fri Aug 24 21:58:15 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 24 Aug 2018 15:58:15 -0400
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
Message-ID: <CAGx1TMDfE5+5pkVx-kz1Q-N742z2bykH=OdKxKcZ91qSM733Hg@mail.gmail.com>

color for the legend comes from trellis.par.get

You can control that for an individual plot with the par.settings argument.

tmp <- data.frame(y=sample(10),
                  group=rep(c("Median", "Maximum"), each=5),
                  year=factor(rep(1998:1999, length=10)))

barchart(y ~ year, data=tmp, group=group, auto.key=TRUE, main="default legend",
         col = c('grey','black'))

barchart(y ~ year, data=tmp, group=group, auto.key=TRUE, main="what you want",
         par.settings=list(superpose.polygon=list(col=c('grey','black'))))

names(trellis.par.get())
trellis.par.get()$superpose.polygon



On Fri, Aug 24, 2018 at 3:37 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> On Wed, 22 Aug 2018, Rich Shepard wrote:
>
>>  More when I have results.
>
>
>   Almost there. I've read the auto.key section in ?barchart and looked at
> examples from stackoverflow on the web without seeing my syntax errors. I
> would like help on two issues:
>
>   1. What I want is to have the legend text in black and the colored
> rectangles match the black and grey of the bars. Instead, I get the legend
> text colored and have no idea where the default colors in the rectangles got
> there.
>
>   2. I've not found how to have the years (rather than the sequence of
> years) as the x-axis labels.
>
>   Here are the dput() output and the script:
>
> structure(list(year = c(1989L, 1989L, 1990L, 1990L, 1991L, 1991L, 1993L,
> 1993L, 1994L, 1994L, 1995L, 1995L, 1996L, 1996L, 1997L, 1997L, 1998L, 1998L,
> 1999L, 1999L, 2000L, 2000L, 2001L, 2001L, 2002L, 2002L, 2003L, 2003L, 2004L,
> 2004L, 2005L, 2005L, 2006L, 2006L, 2007L, 2007L, 2008L, 2008L, 2009L, 2009L,
> 2010L, 2010L, 2011L, 2011L, 2012L, 2012L, 2013L, 2013L, 2014L, 2014L, 2015L,
> 2015L, 2016L, 2016L, 2017L, 2017L, 2018L, 2018L), value = c(91.17, 93.32,
> 91.22, 93.43, 91.24, 92.89, 91.14, 93.02, 93.92, 95.74, 94.34, 96.85, 91.32,
> 95.86, 91.36, 94.25, 91.24, 93.67, 94.33, 97.42, 94.33, 97.42, 94, 94.99,
> 94.32, 96.58, 94.02, 96.57, 94.19, 96.32, 94.05, 95.96, 94.21, 97.4, 94.21,
> 97.28, 94.32, 96.72, 94.13, 97.43, 94.27, 95.95, 94.34, 97.82, 94.23, 97,
> 94.25, 96.6, 94.15, 96.24, 94.01, 96.68, 94.09, 96.96, 94.31, 96.39, 94.35,
> 96.95), type = structure(c(2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), .Label = c("Max", "Med"), class =
> "factor")), class = "data.frame", row.names = c(NA, -58L))
>
> med_max <- barchart(value ~ year, data=stage_heights,
>                     panel = lattice.getOption("panel.barchart"),
>                     default.prepanel =
> lattice.getOption("prepanel.default.barchart"),
>                     box.ratio = 2, horizontal=FALSE,
> auto.key=list(space='right',
>
> col=c('black', 'grey')),
>                     groups=factor(type,labels=c('Median','Maximum')),
> beside=TRUE,
>                     col = c('grey','black'),
> labels=list(c(1989,1990,1991,1992, 1993,1994,
>
> 1995,1996,1997,1998,1999,2000,2001,
>
> 2002,2003,2004,2005,2006,2007,2008,
>
> 2009,2010,2011,2012,2013,2014,2015,
>                                                            2016,2017,2018),
>
> scales=list(x=list(rot=90)),
>                                                          main = 'Median and
> Maximum Stage Heights',
>                                                          ylab = 'Elevation
> (masl)', xlab = 'Year')
> print(med_max)
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 24 22:16:02 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Aug 2018 13:16:02 -0700
Subject: [R] lattice barchart() with two variables
In-Reply-To: <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTKeyhVd1TyZ9WLWg6o6dn-7cnjkW4VEz+EL8mYuRO=Cg@mail.gmail.com>

For the legend, you can use the full "key" argument for more control. The
docs in ?xyplot for "key" Should answer your questions.  "col" controls
text color within the "text" component and rectangle color within the
"rectangle" component , for example. I think this should work as an
alternative to specifying the par.settings components, but I haven't
checked.

For the scales, again, the docs provide the answer:  the "at" and "labels"
components of "x" component of the scales lists can explicitly control the
x -labels, e.g.

scales = list( x = list( at = ..., labels = ...)    etc.

If you are uncomfortable with the R lattice help docs, and you intend to
continue to use lattice plots (a good idea; ggplot is an alternative of
course), Deepayan has written a book that you might wish to get:

http://lmdvr.r-forge.r-project.org/figures/figures.html

There are also numerous web tutorials.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 24, 2018 at 12:38 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 22 Aug 2018, Rich Shepard wrote:
>
> >  More when I have results.
>
>    Almost there. I've read the auto.key section in ?barchart and looked at
> examples from stackoverflow on the web without seeing my syntax errors. I
> would like help on two issues:
>
>    1. What I want is to have the legend text in black and the colored
> rectangles match the black and grey of the bars. Instead, I get the legend
> text colored and have no idea where the default colors in the rectangles
> got
> there.
>
>    2. I've not found how to have the years (rather than the sequence of
> years) as the x-axis labels.
>
>    Here are the dput() output and the script:
>
> structure(list(year = c(1989L, 1989L, 1990L, 1990L, 1991L, 1991L,
> 1993L, 1993L, 1994L, 1994L, 1995L, 1995L, 1996L, 1996L, 1997L,
> 1997L, 1998L, 1998L, 1999L, 1999L, 2000L, 2000L, 2001L, 2001L,
> 2002L, 2002L, 2003L, 2003L, 2004L, 2004L, 2005L, 2005L, 2006L,
> 2006L, 2007L, 2007L, 2008L, 2008L, 2009L, 2009L, 2010L, 2010L,
> 2011L, 2011L, 2012L, 2012L, 2013L, 2013L, 2014L, 2014L, 2015L,
> 2015L, 2016L, 2016L, 2017L, 2017L, 2018L, 2018L), value = c(91.17,
> 93.32, 91.22, 93.43, 91.24, 92.89, 91.14, 93.02, 93.92, 95.74,
> 94.34, 96.85, 91.32, 95.86, 91.36, 94.25, 91.24, 93.67, 94.33,
> 97.42, 94.33, 97.42, 94, 94.99, 94.32, 96.58, 94.02, 96.57, 94.19,
> 96.32, 94.05, 95.96, 94.21, 97.4, 94.21, 97.28, 94.32, 96.72,
> 94.13, 97.43, 94.27, 95.95, 94.34, 97.82, 94.23, 97, 94.25, 96.6,
> 94.15, 96.24, 94.01, 96.68, 94.09, 96.96, 94.31, 96.39, 94.35,
> 96.95), type = structure(c(2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
> 1L), .Label = c("Max", "Med"), class = "factor")), class = "data.frame",
> row.names = c(NA,
> -58L))
>
> med_max <- barchart(value ~ year, data=stage_heights,
>                      panel = lattice.getOption("panel.barchart"),
>                      default.prepanel =
> lattice.getOption("prepanel.default.barchart"),
>                      box.ratio = 2, horizontal=FALSE,
> auto.key=list(space='right',
>
> col=c('black', 'grey')),
>                      groups=factor(type,labels=c('Median','Maximum')),
> beside=TRUE,
>                      col = c('grey','black'),
> labels=list(c(1989,1990,1991,1992, 1993,1994,
>
> 1995,1996,1997,1998,1999,2000,2001,
>
> 2002,2003,2004,2005,2006,2007,2008,
>
> 2009,2010,2011,2012,2013,2014,2015,
>
> 2016,2017,2018),
>
> scales=list(x=list(rot=90)),
>                                                           main = 'Median
> and Maximum Stage Heights',
>                                                           ylab =
> 'Elevation (masl)', xlab = 'Year')
> print(med_max)
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From |r@|nj @end|ng |rom gm@||@com  Fri Aug 24 23:22:09 2018
From: |r@|nj @end|ng |rom gm@||@com (John C Frain)
Date: Fri, 24 Aug 2018 22:22:09 +0100
Subject: [R] Unclear about the output from summary of ca.jo from package
 urca
In-Reply-To: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
References: <CAC8=1eqrWLCeE_SX55utG0rjvaU4zBkPa6ia2qz0Nayg4mtuqA@mail.gmail.com>
Message-ID: <CAHrK516-9YYh_n_BKa0wo_XHzuZiV_+ANHKDM-=VfKSYXPX83Q@mail.gmail.com>

I have posted a reply to your original quesstion  on Cross Validated
explaining how the notation arises.
John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com


On Thu, 23 Aug 2018 at 10:12, Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> I am not sure about the summary of the function ca.jo. I have posted my
> query here :-
>
>
> https://stats.stackexchange.com/questions/363188/interpreting-the-names-used-in-the-output-of-johansen-test-in-package-urca-in-r
>
> I did not receive any reply so I am posting my query here.
>
> Many thanks and best regards,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Aug 24 23:28:49 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 24 Aug 2018 14:28:49 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGxFJbTKeyhVd1TyZ9WLWg6o6dn-7cnjkW4VEz+EL8mYuRO=Cg@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
 <CAGxFJbTKeyhVd1TyZ9WLWg6o6dn-7cnjkW4VEz+EL8mYuRO=Cg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808241422531.19296@salmo.appl-ecosys.com>

On Fri, 24 Aug 2018, Bert Gunter wrote:

> For the legend, you can use the full "key" argument for more control.

Bert,

   This I did.

> For the scales, again, the docs provide the answer:  the "at" and "labels"
> components of "x" component of the scales lists can explicitly control the
> x -labels, e.g.

   A bit of trial-and-error got this working, too. Now the plot command works
as desired:

barchart(value ~ year, data=stage_heights,
                     panel = lattice.getOption("panel.barchart"),
                     default.prepanel = lattice.getOption("prepanel.default.barchart"),
                     box.ratio = 2, horizontal=FALSE, key=list(c(0.2,0.3), columns=2,
                                                               text=list(c('Median','Maximum')),
                                                               rect=list(col=c('black', 'grey'))),
                     groups=factor(type,labels=c('Median','Maximum')), beside=TRUE,
                     col = c('grey','black'), scales=list(x=list(at=rep(1:29),
                                                                 labels=rep(1989:2018),rot=90)),
                     main = 'Median and Maximum Stage Heights',
                     ylab = 'Elevation (masl)', xlab = 'Year')

(Emacs w/ESS does the formatting). I suppose that the Maximum bar is plotted
to the left because alphabetically it preceeds Medium. I can live with this.

   Deepayan's book was one of the first I bought years ago. I've not before
had plots that required more in-depth knowledge of panels, keys, and scales
so I do appreciate your patient mentoring.

Best regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Aug 24 23:31:06 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 24 Aug 2018 14:31:06 -0700 (PDT)
Subject: [R] lattice barchart() with two variables
In-Reply-To: <CAGx1TMDfE5+5pkVx-kz1Q-N742z2bykH=OdKxKcZ91qSM733Hg@mail.gmail.com>
References: <alpine.LNX.2.20.1808220750010.6107@salmo.appl-ecosys.com>
 <CAGxFJbRSkiiRX-xdRTD3n6gVca6R06jcyGJqwB1HL6BCU4Qxqg@mail.gmail.com>
 <alpine.LNX.2.20.1808220901150.6107@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808221006560.6107@salmo.appl-ecosys.com>
 <CAGxFJbQCDRBNZps1HQxWHMa4iKf-pyNR-S-6H13Cbmh8+ajXfA@mail.gmail.com>
 <alpine.LNX.2.20.1808221430000.9436@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1808241227300.19296@salmo.appl-ecosys.com>
 <CAGx1TMDfE5+5pkVx-kz1Q-N742z2bykH=OdKxKcZ91qSM733Hg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1808241428550.19296@salmo.appl-ecosys.com>

On Fri, 24 Aug 2018, Richard M. Heiberger wrote:

> color for the legend comes from trellis.par.get
> You can control that for an individual plot with the par.settings argument.
> tmp <- data.frame(y=sample(10),
>                  group=rep(c("Median", "Maximum"), each=5),
>                  year=factor(rep(1998:1999, length=10)))
>
> barchart(y ~ year, data=tmp, group=group, auto.key=TRUE, main="default legend",
>         col = c('grey','black'))
>
> barchart(y ~ year, data=tmp, group=group, auto.key=TRUE, main="what you want",
>         par.settings=list(superpose.polygon=list(col=c('grey','black'))))
>
> names(trellis.par.get())
> trellis.par.get()$superpose.polygon

   Thanks, Richard!

   Before venturing into par.settings I worked off of Bert's advice and
careful reading of the ?xyplot details allowed me to fix the two remaining
issues. Your suggestions will definitely be of value when I have other
complex lattice plots to properly display.

Best regards,

Rich



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 25 01:20:09 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 25 Aug 2018 11:20:09 +1200
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
Message-ID: <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>


See in-line below.

On 08/25/2018 01:10 AM, Ista Zahn wrote:

> On Thu, Aug 23, 2018 at 6:57 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> I *think* that this is an R question (and *not* an RStudio question!)
> 
> I think this is actually and Ubuntu question, and probably belongs on
> R-sig-debian.

Well, it's about installing R --- *could* be independent of OS.

>>
>> I have, somewhat against my better judgement, decided to experiment with
>> using RStudio.
>>
>> I downloaded and install RStudio.  Easy-peasy.  Nice lucid instructions.
>>
>> Then I tried to start RStudio ("rstudio" from the command line)
>> and got a pop-up window with the error message:
>>
>>> R shared library (/usr/lib64/R/lib/libR.so) not found. If this
>>> is a custom build of R, was it built with the --enable-R-shlib option?
>>
>> Oops, no, I guess it wasn't.  So I carefully did a
>>
>>       sudo make uninstall
>>       make clean
>>       make distclean
>>
>> and then did
>>
>>       ./R-3.5.1/configure <various flags>
>>
>> making sure I added the --enable-R-shlib flag.
>>
>> Then I did make and sudo make install.
> 
> IMO if you are compiling and installing software yourself on Linux
> your are Doing It Wrong. Use the package manager, that is what it is
> there for.

I was pretty sure that the foregoing was a complete red herring.  And I 
was right.

I have been told by younger and wiser heads that installing from source 
is The Right Thing to Do.  Moreover I'd always had the impression that 
the version of R provided by the package manager persistently lags one 
or two releases behind the current version.  However, given that the 
suggestion had been made, I decided I'd try it.

The process for installing R using the package manager is far from 
straightforward and few people give clear instructions on this issue.
(Instructions are usually incomplete and full of jargon and acronyms 
that the instructors blithely assume assume that the instructees 
understand.  (They *don't*! In this instance (mirabile dictu!) I managed 
(using Uncle Google) to find very clear and explicit instructions at:

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart

I followed these instructions, and everything went swimmingly.  I indeed 
got the current version of R (3.5.1, "Feather Spray").  So my previous 
impression was incorrect (given that one carefully follows the rather 
complex installation procedures, at least).

Interestingly (???) the "new" R was installed in /usr/bin and not in 
/usr/local/bin.

I then tried issuing the command:

     rstudio

Exactly the same pop-up error.  No help at all, as I expected.

I then tried

     sudo apt install r-base-dev

thinking that this might be needed to get the libR.so created (in the 
right place).  No joy.

I then tried the symlink strategy that I had previously suggested.  No 
joy there either.

Then finally, in desperation, I copied libR.so from /usr/lib/R/lib to
/usr/lib64/R/lib.  Bingo!!!  I can now start Rstudio!!!

It remains mysterious to me why the symlink procedure did not work, 
whereas making a copy of libR.so *did* work.

However I guess this really doesn't matter.  It's now working.

cheers,

Rolf

> --Ista
> 
> It all seemed to go ...
>> but then I did
>>
>>       rstudio
>>
>> again and got the same popup error.
>>
>> There is indeed *no* libR.so in /usr/lib64/R/lib.
>>
>> There *is* a libR.so in /usr/lib/R/lib, but (weirdly) ls -l reveals that
>> it dates from the my previous install of R-3.5.1 for which I *did not*
>> configure with --enable-R-shlib.
>>
>> Can anyone explain to me WTF is going on?
>>
>> What should I do?  Just make a symbolic link from /usr/lib/R/lib/libR.so
>> to /usr/lib64/R/lib/libR.so?
>>
>> It bothers me that /usr/lib/R/lib/libR.so was not "refreshed" from my
>> most recent install of R.
>>
>> I plead for enlightenment.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> P.S. I'm running Ubuntu 18.04.  And the previous install of R was done
>> under Ubuntu 18.04.
>>
>> R. T.
-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From t@n@@@ @end|ng |rom gm@||@com  Sat Aug 25 03:28:59 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Fri, 24 Aug 2018 18:28:59 -0700
Subject: [R] installing R 3.5.1
Message-ID: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>

Dear all,

I am trying to install R 3.5.1 on my Ubuntu 14.04 system; however, I am
getting the following message :

sudo apt-get install r-base
[...]
The following packages have unmet dependencies:
 r-base : Depends: r-recommended (= 3.5.1-1trusty) but it is not going to
be installed
E: Unable to correct problems, you have held broken packages.

In the file /etc/apt/sources.list , I have set up :

deb https://cloud.r-project.org/bin/linux/ubuntu trusty/
deb https://cloud.r-project.org/bin/linux/ubuntu trusty-cran35/

Would you please advise, what shall I do next ? Thanks a lot !

-- bogdan

	[[alternative HTML version deleted]]



From ggrothend|eck @end|ng |rom gm@||@com  Sat Aug 25 04:06:22 2018
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Fri, 24 Aug 2018 22:06:22 -0400
Subject: [R] looking for formula parser that allows coefficients
In-Reply-To: <CAErODj-DW3AQCH8SHHHaNHAoGMNmnMvi=M0QK2Jm1Dk63ksm4Q@mail.gmail.com>
References: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
 <CAP01uRm41Zy-UamFBYshbdRjA9XwnwafQHszYEbH0FjDjE4xCw@mail.gmail.com>
 <CAErODj-DW3AQCH8SHHHaNHAoGMNmnMvi=M0QK2Jm1Dk63ksm4Q@mail.gmail.com>
Message-ID: <CAP01uRn4OoR0uk0m4oqQc2iOF7BN4PRb7UbrkE+Y5cxZq35Hqw@mail.gmail.com>

Also here is a solution that uses formula processing rather than
string processing.
No packages are used.

Parse <- function(e) {
  if (length(e) == 1) {
    if (is.numeric(e)) return(e)
    else setNames(1, as.character(e))
  } else {
    if (isChar(e[[1]], "*")) {
       x1 <- Recall(e[[2]])
       x2 <- Recall(e[[3]])
       setNames(unname(x1 * x2), paste0(names(x1), names(x2)))
    } else if (isChar(e[[1]], "+")) c(Recall(e[[2]]), Recall(e[[3]]))
    else if (isChar(e[[1]], "-")) {
      if (length(e) == 2) -1 * Recall(e[[2]])
      else c(Recall(e[[2]]), -Recall(e[[3]]))
    } else if (isChar(e[[1]], ":")) setNames(1, paste(e[-1], collapse = ":"))
  }
}

# test
fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2
Parse(fo[[3]])

giving:

         x1    x3 x1:x3 x2:x2
  2.0  -1.1   1.0  -1.0   0.2
On Wed, Aug 22, 2018 at 11:50 AM Paul Johnson <pauljohn32 at gmail.com> wrote:
>
> Thanks as usual.  I owe you more KU decorations soon.
> On Wed, Aug 22, 2018 at 2:34 AM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > Some string manipulation can convert the formula to a named vector such as
> > the one shown at the end of your post.
> >
> > library(gsubfn)
> >
> > # input
> > fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2
> >
> > pat <- "([+-])? *(\\d\\S*)? *\\*? *([[:alpha:]]\\S*)?"
> > ch <- format(fo[[3]])
> > m <- matrix(strapplyc(ch, pat)[[1]], 3)
> > m <- m[, colSums(m != "") > 0]
> > m[2, m[2, ] == ""] <- 1
> > m[3, m[3, ] == ""] <- "(Intercept)"
> > co <- as.numeric(paste0(m[1, ], m[2, ]))
> > v <- m[3, ]
> > setNames(co, v)
> > ## (Intercept)          x1          x3       x1:x3       x2:x2
> > ##         2.0        -1.1         1.0        -1.0         0.2
> > On Tue, Aug 21, 2018 at 6:46 PM Paul Johnson <pauljohn32 at gmail.com> wrote:
> > >
> > > Can you point me at any packages that allow users to write a
> > > formula with coefficients?
> > >
> > > I want to write a data simulator that has a matrix X with lots
> > > of columns, and then users can generate predictive models
> > > by entering a formula that uses some of the variables, allowing
> > > interactions, like
> > >
> > > y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2
> > >
> > > Currently, in the rockchalk package, I have a function simulates
> > > data (genCorrelatedData2), but my interface to enter the beta
> > > coefficients is poor.  I assumed user would always enter 0's as
> > > place holder for the unused coefficients, and the intercept is
> > > always first. The unnamed vector is too confusing.  I have them specify:
> > >
> > > c(2, 1.1, 0, 3, 0, 0, 0.2, ...)
> > >
> > > I the documentation I say (ridiculously) it is easy to figure out from
> > > the examples, but it really isnt.
> > > It function prints out the equation it thinks you intended, thats
> > > minimum protection against user error, but still not very good:
> > >
> > > dat <- genCorrelatedData2(N = 10, rho = 0.0,
> > >           beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
> > >           means = c(0,0,0), sds = c(1,1,1), stde = 0)
> > > [1] "The equation that was calculated was"
> > > y = 1 + 2*x1 + 1*x2 + 1*x3
> > >  + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
> > >  + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
> > >  + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
> > >  + N(0,0) random error
> > >
> > > But still, it is not very good.
> > >
> > > As I look at this now, I realize expect just the vech, not the whole vector
> > > of all interaction terms, so it is even more difficult than I thought to get the
> > > correct input.Hence, I'd like to let the user write a formula.
> > >
> > > The alternative for the user interface is to have named coefficients.
> > > I can more or less easily allow a named vector for beta
> > >
> > > beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)
> > >
> > > I could build a formula from that.  That's not too bad. But I still think
> > > it would be cool to allow formula input.
> > >
> > > Have you ever seen it done?
> > > pj
> > > --
> > > Paul E. Johnson   http://pj.freefaculty.org
> > > Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> > >
> > > To write to me directly, please address me at pauljohn at ku.edu.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
>
>
>
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From ggrothend|eck @end|ng |rom gm@||@com  Sat Aug 25 04:24:55 2018
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Fri, 24 Aug 2018 22:24:55 -0400
Subject: [R] looking for formula parser that allows coefficients
In-Reply-To: <CAP01uRn4OoR0uk0m4oqQc2iOF7BN4PRb7UbrkE+Y5cxZq35Hqw@mail.gmail.com>
References: <CAErODj9jxYzSOfQ9m8Zm_fCkxHvHvP-zyCKTi8-DgoeYyQML-A@mail.gmail.com>
 <CAP01uRm41Zy-UamFBYshbdRjA9XwnwafQHszYEbH0FjDjE4xCw@mail.gmail.com>
 <CAErODj-DW3AQCH8SHHHaNHAoGMNmnMvi=M0QK2Jm1Dk63ksm4Q@mail.gmail.com>
 <CAP01uRn4OoR0uk0m4oqQc2iOF7BN4PRb7UbrkE+Y5cxZq35Hqw@mail.gmail.com>
Message-ID: <CAP01uRn10CMKtEqgmmw_ogsEZk7OWM3bsPsBK5dvoyFusyJvOA@mail.gmail.com>

The isChar function used in Parse is:

  isChar <- function(e, ch) identical(e, as.symbol(ch))
On Fri, Aug 24, 2018 at 10:06 PM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> Also here is a solution that uses formula processing rather than
> string processing.
> No packages are used.
>
> Parse <- function(e) {
>   if (length(e) == 1) {
>     if (is.numeric(e)) return(e)
>     else setNames(1, as.character(e))
>   } else {
>     if (isChar(e[[1]], "*")) {
>        x1 <- Recall(e[[2]])
>        x2 <- Recall(e[[3]])
>        setNames(unname(x1 * x2), paste0(names(x1), names(x2)))
>     } else if (isChar(e[[1]], "+")) c(Recall(e[[2]]), Recall(e[[3]]))
>     else if (isChar(e[[1]], "-")) {
>       if (length(e) == 2) -1 * Recall(e[[2]])
>       else c(Recall(e[[2]]), -Recall(e[[3]]))
>     } else if (isChar(e[[1]], ":")) setNames(1, paste(e[-1], collapse = ":"))
>   }
> }
>
> # test
> fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2
> Parse(fo[[3]])
>
> giving:
>
>          x1    x3 x1:x3 x2:x2
>   2.0  -1.1   1.0  -1.0   0.2
> On Wed, Aug 22, 2018 at 11:50 AM Paul Johnson <pauljohn32 at gmail.com> wrote:
> >
> > Thanks as usual.  I owe you more KU decorations soon.
> > On Wed, Aug 22, 2018 at 2:34 AM Gabor Grothendieck
> > <ggrothendieck at gmail.com> wrote:
> > >
> > > Some string manipulation can convert the formula to a named vector such as
> > > the one shown at the end of your post.
> > >
> > > library(gsubfn)
> > >
> > > # input
> > > fo <- y ~ 2 - 1.1 * x1 + x3 - x1:x3 + 0.2 * x2:x2
> > >
> > > pat <- "([+-])? *(\\d\\S*)? *\\*? *([[:alpha:]]\\S*)?"
> > > ch <- format(fo[[3]])
> > > m <- matrix(strapplyc(ch, pat)[[1]], 3)
> > > m <- m[, colSums(m != "") > 0]
> > > m[2, m[2, ] == ""] <- 1
> > > m[3, m[3, ] == ""] <- "(Intercept)"
> > > co <- as.numeric(paste0(m[1, ], m[2, ]))
> > > v <- m[3, ]
> > > setNames(co, v)
> > > ## (Intercept)          x1          x3       x1:x3       x2:x2
> > > ##         2.0        -1.1         1.0        -1.0         0.2
> > > On Tue, Aug 21, 2018 at 6:46 PM Paul Johnson <pauljohn32 at gmail.com> wrote:
> > > >
> > > > Can you point me at any packages that allow users to write a
> > > > formula with coefficients?
> > > >
> > > > I want to write a data simulator that has a matrix X with lots
> > > > of columns, and then users can generate predictive models
> > > > by entering a formula that uses some of the variables, allowing
> > > > interactions, like
> > > >
> > > > y ~ 2 + 1.1 * x1 + 3 * x3 + 0.1 * x1:x3 + 0.2 * x2:x2
> > > >
> > > > Currently, in the rockchalk package, I have a function simulates
> > > > data (genCorrelatedData2), but my interface to enter the beta
> > > > coefficients is poor.  I assumed user would always enter 0's as
> > > > place holder for the unused coefficients, and the intercept is
> > > > always first. The unnamed vector is too confusing.  I have them specify:
> > > >
> > > > c(2, 1.1, 0, 3, 0, 0, 0.2, ...)
> > > >
> > > > I the documentation I say (ridiculously) it is easy to figure out from
> > > > the examples, but it really isnt.
> > > > It function prints out the equation it thinks you intended, thats
> > > > minimum protection against user error, but still not very good:
> > > >
> > > > dat <- genCorrelatedData2(N = 10, rho = 0.0,
> > > >           beta = c(1, 2, 1, 1, 0, 0.2, 0, 0, 0),
> > > >           means = c(0,0,0), sds = c(1,1,1), stde = 0)
> > > > [1] "The equation that was calculated was"
> > > > y = 1 + 2*x1 + 1*x2 + 1*x3
> > > >  + 0*x1*x1 + 0.2*x2*x1 + 0*x3*x1
> > > >  + 0*x1*x2 + 0*x2*x2 + 0*x3*x2
> > > >  + 0*x1*x3 + 0*x2*x3 + 0*x3*x3
> > > >  + N(0,0) random error
> > > >
> > > > But still, it is not very good.
> > > >
> > > > As I look at this now, I realize expect just the vech, not the whole vector
> > > > of all interaction terms, so it is even more difficult than I thought to get the
> > > > correct input.Hence, I'd like to let the user write a formula.
> > > >
> > > > The alternative for the user interface is to have named coefficients.
> > > > I can more or less easily allow a named vector for beta
> > > >
> > > > beta = c("(Intercept)" = 1, "x1" = 2, "x2" = 1, "x3" = 1, "x2:x1" = 0.1)
> > > >
> > > > I could build a formula from that.  That's not too bad. But I still think
> > > > it would be cool to allow formula input.
> > > >
> > > > Have you ever seen it done?
> > > > pj
> > > > --
> > > > Paul E. Johnson   http://pj.freefaculty.org
> > > > Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> > > >
> > > > To write to me directly, please address me at pauljohn at ku.edu.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Statistics & Software Consulting
> > > GKX Group, GKX Associates Inc.
> > > tel: 1-877-GKX-GROUP
> > > email: ggrothendieck at gmail.com
> >
> >
> >
> > --
> > Paul E. Johnson   http://pj.freefaculty.org
> > Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> >
> > To write to me directly, please address me at pauljohn at ku.edu.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Fri Aug 24 12:13:17 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Fri, 24 Aug 2018 22:13:17 +1200
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
Message-ID: <20180824101317.GC13179@slingshot.co.nz>

On Thu, 23-Aug-2018 at 07:23AM -0700, Jeff Newmiller wrote:

|> This is not reproducible because you have not provided the plot
|> code or sample data. Output of sessionInfo would probably be
|> appropriate as well.

I took it as read that the plotting functions themselves aren't an
issue since they operate as intended outside of the Rmarkdown
space. Any function that uses the function plot() successfully will
do.  I was trying to ascertain how I should be setting up the scaling.

|> As to whether needing to load objects is typical... yes, rmarkdown
|> runs from a fresh environment to emphasize reproducibility, but
|> your load command is bypassing that for us.

The objects loaded from .RData took hours of simulating and it's out
of the question to run them again inside Rmarkdown.  Though the script
used in the creation of .RData is reproducable, perhaps it would be
clearer for me to have saved the objects to a file by a different
name.

Is there a better way to do that??



|> On August 23, 2018 2:15:19 AM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
|> >I'm having difficulty getting plots into ioslides.  It seems to me
|> >that the scale is completely out, but I can't figure out what to do
|> >about it.  Whatever I try, I get the title slide, then a second with a
|> >horizontal line and a vertical line in the bottom right corner.  It
|> >looks like a badly scaled plot about 25 times the size of the plotting
|> >area, so only a fragment is visible.
|> >
|> >This is the code I've tried:
|> >
|> >---
|> >title: "Barking up the wrong tree"
|> >author: "Patrick Connolly"
|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
|> >output: ioslides_presentation
|> >---
|> >
|> >```{r global_options, echo=FALSE}
|> >knitr::opts_chunk$set(tidy=TRUE,
|> >                      warning=FALSE, 
|> >                      message=FALSE,
|> >                      cache=FALSE,
|> >                      dpi=600)
|> >```
|> >
|> >```{r use these functions, echo= FALSE}
|> >  load(".RData") ## code for 6 plotting functions
|> >
|> >``
|> >## 6 different Trees
|> >
|> >```{r 6 different Trees, echo = FALSE, messages=FALSE, fig.width = 7,
|> >fig.height = 5}
|> >
|> >###  par(mfrow = c(2, 3))
|> >plot1()
|> >plot2()
|> >plot3()
|> >plot4()
|> >plot5()
|> >plot6()
|> >}
|> >```
|> >
|> >If I run the plot functions in the Console, it all works and displays
|> >correctly in Rstudiio's plot panel, even the mfrow bit.  But I haven't
|> >worked out how to include the code into Rmarkdown.  I thought it might
|> >be less taxing to not try putting the 6 plots on the same slide, but
|> >it makes no difference when I commented out the mfrow bit.
|> >
|> >I'm not very familiar with the workings of Markdown or Rstudio, but it
|> >does seem strange to me that I need to specifically load the global
|> >environment otherwise it's not visible.  Is that to be expected?
|> >
|> >Ideas welcome, particularly about scaling.
|> 
|> -- 
|> Sent from my phone. Please excuse my brevity.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From berw|n@tur|@ch @end|ng |rom gm@||@com  Sat Aug 25 09:51:25 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Sat, 25 Aug 2018 15:51:25 +0800
Subject: [R] installing R 3.5.1
In-Reply-To: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
Message-ID: <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Bogdan,

On Fri, 24 Aug 2018 18:28:59 -0700
Bogdan Tanasa <tanasa at gmail.com> wrote:

> I am trying to install R 3.5.1 on my Ubuntu 14.04 system; however, I
> am getting the following message :
> 
> sudo apt-get install r-base
> [...]
> The following packages have unmet dependencies:
>  r-base : Depends: r-recommended (= 3.5.1-1trusty) but it is not
> going to be installed
> E: Unable to correct problems, you have held broken packages.

For me such problems are usually fixed by specifying the package that
"is not going to be installed" but on which the package I want to
install depends also to apt-get install.

What does
	sudo apt-get install r-base r-recommended
do on your system?

Cheers,

	Berwin



From beno|t@v@|||@nt @end|ng |rom no-|og@org  Sat Aug 25 11:13:49 2018
From: beno|t@v@|||@nt @end|ng |rom no-|og@org (Benoit Vaillant)
Date: Sat, 25 Aug 2018 11:13:49 +0200
Subject: [R] installing R 3.5.1
In-Reply-To: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
Message-ID: <20180825091348.7tidm7fvhiudr35d@auroras.fr>

Hello Bogdan,

This reply is off topic for the list, appologies. This problem is more
r-sig-debian related (see below).

Though Berwin already mentionned a possible solution, here is another.

On Fri, Aug 24, 2018 at 06:28:59PM -0700, Bogdan Tanasa wrote:
> I am trying to install R 3.5.1 on my Ubuntu 14.04 system;

You are trying to install R (latest version) on a system that is
outdated by the latest LTS (16.04) and more than four years old
now. ;-)

If you go to: https://cloud.r-project.org/bin/linux/ubuntu/

You'll get some hints, like:
"R 3.5 packages for Ubuntu on i386 and amd64 are available for most
stable Desktop releases of Ubuntu until their official end of life
date. However, only the latest Long Term Support (LTS) release is
fully supported."

Note the *only the latest LTS* ;-)

You'll also get the r-sig-debian list link to report issues.

> Would you please advise, what shall I do next ? Thanks a lot !

If you have the time, upgrade your LTS by migrating your system from
14.04 to 16.04 and then 18.04 (Bionic Beaver).

Best regards,

-- 
Beno?t

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180825/5b4a7474/attachment-0002.sig>

From p_conno||y @end|ng |rom @||ng@hot@co@nz  Sat Aug 25 12:21:46 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Sat, 25 Aug 2018 22:21:46 +1200
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
Message-ID: <20180825102146.GD13179@slingshot.co.nz>

I've simplified it so that it's reproducible:


---
title: "Barking up the wrong tree"
author: "Patrick Connolly"
date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
output:
  ioslides_presentation: default
  slidy_presentation: default
  beamer_presentation: default
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(tidy=TRUE,
                      warning=FALSE, 
                      message=FALSE,
                      cache=FALSE,
                      dpi = 300)
         
```
## 6 different Regression Trees

```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}

 par(mfrow = c(2, 3))
plot(1:10)
plot(12:4)
plot(seq(0, 800))
plot(-100:-900)
plot(12:50)
plot(90:54)
```

I've tried it on a different machine which gives a slightly more
informative message:

X11 font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12 could not be loaded

That seems to be associated with the Cairo plotting device which isn't
necessary with pdf devices which I normally use, nor, it would seem by
the plot pane in Rstudio.  Consequently, running the plot code itself
works fine, but if is to be incorporated in HTML, we run into the Cairo
issue, Looking into that one, it appears something has been orphaned
for a couple of years.  If anyone has information about that, I'd be
interested.

TIA


-------------

 version 3.5.0 (2018-04-23)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C               LC_TIME=en_NZ.UTF-8       
 [4] LC_COLLATE=en_NZ.UTF-8     LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] utils     stats     grDevices graphics  methods   base     

other attached packages:
[1] sp_1.3-1        lattice_0.20-35

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.17     knitr_1.20       bindr_0.1.1      magrittr_1.5     tidyselect_0.2.4 munsell_0.5.0   
 [7] colorspace_1.3-2 xtable_1.8-2     R6_2.2.2         rlang_0.2.1      stringr_1.3.1    plyr_1.8.4      
[13] dplyr_0.7.6      tools_3.5.0      grid_3.5.0       htmltools_0.3.6  crosstalk_1.0.0  rprojroot_1.3-2 
[19] yaml_2.1.19      leaflet_2.0.1    assertthat_0.2.0 digest_0.6.15    tibble_1.4.2     bindrcpp_0.2.2  
[25] shiny_1.1.0      purrr_0.2.5      later_0.7.3      htmlwidgets_1.2  promises_1.0.1   evaluate_0.10.1 
[31] glue_1.2.0       mime_0.5         rmarkdown_1.10   stringi_1.2.3    compiler_3.5.0   pillar_1.2.3    
[37] backports_1.1.2  scales_0.5.0     httpuv_1.4.4.2   pkgconfig_2.0.1 
> 



On Thu, 23-Aug-2018 at 07:23AM -0700, Jeff Newmiller wrote:

|> This is not reproducible because you have not provided the plot code or sample data. Output of sessionInfo would probably be appropriate as well.
|> 
|> As to whether needing to load objects is typical... yes, rmarkdown runs from a fresh environment to emphasize reproducibility, but your load command is bypassing that for us.
|> 
|> On August 23, 2018 2:15:19 AM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
|> >I'm having difficulty getting plots into ioslides.  

[...]


-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Aug 25 13:53:31 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 25 Aug 2018 07:53:31 -0400
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180825102146.GD13179@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
Message-ID: <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>

On 25/08/2018 6:21 AM, Patrick Connolly wrote:
> ---
> title: "Barking up the wrong tree"
> author: "Patrick Connolly"
> date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
> output:
>    ioslides_presentation: default
>    slidy_presentation: default
>    beamer_presentation: default
> ---
> 
> ```{r global_options, echo=FALSE}
> knitr::opts_chunk$set(tidy=TRUE,
>                        warning=FALSE,
>                        message=FALSE,
>                        cache=FALSE,
>                        dpi = 300)

Drop the dpi setting and it will work fine.

Duncan Murdoch

>           
> ```
> ## 6 different Regression Trees
> 
> ```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
> 
>   par(mfrow = c(2, 3))
> plot(1:10)
> plot(12:4)
> plot(seq(0, 800))
> plot(-100:-900)
> plot(12:50)
> plot(90:54)
> ```



From edd @end|ng |rom deb|@n@org  Sat Aug 25 14:45:33 2018
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Sat, 25 Aug 2018 07:45:33 -0500
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
 <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
Message-ID: <23425.20333.436940.985925@rob.eddelbuettel.com>


Rolf,

I noticed this thread started by you as well as a few of the excellent
follow-ups. While it conclcuded, allow me a few quick comments:

 - Some of us go through some effort to provide R on Ubuntu (and Debian) in a
   reliable and reproducible manner. And it works and is used by many people.

 - The basic r-base (and r-base-core etc) packages work in the distribution,
   but may be older as the distribution is taken as snapshots in time.  Hence
   the Ubuntu mirror via CRAN. That way you get a choice between eg R 3.4.4
   (not that old) and R 3.5.1. (brand new) in the current Ubuntu 18.04.

 - The (short) instructions at CRAN work: add a repo, install from it.
   Neither they nor the longer (more recent) blog post you found (which says
   the same, with more pictures) suggest to link or move libraries around.

 - We even have "proof" in the sense of fully automated build and use
   systems. Docker is just one example.  Eg this Dockerfile build the r-base
   container available as rocker/r-base (as well as the official r-base)
      https://github.com/rocker-org/rocker/blob/master/r-base/Dockerfile
   and eg this one use it and builds on top to generated an RStudio container
      https://github.com/rocker-org/rocker/blob/master/rstudio/testing/Dockerfile 
   Nowhere in either of these "recipes" are library files moved, renamed, or
   otherwise altered.

 - Nobody ever suggested for _any_ Linux distribution to mix its files below
   /usr with your own compilation.  There lies madness, and it may be the
   root cause of the behaviour local to your machine.  Don't do it.

 - Please consider asking Debian and Ubuntu related questions on r-sig-debian.  

Regards, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org



From @h|v|pmp82 @end|ng |rom gm@||@com  Sat Aug 25 16:00:47 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Sat, 25 Aug 2018 19:30:47 +0530
Subject: [R] NaN in Scoring Sentiment
Message-ID: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>

Hi All- I am running a sentiment scoring model and the code is as below:
sentiments_per_Category <- aggregate(relative_sentiment_frequencies,
                                     by = list(Category =
df$Case.Category), mean)

while i run the head command most of the values are NaN. i then used
complete.cases on my data frame
df[complete.cases(df),]
 but it does not seems to work. Please advice if there is a way to handle
NaN.

Regards, Shivi

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug 25 16:21:47 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 25 Aug 2018 07:21:47 -0700
Subject: [R] NaN in Scoring Sentiment
In-Reply-To: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
References: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
Message-ID: <0B0C9A04-27A4-4F4C-A178-BA45110C3506@dcn.davis.ca.us>

Did you keep the resulting complete cases version of df?

dfc <- df[complete.cases(df),]

and then use that as input?

On August 25, 2018 7:00:47 AM PDT, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>Hi All- I am running a sentiment scoring model and the code is as
>below:
>sentiments_per_Category <- aggregate(relative_sentiment_frequencies,
>                                     by = list(Category =
>df$Case.Category), mean)
>
>while i run the head command most of the values are NaN. i then used
>complete.cases on my data frame
>df[complete.cases(df),]
>but it does not seems to work. Please advice if there is a way to
>handle
>NaN.
>
>Regards, Shivi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From t@n@@@ @end|ng |rom gm@||@com  Sat Aug 25 16:24:40 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 25 Aug 2018 07:24:40 -0700
Subject: [R] installing R 3.5.1
In-Reply-To: <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
 <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>
Message-ID: <CA+JEM02_tV3qFoNK9AdggePEit7KBnDj1eYiL6AEbRX=bp9ULg@mail.gmail.com>

Dear Berwin, thank you for your help.

On my system, after "sudo apt-get install r-base r-recommended", it says :
[..]
The following packages have unmet dependencies:
 r-recommended : Depends: r-cran-kernsmooth (>= 2.2.14) but it is not going
to be installed
                 Depends: r-cran-mass but it is not going to be installed
                 Depends: r-cran-class but it is not going to be installed
                 Depends: r-cran-nnet but it is not going to be installed
E: Unable to correct problems, you have held broken packages.

Although these packages seem to be well installed ..

On Sat, Aug 25, 2018 at 12:51 AM Berwin A Turlach <berwin.turlach at gmail.com>
wrote:

> G'day Bogdan,
>
> On Fri, 24 Aug 2018 18:28:59 -0700
> Bogdan Tanasa <tanasa at gmail.com> wrote:
>
> > I am trying to install R 3.5.1 on my Ubuntu 14.04 system; however, I
> > am getting the following message :
> >
> > sudo apt-get install r-base
> > [...]
> > The following packages have unmet dependencies:
> >  r-base : Depends: r-recommended (= 3.5.1-1trusty) but it is not
> > going to be installed
> > E: Unable to correct problems, you have held broken packages.
>
> For me such problems are usually fixed by specifying the package that
> "is not going to be installed" but on which the package I want to
> install depends also to apt-get install.
>
> What does
>         sudo apt-get install r-base r-recommended
> do on your system?
>
> Cheers,
>
>         Berwin
>

	[[alternative HTML version deleted]]



From t@n@@@ @end|ng |rom gm@||@com  Sat Aug 25 16:27:20 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 25 Aug 2018 07:27:20 -0700
Subject: [R] installing R 3.5.1
Message-ID: <CA+JEM03v-nMsKdzg-R7iEX8maOcL7pyRf8xYgdUh4JQ-eu5yOQ@mail.gmail.com>

Dear Benoit, many thanks for your suggestions. Have a good weekend !

Message: 26
Date: Sat, 25 Aug 2018 11:13:49 +0200
From: Benoit Vaillant <benoit.vaillant at no-log.org>
To: Bogdan Tanasa <tanasa at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] installing R 3.5.1
Message-ID: <20180825091348.7tidm7fvhiudr35d at auroras.fr>
Content-Type: text/plain; charset="iso-8859-15"

Hello Bogdan,

This reply is off topic for the list, appologies. This problem is more
r-sig-debian related (see below).

Though Berwin already mentionned a possible solution, here is another.

On Fri, Aug 24, 2018 at 06:28:59PM -0700, Bogdan Tanasa wrote:
> I am trying to install R 3.5.1 on my Ubuntu 14.04 system;

You are trying to install R (latest version) on a system that is
outdated by the latest LTS (16.04) and more than four years old
now. ;-)

If you go to: https://cloud.r-project.org/bin/linux/ubuntu/

You'll get some hints, like:
"R 3.5 packages for Ubuntu on i386 and amd64 are available for most
stable Desktop releases of Ubuntu until their official end of life
date. However, only the latest Long Term Support (LTS) release is
fully supported."

Note the *only the latest LTS* ;-)

You'll also get the r-sig-debian list link to report issues.

> Would you please advise, what shall I do next ? Thanks a lot !

If you have the time, upgrade your LTS by migrating your system from
14.04 to 16.04 and then 18.04 (Bionic Beaver).

Best regards,

-- 
Beno?t

	[[alternative HTML version deleted]]



From berw|n@tur|@ch @end|ng |rom gm@||@com  Sat Aug 25 16:59:18 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Sat, 25 Aug 2018 22:59:18 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
 <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
Message-ID: <20180825225918.1f91a9cc@absentia>

G'day Rolf,

On Sat, 25 Aug 2018 11:20:09 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> I was pretty sure that the foregoing was a complete red herring.  And
> I was right.

I am not sure whether I agree. :)
 
> I have been told by younger and wiser heads that installing from
> source is The Right Thing to Do. 

Younger heads probably have more time on their hands to play around
with installing from source and debugging when things go wrong.  Wiser
heads probably have figured out how they should do so in the first
place. :)

Seriously, years ago I installed quite a bit of software from source,
also to always have the newest version.  And while I was using Debian
unstable I accepted that from time to time an update would leave me
with a broken system and I would have to spend some time to fix it
again.  Nowadays, I rather spend my time on other things and so am
happy to go with most software with whatever version the package
installer of Ubuntu installs.

The one exception is R, but that is for various good reasons:
  * I want to have the 32 bit and 64 bit architecture installed so
    that I can test my packages on both packages.  
  * I would like to keep old versions around, to test my packages on
    them
  * I like to use the R version that is installed in our computer
    lab when preparing teaching material, and the newest version
    otherwise.

If I ever get the feeling that all these points are easily achievable
with the compiled packages (without having to play around with docker,
sandboxes etc), I would stop compiling R from source.

> Moreover I'd always had the impression that the version of R provided
> by the package manager persistently lags one or two releases behind
> the current version.

From the official repositories, yes.  But CRAN provides since longer
than I can remember up-to-date binary packages for the most common
Linux distributions.  AFAIK, Debian and Ubuntu packages are available
thanks to Dirk Eddelbuettel (initially? mainly?) and others.

> The process for installing R using the package manager is far from 
> straightforward and few people give clear instructions on this issue.

1.) Start a web browser
2.) Go to your favourite CRAN server
3.) Select 'Download R for Linux'
4.) Select the directory "ubuntu/" from the page that is served
5.) Select README.html from the page that is served
6.) Follow the instructions

> (Instructions are usually incomplete and full of jargon and acronyms 
> that the instructors blithely assume assume that the instructees 
> understand.  

I am sure (some) of my students have the same complains about my
lecturing....   

> (They *don't*! In this instance (mirabile dictu!) I managed (using
> Uncle Google) 

You were lucky in this case, usually Uncle Google serves me with
somewhat out-dated (if not wrong) information when I run into a
technical problem with linux.....

> to find very clear and explicit instructions at:
> 
> https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart
> 
> I followed these instructions, and everything went swimmingly. 

You were lucky that you are not sitting behind a firewall (as I seem to
be, not sure whom I have to thank for that).  For me the first step
(installing the GPG key) fails and some further googling was
necessary.  Though, I was working from the CRAN instructions.

> Interestingly (???) the "new" R was installed in /usr/bin and not in 
> /usr/local/bin.

Of course, it is a system Ubuntu package, so it installs to /usr/bin.

> I then tried issuing the command:
> 
>      rstudio
> 
> Exactly the same pop-up error.  No help at all, as I expected.

O.k., as I got a new machine, I installed (X)ubuntu 18.04 from scratch,
no update from an earlier version.  The R version installed from
r-base-core was R 3.4.4.  In a terminal in which I manipulated my PATH
variable so that /usr/bin is early on, I could start R without problem,
and I could start rstudio without problem.

After following the instructions on CRAN and updating my apt
information, I have now R 3.5.1 installed.  And it starts fine from the
command line as does rstudio.  And rstudio starts now with R 3.5.1.

Both these packages work out of the box.  Thus I wonder whether you
have somehow messed up your system during the attempt to install R from
source.  Or have some environment variables set that provide rstudio
with wrong information....

> Then finally, in desperation, I copied libR.so from /usr/lib/R/lib to
> /usr/lib64/R/lib.  Bingo!!!  I can now start Rstudio!!!

I keep wondering why you have a /usr/lib64.

On my Ubuntu boxes, in /usr I have /lib, /lib32 and /libx32, but no
lib64.  As far as I know, Debian/Ubuntu 64bit implementations always
used /usr/lib for its 64 bit libraries and /usr/lib32 for the 32 bit
versions (unlike other distributions who used /usr/lib64 for the former
and /usr/lib for the latter).

In fact, a 'locate /lib64' on my Ubuntu 18.04 system (less than 2 week
old fresh installation) shows:

/lib64
/lib64/ld-linux-x86-64.so.2
/usr/src/linux-headers-4.15.0-32/arch/sh/lib64
/usr/src/linux-headers-4.15.0-32/arch/sh/lib64/Makefile
/usr/src/linux-headers-4.15.0-33/arch/sh/lib64
/usr/src/linux-headers-4.15.0-33/arch/sh/lib64/Makefile

So there seems to be a /lib64, but no /usr/lib64.  How did you get
this?  And why does rstudio think it has to look into that directory?

> It remains mysterious to me why the symlink procedure did not work, 
> whereas making a copy of libR.so *did* work.

Agreed, that is somebody a mystery.

> However I guess this really doesn't matter.  It's now working.

Until it breaks again. :)

I would advise to start at some point with a clean Ubuntu installation,
and then restrict yourself to /usr/local and /opt when installing
software from source.  

Cheers,

	Berwin



From berw|n@tur|@ch @end|ng |rom gm@||@com  Sat Aug 25 17:02:25 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Sat, 25 Aug 2018 23:02:25 +0800
Subject: [R] installing R 3.5.1
In-Reply-To: <CA+JEM02_tV3qFoNK9AdggePEit7KBnDj1eYiL6AEbRX=bp9ULg@mail.gmail.com>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
 <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>
 <CA+JEM02_tV3qFoNK9AdggePEit7KBnDj1eYiL6AEbRX=bp9ULg@mail.gmail.com>
Message-ID: <20180825230225.5b31175e@absentia>

Dear Bogdan,

On Sat, 25 Aug 2018 07:24:40 -0700
Bogdan Tanasa <tanasa at gmail.com> wrote:

> installed E: Unable to correct problems, you have held broken
> packages.

Perhaps this is the problem, did you try "apt-get -f install"?

Cheers,

	Berwin



From t@n@@@ @end|ng |rom gm@||@com  Sat Aug 25 18:00:59 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 25 Aug 2018 09:00:59 -0700
Subject: [R] installing R 3.5.1
In-Reply-To: <20180825230225.5b31175e@absentia>
References: <CA+JEM00Zx5jrUP_Yj--szPBHy3_2F+FTKF0VjYd6op-97Vynxw@mail.gmail.com>
 <20180825155125.61afbe99@ECM-DTC-716.uniwa.uwa.edu.au>
 <CA+JEM02_tV3qFoNK9AdggePEit7KBnDj1eYiL6AEbRX=bp9ULg@mail.gmail.com>
 <20180825230225.5b31175e@absentia>
Message-ID: <CA+JEM02MaMmMRem_cpV-iVE-BS9HJ3LwKU_2yOz2RXw=h9xPiw@mail.gmail.com>

Dear Berwin, thank you very much . I guess that I shall update my Ubuntu OS
;

after "sudo apt-get -f install", I am getting the same message :

The following packages have unmet dependencies:
 r-recommended : Depends: r-cran-kernsmooth (>= 2.2.14) but it is not going
to be installed
                 Depends: r-cran-mass but it is not going to be installed
                 Depends: r-cran-class but it is not going to be installed
                 Depends: r-cran-nnet but it is not going to be installed
E: Unable to correct problems, you have held broken packages.


On Sat, Aug 25, 2018 at 8:02 AM, Berwin A Turlach <berwin.turlach at gmail.com>
wrote:

> Dear Bogdan,
>
> On Sat, 25 Aug 2018 07:24:40 -0700
> Bogdan Tanasa <tanasa at gmail.com> wrote:
>
> > installed E: Unable to correct problems, you have held broken
> > packages.
>
> Perhaps this is the problem, did you try "apt-get -f install"?
>
> Cheers,
>
>         Berwin
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug 25 18:57:29 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 25 Aug 2018 09:57:29 -0700
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
References: <CAGchuN7iL5hi_SbqvG81s+v+oR1h9iyAuADZh-R=DD197QUQ3g@mail.gmail.com>
Message-ID: <753893CA-5D0B-4CB6-9EAD-620ADCF07BC8@dcn.davis.ca.us>

look at the map2 function in the purrr package.

On August 24, 2018 6:44:19 AM PDT, Deepa <deepamahm.iisc at gmail.com> wrote:
>Hello,
>
>Is there an option to include multiple counters in a single for loop in
>R?
>
>For instance, in python there is
>
>for i,j in zip(x,range(0,len(x))):
>
>
>Any suggestions?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From jeremiejuste m@iii@g oii gm@ii@com  Sat Aug 25 19:47:21 2018
From: jeremiejuste m@iii@g oii gm@ii@com (jeremiejuste m@iii@g oii gm@ii@com)
Date: Sat, 25 Aug 2018 19:47:21 +0200
Subject: [R] Multiple counters in a single for loop
Message-ID: <5b819653.1c69fb81.47916.a598@mx.google.com>

Hello,
I'm aware it is not the answer you are expecting but indexes are not that bad to implement as well.

for ( i in 1:length(var1)){
elem1 <-var1[i]
elem2 <-  var2[i]


}

if you want more abstraction you could then wrap that up in a function

HTHOn 25 Aug 2018 18:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> look at the map2 function in the purrr package. 
>
> On August 24, 2018 6:44:19 AM PDT, Deepa <deepamahm.iisc at gmail.com> wrote: 
> >Hello, 
> > 
> >Is there an option to include multiple counters in a single for loop in 
> >R? 
> > 
> >For instance, in python there is 
> > 
> >for i,j in zip(x,range(0,len(x))): 
> > 
> > 
> >Any suggestions? 
> > 
> > [[alternative HTML version deleted]] 
> > 
> >______________________________________________ 
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> >https://stat.ethz.ch/mailman/listinfo/r-help 
> >PLEASE do read the posting guide 
> >http://www.R-project.org/posting-guide.html 
> >and provide commented, minimal, self-contained, reproducible code. 
>
> -- 
> Sent from my phone. Please excuse my brevity. 
>
> ______________________________________________ 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 

From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Aug 25 22:12:32 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 25 Aug 2018 16:12:32 -0400
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <5b819653.1c69fb81.47916.a598@mx.google.com>
References: <5b819653.1c69fb81.47916.a598@mx.google.com>
Message-ID: <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com>

On 25/08/2018 1:47 PM, jeremiejuste at gmail.com wrote:
> Hello,
> I'm aware it is not the answer you are expecting but indexes are not that bad to implement as well.
> 
> for ( i in 1:length(var1)){

This is generally a bad idea:  if length(var1) == 0, it does the wrong 
thing, since 1:0 is c(1L, 0L).  Better to use

for ( i in seq_along(var1) ) {

Duncan Murdoch

> elem1 <-var1[i]
> elem2 <-  var2[i]
> 
> 
> }
> 
> if you want more abstraction you could then wrap that up in a function
> 
> HTHOn 25 Aug 2018 18:57, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> look at the map2 function in the purrr package.
>>
>> On August 24, 2018 6:44:19 AM PDT, Deepa <deepamahm.iisc at gmail.com> wrote:
>>> Hello,
>>>
>>> Is there an option to include multiple counters in a single for loop in
>>> R?
>>>
>>> For instance, in python there is
>>>
>>> for i,j in zip(x,range(0,len(x))):
>>>
>>>
>>> Any suggestions?
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> -- 
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Sun Aug 26 01:37:02 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Sun, 26 Aug 2018 11:37:02 +1200
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
Message-ID: <20180825233702.GE13179@slingshot.co.nz>

On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:

|> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
|> >---
|> >title: "Barking up the wrong tree"
|> >author: "Patrick Connolly"
|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
|> >output:
|> >   ioslides_presentation: default
|> >   slidy_presentation: default
|> >   beamer_presentation: default
|> >---
|> >
|> >```{r global_options, echo=FALSE}
|> >knitr::opts_chunk$set(tidy=TRUE,
|> >                       warning=FALSE,
|> >                       message=FALSE,
|> >                       cache=FALSE,
|> >                       dpi = 300)
|> 
|> Drop the dpi setting and it will work fine.

Still doesn't avoid what I think is the issue with Cairo

   Error in axis(side = side, at = at, labels = labels, ...) : X11
  font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12
  could not be loaded Calls: <Anonymous> ... plot.default -> localAxis
  -> Axis -> Axis.default -> axis

  Execution halted


For interactive plotting, Rstudio plots those 6 plots on one page so
no issue is apparent, as it will if I use a pdf device within ESS.
However, when plotting interactively in ESS, a basic font is used for
the labels which is OK for preliminary quick look.  No error message
is shown, but I suspect that it is defaulting to a crude font because
the helvetica font is not available.

It appears to me that the font problem doesn't arise with Rstudio
unless the desired output is ioslides.  Which brings us back to the
issue with Cairo.  There are lots of hits when I search for
configuring fonts, Cairo and R but I've not found anything I can use.

I would appreciate pointers where I can find useful information.

Thank you.

|> 
|> Duncan Murdoch
|> 
|> >```
|> >## 6 different Regression Trees
|> >
|> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
|> >
|> >  par(mfrow = c(2, 3))
|> >plot(1:10)
|> >plot(12:4)
|> >plot(seq(0, 800))
|> >plot(-100:-900)
|> >plot(12:50)
|> >plot(90:54)
|> >```

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug 26 02:10:14 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 25 Aug 2018 20:10:14 -0400
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180825233702.GE13179@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
 <20180825233702.GE13179@slingshot.co.nz>
Message-ID: <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>

On 25/08/2018 7:37 PM, Patrick Connolly wrote:
> On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:
> 
> |> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
> |> >---
> |> >title: "Barking up the wrong tree"
> |> >author: "Patrick Connolly"
> |> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
> |> >output:
> |> >   ioslides_presentation: default
> |> >   slidy_presentation: default
> |> >   beamer_presentation: default
> |> >---
> |> >
> |> >```{r global_options, echo=FALSE}
> |> >knitr::opts_chunk$set(tidy=TRUE,
> |> >                       warning=FALSE,
> |> >                       message=FALSE,
> |> >                       cache=FALSE,
> |> >                       dpi = 300)
> |>
> |> Drop the dpi setting and it will work fine.
> 
> Still doesn't avoid what I think is the issue with Cairo
> 
>     Error in axis(side = side, at = at, labels = labels, ...) : X11
>    font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12
>    could not be loaded Calls: <Anonymous> ... plot.default -> localAxis
>    -> Axis -> Axis.default -> axis
> 
>    Execution halted
> 
> 
> For interactive plotting, Rstudio plots those 6 plots on one page so
> no issue is apparent, as it will if I use a pdf device within ESS.

So use RStudio, don't use ESS.

> However, when plotting interactively in ESS, a basic font is used for
> the labels which is OK for preliminary quick look.  No error message
> is shown, but I suspect that it is defaulting to a crude font because
> the helvetica font is not available.
> 
> It appears to me that the font problem doesn't arise with Rstudio
> unless the desired output is ioslides.  Which brings us back to the
> issue with Cairo.  There are lots of hits when I search for
> configuring fonts, Cairo and R but I've not found anything I can use.
> 

I don't see a font problem in MacOS.  I don't think you've stated what 
system you are using (but I may have missed it).

Duncan Murdoch

> I would appreciate pointers where I can find useful information.
> 
> Thank you.
> 
> |>
> |> Duncan Murdoch
> |>
> |> >```
> |> >## 6 different Regression Trees
> |> >
> |> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
> |> >
> |> >  par(mfrow = c(2, 3))
> |> >plot(1:10)
> |> >plot(12:4)
> |> >plot(seq(0, 800))
> |> >plot(-100:-900)
> |> >plot(12:50)
> |> >plot(90:54)
> |> >```
>



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug 26 03:00:34 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 26 Aug 2018 13:00:34 +1200
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <20180825225918.1f91a9cc@absentia>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
 <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
 <20180825225918.1f91a9cc@absentia>
Message-ID: <12ea011e-250e-e8ab-d589-42491b6547b5@auckland.ac.nz>


On 08/26/2018 02:59 AM, Berwin A Turlach wrote:

> G'day Rolf,
> 
> On Sat, 25 Aug 2018 11:20:09 +1200
> Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
>> I was pretty sure that the foregoing was a complete red herring.  And
>> I was right.
> 
> I am not sure whether I agree. :)

Huh?  Black is white and up is down???

I did as advised and it made absolutely no difference.  Ergo  I was right.

<SNIP>

> I keep wondering why you have a /usr/lib64.

<SNIP>

> .... How did you get this? 

I have no idea.  It just seems to be there.  And it seems that rstudio 
thinks that it should be there.

> And why does rstudio think it has to look into that directory?
How would I know?  You would have to ask RStudio, not me.

Anyway, I seem to have (for the time being at least) a working system, 
and I don't feel like wasting any more time on this issue.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From berw|n@tur|@ch @end|ng |rom gm@||@com  Sun Aug 26 07:29:48 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Sun, 26 Aug 2018 13:29:48 +0800
Subject: [R] R shared library (/usr/lib64/R/lib/libR.so) not found.
In-Reply-To: <12ea011e-250e-e8ab-d589-42491b6547b5@auckland.ac.nz>
References: <46eb5863-b806-3b85-d7c8-4192c8b6c1ea@auckland.ac.nz>
 <CA+vqiLFGm05Bjk41P-tR3mX3yp3f60aFvcTDR0bqjkJU8V+M7A@mail.gmail.com>
 <3bec4567-c706-ce8e-fda3-13f48ec251f4@auckland.ac.nz>
 <20180825225918.1f91a9cc@absentia>
 <12ea011e-250e-e8ab-d589-42491b6547b5@auckland.ac.nz>
Message-ID: <20180826132948.65495dfe@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Rolf,

On Sun, 26 Aug 2018 13:00:34 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 08/26/2018 02:59 AM, Berwin A Turlach wrote:
>
> > I am not sure whether I agree. :)  
> 
> Huh?  Black is white and up is down???

Nope, but as I said, on my machine RStudio and the R installed from the
Ubuntu repositories worked out of the box.

After adding the CRAN repositories to my apt configuration and
upgrading R, RStudio and the new R version worked again out of the box.

For the R versions that I compile from source, as I install sub
architectures, I need to install symbol links from where libR.so
actually is to where Rstudio expects them.  And RStudio works out of
the box with all these installation, i.e. it seems to follow symbolic
links.
 
> I did as advised and it made absolutely no difference.  Ergo  I was
> right.

That is your conclusion from the data, are you are perfectly entitled
to it. :)

I still think that this is one of the 5% of the cases where you got
your inference wrong.  Given that for me (and presumably many others
[but I neither follow r-sig-Debian nor the Rstudio forums, so I may
have a biased input]) everything works out of the box, my conclusion
from the data is that you have FUBAR'd your system.

Now, this can be from the way you tried to compile R from source (you
never told us what you exactly specified to ./configure, but we would
also have to know whether you made changes to config.site before
compilation) or it could be from some environment variables (set long
time ago and since forgotten [if so, where is it set ~/.bashrc? ~/.R?). 

> <SNIP>
> 
> > I keep wondering why you have a /usr/lib64.  
> 
> <SNIP>
> 
> > .... How did you get this?   
> 
> I have no idea.  It just seems to be there.  And it seems that
> rstudio thinks that it should be there.

As far as I can tell, RStudio expects libR.so in a certain directory
relative to where the home directory (as reported by R on query) of R.
But RStudio's behaviour can also be influenced by environment variable.
 
So the fact that RStudio keeps looking at /usr/lib64 is for me evidence
that your system is compromised, and that RStudio is not starting the
version of R installed from the Ubuntu package manager.

> Anyway, I seem to have (for the time being at least) a working
> system, and I don't feel like wasting any more time on this issue.

Fair enough, but I am concerned that this issue will raise it head
sooner or later again.  So my final advice is to stick to the old adage
from sports: Never change a winning team.  If you system works for you
know, freeze it.  No more updates/upgrades.   Otherwise, good luck when
you try to update R next....

Cheers,
	
	Berwin



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug 26 08:35:03 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 25 Aug 2018 23:35:03 -0700
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
 <20180825233702.GE13179@slingshot.co.nz>
 <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
Message-ID: <7558075D-115E-4B6D-9486-29608FBEF4DC@dcn.davis.ca.us>

a) Duncan, he provided sessionInfo below his reprex.

b) Patrick: you appear to be trying to use a common file to generate multiple output formats. I will caution you that I have found considerable disappointment in trying that, and suggest that you focus your efforts on one output format for each Rmd file.

c) You can add out.width="100%" and out.height="100%" to your chunk to fix the scaling problem. This method is HTML-specific... you would need different strings for LaTeX output.

d) Note that the help files for the rmarkdown output functions are often very interesting. e.g.

?rmarkdown::ioslides_presentation

On August 25, 2018 5:10:14 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 25/08/2018 7:37 PM, Patrick Connolly wrote:
>> On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:
>> 
>> |> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
>> |> >---
>> |> >title: "Barking up the wrong tree"
>> |> >author: "Patrick Connolly"
>> |> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
>> |> >output:
>> |> >   ioslides_presentation: default
>> |> >   slidy_presentation: default
>> |> >   beamer_presentation: default
>> |> >---
>> |> >
>> |> >```{r global_options, echo=FALSE}
>> |> >knitr::opts_chunk$set(tidy=TRUE,
>> |> >                       warning=FALSE,
>> |> >                       message=FALSE,
>> |> >                       cache=FALSE,
>> |> >                       dpi = 300)
>> |>
>> |> Drop the dpi setting and it will work fine.
>> 
>> Still doesn't avoid what I think is the issue with Cairo
>> 
>>     Error in axis(side = side, at = at, labels = labels, ...) : X11
>>    font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size
>12
>>    could not be loaded Calls: <Anonymous> ... plot.default ->
>localAxis
>>    -> Axis -> Axis.default -> axis
>> 
>>    Execution halted
>> 
>> 
>> For interactive plotting, Rstudio plots those 6 plots on one page so
>> no issue is apparent, as it will if I use a pdf device within ESS.
>
>So use RStudio, don't use ESS.
>
>> However, when plotting interactively in ESS, a basic font is used for
>> the labels which is OK for preliminary quick look.  No error message
>> is shown, but I suspect that it is defaulting to a crude font because
>> the helvetica font is not available.
>> 
>> It appears to me that the font problem doesn't arise with Rstudio
>> unless the desired output is ioslides.  Which brings us back to the
>> issue with Cairo.  There are lots of hits when I search for
>> configuring fonts, Cairo and R but I've not found anything I can use.
>> 
>
>I don't see a font problem in MacOS.  I don't think you've stated what 
>system you are using (but I may have missed it).
>
>Duncan Murdoch
>
>> I would appreciate pointers where I can find useful information.
>> 
>> Thank you.
>> 
>> |>
>> |> Duncan Murdoch
>> |>
>> |> >```
>> |> >## 6 different Regression Trees
>> |> >
>> |> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE,
>fig.width = 7, fig.height = 5}
>> |> >
>> |> >  par(mfrow = c(2, 3))
>> |> >plot(1:10)
>> |> >plot(12:4)
>> |> >plot(seq(0, 800))
>> |> >plot(-100:-900)
>> |> >plot(12:50)
>> |> >plot(90:54)
>> |> >```
>> 

-- 
Sent from my phone. Please excuse my brevity.



From jerem|eju@te @end|ng |rom gm@||@com  Sun Aug 26 09:10:45 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Sun, 26 Aug 2018 09:10:45 +0200
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com> (Duncan
 Murdoch's message of "Sat, 25 Aug 2018 16:12:32 -0400")
References: <5b819653.1c69fb81.47916.a598@mx.google.com>
 <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com>
Message-ID: <87pny5mwlm.fsf@gmail.com>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

>> for ( i in 1:length(var1)){
>
> This is generally a bad idea:  if length(var1) == 0, it does the wrong
> thing, since 1:0 is c(1L, 0L).  Better to use
>
> for ( i in seq_along(var1) ) {
>


granted. One should check the validity of their variables before using
them but I argue that seq_along does not protect you from the
unexpected behaviour.

If the length of var1 should not be 0 so

stopifnot(length(var)==0) 
for ( i in 1:length(var1)){

    elem1 <-var1[i]
    elem2 <-  var2[i]

}



From jerem|eju@te @end|ng |rom gm@||@com  Sun Aug 26 09:27:01 2018
From: jerem|eju@te @end|ng |rom gm@||@com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Sun, 26 Aug 2018 09:27:01 +0200
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <87pny5mwlm.fsf@gmail.com>
References: <5b819653.1c69fb81.47916.a598@mx.google.com>
 <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com>
 <87pny5mwlm.fsf@gmail.com>
Message-ID: <CAPHJcdBgYEPUnF8P765CZ4X6TecZZ_v0YWAfZr0oQbK9_1Q37Q@mail.gmail.com>

Of course I meant

>If the length of var1 should not be 0 so

stopifnot(length(var)>0)

On Sun, Aug 26, 2018 at 9:10 AM, Jeremie Juste <jeremiejuste at gmail.com>
wrote:

> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
>
> >> for ( i in 1:length(var1)){
> >
> > This is generally a bad idea:  if length(var1) == 0, it does the wrong
> > thing, since 1:0 is c(1L, 0L).  Better to use
> >
> > for ( i in seq_along(var1) ) {
> >
>
>
> granted. One should check the validity of their variables before using
> them but I argue that seq_along does not protect you from the
> unexpected behaviour.
>
> If the length of var1 should not be 0 so
>
> stopifnot(length(var)==0)
> for ( i in 1:length(var1)){
>
>     elem1 <-var1[i]
>     elem2 <-  var2[i]
>
> }
>



-- 
J?r?mie Juste

	[[alternative HTML version deleted]]



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Sun Aug 26 10:40:32 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Sun, 26 Aug 2018 20:40:32 +1200
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
 <20180825233702.GE13179@slingshot.co.nz>
 <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
Message-ID: <20180826084032.GA6042@slingshot.co.nz>

On Sat, 25-Aug-2018 at 08:10PM -0400, Duncan Murdoch wrote:

|> On 25/08/2018 7:37 PM, Patrick Connolly wrote:
|> >On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:
|> >
|> >|> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
|> >|> >---
|> >|> >title: "Barking up the wrong tree"
|> >|> >author: "Patrick Connolly"
|> >|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
|> >|> >output:
|> >|> >   ioslides_presentation: default
|> >|> >   slidy_presentation: default
|> >|> >   beamer_presentation: default
|> >|> >---
|> >|> >
|> >|> >```{r global_options, echo=FALSE}
|> >|> >knitr::opts_chunk$set(tidy=TRUE,
|> >|> >                       warning=FALSE,
|> >|> >                       message=FALSE,
|> >|> >                       cache=FALSE,
|> >|> >                       dpi = 300)
|> >|>
|> >|> Drop the dpi setting and it will work fine.
|> >
|> >Still doesn't avoid what I think is the issue with Cairo
|> >
|> >    Error in axis(side = side, at = at, labels = labels, ...) : X11
|> >   font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12
|> >   could not be loaded Calls: <Anonymous> ... plot.default -> localAxis
|> >   -> Axis -> Axis.default -> axis
|> >
|> >   Execution halted
|> >
|> >
|> >For interactive plotting, Rstudio plots those 6 plots on one page so
|> >no issue is apparent, as it will if I use a pdf device within ESS.
|> 
|> So use RStudio, don't use ESS.

I'm using Rstudio to try to output ioslides which runs into the font
problem which doesn't arise when plotting to the plot pane.  RStudio's
no advantage when the objective is ioslides.  That observation gives
rise to my hypothesis that to produce ioslides, Cairo is utilized in
ways incomprehensible to me.

|> 
|> >However, when plotting interactively in ESS, a basic font is used for
|> >the labels which is OK for preliminary quick look.  No error message
|> >is shown, but I suspect that it is defaulting to a crude font because
|> >the helvetica font is not available.
|> >
|> >It appears to me that the font problem doesn't arise with Rstudio
|> >unless the desired output is ioslides.  Which brings us back to the
|> >issue with Cairo.  There are lots of hits when I search for
|> >configuring fonts, Cairo and R but I've not found anything I can use.
|> >
|> 
|> I don't see a font problem in MacOS.  I don't think you've stated
|> what system you are using (but I may have missed it).

It has something to do with X11 which I guess MacOS doesn't use.

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
 [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] utils     stats     grDevices graphics  methods   base     

other attached packages:
[1] lattice_0.20-35

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.17     bindr_0.1.1      magrittr_1.5     tidyselect_0.2.4
 [5] munsell_0.5.0    colorspace_1.3-2 xtable_1.8-2     R6_2.2.2        
 [9] rlang_0.2.1      plyr_1.8.4       dplyr_0.7.6      tools_3.5.0     
[13] grid_3.5.0       htmltools_0.3.6  crosstalk_1.0.0  leaflet_2.0.1   
[17] assertthat_0.2.0 digest_0.6.15    tibble_1.4.2     bindrcpp_0.2.2  
[21] shiny_1.1.0      purrr_0.2.5      later_0.7.3      htmlwidgets_1.2 
[25] promises_1.0.1   glue_1.2.0       mime_0.5         compiler_3.5.0  
[29] pillar_1.2.3     scales_0.5.0     httpuv_1.4.4.2   pkgconfig_2.0.1 


|> 
|> Duncan Murdoch
|> 
|> >I would appreciate pointers where I can find useful information.
|> >
|> >Thank you.
|> >
|> >|>
|> >|> Duncan Murdoch
|> >|>
|> >|> >```
|> >|> >## 6 different Regression Trees
|> >|> >
|> >|> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
|> >|> >
|> >|> >  par(mfrow = c(2, 3))
|> >|> >plot(1:10)
|> >|> >plot(12:4)
|> >|> >plot(seq(0, 800))
|> >|> >plot(-100:-900)
|> >|> >plot(12:50)
|> >|> >plot(90:54)
|> >|> >```
|> >

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug 26 12:59:57 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 26 Aug 2018 06:59:57 -0400
Subject: [R] Multiple counters in a single for loop
In-Reply-To: <87pny5mwlm.fsf@gmail.com>
References: <5b819653.1c69fb81.47916.a598@mx.google.com>
 <7d0f3bf7-af64-fbbc-c9d0-1fc3edc0f630@gmail.com> <87pny5mwlm.fsf@gmail.com>
Message-ID: <57752b2b-c27d-e1fb-c0e0-59abd5321b19@gmail.com>

On 26/08/2018 3:10 AM, Jeremie Juste wrote:
> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
> 
>>> for ( i in 1:length(var1)){
>>
>> This is generally a bad idea:  if length(var1) == 0, it does the wrong
>> thing, since 1:0 is c(1L, 0L).  Better to use
>>
>> for ( i in seq_along(var1) ) {
>>
> 
> 
> granted. One should check the validity of their variables before using
> them but I argue that seq_along does not protect you from the
> unexpected behaviour.

I don't see why you argue that.  seq_along(var1) will give an empty 
vector if var1 is empty, so the loop won't run at all.

> 
> If the length of var1 should not be 0 so
> 
> stopifnot(length(var) > 0)
> for ( i in 1:length(var1)){
> 
>      elem1 <-var1[i]
>      elem2 <-  var2[i]
> 
> }

That's a possibility (I made your >0 correction), but maybe having 
length 0 isn't something that should trigger a fatal error, maybe it's 
just that no elements met some condition.

Duncan Murdoch



From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug 26 14:09:48 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 26 Aug 2018 08:09:48 -0400
Subject: [R] Plots in ioslides and R markdown
In-Reply-To: <20180826084032.GA6042@slingshot.co.nz>
References: <20180823091519.GB13179@slingshot.co.nz>
 <F4AC90FC-2F1B-44C8-BF3B-7AED3BB18017@dcn.davis.ca.us>
 <20180825102146.GD13179@slingshot.co.nz>
 <df6508a9-f91c-6988-d095-18d6b77cd405@gmail.com>
 <20180825233702.GE13179@slingshot.co.nz>
 <5964a56e-3ec3-2f0b-4506-522461cd6cda@gmail.com>
 <20180826084032.GA6042@slingshot.co.nz>
Message-ID: <1c32d8ed-eeb3-c7a4-c8bc-e81eabe7df69@gmail.com>

On 26/08/2018 4:40 AM, Patrick Connolly wrote:
> On Sat, 25-Aug-2018 at 08:10PM -0400, Duncan Murdoch wrote:
> 
> |> On 25/08/2018 7:37 PM, Patrick Connolly wrote:
> |> >On Sat, 25-Aug-2018 at 07:53AM -0400, Duncan Murdoch wrote:
> |> >
> |> >|> On 25/08/2018 6:21 AM, Patrick Connolly wrote:
> |> >|> >---
> |> >|> >title: "Barking up the wrong tree"
> |> >|> >author: "Patrick Connolly"
> |> >|> >date: "`r format(Sys.time(), '%a %d/%m/%Y %H:%M')`"
> |> >|> >output:
> |> >|> >   ioslides_presentation: default
> |> >|> >   slidy_presentation: default
> |> >|> >   beamer_presentation: default
> |> >|> >---
> |> >|> >
> |> >|> >```{r global_options, echo=FALSE}
> |> >|> >knitr::opts_chunk$set(tidy=TRUE,
> |> >|> >                       warning=FALSE,
> |> >|> >                       message=FALSE,
> |> >|> >                       cache=FALSE,
> |> >|> >                       dpi = 300)
> |> >|>
> |> >|> Drop the dpi setting and it will work fine.
> |> >
> |> >Still doesn't avoid what I think is the issue with Cairo
> |> >
> |> >    Error in axis(side = side, at = at, labels = labels, ...) : X11
> |> >   font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 12
> |> >   could not be loaded Calls: <Anonymous> ... plot.default -> localAxis
> |> >   -> Axis -> Axis.default -> axis
> |> >
> |> >   Execution halted
> |> >
> |> >
> |> >For interactive plotting, Rstudio plots those 6 plots on one page so
> |> >no issue is apparent, as it will if I use a pdf device within ESS.
> |>
> |> So use RStudio, don't use ESS.
> 
> I'm using Rstudio to try to output ioslides which runs into the font
> problem which doesn't arise when plotting to the plot pane.  RStudio's
> no advantage when the objective is ioslides.  That observation gives
> rise to my hypothesis that to produce ioslides, Cairo is utilized in
> ways incomprehensible to me.

Since that error happens during the axis() call, it's related to the 
graphics device that is being used.  That would be different for an 
ioslides document than it is for interactive display.  On my system (and 
I think on all systems) the png() device is used for ioslides.

If you run debug(png) then rmarkdown::render( <your Rmd file> ), you'll 
see what options are being passed to png.  On my system, it is called 
with no arguments except a filename, so it uses the defaults for all 
other arguments.  That means the "type" argument eventually gets set to 
"quartz".  Yours will be different, but I don't know what it will get. 
Maybe you can choose something different than the default by setting 
options("bitmapType").

Duncan Murdoch
> 
> |>
> |> >However, when plotting interactively in ESS, a basic font is used for
> |> >the labels which is OK for preliminary quick look.  No error message
> |> >is shown, but I suspect that it is defaulting to a crude font because
> |> >the helvetica font is not available.
> |> >
> |> >It appears to me that the font problem doesn't arise with Rstudio
> |> >unless the desired output is ioslides.  Which brings us back to the
> |> >issue with Cairo.  There are lots of hits when I search for
> |> >configuring fonts, Cairo and R but I've not found anything I can use.
> |> >
> |>
> |> I don't see a font problem in MacOS.  I don't think you've stated
> |> what system you are using (but I may have missed it).
> 
> It has something to do with X11 which I guess MacOS doesn't use.
> 
>> sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
> 
> Matrix products: default
> BLAS: /home/pat/local/R-3.5.0/lib/libRblas.so
> LAPACK: /home/pat/local/R-3.5.0/lib/libRlapack.so
> 
> locale:
>   [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>   [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>   [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] utils     stats     grDevices graphics  methods   base
> 
> other attached packages:
> [1] lattice_0.20-35
> 
> loaded via a namespace (and not attached):
>   [1] Rcpp_0.12.17     bindr_0.1.1      magrittr_1.5     tidyselect_0.2.4
>   [5] munsell_0.5.0    colorspace_1.3-2 xtable_1.8-2     R6_2.2.2
>   [9] rlang_0.2.1      plyr_1.8.4       dplyr_0.7.6      tools_3.5.0
> [13] grid_3.5.0       htmltools_0.3.6  crosstalk_1.0.0  leaflet_2.0.1
> [17] assertthat_0.2.0 digest_0.6.15    tibble_1.4.2     bindrcpp_0.2.2
> [21] shiny_1.1.0      purrr_0.2.5      later_0.7.3      htmlwidgets_1.2
> [25] promises_1.0.1   glue_1.2.0       mime_0.5         compiler_3.5.0
> [29] pillar_1.2.3     scales_0.5.0     httpuv_1.4.4.2   pkgconfig_2.0.1
> 
> 
> |>
> |> Duncan Murdoch
> |>
> |> >I would appreciate pointers where I can find useful information.
> |> >
> |> >Thank you.
> |> >
> |> >|>
> |> >|> Duncan Murdoch
> |> >|>
> |> >|> >```
> |> >|> >## 6 different Regression Trees
> |> >|> >
> |> >|> >```{r 6 different Regression Trees, echo = FALSE, messages=FALSE, fig.width = 7, fig.height = 5}
> |> >|> >
> |> >|> >  par(mfrow = c(2, 3))
> |> >|> >plot(1:10)
> |> >|> >plot(12:4)
> |> >|> >plot(seq(0, 800))
> |> >|> >plot(-100:-900)
> |> >|> >plot(12:50)
> |> >|> >plot(90:54)
> |> >|> >```
> |> >
>



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Sun Aug 26 23:08:38 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 17:08:38 -0400
Subject: [R] Help with DNA Methylation Analysis
Message-ID: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>

Good evening,

  I am attempting to run the following analysis on TCGA data, however
something is being reported as an error in my arguments... any ideas as to
what is incorrect in the following? Thanks!

1 library(TCGAbiolinks)
2
3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
4 path <? "."
5
6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
level = 3)
7 TCGAdownload(query.met, path = path )
8 met <? TCGAprepare(query = query.met,dir = path,
9                      add.subtype = TRUE, add.clinical = TRUE,
10                    summarizedExperiment = TRUE,
11                      save = TRUE, filename = "lgg_gbm_met.rda")
12
13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform = "IlluminaHiSeq_
RNASeqV2",level = 3)
15
16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
results")
17
18 exp <? TCGAprepare(query = query.exp, dir = path,
19                    summarizedExperiment = TRUE,
20                      add.subtype = TRUE, add.clinical = TRUE,
21                    type = "rsem.genes.normalized_results",
22                      save = T,filename = "lgg_gbm_exp.rda")

To download data on DNA methylation and gene expression?

1 library(summarizedExperiment)
2 # get expression matrix
3 data <? assay(exp)
4
5 # get sample information
6 sample.info <? colData(exp)
7
8 # get genes information
9 genes.info <? rowRanges(exp)

Following stepwise procedure for obtaining GBM and LGG clinical data?

1 # get clinical patient data for GBM samples
2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
3
4 # get clinical patient data for LGG samples
5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
6
7 # Bind the results, as the columns might not be the same,
8 # we will plyr rbind.fill , to have all columns from both files
9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
10
11 # Other clinical files can be downloaded,
12 # Use ?TCGAquery_clinic for more information
13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
14
15 # Also, you can get clinical information from different tumor types.
16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
18    samples = c("TCGA-06-5416-01A-01D-1481-05",
19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))


# Searching idat file for DNA methylation
query <- GDCquery(project = "TCGA-GBM",
                 data.category = "Raw microarray data",
                 data.type = "Raw intensities",
                 experimental.strategy = "Methylation array",
                 legacy = TRUE,
                 file.type = ".idat",
                 platform = "Illumina Human Methylation 450")

**Repeat for LGG**

To access mutational information concerning TMZ methylation?

> mutation <? TCGAquery_maf(tumor = "lgg")
2   Getting maf tables
3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
4   We found these maf files below:
5       MAF.File.Name
6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
7
8   3 LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
9
10       Archive.Name Deploy.Date
11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
  10-DEC-13
12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0   24-DEC-14
13
14   Please, select the line that you want to download: 3

**Repeat this for GBM***

Selecting specified lines to download?

1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)



Downloading data via the Bioconductor package RTCGAtoolbox?

library(RTCGAToolbox)
2
3 # Get the last run dates
4 lastRunDate <? getFirehoseRunningDates()[1]
5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
6
7 # get DNA methylation data, RNAseq2 and clinical data for LGG
8 lgg.data <? getFirehoseData(dataset = "LGG",
9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate = lastRunDate,
10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
11       Mutation = T,
12       fileSizeLimit = 10000)
13
14 # get DNA methylation data, RNAseq2 and clinical data for GBM
15 gbm.data <? getFirehoseData(dataset = "GBM",
16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
18       fileSizeLimit = 10000)
19
20 # To access the data you should use the getData function
21 # or simply access with @ (for example gbm.data at Clinical)
22 gbm.mut <? getData(gbm.data,"Mutations")
23 gbm.clin <? getData(gbm.data,"Clinical")
24 gbm.gistic <? getData(gbm.data,"GISTIC")






Genomic Analysis/Final data extraction:

Enable ?getData? to access the data

Obtaining GISTIC results?

1 # Download GISTIC results
2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
3
4 # get GISTIC results
5 gistic.allbygene <? gistic at GISTIC@AllByGene
6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene

Repeat this procedure to obtain LGG GISTIC results.

***Please ignore the 'non-coded' text as they are procedural
steps/classifications***

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Sun Aug 26 23:36:59 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 26 Aug 2018 14:36:59 -0700
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
Message-ID: <CAGxFJbQPXwDMxj9WUcP+Qz8MsFiPZ5uqrezOCcJBQX=DxT+DFg@mail.gmail.com>

You should probably post this on the Bioconductor list rather then here, as
you would more likely find the expertise you seek there. You are using
Bioconductor packages after all.

https://support.bioconductor.org/

Cheers,
Bert


On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Good evening,
>
>   I am attempting to run the following analysis on TCGA data, however
> something is being reported as an error in my arguments... any ideas as to
> what is incorrect in the following? Thanks!
>
> 1 library(TCGAbiolinks)
> 2
> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> 4 path <? "."
> 5
> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
> level = 3)
> 7 TCGAdownload(query.met, path = path )
> 8 met <? TCGAprepare(query = query.met,dir = path,
> 9                      add.subtype = TRUE, add.clinical = TRUE,
> 10                    summarizedExperiment = TRUE,
> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> 12
> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> "IlluminaHiSeq_
> RNASeqV2",level = 3)
> 15
> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> results")
> 17
> 18 exp <? TCGAprepare(query = query.exp, dir = path,
> 19                    summarizedExperiment = TRUE,
> 20                      add.subtype = TRUE, add.clinical = TRUE,
> 21                    type = "rsem.genes.normalized_results",
> 22                      save = T,filename = "lgg_gbm_exp.rda")
>
> To download data on DNA methylation and gene expression?
>
> 1 library(summarizedExperiment)
> 2 # get expression matrix
> 3 data <? assay(exp)
> 4
> 5 # get sample information
> 6 sample.info <? colData(exp)
> 7
> 8 # get genes information
> 9 genes.info <? rowRanges(exp)
>
> Following stepwise procedure for obtaining GBM and LGG clinical data?
>
> 1 # get clinical patient data for GBM samples
> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
> 3
> 4 # get clinical patient data for LGG samples
> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
> 6
> 7 # Bind the results, as the columns might not be the same,
> 8 # we will plyr rbind.fill , to have all columns from both files
> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
> 10
> 11 # Other clinical files can be downloaded,
> 12 # Use ?TCGAquery_clinic for more information
> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
> 14
> 15 # Also, you can get clinical information from different tumor types.
> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>
>
> # Searching idat file for DNA methylation
> query <- GDCquery(project = "TCGA-GBM",
>                  data.category = "Raw microarray data",
>                  data.type = "Raw intensities",
>                  experimental.strategy = "Methylation array",
>                  legacy = TRUE,
>                  file.type = ".idat",
>                  platform = "Illumina Human Methylation 450")
>
> **Repeat for LGG**
>
> To access mutational information concerning TMZ methylation?
>
> > mutation <? TCGAquery_maf(tumor = "lgg")
> 2   Getting maf tables
> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
> 4   We found these maf files below:
> 5       MAF.File.Name
> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
> 7
> 8   3 LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
> 9
> 10       Archive.Name Deploy.Date
> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>   10-DEC-13
> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>  24-DEC-14
> 13
> 14   Please, select the line that you want to download: 3
>
> **Repeat this for GBM***
>
> Selecting specified lines to download?
>
> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>
>
>
> Downloading data via the Bioconductor package RTCGAtoolbox?
>
> library(RTCGAToolbox)
> 2
> 3 # Get the last run dates
> 4 lastRunDate <? getFirehoseRunningDates()[1]
> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
> 6
> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
> 8 lgg.data <? getFirehoseData(dataset = "LGG",
> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate = lastRunDate,
> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
> 11       Mutation = T,
> 12       fileSizeLimit = 10000)
> 13
> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
> 15 gbm.data <? getFirehoseData(dataset = "GBM",
> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
> 18       fileSizeLimit = 10000)
> 19
> 20 # To access the data you should use the getData function
> 21 # or simply access with @ (for example gbm.data at Clinical)
> 22 gbm.mut <? getData(gbm.data,"Mutations")
> 23 gbm.clin <? getData(gbm.data,"Clinical")
> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>
>
>
>
>
>
> Genomic Analysis/Final data extraction:
>
> Enable ?getData? to access the data
>
> Obtaining GISTIC results?
>
> 1 # Download GISTIC results
> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
> 3
> 4 # get GISTIC results
> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>
> Repeat this procedure to obtain LGG GISTIC results.
>
> ***Please ignore the 'non-coded' text as they are procedural
> steps/classifications***
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Sun Aug 26 23:37:45 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 17:37:45 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CAGxFJbQPXwDMxj9WUcP+Qz8MsFiPZ5uqrezOCcJBQX=DxT+DFg@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CAGxFJbQPXwDMxj9WUcP+Qz8MsFiPZ5uqrezOCcJBQX=DxT+DFg@mail.gmail.com>
Message-ID: <CAPQaxLN+=J1ZkTTEJ7EQRotZy3cA7=rkibewzwxjmjLSTfcLPA@mail.gmail.com>

Thanks! Will do.

On Sun, Aug 26, 2018 at 5:37 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> You should probably post this on the Bioconductor list rather then here,
> as you would more likely find the expertise you seek there. You are using
> Bioconductor packages after all.
>
> https://support.bioconductor.org/
>
> Cheers,
> Bert
>
>
> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Good evening,
>>
>>   I am attempting to run the following analysis on TCGA data, however
>> something is being reported as an error in my arguments... any ideas as to
>> what is incorrect in the following? Thanks!
>>
>> 1 library(TCGAbiolinks)
>> 2
>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> 4 path <? "."
>> 5
>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> level = 3)
>> 7 TCGAdownload(query.met, path = path )
>> 8 met <? TCGAprepare(query = query.met,dir = path,
>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>> 10                    summarizedExperiment = TRUE,
>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> 12
>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>> "IlluminaHiSeq_
>> RNASeqV2",level = 3)
>> 15
>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> results")
>> 17
>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> 19                    summarizedExperiment = TRUE,
>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>> 21                    type = "rsem.genes.normalized_results",
>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>
>> To download data on DNA methylation and gene expression?
>>
>> 1 library(summarizedExperiment)
>> 2 # get expression matrix
>> 3 data <? assay(exp)
>> 4
>> 5 # get sample information
>> 6 sample.info <? colData(exp)
>> 7
>> 8 # get genes information
>> 9 genes.info <? rowRanges(exp)
>>
>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>
>> 1 # get clinical patient data for GBM samples
>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>> 3
>> 4 # get clinical patient data for LGG samples
>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>> 6
>> 7 # Bind the results, as the columns might not be the same,
>> 8 # we will plyr rbind.fill , to have all columns from both files
>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>> 10
>> 11 # Other clinical files can be downloaded,
>> 12 # Use ?TCGAquery_clinic for more information
>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>> 14
>> 15 # Also, you can get clinical information from different tumor types.
>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>
>>
>> # Searching idat file for DNA methylation
>> query <- GDCquery(project = "TCGA-GBM",
>>                  data.category = "Raw microarray data",
>>                  data.type = "Raw intensities",
>>                  experimental.strategy = "Methylation array",
>>                  legacy = TRUE,
>>                  file.type = ".idat",
>>                  platform = "Illumina Human Methylation 450")
>>
>> **Repeat for LGG**
>>
>> To access mutational information concerning TMZ methylation?
>>
>> > mutation <? TCGAquery_maf(tumor = "lgg")
>> 2   Getting maf tables
>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>> 4   We found these maf files below:
>> 5       MAF.File.Name
>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>> 7
>> 8   3 LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>> 9
>> 10       Archive.Name Deploy.Date
>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>   10-DEC-13
>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>  24-DEC-14
>> 13
>> 14   Please, select the line that you want to download: 3
>>
>> **Repeat this for GBM***
>>
>> Selecting specified lines to download?
>>
>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>
>>
>>
>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>
>> library(RTCGAToolbox)
>> 2
>> 3 # Get the last run dates
>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>> 6
>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate = lastRunDate,
>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>> 11       Mutation = T,
>> 12       fileSizeLimit = 10000)
>> 13
>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>> 18       fileSizeLimit = 10000)
>> 19
>> 20 # To access the data you should use the getData function
>> 21 # or simply access with @ (for example gbm.data at Clinical)
>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>
>>
>>
>>
>>
>>
>> Genomic Analysis/Final data extraction:
>>
>> Enable ?getData? to access the data
>>
>> Obtaining GISTIC results?
>>
>> 1 # Download GISTIC results
>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>> 3
>> 4 # get GISTIC results
>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>
>> Repeat this procedure to obtain LGG GISTIC results.
>>
>> ***Please ignore the 'non-coded' text as they are procedural
>> steps/classifications***
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Aug 27 02:22:38 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 20:22:38 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
Message-ID: <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>

 Thank you! I will make note of that. Unfortunately, lines 1 and 4 of the
first portion of this analysis appear to be where the error begins... to
which several subsequent lines also come up as ?errored?. Perhaps this is
an issue of the capitalization and/or spacing (something within the text)?
The proposed method for methylation data extraction is based on the first
third of the following TCGA workflow:
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308

Best,

Spencer Brackett












On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com> wrote:

> Hi Spencer.
>
> Should you capitalize the following library import?
>
> library(summarizedExperiment)
>
> In other words, I think that line should be:
>
> library(SummarizedExperiment)
>
> Hope this helps.
>
> ~Caitlin
>
>
>
>
> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Good evening,
>>
>>   I am attempting to run the following analysis on TCGA data, however
>> something is being reported as an error in my arguments... any ideas as to
>> what is incorrect in the following? Thanks!
>>
>> 1 library(TCGAbiolinks)
>> 2
>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> 4 path <? "."
>> 5
>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> level = 3)
>> 7 TCGAdownload(query.met, path = path )
>> 8 met <? TCGAprepare(query = query.met,dir = path,
>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>> 10                    summarizedExperiment = TRUE,
>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> 12
>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>> "IlluminaHiSeq_
>> RNASeqV2",level = 3)
>> 15
>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> results")
>> 17
>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> 19                    summarizedExperiment = TRUE,
>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>> 21                    type = "rsem.genes.normalized_results",
>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>
>> To download data on DNA methylation and gene expression?
>>
>> 1 library(summarizedExperiment)
>> 2 # get expression matrix
>> 3 data <? assay(exp)
>> 4
>> 5 # get sample information
>> 6 sample.info <? colData(exp)
>> 7
>> 8 # get genes information
>> 9 genes.info <? rowRanges(exp)
>>
>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>
>> 1 # get clinical patient data for GBM samples
>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>> 3
>> 4 # get clinical patient data for LGG samples
>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>> 6
>> 7 # Bind the results, as the columns might not be the same,
>> 8 # we will plyr rbind.fill , to have all columns from both files
>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>> 10
>> 11 # Other clinical files can be downloaded,
>> 12 # Use ?TCGAquery_clinic for more information
>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>> 14
>> 15 # Also, you can get clinical information from different tumor types.
>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>
>>
>> # Searching idat file for DNA methylation
>> query <- GDCquery(project = "TCGA-GBM",
>>                  data.category = "Raw microarray data",
>>                  data.type = "Raw intensities",
>>                  experimental.strategy = "Methylation array",
>>                  legacy = TRUE,
>>                  file.type = ".idat",
>>                  platform = "Illumina Human Methylation 450")
>>
>> **Repeat for LGG**
>>
>> To access mutational information concerning TMZ methylation?
>>
>> > mutation <? TCGAquery_maf(tumor = "lgg")
>> 2   Getting maf tables
>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>> 4   We found these maf files below:
>> 5       MAF.File.Name
>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>> 7
>> 8   3 LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>> 9
>> 10       Archive.Name Deploy.Date
>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>   10-DEC-13
>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>  24-DEC-14
>> 13
>> 14   Please, select the line that you want to download: 3
>>
>> **Repeat this for GBM***
>>
>> Selecting specified lines to download?
>>
>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>
>>
>>
>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>
>> library(RTCGAToolbox)
>> 2
>> 3 # Get the last run dates
>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>> 6
>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate = lastRunDate,
>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>> 11       Mutation = T,
>> 12       fileSizeLimit = 10000)
>> 13
>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>> 18       fileSizeLimit = 10000)
>> 19
>> 20 # To access the data you should use the getData function
>> 21 # or simply access with @ (for example gbm.data at Clinical)
>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>
>>
>>
>>
>>
>>
>> Genomic Analysis/Final data extraction:
>>
>> Enable ?getData? to access the data
>>
>> Obtaining GISTIC results?
>>
>> 1 # Download GISTIC results
>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>> 3
>> 4 # get GISTIC results
>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>
>> Repeat this procedure to obtain LGG GISTIC results.
>>
>> ***Please ignore the 'non-coded' text as they are procedural
>> steps/classifications***
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Aug 27 02:34:13 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 20:34:13 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
Message-ID: <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>

Caitlin,

  Forgive me, but I?m not quite sure exactly what your question is asking.
The data is originally from the TCGA and I have it downloaded onto another
R script. I opened a new script to perform the functions I posted to this
forum because I was unable to input any other commands into the console....
due to the fact that the translated data filled the entirety of said
consule. Perhaps overloaded it? Regardless, I was unable to input any
further commands.

-Spencer Brackett


On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com> wrote:

> You're welcome Spencer :)
>
> The 4th line:
>
> path <? "."
>
> refers to the current directory (the dot in other words). Is the data
> stored in the same directory where the code is being run?
>
>
>
> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4 of the
>> first portion of this analysis appear to be where the error begins... to
>> which several subsequent lines also come up as ?errored?. Perhaps this is
>> an issue of the capitalization and/or spacing (something within the text)?
>> The proposed method for methylation data extraction is based on the first
>> third of the following TCGA workflow:
>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308
>>
>> Best,
>>
>> Spencer Brackett
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com> wrote:
>>
>>> Hi Spencer.
>>>
>>> Should you capitalize the following library import?
>>>
>>> library(summarizedExperiment)
>>>
>>> In other words, I think that line should be:
>>>
>>> library(SummarizedExperiment)
>>>
>>> Hope this helps.
>>>
>>> ~Caitlin
>>>
>>>
>>>
>>>
>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>>
>>>> Good evening,
>>>>
>>>>   I am attempting to run the following analysis on TCGA data, however
>>>> something is being reported as an error in my arguments... any ideas as
>>>> to
>>>> what is incorrect in the following? Thanks!
>>>>
>>>> 1 library(TCGAbiolinks)
>>>> 2
>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>>>> 4 path <? "."
>>>> 5
>>>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>>>> level = 3)
>>>> 7 TCGAdownload(query.met, path = path )
>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>> 10                    summarizedExperiment = TRUE,
>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>> 12
>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>> "IlluminaHiSeq_
>>>> RNASeqV2",level = 3)
>>>> 15
>>>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>>>> results")
>>>> 17
>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>> 19                    summarizedExperiment = TRUE,
>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>> 21                    type = "rsem.genes.normalized_results",
>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>
>>>> To download data on DNA methylation and gene expression?
>>>>
>>>> 1 library(summarizedExperiment)
>>>> 2 # get expression matrix
>>>> 3 data <? assay(exp)
>>>> 4
>>>> 5 # get sample information
>>>> 6 sample.info <? colData(exp)
>>>> 7
>>>> 8 # get genes information
>>>> 9 genes.info <? rowRanges(exp)
>>>>
>>>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>>>
>>>> 1 # get clinical patient data for GBM samples
>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>>>> 3
>>>> 4 # get clinical patient data for LGG samples
>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>>>> 6
>>>> 7 # Bind the results, as the columns might not be the same,
>>>> 8 # we will plyr rbind.fill , to have all columns from both files
>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>>>> 10
>>>> 11 # Other clinical files can be downloaded,
>>>> 12 # Use ?TCGAquery_clinic for more information
>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>>>> 14
>>>> 15 # Also, you can get clinical information from different tumor types.
>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>>>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>>>
>>>>
>>>> # Searching idat file for DNA methylation
>>>> query <- GDCquery(project = "TCGA-GBM",
>>>>                  data.category = "Raw microarray data",
>>>>                  data.type = "Raw intensities",
>>>>                  experimental.strategy = "Methylation array",
>>>>                  legacy = TRUE,
>>>>                  file.type = ".idat",
>>>>                  platform = "Illumina Human Methylation 450")
>>>>
>>>> **Repeat for LGG**
>>>>
>>>> To access mutational information concerning TMZ methylation?
>>>>
>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
>>>> 2   Getting maf tables
>>>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>>>> 4   We found these maf files below:
>>>> 5       MAF.File.Name
>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>>>> 7
>>>> 8   3
>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>>>> 9
>>>> 10       Archive.Name Deploy.Date
>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>>>   10-DEC-13
>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>>>  24-DEC-14
>>>> 13
>>>> 14   Please, select the line that you want to download: 3
>>>>
>>>> **Repeat this for GBM***
>>>>
>>>> Selecting specified lines to download?
>>>>
>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>>>
>>>>
>>>>
>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>>>
>>>> library(RTCGAToolbox)
>>>> 2
>>>> 3 # Get the last run dates
>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>>>> 6
>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
>>>> lastRunDate,
>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>>>> 11       Mutation = T,
>>>> 12       fileSizeLimit = 10000)
>>>> 13
>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>>>> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>>>> 18       fileSizeLimit = 10000)
>>>> 19
>>>> 20 # To access the data you should use the getData function
>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Genomic Analysis/Final data extraction:
>>>>
>>>> Enable ?getData? to access the data
>>>>
>>>> Obtaining GISTIC results?
>>>>
>>>> 1 # Download GISTIC results
>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>>>> 3
>>>> 4 # get GISTIC results
>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>>>
>>>> Repeat this procedure to obtain LGG GISTIC results.
>>>>
>>>> ***Please ignore the 'non-coded' text as they are procedural
>>>> steps/classifications***
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]



From b|oprogr@mmer @end|ng |rom gm@||@com  Mon Aug 27 02:41:50 2018
From: b|oprogr@mmer @end|ng |rom gm@||@com (Caitlin)
Date: Sun, 26 Aug 2018 17:41:50 -0700
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
 <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
Message-ID: <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>

No worries Spencer. There is no downloaded data? Nothing is physically
stored on your hard drive? The dot in the path would be interpreted (no pun
intended!) as something like the following:

If the TCGA data was stored in a file named "tcga_data.dat" and it was in a
directory named "C:\spencer", the 4th line of that script would set the
path to "C:\spencer\tcga_data.dat" if you ran the script from that same
folder. If your tcga data is not stored in the same file from which the
script is being ran, it won't find any data to work with. Does this help?


On Sun, Aug 26, 2018 at 5:34 PM Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Caitlin,
>
>   Forgive me, but I?m not quite sure exactly what your question is asking.
> The data is originally from the TCGA and I have it downloaded onto another
> R script. I opened a new script to perform the functions I posted to this
> forum because I was unable to input any other commands into the console....
> due to the fact that the translated data filled the entirety of said
> consule. Perhaps overloaded it? Regardless, I was unable to input any
> further commands.
>
> -Spencer Brackett
>
>
> On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com> wrote:
>
>> You're welcome Spencer :)
>>
>> The 4th line:
>>
>> path <? "."
>>
>> refers to the current directory (the dot in other words). Is the data
>> stored in the same directory where the code is being run?
>>
>>
>>
>> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>>
>>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4 of
>>> the first portion of this analysis appear to be where the error begins...
>>> to which several subsequent lines also come up as ?errored?. Perhaps this
>>> is an issue of the capitalization and/or spacing (something within the
>>> text)? The proposed method for methylation data extraction is based on the
>>> first third of the following TCGA workflow:
>>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308
>>>
>>> Best,
>>>
>>> Spencer Brackett
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com> wrote:
>>>
>>>> Hi Spencer.
>>>>
>>>> Should you capitalize the following library import?
>>>>
>>>> library(summarizedExperiment)
>>>>
>>>> In other words, I think that line should be:
>>>>
>>>> library(SummarizedExperiment)
>>>>
>>>> Hope this helps.
>>>>
>>>> ~Caitlin
>>>>
>>>>
>>>>
>>>>
>>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>
>>>>> Good evening,
>>>>>
>>>>>   I am attempting to run the following analysis on TCGA data, however
>>>>> something is being reported as an error in my arguments... any ideas
>>>>> as to
>>>>> what is incorrect in the following? Thanks!
>>>>>
>>>>> 1 library(TCGAbiolinks)
>>>>> 2
>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>>>>> 4 path <? "."
>>>>> 5
>>>>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>>>>> level = 3)
>>>>> 7 TCGAdownload(query.met, path = path )
>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>>> 10                    summarizedExperiment = TRUE,
>>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>>> 12
>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>>> "IlluminaHiSeq_
>>>>> RNASeqV2",level = 3)
>>>>> 15
>>>>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>>>>> results")
>>>>> 17
>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>>> 19                    summarizedExperiment = TRUE,
>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>>> 21                    type = "rsem.genes.normalized_results",
>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>>
>>>>> To download data on DNA methylation and gene expression?
>>>>>
>>>>> 1 library(summarizedExperiment)
>>>>> 2 # get expression matrix
>>>>> 3 data <? assay(exp)
>>>>> 4
>>>>> 5 # get sample information
>>>>> 6 sample.info <? colData(exp)
>>>>> 7
>>>>> 8 # get genes information
>>>>> 9 genes.info <? rowRanges(exp)
>>>>>
>>>>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>>>>
>>>>> 1 # get clinical patient data for GBM samples
>>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>>>>> 3
>>>>> 4 # get clinical patient data for LGG samples
>>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>>>>> 6
>>>>> 7 # Bind the results, as the columns might not be the same,
>>>>> 8 # we will plyr rbind.fill , to have all columns from both files
>>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>>>>> 10
>>>>> 11 # Other clinical files can be downloaded,
>>>>> 12 # Use ?TCGAquery_clinic for more information
>>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>>>>> 14
>>>>> 15 # Also, you can get clinical information from different tumor types.
>>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>>>>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>>>>
>>>>>
>>>>> # Searching idat file for DNA methylation
>>>>> query <- GDCquery(project = "TCGA-GBM",
>>>>>                  data.category = "Raw microarray data",
>>>>>                  data.type = "Raw intensities",
>>>>>                  experimental.strategy = "Methylation array",
>>>>>                  legacy = TRUE,
>>>>>                  file.type = ".idat",
>>>>>                  platform = "Illumina Human Methylation 450")
>>>>>
>>>>> **Repeat for LGG**
>>>>>
>>>>> To access mutational information concerning TMZ methylation?
>>>>>
>>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
>>>>> 2   Getting maf tables
>>>>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>>>>> 4   We found these maf files below:
>>>>> 5       MAF.File.Name
>>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>>>>> 7
>>>>> 8   3
>>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>>>>> 9
>>>>> 10       Archive.Name Deploy.Date
>>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>>>>   10-DEC-13
>>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>>>>  24-DEC-14
>>>>> 13
>>>>> 14   Please, select the line that you want to download: 3
>>>>>
>>>>> **Repeat this for GBM***
>>>>>
>>>>> Selecting specified lines to download?
>>>>>
>>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>>>>
>>>>>
>>>>>
>>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>>>>
>>>>> library(RTCGAToolbox)
>>>>> 2
>>>>> 3 # Get the last run dates
>>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>>>>> 6
>>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
>>>>> lastRunDate,
>>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>>>>> 11       Mutation = T,
>>>>> 12       fileSizeLimit = 10000)
>>>>> 13
>>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>>>>> 16       runDate = lastDate, gistic2_Date = getFirehoseAnalyzeDates(1),
>>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>>>>> 18       fileSizeLimit = 10000)
>>>>> 19
>>>>> 20 # To access the data you should use the getData function
>>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
>>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Genomic Analysis/Final data extraction:
>>>>>
>>>>> Enable ?getData? to access the data
>>>>>
>>>>> Obtaining GISTIC results?
>>>>>
>>>>> 1 # Download GISTIC results
>>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>>>>> 3
>>>>> 4 # get GISTIC results
>>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>>>>
>>>>> Repeat this procedure to obtain LGG GISTIC results.
>>>>>
>>>>> ***Please ignore the 'non-coded' text as they are procedural
>>>>> steps/classifications***
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>

	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Aug 27 02:49:48 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 20:49:48 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
 <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
 <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>
Message-ID: <CAPQaxLOH8TDjhutsh5Ck9oWEz2zeR=_umMjFcYBWvxncL6FJew@mail.gmail.com>

Caitlin,

 Perhaps that is the problem. To be more specific, the data was transferred
from the TCGA database to a CSV file... there are technically two separate
files (CSV) for this analysis.... one for GBM and one for LGG. Both CVS
files were then individually downloaded onto my open R console. Upon
arranging them with the summary () function, the data expanded and took up
the whole console page... even seemingly abrogating the arguments which
allowed for the data to be downloaded onto R in the first place. Are you
suggesting that I would need to utilize a flash drive to successfully
utilize the function you suggested? Or could I perhaps do so with the CSV
field I mentioned? If so, how?

-Spencer B

On Sun, Aug 26, 2018 at 8:42 PM Caitlin <bioprogrammer at gmail.com> wrote:

> No worries Spencer. There is no downloaded data? Nothing is physically
> stored on your hard drive? The dot in the path would be interpreted (no pun
> intended!) as something like the following:
>
> If the TCGA data was stored in a file named "tcga_data.dat" and it was in
> a directory named "C:\spencer", the 4th line of that script would set the
> path to "C:\spencer\tcga_data.dat" if you ran the script from that same
> folder. If your tcga data is not stored in the same file from which the
> script is being ran, it won't find any data to work with. Does this help?
>
>
> On Sun, Aug 26, 2018 at 5:34 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Caitlin,
>>
>>   Forgive me, but I?m not quite sure exactly what your question is
>> asking. The data is originally from the TCGA and I have it downloaded onto
>> another R script. I opened a new script to perform the functions I posted
>> to this forum because I was unable to input any other commands into the
>> console.... due to the fact that the translated data filled the entirety of
>> said consule. Perhaps overloaded it? Regardless, I was unable to input any
>> further commands.
>>
>> -Spencer Brackett
>>
>>
>> On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com> wrote:
>>
>>> You're welcome Spencer :)
>>>
>>> The 4th line:
>>>
>>> path <? "."
>>>
>>> refers to the current directory (the dot in other words). Is the data
>>> stored in the same directory where the code is being run?
>>>
>>>
>>>
>>> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>>
>>>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4 of
>>>> the first portion of this analysis appear to be where the error begins...
>>>> to which several subsequent lines also come up as ?errored?. Perhaps this
>>>> is an issue of the capitalization and/or spacing (something within the
>>>> text)? The proposed method for methylation data extraction is based on the
>>>> first third of the following TCGA workflow:
>>>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308
>>>>
>>>> Best,
>>>>
>>>> Spencer Brackett
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Spencer.
>>>>>
>>>>> Should you capitalize the following library import?
>>>>>
>>>>> library(summarizedExperiment)
>>>>>
>>>>> In other words, I think that line should be:
>>>>>
>>>>> library(SummarizedExperiment)
>>>>>
>>>>> Hope this helps.
>>>>>
>>>>> ~Caitlin
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>
>>>>>> Good evening,
>>>>>>
>>>>>>   I am attempting to run the following analysis on TCGA data, however
>>>>>> something is being reported as an error in my arguments... any ideas
>>>>>> as to
>>>>>> what is incorrect in the following? Thanks!
>>>>>>
>>>>>> 1 library(TCGAbiolinks)
>>>>>> 2
>>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and
>>>>>> GBM.
>>>>>> 4 path <? "."
>>>>>> 5
>>>>>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>>>>>> level = 3)
>>>>>> 7 TCGAdownload(query.met, path = path )
>>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>>>> 10                    summarizedExperiment = TRUE,
>>>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>>>> 12
>>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>>>> "IlluminaHiSeq_
>>>>>> RNASeqV2",level = 3)
>>>>>> 15
>>>>>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>>>>>> results")
>>>>>> 17
>>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>>>> 19                    summarizedExperiment = TRUE,
>>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>>>> 21                    type = "rsem.genes.normalized_results",
>>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>>>
>>>>>> To download data on DNA methylation and gene expression?
>>>>>>
>>>>>> 1 library(summarizedExperiment)
>>>>>> 2 # get expression matrix
>>>>>> 3 data <? assay(exp)
>>>>>> 4
>>>>>> 5 # get sample information
>>>>>> 6 sample.info <? colData(exp)
>>>>>> 7
>>>>>> 8 # get genes information
>>>>>> 9 genes.info <? rowRanges(exp)
>>>>>>
>>>>>> Following stepwise procedure for obtaining GBM and LGG clinical data?
>>>>>>
>>>>>> 1 # get clinical patient data for GBM samples
>>>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>>>>>> 3
>>>>>> 4 # get clinical patient data for LGG samples
>>>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>>>>>> 6
>>>>>> 7 # Bind the results, as the columns might not be the same,
>>>>>> 8 # we will plyr rbind.fill , to have all columns from both files
>>>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>>>>>> 10
>>>>>> 11 # Other clinical files can be downloaded,
>>>>>> 12 # Use ?TCGAquery_clinic for more information
>>>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>>>>>> 14
>>>>>> 15 # Also, you can get clinical information from different tumor
>>>>>> types.
>>>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>>>>>> 17 data <? TCGAquery_clinic(clinical_data_type = "clinical_patient",
>>>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>>>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>>>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>>>>>
>>>>>>
>>>>>> # Searching idat file for DNA methylation
>>>>>> query <- GDCquery(project = "TCGA-GBM",
>>>>>>                  data.category = "Raw microarray data",
>>>>>>                  data.type = "Raw intensities",
>>>>>>                  experimental.strategy = "Methylation array",
>>>>>>                  legacy = TRUE,
>>>>>>                  file.type = ".idat",
>>>>>>                  platform = "Illumina Human Methylation 450")
>>>>>>
>>>>>> **Repeat for LGG**
>>>>>>
>>>>>> To access mutational information concerning TMZ methylation?
>>>>>>
>>>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
>>>>>> 2   Getting maf tables
>>>>>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>>>>>> 4   We found these maf files below:
>>>>>> 5       MAF.File.Name
>>>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>>>>>> 7
>>>>>> 8   3
>>>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>>>>>> 9
>>>>>> 10       Archive.Name Deploy.Date
>>>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>>>>>   10-DEC-13
>>>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>>>>>  24-DEC-14
>>>>>> 13
>>>>>> 14   Please, select the line that you want to download: 3
>>>>>>
>>>>>> **Repeat this for GBM***
>>>>>>
>>>>>> Selecting specified lines to download?
>>>>>>
>>>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>>>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>>>>>
>>>>>>
>>>>>>
>>>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>>>>>
>>>>>> library(RTCGAToolbox)
>>>>>> 2
>>>>>> 3 # Get the last run dates
>>>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>>>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>>>>>> 6
>>>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>>>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>>>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
>>>>>> lastRunDate,
>>>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic = TRUE,
>>>>>> 11       Mutation = T,
>>>>>> 12       fileSizeLimit = 10000)
>>>>>> 13
>>>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>>>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>>>>>> 16       runDate = lastDate, gistic2_Date =
>>>>>> getFirehoseAnalyzeDates(1),
>>>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm = TRUE,
>>>>>> 18       fileSizeLimit = 10000)
>>>>>> 19
>>>>>> 20 # To access the data you should use the getData function
>>>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
>>>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>>>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>>>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Genomic Analysis/Final data extraction:
>>>>>>
>>>>>> Enable ?getData? to access the data
>>>>>>
>>>>>> Obtaining GISTIC results?
>>>>>>
>>>>>> 1 # Download GISTIC results
>>>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>>>>>> 3
>>>>>> 4 # get GISTIC results
>>>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>>>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>>>>>
>>>>>> Repeat this procedure to obtain LGG GISTIC results.
>>>>>>
>>>>>> ***Please ignore the 'non-coded' text as they are procedural
>>>>>> steps/classifications***
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>

	[[alternative HTML version deleted]]



From er|nm@hodge@@ @end|ng |rom gm@||@com  Mon Aug 27 04:40:15 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sun, 26 Aug 2018 20:40:15 -0600
Subject: [R] Using a different compiler to create a package with source code
Message-ID: <CACxE24nCQ8AsREWvzZKvtHL=HR8LHC_=NRrryB4Y1NjKaZFMDQ@mail.gmail.com>

Hello!
I need to use the PGI compiler for a new package.  Should I ask here or the
development list, please?

Sorry for the airspace if I'm on the wrong list.

Thanks,
Erin


Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug 27 04:44:19 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 26 Aug 2018 19:44:19 -0700
Subject: [R] 
 Using a different compiler to create a package with source code
In-Reply-To: <CACxE24nCQ8AsREWvzZKvtHL=HR8LHC_=NRrryB4Y1NjKaZFMDQ@mail.gmail.com>
References: <CACxE24nCQ8AsREWvzZKvtHL=HR8LHC_=NRrryB4Y1NjKaZFMDQ@mail.gmail.com>
Message-ID: <2233319D-DDE5-4B64-B702-4893BE35B613@dcn.davis.ca.us>

Wrong list, though you will probably need to recompile R itself and every other package you want to use in conjunction with this special package in order to do this... and you may not find many or even any people interested in helping as a result.

On August 26, 2018 7:40:15 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello!
>I need to use the PGI compiler for a new package.  Should I ask here or
>the
>development list, please?
>
>Sorry for the airspace if I'm on the wrong list.
>
>Thanks,
>Erin
>
>
>Erin Hodgess, PhD
>mailto: erinm.hodgess at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From er|nm@hodge@@ @end|ng |rom gm@||@com  Mon Aug 27 04:45:05 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sun, 26 Aug 2018 20:45:05 -0600
Subject: [R] 
 Using a different compiler to create a package with source code
In-Reply-To: <2233319D-DDE5-4B64-B702-4893BE35B613@dcn.davis.ca.us>
References: <CACxE24nCQ8AsREWvzZKvtHL=HR8LHC_=NRrryB4Y1NjKaZFMDQ@mail.gmail.com>
 <2233319D-DDE5-4B64-B702-4893BE35B613@dcn.davis.ca.us>
Message-ID: <CACxE24k=2ztX_YA5M0VOWCuQMSHCtSoMTsENyXzi+Gpj1AErfA@mail.gmail.com>

OK.  Thanks for the info!

Sincerely,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Sun, Aug 26, 2018 at 8:44 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Wrong list, though you will probably need to recompile R itself and every
> other package you want to use in conjunction with this special package in
> order to do this... and you may not find many or even any people interested
> in helping as a result.
>
> On August 26, 2018 7:40:15 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >Hello!
> >I need to use the PGI compiler for a new package.  Should I ask here or
> >the
> >development list, please?
> >
> >Sorry for the airspace if I'm on the wrong list.
> >
> >Thanks,
> >Erin
> >
> >
> >Erin Hodgess, PhD
> >mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Aug 27 05:49:23 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 26 Aug 2018 23:49:23 -0400
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CABDKo+yuFT=V41jzwyUD9ACskUfhaA9inChZbR+a-O3Cz_PoNQ@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
 <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
 <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>
 <CAPQaxLOH8TDjhutsh5Ck9oWEz2zeR=_umMjFcYBWvxncL6FJew@mail.gmail.com>
 <CABDKo+wmSAMqP=ERvoAz1AZrj0p+jZhhYCoFohNkGcT81Zecvw@mail.gmail.com>
 <CAPQaxLP0LZOsXC4L4WF4DVFC=mvr=cKHs2KQAe0YXWJUHAsDEg@mail.gmail.com>
 <CABDKo+yuFT=V41jzwyUD9ACskUfhaA9inChZbR+a-O3Cz_PoNQ@mail.gmail.com>
Message-ID: <CAPQaxLPC+natdQ=rwfKkmdq=CK=Aw9-M-Nn71=bvDRZaZudyZA@mail.gmail.com>

Hello all,

  To begin my analysis, I downloaded two TCGA datasets (GBM and LGG), both
csv files, onto on r script after loading the cBioLite package. Following
this, I inputted the following argument...

> the_data<-read.csv(file=?c:/file_name.csv,header=TRUE,sep=?,?)

Upon running the line I received this...

+

If continue to press enter, the + sign continues to appear on every
subsequent/new line.

Does anyone know what this is indicative of and how I may continue on with
my analysis

My next step after this would have been the following (the numbers before
each command being line markers; not part of line)..

1 library(TCGAbiolinks)
2
3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
4 path <? "."

Best wishes,

Spencer Brackett

On Sun, Aug 26, 2018 at 9:13 PM Caitlin <bioprogrammer at gmail.com> wrote:

> You're welcome Spencer :)
>
> I hope I was able to help you. If this problem persists, or a new one
> appears, feel free to post or email. You might also like:
>
> https://www.biostars.org/
>
> It is quite similar to StackOverflow but with a biological sciences focus.
>
> Hope this helps!
>
> ~Caitlin
>
>
>
> On Sun, Aug 26, 2018 at 6:02 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Caitlin,
>>
>>  Thanks again! I already have the two files stored in those two CSV files
>> via my desktop, but if tuning those with this function do not work, then I
>> will try it with a flash drive.
>>
>> Best,
>>
>> Spencer Brackett
>>
>> On Sun, Aug 26, 2018 at 8:56 PM Caitlin <bioprogrammer at gmail.com> wrote:
>>
>>> Hmm...could you store each in its own file (a flash drive would be fine)
>>> then use:
>>>
>>> the_data <- read.csv(file="c:/file_name.csv", header=TRUE, sep=",")
>>>
>>> to read each into your script? The data would then exist as a dataframe object that you could then work with.
>>>
>>>
>>> On Sun, Aug 26, 2018 at 5:50 PM Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>>
>>>> Caitlin,
>>>>
>>>>  Perhaps that is the problem. To be more specific, the data was
>>>> transferred from the TCGA database to a CSV file... there are technically
>>>> two separate files (CSV) for this analysis.... one for GBM and one for LGG.
>>>> Both CVS files were then individually downloaded onto my open R console.
>>>> Upon arranging them with the summary () function, the data expanded and
>>>> took up the whole console page... even seemingly abrogating the arguments
>>>> which allowed for the data to be downloaded onto R in the first place. Are
>>>> you suggesting that I would need to utilize a flash drive to successfully
>>>> utilize the function you suggested? Or could I perhaps do so with the CSV
>>>> field I mentioned? If so, how?
>>>>
>>>> -Spencer B
>>>>
>>>> On Sun, Aug 26, 2018 at 8:42 PM Caitlin <bioprogrammer at gmail.com>
>>>> wrote:
>>>>
>>>>> No worries Spencer. There is no downloaded data? Nothing is physically
>>>>> stored on your hard drive? The dot in the path would be interpreted (no pun
>>>>> intended!) as something like the following:
>>>>>
>>>>> If the TCGA data was stored in a file named "tcga_data.dat" and it was
>>>>> in a directory named "C:\spencer", the 4th line of that script would set
>>>>> the path to "C:\spencer\tcga_data.dat" if you ran the script from that same
>>>>> folder. If your tcga data is not stored in the same file from which the
>>>>> script is being ran, it won't find any data to work with. Does this help?
>>>>>
>>>>>
>>>>> On Sun, Aug 26, 2018 at 5:34 PM Spencer Brackett <
>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>
>>>>>> Caitlin,
>>>>>>
>>>>>>   Forgive me, but I?m not quite sure exactly what your question is
>>>>>> asking. The data is originally from the TCGA and I have it downloaded onto
>>>>>> another R script. I opened a new script to perform the functions I posted
>>>>>> to this forum because I was unable to input any other commands into the
>>>>>> console.... due to the fact that the translated data filled the entirety of
>>>>>> said consule. Perhaps overloaded it? Regardless, I was unable to input any
>>>>>> further commands.
>>>>>>
>>>>>> -Spencer Brackett
>>>>>>
>>>>>>
>>>>>> On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> You're welcome Spencer :)
>>>>>>>
>>>>>>> The 4th line:
>>>>>>>
>>>>>>> path <? "."
>>>>>>>
>>>>>>> refers to the current directory (the dot in other words). Is the
>>>>>>> data stored in the same directory where the code is being run?
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>>>
>>>>>>>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4
>>>>>>>> of the first portion of this analysis appear to be where the error
>>>>>>>> begins... to which several subsequent lines also come up as ?errored?.
>>>>>>>> Perhaps this is an issue of the capitalization and/or spacing (something
>>>>>>>> within the text)? The proposed method for methylation data extraction is
>>>>>>>> based on the first third of the following TCGA workflow:
>>>>>>>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=0.0715308
>>>>>>>>
>>>>>>>> Best,
>>>>>>>>
>>>>>>>> Spencer Brackett
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>> Hi Spencer.
>>>>>>>>>
>>>>>>>>> Should you capitalize the following library import?
>>>>>>>>>
>>>>>>>>> library(summarizedExperiment)
>>>>>>>>>
>>>>>>>>> In other words, I think that line should be:
>>>>>>>>>
>>>>>>>>> library(SummarizedExperiment)
>>>>>>>>>
>>>>>>>>> Hope this helps.
>>>>>>>>>
>>>>>>>>> ~Caitlin
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
>>>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>>>>>
>>>>>>>>>> Good evening,
>>>>>>>>>>
>>>>>>>>>>   I am attempting to run the following analysis on TCGA data,
>>>>>>>>>> however
>>>>>>>>>> something is being reported as an error in my arguments... any
>>>>>>>>>> ideas as to
>>>>>>>>>> what is incorrect in the following? Thanks!
>>>>>>>>>>
>>>>>>>>>> 1 library(TCGAbiolinks)
>>>>>>>>>> 2
>>>>>>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG
>>>>>>>>>> and GBM.
>>>>>>>>>> 4 path <? "."
>>>>>>>>>> 5
>>>>>>>>>> 6 query.met <? TCGAquery(tumor =
>>>>>>>>>> c("LGG","GBM"),"HumanMethylation450",
>>>>>>>>>> level = 3)
>>>>>>>>>> 7 TCGAdownload(query.met, path = path )
>>>>>>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>>>>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>>>>>>>> 10                    summarizedExperiment = TRUE,
>>>>>>>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>>>>>>>> 12
>>>>>>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and
>>>>>>>>>> GBM.
>>>>>>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>>>>>>>> "IlluminaHiSeq_
>>>>>>>>>> RNASeqV2",level = 3)
>>>>>>>>>> 15
>>>>>>>>>> 16 TCGAdownload(query.exp,path = path, type =
>>>>>>>>>> "rsem.genes.normalized_
>>>>>>>>>> results")
>>>>>>>>>> 17
>>>>>>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>>>>>>>> 19                    summarizedExperiment = TRUE,
>>>>>>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>>>>>>>> 21                    type = "rsem.genes.normalized_results",
>>>>>>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>>>>>>>
>>>>>>>>>> To download data on DNA methylation and gene expression?
>>>>>>>>>>
>>>>>>>>>> 1 library(summarizedExperiment)
>>>>>>>>>> 2 # get expression matrix
>>>>>>>>>> 3 data <? assay(exp)
>>>>>>>>>> 4
>>>>>>>>>> 5 # get sample information
>>>>>>>>>> 6 sample.info <? colData(exp)
>>>>>>>>>> 7
>>>>>>>>>> 8 # get genes information
>>>>>>>>>> 9 genes.info <? rowRanges(exp)
>>>>>>>>>>
>>>>>>>>>> Following stepwise procedure for obtaining GBM and LGG clinical
>>>>>>>>>> data?
>>>>>>>>>>
>>>>>>>>>> 1 # get clinical patient data for GBM samples
>>>>>>>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
>>>>>>>>>> 3
>>>>>>>>>> 4 # get clinical patient data for LGG samples
>>>>>>>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
>>>>>>>>>> 6
>>>>>>>>>> 7 # Bind the results, as the columns might not be the same,
>>>>>>>>>> 8 # we will plyr rbind.fill , to have all columns from both files
>>>>>>>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
>>>>>>>>>> 10
>>>>>>>>>> 11 # Other clinical files can be downloaded,
>>>>>>>>>> 12 # Use ?TCGAquery_clinic for more information
>>>>>>>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","clinical_radiation")
>>>>>>>>>> 14
>>>>>>>>>> 15 # Also, you can get clinical information from different tumor
>>>>>>>>>> types.
>>>>>>>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
>>>>>>>>>> 17 data <? TCGAquery_clinic(clinical_data_type =
>>>>>>>>>> "clinical_patient",
>>>>>>>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
>>>>>>>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
>>>>>>>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> # Searching idat file for DNA methylation
>>>>>>>>>> query <- GDCquery(project = "TCGA-GBM",
>>>>>>>>>>                  data.category = "Raw microarray data",
>>>>>>>>>>                  data.type = "Raw intensities",
>>>>>>>>>>                  experimental.strategy = "Methylation array",
>>>>>>>>>>                  legacy = TRUE,
>>>>>>>>>>                  file.type = ".idat",
>>>>>>>>>>                  platform = "Illumina Human Methylation 450")
>>>>>>>>>>
>>>>>>>>>> **Repeat for LGG**
>>>>>>>>>>
>>>>>>>>>> To access mutational information concerning TMZ methylation?
>>>>>>>>>>
>>>>>>>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
>>>>>>>>>> 2   Getting maf tables
>>>>>>>>>> 3   Source: https://wiki.nci.nih.gov/display/TCGA/TCGA+MAF+Files
>>>>>>>>>> 4   We found these maf files below:
>>>>>>>>>> 5       MAF.File.Name
>>>>>>>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_DNASeq.1.somatic.maf
>>>>>>>>>> 7
>>>>>>>>>> 8   3
>>>>>>>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.somatic.maf
>>>>>>>>>> 9
>>>>>>>>>> 10       Archive.Name Deploy.Date
>>>>>>>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_DNASeq_automated.Level_2.1.0.0
>>>>>>>>>>   10-DEC-13
>>>>>>>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_DNASeq_curated.Level_2.1.3.0
>>>>>>>>>>  24-DEC-14
>>>>>>>>>> 13
>>>>>>>>>> 14   Please, select the line that you want to download: 3
>>>>>>>>>>
>>>>>>>>>> **Repeat this for GBM***
>>>>>>>>>>
>>>>>>>>>> Selecting specified lines to download?
>>>>>>>>>>
>>>>>>>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
>>>>>>>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
>>>>>>>>>>
>>>>>>>>>> library(RTCGAToolbox)
>>>>>>>>>> 2
>>>>>>>>>> 3 # Get the last run dates
>>>>>>>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
>>>>>>>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
>>>>>>>>>> 6
>>>>>>>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
>>>>>>>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
>>>>>>>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
>>>>>>>>>> lastRunDate,
>>>>>>>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic =
>>>>>>>>>> TRUE,
>>>>>>>>>> 11       Mutation = T,
>>>>>>>>>> 12       fileSizeLimit = 10000)
>>>>>>>>>> 13
>>>>>>>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
>>>>>>>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
>>>>>>>>>> 16       runDate = lastDate, gistic2_Date =
>>>>>>>>>> getFirehoseAnalyzeDates(1),
>>>>>>>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm =
>>>>>>>>>> TRUE,
>>>>>>>>>> 18       fileSizeLimit = 10000)
>>>>>>>>>> 19
>>>>>>>>>> 20 # To access the data you should use the getData function
>>>>>>>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
>>>>>>>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
>>>>>>>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
>>>>>>>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Genomic Analysis/Final data extraction:
>>>>>>>>>>
>>>>>>>>>> Enable ?getData? to access the data
>>>>>>>>>>
>>>>>>>>>> Obtaining GISTIC results?
>>>>>>>>>>
>>>>>>>>>> 1 # Download GISTIC results
>>>>>>>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
>>>>>>>>>> 3
>>>>>>>>>> 4 # get GISTIC results
>>>>>>>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
>>>>>>>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
>>>>>>>>>>
>>>>>>>>>> Repeat this procedure to obtain LGG GISTIC results.
>>>>>>>>>>
>>>>>>>>>> ***Please ignore the 'non-coded' text as they are procedural
>>>>>>>>>> steps/classifications***
>>>>>>>>>>
>>>>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>>>
>>>>>>>>>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Mon Aug 27 08:32:40 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 27 Aug 2018 09:32:40 +0300
Subject: [R] Help with DNA Methylation Analysis
In-Reply-To: <CAPQaxLPC+natdQ=rwfKkmdq=CK=Aw9-M-Nn71=bvDRZaZudyZA@mail.gmail.com>
References: <CAPQaxLNET8bU_fFST1iw=eFOEFRUq-mg3HguONO_ZaiM8+H9mA@mail.gmail.com>
 <CABDKo+yX-vDacxhiOE7=c+v1F+2ecF3eUwq3uk29Eo53bksBhQ@mail.gmail.com>
 <CAPQaxLO8FOdsq_yN9-UHqwMLwG2sruBSXyFdko=LLb2e8HB33w@mail.gmail.com>
 <CABDKo+zVyihEKcueWQ_5prZEN7NNqJm9pz0fF1LcXht-sfDP9Q@mail.gmail.com>
 <CAPQaxLMdm8785SPgSLLEviRv=bBETRNYNyoJJpcPU2dApvsw7w@mail.gmail.com>
 <CABDKo+z+UJzLaFajBO_K-+WQUYriXRJ6nbLN5VGzVNk43xa4Hw@mail.gmail.com>
 <CAPQaxLOH8TDjhutsh5Ck9oWEz2zeR=_umMjFcYBWvxncL6FJew@mail.gmail.com>
 <CABDKo+wmSAMqP=ERvoAz1AZrj0p+jZhhYCoFohNkGcT81Zecvw@mail.gmail.com>
 <CAPQaxLP0LZOsXC4L4WF4DVFC=mvr=cKHs2KQAe0YXWJUHAsDEg@mail.gmail.com>
 <CABDKo+yuFT=V41jzwyUD9ACskUfhaA9inChZbR+a-O3Cz_PoNQ@mail.gmail.com>
 <CAPQaxLPC+natdQ=rwfKkmdq=CK=Aw9-M-Nn71=bvDRZaZudyZA@mail.gmail.com>
Message-ID: <CAGgJW76vc_TKJrxmxTPDrp03CZqS-vWZxwmZ+JvPPJ2n496v5Q@mail.gmail.com>

Your problem is that the command you entered

> the_data<-read.csv(file=?c:/file_name.csv,header=TRUE,sep=?,?)

is missing a double quote after the .csv. The statement should be

> the_data<-read.csv(file=?c:/file_name.csv",header=TRUE,sep=?,?)

The '+' sign is a prompt from R that indicates it has not yet seen the end
of a statement, and it is expecting you to continue from the previous line.

The explanation: you are supplying the read.csv() function three arguments,
one each for the parameters 'file', 'header' and 'sep'.
The parameters 'file' and 'sep' are expecting strings as arguments, such as
"c:/file_name.csv" or "c:/myspecialdata.csv".
The parameter 'sep' (for separator) indicates that the separator is a comma.
Note that you could also have written

> the_data<-read.csv(file=?c:/file_name.csv")

as the default values for the parameter 'header' is TRUE, and for the
parameter 'sep' is comma.
You can confirm this by looking at the help via

> ?read.csv

HTH,
Eric


On Mon, Aug 27, 2018 at 6:49 AM, Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Hello all,
>
>   To begin my analysis, I downloaded two TCGA datasets (GBM and LGG), both
> csv files, onto on r script after loading the cBioLite package. Following
> this, I inputted the following argument...
>
> > the_data<-read.csv(file=?c:/file_name.csv,header=TRUE,sep=?,?)
>
> Upon running the line I received this...
>
> +
>
> If continue to press enter, the + sign continues to appear on every
> subsequent/new line.
>
> Does anyone know what this is indicative of and how I may continue on with
> my analysis
>
> My next step after this would have been the following (the numbers before
> each command being line markers; not part of line)..
>
> 1 library(TCGAbiolinks)
> 2
> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> 4 path <? "."
>
> Best wishes,
>
> Spencer Brackett
>
> On Sun, Aug 26, 2018 at 9:13 PM Caitlin <bioprogrammer at gmail.com> wrote:
>
> > You're welcome Spencer :)
> >
> > I hope I was able to help you. If this problem persists, or a new one
> > appears, feel free to post or email. You might also like:
> >
> > https://www.biostars.org/
> >
> > It is quite similar to StackOverflow but with a biological sciences
> focus.
> >
> > Hope this helps!
> >
> > ~Caitlin
> >
> >
> >
> > On Sun, Aug 26, 2018 at 6:02 PM Spencer Brackett <
> > spbrackett20 at saintjosephhs.com> wrote:
> >
> >> Caitlin,
> >>
> >>  Thanks again! I already have the two files stored in those two CSV
> files
> >> via my desktop, but if tuning those with this function do not work,
> then I
> >> will try it with a flash drive.
> >>
> >> Best,
> >>
> >> Spencer Brackett
> >>
> >> On Sun, Aug 26, 2018 at 8:56 PM Caitlin <bioprogrammer at gmail.com>
> wrote:
> >>
> >>> Hmm...could you store each in its own file (a flash drive would be
> fine)
> >>> then use:
> >>>
> >>> the_data <- read.csv(file="c:/file_name.csv", header=TRUE, sep=",")
> >>>
> >>> to read each into your script? The data would then exist as a
> dataframe object that you could then work with.
> >>>
> >>>
> >>> On Sun, Aug 26, 2018 at 5:50 PM Spencer Brackett <
> >>> spbrackett20 at saintjosephhs.com> wrote:
> >>>
> >>>> Caitlin,
> >>>>
> >>>>  Perhaps that is the problem. To be more specific, the data was
> >>>> transferred from the TCGA database to a CSV file... there are
> technically
> >>>> two separate files (CSV) for this analysis.... one for GBM and one
> for LGG.
> >>>> Both CVS files were then individually downloaded onto my open R
> console.
> >>>> Upon arranging them with the summary () function, the data expanded
> and
> >>>> took up the whole console page... even seemingly abrogating the
> arguments
> >>>> which allowed for the data to be downloaded onto R in the first
> place. Are
> >>>> you suggesting that I would need to utilize a flash drive to
> successfully
> >>>> utilize the function you suggested? Or could I perhaps do so with the
> CSV
> >>>> field I mentioned? If so, how?
> >>>>
> >>>> -Spencer B
> >>>>
> >>>> On Sun, Aug 26, 2018 at 8:42 PM Caitlin <bioprogrammer at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> No worries Spencer. There is no downloaded data? Nothing is
> physically
> >>>>> stored on your hard drive? The dot in the path would be interpreted
> (no pun
> >>>>> intended!) as something like the following:
> >>>>>
> >>>>> If the TCGA data was stored in a file named "tcga_data.dat" and it
> was
> >>>>> in a directory named "C:\spencer", the 4th line of that script would
> set
> >>>>> the path to "C:\spencer\tcga_data.dat" if you ran the script from
> that same
> >>>>> folder. If your tcga data is not stored in the same file from which
> the
> >>>>> script is being ran, it won't find any data to work with. Does this
> help?
> >>>>>
> >>>>>
> >>>>> On Sun, Aug 26, 2018 at 5:34 PM Spencer Brackett <
> >>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>
> >>>>>> Caitlin,
> >>>>>>
> >>>>>>   Forgive me, but I?m not quite sure exactly what your question is
> >>>>>> asking. The data is originally from the TCGA and I have it
> downloaded onto
> >>>>>> another R script. I opened a new script to perform the functions I
> posted
> >>>>>> to this forum because I was unable to input any other commands into
> the
> >>>>>> console.... due to the fact that the translated data filled the
> entirety of
> >>>>>> said consule. Perhaps overloaded it? Regardless, I was unable to
> input any
> >>>>>> further commands.
> >>>>>>
> >>>>>> -Spencer Brackett
> >>>>>>
> >>>>>>
> >>>>>> On Sun, Aug 26, 2018 at 8:27 PM Caitlin <bioprogrammer at gmail.com>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> You're welcome Spencer :)
> >>>>>>>
> >>>>>>> The 4th line:
> >>>>>>>
> >>>>>>> path <? "."
> >>>>>>>
> >>>>>>> refers to the current directory (the dot in other words). Is the
> >>>>>>> data stored in the same directory where the code is being run?
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> On Sun, Aug 26, 2018 at 5:22 PM Spencer Brackett <
> >>>>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>>>
> >>>>>>>>  Thank you! I will make note of that. Unfortunately, lines 1 and 4
> >>>>>>>> of the first portion of this analysis appear to be where the error
> >>>>>>>> begins... to which several subsequent lines also come up as
> ?errored?.
> >>>>>>>> Perhaps this is an issue of the capitalization and/or spacing
> (something
> >>>>>>>> within the text)? The proposed method for methylation data
> extraction is
> >>>>>>>> based on the first third of the following TCGA workflow:
> >>>>>>>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5302158/#!po=
> 0.0715308
> >>>>>>>>
> >>>>>>>> Best,
> >>>>>>>>
> >>>>>>>> Spencer Brackett
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On Sun, Aug 26, 2018 at 8:07 PM Caitlin <bioprogrammer at gmail.com>
> >>>>>>>> wrote:
> >>>>>>>>
> >>>>>>>>> Hi Spencer.
> >>>>>>>>>
> >>>>>>>>> Should you capitalize the following library import?
> >>>>>>>>>
> >>>>>>>>> library(summarizedExperiment)
> >>>>>>>>>
> >>>>>>>>> In other words, I think that line should be:
> >>>>>>>>>
> >>>>>>>>> library(SummarizedExperiment)
> >>>>>>>>>
> >>>>>>>>> Hope this helps.
> >>>>>>>>>
> >>>>>>>>> ~Caitlin
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> On Sun, Aug 26, 2018 at 2:09 PM Spencer Brackett <
> >>>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>>>>>
> >>>>>>>>>> Good evening,
> >>>>>>>>>>
> >>>>>>>>>>   I am attempting to run the following analysis on TCGA data,
> >>>>>>>>>> however
> >>>>>>>>>> something is being reported as an error in my arguments... any
> >>>>>>>>>> ideas as to
> >>>>>>>>>> what is incorrect in the following? Thanks!
> >>>>>>>>>>
> >>>>>>>>>> 1 library(TCGAbiolinks)
> >>>>>>>>>> 2
> >>>>>>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG
> >>>>>>>>>> and GBM.
> >>>>>>>>>> 4 path <? "."
> >>>>>>>>>> 5
> >>>>>>>>>> 6 query.met <? TCGAquery(tumor =
> >>>>>>>>>> c("LGG","GBM"),"HumanMethylation450",
> >>>>>>>>>> level = 3)
> >>>>>>>>>> 7 TCGAdownload(query.met, path = path )
> >>>>>>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
> >>>>>>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
> >>>>>>>>>> 10                    summarizedExperiment = TRUE,
> >>>>>>>>>> 11                      save = TRUE, filename =
> "lgg_gbm_met.rda")
> >>>>>>>>>> 12
> >>>>>>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG
> and
> >>>>>>>>>> GBM.
> >>>>>>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> >>>>>>>>>> "IlluminaHiSeq_
> >>>>>>>>>> RNASeqV2",level = 3)
> >>>>>>>>>> 15
> >>>>>>>>>> 16 TCGAdownload(query.exp,path = path, type =
> >>>>>>>>>> "rsem.genes.normalized_
> >>>>>>>>>> results")
> >>>>>>>>>> 17
> >>>>>>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
> >>>>>>>>>> 19                    summarizedExperiment = TRUE,
> >>>>>>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
> >>>>>>>>>> 21                    type = "rsem.genes.normalized_results",
> >>>>>>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
> >>>>>>>>>>
> >>>>>>>>>> To download data on DNA methylation and gene expression?
> >>>>>>>>>>
> >>>>>>>>>> 1 library(summarizedExperiment)
> >>>>>>>>>> 2 # get expression matrix
> >>>>>>>>>> 3 data <? assay(exp)
> >>>>>>>>>> 4
> >>>>>>>>>> 5 # get sample information
> >>>>>>>>>> 6 sample.info <? colData(exp)
> >>>>>>>>>> 7
> >>>>>>>>>> 8 # get genes information
> >>>>>>>>>> 9 genes.info <? rowRanges(exp)
> >>>>>>>>>>
> >>>>>>>>>> Following stepwise procedure for obtaining GBM and LGG clinical
> >>>>>>>>>> data?
> >>>>>>>>>>
> >>>>>>>>>> 1 # get clinical patient data for GBM samples
> >>>>>>>>>> 2 gbm_clin <? TCGAquery_clinic("gbm","clinical_patient")
> >>>>>>>>>> 3
> >>>>>>>>>> 4 # get clinical patient data for LGG samples
> >>>>>>>>>> 5 lgg_clin <? TCGAquery_clinic("lgg","clinical_patient")
> >>>>>>>>>> 6
> >>>>>>>>>> 7 # Bind the results, as the columns might not be the same,
> >>>>>>>>>> 8 # we will plyr rbind.fill , to have all columns from both
> files
> >>>>>>>>>> 9 clinical <? plyr::rbind.fill(gbm_clin ,lgg_clin)
> >>>>>>>>>> 10
> >>>>>>>>>> 11 # Other clinical files can be downloaded,
> >>>>>>>>>> 12 # Use ?TCGAquery_clinic for more information
> >>>>>>>>>> 13 clin_radiation <? TCGAquery_clinic("lgg","
> clinical_radiation")
> >>>>>>>>>> 14
> >>>>>>>>>> 15 # Also, you can get clinical information from different tumor
> >>>>>>>>>> types.
> >>>>>>>>>> 16 # For example sample 1 is GBM, sample 2 and 3 are TGCT
> >>>>>>>>>> 17 data <? TCGAquery_clinic(clinical_data_type =
> >>>>>>>>>> "clinical_patient",
> >>>>>>>>>> 18    samples = c("TCGA-06-5416-01A-01D-1481-05",
> >>>>>>>>>> 19  "TCGA-2G-AAEW-01A-11D-A42Z-05",
> >>>>>>>>>> 20  "TCGA-2G-AAEX-01A-11D-A42Z-05"))
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> # Searching idat file for DNA methylation
> >>>>>>>>>> query <- GDCquery(project = "TCGA-GBM",
> >>>>>>>>>>                  data.category = "Raw microarray data",
> >>>>>>>>>>                  data.type = "Raw intensities",
> >>>>>>>>>>                  experimental.strategy = "Methylation array",
> >>>>>>>>>>                  legacy = TRUE,
> >>>>>>>>>>                  file.type = ".idat",
> >>>>>>>>>>                  platform = "Illumina Human Methylation 450")
> >>>>>>>>>>
> >>>>>>>>>> **Repeat for LGG**
> >>>>>>>>>>
> >>>>>>>>>> To access mutational information concerning TMZ methylation?
> >>>>>>>>>>
> >>>>>>>>>> > mutation <? TCGAquery_maf(tumor = "lgg")
> >>>>>>>>>> 2   Getting maf tables
> >>>>>>>>>> 3   Source: https://wiki.nci.nih.gov/
> display/TCGA/TCGA+MAF+Files
> >>>>>>>>>> 4   We found these maf files below:
> >>>>>>>>>> 5       MAF.File.Name
> >>>>>>>>>> 6   2             hgsc.bcm.edu_LGG.IlluminaGA_
> DNASeq.1.somatic.maf
> >>>>>>>>>> 7
> >>>>>>>>>> 8   3
> >>>>>>>>>> LGG_FINAL_ANALYSIS.aggregated.capture.tcga.uuid.curated.
> somatic.maf
> >>>>>>>>>> 9
> >>>>>>>>>> 10       Archive.Name Deploy.Date
> >>>>>>>>>> 11   2 hgsc.bcm.edu_LGG.IlluminaGA_
> DNASeq_automated.Level_2.1.0.0
> >>>>>>>>>>   10-DEC-13
> >>>>>>>>>> 12   3 broad.mit.edu_LGG.IlluminaGA_
> DNASeq_curated.Level_2.1.3.0
> >>>>>>>>>>  24-DEC-14
> >>>>>>>>>> 13
> >>>>>>>>>> 14   Please, select the line that you want to download: 3
> >>>>>>>>>>
> >>>>>>>>>> **Repeat this for GBM***
> >>>>>>>>>>
> >>>>>>>>>> Selecting specified lines to download?
> >>>>>>>>>>
> >>>>>>>>>> 1 gbm.subtypes <? TCGAquery_subtype(tumor = "gbm")
> >>>>>>>>>> 2 lgg.subtypes <? TCGAquery_subtype(tumor = "lgg?)
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> Downloading data via the Bioconductor package RTCGAtoolbox?
> >>>>>>>>>>
> >>>>>>>>>> library(RTCGAToolbox)
> >>>>>>>>>> 2
> >>>>>>>>>> 3 # Get the last run dates
> >>>>>>>>>> 4 lastRunDate <? getFirehoseRunningDates()[1]
> >>>>>>>>>> 5 lastAnalyseDate <? getFirehoseAnalyzeDates(1)
> >>>>>>>>>> 6
> >>>>>>>>>> 7 # get DNA methylation data, RNAseq2 and clinical data for LGG
> >>>>>>>>>> 8 lgg.data <? getFirehoseData(dataset = "LGG",
> >>>>>>>>>> 9       gistic2_Date = getFirehoseAnalyzeDates(1), runDate =
> >>>>>>>>>> lastRunDate,
> >>>>>>>>>> 10       Methylation = TRUE, RNAseq2_Gene_Norm = TRUE, Clinic =
> >>>>>>>>>> TRUE,
> >>>>>>>>>> 11       Mutation = T,
> >>>>>>>>>> 12       fileSizeLimit = 10000)
> >>>>>>>>>> 13
> >>>>>>>>>> 14 # get DNA methylation data, RNAseq2 and clinical data for GBM
> >>>>>>>>>> 15 gbm.data <? getFirehoseData(dataset = "GBM",
> >>>>>>>>>> 16       runDate = lastDate, gistic2_Date =
> >>>>>>>>>> getFirehoseAnalyzeDates(1),
> >>>>>>>>>> 17       Methylation = TRUE, Clinic = TRUE, RNAseq2_Gene_Norm =
> >>>>>>>>>> TRUE,
> >>>>>>>>>> 18       fileSizeLimit = 10000)
> >>>>>>>>>> 19
> >>>>>>>>>> 20 # To access the data you should use the getData function
> >>>>>>>>>> 21 # or simply access with @ (for example gbm.data at Clinical)
> >>>>>>>>>> 22 gbm.mut <? getData(gbm.data,"Mutations")
> >>>>>>>>>> 23 gbm.clin <? getData(gbm.data,"Clinical")
> >>>>>>>>>> 24 gbm.gistic <? getData(gbm.data,"GISTIC")
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> Genomic Analysis/Final data extraction:
> >>>>>>>>>>
> >>>>>>>>>> Enable ?getData? to access the data
> >>>>>>>>>>
> >>>>>>>>>> Obtaining GISTIC results?
> >>>>>>>>>>
> >>>>>>>>>> 1 # Download GISTIC results
> >>>>>>>>>> 2 gistic <? getFirehoseData("GBM",gistic2_Date ="20141017" )
> >>>>>>>>>> 3
> >>>>>>>>>> 4 # get GISTIC results
> >>>>>>>>>> 5 gistic.allbygene <? gistic at GISTIC@AllByGene
> >>>>>>>>>> 6 gistic.thresholedbygene <? gistic at GISTIC@ThresholedByGene
> >>>>>>>>>>
> >>>>>>>>>> Repeat this procedure to obtain LGG GISTIC results.
> >>>>>>>>>>
> >>>>>>>>>> ***Please ignore the 'non-coded' text as they are procedural
> >>>>>>>>>> steps/classifications***
> >>>>>>>>>>
> >>>>>>>>>>         [[alternative HTML version deleted]]
> >>>>>>>>>>
> >>>>>>>>>> ______________________________________________
> >>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >>>>>>>>>>
> >>>>>>>>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Mon Aug 27 11:01:40 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 27 Aug 2018 09:01:40 +0000
Subject: [R] NaN in Scoring Sentiment
In-Reply-To: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
References: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
Message-ID: <8444c6baab4642d8bdf8bfcfe4761db3@SRVEXCHCM1302.precheza.cz>

Hi

the output seems to me rather weird. Unles you have NaNs in input data frame you should not get NaN as a result.

Anyway, your aggregate will give you NA or NaN even when there is only one NA or NaN in your input data frame. So I suggest to use

sentiments_per_Category <- aggregate(relative_sentiment_frequencies,                                      by = list(Category = df$Case.Category), mean, na.rm=TRUE)

This should strip all NAs before calculating mean in each category.

Complete cases removes all lines with at least one NA in your data frame, which probably results to empty data frame.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Shivi Bhatia
> Sent: Saturday, August 25, 2018 4:01 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] NaN in Scoring Sentiment
>
> Hi All- I am running a sentiment scoring model and the code is as below:
> sentiments_per_Category <- aggregate(relative_sentiment_frequencies,
>                                      by = list(Category = df$Case.Category), mean)
>
> while i run the head command most of the values are NaN. i then used
> complete.cases on my data frame df[complete.cases(df),]  but it does not seems
> to work. Please advice if there is a way to handle NaN.
>
> Regards, Shivi
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From @h|v|pmp82 @end|ng |rom gm@||@com  Mon Aug 27 12:31:03 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Mon, 27 Aug 2018 10:31:03 +0000 (UTC)
Subject: [R] NaN in Scoring Sentiment
In-Reply-To: <8444c6baab4642d8bdf8bfcfe4761db3@SRVEXCHCM1302.precheza.cz>
References: <CAB=p7SrWeLzpFbR_6zpJSpUhauL+D1Jm-WQZ2Da2eNC+LMaTjQ@mail.gmail.com>
 <8444c6baab4642d8bdf8bfcfe4761db3@SRVEXCHCM1302.precheza.cz>
Message-ID: <304559663.3649674.1535365863210@mail.yahoo.com>

Thanks you Petr. This worked.?
Regards, Shivi?


Sent from Yahoo Mail for iPhone


On Monday, August 27, 2018, 14:31, PIKAL Petr <petr.pikal at precheza.cz> wrote:

Hi

the output seems to me rather weird. Unles you have NaNs in input data frame you should not get NaN as a result.

Anyway, your aggregate will give you NA or NaN even when there is only one NA or NaN in your input data frame. So I suggest to use

sentiments_per_Category <- aggregate(relative_sentiment_frequencies,? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? by = list(Category = df$Case.Category), mean, na.rm=TRUE)

This should strip all NAs before calculating mean in each category.

Complete cases removes all lines with at least one NA in your data frame, which probably results to empty data frame.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Shivi Bhatia
> Sent: Saturday, August 25, 2018 4:01 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] NaN in Scoring Sentiment
>
> Hi All- I am running a sentiment scoring model and the code is as below:
> sentiments_per_Category <- aggregate(relative_sentiment_frequencies,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? by = list(Category = df$Case.Category), mean)
>
> while i run the head command most of the values are NaN. i then used
> complete.cases on my data frame df[complete.cases(df),]? but it does not seems
> to work. Please advice if there is a way to handle NaN.
>
> Regards, Shivi
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/





	[[alternative HTML version deleted]]



From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug 27 18:25:08 2018
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 27 Aug 2018 19:25:08 +0300
Subject: [R] "use of NULL environment is defunct" when trying to lock a
 reference class
Message-ID: <20180827192508.325baf02@trisector>

Hi!

I'm trying to create a persistent memoising class with a destructor and
an option to evaluate cache misses in parallel. I want to lock all
its fields because it doesn't make sense to change them after the
filename, the environment object and the function are set in the
object. (I'm not sure whether I should lock the environment field I use
as the hash, though.)

The problem is, I can't figure out how to use class$lock(...) properly:

> test.class <- setRefClass("test", fields=c("field"))
> test.class$lock("field")
Error in .makeDefaultBinding(current at field, current at className, TRUE, environment(current)) :
  use of NULL environment is defunct

By looking at traceback() and source of methods:::.lockRefFields,
I see that environment(zzz at generator$def at fieldPrototypes[["field"]])
is, indeed, NULL.

I'm using R version 3.3.3 (2017-03-06),  version$`svn rev` is "72310".

What am I doing wring?

-- 
Best regards,
Ivan

P.S. Please Cc me in your replies to the list, if possible.



From er|cjberger @end|ng |rom gm@||@com  Mon Aug 27 20:48:50 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 27 Aug 2018 21:48:50 +0300
Subject: [R] "use of NULL environment is defunct" when trying to lock a
 reference class
In-Reply-To: <20180827192508.325baf02@trisector>
References: <20180827192508.325baf02@trisector>
Message-ID: <CAGgJW75JO4gFyLadqYUN9_Fgcon0w4=MONtYP4v7TUvrEVOwrg@mail.gmail.com>

Hi Ivan,
Unfortunately I cannot answer your question.
However, I do have quite a bit of experience using R's reference classes
and you might want to consider the more recent R6 package.
It provides R6 classes which have advantages over
reference classes.  See for example:

1. Hadley Wickham on R6 (chapter 16 in "Advanced R")
https://adv-r.hadley.nz/r6.html

2. The R6 package documentation which seems to mention 'lock' in quite a
few places
https://cran.r-project.org/web/packages/R6/R6.pdf

HTH,
Eric


On Mon, Aug 27, 2018 at 7:25 PM, Ivan Krylov <krylov.r00t at gmail.com> wrote:

> Hi!
>
> I'm trying to create a persistent memoising class with a destructor and
> an option to evaluate cache misses in parallel. I want to lock all
> its fields because it doesn't make sense to change them after the
> filename, the environment object and the function are set in the
> object. (I'm not sure whether I should lock the environment field I use
> as the hash, though.)
>
> The problem is, I can't figure out how to use class$lock(...) properly:
>
> > test.class <- setRefClass("test", fields=c("field"))
> > test.class$lock("field")
> Error in .makeDefaultBinding(current at field, current at className, TRUE,
> environment(current)) :
>   use of NULL environment is defunct
>
> By looking at traceback() and source of methods:::.lockRefFields,
> I see that environment(zzz at generator$def at fieldPrototypes[["field"]])
> is, indeed, NULL.
>
> I'm using R version 3.3.3 (2017-03-06),  version$`svn rev` is "72310".
>
> What am I doing wring?
>
> --
> Best regards,
> Ivan
>
> P.S. Please Cc me in your replies to the list, if possible.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From tu||y@ho|me@ @end|ng |rom wyo@gov  Mon Aug 27 22:14:03 2018
From: tu||y@ho|me@ @end|ng |rom wyo@gov (Tully Holmes)
Date: Mon, 27 Aug 2018 14:14:03 -0600
Subject: [R] Warning: unable to access index for repository...
Message-ID: <CAKGhYij=MzTz+V9THKAzLZmw4yc7QYJExYGezp3N1P8vAzgxGg@mail.gmail.com>

Good afternoon,

I'm trying to install a package with the "install.packages" command in
RGUI, and get the following error message:


> install.packages ("tidyverse")
Warning: unable to access index for repository
https://mran.microsoft.com/snapshot/2017-05-01/src/contrib:
  cannot open URL ''
Warning: unable to access index for repository
https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3:
  cannot open URL '
https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3/PACKAGES
'
Warning message:
package ?tidyverse? is not available (for R version 3.3.3)


Is there any documentation available that might document all the
destination IP addresses that are involved when the "install.packages"
command is ran?  Our R server is in a part of the state network that has
limited access to the internet, so I need to have outbound openings made in
the firewall that will let the install.packages command access what it
needs to access .  Earlier I have coordinated with the firewall team to
open ports 80 and 443 outbound from our R server to the 3 IP addresses that
correspond to mran.microsoft.com, cran.microsoft.com, and www.stats.ox.ac.uk.
I looked up these 3 IP addresses at network-tools.com.  I think there might
be additional IP addresses involved, because after these openings were
made, I'm still getting the error message above.

Thanks,

-- 

Tully Holmes

Business Applications Analyst

State of Wyoming

Wyoming Community College Commission

2300 Capitol Ave., 5th Floor, Suite B

Cheyenne, WY 82002

307-777-6832

-- 

E-Mail to and from me, in connection with the transaction 
of public 
business, is subject to the Wyoming Public Records 
Act and may be 
disclosed to third parties.

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 27 22:35:23 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 27 Aug 2018 13:35:23 -0700
Subject: [R] Warning: unable to access index for repository...
In-Reply-To: <CAKGhYij=MzTz+V9THKAzLZmw4yc7QYJExYGezp3N1P8vAzgxGg@mail.gmail.com>
References: <CAKGhYij=MzTz+V9THKAzLZmw4yc7QYJExYGezp3N1P8vAzgxGg@mail.gmail.com>
Message-ID: <CAGxFJbT4HFA=CGE+q-5BJNN9qJtV199vBbW5bh_w=d0WGZW1fA@mail.gmail.com>

The main CRAN repository is at:
https://cran.r-project.org/

A full list of repositories can be found under the "Mirrors" link there.

Cheers,
Bert



On Mon, Aug 27, 2018 at 1:19 PM Tully Holmes <tully.holmes at wyo.gov> wrote:

> Good afternoon,
>
> I'm trying to install a package with the "install.packages" command in
> RGUI, and get the following error message:
>
>
> > install.packages ("tidyverse")
> Warning: unable to access index for repository
> https://mran.microsoft.com/snapshot/2017-05-01/src/contrib:
>   cannot open URL ''
> Warning: unable to access index for repository
> https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3:
>   cannot open URL '
>
> https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3/PACKAGES
> '
> Warning message:
> package ?tidyverse? is not available (for R version 3.3.3)
>
>
> Is there any documentation available that might document all the
> destination IP addresses that are involved when the "install.packages"
> command is ran?  Our R server is in a part of the state network that has
> limited access to the internet, so I need to have outbound openings made in
> the firewall that will let the install.packages command access what it
> needs to access .  Earlier I have coordinated with the firewall team to
> open ports 80 and 443 outbound from our R server to the 3 IP addresses that
> correspond to mran.microsoft.com, cran.microsoft.com, and
> www.stats.ox.ac.uk.
> I looked up these 3 IP addresses at network-tools.com.  I think there
> might
> be additional IP addresses involved, because after these openings were
> made, I'm still getting the error message above.
>
> Thanks,
>
> --
>
> Tully Holmes
>
> Business Applications Analyst
>
> State of Wyoming
>
> Wyoming Community College Commission
>
> 2300 Capitol Ave., 5th Floor, Suite B
>
> Cheyenne, WY 82002
>
> 307-777-6832
>
> --
>
> E-Mail to and from me, in connection with the transaction
> of public
> business, is subject to the Wyoming Public Records
> Act and may be
> disclosed to third parties.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jrkr|de@u @end|ng |rom y@hoo@c@  Mon Aug 27 22:40:53 2018
From: jrkr|de@u @end|ng |rom y@hoo@c@ (John Kane)
Date: Mon, 27 Aug 2018 20:40:53 +0000 (UTC)
Subject: [R] Cant schedule R job using taskscheduleR
In-Reply-To: <CA+dpOJ=RfRW0eSkvES2vCeR1AuQPrYwdMnwJThqqkvwYyB6Oig@mail.gmail.com>
References: <CA+dpOJ=RfRW0eSkvES2vCeR1AuQPrYwdMnwJThqqkvwYyB6Oig@mail.gmail.com>
Message-ID: <603849833.3481199.1535402453427@mail.yahoo.com>

A quick guess it that your version of R is outdated.sessionInfo()
R version 3.5.0 

package ?taskscheduleR? was built under R version 3.5.1
I don't know if that is the source of the error but I'd suggest updating to 3.5.1 as a first step.
   On Friday, August 24, 2018, 9:12:36 a.m. EDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:  
 
 Hi,

I am trying to schedule an R job using taskscheduler_create() function
available in package taskscheduleR.

Below is my code:

> library(taskscheduleR)
Warning message:
package ?taskscheduleR? was built under R version 3.5.1
> taskscheduler_create(taskname = "ABC", rscript = paste("C:\\ABC.R"),
startdate = format(Sys.Date() + 1, "%d/%m/%Y"), schedule = "WEEKLY",
starttime = "16:30", days = c("MON", "TUE", "WED", "THU", "FRI")[1])
[1] "ERROR: Incorrect Start Date."
attr(,"status")
[1] 16389
Warning message:
In system(cmd, intern = TRUE) :
? running command 'schtasks /Create /TN "ABC" /TR "cmd /c
C:/PROGRA~1/R/R-35~1.0/bin/Rscript.exe \"C:\ABC.R\"? >> \"C:\ABC.log\"
2>&1" /SC WEEKLY /ST 16:30 /SD "25/08/2018" /D MON ' had status 16389


However it fails with stating Incorrect Start Date.

Any help to understand what went wrong?

I am using R in Windows. Below is Session Information :

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United
States.1252? ? LC_MONETARY=English_United States.1252 LC_NUMERIC=C
? ? ? ? ? ? ? ? LC_TIME=English_United States.1252

attached base packages:
[1] stats? ? graphics? grDevices utils? ? datasets? methods? base

other attached packages:
[1] taskscheduleR_1.1

loaded via a namespace (and not attached):
[1] compiler_3.5.0? ? tools_3.5.0? ? ? data.table_1.11.4

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]



From jrkr|de@u @end|ng |rom y@hoo@c@  Mon Aug 27 22:53:08 2018
From: jrkr|de@u @end|ng |rom y@hoo@c@ (John Kane)
Date: Mon, 27 Aug 2018 20:53:08 +0000 (UTC)
Subject: [R] importing .v8x file in R
In-Reply-To: <a7c5cb51-1d19-39bf-caa7-fda093cfa4d6@auckland.ac.nz>
References: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
 <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>
 <a7c5cb51-1d19-39bf-caa7-fda093cfa4d6@auckland.ac.nz>
Message-ID: <819857550.3467885.1535403188592@mail.yahoo.com>

A simple google would have let you here SAS Enterprise Guide Implemented at MDACC.It looks like you have a SAS transport file . Check out the SASxport package. It may do what you want.


| 
| 
|  | 
SAS Enterprise Guide Implemented at MDACC


 |

 |

 |



   On Thursday, August 23, 2018, 4:39:45 a.m. EDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:  
 
 On 08/23/2018 08:35 PM, Rui Barradas wrote:
> Hello,
> 
> Sorry but I don't believe this is a question for r-help.
> 
> r-help is meant for questions about R code, you should find out what 
> type of file do you have. Maybe open it and see its contents.
> 
> There is really nothing we can do.

Indeed.? But the OP could try Googling "v8x file extension".
Psigh!

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]



From tu||y@ho|me@ @end|ng |rom wyo@gov  Mon Aug 27 23:55:03 2018
From: tu||y@ho|me@ @end|ng |rom wyo@gov (Tully Holmes)
Date: Mon, 27 Aug 2018 15:55:03 -0600
Subject: [R] Warning: unable to access index for repository...
In-Reply-To: <CAGxFJbT4HFA=CGE+q-5BJNN9qJtV199vBbW5bh_w=d0WGZW1fA@mail.gmail.com>
References: <CAKGhYij=MzTz+V9THKAzLZmw4yc7QYJExYGezp3N1P8vAzgxGg@mail.gmail.com>
 <CAGxFJbT4HFA=CGE+q-5BJNN9qJtV199vBbW5bh_w=d0WGZW1fA@mail.gmail.com>
Message-ID: <CAKGhYiiuoruWBJxjScqFsjy6Rp_kDcGoWCQsE9ra1k4O19nLtw@mail.gmail.com>

Thanks Bert, I'll reference this repository to determine the firewall rules
we will need.

-- 

Tully Holmes

Business Applications Analyst

State of Wyoming

Wyoming Community College Commission

2300 Capitol Ave., 5th Floor, Suite B

Cheyenne, WY 82002

307-777-6832



On Mon, Aug 27, 2018 at 2:35 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> The main CRAN repository is at:
> https://cran.r-project.org/
>
> A full list of repositories can be found under the "Mirrors" link there.
>
> Cheers,
> Bert
>
>
>
> On Mon, Aug 27, 2018 at 1:19 PM Tully Holmes <tully.holmes at wyo.gov> wrote:
>
>> Good afternoon,
>>
>> I'm trying to install a package with the "install.packages" command in
>> RGUI, and get the following error message:
>>
>>
>> > install.packages ("tidyverse")
>> Warning: unable to access index for repository
>> https://mran.microsoft.com/snapshot/2017-05-01/src/contrib:
>>   cannot open URL ''
>> Warning: unable to access index for repository
>> https://mran.microsoft.com/snapshot/2017-05-01/bin/windows/contrib/3.3:
>>   cannot open URL '
>> https://mran.microsoft.com/snapshot/2017-05-01/bin/
>> windows/contrib/3.3/PACKAGES
>> '
>> Warning message:
>> package ?tidyverse? is not available (for R version 3.3.3)
>>
>>
>> Is there any documentation available that might document all the
>> destination IP addresses that are involved when the "install.packages"
>> command is ran?  Our R server is in a part of the state network that has
>> limited access to the internet, so I need to have outbound openings made
>> in
>> the firewall that will let the install.packages command access what it
>> needs to access .  Earlier I have coordinated with the firewall team to
>> open ports 80 and 443 outbound from our R server to the 3 IP addresses
>> that
>> correspond to mran.microsoft.com, cran.microsoft.com, and
>> www.stats.ox.ac.uk.
>> I looked up these 3 IP addresses at network-tools.com.  I think there
>> might
>> be additional IP addresses involved, because after these openings were
>> made, I'm still getting the error message above.
>>
>> Thanks,
>>
>> --
>>
>> Tully Holmes
>>
>> Business Applications Analyst
>>
>> State of Wyoming
>>
>> Wyoming Community College Commission
>>
>> 2300 Capitol Ave., 5th Floor, Suite B
>> <https://maps.google.com/?q=2300+Capitol+Ave.,+5th+Floor,+Suite+B+%0D%0A+%0D%0ACheyenne,+WY+82002&entry=gmail&source=g>
>>
>> Cheyenne, WY 82002
>>
>> 307-777-6832
>>
>> --
>>
>> E-Mail to and from me, in connection with the transaction
>> of public
>> business, is subject to the Wyoming Public Records
>> Act and may be
>> disclosed to third parties.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 

E-Mail to and from me, in connection with the transaction 
of public 
business, is subject to the Wyoming Public Records 
Act and may be 
disclosed to third parties.

	[[alternative HTML version deleted]]



From @hmed@t|@80 @end|ng |rom gm@||@com  Tue Aug 28 00:54:04 2018
From: @hmed@t|@80 @end|ng |rom gm@||@com (Ahmed Attia)
Date: Mon, 27 Aug 2018 19:54:04 -0300
Subject: [R] r-data partitioning considering two variables (character and
 numeric)
Message-ID: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>

I would like to partition the following dataset (dataGenotype) based
on two variables; Genotype and stand_ID, for example, for Genotype
H13: stand_ID number 7 may go to training and stand_ID number 18 and
21 may go to testing.

Genotype    stand_ID    Inventory_date  stemC   mheight
H13             7        5/18/2006  1940.1075   11.33995
H13             7        11/1/2008  10898.9597  23.20395
H13             7        4/14/2009  12830.1284  23.77395
H13            18        11/3/2005  2726.42 13.4432
H13            18        6/30/2008  12226.1554  24.091967
H13            18        4/14/2009  14141.68    25.0922
H13            21        5/18/2006  4981.7158   15.7173
H13            21        4/14/2009  20327.0667  27.9155
H15            9         3/31/2006  3570.06 14.7898
H15            9         11/1/2008  15138.8383  26.2088
H15            9         4/14/2009  17035.4688  26.8778
H15           20         1/18/2005  3016.881    14.1886
H15           20        10/4/2006   8330.4688   20.19425
H15           20        6/30/2008   13576.5 25.4774
H15           32        2/1/2006    3426.2525   14.31815
U21           3         1/9/2006    3660.416    15.09925
U21           3         6/30/2008   13236.29    24.27634
U21           3         4/14/2009   16124.192   25.79562
U21           67        11/4/2005   2812.8425   13.60485
U21           67        4/14/2009   13468.455   24.6203

And the desired output is the following;

A-training

Genotype    stand_ID    Inventory_date  stemC   mheight
H13            7         5/18/2006  1940.1075   11.33995
H13            7         11/1/2008  10898.9597  23.20395
H13            7         4/14/2009  12830.1284  23.77395
H15            9         3/31/2006  3570.06 14.7898
H15            9         11/1/2008  15138.8383  26.2088
H15            9         4/14/2009  17035.4688  26.8778
U21            67        11/4/2005  2812.8425   13.60485
U21            67        4/14/2009  13468.455   24.6203

B-testing

Genotype    stand_ID    Inventory_date  stemC   mheight
H13             18       11/3/2005  2726.42 13.4432
H13             18       6/30/2008  12226.1554  24.091967
H13             18       4/14/2009  14141.68    25.0922
H13             21       5/18/2006  4981.7158   15.7173
H13             21       4/14/2009  20327.0667  27.9155
H15             20       1/18/2005  3016.881    14.1886
H15             20       10/4/2006  8330.4688   20.19425
H15             20       6/30/2008  13576.5 25.4774
H15             32       2/1/2006   3426.2525   14.31815
U21             3        1/9/2006   3660.416    15.09925
U21             3        6/30/2008  13236.29    24.27634
U21             3        4/14/2009  16124.192   25.79562

I tried the following code;

library(caret)
dataPartitioning <- createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
train = dataGenotype[dataPartitioning,]
test = dataGenotype[-dataPartitioning,]

Also tried

createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)

It did not produce the desired output, the data are partitioned within
the stand_ID. For example, one row of stand_ID 7 goes to training and
two rows of stand_ID 7 go to testing. How can I partition the data by
Genotype and stand_ID together?.



Ahmed Attia



From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 28 01:09:03 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 27 Aug 2018 16:09:03 -0700
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
Message-ID: <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>

Just partition the unique stand_ID's and select on them using %in% , say:

id <- unique(dataGenotype$stand_ID)
tst <- sample(id, floor(length(id)/2))
wh <- dataGenotype$stand_ID %in% tst ## logical vector
test<- dataGenotype[wh,]
train <- dataGenotype[!wh,]

There are a million variations on this theme I'm sure.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 27, 2018 at 3:54 PM Ahmed Attia <ahmedatia80 at gmail.com> wrote:

> I would like to partition the following dataset (dataGenotype) based
> on two variables; Genotype and stand_ID, for example, for Genotype
> H13: stand_ID number 7 may go to training and stand_ID number 18 and
> 21 may go to testing.
>
> Genotype    stand_ID    Inventory_date  stemC   mheight
> H13             7        5/18/2006  1940.1075   11.33995
> H13             7        11/1/2008  10898.9597  23.20395
> H13             7        4/14/2009  12830.1284  23.77395
> H13            18        11/3/2005  2726.42 13.4432
> H13            18        6/30/2008  12226.1554  24.091967
> H13            18        4/14/2009  14141.68    25.0922
> H13            21        5/18/2006  4981.7158   15.7173
> H13            21        4/14/2009  20327.0667  27.9155
> H15            9         3/31/2006  3570.06 14.7898
> H15            9         11/1/2008  15138.8383  26.2088
> H15            9         4/14/2009  17035.4688  26.8778
> H15           20         1/18/2005  3016.881    14.1886
> H15           20        10/4/2006   8330.4688   20.19425
> H15           20        6/30/2008   13576.5 25.4774
> H15           32        2/1/2006    3426.2525   14.31815
> U21           3         1/9/2006    3660.416    15.09925
> U21           3         6/30/2008   13236.29    24.27634
> U21           3         4/14/2009   16124.192   25.79562
> U21           67        11/4/2005   2812.8425   13.60485
> U21           67        4/14/2009   13468.455   24.6203
>
> And the desired output is the following;
>
> A-training
>
> Genotype    stand_ID    Inventory_date  stemC   mheight
> H13            7         5/18/2006  1940.1075   11.33995
> H13            7         11/1/2008  10898.9597  23.20395
> H13            7         4/14/2009  12830.1284  23.77395
> H15            9         3/31/2006  3570.06 14.7898
> H15            9         11/1/2008  15138.8383  26.2088
> H15            9         4/14/2009  17035.4688  26.8778
> U21            67        11/4/2005  2812.8425   13.60485
> U21            67        4/14/2009  13468.455   24.6203
>
> B-testing
>
> Genotype    stand_ID    Inventory_date  stemC   mheight
> H13             18       11/3/2005  2726.42 13.4432
> H13             18       6/30/2008  12226.1554  24.091967
> H13             18       4/14/2009  14141.68    25.0922
> H13             21       5/18/2006  4981.7158   15.7173
> H13             21       4/14/2009  20327.0667  27.9155
> H15             20       1/18/2005  3016.881    14.1886
> H15             20       10/4/2006  8330.4688   20.19425
> H15             20       6/30/2008  13576.5 25.4774
> H15             32       2/1/2006   3426.2525   14.31815
> U21             3        1/9/2006   3660.416    15.09925
> U21             3        6/30/2008  13236.29    24.27634
> U21             3        4/14/2009  16124.192   25.79562
>
> I tried the following code;
>
> library(caret)
> dataPartitioning <-
> createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
> train = dataGenotype[dataPartitioning,]
> test = dataGenotype[-dataPartitioning,]
>
> Also tried
>
> createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
>
> It did not produce the desired output, the data are partitioned within
> the stand_ID. For example, one row of stand_ID 7 goes to training and
> two rows of stand_ID 7 go to testing. How can I partition the data by
> Genotype and stand_ID together?.
>
>
>
> Ahmed Attia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Tue Aug 28 01:10:43 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 27 Aug 2018 23:10:43 +0000
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
Message-ID: <AB76DEC9-603A-4796-994C-619669ED2FD0@llnl.gov>

You could start with split()

grp <- rep('', nrow(mydata) )
grp[mydata$stand_ID %in% c(7,9,67)] <- 'A-training'
grp[mydata$stand_ID %in% c(3,18,20,21,32)] <- 'B-testing'

split(mydata, grp)

or perhaps

grp <- ifelse(  mydata$stand_ID %in% c(7,9,67) , 'A-training', 'B-testing' )
split(mydata, grp)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/27/18, 3:54 PM, "R-help on behalf of Ahmed Attia" <r-help-bounces at r-project.org on behalf of ahmedatia80 at gmail.com> wrote:

    I would like to partition the following dataset (dataGenotype) based
    on two variables; Genotype and stand_ID, for example, for Genotype
    H13: stand_ID number 7 may go to training and stand_ID number 18 and
    21 may go to testing.
    
    Genotype    stand_ID    Inventory_date  stemC   mheight
    H13             7        5/18/2006  1940.1075   11.33995
    H13             7        11/1/2008  10898.9597  23.20395
    H13             7        4/14/2009  12830.1284  23.77395
    H13            18        11/3/2005  2726.42 13.4432
    H13            18        6/30/2008  12226.1554  24.091967
    H13            18        4/14/2009  14141.68    25.0922
    H13            21        5/18/2006  4981.7158   15.7173
    H13            21        4/14/2009  20327.0667  27.9155
    H15            9         3/31/2006  3570.06 14.7898
    H15            9         11/1/2008  15138.8383  26.2088
    H15            9         4/14/2009  17035.4688  26.8778
    H15           20         1/18/2005  3016.881    14.1886
    H15           20        10/4/2006   8330.4688   20.19425
    H15           20        6/30/2008   13576.5 25.4774
    H15           32        2/1/2006    3426.2525   14.31815
    U21           3         1/9/2006    3660.416    15.09925
    U21           3         6/30/2008   13236.29    24.27634
    U21           3         4/14/2009   16124.192   25.79562
    U21           67        11/4/2005   2812.8425   13.60485
    U21           67        4/14/2009   13468.455   24.6203
    
    And the desired output is the following;
    
    A-training
    
    Genotype    stand_ID    Inventory_date  stemC   mheight
    H13            7         5/18/2006  1940.1075   11.33995
    H13            7         11/1/2008  10898.9597  23.20395
    H13            7         4/14/2009  12830.1284  23.77395
    H15            9         3/31/2006  3570.06 14.7898
    H15            9         11/1/2008  15138.8383  26.2088
    H15            9         4/14/2009  17035.4688  26.8778
    U21            67        11/4/2005  2812.8425   13.60485
    U21            67        4/14/2009  13468.455   24.6203
    
    B-testing
    
    Genotype    stand_ID    Inventory_date  stemC   mheight
    H13             18       11/3/2005  2726.42 13.4432
    H13             18       6/30/2008  12226.1554  24.091967
    H13             18       4/14/2009  14141.68    25.0922
    H13             21       5/18/2006  4981.7158   15.7173
    H13             21       4/14/2009  20327.0667  27.9155
    H15             20       1/18/2005  3016.881    14.1886
    H15             20       10/4/2006  8330.4688   20.19425
    H15             20       6/30/2008  13576.5 25.4774
    H15             32       2/1/2006   3426.2525   14.31815
    U21             3        1/9/2006   3660.416    15.09925
    U21             3        6/30/2008  13236.29    24.27634
    U21             3        4/14/2009  16124.192   25.79562
    
    I tried the following code;
    
    library(caret)
    dataPartitioning <- createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
    train = dataGenotype[dataPartitioning,]
    test = dataGenotype[-dataPartitioning,]
    
    Also tried
    
    createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
    
    It did not produce the desired output, the data are partitioned within
    the stand_ID. For example, one row of stand_ID 7 goes to training and
    two rows of stand_ID 7 go to testing. How can I partition the data by
    Genotype and stand_ID together?.
    
    
    
    Ahmed Attia
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @end|ng |rom ||n|@gov  Tue Aug 28 01:14:45 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 27 Aug 2018 23:14:45 +0000
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <AB76DEC9-603A-4796-994C-619669ED2FD0@llnl.gov>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
 <AB76DEC9-603A-4796-994C-619669ED2FD0@llnl.gov>
Message-ID: <2A3BA850-7CAC-4D8A-83A8-33A61F0AB003@llnl.gov>

And yes, I ignored Genotype, but for the example data none of the stand_ID values are present in more than one Genotype, so it doesn't matter. If that's not true in general, then constructing the grp variable is a little more complex, but the principle is the same.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 8/27/18, 4:10 PM, "R-help on behalf of MacQueen, Don via R-help" <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

    You could start with split()
    
    grp <- rep('', nrow(mydata) )
    grp[mydata$stand_ID %in% c(7,9,67)] <- 'A-training'
    grp[mydata$stand_ID %in% c(3,18,20,21,32)] <- 'B-testing'
    
    split(mydata, grp)
    
    or perhaps
    
    grp <- ifelse(  mydata$stand_ID %in% c(7,9,67) , 'A-training', 'B-testing' )
    split(mydata, grp)
    
    -Don
    
    --
    Don MacQueen
    Lawrence Livermore National Laboratory
    7000 East Ave., L-627
    Livermore, CA 94550
    925-423-1062
    Lab cell 925-724-7509
     
     
    
    On 8/27/18, 3:54 PM, "R-help on behalf of Ahmed Attia" <r-help-bounces at r-project.org on behalf of ahmedatia80 at gmail.com> wrote:
    
        I would like to partition the following dataset (dataGenotype) based
        on two variables; Genotype and stand_ID, for example, for Genotype
        H13: stand_ID number 7 may go to training and stand_ID number 18 and
        21 may go to testing.
        
        Genotype    stand_ID    Inventory_date  stemC   mheight
        H13             7        5/18/2006  1940.1075   11.33995
        H13             7        11/1/2008  10898.9597  23.20395
        H13             7        4/14/2009  12830.1284  23.77395
        H13            18        11/3/2005  2726.42 13.4432
        H13            18        6/30/2008  12226.1554  24.091967
        H13            18        4/14/2009  14141.68    25.0922
        H13            21        5/18/2006  4981.7158   15.7173
        H13            21        4/14/2009  20327.0667  27.9155
        H15            9         3/31/2006  3570.06 14.7898
        H15            9         11/1/2008  15138.8383  26.2088
        H15            9         4/14/2009  17035.4688  26.8778
        H15           20         1/18/2005  3016.881    14.1886
        H15           20        10/4/2006   8330.4688   20.19425
        H15           20        6/30/2008   13576.5 25.4774
        H15           32        2/1/2006    3426.2525   14.31815
        U21           3         1/9/2006    3660.416    15.09925
        U21           3         6/30/2008   13236.29    24.27634
        U21           3         4/14/2009   16124.192   25.79562
        U21           67        11/4/2005   2812.8425   13.60485
        U21           67        4/14/2009   13468.455   24.6203
        
        And the desired output is the following;
        
        A-training
        
        Genotype    stand_ID    Inventory_date  stemC   mheight
        H13            7         5/18/2006  1940.1075   11.33995
        H13            7         11/1/2008  10898.9597  23.20395
        H13            7         4/14/2009  12830.1284  23.77395
        H15            9         3/31/2006  3570.06 14.7898
        H15            9         11/1/2008  15138.8383  26.2088
        H15            9         4/14/2009  17035.4688  26.8778
        U21            67        11/4/2005  2812.8425   13.60485
        U21            67        4/14/2009  13468.455   24.6203
        
        B-testing
        
        Genotype    stand_ID    Inventory_date  stemC   mheight
        H13             18       11/3/2005  2726.42 13.4432
        H13             18       6/30/2008  12226.1554  24.091967
        H13             18       4/14/2009  14141.68    25.0922
        H13             21       5/18/2006  4981.7158   15.7173
        H13             21       4/14/2009  20327.0667  27.9155
        H15             20       1/18/2005  3016.881    14.1886
        H15             20       10/4/2006  8330.4688   20.19425
        H15             20       6/30/2008  13576.5 25.4774
        H15             32       2/1/2006   3426.2525   14.31815
        U21             3        1/9/2006   3660.416    15.09925
        U21             3        6/30/2008  13236.29    24.27634
        U21             3        4/14/2009  16124.192   25.79562
        
        I tried the following code;
        
        library(caret)
        dataPartitioning <- createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
        train = dataGenotype[dataPartitioning,]
        test = dataGenotype[-dataPartitioning,]
        
        Also tried
        
        createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
        
        It did not produce the desired output, the data are partitioned within
        the stand_ID. For example, one row of stand_ID 7 goes to training and
        two rows of stand_ID 7 go to testing. How can I partition the data by
        Genotype and stand_ID together?.
        
        
        
        Ahmed Attia
        
        ______________________________________________
        R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
        https://stat.ethz.ch/mailman/listinfo/r-help
        PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
        and provide commented, minimal, self-contained, reproducible code.
        
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 28 01:50:47 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 27 Aug 2018 16:50:47 -0700
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
 <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>
Message-ID: <CAGxFJbQJau0JdkvPmcGwL4+6q_-Lj3zDqtFB0du_F3fok_V-hw@mail.gmail.com>

Sorry, my bad -- careless reading: you need to do the partitioning within
genotype.
Something like:

by(dataGenotype, dataGenotype$Genotype, function(x){

  u <- unique(x$standID)

   tst <- x$x2 %in% sample(u, floor(length(u)/2))

   list(test = x[tst,], train = x[!tst,]

   })


This will give a list each component of which will split the Genotype into
test and train dataframe subsets by ID. These lists of data frames can then
be recombined into a single test and train dataframe by, e.g. an
appropriate rbind() call.


HOWEVER, note that you will need to modify this function to decide what to
do if/when there is only one ID in a Genotype, as Don MacQueen already
pointed out.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 27, 2018 at 4:09 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Just partition the unique stand_ID's and select on them using %in% , say:
>
> id <- unique(dataGenotype$stand_ID)
> tst <- sample(id, floor(length(id)/2))
> wh <- dataGenotype$stand_ID %in% tst ## logical vector
> test<- dataGenotype[wh,]
> train <- dataGenotype[!wh,]
>
> There are a million variations on this theme I'm sure.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 27, 2018 at 3:54 PM Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>
>> I would like to partition the following dataset (dataGenotype) based
>> on two variables; Genotype and stand_ID, for example, for Genotype
>> H13: stand_ID number 7 may go to training and stand_ID number 18 and
>> 21 may go to testing.
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13             7        5/18/2006  1940.1075   11.33995
>> H13             7        11/1/2008  10898.9597  23.20395
>> H13             7        4/14/2009  12830.1284  23.77395
>> H13            18        11/3/2005  2726.42 13.4432
>> H13            18        6/30/2008  12226.1554  24.091967
>> H13            18        4/14/2009  14141.68    25.0922
>> H13            21        5/18/2006  4981.7158   15.7173
>> H13            21        4/14/2009  20327.0667  27.9155
>> H15            9         3/31/2006  3570.06 14.7898
>> H15            9         11/1/2008  15138.8383  26.2088
>> H15            9         4/14/2009  17035.4688  26.8778
>> H15           20         1/18/2005  3016.881    14.1886
>> H15           20        10/4/2006   8330.4688   20.19425
>> H15           20        6/30/2008   13576.5 25.4774
>> H15           32        2/1/2006    3426.2525   14.31815
>> U21           3         1/9/2006    3660.416    15.09925
>> U21           3         6/30/2008   13236.29    24.27634
>> U21           3         4/14/2009   16124.192   25.79562
>> U21           67        11/4/2005   2812.8425   13.60485
>> U21           67        4/14/2009   13468.455   24.6203
>>
>> And the desired output is the following;
>>
>> A-training
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13            7         5/18/2006  1940.1075   11.33995
>> H13            7         11/1/2008  10898.9597  23.20395
>> H13            7         4/14/2009  12830.1284  23.77395
>> H15            9         3/31/2006  3570.06 14.7898
>> H15            9         11/1/2008  15138.8383  26.2088
>> H15            9         4/14/2009  17035.4688  26.8778
>> U21            67        11/4/2005  2812.8425   13.60485
>> U21            67        4/14/2009  13468.455   24.6203
>>
>> B-testing
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13             18       11/3/2005  2726.42 13.4432
>> H13             18       6/30/2008  12226.1554  24.091967
>> H13             18       4/14/2009  14141.68    25.0922
>> H13             21       5/18/2006  4981.7158   15.7173
>> H13             21       4/14/2009  20327.0667  27.9155
>> H15             20       1/18/2005  3016.881    14.1886
>> H15             20       10/4/2006  8330.4688   20.19425
>> H15             20       6/30/2008  13576.5 25.4774
>> H15             32       2/1/2006   3426.2525   14.31815
>> U21             3        1/9/2006   3660.416    15.09925
>> U21             3        6/30/2008  13236.29    24.27634
>> U21             3        4/14/2009  16124.192   25.79562
>>
>> I tried the following code;
>>
>> library(caret)
>> dataPartitioning <-
>> createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
>> train = dataGenotype[dataPartitioning,]
>> test = dataGenotype[-dataPartitioning,]
>>
>> Also tried
>>
>> createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
>>
>> It did not produce the desired output, the data are partitioned within
>> the stand_ID. For example, one row of stand_ID 7 goes to training and
>> two rows of stand_ID 7 go to testing. How can I partition the data by
>> Genotype and stand_ID together?.
>>
>>
>>
>> Ahmed Attia
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From @hmed@t|@80 @end|ng |rom gm@||@com  Tue Aug 28 02:46:33 2018
From: @hmed@t|@80 @end|ng |rom gm@||@com (Ahmed Attia)
Date: Mon, 27 Aug 2018 21:46:33 -0300
Subject: [R] 
 r-data partitioning considering two variables (character and
 numeric)
In-Reply-To: <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>
References: <CAG6S0On1C184H8M2YP08wJX-W2VJMcBAhR9qP9niFS7JBomeFQ@mail.gmail.com>
 <CAGxFJbRR6KTcj80NTGSwHZy3CKRN6i+xdMopM3iJsmgrDgZf=w@mail.gmail.com>
Message-ID: <CAG6S0OkBZmrkejifbjfb65eNbE4gKJH=gLKM3DT74vN_h_7VoQ@mail.gmail.com>

Thanks Bert, worked nicely. Yes, genotypes with only one ID will be
eliminated before partitioning the data.


Best regards

Ahmed Attia






On Mon, Aug 27, 2018 at 8:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Just partition the unique stand_ID's and select on them using %in% , say:
>
> id <- unique(dataGenotype$stand_ID)
> tst <- sample(id, floor(length(id)/2))
> wh <- dataGenotype$stand_ID %in% tst ## logical vector
> test<- dataGenotype[wh,]
> train <- dataGenotype[!wh,]
>
> There are a million variations on this theme I'm sure.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 27, 2018 at 3:54 PM Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>>
>> I would like to partition the following dataset (dataGenotype) based
>> on two variables; Genotype and stand_ID, for example, for Genotype
>> H13: stand_ID number 7 may go to training and stand_ID number 18 and
>> 21 may go to testing.
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13             7        5/18/2006  1940.1075   11.33995
>> H13             7        11/1/2008  10898.9597  23.20395
>> H13             7        4/14/2009  12830.1284  23.77395
>> H13            18        11/3/2005  2726.42 13.4432
>> H13            18        6/30/2008  12226.1554  24.091967
>> H13            18        4/14/2009  14141.68    25.0922
>> H13            21        5/18/2006  4981.7158   15.7173
>> H13            21        4/14/2009  20327.0667  27.9155
>> H15            9         3/31/2006  3570.06 14.7898
>> H15            9         11/1/2008  15138.8383  26.2088
>> H15            9         4/14/2009  17035.4688  26.8778
>> H15           20         1/18/2005  3016.881    14.1886
>> H15           20        10/4/2006   8330.4688   20.19425
>> H15           20        6/30/2008   13576.5 25.4774
>> H15           32        2/1/2006    3426.2525   14.31815
>> U21           3         1/9/2006    3660.416    15.09925
>> U21           3         6/30/2008   13236.29    24.27634
>> U21           3         4/14/2009   16124.192   25.79562
>> U21           67        11/4/2005   2812.8425   13.60485
>> U21           67        4/14/2009   13468.455   24.6203
>>
>> And the desired output is the following;
>>
>> A-training
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13            7         5/18/2006  1940.1075   11.33995
>> H13            7         11/1/2008  10898.9597  23.20395
>> H13            7         4/14/2009  12830.1284  23.77395
>> H15            9         3/31/2006  3570.06 14.7898
>> H15            9         11/1/2008  15138.8383  26.2088
>> H15            9         4/14/2009  17035.4688  26.8778
>> U21            67        11/4/2005  2812.8425   13.60485
>> U21            67        4/14/2009  13468.455   24.6203
>>
>> B-testing
>>
>> Genotype    stand_ID    Inventory_date  stemC   mheight
>> H13             18       11/3/2005  2726.42 13.4432
>> H13             18       6/30/2008  12226.1554  24.091967
>> H13             18       4/14/2009  14141.68    25.0922
>> H13             21       5/18/2006  4981.7158   15.7173
>> H13             21       4/14/2009  20327.0667  27.9155
>> H15             20       1/18/2005  3016.881    14.1886
>> H15             20       10/4/2006  8330.4688   20.19425
>> H15             20       6/30/2008  13576.5 25.4774
>> H15             32       2/1/2006   3426.2525   14.31815
>> U21             3        1/9/2006   3660.416    15.09925
>> U21             3        6/30/2008  13236.29    24.27634
>> U21             3        4/14/2009  16124.192   25.79562
>>
>> I tried the following code;
>>
>> library(caret)
>> dataPartitioning <-
>> createDataPartition(dataGenotype$stand_ID,1,list=F,p=0.2)
>> train = dataGenotype[dataPartitioning,]
>> test = dataGenotype[-dataPartitioning,]
>>
>> Also tried
>>
>> createDataPartition(unique(dataGenotype$stand_ID),1,list=F,p=0.2)
>>
>> It did not produce the desired output, the data are partitioned within
>> the stand_ID. For example, one row of stand_ID 7 goes to training and
>> two rows of stand_ID 7 go to testing. How can I partition the data by
>> Genotype and stand_ID together?.
>>
>>
>>
>> Ahmed Attia
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From v|dh|@@|@g|r| @end|ng |rom gm@||@com  Tue Aug 28 01:51:42 2018
From: v|dh|@@|@g|r| @end|ng |rom gm@||@com (Vidya Alagiriswamy)
Date: Mon, 27 Aug 2018 16:51:42 -0700
Subject: [R] importing .v8x file in R
In-Reply-To: <819857550.3467885.1535403188592@mail.yahoo.com>
References: <CAANEQO1oCpcz_1T85MmfOMbJiGjjVkPjDGC4MWsY9nuHne_1EA@mail.gmail.com>
 <5761000f-8e0c-bd9c-c756-7aab6ce308a4@sapo.pt>
 <a7c5cb51-1d19-39bf-caa7-fda093cfa4d6@auckland.ac.nz>
 <819857550.3467885.1535403188592@mail.yahoo.com>
Message-ID: <047ACB2C-E289-4A56-AF89-705A111D225C@gmail.com>

Thank you. Will take look.

Sent from my iPhone

> On Aug 27, 2018, at 1:53 PM, John Kane <jrkrideau at yahoo.ca> wrote:
> 
> A simple google would have let you here SAS Enterprise Guide Implemented at MDACC.
> It looks like you have a SAS transport file . Check out the SASxport package. It may do what you want.
> 
> SAS Enterprise Guide Implemented at MDACC
> 
> 
> On Thursday, August 23, 2018, 4:39:45 a.m. EDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 08/23/2018 08:35 PM, Rui Barradas wrote:
> > Hello,
> > 
> > Sorry but I don't believe this is a question for r-help.
> > 
> > r-help is meant for questions about R code, you should find out what 
> > type of file do you have. Maybe open it and see its contents.
> > 
> > There is really nothing we can do.
> 
> Indeed.  But the OP could try Googling "v8x file extension".
> Psigh!
> 
> cheers,
> 
> Rolf
> 
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Tue Aug 28 13:26:14 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Tue, 28 Aug 2018 11:26:14 +0000
Subject: [R] installing R in ubuntu
Message-ID: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                              I am trying to install R in ubuntu AWS instance....

While getting help from google, I came across something called GPG key. How to get the GPG key for an AWS ubuntu  instance? More over, what is a GPG key?

Any general help on installing R in ubuntu AWS instance?

very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Tue Aug 28 15:13:31 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 28 Aug 2018 15:13:31 +0200
Subject: [R] installing R in ubuntu
In-Reply-To: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <1A3EA26D-B035-413D-A7D4-C66807DC3B4D@gmail.com>

It's a digital signature (GNU Privacy Guard). Typically to allow you to verify that the stuff you install is what it says that it is.

However, you are not likely to get more informative answers than that in this forum. Possible better is the R-SIG-debian lists or forums specifically for AWS. (& it is not like googling for "GPG AWS" draws a complete blank.)

-pd


> On 28 Aug 2018, at 13:26 , akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> dear members,
>                              I am trying to install R in ubuntu AWS instance....
> 
> While getting help from google, I came across something called GPG key. How to get the GPG key for an AWS ubuntu  instance? More over, what is a GPG key?
> 
> Any general help on installing R in ubuntu AWS instance?
> 
> very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From rm@h@rp @end|ng |rom me@com  Tue Aug 28 20:00:43 2018
From: rm@h@rp @end|ng |rom me@com (R. Mark Sharp)
Date: Tue, 28 Aug 2018 13:00:43 -0500
Subject: [R] Writing .nc files
In-Reply-To: <3D8D75DC-B773-44A8-92A3-81403F065A4C@me.com>
References: <CAON01EbSs=z6Gd6vPaa9aQReiJTwi6rqHyKBFJ71Wo+bT=yh+g@mail.gmail.com>
 <144921FD-954D-4B92-BF6C-261DECB2535A@me.com>
 <CAON01Ebn+Anh3O-Ux059F4WcUtfE7n5D40x8kJ2nb9kYkohWJw@mail.gmail.com>
 <3D8D75DC-B773-44A8-92A3-81403F065A4C@me.com>
Message-ID: <18943960-4420-41E9-A894-6E8E9CB78FF4@me.com>

Marco,

Always post to the r-help list to have a better chance of finding someone that can help.

There is a very nice tutorial that you should have found. See http://geog.uoregon.edu/bartlein/courses/geog490/week04-netCDF.html#create-and-write-a-netcdf-file

Mark
R. Mark Sharp, Ph.D.
Data Scientist and Biomedical Statistical Consultant
7526 Meadow Green St.
San Antonio, TX 78251
mobile: 210-218-2868
rmsharp at me.com











> On Aug 28, 2018, at 8:26 AM, R. Mark Sharp <rmsharp at me.com> wrote:
> 
> Marco,
> 
> You will need to ask the list. I have never worked with .nc files.
> 
> Most are wanting to go the other direction .nc to .csv or dataframe. Google search with ?.nc file in r?.
> 
> R. Mark Sharp, Ph.D.
> Data Scientist and Biomedical Statistical Consultant
> 7526 Meadow Green St.
> San Antonio, TX 78251
> mobile: 210-218-2868
> rmsharp at me.com
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>> On Aug 27, 2018, at 10:12 AM, Marco Antonio P?rez <marko.luna13 at gmail.com> wrote:
>> 
>> Hello Mark:
>> 
>> I appreciate your sopport in this subject. But now, I need your help again, please. 
>> I wondering if you know how to transform a .csv file to .nc file_
>> 
>> Thanks a lot!!
>> 
>> 2018-08-10 17:08 GMT-03:00 R. Mark Sharp <rmsharp at me.com>:
>> Marco,
>> 
>> The error message indicates that nlon*nlat is 420 and that 1378620/420 has a remainder. For the matrix to form, all rows have to be complete. 
>> 
>> I am guessing you have at least one value incorrect among nlon, nlat, t or the length of fulldatav.
>> 
>> Mark
>> R. Mark Sharp, Ph.D.
>> Data Scientist and Biomedical Statistical Consultant
>> 7526 Meadow Green St.
>> San Antonio, TX 78251
>> mobile: 210-218-2868
>> rmsharp at me.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>>> On Aug 10, 2018, at 10:00 AM, Marco Antonio P?rez <marko.luna13 at gmail.com> wrote:
>>> 
>>> I am trying to write a function to make a matrix of precipitation with
>>> this secuencie;
>>> ######## PRIMER PERIODO
>>> cordex1 <-
>>> nc_open("pr_CAM-44i_ICHEC-EC-EARTH_rcp45_r12i1p1_SMHI-RCA4_v1_mon_200601-201012.nc")
>>> fullmon1<-ncvar_get(cordex1,"pr")
>>> lat<-ncvar_get(cordex1,"lat", start=c(35.5),count=c(20))
>>> lon <-ncvar_get(cordex1,"lon", start=c(125),count=c(21.5))
>>> t <- ncvar_get(cordex1,"time")
>>> nlon <- dim(lon)
>>> nlat <- dim(lat)
>>> nt <- dim(t)
>>> fulldatav <- as.vector(fullmon1)
>>> fulldata <- matrix(fulldatav, nrow=nlon*nlat, ncol=nt)
>>> lonlat <- expand.grid(lon,lat)
>>> df_cordex1<- data.frame(lonlat,fulldata)
>>> 
>>> but with the expresion  fulldata <- matrix(fulldatav, nrow=nlon*nlat,
>>> ncol=nt) this error appears
>>> Warning message:
>>> In matrix(fulldatav, nrow = nlon * nlat, ncol = nt) :
>>> data length [1378620] is not a sub-multiple or multiple of the number of
>>> rows [420]
>>> 
>>> Somebody help me!!!
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 



From kry|ov@r00t @end|ng |rom gm@||@com  Tue Aug 28 22:49:17 2018
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 28 Aug 2018 23:49:17 +0300
Subject: [R] "use of NULL environment is defunct" when trying to lock a
 reference class
In-Reply-To: <CAGgJW75JO4gFyLadqYUN9_Fgcon0w4=MONtYP4v7TUvrEVOwrg@mail.gmail.com>
References: <20180827192508.325baf02@trisector>
 <CAGgJW75JO4gFyLadqYUN9_Fgcon0w4=MONtYP4v7TUvrEVOwrg@mail.gmail.com>
Message-ID: <20180828234917.7544886d@trisector>

Hi Eric,

Thank you for your answer!

On Mon, 27 Aug 2018 21:48:50 +0300
Eric Berger <ericjberger at gmail.com> wrote:

> you might want to consider the more recent R6 package

Indeed, R6 has private fields which fits my idea of an object with
mutable state even better.

My original problem seems to be solved and I'm posting my code (CC0) in
case someone else needs it as a reference:

require(digest); require(R6)
memoised <- R6Class(
	"memoised", lock_objects=T, lock_class=T, cloneable=F,
	private=list(fun=NULL, storage=NULL, cache=NULL),
	public=list(
		initialize=function(fun, storage) { # constructor
			private$fun <- fun
			private$storage <- storage
			private$cache <- tryCatch(
				{
					load(storage)
					cache
				}, error = function(e) {
					new.env(T, emptyenv())
				}
			)
		},
		eval=function(...) { # behave as cached fun
			hash <- digest(list(...), algo="sha1")
			if (exists(hash, private$cache)) return(get(hash, private$cache))
			val <- private$fun(...)
			assign(hash, val, private$cache)
			val
		},
		par.eval=function(args, cl) { # args is list of argument lists
			# hash all because we'll need them later
			hashes <- lapply(args, digest, algo="sha1")
			# indices of not yet evaluated in the original args array
			missing <- Filter(function(i) !exists(hashes[[i]], private$cache), seq_along(args))
			# evaluate and save them
			values <- parLapply(cl, args[missing], function(l) do.call(private$fun,l))
			private$cache[hashes[missing]] <- values
			# get all requested hashes
			private$cache[hashes]
		},
		finalize=function() { # destructor
			cache <- private$cache # must have known name for restore
			save(cache, file=private$storage)
		}
	)
)

It's still a mystery why did setRefClass refuse to lock my class, but
at least it's not blocking my progress.

-- 
Best regards,
Ivan



From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Aug 29 00:11:12 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 29 Aug 2018 10:11:12 +1200
Subject: [R] [FORGED]  installing R in ubuntu
In-Reply-To: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00911828079E7F4051BDC763C80A0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <9dae54da-b21c-6973-909e-3d701ef11436@auckland.ac.nz>

On 08/28/2018 11:26 PM, akshay kulkarni wrote:
> dear members,
>                                I am trying to install R in ubuntu AWS instance....
> 
> While getting help from google, I came across something called GPG key. How to get the GPG key for an AWS ubuntu  instance? More over, what is a GPG key?
> 
> Any general help on installing R in ubuntu AWS instance?
> 
> very many thanks for your time and effort...

You may find the following link helpful.  I did.

https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-18-04-quickstart

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From g@||@|@@|@nny @end|ng |rom gm@||@com  Wed Aug 29 15:19:34 2018
From: g@||@|@@|@nny @end|ng |rom gm@||@com (Fanny Gallais)
Date: Wed, 29 Aug 2018 15:19:34 +0200
Subject: [R] Estimate parameters differential equations system
Message-ID: <CANSOPkWhUaPMi-JM38qxwCtPVndjzZT8AyPbf+LBkJJy-zqB6Q@mail.gmail.com>

Dear R users,



I am working on a simple mathematical model made of two ordinary
differential equations:



dx/dt=-mx-d1(x-c)

dy/dt=mx-d2y



I would like to fit this model to my data and estimate the corresponding
parameters. The thing is I only have observed data for y, x is unknown. Is
it possible to do this in R?



Thank you for your help

Fanny

	[[alternative HTML version deleted]]



From proi@@mit@mitt@i m@iii@g oii gm@ii@com  Wed Aug 29 13:18:32 2018
From: proi@@mit@mitt@i m@iii@g oii gm@ii@com (proi@@mit@mitt@i m@iii@g oii gm@ii@com)
Date: Wed, 29 Aug 2018 16:48:32 +0530
Subject: [R] Bitbucket code
Message-ID: <447701d43f8a$07241930$156c4b90$@gmail.com>

I installed a local zip file a few days ago and the package was recently
modified on bitbucket , with a stable zip version not yet available.

 

How many days does it usually take to get a stable zip version. How can I
`devtools` it from the bitbucket the fastest way? I have my own sourcetree
and the author has created in cloud.

 

 

 

BR

Amit

 

Listusers, 

Early answers help everyone.  Please acknowledge when you receive a useful
reply.

 

 

 


	[[alternative HTML version deleted]]



From proi@@mit@mitt@i m@iii@g oii gm@ii@com  Wed Aug 29 13:24:41 2018
From: proi@@mit@mitt@i m@iii@g oii gm@ii@com (proi@@mit@mitt@i m@iii@g oii gm@ii@com)
Date: Wed, 29 Aug 2018 16:54:41 +0530
Subject: [R] Bitbucket code
In-Reply-To: <447701d43f8a$07241930$156c4b90$@gmail.com>
References: <447701d43f8a$07241930$156c4b90$@gmail.com>
Message-ID: <00eb01d43f8a$e3759e40$aa60dac0$@gmail.com>

 

I installed a local zip file a few days ago and the package was recently
modified on bitbucket , with a stable zip version not yet available.  I have
tried using `remotes` but `RTOOLS` is not updated for 3.5.1

 

Should I use my clone to install into R, I do not think I can install the
whole package using `source()`

 

How should this be done fast and quick?

 

 

How many days does it usually take to get a stable zip version. How can I
`devtools` it from the bitbucket the fastest way? I have my own sourcetree
and the author has created in cloud.

 

 

 

BR

Amit

 

Listusers, 

Early answers help everyone.  Please acknowledge when you receive a useful
reply.

 

 

 


	[[alternative HTML version deleted]]



From m@rc_@chw@rtz @end|ng |rom me@com  Wed Aug 29 16:25:27 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 29 Aug 2018 10:25:27 -0400
Subject: [R] Bitbucket code
In-Reply-To: <447701d43f8a$07241930$156c4b90$@gmail.com>
References: <447701d43f8a$07241930$156c4b90$@gmail.com>
Message-ID: <D72DA336-D5EF-44DD-85B6-0E62F8F3773C@me.com>


> On Aug 29, 2018, at 7:18 AM, prof.amit.mittal at gmail.com wrote:
> 
> I installed a local zip file a few days ago and the package was recently
> modified on bitbucket , with a stable zip version not yet available.
> 
> How many days does it usually take to get a stable zip version. How can I
> `devtools` it from the bitbucket the fastest way? I have my own sourcetree
> and the author has created in cloud.
> 
> 
> BR
> 
> Amit
> 


Hi,

No need to post twice.

I don't use Bitbucket, but it looks like the devtools package has a install_bitbucket() function, so perhaps that will do what you want.

In terms of making a stable archive file available, that will be entirely up to the package maintainer and when/how they choose to make that available (e.g. via CRAN or other vehicles).

Regards,

Marc Schwartz



From pro|@@m|t@m|tt@| @end|ng |rom gm@||@com  Wed Aug 29 16:31:20 2018
From: pro|@@m|t@m|tt@| @end|ng |rom gm@||@com (Amit Mittal)
Date: Wed, 29 Aug 2018 14:31:20 +0000
Subject: [R] Bitbucket code
In-Reply-To: <D72DA336-D5EF-44DD-85B6-0E62F8F3773C@me.com>
References: <447701d43f8a$07241930$156c4b90$@gmail.com>,
 <D72DA336-D5EF-44DD-85B6-0E62F8F3773C@me.com>
Message-ID: <DM6PR01MB41079586796CE83CD4EE84F1FC090@DM6PR01MB4107.prod.exchangelabs.com>

I stumbled upon `remotes` and that is based on `devtools` but it fails because RTOOLS haven't been upgraded for 3.5.1

Sorry about posting twice and I am pretty sure I added this detail in another msg which will also be released by the moderator q yet :x

------------
Amit Mittal


Sent from my Outlook for Android
https://aka.ms/ghei36

________________________________
From: Marc Schwartz <marc_schwartz at me.com>
Sent: Wednesday, August 29, 2018 7:55:27 PM
To: prof.amit.mittal at gmail.com
Cc: R-help
Subject: Re: [R] Bitbucket code


> On Aug 29, 2018, at 7:18 AM, prof.amit.mittal at gmail.com wrote:
>
> I installed a local zip file a few days ago and the package was recently
> modified on bitbucket , with a stable zip version not yet available.
>
> How many days does it usually take to get a stable zip version. How can I
> `devtools` it from the bitbucket the fastest way? I have my own sourcetree
> and the author has created in cloud.
>
>
> BR
>
> Amit
>


Hi,

No need to post twice.

I don't use Bitbucket, but it looks like the devtools package has a install_bitbucket() function, so perhaps that will do what you want.

In terms of making a stable archive file available, that will be entirely up to the package maintainer and when/how they choose to make that available (e.g. via CRAN or other vehicles).

Regards,

Marc Schwartz



	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Thu Aug 30 00:06:13 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Wed, 29 Aug 2018 18:06:13 -0400
Subject: [R] TCGA biolinks, DNA methylation
Message-ID: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>

Good evening R users,

  I am attempting to carry out DNA methylation analysis on two separate CSV
files (LGG and GBM), which I have downloaded onto my R console. To set the
path<-"." to be indicative of one or both of the csv files, I utilized the
following functions and received the errors shown. How do I set the "." so
that I can begin analysis on my files?

> the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
Error: unexpected string constant in "the_data
<-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
Error: unexpected string constant in
"the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""

This is the preliminary portion of the analysis I am trying to run, which I
am referring to:

1 library(TCGAbiolinks)
2
3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
4 path <? "."
5
6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
level = 3)
7 TCGAdownload(query.met, path = path )
8 met <? TCGAprepare(query = query.met,dir = path,
9                      add.subtype = TRUE, add.clinical = TRUE,
10                    summarizedExperiment = TRUE,
11                      save = TRUE, filename = "lgg_gbm_met.rda")
12
13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform = "IlluminaHiSeq_
RNASeqV2",level = 3)
15
16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
results")
17
18 exp <? TCGAprepare(query = query.exp, dir = path,
19                    summarizedExperiment = TRUE,
20                      add.subtype = TRUE, add.clinical = TRUE,
21                    type = "rsem.genes.normalized_results",
22                      save = T,filename = "lgg_gbm_exp.rda")

Many thanks,

Spencer Brackett

	[[alternative HTML version deleted]]



From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Aug 30 00:34:06 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 29 Aug 2018 18:34:06 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
Message-ID: <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>

Hi,

If you had an actual gene analysis question I'd suggest the
BioConductor email list, but you have a plain old ordinary typo:

 the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")

You're missing the = after the argument sep

 the_data <- read.csv(file = "LGG_clinical_drug.csv", header = TRUE, sep = ",")

Using more spaces in your code would make that typo easier to spot.

Sarah
On Wed, Aug 29, 2018 at 6:06 PM Spencer Brackett
<spbrackett20 at saintjosephhs.com> wrote:
>
> Good evening R users,
>
>   I am attempting to carry out DNA methylation analysis on two separate CSV
> files (LGG and GBM), which I have downloaded onto my R console. To set the
> path<-"." to be indicative of one or both of the csv files, I utilized the
> following functions and received the errors shown. How do I set the "." so
> that I can begin analysis on my files?
>
> > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
> Error: unexpected string constant in "the_data
> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
> Error: unexpected string constant in
> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>
> This is the preliminary portion of the analysis I am trying to run, which I
> am referring to:
>
> 1 library(TCGAbiolinks)
> 2
> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> 4 path <? "."
> 5
> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
> level = 3)
> 7 TCGAdownload(query.met, path = path )
> 8 met <? TCGAprepare(query = query.met,dir = path,
> 9                      add.subtype = TRUE, add.clinical = TRUE,
> 10                    summarizedExperiment = TRUE,
> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> 12
> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform = "IlluminaHiSeq_
> RNASeqV2",level = 3)
> 15
> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> results")
> 17
> 18 exp <? TCGAprepare(query = query.exp, dir = path,
> 19                    summarizedExperiment = TRUE,
> 20                      add.subtype = TRUE, add.clinical = TRUE,
> 21                    type = "rsem.genes.normalized_results",
> 22                      save = T,filename = "lgg_gbm_exp.rda")
>
> Many thanks,
>
> Spencer Brackett
>
-- 
Sarah Goslee
http://www.functionaldiversity.org



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Thu Aug 30 00:58:34 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Wed, 29 Aug 2018 18:58:34 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
Message-ID: <CAPQaxLPdeGESo-2AYmpxab88xFsFkRYJCzeNWyyrP86dFDKL0w@mail.gmail.com>

  Thank you! The line however was still found to be errored after I fixed
the mistake. Is there anything else I can do to maybe set the ?.? As an
object?

Spencer

On Wed, Aug 29, 2018 at 6:34 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> If you had an actual gene analysis question I'd suggest the
> BioConductor email list, but you have a plain old ordinary typo:
>
>  the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>
> You're missing the = after the argument sep
>
>  the_data <- read.csv(file = "LGG_clinical_drug.csv", header = TRUE, sep =
> ",")
>
> Using more spaces in your code would make that typo easier to spot.
>
> Sarah
> On Wed, Aug 29, 2018 at 6:06 PM Spencer Brackett
> <spbrackett20 at saintjosephhs.com> wrote:
> >
> > Good evening R users,
> >
> >   I am attempting to carry out DNA methylation analysis on two separate
> CSV
> > files (LGG and GBM), which I have downloaded onto my R console. To set
> the
> > path<-"." to be indicative of one or both of the csv files, I utilized
> the
> > following functions and received the errors shown. How do I set the "."
> so
> > that I can begin analysis on my files?
> >
> > > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
> > Error: unexpected string constant in "the_data
> > <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> > > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
> > Error: unexpected string constant in
> > "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
> >
> > This is the preliminary portion of the analysis I am trying to run,
> which I
> > am referring to:
> >
> > 1 library(TCGAbiolinks)
> > 2
> > 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> > 4 path <? "."
> > 5
> > 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
> > level = 3)
> > 7 TCGAdownload(query.met, path = path )
> > 8 met <? TCGAprepare(query = query.met,dir = path,
> > 9                      add.subtype = TRUE, add.clinical = TRUE,
> > 10                    summarizedExperiment = TRUE,
> > 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> > 12
> > 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
> > 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> "IlluminaHiSeq_
> > RNASeqV2",level = 3)
> > 15
> > 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> > results")
> > 17
> > 18 exp <? TCGAprepare(query = query.exp, dir = path,
> > 19                    summarizedExperiment = TRUE,
> > 20                      add.subtype = TRUE, add.clinical = TRUE,
> > 21                    type = "rsem.genes.normalized_results",
> > 22                      save = T,filename = "lgg_gbm_exp.rda")
> >
> > Many thanks,
> >
> > Spencer Brackett
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug 30 01:06:39 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 29 Aug 2018 16:06:39 -0700
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
Message-ID: <CAGxFJbQaNYF_9Le18q2AksWcW3jHKiHRkxCEnsUXHeeBG5PP3w@mail.gmail.com>

As an aside, the sep = "," can be omitted, as that's the default anyway.

In his response to Sarah, the OP gave us only "the line was found to be
errored," which of course is useless. Perhaps if he provided explicit
information on what the call and the error was...

-- Bert



On Wed, Aug 29, 2018 at 3:34 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> If you had an actual gene analysis question I'd suggest the
> BioConductor email list, but you have a plain old ordinary typo:
>
>  the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>
> You're missing the = after the argument sep
>
>  the_data <- read.csv(file = "LGG_clinical_drug.csv", header = TRUE, sep =
> ",")
>
> Using more spaces in your code would make that typo easier to spot.
>
> Sarah
> On Wed, Aug 29, 2018 at 6:06 PM Spencer Brackett
> <spbrackett20 at saintjosephhs.com> wrote:
> >
> > Good evening R users,
> >
> >   I am attempting to carry out DNA methylation analysis on two separate
> CSV
> > files (LGG and GBM), which I have downloaded onto my R console. To set
> the
> > path<-"." to be indicative of one or both of the csv files, I utilized
> the
> > following functions and received the errors shown. How do I set the "."
> so
> > that I can begin analysis on my files?
> >
> > > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
> > Error: unexpected string constant in "the_data
> > <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> > > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
> > Error: unexpected string constant in
> > "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
> >
> > This is the preliminary portion of the analysis I am trying to run,
> which I
> > am referring to:
> >
> > 1 library(TCGAbiolinks)
> > 2
> > 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
> > 4 path <? "."
> > 5
> > 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
> > level = 3)
> > 7 TCGAdownload(query.met, path = path )
> > 8 met <? TCGAprepare(query = query.met,dir = path,
> > 9                      add.subtype = TRUE, add.clinical = TRUE,
> > 10                    summarizedExperiment = TRUE,
> > 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> > 12
> > 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
> > 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> "IlluminaHiSeq_
> > RNASeqV2",level = 3)
> > 15
> > 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> > results")
> > 17
> > 18 exp <? TCGAprepare(query = query.exp, dir = path,
> > 19                    summarizedExperiment = TRUE,
> > 20                      add.subtype = TRUE, add.clinical = TRUE,
> > 21                    type = "rsem.genes.normalized_results",
> > 22                      save = T,filename = "lgg_gbm_exp.rda")
> >
> > Many thanks,
> >
> > Spencer Brackett
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Aug 30 01:07:19 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 29 Aug 2018 19:07:19 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLPdeGESo-2AYmpxab88xFsFkRYJCzeNWyyrP86dFDKL0w@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAM_vjukdbH3f1ZyTwgjx_JbvNArQKUf_JmuWFYNBfFtTuZ6BPA@mail.gmail.com>
 <CAPQaxLPdeGESo-2AYmpxab88xFsFkRYJCzeNWyyrP86dFDKL0w@mail.gmail.com>
Message-ID: <CAM_vju=nSdoC5gEPuA8yOTTDhXfq5js5bWZr_OXFT03Z_xK6BQ@mail.gmail.com>

On Wed, Aug 29, 2018 at 6:58 PM Spencer Brackett
<spbrackett20 at saintjosephhs.com> wrote:
>
>   Thank you! The line however was still found to be errored after I fixed the mistake. Is there anything else I can do to maybe set the ?.? As an object?

But presumably with a different error, which you don't tell us.

The "." doesn't appear anywhere in the read.csv() command that you
initially reported an error in.
All a path of "." means is "look in the current directory." So later
in your download commands, files should be saved to the current
working directory. But that doesn't have anything to do with your
current csv file.

What does

getwd()

tell you? If it is NOT the same directory that contains
LGG_clinical_drug.csv then you need to tell read.csv() where to look
for it.

the_data <- read.csv(file = "path/to/file/LGG_clinical_drug.csv",
header = TRUE, sep = ",")

with whatever the actual path is.

If that's NOT the problem, or it still doesn't work, you'll need to
tell us more information. Like what the error message is, what getwd()
returns, and where the file actually is on your system.

The read.csv() commands don't seem to have anything at all to do with
the remaining part of the sample analysis you're trying to run


> Spencer
>
> On Wed, Aug 29, 2018 at 6:34 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> If you had an actual gene analysis question I'd suggest the
>> BioConductor email list, but you have a plain old ordinary typo:
>>
>>  the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>>
>> You're missing the = after the argument sep
>>
>>  the_data <- read.csv(file = "LGG_clinical_drug.csv", header = TRUE, sep = ",")
>>
>> Using more spaces in your code would make that typo easier to spot.
>>
>> Sarah
>> On Wed, Aug 29, 2018 at 6:06 PM Spencer Brackett
>> <spbrackett20 at saintjosephhs.com> wrote:
>> >
>> > Good evening R users,
>> >
>> >   I am attempting to carry out DNA methylation analysis on two separate CSV
>> > files (LGG and GBM), which I have downloaded onto my R console. To set the
>> > path<-"." to be indicative of one or both of the csv files, I utilized the
>> > following functions and received the errors shown. How do I set the "." so
>> > that I can begin analysis on my files?
>> >
>> > > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>> > Error: unexpected string constant in "the_data
>> > <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>> > > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>> > Error: unexpected string constant in
>> > "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>> >
>> > This is the preliminary portion of the analysis I am trying to run, which I
>> > am referring to:
>> >
>> > 1 library(TCGAbiolinks)
>> > 2
>> > 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> > 4 path <? "."
>> > 5
>> > 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> > level = 3)
>> > 7 TCGAdownload(query.met, path = path )
>> > 8 met <? TCGAprepare(query = query.met,dir = path,
>> > 9                      add.subtype = TRUE, add.clinical = TRUE,
>> > 10                    summarizedExperiment = TRUE,
>> > 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> > 12
>> > 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> > 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform = "IlluminaHiSeq_
>> > RNASeqV2",level = 3)
>> > 15
>> > 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> > results")
>> > 17
>> > 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> > 19                    summarizedExperiment = TRUE,
>> > 20                      add.subtype = TRUE, add.clinical = TRUE,
>> > 21                    type = "rsem.genes.normalized_results",
>> > 22                      save = T,filename = "lgg_gbm_exp.rda")
>> >
>> > Many thanks,
>> >
>> > Spencer Brackett
>> >
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org



From pd@|gd @end|ng |rom gm@||@com  Thu Aug 30 10:48:10 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 30 Aug 2018 10:48:10 +0200
Subject: [R] Estimate parameters differential equations system
In-Reply-To: <CANSOPkWhUaPMi-JM38qxwCtPVndjzZT8AyPbf+LBkJJy-zqB6Q@mail.gmail.com>
References: <CANSOPkWhUaPMi-JM38qxwCtPVndjzZT8AyPbf+LBkJJy-zqB6Q@mail.gmail.com>
Message-ID: <39D9F9FA-6506-4AB1-B098-738FBDF2F1D6@gmail.com>

If you can solve the system and the parameters are identifiable from the y component, then I would think that nls() can do it. However, beware unidentifiablity: If x stays constant at its equilibrium value of (er...) d1*c/(m+d1), then even knowing x won't allow you to tease out c, d1, and m; and not knowing x you can't separate m from x in the mx term in dy/dt. So it likely depends on the exact experiment, especially the initial conditions of the system whether you can estimate things or not.

-pd

> On 29 Aug 2018, at 15:19 , Fanny Gallais <gallais.fanny at gmail.com> wrote:
> 
> Dear R users,
> 
> 
> 
> I am working on a simple mathematical model made of two ordinary
> differential equations:
> 
> 
> 
> dx/dt=-mx-d1(x-c)
> 
> dy/dt=mx-d2y
> 
> 
> 
> I would like to fit this model to my data and estimate the corresponding
> parameters. The thing is I only have observed data for y, x is unknown. Is
> it possible to do this in R?
> 
> 
> 
> Thank you for your help
> 
> Fanny
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From B|||@Po||ng @end|ng |rom ze||@@com  Thu Aug 30 14:41:37 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 30 Aug 2018 12:41:37 +0000
Subject: [R] Obtaining Complete Dataset with Imputed Values
In-Reply-To: <CAMOcQfOFkwSUVhXGCy7-R-3YGLC0swMY-1TjBLTQTR_jpJsgRQ@mail.gmail.com>
References: <CAMOcQfOFkwSUVhXGCy7-R-3YGLC0swMY-1TjBLTQTR_jpJsgRQ@mail.gmail.com>
Message-ID: <BN7PR02MB5073FD3BECD27322684988B7EA080@BN7PR02MB5073.namprd02.prod.outlook.com>

Good morning Paul.

I am unfamiliar with the package you are using but I have been working through the tutorial for this purpose using finalfit, if that is any help.

Cheers

WHP

http://www.datasurg.net/2018/08/29/five-steps-for-missing-data-with-finalfit/


From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
Sent: Friday, August 24, 2018 2:57 PM
To: r-help at r-project.org
Subject: [R] Obtaining Complete Dataset with Imputed Values

Dear friends, hope all is well with you,

I am working with package mi for data inputation. Currently working with R
version 3.5.0 (64-bit).

Say my data is defined as dat, and I do the following:

datimputations <- mi(dat[2:5], n.iter=50)
completedat <- complete(datimputations)

After using the complete function, I get the following error message:

Error in complete(datimputations, m = 1) : 'data' not of class 'mids'

How can I retrieve the processed dataframe (along with the imputed values)?

Here is my dput() for you to see

> dput(head(dat,100))
structure(list(TransitDate = structure(c(496990800, 499669200,
502261200, 504939600, 507618000, 510037200, 512715600, 515307600,
517986000, 520578000, 523256400, 525934800, 528526800, 531205200,
533797200, 536475600, 539154000, 541573200, 544251600, 546843600,
549522000, 552114000, 554792400, 557470800, 560062800, 562741200,
565333200, 568011600, 570690000, 573195600, 575874000, 578466000,
581144400, 583736400, 586414800, 589093200, 591685200, 594363600,
596955600, 599634000, 602312400, 604731600, 607410000, 610002000,
612680400, 615272400, 617950800, 620629200, 623221200, 625899600,
628491600, 631170000, 633848400, 636267600, 638946000, 641538000,
644216400, 646808400, 649486800, 652165200, 654757200, 657435600,
660027600, 662706000, 665384400, 667803600, 670482000, 673074000,
675752400, 678344400, 681022800, 683701200, 686293200, 688971600,
691563600, 694242000, 696920400, 699426000, 702104400, 704696400,
707371200, 709963200, 712641600, 715320000, 717912000, 720590400,
723182400, 725860800, 728539200, 730958400, 733636800, 736232400,
738910800, 741502800, 744181200, 746859600, 749451600, 752130000,
754722000, 757400400), class = c("POSIXct", "POSIXt"), tzone = ""),
Transits = c(14L, 14L, 13L, 10L, 11L, 14L, 14L, 14L, 16L,
6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L, 8L, 10L,
9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L,
7L, 7L, 8L, 4L, 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L,
5L, 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L, 5L, 6L, 7L, 6L,
9L, 8L, 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L,
14L, 15L, 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L,
9L, 12L, 8L, 12L, 10L, 11L, 10L, 9L, 10L), CargoTons = c(154973L,
129636L, 136884L, 86348L, 109907L, 154506L, 144083L, 152794L,
124861L, 60330L, 65221L, 61718L, 53997L, 83536L, 63218L,
98222L, 54719L, 98470L, 18263L, 104255L, 62869L, 62523L,
75344L, 81476L, 92818L, 87457L, 85231L, 77897L, 57699L, 96989L,
109361L, 59799L, 91116L, 82241L, 74251L, 124361L, 68751L,
61719L, 68017L, 37760L, 32513L, 56359L, 51333L, 80859L, 75852L,
65760L, 96043L, 38820L, 63202L, 102647L, 49104L, 53482L,
121305L, 71795L, 76704L, 146097L, 73047L, 68557L, 110642L,
77616L, 97767L, 52059L, 58658L, 66350L, 69303L, 76013L, 91909L,
108445L, 94454L, 101249L, 112131L, 56290L, 118342L, 70618L,
64783L, 112839L, 120506L, 94243L, 130768L, 133643L, 146321L,
140736L, 147234L, 158953L, 189888L, 93819L, 130021L, 130124L,
55088L, 114783L, 95184L, 82205L, 80321L, 65422L, 98933L,
93713L, 98417L, 97210L, 88464L, 94659L), RcnstPCUMS = c(229914L,
214547L, 215890L, 158695L, 173125L, 222533L, 212490L, 222125L,
266913L, 94268L, 112967L, 95480L, 87654L, 108996L, 97973L,
139247L, 93817L, 133197L, 40020L, 169749L, 102590L, 112121L,
140241L, 122989L, 144592L, 144979L, 123748L, 123249L, 70081L,
155218L, 168096L, 104743L, 163384L, 142648L, 129188L, 183170L,
99299L, 99873L, 111648L, 55890L, 59183L, 95568L, 72550L,
104562L, 100478L, 92665L, 130625L, 54786L, 105900L, 135833L,
70932L, 73247L, 149632L, 94317L, 87926L, 181989L, 92778L,
107097L, 153246L, 105175L, 126393L, 81976L, 95518L, 109019L,
95370L, 140492L, 125795L, 157978L, 138424L, 138160L, 180320L,
78757L, 135860L, 85921L, 114847L, 151965L, 152561L, 132841L,
204839L, 209567L, 224436L, 210209L, 227143L, 245968L, 264969L,
158648L, 222251L, 194335L, 111618L, 189643L, 137438L, 124953L,
163155L, 107633L, 164525L, 135102L, 152072L, 126636L, 121008L,
137824L), TotalToll = c(420742L, 392621L, 395078L, 290411L,
316818L, 407235L, 388856L, 406488L, 482774L, 172510L, 206729L,
174728L, 160406L, 199462L, 179290L, 254822L, 171685L, 243750L,
73236L, 310640L, 187739L, 205181L, 249438L, 225069L, 264603L,
265311L, 226458L, 225545L, 128248L, 284048L, 296023L, 184934L,
298992L, 261045L, 236414L, 335201L, 181717L, 182767L, 204315L,
102278L, 108304L, 174889L, 132766L, 191348L, 183874L, 169576L,
239043L, 100258L, 212859L, 273024L, 142573L, 147226L, 300760L,
189577L, 176731L, 365797L, 186483L, 215264L, 308024L, 211401L,
254049L, 164771L, 191991L, 219128L, 191693L, 282388L, 252847L,
317535L, 278232L, 277701L, 356022L, 158301L, 273078L, 172701L,
230842L, 305449L, 306647L, 267010L, 406202L, 421229L, 451116L,
422520L, 456557L, 494395L, 582202L, 350612L, 491174L, 429480L,
239858L, 419111L, 303737L, 276146L, 360572L, 237868L, 358627L,
298575L, 336079L, 279865L, 267427L, 304591L)), row.names = c(NA,
100L), class = "data.frame")

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From j|ox @end|ng |rom mcm@@ter@c@  Thu Aug 30 16:18:30 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 30 Aug 2018 14:18:30 +0000
Subject: [R] Obtaining Complete Dataset with Imputed Values
In-Reply-To: <24780_1535632920_w7UCfxIP009372_BN7PR02MB5073FD3BECD27322684988B7EA080@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <CAMOcQfOFkwSUVhXGCy7-R-3YGLC0swMY-1TjBLTQTR_jpJsgRQ@mail.gmail.com>
 <24780_1535632920_w7UCfxIP009372_BN7PR02MB5073FD3BECD27322684988B7EA080@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A550E@FHSDB2D11-2.csu.mcmaster.ca>

Dear Paul and WHP,

My guess: Paul apparently has loaded the mice package after the mi package. Both packages have complete() functions, but for objects of different classes -- "mids" in the case of mice. Consquently, complete() in the mice package is shadowing complete() in the mi package.

The solution is not to load both packages unless you actually need to, load mi after mice (though then other similar problems might surface), or invoke mi::complete()  explicitly.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bill Poling
> Sent: Thursday, August 30, 2018 8:42 AM
> To: Paul Bernal <paulbernal07 at gmail.com>; r-help at r-project.org
> Subject: Re: [R] Obtaining Complete Dataset with Imputed Values
> 
> Good morning Paul.
> 
> I am unfamiliar with the package you are using but I have been working
> through the tutorial for this purpose using finalfit, if that is any help.
> 
> Cheers
> 
> WHP
> 
> http://www.datasurg.net/2018/08/29/five-steps-for-missing-data-with-
> finalfit/
> 
> 
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
> Sent: Friday, August 24, 2018 2:57 PM
> To: r-help at r-project.org
> Subject: [R] Obtaining Complete Dataset with Imputed Values
> 
> Dear friends, hope all is well with you,
> 
> I am working with package mi for data inputation. Currently working with R
> version 3.5.0 (64-bit).
> 
> Say my data is defined as dat, and I do the following:
> 
> datimputations <- mi(dat[2:5], n.iter=50) completedat <-
> complete(datimputations)
> 
> After using the complete function, I get the following error message:
> 
> Error in complete(datimputations, m = 1) : 'data' not of class 'mids'
> 
> How can I retrieve the processed dataframe (along with the imputed values)?
> 
> Here is my dput() for you to see
> 
> > dput(head(dat,100))
> structure(list(TransitDate = structure(c(496990800, 499669200, 502261200,
> 504939600, 507618000, 510037200, 512715600, 515307600, 517986000,
> 520578000, 523256400, 525934800, 528526800, 531205200, 533797200,
> 536475600, 539154000, 541573200, 544251600, 546843600, 549522000,
> 552114000, 554792400, 557470800, 560062800, 562741200, 565333200,
> 568011600, 570690000, 573195600, 575874000, 578466000, 581144400,
> 583736400, 586414800, 589093200, 591685200, 594363600, 596955600,
> 599634000, 602312400, 604731600, 607410000, 610002000, 612680400,
> 615272400, 617950800, 620629200, 623221200, 625899600, 628491600,
> 631170000, 633848400, 636267600, 638946000, 641538000, 644216400,
> 646808400, 649486800, 652165200, 654757200, 657435600, 660027600,
> 662706000, 665384400, 667803600, 670482000, 673074000, 675752400,
> 678344400, 681022800, 683701200, 686293200, 688971600, 691563600,
> 694242000, 696920400, 699426000, 702104400, 704696400, 707371200,
> 709963200, 712641600, 715320000, 717912000, 720590400, 723182400,
> 725860800, 728539200, 730958400, 733636800, 736232400, 738910800,
> 741502800, 744181200, 746859600, 749451600, 752130000, 754722000,
> 757400400), class = c("POSIXct", "POSIXt"), tzone = ""), Transits = c(14L, 14L,
> 13L, 10L, 11L, 14L, 14L, 14L, 16L, 6L, 8L, 6L, 6L, 7L, 7L, 9L, 7L, 9L, 3L, 12L, 7L,
> 8L, 10L, 9L, 10L, 11L, 9L, 9L, 5L, 11L, 12L, 7L, 12L, 10L, 9L, 13L, 7L, 7L, 8L, 4L,
> 4L, 7L, 5L, 7L, 7L, 6L, 9L, 4L, 7L, 9L, 5L, 5L, 10L, 6L, 6L, 13L, 6L, 7L, 10L, 7L, 8L,
> 5L, 6L, 7L, 6L, 9L, 8L, 10L, 9L, 9L, 12L, 5L, 9L, 6L, 7L, 10L, 10L, 9L, 14L, 14L, 15L,
> 14L, 16L, 17L, 18L, 11L, 15L, 14L, 8L, 13L, 10L, 9L, 12L, 8L, 12L, 10L, 11L, 10L,
> 9L, 10L), CargoTons = c(154973L, 129636L, 136884L, 86348L, 109907L,
> 154506L, 144083L, 152794L, 124861L, 60330L, 65221L, 61718L, 53997L,
> 83536L, 63218L, 98222L, 54719L, 98470L, 18263L, 104255L, 62869L, 62523L,
> 75344L, 81476L, 92818L, 87457L, 85231L, 77897L, 57699L, 96989L, 109361L,
> 59799L, 91116L, 82241L, 74251L, 124361L, 68751L, 61719L, 68017L, 37760L,
> 32513L, 56359L, 51333L, 80859L, 75852L, 65760L, 96043L, 38820L, 63202L,
> 102647L, 49104L, 53482L, 121305L, 71795L, 76704L, 146097L, 73047L,
> 68557L, 110642L, 77616L, 97767L, 52059L, 58658L, 66350L, 69303L, 76013L,
> 91909L, 108445L, 94454L, 101249L, 112131L, 56290L, 118342L, 70618L,
> 64783L, 112839L, 120506L, 94243L, 130768L, 133643L, 146321L, 140736L,
> 147234L, 158953L, 189888L, 93819L, 130021L, 130124L, 55088L, 114783L,
> 95184L, 82205L, 80321L, 65422L, 98933L, 93713L, 98417L, 97210L, 88464L,
> 94659L), RcnstPCUMS = c(229914L, 214547L, 215890L, 158695L, 173125L,
> 222533L, 212490L, 222125L, 266913L, 94268L, 112967L, 95480L, 87654L,
> 108996L, 97973L, 139247L, 93817L, 133197L, 40020L, 169749L, 102590L,
> 112121L, 140241L, 122989L, 144592L, 144979L, 123748L, 123249L, 70081L,
> 155218L, 168096L, 104743L, 163384L, 142648L, 129188L, 183170L, 99299L,
> 99873L, 111648L, 55890L, 59183L, 95568L, 72550L, 104562L, 100478L,
> 92665L, 130625L, 54786L, 105900L, 135833L, 70932L, 73247L, 149632L,
> 94317L, 87926L, 181989L, 92778L, 107097L, 153246L, 105175L, 126393L,
> 81976L, 95518L, 109019L, 95370L, 140492L, 125795L, 157978L, 138424L,
> 138160L, 180320L, 78757L, 135860L, 85921L, 114847L, 151965L, 152561L,
> 132841L, 204839L, 209567L, 224436L, 210209L, 227143L, 245968L, 264969L,
> 158648L, 222251L, 194335L, 111618L, 189643L, 137438L, 124953L, 163155L,
> 107633L, 164525L, 135102L, 152072L, 126636L, 121008L, 137824L), TotalToll
> = c(420742L, 392621L, 395078L, 290411L, 316818L, 407235L, 388856L,
> 406488L, 482774L, 172510L, 206729L, 174728L, 160406L, 199462L, 179290L,
> 254822L, 171685L, 243750L, 73236L, 310640L, 187739L, 205181L, 249438L,
> 225069L, 264603L, 265311L, 226458L, 225545L, 128248L, 284048L, 296023L,
> 184934L, 298992L, 261045L, 236414L, 335201L, 181717L, 182767L, 204315L,
> 102278L, 108304L, 174889L, 132766L, 191348L, 183874L, 169576L, 239043L,
> 100258L, 212859L, 273024L, 142573L, 147226L, 300760L, 189577L, 176731L,
> 365797L, 186483L, 215264L, 308024L, 211401L, 254049L, 164771L, 191991L,
> 219128L, 191693L, 282388L, 252847L, 317535L, 278232L, 277701L, 356022L,
> 158301L, 273078L, 172701L, 230842L, 305449L, 306647L, 267010L, 406202L,
> 421229L, 451116L, 422520L, 456557L, 494395L, 582202L, 350612L, 491174L,
> 429480L, 239858L, 419111L, 303737L, 276146L, 360572L, 237868L, 358627L,
> 298575L, 336079L, 279865L, 267427L, 304591L)), row.names = c(NA, 100L),
> class = "data.frame")
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-
> help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From orch|dn @end|ng |rom ||ve@com  Thu Aug 30 18:46:40 2018
From: orch|dn @end|ng |rom ||ve@com (dani)
Date: Thu, 30 Aug 2018 16:46:40 +0000
Subject: [R] standardized regression coefficients in GAM
Message-ID: <BYAPR06MB38320BDE72A62F65A4D9E5B5D6080@BYAPR06MB3832.namprd06.prod.outlook.com>

Hello everyone,


I was wondering if anyone can help me calculate standardized regression coefficients from a GAM model.

I have some dummy and some continuous covariates in my GAM model. I know I could standardize only the continuous covariates and re-run the model to get the standardized coefficients. Can anyone help with some R code to create the standardized coefficients after obtaining a GAM model based on unstandardized coefficients?


Also, on a separate note, what do I do with the dummy covariates - should I just include them as they are in the model with standardized variables? I do not see how I can standardize dummy variables.


Thank you!

Best,

Dani

<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]



From j|ox @end|ng |rom mcm@@ter@c@  Thu Aug 30 20:37:17 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 30 Aug 2018 18:37:17 +0000
Subject: [R] standardized regression coefficients in GAM
In-Reply-To: <2250_1535647791_w7UGnopD005648_BYAPR06MB38320BDE72A62F65A4D9E5B5D6080@BYAPR06MB3832.namprd06.prod.outlook.com>
References: <2250_1535647791_w7UGnopD005648_BYAPR06MB38320BDE72A62F65A4D9E5B5D6080@BYAPR06MB3832.namprd06.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8368A5784@FHSDB2D11-2.csu.mcmaster.ca>

Dear Dani,

I'll address your questions briefly below. They aren't unique to GAMs.

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of dani
> Sent: Thursday, August 30, 2018 12:47 PM
> To: r-help at r-project.org
> Subject: [R] standardized regression coefficients in GAM
> 
> Hello everyone,
> 
> 
> I was wondering if anyone can help me calculate standardized regression
> coefficients from a GAM model.
> 
> I have some dummy and some continuous covariates in my GAM model. I
> know I could standardize only the continuous covariates and re-run the model
> to get the standardized coefficients. Can anyone help with some R code to
> create the standardized coefficients after obtaining a GAM model based on
> unstandardized coefficients?

Why one would want to do this isn't clear to me, but you can just multiply each such coefficient by the standard deviation of the corresponding X and divide by the standard deviation of Y.

> 
> 
> Also, on a separate note, what do I do with the dummy covariates - should I
> just include them as they are in the model with standardized variables? I do
> not see how I can standardize dummy variables.

Standardizing dummy regressors is nonsense, so don't do it. If there are interaction regressors in your model, don't standardize those either.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> 
> 
> Thank you!
> 
> Best,
> 
> Dani
> 
> <http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



From orch|dn @end|ng |rom ||ve@com  Thu Aug 30 20:43:28 2018
From: orch|dn @end|ng |rom ||ve@com (dani)
Date: Thu, 30 Aug 2018 18:43:28 +0000
Subject: [R] standardized regression coefficients in GAM
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8368A5784@FHSDB2D11-2.csu.mcmaster.ca>
References: <2250_1535647791_w7UGnopD005648_BYAPR06MB38320BDE72A62F65A4D9E5B5D6080@BYAPR06MB3832.namprd06.prod.outlook.com>,
 <ACD1644AA6C67E4FBD0C350625508EC8368A5784@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <BYAPR06MB3832B6A24706E379A8E5D241D6080@BYAPR06MB3832.namprd06.prod.outlook.com>

Dear Dr Fox,


Thank you so much for your response! I will report the results of the regression models only based on unstandardized coefficients then, it seems to be best.


Thanks for taking the time to respond and clarify this issue for me!

Best regards,

Dani


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: Fox, John <jfox at mcmaster.ca>
Sent: Thursday, August 30, 2018 11:37 AM
To: dani
Cc: r-help at r-project.org
Subject: RE: standardized regression coefficients in GAM

Dear Dani,

I'll address your questions briefly below. They aren't unique to GAMs.

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of dani
> Sent: Thursday, August 30, 2018 12:47 PM
> To: r-help at r-project.org
> Subject: [R] standardized regression coefficients in GAM
>
> Hello everyone,
>
>
> I was wondering if anyone can help me calculate standardized regression
> coefficients from a GAM model.
>
> I have some dummy and some continuous covariates in my GAM model. I
> know I could standardize only the continuous covariates and re-run the model
> to get the standardized coefficients. Can anyone help with some R code to
> create the standardized coefficients after obtaining a GAM model based on
> unstandardized coefficients?

Why one would want to do this isn't clear to me, but you can just multiply each such coefficient by the standard deviation of the corresponding X and divide by the standard deviation of Y.

>
>
> Also, on a separate note, what do I do with the dummy covariates - should I
> just include them as they are in the model with standardized variables? I do
> not see how I can standardize dummy variables.

Standardizing dummy regressors is nonsense, so don't do it. If there are interaction regressors in your model, don't standardize those either.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



>
>
> Thank you!
>
> Best,
>
> Dani
>
> <http://aka.ms/weboutlook>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From k@be||me|@ne @end|ng |rom y@hoo@co@uk  Thu Aug 30 23:39:48 2018
From: k@be||me|@ne @end|ng |rom y@hoo@co@uk (KABELI MEFANE)
Date: Thu, 30 Aug 2018 21:39:48 +0000 (UTC)
Subject: [R] R code for parameter estimates
References: <966262583.1956370.1535665188559.ref@mail.yahoo.com>
Message-ID: <966262583.1956370.1535665188559@mail.yahoo.com>

Hello R -helpers


Can you please be kind enough to help me the R code for GEV parameter estimates using Bayes, I have done them using MLE and it would really be nice to compare. I am trying to model rainfall data, i have used sevaral distributions such as lognormal, Burr, Pearson, GEV but the three parameter lognormal and log Pearson were a hustle due to the shift parameter. NowI want to use Bayes.

Best Regards
Kabeli Mefane

?Tell me and I'll forget; show me and I may remember; involve me and I'll understand.?

	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Fri Aug 31 02:53:38 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Thu, 30 Aug 2018 20:53:38 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
Message-ID: <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>

Hello again,

My apologies for the delayed response... computer troubles. In reference to
Ms. Goslee's and Mr. Barry's query, the following is the error code
received after I inputted my R command

 the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
Error: unexpected string constant in
"the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""

Given this, should I proceed with implementing the path<getwd() ,since I
am, as he suggested trying to set the variable *path* to my working
directory with path<-"."

Mr. Mittal also recommended importing with r studio, which I shall try in
the meantime.

Many thanks,

Spencer Brackett


On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <prof.amit.mittal at gmail.com>
wrote:

> Use r studio and import from the menu. Read_csv has changed
>
> Also you can see any format problems
>
> On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Good evening R users,
>>
>>   I am attempting to carry out DNA methylation analysis on two separate
>> CSV
>> files (LGG and GBM), which I have downloaded onto my R console. To set the
>> path<-"." to be indicative of one or both of the csv files, I utilized the
>> following functions and received the errors shown. How do I set the "." so
>> that I can begin analysis on my files?
>>
>> > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>> Error: unexpected string constant in "the_data
>> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>> Error: unexpected string constant in
>> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>>
>> This is the preliminary portion of the analysis I am trying to run, which
>> I
>> am referring to:
>>
>> 1 library(TCGAbiolinks)
>> 2
>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> 4 path <? "."
>> 5
>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> level = 3)
>> 7 TCGAdownload(query.met, path = path )
>> 8 met <? TCGAprepare(query = query.met,dir = path,
>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>> 10                    summarizedExperiment = TRUE,
>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> 12
>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>> "IlluminaHiSeq_
>> RNASeqV2",level = 3)
>> 15
>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> results")
>> 17
>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> 19                    summarizedExperiment = TRUE,
>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>> 21                    type = "rsem.genes.normalized_results",
>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>
>> Many thanks,
>>
>> Spencer Brackett
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Fri Aug 31 03:05:17 2018
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Thu, 30 Aug 2018 21:05:17 -0400
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
 <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>
 <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
Message-ID: <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>

My apologies... the following is what I received from the correction

 the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep=",")
Warning messages:
1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
  line 3 appears to contain embedded nulls
2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
  line 4 appears to contain embedded nulls
3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
  line 5 appears to contain embedded nulls
4: In scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :
  embedded nul(s) found in input
>


On Thu, Aug 30, 2018 at 8:57 PM Patrick Barry <pdbarry at alaska.edu> wrote:

> You still haven't fixed the first thing both Sarah and I pointed out. You
> are lacking an = between sep and ","
>
> the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>
> should be
>
> the_data <- read.csv(file = "GBM_clinical_drug.csv", header = TRUE, *sep
> = ","*)
>
> as Sarah pointed out, you should use spaces to help make these errors more
> obvious.
>
> On Thu, Aug 30, 2018 at 4:53 PM, Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Hello again,
>>
>> My apologies for the delayed response... computer troubles. In reference
>> to
>> Ms. Goslee's and Mr. Barry's query, the following is the error code
>> received after I inputted my R command
>>
>>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>> Error: unexpected string constant in
>> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""
>>
>> Given this, should I proceed with implementing the path<getwd() ,since I
>> am, as he suggested trying to set the variable *path* to my working
>> directory with path<-"."
>>
>> Mr. Mittal also recommended importing with r studio, which I shall try in
>> the meantime.
>>
>> Many thanks,
>>
>> Spencer Brackett
>>
>>
>> On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <prof.amit.mittal at gmail.com>
>> wrote:
>>
>> > Use r studio and import from the menu. Read_csv has changed
>> >
>> > Also you can see any format problems
>> >
>> > On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
>> > spbrackett20 at saintjosephhs.com> wrote:
>> >
>> >> Good evening R users,
>> >>
>> >>   I am attempting to carry out DNA methylation analysis on two separate
>> >> CSV
>> >> files (LGG and GBM), which I have downloaded onto my R console. To set
>> the
>> >> path<-"." to be indicative of one or both of the csv files, I utilized
>> the
>> >> following functions and received the errors shown. How do I set the
>> "." so
>> >> that I can begin analysis on my files?
>> >>
>> >> > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>> >> Error: unexpected string constant in "the_data
>> >> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>> >> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>> >> Error: unexpected string constant in
>> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>> >>
>> >> This is the preliminary portion of the analysis I am trying to run,
>> which
>> >> I
>> >> am referring to:
>> >>
>> >> 1 library(TCGAbiolinks)
>> >> 2
>> >> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>> >> 4 path <? "."
>> >> 5
>> >> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>> >> level = 3)
>> >> 7 TCGAdownload(query.met, path = path )
>> >> 8 met <? TCGAprepare(query = query.met,dir = path,
>> >> 9                      add.subtype = TRUE, add.clinical = TRUE,
>> >> 10                    summarizedExperiment = TRUE,
>> >> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>> >> 12
>> >> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>> >> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>> >> "IlluminaHiSeq_
>> >> RNASeqV2",level = 3)
>> >> 15
>> >> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>> >> results")
>> >> 17
>> >> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>> >> 19                    summarizedExperiment = TRUE,
>> >> 20                      add.subtype = TRUE, add.clinical = TRUE,
>> >> 21                    type = "rsem.genes.normalized_results",
>> >> 22                      save = T,filename = "lgg_gbm_exp.rda")
>> >>
>> >> Many thanks,
>> >>
>> >> Spencer Brackett
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 31 04:20:40 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 30 Aug 2018 19:20:40 -0700
Subject: [R] R code for parameter estimates
In-Reply-To: <966262583.1956370.1535665188559@mail.yahoo.com>
References: <966262583.1956370.1535665188559.ref@mail.yahoo.com>
 <966262583.1956370.1535665188559@mail.yahoo.com>
Message-ID: <CAGxFJbR7w1RaAb5=4dZ47k2=BrVvFjadx5HATaw-WxETQsOmpg@mail.gmail.com>

As you have completely failed to follow procedures described in the posting
guide linked below, your post is unlikely to receive any response.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 30, 2018 at 3:08 PM KABELI MEFANE via R-help <
r-help at r-project.org> wrote:

> Hello R -helpers
>
>
> Can you please be kind enough to help me the R code for GEV parameter
> estimates using Bayes, I have done them using MLE and it would really be
> nice to compare. I am trying to model rainfall data, i have used sevaral
> distributions such as lognormal, Burr, Pearson, GEV but the three parameter
> lognormal and log Pearson were a hustle due to the shift parameter. NowI
> want to use Bayes.
>
> Best Regards
> Kabeli Mefane
>
> ?Tell me and I'll forget; show me and I may remember; involve me and I'll
> understand.?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Fri Aug 31 13:03:00 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 31 Aug 2018 13:03:00 +0200
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
 <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>
 <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
 <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
Message-ID: <34AA2079-B7A4-4DC1-8CFF-EE271C843DD0@gmail.com>

At this point, it seems pretty clear that the issue is in the data file itself. Possibilities are that it is either not a CSV file to begin with or in some exotic encoding (utf-16?). 

You probably need to look at the file in a text editor to see whether the context makes sense as comma-separated variables. 

Also, perhaps review the download mechanism --- recently I have found several students shooting themselves in the foot by downloading .csv files, having them automatically  opened by Excel and the save them _in_ Excel, garbling the file in the process.

-pd

> On 31 Aug 2018, at 03:05 , Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> My apologies... the following is what I received from the correction
> 
> the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep=",")
> Warning messages:
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>  line 3 appears to contain embedded nulls
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>  line 4 appears to contain embedded nulls
> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>  line 5 appears to contain embedded nulls
> 4: In scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :
>  embedded nul(s) found in input
>> 
> 
> 
> On Thu, Aug 30, 2018 at 8:57 PM Patrick Barry <pdbarry at alaska.edu> wrote:
> 
>> You still haven't fixed the first thing both Sarah and I pointed out. You
>> are lacking an = between sep and ","
>> 
>> the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>> 
>> should be
>> 
>> the_data <- read.csv(file = "GBM_clinical_drug.csv", header = TRUE, *sep
>> = ","*)
>> 
>> as Sarah pointed out, you should use spaces to help make these errors more
>> obvious.
>> 
>> On Thu, Aug 30, 2018 at 4:53 PM, Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>> 
>>> Hello again,
>>> 
>>> My apologies for the delayed response... computer troubles. In reference
>>> to
>>> Ms. Goslee's and Mr. Barry's query, the following is the error code
>>> received after I inputted my R command
>>> 
>>> the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
>>> Error: unexpected string constant in
>>> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""
>>> 
>>> Given this, should I proceed with implementing the path<getwd() ,since I
>>> am, as he suggested trying to set the variable *path* to my working
>>> directory with path<-"."
>>> 
>>> Mr. Mittal also recommended importing with r studio, which I shall try in
>>> the meantime.
>>> 
>>> Many thanks,
>>> 
>>> Spencer Brackett
>>> 
>>> 
>>> On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <prof.amit.mittal at gmail.com>
>>> wrote:
>>> 
>>>> Use r studio and import from the menu. Read_csv has changed
>>>> 
>>>> Also you can see any format problems
>>>> 
>>>> On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>> 
>>>>> Good evening R users,
>>>>> 
>>>>>  I am attempting to carry out DNA methylation analysis on two separate
>>>>> CSV
>>>>> files (LGG and GBM), which I have downloaded onto my R console. To set
>>> the
>>>>> path<-"." to be indicative of one or both of the csv files, I utilized
>>> the
>>>>> following functions and received the errors shown. How do I set the
>>> "." so
>>>>> that I can begin analysis on my files?
>>>>> 
>>>>>> the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
>>>>> Error: unexpected string constant in "the_data
>>>>> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
>>>>>> the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
>>>>> Error: unexpected string constant in
>>>>> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
>>>>> 
>>>>> This is the preliminary portion of the analysis I am trying to run,
>>> which
>>>>> I
>>>>> am referring to:
>>>>> 
>>>>> 1 library(TCGAbiolinks)
>>>>> 2
>>>>> 3 # Download the DNA methylation data: HumanMethylation450 LGG and GBM.
>>>>> 4 path <? "."
>>>>> 5
>>>>> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"HumanMethylation450",
>>>>> level = 3)
>>>>> 7 TCGAdownload(query.met, path = path )
>>>>> 8 met <? TCGAprepare(query = query.met,dir = path,
>>>>> 9                      add.subtype = TRUE, add.clinical = TRUE,
>>>>> 10                    summarizedExperiment = TRUE,
>>>>> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
>>>>> 12
>>>>> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and GBM.
>>>>> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
>>>>> "IlluminaHiSeq_
>>>>> RNASeqV2",level = 3)
>>>>> 15
>>>>> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
>>>>> results")
>>>>> 17
>>>>> 18 exp <? TCGAprepare(query = query.exp, dir = path,
>>>>> 19                    summarizedExperiment = TRUE,
>>>>> 20                      add.subtype = TRUE, add.clinical = TRUE,
>>>>> 21                    type = "rsem.genes.normalized_results",
>>>>> 22                      save = T,filename = "lgg_gbm_exp.rda")
>>>>> 
>>>>> Many thanks,
>>>>> 
>>>>> Spencer Brackett
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From n|cho|@@@wr@y @end|ng |rom nt|wor|d@com  Fri Aug 31 13:42:19 2018
From: n|cho|@@@wr@y @end|ng |rom nt|wor|d@com (Nick Wray)
Date: Fri, 31 Aug 2018 12:42:19 +0100 (BST)
Subject: [R] Main label on Cullen and Frey
Message-ID: <2040384799.899784.1535715740012@mail2.virginmedia.com>

Hello   Does anyone know how to modify the main label when you plot a Cullen & Frey (sounds like an Oxford gentleman's outfitters - statistically significant waistcoats a speciality) diagram from the "descdist" function?  I've tried setting a variable to the descdist(data) but it just returns the summary statistics.

Thanks

Nick Wray
	[[alternative HTML version deleted]]



From n|cho|@@@wr@y @end|ng |rom nt|wor|d@com  Fri Aug 31 16:40:55 2018
From: n|cho|@@@wr@y @end|ng |rom nt|wor|d@com (Nick Wray)
Date: Fri, 31 Aug 2018 15:40:55 +0100 (BST)
Subject: [R] Resetting bin size in histogram having already changed to
 relative frequencies
Message-ID: <1389669594.915788.1535726455670@mail2.virginmedia.com>

Hello again.  I am trying to alter the bin size on a histogram where I have reset the vertical axis to relative frequency, rather than absolute.  Beneath is a simple example (not my real data) of this:

xvals<-rnorm(1000,0,1)
xvals
hist(xvals)
h<-hist(xvals,plot=F)

h
h$counts
h$counts<-h$counts/sum(h$counts)
h$counts
plot(h,freq=T,ylab="Relative Frequency")


This gives me a plot with bin sizes of 0.5 and the relative frequency, but I cannot reset the bin size as well.  I don't know whether the only way to do it is to reset all the h$mids etc as well but this seems horrendously complicated and I wonder whether I am missing something simple

Any ideas I would be thankful for   Nick Wray

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 31 16:48:52 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 31 Aug 2018 07:48:52 -0700
Subject: [R] Resetting bin size in histogram having already changed to
 relative frequencies
In-Reply-To: <1389669594.915788.1535726455670@mail2.virginmedia.com>
References: <1389669594.915788.1535726455670@mail2.virginmedia.com>
Message-ID: <CAGxFJbQNSxnSzy3SNWuQnw6UJS8-pRvxA_WX-K7AKBLb+=PJPg@mail.gmail.com>

Consult the docs, please. ?hist and the "breaks" argument. Also note the
"freq" argument, which means you should not be computing relative
frequencies manually.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 31, 2018 at 7:42 AM Nick Wray via R-help <r-help at r-project.org>
wrote:

> Hello again.  I am trying to alter the bin size on a histogram where I
> have reset the vertical axis to relative frequency, rather than absolute.
> Beneath is a simple example (not my real data) of this:
>
> xvals<-rnorm(1000,0,1)
> xvals
> hist(xvals)
> h<-hist(xvals,plot=F)
>
> h
> h$counts
> h$counts<-h$counts/sum(h$counts)
> h$counts
> plot(h,freq=T,ylab="Relative Frequency")
>
>
> This gives me a plot with bin sizes of 0.5 and the relative frequency, but
> I cannot reset the bin size as well.  I don't know whether the only way to
> do it is to reset all the h$mids etc as well but this seems horrendously
> complicated and I wonder whether I am missing something simple
>
> Any ideas I would be thankful for   Nick Wray
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Fri Aug 31 17:12:20 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 31 Aug 2018 08:12:20 -0700
Subject: [R] TCGA biolinks, DNA methylation
In-Reply-To: <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
References: <CAPQaxLN478eMicym7Cm7v++Ypfq4A7wF6XCVBkmO1trKtkDJqQ@mail.gmail.com>
 <CAP8zaQBSyx=uNAjH0BsX5zWkOoGV1g6yVe3aassJ0MFxj5zVgA@mail.gmail.com>
 <CAPQaxLN4Ji3rn9EF_2mKT1Z2-UY5Tx4M+3GNY4J-Ou-hMte_bg@mail.gmail.com>
 <CAPMtxSisrfmnMM79yT_XdvJXYdHUs6nyxw-_-CJ6rPZUpVhLpA@mail.gmail.com>
 <CAPQaxLOHTskYcm_DJBWP71zWu3aNv5G9u-cSbcFhcs697ZNpzg@mail.gmail.com>
Message-ID: <CAF8bMcbCFbVbdgDbqbisyKZ+fYnBmW8ybSQD4mMym8Rgaa_9qg@mail.gmail.com>

Try adding fileEncoding="UTF-16" to your read.csv() call.  Many Windows
programs write UTF-16 files by default.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Aug 30, 2018 at 6:05 PM, Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> My apologies... the following is what I received from the correction
>
>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep=",")
> Warning messages:
> 1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   line 3 appears to contain embedded nulls
> 2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   line 4 appears to contain embedded nulls
> 3: In read.table(file = file, header = header, sep = sep, quote = quote,  :
>   line 5 appears to contain embedded nulls
> 4: In scan(file = file, what = what, sep = sep, quote = quote, dec = dec,
> :
>   embedded nul(s) found in input
> >
>
>
> On Thu, Aug 30, 2018 at 8:57 PM Patrick Barry <pdbarry at alaska.edu> wrote:
>
> > You still haven't fixed the first thing both Sarah and I pointed out. You
> > are lacking an = between sep and ","
> >
> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
> >
> > should be
> >
> > the_data <- read.csv(file = "GBM_clinical_drug.csv", header = TRUE, *sep
> > = ","*)
> >
> > as Sarah pointed out, you should use spaces to help make these errors
> more
> > obvious.
> >
> > On Thu, Aug 30, 2018 at 4:53 PM, Spencer Brackett <
> > spbrackett20 at saintjosephhs.com> wrote:
> >
> >> Hello again,
> >>
> >> My apologies for the delayed response... computer troubles. In reference
> >> to
> >> Ms. Goslee's and Mr. Barry's query, the following is the error code
> >> received after I inputted my R command
> >>
> >>  the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",")
> >> Error: unexpected string constant in
> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=TRUE,sep",""
> >>
> >> Given this, should I proceed with implementing the path<getwd() ,since I
> >> am, as he suggested trying to set the variable *path* to my working
> >> directory with path<-"."
> >>
> >> Mr. Mittal also recommended importing with r studio, which I shall try
> in
> >> the meantime.
> >>
> >> Many thanks,
> >>
> >> Spencer Brackett
> >>
> >>
> >> On Wed, Aug 29, 2018 at 10:14 PM Amit Mittal <
> prof.amit.mittal at gmail.com>
> >> wrote:
> >>
> >> > Use r studio and import from the menu. Read_csv has changed
> >> >
> >> > Also you can see any format problems
> >> >
> >> > On Thu, 30 Aug 2018 3:36 am Spencer Brackett, <
> >> > spbrackett20 at saintjosephhs.com> wrote:
> >> >
> >> >> Good evening R users,
> >> >>
> >> >>   I am attempting to carry out DNA methylation analysis on two
> separate
> >> >> CSV
> >> >> files (LGG and GBM), which I have downloaded onto my R console. To
> set
> >> the
> >> >> path<-"." to be indicative of one or both of the csv files, I
> utilized
> >> the
> >> >> following functions and received the errors shown. How do I set the
> >> "." so
> >> >> that I can begin analysis on my files?
> >> >>
> >> >> > the_data <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",")
> >> >> Error: unexpected string constant in "the_data
> >> >> <-read.csv(file="LGG_clinical_drug.csv",header=T,sep",""
> >> >> > the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",")
> >> >> Error: unexpected string constant in
> >> >> "the_data<-read.csv(file="GBM_clinical_drug.csv",header=T,sep",""
> >> >>
> >> >> This is the preliminary portion of the analysis I am trying to run,
> >> which
> >> >> I
> >> >> am referring to:
> >> >>
> >> >> 1 library(TCGAbiolinks)
> >> >> 2
> >> >> 3 # Download the DNA methylation data: HumanMethylation450 LGG and
> GBM.
> >> >> 4 path <? "."
> >> >> 5
> >> >> 6 query.met <? TCGAquery(tumor = c("LGG","GBM"),"
> HumanMethylation450",
> >> >> level = 3)
> >> >> 7 TCGAdownload(query.met, path = path )
> >> >> 8 met <? TCGAprepare(query = query.met,dir = path,
> >> >> 9                      add.subtype = TRUE, add.clinical = TRUE,
> >> >> 10                    summarizedExperiment = TRUE,
> >> >> 11                      save = TRUE, filename = "lgg_gbm_met.rda")
> >> >> 12
> >> >> 13 # Download the expression data: IlluminaHiSeq_RNASeqV2 LGG and
> GBM.
> >> >> 14 query.exp <? TCGAquery(tumor = c("lgg","gbm"), platform =
> >> >> "IlluminaHiSeq_
> >> >> RNASeqV2",level = 3)
> >> >> 15
> >> >> 16 TCGAdownload(query.exp,path = path, type = "rsem.genes.normalized_
> >> >> results")
> >> >> 17
> >> >> 18 exp <? TCGAprepare(query = query.exp, dir = path,
> >> >> 19                    summarizedExperiment = TRUE,
> >> >> 20                      add.subtype = TRUE, add.clinical = TRUE,
> >> >> 21                    type = "rsem.genes.normalized_results",
> >> >> 22                      save = T,filename = "lgg_gbm_exp.rda")
> >> >>
> >> >> Many thanks,
> >> >>
> >> >> Spencer Brackett
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



